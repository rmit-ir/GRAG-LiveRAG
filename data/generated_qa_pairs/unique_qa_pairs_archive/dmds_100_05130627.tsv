qid	question	answer	context	document_ids	question_factuality	question_premise	question_phrasing	question_linguistic_variation	question_multi-doc	user_expertise-categorization	generation_timestamp	question_length	answer_length	context_length
1	space telescopes seeing far stars difference between wise infrared and james webb purpose comparing both	While both WISE and James Webb Space Telescope observe in infrared wavelengths, they serve different primary purposes. WISE maps the entire sky in far-infrared, particularly excelling at detecting cold objects like dust clouds and star-forming regions such as the LBN 114 nebula. It observes at wavelengths of 3.6 to 22 microns and is especially good at seeing warm interstellar dust and complex organic molecules. The James Webb telescope, as the flagship mission of the 2010s, has a different primary purpose - it will teach us about how the Universe grew up and what the very first stars and galaxies were like. While both observe in infrared, they are optimized for different scientific goals and complement each other rather than compete.	"[""One of my favorite space missions is WISE: the Wide-field Infrared Survey Explorer, which mapped the entire sky in the far-infrared, well outside what our mere human eyes can see. At those wavelengths, objects we'd consider to be frigidly cold glow brightly. Those include clouds of dust and gas surrounding freshly-born stars, like the nebula called LBN 114.55 + 00.22:\nYou can see why I like WISE so much; the images it sent to Earth were spectacular! [Click to embiggen.] LBN 114 (for short) is a classic star-forming region. About 30 light years in diameter, it’s a dense clot of gas and dust, and in its core it’s busily churning out new stars. Some of these are massive, hot, blue stars, which blast ultraviolet light and also blow out a gale of subatomic particles, like the solar wind but far faster and stronger. The light and winds from these stars eats away at the inside of the cloud, carving a cavity in it.\nYou can actually see that in this image; the center of the nebula is dimmer, where the gas and dust have been pushed away. The overall effect makes LBN 114 look like a vast flower in space—though one that’s 300 trillion kilometers across.\nYou may have noticed the central part of the nebula is red. Why would that be if the stars lighting it up are blue? There’s more than one reason, but first, remember this is an infrared picture. What you see as red is actually way out in the infrared, at a wavelength of 22 microns (compare that to the reddest light the eye can see, at about 0.7 microns). Green is 12 microns, cyan is 4.6, and blue is 3.6 microns. As a rule of thumb, the cooler an object is, the redder the light it emits. So in WISE images the warmest objects are blue, and the coolest red.\nStar birth regions like LBN 114 are choked with complex organic molecules called polycyclic aromatic hydrocarbons, or PAHs. Think of it as soot, which is pretty close to what it is! Warm interstellar dust tends to glow very strongly at around 12 microns, which is why you see so much frilly green material in images like this. Cooler dust emits at 22 microns, so it looks red in WISE images. You might expect that near the hot stars the dust would be even warmer, but things can get complicated. For example, some dust is laden with metals like magnesium and silicon, which help the dust cool off. This is pretty commonly seen in WISE images of objects like this (such as the Lambda Centauri Nebula, and the dust surrounding the star CY Camelopardalis—click those for more beautiful WISE images).\nAs an aside, the bright star in the picture is called HIP 117078, a massive red supergiant near the end of its life. It’s a long way off, 18,000 light years or so, three times farther than LBN 114. One day it’ll explode, but probably not for a long time…and it’s too far away to hurt us here on Earth.\nAs you can see, this whole region of space is thick with dust, which absorbs visible light pretty well. There’s a lot of gas in this nebula, which glows strongly in visible light. However, in visible light this nebula is pretty faint when seen from Earth because all that dust in the way sucks down the light. At its distance of 6000 light years, LBN 114 is about half the size of the full Moon on the sky, yet it’s a relatively obscure object (I couldn’t find much in the professional journals about it). If there were no dust in the way, it might be visible to the naked eye on a dark night.\nAnd this is why we build observatories like WISE: to show us what we otherwise could not see. How can we possibly understand what’s going in the Universe around us if we’re missing pieces of the puzzle? I wish we had a dozen observatories like WISE peering into the dark…because at some wavelengths, the Universe isn’t so dark. And we might not otherwise know.\nImage credit: NASA/JPL-Caltech/WISE Team"", 'In order to reap the greatest rewards, we have to think big and invest big. One of these four missions will deliver like never before.\nWhen it comes to exploring the Universe and understanding what it’s made of, how it came to be, and what its ultimate fate is, no observatory has taught us more than the Hubble Space Telescope. It was the first flagship mission for NASA Astrophysics, the most revolutionary class of missions that NASA invests in of any type. What we’ve gained, both scientifically and in terms of human perspective, is immeasurable.\nAt the same time that the President’s budget threatens to terminate an upcoming flagship mission, the final selection for NASA Astrophysics’ flagship mission of the 2030s is imminent. Over the next few months, the four proposals will be ranked according to the recommendations of the National Resource Council. Any one of the four would be a worthy choice, but they all deserve a chance to fly. Here’s what the possibility means to all of us.\nAlthough we don’t really think of it that way, the Hubble Space Telescope was extremely controversial at the outset. Although it’s rarely discussed, the plans to build and launch Hubble as the world’s first major astronomical observatory in space were met with much resistance, as it would be the most expensive science mission ever put together to date.\nIn terms of initial cost, Hubble was the single most expensive mission in the history of astrophysics, costing $5 billion before it was ever successfully deployed. Over its lifetime, including continued operations, maintenance, and four servicing missions, it’s cost humanity between $15-$20 billion. Yet when we look back, 29 years later, at what Hubble has revealed to us, what we know is so different from what we ever anticipated.\nOriginally designed with the primary purpose of measuring the expansion rate of the Universe — the Hubble constant, hence the name — its greatest discoveries were entirely unexpected. As a direct result of Hubble, we not only successfully measured the expanding Universe to better precision than ever before, we:\n- discovered the earliest, most distant galaxies ever seen,\n- learned how galaxies evolved and grew up,\n- found four new moons of Pluto,\n- took the first direct image of a planet outside of our own Solar System,\n- and even measured how much time has passed since the hot Big Bang.\nThat’s just a tiny sample of the thousands of discoveries that Hubble has brought to our world. More scientific papers have been published using Hubble’s data than from any scientific instrument in history.\nThe science gains from a flagship mission in Astrophysics — what Thomas Zurbuchen of NASA calls “civilization-class science” — are unparalleled. By building a powerful observatory that’s optimized to measure the Universe with a better combination of resolution and light-gathering power across a particular set of wavelengths, it can accomplish scientific goals that no other mission can. By also building in a suite of state-of-the-art instruments, it becomes extraordinarily versatile and adaptable, able to measure aspects of the Universe and objects within it that we don’t even know about at the time of its launch.\nIt’s hard to imagine a grander goal for humanity than understanding the greatest mysteries of our Universe, and learning what the implications are for us and our place within it. Yet that is what these flagship missions — and only our flagship missions — can do. If I had to summarize our three most important (and, not coincidentally, most expensive) flagship astrophysics missions, it would be as follows:\n- Hubble, our flagship of the 1990s, showed us what our Universe looks like.\n- For the 2000s, we launched a suite of moderate-budget observatories across a variety of wavelengths, including Spitzer (in the infrared) and Chandra (in the X-ray).\n- James Webb, the flagship of the 2010s, will teach us how our Universe grew up, and what the very first stars and galaxies were like.\n- WFIRST, the flagship for the 2020s, will reveal to us our Universe’s ultimate fate, and explore Earth-like worlds beyond our Solar System as never before.\nIn just a few months, the National Resource Council, a branch of the National Academies of Science, will select which grand plan we’ll shoot for, as a civilization, for astronomy in the 2030s. To uncover the answers to the greatest open questions about our Universe today, we need to build observatories that are up to the technological challenges that pushing past the current frontiers in astronomy demands.\nThe cutting-edge teams who’ve submitted proposals have banded together to identify four huge ways that we can expand our knowledge of the Universe in a profound way. They cover the following four fields:\n- exoplanet science (the HabEx mission),\n- X-ray astronomy (the Lynx mission),\n- infrared astronomy (the OST mission),\n- and optical astronomy (the LUVOIR mission).\nAll four of these proposed missions are the result of dreaming big, and each one will showcase what astronomy missions, if we truly invest in them, are capable of teaching us.\nThe Habitable Exoplanets Observatory (HabEx). The ultimate goal of HabEx is simple: to directly image Earth-like planets around other Sun-like stars. While other observatories will detect such worlds indirectly, or image larger planets farther away from smaller stars, HabEx plans to fill that ultimate of niches: imaging a world like our own around a star like our own. A space-based optical telescope with a 4-meter diameter, combined with a starshade, will enable this great leap forward for astronomy.\nIts instruments will enable us to characterize the atmospheres of Earth-like and non-Earth-like worlds, seeking signs of water, oxygen, ozone, and other molecules that may be true signatures of life on that world. It will also be of good use as a general astronomical observatory, similar to an upgraded version of what Hubble is today.\nThe biggest downside for HabEx is that it’s inferior in nearly every way to LUVOIR, while only representing a marginal upgrade over WFIRST for general astronomy.\nLynx X-ray Observatory. Right now, our best windows on the high-energy Universe are observatories like NASA’s Chandra, which is already 20 years old today. In order to build a better X-ray observatory, you need to improve four different technologies:\n- The optical assembly, which provides you with resolution, sensitivity, and field-of-view.\n- A calorimeter, which allows you to determine the energy of each incoming X-ray over a particular energy range.\n- A high-definition imager, which allows you to cover a large field-of-view with a high imaging frame rate, ideal for imaging rapidly changing or transient sources.\n- And a grating spectrometer, which enables you to detect the signatures and locations of elements like carbon, iron, and oxygen at high resolutions.\nWhile Chandra only has the same resolving power as an 8″ (0.20 meter) telescope, Lynx will really take a great leap beyond, with sensitivity that’s greater by a factor of 50-to-100, depending on the energy of the X-rays, and sixteen times the field of view.\nThe greatest strike against Lynx is the presence of the European Space Agency’s Athena, which will have a similar field-of-view but less sensitivity. Lynx, as proposed, will have 10 times the imaging resolution and better spectroscopic power for low-energy X-rays, crucial for identifying the astronomical signal of ionized oxygen.\nOrigins Space Telescope (OST). While the James Webb Space Telescope will probe a portion of the infrared spectrum — the near-IR and the mid-IR — the only far-IR observatory ever launched by NASA was Spitzer, which is already 16 years out of date and operating beyond its safety capabilities.\nDesigned with a 5.9-meter primary mirror and with instruments operating at liquid helium (4 K) temperatures, it will reach sensitivities over 1,000 times greater than Herschel or SOFIA, which are the only observatories to cover the same wavelengths, spectroscopically, as OST. Equipped with 5 separate science instruments, it will investigate the growth of black holes and galaxies, the formation of planets and solar systems, the abundances and growth of heavy elements and dust in the Universe, and identify the ingredients of life throughout the cosmos.\nAlthough there are no NASA or ESA counterparts truly competing with OST, its great drawback is its partial overlap with the James Webb Space Telescope (at short wavelengths) and the ground-based ALMA (at long wavelengths). But it will still explore a large wavelength range (from 30–300 microns) that no other mission, existing or even proposed, can match.\nThe Large Ultraviolet Optical and Infrared telescope (LUVOIR). This is the big dream: the ultimate successor to Hubble. It is proposed to have a diameter of a whopping 15 meters, giving it 40 times the light-gathering power of Hubble and unprecedentedly high resolution. If you were to put the Milky Way galaxy anywhere within the observable Universe, not only would LUVOIR see it, it would be able to resolve it into more than 100 pixels across no matter where it were located.\nLUVOIR will be capable of performing such scientific tasks as:\n- directly imaging geysers and volcanic eruptions on the moons of Jupiter and Saturn,\n- directly imaging any Earth-like planets within about 100 light-years of Earth,\n- measure individual stars in galaxies up to 300 million light-years away,\n- characterizing the types of stars in every galaxy in the Universe, including billions that are too faint, small, or distant for Hubble to see,\n- to map out the gas surrounding each and every galaxy, including both absorption and (hitherto elusive) emission features,\n- and to measure the dark matter profiles, such as from rotation curves, of any galaxy at all.\nIn terms of ambition, LUVOIR outclasses all of these missions. But the final price tag is LUVOIR’s biggest drawback. Unless we convince the US government to increase its funding and commit somewhere around $20 billion to build this transformative observatory, we’ll have to settle for much less.\nChoosing which of these missions to build and fly will, in many ways, inform our plans for the next 30 years (or more) of astronomy. NASA is the pre-eminent space agency in the world. This is where science, research, development, discovery, and innovation all come together. The spinoff technologies alone justify the investment, but that’s not why we do it. We are here to discover the Universe. We are here to learn all that we can about the cosmos and our place within it. We are here to find out what the Universe looks like and how it came to be the way it is today.\nPeople will always argue over budgets — the penny-pinchers are always happy to propose something that’s faster, cheaper, and worse — but the reality is this: the budget for NASA Astrophysics as a whole is just $1.35 billion per year: less than 0.1% of the federal discretionary budget and less than 0.03% of the total federal budget. And still, for that tiny amount, NASA has steadily built a flagship program that’s the envy of the free world.\nIn an ideal society, we wouldn’t have to choose between these four diverse mission in exploring all there is that’s out there. We wouldn’t have to worry about being forced to settle for scaled-down versions of these missions. We would value discovery and exploration of the unknown — and peeling back the veil of our cosmic ignorance — more than we valued getting a limited amount of surefire science for the smallest possible investment. If we choose to make a greater investment, we could explore the Universe in ways we only dream of today.\nBut even if we don’t, there’s a revolutionary observatory on the horizon. One of these four candidates, a little over a decade from now, will show us the Universe beyond our presently-known frontiers. For any of them, the greatest discoveries may well be something we cannot even conceive of today; the way we make unexpected progress is by looking as we never have before. Whichever one comes to fruition, we will be explorers in uncharted territory. The Universe awaits our choice.\nStarts With A Bang is now on Forbes, and republished on Medium thanks to our Patreon supporters. Ethan has authored two books, Beyond The Galaxy, and Treknology: The Science of Star Trek from Tricorders to Warp Drive.']"	['<urn:uuid:892a8f72-118f-4422-b361-ef3c1803c7e6>', '<urn:uuid:1f25a44d-7af6-4090-89e2-ec596998a786>']	open-ended	with-premise	long-search-query	distant-from-document	comparison	novice	2025-05-13T06:27:57.068978	15	120	2738
2	What are the physical characteristics of the Piping Plover, and what specific beach habitats does it rely on for its survival in South Texas?	The Piping Plover is a small, stocky shorebird about 7 1/4 inches long with a 15-inch wingspan. It has sandy-colored feathers with grayish-brown crowns and backs, white foreheads, and dark bands across their crowns. They have yellow-orange legs, incomplete dark rings around their necks, and black bands across their foreheads from eye to eye. As for their habitat in South Texas, they primarily occupy beaches, bays, and lagoons during non-breeding season from July through May. They spend most time foraging and resting on mudflats, sandflats, or algal flats in back bays, and move to beaches during high tides.	"[""South Texas Wildlife Management\nThe South Texas Brushlands are better known for its large ranches and deer, but it also supports a very diverse assemblage of habitats supporting many nongame species. The high number of unique species occurring within the region are in part due to the southern location of the region being quite different than the rest of Texas, but also to the unique habitats like Tamaulipan floodplain forest which reach the limits of their range in southern Texas. Among nongame species in South Texas using this diverse assemblage of habitats there are a number of federally listed threatened and endangered species which include: mammals such as ocelots and jaguarundis, and ; birds like brown pelican, whooping crane, bald eagle, northern aplomado falcon, piping plover, least tern (inland breeding populations); plants such as black lace cactus, star cactus, Walker's manioc, Johnston's frankenia, Texas ayenia, South Texas ambrosia, ashy dogweed, slender rush-pea. Other federally listed species occur in some of the habitats at the edge of the South Texas Brushland ecosystem are not in this report and can be found in the Texas Parks and Wildlife Department Nature/Endangered Resources web pages.\nHabitats in the region range from classic hill country cedar brakes, riparian woodlands and grasslands at the edge of the northwestern counties. Remnant tracts of coastal prairie occur in the east. Oak-prairie dominates northeastern counties, and liveoak mottes associated with grasslands do the same in Brooks, Kenedy & Kleberg Counties. Mixed brush grasslands dominated by mesquite occur throughout most of the ranchland. Tamaulipan scrub forest grow along the Rio Grande River, and major areas of intense agriculture are managed in the Lower Rio Grande Valley, near Corpus Christi and Uvalde. Ash/elm/hackberry forests occur along the few creeks and rivers along with some pecan groves along the San Antonio River. Beaches and hyper-saline lagunas dominate the edge of the Gulf of Mexico.\nLoss of native habitat and reduction in quality of the remaining plant communities is the primary reason for declining populations of most species: game, nongame, and federally listed threatened and endangered. Natural occurring fire as an ecological force which formally helped mold the native grassland and brushland habitats has essentially disappeared with only a few landowners currently using it as a management tool. Agriculture and urban sprawl has occupied large areas of some of the most productive habitats in the region. Use of heavy machinery (root plowing, cabling, chaining, roller chopping, and rome disking to reduce brush for livestock grazing and subsequent seeding of the range with introduced grasses, like bufflegrass, has greatly modified the plant species composition of native habitats and reduced the quality of the land for wildlife.\nThe classic endangered mammal of the South Texas Brush Country that has been greatly impacted by brushland management is the ocelot. This species is a rare, colorful, spotted cat that once occurred throughout South Texas, the southern Edwards Plateau Region, and along the Coastal Plain, but now is restricted to the southernmost 13 counties of the state because of loss of habitat. This species occurs in dense thorny shrublands of the Lower Rio Grande Valley and Rio Grande Plains. Typical habitat consists of mixed brush species with an interspersion of trees. Optimal habitat has at least 95 percent canopy cover of shrubs, whereas marginal habitat has 75 to 95 percent canopy cover. Preferred shrub density is where depth of vision from outside the brush line is restricted to about five feet. Tracts of at least 100 acres of isolated dense brush, or 75 acres of brush interconnected with other habitat tracts by brush corridors, are considered very important. These habitat settings are very rare in the region and is the main reason for low numbers of this species.\nAn endangered bird which depends heavily on South Texas beaches and lagunas for its survival is the Piping Plover. This species is a small, stocky, sand-colored plover with orange legs that occupies Texas beaches, bays and lagoons during the non-breeding season which runs from July through May. The birds spends most of its time foraging and resting on mudflats, sandflats or algal flats in the back bays and retreats to the beaches during high tides. Major threats to the species in Texas are disturbance and development along the beaches as well as chemical spills from the petroleum industry within the bay/laguna systems and the Gulf of Mexico."", 'Piping Plover (Charadrius melodus)\n- Texas Status\n- U.S. Status\n- Threatened, Listed 1/10/1986\n- The piping plover is a small shore bird, about 7 1/4 inches long with a 15 inch wingspan. Distinguishing characteristics include sandy-colored feathers with grayish-brown crowns and backs, white foreheads, and dark bands across their crowns. Dark, but incomplete rings encircle their necks. These little birds have yellow-orange legs, black bands across their foreheads from eye to eye, and black rings around the base of their necks. They are small, stocky, sandy-colored birds that resemble sandpipers, with short, stubby bills.\n- Life History\n- Piping plovers reach sexual maturity at one year, and mate from late March through April. Males compete against each other for females\' attention. They perform elaborate flights, and then scrape nests in the sand, tossing shells and small stones and twigs into them with their beaks. To create a nest, they scrape a shallow depression in the sand about 1 by 2.5 inches (2.5 by 6 cm). After their nests are built, they stand beside them with their wings partially spread and tails fanned. The males repeat this behavior until a female indicates interest. Once he has her attention, he begins a high-stepping ""dance,"" continuing the courtship ritual. Females will lay about four gray to pale sand-colored eggs with a few dark spots. After an incubation period of 25 days, the young hatch within four to eight hours of each other, and fledge 30 to 35 days later. Although both sexes share responsibility for incubating the eggs, females commonly leave the young when the hatchlings are 14 to 20 days old. Males often remain with them until they can fly.\nThe chicks can move freely from their nests within hours of drying off. When predators or intruders come close, the young squat motionless on the sand while the parents attempt to attract the attention of the intruders to themselves, often by feigning a broken wing. Gulls, crows, raccoons, foxes and skunks are threats to the eggs and falcons may prey on the adult birds. The young plovers and adult plovers generally return to the same nesting area year after year. Plovers often run short distances, pausing to stare at the ground with a slightly tilted head, before picking a food item from the sand. When not feeding, plovers rest and preen.\nThere are just over 5,000 known pairs of breeding piping plovers. Texas is the wintering home for 35 percent of the known population of piping plovers. They begin arriving in late July or early August, and will remain for up to nine months. The piping plover\'s diet includes marine worms, beetles, spiders, crustaceans, mollusks and other small marine animals. Their life span is less than five years, but on occasion, up to 14 years.\n- These shorebirds live on sandy beaches and lakeshores.\n- Piping plovers migrate through the Great Lakes along the river systems through the Bahamas and West Indies. They are currently found along the Atlantic Coast from Canada to North Carolina and along the shorelines of Lakes Michigan and Superior. Gulf Coast beaches from Florida to Mexico, and Atlantic coast beaches from Florida to North Carolina provide winter homes for plovers.\n- Threats and Reasons for Decline\n- Habitat alteration and destruction are the primary causes for the decline of the Piping Plover. Loss of sandy beaches and lakeshores due to recreational, residential, and commercial\ndevelopment has reduced available habitat on the Great Lakes, Atlantic Coast, and the Gulf of Mexico. Reservoir construction, channel excavation, and modification of river flows have eliminated sandbar nesting habitat along hundreds of miles of the Missouri\nand Platte Rivers. Winter habitats along the Gulf coast are\nthreatened by industrial and urban expansion and maintenance activities for commercial waterways. Pollution from spills of petrochemical products and other hazardous materials is also\nOn the breeding grounds, reproductive success can be curtailed by human disturbance. Vehicular and foot traffic destroys eggs and chicks. The presence of people on beaches and sandbar islands inhibits incubation and other breeding behavior. Changes in land use such as agricultural development, urbanization, and use of beaches has brought an increase in the number of unleashed pets and other predators such as gulls, skunks, and foxes.\nIncreased recreational use of Gulf beaches may also threaten the quality of wintering sites. Beach traffic, including vehicles and ATV\'s, as well as the activities of unleashed dogs, can disturb birds and degrade habitat. Beach raking, a practice associated with high recreational use, removes driftwood, seaweed, and other debris used by roosting plovers, and may disrupt nutrient cycles and remove prey organisms from foraging areas where plovers forage on the beach.\nIn 2001, the total population of Piping Plovers in North America was estimated to be 5,945 breeding adults. The Texas Gulf Coast had the highest wintering population, with about 1,042 individuals detected. This represents about 44% of birds detected on the wintering grounds during the 2001 International Piping Plover Census. Most of the plovers that winter on the Texas coast are found in the lower Laguna Madre, where tidal flats are extensive and productive. It is up to Texans to insure that the wintering habitat so vital to the survival of this species is protected.\n- Ongoing Recovery\n- State, federal, and private organizations are collaborating to monitor Piping Plover populations and assess current and potential habitat on breeding and wintering grounds. Research concerning reproductive success, food habits, habitat selection, and limiting factors is underway. The results of these studies will help biologists\ndevelop management plans designed to benefit Piping Plovers.\nProtective measures, such as signs or fences, are being implemented to reduce human disturbance to breeding birds. Vegetation management, predator control, pollution abatement,\nand habitat creation/restoration are management strategies being used to benefit Piping Plover populations. Biologists continue to assess habitat availability and quality throughout the plover\'s range in Texas, and identify essential habitat for management and protection. Finally, public information campaigns concerning Piping\nPlover conservation are a vital part of the recovery process.\nCritical habitat was designated for wintering Piping Plovers in July of 2001. This designation identifies areas that are important to the plovers on their wintering grounds, and provides the public and resource agencies with information that can be used to minimize impacts to these areas.\n- How You Can Help\n- Whether you enjoy fishing, boating, swimming, or viewing wildlife, please remember that your actions, especially when multiplied by thousands of other recreational users, can have an immense impact on the bays and estuaries of the Texas Coast. Responsible\nrecreational use should include proper disposal of trash and other\npotential pollutants, respect for private property rights, preventing harm to plants and wildlife, and generally keeping human impacts to a minimum. Minimize driving on the beach and keep pets on a leash. Extensive driving on tidal flats on the bayside of barrier islands should also be minimized, as significant rutting can alter\nthe habitat required by these birds. Avoid disturbance to foraging shorebirds to the greatest extent possible.\nYou can be involved in the conservation of Texas\' nongame wildlife resources by supporting the Special Nongame and Endangered Species Conservation Fund. Special nongame stamps are available at Texas Parks and Wildlife Department (TPWD) field offices, most state parks, and the License Branch of TPWD headquarters in Austin. Conservation organizations in Texas also welcome your participation and support.']"	['<urn:uuid:bf4fe9a2-4ec9-4717-8cc1-102a788392d1>', '<urn:uuid:79882e0a-261d-4df6-8b57-c0222a37a139>']	open-ended	direct	verbose-and-natural	similar-to-document	multi-aspect	expert	2025-05-13T06:27:57.068978	24	98	1954
3	hey I want to start a website what is the most important thing search engines look at to find my site	The most important thing for search engines is the words on your site. Search engines can only discover and crawl your site through its text content - they cannot see graphics, videos, maps, social media links, or other elements. They can only see the words, which is why regularly updating and evaluating your site's copy is crucial. This makes your site's copy the first and most important step towards good SEO (Search Engine Optimization).	['Last week, we discussed what SEO copywriting is and why you should write for your readers first, not search engines.\nPatterning your writing after the reader-focused methods we discussed is a big part of SEO copywriting, but it doesn’t quite take your SEO efforts far enough. This week, we’ll look at the final steps for optimizing your page’s copy.\nRemember, these tips aren’t the end-all, be-all for SEO. There are many additional SEO strategies that don’t involve your site’s copy. (Perhaps we’ll cover those in an another post.)\nSo why focus on copy?\nThe reason we’re focusing solely on copy is that it’s the first, most important step towards good SEO. Why? Because the only way search engines can discover and crawl your site is through the words on it. They don’t come to your site based on its graphics, videos, maps, social media links, or anything else. They can only see the words. That’s why regularly reevaluating and updating the copy on your site is so important.\nOnce you’re satisfied with your site’s copy says, it’s time to touch it up, so it can be found more easily. Here are the main areas to focus on:\nYour keyword research likely happened before you even wrote anything, so you already know which words, phrases, and synonyms are good to use.\nNow it’s time to make sure they’re in all the right places. In your main content, they should be used carefully and naturally. To make sure you didn’t overuse them, paste your copy into this SEO tool to measure your keyword density.\nTo give you a frame of reference, Yoast recommends that your keyword density be between 0.5% and 2.5%. Anything much higher than that could get you penalized.\nYour keywords should be found in a few other places too, such as:\n- Your URL\n- Page title/ Title tag\n- Post title\n- Meta description\n- Image tags\nWe’ll cover a few of these in more detail below, because they’re important for SEO copywriting in more ways than one.\nWhile writing this post, I searched Google for “seo copywriting.” Here’s what the first three results looked like.\nThe titles in blue are their sites’ title tags. Notice they all hold the exact search term I typed. The titles also give a clear indication of what will be on their pages.\nWhen I clicked Copyblogger’s link, the heading of their page actually looked like this:\nThe page itself didn’t say “SEO Copywriting Tips, Secrets, and Strategies,” like the search result. Why did they create a unique title tag? Because they wanted me to see a more specific title than “SEO Copywriting Made Simple.” They wanted me to know exactly what to anticipate from their page.\nYou can do the same thing. Remember, users only know what your search result tells them. If you want them to click through, your title needs to be specific and compelling.\nAlso notice that Neil Patel’s title is longer than what’s actually displayed. If you want your whole title to show, Moz recommends that you keep it between 50-60 characters. They also have a handy preview tool you can use for free to see what your title tag will look like.\nTo learn how to customize your title tags (instead of letting Google fill it in with default text), read Neil Patel’s article How to Create Search Engine Friendly Title Tags.\nLet’s look at my screenshot again.\nNotice the small descriptions beneath the title tag and URL? Those are the meta descriptions.\nOnce again, users only know what your search result tells them. So this little description is a super valuable resource for convincing users to click your link.\nSee how a couple words are bold in each meta in my screenshot? They’re bold to show me they are exact matches with my search terms and are probably most relevant to my needs. So always include your keywords in your metas.\nTo have a better chance of the entire meta showing up in the display, Yoast recommends making it no longer than 320 characters.\nIf you don’t customize the meta description, Google will populate it with text from your site, and you’ll miss an opportunity to use clickthrough-focused copy. One helpful way to get more clickthroughs is to include a CTA, like Copyblogger did.\nTo learn how to customize your meta descriptions, read Yoast’s article How to Create the Right Meta Description.\nWe discussed the importance of visuals in our last post about SEO copywriting. But simply including them isn’t enough. While readers enjoy images once they see your page, search engines can’t read what’s on those images and can’t use them to drive more readers to your site.\nHowever, there are two elements about an image that a search engine can read.\n- Alt tags\n- Title tags\nWe already mentioned including a keyword in both of these. This helps your site’s SEO for obvious reasons, but it also helps your image appear in Google’s image search, potentially bringing more traffic to your site.\nWordPress uses the image’s filename as a title tag by default, and if you don’t add an alt tag, it uses the filename there too.\nYou can leave the title tag alone, as long as it uses a keyword. (You may want to get in the habit of naming your images this way as you save them.)\nBut you may want to edit the alt tag to give more explanation. This lets search engines know exactly what is on the image, which is particularly helpful for content-filled images like infographics. With good alt and title tags, you can actually get some SEO juice for all the work you put into that graphic.\nTo learn how to edit alt and title tags, read Yoast’s article about image optimization.\nSearch engines like when you link to other pages in your site. It helps them see how all the pages work together. It also helps users discover more of your site.\nThis strategy is particularly useful if you have a blog. You can link back and forth between your blog and main site pages, as well as between your blog posts. Internal links to your blog give you an easy chance to demonstrate your expertise to your readers.\nWhen you link to other pages in your site, choose which word you place the link in strategically. For example, let’s say I wanted to link to my post about writing hacks inside this post.\nHere’s what I should not say:\nTo make sure your writing is clear and easy to read, check out my post about writing hacks here.\nI linked a post about writing hacks to the word “here.” *Insert face palm* That word gives search engines zero ideas about what content they’ll find at the link.\nTo give the page you’re linking to more credibility with search engines (and more SEO juice, as a result), place the link inside a keyword for that page.\nHere’s what I should say:\nTo make sure your writing is clear and easy to read, check out these writing hacks.\nNow I’ve given that post another link and clearly labeled that page to be about writing hacks. This SEO practice is easy to do and well worth it. Just make sure you’re using internal links naturally—they need to be relevant to what you’re discussing and should be introduced well.\nCategories and Tags\nThese are mainly relevant to sites with lots of internal content, such as articles or products. Blogs, online magazines, and e-commerce sites may use these.\nCategorize your posts or products by topic, then tag them with more specific words. Again, use your keywords, their synonyms and variations, and other relevant words here.\nWhen choosing your categories and tags, think like your readers. If they were trying to learn about the content your post covers, what search terms would they be using? Only use words they would use; not the ones you may want to, such as your brand name or industry jargon words.\nHonest SEO Copywriting: In It for the Long Haul\nIf you write for your readers first (as discussed in our last post) and optimize for search engines second (in the ways we discussed here), your site’s copy will strengthen the credibility and SEO of your site, as well as appeal to your readers.\nEthical SEO copywriting does take time, careful planning, and research, but it won’t come back to bite you like taking shortcuts will. While it does take some time to begin seeing results from your efforts, the more you focus on producing excellent copy and following SEO best practices, the more certain you can be that the results will come. And, just as importantly, the search engine penalties won’t.\nYour readers will appreciate your efforts, trust you more, and be far more prone to convert than if you gave up on quality content and took shortcuts instead.\nTo wrap up, let’s review the SEO copywriting “touch-up” steps:\nTo help you remember all the points we covered in this post and the last one (SEO Copywriting: Why Your readers Should Come First), I created a handy copywriting checklist. Just download the list and either save it to your computer or print and display it to help you remember these points as you write and optimize your content.\nThanks for reading! Which of these tips was most helpful to you?\nIf you missed the first post in this mini series, read it here: SEO Copywriting: Why Your Readers Should Come First.\n*Update: The next (and final) post in this series is live! Read it here: SEO Copywriting: 13 Questions to Ask Before Publishing Your Content.']	['<urn:uuid:93a67ad0-a6d0-438b-8252-8d7d5cfe5aca>']	open-ended	with-premise	long-search-query	distant-from-document	single-doc	novice	2025-05-13T06:27:57.068978	21	74	1613
4	Which focuses more on relationships: project management soft skills or people-centered conflict resolution?	People-centered conflict resolution focuses more on relationships, as it highly values the needs and feelings of those directly involved, while project management soft skills, though interpersonal, include broader aspects like communication, teamwork, and general problem-solving.	"['Project Management Skills are some of the most important skills that you need to possess to be a successful project manager.\nIn addition, it’s good to know there are a variety of project management skills that you will need to master to be successful.\nIn this article, we will take a look at some of the most important project management skills that you need to consider, allowing you to use these in both your personal and professional life.\nWhat are Project Management Skills?\nProject management skills encompass all of the abilities and knowledge needed to plan, execute, and close a project successfully. They include everything from scheduling and budgeting to risk management and stakeholder communications.\nTo be a successful project manager, it is important to have a well-rounded set of skills that can be applied in a variety of situations.\nMoreover, project management skills are not only for project managers. In today’s business environment, many employees are expected to have at least some project management skills.\nWhether you are working on a small team or managing a large organization, these skills will help you to get the job done efficiently and effectively.\nWhy Is it Important To Recognize Project Management Skills & Their Benefits?\nProject management skills are important because they provide individuals with the ability to successfully manage projects from start to finish.\nProject management skills can also help to improve communication and collaboration among team members, as well as increase the overall success rate of projects.\nThe following are some of the key benefits that can be gained from possessing strong project management skills:\n- Increased Efficiency\n- Improved Communication\n- Enhanced Collaboration\n- More Effective Planning\n- Greater Control Over Projects\n- Decreased Risk of Failure\n- Increased ROI\n- More Satisfied Customers\n- More Profitable Projects\n- Stronger Career Prospects\n10 Examples of Project Management Skills\nHere’s a list of project management skills that can help you succeed in any role.\nThe first and most important skill on this list is communication. As a project manager, you need to be able to communicate clearly with your team, clients, and other stakeholders. This means being able to explain complex concepts in simple terms, writing clear and concise emails, and giving effective presentations.\nA good project manager is organized and can keep track of all the different aspects of their project. This includes creating timelines, setting deadlines, and keeping all the different balls they are juggling in the air (at the same time).\nPlanning is a critical component of any successful project. A good project manager will create detailed plans that consider all the different risks and potential problems that could occur. They will also have contingency plans in place in case something does go wrong.\nA project manager needs to be good at time management to keep their project on track. This means being able to prioritize tasks, set deadlines, and make sure everyone on the team is working efficiently.\nProblems will inevitably arise during any project. A good project manager will be able to quickly identify the root cause of the problem and come up with a solution. They will also be able to communicate the problem and solution to the team and other stakeholders effectively.\nA big part of a project manager’s job is making decisions. This could be anything from deciding which vendor to use for a particular service to how to handle a conflict within the team. A good project manager can weigh all the different options and make a decision based on what is best for the project.\nA good project manager knows when to delegate tasks to other members of the team. They will assign tasks based on each person’s strengths and abilities and make sure that everyone has a clear understanding of their role in the project.\nConflicts will inevitably arise during any project. A good project manager will be able to quickly identify the root cause of the conflict and come up with a solution that satisfies all parties involved. They will also be able to effectively communicate the resolution to the team and other stakeholders.\nA good project manager needs to be a strong leader. This means being able to inspire and motivate the team, provide clear direction, and make tough decisions when necessary.\nA successful project requires a team of people working together towards a common goal. A good project manager knows how to get the best out of each member of the team and how to build a cohesive unit that can work effectively together.\nHow To Identify & Master Project Management Skills\nProject management skills are essential for any individual who wants to be successful in managing projects.\nBy definition, project management is the application of knowledge, skills, tools, and techniques to project activities to meet project requirements. To acquire these skills, one must first identify what they are.\nHere’s how to do so.\nUnderstand The Different Types Of Project Management Skills\nThere are many different types of project management skills, and it’s important to understand each one. The most common skill sets include technical skills, interpersonal skills, and organizational skills.\nTechnical skills are those related to the actual implementation of a project. This might include knowledge of specific software or hardware, as well as an understanding of project management methodologies.\nInterpersonal skills are those that help you interact with other people involved in the project. This includes communication and negotiation skills.\nOrganizational skills are those that help you keep the project organized and on track. This might include time management and task prioritization skills.\nAssess Your Own Skill Set\nOnce you understand the different types of project management skills, it’s time to assess your own skill set. Ask yourself which skills you already possess and which ones you need to work on.\nIf you’re not sure where to start, consider taking a project management certification course. This will help you identify your strengths and weaknesses, as well as allow you to learn new skills.\nDevelop a Plan To Improve Your Skills\nOnce you’ve identified the project management skills you need to work on, it’s time to develop a plan to improve them. Knowing where you’re going is key to getting better at anything, and project management is no different.\nPractice, Practice, Practice\nThe best way to improve your project management skills is to practice them. Find opportunities to use your skills in real-world situations. This will not only help you become more proficient in using them, but it will also help you build confidence in your abilities.\nSeek Feedback From Others\nDon’t forget to seek feedback from others. Ask your colleagues, friends, or family members for honest feedback on your performance. This can be an invaluable source of information for identifying areas where you need improvement.\nHow To Improve Project Management Skills in The Workplace\nThe workplace is one of the key places where people learn and develop essential skills. Whether it’s learning how to use a new software program or gaining an understanding of customer service, the workplace is where we build our professional toolkits.\nExpanding further on this, project management skills are needed in nearly every workplace. From small businesses to global enterprises, being able to manage projects effectively is a key ingredient for success.\nConsider the following situations that can help you improve your project management skills in the workplace.\n- You’re in charge of a project that is behind schedule\n- One of your team members is not meeting their deadlines\n- There is a conflict between two team members who are working on the same project\n- Your team is struggling to stay organized and on track\n- You’ve been asked to take on a new project that is outside of your comfort zone\nHow To Highlight Project Management Skills In Resume & Job Interview\nWhen creating a resume or sitting for a job interview, it’s important to be able to show off your project management skills. You want to demonstrate to potential employers that you can successfully lead and oversee projects from start to finish.\nWhen creating your resume, make sure to include any relevant experience you have in managing projects. This can include both paid and volunteer work. Be sure to list specific details about each project you oversaw, such as the size of the team, the budget, and the timeline.\nIn a job interview, be prepared to talk about times when you had to manage a challenging project. This is a great opportunity to showcase your problem-solving skills and how you were able to overcome any obstacles.\nWhen discussing your project management skills, use specific examples and avoid generalities. This will help the interviewer get a better sense of your abilities and how you would be able to handle managing a project at their company.\nWhat is the Main Difference Between Soft & Hard Project Management Skills\nThe main difference between soft and hard project management skills is that soft skills are more interpersonal, while hard skills are more technical.\nSoft skills involve things like communication, teamwork, and problem-solving, while hard skills are focused on specific tasks such as budgeting, scheduling, and engineering. Hard skills are usually easier to quantify and measure than soft skills.\nThere are many debates among project managers about which kind of skills are more important. Some people believe that hard skills are the most essential since they directly contribute to the success of a project.\nOthers argue that soft skills are equally important since they can make or break a team’s ability to work together effectively. Ultimately, the best approach is to focus on developing both types of skills.\nProject Management Skills FAQs\nWhat Are The 3 Critical Skills Of A Project Manager?\n3 critical skills of a project manager include:\n- Being able to effectively communicate with all members of the project team, including those who may have different levels of experience or expertise\n- Being able to create and maintain a detailed project schedule\n- Being able to identify and resolve potential conflicts within the project team\nWhat Skills Do You Need For Project Work?\nTo be successful at project work, it is important to have strong problem-solving skills, as well as be organized and detail-oriented. Additionally, being able to effectively communicate with all members of the team is essential.\nIs Project Management A Hard Skill?\nWhile some people may view project management as a soft skill, it is generally considered to be a hard skill. This is because it requires specific knowledge and experience to be successful. This can be acquired through formal education or training, as well as on-the-job experience.', ""Dealing with conflict\n- Options for conflict management\n- Power and dominance\n- Denial or withdrawal\n- People-centred and task-centred considerations\nCan you remember a trip when some form of conflict took the edge off your enjoyment? You might even remember a trip where a conflict significantly affected the safety of the trip, or led to a serious accident. Understanding how conflict can arise and how to handle it constructively can make your trip more enjoyable and probably safer. Negative outcomes such as a divided group, a poorly resolved navigational disagreement or an outright morale-sapping interpersonal clash are to be avoided if at all possible.\nExperienced leaders have an awareness of potential ‘hot spots’ even before the trip starts. Are there people on the trip who have been involved in conflicts on previous trips? Are there personality combinations which don’t always work well together? Are there potential areas of conflict in the route choice or the challenge of the trip?\nAs the trip progresses be alert for differences and potential problems. Remember, you may be looking at simply managing the process rather than resolving the problem. Particularly on shorter trips, it might be best to simply control the situation for the short term. On longer trips, however, it could be important to at least defuse the situation, and preferably to bring it to resolution. It is also important to remember that the way we might approach conflict on a trip involving friends, who know each other well, may be different to how we would approach a similar situation on a trip with a group who may not see each other again.\nOptions for conflict management\nIf a conflict develops, there are a number of approaches which may be taken in seeking a resolution. The model presented in Figure 54.1 provides an overall description of five conflict management techniques. The discussion below examines the applicability of each in the outdoors, considering the balance between the need to satisfy others’ needs against your own.\nA collaborative approach requires a level of trust and commitment from both sides. This draws each party into an honest examination of both positions, and encourages each side to make an effort to understand the other. The aim is to reach a win/win solution that both sides are happy with—which may be quite different from the initial position of both. Clearly this can be a time-consuming process and may not be possible in some circumstances, such as when there is an emergency or a time pressure, or when one or other party is not prepared to make the effort needed, or even acknowledge that a conflict exists.\nApproach: ‘Let’s talk this through’. ‘Let’s get together and thrash this out’.\nA compromise approach, each party shifting to a middle position, may be deceptively similar to the collaborative approach. However if goodwill is missing, or if one or other party feels that they have given up more than they wanted, then the compromise is more of a win/lose or even a lose/lose outcome. Negotiating a compromise in an atmosphere of mistrust can encourage distortions of the truth, and will not work well where there are ‘either/or’ situations involved.\nApproach: ‘I’ll give a bit – you give a bit, and we’ll meet half way’.\nPower and dominance\nWhen the resolution process becomes a power struggle and a lack of cooperation prevails, then we can finish up with the lose/lose option of power and dominance. The power may come from the set up in the group (such as the leader taking charge) from other forms of manipulation, or a power base evolving from the social dynamics in the group. Voting, while seemingly a democratic form of collaboration if not compromise, may be a form of power-based leadership.\nA resolution such as this does not always feel very comfortable and the problem may re-emerge later. At times however, such as in an emergency, a dominant leader may take charge. In this situation the process may well have the ready compliance of the whole group, or may rapidly achieve acceptance if the strategic direction selected appears to be working.\nApproach: ‘I have decided that we will…’. ‘You will…’. ‘If you don’t come with us, we’ll…’.\nSuppression of conflict, while quite common, is not generally a satisfying outcome. It is a lose/lose form of conflict management. While it is in one sense cooperative, both parties are in all likelihood holding onto the conflict and it may well arise again. If the leader or the group establishes a norm that it isn’t acceptable to have conflict in this group, then the process may go underground. In which case, even if there is discontent, the issue may not be touched on for the rest of the trip. This may be useful if a higher premium is placed on maintaining good relationships in the group and the conflict can safely be ignored. However, there is no airing of the issues or resolution of the problem. In club groups, where people participate together on activities regularly, suppression of issues will very likely result in them resurfacing in other club settings or on future trips.\nApproach: ‘We don’t argue in this group’. ‘We run a happy ship here’.\nDenial or withdrawal\nFinally there is the option of denial or withdrawal, characterised by ‘Perhaps if I ignore it, it will go away’. This is another lose/lose process in which the issue is not dealt with, and there is no expression of feeling. Effectively, all parties pretend the issue doesn’t exist. For minor issues this can be the best policy, and certainly for personal issues between group members where the leader is not really involved, this can be a suitable response.\nApproach: ‘It will sort itself out’. ‘Don’t worry, there probably isn’t a real problem anyway’.\nPeople-centred and task-centred considerations\nAnother dimension worth considering in the conflict resolution process is the extent to which the parties involved in the conflict are adopting people-centred and task-centred approaches. People-centred approaches highly value the needs and feelings of those directly involved. In contrast, task-centred approaches place the achievement of goals (or the interests of the total group) more highly, as shown in Figure 54.2. Conflict resolution is easiest where there is a balance between people and task needs, and recognising this dimension can assist in achieving a solution.\nQuite frequently in outdoors circumstances, the key issue causing the disagreement is differences between people and task needs. For example, some group members may value ‘peak bagging’ more than any other aspect of the trip, and if it is getting late on Sunday when others want to be heading for the cars, conflict can easily result. As in so many aspects of outdoor leadership, active planning and a willingness to modify goals during the trip will assist in preventing the conflict in the first place.\nImportance of relationship (people centred)\n|• People accept differences|\n• Problem solving is easy\n• Differences are expressed and understood\n• Issue is not worth resolving\n|• People are more concerned with truth than with their own positions|\n• Differences are expressed and understood\n• Issues are considered worth raising and working toward agreement\n• Problem solving negotiation is win–win\n• The relationship can be strengthened\n• If relationship ends, the ending is painful but not bitter\n|• Differences present problems|\n• Little things easily become big things\n• Situations can escalate\n|• Differences present almost insurmountable problems|\n• Situations have the potential to polarise parties\n• People have low willingness to work toward agreement\n• Situations can become win-lose\n• Escalation or suppression is likely\n• People can break off the relationship\n• Ending will be painful and 'dirty' (blame, attack, defence, and so on\n|Low Importance of issue (task centred) High|\nWhatever form of conflict management you use, some general points for conducting the process may be helpful:\n- Before you get too far into the process, be sure you have the facts, and that the problem is as clearly defined as possible.\n- Keep focused on the interests of the parties rather than being distracted by outcomes.\n- If you can involve the whole group, use them to generate a range of options, and then select an alternative.\n- Keep in mind both the need to get on with the job, but also the needs of the individuals involved.\nUp to a point, healthy, constructive conflict can be a good thing. Encouraging people to air issues, to debate them in a robust fashion and bring out a range of views into the open can lead to satisfactory resolutions which stick. The good leader will develop the skill of knowing when to step in and how to harness the energy of this type of discussion. The challenge is to know when and how to do this with grace and dignity!""]"	['<urn:uuid:730ddf6b-a737-4021-b766-a3452b43ad5f>', '<urn:uuid:2b6f0627-e596-4ce9-a86d-bc9173160614>']	factoid	direct	concise-and-natural	similar-to-document	comparison	expert	2025-05-13T06:27:57.068978	13	35	3243
5	military training program pass fail statistics pathfinder graduation numbers initial final students	The Pathfinder Class 703-15 course began with 55 students and graduated with only 22, representing a graduation rate of approximately 50 percent. According to instructors, this course is considered the most academically challenging course to get into for the Army.	['By Senior Airman Stephanie Serrano\n19th Airlift Wing Public Affairs\nC-130 Aircrew delivered precision airdrops helping Army soldiers sharpen their drop zone security skills.\nThe most recent iteration of GREEN FLAG Little Rock used combat airlift to support the Army’s Pathfinder Course.\nThe Pathfinder course is a multi-service advanced three-week-course designed to teach military members how to establish and operate helicopter landing zones and drop zones in day and night operations. It also helps hone skills in set up and preparations of sling loads as well as establish and control all three major types of air drops: verbally initiated release system, ground mark release system and computed air release point zones.\n“Today we had our students set up a GMRS drop zone, it’s the most tactically secure of all of our drop signals,” said Tech. Sgt. Bertrand Fitzpatrick, a U.S. Air Force, U.S. Army pathfinder school operations instructor. “It’s designed to allow personnel to mark the drop zone accordingly to where there is almost no prior communication required with the aircraft.”\nThe only information the C-130 crew knew in the scenario was the location of the drop zone. There was no other communication between ground and air.\nA Team Little Rock C-130 flew over the designated release point and delivered a single bundle landing within 25 yards from the designated point of impact making it a success.\n“When you see an aircraft, especially when there’s little coordination between the ground troops and the plane, and it flies over and puts whatever the item is that they’re dropping. It lands within 25 yards of the designated point of impact. It’s awesome. It shows you the inherent capability of the joint force,” said Fitzpatrick.\nOne of the most difficult parts of the course is the sling loads hands on training and the drop zones. Sling load training takes place in week one of the course while drop zones are the last portion in week three. In this, trainees are taught to properly rig various items for transport by helicopter, as well as inspect them. Inspecting is critical in making sure it’s safe to fly. The trainees have three chances to pass the test.\n“The inspection process is extremely rigorous, this is where we lose 20-30 percent of the class,” said Fitzpatrick.\nDrop zones are the last portion of the course before beginning the field training exercise. The drop zone training contains the hardest academic challenges because there is so much data the trainees need to know and account for when directing a plane to drop cargo.\n“This is the hardest course to get into for the Army since it’s the most academically challenging,” said Sgt 1st Class Richard Jackson, a 1st Battalion 507th Parachute Infantry Regiment U.S. Army pathfinder instructor. “Only 50 percent of the students graduate the course.”\nThe Pathfinder Class 703-15 course began with 55 students and graduated with only 22.\nThe 34th Combat Training Squadron conducts approximately six GREEN FLAG Little Rock missions a year, four of which are mandatory.']	['<urn:uuid:4ba58d1a-edc0-409e-87b9-f1e14b9c4ce4>']	factoid	with-premise	long-search-query	distant-from-document	single-doc	expert	2025-05-13T06:27:57.068978	12	40	501
6	How do Alaskans handle and share their preserved fish with others, and what are the main steps involved in processing fish for storage?	Alaskans often share their preserved fish, particularly smoked salmon, with family and friends by carefully packaging and shipping it in USPS Flat Rate Boxes. They wrap each jar in multiple layers of bubble wrap and cardboard, ensuring the jars are secure and won't break during shipping. As for processing fish, the steps include cleaning, filleting, and then preserving through various methods. The basic procedures used in fish processing are heating, freezing, controlling water activity (through drying or adding chemicals), and irradiating. Before storage, fish should be properly glazed or wrapped and transferred to a low-temperature environment.	"[""Copper River Record October 24, 2019\nBy Robin Mayo\nSitting tucked under the wide branches of a spruce tree, we are bundled against the early morning chill and prepared with thermos mugs of coffee, binoculars, and bear spray. This is the perfect spot to see out across the valley at first light.\nHalfway up the mountainsides, a layer of wispy clouds is sailing upriver at a steady pace. At river level, fog is rising from the ponds and sloughs and drifting slowly downriver. It catches on hillocks and patches of spruce, piling up briefly before being combed into strands and continuing to drift close to the surface.\nSeveral hundred yards below us, we harvested a moose in a small meadow in the bend of a slough. We have spent the last three days field dressing, hauling, and hanging the moose on a high pole. All looking forward to watching the gut pile, backbone, and head left behind. A Gray Jay arrived soon after we did, bravely flitting nearby and hauling off any beak-sized tidbit it could pull loose. Surely word has spread among the ravens, magpies, and eagles already. Bears and wolves will not be far behind. Nothing will be wasted.\nThe fog is thickening as a few rays of sun start to reach the ground, well soaked by a night of rain. Soon the valley floor is fully carpeted, only a few ghostly outlines of the tallest spruce trees are visible. I am struck by how slow and subtle yet complete every change in the fog is. You cannot really see movement, but within a few minutes everything is transformed. The air and water are interacting under a complex set of rules: temperature, sun, dew point, breeze, topography.\nThe fog drifts slowly down valley at ground level, but as it lifts to the level of the upriver breeze it is caught and sails with that current. It is okay to be moving in different directions at different levels, I remind myself. It is okay to live within conflicting values, habits, and cultures. My partner eats meat and potatoes, frosted mini wheats with milk. I also like things like asparagus, couscous, and feta cheese. This bothered me at first, but now I smile, privately pleased to eat a whole avocado at one sitting without guilt.\nThe coffee is no longer enough, I have started to think about the four potatoes and one onion that we carried up yesterday evening. The only part of the moose that didn’t get hauled downriver is the ragged end of one of the backstraps.\nOnce the fog is totally gone I’ll go make breakfast. If you cut the potatoes in irregular chunks they won’t stick together as they fry. I’ll wait to add the onion, so the potatoes will have time to get perfectly brown on every side. The meat I will cut across the grain in finger-shaped steaks to roll in seasoned flour then fry hot and fast.\nAn eagle arrives but does not approach the gut pile, watching for ten minutes from the top of a dead spruce. A magpie swoops in to check us out, keen eye locked on our hiding place as he cocks his head to and fro, wondering who we are trying to fool.\nThe fog has gathered itself for another act in the morning drama. It is draped across the valley, some places thick as a blizzard, others thin so the layered silhouettes of ridgelines show. The camera on my phone proves to be totally inept, so I content myself with admiring the way shafts of sun cut between tall spruce, sending rays to the ground.\nSurely news of this bounty has spread through the valley on the breezes and scavengers are converging, waiting and watching until the smell of our piss fades and they deem it safe to approach. The big bull had an old wound on one hind leg, a thick hard mass of scar tissue all the way around the bone with three puncture wounds that never fully healed, deep pockets of grainy pus ringed with bare skin. At some point a wolf or bear had hold of that leg, but he kicked free.\nTen minutes ago the fog looked ready to lift and burn off for good, but the air has gone still now and clumps linger in spite of the direct rays of the sun. The warmth reaches in to our hiding place, welcome on chilled fingers and toes.\nIgnoring the rumble of my stomach, I wait patiently while pillows soften to shrouds, which dissolve into tufts, which slowly fade. The spell is over. I gather my coffee mug and straighten stiff legs. Walking back to camp, I decide to save half of the onion for stir-fry moose tomorrow.\nMorning sun cuts through the morning fog at Moose Camp Robin Mayo photo\nBy Robin Mayo\nAsk any Rural Alaskan what they are up to, or how they are doing, and the odds are very good this time of year that their answer will include the word “busy.” Especially as the endless sunlight starts to fade into autumn, we wear our busy-ness as a badge of honor, proof that we are keeping up with the pack in the nonstop race that is summer.\nAnd really, how could we not be busy? For many of us, this is full-throttle season at work. Resource managers and –ologists are cramming in as much fieldwork as possible, and anyone with a seasonal or tourism-related job is making every minute count. Hikers, paddlers, climbers, bikers, and backpackers are doing their thing. We are also wedging in building projects and visits from friends and relatives.\nAnd on top of all this, we are filling our freezers, pantries, and woodsheds with food and fuel for the winter. I don’t know of a household in the Copper River Valley that doesn’t harvest fish, meat, berries, vegetables, or firewood for the winter ahead. Many of us do all five, which is a tall order.\nOn WISE’s Copper Country Discovery Tour, we visit with Princess Tours guests from around the world, and share our lifestyle with them. One of the things that amazes 100% of these people is how much Alaskans are able to subsist from the land. In most developed parts of the world it is uncommon, and we’ve had many people exclaim, as they nibble on a berry or fresh willow leaf, that this is the first time they have eaten something straight out of the wild.\nHow does it feel? Exhilarating, empowering, and even a little dangerous. I had one guest ask me to please stop encouraging her husband to eat things, she was terrified he would inadvertently ingest an insect, apparently a fate worse than death! For others it triggers fond childhood memories of picking berries or canning preserves with an older relative.\nFor me, subsistence is a fierce pleasure, a love song to the land. I run my fingers along the jars of amber smoked salmon and golden sauerkraut in the pantry, feeling like that ambitious ant in Aesop’s fable. Recently I posted a picture of freshly caught Sockeye on Facebook, which not surprisingly touched off a small debate amongst friends, some of whom were feeling deprived of their yearly fish with the early-season closures.\nOne facebooker stated the opinion that subsistence fish should only be shared with family, and that these special seasons should only be available to those who only live in “real” subsistence villages, which she defined as off the road system. As you can imagine, there was a small tsunami of Copper Basin and other Alaskan residents defending our tradition of sharing with all, and our legacy as a place where subsistence is a truly traditional way of life. It was a wonderful affirmation of how these activities not only fill our bellies, but fill our hearts as well.\nBusy? Overwhelmed, even? Don’t worry, soon enough the long dark will be here, and there will be time to read that book, clean that house, or knit that sock. For now, I’m thoroughly enjoying the headlong rush of summer into fall, and the feeling of urgency to pick those berries, cut that wood, fill that freezer.\nCopper River Record October 2017\nBy Robin Mayo\nYou catch the fish. You clean the fish. You fillet the fish. You brine the fish. You smoke the fish. You pack the jars and run the pressure canner. You unload the canner and line up the jars on the counter, listening for that immensely satisfying “ploink” that means the jar has sealed. You remove the rings, clean the jars, and fill your pantry with bounty.\nIf you are wise and humble, you are now finished. But perhaps you succumb to the sin of pride and post some pictures on facebook. A cooler full of silvery fish. Fillets glistening ruby-orange. A dusky interior shot of the smokehouse. Lines of jars on the counter.\nAnd the next thing you know you are inundated with requests from far-off family and friends, wanting a taste. You now have one more step: ship the fish.\nThe two greatest inventions ever for Alaskans who wish to keep in touch with the outside world without breaking the bank are the Alaska Airlines Companion Fare, and the USPS Flat Rate Box. I still remember how excited I was when I discovered that half a dozen pint jars of salmon fit perfectly in a medium flat rate box. It is elegant, efficient, and most importantly, affordable. For $13.60, you can ship anything that fits in the box, anywhere in the US. If it weighs more than two pounds, this is the best bargain around. The heaviest flat rate box I ever received was filled with cool old horseshoes, a lucky shipment for sure.\nFor most situations, I am a “good enough” kind of person. I don’t sweat the details, and strive for simplicity. But for packing jars of smoked salmon for mailing, my motto changes to “Anything worth doing is worth overdoing!” When in doubt, use more tape and bubble wrap. Double up on everything. Did I mention tape and bubble wrap?\nThis is a great way to recycle materials, including bubble wrap, padded envelopes, and anything else cushy. When sending care packages to my wayward daughters, I use fresh socks, purchased by the bundle at Costco. Make Matt Morse happy and use plastic grocery bags instead of sending them to the landfill. You can definitely use some of those Amazon Prime boxes which seem to multiply in the shed. Corrugated cardboard is amazing stuff, as it lends strength and cushioning. It is always good to add something absorbent, in case of disaster. For this I favor back issues of the Copper River Record, so the recipient gets some excellent reading material as well.\nStart with two medium sized flat rate boxes, available for free at any post office. Fold the bottom of one and tape it well. Line the box with a large plastic bag, such as a kitchen-sized garbage bag. Fold but do not tape the bottom of the second box, and slide it inside the first box, so you now have a double-thick box with a layer of plastic in between. Cut a rectangle of cardboard to fit inside the bottom of the box.\nThis trick works best with wide mouth, straight sided pint mason jars. Narrow mouth pints are a little taller and leave less room for padding, but I sometimes send them anyways because I like to get rid of them. If you use wide-mouth half pints, you can stack them in pairs and send a whole dozen.\nMake sure each jar has a metal ring, well tightened. First, wrap only the exposed glass sides in small-gauge bubble wrap, or other similar cushy padding. Add another layer which covers the metal ring as well, and folds over to pad the top and bottom of the jar. Secure the whole bundle with plenty of tape.\nWhen all the jars are individually wrapped, it’s time to pack the box. Cut strips of corrugated cardboard and put them between the jars, around the edges, and anywhere else they will fit. The jars should be packed snugly, but not too tight, and there should not be any movement if you shake it. Try closing the box before deciding if you need another layer of cardboard on top of the jars.\nFold the flaps and tape up the inside box, trim and seal the plastic bag, then tape up the outside box. I’ve never had a flat rate box rejected because it bulges a little, but it will be the strongest if the flaps meet. Address the box, and finish it off with plenty of strong tape around every axis. Save another fifty cents by printing your own shipping label at USPS Click and Ship.\nI’ve never had a failure when shipping salmon this way. But sometimes you don’t want to ship so many jars, you just need a bombproof way of shipping a jar or two. For this purpose, I make each jar into a padded and leak-proof bundle. Several layers of bubble wrap, covered by a full edition of the Copper River Record, folded and taped so all sides are covered. This is packed in a gallon ziplock bag, then put into a larger carton along with whatever else you are shipping. Make sure the jar can’t shift in the larger box. I like to roll the jars up in sheets of corrugated cardboard which are cut to fit the dimensions of the box. Once again, a redundant layer or two is much preferred over a mess of fish oil and broken glass. One box I am presently packing includes jars of smoked salmon and a laptop computer, so you could say the stakes are high.\nIs all this hassle worth it? Your relatives will love you, and attempt to reciprocate by sending you ripe peaches, or some other local treat. This will probably be somewhat less successful than your salmon mailing escapade. Your friends will want to visit. Ask them to schedule the trip for fishing season next year, so they can help tend the smokehouse, and listen for the “ploink.”\nEach jar is individually wrapped\nWho We Are\nWISEfriends are several writers connected with Wrangell Institute for Science and Environment, a nonprofit organization located in Alaska's Copper River Valley. Most of these articles originally appeared in our local newspaper, the Copper River Record."", 'Traditional methods of processing fish is confined to drying, smoking and salting while the non-traditional methods of processing fish are: canning and freezing. The development of new fishery products and convenience items in the Philippines has a brighter future.\nWhat are the methods of processing fish?\nThe four basic procedures used in the final processing of fish products are heating, freezing, controlling water activity (by drying or adding chemicals), and irradiating. All these procedures increase the shelf life of the fish by inhibiting the mechanisms that promote spoilage and degradation.\nWhy do fishes need to be processed what are the ways of processing fishes?\nPreservation techniques are needed to prevent fish spoilage and lengthen shelf life. They are designed to inhibit the activity of spoilage bacteria and the metabolic changes that result in the loss of fish quality.\nWhat is the most popular techniques in processing fish?\nThe most popular fish preservation method is solar drying. It is done in combination with salting.\nWhat is the important of fish processing?\nThe major products are dried, salted, fermented, and smoked fish. … The operations of importance in fish processing are washing, degutting, salting, fermentation, drying, and smoking. These operations contribute to the development of flavor, texture, color, and improved storage characteristics of the products.\nWhat are the tools used in fish processing?\nTools and Equipment for Fish or Food Processing\n- Pressure Cooker. Weighing Scales. Triple beam balance. Measuring spoons. Measuring cup.\n- Thermometer. Glass tube thermometer. Salinometer. Psychrometer. Anemometer.\n- Refractometer. Knives. Filleting knives.\n- Scissors. Descalers or scalers. Oil drum. Earthen pots.\nWhat is traditional fish processing method?\nSmoking, sun drying, and salting are common traditional processing methods associated with small-scale fisheries value chains and are often practiced using low cost technology and with minimal services and facilities.\nWhat is the fish processing technology?\nFish processing can be subdivided into fish handling, which is preliminary processing of raw fish, and the manufacture of fish products. … Ancient methods of preserving fish included drying, salting, pickling and smoking.\nWhy do fish cooks very quickly even at low heat?\nThis is the connective tissue called “collagen,” a structural protein that holds together short, thick muscle fibers. In fish, muscle fibers are much shorter than they are in beef, and collagen dissolves easily during cooking. So fish cooks quickly and there’s no tenderizing to do.\nWhat are the treatment of fish before storage?\nAs soon as fish are removed from a freezer, they should be glazed or wrapped (unless they have been packaged before freezing) and immediately transferred to a low temperature store. When it is known that storage will be for a short period only, glazing or wrapping may not be necessary or practical.\nWhat is filleting in fish processing?\nA fish fillet, from the French word filet (pronounced [filɛ]) meaning a thread or strip, is the flesh of a fish which has been cut or sliced away from the bone by cutting lengthwise along one side of the fish parallel to the backbone. In preparation for filleting, any scales on the fish should be removed.\nWhat is the last step in preparing fish before cooking?\n- Step 1: Bonk and bleed out the fish. In order to minimize suffering for the fish and prevent spoilage of the meat, fish must be “bonked” and bled out immediately after removing the hook. …\n- Step 2: Remove scales or skin. …\n- Step 3: Open the belly and remove the innards. …\n- Step 4: Prepare for cooking. …\n- Step 5: Cook the fish.\nCan you identify and explain the parts and functions of fish?\nFish are animals that are cold-blooded, have fins and a backbone. Most fish have scales and breathe with gills. … They are either single fins along the centerline of the fish, such as the dorsal (back) fins, caudal (tail) fin and anal fin, or paired fins, which include the pectoral (chest) and pelvic (hip) fins.\nWhat is fish made of?\nThe skeleton of the fish is made of either cartilage (cartilaginous fishes) or bone (bony fishes). The fins are made up of bony fin rays and, except for the caudal fin, have no direct connection with the spine.\nWhat is handling of fish?\nKeeping a fish above water prevents the fish from ‘breathing’ and further adds to angling-induced stress. Handle fish gently. It’s common to see anglers beaching their catch in many of our fisheries. … Wet hands help keep fish slimy and parasite-free. Watch the water temperature.']"	['<urn:uuid:de31aff0-1f31-4786-b0a4-9871a83fedc3>', '<urn:uuid:e7d47fe5-6b55-4c7e-9bd6-0f6d0d8cacfc>']	open-ended	direct	verbose-and-natural	distant-from-document	multi-aspect	novice	2025-05-13T06:27:57.068978	23	96	3169
7	What is the purpose of the Page_PreRender method?	The Page_PreRender method is the last opportunity to modify the Viewstate based on the PostBackEvent before the page is rendered. It occurs just before the SaveViewState method, which saves the updated Viewstate for processing on the next page.	['Page Life Cycle in ASP.NET\nSee more tutorials in Performance. This post has Comments Off on Page Life Cycle in ASP.NET.\nAn important article on the different methods and order they are executed during the load of an .aspx web page. ASP.NET.\nIn this article, we are going to discuss the different methods and order they are executed during the load of an .aspx web page.\nWhen a visitor first requests an .aspx page on your server, the server sends it to the HTTP Pipeline. The HTTP Pipeline handles all processes involved in converting all of the application code into HTML to be interpreted by the browser. The first class initiated is called HttpRuntime. This class finds a free HttpApplication object to start processing the request. The HttpApplication object then runs the appropriate handler assigned in the web.config and machine.config files for the requested extension.\nThe extension .aspx can be handled by the HandlerClass or HandlerFactory class. The HttpApplication objects starts the IHttpHandler interface which begins processing the application code by calling the processRequest() method.\nThe processRequest() method then calls the FrameworkInitialize() method which begins building the control trees for the requested page. Now the processRequest() method cycles through the page’s life cycle in the order listed below.\n|LoadViewState||View State Loading|\n|LoadPostData||Postback Data Processing|\n|RaisePostDataChangedEvent||PostBack Change Notification|\n|RaisePostBackEvent||PostBack Event Handling|\n|Page_PreRender||Page Pre Rendering Phase|\n|SaveViewState||View State Saving|\nThe first processed method is Page_Init(). Once the control tree has been created, the controls declared in the .aspx file are initialized. The controls can modify some of the settings set in this method to be used later in the page life cycle. Obviously no other information is available to be modified at this time.\nThe next processed method is LoadViewState(). The Viewstate contains stored information that is set by the page and controls of the page. This is carried to and from every aspx page request per visitor.\nThe next processed method is LoadPostData(). These are values associated with the HTML form elements the visitor has typed, changed or selected. Now the control has access to this information which can update their stored information pulled from the Viewstate.\nThe next processed method is Page_Load(). This method should look familiar and is usually the most common used method on the server side application code for an .aspx file. All code inside of this method is executed once at the beginning of the page.\nThe next processed method is RaisePostDataChangedEvent(). When a visitor completes a form and presses the submit button, an event is triggered. This change in state signals the page to do something.\nThe next processed method is RaisePostBackEvent(). This method allows the page to know what event has been triggered and which method to call. If the visitor clicks Button1, then Button1_Click is usually called to perform its function.\nThe next processed method is Page_PreRender(). This method is the last chance for the Viewstate to be changed based on the PostBackEvent before the page is rendered.\nThe next processed method is SaveViewState(). This method saves the updated Viewstate to be processed on the next page. The final Viewstate is encoded to the _viewstate hidden field on the page during the page render.\nThe next processed method is Page_Render(). This method renders all of the application code to be outputted on the page. This action is done with the HtmlWriter object. Each control uses the render method and caches the HTML prior to outputting.\nThe last processed method is Page_Unload(). During this method, data can be released to free up resources on the server for other processes. Once this method is completed, the HTML is sent to the browser for client side processing.\nNow you should have a little bit better understanding of the order of methods executed in the request of an .aspx file.']	['<urn:uuid:3798289c-bd64-43cf-8d5b-3d378b62a3f6>']	open-ended	direct	concise-and-natural	similar-to-document	single-doc	expert	2025-05-13T06:27:57.068978	8	38	633
8	radiation belts discovery exploration impact space missions	The Van Allen radiation belts were discovered through the Explorer 1 mission on January 31, 1958, when its cosmic ray detector revealed unexpectedly low cosmic ray counts, suggesting a belt of trapped radiation around Earth. The belts pose significant challenges for space missions, as most spacecraft are not designed to withstand high levels of particle radiation and wouldn't last a day in them. As a result, spacecraft must quickly transit through the belts while non-essential instruments are turned off for protection. To study these belts more effectively, NASA launched radiation-shielded Van Allen Probes in 2012, which orbit Earth in highly elliptical paths to gather data about these regions.	"['The Van Allen radiation belt is a torus of energetic charged particles (i.e. a plasma) around Earth, trapped by Earth\'s magnetic field. The Van Allen belts are closely related to the polar aurora where particles strike the upper atmosphere and fluoresce. The presence of a radiation belt had been theorized prior to the Space Age and the belt\'s presence was confirmed by the Explorer I on January 31, 1958 and Explorer III missions, under Doctor James Van Allen.\nThe trapped radiation was first mapped out by Explorer IV and Pioneer III.Qualitatively, it is very useful to view this belt as consisting of two belts around Earth, the inner radiation belt and the outer radiation belt. The particles are distributed such that the inner belt consists mostly of protons while the outer belt consists mostly of electrons. Within these belts are particles capable of penetrating about 1 g/cm2 of shielding (e.g., 1 millimetre of lead).\nThe term \'Van Allen Belts\' refers specifically to the radiation belts surrounding Earth; however, similar radiation belts have been discovered around other planets. The Sun does not support long-term radiation belts.\nThe Earth\'s atmosphere limits the belts\' particles to regions above 200-1000 km, while the belts do not extend past 7 Earth radii RE. The belts are confined to an area which extends about 65¡ from the celestial equator.\nEnlarged View of this image\nThe big outer radiation belt extends from an altitude of about 10,000Ð65,000 km and has its greatest intensity between 14,500Ð19,000 km. The outer belt is thought to consist of plasma trapped by the Earth\'s magnetosphere. The USSR\'s Luna 1 reported that there were very few particles of high energy within the outer belt. The gyroradii for energetic protons would be large enough to bring them into contact with the Earth\'s atmosphere. The electrons here have a high flux and along the outer edge and electrons with kinetic energy E > 40 keV can drop to normal interplanetary levels within about 100 km (a decrease by a factor of 1000). This drop-off is a result of the solar wind.\nThe particle population of the outer belt is varied, containing electrons and various ions. Most of the ions are in the form of energetic protons, but a certain percentage are alpha particles and O+ oxygen ions, similar to those in the ionosphere but much more energetic. This mixture of ions suggests that ring current particles probably come from more than one source.\nThe outer belt is larger and more diffused than the inner, surrounded by a low-intensity region known as the ring current. Unlike the inner belt, the outer belt\'s particle population fluctuates widely and is generally weaker in intensity (less than 1 MeV), rising when magnetic storms inject fresh particles from the tail of the magnetosphere, and then falling off again.\nThere is debate as to whether the outer belt was discovered by the US Explorer IV or the USSR Sputnik II/III.\nThe inner Van Allen Belt extends from roughly 1.1 to 3.3 Earth radii, and contains high concentrations of energetic protons with energies exceeding 100 MeV, trapped by the strong (relative to the outer belts) magnetic fields in the region.\nIt is believed that protons of energies exceeding 50 MeV in the lower belts at lower altitudes are the result of the beta decay of cosmic ray neutrons. The source of lower energy protons is believed to be proton diffusion due to changes in the magnetic field during geomagnetic storms.\nSolar cells, integrated circuits, and sensors can be damaged by radiation. In 1962, the Van Allen belts were temporarily amplified by a high-altitude nuclear explosion (the Starfish Prime test) and several satellites ceased operation.\nMagnetic storms occasionally damage electronic components on spacecraft. Miniaturization and digitization of electronics and logic circuits have made satellites more vulnerable to radiation, as incoming ions may be as large as the circuit\'s charge. Electronics on satellites must be hardened against radiation to operate reliably.\nThe Hubble Space Telescope, among other satellites, often has its sensors turned off when passing through regions of intense radiation. An object satellite shielded by 3 mm of aluminum will receive about 2500 rem (25 Sv) per year.\nProponents of the Apollo Moon Landing Hoax have argued that space travel to the moon is impossible because the Van Allen radiation would kill or incapacitate an astronaut who made the trip. Van Allen himself, still alive and living in Iowa City, has dismissed these ideas.\nIn practice, Apollo astronauts who travelled to the moon spent very little time in the belts and received a harmless dose. Nevertheless NASA deliberately timed Apollo launches, and used lunar transfer orbits that only skirted the edge of the belt over the equator to minimise the radiation. Astronauts who visited the moon probably have a slightly higher risk of cancer during their lifetimes, but still remain unlikely to become ill because of it.\nIt is generally understood that the Van Allen belts are a result of the collision of Earth\'s magnetic field with the solar wind. Radiation from the solar wind then becomes trapped within the magnetosphere. The trapped particles are repelled from regions of stronger magnetic field, where field lines converge. This causes the particle to bounce back and forth between the earth\'s poles, where the magnetic field increases.\nThe gap between the inner and outer Van Allen belts is caused by low-frequency radio waves that eject any particles that would otherwise accumulate there. Solar outbursts can pump particles into the gap but they drain again in a matter of days.\nThe radio waves were originally thought to be generated by turbulence in the radiation belts, but recent work by James Green of the NASA Goddard Space Flight Center comparing maps of lightning activity collected by the Micro Lab 1 spacecraft with data on radio waves in the radiation-belt gap from the IMAGE spacecraft suggests that they\'re actually generated by lightning within Earth\'s atmosphere. The radio waves they generate strike the ionosphere at the right angle to pass through it only at high latitudes, where the lower ends of the gap approach the upper atmosphere.\nThe Soviets once accused the U.S. of creating the inner belt as a result of nuclear testing in Nevada. The U.S. has, likewise, accused the USSR of creating the outer belt through nuclear testing. It is uncertain how particles from such testing could escape the atmosphere and reach the altitudes of the radiation belts. Likewise, it is unclear why, if this is the case, the belts have not weakened since atmospheric testing was banned by treaty. Thomas Gold has argued that the outer belt is left over from the aurora while Dr Alex Dessler has argued that the belt is a result of volcanic activity.\nIn another view, the belts could be considered a flow of electric current that is fed by the solar wind. With the protons being positive and the electrons being negative, the area between the belts is sometimes subjected to a current flow, which ""drains"" away. The belts are also thought to drive aurora, lightning and many other electrical effects.\nThe belts are a hazard for artificial satellites and moderately dangerous for human beings and difficult and expensive to shield against.\nThere is a proposal by the late Robert L. Forward called HiVolt which may be a way to drain at least the inner belt to 1% of its natural level within a year. The proposal involves deploying highly electrically charged tethers in orbit. The idea is that the electrons would be deflected by the large electrostatic fields and intersect the atmosphere and harmlessly dissipate.\nSome scientists, however, theorize that the Van Allen belts carry some additional protection against solar wind, which means that a weakening of the belts could harm electronics and organisms, and that they may influence the Earth\'s telluric current, dissipating the belts could influence the behavior of Earth\'s magnetic poles.\nReferences and Links\n\'Zebra Stripes\' in Earth\'s Magnetic Field Have Surprising Source Live Science - April 3, 2014\nStrange stripe-like features in Earth\'s magnetic field are caused by the planet\'s spin, and not by the constant bombardment of solar particles as previously thought, scientists say. The so-called ""zebra stripes"" form when the electric field around Earth generated by the planet\'s rotation - previously thought to be too weak to impact the fast-moving particles - creates a striped pattern in the inner electron belt.\nEarth\'s radiation belt: Van Allen probes reveal \'zebra stripes\' in space Science Daily - March 20, 2014\nScientists have discovered a new, persistent structure in one of two radiation belts surrounding Earth. NASA\'s twin Van Allen Probes spacecraft have shown that high-energy electrons in the inner radiation belt display a persistent pattern that resembles slanted zebra stripes. Surprisingly, this structure is produced by the slow rotation of Earth, previously considered incapable of affecting the motion of radiation belt particles, which have velocities approaching the speed of light.\nNASA Discovers New Radiation Belt Around Earth Live Science - February 28, 2013\nA ring of radiation previously unknown to science fleetingly surrounded Earth last year before being virtually annihilated by a powerful interplanetary shock wave, scientists say. NASA\'s twin Van Allen space probes, which are studying the Earth\'s radiation belts, made the cosmic find. The surprising discovery - a new, albeit temporary, radiation belt around Earth - reveals how much remains unknown about outer space, even those regions closest to the planet, researchers added. After humanity began exploring space, the first major find made there were the Van Allen radiation belts, zones of magnetically trapped, highly energetic charged particles first discovered in 1958.\nALPHABETICAL INDEX OF ALL FILES\nCRYSTALINKS HOME PAGE\nPSYCHIC READING WITH ELLIE\n2012 THE ALCHEMY OF TIME', ""In the News\nThis month marks the 60th anniversary of the launch of America’s first satellite, Explorer 1. The small, pencil-shaped satellite did more than launch the U.S. into the Space Age. With its collection of instruments, or scientific tools, it turned space into not just a new frontier, but also a place of boundless scientific exploration that could eventually unveil secrets of new worlds – as well as the mysteries of our own planet.\nHow They Did It\nAt the height of competition for access to space, the U.S. and the Soviet Union were both building satellites that would ride atop rockets in a quest to orbit Earth. The Soviets launched Sputnik 1 on October 4, 1957. Shortly thereafter, on January 31, 1958, the U.S. launched Explorer 1, the satellite that would begin a new age of scientific space exploration.\nUsing rockets to do science from orbit was a brand-new option in the late 1950s. Before this time, rockets had only been used for military operations and atmospheric research. Still, rockets of that era weren’t very reliable and none had been powerful enough to place an object into Earth orbit.\nExplore our collection of standards-aligned lessons for grades K-9.\nIn order to lift Explorer 1 to its destination in Earth orbit, an existing U.S. Army rocket, the Jupiter C, was fitted with a fourth stage, provided by the Jet Propulsion Laboratory in Pasadena, California. For this stage, a rocket motor was integrated into the satellite itself. The new, four-stage rocket was called “Juno 1.”\nPrior to these first orbiting observatories, everything we knew about space and Earth came from Earth-based observation platforms – sensors and telescopes – and a few atmospheric sounding rockets. With the success of Explorer 1 and the subsequent development of more powerful rockets, we have been able to send satellites beyond Earth orbit to explore planets, moons, asteroids and even our Sun. With a space-based view of Earth, we are able to gain a global perspective and acquire a wide variety and amount of data at a rapid pace.\nWhy It’s Important\nThe primary science instrument on Explorer 1 was a cosmic ray detector designed to measure the radiation environment in Earth orbit – in part, to understand what hazards future spacecraft (or space-faring humans) might face. Once in space, this experiment, provided by James Van Allen of the University of Iowa, revealed a much lower cosmic ray count than expected. Van Allen theorized that the instrument might have been saturated by very strong radiation from a belt of charged particles trapped in space by Earth's magnetic field. The existence of the radiation belts was confirmed over the next few months by Explorer 3, Pioneer 3 and Explorer 4. The belts became known as the Van Allen radiation belts in honor of their discoverer.\nAlthough we discovered and learned a bit about the Van Allen belts with the Explorer missions, they remain a source of scientific interest. The radiation belts are two (or more) donut-shaped regions encircling Earth, where high-energy particles, mostly electrons and ions, are trapped by Earth's magnetic field. The belts shrink and swell in size in response to incoming radiation from the Sun. They protect Earth from incoming high-energy particles, but this trapped radiation can affect the performance and reliability of our technologies, such as cellphone communication, and pose a threat to astronauts and spacecraft. It’s not safe to spend a lot of time inside the Van Allen radiation belts.\nMost spacecraft are not designed to withstand high levels of particle radiation and wouldn’t last a day in the Van Allen belts. As a result, most spacecraft travel quickly through the belts toward their destinations, and non-essential instruments are turned off for protection during this brief time.\nTo conquer the challenge of extreme radiation in the belts while continuing the science begun by Explorer 1, NASA launched a pair of radiation-shielded satellites, the Van Allen Probes, in 2012. (The rocket that carried the Van Allen Probes into space was more than twice as tall as the rocket that carried Explorer 1 to orbit!)\nThe Van Allen Probes carry identical instruments and orbit Earth, following one another in highly elliptical, nearly identical orbits. These orbits bring the probes as close as about 300 miles (500 kilometers) above Earth’s surface, and take them as far out as about 19,420 miles (31,250 kilometers), traveling through diverse areas of the belts. By comparing observations from both spacecraft, scientists can distinguish between events that occur simultaneously throughout the belts, those that happen at only a single point in space, and those that move from one point to another over time.\nThe Van Allen Probes carry on the work begun by Explorer 1 and, like all successful space missions, are providing answers as well as provoking more questions. NASA continues to explore Earth and space using spacecraft launched aboard a variety of rockets designed to place these observatories in just the right spots to return data that will answer and inspire questions for years to come.\n- *NEW* Build a Satellite (Grades 5-8) – Students will use the engineering design process to design, build, test and improve a model satellite intended to investigate the surface of a planet.\n- Rocket Lessons and Activities (Grades K-9) – Use these exciting lessons to help your students experience the thrill of building their own rockets using the engineering design process!\n- Earth Science Lessons and Activities (Grades K-12) – Use these lessons to engage your students in studying Earth from space!\n- Build Your Own Space Mission – Have younger students play this game to place instruments aboard a spacecraft and launch it into space!\n- Download the GLOBE Observer app and have students be citizen scientists in support of NASA Earth science missions! Learn more about how to participate.""]"	['<urn:uuid:0e89d757-652c-4b3c-89d8-85b6aad331c3>', '<urn:uuid:eaa70d8f-a6c4-4a71-93e0-6aef3c00e2b7>']	open-ended	direct	short-search-query	distant-from-document	multi-aspect	expert	2025-05-13T06:27:57.068978	7	108	2585
9	ar vr healthcare education differences strengths applications practical training	Virtual Reality (VR) and Augmented Reality (AR) serve different purposes in healthcare education. VR completely immerses users in a computer-generated world, cutting them off from physical reality, ideal for simulating surgeries and providing risk-free practice environments. AR, on the other hand, extends the real world with computer-generated information and images, typically through smartphones or tablets, allowing users to view reality while receiving additional information overlaid on it. AR is particularly suited for practical applications like maintenance procedures where technicians can see real-time instructions while working, while VR is better for fully immersive training scenarios. Both technologies contribute to healthcare education by providing interactive and immersive learning experiences, though they differ in their level of immersion and practical applications.	['The healthcare sector, more than ever, demands constant learning and adaptation. With the rapid evolution of medical science and the urgency to train healthcare professionals effectively, technology plays a pivotal role.\nAnd what better way to integrate technology into this dynamic sector than through gadgets? Here’s how the latest tech tools and innovations can facilitate superior education in healthcare.\nHow to Utilize Technology to Improve Education in the Healthcare Sector\nIn a domain as dynamic and crucial as healthcare, the role of education is paramount. Keeping pace with the myriad advances in medical science requires an educational approach that’s both innovative and effective.\nAs the world becomes more digitized, the healthcare sector is witnessing a revolution in the way professionals learn and train, all thanks to gadgets and technological tools.\nVideo Learning: A Comprehensive Approach to Digital Education\nIn an age where digitization is the norm, Video learning emerges as a keystone in healthcare education. Its significance transcends mere convenience. With advancements in filming technologies and accessibility to the internet, these digital classrooms have become centers of knowledge dissemination.\nThe power of Video learning lies not just in its ability to illustrate and demonstrate but also in its vast reach. Modern platforms, optimized for various devices from smartphones to personal computers, offer a wealth of content.\nThis mode of learning transcends geographical boundaries. Students, irrespective of their location, have the opportunity to access knowledge from global experts, opening doors to techniques, theories, and cases that might be rare in their vicinity.\nThis globalized approach to education ensures that learners get a holistic view, prepping them for myriad challenges.\nAI-Driven Learning: Revolutionizing Personalized Education\nThe wave of Artificial Intelligence (AI) has touched numerous sectors, and education in the healthcare domain is no exception. The inception of AI-Powered Bots and Applications is reshaping the dynamics of traditional learning.\nWhat sets AI-driven learning apart is its ability to “understand” the learner. Unlike standard educational tools, these smart tools register the learning patterns, strengths, and areas that require improvement for each individual.\nBased on these insights, the content is curated, ensuring that the learning experience is bespoke.\nBut the wonders of AI don’t stop at content curation. These intelligent systems actively interact with students, answering queries, providing clarifications, and even suggesting further reading or modules based on individual progress.\nSuch proactive learning aids can be invaluable, especially in a field as intricate and ever-evolving as healthcare.\nThe integration of AI in learning not only makes the process more efficient but also ensures that the content resonates with the learner, maximizing retention and application of knowledge. In essence, AI-driven tools are like personal tutors, dedicated to enhancing the learning journey of each student.\nThe Magic of VR and AR in Healthcare Education\nVirtual Reality (VR) and Augmented Reality (AR) are not just for gamers. In the healthcare sector, these technologies provide an immersive environment, perfect for a range of educational applications.\nFrom simulating intricate surgeries to visualizing drug interactions at a cellular level, VR and AR headsets offer students a risk-free platform to practice, learn, and explore.\nInteractive Tablets and Smartboards\nThe conventional methods of using textbooks and 2D diagrams are gradually being overshadowed by more interactive and immersive tools. Interactive Tablets and Smartboards have emerged as powerful devices to project 3D representations of the human anatomy, allowing students to grasp complex structures and processes in a more intuitive manner.\nThe ability to rotate, zoom, and peel through layers gives learners a holistic understanding, deepening their insights into the marvel that is the human body.\nWearable Gadgets: Bridging the Gap Between Theory and Real-life Medical Practice\nIn the rapidly evolving technological landscape, wearable gadgets have carved a niche for themselves. While the general populace might identify them as tools for tracking daily health metrics like steps taken or heart rate, their potential in healthcare education is profound and far-reaching.\nDelving Deep into Patient Simulation\nThe essence of wearable gadgets in healthcare education lies in their ability to simulate intricate patient scenarios. Instead of just relying on textbook cases, students can now witness real-time vitals and health parameters through these devices.\nFor instance, a smartwatch could be programmed to replicate the heartbeat patterns of a patient experiencing arrhythmia or a fitness band could simulate oxygen saturation levels in certain respiratory diseases.\nThis dynamic and real-time representation offers students an unprecedented hands-on approach to understanding diseases, their manifestations, and potential interventions.\nIt’s one thing to read about a condition and entirely another to see it unfold in real time. Such immersive experiences foster deeper understanding and retention of knowledge.\nEnriched Training Through Real-world Experiences\nApart from simulating diseases, wearable gadgets also provide a continuous stream of data, helping students understand the progression of certain conditions and the efficacy of interventions.\nFor example, observing how vitals change post-administration of a drug can give invaluable insights into its effects and potential side effects.\nThe integration of wearable technology in healthcare education equips students with a more pragmatic understanding of medical situations. It moves them away from abstract learning and plunges them into the heart of real-life medical scenarios.\nThis transition from theoretical knowledge to practical understanding ensures that budding healthcare professionals are not just well-informed, but also adept at handling real-world challenges.\nThe confluence of technology and healthcare education is creating a paradigm shift in the way professionals are trained. By integrating gadgets and advanced tech tools into the curriculum, the healthcare sector is set to produce professionals who are not just well-versed in theory, but also adept at harnessing technology for practical applications.\nThe fusion of gadgets and education heralds a promising era for healthcare professionals worldwide.', 'VR, AR, MR – for many non-experts these terms are easy to confuse. Meanwhile another technological revolution is bearing down on us, under the umbrella term of Extended Reality or xR. For mobile devices, Virtual, Augmented or Mixed Reality applications are already a reality in a variety of different forms. (Published in Swiss IT Magazine issue 01-02, written by Reto Grob)\nIn order to find your way around the world of Extended Reality, it is well worth knowing the differences between each of the above terms, although there is no clear-cut, generally accepted differentiation. Virtual Reality (VR) refers to a world beyond the one that we can physically see; it is generated by a computer. In this case there is a clear separation between the two types of reality. The user is totally surrounded by this world and is meanwhile totally cut off from the real world. Depending on the application, the user may be able to interact with the objects and events in the VR world.\nWhen realities merge\nAugmented Reality (AR) is a computer-generated extension of the real world using information and images. You can watch visible reality via a smartphone, (more rarely at present using AR glasses and headsets), while the device recognizes an object you are looking at in the real world (for example, a historic building) and displays some text about it. To do this, mobile devices need to be equipped with a good camera, movement sensors and a powerful CPU.\nFinally, Mixed Reality (MR) is a stronger version of AR. In this, the physical reality is further merged with the virtual (VR) Reality. The user can embed computer-generated items in real surroundings, walk around them and manipulate them interactively. VR, AR and MR are referred to jointly under the umbrella term of Extended Reality (xR). Mobile xR is the term for its implementation on smartphones and tablets. These devices are already widely available, and this allows mobile xR applications to spread rapidly. For effective Mixed Reality applications, headsets or glasses are better (such as Microsoft’s Hololens, Google Glass, or Magic Leap One).\nWhere are we now?\n1982: Damien Broderick referred to “Virtual Reality” for the first time in his science fiction novel The Judas Mandala. And 35 years on? In an edition of the Swiss weekly “Schweiz am Wochenende” in December 2017, the Silicon Valley correspondent called virtual reality a “missed revolution.” Obviously the initial euphoria has evaporated. Not because the technology has basically failed to deliver, but because everything is moving a lot faster, and the VR glasses it requires are still relatively cumbersome. Augmented and Mixed Reality, which build on it, have already left pure virtual Reality behind. Nevertheless, the sector is still made fun off. People claim that it is “playing around” rather than serious research and development.\nPractical applications already exist\nAll areas of Extended Reality are based, to put it simply, on technologies that are not so very new. 3D data and game engines. Virtual Reality is also mainly at home in computer games. This is where digital interaction between humans and computers occurs. In Augmented Reality and Mixed Reality, in addition to the human and the computer, it is the surroundings, or the real world, that join in as a third dimension. With AR, you are for the main part still moving in a two-dimensional area, because the mobile devices used to display it have traditional 2D screens.\nARKit and ARCore\nMany people still remember the Peakfinder app from 2010, a unique, very expensive pioneer in the “Stone Age” of AR. Today’s mobile devices are already equipped with much more highly developed basic frameworks like ARKit or ARCore from Apple or Google. They form the basis and shorten the path to totally new mobile apps, as you can use them to develop faster and cheaper applications. An example is the Ikea Place furniture catalog for the iPhone and iPad. While the camera shows your own living room, you can choose a virtual armchair from the catalog and add it to the image, so you can judge for yourself whether the size and color will fit with the place you have in mind.\nARKit still has its shortcomings – for example, recognition of surfaces in the room does not always work well. Space recognition and positioning still needs to be noticeably more precise. Nevertheless, Apple has got ahead of the pack in the mobile xR world. Android has good technical AR frameworks, but these are not as widely available as on iOS, and Google will need to make a huge effort to catch up.\nMany uses in education, industry and marketing\nThe descriptions of the following research and pilot projects are simplified, and they are representative of thousands of similar prototypes worldwide. Medical students will in future learn human anatomy from a virtual patient lying on the table in front of them, with the organs and body parts labeled on the screen. This reduces the cognitive burden of understanding the 3D representation.\nThat allows them to focus on the functions instead of the interpretation of 2D images. This means faster learning and better quality learning. Overall, the technology opens up completely new options in education. Students do not all have to be in the same place. For example, they can see a virtual object in front of them on a table, which they can turn and open following the teacher’s instructions.\nFor the maintenance of railway carriages, technicians can, for example, walk round the carriage, while the AR application shows them the items to be inspected in their current condition and what they should look like, stores the history and even generates a paperless invoice, Or to carry out a repair, they can connect live to a colleague at headquarters who is an expert and can show them the procedure on their tablet. This improves the quality of maintenance and the cost effectiveness of the maintenance assignment.\nFinally, an apartment purchaser can have the interior decorator show them what the finished kitchen could look like while they are standing in the shell of the building, by pointing a tablet at the relevant location. As part of a pilot project with the Swiss railways (SBB), you can already take a virtual walk on your smartphone through the main station in Zurich. The list of the many other opportunities for tourism, marketing, media and entertainment is well beyond the scope of this article.\nHeadsets and glasses: not if, just when\nAlthough xR glasses could certainly be improved in many ways, the question is not whether they will come, but when. They are particularly suitable for MR applications, while Augmented Reality, as we already mentioned, is more at home on mobile phones and tablets. For solution providers, what will make or break them will be how they generally deal with the topic of xR. From the point of view of software and content, the companies most likely to succeed in the long term are those that understand the whole gamut of Extended Reality as a continuum, and perhaps even adopt it as their core identity – unlike those that focus on a fixed point in this continuum. Especially in the business world, there is huge potential for xR, as the example applications described above demonstrate. Although specific applications are already on the market, there is still a need for improvement in both hardware and software – for example comfortable glasses, field of view, voice recognition, eye tracking, gesture control and performance. But just sitting back and waiting is not the right approach. You can already deduce from today’s xR glasses how they will work in future, prepare for it, and gain some important insights.\nWhere is this heading?\nLike any technology revolution, Extended Reality brings opportunities and risks. One thing is certain: the boundaries between what we know physically and virtual reality will disappear one day. It will no longer be “either/or”; we will transition seamlessly between the real world and the computer generated world. One day children will also play, discover and be amazed in Mixed Reality. At the Game Technology Center of the Zurich Federal Institute of Technology, a team led by Bob Sumner is researching Augmented Creativity. Figures in painting books come to life, and visits to the Art Museum become a creative game for children rather than a boring duty. How will we learn to handle all this? Will we still be able to distinguish the real world from the artificial one? How will it affect our memories: what was real and what was not? Mobile phones could become obsolete in the not-too-distant future. We will develop services that we cannot even imagine today, and use them via mobile xR. With so much uncertainty and so many new things, getting advice from experts is becoming more and more important. Because, as so often, the question will be whether all these possibilities are actually useful.']	['<urn:uuid:45faccf3-68a0-4a38-95ea-b7ba9fcd39f5>', '<urn:uuid:71030360-dd03-464f-8617-e2f305842132>']	open-ended	direct	long-search-query	similar-to-document	comparison	expert	2025-05-13T06:27:57.068978	9	118	2425
10	what is special about golden stool ashanti kingdom never touch ground	The golden stool is so precious that not even the monarch may sit on it. It is believed to be the source of the Ashanti nation's strength and bravery, and must never touch the ground. It must be 'fed' at regular intervals, as it is believed that if it becomes hungry, it might sicken and die, taking the Ashanti Kingdom with it. The stool is believed to have descended from heaven in a peal of thunder in the 18th century and serves as both a shrine, a sacred symbol and a repository of ancestral forces.	['Photos At the 25th Anniversary Jubilee celebrations of Ghana’s Asantehene, the Chief Sword Bearer accompanies the king. His duty it is to absorb evil intent directed toward the monarch. He is recognised by an eagle feather headdress featuring a pair of gilt ram’s horns.The Asantehene, Otumfuo Opoku Ware II, is carried to his Silver Jubilee in a Palanquin. He is shielded from the sun by enormous umbrellas fashioned from silk damask, reflecting the wealth and power of the Ashanti Kingdom. Special attendants run alongside the palanquin supporting the weight the king’s arms laden with gold jewelry.The most honoured guest at the Jubilee is the Queen Mother, Nana Afua Kobi, who arrives in her palanquin surrounded by fan bearers. Known as Asantehemaa, she is regarded as the true mother of the nation, the most powerful woman in its matrilineal society, and the one who is responsible for the selection of the King.The Chief Sword Bearer, carries the symbol of his office, a legendary ceremonial sword called Mponponsuo with a snake on its handle, which is used whenever allegiance is sworn to the king. From his neck hang leather amulets covered with gold leaf. Before the ceremony, this jewellery is ritually washed and the liquid is then sprinkled on the king and his court to protect their souls and those of the nation.Paramount chiefs from all over the Ashanti nation arrive to honour the king. They are shielded from the sun by enormous umbrellas fashioned from silk damask, reflecting the wealth and power of their owners.The golden stool, is so precious that not even the monarch may sit on it. The stool is believed to be the source of the nation’s strength and bravery, the Ashanti have gone to war several times to protect it. It must never touch the ground and must be “fed” at regular intervals, for if it should become hungry, it might sicken and die, and with it would perish the Ashanti Kingdom. Believed to have descended from heaven in a peal of thunder in the 18thC, it serves as both a shrine, a sacred symbol and a repository of ancestral forces.The bunch of keys carried by the key bearer shows that every door in the Ashanti palace is locked. Thus, the building is secure.Sitting in state at the Jubilee, the Asantehene wears robes made from traditional Kente cloth. Known as “the cloth that befits kings.”, Kente denotes prestige and elicits both respect and humility from all those who understand its symbolism. It is woven with motifs that refer to traditional proverbs concerning kingship and culture. Accompanying the Asantehene is the Chief Sword Bearer whose duty is to absorb evil intent directed toward the monarch. The Sword Bearer carries a legendary ceremonial sword called Mponponsuo and wears an eagle-feather headdress featuring a pair of gilt rams horns.This sword bearer wears a gold washed head piece and a pectoral disc marking his role as a soul washer charged with absorbing any evil aimed at the king.This young dancer is adorned with gold belonging to the royal treasury, among which are large breast-shaped plaques brought out at state ceremonies. Her bracelets are made from hollow-cast gold beads threaded together with ancient glass beads, which are even more valuable than the gold.An Adioukrou Queen Mother indicates her status by wearing gold turtle and crocodile talismans in her hair. Her jewelry symbolizes her husband’s substantial authority and worth. This ostentatious display is known as the “coming of wealth” ritual, and publicly declares that a man has reached an impressive stage in the accumulation of riches. Sprinkled on her face is gold dust, once the main currency of all Akan people.Female court dancers perform the Adowa, a traditional Ashanti dance that delights the royal assembly with provocative movements and complex foot work.Ashanti paramount chiefs delight in the festive atmosphere: the chief greets his subjects with joy from his palanquin. Following him are large wooden Fontomfrom drums which “speak” of the king’s ancestry Ashanti paramount chiefs delight in the festive atmosphere: the chief greets his subjects with joy from his palanquin. Following him are large wooden Fontomfrom drums which “speak” of the king’s ancestry.Safeguarding his chief, a young Soul Bearer wears a gilded ram’s horn headdress, gold amulets and feathers. These talismans protect the chief from danger.The principal spokesmen for Ashanti chiefs are called linguists, or Okyeame, who act as intermediaries between leaders and those who wish to address them. The Akan say “a linguist makes the chief’s words sweet” and “there are no bad chiefs, only bad messengers”. They repeat the words of both speakers in a highly poetic language, and a chief’s fame can depend on their eloquence. The Asantehene has thirteen senior and three junior linguists: most paramount chiefs have between four and eight. The linguists carry a distinctive staff, a symbol of authority, called Okyeame Poma, with carved and gilded finals representing proverbs. Nuggets of traditional wisdom, these proverbs address subjects and situations with cautionary wit.The Proverbs illustrated by these linguist staffs are: Top Left: “No matter how fat the frog grows it can never surpass the mudfish.”( A chief rules despite the power of his peers.) Top Centre: “The power of the eagle shows not only in the air but on land.” Top Right:“The chief holds the key to the treasury.” Bottom Left: “When the kite’s away the hawk sits on its eggs.” (In the king’s absence the throne is always guarded by his kin.” Bottom Centre: “See no evil, hear no evil, speak no evil.” Bottom Right: “Food is for the man who owns it, not for the hungry man.” (Work before enjoyment)This Ashanti paramount chief wears a medallion and headband decorated with stylized moon and star motifs, reflecting the proverb, “The evening star, desirous of being married, always stays close to the moon.” The design signifies fidelity, both of a husband to his wife, and of a subject to his king.Top Left: The gold jewelry worn by Ashanti royal guests at the Jubilee is not only visually impressive but also bears powerful symbolic meaning. Bottom Left: The starburst ring seen on the hand of the Ashanti chief is named after a delicious fruit, and reflects the proverb, “It may not speak, but it breathes,” suggesting a leader who is calm but able to exert authority when opposed. The smaller ring features a palm beetle design, which refers to a proverb that teaches patience is a virtue. Top Right: The Asantehene rests his feet on a footstool that prevents evil spirits entering his body from the ground. Bottom Right: The sandals of Akan chiefs are covered with protected gold-leaf talismans.The Asantehene often wears a gold ring on every finger, each one referring to his exalted personality traits. His arms are so heavily laden with gold jewelry that when he moves they must be supported by a special attendant.']	['<urn:uuid:b6d05ed9-6613-499f-b66e-4c150f8be1ed>']	factoid	direct	long-search-query	similar-to-document	single-doc	novice	2025-05-13T06:27:57.068978	11	95	1140
11	What percentage of GC content is recommended for primers?	The recommended GC content for primers is 50 to 60 percent.	"[""Discussion of all aspects of biological molecules, biochemical processes and laboratory procedures in the field.\n5 posts • Page 1 of 1\nI need help with primer design please. I want to design primers for Mus musculus GMCSF gene. I found it's cDNA but it's too long so I take a part of it where starts with the initiation codon ATG as follows:\n1 ggtcagactg cccaggcagg gtgggaaagg cctttaaagc agcccgcagg tgggctgcca\n61 gttcttggaa gggcttatta atgaaaaccc cccaagcctg acaacctggg ggaaggctca\n121 ctggccccat gtatagctga taagggccag gagattccac aactcaggta gttcccccgc\n181 ccccctggag ttctgtggtc accattaatc atttcctcta actgtgtata taagagctct\n241 tttgcagtga gcccagtact cagagagaaa ggctaaggtc ctgaggagga tgtggctgca\n301 gaatttactt ttcctgggca ttgtggtcta cagcctctca gcacccaccc gctcacccat\n361 cactgtcacc cggccttgga agcatgtaga ggccatcaaa gaagccctga acctcctgga\n421 tgacatgcct gtcacgttga atgaagaggt agaagtcgtc tctaacgagt tctccttcaa\n481 gaagctaaca tgtgtgcaga cccgcctgaa gatattcgag cagggtctac ggggcaattt\n541 caccaaactc aagggcgcct tgaacatgac agccagctac taccagacat actgcccccc\n601 aactccggaa acggactgtg aaacacaagt taccacctat gcggatttca tagacagcct\n661 taaaaccttt ctgactgata tcccctttga atgcaaaaaa ccaggccaaa aatgaggaag\n721 cccaggccag ctctgaatcc agcttctcag actgctgctt ttgtgcctgc gtaatgagcc\n781 aggaacttgg aatttctgcc ttaaagggac caagagatgt ggcacagcca cagttggaag\n841 gcagtatagc cctctgaaaa cgctgactca gcttggacag cggaagacaa acgagagata\n901 ttttctactg atagggacca ttatatttat ttatatattt atatttttta aatatttatt\n961 tatttattta tttatttttg caactctatt tattgagaat gtcttaccag aataataaat\n1021 tattaaaact ttt\nI designed these primers but have no idea if it is good or not.\nCAA GCATGC ACCATGTGGCTGCAGAATTTA (forward primer)\nCAA: for protecting my restriction site during PCR\nGCATGC: restriction site\nACC: Kozak sequence\nCAA GGTACC TTACCTGGGCTTCCTCATTTT (reverse primer)\nI used pearlprimer,there it says for dimers:\nForward vs. Forward: -4.81 kcal/mol (Is it much?)\nForward vs. Reverse: -0.45 kcal/mol\nReverse vs. Reverse: -1.57 kcal/mol\nMy forward primer Tm is 60.78\nMy reverse primer Tm is: 59.79. But these Tm values are without restriction site,kozak sequence only ACCATGTGGCTGCAGAATTTA for forward and TTACCTGGGCTTCCTCATTTT for reverse. Should I calculate Tm with kozak, restriction site included again??\nI will be grateful if someone help me please, it is very important for me\nDon't anyone know primer design? Please I really need help to start my reseach project. It is my first time designing primer so I have no idea if I do the design right or not?\nKindly request you to give a hand\nI would really like to know too! honestly there are so many ways and methods on web I found. The thing is maybe I dont have the courage to apply it without returning to an experianced person!\nWill follow up the thread...\nAHH, Gravity! Such a cold cruel mistress.\nSorry I was not able to respond to your question earlier. Unfortunately, I just joined. Hopefully I still could provide some assistance.\nThere are several guidelines for designing primers for PCR or sequencing. (1) The primer length should range 18 to 22 bases. Your primers are 21 bases in length and should be okay. (2)50 to 60 percent GC content. Your primers have 43 percent GC content. However, since they are 21 bases in length, this should also be okay. (3) Should have a GC lock. 2 of 3 of the 3 prime bases should be G or C with the final 3 prime base G or C. The primers you have listed are AT rich along the 3 prime end. They could still work as many primers lacking the GC lock have before. But it is a guideline to remember in the future.\nSpecifically for PCR forward and reverse primers, the Tm values should be within 4 degrees.\nI would recommend including the Kozak sequence and restriction site in the Tm values. Basically you have tailed 21 base length primers with these added sequences. During the first round of PCR, the additional bases will be included in the amplified product. Therefore, the Kozak sequence and restriction site will become part of the priming site.\nHopefully you will find this information helpful at this late date.\nSorry, I forgot to add one thing. I reviewed the primer sequence for secondary structure. It appears as though the forward primer has a 5 base compliment to itself (CTGCA). This likely accounts for the higher potential of primer dimer. Probably not to big of a concern. The reverse primer actually has a 7 base compliment to the product sequence beginning at base 308. I think your primers are okay for both.\n5 posts • Page 1 of 1\nWho is online\nUsers browsing this forum: No registered users and 0 guests""]"	['<urn:uuid:6fdaaae8-3655-4b80-8ed0-6537f83adf41>']	factoid	direct	concise-and-natural	similar-to-document	single-doc	novice	2025-05-13T06:27:57.068978	9	11	711
12	I'm having trouble with my Kenwood TK-809 radio - when I press PTT there's a carrier but no audio transmission. What's the likely cause and how can I fix this issue?	This is a common problem related to Encode Scripts. To fix it, you need to enable TX Mic audio in Advanced Options > Encode formats. Then create a script with TXM command to enable TX Mic audio. Finally, assign this script to PTT press through Main menu > System parameters > F2, selecting Encode PTT-Press and choosing your script.	"['From George Smart\'s Wiki\nThis page details the conversion and programming of some of the Kenwood PMRs available on the second hand market.\nThere are two versions of the Kenwood Programming Software (KPG-20D and KPG-67D) on this page. They are in the downloads section below. They will program the following radios:\n|Model||Class||Channels||Band||Frequency Range||Bandwidth||Program Software|\n|TK-249T||Portable Radio||200||VHF||150-174||Hardware Adjusted||KPG-20D|\n|TK-249E||Portable Radio||200||VHF||146-174||Hardware Adjusted||KPG-20D|\n|TK-349T||Portable Radio||200||UHF||438-470||Hardware Adjusted||KPG-20D|\n|TK-349T4||Portable Radio||200||UHF||420-450||Hardware Adjusted||KPG-20D|\n|TK-349E||Portable Radio||200||UHF||440-470||Hardware Adjusted||KPG-20D|\n|TK-349M4||Portable Radio||200||UHF||400-420||Hardware Adjusted||KPG-20D|\n|TK-709T||Mobile Radio||200||VHF||150-174||Hardware Adjusted||KPG-20D|\n|TK-709E||Mobile Radio||200||VHF||146-174||Hardware Adjusted||KPG-20D|\n|TK-809T||Mobile Radio||200||UHF||438-470||Hardware Adjusted||KPG-20D|\n|TK-809T4||Mobile Radio||200||UHF||420-450||Hardware Adjusted||KPG-20D|\n|TK-809E||Mobile Radio||200||UHF||440-470||Hardware Adjusted||KPG-20D|\n|TK-809M4||Mobile Radio||200||UHF||400-420||Hardware Adjusted||KPG-20D|\n|TK-762GE||Mobile Radio||8||VHF||146-174||Wide or Narrow||KPG-67D|\n|TK-762G(N)E||Mobile Radio||8||VHF||146-174||Narrow Only||KPG-67D|\n|TK-760GE||Mobile Radio||128||VHF||146-174||Wide or Narrow||KPG-67D|\n|TK-760G(N)E||Mobile Radio||128||VHF||146-174||Narrow Only||KPG-67D|\n|TK-862GE||Mobile Radio||8||UHF||440-470||Wide or Narrow||KPG-67D|\n|TK-862G(N)E||Mobile Radio||8||UHF||440-470||Narrow Only||KPG-67D|\n|TK-860GE||Mobile Radio||128||UHF||440-470||Wide or Narrow||KPG-67D|\n|TK-860G(N)E||Mobile Radio||128||UHF||440-470||Narrow Only||KPG-67D|\n|TK-260GE||Portable Radio||8||VHF||146-174||Wide or Narrow||KPG-67D|\n|TK-260G(N)E||Portable Radio||8||VHF||146-174||Narrow Only||KPG-67D|\n|TK-260G(N)T||Portable Radio||8||VHF||146-174 OR 136-150||Narrow Only||KPG-67D|\n|TK-270GE||Portable Radio||128||VHF||146-174||Wide or Narrow||KPG-67D|\n|TK-270G(N)E||Portable Radio||128||VHF||146-174||Narrow Only||KPG-67D|\n|TK-270G(N)T||Portable Radio||128||VHF||146-174||Narrow Only||KPG-67D|\n|TK-360GE||Portable Radio||8||UHF||440-470 OR 403-430||Wide or Narrow||KPG-67D|\n|TK-360G(N)E||Portable Radio||8||UHF||440-470 OR 403-430||Narrow Only||KPG-67D|\n|TK-370GE||Portable Radio||128||UHF||440-470||Wide or Narrow||KPG-67D|\n|TK-370G(N)E||Portable Radio||128||UHF||440-470||Narrow Only||KPG-67D|\nThese programs, Kenwood KPG-20D and Kenwood KPG-67D programming software, seem to be freely availiable and various people are distributing it freely. I could not find a manual or an EULA for the software - I have assumed it is freely distributable. If this is not the case, I will remove this software immediately.\n- Kenwood KPG-20D Programming Software\n- Kenwood KPG-56D Programming Software\n- Kenwood KPG-67D Programming Software\nThe end column of the list above will show you what version of the program you need.\nThe usage of this software is quite complex. I wasn\'t able to find a manual for this program though there is apparently one. So this small section aims to outline basic functionality.\nFrom the Main menu, enter the Basic level KPG-20D.\n- Press F3 to load a datafile. My datafile (with program from above) is called M1GEO_70.DAT\n- Set Priority channel: OFF\n- Set Preference channel: OFF\n- Pressing F7 enters the Channel menu\n- The ch column is the channel number, and it determines the channel order\n- The ds column is the string appearing on the screen for the given channel. This may be alphanumeric or numerical, depending on Main menu > Setup radio > Channel readout mode\n- tx.freq. and rx.freq. are the transmit and receive frequencies in MHz (if you cannot enter the frequency you want, see below)\n- SAT tx and SAT rx allow for CTCSS, DCS and SelCall to be set. Press F1 for more.\n- scan allows for individual channels to be include or exclude from a scan\n- clk allows for the clock frequency of the radios CPU to be moved to reduce possible interference.\n- From Main menu > Advanced options, you can select either Keys, microphone or Keys, front panel to set microphone and front panel button functions.\n- Under Main menu > Advanced options > Configuration you can select the TransLink port (the programming cable port), Licencing information, and the like.\n- Have a look around, using the help (F1) to see if you can tweak anything.\n- Set the Encode scripts (See below)\n- Return to Basic level KPG-20D from Main menu\n- Press F5 to program the radio via the TransLink cable.\n- Job done :)\nModifying Frequency Limits\nBecause Kenwood make Amateur Radio equipment as well as commercial, the software will not (as standard) accept frequencies in the amateur radio bands. This is easily rectified by editing the program\'s "".msg"" file. The two images show the TK-709 T frequency range has been modified from 150-170 MHz to 140-170 MHz, thus covering the 2 metre amateur bands. This process holds for other models of radio too.\nClick to enlarge\nInside your standard file browser, locate the program\'s "".msg"" file, for KPG-20D called ""Kpg-20d.msg"". Open this with your preferred HEX editor. Here, I use ""Hex Workshop v6.7"" (free).\nInside the HEX editor, search for the radio model. Here, I search for ""TK-709 T"":\nWhen you find the radio in the message file, you will need the frequency range label and the minimum and maximum frequency.\nTK-709 T;0001;150..174 MHz;000;150000000;174000000;5000;6250;-34400000;160000000.P\nChange this to be\nTK-709 T;0001;140..174 MHz;000;140000000;174000000;5000;6250;-34400000;160000000.P\nSave the HEX. Re-start the program and the frequency range will have changed. You may need to tweak the receiver tuning to improve sensitivity.\nA common problem reported is that when pressing PTT, the radio transmits a carrier but no audio. This is probably due to the Encode Scripts (left image). These are set already in M1GEO_70.DAT. Under Advanced Options > Encode formats: F4 and F5 go through scripts. TXM enables the TX Mic audio - This fixes the problem with no TX audio.\nYou next need to assign this to the PTT press (right image). From the Main menu > System parameters > F2. Use the up/down arrows to select Encode PTT-Press. Then select the script you created above: Use Insert key to get list of scripts.\nClick to enlarge\nWhen the PTT button is pressed, the script (here called TXPRESS) is run. This sets the modulation source to be the microphone. Job done.\nIf you require sending tones, data, etc. this can be done with Encode scripts. Check out the Kenwood documentation in the section below. A good example is if you have programmed CTCSS or DCS options in the SAT (subaudible tones) you need to enable their transmission, with the SCTP instruction after the TXM instruction in the Encode PTT-Press script.\nThis software is much simpler than the KPG-20D software. There are no encode scripts to worry about. I haven\'t had time to write this section up properly with images yet, but it\'s fairly obvious. I had results pretty much instantly with this program.\nRunning under DOSBox\nIf you are running an operating system other than Microsoft DOS or a DOS based version of Widnows (95 or 98), for example Ubuntu Linux or Windows XP/Vista (God help you)/7 you are likely to have trouble with running DOS programs. For some reason, Microsoft seem to excel at removing backwards compatability from their software. A simple away around this is to use DOSBox. DOSBox is a brilliant piece of software, for anything like this!\n""DOSBox is a DOS-emulator that uses the SDL-library which makes DOSBox very easy to port to different platforms."" -- http://www.dosbox.com/information.php\nUsing DOSBox we can run the Kenwood programming software under newer versions of Windows (or any other OS supported by DOSBox). It\'s pretty simple. Here we work through for the KPG-20D software, but the process for KPG-67D is very similar. Adjust the paths as required:\n- Get DOSBox. Install it.\n- Edit Dosbox.conf to set the serial port settings. You need to set serial1. Change com1 to whatever com port you need. Use ttyS0 for the first serial port on UNIX systems. Check Dosbox.conf for details. Under Windows, use DOSBox x.xx Options to edit this file. Under UNIX, it\'s in /home/USER/.dosbox/. Here I use a USB-Serial adapter, which is at /dev/ttyUSB0.\n- serial1=directserial realport:ttyUSB0\n- Run DOSBox. You need to mount your hard drive so you can access it in the DOSBox enviroment. At the DOSBox terminal:\n- mount c c:\\\n- cd DOCUME~1\\CHRIS\\DESKTOP\\KPG-20D\\ (change directory into wherever you extraged the program - here the desktop)\nRefer to the usage section above for how to actually use the programs to set up the radios.\nClick to enlarge\nSome useful documentation regarding the Kenwood Radios mentioned on this page..\n- Kenwood KPG-20D Manual\n- Kenwood ICM Functional Specification\n- Microphone instruction and service manuals.\n- Notes regarding the KPG-20D Software\nThis section details the programming of a Kenwood TK-809 (T4) radio. Many of the radios in this series are the same, and use the Kenwook KPG-20D programming software. The Kenwood KPG-20D software is available on the internet and on many user groups. The version I have came from the radio-programming Yahoo group. I have also included a copy on this page with my channel data down the page.\nThe radio I mention (TK-809 T4) is shown below\nInside the radio, there are 3 variable resistors that allow you to adjust certain parameters. The red pot allows you to set the deviation on the radio. This is the same as microphone gain. The green pot allows you to set the maximum RF power output. Note that there is also a setting in software, allowing you to set (typically) 5 watts or 25 watts. You should set this to 25 watts when the radio is in the high power (25 watt) mode. The blue pot allows you to set the squelch level.\n|Red||Set the deviation level|\n|Green||Set the high RF power (set in software) level|\n|Blue||Set the squelch level|\nThe data file (M1GEO_70.DAT included in the KPG-20D software) includes 432MHz to 435MHz at 25KHz spacing and also has PMR-446 frequencies programmed in. There is no CTCSS or SellCall data set, but this may be modified inside the program. It was intended for the TK-809 T4 radio, but may fit others.\n|Standard LCD Display showing frequency, 3_500 translates to 433.500.|\n|The LCD Display changes to reflect that there is a TX shift for repeater use.|\n|PMR 446, Channel 1 through 8.|\n|All segments and symbols on the LCD to test display.|\nFrom the Kenwood ICM Manual:\n|Err 1||Hardware Fault: Tested on power-up. No real meaning behind this, other than something is wrong with the hardware|\n|Err 2||EEPROM Error: Tested on power-up. This means that the program/channel data is corrupt (CRC error). Try reprogramming?|\n|Err 3||PLL Out of Lock: Tested continuously. Appears when PLL is out of lock in TX or RX. Adjust VCO?|\nThis radio is similar to the TK-809, though I believe slightly newer. The 862G is an 8 channel radio that is programmed by the Kenwood KPG-67D software.\nThis radio is similar to the TK-862G(N), but is the VHF version. The 762G is also 8 channel radio that is programmed by the Kenwood KPG-67D software.\n- M1GEO 2M APRS (RAR compressed DAT file) - APRS Data file, contains some club net frequencies, APRS frequency and a few FM simplex channels.\nThe microphone socket on the this series of Kenwood radio has a 6-pin connector on the front panel. Connections for the Kenwood KMC-18 microphone are given below. There is a Instruction Manual and a Service Manual for the microphone.\n|2||PSB||Power Supply (+13.8 volts)|\n|4||PTT||Press To Talk (Transmit)|\n|5||ME||Microphone Earth (ground)|\n|6||MIC||MIC/DTMF signal output|\n|7||HK2||Hook switch output (I\'ve no idea what this does yet?!)|']"	['<urn:uuid:61f5b1a8-3f84-4042-9848-bc58ef005879>']	factoid	with-premise	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-13T06:27:57.068978	31	59	1726
13	I teach economics - what's the link between scarcity and emotional investing?	Scarcity, which refers to limited resources to satisfy economic wants, affects how people make choices. When making investment decisions under scarcity conditions, people's choices are often influenced by psychological biases rather than pure economic rationality - they tend to feel the pain of losses more than the joy of gains, and follow herd mentality rather than making optimal decisions to maximize their wealth.	"['A point on the frontier of the production possibilities curve is:\nAttainable and resources are fully employed\nWhich of the following would be a positive economic statement?\nBankers are now charging higher interest rates on credit cards to cover the increased cost of loaning funds to consumers\nRational behavior implies that people will make different choices because their circumstances and available information differ\nWhen an economist says that there is ""too much of a good thing,"" the economist is suggesting that:\nThe marginal benefit of the thing is less than the marginal cost\nMicroeconomics is the study of economics from the standpoint of:\nSpecific economic units which make up our economic system\nFrom an economic perspective, when consumers leave a fast-food restaurant because the lines to be served are too long, they have concluded that the:\nMarginal cost of waiting is greater than the marginal benefit of being served\nWhich is an illustration of a microeconomic question?\nWill a new type of television set increase the number of buyers?\nWhat is a major opportunity cost of going to college on a full-time basis?\nThe foregone income that could be earned working full-time job\nRefer to the above production possibilities curves. Curve (a) is the current curve for the economy. The movement from curve (a) to curve (b) suggests:\nAn improvement in capital goods technology but not in consumer goods technology\nRefer to the above graph. The marginal opportunity cost of the fourth unit of bread is\n4 units of drill presses\nThe term scarcity in economics refers to the fact that:\nNo country can produce enough products to satisfy everybody\'s economic wants\nWhich one of the following would be a normative economic statement?\nThe worsening balance of trade must be corrected if this nation is to remain competitive in the world economy\nEconomic theory involves the logical development of hypotheses which are then tested against actual outcomes\nWhich situation would most likely cause a nation\'s production possibilities curve to shift inward?\nThe destruction from bombing and warfare in a losing military conflict\nWhich of the following would be a normative economic statement?\nThe government should raise taxes to bring in $10 billion more in revenue next year\nThe general concern of economics is with the study of the:\nOptimal use of limited productive resources to satisfy economic wants\nA schedule or curve that shows the various combinations of two products a consumer can purchase with a specific amount of money income is:\nA budget line\nWhich would be considered a macroeconomic study? A study of the effect of:\nGovernment spending to increase employment\nWhat is the best economic explanation for why a person would drop out of college to take a job or start a business?\nIf the expected future benefits from starting a business are greater than the costs\nEconomics is a social science concerned with:\nThe best use of scarce resources to achieve the maximum satisfaction of economic wants\nAs a student of economics, when you speak of scarcity, you are referring to the ability of society to:\nSatisfy economic wants given limited resources\nThe production possibilities curve represents:\nMaximum combinations of products available with fixed resources and technology\nAfter graduating from high school, Ron Willis plans to go to college. The college tuition is $15,000 a year. But, instead of going to college, Ron could take a full-time job paying $20,000. If Ron decides to go to college, what is his opportunity cost for attending for one year?\nA reduction in the level of unemployment would have which effect with respect to the nation\'s production possibilities curve?\nIt would not shift the curve; it would be represented by moving from a point inside the curve toward the curve\nWhich question is an illustration of a macroeconomic question?\nHow does a cut in the business tax rate increase business investment in the economy?\nThe law of increasing opportunity costs says that:\nAlong a production possibilities curve, increases in the production of one type of good require larger and larger sacrifices of the other type of good\nThe combination of food and clothing shown by point F on the above graph:\nIs attainable but involves the unemployment and inefficient use of some of society\'s resources\nThe effect of specialization and international trade will:\nCause a rightward shift in a nation\'s production possibilities curve\nClara states that ""there is a high correlation between the level of people\'s education and the level of their income."" Ellie replies that the correlation occurs because ""more education is the best way to earn more income in this country.""\nClara\'s statement is positive and Ellie\'s statement is normative\nThe statement that ""the unemployment rate will increase as the economy moves into a recession"" is an example of:\nThe role of the entrepreneur in society is to:\nBring the factors of production together and take the risks of producing\nAssume that a consumer has $12 in income and she can buy only two goods, apples or bananas. The price of an apple is $1.50 and the price of a banana is $0.75.\nIf the consumer spent all of her money on either apples or bananas, how many apples or how many bananas would she be able to buy?\n8 apples and 16 bananas\nThe production possibilities curve for two products is concave because:\nAs the production of a good increases, there is an increase in opportunity cost\nRefer to the above production possibilities curves. Curve (a) is the current curve for the economy. Given production possibilities curve (a), point N suggests that the economy is\nAttaining both full employment and full production\nIf opportunity costs were constant, then the production possibilities curve would be:\nA straight line\nRefer to the above graph. Which point on the production possibilities curve would indicate that there is unemployment in this economy?\nThe concept of ""rational behavior"" suggests that:\nPeople make different choices because their circumstances and information differ\nTammie makes $150 a day as a bank clerk. She takes off two days of work without pay to fly to another city to attend the concert of her favorite music group. The cost of transportation for the trip is $250. The cost of the concert ticket is $50. The opportunity cost of Tammie\'s trip to the concert is:\nHenry wants to buy a book. The economic perspective suggests that Henry will buy the book if:\nThe marginal benefit of the book is greater than its marginal cost\nThe combination of food and clothing shown by point G on the above graph:\nIs not attainable, given society\'s available resources and technology\nThe comment that ""social security taxes must be reduced if there are to be adequate incentives to work"" is an example of a normative economic statement.', 'Behavioral Biases and Their Effect on Investors’ Decisions\nMost important decisions we make in life involve two elements: the objective, measurable facts, and our subjective views on the desirability of what is there to gain and what is there to lose by our decision. There is no formula. Both elements are important and neither is sufficient by itself. It is no different when we make decisions about risk and investments. The challenge all investors face is that while objective elements can be tracked and measured, subjective elements are sometimes influenced by personal biases and can be made with irrational thinking.\nTraditional finance theories assume that investors are rational and make optimal investment decisions to maximize their wealth. However, behavioral finance theories indicate that when making investment decisions, investors fail to remain fully rational due to various psychological biases.\nIn their groundbreaking paper, “Prospect Theory: An Analysis of Decision under Risk” (1979), Daniel Kahneman and Amos Tversky convincingly demonstrate that even when all information is available, individuals are highly susceptible to cognitive errors. They concluded that human beings are by and large irrational decision-makers.\nAs human beings, we all have certain built-in biases. We will focus on the three most prevalent: confirmation bias, loss aversion, and herd mentality.\nPeople mostly will look for information or ideas that will validate their own beliefs. For example, when watching a TV channel, viewers will choose a channel that represents their political views, and avoid those with opposed opinions (CNN and Fox News). Many times even if the person reads the two sides of an argument/opinion, the confirmation bias will cause the person to only remember the information which confirms his thoughts about the topic. In investments as well, investors tend to stick to one view for a long time, validating it by reading only supporting research.\nSource: Billy Ireland\nIn their research, psychologists Amos Tversky and Daniel Kahneman found that people’s attitudes toward the probability of gains (“upside risk”) may be very different from their attitudes toward the probability of losses (“downside risk”). Most people feel the pain of loss much more than the joy of gains.\nOne example is the fear of flying. We all know that the chance of an airplane accident is significantly lower than the chance of an automobile accident, yet most people are still more afraid of flying than driving. Why is that? The answer is very simple, passengers give more weight to the magnitude of an accident than to the probability of an accident. In an airplane accident, the outcome will most likely be fatal.\nWe are all social animals. It is known that people do not like to be left out of a trend or a movement. The herd mentality can be seen in the financial markets. Just think about the recent “hot” investments in bitcoin and marijuana stocks, many investors joined the party late and suffered significant losses.\nHistorical examples of herd driven bubbles and busts:\nIs there a way to avoid falling into the biases trap?\nThe answer is no; We are all human and for that we cannot eliminate 100% of the influence of these emotional biases. We can, however, minimize their effect on our investment decisions by having a well thought out methodology that takes into account the objective facts as well as our subjective views.\nHere are some suggestions:\n- Having the appropriate tools to objectively determine potential risks and returns on an investment idea/asset are extremely important. CNBC and Bloomberg TV are not objective tools.\n- Define what risk is for you. Is it an asset price volatility, low return, or a full loss of principal? In the case of institutional investors, the risk may come from a decline in reputation or loss of job security.\n- Define in advance what risks you are willing to take and for what level of return. The best investment ideas are asymmetrical in terms of potential gain and loss, in your favor.\n- Remember you can always be, and many times will be, wrong. But be able to assess what the implications are of you being wrong and manage that risk accordingly.\n- Have a colleague with an opposing opinion “break” your investment thesis to test the strength of your idea.\n- When the fear and discomfort, or enthusiasm, you feel about an investment idea is shared by almost everyone else, go back to the drawing board and retest your theses.\nJust by following these simple guidelines for decision making, you’ll be doing better than the majority of investors in the market place. Underlying fear and greed are the propellers that drive the engine – so what investors have to remember is that going against the herd is often difficult, but the best decision. We all know to buy low, and sell high – but putting that into practice is more difficult than we think.']"	['<urn:uuid:fe0ccebc-7e9b-4440-b7ce-2e16a76f4a69>', '<urn:uuid:6560f05a-d6fb-4585-b77f-5158f93815dd>']	factoid	with-premise	concise-and-natural	distant-from-document	multi-aspect	expert	2025-05-13T06:27:57.068978	12	63	1937
14	what common artistic influence connects op art and pop art both influenced by dada bauhaus abstract techniques	Both Op art and Pop art were influenced by the Bauhaus movement and its abstract principles. Op art directly derived from Bauhaus constructivist practices focusing on design and composition, while Pop art expanded upon abstract expressionism and shared similarities with Dada through the use of found objects and images.	"['The Spirit of The Century\nAt the turn of the twentieth century, artists began using industrial materials and movement (literal and optical) to reflect the mechanical and electrical revolutions that were radically reshaping the modern world. The Italian Futurists and Russian Constructivists advocated that all art be based on speed, movement, and industrial materials, leading to the first kinetic sculpture by Naum Gabo in 1920. Russian émigré László Moholy-Nagy introduced these ideas to the curriculum of the German Bauhaus, declaring the machine “the spirit of this century.” Succeeding Moholy-Nagy in 1928, Josef Albers continued to advance the application of science to art, developing theories using color and geometry to create optical effects.\nWhen the National Socialists forced Bauhaus teachers to expatriate from Germany, the location of this creative ferment was effectively transferred to the United States, where, in 1936, a group of American artists influenced by early Modern European art formed the American Abstract Artists group. Among the founders were Burgoyne Diller and Fritz Glarner, who boasted among their members the recently immigrated Josef Albers.\nAfter World War II, the ideas generated at the Bauhaus about abstraction, motion, and color catalyzed an international exploration of Kinetic art. In 1955, Galerie Denise René, Paris, organized the first exhibition of Kinetic art, Le Mouvement, introducing works by Yaacov Agam, Pol Bury, Alexander Calder, Marcel Duchamp, Robert Jacobsen, Jesús-Rafael Soto, Jean Tinguely, and Victor Vasarély. During the late 1950s in Düsseldorf, Germany, Heinz Mack, Otto Piene, and, later, Günther Uecker founded a Europe-wide movement named Group Zero that was against the use of technology for war, and in support of its use in art.\nBy the 1960s, Kinetic art had spread to the U.S. The Howard Wise Gallery, New York, organized numerous exhibitions between 1960 and 1970. In 1968, the Nelson-Atkins Museum, Kansas City, organized The Magic Theatre, an unprecedented sensory exhibition developed by engineers and artists. Capturing the rising trend, popular theorist Marshal McLuhan looked specifically to artists to transform our postwar nation into a technological culture: “The serious artist is the only person able to encounter technology with impunity, just because he is an expert aware of the changes in sense perception.”\nAfter the National Socialists closed the Bauhaus in 1933, László Moholy-Nagy and other Bauhaus instructors fled Nazi Germany and came to the United States, where they spread their art and design theories at schools such as Black Mountain College, Illinois Institute of Design, MIT, and Yale University. As pupils of Josef Albers at Yale, artists Richard Anuskiewicz and Julian Stanczak were informed by the Bauhaus artist’s color theories and developed them into what has become known as Op art. In a 1964 article, Time magazine coined the term “Op art” to describe this new, intense visual art style that had erupted across the Western world and spread from art into fashion and graphic design. American Op artists were particularly influenced by Yaacov Agam, Bridget Riley, and Victor Vasarély to create illusions of motion and volume by employing moiré patterns and shifting images that disrupted the retinal focus and created after-images. Op art preyed upon the fallibility of vision to create the sense of movement. The fashion for this art movement crested in 1965 with a series of important international exhibitions.\nThe Projected Image\nA number of people, including Thomas Edison (the inventor of the light bulb), experimented with various motion picture apparatuses in the mid-1890s. Incorporating such scientific pursuits into an art form, László Moholy-Nagy strove to explore “the new culture of light” in creating his Light-Space Modulator (1930), a kinetic sculpture with an electric motor that projected light. Through the introduction of television, video recorders, and computers, artists gained access to the new media of light, sound, and motion. Artists began to utilize the black box environment of the cinema as a theater for creating immersive artistic experiences that stretched pictorial imagery across physical space. At this time, we see the confluence of art film, theater, and Kinetic art developed into video and installation art, arguably one of the defining artistic genres of contemporary art.\nThe extraordinary popularity of Op art spread to fashion and design; yet, the intensity of the visual stimulation exhausted the retinas of a generation and its vogue quickly faded in the late 1960s. Critics began to deride the trend as based simply on visual effects. As a response to the perceived excess of Op art and its predecessor Abstract Expressionism, artists and critics sought to reduce art to simple geometric forms and pure, brilliant color. In 1964, critic Clement Greenberg curated an exhibition titled Post Painterly Abstraction, in which he endeavored to define a formal theory for the evolution of painting from the gesture of Abstract Expressionism to a hard-edged abstraction that created an “optical” effect. Beginning in the 1950s, artists developed Color Field painting, geometric abstraction, and, eventually, Minimal art based on these principles. Painters Gene Davis, Al Held, and Frank Stella created differing visions of art concerned with the direct experience of color and form. Frank Stella famously proclaimed: “What you see is what you see.”\nTouch of the Hand, Click of the Mouse\nKinetic art, geometric abstraction, Op art, and the projected image still influence artists working today. Technological advances over the past twenty-five years, from the personal computer to wireless communications to digital editing and imaging in video, have provided artists with new tools. Artists responding to these new technologies continue to adopt the visionary ideas of the Bauhaus, adapting them for the twenty-first century. Josiah McElheny employs the Walk-In Infinity Chamber technology to present his finely crafted versions of 1950s modern design in a reflective box that suggests the melding of past and future in a continuous space.\nAs our world becomes ever more based in the flat digital screens of televisions, computers, and cell phones, people increasingly crave the human hand in art and artwork that creates a pure sensation. Critic Dave Hickey prophesized that, “the issue of the nineties will be beauty” (1993). Indeed, a new generation of artists such as Michelle Grabner, Bruce Pearson, and James Siena has made works characterized by their sensuousness— rich in color and intense with pattern. These artists emulate the stimulating visual quality of Op art in the sixties, while maintaining conceptual foundations that reference advertising, architecture, and scientific systems, to create what one curator coined as “post-hypnotic.”\nContemporary Video Projections\nFrom television to movies, the moving image is the medium that has helped define and shape our culture. Today’s computerized formats in film, video, and light projections have evolved dramatically from their original models, and as in the past, artists have adapted to these technological advances. From stop animation to digitally manipulated effects, the infinite potential of this medium has been unleashed. Techniques such as collage have translated to video, as demonstrated in the Museum’s 2005 exhibition CUT: Film as Found Object in Contemporary Video. Within the show, editing techniques were likened to physical properties such as to stretch, to remove, to match, and to arrange. For the duration of Sensory Overload, the Museum will rotate contemporary videos from its Collection and works on loan. The range of subjects and approaches to the medium will speak to the techniques of CUT, among others.\nSee it first. See it free.\nJoin or Renew\nBecome a Museum Members today!\nJoin Chief Curator Joe Ketner for a brief, informative tour of works featured in Sensory Overload.', 'Pop art employs aspects of mass culture, such as advertising, comic books and mundane cultural objects. It is widely interpreted as a reaction to the then-dominant ideas of abstract expressionism, as well as an expansion upon them. And due to its utilization of found objects and images it is similar to Dada.\nPop art is aimed to employ images of popular as opposed to elitist culture in art, emphasizing the banal or kitschy elements of any given culture, most often through the use of irony. It is also associated with the artists\' use of mechanical means of reproduction or rendering techniques.\nMuch of pop art is considered incongruent, as the conceptual practices that are often used make it difficult for some to readily comprehend. Pop art and minimalism are considered to be art movements that precede postmodern art, or are some of the earliest examples of Post-modern Art themselves.\nPop art often takes as its imagery that which is currently in use in advertising. Product labeling and logos figure prominently in the imagery chosen by pop artists, like in the Campbell\'s Soup Cans labels, by Andy Warhol. Even the labeling on the shipping box containing retail items has been used as subject matter in pop art, for example in Warhol\'s Campbell\'s Tomato Juice Box 1964, (pictured below), or his Brillo Soap Box sculptures.\nOp art, also known as optical art, is a style of visual art that makes use of optical illusions.\n""Optical art is a method of painting concerning the interaction between illusion and picture plane, between understanding and seeing."" Op art works are abstract, with many of the better known pieces made in black and white. When the viewer looks at them, the impression is given of movement, hidden images, flashing and vibration, patterns, or alternatively, of swelling or warping.\nOp art is derived from the constructivist practices of the Bauhaus. This German school, founded by Walter Gropius, stressed the relationship of form and function within a framework of analysis and rationality. Students were taught to focus on the overall design, or entire composition, in order to present unified works.\nWhen the Bauhaus was forced to close in 1933, many of its instructors fled to the United States where the movement took root in Chicago and eventually at the Black Mountain College in Asheville, North Carolina, where Anni and Josef Albers would come to teach.\nhe term first appeared in print in Time magazine in October 1964 in response to Julian Stanczak\'s show Optical Paintings at the Martha Jackson gallery, though works which might now be described as ""op art"" had been produced for several years previously. For instance, Victor Vasarely\'s painting, Zebras (1938), is made up entirely of curvilinear black and white stripes that are not contained by contour lines.\nConsequently, the stripes appear to both meld into and burst forth from the surrounding background of the composition. Also the early black and white Dazzle panels of John McHale installed at the This Is Tomorrow exhibit in 1956 and his Pandora series at the Institute of Contemporary Arts in 1962 demonstrate proto-op tendencies.\nIn the 1960s Arnold Schmidt (Arnold Alfred Schmidt) had several solo exhibitions of his large, black and white shaped optical paintings exhibited at the Terrain Gallery in New York. Some members of the group Nouvelle Tendence (1961-1965) in Europe also were engaged in Op art as Almir Mavignier and Gerhard von Graevenitz, mainly with their serigraphics.\nThey studied optical illusions. The term ""Op"" irritated many of the artists labeled under it, specifically including Albers and Stanczak. They had discussed upon the birth of the term a better label, namely perceptual art']"	['<urn:uuid:101d1149-f292-49fa-8211-aed90bab98fd>', '<urn:uuid:63a42a28-3a29-4d7f-83c7-3b251c1dd381>']	factoid	direct	long-search-query	similar-to-document	comparison	novice	2025-05-13T06:27:57.068978	17	49	1841
15	key parts performance management system SMART goals differences	The key components of performance management systems and SMART goals definitions have some notable differences across approaches. The TPR (Task, Procedure, Relationship) framework focuses on understanding what needs to be done, how it will be done, and how people will behave toward each other. In contrast, the traditional SMART framework emphasizes being Specific, Measurable, Attainable, Relevant and Time-bound. However, there is an enhanced SMART2 standard that expands these components: Specific & Short focuses on unambiguous purpose, Measurable & Meaningful emphasizes relevant progress indicators, Attainable & Assigned stresses owner confidence, Relevant & Results highlights visible intended impact, and Timelined & Traceable ensures contribution to higher goals in required timeframes. Both approaches aim to improve performance, but they emphasize different aspects - TPR focuses more on behavioral and procedural elements, while SMART frameworks concentrate more on goal characteristics and measurability.	['Performance management is important to individuals, teams and organizations. Often even with best practices in place the stakeholders still do not achieve the expected outcomes in terms of performance and performance improvement. By focusing on the Task, Procedure and Relationship (TPR) aspects of the performance management system and implementing some TLC (Training, Leadership and Collaboration), individuals and teams can make the system work.\nI learned many years ago that only three things are important when considering any individual, team or organization activity:\n– Task: The focus of the activity and the deliverable/outcome – “What is it we/I have to do?”\n– Procedure: Is the process clear, relevant and understood – “How will I/we do it?”\n– Relationships: Individual and group behaviors and their impact – “How will we behave towards each other?”\nI use this as a checklist for activities I am involved with, whether as a leader or a participant.\nWhen we look at individual performance management in the context of teams and organizations, the same is true:\n– Task: Is there a clear and consistent understanding of what the performance management system is about? What outcomes are expected? Usually a statement of intent or definition can be helpful here.\n“To enable all staff/members to maximize their individual contribution towards achieving the aims of the team/organization in line with their position/role.”\n– Procedure: Do the participants understand how it works? And what their role is in the process? If we fail to engage individuals in the process and to have ownership for their role in the process, we get suboptimal outcomes. In the “digital era”, we need to leverage the relevant technology to achieve the system’s aims and tasks.\n– Relationships: There are many stakeholders who can be part of the individual’s/team’s performance management ecosystem. These normally include those whose input can impact the performance (direct), those who use or have a vested interest in the output (direct and indirect), and those who provide support and guidance (direct). How do we ensure they are appropriately engaged in the process and how do our values inform the behaviors and practices of the members of the ecosystem?\nBest practice models\nWhen we plan the TPR for a best practice performance management system, we often fail to consider how the plan will be executed. There are many pitfalls that can be avoided in the implementation of a performance management system. Let us take a look at some of the critical success factors:\n– Ownership of Performance: Performance within any performance system only occurs when each individual performs their role to the expected performance standard and continually strives to improve their performance. So, each individual operating alone, as part of a team and/or as part of an organization must own their own performance. The most obvious example of this is in professional team sports. Does the system allow individuals to take ownership of their own performance and performance improvement? There is much written on this topic but what it all comes down to is: Have they the required knowledge and skills? And are they motivated to set and achieve ambitious goals in line with the overall aims of the system.\n– Quality of Goals/Objectives/Key Performance Indicators (KPIs): So often do we set ourselves up for disappointment by setting a poor goal. Perhaps it’s unrealistic, undefined, unrelated or incomplete. Whatever the issue, a good approach to getting it right is to test it against the SMART2 standard:\n- Specific & Short – “Unambiguous Focus on Purpose”\n- Measurable & Meaningful – “Relevant Indicator of Progress”\n- Attainable & Assigned – “Owner Confidence in Outcomes”\n- Relevant & Results – “Visible Impact where Intended”\n- Timelined & Traceable – “Contributes to Higher Goal in the Required Timeframe”\n– Leader/Coach/Mentor Role: As an individual, interpreting what is expected of you or what you expect from yourself can be a challenge. What is an acceptable performance standard? Who are you accountable to? And are their expectations consistent? Where the individual owns and sets SMART2 goals and KPIs, their leader, coach or mentor acts as their supporting guide, helping to determine the priorities, alignment within the ecosystem, and facilitating resources for the individual to be successful and continually improve.\n– Stakeholder Engagement: Setting and achieving ambitious goals and KPIs with the ultimate aim of meeting personal and ecosystem performance outcomes requires effective and efficient engagement between the individual and the stakeholders, in particular the leader/coach/mentor and direct stakeholders. Awareness of progress, regular feedback, review and records are essential, along with ownership commitment and motivation to perform.\nA little TLC is all it takes to make performance management work\n– Training: Performance management is about Task, Procedure and Relationships. For an individual or team to perform, they need to be trained in each of these domains as they relate to performance management. An organization should aim for consistent understanding and implementation of the practices, use of related technology and behaviors that demonstrate that each individual understands:\n- What is it we/I have to do?\n- How will we/I do it?\n- How will we/I behave towards other stakeholders?\n– Leadership: Most individuals will be inspired by having some form of benchmark performance standard relating to their role and goals. The role of the leader/coach/mentor is to guide individuals and teams in finding and setting their performance benchmarks in line with the organization’s overall aims.\n– Collaboration: There are multiple different types of stakeholders in an individual’s and/or team’s performance ecosystem, which must be engaged at the appropriate level and with the appropriate frequency. Collaboration is about creating and maintaining productive relationships that enable continuous performance improvement, and modern digital and social technology can have a significant impact as part of the overall performance management system.\nDeclan Kavanagh is an international advisor and entrepreneur with over 37 years’ experience in technology-related business. He graduated in Engineering in 1979 and worked with several multinational ICT-related organizations, rising to CEO level and acquiring an ACCA & MBA along the way. He jumped into the entrepreneurial world as a consultant in 2000 and founded his own successful software services company in 2003, which was acquired by Capgemini in 2008. His work today involves advising and supporting technology and technology-enabled organizations with strategy development and execution.\nOver his career, he has had significant experience in change management as it relates to the organization and individuals, including starting, scaling, merging, demerging, right-sizing, turnaround and transformation of organizations and their performance. Much of his current work relates to “Digital Business & Workplace” performance transformation and improvement.\nHis home base is Dublin, Ireland, but his client base spans the globe. He is also author of “Advantage – A Roadmap for Entrepreneurs and Leaders in the Digital Age”.', 'What is Goal Setting?\nAll businesses share a primary goal: Success. Goal settings, aligning and tracking those goals through actions and results are critical to greater business execution…and, as a result, greater success.\nMost organizations see a dramatic increase in employee and business performance when they effectively set individual employee goals and closely tie them to the company’s overall strategy.\nThe process of setting goals should be a collaborative process between an employee and his or her manager. Whether writing long- or short-term goals, the most widely-used framework is S-M-A-R-T.\n- Specific: Well-defined to inform employees exactly what is expected, when, and how much. With specific goals, managers can easily measure progress toward goal completion.\n- Measurable: Provide milestones to track progress and motivate employees toward achievement.\n- Attainable: Success needs to be achievable with effort by an average employee, not too high or too low.\n- Relevant: You should focus on the greatest impact to the overall company strategy.\n- Time-bound: Establish enough time to achieve the goal, but not too much time to undermine performance. Goals without deadlines tend to be overtaken by the day-to-day crises.\nGoal alignment is critical for business success. It ensures that each person within your organization can see the direction for the business and know how their job fits in with the “Big Picture”. To achieve goal alignment in your organization, you must first clearly communicate your strategic business objectives across the entire company. By allowing managers to access and view the goals of other departments, your organization can greatly reduce redundancy while finding better ways to support each other. With everyone working together toward the same objectives, your company can execute strategy faster, with more flexibility and adaptability. Essentially, goal alignment strengthens your leadership and creates organizational agility by allowing managers to:\n- Focus employees’ efforts on your company’s most important goals;\n- Understand more clearly all responsibilities associated with specific goals; and\n- Strengthen accountability by assigning measurable, articulated goals visible company-wide.\nOnce you’ve established your company-wide and individual goals, the next step is tracking progress on those goals. It’s important for employees to track their progress on goals because they need to have the information available during the all-important review process. Additionally, managers need to be aware of progress on goals to step in with assistance or resources when it appears that goal targets will possibly be missed. Having this information handy is also helpful when management is not aware of all of the steps involved in reaching a goal and strong documentation assists you in discussions of past projects and successes when review time rolls around. Tracking your goals in a centralized location helps you stay on track in several ways:\n- Organize, manage and reassess your goals frequently\n- Create action plans with milestones for larger goals\n- Track your time to make sure your daily efforts are focused on meaningful tasks\nTools for Setting, Aligning and Tracking Company-wide Goals\nWhat do you do when it’s time to set goals—quarterly or annually? What is the best way to track these goals?\nGoal software is the solution to make life easier for both employees and managers alike. This software is a valuable tool to communicate goals company-wide and hold people accountable for achieving those goals in support of the company’s strategic plan. Employees can use the software when setting goals. They can use it to include smaller tasks and milestones that are basically landmarks on the way to the completion of longer-term goals with metrics to establish how success will be measured on the goal.\nGoals can be cascaded from the top down and made visible to all; everyone within the company is now fully armed with the information necessary when setting goals. They can create individual goals that support company goals and link to others if the success of their goal is dependent upon the actions of a co-worker or manager in another department or location.\nFinally, dashboards provide a snapshot of your progress on your goal setting based upon the target dates you and your manager have provided. The secret to effective goal setting and high performance: review your goals at least once a week or month to clarify your focus and use this information as a basis for goal performance discussions with your manager. You can use the opportunity to review the progress and adjust timelines or request additional resources if necessary or expand the goal once more information is gathered from other sources.\nCase Study: Avnet\nThe issue: Avnet, Inc. a Fortune 500 company, wanted to create an environment that engaged employees in the success of the company. The company looked for a software solution that would assist them with setting goals, conduct timely performance reviews, create a pay-for-performance culture and provide ongoing employee development.\nThe solution: Avnet implemented SuccessFactors goal management and performance management applications to help drive consistency across the enterprise and increase employee engagement across the company.\nThe result: Avnet increased engagement from 70 to 75%, resulting in higher performing branches and overall stronger financial performance. They found a direct link between top engagement scores and top performing branches of the company.\nEmployees who clearly understand their individual goals—and how they relate to the larger goals of the company—naturally become more engaged with their work. Successful companies realize that their achievements are linked to their ability to manage, track and communicate goals – informing their workforce and linking reward systems with individual and team performance to keep them engaged in their work. SuccessFactors Goal Management Software helps managers and employees set goals, align them to corporate goals, and track progress to measure success. Many employees may find it difficult to write SMART goals, but with our Goal Management Software, we’ve made the process easier by including a Smart Goal Wizard providing a library of targeted goals by job description so you can simply select one or write your own based upon key words in the description. Managers can use the software to assign or cascade goals to one or more members of their team, thereby communicating the importance of these goals to the overall company strategy. Employees can create calendar events to stay on track with their goals and with the increased visibility managers can view progress on team goals and take corrective action before any goals are missed. The process of setting goals, aligning them with corporate objectives and tracking them has just been made easier resulting in more time to focus on strategy and greater business execution.']	['<urn:uuid:26b45909-5117-4b77-b21b-85391f121379>', '<urn:uuid:2cb55778-5b28-4855-adad-a78adaf32441>']	open-ended	with-premise	short-search-query	distant-from-document	comparison	novice	2025-05-13T06:27:57.068978	8	138	2207
16	Which features distinguish Angry IP Scanner from KisMAC?	Angry IP Scanner is a cross-platform tool that works on Windows, Mac, and Linux without installation, offering both IP and port scanning capabilities with an intuitive interface for beginners. KisMAC, on the other hand, is a Mac-specific WiFi analyzer with restricted network card support, primarily focused on drawing network coverage maps and identifying channel usage, making it more suitable for experienced users.	['What is the Best WiFi Analyzer and How to Use One on a Mac\nThe benefits of a WiFi network come with certain complications that revolve around the implementation, security, and maintenance of the network. The flexibility and utility of a WiFi network can be very dependent on the positioning of your router, the channel that you choose to use for data transmission, and the ability of the signal to reach all intended users. In order to keep your WiFi network operating at peak efficiency, the use of tools such as a WiFi signal analyzer can be extremely beneficial.\nWhat is a WiFi Analyzer?\nA Wifi analyzer is a specific type of network analyzer that is designed to work with wireless networks. They can be obtained as an application which runs on a computer or a mobile device as well as in hardware implementations that are usually used by dedicated network engineers. A WiFi analyzer can be used in conjunction with your firewall and security programs to assist in tuning your network so it attains optimal performance.\nSome of the uses of a network or WiFi analyzer are to:\n- Provide statistics for recent and current network usage.\n- Detect bottlenecks in network traffic such as overused channels.\n- Identify dead spots in your WiFi network’s coverage.\n- Assist in determining the best location for your wireless router.\n- Monitor network traffic and the flow of data packets.\n- Display network statistics in a user-friendly interface.\nHow a WiFi Analyzer App Can Help Improve Your WiFi\nA variety of issues can cause problems for the users of a WiFi network. Among them are:\n- The unreliability of WiFi connections. If you are getting blown off the network with any regularity it could be the sign of an underlying network problem.\n- Slow data transmission.\n- Uneven WiFi coverage leading to seemingly inexplicable dead spots that pop up throughout the covered area.\n- WiFi signal leakage that can cause security issues by allowing individuals to access your network from outside your home or office.\nLet’s look at how a WiFi analyzer for your Mac can help alleviate or at least minimize these issues.\nUnreliable Connections and Dead Spots\nProperly positioning your WiFi router is an essential component in enabling it to provide the best coverage of your intended area of usage. It should be in a central location and be situated where it is free from obstructions. Putting your router in a cabinet can definitely have a negative impact on its ability to serve all of your users.\nUsing a WiFi analyzer you can display a map of your network and determine where dead spots or obstructed connectivity is impacting the network’s performance. Analyzing the data provided by the tool can be instrumental in allowing you to reposition your router to achieve better results. Your chance of improving your WiFi coverage is far greater when using an analyzer application than blindly moving your router around.\nWiFi Signal Leakage\nSignal leakage can be a major problem for both businesses and home users. Nefarious individuals can attempt to break into your network from outside your building, making it difficult or impossible to identify the attackers until they have gained access to your network.\nA WiFi analyzer can be useful in tuning your router in an attempt to keep the signal within accepted boundaries. It can also help you identify unauthorized efforts to access the network.\nSlow Data Transmission\nThis issue can also be combined with dropped connections and can often be the result of using a busy WiFi channel for data transmission. Many users simply go with their router’s default channel. In areas such as apartment buildings, where the signal from several routers can overlap, this can cause network traffic jams that slow down your access and can cause a connection to fail.\nA WiFi analyzer can help you identify the channels that are in use and enable you to find a less-used one for your network. Once you determine the channel you want to use, you can update your router’s configuration to take advantage of the information returned by the analyzer. Again, you could do this with trial and error, but using an analyzer is a much more efficient way to go.\nChoosing a WiFi Analyzer\nThere are a couple of factors that might influence your choice of a WiFi analyzer. Obviously, the platform you will run the app on is important. You need an app that supports the operating system you are using.\nYou can obtain WiFi analyzers that are freeware and do not require any financial investment. There are also commercial products available. In some case, they may have additional features not found in the free offerings.\nAnalyzing Your WiFi with KisMAC\nLet’s look at how to analyze your WiFi using the KisMAC WiFi analysis application. It is one of the best free WiFi analyzers for the Mac, but you may have issues using it due to the restriction on the network cards that it supports. It is a freeware tool that is intended for experienced users. You can use the tool to draw maps of network coverage to help you find better positioning and identify dead spots. It displays all network activity in range and allows you to see which channels are heavily used so you can pick one for your network.\nThe Best WiFi Analyzers for macOS\nHere are some alternative WiFi analyzers for the Mac that you may find helpful in troubleshooting or optimizing your WiFi network.\nNetSpot is a great WiFi signal analyzer that is available as a free download to allow you to test-drive the application before upgrading. The app displays the network information in a user-friendly interface and provides all of the details that you need to get your WiFi running at peak efficiency.\n“The easiest part about NetSpot, is everything about it. The verdict we have settled on comes after years of using subpar Wi-Fi analyzer tools that either offered a decent user interface, or the top features – but never both of those things. We can confidently conclude there isn’t a competitor that puts user experience on the front foot like NetSpot does, without holding anything back in terms of performance.” NetSpot Review at thesweetbits.com\nUpgrading to the paid version allows you to conduct surveys and draw maps of your WiFi network, making it a great tool to use when planning and installing WiFi.\nHere is another WiFI analyzer that presents its data in an intuitive user-interface. A free light version is available, with paid versions providing more features. It can help you find the best channel for your network to use and has enhanced capabilities such as spectrum analysis in the Pro version. This can help you eliminate sources of interference that are impacting your WiFi network.\nThis tool for the Mac provides detailed graphical representations of nearby WiFi networks. Advanced features such as filtering and the ability to show signal level changes over time make this a great tool for analyzing your network. You can connect to detected networks with the click of a button if you are authorized or if they are not password protected.\nMacOS WiFi Analyzer\nHolding down the option key on your Mac’s keyboard while clicking on the WiFi icon in the menu bar will give you the option to “Open Wireless Diagnostics” and scan all available wireless networks. This tool is part of the macOS operating system and may be just what you need to find the best channel for you to use.\nWe hope that this discussion of WiFi analyzers has pointed out some ways that this type of tool can help you improve your WiFi network at home or at the office. If you are experiencing any issues with your WiFi network, one of the tools mentioned above can assist in resolving your difficulties.', 'Not all Network IP scanners are created equally; let me introduce you to some of the best network scanners in the market that you can use for IP and port scanning.\nComputer networking has revolutionized how we communicate with each other, send files, and access data not directly on our devices. It has not only made communication between wired devices possible, but it has also made it possible for devices in remote locations not to have any form of wire connecting them to communicate effectively among themselves.\nOne important task in the area of networking is network scanning; with this, network admins are able to find out the devices connected to their network, and for each device, they can also investigate the ports open in them.\nThe tool for the job is known as network scanners or Lan IP scanners, and in this article, we will be recommending some of the best network scanners in the market that you can use. It might interest you to know that a good number of network scanners that you can use for network scanning are free to use.\nYou will not find it difficult using most of the tools I will discuss below as they are quite popular, and you will get helpful guides and even videos on how to make use of them on YouTube.\nTop 10 Network Scanning Tools to scan IP & Port\nHere is a list of top 10 IP scanners for Network Administrator to Manage Intranet users in your local area network.\nOpUtils – Best IP and Port Scanners\nThe OpUtils is one of the tools offered by ManageEngine, and it is one of the best IP and port scanners in the market. The company calls it an IP address and switch port management software. With this tool, network engineers are able to efficiently monitor and diagnose computer networks.\nThis tool does not only monitor IPs and ports but also has the ability to detect rogue devices in other to protect your network from intrusion. It also has support for bandwidth monitor and comes with a notification system to let you know if there is a critical issue with your server or network as a whole.\nNmap– Best Free Network Mapper tool\nThe Network Mapper tool, rightfully called Nmap, is a networkdiagnostic and security tool that you can use for scanning networks to discover the devices connected to a network and details about the devices.\nThe Nmap tool is an advanced tool for network scanning and offers you a lot of features that make network discovery and security audit possible even at a large scale. This tool is an open-source tool, and as such, you can verify how it works.\nNmap is powerful and has support for scanning huge networks. This for a reason, you will need to specify the scan range of a network; else, it will take a long time as it is designed for scanning any size of the network.\nThe tool is also portable and flexible. However, the learning curve is a bit steep, and you will need to grasp it to know how to fully make use of the free Security Scanner.\nAngry IP Scanner – Best network scanning tools\nThe Angry IP Scanner, also known simply as ipscan, is arguably one of the best network scanning tools in the market. Angry IP Scanner acts as both an IP scanner and port scanner. One thing you will come to like about this network scanner is that it is quite easy to use thanks to its intuitive interface that even beginners would understand.\nHowever, it does have support for advanced features that new users might require digging. This tool is free and open-source – and currently has over 29 million so far.\nIt works on Windows, Mac, and Linux without the need for installation. It offers support for many data fetchers and allows you to export results in many formats.\nAre you looking for an IP address manager that will help you save time and prevent costly errors? Then the IP address Manager provided by Solarwinds is here for you – even though it does not come cheap. This tool has support for automatic IP scanning and tracking, subnet discovery, hybrid DNS Management, and Infoblox integration, among others.\nThis tool has been developed for industrial-level clients, and as such, the size of your network does not matter. IP Address Manager has support for monitoring the network and alerting you should IP conflict, and other problems occur. With this tool, debugging, troubleshooting, and even managing your network as a whole becomes easy.\nIf all you need is a basic IP scanner that you can use to find the devices on your network, then the Spiceworks IP Scanner is the network scanner for you. This community-provided tool has been developed to make finding devices and their associated details easy.\nAll you need to start finding out devices in your network is to provide IP ranges, and the tool will do the scanning job for you, providing you information such as Operating System (OS), MAC address, open ports, and description, among others of each of the device on the network within the range you specified. This tool is available for only Windows and Mac.\nThe Free IP Scanner 3.3 is also another basic IP scanner that you can use to monitor your network. This tool is so easy to use that even regular users with no networking experience can use it to monitor their network.\nLet the simple interface not make you think this is an inferior tool, for its price, which is free; you get a fast and multithreaded scanner that works. How it does this is simple; it sends pings to IP addresses in an IP range you specify and see whether it will get a response or not.\nOptionally, it finds out other details, including the open ports on each device. This tool also supports the NetBIOS system.\nPRTG Network Monitor has been developed from the ground up for professional use. This tool does not only scan your network to monitor it; it also provides you a visualization tool that makes it easy to understand the report of the scan.\nThe tool monitors all the systems, devices, traffic, and applications in your IT infrastructure. One thing you will like about PRTG Network Monitor is its support for traffic analysis which is done via packet sniffing. The tool is not a free tool – it is paid, but as a new user, you are allowed to use the tool for free for up to 30 days before you will be required to make payment in order to use it.\nThis list is not complete without Wireshark, which is the de facto and widely-used network protocol analyzer. It is one of the oldest in the space. This software comes with a good number of tools included that all work together to give you a better idea of what’s happening in your computer network.\nAside from being a good IPLan scanner that reveals devices connected to your network and the ports that are open in each of the devices, Wireshark does offer other tools, which include packet sniffer, Network Instruments Observer, NetScreen snoop, Novell LANalyzer, RADCOM WAN/LAN Analyzer, Shomiti/Finisar Surveyor, and Tektronix K12xx, among others.\nThe Lapsweeper IP Scanner has proven to be one of the best IP scanners in the market that you can use to monitor your network. With this tool, you can ping computers, discover new devices in your network, grouping computers in the same IP location, and tracking IP usage in the network.\nLapsweeperhas support for scheduled scanning of the network and splitting the network into subnets to customize individual behavior. One thing you will come to like about this tool is that it allows you to exclude devices based on their types and IP address. It does allow you to import your entire network setup too.\nLast on the list of our recommended network scanners is the Slitheris Network Discovery, which is a premium IP scanner. You can only use this tool on a Windows computer. This tool is a paid tool, but you can use it to scan the first 50 devices in your network.\nThis means that the Slitheris Network Discovery is free for home users and small businesses with less than 50 devices. It has support for visual ping sweep, credential-free, and agentless Windows OS detection and fingerprinting.\nFAQs About Network IP Scanners\nWhat is the Difference Between IP Scanners and Port Scanners?\nIP scanner is the name given to most network scanners that have support for scanning computer networks for devices connected to the network and the port opened for each device.\nHowever, if you are to look at them individually, you will see that IP scanners work in a different way compared to port scanners. For IP scanners, they scan networks to discover devices, while port scanners scan devices to discover open ports.\nIs the Use of IP Scanners Illegal?\nNetwork IP scanning is not illegal. However, this does not mean you should go about scanning any network to discover the connected devices and open ports in them, as that could get you into legal trouble. Not because doing so in itself is illegal as there’s no law that makes it illegal, but the owner of the network could sue you.\nAre Free Network IP Scanners Effective?\nMany free IP scanners are surprisingly effective, and as such, you might not have the need to make use of a paid one. However, if there is an advanced feature offered by a paid network scanner that you can find in the free ones you use, then you can go ahead and make use of the paid one – but many of the free ones do work effectively.\nLooking at the list above, you can see that there are a good number of options available regardless of your operating system and even budget. Many of the network scanners are even free, which means that you do not need money to make use of some of them.']	['<urn:uuid:2e8fdbd6-db18-4c8f-b7b3-c06859f4b4bd>', '<urn:uuid:bffb3e74-e202-4a15-a2a0-e309762c1138>']	open-ended	direct	concise-and-natural	similar-to-document	comparison	expert	2025-05-13T06:27:57.068978	8	62	2997
17	How do protective gear requirements differ between Mars exploration and marching band performances, particularly regarding oxygen and temperature management?	For marching band performances, uniforms evolved from thick wool materials that caused overheating and heat exhaustion to more breathable polyester-cotton blends in the 1960s to protect musicians during hot weather performances. Modern uniforms include specialized shoes, gloves for different instruments, and moisture-wicking undershirts. For Mars exploration, the lack of a protective magnetic field and low oxygen atmosphere presents different challenges - the planet's thin atmosphere provides little protection from radiation, and any future human missions would need sophisticated oxygen supply systems. This is evidenced by findings from the Curiosity rover showing how Mars lost most of its oxygen when its magnetic field declined, leading to current low oxygen levels that make the planet inhospitable without protective gear.	['An essential part of being in a marching band is wearing and caring for your uniform.\nThe reason why marching bands wear uniforms dates back to the middle ages. During the middle ages, musicians would join local feudal armies and play to direct soldiers to the battlefields, raise morale, and energize the soldiers.\nTo show their allegiance to their army and feudal lords, musicians and soldiers would wear plumes (feathers worn on a helmet or hat). The first item of the marching band uniform that existed were hats with colored plumes.\nDuring the 17th through 19th centuries, history began to see armies wearing uniforms of the same color and similar style.\nThe French’s military uniforms were popular, as well as their ornamentation. Ornamentation included buttons, elaborate trim, and braided ropes. Because members of the military bands were enlisted soldiers and would wear the same uniform as their fellow soldiers.\nFun Fact: Due to the use of gunpowder, which would result in smoke and dust, wearing brightly colored uniforms helped the soldiers identify their men, not confuse them for the enemy.\nAn example of the “French style” military uniforms and coats.\nOver time, marching bands became more common in schools and universities.\nThe uniforms represent the history and origin of marching bands, military drum, and bugle corps. Marching bands still excite and increase the morale of others, but instead of soldiers, it is football players and the audience at games and other school spirit-related events.\nThe Modern Marching Band Uniform\nMarching band uniforms were once made from thick and heavy wool fabrics, like old military uniforms. These wool uniforms were hard to move in and caused many musicians to overheat, resulting in heat exhaustion and heat stroke.\nIf you are currently a member of marching band you will be happy to note; In the 1960s, wool was replaced with fabrics made of a blend of polyester and cotton, which were more comfortable and breathable.\nI know in the hot early summer performances especially if you live in the south it’s easy to feel like you are baking in those uniforms!\nModern marching band uniforms have five standard pieces with unique names, styles, and colors.\nMarching Shako and Plume\nThe first piece of your marching band uniform is the shako. The shako is the traditional marching band uniform hat. Shakos are tall cylinder-shaped military caps that feature multiple colors, a decorative metallic plate, a symbol related to your school, or all three!\nThe name “shako” pays tribute to the military history of marching bands and their uniform styles. In the beginning, shakos were hats that shepherds would wear in Hungary.\nThe style was adopted by the military and became a part of the uniforms of Hungarian hussar troops early in the 18th century. In the 19th century, shako-style military hats were standard in militaries across Europe and the Americas.\nShakos have either plastic or metal chain link straps that are worn under your chin (or if you are in the battery/drumline, you may wear your chin strap under your bottom lip).\nThere are many variations of style for shakos that you will see in the marching arts today. Drum majors in HBCU (Historically Black Colleges and Universities) schools and at other universities like Ohio State University wear what are often called Q-tip hats.\nNote: Check out our list of the 30 most amazing college/university marching bands!\nAlso called busby hats this website makes these specialized hats if you are looking for some for your marching band.\nQ-tip hat wasn’t all that bad – it was hollow inside and had a drawstring area that pulled closed to keep it from slipping down your head to your neck. Thus, it was the perfect place to store your money, lip gloss, candy bars, flasks, stash, etc. when traveling to an away game!-Groovymerlin *source: Flickr\nSome high school and college bands may wear cowboy hats when performing on the fields. These are another alternative form of a shako that some bands in the American South (ex: University of Texas Austin Longhorn Band).\nMarching Band Plume\nThe second piece of a marching band uniform is the plume.\nA plume is the feathers/pom-pom/streamers that are placed at the top of your shako. Plumes date back to colored plumes worn by militaries and marching musicians during the middle ages.\nMarching bands wear plumes today to not only honor the timeless military traditions, but to add style and color to their show.\nPlumes often make it easier for the audience to follow the lines created in formations as the marching band performs.\nTop TIp: Always be sure that your plume is inserted fully into your shako before stepping out on the field, so it doesn’t fall out mid-performance!\nMarching Band Jacket\nThe third piece of a marching band uniform and the most recognizable feature is the jacket.\nThere are many different styles, designs, and ornamentation that can be found on marching jackets. Marching band uniform jackets make the band look uniform, add to the visual effects of the drill, and help make shapes on the field easier for the audience to see.\nA famous brand that makes marching band uniform jackets is DeMoulin, and on their website, you can see hundreds of different uniform jacket styles and colors. Some universities that wear DeMoulin jackets include Pennsylvania State University, The University of Florida, and Clemson University. Below are the uniform jackets for the three schools mentioned.\nMarching Band Bibbers\nMarching band uniforms are called bibbers or bibs. Bibbers are overall-type pants that are worn underneath your uniform jacket.\nBibbers come in many different styles and colors, but they always have three features that are the same: shoulder straps, a long zipper, and a distinct pleat that runs down each leg.\nTop Tip: Don’t forget to always align your uniform pants at the pleats before hanging them up after wearing them to keep that crisp pleat in place.\nBibbers aren’t the most attractive or stylish pants and tend to fit very well or are super big and baggy. Everyone in a high school or college marching band will wear baggy bibbers at some point; think of it as a marching right of passage.\nBelow are examples of standard marching band uniform bibbers.\nMarching Band Shoes\nThe final piece of a marching band uniform is your shoes. Marching uniform shoes are typically white or black and look like old-fashioned nurse shoes.\nTwo of the most popular brands of marching band shoes are Dinkles and Bando, and most marching musicians call their shoes by their brand name or simply “shoes.” Marching uniform shoes are designed to last, and it is common to wear one pair of shoes all four years of high school or college.\nTop Tip: We researched what shoes are the best for marching band practice on and off the field. Check out this article to find out the results: Best Shoes for Marching Band (Read This First!)\nAdditional Accessories for Marching Band Uniforms\nAll marching band uniforms have shakos, plumes, jackets, bibbers, and shoes, but your school may have additional accessories.\nSome schools will wear gauntlets on the ends of the uniform jacket. Gauntlets date back to the Middle Ages and were popular in armor to protect a knight’s wrists from being cut. Below are examples of uniform gauntlets.\nAnother typical marching band uniform accessory is gloves.\nGloves are traditionally worn for parades, pre-game, and half-time performances. The purpose of gloves is for uniformity among all band members. The gloves are usually made of white or black cotton, and it is recommended that you buy at least two pairs of gloves so you will always have a fresh or clean pair to wear.\nBrass players wear full-fingered gloves, woodwinds will cut the tips of the fingers off so they can use their fingers to cover holes and keys on their instrument adequately, and members of the drumline or battery will rarely wear gloves.\nGloves are especially useful for Color Guard as they are tossing and catching their flags and rifles.\nSome marching band uniforms will include shoulder cords which may be a standard part of their uniform jackets.\nThese can indicate graduating seniors/ members of leadership/ or the drum major.\nShoulder cords are inspired by the French-style military uniforms of the 17th-19th centuries and are part of military dress uniforms today. Your uniform jacket will have a button near the collar that secures a shoulder flap to your jacket. Cords will be placed under the shoulder flap and can come in many different styles and colors.\nIt is popular for members of marching bands to wear a t-shirt underneath their bibbers. These shirts can be spirit shirts or include the year and show theme for your high school.\nTop Tip: If your school has a uniform shirt, you should remember to wear it because after competitions or in the stands during hot weather; you may be permitted to take off your uniform jacket.\nThe final extra accessory can be a baseball cap that all band members wear in the stands or during pep performances. Many college and university marching bands have their members wear baseball caps in the stands and require the traditional shako for march-overs (the process of marching as an entire band in a parade formation to the stadium before a game), pre-game, and halftime shows.\nMarching Band Uniform FAQ’s\nWhy do marching bands wear Napoleonic uniforms?\nMarching band uniform styles are heavily influenced by the Napoleonic era. The late 1700’s and early 1800’s in France and Europe had a distinct and strong military look. The style of the uniforms and specifically the plumes now worn by American marching bands mimic this look and haven’t deviated too far from it.\nThis look seems to be prevalent because of it’s sharp clean look and its deep history in the marching band world.\nDo you get to keep your marching band uniform?\nTypically bands will not let you keep your uniform during the season or after it is over. Most bands will have a specific storage area in the band room where they will hang the uniforms after performances. The uniforms will be kept in garment bags that zip up and have your name labeled on them.\nMany bands, especially those on tight budgets will use the same uniforms year after year. You can expect when you are a freshman you will be measured for a uniform and either use one that has been worn by a previous student or have a new one ordered.\nNote: Sometimes band members will get to keep an accessory that they used for the show. Things such as the gauntlet, cape, or other items used to modify the uniform to fit the show theme for that year.\nWhen the band does upgrade to new uniforms they will generally try and sell the old ones or donate them to another organization.\nOften when selling old uniforms your corps will allow alumni the first chance to purchase the old ones.\nWhat do you wear under a band uniform?\nAs we discussed above you will generally wear your school spirit shirt or t-shirt under your jacket. Under your bibbers, you generally wear lightweight shorts, gym shorts, or bike shorts. Some bands that perform in cold weather will wear tight-fitting longjohns or leggings under the bibbers.\nHow do you iron a band uniform?\nCheck with the manufacturer’s directions and your band director before ironing to get specific instructions for your uniform. Most uniforms can tolerate low heat.\nIf you need to reset the hem on your pants you can use a lightly clean damp cloth placed in between your iron and your uniform. This will make it easier to iron out the old hem and set the new on.\nMake sure your cloth it is colorfast (use a white one) and won’t bleed onto your uniform.\nTop Tip: Be extremely cautious about ironing over buttons, zippers, or metal work as the heat from the iron could melt or imprint the button onto the material.\nHow do you wash your marching band uniform jackets & pants?\nCare and cleaning of your marching band uniform will be specific to the type of uniform you have and the instructions that came with it from the company it was ordered. Always check with your band director first to get any instructions specific to your uniform type.\n#1 . To clean your uniform you will want to remove anything that is attached and can be removed such as cords, emblems, or patches. They will likely be a snap you undo or velcro that is holding it on.\n#2. Generally Marching band Jackets and bibbers can be machine washed separately on gentle cycle in cold water with very mild detergent. No detergents that use fragrance or harsh chemicals.\nMake sure to keep your colors separate and especially anything that is white needs to be washed separately to keep it pure and brilliant in color.\n#3. Dry your uniform by hanging it in a safe place. Do not put your uniform in the dryer! It will shrink and can be ruined. Put it out on a line to hang dry preferably out of direct sunlight.\nIf you have a stain on your uniform try to blot it up immediately with a clean towel or rag. Blot, do not rub! Most uniforms will do ok with a stain remover that you can apply before washing it, but check with the manufacturer first!\nTop Tip: Be sure that you don’t ever put your uniform away for storage if it is wet. Whether it’s wet from rain or sweat it needs to fully dry or it can easily start to get moldy and smell like mildew.\nUniformity is the ultimate goal for marching bands, and their uniforms help achieve a clean and cohesive appearance while representing their school’s colors or logos.\nWith a history of military service and the legacy of marching bands, your uniform is a symbol of the past and the future.\nThe first time wearing the entire uniform in high school is exciting and quickly becomes your Friday evening outfit of choice. In college and university marching bands, wearing the uniform for the first time is a special moment because you worked hard to become part of the marching band.\nWhile the first time you wear a uniform is a moment you never forget, the last time you wear your uniform your senior year is incredibly emotional. That uniform represents the last four (or five for college students) years of your life, the memories you have made, the shows you have played, and the family you were so fortunate to be a part of. Always wear your uniform with pride!\nDisclaimer: This post may contain affiliate links. We only recommend high-quality products that are used and recommended by real musicians. If you use these links to buy something we earn a small commission.', 'During the same relative time period, other clues indicate more oxygen was present in the atmosphere thanfound currently\nSpace news (planetary science: Martian rocks containing manganese oxide minerals; indicating a wetter surface with more atmospheric oxygen than presently found on Mars) – Mars (the Red Planet), 154 million miles (249 kilometers) from Sol, or 141 million miles (228 million kilometers) from Earth, on average –\nNASA’s Curiosity Mars rover has found rocks at a place called Windjana containing manganese oxide minerals according to reports from planetary scientists studying samples from the region. On Earth rocks of this type formed during the distant past in the presence of abundant water and atmospheric oxygen. This news added to previous reports of ancient lakes and other groundwater sources during Mar’s pastpoints to a wetter environment in the study region Gale Crater during this time.\nPlanetary scientists used the laser-firing instrument on the Curiosity Mars rover to detect high levels of manganese-oxide in mineral veins found at Windjana. “The only ways on Earth that we know how to make these manganese materials involve atmospheric oxygen or microbes,” said Nina Lanza, a planetary scientist at Los Alamos National Laboratory in New Mexico. “Now we’re seeing manganese oxides on Mars, and we’re wondering how the heck these could have formed?”\nPlanetary scientists are looking at other processes that could create the manganese-oxide they found in rocks in Mar’s Gale Crater region. Possible culprits at this point include microbes, but even optimistic planetary scientists are finding little fan fair accompanyingtheir ideas. Lanza said, “These high manganese materials can’t form without lots of liquid water and strongly oxidizing conditions. Here on Earth, we had lots of water but no widespread deposits of manganese oxides until after the oxygen levels in our atmosphere rose.”\nGeologists have found high concentrations of manganese oxide minerals is an important marker of a major shift in Earth’s atmospheric composition, from relatively low oxygen levels during the distant past, to the oxygen-rich environment we live in today. Planetary scientists studying the rocks they found in Gale Crater suggest the presence of these materials indicates oxygen levels on Mars rose also, before declining to the present low levels detected. The question is how was Mar’s oxygen-rich atmosphere formed?\n“One potential way that oxygen could have gotten into the Martian atmosphere is from the breakdown of water when Mars was losing its magnetic field,” said Lanza. “It’s thought that at this time in Mars’ history, water was much more abundant. Yet without a protective magnetic field to shield the surface, ionizing radiation started splitting water molecules into hydrogen and oxygen. Because of Mars’ relatively low gravity, the planet wasn’t able to hold onto the very light hydrogen atoms, but the heavier oxygen atoms remained behind. Much of this oxygen went into rocks, leading to the rusty red dust that covers the surface today. While Mars’ famous red iron oxides require only a mildly oxidizing environment to form, manganese oxides require a strongly oxidizing environment, more so than previously known for Mars.“\nLanza added, “It’s hard to confirm whether this scenario for Martian atmospheric oxygen actually occurred. But it’s important to note that this idea represents a departure in our understanding for how planetary atmospheres might become oxygenated. Abundant atmospheric oxygen has been treated as a so-called biosignature or a sign of extant life, but this process does not require life.“\nThe Curiosity rover has been investigating Gale Crater for around four years and recent evidence supports the possibilityconditions needed to form these deposits were present in other locations. The concentrations of manganese oxide discovered were found in mineral-filled cracks in sandstones in a region of the crater called “Kimberley”. NASA’s Opportunity rover has been exploring the surface of the planet since 2004 and recently reported similar high manganese deposits in a region thousands of miles away. Supporting the idea environments required to form similar deposits could be found well beyond Gale Crater.\nWhat’s next for Curiosity?\nNASA’s Curiosity rover’s currently collecting drilled rock powder from the 14th drill site called the Murray formation on the lower part of Mount Sharp. Plans call for NASA’s mobile laboratory to head uphill towards new destinations as part of a two-year mission extension starting near the beginning of October.\nThe rover will go forward about a-mile-and-a-half (two-and-a-half-kilometers) to a ridge capped with material rich in the iron-oxide mineral hematite first identified by observations made with NASA’s Mars Reconnaissance Orbiter. Just beyond this area, there’s also a region with clay-rich bedrock planetary scientists want to have a closer look.\nNASA has been exploring these key exploration sites on lower Mount Sharp as part of an effort to investigate evidence the Red planet was once a much wetter environment, which contrasts with the pictures of Mars we have received from our orbiters and rovers. A wetter environment where life could have taken root and grown.\n“We continue to reach higher and younger layers on Mount Sharp,” said Curiosity Project Scientist Ashwin Vasavada, of NASA’s Jet Propulsion Laboratory, Pasadena, California. “Even after four years of exploring near and on the mountain, it still has the potential to completely surprise us.”\nPlanetary scientists found the Murray formation consists primarily of mudstone, which on Earth would form from mud accumulated on the bottom on an ancient lake. This seems to indicate any lake environment that existed on the Red Planet lasted awhile, but we’ll need to investigate this possibility more. Plans are for Curiosity to investigate the upper regions of the Murray formation, ahead, for at least one year of the mission.\n“We will see whether that record of lakes continues further,”Vasavada said. “The more vertical thickness we see, the longer the lakes were present, and the longer habitable conditions existed here. Did the ancient environment change over time? Will the type of evidence we’ve found so far transition to something else?”\nVasavada said, “The Hematite and the Clay units likely indicate different environments from the conditions recorded in the older rock beneath them and different from each other. It will be interesting to see whether either or both were habitable environments.”\nTo investigate Martian rocks for evidence of past life in advance of sending humans to work and live on the Red Planet\nSpace news (missions to Mars: successor to Curiosity rover; Mars 2020 rover) – NASA’s Jet Propulsion Laboratory in Pasadena, California –\nNASA managers are looking forward to shifting gears on the Mars rover program in the 2020s. NASA’s Mars 2020 rover’s expected to arrive at the Red Planet around February 2021, carrying a science instrument package designed to build upon the success of NASA’s Mars Curiosity rover. It will investigate regions of the planet astrobiologists think were once favorable to microbial life, by collecting soil and rock samples, and then leaving them on the surface for a future Mars mission to collect for the possible return to Earth.\n“The Mars 2020 rover is the first step in a potential multi-mission campaign to return carefully selected and sealed samples of Martian rocks and soil to Earth,” said Geoffrey Yoder, acting associate administrator of NASA’s Science Mission Directorate in Washington. “This mission marks a significant milestone in NASA’s Journey to Mars, to determine whether life has ever existed on Mars, and to advance our goal of sending humans to the Red Planet.”\nNASA engineers, scientists and mission planners are ready to begin final design and construction of the next Mars rover. In the end, Mars 2020 will looklike its six-wheeled, one-ton predecessor, Curiosity, but with a science instrument package designed to begin a new phase of exploration of the surface of Mars. It will begin exploring specifically selected regions of the planet for signs of life and the resources needed for future colonists to survive. Using two science instruments mounted on the rover’s robotic arm and two instruments on the mast, NASA’s Mars 2020 rover’s expected to show us new things about the Red Planet.\nCurrent plans call for the Mars 2020 rover to use an upgraded version of the same sky crane landing system used by Curiosity. Engineers and designers have added a few improvements to the system opening up more potential landing sites on Mars with this edition. Giving mission planners more options to explore the Red Planet to a greater degree and hopefully provide a few more answers to the questions we have all been asking ourselves about Mars.\n“By adding what’s known as range trigger, we can specify where we want the parachute to open, not just at what velocity we want it to open,” said Allen Chen, Mars 2020 entry, descent and landing lead at NASA’s Jet Propulsion Laboratory (JPL) in Pasadena, California. “That shrinks our landing area by nearly half.”\nEngineers and designers have also added a suite of cameras and a microphone providing data onboard computers will analysis during descent and landing of the rover. This will help the spacecraft land in a safe zone and capture the sounds and imagery of the entry, descent, and landing as never before. We expect this data to eventually make for a thrilling video and improve the chances of future Mars missions.\n“As it is descending, the spacecraft can tell whether it is headed for one of the unsafe zones and divert to safe ground nearby,” said Chen. “With this capability, we can now consider landing areas with unsafe zones that previously would have disqualified the whole area. Also, we can land closer to a specific science destination, for less driving after landing.”\n“Nobody has ever seen what a parachute looks like as it is opening in the Martian atmosphere,” said JPL’s David Gruel, assistant flight system manager for the Mars 2020 mission. “So this will provide valuable engineering information.”\n“This will be a great opportunity for the public to hear the sounds of Mars for the first time, and it could also provide useful engineering information,” said Mars 2020 Deputy Project Manager Matt Wallace of JPL.\nMars 2020 rover goes forward\nAs the optimist said, “So far, so good.” NASA has completed stage three of a four-stage approval process needed for the Mars 2020 rover to go for launch. Now engineers and designers get to work assembling the final systems of NASA’s next Mars rover. Fortunately, they have already done a lot of the work during the building of Curiosity, and even have some spare parts and hardware that should work just fine laying around somewhere in the Jet Propulsion Laboratory.\n“Since Mars 2020 is leveraging the design and some spare hardware from Curiosity, a significant amount of the mission’s heritage components have already been built during Phases A and B,” said George Tahu, Mars 2020 program executive at NASA Headquarters in Washington. “With the KDP to enter Phase C completed, the project is proceeding with final design and construction of the new systems, as well as the rest of the heritage elements for the mission.”\nPlanners under pressure to provide details of long-term plans before Presidential election\nSpace news (Deep space missions: go for Mars; Orion spacecraft) – Marshall Space Flight Center in Huntsville, Alabama –\nNASA plans to travel to the Red Planet for a three-year mission to set up operations for future missions and possible colonization recently took one step forward. NASA mission managers and other experts gavethe Safety Oversight Board an update on thecurrent status of plans to travel to Mars duringthe latest Aerospace Safety Advisory Panel (ASAP) meeting. The committee members took a very close look at their plans and pointed out America and NASA can’t afford to fumble the ball at this point in history. That with the Presidential election taking place, they‘ll need to see more on NASA’s future plans to travel to Mars, before more funding for futuremissions will be forthcoming.\nNASA at this point’s trying to get work completed on the planned debut for the Space Launch System (SLS) with the launch of Exploration Mission Orion (EM-1) in 2017-2018. The second test of the Space Launch System (SLS) is scheduled for around 2021, with a crew this time, but NASA’s presently trying to reduce the five-year gap between the first two SLS missions. This launch system or something similar is needed for plans to travel to Mars and colonize the Red Planet sometime in the 2030s.\nAt this point in time, these are the only scheduled SLS missions, but NASA’s documents do show preliminary plans for 41 SLS missions between 2018 to 2046 towards future surface missions on Phobos and then the Red Planet. NASA also provided a generalized plan calling for astronauts to journey to the fourth planet from the Sun for a permanent stay sometime in the 2030s. At this point, however, concrete long-term plans surrounding future manned trips to Mars are hazy due to NASA’s funding outlook, which isonly estimated for long-term space mission requirements. Experts agree, though, a hefty increase in funding’s going to be needed for a realistic, viable plan and tripto the Red Planet. Getting it ready for more colonizers is a different question, though, requiring additionalthought, planning, and funding.\nNASA’s Associate Administrator for Human Exploration and Operations Bill Gerstenmaierstated the SLS will launch at least once a year when questioned about the tight schedule of EM-1. NASA’s monster rocket system isn’t scheduled to take astronauts into space until sometime in the next decade, so expectations are for NASA to plan and execute a range of different unmanned space missionsto test the system. This could include a mission to Jupiter’s moon Europa, to take a dip in the ocean of water planetary scientists think exists below its icy crust.\nBill Hill, Deputy Associate Administrator for Exploration Systems Development (ESD) for NASA’s Human Exploration and Operations Mission Directorate (HEOMD), updated board members on the status of current plans for astronauts to travel to Mars by the 2030s. At this point in the planning, program managers are still reviewing options, rather than adding a foundation to present plans.\nNASA planners have significant hurdles to overcome if they’re to successfully send astronauts to the Red Planet and allow them to get back into orbit. The first obstacle’s going to be designing, engineering and testing a Solar Electric Propulsion (SEP) system capable of generating enough energy to get a spacecraft up to a significant percentage of the speed of light. The Helios space probes hold the record for the fastest recorded human spacecraft at around 150,000 miles per hour as they whip around the Sun measuring the solar wind and environment. The second significant hurdle’s collecting enough oxygen from the frozen regions of Mars to provide the fuel required to travel from the surface back into orbit. Plans for a three-year mission are also of concern to scientists, engineers and planners worried about the dangers and problems astronauts will face living, working and staying healthy during a long-duration space mission.\nOf concern previously and still a problem the committee mentioned was the need for engineers and scientists to producea heat shield for the Orion spacecraft capable of surviving reentry. The spacecraft will have to survive a 13.5 kilometers per second entry velocity and planners indicated this capability’s on the agency’s must-do list. At present, Orion isn’t going to survive the fall to Earth after it returns from Mars, according to engineers and scientists. Committee members also noted they have been asking NASA managers for a formal outline of their plans to send astronauts to Mars for awhile. They specifically wanted to know what new technologies will be needed to successfully allow astronauts to travel to the Red Planet to begin colonization.\nNASA officials responded to committee member requests by stating the agency was in the process of “adding meat to the bones” of the transitional phase of their plans to send astronauts to Mars. During this phase 0, NASA’s turns its attention toward successful test flights for the SLS and Orion, while using the International Space Station (ISS) to test the effects of living and working in space for long periods of time.\nThe Asteroid Redirect Mission’s (ARM) phase 1 of NASA’s three-part plan to send astronauts to the Red Planet. Initially, this mission had a nominal date of around 2021, but planners have recently updated the mission launch date to around 2026. They’ll need to complete this mission successfully in order to learn some of the things they’ll need to know to send astronauts to Mars to begin colonization. During this phase, engineers and scientists will test the flight capability of the system using the Exploration Missions.\nPhase 2 of NASA’s plans to send astronauts to Mars will test all flight elements needed to travel to the Red Planet, during planned Beyond Earth Orbit test missions. The committee thanked Mars Mission managers but asked to see more detail and definite plans on NASA’s current outline.\nMankind goes for Mars\nMr. Hill commented that NASA’s already learned many needed lessons towards phase 0 of their Mars Mission plans. He added that the nation had already invested significantly in the technology neededto send astronauts to Mar during the decades ahead. That more work needed to be done in order to not loose this work and get the job done within a specific time period. Specific milestones have been met and Exploration Mission 1’s (EM-1) on target for a launch window between September to November 2018.']	['<urn:uuid:2cf9d16a-dac4-4069-99ce-c7f76252664b>', '<urn:uuid:abefd97d-7bd0-4a46-8737-3aa150368e1c>']	open-ended	direct	verbose-and-natural	distant-from-document	three-doc	expert	2025-05-13T06:27:57.068978	19	117	5374
18	What would happen to a nation's production possibilities curve in the aftermath of a devastating military conflict where the country suffered significant bombing?	The nation's production possibilities curve would shift inward due to the destruction from bombing and warfare in a losing military conflict.	"['A point on the frontier of the production possibilities curve is:\nAttainable and resources are fully employed\nWhich of the following would be a positive economic statement?\nBankers are now charging higher interest rates on credit cards to cover the increased cost of loaning funds to consumers\nRational behavior implies that people will make different choices because their circumstances and available information differ\nWhen an economist says that there is ""too much of a good thing,"" the economist is suggesting that:\nThe marginal benefit of the thing is less than the marginal cost\nMicroeconomics is the study of economics from the standpoint of:\nSpecific economic units which make up our economic system\nFrom an economic perspective, when consumers leave a fast-food restaurant because the lines to be served are too long, they have concluded that the:\nMarginal cost of waiting is greater than the marginal benefit of being served\nWhich is an illustration of a microeconomic question?\nWill a new type of television set increase the number of buyers?\nWhat is a major opportunity cost of going to college on a full-time basis?\nThe foregone income that could be earned working full-time job\nRefer to the above production possibilities curves. Curve (a) is the current curve for the economy. The movement from curve (a) to curve (b) suggests:\nAn improvement in capital goods technology but not in consumer goods technology\nRefer to the above graph. The marginal opportunity cost of the fourth unit of bread is\n4 units of drill presses\nThe term scarcity in economics refers to the fact that:\nNo country can produce enough products to satisfy everybody\'s economic wants\nWhich one of the following would be a normative economic statement?\nThe worsening balance of trade must be corrected if this nation is to remain competitive in the world economy\nEconomic theory involves the logical development of hypotheses which are then tested against actual outcomes\nWhich situation would most likely cause a nation\'s production possibilities curve to shift inward?\nThe destruction from bombing and warfare in a losing military conflict\nWhich of the following would be a normative economic statement?\nThe government should raise taxes to bring in $10 billion more in revenue next year\nThe general concern of economics is with the study of the:\nOptimal use of limited productive resources to satisfy economic wants\nA schedule or curve that shows the various combinations of two products a consumer can purchase with a specific amount of money income is:\nA budget line\nWhich would be considered a macroeconomic study? A study of the effect of:\nGovernment spending to increase employment\nWhat is the best economic explanation for why a person would drop out of college to take a job or start a business?\nIf the expected future benefits from starting a business are greater than the costs\nEconomics is a social science concerned with:\nThe best use of scarce resources to achieve the maximum satisfaction of economic wants\nAs a student of economics, when you speak of scarcity, you are referring to the ability of society to:\nSatisfy economic wants given limited resources\nThe production possibilities curve represents:\nMaximum combinations of products available with fixed resources and technology\nAfter graduating from high school, Ron Willis plans to go to college. The college tuition is $15,000 a year. But, instead of going to college, Ron could take a full-time job paying $20,000. If Ron decides to go to college, what is his opportunity cost for attending for one year?\nA reduction in the level of unemployment would have which effect with respect to the nation\'s production possibilities curve?\nIt would not shift the curve; it would be represented by moving from a point inside the curve toward the curve\nWhich question is an illustration of a macroeconomic question?\nHow does a cut in the business tax rate increase business investment in the economy?\nThe law of increasing opportunity costs says that:\nAlong a production possibilities curve, increases in the production of one type of good require larger and larger sacrifices of the other type of good\nThe combination of food and clothing shown by point F on the above graph:\nIs attainable but involves the unemployment and inefficient use of some of society\'s resources\nThe effect of specialization and international trade will:\nCause a rightward shift in a nation\'s production possibilities curve\nClara states that ""there is a high correlation between the level of people\'s education and the level of their income."" Ellie replies that the correlation occurs because ""more education is the best way to earn more income in this country.""\nClara\'s statement is positive and Ellie\'s statement is normative\nThe statement that ""the unemployment rate will increase as the economy moves into a recession"" is an example of:\nThe role of the entrepreneur in society is to:\nBring the factors of production together and take the risks of producing\nAssume that a consumer has $12 in income and she can buy only two goods, apples or bananas. The price of an apple is $1.50 and the price of a banana is $0.75.\nIf the consumer spent all of her money on either apples or bananas, how many apples or how many bananas would she be able to buy?\n8 apples and 16 bananas\nThe production possibilities curve for two products is concave because:\nAs the production of a good increases, there is an increase in opportunity cost\nRefer to the above production possibilities curves. Curve (a) is the current curve for the economy. Given production possibilities curve (a), point N suggests that the economy is\nAttaining both full employment and full production\nIf opportunity costs were constant, then the production possibilities curve would be:\nA straight line\nRefer to the above graph. Which point on the production possibilities curve would indicate that there is unemployment in this economy?\nThe concept of ""rational behavior"" suggests that:\nPeople make different choices because their circumstances and information differ\nTammie makes $150 a day as a bank clerk. She takes off two days of work without pay to fly to another city to attend the concert of her favorite music group. The cost of transportation for the trip is $250. The cost of the concert ticket is $50. The opportunity cost of Tammie\'s trip to the concert is:\nHenry wants to buy a book. The economic perspective suggests that Henry will buy the book if:\nThe marginal benefit of the book is greater than its marginal cost\nThe combination of food and clothing shown by point G on the above graph:\nIs not attainable, given society\'s available resources and technology\nThe comment that ""social security taxes must be reduced if there are to be adequate incentives to work"" is an example of a normative economic statement.']"	['<urn:uuid:fe0ccebc-7e9b-4440-b7ce-2e16a76f4a69>']	factoid	direct	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-13T06:27:57.068978	23	21	1126
19	As a mental health researcher, I wonder what physical diseases are worsened by loneliness?	Loneliness can exacerbate or contribute to numerous physical conditions including Alzheimer's, obesity, diabetes, high blood pressure, heart disease, neurodegenerative diseases, cancer, stroke, poor sleep quality, diminished executive function, accelerated cognitive decline, and impaired immune system function. Studies have shown that emotional isolation is as high a risk factor for mortality as smoking, and individuals who report feeling lonely are more likely to die an early death than those who do not.	['Says Prof. Rokach, “There is such a stigma about it. People will talk about having depression or even schizophrenia, but … I’ve been practicing for more than 30 years, and never has anyone come to me and said, ‘I feel lonely.’ But then they start talking and it comes out.”This is why David Sutcliffe has launched a bit of a one-man shame-reduction campaign. …“Social isolation just may be the greatest environmental hazard of city living,” writes Vancouver-based author Charles Montgomery in his new book, Happy City: Transforming Our Lives Through Urban Design. “Worse than noise, pollution, or even crowding.” And the way we’ve built cities – suburbs with no central meeting place, prioritizing the car and the condo tower, passing restrictive zoning bylaws – has made the problem worse, he says in an interview. “If we’re concerned about happiness, then social disconnection in Canadian cities is an acute problem.”Mr. Montgomery points to cities that have done things right, from Portland, Ore., turning its intersections into urban piazzas to the community gardens built in disused lofts in Berlin. Research has shown that a varied streetscape will cause people to slow down, and perhaps even exchange a smile or flirtatious glance, and that even a brief exposure to nature – cutting through a park – makes us feel more generous, and more social.\nProf. Cacioppo notes that lonely people will either withdraw into their shells or attempt to soothe their pain by lashing out.\nGroup therapy has been a huge help. He also is evangelical about sharing his story, to combat what he calls “society’s tranquillity mask” – our tendency to pretend that everything is swell, even when it isn’t\n“There are a lot of people walking around who feel that they don’t fit in, they don’t belong. That sense of disconnection is really common. But when you realize that you’re like everyone else, not only in your dreams and passions but also in your pain and sadness, there’s incredible comfort in that.”\nEmotional isolation is ranked as high a risk factor for mortality as smoking. A partial list of the physical diseases thought to be caused or exacerbated by loneliness would include Alzheimer’s, obesity, diabetes, high blood pressure, heart disease, neurodegenerative diseases, and even cancer—tumors can metastasize faster in lonely people.“Real loneliness,” as she called it, is not what the philosopher Søren Kierkegaard characterized as the “shut-upness” and solitariness of the civilized. Nor is “real loneliness” the happy solitude of the productive artist or the passing irritation of being cooped up with the flu while all your friends go off on some adventure. It’s not being dissatisfied with your companion of the moment—your friend or lover or even spouse— unless you chronically find yourself in that situation, in which case you may in fact be a lonely person. Fromm-Reichmann even distinguished “real loneliness” from mourning, since the well-adjusted eventually get over that, and from depression, which may be a symptom of loneliness but is rarely the cause.\nLoneliness, she said—and this will surprise no one—is the want of intimacy.Loneliness “is not synonymous with being alone, nor does being with others guarantee protection from feelings of loneliness,” writes John Cacioppo, the leading psychologist on the subject.A key part of feeling lonely is feeling rejected, and that, it turns out, is the most damaging part.Suomi – in monkeys separated from their mothers in the first four months of life, some important immunity-related genes show a different pattern of expression. Among these were genes that help make the protein that inflames tissue and genes that tell the body to ward off viruses and other microbes.known for insisting that no patient was too sick to be healed through trust and intimacy. She figured that loneliness lay at the heart of nearly all mental illness and that the lonely person was just about the most terrifying spectacle in the world.\nI didn’t need genetics, though, to see how defective the peer-raised monkeys’ development had been. Suomi took me outside to watch them. They huddled in nervous groups at the back of the cage, holding tight to each another. Sometimes, he said, they invite aggression by cowering; at other times, they fail to recognize and kowtow to the alpha monkeys, so they get picked on even more. The most perturbed monkeys might rock, clutch at themselves, and pull out their own hair, looking for all the world like children with severe autism.As far as he’s concerned, these are, in too many cases, symptoms of the same social disorder:\nthe failure to help families raise their children.One of the most effective economic and social policies, he told me, would be “supplementing the parenting environment of disadvantaged young children.”turns out that Tylenol can reduce the pain of heartbreak.\nThen suddenly I stopped being lonely. It was too difficult for me to keep being lonely. So I started being curious.\nKrishnamurti on loneliness/peace\nmay 2013 – science of loneliness – how isolation can kill you (via Jennifer)\n[same article as above – some different highlights – a yr later]\nFromm-Reichmann would later become world-famous as the dumpy little therapist mistaken for a housekeeper by a new patient, a severely disturbed schizophrenic girl named Joanne Greenberg. ….She figured that loneliness lay at the heart of nearly all mental illness and that the lonely person was just about the most terrifying spectacle in the world.\nIn a way, these discoveries are as consequential as the germ theory of disease. Just as we once knew that infectious diseases killed, but didn’t know that germs spread them, we’ve known intuitively that loneliness hastens death, but haven’t been able to explain how. Psychobiologists can now show that loneliness sends misleading hormonal signals, rejiggers the molecules on genes that govern behavior, and wrenches a slew of other systems out of whack. They have proved that long-lasting loneliness not only makes you sick; it can kill you. Emotional isolation is ranked as high a risk factor for mortality as smoking.\nLoneliness, she said—..—is the want of intimacy.\nAs W. H. Auden put it, “We must love one another or die.”\nA key part of feeling lonely is feeling rejected, and that, it turns out, is the most damaging part.\nCole figured that a man who’d hide behind a false identity was probably more sensitive than others to the pain of rejection. His temperament would be more tightly wound, ..His heart would beat faster, stress hormones would flood his body, his tissues would swell up, and white blood cells would swarm out to protect him against assault. If this state of inflamed arousal subsided quickly, it would be harmless. But if the man stayed on high alert for years at a time, then his blood pressure would rise, and the part of his immune system that fends off smaller, subtler threats, like viruses, would not do its job.\nnatural selection favored people who needed people.\nIt’s tempting to say that the lonely were born that way—it’d let the rest of us off the hook. And, as it turns out, we’d be about half right, because loneliness is about half heritable.\nDeprive us of the attention of a loving, reliable parent, and, if nothing happens to make up for that lack, we’ll tend toward loneliness for the rest of our lives.\nHeckman believes that the life of a child at the lower end of the U.S. socioeconomic spectrum is starting to look more like the life of one of Suomi’s lonely macaques.\n“As inequality has increased, childhood inequality has increased,” Heckman said, “So has inequality of parenting.” For the first time in 30 years, mental health disabilities such as ADHD outrank physical ones among American children. Heckman doesn’t think that’s only because parents seek out attention-deficit diagnoses when their children don’t come home with A’s. He thinks it’s also because emotional impoverishment embeds itself in the body. “Mothers matter,” he says, “and mothering is in short supply.”\nnagging mother app as motivator.. army – better fighters… school – teach social skills..\n? non-resonating section for me ie: – nagging mother – as extrinsic motivation – non-lasting and counter to what is needed .. army – said not only helped with ptsd, but made them better fighters..? .. school – takes child from natural attachment (Maté)\nCole can imagine giving people medications to treat loneliness, particularly when it exacerbates chronic diseases such as diabetes and high blood pressure. These could be betablockers, which reduce the physical effects of stress; anti-inflammatory medicine; or even Tylenol—since physical and emotional pain overlap, it turns out that Tylenol can reduce the pain of heartbreak.\nit’s not just early life that counts,’ ” he says. “We have to choose our life well.”\nGuy Winch – emotional hygiene\n“Loneliness is difficult to confess… Like depression … it can run deep in the fabric of a person.” Superb read brainpickings.org/2016/07/11/the…\nHow do we live, if we’re not intimately engaged with another human being?\nYou can be lonely anywhere, but there is a particular flavour to the loneliness that comes from living in a city, surrounded by millions of people.\nCities can be lonely places, and in admitting this we see that loneliness doesn’t necessarily require physical solitude, but rather an absence or paucity of connection, closeness, kinship: an inability, for one reason or another, to find as much intimacy as is desired.Unhappy, as the dictionary has it, as a result of being without the companionship of others. Hardly any wonder, then, that it can reach its apotheosis in a crowd.\nWhat does it feel like to be lonely? It feels like being hungry: like being hungry when everyone around you is readying for a feast. It feels shameful and alarming, and over time these feelings radiate outwards, making the lonely person increasingly isolated, increasingly estranged. It hurts, in the way that feelings do, and it also has physical consequences that take place invisibly, inside the closed compartments of the body. It advances, is what I’m trying to say, cold as ice and clear as glass, enclosing and engulfing.\nThough it feels entirely isolating, a private burden no one else could possibly experience or share, it is in reality a communal state, inhabited by many people.\nIt’s an unusual formulation, a lonely one; not at all the same thing as admitting one is lonely. Instead, it suggests with that a, that unassuming indefinite article, a fact that loneliness by its nature resists. Though it feels entirely isolating, a private burden no one else could possibly experience or share, it is in reality a communal state, inhabited by many people. In fact, current studies suggest that more than a quarter of American adults suffers from loneliness, independent of race, education and ethnicity, while 45 per cent of British adults report feeling lonely either often or sometimes. Marriage and high income serve as mild deterrents, but the truth is that few of us are absolutely immune to feeling a greater longing for connection than we find ourselves able to satisfy..t..The lonely ones, a hundred million strong. Hardly any wonder Hopper’s paintings remain so popular, and so endlessly reproduced.\nmaté basic needs (video) – 1 min\nThere are so many things that art can’t do. It can’t bring the dead back to life, it can’t mend arguments between friends, or cure AIDS, or halt the pace of climate change. All the same, it does have some extraordinary functions, some odd negotiating ability between people, including people who never meet and yet who infiltrate and enrich each other’s lives. It does have a capacity to create intimacy; it does have a way of healing wounds, and better yet of making it apparent that not all wounds need healing and not all scars are ugly.\nloneliness, longing, does not mean one has failed, but simply that one is alive.\nWe are in this together, this accumulation of scars, this world of objects, this physical and temporary heaven that so often takes on the countenance of hell. What matters is kindness; what matters is solidarity. What matters is staying alert, staying open, because if we know anything from what has gone before us, it is that the time for feeling will not last.\nmost common attribute of people who are waking up: loneliness\nBut our desire to fit in and be accepted is slowly being drowned out by our desire to be free.\nSeeming is but a garment I wear\nFor the first time the sun kissed my own naked face and my soul was inflamed with love for the sun, and I wanted my masks no more.\nI have found both freedom of loneliness and the safety from being understood, for those who understand us enslave something in us.\nCarl Jung via ideapod .. on where loneliness comes from\nLoneliness does not come from having no people about one, but from being unable to communicate the things that seem important to oneself, or from holding certain views which others find inadmissible.”\n― C.G. Jung\nthinking of all the things/people.. but esp of James‘ latest.. on worst thing for survivor w/shrapnel of abuse.. loneliness.. things others find inadmissible to speak out loud:\nThe child abuse inquiry has been devastatingly inept – but it must go on – We survivors placed our faith in this inquiry. It must go ahead – for us, and for the thousands of children whose appalling suffering continues\nI don’t like the term “victim”. I prefer “survivor with shrapnel”. And speaking as one of those survivors, let me make it clear that evenmore debilitating than the physical pain of abuse, is the loneliness.\n2 min video from campaign to end loneliness: make friends\nJohn Hagel (@jhagel) tweeted at 7:07 AM – 2 Jan 2019 :\nIn a BBC survey of 55,000 people from all over the world, some surprising findings on loneliness – younger people are the loneliest and living alone is not correlated with loneliness https://t.co/4vNIEXRkyk (http://twitter.com/jhagel/status/1080465512222453761?s=17)\ncommunity solutions to loneliness epidemic via shareable: https://www.shareable.net/community-solutions-to-the-loneliness-epidemic/\nfound on fb – via sandy share – linked to image\nloneliness is the place from which we pay real attention to voices other than our own; being alone allows us to find the healing power in the other\nhuman beings are made to belong. loneliness is a single malt taste of the very essentiality that makes conscious belonging possible.. the doorway is closer than we think i am aloe; therefore i belong\nbrown belonging law et al\nvia maria – hannah arendt on isolation and loneliness: https://www.brainpickings.org/2016/12/20/hannah-arendt-origins-of-totalitarianism-loneliness-isolation/\nTerror can rule absolutely only over men who are isolated against each other… Therefore, one of the primary concerns of all tyrannical government is to bring this isolation about. Isolation may be the beginning of terror; it certainly is its most fertile ground; it always is its result. This isolation is, as it were, pretotalitarian; its hallmark is impotence insofar as power always comes from men acting together…; isolated men are powerless by definition.\nIn isolation, man remains in contact with the world as the human artifice; only when the most elementary form of human creativity, which is the capacity to add something of one’s own to the common world, is destroyed, isolation becomes altogether unbearable… Isolation then becomes loneliness.\nWhile isolation concerns only the political realm of life, loneliness concerns human life as a whole. ..loneliness.. the experience of not belonging to the world at all, which is among the most radical and desperate experiences of man.\nThis is why our insistence on belonging, community, and human connection is one of the greatest acts of courage and resistance in the face of oppression\nlet’s get back/to maté basic needs', 'Technology has connected individuals like never before, and yet more people are feeling lonely and isolated. Loneliness can lead to serious health concerns – and even early death – causing experts to respond to the issue.\nIn 2023, U.S. Surgeon General Dr. Vivek Murthy issued an advisory calling loneliness and isolation a health epidemic. It notes that loneliness and social isolation can contribute to a worsening of mental and physical health issues.\nIt’s an issue that affects people across generations and life circumstances. A 2020 Harvard study found that 61% of adults ages 18 to 25 reported feeling serious loneliness, compared with 39% across the general population. In 2023, one in three adults ages 50 to 80 reported feeling isolated from others. Mothers of young children are also at risk, with 51% reporting they are lonely.\nMelissa Laughlin Holtz, a Mental Health Clinician with ThedaCare Behavioral Health, explained those are all concerning statistics. She added that people experiencing loneliness are more likely to suffer adverse health consequences including depression, anxiety, poor sleep quality, diminished executive function, accelerated cognitive decline or dementia, impaired immune system, higher inflammation, heart disease, stroke and risk of suicide. Studies have shown that individuals who report feeling lonely are more likely to die an early death than those who do not.\nUnpacking the Uptick\nMultiple factors have led to the increase in loneliness. Experts say the COVID-19 pandemic, which in many cases required people to isolate from others, played a part in worsening the issue.\nAt the same time, loneliness was a problem well before the pandemic. Many variables can influence loneliness. People may feel unwelcome due to their gender, sexual orientation, race, age or health conditions. This can lead to feelings of isolation.\n“Many LGBTQIA+ and Black, Indigenous and People of Color may feel like they are being ‘othered’ or are not welcome in spaces that they want to be,” Laughlin Holtz said. “Older adults and individuals living with disabilities or chronic diseases are another group of people who can feel isolated, especially if it’s hard for them to leave their home.”\nAnyone can feel lonely or isolated. The key to addressing those feelings is finding ways to reach out and get involved in activities you enjoy, Laughlin Holtz noted.\nTechnology can have pluses and minuses when it comes to feeling lonely, she continued. While it connects people whenever and wherever they may be, it can also prevent true communication from happening.\n“How often do you visit a restaurant and see people on their phones despite being seated with friends or loved ones?” Laughlin Holtz asked. “We’re missing these connections even when they are right in front of us.”\nLaughlin Holtz offers these ideas for fostering greater connection and well-being:\n- Stop comparing yourself with others. This fits well with taking a break from social media. While social media often seems like an appealing way to maintain connections with loved ones, it can sometimes increase feelings of loneliness.\n- Practice gratitude. Keep a daily gratitude journal where you write down things that you’re grateful for. You can later go back and read them when you’re feeling down.\n- Take time to reflect. This could be journaling, taking a mindful walk, or practicing meditation.\n- Join a club or take a class. Sign up for an activity that gets you out of the house. Volunteering for a local organization can help you feel more connected to other individuals while doing good for your community.\n- Get outdoors. Take a walk or spend time in nature, making sure you pay attention to the sights, sounds, and smells around you. Time in nature can ease emotional distress and boost overall wellness.\n- Engage in activities. Participate in a hobby or sport you enjoy.\n- Spend time with animals. Pets have been shown to reduce stress, depression, and anxiety.\n- Open up and talk to someone. This could be a friend, family member, faith leader, primary care provider or therapist.\n- Develop a routine that provides balance and familiarity. Make a daily schedule that includes physical activity, time with friends or loved ones, a project or hobby and a calming pleasure.\n- Savor the small stuff. Seemingly minor gestures like smiling at the barista or thanking the bagger at the grocery store can create feelings of connection.\nHow to Help\nIf family members and friends realize someone they know is lonely, it is important to reach out and let them know you are there and ready to listen explained Laughlin Holtz.\n“You might have to be patient,” she said. “When someone is lonely, especially if it’s accompanied by poor mental or physical health, they may become angry or feel misunderstood by others. You may need to provide encouragement and support, reminding them that when they connect with some help, they will start feeling better.”\nThose experiencing loneliness or other mental health struggles can talk to their primary care provider, who can connect them to resources. ThedaCare Behavioral Health also offers many care options, including group therapy and Behavioral Health Walk-in Care in Neenah.\nFor nearly 115 years, ThedaCare® has been improving the health and well-being of the communities it serves in Northeast and Central Wisconsin. The organization delivers care to more than 650,000 residents in 17 counties, and employs approximately 7,000 providers and team members at 180 points of care, including eight hospitals. As an organization committed to being a leader in Population Health, team members are dedicated to empowering people to live their unique, best lives. ThedaCare is a not-for-profit health system with a level II trauma center, comprehensive cancer treatment, stroke and cardiac programs, as well as primary care. ThedaCare also partners with communities to understand needs, find solutions together, and encourage health awareness and action. In 2024, ThedaCare and Froedtert Health combined to form one system to strengthen local health care and provide high-quality services for treatment and prevention in a coordinated manner.']	['<urn:uuid:0cf87446-8dd3-438a-b0a8-4d610cdbd1b0>', '<urn:uuid:b90d8be6-8e11-4213-9b65-ad5f30b03c75>']	factoid	with-premise	concise-and-natural	distant-from-document	three-doc	expert	2025-05-13T06:27:57.068978	14	71	3591
20	Why are people moving away from traditional carrying baskets?	While traditional hampers - large wicker baskets used for transport and storage - have historical significance, particularly in British and agricultural contexts, modern consumer preferences are shifting towards disposable packaging options. This shift is driven by convenience, cost-effectiveness, and changing lifestyles, especially in urban areas. However, this trend faces growing scrutiny due to environmental concerns, leading to increased demand for sustainable alternatives and eco-friendly packaging solutions that could potentially bring back elements of traditional reusable container systems.	"['Definitions for hamperˈhæm pər\nThis page provides all possible meanings and translations of the word hamper\nshackle, bond, hamper, trammel(noun)\na restraint that confines or restricts freedom (especially something used to tie down or restrain a prisoner)\na basket usually with a cover\nhamper, halter, cramp, strangle(verb)\nprevent the progress or free movement of\n""He was hampered in his efforts by the bad weather""; ""the imperialist nation wanted to strangle the free trade between the two small countries""\nhandicap, hinder, hamper(verb)\nput at a disadvantage\n""The brace I have to wear is hindering my movements""\na large basket, usually with a cover, used for the packing and carrying of articles; as, a hamper of wine; a clothes hamper; an oyster hamper, which contains two bushels\nto put in a hamper\nto put a hamper or fetter on; to shackle; to insnare; to inveigle; hence, to impede in motion or progress; to embarrass; to encumber\na shackle; a fetter; anything which impedes\narticles ordinarily indispensable, but in the way at certain times\nOrigin: [See Hamper to shackle.]\nA hamper is a primarily British term for a wicker basket, usually large, that is used for the transport of items, often food. In North America, the term generally refers to a household receptacle for clean or dirty clothing, regardless of its composition, i.e. ""a laundry hamper"". In agricultural use, a hamper is a wide-mouthed container of basketwork that may often be carried on the back during the harvesting of fruit or vegetables by hand by workers in the field. The contents of the hamper may be decanted regularly into larger containers or a cart, wagon, or truck. The open ventilation and the sturdiness offered by a hamper has made it suitable for the transport of food, hence the use of the picnic hamper. At one time it was common for laundry services to leave a large basketwork container with a lid which is now commonly referred to as a clothes hamper. The same type of container would be used to return clean clothing, which would be put away by the laundry service and the empty container left in place of the full container for later pickup. This type of daily or bi-daily hamper service was most common with Chinese laundry services in 19th century England and America.\nChambers 20th Century Dictionary\nham′pėr, v.t. to impede or perplex: to shackle.—n. a chain or fetter.—p.adj. Ham′pered, fettered, impeded.—adv. Ham′peredly.—n. Ham′peredness. [First about 1350, in Northern writers, prob. rel. to Ice. hemja (pt.t. hamdi), to restrain; Ger. hemmen.]\nham′pėr, n. a large basket for conveying goods.—v.t. to put in a hamper.—ns. Han′ap, a large drinking-cup; Han′aper, an old name for a receptacle for treasure, paper, &c., long the name of an office in the Court of Chancery. [For hanaper—O. Fr. hanapier—hanap, a drinking-cup—Old High Ger. hnapf; A.S. hnæp, a bowl.]\nA type of homemade gift or basket of products created and designed in various colors, materials, products, shapes, sizes and styles with a type of packaging to cover the basket.\nSome people buy a Christmas hamper, Mother\'s day hamper, wine hamper etc. to give as a gift, present or prize at specific times of the year of for a competition or raffle to raise money for charity.\nThe numerical value of hamper in Chaldean Numerology is: 7\nThe numerical value of hamper in Pythagorean Numerology is: 7\nSample Sentences & Example Usage\nThese discussions improve outcomes and do not hamper hope.\nWith this in mind, the existing differences should not hamper our bilateral relations.\nHave you ever taken something out of the clothes hamper because it had become, relatively, the cleanest thing?\nHis absence will not hamper the party\'s work. We will stand up against the objectionable bills tabled by the government.\nEnacting legislation that would hamper that trust by not allowing officers\' names to be released is not in my opinion the best way to improve or repair that level of trust.\nImages & Illustrations of hamper\nTranslations for hamper\nFrom our Multilingual Translation Dictionary\n- korbo, malhelpiEsperanto\n- cesta, estorbar, canasta, obstaculizarSpanish\n- takistama, segamaEstonian\n- estää, pidäke, vaikeuttaa, kori, este, [[panna]] [[koriin]], kahlita, haitataFinnish\n- կողով, զամբյուղArmenian\n- tokanga, whakatomoMāori\n- wasmand, waarloos, korf, hindernis, inkorven, blokkeren, mand, beletsel, pakmand, obstakel, sluitmand, struikelblokDutch\n- impedir, seira, estorvar, obstruir, balaio, canastraPortuguese\n- корзина, затруднятьRussian\n- hämma, hindraSwedish\nGet even more translations for hamper »\nFind a translation for the hamper definition in other languages:\nSelect another language:', 'Single-use plastic packaging refers to the use of plastic materials for packaging products that are intended to be used once and then discarded. This type of packaging is widely used across various industries, including food and beverages, healthcare, personal care, and household products. Single-use plastic packaging offers convenience and affordability, but it has also raised concerns due to its negative environmental impact.\nSingle-use plastic packaging is any form of packaging made from plastic materials that are designed for one-time use. These packaging materials include plastic bottles, bags, containers, wraps, and other disposable items. They are commonly used for packaging products that require protection, preservation, or containment. Single-use plastic packaging is typically lightweight, cost-effective, and offers various functionalities such as sealing, flexibility, and transparency.\n|UNIT||Value (USD Million/Billion)|\nThe single-use plastic packaging market has witnessed significant growth in recent years, driven by factors such as urbanization, changing lifestyles, and the rising demand for convenience products. However, concerns over plastic waste management and environmental pollution have led to increased scrutiny and regulations on single-use plastics. This has prompted the industry to explore sustainable alternatives and adopt more environmentally friendly practices.\nKey Market Insights\n- Growing Demand for Convenience: The fast-paced lifestyle and increasing urbanization have fueled the demand for convenience products, driving the growth of single-use plastic packaging. Consumers prefer products that are easy to use, portable, and require minimal effort for disposal.\n- Environmental Concerns: The environmental impact of single-use plastic packaging, particularly plastic waste and pollution, has become a significant concern. Governments, organizations, and consumers are increasingly focusing on reducing plastic waste and promoting sustainable alternatives.\n- Regulatory Measures: Many countries have implemented regulations and policies to curb the use of single-use plastics. Bans on certain plastic products and the imposition of plastic taxes or levies have influenced market dynamics and encouraged the adoption of eco-friendly packaging solutions.\n- Shift Towards Sustainable Packaging: The industry is witnessing a shift towards sustainable packaging alternatives, such as biodegradable plastics, compostable materials, and recyclable packaging. Manufacturers are investing in research and development to develop innovative and eco-friendly packaging solutions.\n- Changing Consumer Lifestyles: The busy and on-the-go lifestyles of consumers have increased the demand for convenience products, which are often packaged in single-use plastic materials.\n- E-commerce Boom: The rapid growth of e-commerce has led to a surge in demand for packaging materials that can protect products during transportation. Single-use plastic packaging offers durability, flexibility, and cost-effectiveness for e-commerce packaging needs.\n- Increased Food and Beverage Consumption: The rising population and changing dietary habits have resulted in increased consumption of packaged food and beverages. Single-use plastic packaging provides a convenient and hygienic solution for food and beverage products.\n- Cost-Effective Packaging: Single-use plastic packaging is often more affordable compared to other packaging materials, making it an attractive choice for manufacturers, especially in price-sensitive markets.\n- Environmental Concerns and Regulations: Growing concerns about plastic waste and pollution have led to stricter regulations on single-use plastics. This has created challenges for manufacturers and increased the demand for sustainable packaging alternatives.\n- Shifting Consumer Preferences: As consumers become more aware of the environmental impact of single-use plastics, their preferences are shifting towards eco-friendly packaging options. This has created a need for manufacturers to adapt and invest in sustainable packaging solutions.\n- Recycling and Waste Management Issues: The recycling infrastructure for plastic packaging is often inadequate, leading to low recycling rates. Improving recycling capabilities and waste management systems is crucial to address the environmental impact of single-use plastic packaging.\n- Alternative Packaging Materials: The development and adoption of alternative packaging materials, such as paper-based packaging, bioplastics, and compostable materials, pose a challenge to the growth of single-use plastic packaging.\n- Sustainable Packaging Solutions: The demand for sustainable packaging alternatives presents a significant opportunity for manufacturers to develop and offer eco-friendly options. Investing in research and development to create innovative and sustainable packaging materials can help companies capitalize on this growing market segment.\n- Circular Economy Initiatives: The concept of a circular economy, where materials are reused, recycled, or composted, provides opportunities for the single-use plastic packaging market. Embracing circular economy principles can help reduce plastic waste and create a more sustainable packaging ecosystem.\n- Collaboration and Partnerships: Collaboration among stakeholders, including packaging manufacturers, brand owners, retailers, and waste management organizations, can foster the development of effective recycling and waste management solutions. Partnerships can also drive innovation and the adoption of sustainable packaging practices.\n- Consumer Education and Awareness: Educating consumers about the environmental impact of single-use plastics and promoting the benefits of sustainable packaging can create opportunities for companies to meet the evolving consumer preferences and capture a larger market share.\nThe single-use plastic packaging market is influenced by various dynamic factors. These include changing consumer preferences, regulatory landscape, advancements in packaging technology, and the emergence of sustainable packaging solutions. The market is characterized by intense competition, with players striving to differentiate themselves by offering innovative and sustainable packaging options. Collaborations and partnerships across the value chain are becoming increasingly important to address the challenges associated with plastic waste management and create a more sustainable packaging ecosystem.\nThe single-use plastic packaging market exhibits regional variations in terms of consumption patterns, regulations, and market dynamics. Developed regions such as North America and Europe have been at the forefront of implementing regulations to reduce single-use plastics. These regions also witness a higher consumer awareness and demand for sustainable packaging alternatives. In contrast, developing regions, particularly in Asia-Pacific and Latin America, are experiencing rapid industrialization and urbanization, driving the demand for single-use plastic packaging. However, these regions are also witnessing a growing emphasis on environmental sustainability, leading to increased efforts to reduce plastic waste and promote sustainable packaging practices.\nThe single-use plastic packaging market is highly competitive, with numerous players operating on both global and regional levels. Key players in the market include packaging manufacturers, material suppliers, and brand owners. These companies are actively investing in research and development to develop sustainable packaging solutions and gain a competitive edge. Partnerships, acquisitions, and collaborations are common strategies adopted by market players to expand their product portfolio, enhance their market presence, and address the challenges associated with plastic waste management.\nThe single-use plastic packaging market can be segmented based on various factors, including packaging type, end-use industry, and geography.\n- By Packaging Type:\n- Bags and Pouches\n- Wraps and Films\n- By End-Use Industry:\n- Food and Beverages\n- Healthcare and Pharmaceuticals\n- Personal Care and Cosmetics\n- Household Products\n- By Geography:\n- North America\n- Latin America\n- Middle East and Africa\n- Bottles: Single-use plastic bottles are extensively used for packaging beverages, including water, soft drinks, juices, and alcoholic beverages. The demand for lightweight and convenient packaging options has contributed to the growth of single-use plastic bottles in the market.\n- Bags and Pouches: Single-use plastic bags and pouches are widely used for packaging various products, such as snacks, groceries, and personal care items. The convenience and affordability offered by these packaging options have led to their widespread adoption.\n- Containers: Single-use plastic containers are commonly used for packaging food products, including ready-to-eat meals, sauces, and condiments. The durability and ability to preserve the freshness of the products have made plastic containers a preferred choice for manufacturers and consumers.\n- Wraps and Films: Single-use plastic wraps and films are used for packaging purposes, such as wrapping fresh produce, meat, and dairy products. These packaging materials provide protection, extend shelf life, and enhance the visual appeal of the products.\nKey Benefits for Industry Participants and Stakeholders\n- Cost-Effectiveness: Single-use plastic packaging is often more cost-effective compared to other packaging materials. It provides a cost advantage for manufacturers, particularly in price-sensitive markets.\n- Convenience and Functionality: Single-use plastic packaging offers convenience and various functionalities, such as sealing, flexibility, and transparency. These features enhance the usability and attractiveness of the packaged products.\n- Product Protection and Preservation: Plastic packaging provides effective protection against contamination, moisture, and physical damage. It helps preserve the freshness, quality, and shelf life of the packaged products.\n- Branding and Marketing Opportunities: Plastic packaging offers ample space for branding, labeling, and product information. Manufacturers can leverage this opportunity to enhance their brand visibility and communicate with consumers effectively.\n- Product Differentiation: The versatility of plastic packaging allows manufacturers to create unique shapes, sizes, and designs, enabling product differentiation in the market. This can help companies stand out and attract consumer attention.\n- Cost-effective packaging solution\n- Versatility and functionality\n- Excellent product protection\n- Environmental impact and concerns\n- Recycling and waste management challenges\n- Shifting consumer preferences\n- Growing demand for sustainable packaging\n- Circular economy initiatives\n- Collaboration and partnerships\n- Regulatory restrictions on single-use plastics\n- Competition from alternative packaging materials\n- Negative public perception and consumer backlash\nMarket Key Trends\n- Adoption of Sustainable Alternatives: The market is witnessing a growing trend towards the adoption of sustainable packaging alternatives. Manufacturers are exploring biodegradable plastics, compostable materials, and recyclable packaging to address the environmental concerns associated with single-use plastics.\n- Innovation in Packaging Technology: Advancements in packaging technology are driving innovation in the single-use plastic packaging market. Manufacturers are developing new materials, designs, and production techniques to enhance the functionality and sustainability of plastic packaging.\n- Circular Economy Initiatives: The concept of a circular economy is gaining traction in the packaging industry. Companies are exploring closed-loop systems, recycling initiatives, and partnerships to ensure the proper disposal and recycling of single-use plastic packaging.\n- Consumer Awareness and Education: Increasing consumer awareness about the environmental impact of single-use plastics is influencing purchasing decisions. Consumers are demanding more sustainable packaging options and actively supporting brands that prioritize eco-friendly practices.\nThe COVID-19 pandemic has had a significant impact on the single-use plastic packaging market. The increased demand for essential products, such as food, beverages, and personal care items, led to a surge in the use of single-use plastic packaging. The need for hygienic and convenient packaging options during the pandemic further drove the demand for single-use plastics. However, the pandemic also highlighted the importance of sustainable packaging and the need to address plastic waste management. The crisis has accelerated efforts to develop and adopt eco-friendly packaging alternatives, such as compostable materials and biodegradable plastics, to reduce the environmental impact of single-use plastic packaging.\nKey Industry Developments\n- Ban on Single-Use Plastics: Several countries and cities have implemented bans on certain single-use plastic products, such as plastic bags and straws. These bans aim to reduce plastic waste and promote the use of reusable and sustainable packaging alternatives.\n- Plastic Taxes and Levies: Governments have introduced taxes and levies on single-use plastics to discourage their usage and promote environmentally friendly alternatives. These fiscal measures encourage manufacturers to adopt sustainable packaging practices and invest in eco-friendly materials.\n- Collaboration for Recycling Infrastructure: Various stakeholders, including packaging manufacturers, waste management companies, and governments, are collaborating to improve recycling infrastructure. Investments are being made to enhance recycling capabilities and promote the circular economy.\n- Product Innovation: Manufacturers are focusing on developing innovative packaging materials and designs to reduce the environmental impact of single-use plastics. This includes the use of bio-based plastics, compostable materials, and packaging designs that minimize material usage.\n- Embrace Sustainability: Companies should prioritize sustainability and invest in research and development to develop eco-friendly packaging solutions. This will not only address environmental concerns but also cater to the changing consumer preferences and regulatory requirements.\n- Collaborate Across the Value Chain: Collaboration among packaging manufacturers, brand owners, retailers, and waste management organizations is crucial to develop effective recycling and waste management systems. Partnerships can also drive innovation and help create a more sustainable packaging ecosystem.\n- Educate Consumers: It is important to educate consumers about the environmental impact of single-use plastics and the benefits of sustainable packaging. Communication campaigns and labeling initiatives can help raise awareness and influence consumer behavior towards more eco-friendly choices.\n- Adapt to Regulatory Changes: Companies should closely monitor and adapt to changing regulations on single-use plastics. This includes complying with bans, implementing recycling programs, and exploring alternative packaging materials to ensure business continuity.\nThe single-use plastic packaging market is undergoing a significant transformation. The increasing focus on sustainability and the drive towards a circular economy will shape the future of the industry. The market is expected to witness a shift towards more sustainable packaging alternatives, such as bio-based plastics, compostable materials, and reusable packaging solutions. Collaboration and innovation will play a crucial role in addressing plastic waste management challenges and meeting the evolving consumer demands. The adoption of sustainable packaging practices will not only contribute to environmental conservation but also provide long-term business opportunities for industry participants.\nThe single-use plastic packaging market is at a turning point, with growing concerns over plastic waste and environmental pollution. While single-use plastics offer convenience and affordability, the negative impact on the environment has led to increased scrutiny and regulations. The industry is responding by exploring sustainable alternatives, investing in research and development, and collaborating across the value chain. The future of the market lies in adopting eco-friendly practices, embracing the circular economy, and educating consumers about the benefits of sustainable packaging. By prioritizing sustainability and innovation, industry participants can navigate the changing landscape and contribute to a more environmentally conscious and responsible packaging industry.']"	['<urn:uuid:9f166216-8721-42bb-a8aa-3fb4ff6323ee>', '<urn:uuid:0b1c65f9-0336-4525-8f92-768273a00e87>']	open-ended	direct	concise-and-natural	distant-from-document	three-doc	novice	2025-05-13T06:27:57.068978	9	77	2956
21	I want to monitor pollution outdoors - which reads faster, AirBox or NetPID?	NetPID reads data every 5 seconds, while AirBox takes measurements over a 5-minute period, making NetPID significantly faster in providing real-time pollution data.	"['In the tech-driven world spurred by the advent of COVID-19, people are warming up to the idea of social innovation to achieve real success driven by data and open-source collaboration.\nBut as with any collaboration, support is hard to achieve. Not only would the initiating members have to get support from the tech community, they must find a way for the society to participate and the government to lend their support in making their effort a success.\nAnd one good example of this is EdiGreen’s AirBox by Edimax in Taiwan.\nThe AirBox by Edimax. Image via Edimax\nWhat is AirBox\nAirBox is a project involving the collaboration between Academia Sinica, the community and a private industry operator (Edimax) to provide physical monitoring equipment to schools and citizens for PM2.5 sensing (air quality), temperature, humidity, and upload the collected information to the cloud platform. Information is integrated to the map, allowing users to monitor the air quality information of each other through the web or the application.\nAirBox is the brainchild of Chen Ling-jyh, a research fellow at Academia Sinica as well as Hsu Wuulong who is a founder of LASS, an online community for location-awareness sensing systems. Chen and Hsu met in 2015 and worked together on an open-source air quality sensor. It started out with connecting with a group of makers to build the AirBoxes at their own expense and to install the AirBoxes in as many locations as possible in the country.\nTaipei added the AirBox to its Smart City project to improve prediction accuracy of PM2.5 level, helping to boost the project further by gaining the attention of the public through the media..\nWithout such collaboration, the entire project could not have been a success.\nImage is a screen capture via BBC Click’s Inside Taiwan’s Tech Industry\nHow would someone know when the air pollution level is at a dangerous level, when they should be wearing a face mask or choose to avoid engaging in outdoor activities in order to keep themselves safe? Usually, the PM2.5 reading would be included in air quality reports from the environmental authorities. But where is this data coming from, and how accurate is it for the community?\nA research titled An Empirical Study of PM2.5 Forecasting Using Neural Network was published in August 2017 by Chen Ling-jyh, Sachit Mahajan and Tzu-Chieh Tsai to explore the possibilities of having hourly forecast of PM2.5, considering the fact that the right forecast model could improve prediction accuracy.\nIn the research, data used was gathered from the real world data from the AirBox project, showing that the proposed method of using Neural Netwoek Autoregression (NNAR) method accurately did the prediction with significantly low error, whilst providing a comparative analysis of two other models (Holt-Winters and ARIMA, autoregressive integrated moving average).\nOne of the challenges faced by the team was when the environmental engineers started disputing the accuracy of the AirBox, as both AirBox and the air testing station both were measuring the PM2.5 level. But the measuring method differs. Environmental engineers would take the average of the reading over a period of one hour or more from the data of air testing stations, whereas AirBox utilizes the microsensors to record the value over a 5-minute period. By doing so, the reading could easily be influenced by other external events such as a passing truck carrying dirt, or even a smoker standing next to the device.\nThe AirBox device as well as the application that users could access for information regarding air quality. Image via Edimax website.\nDifference In a Nutshell\nTo put it simply, the “end users” are different. Air testing stations collect data on a wide range of atmospheric indicators, while it might serve well as a general data, it might not meet the needs of the public. On the other hand, AirBox utilizes IoT (Internet of Things) as a mean to acquire information of air quality in real time whilst analyzing the data from an information engineering and big data perspective. For the public, this data would be more in their direct interest. But in no way these two are incompatible, but instead could complement each other for better analyses.\nWith real-time data, users would be kept well-informed of the air pollution around their area. Besides that, data gathered from AirBox could potentially assist in analyzing the origin of pollution, by analyzing the change of reading at different AirBox sites at different periods of time.\nAs researchers are looking into the relationship between PM2.5 and ill health conditions such as asthma and heart disease, more real time data from specific places could potentially help researchers gain more accurate data.\nIn an interview with BBC reporters on BBC Click, Chen Ling-Jyh introduced a surprising discovery of the reason for the ‘purple reading’, or what they call it bad pollution. They found that traditional incense burning was the culprit of the pollution. As a result, two well-known temples in Taiwan, namely the Xingtian Temple and the Longshan Temple, no longer have incense burners. On top of that, AirBox was installed in these locations.\nProfessor Chen Ling-jyh, a fellow researcher at Academia Sinica. Air quality of Taiwan populated on the map. Discovery of the source of pollution shared on Facebook, a social networking site. Image of the incense burner in a Taiwanese temple. All images are screen captures via BBC Click’s Inside Taiwan’s Tech Industry\nThe main learning point of the project was simple: the solution to pollution starts from understanding air quality. AirBox gathers data to the people, and through data the members of the public are given the power to improve air quality though changing their lifestyles.\nKeeping it Open Source\nThe value of keeping AirBox open source outweighs the value of patenting the item. While it was not a difficult device to produce, proprietary system would not have the ability to scale and mature. But with the software being available to the public, more people could facilitate the growth.\nOwing its success to their transparency in keeping information open-source, AirBox is being exported overseas to countries like Singapore, Korea and the US.\nWith simple color coding, people could understand the air quality better. Schools could make decisions on postponing outdoor activities from the air quality information, to ensure students would not be unnecessarily subjected to pollution.\nSchools could also gain access to air quality data in their surrounding area to facilitate better decision making. Image via Edimax\nIn a data-driven society, information is used as a nudge to encourage people toward making better, informed decisions. The reliability of data is important to gain the trust of all stakeholders.\nWhen trust between the government, academia, industry operator and the general public is created, everyone could do their part in increasing the quality of life. And this is exactly what the AirBox project in Taiwan achieved. The future is COLLABORATION.\nSource: Mahajan, Sachit & Chen, Ling-Jyh & Tsai, Tzu-Chieh. (2017). An Empirical Study of PM2.5 Forecasting Using Neural Network. 10.1109/UIC-ATC.2017.8397443.\nNote: AirBox is not to be confused with airbox in the car (the empty chamber on the inlet of most combustion engine)', 'High sensitivity VOC monitoring station\nAutonomous VOC monitoring station suitable for creating complex networks. NetPID enables reliable detection of VOCs even in harsh weather conditions.\nNetPID is based on the use of sensitive photoionization detectors capable of determining the presence of VOC at ppb level.\nNetPID acquires every 5 seconds and stores data from each sensor. Measurements history is available at any time due to the internal storage. Remote data handling option is available at any time via PC, Tablet or Smartphone.\nOn-demand sampling of the air for VOCs and odors characterization with OdorPrep ® is available if you get OdorSENS: optional tool of the OdorPrep App. OdorSens allows to check the current status of each sensor and set thresholds limit for sampling activation. Options for e-mail alerting and push notifications are included.\nFugitive emissions of voc\nDeriving for example from the storage, unloading, handling of crude and refined oil.\nForecast fugitive emissions to implement corrective actions. Evaluation of the odor emissions as part of the health impact assessment plan.\nRemote unattended monitoring\nRemote monitoring of VOCs in high temporal resolution, real-time data available through online platform and alert notification system.\n|PERFORMANCE||PID PPB||PID HS (High sensitivity)|\n|Resolution||1 ppb||0.5 ppb|\n|Range||0 – 40 ppm||0 – 3 ppm|\n|Response time T90 (S)||< 8||< 12|\n|Sensitivity||>30 mV/ppm||> 600 mV/ppm|\n|Consumption||100 mW||100 mW|\n|Features of the Lamp||10.6 eV 10,000 Hours||10.6 eV 10,000 Hours|\n|Operating temperature||-40 – 65 °C||0 – 40 °C|\n|Sensitivity to humidity||0 – 99% RH, non condensing||0 – 99% RH, non condensing|\nThe control unit\nThe control unit is made of inert polymeric material capable of minimizing the influence of the external ambient temperature. The response and sensitivity of the sensors positioned inside the unit have been further optimized thanks to a fluid system designed to expose the photoionization detector to forced air circulation. There is also a filter at the suction point inlet to limit the influence of dust.\n|Dimension (H x L x W)||100 mm x 300 mm x 300 mm|\n|Power supply||5 to 24 V ; 15 W|\n|Data storage||Years depending on the setting|\n|Comunication||3G / 4G (SIM card not included)|\nData storage and communication system\nNetPID acquires every 5 seconds and stores the data of each sensor. The measurement history is available at any time thanks to the internal memory. NetPID can operate in two ways: autonomous (Stand-alone) and online.\nStand-alone mode is the operation mode if an internet connection is not available. You can have remote access to NetPID through the exposed access point and via the network interface, if it is connected via LAN cable or Wi-Fi.\nOnline mode is available whenever NetPID has an Internet connection. All the features of the stand-alone mode are included. In addition, NetPID synchronizes and updates the data in real time with an online platform to view and download the collected data. Through the online platform it is also possible to set threshold values (""trigger"") for each sensor and activate notifications via email\n- High Sensitivity\nReliable measurements of VOCs at ppb or sub ppb level. Fence Electrode technology for suppressing the non-specific contribution of moisture. Pressure, Temperature and relative humidity measurements included.\n- Response Optimization\nThe control unit is made of inert polymeric material capable of minimizing the influence of the external ambient temperature. Response and sensitivity of sensors have been further optimized thanks to a new fluidic system design.\n- High Temporal Resolution\nNetPID synchronizes and updates data in real-time with an online platform that let\'s you viewing and downloading the collected data. You can even set threshold values (""triggers"") for each sensor and activate e-mail notifications.']"	['<urn:uuid:8646225d-c516-454b-a303-a24346850012>', '<urn:uuid:22e9b31b-c456-4546-bbf8-d0c589803d1e>']	factoid	with-premise	concise-and-natural	distant-from-document	comparison	novice	2025-05-13T06:27:57.068978	13	23	1786
22	I'm trying to understand corn better - what makes it different from wheat for people who can't eat gluten, and what interesting discoveries have scientists made about corn's resistance to pesticides?	Corn is naturally gluten-free, unlike wheat which contains proteins that can cause digestive problems in some people. While corn contains amino acids, it doesn't have the same proteins that cause issues for those with gluten sensitivity or celiac disease. As for pesticide resistance, scientists made an interesting discovery in the 1980s when they found bacteria in a Roundup manufacturing plant's waste water that was immune to the herbicide. This discovery led to the development of pesticide-resistant corn varieties, as scientists were able to transfer the resistant genes from these bacteria into crop plants.	"[""14 August, 2017\nWhat does fact checked mean?\nAt Healthfully, we strive to deliver objective content that is accurate and up-to-date. Our team periodically reviews articles in order to ensure content quality. The sources cited below consist of evidence from peer-reviewed journals, prominent medical organizations, academic associations, and government data.\nThe information contained on this site is for informational purposes only, and should not be used as a substitute for the advice of a professional health care provider. Please check with the appropriate physician regarding health questions and concerns. Although we strive to deliver accurate and up-to-date information, no guarantee to that effect is made.\nCornbread with butter drizzled on top is a classic American treat, but you might hesitate to eat it if you are concerned about its gluten content. Although most Americans consume foods containing gluten every day, trouble-free, some suffer side effects, including bloating and irritation of the small intestine. Celiac disease is an autoimmune disorder that makes you sick whenever you eat gluten. Symptoms of celiac disease include weight loss, pain and lethargy.\nGlutens are proteins contained in wheat, barley and rye foodstuffs. Rice and corn are grains that are naturally gluten free. Corn does contain some amino acids or building blocks of proteins, but it doesn't have the same ones that cause digestive problems in some humans. Glutens in wheat provide the elasticity that helps form bread and gives a satisfying chew to pizza dough. Corn flour doesn't have the glue-like quality of wheat flour, so you typically add a binder such as eggs to corn flour dough to keep it intact when baking.\nCorn flour works well as a substitute for wheat flour and provides a pleasant, slightly gritty texture to breads and cakes. If you just want to cut down on the amount of gluten in your breads, pancakes or tortillas, you can mix corn flour together with wheat flour to get a product that holds together well but also has a distinct corn flavor. You can use corn flour as a thickener in stews and soups, but be aware that it will impart its flavor profile to your foods.\nCorn meal and corn flours were staples in Native American cultures before Europeans adopted it as a crop. Corn also had its public relation problems when Europeans who relied on corn as a staple developed pellagra. Now understood as the result of an incomplete processing of corn grain, pellagra results from niacin deficiency, and symptoms include insomnia, aggression and intolerance of sunlight. Native Americans in Mexico soaked corn in lime water, a process that liberated niacin and made it available for absorption. When purchasing corn products, check the packaging information to make sure the only starches or flour used are from corn, not blends of different grains.\nFollowing a gluten-free diet is mandatory for those people diagnosed with an existing disorder or sensitivity, but you might elect to avoid gluten for other reasons. The breads, pastries and pastas that contain gluten also can be calorie-dense, so reducing consumption of those foods can help weight loss efforts. Merely substituting gluten-containing cakes with those that are gluten-free will not aid weight loss efforts. Many foods containing gluten are fortified with vitamins and minerals. By eliminating all gluten from your diet, you can also inadvertently lower important nutrients such as folate in your daily intake, so talk with your health care provider or nutritionist before embarking on a totally gluten-free diet.\n- MedlinePlus: Celiac Disease -- Nutritional Considerations\n- Exploratorium: Goodness Gracious! Great Balls of Gluten!\n- European Food Information Council; The Origins of Maize --The Puzzle of Pellagra; December 2001\n- The Cook's Thesaurus: Wheat Flours; Lori Alden\n- Fitness; Healthy Diet Myths Debunked; Karen Ansel;\n- Brand X Pictures/Brand X Pictures/Getty Images"", 'Outside of drought and hail, insects and weeds are the worst threats to agricultural crops, so it’s not surprising that those pests were the first to be attacked by genetic engineers.\nWeeds were the first targets. In the 1980s, Monsanto already produced the powerful herbicide Roundup. It works by disrupting the action of an enzyme that is found in almost all plants but not in humans. The problem was how to apply Roundup to the plants you don’t want and keep it off the plants you do – get it on the weeds while keeping it away from the crops. That’s tough to do, so farmers were using Roundup early in the growing season to kill weeds that sprouted before the crops, and then switching to less powerful herbicides after the crops germinated.\nGenetic engineers wondered if they could find a gene that would allow crops to survive and even thrive when they are exposed to Roundup. The reasoning was that the pesticide worked on enzymes, and enzymes are proteins that are produced by genes – therefore, there might be a gene that could protect the crop from the pesticide.\nProfessor Don Lee (right) says that the scientists found their resistant gene in an unusual source that was actually natural. “Monsanto, the company that developed Roundup resistance went looking for Roundup resistance in nature,” he says. “And guess where they found it? They went to bacteria that were in the waste water treatment facility of their one of their Roundup manufacturing plants!”\nIn the early 80s, workers at a Roundup manufacturing plant in Louisiana noticed that bacteria were breaking down the chemical residue left over. Scientists took 20 different bacteria from the waste facility and found one of that was totally immune to the effect of Roundup or other glyphosate pesticides.\nThe next task was to put the gene from the bacteria into crop plants.\nIn 1987, Monsanto started field trials with GMO biotech plants. It took until 1996 to complete the tests, get the regulators to approve of the new hybrids and introduce to the world “Roundup Ready Soybeans.” Farmers could now plant the soybeans, wait for the weeds and the crop to come up and spray once with Roundup. The weeds would die and the crops would grow without the pressure from competing weeds.\nIn 1997, Monsanto introduced GMO varieties of canola and cotton.\nOther companies used similar strategies. For example, the German firm AgrEvo had their own powerful herbicide named “Liberty,” that killed plants by disrupting their ability to use nitrates from the soil. In 1995, they introduced in Canada a genetically modified variety of canola that could resist the action of Liberty herbicide. In 1997, their GM corn variety was introduced in the U.S.\nThe European corn borer was the next pest to be attacked by GMOs in 1996 with the introduction of “Bt corn hybrids.” The corn borer is the most damaging insect pest of corn throughout the U.S. and Canada with losses exceeding $1 billion a year in the 1990s.\nFor decades, agricultural scientists have known that a common bacteria found in the soil can produce toxins that are deadly to insects but harmless to humans because they are destroyed within seconds by the acids in the human digestive tract. The bacteria are known as Bacillus thuringiensis and the toxins they produce – not surprisingly – are known as Bt toxins. There are thousands of different kinds of Bt bacteria and they produce different toxins that affect different insects. In fact, organic farmers have used these Bt microorganisms for decades since they produce natural insecticides.\nIn the early 90s, genetic engineers realized that the genes of Bacillus thuringiensis were what produced the Bt toxin, and they found a way to isolate those specific genes. They transferred those genes into a second bacteria – Agrobacterium – that has the ability to get into the nuclei of plants like corn and transfer genetic material to the corn. Then, they figured out how to find the specific plants that had been altered by including other genes that were resistant to chemicals like antibacterial drugs.\nMycogen and Ciba Seeds (now Novartis Seeds) first introduced Bt corn hybrids in 1996. Farmers found out that the corn borers died after eating only a few bites of the Bt corn plant. Monsanto was not far behind with its own Bt corn, and other companies like Pioneer have either developed their own strains or licensed the technology from other companies.\nBt technology has also been used to attack other insect pests in cotton, potatoes and soybeans.\nSince then, there have been a number of new genetic modifications to a wide variety of crops –\n- Sweet potatoes have been enhanced with more protein and other nutrients.\n- Golden rice has been modified by the International Rice Research Institute to provide a low level of Vitamin A. They spliced in genes from the daffodil plant that produce the vitamin, also known as beta carotene.\n- Carrots have been modified to provide at least a little calcium.\nAgricultural scientists are now taking genetic modification further by “stacking” two or more genetic traits in a single plant. In one variety, there eight different genetic modifications in a single hybrid of corn.']"	['<urn:uuid:979d607f-2e02-4fe1-a006-04951b3d53ec>', '<urn:uuid:171a43c1-7a19-4f03-88bc-25bc4259d3b0>']	factoid	with-premise	verbose-and-natural	similar-to-document	multi-aspect	novice	2025-05-13T06:27:57.068978	31	93	1504
23	need tips prevent waterfowl damage lake quality water pollution environment protect	To protect lake water quality from waterfowl damage: 1) Absolutely avoid feeding any waterfowl, as their droppings contain nitrogen and phosphorous that accelerate algae growth and can lead to dangerous blue-green algae. Their feces also contribute to E. coli contamination and can contain parasites causing swimmers itch. 2) Create natural shoreline buffers with native plants extending 20-30 feet back from the shore - this not only deters waterfowl but also benefits lake health. 3) For lakefront properties, maintain natural vegetation instead of lawns, as geese prefer grazing on open grass areas. One adult goose can eat four pounds of grass daily and produce one to three pounds of droppings. These measures help maintain water quality, particularly in headwater lakes where environmental degradation primarily comes from resident actions.	['Embark on a fishing adventure, catch a glimpse of wildlife and explore nature at Eagle Lake!\nThe lake is a popular with anglers and the varying depths of the lake makes for great fishing year round.\nNatives species to the lake include brook trout, lake trout, whitefish, brown bullhead, white sucker and the smelt. Specific programs to stock the lake with walleye, rainbow trout, smallmouth bass, and yellow perch have taken place over many decades. Northern Pike were also introduced to the lake approximately five years ago.\nThe lake is home to at least three sets of loons, snapping turtles, many families of duck, otters, deer, bald eagles, osprey and over 90 other species of birds. Black bears are also frequently spotted at the township landfill site.\nEagle Lake and the surround community is home to many species of stunning flora and there are multiple nature and hiking trails to explore.\nBe sure to check out the Discover Trails website for more information. Whether you are looking for a short 30 minute hike on foot through Mikisew Provincial Park or a longer day journey by bike with a 65 km ride around the entire lake this website should be your first spot when planning an adventure!\nCANADIAN GEESE AT EAGLE LAKE\nA new family spotted on the lake on July 2016\nOver the past few years we have had numerous complaints about Canada Geese fouling peoples’\nproperty. Ironically, Canada Geese did not historically stay on Eagle Lake during the summer but only\nstopped temporarily when they were migrating. Unlike most waterfowl, these geese feed primarily on land, and prefer grazing on large open lots which they do for around twelve hours a day. They digest very quickly (approximately one hour) and require large amounts of food from which to obtain their nutrition. For example, it is estimated that an adult Canada Goose will eat four pounds of grass per day and deposit one to three pounds of droppings on the lawn or in the water.\nWhen they are moulting they cannot fly. Since the moulting period lasts for a month or more, they must be able to find sufficient forage in the water or within walking distance of their waterway. Traditionally, Eagle Lake did not provide conditions suitable for this feeding pattern. However, there are now numerous properties from which the geese can easily access the grass they enjoy for forage. These lawns also provide wide, unobstructed views of any approaching predators and ready access to the safety provided by the water. By nature, these are tundra animals that congregate on low vegetation in close proximity to water.\nThe main problem for lakefront property owners is the mess that is created on their properties. The droppings are extensive, messy, and a potential health risk. They contribute to e coli contamination, and can contain parasites such as that which causes swimmers itch. In addition to polluting the Lake, the fecal material contain both nitrogen and phosphorous which accelerate the growth of algae. With the recent emergence of the dangerous blue/green algae in Lake Bernard, this represents a significant potential threat for our Lake. Adult geese can also become aggressive if disturbed, particularly when breeding and nesting.\nThere are a number of things a property owner can do to prevent these problems: Firstly, do not feed these geese or any other waterfowl. Human food such as bread and popcorn does not contain the nutrition they require, and feeding encourages them to return. Secondly, if you maintain a lawn, a natural or artificial barrier can limit or eliminate their access to your lawn. The preferable option involves creating a barrier of natural vegetation at the shoreline. Canada Geese will not wander through underbrush that limits their visibility and reduces their sightlines. Ideally, the barrier should be over thirty inches tall. It works best if it continues 20 to 30 feet back from the shoreline. This option provides numerous other benefits for the health of the Lake and the shoreline.\nFor more expedient solution, you can create a barrier such as a fence. Other, more elaborate, options that have been suggested include a wire stretched across the shoreline, or plastic netting placed on the grass.\nEagle Lake has always been fortunate because, as a headwater lake, the only way the water or environment can become degraded is through the action of residents whose property is on or near the lake or those that use it on a temporary basis. Historically, the main environmental concern for the ELCA centred on the high level of phosphorous in the water which represented the most immediate threat to the Lake.\nRecently another threat to the health of the Lake has been identified. Invasive Phragmites (European Common Reed) has been identified in the south basin of the Lake. The most dense outcrop of this perennial grass is growing at the property located at 40 Angus Point Road. For more information from the ELCA on phragmites, please check out the February 2017 and June 2017 newsletters.\nUpdate – July 2017: Recently, the ELCA partnered with Robert Canning to draft the Eagle Lake Visit Report_DRAFT. The Eagle Lake Conservation Association (ELCA) had a number of concerns regarding phragmites on their lake, primarily related to the distinction between native and invasive subspecies and management options for shoreline phragmites adjacent to a proposed boat launch development site. Awareness of phragmites on Eagle Lake by the ELCA began around 2015/2016 when this species was observed at the future municipal boat launch site. Interviews with other shoreline residents indicate that this plant may have been present in the lake for between 5-10 years.', 'Geese, ducks and swans can be a beautiful part of our lake and stream ecosystems, but overly large populations can cause significant impacts on water quality, human health, and other native plants and wildlife. So what can you do to help keep overly large populations away from our lakes and streams? Following some of the suggestions below will help you make a difference.\nDo Not Feed Waterfowl - Ever!\nFeeding waterfowl is an understandably fun activity, especially for young children, but it is one of the biggest reasons that these populations have spiraled out of control in recent history. The single most important thing you can do to help protect water quality and human health is to pledge to STOP feeding all geese, ducks, swans, and even seagulls. Not only does feeding encourage these birds to stay in one place for long periods of time, but it also makes them more accustomed to human interaction, which in turn can make them act more aggressively towards people. In addition, bread and other human foods are not healthy for waterfowl – their native diet includes plants, seeds and insects, and human food lacks the nutrients and roughage needed to keep these creatures healthy.\nCreate a Barrier\nDo you live on a lake or near a pond? Canada geese in particular prefer beaches or short mowed shorelines and are found in much larger numbers when these conditions—or, habitat—are available. The birds like open areas so they can watch out for predators, and planting a buffer of native grasses, flowers, or shrubs along your shoreline or utilizing native plants in your yard can create a visual block so that geese and swans will avoid those areas. A more natural shoreline not only keeps geese off your lawn, but it also helps protect water quality and provides great habitat for native insects and wildlife. Vegetative or rock barriers are often most effective, but even a simple fence can sometimes help discourage birds. Read on for basic ideas, but for more detailed information on how to create a natural shoreline, check out the Clear Choices Clean Water Shorelines page.\n- Vegetative barriers: Simply leaving an unmowed strip of vegetation approximately 20-30 feet out from the shoreline is the easiest step you can take and a very effective method for deterring geese. Even better would be planting native shrubs, hedges, or other taller plants around the water. See the Shorelines page for more ideas on beautiful native shoreline plantings that do double duty as goose repellents. Interestingly, some research suggests that geese prefer fertilized grass to unfertilized, so taking the Clear Choices Clean Water Fertilizer pledge can also help deter waterfowl!\n- Rock barriers: Large boulders, greater than 2 feet in diameter, placed along the shoreline may help impede waterfowl movement towards shore. This is even more effective when used in conjunction with vegetative barriers.\n- Fence barriers: Even a simple fence can deter waterfowl from walking up onto your property. Any fence should be at least 30 inches tall and have openings no larger than 3 inches in diameter. Examples of effective fencing include woven wire, chicken wire, plastic snow fencing, or construction fencing. Again, effectiveness of this option is enhanced when it is used in conjunction with other methods.\nRemove Nesting Materials or Destroy Eggs\nIf you have a large population of Canada Geese, you may need to take more aggressive measures to reduce or eliminate the group. Nest and egg destruction is one such action. Another approach is to trap the geese and either relocate or euthanize them. Both of these actions require permits. Several resources are listed below to help you if you are interested in these activities.\nHunting Geese and Ducks\nCanada geese and ducks can be hunted in compliance with state and federal regulations during the regular waterfowl season from November to February, with specific dates varying annually. There is also a special early hunting season for geese that typically runs the first two weeks of September. Mute Swans are a federally protected bird and currently do not have a regulated hunting season, so refrain from hunting them! If a swan becomes a nuisance on your property, you can contact IDNR Division of Fish and Wildlife for assistance with control.\nOther Deterrent Methods\nScare them away: Various methods are available for scaring geese away from your shoreline. Generally, loud noise making devices such as propane cannons, whistles, alarms, or pre-recorded goose distress sounds can be helpful when used in conjunction with other control methods. Be aware that noise making methods may require special permitting depending on local ordinances. Visual deterrents such as Mylar tape or scarecrows can also be effective, as well as regular patrol of the area by your dog!\nChemical repellents: There are a few chemical repellents available to control geese, but they tend to be used as a last resort due to their high cost and short duration of control. These are most often used in areas with significant human traffic, such as grassy picnic areas or parks. As with any chemical product, always use caution and follow label directions carefully when applying.\nScooping the Poop\nIf you clean up your shoreline or your pier by removing droppings, make sure you are disposing of them properly. Don’t sweep or wash them from your lawn or pier into the water – that’s just adding more nutrients and bacteria into the lake or stream! Instead, scoop the droppings and throw them in the trash, flush them down the toilet, bury them in the yard, or put them in an underground pet waste digester.\nGeese or Other Waterfowl Becoming a Nuisance?\nIf geese or other waterfowl are becoming a problem, this handy guide from the Indiana Department of Natural Resources can help you determine the best course of action.\nIf the problem reaches the point where a professional needs to be called, here is a list of IDNR approved waterfowl control operators.']	['<urn:uuid:c3c02a6f-1c5d-42dc-b9c9-3cacce5a9f71>', '<urn:uuid:33c879d2-dbff-4459-8eb7-485eb951426e>']	open-ended	with-premise	long-search-query	similar-to-document	three-doc	novice	2025-05-13T06:27:57.068978	11	127	1929
24	goes r vs himawari imaging speed comparison	The GOES-R and Himawari satellites have different imaging capabilities. Himawari obtains a global scan every 10 minutes and images of Japanese territory every 2.5 minutes. GOES-R produces full images of the Western Hemisphere every 15 minutes, continental United States every 5 minutes, and specific storm regions every 30 seconds. While both satellites have identical spectral coverage and resolution, the GOES-R surpasses Himawari in terms of collection speed.	['CAPE CANAVERAL, Fla. >> The most advanced weather satellite ever built rocketed into space Saturday night, part of an $11 billion effort to revolutionize forecasting and save lives.\nThis new GOES-R spacecraft will track U.S. weather as never before: hurricanes, tornadoes, flooding, volcanic ash clouds, wildfires, lightning storms, even solar flares. Indeed, about 50 TV meteorologists from around the country converged on the launch site — including NBC’s Al Roker — along with 8,000 space program workers and guests.\n“What’s so exciting is that we’re going to be getting more data, more often, much more detailed, higher resolution,” Roker said. In the case of tornadoes, “if we can give people another 10, 15, 20 minutes, we’re talking about lives being saved.”\nThink superhero speed and accuracy for forecasting. Super high-definition TV, versus black-and-white.\n“Really a quantum leap above any satellite NOAA has ever flown,” said Stephen Volz, the National Oceanic and Atmospheric Administration’s director of satellites.\n“For the American public, that will mean faster, more accurate weather forecasts and warnings,” Volz said earlier in the week. “That also will mean more lives saved and better environmental intelligence” for government officials responsible for hurricane and other evacuations.\nAirline passengers also stand to benefit, as do rocket launch teams. Improved forecasting will help pilots avoid bad weather and help rocket scientists know when to call off a launch.\nThe first in a series of four high-tech satellites, GOES-R hitched a ride on an unmanned Atlas V rocket, delayed an hour by rocket and other problems. NOAA teamed up with NASA for the mission.\nThe satellite — valued by NOAA at $1 billion — is aiming for a 22,300-mile-high equatorial orbit. There, it will join three aging spacecraft with 40-year-old technology, and become known as GOES-16. After months of testing, this newest satellite will take over for one of the older ones. The second satellite in the series will follow in 2018. All told, the series should stretch to 2036.\nGOES stands for Geostationary Operational Environmental Satellite. The first was launched in 1975.\nGOES-R’s premier imager — one of six science instruments — will offer three times as many channels as the existing system, four times the resolution and five times the scan speed, said NOAA program director Greg Mandt. A similar imager is also flying on a Japanese weather satellite.\nTypically, it will churn out full images of the Western Hemisphere every 15 minutes and the continental United States every five minutes. Specific storm regions will be updated every 30 seconds.\nForecasters will get pictures “like they’ve never seen before,” Mandt promised.\nA first-of-its-kind lightning mapper, meanwhile, will take 500 snapshots a second.\nThis next-generation GOES program — $11 billion in all — includes four satellites, an extensive land system of satellite dishes and other equipment, and new methods for crunching the massive, nonstop stream of expected data.\nHurricane Matthew, interestingly enough, delayed the launch by a couple weeks. As the hurricane bore down on Florida in early October, launch preps were put on hold. Matthew stayed far enough offshore to cause minimal damage to Cape Canaveral, despite some early forecasts that suggested a direct strike.', 'Japan’s H-IIA launch vehicle is set for liftoff from the picturesque Tanegashima Space Center on Wednesday, carrying into orbit the Himawari-9 advanced meteorological satellite.\nLiftoff – pushed from Tuesday due to bad weather – is expected at 6:20 UTC, the opening of a launch window of nearly three hours. Blasting off from the southern tip of Tanegashima Island, the 53-meter tall H-IIA will scream away with a thrust of 685 metric tons, delivered by a cryogenic core stage and a pair of Solid Rocket Boosters which will fire for the first 100 seconds of the flight.\nWith the boosters gone, the core continues to fire its 109-metric ton force LE-7A engine until six and a half minutes into the flight, handing off to the cryogenic second stage which will be tasked with a pair of burns of its LE-5B engine – first a five and a half-minute burn into a Parking Orbit ahead of a burn of a little over three minutes to boost the 3,500-Kilogram satellite into Geostationary Orbit with separation planned 28 minutes after liftoff.\nThis is Japan’s second launch of the year following up on the Astro-H (Hitomi) space observatory in February which enjoyed a flawless launch but succumbed to a chain of onboard failures just a few weeks into the mission well before any meaningful observations of the X-Ray universe could be made.\nHimawari-9 is the second in a pair of identical Geostationary Meteorological Satellites (GMS) ordered from Mitsubishi Electric in 2009 by the Japanese Meteorological Agency. The Himawari-8 satellite was lifted into orbit in October 2014 to replace the aging Himawari-6 satellite launched in 2005 and to significantly enhance global imaging capabilities with the inauguration of the Advanced Himawari Imager (AHI) – the main instrument of the new generation of satellites.\nThe Himawari-8/9 satellites are currently the most advanced Geostationary MeteoSats in terms of image resolution, spectral coverage and image acquisition time – obtaining a global scan every ten minutes in addition to images of the Japanese territory every two and a half minutes. The GOES-R-class satellites operated by NASA and NOAA – set to debut later this month – have identical spectral coverage and resolution but will surpass Himawari in terms of collection speed.\nBuilt by Mitsubishi Electric based on the DS-2000 Geostationary Satellite Bus, Himawari-9 weighs 3,500 kg at liftoff and hosts a single power-generating solar array that is deployed once in orbit. The main instrument, AHI, was developed by Exelis and covers 16 spectral bands, three in the visible wavelengths at a resolution of 0.5/1 Kilometers and 13 infrared channels at a two-Kilometer resolution.\nThe two-axis imaging instrument sweeps out image strips in the East-West directions and steps North/South for each successive scan to assemble a global frame every ten minutes, requiring 23 North/South steps. In addition, three regional frames will be collected every 2.5 minutes covering Japan plus a targetable region of interest to deliver high-speed data on targets such as Typhoons.\nHimawari’s spectral coverage permits data to be used for a variety of applications including environmental monitoring and operational weather now- and forecasting. The infrared channels are used to deliver relevant data for the observation of cloud distribution and properties, atmospheric water, aerosols, rainfall, temperature and a number of other properties.\nThe Himawari satellites also carry a data collection system terminal to receive data from deployed terminals such as remote weather stations and sea-state platforms. Space Radiation is monitored by a dedicated detector to provide data on the radiation environment in Geostationary Orbit.\nHimawari 8 and 9 each are built for a 15-year lifetime including eight years of primary service delivering meteorological data, ensuring operational service will be available through 2031.\nHimawari-9 was originally set for liftoff on November 1st, but a bad weather forecast for the rocket’s rollout on Monday prompted the decision to push the rollout to Tuesday and set up for liftoff on Wednesday at 3:20 p.m. local time. The mission has a luxuriously long window of two hours and 58 minutes, providing plenty of time to deal with any hold-ups in the countdown. Weather is expected to be favorable with temperatures around 22°C, mostly clear skies and light winds at 7 meters per second.\nCountdown & Launch Sequence\nH-IIA began its rollout to the launch pad at 16:30 UTC on Tuesday, marking the start of the rocket’s countdown. It takes around half an hour for the rocket to complete the 400 meter trip from its Vehicle Assembly Building before being carefully centered on the launch pad to begin the connection of ground system umbilicals.\nAbout eight hours before launch, teams evacuate the launch pad to get ready for the long propellant loading sequence.\nBeginning at about X-7 Hours and 45 Minutes, the complex tanking sequence gets underway with the pressurization and chilldown of ground support systems handling the -183-degree Celsius LOX and -253°C LH2. Fueling goes through a number of steps including ground support system chilldown, propellant tank chilldown and propellant loading, before tanking enters replenish mode.\nThe propellant loading sequence takes approximately three hours until 116,600 Kilograms of cryogenics needed for launch are on board. Replenishing the propellants as they boil off, the tanks are kept at topping level until late in the countdown.\nThe majority of the countdown will be spent with extensive tests of the launch vehicle’s flight control system, checks of all electronics and controllers and verifications of the radio link between the launcher and the ground. Over the final hour of the countdown, last-minute items will be closed out and the vehicle will be reconfigured for the Automatic Countdown Sequence starting just 4.5 minutes prior to blastoff.\nAs computers are given control of the countdown, H-IIA’s Propellant Tanks will be pressurized for flight. At X-3 minutes, the launch vehicle is switched to internal power while Himawari-9 will have been switched to battery power ahead of the final countdown sequence. One minute before liftoff, thousands of Kilograms of water are being poured over the launch platform to suppress the acoustic loads at ignition & liftoff.\nLaunch Vehicle Ordnances will be armed at X-30 Seconds and the Guidance System of the Vehicle is switched to Flight Mode 12 Seconds later before the sparklers underneath the LE-7A main engine ignite to burn off residual Hydrogen.\nIgnition Sequence Start is commanded at X-5.2 Seconds and the LE-7A Engine soars to life as the turbopumps spin up to flight speed – monitored by on-board computers to make sure the engine is healthy before the booster ignition command is issued at T-0 to commit the vehicle to launch.\nAs the boosters ignite, H-IIA will jump off its pad with a total thrust of 684,500-Kilogram-force. The twin boosters deliver 78% of the total liftoff thrust as the H-IIA climbs away from its sea-side launch pad with the usual scream unique to Japan’s H-II rockets.\nThe 285-metric ton launch vehicle will make a short vertical ascent before executing its roll and pitch program to achieve the planned ascent trajectory – flying south-east for a trip across the Pacific, heading for an orbit inclined 22.4 degrees.\nThe two boosters fly in a special configuration with a shorter burn time, but higher thrust – optimized for a GTO mission profile. Each of the twin boosters will be delivering 281,200-Kilogram force of thrust over the course of a 98-second burn to accelerate the launcher to a speed of 1.5 Kilometers per second.\nAs thrust on the boosters tails off when their solid propellant is depleted, sensors will detect a pressure-drop and trigger the separation of the 15-meter long boosters around ten seconds after burnout at an altitude of 53 Kilometers.\nWith the boosters gone, the 37.2-meter Core Stage will continue powered ascent using the LE-7A alone, burning 260 Kilograms of cryogenics per second to generate 109,300 Kilogram-force of thrust when flying in the tenuous outer layers of the atmosphere.\nWhen reaching an altitude of 142 Kilometers at a mission elapsed time of four minutes and five seconds, H-IIA will separate its protective payload fairing, exposing the payload on its way uphill and shedding no-longer needed weight.\nThe first stage will continue operation until T+6 minutes and 36 seconds, boosting the stack to a velocity of 5.3 Kilometers per second. Stage separation occurs eight seconds after cutoff at an altitude of 220 Kilometers as pyrotechnics cut the connection between stages and springs push the Core Stage away.\nThe LE-5B engine of the second stage will ignite six seconds after stage separation, at T+6:50 to deliver 13,970kgf of thrust for a burn of five minutes and 20 seconds tasked with lifting the stack into a Parking Orbit around 250 Kilometers in altitude.\nWith the conclusion of the first burn of the 9.2-meter long second stage, the vehicle enters a coast phase of eleven and a half minutes, continuing on a south-easterly heading targeting a point near the equator for the second ignition in order to insert Himawari-9 into a Geostationary Transfer Orbit peaking over the equator which eases the process of phasing the satellite into its operational orbit.\nAt T+23 minutes and 50 seconds, the second stage will re-ignite on a burn of three and a quarter minutes that will raise the apogee of the orbit to Geostationary Altitude. Himawari-9 is targeting an insertion orbit of 250 by 35,976 Kilometers at an inclination of 22.4 degrees.\nSecond stage shutdown is expected just after hitting T+27 minutes with injection at an altitude of 250 Kilometers and a velocity of 10.2 Kilometers per second.\nHimawari-9 will be separated just before T+28 minutes, beginning to execute a pre-programmed sequence of establishing a stable three-axis orientation, initiate communications with ground stations and deploying its single solar array. Over the first hours and days, the spacecraft completes a series of health checks to make sure it made it into orbit in good shape. A few days into the mission, Himawari-9 will begin raising its orbit to enter Geostationary Orbit for a several months of checkouts and commissioning before being cleared for regular service.']	['<urn:uuid:4cebe17d-396a-4a31-b181-e50a7adae398>', '<urn:uuid:2461712e-d8a5-4455-a3bf-84aa3e8f8963>']	open-ended	direct	short-search-query	similar-to-document	comparison	novice	2025-05-13T06:27:57.068978	7	67	2188
25	tallow candles lighting quality characteristics	Tallow candles generated a light that was strong smelling, smoky and wavering at best.	['Evil smelling things… Anne stripped off her coat and eyed the half-gone tallow candle in the dish. I wager there’s more of pig than sheep in those candles… from THE TURNING OF ANNE MERRICK\nWe take it for granted, don’t we? It’s dark and you turn the switch. There it is – hanging from the ceiling, or maybe aimed at your work surface, or even held in your hand – odor-free, safe, brilliant light. So conditioned am I to this convenience, when a bad storm strikes, and our power goes out, I stumble about the house trying to get to my stash of emergency candles by flicking on the useless wall switches along the way.\nLiving in a well-illuminated world is a relatively new phenomenon. Though it can be hard to imagine the darkness of the 18th century world when you live in a big metropolitan and light-polluted area like Chicago, I keep lighting at the forefront of my mind as I imagine and write stories to take myself and my readers back in time. Since research in means and methods is essential in order for me to feel and write a credible historical fiction, I have been known to go out and tramp the northwoods at midnight to get a sense for the natural light cast by a waxing or waning moon, or to find out how long it really takes for our eyes to adjust to the light cast by a star-filled sky. I bought a reproduction of a pierced tin lantern and equipped it with a beeswax candle to experience for myself exactly how it might light my path on a moonless night.\nWhen “lighting” my 18th century scenes, I am limited to flame-based light — the minimal golden glow derived from hearthfire or campfire, and the more portable forms of pinepitch torches, candles, oil lamps and rush lights. It has helped me to view the works of “candlelight painters” like Carravagio, de la Tour, and van Schendel to feel this sans-electricity atmosphere.\nCandles – the go-to light for most historical fiction writers, were in reality, a very expensive commodity and used with some discretion. Candles were not generally used to illuminate a room, but more often carried from place to place to illuminate a small area. The candles of yore were nowhere near the equivalent to the even burning, scented paraffin tapers and pillars we pick up at the Bed Bath and Beyond. If you were burning a candle back in 1777, it was most likely one made from tallow with a plaited cotton wick, and even those varied in quality depending on the type of tallow used and the quality of the wick fiber. Tallow candles generated a light that was strong smelling, smoky and wavering at best. Sweet-smelling, gentle glowing beeswax candles were quite an extravagance for most Americans, and prior to the Revolution, all candles were heavily taxed, and used judiciously by even the wealthy.\nColonial Americans contributed to lighting technology when they discovered the grayish green berries of bayberry bushes produced a naturally aromatic, clean-burning wax. Both gathering the huge amount of “candleberries” necessary (15 pounds of berries for one pound of wax) and extracting the wax was a tedious process that produced few candles. For this reason bayberry candles were cherished and used for special occasions.\nNeither beeswax or tallow candles had the stability to fare very well in un-airconditioned hot weather. A summer day would cause expensive tapers to droop into uselessness. A great advance in candle technology came about in the mid 18th century with the development of the spermaceti candle. Spermaceti candles were made from the waxy substance derived from the head of a sperm whale. Stable, smokeless, clean-smelling and emitting a pure white light, spermaceti candles were also very expensive – but they cast best quality light at the time, and became the standard by which all light is measured. The terms “candlepower” and “footcandle” are based on the amount of light a spermaceti candle of a certain size produces at a distance of one foot from the flame.\nPeople who could not afford candles of any sort used “lights” made from natural materials like rushes or cattails dipped in grease, or resinous splinters of pinewood known as “fat wood” or “heartwood”. These lights were held fast in special “pinching” holders. Extremely smoky, odiferous, and short-lived, the quality of the light cast by these means was the poorest.\nOil lamps were used as a cheap way to bring light into the home. Simple “betty” or “cruisie” lamps made of iron or tin equipped with wicks of twisted cloth could be filled with fish oil or other animal fat. Imagine sewing a shirt, or knitting a stocking, or repairing your rifle to the smoky light of burning rancid pork fat.\nAny of these light sources were easily extinguished by wind or rain, or inattention. Wicks needed to be tended and trimmed to keep candles burning evenly and safely. Lamp wicks would often draw up oil quicker than it burned, causing the oil to spill over and catch fire. Wicks falling below the surface of the fat in a lamp or melted wax of a candle would sputter or gutter, and needed to be picked back out with the aid of a pickwick. It was no small thing to lose your light in the time period I write about, as the first practical friction matches would not come into being until nearer the mid-nineteenth century. By striking flint to steel and catching the spark in some dry tinder a skilled and lucky person might have a flame going in half an hour – if you were lucky!\nI know it all sounds like quite a pain, but I can’t help but find the thought of living in a nighttime world lit only by the soft glow cast by moon, stars and flame to be somehow peaceful, beautiful, and yes… quite romantic.']	['<urn:uuid:7dd59205-41ea-439f-aba4-96c0ad999d10>']	factoid	direct	short-search-query	similar-to-document	single-doc	expert	2025-05-13T06:27:57.068978	5	14	992
26	What are the limitations of optical methods for fiber inspection?	Optical methods can only inspect fiber orientation in single-layer fabrics or the uppermost layer of multi-layer stacks. They cannot see into the inner layers, which is a significant limitation because shearing and fiber orientation in the individual layers can differ considerably when compared with single-layer forming.	['Eddy current testing in CFRP production\n- 290 Downloads\nEddy current testing has established itself as a nondestructive test method in CFRP production. By exploiting the electrical conductivity of carbon fibers, it is possible to detect fiber orientation, surface weight, area density and fiber volume content as well as ripples and folds in stacks, preforms and composite components. This article presents recent applications and discusses future perspectives for deployment in CFRP production.\nForming Multi-layer Semifinished Products\nNondestructive testing of multi-layer stacks, preforms and composite components for correct fiber orientation and freedom from defects is a recurrent task in CFRP production. The shearing of textile materials that results when flat semifinished products are draped into multi-curved 3-D geometries, changes local fiber orientation and hence the rigidity of the composite components. What is more, areas with extreme shearing also increase fiber volume content and are prone to the formation of folds and dry spots that need to be eliminated through suitable process control. Fiber orientation must be known in particular for calculating rigidity and deformation.\nOptical methods allow fiber orientation to be inspected quickly and precisely for single-layer fabrics or the uppermost layer of multi-layer stacks. However, one of the major challenges in process development is that the forming behavior of multi-layer stacks such as textile sheet materials, prepregs or organic sheets is essentially different from the forming behavior of single-layer semifinished products. Owing to the complex friction and glide conditions between the individual layers, defects occur when forming stacks that are not seen when forming single-layer semifinished products. Similarly, shearing and fiber orientation in the individual layers can differ considerably when compared with single-layer forming . A lack of information about the paths of the fibers in the inner layers is therefore generally reflected in additional safety factors and hence in increased component weight and material costs.\nExploiting Electrical Conductivity\nInline and 3-D Testing\nThe difference to eddy current testing on metals is the higher testing frequency.\nAutomatic Detection of Thread Paths\nSoftware automatically reconstructs the local orientation of the individual layers.\nFigure 8 (center) shows an example of the automatic import of measured yarn directions in a finite element (FE) model for the second layer. On the right, the result of an FE simulation is depicted.\nEddy current testing is currently starting to be deployed in automotive series production, and online and offline eddy current testing systems are in use in a large number of CFRP production processes. This has led to an improved understanding of eddy current distribution in carbon-fiber materials, and will predictably result in the development of specialized sensors with greater resolution and measurement depth, adapted to the fiber structure and anisotropic conductivity of carbon fiber materials. Typical detection depths are currently between 8 and 12 carbon-fiber layers. A recent paper presented sensors that can detect small fiber waves with an amplitude of 3 mm up to the 18th layer . Another foreseeable trend will be the development of sensor arrays to speed up the testing process similar to those familiar from ultrasonic testing. A challenge that still needs to be tackled in this respect is the implementation of flexible, three-dimensional testing heads that adapt to the surface geometry in order to prevent sensor liftoff for curved component.\nThe method supplies information that was previously difficult to access.\nFurthermore, the range of detectable characteristics in CFRPs is far from being exhausted. All effects that have a direct or indirect influence on the conductivity of the fibers, or on the electrical contact between the fibers, fiber bundles and layers, could potentially be detected with eddy current testing. It has already been shown that local burns — so-called hot spots — can be detected , and also that aging and load history can be determined in the eddy current signal . At the same time, it is expected that the use of eddy current testing for process monitoring and quality assurance will further grow. The possibility of being able to detect fiber orientation and defects in the multi-layer structures of three-dimensional preforms and CFRP components in a nondestructive way provides a method that can supply information for design, process development and quality assurance that was previously difficult to access and will conceivably raise the quality of CFRP structures while continuing to reduce raw material cost.\nThe work on 3-D fiber orientation detection described here is part of the “3-D Fast” project that is funded by the European Regional Development Fund (ERDF) and the Free State of Saxony (funding code 100224749). The authors would like to thank the aforementioned institutions for the provision of financial resources. Parts of the findings represented here are based on work performed by Martin Schulze and Matthias Pooch (Fraunhofer IKTS) and Matthias Hübner and Andreas Nocke (TU Dresden), whom the authors wish to thank for kindly making them available.\n- Nezami, F. N.: Automatisiertes Preforming von Kohlefaserhalbzeugen mit aktiven Materialführungssystemen zur Herstellung komplexer Faserverbundstrukturen. (Automated preforming of carbon-fiber semifinished products with active material guidance systems for the production of complex fiber composite structures.) Dissertation, TU Dresden, Faculty of Mechanical Science and engineering, 2015Google Scholar\n- Owston, C. N.: Eddy current methods for the examination of carbon-fibre-reinforced epoxy resins. In: Materials Evaluation 34 (1976), pp. 37–244Google Scholar\n- Gäbler, S.: Untersuchung des Anwendungspotenzials der Hochfrequenzwirbelstrommesstechnik zur Charakterisierung dielektrischer Eigenschaften von Epoxidharzen und Faserverbundmaterialien. Dissertation, TU Dresden, Faculty of Electrical EngineeringGoogle Scholar']	['<urn:uuid:00e974d8-4a31-41f3-8339-de8dfd562c58>']	open-ended	direct	concise-and-natural	similar-to-document	single-doc	novice	2025-05-13T06:27:57.068978	10	46	895
27	how many pounds lamb calculate per person serving size	For generous portions, figure on one half pound of American lamb per serving.	['A Leg Up\n(Family Features) Spring celebrations wouldn’t be the same without one classic centerpiece: leg of lamb. Whether roasted or grilled, a leg of lamb is a tried and true addition to the Easter or Passover table. As elegant as it is, it’s also quite simple to prepare.\nFor a new take on tradition, swap conventional mint jelly with a vibrant salsa verde or mint-pistachio pesto for a fresh, but familiar, flavor that complements the rich taste of American lamb.\nBoneless Leg of American Lamb\nFollow these easy guidelines for preparing the perfect roast:\n- For generous portions, figure on one half pound of American lamb per serving.\n- Use a good meat thermometer to determine doneness. Medium Rare: 145°F; Medium: 160°F.\n- Remove the roast from the oven when the internal temperature reaches 10 degrees less than your desired temperature; it will reach desired doneness while it rests, allowing the meat’s juices to settle.\n- Carve the roast across the grain so the meat will be tender.\nFind more springtime celebration-worthy American lamb recipe ideas at americanlamb.com.\nRecipe: Roasted Boneless Leg of American Lamb with Fingerling Potatoes, Leeks and Mint Salsa Verde\nMint Salsa Verde\n- 3 garlic cloves, smashed and peeled\n- 2 cups loosely packed fresh flat-leaf parsley leaves\n- 1 cup loosely packed fresh mint leaves\n- 3 anchovy fillets\n- 1 tablespoon capers, drained and rinsed\n- 1/2 teaspoon kosher salt\n- 1/4 teaspoon freshly ground black pepper\n- 2 tablespoons plus 1/3 cup extra-virgin olive oil, divided\n- 3-3 1/2 pounds boneless leg of American lamb, butterflied\n- 2 1/2 teaspoons kosher salt, divided\n- 3 large leeks\n- 2 pounds fingerling potatoes, halved lengthwise\n- 1 tablespoon extra-virgin olive oil\n- Position rack in lower third of oven (so roast will be in the middle) and heat to 325°F.\n- With food processor running, add garlic cloves. When finely minced, stop motor, remove top and scrape down bowl. Add parsley, mint, anchovies, capers, salt and pepper. Pulse until ingredients are finely chopped. Pour in 2 tablespoons olive oil and pulse to combine. Transfer about two-thirds of paste to small bowl and cover with remaining olive oil. Cover tightly and refrigerate until serving time, or up to 2 days.\n- Lay lamb flat on cutting board with fat side up. Trim fat to no more than 1/8 inch. Turn meat over and trim away any large chunks of fat from interior, but leave the rest intact. Be careful not to trim away connective tissue that holds meat together. Season lamb on both sides with 2 teaspoons salt.\n- Spread salsa verde paste over interior of meat to edges, rubbing into crevices. Reserve remaining salsa verde. Roll lamb up lengthwise into cylinder. Use kitchen twine to tie cylinder at 1 1/2-inch intervals. Tie another piece of twine lengthwise to secure ends. Allow lamb to sit at room temperature 1-2 hours before roasting. (If you plan to wait more than 2 hours before roasting, loosely cover and refrigerate roast, but bring to room temperature before cooking.) Pat outside of roast dry using paper towels before roasting.\n- Trim dark green tops from leeks. Halve leeks lengthwise and rinse well. Pat dry and cut into 2-inch pieces. Put leeks and halved potatoes in large roasting pan. Drizzle vegetables with olive oil, season with remaining salt and toss to coat. Spread vegetables around roasting pan in even layer. Place lamb roast on top, seam-side down and transfer to oven. Roast until an instant-read thermometer inserted into center of meat reaches 135°F for medium-rare, about 1-1 1/2 hours.\n- Transfer lamb to cutting board and allow meat to rest for 20-30 minutes, loosely covered with foil. (The internal temperature will increase to 145°F.) Bring reserved salsa verde to room temperature. Toss vegetables in roasting pan to coat in pan drippings. If they are tender and browned, set aside in a warm spot while meat rests. If not, return to oven to finish cooking.\n- Trim away kitchen twine and cut roast into 1/2-inch-thick slices. Arrange slices over vegetables. Stir salsa verde to incorporate oil, spoon it over meat and serve.\nRecipe: Grilled Butterflied American Lamb Leg with Mint-Pistachio Pesto\n- 3 pounds boneless leg of American lamb, butterflied\n- salt and pepper (to taste)\n- 1 cup shelled pistachios\n- 1 cup fresh mint (leaves only)\n- 1/2 cup fresh Italian parsley\n- 1/4 cup plus 2 tablespoons extra-virgin olive oil\n- 2 tablespoons red wine vinegar\n- 1 tablespoon lemon juice (to taste)\n- 1 teaspoon lemon zest\n- 1/2 teaspoon sea salt (to taste)\n- freshly ground black pepper (to taste)\n- pinch red chili pepper flakes\n- Heat oven to 350°F.\n- Lay lamb leg open on a cutting board. Trim off visible fat. Season lamb generously with salt and pepper; allow to sit at room temperature for 30 minutes prior to grilling.\n- Toast pistachios by placing in single layer in shallow dish or pan and baking 8 to 10 minutes.\n- In food processor, add pistachios, mint, parsley, oil, vinegar, lemon juice, lemon zest, salt, pepper and chili flakes; blend until somewhat chunky.\n- Heat grill to medium-high. Grill lamb leg to medium-rare (remove from heat when thermometer reads between 130°F and 135°F), or to desired doneness. Rest meat, lightly covered, for at least 10 minutes before serving. Slice meat across grain into thin slices.\n- Serve lamb with pesto, grilled vegetables and salad.']	['<urn:uuid:e7b68550-6c25-4696-8d64-27993ddde8c5>']	factoid	direct	long-search-query	distant-from-document	single-doc	novice	2025-05-13T06:27:57.068978	9	13	911
28	studying visual arts and textile design compare importance of self expression creativity in both fields explain how they contribute to career opportunities	Visual arts and textile design both emphasize creativity and self-expression, though in different ways. In visual arts, creativity and self-expression are fundamental as they improve imagination, enable self-realization, and lead to better problem-solving techniques. This translates into career opportunities in photography studios, art galleries, advertising agencies, and film production. In textile design, creativity is expressed through structural aspects of fabric, using different colored yarns and varying weaving techniques to create unique designs. This creativity opens career paths in the apparel industry and fashion design, where textile design is crucial for bringing new products to market. Both fields allow professionals to work as freelancers, whether as independent artists or textile designers, and both require formal education at specialized schools to master their complexities.	"['Visual arts, as the name itself suggests, refers to multiple forms of art that can be seen by our naked eyes, hence Visual arts is a multidisciplinary concept that involves expressions through visual means and encompasses art forms like:\n- Fine arts\n- Contemporary arts\n- Applied and Decorative arts\n- Conceptual art\n- Textile art\nMany people may argue that Performing arts ( dance, music, theater, etc ) as can also be seen by our eyes, forms a part of Visual arts --- yes it does,but not directly,as there exists a difference between both:\n- Firstly, artists in Performing arts use their body ( body language, facial expressions and voice ) to deliver their art, while in Visual artists use only physical mediums like paints, ink, colors, canvas, videos, photos , etc are used for the same.\n- Secondly, in Performing arts, audience has to be present and immerse themselves while the art is performed and finished to feel the emotions and understand the message delivered by the artist(s) - while on the other hand in comparison to the Performing arts, Visual arts in order to gain its awe doesn’t demand the presence of the audience while is performed ( or made ).\nHence,Performing arts can be said to be an indirect part of Visual arts ,just because performing arts lies under the category of Fine arts i.e. carries some meaning and message with it.\nFORMS OF VISUAL ARTS:\nAny painting, printed material, videos, art films, photography, mosaics, calligraphy, drawing, graphics, conceptual art, architecture, sculpture and performing art that serves as a medium to showcase artistry and holds some message or meaning, comes into the category of Fine arts, which originated in Western Europe.\n- Conceptual art is the form of art that takes rationality of idea as its biggest priority.Surrealism and Minimalism are the best examples of conceptual visual arts,pioneered by French artist Marcel Duchamp ( France, 1887 - 1968 ) in early 20th century.Hence, in conceptual art aesthetics,technicality and cultural approach are not able to surpass the importance of a brilliant idea or imagination.Film making,videos or directory making is also a type of conceptual art as both works on a story or an idea,which is visually delivered to the audience.\n- Calligraphy refers to a very fashionable way of writing alphabets or words through a pointed pen or brush (Quill, Dip pen, Ink brush, Qalam and Fountain pen) ,to make them look more attractive and stylish.It is a very common art style that we can see in various invitation cards or in the brand names) .This art originated from Rome and then was further taken to other parts of the world.It has now following establishments:\n- Islamic (by the use of Qalam , and includes Arabic, Ottoman, and Persian calligraphy)\n- Korean,Taiwan,Vietnam and Japnese (highly influenced by Chinese Calligraphy known as Shūfǎ- which means ""the method or the way of writing.)\n- Western and\nA person has to be an adept in fine arts , to make his/her own identity in this big visual arts industry ,if yearns so.\nHence,Some of the most remarkable fine artists and their veteran fields, known since ages that can be taken as an inspiration are:\n- Leonardo Da Vinci- Italy (1452-1519)- Cartography, Symbolism and Expressionism\n- Rembrandt- Netherlands (1606-1669) - Print making and Baroque paintings\n- Wassily Kandisky - Russia (1866-1944) - Pioneer of Abstract art - Abstract art , Expressionism and Geometric abstraction.\n- Henri Matisse- France (1869-1964) - Expressionism and Fauvism\n- Piet Mondarian - Netherlands (1872-1944) - Expressionism, Cubism and Fauvism\n- Pablo Picasso - Spain (1881-1973) - Expressionism , Surrealism and Cubism.\n- Salvador Dali- Spain (1904-1989) - Surrealism and Expressionism\n- Jackson Pollock- United States (1912-1956) - Abstract Expressionism, Expressionism and Modern art\n2. Contemporary Arts:\nContemporary visual arts is what we call today\'s prevailing art.It is made by currently living artists and is known to take inspiration from nature,technology,materialistic objects,daily life activities,culture,daily problems and stress,etc.Today there are hundreds of art galleries exhibiting the work of contemporary artists, who always strive for creating something new.\nBody art, Sand paintings, Pop art, Graffiti, Decorative art and crafts, Minimalism and Three - Dimensional paintings are the latest examples of Contemporary art.\n- Body art is a very interesting visual arts form done on the human body, like making tattoos and full body painting.This art is now becoming very famous as an annual celebration and a fun game in many countries like USA and Australia, where participants paint the bodies of their partners (another participants) either related to a pre-determined theme or any design they want to.One of the most famous event of this type is, Sydney Body Art Ride, where participants forms a living rainbow that submerges into pacific ocean.\n- Minimalism is a new kind of contemporary visual arts that grabs attention by painting the materialist objects , used in daily life, hence is the simplest form of art.Sometimes minimalist artist forms a painting with a simple tea cup in between and a simple single color background. While some may say ,Minimalism is a part of modern paintings , but is still practiced by the artists all around the world, hence is an important category under Contemporary art too. (modern art and contemporary art in many cases overlaps each other).\n- Three Dimensional paintings and street art are most creative art form where artist draws or paints Three-Dimensional figures , which due to having three dimensions just looks like reality.While both of these visual arts,fills the boring premises with colors and makes the arena joyful.\n- Pop art i.e Popular art , emerged from Abstract Expressionism in 1950s in Britain.This type of visual arts is best known for vibrant use of colors, especially for advertising for large masses ,writing comic books. and pictures of celebrities.The best example of Pop art can be seen as Marilyn Diptych by Andy Warhol and Whaam! by Roy Lichtenstein .Pop art is the most loved art by kids,who loves to read comics and collect the clippings of their favorite ones.\nSome of the most famous contemporary artists in the world are:\n- Jeff Koon - United States (born 1955) - Pop art and contemporary art\n- Yayoi Kusama - Japan (born 1929) - Conceptual art, Minimalism, Feminist art, Contemporary art, and Pop art.\n- Damien Steven Hirst - United Kingdom (born 1965) - Conceptual art, Modern art, Modernism, Expressionism and Contemporary art.\n- Anish Kapoor - India (born 1954) - Contemporary art\n- Ai Weiwei - China (born 1957) - Contemporary art and Conceptual art\n- Cindy Sherman - United States (born 1954) - Photogarphy\n- Takashi Murakami - Japan (born 1962) - Pop art and contemporary art\n- Edward Joseph Ruscha IV - United States (born 1937) - Pop art, Conceptual art, Modern art, and Contemporary art.\nApplied art and Decorative art, though originated in ancient times,but is still practiced today i.e. decorating beautifully any object used everyday. Decorative visual arts with true gold and silver works has been very famous in Islamic, Jewish ,Chinese and Japanese cultures since long and were taken as matter of prestige to exchange them as gifts on the special occasions.Today,Decorative arts and crafts are generally used for interior designing and home decor and has become the best source of recycling waste materials.Jewelry designing,Pottery and Plastic art are now the most common example of this form of art.\nHence, Fashion Designing, Graphic Designing, Jewelry Designing, Interior Designing, Footwear Designing (gaining fame these days) , Industrial Design and Decorative Art are all examples of applied visual arts. As Applied art is still practiced today,it also falls under the category of Contemporary art.\nThough,both Applied art as well as Fine arts focuses on aesthetics, applied arts are further used for functional use and Fine arts are used for intellectual stimulation,hence are different.\nTextile art is a very important and old part of visual arts,i.e doing artistic work from any king of fiber.Weaving and Knitting has been done not only domestically but also for business purposes since ages.We all have wore the beautiful sweaters with cute designs made by our grandmothers or mothers,which is an art in itself.Textile art can also be said as a part of contemporary art,as is practiced by living artists also,but is so vast that is worth elaborating individually.\nYarn bombing has been the most recent form of this art in which the artist beautifies the external environment and objects.Other contemporary forms of textile art are\n- Applique (visual arts-forming a picture with an ornamental needle)\n- Bead work\n- Embroidery and\nIMPORTANCE OF VISUAL ARTS:\nVisual arts holds a very important place in not only the artist\'s life but also its audience.Visual art development in bot society as well as culture.Teaching visual arts in school,colleges and at home,enables the mental growth and enhancement in creativity and imagination of children,also leads to creative ideas to daily life problems.The importance of art can be justified by the following advantages that it holds:\n- Improves creativity and imagination\n- Enables self expression and self realization\n- Enables better self understanding\n- Encourages discipline (keeps one engaged in productive work)\n- Leads to better problem solving techniques\n- Visual arts improves analytical and observation abilities (mental health and concentration)\n- Aids in better communication (both verbal and non-verbal)\n- Documenting history and rich culture\n- Best source of entertainment\n- Recycling and use of waste materials\n- beautifies old objects (Example - The Rock Garden of Chandigarh)\n- Enhances cross-cultural understanding and appreciation\n- Grabs attention towards social issues and problems\n- Encourages team work and mutual understanding\nCAREER IN VISUAL ARTS:\nRemoving all the doubts,today visual arts has infinite number of opportunities to make a very successful career in.Today even government recruits people,adept in art.\nMajor employers for visual artists are:\n- Photography studios\n- Art galleries\n- Advertising agencies\n- Interior designing firms\n- Fashion designing firms\n- Film productions\n- Merchandising firms\nYou can even work as freelancer for visual arts (best options) like:\n- Fashion designer with your own boutique\n- Interior designer\n- Graphic designer\n- an Architect\n- an Artist ( Cartoonist, 3D artist, Graffiti, Painter, Motion artist, Layout planner, street artist, Applied artist, etc )\n- Art dealer\n- Footwear designer\n- Jewelry designer\n- Film- maker\nSo,as these all fields are very attractive and flourishing these days, each and every visual arts industry has its own complexities and hardships, which you will definitely not be able to understand unless you study them from a professional school of arts, which specializes in either of them or in all.Below is the list of some biggest visual arts schools all around the world (not on the basis of rankings):\n- Royal College of Arts -UK\n- Massachusetts Institute of Technology-US\n- California Institute of Art-us\n- Art Center College of Design-US\n- Glasgow School of Art (GSA)-UK\n- Pratt Institute-US\n- Yale University-US\nTalking in context of India,best visual arts schools are:\n- Faculty of Music & Fine Arts – University of Delhi\n- Sir J. J. Institute of Applied Art, Mumbai\n- Bharati Kala Mahavidyalaya (College of Fine Arts)\n- MS University of Baroda - Fine Arts Faculty\n- Banaras Hindu University - Faculty of Visual Arts\nFIFTEEN MOST FAMOUS QUOTES BY ARTISTS IN THE WORLD : (best of visual arts)\n- “Art washes away from the soul the dust of everyday life” by Pablo Picasso.\n- “Poor is the pupil who does not surpass his master” by Leonardo da Vinci.\n- “Creativity takes courage” by Henri Matisse.\n- “The position of the artist is humble. He is essentially a channel” by Piet Mondarian.\n- “Those who do not want to imitate anything, produce nothing"" by Salvador Dali.\n- “Have no fear of perfection, you\'ll never reach it” by Salvador Dali.\n- ""Artists don\'t make objects. Artists make mythologies"" by Anish Kapoor.\n- “Every good painter paints what he is” by Jackson Pollock.\n- “Life obliges me to do something, so I paint” by Rene Magritte.\n- “There is no must in art because art is free” by Wassily Kandinsky.\n- “Creativity is allowing yourself to make mistakes. Art is knowing which ones to keep” by Scott Adams.\n- “Every child is an artist. The problem is how to remain an artist once he grows up” by Pablo Picasso.\n- ""The world of reality has its limits; the world of imagination is boundless"" by Jean-Jacques Rousseau.\n- “If you hear a voice within you saying, ‘You are not a painter,’ then by all means paint, boy, and that voice will be silenced” by Vincent van Gogh.\n- “I want the people looking at my work to feel a sense of all the possibilities of painting, and, through that, in life as a whole. When that happens, I feel I’ve accomplished something useful” by Wolf Kahn.', 'Currently the fabric weaving method mainly depends on the textile design. Everyone nowadays wants to decorate themselves beautifully. As a result, new fashions are being taken as a challenge. In this case, textile designs have been added as a new dimension in fashion. This creates variety in the design of the garment and makes it look more attractive. People of all ages, starting from the young generation, have emphasized on the design of clothing.\nWhat is Textile Design?\nThe textile design of the fabric is usually reflected in the interlacement of warp and weft yarns when making oven fabrics. It is the reflection of textile fabrics on paper. Again different designs are also embossed on the fabric using different colors. This is basically called textile design. Everything from the exterior of a fabric to the structure and production process are also included in textile design.\nTypes of Textile Design:\nTextile designs are first printed on paper and later used in textile weaving. Textile design is divided into three branches. Those are:\n- Printed textile design\n- Woven textile design\n- Mixed media textile design\n2. Woven textile design:\nWoven textile design is the design that is done on the fabric through the yarn when weaving this fabric. This is usually done by making brackets between warp and weft yarn. It is also used in the case of the original ground pattern of the cloth.\n3. Mixed media textile design:\nIn this case, the texture of the fabric can also be seen in the sewing, block, batik and even in the weaving technique. That is to say, a combination of many designs emerges from the fabric, so it is called mixed media textile design.\nIn addition to the above categories, textile design can also be divided into two more ways. One is the fabric used in household furniture and the other is the wearable fabric.\nTextile design for home goods:\nTextile design of fabrics used in household furniture is usually simple. In this case the application of oven textile design can be seen in weaving technique. But now there are also variations in the design of the fabrics used to make the household furniture more glamorous.\nTextile design for apparel or clothing industry:\nIn addition to the fabrics used in household furniture, the application of textile design can be seen in the everyday wear of people. In this case, from woven textile design to printed and even mixed media textile design is used to decorate the garments. Any garment can be presented in a more attractive way through its texture decoration.\nImportance of Textile Design:\n- Textile designs are basically expressed in terms of the structural aspect of the fabric.\n- The designs are embellished on the fabric through the use of yarns of different colors. The use of single color yarn as well as different colored yarns creates variety in the design of the fabric. This makes the dress look more attractive.\n- Textile designs are usually fixed on the fabric. Once a design is created, it is no longer possible to change it.\n- It takes a little more time to create a textile design. Because it is done with the technique of weaving cloth.\n- Textile designs cost more than artistic designs. On the other hand, the brilliance of textile design is less than that of artistic design.\n- Textile design is an important part of the textile production process. Usually, to highlight a band, one has to look at the textile design of that band’s clothes. One costume band differs from another because of this design.\n- Both middle-aged men and women avoid more glamorous clothing. They usually focus on the design of the fabric. They prefer structural design. Nowadays the younger generation also pays more attention to textile design than decorative design.\n- In addition, in hot weather, people avoid more luxurious clothes. At this time people buy clothes based on the design of the clothes. By wearing such clothes, the person feels refreshed.\n- Creativity can also be expressed through textile designs. Clothing can be enhanced with many unique textile designs. Apart from diversifying the color of the yarn, the garment can also be designed by changing the yarn during weaving. In many cases, the combination of cotton yarn as well as silk yarn creates variation in the texture of the fabric.\nThe basic structure of a garment depends on the design. It takes clothing to a whole new level. Textile design is one of the first things that any band, starting from the apparel industry, looks for in bringing a new dress to the market. Nowadays, it is also of interest to fashion designers. Before designing any garment, one has to design with an idea on its textile design. Moreover, the dress will lose its appeal.\nAuthor of this Article:\nB.Sc. in Clothing and Textile\nGovt. College of Applied Human Science, Dhaka\nYou may also like:\n- Implementation of Decorative Design in Dress Designing\n- Top 10 Best Fashion Design Schools in the World\n- Application of CAD in Jacquard Designing\n- Role of Software and Technology in Fashion Designing\n- Classification of Dress Design in Fashion Designing\nFounder & Editor of Textile Learner. He is a Textile Consultant, Blogger & Entrepreneur. He is working as a textile consultant in several local and international companies. He is also a contributor of Wikipedia.']"	['<urn:uuid:1445a34f-a32b-440b-87f8-617ea490657f>', '<urn:uuid:617c3706-1a38-46ec-99b1-a277ef94bb00>']	open-ended	with-premise	long-search-query	similar-to-document	multi-aspect	expert	2025-05-13T06:27:57.068978	22	122	3041
29	vitamin b12 deficiency symptoms versus vitamin e deficiency symptoms nervous system	Both vitamin deficiencies affect the nervous system but in different ways. Vitamin B12 deficiency causes numbness in legs, hands, or feet, problems with walking and balance, and can lead to memory loss and hallucinations. Vitamin E deficiency causes difficulty swallowing, muscle tremors, varying degrees of paralysis, and difficulty breathing.	"['Vitamin E (tocopherol) is best known for its immune-boosting function. It serves as an antioxidant, working with selenium to eliminate free radicals. It also helps to repair damage to the body, and ensures the health of the white blood cells. Because of this important role, and its function as a structural component of various membranes, vitamin E is necessary for the function of just about every system in the body.\nThis vitamin is involved in many complex interactions with other nutrients. Its relationship with selenium has already been mentioned. Research suggests that vitamin E may also aid in the synthesis and metabolism of a number of other vitamins and minerals:\nVitamin E is one nutrient that animals cannot synthesize. Plants, however, produce vitamin E in abundance, making all green, growing forages and fresh, minimally processed grains good sources. Oils derived from grains are also high in vitamin E, provided that they are fresh.\nDogs and cats can use the vitamin E stored in the tissues of other animals. Liver and fatty meats are good sources. Raw or lightly cooked eggs are also suitable, as are nuts, wheat germ, and green vegetables.\nCauses of Deficiency\nOne common cause of vitamin E deficiency is stress, including injury, illness, and high levels of performance.\nIn grazing animals, a deficiency can be brought about by insufficient amounts of fresh forage in the diet. Sometimes this is caused by drought, while in other cases confinement is the problem.\nIn pets, particularly cats, a deficiency can be caused by high levels of unsaturated fats, including those found in tuna. Vitamin E is required to protect the body from free radical damage caused by these types of fats, so the higher the level of unsaturated fat in the diet, the higher the requirement for vitamin E will become.\nAll animals eating grain are at risk for vitamin E deficiency if their rations are not high-quality. Unfortunately, this vitamin is rather unstable and will break down quickly under less-than-ideal conditions. Factors that may cause deterioration of vitamin E in feeds include:\n- Rancid oils (unsaturated fats).\n- High temperatures.\n- Prolonged storage times.\nSymptoms of Deficiency\nUnfortunately, a vitamin E deficiency can sometimes be hard to identify because of its wide range of symptoms. Some of the symptoms that might occur include:\n- Lowered immune system.\n- Fever in cats.\n- Separation from the herd or flock.\n- Eye problems.\n- Difficulty swallowing.\n- Poor skin health.\n- Reduced wool production.\n- Increased levels of external parasites.\n- Muscle pain.\n- Muscular dystrophy (most common symptom in all species).\n- Arched back.\n- Difficulty standing.\n- Muscle tremors.\n- Varying degrees of paralysis.\n- Difficulty breathing.\n- Weak pulse.\n- Increased heart rate.\n- Cardiac arrhythmia.\n- Blue extremities.\n- Lack of appetite.\n- Metabolic disorders.\n- Severe abdominal pain in cats.\n- Lumps in fatty tissues in cats.\n- Dark urine.\n- Low fertility.\n- Retained placentas.\n- Reduced milk production.\n- Weak offspring.\n- Poor growth.\n- Sudden collapse.\nSymptoms of Toxicity\nVitamin E appears to be safe for most pets and farm animals. There are questions as to whether excessive supplementation may reduce milk production and meat tenderness, but this is not certain at the present time. The only known effect of excess vitamin E on pets and most types of livestock is exacerbation of a preexisting vitamin K deficiency.\nChickens, however, have a lower tolerance threshold for vitamin E supplementation than other types of livestock. Symptoms of toxicity include:\n- Exacerbation of preexisting vitamin K deficiency.\n- Waxy feathers.\n- Reduced pigmentation in beaks, legs, and feet.\n- Reduced growth.\nOne of the main uses of vitamin E in livestock is to prevent muscular dystrophy and sudden death in young animals.\nThe immune-boosting role of this vitamin can also be used to advantage in some cases. For instance, vitamin E is routinely used to ward off disease in stressed calves, can help laying hens cope with heat stress, and is often beneficial for pets suffering from allergies, skin problems, heart disease, and a variety of autoimmune problems. It may also help animals return to health after an illness, as well as slow the aging process.\nVitamin E may improve reproductive performance in a number of ways, as well. It is sometimes used to treat infertility in horses. In sheep, it shows potential to improve lamb weaning weights.\nStudies suggest that supplementation may increase the quality of animal-derived foods. For instance, vitamin E is known to prolong the shelf life of beef when fed to cattle before slaughter. It also appears to have a positive effect on the flavor and cheese yield of milk when given to dairy cattle.\nContent regarding medical conditions and treatment is provided for general information purposes only, and is not to be construed as legal, medical, or professional advice. Please consult your veterinarian for advice regarding your specific animal’s needs.', ""You may think nutrient deficiencies are a thing of the past, reserved for sailors trapped at sea. But even today, it’s possible to lack some of the essential nutrients your body needs to function optimally.\n“Nutrient deficiencies alter bodily functions and processes at the most basic cellular level,” says Tricia L. Psota, PhD, RDN, a lecturer at the George Washington University Milken Institute School of Public Health in Washington, DC. “These processes include water balance, enzyme function, nerve signaling, digestion, and metabolism. Resolving these deficiencies is important for optimal growth, development, and function.”\nNutrient deficiencies can also lead to diseases. “For example, calcium and vitamin D deficiencies can cause osteopenia or osteoporosis, two conditions marked by brittle bones,” says Kate Patton, a registered dietitian at the Cleveland Clinic in Ohio. “And inadequate iron can cause anemia, which zaps your energy.”\nTelltale symptoms are usually the first clue that you are low in one or more important vitamins or minerals, says Patton. Here's how to recognize seven common nutrient deficiencies.\n1. Calcium Strengthens Your Musculoskeletal System\nCalcium is important for maintaining strong bones and controlling muscle and nerve function. Signs of severely low calcium include muscle cramps and abnormal heart rhythms, Patton says. Make sure you're getting enough with at least three servings of milk or yogurt a day, she says. Other good sources of calcium are cheese, calcium-fortified orange juice, and dark leafy greens.\n2. Vitamin D Is Essential for Maintaining Strong Bones\nThis vitamin is also critical for bone health. Symptoms of a vitamin D deficiency can be vague — fatigue and muscle aches or weakness. “If it goes on long term, a vitamin D deficiency can lead to softening of the bones,” Dr. Psota says.\nTo get enough vitamin D, Patton suggests having three servings of fortified milk or yogurt daily; eating fatty fish, such as salmon or tuna, twice a week; and spending some time outside in the sunshine every day.\n3. Potassium Helps Muscles and Nerves Function Properly\nPotassium helps your heart, nerves, and muscles work properly. You could become low in potassium in the short term because of diarrhea or vomiting, excessive sweating, antibiotics or diuretics, or because of chronic conditions such as eating disorders and kidney disease, according to the U.S. National Library of Medicine. Symptoms of a deficiency include muscle weakness, constipation, tingling and numbness, and in severe cases, an abnormal heart rhythm.\nFor natural potassium sources, Psota recommends bananas, whole grains, milk, vegetables, beans, and peas.\n4. Iron Is Necessary for Oxygen-Rich Blood\nIron is necessary to produce red blood cells, which carry oxygen throughout your body. When iron levels get too low, there may be a deficiency in red blood cells, a condition called anemia. Anemia causes fatigue; pale skin; and dull, thin, sparse hair, Patton says. To boost iron levels, she recommends eating iron-fortified cereal, beef, oysters, beans (especially white beans, chickpeas, and kidney beans), lentils, and spinach.\n5. Vitamin B12 Aids in the Production of Brain Chemicals\nVitamin B12 aids the production of DNA and helps make neurotransmitters. Harvard Health Publishing says that vegans may be at particular risk for vitamin B12 deficiency because plants don't make the nutrient, as are people who've had weight loss surgery, because the procedure makes it difficult for the body to extract B12 from food. Symptoms of severe B12 deficiency include numbness in the legs, hands, or feet; problems with walking and balance; anemia; fatigue; weakness; a swollen, inflamed tongue; memory loss; paranoia; and hallucinations.\nYou can get vitamin B12 from animal sources. “Boost your levels of B12 by eating more fish, chicken, milk, and yogurt,” Patton says. If you’re vegan, opt for vegan foods fortified with B12, such as nondairy milk, meat substitutes, and breakfast cereals.\n6. Folate Is Vital for Women of Childbearing Age\nFolate, or folic acid, is a particularly important vitamin for women of childbearing age, which is why prenatal vitamins contain such a hefty dose. A folate deficiency can decrease the total number of cells and large red blood cells and cause neural tube defects in an unborn child, Psota says. Symptoms of a folate deficiency include fatigue, mouth sores, poor growth, and changes in the color of hair, skin, and nails.\nThe Institute of Medicine’s Food and Nutrition Board recommends that women who could become pregnant should make sure they get 400 mcg of folic acid daily, whether through food or a supplement. To get folate from food, go for fortified cereals, beans, lentils, and leafy greens, Psota says.\n7. Magnesium May Boost Your Energy Level\nMagnesium helps support bone health and assists in energy production. Although deficiency is fairly uncommon in otherwise healthy people, it can affect those who take certain medications, have certain health conditions, or consume too much alcohol, according to the National Institutes of Health’s Office of Dietary Supplements.\nMagnesium deficiency can cause loss of appetite, nausea and vomiting, fatigue, and weakness. In more severe cases, it can lead to numbness, muscle cramps, seizures, abnormal heart rhythms, personality changes, or low potassium or calcium levels.\nTo help your levels return to normal, eat more magnesium-rich foods, such as almonds, cashews, peanuts, spinach, black beans, and edamame, Patton says.\nFrom Nutrient Deficiency to Healthy Eating\nIf you suspect you have a nutrient deficiency, talk to your doctor. “Blood tests can help determine if you are deficient,” Patton says. And if you are, your doctor may refer you to a registered dietitian or recommend supplements.\nThe best way to avoid or remedy nutrient deficiencies is to make sure you are eating a balanced, nutrient-rich diet, Patton says. “I encourage food first, but if you are at an increased risk of a nutrient deficiency, you may benefit from taking a multivitamin,” she says. And those at risk include the elderly, smokers, those who are lactose-intolerant, and those who have recently had bariatric surgery. Make sure to check with your doctor if you have questions about your risk.""]"	['<urn:uuid:0cf2cd80-1080-43f7-b3dd-37d7c7166dd4>', '<urn:uuid:5a0e0092-07b8-42a5-bbf1-c19888443c01>']	factoid	direct	long-search-query	similar-to-document	comparison	expert	2025-05-13T06:27:57.068978	11	49	1811
30	What are the main types of specialty landscape lights used for retaining walls and outdoor staircases, and how do they differ from each other?	For retaining walls and outdoor staircases, there are two main types of specialty lights: capstone lights and wall lights. Capstone lights, also known as step lights or under cap lights, are primarily used under capstones or step units in retaining walls and hardscape structures. Wall lights can range from standard mounted house fixtures to smaller accent-type lights that mount on retaining walls or outdoor staircases.	['Welcome your evening guests by installing landscape lights. We can accent the shrubs in your landscape, glorify the architecture of your home, and light the pathway to your front door with LED landscape lights. A well-lit home can deter thieves and burglars while also impressing your neighbors. Landscape lighting creates a sense of character for your home.\nLighting Lingo and The Three Most Popular Types of Landscape Lights\nWhen we start discussing certain lighting terminology, as with many other specialty fields, things can get confusing. Let us break it down a little bit so you can better communicate what you are looking for in your nightscape:\nThe three most popular type of lights in a landscape are path lights, up lights, and well lights.\nPath lights are often also known as “spread lights.” While the purpose of path and spread lights is the same, there is a slight difference between the two. Path lights typically shine downward onto a pathway, to where as spread lights usually shine outward along a pathway. Both lights keep your path to the front door or through your garden illuminated, but spread lights tend to make things brighter.\nUp lights are often referred to as “accent lights.” We tend to use the same fixtures for up lights and accent lights. Up lights usually shine straight upwards or very close to straight up. Their purpose is usually to illuminate a tree or highlight an area of the house. Accent lights shine at more of an angle and commonly highlight hedges. Conveniently, most of today’s up lights are adjustable for accenting plants or other landscape features on your home. Therefore, we use up lights and accent lights as interchangeable terms for an above ground fixture that is held up with a stake in the ground and can shine anywhere from a 90 degree angle to straight up in the air.\nUp lights are often thought of as “well lights.” While both up lights and well lights may shine straight into the air, well lights are buried in the ground and up lights are above ground. Thus some people refer to well lights as “in-ground” lights. Well lights are quite useful for spot lighting large trees in the middle of the yard and allows a light to be recessed into the lawn for easy lawn maintenance. Since in-ground lights usually have a longer and larger distance to illuminate, they are usually a little bit brighter than up lights or path lights.\nLighting Lingo for Specialty Landscape Lighting\nA few more tips can probably help you keep everything straight when you are ready to invest in high quality, professionally installed landscape lighting systems. Other types of landscape lights would include capstone lights, wall lights, and beacon lights.\nCapstone lights are also sometimes referred to as “step lights” or “under cap” lights. These are primarily used for under capstones or step units in retaining walls and other hardscape structures. Wall lights can vary from the standard light fixture you might find mounted on your house, to a smaller accent-type of light that is mounted on your retaining wall or the walls of your outdoor staircase. Beacon lights are often called “bollard” lights and while the only real difference is the height, the purpose of both beacon and bollard lights in a landscape is to highlight the depth of large beds. These fixtures tend to be common around custom water features and some of the larger, more extensive landscapes in an attempt to illustrate the depth and distance the landscaped area covers.\nUnderstanding the names of these different light fixtures will allow you to communicate to our professionals exactly what you want in your nightscape. However, the difference in nomenclature across manufacturers can make the ordering process a bit confusing. We have found that getting to know your local manufacturers/brands of landscape lighting helps a lot with the ordering process.\nThe Three Most Common Landscape Lighting Brands in Springfield, MO and Surrounding Areas\nDifferent manufacturers call each type of light something slightly different. Some of the more popular landscape lighting brands in Springfield would be FX Luminare, Kichler, and Vista.\nFX Luminare has recently merged with one of the big three irrigation outfits in the nation, Hunter Industries. They now keep a local representative in our area to ensure the best possible customer service when we deal with product issues common to the landscape lighting industry and just the lighting industries in general. Kichler offers workshops and seminars to our employees so we can continue to improve our skills and quality of service to you. The greatest benefit of having a local representative from your landscape lighting supplier is the tips, tricks, and important information they share with us to help improve the quality and speed of initial installation and/or troubleshooting of lighting systems in a landscape. Vista tends to serve as an alternative for some lights if our customer is trying to keep on a budget.\nAll of these companies have excellent websites. We encourage our customers to browse our supplier’s websites prior to calling us for a lighting design consultation and estimate. There are many options when it comes to landscape lighting: brand of light fixtures, light fixture selection, light fixture finish, fixture placement, bulb type (incandescent, LED, etc), number of bulbs, etc. The more choices you have narrowed down, the faster we can get through a landscape lighting installation consultation and provide you with an estimate.']	['<urn:uuid:87d4429e-a010-48f0-8e7d-d10169edd264>']	factoid	direct	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-13T06:27:57.068978	24	65	908
31	Are Pietrasanta and Massa Lombarda both in Italy?	Yes, both locations are in Italy. Pietrasanta is mentioned as being between the town and municipality of Camaiore, while Massa Lombarda is specifically noted as being west of Ravenna, Italy.	"[""- Sustainable Architecture\n- Workshop The City and The Water - final exhibition\nA place with an unusual atmosphere - two lakes originating from a former quarry and kiln, one of which is now used for game fishing, and the steep, green hills of Versilia. This is the small artisan area between the town Pietrasanta and the municipality of Camaiore, where the workshop The City and The Water restoration project took place.\nThe idea of active urban reclamation started in 2012 with the arrival of a new generation of artists in the abandoned workshops. Now, thanks to the collaboration with the DESTeC i.e. Territorial Energy System Engineering and Construction Department, Pisa University, the project has reached another dimension in the form of an International Summer School which has organised an international workshop “The City and The Water, Architecture arts and self construction experiences for a new artisan area in Pietrasanta”, under the exceptional guidance of director Santiago Cigureda from the collective “Recetas Urbanas”. This Spanish architect is famous for his self-construction work which he creates and builds together with the local community in question.\nSo, in two weeks the group of seventeen students from all over the world, together with Santiago Cigureda, the professors, CAV (Pietrasanta Centre of Visual Arts) lecturers and most of all the artistic workshop “I 2 Luoghi”, who provided available rooms and materials, passed from the initial analysis to the hands-on building. A project focused on intensifying the dialogue with the citizens and encouraging them to benefit from a unique setting besides making it reusable for different activities. In fact, on the last night there was a presentation of the students' individual interventions with video clips - for the concert on the new stage and space for the firework display in the reclaimed square.\nIt is an extraordinary experience for the Italian scenario where self-building is often connected to local construction skills. In the meantime, in Pietrasanta it all started with recycling existing material in the area in order to minimise the impact on the economy and environment but also as an example within reach of all the involved communities.\nThe workshop, which we followed with Livegreenblog from the very first phases was sponsored by GranitiFiandre. We sincerely hope that the regenerative process continues and converts many so that self-building, guided by experts, can become a real cultural and social promoter for the territory, even in these times of economical tight circumstances!\nIn the coming weeks we will analyse the workshop experience from different angles (students. artisans, local administration), so stay tuned.\n“The City and The Water, Architecture arts and self construction experiences for a new artisan area in Pietrasanta”\nOrganisers: DESTeC Territorial Energy System Engineering and Construction Department, Pisa University, Pietrasanta Municipality and CAV, Pietrasanta Visual Arts Centre.\nIn collaboration with: Artistic workshop “I 2 Luoghi” and Santiago Cigureda, Recetas Urbanas (http://www.recetasurbanas.net/) and Livegreenblog\nScientific director: Santiago Cigureda\nCourse Director: Prof. Roberto Pierini\nParticipants: Baldani Martina, Benvenuti Federico, Chiofalo Eleonora, Cini Chiara, Corradi Laura, DiBugno Martina, Ferrazzino Federico, Han Zijian, Hu Dan, Leddi Anna, Martirosyan Levon, Mitidieri Guido, Nersesyan Nina, Osella Valeria, Pells Lucia, Sluter Sage, Vagli Emilio\nVisting Professor: Alessandra Capanna, La Sapienza, Roma\nTeaching Staff: Enrico Bascherini, Marco Giorgio Bevilacqua, Lucia Giorgetti, Stefania Landi, Luca Lanini, Giulia Lenziardi, Roberto Pierini, Chiara Porroni, Lorenzo Secchiari (all DESTeC)\nMedia Partner: Floornature.com\nMain Sponsor: GranitiFiandre\nImages: Courtesy of Paolo Vezzoni, Maurizio Bottazzi - zero+"", 'How might architecture aid in solving the housing crisis and help build a more sustainable future? West of Ravenna, Italy, in the small town of Massa Lombarda, Mario Cucinella Architects has completed a prototype for a home that aims to do both, by combining some of the newest technology with the oldest housing materials. The dwelling, called TECLA, is the first 3D-printed home made from clay, and its founder, Mario Cucinella, hopes that its program design can become a viable option to house people who lack adequate housing due to financial issues or displacement.\nThe twin-circular design of the TECLA prototype includes a bedroom, living room and bathroom. It is the first 3D-printed home made of clay. Credit: Iago Corazza\nBut while previous structures have been built using concrete or synthetic materials like plastic, TECLA — whose named is both derived from writer Italo Calvino’s fictional city of Thekla, and an amalgamation of “technology” and “clay” — was built from soil found at the site mixed with water, fibers from rice husks and a binder, the last of which Cucinella notes is less than 5% of the total volume. Cucinella believes this approach can be replicated in different parts of the world, using whatever local materials are available, and could be particularly helpful in underserved rural areas, where industrial construction materials may be harder to come by.\nPrinting with clay does have its drawbacks. It’s a much slower process than quick-drying concrete — the design can be printed in 200 hours but the clay mixture can take weeks to dry, depending on climate, according to Cucinella — and it also has height limitations (all-clay skyscrapers are not in the future).\nRelated video: See the first community of 3D-printed homes\nHowever, the program’s flexibility of using available soil and its ease of construction means that TECLA could be well-suited to provide housing in many different countries. In 2015, Habitat for Humanity estimated that a staggering 1.6 billion people lack adequate housing, and UN-Habitat — the United Nations program for human settlements and sustainable urban development — estimates that by 2030, 3 billion people, or 40% of the world’s population, will require access to accessible and affordable residences.\n“You can build this kind of house in many more places when you are not dependent on some specific product,” Cucinella explained in a video interview.\nTradition meets new technology\nBuilding homes from earth, Cucinella pointed out, is not new. Adobe — made from a mix of earth, water and organic material — is one of the world’s earliest construction materials, known for its durability, biodegradability and natural insulation.\n“The challenge was really using an old material in the history of architecture with new technology to find a new shape of house,” Cucinella said.\nThe project uses WASP printers to make everything from the structure of the home down to the furnishings. Credit: Iago Corazza\nTo that end, the Crane WASP printers mixed water with the local earth, and then printed the 60-square-meter (645-square-foot) TECLA prototype layer by layer, using an intricate lattice work pattern. The design features two circular spaces joined together, with skylights in each filtering light onto its textured walls. The residence includes a living area, a bedroom and bathroom. Its furnishings, including tables and chairs, can also be printed using WASP’s machinery, while components like doors and windows were installed post-printing.\nBut the idea behind TECLA isn’t necessarily to replicate the same home for any environment, but to adjust the design based on the location. “We are not producing one type of house that you can print and do it everywhere… Because, of course, it’s different if you design a house in the north of Italy, or… in the middle of Africa, or in South America,” Cucinella explained. “We adapt the house to different climates.”\nA rendering of TECLA before it was printed shows what the bedroom could look like with a family living in it. Credit: Mario Cucinella Architects\nA rendering of what a TECLA community might look like. “If we look to the past, we can tap into the knowledge of how architects were able to design buildings with no energy for many, many centuries,” Cucinella said. Credit: Mario Cucinella Architects\nCucinella claims that TECLA is low-waste since its shell is biodegradable (extra fittings like doors and windows are not) and the construction process uses far less energy than building a standard home.\n“When we talk about sustainability, I think we need to also think about the process of construction, because construction processes are very high-consuming and (make) high emissions of CO2 (carbon dioxide),” Cucinella said.\nHe believes we can learn from pre-industrial architectural design to make buildings that won’t harm the planet. “If we look to the past, we can tap into the knowledge of how architects were able to design buildings with no energy for many, many centuries,” he said.\nThe TECLA prototype is currently undergoing structural and thermal performance testing — an essential step before the project can be scaled. If it goes into production, Cucinella said he would happily live there, saying the materials evoke a sense of home and history.\n“You get the feeling of something long ago from your memory,” he said.\nTop caption: A photograph of TECLA at night.']"	['<urn:uuid:95d8f314-dd67-4af8-802b-a1cba48a08b9>', '<urn:uuid:47846e26-0d42-457e-810c-cf3498ce81ce>']	factoid	direct	concise-and-natural	similar-to-document	comparison	novice	2025-05-13T06:27:57.068978	8	30	1446
32	underwater guide roles responsibilities risk measures	A Dive Master has two primary criteria: ensuring the dive is SAFE and ENJOYABLE. Their responsibilities vary by location - in some places they oversee 40-50 divers without entering water, while in others they lead smaller groups underwater. For safety in South African conditions with poor visibility and currents, drift diving is recommended where the Dive Master descends with the group at the slowest diver's pace. Regarding risk assessment, five key steps must be followed: identifying hazards, determining who may be harmed, assessing risk levels, recording the assessment, and conducting periodic reviews. The assessment should consider both 'generic' risks that remain constant and 'specific' risks that vary with conditions.	['There was an article on page 94 of the Submerge magazine of April/May 2017 regarding “What to expect from your Dive Master”. Our trusted friend Rikki Schick brought up some valid points relevant to our diving conditions in Durban/Umkomaas Seas. This was his reply …\n“A bit of my history first. I have been diving for 60 years, am still diving, brought NAUI to South Africa in 1980 to professionalize the recreation of scuba diving, owned a dive shop and school for 20 plus years, had the first dive concession at Sodwana Bay, etc. I have seen Dive Mastering in many places around the world. There is NO hard and fast rule when it comes to Dive Mastering. It depends on the area and conditions where the dive is taking place. Having said that, the Dive Master must make sure that there are two criteria that he adheres to.\nHe must make sure that the dive is SAFE and ENJOYABLE for the divers under his control.\nIn some areas of the world the Dive Master might not even enter the water. This will happen when he has as many as 40 to 50 divers under his control off the same boat. His job is to find a safe diving site. He will tick the divers on his list when they enter the water and tick them back on board when they are on the boat. He will have some rescue divers near him for him to direct when needed. He never enters the water.\nA Dive Master who goes straight to the bottom and expects the divers to follow, as mentioned in your article, is a good system of Dive Mastering if he can control the amount of divers (usually about 10), the water has top to bottom GOOD VISIBILITY and there is NO current.\nThis form of Dive Mastering is not suitable for diving in most of the South African conditions, especially Aliwal Shoal. We have currents (drift diving) and poor visibility. My facility stopped this kind of diving in 1980. On our second dive we saw what was happening. Divers were going down head first (wrong) and losing their buddies. Some divers were getting left behind by not being able to get to the buoy because of the current.\nThe average depth on top of Aliwal Shoal is 15 meters and the average visibility is 8 meters. If a Dive Master decides to go down first, he is at 15 meters or deeper with 8 meters of visibility and does not see his divers. Is this a safe dive?\nNO, NO, NO. Rule number one broken.\nSome of the divers might be battling to get to the buoy because of the current. Is this enjoyable?\nNO, NO, NO. Rule number two broken- and the dive has hardly started.\nWhen (or if) the divers do get to the Dive Master sitting comfortably on the bottom, half their air could easily have already been consumed. It takes time, effort and money to get someone onto a scuba diving course and in one fell swoop, an uncaring, inexperienced Dive Master manages to chase away a trained diver. This person now goes on to some other sport and the dive industry loses a participant and potentially money. This has often happened. In preparing this article I have spoken to two people to whom this has happened recently.\nWe found the most comfortable and safest way to dive when there is any chance of a current, is to do a drift dive. We always did a drift dive on Aliwal Shoal, no exceptions. Never try to outswim a current. During the dive briefing, our divers were told never to go below the Dive Master. The group, including the Dive Master, went down as one. The Dive Master always descended at the rate of the slowest diver. This made for a safe and enjoyable experience for all on the dive with the Dive Master in full control of all the divers in his group.”', 'A risk assessment is an assessment of how diving and diver training activities are conducted.\nIts purpose is to evaluate whether sufficient precautions have been put in place to prevent harm befalling any of the persons taking part.\nDefinitions: ‘hazard’ – anything with the potential to cause harm, ‘risk’ – the likelihood that harm from the hazard will be realised\nThere are five steps in conducting a risk assessment\nStep 1 - Identify the hazards\nIdentify the potential hazards to the participants from the activities being carried out and from the environment in which they will be carried out. Some hazards (e.g. rapid ascent) will be common to all environments from swimming pools to hard boat dives in the open sea. Others will be very specific to the particular location or activity. Identify only significant hazards. Including those of a trivial nature only makes the process unwieldy and detracts from the identification of those that are significant.\nStep 2 - Decide who may be harmed\nAssess how many hazards will apply to all divers, whereas some will be more appropriate to particular groups such as trainees. How they will be affected is determined by identifying the ‘Maximum Severity’ to occur if subjected to that hazard\nStep 3 - Assess the risk\nThis is a matter of judging each of the hazards identified to determine whether the risk is considered to be high, medium or low. Often common sense will allow this judgement to be made directly from experience and knowledge. In other cases, a judgement can be made by considering the frequency with which the risk can be expected to occur and the ‘maximum severity’ of the consequences if it does. One way of expressing this assessment is by using the following matrix:\n|Risk Evaluation Matrix|\n|Severity >||Fatal||Major Injury||Moderate Injury||Minor Injury||Trivial Injury|\nStep 4 – Record the assessment\nFor clubs (branches) recording each assessment is essential and each assessment plan should form part of their filed and recorded RA information.\nStep 5 - Periodically review assessment\nRisks may change with time. For some risks such changes may be very infrequent, while for others they will vary with each location or occurrence. Swimming\nFor instance, risks involved in training in a swimming pool may only vary when either the type of training to be carried out is varied or the swimming pool environment itself is subject to change. Once prepared, a risk assessment for such a venue will remain valid for a considerable period.\nSheltered Water & Open Sea\nWhere diving is carried out in sheltered water or open sea conditions, some aspect relevant to the diving activities may not change, while other aspects relevant to the site conditions may change on each occasion. For such a location a risk assessment can be prepared which will cover many of the risks which remain constant, only those risks which vary (e.g. Weather, underwater visibility or specific activity dependants) needing to be addressed specifically on the day and throughout the day.\n‘Generic’ or ‘Specific’?\nRisk assessment plan\nMany risks may, therefore, be ‘generic’, that is they remain unchanged but relevant to the location. This is the content of the Risk Assessment Plan that is required by the Estate Owner.\nDive manager planning sheet\nOthers are more ‘specific’, implying that they may change depending upon the diving activity, location and water conditions. These risks can be covered by the dive planning sheet used by the Dive manager on the day. It should identify aspects that exist on the day of diving that is different from those listed in the Risk Assessment Plan.\nThe risk assessment should, however, be reviewed on each occasion and throughout the day to ensure that the risks identified are still valid. Any changes should be noted, signed and dated to show the changing situation has been assessed, that no further risks have arisen and that the appropriate controls are in place.']	['<urn:uuid:f7f9eaaa-6e8c-4ca2-acc1-48704199ed00>', '<urn:uuid:8926e84c-1910-426a-9a7e-a714ec5d7bd5>']	open-ended	direct	short-search-query	distant-from-document	multi-aspect	expert	2025-05-13T06:27:57.068978	6	109	1321
33	differences between credit reports scores which companies provide each service calculation method	Credit reports list credit history without interpretation, while credit scores are three-digit numbers calculated using formulas applied to report data. The main credit bureaus - Experian, TransUnion, and Equifax - provide credit reports, while FICO and VantageScore are the dominant companies that calculate credit scores in the U.S. These scores aim to predict likelihood of repayment. Credit reports are available free once every 12 months from each bureau through Annualcreditreport.com, but credit scores typically require payment, though some free options exist through financial institutions.	"[""In the United States, a credit score is a number based on a statistical analysis of a person's credit files, that in theory represents the creditworthiness of that person, which is the likelihood that people will pay their bills. A credit score is primarily based on credit report information, typically from one of the three major credit bureaus: Experian, TransUnion, and Equifax. Income and employment history (or lack thereof) are not considered by the major credit bureaus when calculating credit scores.\nAmericans are entitled to one free credit report in every 12-month period from each of the three credit bureaus, but are not entitled to receive a free credit score. The three credit bureaus run Annualcreditreport.com, where users can get their free credit reports. Credit scores are available as an add-on feature of the report for a fee. If the consumer disputes an item on a credit report obtained using the free system, under the Fair Credit Reporting Act (FCRA), the credit bureaus have 45 days to investigate, rather than 30 days for reports obtained otherwise.\nThe Discover it® Secured is a standout secured card that provides cardholders the opportunity to earn cash back while building credit. A cashback program is hard to find with secured cards, and the Discover it® Secured offers 2% cash back at restaurants & gas stations on up to $1,000 in combined purchases each quarter. Plus, 1% cash back on all your other purchases. In addition, there is a new cardmember offer where Discover will match ALL the cash back earned at the end of your first year, automatically. This is a great way to get a lot of rewards without needing to do any extra work.In addition to a cashback program, this card provides valuable credit resources such as free access to your FICO® Score and a Credit Resource Center — just note these services are available whether you’re a cardholder or not. Discover also takes the guesswork out of wondering when you’re ready for an unsecured card (aka a regular credit card) by performing automatic monthly account reviews, starting at eight months of card membership.\nThe system of credit reports and scores in Canada is very similar to that in the United States and India, with two of the same reporting agencies active in the country: Equifax and TransUnion. (Experian, which entered the Canadian market with the purchase of Northern Credit Bureaus in 2008, announced the closing of its Canadian operations as of April 18, 2009).\nThe Fact Act stands for the Fair and Accurate Credit Transactions Act of 2003 (FACTA). Under this act, several new provisions were set forth that amended the consumer rights law found in the Fair Credit Reporting Act of 1970 (FCRA). These amendments are a viable way to help reduce the risk of identity theft and fraud and acts as a way to help regulate all consumer financial information such as their social security numbers and other personal information.\nEspecially if you’ve had good enough credit to open an elite credit card with an excellent rewards program, it makes sense that some of your very first credit accounts are collecting dust. It might seem financially responsible to clean house financially and close some of your older or neglected credit accounts, but consider this: your oldest accounts are also your greatest and longest source of credit history. If you close them, the pool of information that dictates your credit score will shrink, making you more vulnerable to credit report dings.\nEnvironmental Variables. We and our service providers may also collect certain environmental variables, such as computer or device type (Windows or Macintosh), screen resolution, operating system version, Internet browser, wireless carrier, Wi-Fi status and Internet browser version. Many of these environmental variables are collected by most browsers, and can be used to optimize your experience on the Site.\nNo, credit reports list your credit history without interpretation. Credit scores, on the other hand, apply a formula to the data in your report to create a three-digit number predicting how likely you are to repay money as agreed. Two companies dominate credit scoring in the U.S.: FICO® and VantageScore®. NerdWallet partners with TransUnion® to provide your VantageScore® 3.0, based on information in your TransUnion® credit report. Credit score is only one factor lenders consider and they may not use the TransUnion VantageScore.\nNot all of your lenders report to all three of the credit bureaus – While some lenders do report your credit information to all three credit bureaus, this isn’t mandatory. There are almost always going to be differences in your credit history at one or more of the credit bureaus, though many will be minor and won’t affect your ability to get credit.\nChua learned about credit the hard way. He ruined his score by running up debt in college. He read up on how to fix it, went on internet forums, and eventually got his credit into good shape—then he landed a job at consumer credit firm Credit Karma. Even with all that effort, though, the big reason for his success was simple: He didn’t miss a payment for seven years. He also used at most 5 percent of his credit limit, since scores can be hurt by high “utilization rates.”\nIt depends. According to the Fair Credit Reporting Act you have the right to ask that the information on your credit reports be verified as accurate and not outdated. The credit bureaus have 30 days to complete the verification process or they must remove or change the information to coincide with your dispute. Credit repair companies may assist you in writing and that is something that you can do on your own, for free. It is sort of like cleaning your gutters or changing your oil. You can do it yourself for a fraction of the cost…the question is, do you really want to?\nCredit reporting companies must investigate the items in question — usually within 30 days — unless they consider your dispute frivolous. They also must forward all the relevant data you provide about the inaccuracy to the organization that provided the information. After the information provider receives notice of a dispute from the credit reporting company, it must investigate, review the relevant information, and report the results back to the credit reporting company. If the information provider finds the disputed information is inaccurate, it must notify all three nationwide credit reporting companies so they can correct the information in your file."", 'Should You Ever Pay for Your Credit Score?\nIt’s easier than ever to check your credit score. Your banks, credit union, credit card issuer, and a handful of online memberships sites all offer free access. However, while it generally doesn’t make sense to pay for something you can get for free, there are times when you might want to open your wallet — such as when you’re applying for a mortgage.\nTHERE ARE MANY CREDIT SCORES AVAILABLE\nTo start, it’s important to realize that there are many different credit scores. A credit score is like a grading program that looks over one of your credit reports to determine your grade, and these programs get updated over time. Currently, FICO makes dozens of scores for lenders to use when reviewing applications, and VantageScore, a major rival in the U.S., offers four different credit scores.\nFICO and VantageScore credit scores both use similar scoring criteria, create a score based on the information in one of your credit reports, and (for the most part) use a 300 to 850 score range. As a result, the scores tend to track in the same direction. For example, if your FICO Score 8 (one scoring model) is improving over time, your FICO Score 9 and VantageScore 4 could be as well.\nThe tricky part is you don’t know which scoring model the creditor will use, and which of your three credit reports (from Experian, Equifax, or TransUnion) your score will be based on. So, even if you check one of your credit scores before applying for a loan or card, the creditor might use a different score when reviewing your application.\nWHEN TO BUY A CREDIT SCORE (AND WHICH SCORES TO BUY)\nAn exception is when you apply for a mortgage. Most mortgage lenders follow Fannie Mae and Freddie Mac underwriting guidelines, which require the lender to use specific credit scoring models.\nMortgage lenders try to review three credit scores, one based on each of your credit reports, and use the middle score to determine your eligibility for a mortgage. The scores they use are:\n- FICO Score 2, also known as Experian/Fair Isaac Risk Model V2SM\n- FICO Score 5, also known as Equifax Beacon 5.0\n- FICO Score 4, also known as TransUnion FICO Risk Score, Classic 04\nBecause you know which scores most mortgage lenders will use, you might want to check your scores if you want to buy a home. However, these scores aren’t available for free.\nYou can buy them directly from FICO by visiting the MyFICO website, or you may be able to find third-party companies that include the scores. Additionally, your mortgage broker or lender may be able to check your scores, although the check might count as a hard inquiry (the type that may hurt your scores).\nHOW TO GET YOUR CREDIT SCORES FOR FREE\nYou can check and monitor several of your credit scores for free. Although these won’t be the exact scores mortgage lenders use, other types of creditors may use these scores, and they can give you a general idea of where you stand in terms of credit scoring.\nSome of these programs also include free credit monitoring, which can notify you if there’s a new account or suspicious activity on your credit report. This could be an indication that you’ve been a victim of identity theft, helping you act quickly to close the account and limit the impact.\nHere’s an overview of some of the major free sources, which credit scoring model they offer, and which credit reports the scores are based on. We’ve also limited the list to services that also include free credit monitoring, which can send you an alert if there’s a significant or suspicious change to your credit report.\n|COMPANY||SCORING MODEL||BASED ON:|\n|American Express MyCredit Guide||VantageScore 3.0||TransUnion|\n|Credit Karma||VantageScore 3.0||TransUnion and Equifax|\n|Credit Scorecard from Discover||FICO Score 8||Experian|\n|Credit Sesame||VantageScore 3.0||TransUnion|\n|CreditWise from Capital One||VantageScore 3.0||TransUnion|\n|CreditWorks Basic from Experian||FICO Score 8||Experian|\nYou can also get free credit scores from hundreds of banks, credit unions, credit card issuers, and other financial institutions through VantageScore and FICO programs. However, the scores might not come with access to your credit reports or credit monitoring.\nTHE FREE SCORES ARE USUALLY ENOUGH\nYou might want to buy access to specific credit scores while shopping for a home. But generally, the free credit scores you can get are enough to help you determine where you fall in the scoring range. Regardless, you can improve most scores by paying down credit card balances and make your monthly payments on time.']"	['<urn:uuid:0dda84bf-04d2-4dec-aa47-3d4e34402b80>', '<urn:uuid:87e12f06-3a63-4357-9822-0049ddffdc2d>']	factoid	direct	long-search-query	distant-from-document	three-doc	expert	2025-05-13T06:27:57.068978	12	84	1842
34	I'm doing research on ocean exploration tools - what new technology is being used to explore the Antarctic waters, and how might industrial activities affect the areas being studied?	The remotely operated vehicle MARUM-QUEST is being deployed for the first time in Antarctic waters to examine hot vents and cold seeps, with scientists onshore able to follow the dives in real time. However, these same areas are targets for industrial deep-sea mining operations, which plan to use systems similar to offshore oil and gas extraction to remove minerals. The United Nations has already issued 29 licenses to explore the deep sea for rare minerals, and scientists warn that such mining activities could cause irreversible damage to these marine ecosystems.	['Remotely operated vehicle MARUM-QUEST for the first time in Antarctic waters\nMARUM scientists explore hot vents and cold seeps in the Southern Ocean\nWhere the Earth’s plates meet, there is evidence of their motion. An expedition of the Research Vessel POLARSTERN will explore this activity in the Southern Ocean in detail. The major focus of the MARUM expedition is to examine hot vents and cold seeps. This will be the first deployment of the remotely operated vehicle MARUM-QUEST in the Antarctic region. The start of the expedition is scheduled for 13 April 2019.\nFor chief scientist Gerhard Bohrmann and his team it is not the first expedition to the Southern Ocean. The researchers have been studying questions relating to the circulation of fluids and gases at hot vents and cold seeps along the Sandwich Plate since 2012. With an east-west width of 350 kilometers and a north-south length of around 550 kilometers, the Sandwich Plate is a relatively small plate, but it represents the most active crustal area between the large South American and Antarctic Plates. The Sandwich Plate is formed by spreading and volcanism at the East Scotia Ridge. It is drifting toward the east, where it collides with the South American Plate. The result is a deep-sea trench extending to eight kilometers below the sea surface, and a chain of active volcanoes the South Sandwich Island Arc.\nAt the hot vents in this area, unique chemosynthetic-based ecosystems occur both on the ridge itself and on the underwater volcanoes of the South Sandwich volcanic arc. It is presumed that cold seeps will also be found here. Fluids and gases are released from both hot vents and cold seeps. The objective of the cruise is to examine these two systems in greater detail and to compare them. To help achieve this goal the remotely operated vehicle MARUM-Quest will make its first dive in the southern polar region.\nOrganisms living at the vents and seeps obtain energy from chemical compounds in the fluids released at these sites. In particular, the geographic proximity of a spreading ridge to a subduction zone in the target area raises additional interest for the expedition team. A multidisciplinary approach is being applied, involving experts from geology, geochemistry, biology, microbiology and marine biogeography. Furthermore, for the first time, scientists onshore at MARUM – the Center for Marine Environmental Sciences of the University of Bremen will be able to follow the dives during the cruise and thus be able to contribute their expertise in real time.\nIn the upcoming years, Expedition PS119 will also be included as a theme for a number of public exhibitions. Collaborative projects are already underway with the International Maritime Museum in Hamburg, the Humboldt Laboratory of the Humboldt Forum and the Lokschuppen Exhibition Center in Rosenheim.\nMARUM produces fundamental scientific knowledge about the role of the ocean and the ocean floor in the total Earth system. The dynamics of the ocean and the ocean floor significantly impact the entire Earth system through the interaction of geological, physical, biological and chemical processes. These influence both the climate and the global carbon cycle, and create unique biological systems. MARUM is committed to fundamental and unbiased research in the interests of society and the marine environment, and in accordance with the Sustainable Development Goals of the United Nations. It publishes its quality-assured scientific data and makes it publicly available. MARUM informs the public about new discoveries in the marine environment and provides practical knowledge through its dialogue with society. MARUM cooperates with commercial and industrial partners in accordance with its goal of protecting the marine environment.', 'Mining the sea floor for precious metals such as zinc and cobalt could lead to ‘irreversible’ damage to marine eco-systems, scientists warn.\nDemand for battery powered devices such as electric cars has created a drive to mine the cobalt rich seabed, say researchers from Bigelow Lab for Ocean Sciences.\nExperts at the Maine, New England research facility examined the potential impact of disruption from mining to deep sea micro-organisms and the surrounding system.\nMicrobes on the seafloor are responsible for essential ecosystem services, said Beth Orcutt, a senior researcher at Bigelow, who urged caution from mining companies.\nThey found that environments that are promising for mining are also often sites of globally important microbial processes and unusual animal communities.\nScroll down for video\nThe Mafuta diamond mining vessel, operated by Debmarine Namibia, searches for diamonds using a ‘crawler’ tractor to suck up sediment from the seabed. More mining operations for other types of minerals are expected to come online in the coming years\nOrcutt said these communities are ‘very slow to recover from disturbances’ and so said policy makers should consider the impact when issuing licences.\n‘The push for deep-sea mining has really accelerated in the last few years, and it is crucial that policy makers and the industry understand these microbes and the services they provide’.\nOne of the first companies with a licence to explore the seabed for mining opportunities is Nautilus Minerals.\nThey plan to use a version of the systems created for offshore oil and gas extraction to remove gold, silver, zinc and copper from the deep ocean.\nThe European Commission says the quantity of minerals on the ocean floor is ‘potentially large’.\nThey say any mining on the sea bed should be to ensure security of supply and fill a gap in the market where either recycling isn’t possible or the burden on land minerals is too high.\nThe commission is working on a range of studies to investigate the impact and potential of seabed mining.\nThe United Nations has issued 29 licences to explore the deep sea for rare minerals that will go on to be used in electric vehicles and other battery devices.\nSome mining operations are already in place. De Beers and the Namibian government have an operation searching for diamonds at sea using a ‘crawler’ tractor to suck up sediment from the seabed in the Atlantic Ocean.\nA 2019 Greenpeace report said unless safeguards were put in place there would be ‘severe and irreversible harm’ to the world’s oceans from mining.\n‘This greedy industry could destroy wonders of the deep ocean before we even have a chance to study them,’ said Louisa Casson from the campaign group.\nResearchers from Bigelow say the impact varies from site to site, with not all locations on the seabed as vulnerable as each other.\nTheir findings indicate that the likely impacts of mining on microbial ecosystems vary substantially, from minimal disturbance to the irreversible loss of important ecosystem processes.\nHydrothermal vent systems are likely to be the most sensitive as well as the most valuable for mining operations, according to Orcutt and her team.\nTiny crabs, tubeworms, and other sea life live next to a hot hydrothermal vent.These vents contain potentially large amounts of precious metals such as cobalt and zinc\nThe hot, mineral-rich waters support robust communities of microbes that form the vital base of the food web in these ecosystems, she explained.\n‘These microbes have incredible potential to inspire new solutions to all sorts of medical and technical challenges we face today,’ said Julie Huber, a scientist from the Woods Hole Oceanographic Institution and co-author of the new study.\n‘But if we damage or destroy a habitat like a hydrothermal vent, we lose the diverse pool of microbial genetic information from which we can find new drugs.’\nThe International Seabed Authority of the United Nations is working to establish guidelines for countries and contractors to explore the seafloor for minerals.\nThe heat and minerals expelled by the vent allow these creatures to survive without sunlight. They are important eco-systems that would be irreversibly destroyed if disrupted, say scientists\nThe team behind the study say that as well as considering how much microbial life is present at a potential mining site, as is currently in the draft guidelines, they should also look at the role microbes are playing and any impact on them from mining.\n‘It is important to understand the potential impacts of mining activities to figure out if they should occur and how to manage them if they do,’ said James Bradley, a scientist at Queen Mary University of London and co-author on the paper.\n‘This is an important conversation between policy makers, industry, and the scientific community, and it’s important that we work together to get this right.\n‘Once these ecosystems are damaged, they may never fully recover.’\nGreenpeace have called on governments to create a strong global ocean treaty to protect the underwater environments.\nThe research has been published in the journal Limnology and Oceanography Reports.\nWHAT IS SEABED MINING?\nThe number of minerals, including precious metals such as gold, zinc and cobalt buried in the seabed could be significant, say the EU.\nAs demand for electronic technologies such as electric cars and smartphones has increased, the idea of mining the seabed has become more prominent.\nIt is a complex and expensive process, but will become more lucrative as the supply of minerals from land based sources or recycling reduces.\nThere is currently a series of ‘explorations’ happening to discover the most valuable sites to mine.\nIt’s expected the most likely sites are around hydrothermal vents between 4,600ft and 12,100ft below the surface.']	['<urn:uuid:be675c35-2ce9-4f0b-8bdf-bd93a29c3e0f>', '<urn:uuid:4c55c640-de2d-4d49-98ad-1b78b71b6f14>']	factoid	with-premise	verbose-and-natural	distant-from-document	multi-aspect	novice	2025-05-13T06:27:57.068978	29	90	1543
35	I love both old clothing stories and manufacturing history. What are the differences between how Levi jeans and denim shirts became popular in American fashion?	Levi jeans and denim shirts followed different paths to popularity in American fashion. Jeans became popular through their practical use by miners during the California Gold Rush, where Levi Strauss partnered with tailor Jacob Davis to create riveted workpants that could withstand intense physical labor. These jeans later gained widespread acceptance during the Depression when they became everyday wear due to their durability and affordability. In contrast, denim shirts gained popularity through their association with cowboys in Hollywood. While both Mexican and American ranchers used denim shirts for practical purposes, it was rodeo cowboys, actors in Westerns, and visitors to Dude Ranches who transformed them into leisure wear. The first commercial denim shirts were made by Miller & Co in Denver in the 1920s, targeting film enthusiasts and recreational cowboys who wanted to dress like their silver screen heroes.	"['Physical work has a kind of tough glamor. Maybe it’s the honesty of a task whose difficulty can’t be faked or avoided. As weightlifters say, the iron doesn’t lie. Maybe it’s the self-knowledge which comes to those who master the material world in some small way. Or maybe it’s how society pays back in style—if not in money—those who shoulder the heaviest loads.\nWhatever the reasons, that glamor rubbed off on denim. Since 1870, when a small tailor in Reno made the first riveted work pants in duck canvas and blue denim, jeans have been infectiously popular. Their heavy cotton cloths won acclaim from loggers, ranchers, factory workers, and cowboys. Their connection to physical labor is clear from the early marketing of the major commercial manufacturers, Levi Strauss in California, H.D. Lee in Kansas, and the Blue Bell Overall Company in North Carolina, who would eventually trade under the name of their flagship model, the Wrangler. Each stresses how their product is hard working, robust, and practical—like their customers.\nWhile jeans have always been the primary role for denim, another iconic garment would emerge in the twentieth century: the denim shirt.\nLike jeans, the denim shirt was transformed from practical garment to cultural icon when cowboys came to Hollywood. Mexican and American ranchers favored denim cloth for its practicality, as did soldiers in the American Civil War. But it was rodeo cowboys, actors in Westerns, and visitors to Dude Ranches who created demand for denim shirts as leisure wear. The weekend warriors, recreational cowboys, and film enthusiasts didn’t have access to the Southwestern tailors used by professionals, but they still wanted to dress like them.\nIn the 1920s, Miller & Co in Denver became the first company to make denim shirts commercially. Levi’s followed suit in the following decade, and in the 1940s another Coloradan, Jack Weil, became the first to use snap fasteners rather than buttons. His business, Rockmount Ranch Wear Manufacturing Company, created the Western shirt as we know it today. Those fasteners were copied across the industry, and in 1954 another icon was born through Levi’s offering, the Sawtooth Western shirt, named for its pointed chest pocket flaps.\nCommercial Western shirts were always imitations, in the sense that they were made for people other than the professionals. By the time the open range gave way to regulated cattle grazing in most of the United States, the most famous cowboys were actually actors. The 1920s had Tom Mix, with his absurdly large hats, and endorsements for “Yankiboy play clothes” for children. Then came Gary Cooper, Clayton Moore, Clint Eastwood, John Wayne, Paul Newman and Tommy Lee Jones. More recently we have the cinematic arc from John Travolta’s Urban Cowboy to Brokeback Mountain. In Hollywood, the cowboy never died. Thanks to Hollywood, neither did their clothes.\nWhy did rough cotton work clothes come to dominate American and world fashion? One possibility is that denim tapped into a distinctly American mythology, that appealed to people far beyond its borders. By the Second World War it stood for a much larger cultural project, one that American labor was underwriting. It came to signify work which is hard and sometimes violent, but has the power to create the world anew. Think of Marlon Brando in Levi’s 501s, or Norman Rockwell’s iconic painting of Rosie the Riveter. The myth is individual and yet universal. It is the promise that anything can be achieved so long as we have energy and sweat left to give it. Like any good myth, it could mean different things to different people: its individuality and cool could be expressed in different ways by Bob Dylan, John Wayne, and Marvin Gaye.\nIn the same way, the denim shirt has been re-worked and reimagined for different places and purposes, from “heritage” revivals of workwear through to highly refined tailoring. Here are some ways to enjoy denim shirts today.\nWorkwear & Heritage\nA few years ago the New York Times asked if the blue-collar shirt was still blue collar. In one way the answer is clearly no: a blue Oxford shirt tells you nothing about a person’s profession today. But on the other hand, most mass-market workwear-inspired clothing is a softer, more domestic version of the real thing, and has little connection to practical workwear. You wouldn’t get far in a lumbermill or on a building site in H&M stretch denim.If you want the closest thing to the original, Rockmount will sell you a very classic fit denim Western shirt, as will any number of nostalgic cowboy retailers like Crazy Horse West. But if you want an original that has evolved rather than ossified, good candidates include two models from Levi’s, the Barstow (single point pockets) and Sawtooth (classic double pointed pockets), as well as models from Lee and Wrangler.\nMore sophisticated is Ralph Lauren’s RRL line of neo-Western workwear themed around the Laurens’ ranch in Colorado, the spiritual home of the Western shirt. The RRL Buffalo shirt has a modern fit but plenty of classic details. An Italian take on the same theme is the Barbanera denim Western shirt.\nFinally, like all denim products, Japanese reinterpretations of Americana can be fantastic. If you want a reinterpretation in heavy 10oz denim, look no further than Bryceland’s Japanese-made Sawtooth Westerner, or go even heavier with a 12oz model by Iron Heart.\nThe first time I remember seeing a convincing tailored look with dark denim shirting was from the Korean tailor B&Tailor. But in recent years, many more traditional and contemporary brands in the classic menswear space have turned to denim for “in-between” shirts.\nDenim brings texture, informality, and the beauty of aging. A light wash denim shirt is perhaps the easiest way to tone down a tailored look without changing the fundamental pieces. In place of a classic Oxford cloth button down, try this washed denim button down by Drake’s from their factory in Somerset; for a more minimalist dress shirt, consider the spread collar model from Natalino in soft Japanese denim. Both are made with unfused collars for a more relaxed look.\nIf you’re interested in provenance, you can’t do much better than a storied Neapolitan tailor: take a look at Rubinacci’s models, with vivid mother of pearl buttons and crow’s foot stitching. Or if you want the absolute premium option, your best choice might well be the revived luxury Italian maker Marol. Choose from a one-piece collar offering that’s almost resort wear, with silk detail stitching, or the top-end cotton/cashmere/silk denim twill model, with a generous spread collar, hand-cut and hand-stitched buttonholes.\nBespoke, Custom and Specialist\nThis is where things get interesting. The good, the bad, and the ugly, if you will. If you want to go full John Wayne cosplay, you need to visit Historical Emporium. Now that’s out of the way, anything else is possible through bespoke and MTO shirtmaking. Forum favorites Luxire and Proper Cloth both offer a range of denim options. Proper Cloth have the more interesting fabrics in my opinion (Albiate extra heavy denim, indigo corduroy, and more) but they are only available as limited runs and you have to be quick. The great advantage to Luxire is that they offer on-demand garment washing (fading the finished shirt, not the roll of cloth, giving that familiar aged look), so you can order custom denim in any tone of your choice. (This is something that most bespoke tailors can’t provide.)\nThe other option is to order your own cloth for (or through) a tailor. The best option is generally to ask your shirtmaker what he has access to, but you can also look at mills and merchants such as Acorn, Albini and Canclini. Of special note is Simon Crompton’s collaboration with Albini, “Everyday Denim”: a pale, almost-business-blue with the richness and aging of real denim, making for a very versatile and subtle shirt.\nFinally, I will repeat the advice I received from wiser men: just because you can, doesn’t mean you should. Where you draw the line is a question of your own judgment and style, but I stick to the same rule for denim shirts as I do with jeans: be very careful about pleats.\nSteven E. Weil and G. Daniel DeWeese, Western Shirts: A Classic American Fashion (Gibbs Smith, 2004)\nGraham Marsh and Paul Trynka, Denim: From Cowboys to Catwalks: a History of the World’s Most Legendary Fabric (Aurum, 2005)\nThe Wild Bunch dir. Sam Peckinpah (1969)\nUrban Cowboy dir. James Bridges (1980)\nBrokeback Mountain dir. Ang Lee (2005)\nLatest posts by Alexander Freeling (see all)\n- From Sketch to Garment: Acre and Row’s Design Process - October 30, 2020\n- Enamel Craft and Design - September 18, 2020\n- E. Gucewicz Sunglasses: Handcrafted From Home - July 7, 2020\n- Lockdown Footwear - April 29, 2020\n- Review: Dalgado Gloves - January 31, 2020', ""There are two stories to the legend behind Levi Strauss, the man responsible for the most worn garment in all the world…Levi jeans. Like all good stories, the lines between myth and fact are blurred, but the truth is simple: Everyone loves Levis.\nThe most famous jeans in the world might not have ever been, were it not for the California Gold Rush of 1849. German immigrant Levi Strauss had big plans when he headed out west with a supply of canvas, needles, thread and scissors, which he planned to sell to the miners out digging for their fortunes. But during the journey to the west, bored travelers bought Levi out of most of his supplies, leaving him with an abundance of canvas material and little else.\nEver the shrewd businessman, Levi planned to make tents for the homeless miners, but the gold diggers didn’t want tents, preferring to sleep beside their ‘diggins’ in the mud and muck. The one thing they did need was a pair of sturdy pants, as their city clothes fell apart from the constant wear and tear experienced in the abrasive business of mining. And so Levi gave the miners what they needed: strong, durable pairs of ‘waist-high’ overalls made out of canvas. And the rest is history…or is it?\nThe legend of Levi has been picked over and guessed at for over 100 years, and perhaps the truth will never be known. What we do know is that German immigrant Levi Strauss is responsible for his world-famous jeans, but maybe the story isn’t so glamorous. Maybe a fabrication just sold more jeans, or sounded better.\nUnfortunately, we will probably never know, as the Levi Strauss documentation was lost in a factory fire in 1913 when the great San Francisco earthquake nearly destroyed the heart of the West Coast metropolis. Records were lost, and according to the experts at Levi Strauss, the Gold Rush story may be pure myth. Perhaps the story is a much simpler one.\nYes, Levi did own a dry goods business, and yes, he was successful selling canvas, needles, and thread to his loyal customers. But maybe the real hero is Jacob Davis. Who? Yes, Jacob Davis was a tailor with a problem. He kept ripping the pockets of his pants, and had the ingenious idea of putting metal rivets at the stress points, the pocket corners and the button fly. Unfortunately, Davis’ idea cost $68 to patent, an amount a small businessman couldn’t afford. So he contacted one of his fabric suppliers, Levi Strauss, and partnered with him to create the best invention since sliced bread (although we think sliced bread came after, and is pretty darn good, too).\nThus, on May 20th, 1873, the world as we know it changed… and for the better. Levi Strauss was now in the business of making sturdy workpants guaranteed to withstand the most arduous strain and stress, thanks to a new-fangled invention: the metal rivet. Metal rivets were like industrial strength staples that secured the cloth with exceptional strength to withstand the most rigorous abuse put to clothes.\nBut the story doesn’t end there. Levi became famous for his riveted pants (then called workpants) made out of serge de Nimes, a sturdy twill fabric produced in France. Shorten that French phrase to ‘denim,’ and now we’re in business. In 1890, the first Levi’s 501 jeans were stitched, and the model soon became the Levi’s flagship. These tough and sturdy workpants made working life a whole lot easier, but when the Depression struck in the 40’s, Levis survived only because of mass acceptance for everyday wear.\nTimes were tough, and mothers couldn’t afford to keep their kids in clothes. Kids are hard on delicate fabrics, and pants were ripped and torn, worn and shred before the summer months were over. And so, wearing denim dungarees (still considered workpants only) was the only answer for durable pants in the time of strict fabric rationing.\nKids experienced a joy unknown to anyone who hasn’t run, crawled, rolled and splashed with reckless abandon for fear of ruining their ‘good clothes.’ Denim freed adolescents from the proper constraints of careful play when the almost-indestructible denim dungaree hit the market.\nDenim jeans and ‘teenager’ grew up together, literally. Before the baby boom prosperity of post-World War II America, youths were kids, and teens were young adults. But the disposable income teens were making during this financially abundant time didn’t need to go to put food on the table, so instead it went into music, cars, and most importantly, clothes. The teenager was born, and he wanted jeans.\nThe 50’s wouldn’t have been the same had it not been for the teenage uniform of straight-legged, cuffed hem jeans. Actors like the wild Marlon Brando and James Dean, the definitive rebel without a cause, popularized jeans for fashion’s sake, and teenagers couldn’t wait to slip into a pair of the indigo-dyed denim.\nBoys paired their straight-legged denim with tight white t-shirts, leather jackets and army boots. Girls put sloppy oversized white oxford shirts, bobby socks and saddle shoes with their jeans. Levis became the symbol of America, its freedom and its strength. Even in the turbulent 60’s and decadent 70’s, the soft cotton comfort of denim was a must for casual wear, and the back leather patch with the Levi logo meant quality and fit, guaranteed.\nVintage Levis became a big business in the 80’s when everything that could be done to a pair of jeans was—stonewashing, acid washing, painting, ripping, etc. Nostalgia turned the traditional Levis into collector’s items, but Americans weren’t the only ones nostalgic for the days of sock hops, malteds, and rock and roll. The Japanese embraced the ultimate in American culture, scooping up old denim jeans from the 50’s. But how to know what’s an old pair, and what’s a new? Before 1971, the red tag in the back pocket seam of Levis was a big, capital ‘E.’ When the classic jeans market exploded, these so-called ‘Big E’s’ became an instant status symbol, representing a genuine pair of old vintage denim.\nAnother marker of classic Levis was the akamimi, or red-line. Levis manufactured before 1986 commonly have a red-line selvage (end of material) on the inner seam. Traditionally, the straight side seam would utilize the extra space of the white-edged selvage and be incorporated in the outside leg seam. A red stitch line was apparent in the middle of the white selvage, which gave the jeans the name red-lines or akamimis, meaning ‘red ear.’ In the wake of the vintage denim revival, Levis reissued the old dark denim style…so if you’re a vintage collector, don’t get fooled by a new pair of reissues.\nDecade after decade, Levis remains a constant in quality, and a favorite for all generations. Levis don’t follow the fads…they set them with their classic shades of blue, from deep indigo to light stonewash. Denim is a friend, and Levis did it first—and, some would say, best.\nFashion Sub Categoriesgirl's apparel""]"	['<urn:uuid:9f352b38-d119-420f-9c5e-96678784d250>', '<urn:uuid:118604af-500e-4ec0-9312-25442dfb4db4>']	open-ended	with-premise	verbose-and-natural	similar-to-document	comparison	novice	2025-05-13T06:27:57.068978	25	139	2640
36	As a quality control specialist, I need to understand surface measurement methods - what factors should be considered when measuring and verifying textured surfaces in CNC manufacturing, and what impact does the blasting media hardness have on surface characteristics?	For CNC textures, proper measurement methods and specialized roughness measurement equipment are required for verification during manufacturing. The specifications must clearly define permissible variations in texture depth, roughness measurements, and pattern alignment for quality control. The hardness of blasting media significantly impacts surface characteristics - metallic blast media like chilled iron grit (MOH scale 8/9) and steel shot create different finishes, with harder media (like CI grit at 55-65 HRC) producing more aggressive texturing compared to softer options. These variations in surface finish must be carefully controlled and measured for proper quality assurance.	['Mold Textures in CNC Manufacturing(cam software Bernie)\n- source:NEWRGY CNC Machining\nWhen designing a part, the CAD model will specify the overall shape but the surface texture is an additional attribute that can be added. While some textures are the natural result of the manufacturing process, often additional steps are taken to achieve a desired look and feel. This article will examine the role of textures, different methods for achieving textures, and some of the considerations when working with textured surfaces in CNC manufacturing.\nThe Role of Texture\nTextures influence the visual appearance, feel, and performance of parts. Some examples where texture is important include:\n- Grip surfaces - A rough texture provides friction for improved grip and handling. This is important for consumer products like tools, sporting equipment, and more.\n- Appearance - Textures are added for aesthetic reasons on consumer products, architectural features, signage, etc. They influence light reflection and visual interest.\n- Function - Precision surfaces like molds and dies often require carefully controlled textures to achieve proper performance. This includes directionality to the finish.\n- Measurement and Testing - Reference surfaces with defined texture patterns are used to calibrate measurement equipment in quality control processes.\n- Identification - Marker bands and identification features sometimes rely on specific texture patterns for easy recognition.\nDue to this broad range of applications, being able to accurately and repeatably generate surface textures is very important with CNC.\nCNC Texture Methods\nThere are several techniques that can be used on CNC machinery to impart textures onto parts:\nMilling/Machining: Using traditional milling and machining, different cutters and approaches can create varied textures. Steps between passes, tool paths, stepovers, and cutter geometry all influence the final finish. Things like patterned tool paths, human artifacts, and intentional toolmarks can create identifiable textures.\nEDM: Electrical discharge machining (EDM) alters material via electrical sparks. By controlling the process parameters, surfaces with controlled roughness or patterns can be generated through the erosive effect of the sparking action.\nLaser texturing: Lasers can alter surface morphology through methods like laser etching, engraving, or texturing. The heat input causes micro-structural changes to selectively modify surface roughness. Different patterns and designs can be produced.\nMedia blasting: Blasting the surface with media like sand, glass beads, or other particulates provides a mechanical texture. Variations in media properties, blasting pressure, duration, and masking techniques allow control of the resulting finish.\nChemical texturing: Controlled chemical exposure like etching or anodizing can produce defined surface patterns as material is selectively removed or modified. This works for metals, polymers, and other materials.\nAdditive texturing: Additive techniques like 3D printing, spray coatings, or thick film layers allow physically building up texture onto a surface profile. Roughness, layer height, and droplet size of deposited material influences finish.\nRegardless of process, employing CNC allows for programmed control over all the parameters influencing the texture. This includes things like depth, roughness, directionality, pattern, gradation, and more. The automated nature of CNC machining produces consistent, repeatable results.\nDesign Considerations for CNC Textures\nThere are some important factors to consider when designing and specifying surface textures in CNC work:\n- Function – Determine what physical properties are needed from the texture for proper performance. This guides the selection of fabrication process and texture parameters.\n- Accuracy and tolerances – Specifications should clearly define permissible variations in the texture for production quality control. This includes aspects like depth, roughness measurements, and pattern alignment.\n- Measurement and inspection – Proper methods are required to verify texture during manufacturing. This may require specialized roughness measurement equipment. The means of qualification should be determined early on.\n- Process capabilities – The production method must be capable of achieving the specified texture. Alternate processes should be explored if needed.\n- Directionality – Some textures like grinding patterns rely on consistent directionality for functionality. Paths and orientation should be clearly defined.\n- Transitions – Gradual changes in the texture may be required. The exact profile of texture gradients should be specified.\n- Adjacencies – Interactions between neighboring textures may occur. Effects on the boundaries between textured areas should be considered.\n- Repeatability – Process parameters for automated CNC texturing should be well defined to allow identical reproduction of the texture on multiple products or batches.\nWith careful planning and CNC programming, almost any conceivable surface texture can be manufactured. The automated nature of computer numerical control ensures these textures are generated accurately and consistently time after time. By considering the key factors around functional needs, measurement, capabilities, and design intent, surface texturing can be readily implemented even for complex geometries. With the precision available from CNC machining, intricate textures open up new possibilities for part performance and aesthetics. CNC Milling CNC Machining', 'Abrasive blast medias\nThese metallic blast medias are of a hardness on MOH’s scale 8 / 9\nCast Chilled Iron (CI) MOH Scale 9\nChilled iron grit is produced from (alloy-free) scrap iron, that is re-smeltered in a hot blast furnace. Shot made during this process is then crushed into grit.\nChilled iron grit will shatter on impact rather than wearing round. Continuously formed new edges , combined with a high hardness, density/ mass result in fast cutting/cleaning action.\nChilled iron grit is used in blast rooms and lined (against abrasion) pressure blast cabinets with abrasive reclaim recirculation systems.\nCI grit blasting is ideal for aggressive cleaning applications.\nCI grit will quickly strip many types of surface contaminants from steel and other cast and forged metals.\nCI grit produces an etched surface on metal for a superior adhesion of paint, epoxy, enamel, rubber and other coatings.\nGrit Size and Hardness\nDepending on the size and hardness of the grit, chilled iron makes it ideal for quick stripping of hard scale oxides and keys the surfaces of most normally grades of steel.\nCI grit hardness is between 55-65 HRC and breaks down, shatters and looses its size much quicker than steel as it is very hard and brittle. After muliple use and recycles, it does not round up!\nApplication provides quick and easy scale removal from steel plate, steel profiles and fabrications. Provides for a good surface key for the adhesion of many applied coatings. Mainly used through a compressed air pressure delivery system within a blast cabinet or blast room. If used in an automated Wheel / Turbine abrasive delivery system, chilled iron grit will destroy the internal wear components at a very much increased rate, due to the hardness and density of the chilled iron grit.\nCast Steel Shot MOH Scale 8\nSteel shot blasting is very widely used for cleaning, stripping and shot peening to improve a metal surface. The grade and size of the steel shot will determine the finish achieved on the surface of the metal. The roundness and ball shape of the steel shot produces a clean, smooth and polished surface through a peening action created by the impact of the shot. In a peening application, steel shot is also used to impart a compressive strength and to stress relieve , load bearing metal components such as crankshafts, engine turbine blades and heavy-duty springs and many other.\n- its density is not less than 7gms/cc\n- there are three (3) hardness ranges available to choose from standard hardness 40 -51 Rc, Intermediate hardness 45 -52 Rc, or hardest 52 -62 Rc.\n- is close to spherically round in shape, and graded according to size\n- SAE standard sizes available range from S050 (0.18mm to S930 (3.0mm)\n- Peening grades of higher tolerance and to specification are also readily available\nSizes for different applications\nThe use of smaller steel shot will result in a smoother and more polished surface. Larger shot will clean more aggressively and produce a rougher surface on softer substrates. Both air powered and wheel blast systems can be used to accelerate the steel shot onto the surface of components. Due to the hardness and density of steel shot, it can be recycled as many as 3000 times before being replaced.\nCast Steel Grit – is angular, with sharpe cutting edges, its density is the same as shot, as not less than 7gms /cc\n- SAE standard sizes available range from G 120 (0.125 mm) to G10 (2.8mm)\n- Steel grit blasting is ideal for aggressive cleaning applications. Steel grit will quickly strip many types of surface contaminants from steel and other cast metals. Steel grit is softer than aluminum oxide and does not fracture as easily, making it ideal for so many an applications. (Sometimes even a 50 -50% mix of steel shot and steel grit work together to produce both a fast descaling process and produce the finess of the required surface profile.) Angular steel grit produces an etched surface on metal and provides addition surface area for the adhesion of paint, epoxy, enamel, rubber and other coatings.\nSteel Grit Size and Hardness\n- different chemistries will lead to different operating results depending on the size and hardness of the grit. Multiple chemistries of steel grit are available. Steel grit that is formulated as a softer (40-51 Rc) metal will round off rapidly, making it ideal for quick stripping of oxides and cleaning of moulds. Harder steel grit (54-60 Rc) will maintain the angular nature of the grit for much longer to provide continued cutting action\n- its density is not less than 7gms/cc\n- there are three (3) hardness ranges available to choose from standard hardness 40 -51 Rc, Intermediate hardness 47 -56 Rc, or hardest 54-60 Rc.\n- is multi faced and angular in shape, then graded according to size\n- SAE standard sizes available range from G50 (0.18mm to G16 (2.8mm)\nThe more commonly used medias are:\n- aluminium oxide\n- white aluminium oxide\n- urea and other plastic abrasives\n- corn cob grit\n- walnut shell grit\n- glass beads\n- crushed glass grit\n- silicon carbide\nComplete our online form at www.rosler.com\nPost written by\nShot Blasting Technical Manager']	['<urn:uuid:5e944b7d-f621-4f8b-9d8a-79f783fd5c45>', '<urn:uuid:9f1f1d0f-1945-4086-a686-7905b369d070>']	factoid	with-premise	verbose-and-natural	distant-from-document	three-doc	expert	2025-05-13T06:27:57.068978	39	93	1657
37	How do Tambora's and Pinatubo's cooling mechanisms compare?	Both volcanoes cooled through atmospheric effects - Pinatubo's aerosols blocked enough sunlight to temporarily cool the oceans and decrease sea level, while Tambora's ash and sulfur dioxide reached 27 miles high, creating a 'dry fog' that dimmed sunlight so much that sunspots were visible to the naked eye.	['As our planet heats up, the pace of sea level rise is expected to quicken, making it harder for cities like Miami to stay above water. But since 1992, scientists have studied Earth’s mean sea level via satellites, and they have watched it rise at a steady 3mm per year — no evidence for acceleration.\nThe smoking caldera of Mount Pinatubo on 22 June 1991. Image: USGS\nNow, after more than 20 years of head-scratching, we finally have an explanation: The Mt Pinatubo volcanic eruption of 1991. The largest eruption of the late 20th century, Mt Pinatubo blew its top less than two years before modern sea level record-keeping began. According to research published today in Scientific Reports, the eruption cooled the oceans enough to briefly depress global sea level, masking the expected acceleration in the record so far.\n“We got a very biased view of sea level rise, based on the happenstance timing of the launch of [the first] altimeter satellites,” lead study author John Fasullo of the US National Center for Atmospheric Research told Gizmodo.\nAccounting for Mt Pinatubo, Fasullo and his co-authors conclude that sea level rise is already escalating today, and will continue to do so in the future.\nEstimated rate of global sea level rise based on the satellite altimeter record, which began in late 1992. Image: Fasullo et al. 2016\nThere’s a finite amount of water on our planet, but it rearranges itself in all sorts of ways when the climate shifts. In warmer periods of Earth’s history, sea level gets higher, due to the combined effect of thermodynamics (hot liquids expand to occupy more space than cold liquids) and an increase in the total amount of water in the ocean as ice sheets melt. From the end of the last ice age to today, global mean sea level has risen approximately 125m.\nPerhaps the most important thing we’ve learned about sea level by studying Earth’s past is that it doesn’t rise linearly — it goes in fits and starts, accelerating dramatically as the ice sheets disintegrate. Whether the pace of modern sea level rise will start to escalate, in keeping with the pattern of the past, has enormous implications for the hundreds of millions of people living along vulnerable coastlines. Acceleration could be the difference between 60cm and 6m of sea level rise by the century’s end.\nA) Changes in the reflectivity of the atmosphere over the tropical oceans following the Mt. Pinatubo eruption (black) caused a sudden drop in global mean sea level (blue). B) Corresponding changes in ocean heat content (red) atmospheric water vapour (blue) and water storage on the global land surface (green). Image: Fasullo et al. 2016\nNow, we have our first firm evidence that the rate of sea level rise is already quickening. Analysing numerous model simulations with and without natural factors that can affect global sea level, Fasullo and his colleagues were able to pick out the signal of the Mt Pintaubu eruption, which occurred on 15 June 1991. They found that aerosols from the eruption blocked enough sunlight to temporarily cool the oceans, causing sea level to fall by about 6mm.\nBy some rotten luck, the eruption took place right before the first altimeter, the TOPEX/Poseidon satellite, was launched into orbit in late 1992. In the early days of monitoring sea level from space, Earth’s oceans were rebounding from the temporary effect of the volcano, causing the rate of sea level rise to be artificially high. “That skewed our impression of acceleration,” Fasullo said.\nAccounting for the depression and sudden rebound of sea levels due to the eruption, Fasullo and his colleagues determined that the expected warming-induced acceleration is already under way. “In the next five to 10 years, we should see a clear acceleration emerge from the record,” he said.\nFasullo was reluctant to estimate to how quickly sea level rise will accelerate, or what the total damage will be the end of the century. The Intergovernmental Panel on Climate Change estimates about 1m of sea level rise by the century’s end, while the National Oceanic and Atmospheric Administration predicts 1.2m to 2m. Other scientists have considered the possibility of rapid ice sheet disintegration and come to much higher estimates.\n“The science just isn’t there yet,” Fasullo said. “There’s a wealth of research going on, trying to quantify the contribution of ice sheet [melting] to acceleration. That’s where the main uncertainty lies.”', 'If you think that spring has been slow to arrive, just imagine what it was like during the summer of 1816, known as “The Year Without A Summer.” The root cause of the winter-like weather was a volcanic eruption that took place 200 years ago this month.\nMount Tambora, a 9,500-foot volcanic mountain in Indonesia, had been dormant for hundreds of years before slowly rumbling to life in 1812. This culminated in a series of massive explosive eruptions that took place between April 5 and 11.\nThe volcano’s biggest explosion on April 10 is believed to be the largest single explosion in recorded history, heard more than 1,600 miles away and producing tsunamis as large as 13 feet. All vegetation on Sumbawa, the island that Tambora sits on, was destroyed, and an estimated 4,600 people were killed as a result of the eruption, with as many as 50,000 people dying from hunger and disease in the following year.\nThe impacts of Mount Tambora’s eruption would be felt worldwide. The ash and sulfur dioxide eruption column reached as high as 27 miles above the surface, allowing the particles to travel around the world. As a result, weather conditions were highly unusual over the next year or so.\nThe ash caused a “dry fog” for most of the summer of 1815, producing brilliant sunrises and sunsets but also dimmed the sunlight to the extent that sunspots could be seen with the naked eye. Conditions got even worse in 1816. With dimmed sunlight, colder temperatures became the norm. A frost killed most crops across upstate New York and northern New England. Then, on June 6, snow fell in Albany, N.Y., and as much as a foot of snow accumulated in Quebec City, Canada.\nWhere Did Summer Go?\nThe summer wasn’t completely missing. In fact, short periods of temperatures in the 80s and 90s were reported in July and August, as would be normal for that time of year. However, it was often followed by dramatic temperature swings dropping temperatures near or even below freezing. It was so cold that river and lake ice was reported in parts of northern Pennsylvania! Thanks to an ongoing series of frosts, the 1816 harvest was a complete failure, causing corn and grain prices to jump by 8 to 10 times.\nConditions were no better in the rest of the world. Harvests failed across Europe, causing the century’s worst famine in Great Britain and Germany. Major storms wreaked havoc on Europe, causing severe flooding on many of the continent’s rivers. Overall, an estimated 200,000 people were killed between the famine and floods. In China, the summer rice crop failed thanks to freezes and snow was reported as far south as Taiwan. In all, it is estimated that average surface temperatures dropped by at least 2 degrees worldwide.\nThe cultural impact of Tambora’s eruption wasn’t all bad. Americans set out toward the Mississippi Valley in search of richer soil, settling across the Heartland. Likewise, the crop failure meant that there weren’t enough oats for the horses, causing German inventor Karl Drais to create horseless transportation with the precursor to the bicycle.\nPerhaps the most interesting cultural gift provided by that cold, wet summer came to us from Europe. Writers Mary Shelley, John William Polidori and Lord Byron were forced to remain indoors that summer due to “incessant rainfall,” having a contest to see who could write the scariest story. Polidori wrote The Vampyre, the first short story about vampires, and believed to be one of the inspirations for Bram Stoker’s Dracula. Perhaps you’ve heard of the story written by Mary Shelley, Frankenstein; or, The Modern Prometheus?\nAsh concentrations slowly diminished during the next few years, with unusual weather patterns lasting into the early 1820s. While no volcanic eruption has reached Tambora’s magnitude since, Krakatoa in 1883 and Pinatubo in 1991, both caused substantial temperature drops a year later across the Northern Hemisphere.\nWe want to thank WeatherBug Meteorologist Andrew Rosenthal for researching and writing this article!']	['<urn:uuid:a443db77-b57b-43a4-948e-fcb908fe20bc>', '<urn:uuid:4e27b5da-bf76-473f-b535-badc786fbace>']	factoid	with-premise	concise-and-natural	distant-from-document	comparison	expert	2025-05-13T06:27:57.068978	8	48	1404
38	What are the dates when commercial and recreational anglers are not allowed to fish for Atlantic grouper species, and which specific types of grouper does this restriction apply to?	Several Atlantic grouper species are closed to fishing from January 1 to April 30 in all state and federal waters of the Atlantic, including all state waters off Monroe County (Atlantic and Gulf sides). This closure applies to red, black, yellowfin, yellowmouth, scamp, rock hind, red hind, coney, graysby and tiger grouper.	"[""Boundary Maps and Management Zones\nFlorida state waters are from shore to 3 nautical miles on the Atlantic and from shore to 9 nautical miles on the Gulf. In most places, federal waters extend from where state waters end out to about 200 nautical miles or to where other country's waters begin.\nThe maps below detail important fishing boundaries and management zones.\nState and federal regulations require all commercial fishers and recreational anglers fishing for any reef fish species to have and use certain gear. In state waters, reef fish species include groupers, snappers, amberjacks, gray triggerfish, red porgy, sea bass, hogfish and tilefish. Learn more.\nSeveral species of Atlantic grouper (red, black, yellowfin, yellowmouth, scamp, rock hind, red hind, coney, graysby and tiger) are closed Jan. 1 - April 30 in all state and federal waters of the Atlantic including all state waters off Monroe County (Atlantic and Gulf sides). During this closure, anglers can harvest grouper in open federal waters of the Gulf and return to port in Monroe County by traveling through closed state waters of the Gulf as long as the vessel proceeds directly to port without stopping to fish.\nSt. Joseph Bay and Gulf County: Aug. 16-Sept. 24. This region includes all state waters from the Mexico Beach Canal in Bay County to the westernmost point of St. Vincent Island in Franklin County.\nFranklin County through northwestern Taylor County (including Carrabelle, Lanark and St. Marks): July 1 through Sept. 24. This region includes all state waters from the westernmost point of St. Vincent Island in Franklin County to Rock Island near the mouth of the Fenholloway River in Taylor County.\nFenholloway through Suwannee Rivers Zone (including Keaton Beach and the Steinhatchee area): June 15 through Labor Day. This region includes all state waters east of Rock Island near the mouth of the Fenholloway River in Taylor County and north of Alligator Pass daybeacon #4 near the mouth of the Suwannee River in Levy County. This area has a lowered bag limit June 15-30. See bag limit section for more.\nLevy, Citrus and Hernando counties (including Cedar Key, Crystal River and Homosassa): July 1 through Sept. 24. This region includes all state waters south of Alligator Pass daybeacon #4 near the mouth of the Suwannee River in Levy County and north of the Hernando – Pasco county line.\n- Please do not discard scallop shells in inshore waters commonly used for recreational activities such as the Homosassa River or Crystal River. Piles of discarded scallop shells can create hazards for swimmers and damage seagrass habitat. Scallop shells can be discarded in a trash receptacle or in larger bodies of water where they are more likely to disperse.\nPasco County: Opens third Friday in July and continues 10 days. This region includes all state waters south of the Hernando – Pasco county line and north of the Anclote Key Lighthouse in northern Pinellas County, and includes all waters of the Anclote River.\nIn an effort to identify and retrieve lost and abandoned blue crab traps, the FWC has established regional blue crab trap closures. These six regional closures last up to 10 days and prohibit recreational and commercial harvest of blue crabs with traps in these areas. The closures alternate coasts every year with closures on the east coast of Florida occurring during the even numbered years and closures on the west coast occurring on the odd years.\nEven Year Closures\n- All waters of the St. Johns River system its associated lakes and tributaries from west of the St. Johns River's intersection with the Intercoastal Canal through and including Lake Helen of Blazes from Jan. 16-25\n- All waters from the Georgia/Florida state line, excluding the St. Johns River system, south through Volusia County from Aug. 20-29\n- All waters of Brevard through Palm Beach counties, excluding the St. Johns River system, from Aug. 10-19\nOdd Year Closures\n- All waters of Franklin County to the Florida/Alabama state line however, excluding all waters of the Ochlockonee River and Bay, from Jan. 5-14\n- All waters of Broward through Pasco Counties from July 10-19\n- All waters of Hernando through Wakulla counties including all waters of the Ochlockonee River and Bay from July 20-29\nGag grouper is open in the Gulf state waters June 1-Dec. 31 (excluding Franklin, Wakulla, Taylor, Jefferson and Monroe counties); April 1 - June 30 and Sept. 1 - Dec. 31 in state waters off of Franklin, Wakulla, Taylor and Jefferson counties; and May 1-Dec. 31 in Atlantic state and federal waters.\nLearn more about permit regulations within the Special Permit Zone.\nThe Special Permit Zone includes state and federal waters south of Cape Florida in the Atlantic and south of Cape Sable in the Gulf.\nLearn more about red drum regulations.\nRed drum management zones:\n- Northwest: Escambia through Fred Howard Park Causeway near Pasco County\n- South: Fred Howard Park Causeway through Monroe County (west coast) and Miami-Dade through Volusia counties (east coast)\n- Northeast: Flagler through Nassau counties\nLearn more about spotted seatrout regulations.\nState and federal waters off Florida\n- Western Panhandle: Escambia County through the portions of Gulf County west of longitude 85 degrees, 13.76 minutes but NOT including Indian Pass/Indian Lagoon.\n- Big Bend: Remaining portion of Gulf County plus Indian Lagoon, and Franklin County through Fred Howard Park Causeway in Pinellas County near the Pasco County line.\n- South: Fred Howard Park Causeway in Pinellas County near the Pasco County line through Broward County.\n- Central East: Palm Beach through Volusia counties.\n- Northeast: Flagler through Nassau counties.\nThe Weakfish Management Zone includes state waters from the Florida-Georgia line to the southernmost tip of Amelia Island, the inland waters of Nassau County and the St. Marys River and its tributaries east of Highway 17, north of State Highway 200A and north of the Shave Bridge on the Amelia River.""]"	['<urn:uuid:b65ec54b-205d-4001-a49f-9b36159c3a26>']	open-ended	direct	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-13T06:27:57.068978	29	52	983
39	I work in IT and need to understand data networks better. What is the purpose of backbone cables in network infrastructure, and what security risks do they face from attackers?	Backbone cables are essential connections between telecommunications closets, floor terminals, and equipment rooms within or between buildings. They service both voice and data communications, interconnecting hubs in star-topology networks or serving as the bus cable in bus topology networks. They're also known as riser, vertical, or trunk cables. Regarding security risks, these critical infrastructure components can be targeted in denial-of-service (DoS) attacks, particularly bandwidth flooding attacks where attackers send massive amounts of traffic to clog access links. Additionally, in wired broadcast environments, backbone cables can be vulnerable to packet sniffing, where attackers can capture and record sensitive data being transmitted through the network.	['A cable connection between telecommunications or wiring closets, floor distribution terminals, entrance facilities, and equipment rooms either within or between buildings. This cable can service voice communications or data communications. In star-topology data networks, the backbone cable interconnects hubs and similar devices, as opposed to cables running between hub and station. In a bus topology data network, it is the bus cable. Backbone is also called riser cable, vertical cable, or trunk cable.\nHits - 1613\nThe physical/electrical interconnections between telecommunications rooms and equipment rooms. See also backbone.\nHits - 1282\nUsually a very small portion of an overall optical signal, backscatter occurs when a portion of scattered light returns to the input end of the fiber; the scattering of light in the direction opposite to its original propagation. Light that propagates back toward the transmitter. Also known as back reflection or backscattering.\nHits - 941\nThe mold or form on which silicon dioxide soot is deposited to create the optical fiber preform.\nHits - 940\nAn indication of signal voltage equality and phase polarity on a conductor pair. Perfect balance occurs when the signals across a twisted-pair cable are equal in magnitude and opposite in phase with respect to ground.\nHits - 936\nA cable that has pairs made up of two identical conductors that carry voltages of opposite polarities and equal magnitude with respect to ground. The conductors are twisted to maintain balance over a distance.\nHits - 957\nA coupler whose output has balanced splits; for example, one by two is 50/50, or one by four is 25/25/25/25.\nHits - 905\n|Balanced signal transmission||\nTwo voltages, commonly referred to as tip and ring, equal and opposite in phase with respect to each other across the conductors of a twisted-pair cable.\nHits - 825\nA device that is generally used to connect balanced twisted-pair cabling with unbalanced coaxial cabling. The balun is an impedance-matching transformer that converts the impedance of one transmission media to the impedance of another transmission media. For example, a balun would be required to connect 100 ohm UTP to 120 ohm STP. Balun is short for balanced/unbalanced.\nHits - 995\nA range of wavelengths over which a component will meet specifications.\nHits - 883\nIndicates the transmission capacity of media. For copper cables, bandwidth is defined using signal frequency and specified in hertz (Hz). For optical fiber, wavelength in nanometers (nm) defines bandwidth. Also refers to the amount of data that can be sent through a given channel and is measured in bits per second.\nHits - 1037\nSystems can be limited by power output or bandwidth; bandwidth-limited operation is condition when the total system bandwidth is the limiting factor (as opposed to signal amplitude).\nHits - 849\nA layer of glass deposited on the optical core to prevent diffusion of impurities into the core.\nHits - 870\nA method of communication in which the entire bandwidth of the transmission medium is used to transmit a single digital signal. The signal is driven directly onto the transmission medium without modulation of any kind. Baseband uses the entire bandwidth of the carrier, whereas broadband only uses part of the bandwidth. Baseband is simpler, cheaper, and less sophisticated than broadband.\nHits - 903\n|Basic rate interface (BRI)||\nAs defined by ISDN, consists of two 64Kbps B-channels used for data and one 16Kbps D-channel (used primarily for signaling). Thus, a basic rate user can have up to 128Kbps service.\nHits - 772', 'Types of Network Attacks\nThe internet has become mission critical for many institutions today, including large and small companies, universities, and government agencies. Many individuals also rely on the internet for many of their professional, social, and personal activities. But behind all this utility and excitement, there is a dark side, a side where “bad guys” attempt to wreak havoc in our daily lives by damaging our internet-connected computers, violating our privacy, and rendering inoperable the internet services on which we depend.\nThe field of network security is about how the bad guys can attack computer networks and about how we, soon-to-be experts in computer networking, can defend networks against those attacks, or better yet, design new architectures that are immune to such attacks in the first place. Given the frequency and variety of existing attacks as well as the threat of new and more destructive future attacks, network security has become a central topic in the field of computer networking. One of the features of this course is that it brings network security issues to the forefront.\nSince we don’t yet have expertise in computer networking and internet protocols, we’ll begin here by surveying some of today’s more prevalent security related problems. This will whet our appetite for more substantial discussions in the upcoming modules. So we begin here by simply asking, what can go wrong? How are computer networks vulnerable? What are some of the more prevalent types of attacks today?\nInjecting Malware Into Your Host Through The Internet\nWe attach devices to the internet because we want to receive/send data from/to the internet. This includes all kinds of good stuff, including web pages, e-mail messages, MP3s, telephone calls, live video, search engine results, and so on. But, unfortunately, along with all the good stuff comes malicious stuff-collectively known as malware – that can also enter and infect our devices. Once malware infects our device it can do all kinds of devious things, including deleting our files; installing spyware that collectors our private information, such as social security numbers, passwords, and keystrokes, and then sends this (over the internet of course!) back to the bad guys. Our compromised host may also be enrolled in a network of thousands of similarly compromised devices, collectively known as a botnet , which the bad guys control and leverage for spam e-mail distribution or distributed denial-of-service attacks against targeted hosts.\nMuch of the malware out there today is self-replicating : once it infects one host, from that host it seeks entry into other hosts over the internet , and from the newly infected hosts, it seeks entry into yet more hosts. In this manner, self-replicating malware can spread exponentially fast. Malware can spread in the form of a virus or a worm. Viruses are malware that require some form of user interaction to infect the user’s device. This classic example is an e-mail attachment containing malicious executable code. If a user receivers and opens such an attachment , the user inadvertently runs the malware on the device. Typically, such e-mail viruses are self-replicating : once executed, the virus may send an identical message with an identical malicious attachment to, for example, every recipient in the user’s address book. Worms are malware that can enter a device without any explicit user interaction. For example, a user may be running a vulnerable network application to which an attacker can send malware. In some cases, without any user interaction, the application may accept the malware from the internet and run it creating a worm. The worm in the newly infected device then scans the internet, searching for other hosts running the same vulnerable network application. When it finds other vulnerable hosts, it sends a copy of itself to those hosts. Today, malware, is pervasive and costly to defend against. As you work through this course, we encourage you to think about the following questions: What can computer network designers do to defend internet-attached devices from malware attacks?\nAttacking Servers and Network Infrastructure\nAnother broad class of security threats are known as denial-of-service (DoS) attacks. As the name suggest, a DoS attack renders a network, host, or other piece of infrastructure unusable by legitimate users. Web servers, e-mail servers, DNS servers and institutional networks can all be subjected to DoS attacks. Internet DoS attacks are extremely common, with thousands of DoS attacks occurring every year. Most internet DoS attacks fall into one of three categories:\n- Vulnerability attack : This involves sending a few well-crafted messages to a vulnerable application or operating system running on a targeted host. If the right sequence of packets is sent to a vulnerable application or operating system, the service can stop or worse, the host can crash.\n- Bandwidth flooding : The attacker sends a deluge of packets to the targeted host – so many packets that the target’s access link becomes clogged preventing legitimate packets from reaching the server.\n- Connection flooding : The attacker establishes a large number of half-open or fully open TCP connections at the target host. The host can become so bogged down with these bogus connections that it stops accepting legitimate connections.\nLet’s now explore the bandwidth-flooding attack in more detail. Recalling our delay and loss analysis discussion in section 1.4.2, it’s evident that if the server has an access rate of R bps, then the attacker will need to send traffic at a rate of approximately R bps to cause damage. If R is very large, a single attack source may not be able to generate enough traffic to harm the server. Furthermore, if all the traffic emanates from a single source, an upstream router may be able to detect the attack and block all traffic from that source before the traffic gets near the server. In a distributed DoS (DDoS) attack, illustrated in figure 1.25, the attacker controls multiple sources and has each source blast traffic at the target. With this approach, the aggregate traffic rate across all the controlled sources needs to be approximately R to cripple the service. DDoS attacks leveraging botnets with thousands of compromised hosts are a common occurrence today. DDoS attacks are much harder to detect and defend against than a DoS attack from a single host.\nWe encourage you to consider the following question as you work your way through the course: what can computer network designers do to defend against DoS attacks? We will see that different defences are needed for the three types of DoS attacks.\nMany users today access the internet via wireless devices, such as WiFi-connected laptops or handheld devices with cellular internet connections. While ubiquitous internet access is extremely convenient and enables marvellous new applications for mobile users, it also create a major security vulnerability – by placing a passive receiver in the vicinity of the wireless transmitter, that receiver can obtain a copy of every packet that is transmitted! These packets can contain all kinds of sensitive information, including passwords, social security numbers, trade secrets, and private personal messages. A passive receiver that records a copy of every packet that flies by is called a packet sniffer .\nSniffers can be deployed in wired environments as well. In wired broadcast environments, as in many Ethernet LANs, a packet sniffer can obtain copies of broadcast packets sent over the LAN. As described in section 1.2, cable access technologies also broadcast packets and are thus vulnerable to sniffing. Furthermore, a bad guy who gains access to an institution’s access router or access link to the internet may be able to plant a sniffer that makes a cop of every packet going to/from the organization. Sniffed packets can then be analysed offline for sensitive information\nPacket-sniffing software is freely available at various web sites and as commercial products. Professors teaching a networking course have been known to assign lab exercises that involve writing a packet-sniffing and application-layer data reconstruction program.\nBecause packet sniffers are passive – that is, they do not inject packets into the channel – they are difficult to detect. So, when we send packets into a wireless channel, we must accept the possibility that some bad guy may be recording copies of our packets. As you may have guessed, some of the best defences against packet sniffing involve cryptography.\nMasquerading as Someone You Trust\nIt is surprisingly easy (you will have the knowledge to do so shortly as you proceed through this article) to create a packet with an arbitrary source address, packet content, and destination address and then transmit this hand-crafted packet into the internet, which will dutifully forward the packet to its destination. Imagine the unsuspecting receiver (say an internet router) who receives such a packet, takes the (false) source address as being truthful, and then performs some command embedded in the packet’s contents (say modifies its forwarding table). The ability to inject packets into the internet with a false source address is known as IP spoofing, and is but one of many ways in which one user can masquerade as another user.\nTo solve this problem, we will need end-point authentication, that is, mechanism that will allow us to determine with certainty if a message originates from where we think it does. Once again, we encourage you to think about how this can be done for network applications and protocols as you progress through the modules in this course.\nIn closing this section it’s worth considering how the internet got to be such an insecure place in the first place. The answer, in essence, is that the internet was originally designed to be that way, based on the model of “a group of mutually trusting users attached to a transparent network”- a model in which there is no need for security. Many aspects of this original internet architecture deeply reflect this notion of mutual trust. For example, the ability of one user to send a packet to any other user is the default rather than a request/granted capability, and user identity is taken at declared face value, rather than being authenticated by default.\nBut today’s internet certainly does not involve “mutually trusting users.” Nonetheless, today’s users still need to communicate when they don’t necessarily trust each other, may wish to communicate anonymously, may communicate indirectly through third parties and may distrust the hardware, software, and even the air through which they communicate. We now have many security-related challenges before us as we progress through this course: We should seek defences against sniffing, end-point masquerading, man-in-the-middle attacks, DDoS attacks, malware, and more. We should keep in mind that communication among mutually trusted users is the exception rather than the rule. Welcome to the world of modern computer networking!']	['<urn:uuid:ef76f1c6-4dd1-4375-bf16-0762104cd5a3>', '<urn:uuid:4546cf17-ce40-46e0-a8cd-c408af324893>']	open-ended	with-premise	verbose-and-natural	distant-from-document	multi-aspect	novice	2025-05-13T06:27:57.068978	30	103	2355
40	What considerations go into choosing package delivery times and carriers for shipping orders, and how do these choices affect the final shipping costs?	When choosing delivery times and carriers, several factors impact costs. Earlier deliveries are typically most expensive with minimal discount opportunities, while selecting later timing services may result in the same actual delivery time at a better rate. The main carriers to consider are UPS and FedEx, though their gross rates differ so net pricing and discounts need careful comparison. Additionally, package measurements affect costs through dimensional weight calculations - packages over 5184 cubic inches are billed at dimensional weight or actual weight, whichever is greater. Companies should also consider additional charges like weekend delivery fees and commercial versus residential delivery charges. Understanding these variables helps optimize shipping costs through better carrier selection and delivery timing choices.	['Everyone knows that improper packaging can lead to damaged product, which in turn can lead to returns, wasted shipping expense and customer dissatisfaction. In a worst-case scenario, improper packaging can prevent customers from buying again and generate negative word-of-mouth.\nSo maybe it’s time to give your packaging a little more thought and emphasis. Here are some tips that will help you achieve proper packaging:\nPackaging should fit the product as closely as possible, allowing for as little use of dunnage as possible. Not that you should skimp on dunnage — if the packaged product has room to move it could suffer damage as a result. And dunnage is required to prevent any damage to fragile or high cost items.\nIf you need custom packaging for irregular or high priced goods, many vendors will test your packaging to ensure that it will survive transportation to your customers, and arrive undamaged. Some shipping vendors also will certify your packaging, allowing you to submit claims for transportation damage pertaining to the certified packaging.\nPackaging affects your shipping costs by adding weight to orders. The weight difference between using a double walled carton vs. a single walled carton with foam or air filled dunnage can be significant. Depending on your shipping rates, carton and dunnage selection could affect your cost by $0.20 to $0.50 per package.\nIf you are shipping through the U.S. Postal Service or a postal consolidator, be aware of additional charges that may be added to nonmachinable and balloon packaging. Some examples of nonmachinable packages include mailing tubes, packages weighing more than 35 lbs, packages with a height or width greater than 17″, or length greater than 34″. The balloon rate applies to packages weighing less than 15 lbs. and having a length plus girth of more than 84″, but not greater than 108″.\nDimensional weight factors also have continued to change. Instead of offering a range of oversized cartons at a set rate, small package vendors have gone to the usage of true dimensional weight calculations to arrive at billing rates.\nFor instance, if the measurements of a package (L x W x H) are greater than 5184 cubic inches (12″ x 12″ x 36″), the package will be billed at the dimensional weight (L x W x H/194) or the actual weight, whichever is greater. Packages less than 5184 cubic inches are billed at their actual weight. The dimensional calculation for international packages is L x W x H/166.\nAgain, different packaging combinations may allow large, lightweight items to ship at a rate closer to their actual weight. The dimensional difference between a 12” x 12” x 12” carton and a 13” x 13” x 13” carton is about 2.5 lbs.\nBecause shipping vendors bill according to a scale that rounds up to the next full pound rate (a 3.2 lb package is billed at the 4-lb. rate, for example), you do not have to make large changes to affect your rate. A couple of ounces in dunnage or a half inch in packaging could move you down to a lower rate, saving you money on every package.\nThomas Kiesling is operations manager at Christopher Morgan Fulfillment, a fulfillment and marketing company based in New Berlin, WI.', 'Determining the most cost effective way to send a small parcel shipment can be cumbersome. Although typically shipments are sent with one of the two global players, there are numerous cost elements associated based on what you are shipping, where you are shipping to and from, when you want your shipment to arrive, etc. Therefore, how does one ensure both an optimal sourcing engagement and competitive price when approaching the market, as well as choosing the ideal shipping methodology?\nAs a sourcing professional, understanding the impact market shifts have to pricing and supplier viability, is key in making recommendations to my clients. A standard practice I pursue is conducting a benchmarking exercise. Benchmarking is used to analyze a company’s ‘current state’ in terms of existing category spending behaviors and requirements, and how it compares to what the market is offering similarly profiled customers. This process also establishes necessity versus wants to uncover opportunities to remove unneeded services or optimize the use of a supplier, whether through an incumbent or alternate. The result allows me to provide an informed recommendation on the best choice supplier from both a qualitative and quantitative perspective while encouraging adopting industry best practices allowing for better controls of company spending.\nIdentified below are some of the small parcel service and pricing elements I would incorporate into a benchmark assessment with corresponding considerations for each.\nSupply Base: A major factor when looking at the following elements is who the suppliers that should be assessed are and what do they offer? Today, there are two primary suppliers that must be included in your benchmark, UPS and FedEx. Although there is a comparative translation between services, in terms of pricing, gross rates for these suppliers are not the same so looking at net pricing and discounts is not a true ‘apples-to-apples’ comparison. You must understand the correlation in both pre and post discount costs. Also, who can support both existing requirements and offer innovative and additional solutions that enhance and improve business operations. This may be a smaller more regional player so take a step back and think about this before jumping in.\nTime of Day: Supplier pricing and incentives will vary based on when you want a package to arrive. Typically earlier deliveries are most costly with minimal opportunity to discount. Therefore you should understand the impact of selecting a later timing service that may result in the same actual delivery time and offer an improved net shipping rate; of course depending on where you are shipping from. Make sure to also factor in cost impacts by centralizing shipping within a specific zone and trying to accommodate a standard time of day.\nWeight Factors: Understanding dimensional weight application encourages shipping more efficiently. As DIM calculations are applied to all packages, make sure to understand the pricing variables and incentives available for all weight groups within each shipment category. Although Ground is a creature of its own, typically air shipments should be streamlined when looking at available discounts.\nSurcharges: How and when surcharges are applied can have a pricey impact to overall costs. What do suppliers offer to alleviate these sometimes ignored costs? Some examples would be additional charges and associate discounts for weekend deliveries and comparing commercial versus residential delivery fees and incentives.\nOther Cost Considerations: Ancillary account fees or contractual commitments can pop up based supplier requirements, such as minimum package volumes or revenues and pickup requests, each with an impact to customer spend. The contract should breakdown how these costs are established and what the supplier is willing to offer to offset these costs. Comparing alternative approaches to how these charges and fees are established and incentivized can provide visibility into negotiation tactics as you move forward in sourcing this category.\nAs mentioned, the benchmark will help to uncover your current shipping profile with more clarity and allow you to narrow down your actual need while identifying opportunities for contracting with your incumbent or an alternate supplier. It will guide you to have better controls in place for when and how shipments are sent and produce reduced spending.']	['<urn:uuid:f3e18d3e-2e7a-4494-880d-888d31582197>', '<urn:uuid:b98498b1-cb32-4b80-b4ec-a296fa798abc>']	open-ended	direct	verbose-and-natural	distant-from-document	multi-aspect	novice	2025-05-13T06:27:57.068978	23	116	1220
41	number coal fired boilers shut down urumqi first six months air quality initiative 2012	In Urumqi, 12,900 coal boilers were replaced with gas in the first six months of the air quality improvement initiative launched in late 2012.	"['GENEVA and BARCELONA, Spain, March 26, 2018 /PRNewswire/ --\nNew International Gas Union report highlights case studies of four cities - Beijing, Shanghaiand Urumqi in China, and Santiago, Chile - benefiting from dramatic improvements in air quality thanks to natural gas switch\nA new report from the International Gas Union (IGU) highlights how the increased use of, and switch to, natural gas in power generation, heating can significantly reduce air pollution - a direct cause of around 4000 deaths every day in China as recently as 2015.\nUrban air pollution continues to be a major area of concern across developed and developing countries alike, with 87% of the global population currently living in areas exceeding the World Health Organisation\'s air quality guidelines. In fact, the WHO has suggested that air pollution continues to be ""the world\'s single greatest environmental risk to health"" - stark evidence that local, national and international governments must do more to tackle the problem and reduce the severe impact on human health.\nWith 1.6 million deaths in China throughout 2015 directly caused by PM2.5 pollution - or 4,000 deaths every day - this latest IGU report focuses on three City case studies within the country, and the steps they\'ve taken to limit the environmental, health and economic consequences of pollutants. The study also looks at one South American city, Santiago, Chile, which has also seen dramatic improvements in its air quality in the two decades since it began to switch to a largely gas-powered economy.\nThe new research focuses heavily on the reasons behind, and positive benefits following, a widespread shift from coal to natural gas in residential and industrial energy production. The report highlights case studies in Shanghai, Beijing and Urumqi - three cities across China where local authorities have taken significant steps in fuel switching initiatives that have led, or are leading to, real progress in improving air quality without sacrificing economic development. The final case study examines similar initiatives in Santiago, Chile - a city once known for its poor air quality - where a switch to natural gas has played a central role in air quality regulation and improvement.\n""Of the 5.9 billion people where measurement is available, 4.5 billion of those are exposed to Particulate Matter (PM) concentrations that are at least twice the WHO limit, or above. This, combined with the staggering statistic that PM caused roughly 17% of deaths in China in 2015, must signal to authorities that drastic action is needed,"" said David Carroll, President of the IGU. ""More must be done to tackle the severe impact this is having on human health without sacrificing economic growth - Shanghai, Beijing, Urumqi and Santiago are four prime examples of how this is achieveable, with natural gas playing a leading role.""\n- In 2013, the city was experiencing a pollution crisis - dubbed \'Airpocalypse\' - and over 50% of the days that year were ranked as unhealthy or worse for air quality\n- In 2014, as the city recorded PM concentrations of 85.9 μg/m3 (almost 9 times the WHO limit), the National Government announced a ""war on smog"" and intensified anti-pollution policies\n- With this in mind, and as the capital city, Beijing was one of the early targets in the government\'s fight against pollution - in 2015 the city implemented an aggressive coal to gas substitution policy\n- In 2017, PM concentrations had dropped to 58 μg/m3 - a 54% decrease vs. 2016. That year over 4,450 coal-fired boilers were shut down, and 900,000 households being shifted from coal to gas since 2013\n- As one of China\'s megacities, the urgency to address its air quality issues have been top of mind for the city and national authorities, since the late 1990\'s.\n- Despite this, in 2000 there were more than 3,800 industrial boilers in operation. That year, Shanghai emitted 464,000 tons of SO2 and 141,200 tons of smoke and dust\n- From 2000-2012, Shanghai became the first city in China to embark on a coal-fired boiler retrofit program. This included a focus on enabling supply through completion of transmission and distribution pipe networks, and the enacting of measures for replacing coal with gas boilers\n- In 2012, the City established a fund for gas project incentives, and introduced coal-free and mostly-coal free areas. In 2015, the entire metropolitan area was required to become coal-free by the end of the year\n- By 2016, this had resulted in reduction of all major air pollutants:\n- PM2.5 concentration improved by 15.1% vs. 2015, and 27.4% vs. 2013\n- PM10 concentrations dropped by 14.5%, vs. 2015\n- Total city coal to gas consumption ratio dropped from 43% in 2013 to 33% in 2016\n- The city had one of the worst air quality rankings in the country, due to coal combustion, traffic, and biomass burning all emitting harmful aerosols\n- In late 2012, an air quality improvement initiative was launched to replace coal-fired heating with gas - which grew to 76% of the total heating fuel in the 2012/13 heating season from almost none. 12,900 coal boilers were replaced with gas in the first six months\n- By 2013, this resulted in monthly PM2.5 concentration dropping by 62.8% vs. 2012, a 5 MT reduction in coal consumption, and a 35,000-ton reduction in SO2 and 17,000 in soot\n- By 2014, gas had largely displaced coal as the dominant heating fuel, monthly PM2.5 concentrations had dropped by 75.5%, and there had been a 50% reduction in SO2 since the 2012 heating season. More importantly, this resulted in a 73% reduction in pollution-related lung cancer\n- In 1989, residential heating powered by wood-burning, transport activity, and the use of coal, fuel oil, and diesel by industry had all contributed to the city\'s PM2.5 levels registering in excess of 68 μg/m3, seven times the recommended WHO level\n- Between 1992 and 1998, the city took its initial steps towards air quality regulation, creating a link with Argentina to enable supply of natural gas. Thanks to this, the first gas-fired power plant began generating in 1998\n- By 2004, gas supplied 70% of industrial and 24% of residential energy, before the supply was interrupted up until 2008. In 2009, however, a new LNG terminal was opened to restore supply and emissions dropped by 1.76 μg/m3, versus the 2004-2008 period\n- In 2016, the city has recorded a reduction of 39% of PM10 and 58% of PM2.5 since 1990, as well as a reduction of 2.63 μg/m3 of PM from industrial sources\nArmed with the latest supporting data, the examples above, and other urban area case studies presented in previous IGU urban air quality studies, the IGU supports policies that reduce GHG emissions and emissions of health-damaging air pollutants such as:\n- Improvement of end-use energy efficiency;\n- Increases in combustion efficiency (reducing or eliminating black carbon and other products of incomplete combustion);\n- Encouragement of fuel switching;\n- Increased use of non-combustion renewable energies.\nSupporting testimonial from local stakeholder:\nDr Mauricio Osses A., - Department of Mechanical Engineering, Universidad Tecnica Federico Santa Maria, Santiago, Chile:\n""Based on the analysis of PM filters from 1998 to 2012, it can be concluded that the introduction of mass use of natural gas replacing diesel in the industrial sector has had a positive impact on PM2.5 concentrations from industrial sources.\nSpecifically, a close analysis of changes in industrial air pollutant emissions that resulted from the temporary interruption of supply from Argentina, and the consequent restoration of supply with the LNG terminal completion, demonstrate a strong positive correlation between using natural gas as fuel and cleaner air.""\nTo download the full report, please visit https://www.igu.org/publications-page\nAbout The International Gas Union (IGU)\nThe International Gas Union (IGU) was founded in 1931 and is a worldwide non-profit organisation aimed at promoting the political, technical and economic progress of the gas industry. The Union has more than 150 members worldwide on all continents, representing approximately 97% of the world gas market. The members of the IGU are national associations and corporations within the gas industry worldwide. The IGU organises the World Gas Conference (WGC) every three years, with the forthcoming WGC taking place in Washington, D.C., United States, in June 2018. The IGU\'s working organisation covers all aspects of the gas industry from exploration and production, storage, LNG, distribution and natural gas utilisation in all market segments. www.igu.org\nSOURCE The International Gas Union (IGU)']"	['<urn:uuid:c4fed211-8929-4990-92ff-c2e2eb8d51ad>']	factoid	direct	long-search-query	similar-to-document	single-doc	expert	2025-05-13T06:27:57.068978	14	24	1401
42	bank teller cashier main duties responsibilities and requirements job	Bank tellers handle initial enquiries and basic financial transactions like deposits and withdrawals, handling cheques and some credit and cash card queries. They must have excellent customer service skills and must handle customer needs quickly and efficiently. A degree is not usually required but they need on-the-job training.	['Banking offers a long and varied career path that can lead to substantial rewards. It is a very popular industry that can be difficult to break into, as there is stiff competition for entry level positions and higher level positions demand ability, expertise and, sometimes, an inside track.\nFor those about to climb onto the first rung of the banking sector ladder, there are several positions to choose from. Some require tertiary qualifications, but it is possible to begin a banking career without a degree. If you have decided on a career in banking, then you might be interested in considering these entry level positions.\nBank Teller or Cashier\nThe bank teller or cashier is generally the first point of contact with the bank for members of the public. Tellers handle initial enquiries and basic financial transactions like deposits and withdrawals, handling cheques and some credit and cash card queries. They must have excellent customer service skills and must be able to handle customer needs quickly and efficiently. A degree is not usually required but you will usually need a period of on-the-job training. It is a good entry position but to progress further up the ladder, you will probably need to gain higher qualifications.\nMoney Management Specialist\nThis is another position that does not necessarily demand a tertiary qualification at the entry level, though it may be necessary as you progress to more specialised areas; good customer skills and possibly some experience showing that you are suitable for the role might be enough to win you a job. Recent changes in regulation in the banking industry have led to increasing demand for money management specialists and there are good prospects for advancement.\nCredit analysts have a highly responsible job, as they are required to assess and make decisions regarding customer credit applications. This means analysing the customer’s credit-worthiness, the purpose of the application and formulating a risk assessment and so on. The position usually requires at least a good degree and often some relevant experience.\nFinancial analysts are responsible for making recommendations on the viability of a particular financial transaction. This might include compiling reports that provide market information and other relevant details on which companies base their decisions on how and where to invest. Or else it might involve the preparation of financial models that predict future economic conditions. To become a financial analyst, you will need at least a degree in a finance–related field, or a subject that shows your ability to interpret data, and you will need to be highly competitive. Financial analyst has reputation of being a hard job to get, so patience and determination are crucial.\nLoan officers are the people responsible for approving loans for mortgages, business development and other applications. You will need to have good customer skills and to be able to make informed decisions about the customer’s suitability for the loan. You will probably require a degree in finance or economics and you will need to have an understanding of best lending practices.']	['<urn:uuid:aba140f2-71ea-4fba-ac63-764045c9cee4>']	factoid	direct	long-search-query	similar-to-document	single-doc	novice	2025-05-13T06:27:57.068978	9	48	503
43	Can anything be done to fix a sinkhole?	Yes, if a sinkhole is caught early, it can be stopped by injecting grout into the hole to rebuild a foundation over the degrading bedrock. This process is similar to a dentist filling a cavity - the grout sets, hardens, and stabilizes the hole.	"['Sinkholes are a common feature in Florida\'s limestone-rich bedrock as groundwater easily dissolves the calcium carbonate into solution turning the ground into a slushy mix that washes out under the structures built on top of it.\nBut rarely do they kill.\nOn Thursday night, a sinkhole in Tampa opened up and swallowed the bedroom where Jeffrey Bush, 37, was sleeping. Rescue crews and his brother acted quickly to try and save him, but Friday morning listening devices and cameras placed in the hole failed to pick up any signs of life.\nThe fast-acting sinkhole that likely took Bush in his sleep is unusual. Most sinkholes give warning signs of their impending devastation.\nSinkholes form when water dissolves minerals in the bedrock leaving the structures on top of the ground sitting precariously on loose soil that can quickly wash away.\nIf a sinkhole is in the process of forming the structures on top of it can give a hint to its existence: for example, slumping or sagging fence posts, and trees that start to lean. More subtle signs can include doors and windows that don\'t close properly.\nHeavy rains can trigger the collapse of a sinkhole that had been slowly forming earlier. When rainfall collects in an area where water previously did not collect, that is another sign that the land is subsiding.\nBad enough that sinkholes could be forming under your feet in normal rains. Bring a hurricane to the region and it could feel like not only the sky is falling, but the ground is falling as well.\nThe Worst Kind of Sinkhole\nWhen tropical storm Agatha blew through Guatemala in 2010, the volcano-pocked nation witnessed the worst kind of sinkhole form in the middle of Guatemala City: a 100-foot deep, 66-foot wide circular chasm called a ""piping feature"".\nUnlike most sinkholes where the bedrock is dissolved, the Guatemala City hole formed from water washing away the remnants of ancient volcanic debris, pumice and ash. Much of the city is built on top of this volcanic fill, which reaches depths of 600 feet.\nSinkholes Can Be Stopped\nIf a sinkhole is caught early, cities can inject grout into the hole to rebuild a foundation over the degrading bedrock.\n""It\'s similar to a dentist filling a cavity,"" Anthony Randazzo of Geohazards, Inc., told USAToday. ""It sets and hardens and stabilizes it.""\nSometimes the groundwater dissolving the limestone bedrock flows deep beneath the bedrock. In Mexico, many sinkholes called cenotes expose these underground rivers and show the location of underwater limestone caves.\nWhen entering a cenote it is culturally respectful to ask the Mayan Gods for their protection, to keep any more of the ground surface from falling in on top of your head.\nWhen the earth falls out from under your feet, it may not be a sinkhole at all, but rather an earthquake. When the Alaskan earthquake struck on March 27, 1964, Fourth Avenue dropped 20 feet below normal level as the result of the shifting fault-line.\nWhen sudden seismic shaking occurs near the coast don\'t wait for a tsunami warning siren, head to higher ground.\nBlue holes along low-lying coastlines are the remnants of sinkholes formed during past ice ages when sea level was 300 to 400 feet lower than today. As sea level rose, the sinkholes became flooded, forming vertical caves. The deep blue color of the hole contrasts with the lighter white carbonate sands of the surrounding seafloor and the water is home to many varieties of marine species.\nSCUBA diving in a blue hole can be dangerous as the depth is difficult to judge with just your eyes. Divers must vigilantly check their depth gauges to make sure they don\'t exceed their safety limits.\nExploring the interlinking limestone caves within Northern Madagascar\'s Ankarana National Park is best done in the dry season.\nDuring the wet season, the rivers that flow through the caves and provide the water for some of the lush forests that crop up like oasis on sinkhole floors are infested with crocodiles.\nThe Best Kind of Sinkhole\nThe best kind of sinkhole is one with groundwater still flowing through it to keep from stagnating, where the ground surface isn\'t at risk of further collapse, where no infrastructure has fallen into the sinkhole floor, and where there is no entrance fee to take a quick and refreshing swim.\nOnly trouble with these types of sinkholes is that it can be quite a journey to get to one.\nThis story was provided by Discovery News.']"	['<urn:uuid:cd4279ea-2fb2-4543-9175-384cc2e38076>']	open-ended	with-premise	concise-and-natural	similar-to-document	single-doc	novice	2025-05-13T06:27:57.068978	8	44	751
44	philippines marine biodiversity scientific explanation	The Philippines' exceptional marine biodiversity can be attributed to several factors. The Philippine Archipelago, consisting of 7,107 islands, formed over millions of years from regions as far apart as present-day Hong Kong and Borneo, bringing together temperate and tropical fauna. The country has the second-highest concentration of coastline after Norway, providing extensive habitat. Additionally, oceanographic features like gyres isolate populations, leading to rapid species evolution. The Philippines is part of the Coral Triangle, which contains 75% of known coral species and 40% of coral reef fish species globally.	"['After six weeks in the Philippines trawling the ocean floor, canvassing the jungly flanks of volcanoes and diving in coral reefs, scientists believe they have discovered more than 300 species that are new to science. Their research constituted the largest, most comprehensive scientific survey ever conducted in the Philippines, one of the most species-rich places on earth.\nThe survey, led by the California Academy of Sciences, brought scores of bizarre and unexpected creatures into the annals of life as we know it. It revealed more than 50 kinds of colorful new sea slugs, dozens of spiders and three new lobster relatives that squeeze into crevices rather than carry shells on their backs. The scientists found a shrimp-eating swell shark that lives 2,000 feet under the sea, a starfish that feeds exclusively on sunken driftwood and a cicada whose call sounds like laughter.\nFor two weeks I shadowed teams of scientists—from seahorse specialists to spider experts—as they surveyed reefs, rain forests and the South China Sea. On a deep-sea vessel, scientists dropped traps and nets to obtain a glimmer of the life that exists in the shadowy depths. They surrounded each haul excitedly as it was deposited on deck, picking through the curious sea life and discarding the garbage that inevitably accompanied it. “To see live stalk crinoids”—feather stars—“come up that I’ve only seen as preserved specimens is like a scientist’s dream world!” said invertebrate zoologist Terrence Gosliner, who led the expedition, one afternoon as he sorted spindly starfish and coral from candy wrappers.\nThree new species of deep-sea “bubble snails” that possess fragile, translucent, internal shells arrived in one trawl, along with a snake eel and two new “armored corals” called primnoids, which protect themselves against predatory nibbles from fish by growing large, spiky plates around each soft polyp. Ten-inch-long giant isopods as imagined by science fiction turned up in a trap. “If you saw District 9 I’m sure they modeled the faces of the aliens off these,” said marine biologist Rich Mooi, who studies sea urchins and sand dollars. Later that evening, the catch yielded several two-foot-long, mottled swell sharks that inflate their stomach with water to bulk up and scare off other predators.\n“When I watch the trawl come up it’s like a window onto the frontier,” said Mooi. “You start going through this material wondering, ‘What are they doing down there? Are they interacting with each other?’ We’ve seen a very tiny percentage of that sea bottom—three-quarters of the planet is obscured by this endlessly restless mass of water you can’t see through.”\nMany of the new species found in the survey had evaded science because of their small size—the 30 new species of barnacles discovered measure just fractions of an inch in length—while others lived in areas rarely visited by humans. A primitive, fernlike plant called a spikemoss was found growing on the precipitous upper slopes of a 6,000-foot volcano. “Our scientific understanding of this part of the world is still in its infancy,” said Gosliner. “For people interested in biodiversity and the distribution of organisms and evolution, the Philippines is a treasure trove.”\nYet it is a gravely imperiled treasure trove. The rate of species extinction in the Philippines is “1,000 times the natural rate,” according to the country’s Department of Environment and Natural Resources, because of deforestation, coastal degradation, unsustainable use of resources, climate change, invasive species and pollution. A recent study by Conservation International found that just 4 percent of the Philippines\' forests remained as natural habitat for endemic species, and according to the World Wildlife Fund, destructive commercial fishing has left only 5 percent of coral reefs in the Philippines in excellent condition.\nScientists described the expedition this spring as a kind of emergency response. “We’re living in a burning house,” said Mooi. “In order for firemen to come in and make an effective rescue they need to know who’s in those rooms and what rooms they’re in. When we do biodiversity surveys like this we’re doing nothing less than making a tally of who’s out there, who needs to be paid attention to, and how can we best employ the resources we have to conserve those organisms.”\nFor years scientists have recognized a 2.2-million-square-mile area around Malaysia, Papua New Guinea and the Philippines as being home to the world’s highest diversity of marine plants and animals. It’s known as the Coral Triangle and considered the Amazon basin for marine life. The waters harbor 75 percent of the planet\'s known coral species and 40 percent of its coral reef fish.\nIn 2005 Kent Carpenter, an ichthyologist at Old Dominion University, identified the core of that diversity. Overlaying global distribution maps for nearly 3,000 marine species, including fishes and corals, sea turtles and invertebrates, Carpenter found that the highest concentration of marine species on the planet existed in the central Philippines. “I fell off my chair—literally—when I saw that,” Carpenter recalled recently. He dubbed the region “the Center of the Center.”\nThe reasons for this are not entirely understood. The 7,107 islands that make up the Philippine Archipelago constitute the second-largest island chain in the world after Indonesia. The islands converged over millions of years from latitudes as disparate as those of present-day Hong Kong and Borneo, and they may have brought together temperate and tropical fauna that managed to get along in a crowded environment.\nAnother possible explanation is that the Philippines has a higher concentration of coastline than any country except Norway, providing a lot of habitat. It is also a place where species are evolving more rapidly than elsewhere. Populations become isolated from other populations due to oceanographic features such as swirling currents known as gyres. The populations then diverge genetically and become new species. “The only place on the planet where you have all of the above is in the Central Philippines,” said Carpenter.\nA prime location for this diversity is the Verde Island Passage, a busy commercial sea route off Luzon Island, the largest island in the archipelago. During two decades of diving in the Verde Island Passage, Gosliner, the world’s foremost expert in nudibranchs, or sea slugs, has documented more than 800 species, half of them new to science. There are more species of soft corals at just one dive site than in all of the Caribbean. “Every time I go into the water here I see something I’ve never seen before,” he said.\nOne afternoon, Gosliner emerged from a dive into the shallow water reefs clutching a plastic collection bag that contained two nudibranchs, one colored a bright purple with orange tentacles. “Two new nudis!” he called out. “And the black and electric blue nudibranchs were mating like crazy down there. There were egg masses everywhere. They were having a good ole time.”\nUnlike land slugs, nudibranchs have bright colors that advertise toxic chemicals in their skin. These chemicals may have pharmaceutical value, and several are in clinical trials for HIV and cancer drugs. Gosliner explained that the presence of nudibranchs, which feed on a wide variety of sponges and corals, “are a good indication of the health and diversity of the ecosystem.”\nThe Verde Island Passage ecosystem has faced immense pressures over the past few decades. In the 1970s, Carpenter worked as a Peace Corps volunteer with the Philippines Bureau of Fisheries. “Every 50 feet you’d see a grouper the size of a Volkswagen Bug, big enough to swallow a human being,” he recalls. Today, large predatory fish like sharks are virtually absent. Fishermen now harvest juveniles that haven’t had a chance to reproduce; “it’s at the very level where you can’t get any more fish out of oceans here,” says Carpenter. Destructive fishing methods have devastated the area’s coral. Illegal trade has exacted a further toll; this spring, Filipino officials intercepted a shipment of endangered sea turtles and more than 21,000 pieces of rare black corals bound for mainland Asia, for the jewelry trade.\n“There’s a lot of good policies and regulations in place in the country, but the main weakness right now is enforcement,” says Romeo Trono, country director for Conservation International.\nThe Philippines has more than 1,000 marine protected areas, more than any country in the world, but only a few, Carpenter and other scientists say, are well managed. For 30 years, Apo Island, in the southern Philippines, has been held as a model for community-managed marine reserves. In 1982 a local university suggested the community declare 10 percent of the waters around the island a “no take” zone for fishermen. Initially resistant, the community eventually rallied behind the reserve after seeing how an increase in fish numbers and sizes inside the sanctuary spilled over into the surrounding waters. They established regulations against destructive fishing and a volunteer ""marine guard"" (called bantay dagat) to patrol the fishing grounds and prevent encroaching from outsiders. User fees from the marine sanctuary generate nearly $120,000 per year, and the tourist industry surged after the marine ecosystem recovered.\n“Where marine protected areas have been established and populations of animals and fishes have been allowed to recover, they recover very well and very quickly,” says Gosliner. “The difference between diving in a marine protected area versus an area right next to it is like night and day.”\nOver the next several months, California Academy scientists will use microscopes and DNA sequencing to confirm and describe these new species. The species lists and distribution maps created during the expedition, they hope, will help to identify the most important locations for establishing or expanding marine protected areas, as well as areas for reforestation that will reduce erosion and subsequent sedimentation damage to the reefs.\nBut for the scientists, the survey is just the beginning. “Being able to document the richest and most diverse marine environment on the planet” will help them “get an understanding of what the dimensions of diversity are,” said Gosliner. “We really don’t know the answer to that fundamental question.”\nAndy Isaacson is a writer and photographer who lives in Berkeley, California. His reporting was made possible by a grant from Margaret and Will Hearst that funded the expedition.']"	['<urn:uuid:bf5ce8a6-06ef-4c05-9f70-4d71b0d956b7>']	open-ended	direct	short-search-query	distant-from-document	single-doc	expert	2025-05-13T06:27:57.068978	5	88	1683
45	How do pentatonic scales create game effects and why use middleware?	Pentatonic scales are used to create evocative gaming sounds like happy, triumphant chimes in games like Super Mario Bros and Sonic, making players feel joy and achievement. Regarding middleware, it provides cost-effective benefits by saving programming time and enabling sound designers to work quickly with familiar tools like decibel controls and bus mixing hierarchy, ultimately improving game audio quality while decreasing development time.	"[""The same is true for video game sounds and music. Whether you started playing games as a child, picked up a console controller for the first time as an adult or simply enjoy online and mobile games, chances are there’s at least one video game theme or sound that you find particularly evocative. Here, we’ll be looking at the most iconic pieces of music that you will probably recognise from games on console, PC, mobile and online that you will probably recognise, as well as why certain sounds resonate with us.\nSounds in Video Games: Iconic, Evocative and Instantly Recognisable.\nThe trick to this is the use of pentatonic scales – the key to creating evocative gaming music and sounds found in some of history's best video games. Remember those happy, triumphant chimes when you completed a level in Nintendo’s classic Super Mario Bros. or when you collected rings in Sega’s Sonic the Hedgehog? In addition to making the player feel a sense of joy and achievement, they also had major pentatonic scales in common. These high-pitched chimes let the player know that they were doing something right without the developers having to work out how to give verbal or complex visual clues.\nOf course, as we entered the 90s and beyond, it became clear that gamers wanted more than just happy platformers with chimes – gamers wanted dark, scary adventures. So, as sound design became more sophisticated, developers began to dabble in non-linear sounds to create even more immersive gaming experiences.\nNon-linear noises are created when sounds exceed the normal range that an instrument or human voice is capable of creating. A particularly impressive example of non-linear music that exists in popular culture but outside of gaming is the well-known staccato violin pangs from Hitchcock’s Psycho. Wild animals are also able to make these noises, though they are usually used only during distress calls, which is maybe why the best example of non-linear music in games can be found in titles like Silent Hill, Resident Evil and Amnesia: The Dark Descent. It may, in fact, be that these horror games were so popular partly because the developers used non-linear noises that instantly invoke stress and fear in animals, including us humans.\nSo, with happy and scary music already in the bag, the only element that sound designers had to come up with next was adaptive music. That is, music and sounds that clearly tell the player when more complex things are happening – such as their character being in danger or that they need to prepare for a battle.\nThe need for adaptive music became increasingly clear when stealth games such Metal Gear Solid were being created, as changes in pace and predicament were paired perfectly with well-suited music. It also helped in titles like the Elder Scrolls series, allowing players to catch on when their fun exploration of the landscape had been put on hold due to an approaching troll or giant spider.\nWith the pentatonic scale, a non-linear library of sounds and a wide range of adaptive music, sound developers were eventually able to come up with entire soundscapes and soundtracks, which is what we experience in modern video games today. However, as more platforms appeared that could host games, it became clear that not all games could make-do with or apply these three important sound tricks. Instead, they created their own holy grails of sound design.\nSounds in iGaming: The Universally Pleasant Tone of C.\nBack in the late 90s when video games were working on non-linear noises and adaptive music, there was another game design sector working on their own soundscapes. Now known as the iGaming industry, online casinos such as this good site were one of the first gaming sectors to appear on the internet. Over the years, many of the same sound design staples – particularly the pentatonic scales - were applied to games including poker, roulette and slots. However, over the last twenty years, they’ve begun using a brand-new sound that even the best video games developers can’t deal with quite as well.\nAnthropologist Natasha Dow Schull, of the Massachusetts Institute of Technology, describes this sound as the “universally pleasant tone of C” and has found instances of it in a number of online slots, some of which were created as far back the 90s. That's when the unique tone was created by the then director of Silicon Gaming, who mashed quite a few well-known casino soundscapes together to create the perfect note for all slots. In fact, many of the best slots listed by online casino Wink Slots including two of IGT's big hits Wheel of Fortune and Cleopatra have the tone of C and Schull herself has suggested to developers that all slots should contain the specific noise. As for why the tone is so important, it’s because the tone of C is one of the few noises that connect most other sounds together, making the experience of a casino game feel like one large soundscape instead of a disjointed mass of different sound effects.\nThe Future Sounds of Gaming.\nOf course, as technology evolves so too must the music and sound in games – which is probably why most blockbuster games now have incredibly large sound departments, made up of music composers, sound designers, voice artists and actors. With the introduction of tech like augmented reality (AR) and virtual reality (VR), these departments will be challenged further to create even more evocative, immersive soundscapes, whether they’re working on an online casino slot or on a big blockbuster console title. Whatever sound designers come up with for the future, we’re sure it’ll be fascinating."", 'A common question within the game audio community is: How can I explain the benefits of using middleware to my boss or client? From our side of the fence as audio professionals, it may sometimes seem like a no-brainer. To be able to answer this question pragmatically however, we would need to look at it from the client\'s point of view. Why should they spend extra money on middleware when it may be possible to get the job done without it? How do the benefits stack up against the costs? In today\'s game development landscape where using third party engines like Unreal or Unity with built-in audio capabilities is becoming increasingly popular for their all-in-one solutions, especially amongst the many small indie teams working with tight budgets, how can we justify the investment towards a specialized sound engine?\nFrom the perspective of the producer or studio director planning their project, the license fee is cash that they can\'t spend on something else. Consider a single platform project with a production budget for a single platform budget between $150K and $1.5M USD—the Level B license fee, in line with the production budget, is $6,000. In this example, using Wwise may therefore be equivalent to something in the order of one senior or one and a half junior team member work months. Perhaps that cost means dropping a feature or producing fewer assets. The point is that it\'s a trade-off. To justify the cost, you need to demonstrate how the benefits on the other side of the scale outweigh these considerations, and from a high level perspective, this would ideally involve improving quality while decreasing time spent, for both the sound designers and programmers involved.\nIf Wwise costs the equivalent of hiring an audio programmer for one month, but in fact saves the equivalent cost for two months of an audio programmer’s rate, the numbers would speak for themselves. By using Wwise you\'ve enabled the Producer to in fact add resources by using some on Wwise, and allowed them to improve their margin on their project.\nIn other words, whenever our pitch talks about a particular feature or benefit, we need to be asking ourselves and essentially answering for the client, ""how does this feature save time and/or enhance quality?"" The specific answers will vary from one project to another of course, depending on the requirements and the baseline of features available in the existing engine of choice, but here\'s an overview of how some key Wwise features save time and improve quality.\nMost of the sound designer’s work in Wwise takes place in the authoring application. Creatively, the Authoring workflow delivers a powerful set of features and provides the sound designer with tools in a language they understand. For example, volume expressed in decibels, a bus mixing hierarchy, envelopes, LFOs, and visual editing of parameter curves. It’s the same language used in DAWs and samplers, which allows sound designers to work quickly and accurately. Secondly, separating audio functionality from game objects minimizes dependencies on access to files in the project - the vast majority of the work can be accomplished without modifying scene or map files, game objects, or blueprints, all of which other team members also need access to. This not only saves the sound designer time (which ultimately feeds into quality - less time wrangling blueprints and source control and waiting for access to files means more time spent making the game sound great!), but also allows other team member to save time.\nFor designing and implementing sound effects (we’ll come to VO and music later), the beating heart of Wwise is the Actor-Mixer Hierarchy and its container types - Random, Blend, Switch and Sequence. With these four container types (which can be nested and combined in any way imaginable) we can construct a huge variety of sound behaviors, from essential basics such as picking a sound at random from a pool of variants, to highly complex layering and dynamic sound structuring. On top of this we can define Real-Time Parameter Controls (RTPCs), Switches and States, so that they are received from the game and mapped to a wide variety of sound properties.\nConsider footsteps as an example. If a character requires footstep sounds for 5 different surface materials and 3 different speeds, we can assemble a structure with (from the bottom up): Random Containers containing the samples for each permutation e.g. Grass/Walk and Grass/Run; Blend or Switch Containers mapping each permutation to a “speed” parameter or Switch; and a Switch Container at the top level switching between materials. This can all be assembled in minutes, and all that’s required from code is a “play footstep” Event on each footstep and “material” and “speed” values to be set as they change.\nHere’s another example. A weapon sound may consist of an attack portion, a tail, and a “mechanism” layer that you only hear close up, each with variants. This can be assembled using a Blend Container combining 3 Random Containers, perhaps delaying the mechanism layer by a variable amount of time. Again, this takes minutes to assemble and it all can be triggered by a single Event.\nTo implement these behaviors from scratch would take time and testing, and would be unlikely to deliver the same speed of use as the authoring UI provides. Trust me, I’ve done this using Unity and I know! You may be approaching the cost of a level B license implementing something equivalent to these basic container types alone, and in all likelihood you would still have a less streamlined workflow and a limited set of capabilities from what you would have using Wwise.\nOne of Wwise’s most powerful features is the Profiler. The Profiler connects the authoring tool to the game while it’s running, and monitors everything that is going on in the sound engine. Incoming Events are displayed in real-time along with the associated Actions performed as a result, such as sounds starting and stopping, or changes to volumes and positional information. I could also display error messages, parameter values, and resource usage. It\'s a fantastic tool for debugging and optimization, and it saves huge amounts of time by allowing us to quickly identify if and why sounds are not behaving as intended.\nThere is no “out of the box” audio toolset amongst any of the leading engines that is currently providing anything comparable, and it would be prohibitively expensive and difficult to independently implement what the Profiler does. The question here isn’t so much “What does it cost to implement?” as “What does it cost to do without it?” A bug that could be diagnosed and fixed rapidly by the sound designer alone using the profiler would often require programmer support and more extensive QA testing, as well as more time from a sound designer to fix. Given that we might encounter dozens of such bugs over the course of a typical project, it is very reasonable to estimate that Wwise would be saving at least several days of work, if not weeks.\nWhen the Authoring Tool is connected to the game (with the same connection used for the Profiler), we can edit in real-time. This enables us to mix and fine-tune the game as we play it. In contrast to the way some game engines work when live-editing, when using Wwise, changes are retained at the end of the session and this invaluable for level mixing, but it also means that we can fine-tune RTPC mappings, attenuation, effect sends, timing properties, blends and many other sound properties and behaviors in their context. This significantly reduces the time a sound designer would need to spend on iterations, and elevates the accuracy with which we can mix and tweak, ultimately, helping us drive up quality.\nWwise also provides a number of different ways to control the mix dynamically in response to game Events and States, and the content being played at any given time. High Dynamic Range (HDR) enables the mix to adapt to the loudness of the content being played, surpassing quieter sounds to make room for, and increase the perceived loudness of louder ones. States can modify Bus volume, Filtering or Effects. Ducking, can also be set up with a few clicks.\nWhile a basic ducking system based on whether a sound of a given type is playing may be simple to implement, metering-driven ducking (Side-Chaining) and flexible State mixing are not, and HDR in particular is highly complex. If features like these are required, the implementation time without Wwise may be measured in weeks, not days.\nInteractive Music System\nMost games need some form of interactive or dynamic music, and this is one of the least well-supported areas of audio within game engines. Wwise’s solution is flexible enough to support whatever approach you want to take, with sample accurate synchronization and highly configurable transition behaviors. It is a State driven system, which means all the game needs to do is start the music system when you start the game or level and set States as required.\nImplementing an interactive music player with even a fraction of the power, timing accuracy (vital for music synchronization), and ease of use is likely to take weeks of Programmer time.\nAs with interactive music, VO localization is similarly not well supported by default in most game engines. Wwise, on the other hand, makes it incredibly easy. All you would have to do is drag in assets with matching names and set their language in the import dialog. And, from a coding standpoint, it would require a single function call to set the language.\nCross-platform development is one area where the commonly used engines are particularly strong, and this extends to audio as well. Wwise still manages to provide a bit of an edge, however, with comprehensive control over compression and format conversion at micro and macro levels via ShareSets (see below), invaluable for making per-platform content optimization fast and effective.\nSoundcaster / Prototyping\nA principle that has always been at the heart of Wwise\'s design is to empower sound designers by providing them with maximum control of sound behaviors, with minimum dependency on game code. When a weapon is fired, all the game does is post an Event to Wwise. What happens from there onwards, such as layering, randomizing, sequencing component sounds, and perhaps even affecting other sounds is all in the hands of the sound designer.\nThe Soundcaster enables the sound designer to test these behaviors offline, simulating game inputs before they have been implemented, or in more controlled conditions than the game allows. Therefore, the idea behind breaking the dependency between audio and code also enables implementation designs to be tested before any code is written. The result is that we can clearly establish what works in a rapid prototyping environment and eliminate slower and more costly code iterations.\nShareSets are probably some of the most unacknowledged yet deserving of Wwise features. They are essentially reusable settings templates for Attenuations, Modulators, Effects and conversion settings. Hardly the sexiest sounding, but here\'s the thing: they enable the sound designer to make both sweeping macro level changes and manage tuning of fine details, in an extremely efficient way.\nA great example would be platform optimization. Let\'s say our game is ready to ship but the PS4 SoundBanks exceed their memory budget. How are we going to shave off those 4 MB that we have been asked to cut? Using ShareSets, we can adjust compression settings, affecting the whole platform. Or, we can create a custom setting for an entire category of sounds to compress them more or compress them less, downsample them, or even force them to mono to balance quality against memory usage.\nIn the same way, we can also apply attenuation settings across large or small categories of sounds to ensure that the changes we make in one place are applied everywhere we want them to be.\nThe benefits here in terms of time, efficiency, and keeping a project manageable are huge. The main beneficiary is the sound designer. With Wwise, sound designers can channel all their time into perfecting audio quality rather than wading through settings, adjusting and testing, and adjusting again.\nSo, “What can Wwise do to benefit the project overall?” In summary, it saves significant amounts of sound designer time, establishes an efficient workflow, and allows for time focused on value-added objectives such as creating content and making the project sound great. It also minimizes coding time by putting control and creative features in the hands of the sound designer, which therefore means that it can potentially free up weeks or even months of programming resources to be spent in the best way possible: ensuring that your game or project is the best it can be.']"	['<urn:uuid:e54a5974-206e-4baf-a48d-4d4a40f3bd6c>', '<urn:uuid:08dbdcf9-e3b8-422c-9db5-858999865334>']	factoid	direct	concise-and-natural	similar-to-document	multi-aspect	expert	2025-05-13T06:27:57.068978	11	63	3072
46	moisture damage effects temple grain storage	Moisture damage significantly impacts both temple structures and grain storage. In Wat Bang Nam Phueng Nok, moisture has caused severe deterioration, with plaster crumbling from walls, exposing brickwork, and destroying murals in the lower portions of walls. Similarly, in post-harvest agricultural systems, moisture is a critical concern for grain storage, particularly as climate change brings more frequent high rainfall events and flooding in some regions. Adequate and protected drying, along with proper maintenance of storage structures, are essential practices in both contexts to prevent deterioration and losses. The preservation challenges in both cases demonstrate the crucial importance of protecting structures and contents from moisture damage.	['For those wanting to get away from Bangkok at the weekend there is perhaps no nearer escape than Phra Pradaeng, the huge green oasis almost in the heart of the city but separated from it by a 17km long loop in the Chao Phraya River. Riding around this island on a rented bicycle is a great way to spend a day out. And for Siamrat one of the hidden treasures of Phra Pradaeng island is a pair of old temple buildings at Wat Bang Nam Phueng Nok.\nWat Bang Nam Phueng Nok\nWat Bang Nam Phueng Nok (“Outer Honey Village Temple”) itself is a large temple on the eastern bank of Phra Pradaeng where the ferry crosses from Bang Na. A temple has been situated on this site for at least 350 years, well before Bangkok was the capital city. The current temple building however dates from the 1960’s, being inaugurated by Queen Rambai Barni, previously queen to King Rama VII, in 1966.\nOn walking some 250m further up the road however, one finds on the left hand side by the school two very old and very dilapidated temple buildings, one an ubosot (Ordination Hall) and the other a viharn (Assembly Hall). These buildings are home to some splendid but deteriorated artwork.\nThe ubosot building is the larger of the two buildings and in a serious state of disrepair. Plaster is crumbing from the walls exposing the brickwork behind. Sunlight pierces through the broken tiled double roof and the fragile wooden ceiling to illuminate the interior with evocative rays. But no doubt on a rainy day it is a very different spectacle. If there were ever any murals on the walls all evidence of them has been lost to moisture over the years. However some exquisite paintings of traditional protective guardians known as “tawaraban” have survived on the wooden window shutters.\nThe local community still maintain the ubosot as a place of worship and meditation, the interior being kept clean and with a rather beautiful set of Buddha images set up at the western end.\nThe viharn building has a single roof and stucco work on the gable ends with a garuda image in the centre. Overall it is in no better physical condition than the ubosot. Inside the western end of the room has a raised platform on which a multitude of small buddha images surround two main images. Of great interest in this building are the surviving murals of classic Buddhist jataka tales that tell the stories of the Buddha’s many past lives.\nOn the back wall is a mural of the Chulamani Chedi which according to Buddhist legend holds a relic of the Buddha in Tavatimsa heaven. The god Indra painted in green can be seen with other deities paying their respects to the Lord Buddha.\nOn the side walls only the upper murals have survived, probably because of creeping moisture lower down in the walls. But these upper murals show rows of exquisitely drawn deities.\nAbove the viharn entrance one can still make out the very popular scene of “Calling the Earth Goddess to Witness” in which the Lord Buddha on the point of enlightenment summons Phra Mae Thorani from the earth to defeat the evil forces of Mara by wringing a flood of water from her hair.\nThe artistic quality of these murals is clearly very high and consistent in style with early Bangkok court styles. However the artist has left no indication as to their name or even who sponsored the building and decorating of the temple. Even the year of construction is unknown. There are however some clues.\nThe brick and stucco construction techniques are of Chinese design in a style that became popular in the reigns of Rama II (1809 – 1824) and Rama III (1824 – 1851). Furthermore the doors in the ubosot are rather unusual because in place of traditional tawaraban guardians they are decorated with paintings of chinaware (Vases, bowls, teapots) that was fashionable during the reign of King Rama III.\nHowever the most compelling evidence for both the age and sponsorship of these buildings is to be found in the mural on the rear wall of the viharn. In the top left and right corners can be seen two empty “vimarns”, or celestial palaces, floating in the clouds surrounded by deities. This vimarn symbol was the privy seal of King Rama III and would certainly date this artwork to his reign, 1824 – 1851, and would suggest there was sponsorship from the royal court.\nSo it would appear that this small temple has links back to King Rama III and the quality of the art work suggests that the artist(s) may have also come from royal court circles.\nIn late 2016 a pair of steel roofs on scaffolding were erected over the uobost and viharn to protect them from the weather. Siamrat is not aware of what further restoration is planned but clearly much more needs to be done to prevent further deterioration of the buildings and the artwork within. One hopes that any work is carried out carefully and sympathetically to the history of these beautiful temple buildings. They are well worth a visit.\nWhere to Go', 'Global warming is bringing complex and diverse climate change and impacts in sub-Saharan Africa (SSA; see Box). The economies of, and livelihoods in, many SSA countries are based on smallholder rain-fed agriculture. Whilst agricultural production in many higher-latitude countries is initially likely to benefit from moderate global warming, in tropical regions where crops are already close to critical environmental thresholds, crop yields and areas suitable for growing them will decline. Studies suggest that by 2080, countries such as Tanzania and Zimbabwe could lose up to 30 per cent of their 1990 cereal yields (Parry et al., 2004). Declining yields are likely to trigger further agricultural expansion, deforestation, green house gas (GHG) emissions and subsequently global warming.\nAnticipated climatic changes in sub-Saharan Africa (SSA)\nProjections suggest that by the year 2030, temperatures across SSA will have risen by about 1 °C compared to those of 1980–1999 (Lobell et al., 2008). Additionally, southern Africa is likely to experience a 10 per cent rainfall decrease and more frequent drought, while East Africa is expected to see rainfall increases in the north and decreases in the south. Increasing occurrences of high rainfall events and flooding are also anticipated (Christensen et al., 2007).\nHowever, climatic change is just one stressor among many complex, interacting and dynamic factors that influence smallholder farming households in SSA. Other factors include: population growth, urbanisation, education, health, especially HIV and Aids, financial service provision and market changes. Vulnerability to climate change and adaptive capacity is determined by a similarly wide combination of interacting socio-ecological factors.\nPost-harvest systems are diverse, reflecting the varied nature of the people, place, focal crop or product and the different activity stages involved. Post-harvest systems are influenced by the activities and interactions of many different players. An agricultural innovation systems perspective provides an analytical framework with which to examine technological and institutional change in post-harvest systems; identifying the players and factors affecting demand for, and use of, existing and new post-harvest and climate change knowledge.\nFood security and post-harvest agriculture\nMost cereals consumed in SSA are produced by smallholders, with commercial imports accounting for roughly 25 per cent of the cereal consumption in the region and food aid for about 5 per cent. However, post-harvest losses of cereal grains in SSA are estimated to reach nearly four billion US dollars annually, which in cash terms, equates to wasting 15 per cent of SSA’s annual cereal production (World Bank et al., 2011). As yields are expected to decline and the value of harvested and traded commodities subsequently increases, the cost of not reducing these post-harvest losses also increases. Furthermore, in this scenario, where extra food has to be produced to compensate for losses due to ineffective post-harvest management, this is a waste of valuable resources. With Africa’s population projected to double to two billion people by 2050, and living standards and populations elsewhere also increasing, estimates suggest that global food production will need to increase by 70 per cent. Under a scenario of continuing high population growth and regional disparities in income, an additional 550 million people globally could be at risk of climate-related hunger by 2080, with 65 per cent of this increase occurring in Africa (Parry et al., 2009). There are key post-harvest elements of food availability, stability, access and utilisation. For example, maintaining high quality and sufficient stocks of stored grain enables a household (or a nation) to provide itself with a nutritional and safe supply of food until the next harvest. Given that the market value of grain typically increases up until the next harvest, grain stocks also provide a market-linked asset, part of which can be sold if needed to cover income shocks or emergencies.\nPost-harvest impacts of climate change\nFive key climate change trends affecting different parts of SSA were identified:\nThese climate change trends are unlikely to occur in isolation from each other or other drivers of change.\nThe potential impacts of each of these climate change trends on the different post-harvest activities, assets (human, natural, physical, social and financial) and human well-being outcomes (food security, social, financial and economic) were identified. An example of this analysis for the potential impacts of a general increase in temperature on the drying, pest management and storage activity stages, and selected assets and well-being outcomes is given in the Table.\nPost-harvest agricultural adaptation to climate change\nDespite the significant uncertainty regarding the scale, type and interactions of climate change impacts, mitigation and adaptation activities are needed if we are to avoid the most serious consequences of global warming. After establishing the potential impacts, we identified a range of climate-smart post-harvest agricultural adaptation opportunities (see Box).\nClimate-smart post-harvest agricultural adaptation opportunities\n• Growing and/or storing crops and varieties which are less susceptible to post-harvest pest attack;\n• Prompt harvesting;\n• Adequate and protected drying;\n• Maintenance of the physical storage structures;\n• Careful store cleaning and hygiene;\n• Accurate estimation of food stock requirements;\n• Protection and monitoring of grain to be stored for more than three months;\n• Use of low GHG emission food preparation methods;\n• Understanding and application of basic food safety principles;\n• Increasing farmer access to market information and transport options;\n• Use of early warning seasonal forecasts to project how the climatic conditions might impact on food storage or marketing strategies;\n• Use of more water, energy and resource efficient processing, packaging and transport operations;\n• Ensuring plant breeders evaluate post-harvest as well as pre-harvest crop characteristics; and\n• Helping farmers to learn from others’ and their own experiments.\nSmallholder farming households across SSA are well aware of the importance of good food storage, and perceive their ability to store food as a strength influencing their capacity to adapt to climate change and variability. While the review highlighted just how many climate-smart post-harvest adaptation opportunities are already known and even practised by some farmers, it also illuminated the scale and problems faced in getting these ‘no-regrets’ post-harvest practices into wider social and economic use.\nFactors influencing the adaptive capacity of post-harvest systems\nThe successful application of post-harvest technical solutions is dependent on a well-functioning agricultural innovation system, which through experiential co-learning practice can overcome institutional constraints which are preventing the scaling out and up of post-harvest products and processes. However, across SSA, there is a desperate lack of skilled post-harvest service providers at all levels. As well as the post-harvest skills, understanding is needed of the futility of ‘one-size-fits-all’ solutions and the importance of responsive client-focused services which support experiential learning processes to build the adaptive capacity of smallholder farmers to deal with increasingly uncertain futures. Post-harvest aspects are under-represented in most agricultural curricula. Peer learning is stifled by the very private nature of activities such as grain storage practices which usually occur behind closed doors. Additional knowledge gaps exist as regards understanding post-harvest gender roles. The lack of investment in post-harvest compared to pre-harvest agricultural development, research and policy activities only accentuates the problems of getting post-harvest knowledge into use. Perhaps climate change impacts and shocks will gradually draw attention to the crucial role that post-harvest agricultural adaptation can play in strengthening livelihoods, attracting support and developing skills for getting the many ‘no-regrets’ climate-smart post-harvest adaptation opportunities into use at scale.\nTanya Stathers, Richard Lamboll\nNatural Resources Institute (NRI) University of Greenwich, United Kingdom\nBrighton M. Mvumi\nUniversity of Zimbabwe\nReferences /Sources for further reading\nChristensen et al. 2007. Regional climate projections. Climate Change 2007: The Physical Science Basis. WGI 4AR IPCC.\nLobell et al. 2008. Prioritizing climate change adaptation needs for food security in 2030. Science, 319, 607-610.\nParry et al. 2004. Effects of climate change on global food production under SRES emissions and socio-economic scenarios. Global Environmental Change, 14, 53-67.\nParry et al. 2009. Climate change and hunger: responding to the challenge. WFP.\nWorld Bank et al. 2011. Missing Food: the case of postharvest grain losses in sub-Saharan Africa.']	['<urn:uuid:751029b1-c82f-42aa-bd3f-a4f284388679>', '<urn:uuid:85fb10be-8a71-4532-bd58-00c1d05772e3>']	open-ended	with-premise	short-search-query	similar-to-document	three-doc	expert	2025-05-13T06:27:57.068978	6	105	2184
47	amount grant robert j trulaske jr family foundation streambank restoration huzzah creek	The Robert J. Trulaske, Jr. Family Foundation provided a $100,000 grant for streambank restoration along Huzzah Creek.	['Ozark Land Trust (www.ozarklandtrust.org), a Missouri nonprofit organization, has received a generous $100,000 grant from the Robert J. Trulaske, Jr. Family Foundation for streambank restoration along Huzzah Creek, a major tributary of the Meramec River.\nThe Huzzah Creek watershed, with its crystal clear spring-fed streams, rich plant and animal life is one of the most biologically intact and functioning landscapes within the Meramec River Basin. It also serves as the home to farmers who graze cattle and grow hay, and to those who enjoy the kayak and floating recreation for which the Ozarks are so well known.\n“We are grateful to the Trulaske Foundation for trusting and enabling Ozark Land Trust to protect and improve the health of the Huzzah and Meramec watersheds,” said Larry Levin, Executive Director of OLT. “This support builds upon our partnership with landowners, agencies and other nonprofits to protect the immense beauty and value of the land and waters, and at the same time meet the needs and goals of farmers and ranchers, whose homes and livelihoods depend on the creek’s health and stability.”\nStreambank erosion is of vital concern for landowners in the watershed. Valuable land is washed into streams, filling in pools and reducing aquatic habitat for fish and wildlife. The Foundation’s grant, along with support from other funders, will enable OLT and its partners to stabilize and restore almost a mile along Huzzah Creek, as well as implement numerous other conservation practices.\n“Our Foundation is grateful for the leadership of the Ozark Land Trust and the support of all partners involved in this effort to reverse the effects of erosion and protect habitat along the Huzzah,” said Jeanne Trulaske Dalba, President of the Robert J. Trulaske, Jr. Family Foundation.\nOLT has worked in tandem with the Missouri Department of Conservation, The Nature Conservancy-Missouri Chapter, and a landowners’ committee that includes a variety of residents within the watershed. The groups have built strong relationships over the last 15 years, and a cooperative structure that has been effective in other Missouri watersheds as well.\nIn addition to administering the Foundation’s grant, OLT also holds five conservation easements on more than 500 acres in the Huzzah Creek watershed. Conservation easements keep land in pri- vate hands but prevent intense development, while allowing many productive uses, such as farming, ranching and forestry, to continue. A land trust such as OLT serves as steward of the easements, permanently safeguarding the lands’ important conservation values.\nOzark Land Trust is a nonprofit, tax-exempt organization that works with landowners and partners to protect resources across the Ozark bioregion. A nationally accredited land trust, OLT current protects more than 30,000 acres of forests, farmlands and other natural landscapes for both public and private use. More information can be found at ozarklandtrust.org, on our Facebook Page, on Instagram and Twitter at @ozarklandtrust.\nBefore and After Restoration Photos:\nAn example of a pre-restoration site in the Huzzah Creek watershed. Photo by: Steve Herrington, The Nature Conservancy-Missouri Chapter. Photo may be used with credit\nAn example of completed streambank restoration along Huzzah Creek. The Trulaske grant will fund substantial additional work like this. Photo by: Rob Pulliam, Missouri Department of Conservation. Photo may be used with credit.']	['<urn:uuid:d9721dab-6aa4-449d-80d3-08414827f2ee>']	factoid	direct	long-search-query	similar-to-document	single-doc	expert	2025-05-13T06:27:57.068978	12	17	533
48	As a museum architectural consultant, I'm intrigued by the Len Lye Centre's design philosophy and functionality - how does its unique façade design contribute to both the building's artistic purpose and its practical exhibition capabilities?	The Len Lye Centre's façade is a sophisticated integration of form and function that serves multiple purposes. The exterior features 20 monolithic 14-meter-high curved concrete columns clad in highly polished stainless steel, which creates a shimmering, light-reflecting surface. This design directly connects to Len Lye's artistic philosophy, as he used light as his primary medium. The façade's deeply pocketed shape creates multiple reflections that attract visitors while also transferring light in a holographic effect. Inside, the colonnade functions as a theater curtain, creating moving light patterns on the walkway - a form of passive kinetic architecture that complements the museum's focus on kinetic art and experimental projection. The building successfully houses various kinetic sculptures and experimental works, such as Lye's 'Zebra' piece and contemporary installations by artists like Rebecca Baumann, whose work explores color and light effects through different materials.	"['ARCHICAD 20’s shimmering signature building, the Len Lye Centre, is New Zealand’s only single artist museum. Its design is deeply influenced by the life, ideas, writings and work of the famous New Zealand Kinetic Artist, Len Lye (1901–1980).\nLocation: New Plymouth, New Zealand\nCost: AUD 11.5m, USD 8.3m\nYear of Completion: 2016\nSize: 3,000 sqm | 32,292 sqft\nArchitect: Patterson Associates\n- GRAPHISOFT ARCHICAD\n- GRAPHISOFT BIMx\n- Revit Structures\n- Revit MEP\n- 3ds Max\nLye himself said in 1964, that “great architecture goes fifty-fifty with great art.” The building’s design articulates this philosophy – he believed an artwork was a piece of consciousness communicating with the future. He used light as his primary medium.\nThe Len Lye Centre is situated in Taranaki, New Zealand, a region known for its stainless steel production industries. The 3,000 sqm (32,292 square feet) building engages with the urban square via a light reflecting and transmitting façade. This transfers light in a holographic effect from one place to another to enliven and activate both.\nPhoto ©Patrick Reynolds\n“[Len Lye would] be absolutely thrilled, he’d be dancing around in this place.” John Matthews, Chairman, Len Lye Foundation\nThe Len Lye Centre is designed to fulfil multiple requirements. It needed to integrate with a proposed new art and cultural precinct, which links through to the commercial heart of the city. It also needed to seamlessly merge with an existing heritage Art Gallery facility in a converted movie theater. The finished building introduces new gallery spaces, education studios, a 62 seat cinema, the Len Lye Archive and a dedicated motor room for his kinetic works. The resulting space is reverential, creating a sensory experience from light as a ‘temple’ for art.\n“Lye was fascinated with temples and in conceiving the overall design it seemed appropriate to draw inspiration from the “megarons, or great halls, of the classical world, as well as from Polynesian forms and ideas. These ideas also influenced Lye. To do this, we developed our thinking in a holistic or adaptive way; as a systems methodology. This ment that rather than using proportion or aesthetics, we used patterns in the ecology of the project’s environments to drive the design elements. For example, the shimmering, iridescent colonnade façade is manufactured locally using stainless steel - Taranaki’s ‘local stone’ – this links both Lye’s innovations in kinetics and light as well as the region’s industrial innovation. So by using stainless steel we can celebrate and communicate to visitors the reason for the fortunate gift of his art works to Taranaki.”\nsays Andrew Patterson, director, Patterson Associates\nPatterson Associates | Photo ©Davor Popadich\nThe façade’s deeply pocketed shape provides a series of images or reflections and attracts people to the facility as a result. Viewed from above, the colonnade’s top edges create a local koru form, displaying the Museum’s Polynesian influences.\nInside the building, the colonnade creates a theater curtain, with three asymmetric ramped sides embracing the space of a processional journey ascending along a ramp into various galleries. There are divisions in the circulation. Light is drawn inside through the apertures in the colonnade, and these create moving light patterns on the walkway, perhaps a form of passive kinetic architecture.\nTeamwork and the modern colonnade\nPatterson Associates’ 28-member team is united and motivated by architectural innovation, bringing their diverse expertise together to collaborate. A broad range of disciplines come together in their architectural work. Each project comes from selecting individual talents to create the right ‘super team’ for particular projects. For the Len Lye Centre, four out of the practice’s 14 ARCHICAD users formed the super team working together closely using ARCHICAD’s Teamwork.\nThe façade of the len Lye Centre consists of 20 monolithic 14 meter-high curved, pre-cast concrete columns. Their exterior surfaces are clad in highly polished stainless steel curtains with glazing hidden in between each column. The shapes of the columns are designed to reflect light through these into the building according to the time of day and reflect light back out at night. Scale, materials, light and atmosphere are composed as in a film to activate the senses and incite a poetic dimension. The façade acts as a kind of living object connecting the outer and inner spaces it divides.\nStarting the project in 2010 with ARCHICAD 14, the design team’s biggest challenge was the modeling of this façade. Due to the complexity of the geometry they used Rhino to model single façade shapes, then exported to ARCHICAD to link the modules together. Later, when ARCHICAD 15 and 16 were introduced, the façade was remodeled using the Shell and Morph tools.\n“Using the Teamwork file has always been fantastic; the late change of color code identity message within Teamwork is great.” Shane Taylor, BIM Manager, Pattersons\nThe design team built a detailed, live, 3D model, integrating the 3D structural and MEP elements as well. This model was used to extract all of the project documentation, to communicate the design intent towards the client, and to clarify construction issues during the two years of construction.\n“BIM is a tool that we use to communicate with stakeholders, with the builders, with everybody connected to the project. It’s a leadership tool that enables us to deliver the project.” Andrew Patterson, Director\nThe role of OPEN BIM in the design and construction\nPattersons recognized early on the importance of a strong OPEN BIM foundation for their design and construction workflows.\nOPEN BIM was fundamental in working out the complex geometry of the building in three dimensions, ensuring a seamless transition between consultants from design to manufacture.\nOnce the geometry of the façade was ready in ARCHICAD, it was exported to Ecotect 2011 in conjunction with Radiance to document sun path reflections. The architectural model of the colonnade columns was transferred directly to the pre-cast manufacturers, while the light transferring effect was tested on site with real size sample elements.\nSetting protocols early in the project between BIM managers of each consultant was key. As this was a test project using the IFC translator for some of the consultants, a number of demo models were exchanged between consultants to confirm that future exchanges would be seamless. OPEN BIM data exchange was implemented and data shared on a weekly basis.\nIFC import-export for mechanical and structural work was critical to the success of the project. The imported mechanical and structural models remained in the architectural model for reference only (hidden layer), then the structural engineers concrete components and the MEP elements were re-imported into the model and took precedence on the BIM model.\nThe final model was exported to SketchUp to allow the Gallery staff to place artwork within the building, forward planning the exhibitions two years before the gallery actually opened. For rendering and animations, the model was exported to 3ds Max of Autodesk.\n“The function of IFC open file format has greatly eased the collaboration process between the architect and the engineers.” Shane Taylor BIM Manager, Pattersons\nBIMx on the construction site\nSince the Len Lye Centre was fully modeled, it was an easy and natural step to generate a BIMx model from it containing all the 2D information available in the model. Patterson Associates has used BIMx since the day it first came on the market.\n“The Len Lye Centre’s BIMx model was used during site inspections, while the builders used it when making site rounds, allowing them to visualize the building three dimensionally when resolving complete junctions. And the tool also came in handy when the client required simulations on how the designed museum spaces would work in specific event scenarios.” Says Shane Taylor, BIM Manager, Pattersons.\n“This is a fantastic tool that openly and interactively explores 3D Building Information Models on mobile devices. It saves us from having to carry big paper files to the site!” Shane Taylor BIM Manager, Pattersons\nValue management with ARCHICAD\nAn art gallery project always requires a highly-serviced environment, resulting in very high MEP – mainly HVAC – costs, which can be as high as 25% of the total building cost. ARCHICAD was indispensable when Pattersons value-managed the project due to funding difficulties they were able to coordinate the various HVAC engineers and sub-consultants to reduce that cost significantly just by the way the ducting worked through the building.\nThe very strict international artwork loan standards narrow down the environmental range the museum has to comply with. With an art museum this size, this usually means two to three plant rooms. Once Pattersons decided to move from the initially planned two plant rooms to one, they could implement this change very quickly via the exchange process between consultants, saving a major portion of the building budget.\nBy using state-of-the-art BIM tools, Patterson Associates have created a concept design that has resulted in a breathtaking, inspiring building, reaching far beyond the borders of New Zealand. Tasked with a number of requirements, the Len Lye Centre is a building for the future, firmly rooted in the community and the vision of the artist who inspired it.\nAbout Patterson Associates\nCongratulations to Andrew Patterson for winning the New Zealand Institute of Architects 2017 Gold Medal!\nPatterson Associates is a New Zealand practice. Its philosophy is based on a very simple idea: if a building can feel like it naturally ‘belongs,’ or fits logically in a place, to an ecology, a time and culture, then the people that inhabit the building will likely feel a sense of belonging there as well. This methodology connects theories of beauty and environment. As well as its New Zealand work, Patterson’s have clients and projects as far afield as India, Singapore, Australia, Germany and China.', ""Design is a static, unmoving thing – at least until we ourselves cause the thing to move. But is that necessarily true?\nA new exhibition in New Plymouth is challenging this prevailing belief. Starting from the work of late New Zealand artist Len Lye, the Govett-Brewster Art Gallery presents Set in Motion, with work by four artists working in the field of kinetic sculpture and experimental projection.\nRoss Manning 'Six Short Films' 2016. Installation view at the Govett-Brewster Art Gallery/Len Lye Centre.\nAside from the work of Lye (who was born in 1901, and died in 1980), the exhibition presents kinetic sculpture, projection and live performances by artists Rebecca Baumann (Australia), Žilvinas Kempinas (Lithuania and the United States), Taree Mackenzie (Australia) and Ross Manning (Australia). The exhibition, which runs until 27 November, considers how artists today experiment with everyday technical and industrial objects and materials in their explorations of movement, light and sound.\nDirector Simon Rees says, “Len had it right when he famously said that his ‘work was looking pretty good for the 21st century’, as his kinetic sculpture Zebra looks right at home alongside this spectacular group of objects made today.”\nŽilvinas Kempinas 'O2' 2006, magnetic tape, fan. Private Collection. Courtesy of the artist and Lio Malca, New York.\nExhibition curator Sarah Wall says the show celebrates the talents of a visionary New Zealand artist whose sculptures and films continue to resonate and excite more than three decades after his passing. “It inspires us to consider how Lye’s work continues to be a catalyst and source of inspiration for artists today,” she says.\nThe exhibition will also push people towards sensory overload because of the dynamic play of colour, light and sculptures moving in space, Wall says. “Len Lye was an artist who constantly pushed the boundaries of his practice, experimenting with new materials, techniques and technology in his attempts to make motion ‘tangible’. One of Lye’s great skills was his resourcefulness and inventiveness in adapting tools and techniques to his own creative ends.”\nLye came to prominence through his experimental film and kinetic sculpture. In Lye’s Zebra (1965, 2009), a fibreglass rod spins and swirls into constantly changing figures and patterns of motion. “Color Cry (1952-53) was the first direct film Lye made while living in New York’s Greenwich Village,” explains Wall. “Made by applying his own photogram techniques to film, Color Cry is much more than a film of colour and movement, it’s a play of shadow and light.”\nLen Lye 'Zebra' 1965 (2009 reconstruction) details. Len Lye Foundation Collection. Courtesy of the Govett-Brewster Art Gallery/Len Lye Centre. Photography Sarah Dalle Nogare.\nCentral to Rebecca Baumann’s practice is her interest in colour and its effect and transference through different materials. In her kinetic sculpture Once More with Feeling (2014), Baumann replaced aluminium prisms of a tri-vision billboard with transparent panels of plexiglass so that, when spot lit, lines of coloured light are cast around the space.\nThe other artists at the exhibition also boast some impressive accolades. Žilvinas Kempinas is a Calder Prize winner and has had works installed at major museums all over the world. His sculptures, made from tape unspooled from old VHS tapes, almost seem to defy gravity and logic by making the tape dance and fly through the air thanks to the breeze from nearby fans.\nUsing video equipment and props, Taree Mackenzie makes illusory images and environments. Viewers find it hard to match the image they see to the equipment producing it. In Black Line Formation (2013), an abstract play of lines moves and intersects across a white screen. Nearby on the floor is a hand-cam, a light box, and a small geometric structure on top of a slowly spinning turntable. The purpose of them is to make these “everyday” objects the things that power the projection.\nRebecca Baumann 'Once More with Feeling' 2016. Installation view at the Govett-Brewster Art Gallery/Len Lye Centre. Photo Glenn Jeffery.\nRoss Manning adapts and reuses everyday objects and technology to create kinetic sculptures that produce old school sci-fi visual effects. For Set in Motion, he presents a new kinetic sculpture based on his research in the Len Lye Foundation Collection and Archive.\nAside from the kinetic sculptures, Set in Motion also includes drawings and sketches that give an insight into the artists’ thinking and working. There’s also a catalogue featuring commissioned essays by Amelia Groom, Adam Jasper, Hannah Mathews, Patrice Sharkey and Danni Zuvela.\nThe takeaway from all this: kinetic design is very much a part of our world today. All we have to do to notice it, it seems, is to stop moving ourselves.""]"	['<urn:uuid:fc9c8972-b764-43ac-99d9-559b9a3ea53b>', '<urn:uuid:61a88d2b-c718-442e-8613-940025631201>']	open-ended	with-premise	verbose-and-natural	similar-to-document	three-doc	expert	2025-05-13T06:27:57.068978	35	140	2378
49	chamomile tea dosage side effects pregnancy	Adults can drink 3-4 cups of chamomile tea daily between meals, using 2-4 grams of dried herb per cup steeped for 10-15 minutes. However, pregnant women should avoid chamomile as it may lead to miscarriage. Side effects can include vomiting when consumed in high concentrations and allergic reactions in people sensitive to related plants like daisies and ragweed.	"['Anthemis arvensis, Anthemis cotula, Anthemis nobile, Anthemis nobilis, Anthemis xylopoda, apigenin, Asteraceae/Compositae (family), baboonig, babuna, babunah, babunah camomile, babunj, bunga kamil, camamila, camamilla, camomile, camomile sauvage, camomilla, Camomille Allemande, Campomilla, chamaemeloside, Chamaemelum nobile L., chamomile flowers, Chamomilla, Chamomilla recutita, chamomillae ramane flos, chamomille commune, classic chamomile, common chamomile, double chamomile, Echte Kamille (Dutch), English chamomile, feldkamille (German), fleur de chamomile (French), fleurs de petite camomille (French), Flores Anthemidis, flos chamomillae, garden chamomile, German chamomile, Grosse Kamille, Grote Kamille, ground apple, Hungarian chamomile, Kamille, Kamillen, kamitsure, kamiture, Kleine, kleme kamille, lawn chamomile, low chamomile, manzanilla, manzanilla chiquita, manzilla comun, manzanilla dulce, matricaire, Matricaria chamomilla, Matricaria maritime (L.), Matricaria recutita, Matricaria suaveolens, matricariae flos, matricariae flowers, may-then, Nervine, pin heads, rauschert, Romaine, romaine manzanilla, Roman chamomile, Romische Kamille, single chamomile, STW 5 (containing Iberis, peppermint, chamomile), sweet chamomile, sweet false chamomile, sweet feverfew, true chamomile, whig-plant, wild chamomile.\nChamomile has been used medicinally for thousands of years and is widely used in Europe. It is a popular treatment for numerous ailments, including sleep disorders, anxiety, digestion/intestinal conditions, skin infections/inflammation (including eczema), wound healing, infantile colic, teething pains, and diaper rash. In the United States, chamomile is best known as an ingredient in herbal tea preparations advertised for mild sedating effects.\nGerman chamomile (Matricaria recutita) and Roman chamomile (Chamaemelum nobile) are the two major types of chamomile used for health conditions. They are believed to have similar effects on the body, although German chamomile may be slightly stronger. Most research has used German chamomile, which is more commonly used everywhere except for England, where Roman chamomile is more common.\nAlthough chamomile is widely used, there is not enough reliable research in humans to support its use for any condition. Despite its reputation as a gentle medicinal plant, there are many reports of allergic reactions in people after eating or coming into contact with chamomile preparations, including life-threatening anaphylaxis.\nThese uses have been tested in humans or animals. Safety and effectiveness have not always been proven. Some of these conditions are potentially serious, and should be evaluated by a qualified healthcare provider.\nChamomile is not well-known for its cardiac effects, and there is little research in this area. Large, well-designed randomized controlled trials are needed before a firm conclusion can be made.\nIn early study, inhaling steam with chamomile extract has been reported to help common cold symptoms. Further research is needed to confirm these results.\nDiarrhea in children\nPreliminary study reports that chamomile with apple pectin may reduce the length of time that children experience diarrhea. Further research is needed before a strong recommendation can be made.\nThe German Commission E authorizes the use of topical chamomile for diseases of the skin. However, little research has been done on topical chamomile for eczema and further research is needed.\nChamomile is used traditionally for numerous gastrointestinal conditions, including digestion disorders, ""spasm"" or colic, upset stomach, flatulence (gas), ulcers, and gastrointestinal irritation. However, currently there is a lack of reliable human research available in any of these areas. Additional study is needed.\nHemorrhagic cystitis (bladder irritation with bleeding)\nPreliminary study reports that the combination of chamomile baths plus chamomile bladder washes and antibiotics is superior to antibiotics alone for hemorrhagic cystitis. Additional research is necessary before a conclusion can be reached.\nPreliminary study reports that chamomile ointment may improve hemorrhoids. Better evidence is needed before a strong recommendation can be made.\nChamomile is reputed to have anti-spasmodic activity, but there is little research to substantiate this claim. Additional research evaluating chamomile alone is needed.\nMucositis from cancer treatment (mouth ulcers/irritation)\nPoor-quality studies have used chamomile mouthwash for the prevention or treatment of mouth mucositis caused by radiation therapy or cancer chemotherapy. Results are conflicting, and it remains unclear if chamomile is helpful in this situation.\nQuality of life in cancer patients\nA small amount of research suggests that massage using chamomile essential oil may improve anxiety and quality of life in cancer patients. However, this evidence is not high quality. Additional study is needed before a firm conclusion can be reached.\nTopical chamomile preparations have traditionally been used to soothe skin inflammation. The existing human evidence shows that chamomile may be of little, if any, benefit while animal studies support its anti-inflammatory action. Additional human research is needed in this area.\nSleep aid / sedation\nTraditionally, chamomile preparations, such as tea and essential oil aromatherapy, have been used for insomnia and sedation (calming effects). Better research is needed before a recommendation can be made.\nVaginitis (inflammation of the vagina)\nVaginitis may involve itching, discharge, or pain with urination. Chamomile douche may improve symptoms of vaginitis with few side effects. Because infection (including sexually transmitted diseases), poor hygiene, or nutritional deficiencies can cause vaginitis, medical attention should be sought by people with this condition. Better research is needed before a conclusion can be drawn regarding the role of chamomile in the management of vaginitis.\nThere is promising preliminary evidence supporting the topical use of chamomile for wound healing. However, the available literature is not adequate to support a recommendation either for or against this use.\nPost-operative sore throat/hoarseness due to intubation\nChamomile spray has not been found to prevent post-operative sore throat and hoarseness any more than normal saline.\n*Key to grades:\nA: Strong scientific evidence for this use;\nB: Good scientific evidence for this use;\nC: Unclear scientific evidence for this use;\nD: Fair scientific evidence against this use (it may not work);\nF: Strong scientific evidence against this use (it likely does not work).\nThe below uses are based on tradition, scientific theories, or limited research. They often have not been thoroughly tested in humans, and safety and effectiveness have not always been proven. Some of these conditions are potentially serious, and should be evaluated by a qualified healthcare provider. There may be other proposed uses that are not listed below. Abdominal bloating, abortifacient, abrasions, abscesses, acne, anorexia, antibacterial, anticoagulant, antifungal, antioxidant, antipruritic, antispasmodic, antiseptic, anxiety, aromatic, arthritis, asthma, back pain, bedsores, bladder disorders, blood purification, bruises, burns, cancer, canker sores, carpal tunnel syndrome, catarrh, chicken pox, constipation, contact dermatitis, cough, Crohn\'s disease, croup, delirium tremens (DTs), diaper rash, diaphoretic, diuretic (increasing urination), diverticulitis, dry skin, dysmenorrhea (painful menstruation), ear infections, eye disorders (blocked tear ducts), eye infections, fatty liver, fever, fistula healing, frostbite, gallstones, gingivitis, gout, hay fever, headaches, heartburn, hives, hypoglycemia (low blood sugar), hysteria, impetigo, inflammatory conditions, insect bites, insomnia, intestinal cramps, irregular menstrual cycles, irritable bowel syndrome, kidney disorders, leg ulcers, liver disorders, low back pain, malaria, mastitis (breast inflammation), menopause, menstrual cramps, menstrual disorders, morphine withdrawal, motion sickness, muscle strength, nasal inflammation, nausea, nervous stomach, neuralgia (nerve pain), nightmares, oral hygiene (mouthwash), osteoporosis, parasites/worms, peptic ulcers, perineal trauma, poison ivy, post-natal depression, psoriasis, rash (heat), respiratory inflammatory, restlessness, rheumatism, Roehmheld\'s syndrome, sciatica, seizure disorder, sinusitis, stomach cramps, sunburn, sunstroke, teething pain (mouth rinse), tension, tics, toothache, travel sickness, tuberculosis, ulcerative colitis, ulcers, uterine disorders, uterine stimulant, uterine tonic, vaginal infections, viral infection (flu-like symptoms or polio), vomiting, vomiting/nausea during pregnancy.\nThe below doses are based on scientific research, publications, traditional use, or expert opinion. Many herbs and supplements have not been thoroughly tested, and safety and effectiveness may not be proven. Brands may be made differently, with variable ingredients, even within the same brand. The below doses may not apply to all products. You should read product labels, and discuss doses with a qualified healthcare provider before starting therapy.\nAdults (18 years and older)\nCapsules/tablets containing 400 to 1,600 milligrams in divided doses have been taken by mouth daily. As a liquid extract (1:1 in 45% alcohol), 1 to 4 milliliters three times daily has been taken by mouth. As a tincture (1:5 in alcohol), 15 milliliters three to four times per day has been used. As a mouth rinse, a 1% fluid extract or 5% tincture has been used.\nChamomile is frequently consumed as tea, and 1 to 4 cups of chamomile tea taken daily (from tea bags) is a common dose.\nThere are no standard doses for chamomile used on the skin. Some natural medicine publications have recommended paste, plaster, or ointment containing 3% to 10% chamomile flower heads. Chamomile has been also used as a bath additive and as a douche.\nChildren (younger that 18 years)\nThere is not enough reliable scientific data available to recommend the safe use of chamomile products in children.\nThe U.S. Food and Drug Administration does not strictly regulate herbs and supplements. There is no guarantee of strength, purity or safety of products, and effects may vary. You should always read product labels. If you have a medical condition, or are taking other drugs, herbs, or supplements, you should speak with a qualified healthcare provider before starting a new therapy. Consult a healthcare provider immediately if you experience side effects.\nThere are multiple reports of serious allergic reactions to chamomile taken by mouth or as an enema, including anaphylaxis, throat swelling, and shortness of breath. Skin allergic reactions have been frequently reported, including dermatitis and eczema. Chamomile eyewash can cause allergic conjunctivitis (pinkeye).\nPeople with allergies to other plants in the Asteraceae (Compositae) family should avoid chamomile. Examples include: aster, chrysanthemum, mugwort, ragweed, and ragwort. Cross-reactions may occur with celery, chrysanthemum, feverfew, tansy, and birch pollen. Individuals with allergies to these plants should avoid chamomile. Contact skin allergy has been reported.\nImpurities (adulterants) in chamomile products are common and may cause adverse effects. Atopic dermatitis (skin rash) has been reported.\nChamomile in various forms may cause drowsiness or sedation. Use caution when driving or operating heavy machinery. In large doses, chamomile can cause vomiting. Due to its coumarin content, chamomile may theoretically increase the risk of bleeding. Caution is advised in patients with bleeding disorders or taking drugs that may increase the risk of bleeding. Dosing adjustments may be necessary. Increases in blood pressure are possible.\nPregnancy and Breastfeeding\nIn theory, chamomile may act as a uterine stimulant or lead to abortion. It therefore should be avoided during pregnancy. There is not enough scientific data to recommend the safe use of chamomile while breastfeeding.\nMost herbs and supplements have not been thoroughly tested for interactions with other herbs, supplements, drugs, or foods. The interactions listed below are based on reports in scientific publications, laboratory experiments, or traditional use. You should always read product labels. If you have a medical condition, or are taking other drugs, herbs, or supplements, you should speak with a qualified healthcare provider before starting a new therapy.\nInteractions with Drugs\nChamomile interactions are not well studied scientifically.\nChamomile may increase the amount of drowsiness caused by some drugs. Examples include benzodiazepines such as lorazepam (Ativan©) or diazepam (Valium©), barbiturates such as phenobarbital, narcotics such as codeine, some antidepressants, and alcohol. Caution is advised while driving or operating machinery.\nIn theory, chamomile may increase the risk of bleeding when used with anticoagulants or antiplatelet drugs. Some examples include aspirin, anticoagulants (""blood thinners"") such as warfarin (Coumadin©) or heparin, anti-platelet drugs such as clopidogrel (Plavix©), and non-steroidal anti-inflammatory drugs (NSAIDs) such as ibuprofen (Motrin©, Advil©) or naproxen (Naprosyn©, Aleve©).\nChamomile may interfere with the way the body processes certain drugs using the liver\'s ""cytochrome P450"" enzyme system. As a result, the levels of these drugs may be increased in the blood and may cause increased effects or potentially serious adverse reactions. Patients using any medications should check the package insert and speak with a healthcare professional including a pharmacist about possible interactions.\nBe aware that many tinctures contain high levels of alcohol and may cause vomiting when taken with metronidazole (Flagyl©) or disulfiram (Antabuse©).\nAn extract containing Matricaria chamomile, Sideritis euboea, Sideritis clandestine, and Pimpinella anisum was associated with selective estrogen receptor modulator (SERM) properties against osteoporosis. Theoretically, chamomile may interact with SERM drugs like raloxifene (prescription drug used for osteoporosis) or tamoxifen (a prescription drug used for cancer).\nConstituents in chamomile may alter blood sugar or blood pressure. Patients taking medications that affect blood sugar or blood pressure should be cautious.\nChamomile may have anti-inflammatory effects. Theoretically, use of chamomile with other anti-inflammatory drugs, such as NSAIDs or ibuprofen, may have additive effects.\nChamomile may interact with medications that act as cardiac depressants, central nervous system depressants, calcium channel blockers, cardiac glycosides, and respiratory depressants.\nChamomile may also interact with antibiotics, antifungals, antihistamines, diuretics, as well as drugs for high cholesterol, ulcers, diarrhea, or gastrointestinal disorders.\nInteractions with Herbs and Dietary Supplements\nChamomile may increase the amount of drowsiness caused by some herbs or supplements. Caution is advised while driving or operating machinery.\nIn theory, chamomile may increase the risk of bleeding when taken with other products that are believed to increase the risk of bleeding. Multiple cases of bleeding have been reported with the use of Ginkgo biloba, and fewer cases with garlic and saw palmetto. Numerous other agents may theoretically increase the risk of bleeding, although this has not been proven in most cases.\nChamomile may interfere with the way the body processes certain drugs using the liver\'s ""cytochrome P450"" enzyme system. As a result, the levels of other herbs or supplements may become too high in the blood. It may also alter the effects that other herbs or supplements possibly have on the P450 system. Patients using any medications should check the package insert and speak with a healthcare professional including a pharmacist about possible interactions.\nChamomile may have anti-estrogenic effects and interact with herbs and supplements like red clover or soy.\nBased on preliminary study, constituents in chamomile may alter blood sugar or blood pressure. Patients taking herbs or supplements that affect blood sugar or blood pressure should be cautious.\nChamomile may have anti-inflammatory effects. Theoretically, the use of chamomile with other anti-inflammatory herbs and supplements may have additive effects.\nChamomile may interact with herbs and supplements that act as cardiac depressants, cardiac glycosides, respiratory depressants, or spasmolytics.\nChamomile may also interact with antibacterial, antifungal, antihistamine, or diuretic herbs and supplements, as well as herbs and supplements used for high cholesterol, ulcers, diarrhea, or gastrointestinal disorders.\nThis information is based on a systematic review of scientific literature edited and peer-reviewed by contributors to the Natural Standard Research Collaboration (www.naturalstandard.com).\nNatural Standard Bottom Line Monograph, Copyright © 2011 (www.naturalstandard.com). Commercial distribution prohibited. This monograph is intended for informational purposes only, and should not be interpreted as specific medical advice. You should consult with a qualified healthcare provider before making decisions about therapies and/or health conditions.\nWhile some complementary and alternative techniques have been studied scientifically, high-quality data regarding safety, effectiveness, and mechanism of action are limited or controversial for most therapies. Whenever possible, it is recommended that practitioners be licensed by a recognized professional organization that adheres to clearly published standards. In addition, before starting a new technique or engaging a practitioner, it is recommended that patients speak with their primary healthcare provider(s). Potential benefits, risks (including financial costs), and alternatives should be carefully considered. The below monograph is designed to provide historical background and an overview of clinically-oriented research, and neither advocates for or against the use of a particular therapy.\nThe information in this monograph is intended for informational purposes only, and is meant to help users better understand health concerns. Information is based on review of scientific research data, historical practice patterns, and clinical experience. This information should not be interpreted as specific medical advice. Users should consult with a qualified healthcare provider for specific questions regarding therapies, diagnosis and/or health conditions, prior to making therapeutic decisions.\n- Aertgeerts P, Albring M, Klaschka F, et al. [Comparative testing of Kamillosan cream and steroidal (0.25% hydrocortisone, 0.75% fluocortin butyl ester) and non-steroidal (5% bufexamac) dermatologic agents in maintenance therapy of eczematous diseases]. Z Hautkr 2-1-1985;60(3):270-277.\n- Benetti C, Manganelli F. [Clinical experiences in the pharmacological treatment of vaginitis with a camomile-extract vaginal douche]. Minerva Ginecol 1985;37(12):799-801.\n- de la Torre MF, Sanchez MI, Garcia Robaina JC, et al. Clinical cross-reactivity between Artemisia vulgaris and Matricaria chamomilla (chamomile). J Investig Allergol Clin Immunol 2001;11(2):118-122.\n- Glowania HJ, Raulin C, Swoboda M. [Effect of chamomile on wound healing—a clinical double-blind study]. Z Hautkr 9-1-1987;62(17):1262, 1267-1271.\n- Hormann H, Korting H. Evidence for the efficacy and safety of topical herbal drugs in dermatology: part 1: anti-inflammatory agents. Phytomedicine 1994;1(2):161-171.\n- Ikram M. Medicinal plants as hypocholesterolemic agents. J Pak Med Assoc 1980;30(12):278-281.\n- Konig GM, Wright AD, Keller WJ, et al. Hypoglycaemic activity of an HMG-containing flavonoid glucoside, chamaemeloside, from Chamaemelum nobile. Planta Med 1998;64(7):612-614.\n- Kyokong O, Charuluxananan S, Muangmingsuk V, et al. Efficacy of chamomile-extract spray for prevention of post-operative sore throat. J Med Assoc Thai 2002;85 Suppl 1:S180-S185.\n- Maiche A, Grohn P, Maki-Hokkonen H. Effect of chamomile cream and almond ointment on acute radiation skin reaction. Acta Oncol 1991;30:395-397.\n- Maiche A, Maki-Kokkonen H, Grohn P. [Comparative trial of chamomile cream in radiotherapy]. Suomen Laakarilehti 1991;46(24):2206-2208.\n- Patzelt-Wenczler R, Ponce-P©schl E. Proof of efficacy of Kamillosan cream in atopic eczema. Eur J Med Res 2000;5:171-175.\n- Rycroft RJ. Recurrent facial dermatitis from chamomile tea. Contact Dermatitis 2003;48(4):229.\n- Saller R, Beschomer M, Hellenbrecht D, et al. Dose dependency of symptomatic relief of complaints by chamomile steam inhalation in patients with common cold. Eur J Pharmacol 1990;183:728-729.\n- Weizman Z, Alkrinawi S, Goldfarb D, et al. Efficacy of herbal tea preparation in infantile colic. J Pediatr 1993;122(4):650-652.\n- Wilkinson S, Aldridge J, Salmon I, et al. An evaluation of aromatherapy massage in palliative care. Palliat Med 1999;13(5):409-417.\nCopyright © 2011 Natural Standard (www.naturalstandard.com)\nCopyright © 2011 Natural Standard (www.naturalstandard.com)', '- German Chamomile Scientific Name\n- Other Names for German Chamomile\n- German Chamomile Description\n- German Chamomile Cultivation\n- Matricaria recutita Range of Distribution\n- Matricaria recutita Uses\n- Matricaria recutita Health Benefits\n- Dosage of Matricaria recutita\n- Side Effects of Matricaria recutita\n- Profile of German Chamomile in Homeopathy\n- German Chamomile Drug Interactions\n- Where to buy German Chamomile\n- German chamomile pictures\nGerman chamomile is an annual plant belonging to the Asteraceae family. The flower is known for its medicinal properties. The flower is grown in many parts of the world, such as Europe and Asia.\nGerman Chamomile Scientific Name\nThe scientific name for this plant is “Matricaria recutita”.\nOther Names for German Chamomile\nThe flower is also known by several other names such as\nPicture 1 – German chamomile\n- Matricaria suaveolens\n- Matricaria chamomilla\n- Chamomilla recutita\n- Chamomilla chamomilla\n- Blue Chamomile\n- Camomille Allemande\n- Echte Kamille\n- Fleur de Camomile\n- Hungarian Chamomile\n- Kleine Kamille\n- Manzanilla Alemana\n- Matricariae Flos\n- Pin Heads\n- Sweet False Chamomile\n- True Chamomile\n- Wild Chamomile\nGerman Chamomile Description\nThe German Chamomile plant has small and dainty flowers that look much like daisies. These flowers are arranged in paniculate capitula. The white ray-like petals are all spread around a raised disc-shaped yellow center. The florets are equipped with a ligule. The width of a petal is less than one inch. The flower receptacle is swollen, hollow and lacking in scales. The stems on which the flowers grow are long, smooth and thin and light green in color. The stem has several branches. The narrow and long leaves are tripinnate or bipinnate. Sometimes these plants can grow near the ground and at other times they can be found in herb gardens. The plant can reach up to a height of 3 feet. The flowers of this plant have a sweet fragrance. German chamomile plant has a fibrous root system.\nGerman Chamomile Cultivation\nGerman Chamomile seeds require light for germination. Hence it is a delicate process to grow these plants from seed. Generally direct seeding is used to cultivate these plants. For proper growth and survival, the seeds need to be grown on open soil. It is important that seeds of superior quality are sown for vegetative propagation. The growing season lasts for two months. The seeds take one or two weeks to germinate. Seeds can be planted outdoors around the month of August. Alternatively, these plants can be grown initially in propagation trays around March. The number of seeds per gram of soil should range between 10,000 and 18,000. After the plants reach a certain level of maturity, they can be shifted to outdoors. Spraying chamomile tea on the plants aids in calcium absorption from the compost piles where they are planted. When they are grown outdoors, the seeds can be spread gently around some good soil. Individual plants should have a space of six inches between them. The plants are sturdy and strong after being firmly established. The plant can be grown in outdoors for gardening, landscaping and mass planting and can also be grown out of containers. It is however, advisable not to grow these plants in containers.\nThe plant can be grown on a wide variety of soils. However, a well-drained and sandy soil is preferred for growing German chamomile. The pH content of the soil should be between 7.0 and 7.5. The plant should have access to plenty of sunlight for healthy development. The plant needs to be watered regularly. However, care should be taken not to overdo the watering process.\nThe soil used for this plant should be tested before plantation. Depending on the results of the tests, certain minerals like phosphorus, nitrogen and potassium may need to be added. The major nutrients required by this plant for proper growth and development are as follows:\n- Carbon (C)\n- Oxygen (O)\n- Hydrogen (H)\n- Phosphorus (P)\n- Potassium (K)\n- Nitrogen (N)\n- Sulfur (S)\n- Calcium (Ca)\n- Magnesium (Mg)\nThe best time to grow these plants is in autumn or during earlier months after winter. The rate of germination depends on when the seeds are sown. Plants which are sown late will have a lower germination rate. As a result, these plants will develop less number of flower stalks and growth of flowers will be less.\nMatricaria recutita Range of Distribution\nThe German chamomile plant is native to a wide variety of regions all across the globe. Commercially, these plants are grown in\n- All over Europe, especially in countries like Hungary, France, Germany, Italy, Greece and Spain\n- Parts of former USSR, such as Ukraine, Belarus and Moldova\n- North African countries like Egypt, Morocco and Ethiopia\n- South Africa (Free State, Lesotho, Eastern Cape, KwaZulu-Natal, Gauteng and Mpumalanga provinces)\n- Temperate regions of Asia, comprising of countries such as North India, Pakistan, Afghanistan, Japan and Turkey\n- East Coast of North America\n- South American countries like Brazil and Argentina\n- Australia and New Zealand\nThe Matricaria recutita flower plant is also grown in the icy regions ranging between North Caucasus and South Siberia.\nMatricaria recutita Uses\nThe German chamomile is extensively used for its positive health effects. It has antispasmodic, anti-cholesterol, anti-inflammatory, anxiolytic and antimutagenic properties. The plant includes the following chemical components:\n- Volatile oils like Bisabolol oxides, α-Bisabolol and Matricine\n- Flavonoids including quercitin and apegenin\nThe flower extract of this plant is used to make essential oils, ointments and capsules. The dried herb of this plant is also used to make chamomile tea. Chamomile tea prevents the growth of fungus. It is thus often spread over seedlings to prevent damp and fungus. The plant is also used for cosmetic purposes. It is used to prepare a hair rinsing solution for blonde hair. In agriculture, this plant is known to facilitate the growth and overall health of plants used for the production of essential oils. The plant helps in increasing the production of these essential oils. It strengthens the scent and flavor of herb plants like basil, oregano, sage and spearmint. This plant is also used to manufacture herb beers.\nGerman chamomile is also used in aromatherapy. The sweet fragrance of these flowers is believed to elevate the mood and bring relaxation to a person’s mind and body. Research shows that chamomile has a calming effect on our brain waves. Chamomile oil is used in aromatherapy to treat insomnia and sleep disorders.\nMatricaria recutita Health Benefits\nThe Matricaria recutita plant is popular for its beneficial health aspects. The plant is used to treat various health problems, such as\n- Gum inflammation (gingivitis)\n- Sore throats\n- Chest colds\n- Stomach ulcers\n- Inflammatory bowel disease (ulcerative colitis)\n- Minor first-degree burns\n- Children health issues like chickenpox, colic and diaper rash\nApart from the above mentioned health issues, this plant also offers relief from inflammation. It facilitates a speedy recovery of wounds.\nIt offers relief from anxiety and calms the nerves. The plant extracts act as a sedative, helping us to have a good night’s sleep.\nAntispasmodic properties of this plant help in reducing muscle spasms. It also relaxes the intestinal muscles and gives relief from diarrhea, indigestion, stomach cramps, gas and irritable bowel syndrome.\nExtracts from German chamomile are used to make creams or ointments which have a soothing effect on the skin. In European countries, it is often used to this effect and also to treat eczema. It has strong tissue regenerating properties.\nThe oil of this plant helps in reduction of swelling. It also prevents the growth of viruses, bacteria and fungi. The oil is also an important antidote to premenstrual syndrome (PMS) as well as other menopausal and menstrual problems such as menstrual cramps.\nThe German chamomile oil has the following therapeutic properties:\nResearch on the benefits of German chamomile has also been conducted on rats. The results indicate that the plant aids in reduction of body weight.\nDosage of Matricaria recutita\nAdults can drink the chamomile tea 3 or 4 times in a day between meals. The tea should be prepared in the following way: Two to four grams of dried chamomile herb should be added on a cup of simmering water and kept for around 10 to 15 minutes.\nCapsules with strength ranging between 300 to 400 mg should be taken thrice daily.\nLiquid chamomile extract can be consumed up to 1 to 1.5 teaspoons thrice daily.\nAround 100 to 150 drops of chamomile tincture containing 45% alcohol can be mixed in hot water and consumed three times daily.\nChamomile tea can be cooled and used for gargling. An oral rinse may be prepared by adding 10 to 15 drops of chamomile liquid in 100 milliliters of moderately hot water. The oral rinse may be used thrice daily.\nA few drops of chamomile essential oil can be added to hot water. The steam emitting from this mixture can be inhaled to soothe a cough.\nA bath using chamomile oil can give relief from hemorrhoids and insect bites. This can soothe the skin and heal cuts and eczema. The bath can be prepared by adding 5 to 10 drops of chamomile oil or a quarter of a pound of dried flowers to a tub of water.\nPowdered chamomile herb can be mixed with water to create a paste. This paste can then be applied to heal skin inflammations and infections.\nA cream containing 3 to 10% of crude drug chamomile can be applied as an antidote to eczema, psoriasis or flaky and dry skin.\nFor children under the age of 18, the dosage is half of the adult dose. To deal with pediatric problems or with colic, chamomile tea can be consumed daily. The consumption limit for children however, should not exceed more than half cup or 1-2 ounces of chamomile tea.\nThe dosage for chamomile supplements, like any other herbal nutrition supplements, should be as per the recommendations made by doctors. The dosage varies, depending on the medicinal purposes for which it is used.\nSide Effects of Matricaria recutita\nGerman chamomile is widely used by people to avail its therapeutic qualities. However, certain side effects can be triggered by the use of this oil. The oil when used can exaggerate certain health issues. The oil can also react badly with certain other medications, herbs or supplements. It is thus advisable to consult a doctor while consuming chamomile and its products.\nAsthma patients should avoid consuming chamomile as it may worsen the existing asthmatic symptoms.\nChamomile oil and extracts are generally considered safe for pregnant and lactating women. However, a doctor needs to be consulted to supervise the dosage or if it is suitable at all for the pregnant woman to drink chamomile tea or use chamomile products during her pregnancy. This is because consumption of chamomile oil may lead to miscarriage in pregnant women. Especially, chamomile should not be consumed at this stage as an essential oil or a tincture preparation.\nVomiting may be induced by drinking too much of chamomile tea of high concentrations.\nConsumption of chamomile may lead to allergic reactions for people who are already allergic to other Asteraceae species such as daisies, asters, ragweed or chrysanthemums.\nProfile of German Chamomile in Homeopathy\nGerman chamomile acts as a good homeopathic remedy for people who find it difficult to cope up with pain. Some individuals may find it difficult to have control over their emotions and might often experience inner conflict, hostility and irritation. They might experience unpredictable moods, a hot temper and an active dislike of being touched. They feel stressful if they feel like their space is being invaded or if someone interferes about their matters. Often such behavior is displayed by children and such conditions are medically termed as Attention Deficit Hyperactivity Disorder or ADHD. German chamomile can give relief from such stressful mental conditions.\nGerman Chamomile Drug Interactions\nThe German chamomile plant or its extracts can react adversely when it interacts with certain other drugs. Hence users of these drugs should consult a physician before consuming chamomile oil, herbs, flowers or ointments.\nThe following is a list of drugs with which the chamomile plant or its extracts can have a negative reaction:\n1. Sedatives or drugs having a sedative effect, such as\n- Anticonvulsants, such as Valproic acid (Depakote) and Phenytoin (Dilantin)\n- Benzodiazepines, such as Diazepam (Valium) and Alprazolam (Xanax)\n- Drugs meant for the treatment of insomnia, for e.g. Zaleplon (Sonata), Ramelteon (Rozerem), Eszopiclone (Lunesta) and Zolpidem (Ambien)\n- Tricyclic antidepressants like Amitriptyline (Elavil)\n- Sedative herbs such as catnip, valerian and kava\n2. Certain liver enzymes decompose Chamomile as well as other drugs. Chamomile can enter into a reaction with such drugs.\n- Birth control pills\n- Antihistamine drugs like Fexofenadine\n- Statins, which help in lowering the cholesterol levels of the body\n- Certain antifungal drugs\nWhere to buy German Chamomile\nGerman chamomile essential oils and ointments can be found in any aromatherapy shop.\nGerman chamomile capsules are found in retail medicine and healthcare shops.\nChamomile flowers are available in shops packed in pouches. The flowers can be bought from florists. Alternatively, they can be ordered from flower shops for home delivery.\nBeverages made from this plant such as chamomile tea can be found in grocery stores selling tea. Herb beers can be found in any alcohol shop selling beers.\nThe various chamomile products can also be brought online at reasonable prices.\nGerman chamomile pictures\nBelow are some pictures showing the German chamomile plant, with its flowers having white petals.\nThe German Chamomile plant has long been in use for its beneficial properties. In folk medicine, the plant has always been connected with female health. In fact, the word “Matricaria” essentially means “Caring for the womb”. Besides female health, its use in relieving mental stress, coupled with its sweet fragrance has made it a popular choice as herbal health supplement for millions.']"	['<urn:uuid:f9fc6c94-b923-49b6-b31d-6780d8cd7ea0>', '<urn:uuid:ae6cdbc8-f064-4184-8c68-f3c87ef96ba0>']	factoid	direct	short-search-query	similar-to-document	multi-aspect	novice	2025-05-13T06:27:57.068978	6	58	5255
50	how does rhinoplasty surgery change shape nose what parts modified	Rhinoplasty can modify multiple parts of the nose. The top third (bony portion) can be adjusted by removing humps, narrowing wide nasal bones, or correcting crookedness. The middle portion (mid vault) made of cartilage can be modified to fix pinching or wideness. The tip can be narrowed through trimming cartilages and placing sutures. Inside the nose, the septum can be straightened and turbinates reduced to improve breathing. Finally, wide nostrils can be narrowed either through internal or external incisions.	['A rhinoplasty refers to changing the shape of the nose. It can involve both surgical and nonsurgical ways of changing the shape of the nose and, in general, it was the most common procedure performed on the face in 2016. We find that anyone who is unhappy with the shape of their nose with a healthy outlook on life is a good candidate for rhinoplasty. Most of the time both men and women have to be past the puberty stage in order to undergo rhinoplasty and that is because we want to make sure that the nose has stopped growing and changing shape. Most of our patients are between the ages of 15 and 50-60 years. Interestingly, in patients who are more mature, doing a rhinoplasty can make them look younger. This happens because in the aging process the nose tends to droop and makes them look older, so we can lift the tip and therefore get a more youthful appearance.\nWith rhinoplasty surgery, no two noses are the same and we can do all sorts of things to the nose to improve its look. We can straighten the nose, both bony or cartilaginous portion, we can make the nose smaller, we can make the nose larger, we can lift the tip or lower the tip. If you have trouble breathing through your nose, then we can perform surgery inside the nose to open up the airways and help you breathe better.\nWhen it comes time to do the actual procedure, there are two types of approaches. One is the closed or endonasal approach and the other is the open approach. The method chosen depends on your anatomy and the surgeon you see. There are benefits to the closed or intranasal approach including no outside or external scar noted, and a faster healing time because you don’t have to lift as much skin or make as many cuts in the skin. The downsides can be significant because the visibility is much less when you cannot see the entire nose, and you may have problems with symmetry afterwards because you can’t see both sides of the nose at the same time. Additionally, because there is not as much room to maneuver, you are unable to perform as many maneuvers as you can with the open approach. I typically reserve the closed rhinoplasty approach for people who don’t need much tip work and have a small bump. If someone has more of a crooked nose, a very large or deviated nose, then I prefer to use the open approach, which allows more visibility and more room to make maneuvers. This is the open approach that starts with a small incision in the columella, which is the bridge of skin between the two nostrils. We shape the incision not as a straight line, which is easy to follow and track, but almost like an upside-down V with two arms attached to it. This type of incision heals really well, and over the course of the healing period, fades almost to invisibility. The open approach allows us to lift the skin of the entire nose so we can see both sides of the nose at the same time and have more room to do things like cartilage grafting. Personally, I feel the dissection is cleaner with an open approach, and because we can see all types of irregularities, I know exactly what is under the skin causing those irregularities and we can take care of those in a predictable fashion. The down side is that there is risk for poor scar formation, but if you sew the incision back together nicely, this is a much smaller possibility. The only additional consideration is that there is more swelling afterwards and final results can take anywhere from 6 to 12 months to fully see the results. In the end, though, this would be a nose you will have for the rest of your life and if it means a few extra months of healing time for a lifetime of a nice-looking nose, that is usually a small price to pay for a result that you will love.\nWe usually begin with the rhinoplasty, focusing on the top third of the nose, which is the bony portion. This is where you have bony humps. You can have widened nasal bones or nasal bones that are too crooked. We use a combination of rasps or files and osteotomes, which are instruments that cut the bone in order to mobilize them and get them either narrower or in the midline or both. If someone has a large hump, we can use the same cutting instrument to remove that hump and then use a file to gently smooth over the edges.\nFollowing that, osteotomies, or cuts in the bone, are done to narrow the nasal bones to make the bridge appear narrow. If the bony pyramid is crooked in the nose, then we have to make very selective and artistic cuts in the bone and mobilize it so we can shift them back in the middle.\nNext is called the mid vault, which is made out of cartilage. The mid vault is, as it says, the middle portion of the nose where you can get pinching, which can cause breathing problems, or too wide of a mid vault. If the mid vault in this area is crooked, it might be because of a septal deviation that can occur. The septum is the wall that divides the two sides of the nose and comes all the way up to the top of the bridge. If it is deviated at the top of the bridge, it will look crooked on frontal view. We do special cartilage grafting techniques to place cartilage in the mid vault in order to open the nasal airway to help you breathe better.\nNext is the tip work and this is where a true rhinoplasty artist is tested. The tip is a three dimensional structure that requires very finessed maneuvering and stabilizing in order for you to have a nice predictable and refined result. There are two tip cartilages that meet in the midline and typically we trim a little of these tip cartilages and place sutures to narrow the tip. In the middle of the nose, we want to secure the tip to the septum. Again, the septum comes to the edge of the nose and is the wall that divides the two sides. We typically use cartilage grafting to secure the tip to the septum so that when you smile, your tip won’t droop, and as you age the tip won’t droop either. We use longer lasting sutures to hold things in place so that as you heal, the tip stays in place.\nFinally, the inside of the nose can have either a septal deviation, which can block your breathing, or turbinate hypertrophy. The turbinates inside the nose appear like fingers because they are long, flesh-colored bones, and they swell up with things like allergies and colds. During rhinoplasty surgery, we can make these turbinates smaller and straighten the septum to help you breathe better.\nWe address the nostrils last. If a patient has wide nostrils, there are ways to narrow them, either through the inside of the nose or making external incisions on the outside of the nose. I typically like to reserve nostril reduction for the end because sometimes the tip looks more narrow and you don’t need to narrow the nostrils, and this helps avoid an incision on the outside of the nose.\nRecovery from a rhinoplasty can last anywhere from 7 to 14 days. We typically give our patients a rhinoplasty kit that has everything they will need in order to recover well. This can include nasal saline to clean the nose, hydrogen peroxide to clean dried blood and mucus. In addition, we give Arnica impregnated patches as well as Arnica pills to bring down bruising and swelling. Although these are not miracle medications, they do help reduce the bruising from 14 days down to about 7-10 days. After one week the cast comes off the nose, as do the stitches. Tubes are also placed inside the nose to act as an internal cast and these are removed at the same time. It is at this time that the patient feels better and can breathe more easily. The bruising is also starting to settle and the swelling is also coming down. By two weeks enough of the swelling has come down to where you will look normal walking outside and people won’t question whether or not you just had surgery. The nose will continue to refine itself over the next 6 to 12 months as it gets more and more refined. We see our patients at the one-week mark, one-month mark, three-month mark, six-month mark and yearly after that.\nWhen you are ready for your rhinoplasty consultation, please give us a call and we can schedule an appointment. It will take about one hour for the consultation. Currently prices can range anywhere from $9,500 to $18,000, depending on the complexity of the case. We will be happy to morph your pictures and give you a copy before you leave the office.\nSince there is usually a range in the price of a rhinoplasty, this usually correlates with how difficult a rhinoplasty will be. There are some factors that make a nose easier than others, and other factors that make noses more difficult. On the lower end of the range, noses that are easier are ones that are more symmetric, straighter, and have minimal changes. This might include a small bump on the bridge or a slightly widened tip. Typically these noses are relatively straightforward.\nAlong the spectrum, as noses become more difficult, some factors include asymmetries such as one nostril being larger or smaller compared to the other one, a really large bump on the bridge or dorsum, and asymmetries in the cheeks where one cheek is flatter compared to the other. When one cheek is flatter, the nose is sitting on an uneven table and we have to keep this in mind when straightening the nose. If the client has significant crookedness of the nose where it leans more towards one side than the other, this can also make it more difficult to make it straighter. The bony portions of the nose can be fractured back into the midline, but if the cartilaginous part of the nose is deviated or crooked, we have to come up with complex grafting to make it appear straighter. One can imagine taking a few crooked pieces of wood or building blocks and putting them together to make them look straighter. When we do this, healing is slightly more unpredictable, which makes the surgery more difficult.\nAnother thing that can make the nose more difficult to work with is thick skin. Usually with thick skin come thinner, weaker cartilages so we need to really strengthen the framework of the nose in order to support the healing in the postoperative period. Thickened skin will decrease the definition of the nose and also lengthen the postoperative healing time. In these patients, the healing can continue to improve for at least one or even two years. In the past, to help combat thickened skin, rhinoplasty surgeons have tried to thin the skin by removing skim, muscle and fat from underneath the skin envelope. Unfortunately, this doesn’t translate into long-term thin skin as the lymphatic vessels are also removed during this dissection. The lymphatic system is the system of vessels that is used to drain swelling. Once those are removed, there is swelling that just stays around almost indefinitely. If this happens, the skin still appears thickened, which makes a nice natural looking result a little harder to achieve.\nAdditionally, thin skin can make a rhinoplasty difficult because any little imperfection shows through the thin skin. This can usually be diagnosed at the time of the consultation, where if the edges of the cartilage are very visible underneath the skin, then I can prepare the client about what to expect before surgery . In primary rhinoplasty, it is rare that we need to thicken the skin and it is more common in revision rhinoplasty when the skin is already slightly thin. We can use a temporalis fascia graft, which is taking the covering of the temporalis muscle, which is located in the temple. A small incision is made through the scalp and the temporalis fascia is isolated and removed and serves as a little blanket that goes over the framework of the nose in order to thicken the skin. As you can see, this can add extra time to the procedure, which adds extra costs.\nWe can also discuss the preoperative planning, which is usually done through the use of morphing imagines during the consultation. We like to use Adobe Photoshop to morph the frontal view as well as the profile view in order to show the client what changes we are thinking of and with a reasonable expectation to have after surgery. I like to use these morphs because they tell me how much of a bump to remove, how much to lift the tip, as well as how much to narrow the nose from frontal view. In addition, it serves as a nice communication tool between the client and me, so that we are both on the same page when it comes to achieving a result we both like. Of course, morphing images has its drawbacks. Nothing is guaranteed and things do change during the timing of surgery . All in all, it helps to show the client, whether they want a curve to their profile versus a straight profile. In addition, we can narrow the tip and narrow the nostrils to show them how much can be narrowed during the time of surgery. Although the results are not guaranteed, we do get very close to achieving a nice result. This also helps me with my own surgical planning so I can achieve a result that the client is looking for.\nThere is some unpredictability when it comes to rhinoplasty surgery and that is why it is hard to guarantee a certain result. We do our best to diagnose any issues by looking at the outside of the skin, but until we are really into the procedure and have the skin lifted up can we see exactly what is going on. For example, sometimes it is difficult to make a nose perfectly straight because as we are fracturing the nasal bones, they become more and more unstable. If it reaches a certain point where the bones are too unstable to adjust, then it’s best to leave the bones where they are and come back for a second procedure only if necessary. Of course, we never want to come back for a second procedure if we don’t need to, but if we go too far, this can cause irreversible changes and irregularities that become even more difficult to correct after the primary procedure.\nI like to tell patients that although we may not be able to get a perfect result, we get a very good result dealing with what we have to work with. It is similar to baking a cake, where you might have all the ingredients except for eggs and you can still make the cake. Making a cake without eggs will still taste like cake but it may not taste as good as cake made with eggs. This is similar to times when we are looking for straighter pieces of cartilage and we may not have them available, but the nose, all in all, looks much straighter than it did preoperatively.\nRhinoplasty surgery is the most complex plastic surgery that one can do for the face. The nose is right in the center of the face and it cannot be hidden with makeup, hair or clothing, as in other parts of the face or the body. Every single millimeter counts and when 1 mm is off in the wrong place, it can make the nose look unnatural or have an unsatisfactory result. The nose is also a three dimensional structure and it must look good for every angle including the front, the sides, as well as the base view. Keeping this in mind, I do walk around the nose during the surgery to make sure it looks good from every angle and the patient is happy. When it comes to the final result, most people will judge your nose based on the three-quarters view because that is the view that people look at you the most. This is in contradistinction to how we usually look at our nose, which is from the frontal view in front of a mirror. But when you take pictures and when people see you, it is mostly the three-quarters and the profiles that have the most impact on people.\nIn the end, a great candidate for rhinoplasty surgery is a client who has very reasonable expectations with their procedure. Those clients looking for perfection are ones I do not like to operate on because perfection, by definition, is possible. Instead, we get very very close to a nice-looking nose that looks like it has not been operated on, and looks natural. Our goal is never to have someone look at your nose and think that you had surgery previously.']	['<urn:uuid:1bc7f0cb-5822-42f4-a746-88ab5bd591ba>']	open-ended	direct	long-search-query	similar-to-document	single-doc	novice	2025-05-13T06:27:57.068978	10	79	2908
51	lost job worried about money curious what buddhist monks do when they have no income	The Buddha taught that as long as monastics practice sincerely, they will not starve. Even in situations where monastics had very little money and had to be careful about food expenses, by maintaining trust in the Buddha's teachings and not working for money, they received support from kind people and never went hungry.	['This article was originally published in Chinese in Dharma Drum Humanity Magazine as 以願導航 創造共善能量場. (Interview edited by Hezhen Lin, Dharma Drum Humanity Magazine Issue 415)\nInterview with Dharma Drum Humanity Magazine (download)\nFor a long time, I searched for answers about the meaning of life. In 1975, I happened to participate in a meditation course led by two Lamas, and heard them say, “You don’t have to believe anything I say. You should still think about it and put it into practice, to see whether what I have said benefits you.” From then on, I developed an interest in Buddhism.\nTraveling afar to the East to ordain and seek the Dharma\nAt that time, there were few places in America where you could learn the Dharma. I decided to quit my job as an elementary school teacher, traveled afar to Nepal and India to seek the Dharma, and relied upon Lama Thubten Yeshe and Lama Zopa Rinpoche as my teachers. In 1977, I received the sramaneri ordination from my preceptor Kyabje Ling Rinpoche, who was His Holiness the Dalai Lama’s senior tutor.\nAs the bhikshuni sangha lineage was no longer extant in the Tibetan tradition, there were a few nuns who went to Taiwan to receive the Triple Platform ordination. Nine years after becoming a sramaneri, I sought help from a Dharma friend, and after receiving permission from His Holiness the Dalai Lama, in 1986 I went to Yuanheng Temple in Taiwan to receive the full ordination, officially becoming a member of the sangha. In my Dharma practice, I rely upon the Tibetan tradition, and in upholding the Vinaya I follow the Dharmaguptaka Vinaya. I often remind myself to be mindful of my comportment, to conduct myself appropriately in order to be in accord with the wishes of my teachers in both lineages.\nLiving in a different cultural setting gave me the opportunity to observe how American culture had conditioned and influenced my life. When I saw how others did things differently, I would reflect: Is it always good for me to do things according to American custom? Are American values and ways of doing things suitable for other cultures? Is democracy suited to all situations? Thinking in this way helped to expand my perspective, and I learned how to view matters from a range of perspectives.\nWhen I first began to learn the Dharma, many sutras and treatises had yet to be translated into English; we had to rely on oral transmission from our spiritual mentors. I greatly treasured the opportunity to learn from my eminent teachers. When listening to them teach the Dharma, I often felt that what they were describing was their own practice and the experiences they had personally gained from putting the Dharma into practice. I felt fortunate to be able to hear the Dharma from them. My teachers also gave me personal instructions, at times asking me to do things that I didn’t want to do, or to take on tasks that I felt I wasn’t capable of handling. Although their instructions challenged my self-esteem and my abilities, I knew that my spiritual mentors were wise and compassionate, and I had complete trust in them.\nA few months after I received sramaneri ordination, my teacher was going to teach a one-month meditation course for Westerners. I was still very new in the sangha community, but I was asked to take on the role of his teaching assistant. I felt that I lacked learning and was unable to take on this responsibility and reported this to my teacher, who looked me in the eye sternly and said, “You’re selfish!” His scolding woke me up, and I mustered the courage to take on the duty of sharing the Dharma.\nPropagating the Dharma worldwide according to causes and conditions\nAnother time, my teacher sent me to a Dharma center in Italy to be the spiritual program coordinator as well as the disciplinarian of the monastic community. Although I was not keen to do this, I followed my teacher’s instruction and learned a lot through being put in this very difficult position. In the past, if my teacher had pointed out that I had problems managing my anger, I would not have taken his words to heart. However, after taking on the position at the Italian Dharma center, I truly saw how easily I got angry. This forced me to learn the Dharma antidotes to counteract anger.\nIn 1987 I was sent to Singapore to teach and everything seemed to be going smoothly. Then, during a brief period when I returned to America, my teacher suddenly sent me a letter, transferring me to a Dharma center in Australia. This was a major change in my life, yet I had not been asked about my views on it. At that moment I was dumbfounded, disheartened, and perplexed; I wondered, had someone criticized me at the place where I had been assigned a position at that time? For a split second the thought of leaving arose, and that terrified me. Right then I knew that the only thing to do was to let go of my anger, practice thought transformation, and recognize that my emotions are my own responsibility, they are not my teacher’s fault. It was clear to me that when I was unhappy, it was not my teacher’s fault, not the Dharma’s fault, not anyone else’s fault. Rather, my unhappiness was a direct result of my own mental afflictions and the only way out was to practice the Buddha’s teachings.\nDue to external conditions at the time, I was unable to take on the assignment in Australia. I wrote a letter to my teacher to explain the reasons, and waited for him to give me a new assignment, but time passed and there was still no news. I had no place to live and so requested him, “May I make my own decision?” He replied that I could. In the subsequent two years, I traveled along like a cloud floating in the sky, as I had no stable source for the four monastic requisites. I could only stay in one layperson’s house after another, and during this time I wrote the two books Open Heart, Clear Mind and Taming the Mind. After returning to Dharamsala for a year to receive teachings, I then returned to America on a Dharma teaching tour.\nTransforming adversity into resources for spiritual practice\nThat was a very difficult time, but I never thought of disrobing. That I was able to persevere came from my understanding of karma: my loneliness and difficulties were not caused by my ordination, but by my untamed mind—it was ignorance and self-centeredness that had caused me to wind up in that situation. Thinking like this was very helpful, because I had no one to take my anger out on, and instead I had to look at the source of my problems. If I didn’t like the result, then I had to stop creating the cause, and that meant practicing the Dharma diligently.\nIn the Tibetan refugee communities in India and Nepal, lay devotees were often unable to offer material support to foreign monastics. As a result of being unable to support themselves, many Western monastics had no choice but to give up their robes, and return to their countries to work. However, when I ordained I made many resolutions, one of which was never to work for money. The Buddha said that as long as monastics practice sincerely, they will not starve. Even when I was in India, when I didn’t have enough money to buy a return ticket to America and had to be careful not to spend too much on food, I always trusted the Buddha.\nAlthough I am not a very good practitioner, I just try my best and don’t have a motivation that hopes to receive support when I connect with people. I just share the Dharma when there is a request from others. I’m grateful for the kind support I’ve received from many people, and I’ve never gone hungry. Even when I felt lonely, I just had to open my eyes and look around to see that I was surrounded by the kindness of others.\nTo establish a firm foundation for Dharma practice, it’s essential to let go of—or at least to gradually reduce the eight worldly concerns: attachment to gain and aversion to loss; attachment to a good reputation and aversion to a bad one; attachment to praise and aversion to blame; and attachment to sense pleasure and aversion to what is unpleasant. Although I am currently unable to cut the eight worldly concerns, I reflect on them often, which helps me to relax and not grasp at things. Contemplating the disadvantages of samsara helps to reduce and then let go of expectations that everything should go according to my wishes. I have also come to understand that being criticized or having my reputation ruined is actually beneficial because it helps me to subdue the mind of “I want this, I don’t like that; things should be this way,” and to cultivate humility. In spiritual practice, having a sense of humor is important. Whenever my mind craves for worldly things or people, I make fun of myself, and through this remind myself not to grasp at them.\nAside from this, cultivating love, compassion, and bodhicitta also help to counteract our attachment to “I, me, my, and mine.” Just as Nagarjuna said in his Precious Garland of Advice to a King, “May I bear the results of sentient beings’ negativity, and may they have the results of all my virtue.” This thought-training technique of taking and giving involves visualizing taking others’ suffering into our heart, and by doing so destroying our self-centered mind, and then imagining that we give our body, wealth, merit, virtue, to sentient beings with compassion that wishes them to have happiness and be free from suffering. This process expands our perspective on life and enables us to have a more open heart and to empathize with others’ needs.\nReturning to America to establish a monastic community\nWhen I returned to America on a Dharma teaching tour in 1989, I realized that because many people were unfamiliar with Buddhism, they did not understand the purpose of making offerings to monastic communities. Dharma centers were often run by laypeople, and monastics were asked to organize events, and also participate in tasks such as cooking in the kitchen and cleaning rooms. In 1992, Dharma Friendship Foundation invited me to be their resident spiritual teacher. I was the only bhikshuni there and missed the companionship of fellow monastics. The aspiration arose to establish a monastery where Tibetan Buddhist bhikshunis could practice in community.\nIn 2003, Sravasti Abbey was incorporated and we purchased the land. The only residents were me and two cats, with no organization supporting us. As I sat in my chair wondering how we were going to pay off the mortgage, the cats sat there looking at me, as if to say, “You have to feed us well.” Subsequently at the Western Buddhist Monastic Gathering, I sought advice from elders who had founded monasteries in the West on how to manage a sangha community, and gained a lot of inspiration through that process. Venerable Wu Yin and Venerable Jendy from Luminary International Buddhist Association also gave me a lot of wise advice. Keeping in mind my resolve, and with deep conviction in the support we had from the Buddhas and bodhisattvas, I simply went along with causes and conditions and opened the doors of the Abbey. Gradually, support started to come in, and we even paid off the mortgage in advance.\nMy students from Dharma Friendship Foundation often came to visit the Abbey. At first, they came to offer help and were merely curious about monastic life, but after a few years, they wished to take ordination. At present, Sravasti Abbey already has 14 resident monastics and one lay trainee. We are the sole training monastery for Tibetan Buddhist bhikshunis in America.\nFrom finding peace within to bringing peace to others and the world\nIt’s very important for monasteries to exist in society. Personally, when I was a sramaneri, I only focused on my personal spiritual practice. It was only when I became a bhikshuni that I truly understood that the Dharma and Vinaya have been sustained and I could receive the bhikshuni ordination because hundreds of thousands of monastics before me in the past, from the Buddha’s time up to the present, have ordained and passed the lineage down from one generation to the next, thereby preserving the Dharma and the Vinaya. As such I also have responsibility to enable the transmission of the Three Jewels to continue.\nIn this materialistic world, to have a monastery where a monastic community lives and practices together is like a lighthouse that guides society onto the right path. The presence of monastics inspires individuals and society to reflect: What are our values? What is our responsibility to future generations? Shall we preserve the natural environment for them? Do we really need to wage wars? It’s because monastics give their bodies and minds to their spiritual practice to seek the path to liberation that a layperson once wrote us to say, “Knowing that there are people practicing together in a monastery like you are brings us great comfort and inspiration.” When laypeople encounter difficulties in life, they can seek out the monastic community for help; they can come to practice together with us, listen to teachings, and create virtue. Learning the Dharma and creating virtue alleviates their worry and distress.\nFor instance, after the US presidential elections in November, 2016, many people felt upset and despondent, and wrote to Sravasti Abbey for help. Some people wondered, “This world is already in such a terrible condition, what can we do? Or is the situation hopeless?” We spent a week giving talks and posting them on the internet to help people view the present situation from a Dharma perspective. Buddhist practice involves growing through difficulties, and not expecting to live in a perfect world, or waiting for great spiritual practitioners to change the world. The situation before us is the ripening of our karma, and we must face and accept it, and then with compassion, act to ameliorate the situation.\nWhen I’m unhappy about the harm some government officials are doing to the country and the world, I chant “Homage to our fundamental teacher, Shakyamuni Buddha,” and bow to all the Buddhas and bodhisattvas. While bowing, I visualize all the politicians whom I disagree with all around me and imagine that I’m leading them to bow to the Buddha together. I hope we’ll make a positive connection in this life, and I dedicate the merit so that in future lives, we may have the opportunity to practice the Buddhadharma and move in a virtuous direction together.\nTo have the circumstances to practice the Dharma together with other like-minded people in contemporary society is rare and precious. Even though we may admire great spiritual teachers, these great masters do not have the same strong connection to the circumstances around us as we do. If someone needs to exert positive influence on these circumstances, it has to begin with us and our actions.\nThink about how the Buddhas and bodhisattvas practiced for countless great eons in order to guide us. They have never given up on a single sentient being. We should learn from their bodhicitta resolve and do our best in difficult circumstances to cultivate compassion and wisdom, thereby creating an “energy field for the common good,” that has the power to bring peace and harmony to society.\nThis article is available on this website in Chinese: 以願導航 創造共善能量場']	['<urn:uuid:cfabc081-3438-4bbe-86d9-824429a831b0>']	factoid	with-premise	long-search-query	distant-from-document	single-doc	novice	2025-05-13T06:27:57.068978	15	53	2632
52	difference psyd phd psychology clinical practice	In terms of clinical practice and counseling clients, both PsyD and PhD Psychology degrees have equal status and function similarly. The main difference is that the PsyD (Doctor of Psychology) is an applied, clinically-focused doctorate degree similar to an MD in medicine, while the PhD in Psychology is a research doctoral degree. PhD graduates may favor academic research or teaching at the university level rather than clinical practice.	"[""Earning a doctoral degree in psychology may be on your radar if you are interested in pursuing potential careers in academics, consulting, research, and as licensed counseling and clinical psychologists[i]. Psychologists study the human brain, cognitive functions, emotional and social behaviors through various techniques and interventions.\nIn the U.S.A., a doctoral degree such as the Ph.D., Psy.D., and Ed.D. earned from an APA-accredited program may be translate into eligibility to sit for the Examination for Professional Practice of Psychology examinations in one’s state.\nYou are searching for a terminal degree program in the field of psychology and see you have options including the PsyD (Doctor of Psychology), the Doctor of Philosophy (PhD) in Psychology, and the Education Specialist degree.[iii] While academically similar, there are differences between these degrees – somewhat like different roads, that prospective doctoral students should clarify before embarking on a doctorate in psychology program.\nThe Doctor of Psychology, abbreviated ‘PsyD, Psy D, or Psy.D. is an applied, clinically-focused doctorate degree somewhat like an MD in medicine. Earning a PsyD degree typically prepares a graduate to fulfill the educational requirements for state licensure; licensure is a requirement for use of the title “psychologist” in most states.[iv]\nThe PhD in Psychology is a research doctoral degree in psychology. Earning a PhD Psychology typically prepares graduates to fulfill the educational requirements for state licensure. That said, those who pursue their PhD in psychology may favor academic research or teaching at the university level rather than clinical practice.\n|Clinical Psychology Ph.D.\n|Wisconsin School Of Professional Psychology\n|Doctor of Business Administration - Industrial Organizational Psychology\n|Ph.D. in General Psychology: Cognition and Instruction (Qualitative Research)\n|Grand Canyon University\nIn terms of potentially counseling clients and practicing in a clinical setting, both the Psy D and the PhD Psychology degrees have equal status and function about the same. Ultimately, your decision may boil down to whether you prefer to learn in a hands-on clinical setting or to conduct research.\nThe admission requirements for each psychology school and doctor of psychology program may differ. Some schools may choose candidates that they feel ‘fit’ their schools’ mission in terms of clinical and research experiences. You are always advised to check with the requirements of the specific schools on your list. Potential admission requirements may include:\nDID YOU KNOW?\n5,277 Research Doctorates and 1,444 Professional Doctorates in Psychology were awarded in 2014?[ii]\nHow long does it take to earn a Doctorate in Psychology? Program lengths for PsyD, Psychology PhD and EdD Psychology Programs may vary between schools and depend on whether you pursue your graduate study on a part-time or full-time basis, among other factors.\nBrowse our PsyD categories and find your specialty areas:\nEarning a Doctorate in Psychology takes time and many students are juggling work and family too! If you are wondering how to manage your time – study, research, career, family – an online PsyD might be perfect for you!. There are many online PsyD programs available but it is worth a search to find out if these programs meet your needs.\nHow has earning a Psy.D. enhanced your career?\nWith my Psy.D. degree, I see patients, and have worked for groups, at treatment facilities, and now see them on my own. I teach online courses to up and coming masters and doctoral students in psychology. I review case files and write reports or testify on cases about patients' mental health history and issues. I also write for a number of publications, which brings me great joy in my ability to share useful information to help a broader audience.\nVery. Especially if you are aiming for an American Board of Professional Psychology. Why? To attain board certification by the ABPP one of the requirements is that an individual has earned “A doctoral degree from a program in professional psychology which at the time the degree was granted was accredited by the APA, CPA, or was listed in the publication Doctoral Psychology Programs Meeting Designation Criteria[vi].”\nWho is the APA? The APA Commission on Accreditation (APA-CoA) is recognized by both the secretary of the U.S. Department of Education and the Council for Higher Education Accreditation, as the national accrediting authority for professional education and training in psychology.\nWhat is the Scope of APA Accreditation? The APA accredits doctoral graduate programs in clinical, counseling, school psychology and combination programs, internships, postdoctoral residency programs in traditional and specialty areas of psychology.\nSOURCES: [i] bls.gov/ooh/life-physical-and-social-science/psychologists.htm |[ii] datausa.io/profile/cip/42/ |[iii] [i] |[iv] [i] |[v] apa.org/ed/graduate/specialize/index.aspx |[vi] abpp.org/i4a/pages/index.cfm?pageid=3290""]"	['<urn:uuid:ec861812-73ab-4d0a-9e4b-6ddb96cb9428>']	open-ended	direct	short-search-query	similar-to-document	single-doc	expert	2025-05-13T06:27:57.068978	6	68	747
53	global flight communications system operational protection	The ACARS protocol serves as the fundamental air-to-ground data communications infrastructure used by hundreds of airlines worldwide to communicate with air traffic control, aviation authorities, and operations centers. While it has proven highly reliable for transmitting critical information about aircraft operations, weather, and positioning, the system requires robust cybersecurity protection. This protection is implemented through Security Operations Centers that safeguard the entire ecosystem of interconnected elements, including airport terminals, ATM networks, communication systems, and ground surveillance equipment. These centers employ trained personnel who must develop competencies in situation awareness, service provision, and management of non-routine situations to effectively protect against cyberthreats.	"['This article is the first in a series on the Aircraft Communications Addressing and Reporting System (ACARS) which, for the last 40 years, has served as the foundation of aviation communications. This multi-part series will provide an overview of ACARS, how it has evolved over the years, misconceptions about the technology, and what we can expect to see moving forward. First up, an overview of ACARS and what it means to the aviation industry.\nWith ACARS coming up on its 40th year in use, Connected Aviation Today was prompted to take a look back at the technology, its evolution, how far it’s come and how it supports critical airline procedures today.\nSince 1978, ACARS has been a critical part of aircraft communication across the globe and, according to Rockwell Collins, is the air-to-ground data communications infrastructure hundreds of airlines around the world use to communicate with air traffic control, national aviation authorities and their own operations centers.\nBut while ACARS has been considered the foundation of aviation communication, there seems to be some confusion about exactly what ACARS is as well as a fairly common misperception that ACARS is an outdated technology that will soon be replaced by newer ones.\nDan Pendergast, senior marketing director, Commercial Aviation and Network Services at Rockwell Collins, sheds some light on ACARS and its role in the aviation industry over the last four decades.\n“At a fundamental level, ACARS is a flexible aviation communications protocol defined by ARINC 618, Air/Ground Character Oriented Protocol Specification and managed by an industry organization called the Airlines Electronic Engineering Committee (AEEC),” explains Pendergast. “Essentially, ACARS allows information to be consistently sent to various stakeholders that are part of the end-to-end aviation communication system. The ACARS protocol defines the rules, syntax, semantics and synchronization of communication, but does not define how it must be implemented, meaning that ACARS messages can be sent over a wide range of technologies including HF, VHF, and now over Internet Protocol (IP), WiFi and cellular services.”\nInitially, the ACARS protocol supported aircraft communications over VHF frequencies. Since then, it has evolved to support multiple other communications frequencies such as HF and L-band satellite. Today, with new broadband communications systems such as cellular, Wi-Fi and Ku and Ka-band satellite being enabled for aviation, ACARS is well positioned and able to support IP communications between the aircraft and ground operations.\n“When it was initially developed, it [ACARS] had a very limited use,” explained Pendergast. “It was primarily used to give the airlines better information on the times associated with an aircraft’s operation. Right away, airlines found this information to be particularly helpful with calculating crew pay, for example.”\n“In 1978, Rockwell Collins developed a private, global aviation network to support ACARS messages,” said Pendergast. The ACARS network proved to be very reliable, consistently available for aircraft communications and “over time, more and more applications were developed that used the ACARS network. ACARS became a system not only associated with communicating aircraft operation, but also weather information, weight and balance of the aircraft, aircraft and engine health, and in-flight aircraft positioning.”\nWith the demonstrated performance of ACARS and all of the applications available, it’s not difficult to see how air traffic control would find value in the ability to communicate to an aircraft using data rather than voice for routine air traffic control messages.\n“Air traffic control started using limited messages for giving the aircraft clearance to depart from the gate,” Pendergast elaborated. “Then it was adapted to send information between air traffic controllers and pilots using satellite communications as they were flying over the ocean to enable aircraft position reporting and routine air traffic control clearances and text communication.”\nWith so many applications that airlines have woven into their critical procedures, ACARS has become an underpinning for aircraft communication and operations.\nThose who think ACARS is outdated have not accounted for its ability to adapt to and integrate with newer communication technologies as they become available. And while some might argue that the technology is obsolete, it’s used today by airlines across the board as a foundational communication tool that ensures passenger and crew safety as well as efficient operations.\n“Now, ACARS has become a network that, for many airlines, is critical to their operation as a whole. Because it’s grown and become so well used and it has, through our services, excellent reliability and availability and performance, the airlines have come to rely on it as the primary means to communicate to the aircraft and for the pilots to communicate back from the aircraft,” stated Pendergast.\nIn our next article, Dan Pendergast will discuss a few of the misconceptions about ACARS, provide insight on where these misconceptions come from, and share his thoughts on how ACARS providers are responding.', ""Cybersecurity should be a top concern of any business these days, particularly for those in industries that deal with public safety. Air Traffic Control centers must be well prepared to deal with cyberthreats. Recent attacks on large entities such as Air India, the Colonial Pipeline and the Irish Health system elevate the discussion on planning for continuous improvements in cybersecurity. Here's a look at solutions for the aviation industry to make data transmission over electronic networks are as safe as possible.\nBreach Concerns in Aviation\nHow do hackers do it? How do they manage to penetrate the private networks of tech giants? A great deal of cyberattacks are done with automation software purchased from the dark web where cybercriminals sell each other stolen confidential data. That's why every business is now a target - so criminals can steal valuable information and sell it to other criminals.\nRisk management in the form of training a staff how to respond to a cyberattack is the key to protecting your digital assets. Aviation companies must invest in robust cybersecurity to ensure they have an enormous edge over skilled hackers. This includes hardware and software to support air traffic management with a focus on safety engineering. The emerging solution for ATSEP to defend against cybercriminals is a Security Operations Center (SOC) with initial and continuous staff training.\nSecurity Operations Centers\nA SOC is a cybersecurity division within an organization that uses people, processes and technology to monitor, protect and streamline its operation. No two of these centers are alike, as each one must be customized to respond to different levels and types of cyberthreats. SOCs employ engineers and cybersecurity analysts to detect, identify, block and prevent cybersecurity activity. They often are started to conduct infrastructure audits to detect system vulnerabilities then fix them.\nEstablishing and routinely updating a policy of cybersecurity requirements is an essential data protection strategy for today's large organizations. The best way to prevent cybersecurity breaches is to prepare for one using multiple layers of protection. Although the most sophisticated hackers can eventually crack a complex system, you at least need to make it extremely challenging for them to the point it's not worth their time to bother.\nATSEP is responsible for the ATC system maintenance and operations in Air Traffic Control and must guard its valuable assets. It's essential for trainees to learn the tools involved with Security Orchestration, Automation and Response (SOAR). Within this set of tools is a Threat Intelligence Platform (TIP).\nSkyRadar's ATSEP Cybersecurity Training\nYou can train your aviation team by working with SkyRadar, which provides an ATSEP Cybersecurity Training Module. It meets international training standards set by ICAO and EASA. The program categorizes skill sets for trainees based on these competency elements:\n• Situation Awareness\n• Service Provision\n• Management of non-routine Situations\n• Problem Solving and Decision Making\n• Self-Management and Continuous Learning\n• Workload Management\nEngineers and other personnel who go through SkyRadar's cybersecurity training program must pay attention to technical, procedural and social elements. This solution is based on competence and skill building requirements, typical ATM infrastructure and lessons from large cybersecurity breaches in major industries such as banking, finance and energy.\nCybersecurity Training Phases\nAirport personnel should be aware of cybersecurity if they engage through an Air Traffic Control network. This education usually requires previous experience using terminal software. Here are the four phases of training following the selection process.\n- Initial Training - Basic knowledge and skills and qualification training\n- Unit Training - Learn practice and theory with continued qualification training\n- Continuation Training - Focus on emergency and conversions plus review lessons\n- Development Training - Deeper hands-on training\nSkills developed from SkyRadar's training system, which uses powerful simulators, are applicable to various other sectors including aeronautical and meteorological operations. The knowledge is relevant to understanding navigation and surveillance systems, as well as monitoring and control systems. It also applies to IT infrastructure for data processing, automation and communication systems.\nKeeping Aviators Safer from Cybercriminals\nThe ecosystem of an air traffic management operation comprises interconnected elements such as an airport and airline terminals, an ATM network and communication system, ground surveillance and navigation equipment. Supply chains contribute to the system as well. All of these elements can be protected with interconnected cybersecurity solutions using IoT technology.\nSkyRadar's training program features training labs with cyberattack simulators that allow trainees to experience what a breach is like and learn how to counter the attack. This knowledge is useful for engineers and analysts who work for SOCs.\nSecurity Operations Centers in Air Traffic Control environments are helping pave the way to greater cybersecurity protection with the right personnel, processes and technology. ATSEP members can become more knowledgeable about how to fight cybersecurity supported by in SkyRadar's Breach, Attack & Defense training system.\nReferences and Further Reading\n- Gartner Top Security and Risk Trends for 2021 (April 2021)\n- Tips for Selecting the Right Tools for Your Security Operations Center (January 2020), by Toby Bussa, Jeremy D'Hoinn\n- Market Guide for Security Orchestration, Automation and Response Solutions (September 2020), by Claudio Neiva, Craig Lawson, Toby Bussa, Gorka Sadowski\n- Read more about Cybersecurity for ATSEP and AVSEC (2019-today), by Dawn Turner, Martin Rupp, Peter Smirnoff, Ulrich Scholten, Alex Cosper and Dennis Vasilev.\n- More articles on Cryptography, Key Blocks and Key Management (2018 - today), by Martin Rupp\n- Articles on the protection of critical platforms and strategic response (2017 - today), by Ulrich Scholten and Stefan Hansen\n- Articles on Key Management and HSMs (2017 - today), by Peter Smirnoff\n- Articles on Digital Signing, the eIDAS standard, cyber-security and ATSEP qualification (2016 - today), by Dawn M. Turner""]"	['<urn:uuid:7a64279e-ce5c-447f-a26d-4b2dbc90abaf>', '<urn:uuid:4ad3c43f-2f17-426c-83c3-a99ae639f9e6>']	open-ended	with-premise	short-search-query	distant-from-document	multi-aspect	expert	2025-05-13T06:27:57.068978	6	101	1742
54	I've heard about something called an osmotic pressure gradient in cells, and I'm wondering how it relates to these different measurements. What's the connection between osmotic pressure and osmolality/osmolarity measurements?	Osmotic pressure is directly related to both osmolality and osmolarity measurements. In passive transport, osmotic pressure (π) is determined by the concentration of solutes and can cause water movement across membranes. Solutions can be classified as isotonic (equal osmotic pressure), hypertonic (higher osmotic pressure), or hypotonic (lower osmotic pressure, causing cells to expand). When measuring these conditions, osmolality (Osm/Kg) and osmolarity (Osm/L) help determine the concentration differences that drive osmotic pressure. The transport of water across membranes occurs through osmosis, which uses the energy stored in these concentration gradients, and the measurements help quantify these gradients.	['Flashcards in Passive transport of neutral particles. Deck (26):\nDefine passive transport.\nIt uses energy stored in gradients of; concentration, electric potential, chemical potential, osmotic pressure, hydrostatic pressure, to move atoms ions or molecules in a particular direction.\nWhat is the formula and definition of flux density.\nFlux density is a measure of transport.\nFlux density J- the amount (of substance) that moves through a unit area normal to the direction of motion x during a unit time interval.\nWhat is an exergonic(Spontaneous) process?\nIt reduces the free energy of a system.\nWhat is simple diffusion?\nProcess by which the solutes move from a high concentration to a low concentration.\nWhat is Ficks law?\nD= diffusion constant m^2/s\nWhat is the diffusion constant?\nD=diffusion constant, T=absolute temperature, u= particle mobility.\nFor biological molecules, D is usually 10^-11 m^2/s to 10^-10 m^2/s\nWhat is the diffusion constant for spherical particles in a liquid.\nWhat is molecule mass of a spherical molecule and its relevance to the diffusion constant?\nAt constant temperature and viscosity;\nD~1/(square root)M is the diffusion constant proportionality for small molecules.\nWhat is Ficks second law?\nDescribes the variations of the concentration of the diffusing substance in time and space.\n(t)*= diffusion time.\nDescribe the assumptions of diffusion across a membrane\nDiffusion across a membrane is much slower than simple diffusion.\nWe can assume that the concentrations inside the membrane change linearly and that concentrations of both sides do not change over time.\nHow do you calculate the flux density of the membrane?\nd= membrane thickness,m\nP= permeablity, m/s\nHow do you calculate membrane permeability of Lipophilic substances?\ndc/dx= (y)* (c1-c2)/d\n(y)*= partition coefficient.\nHow do you calculate membrane permeability through pore?\nr= radius of pores\nn=concentration of pores.\nWhat is the definition of facilitated diffusion?\nPassive transport facilitated by a transport protein. The protein is usually only adapted to transport a particular substance\nHow do you calculate flux density of facilitated diffusion?\nC= conc of diffusing substance\nJ0= maximum(saturated) flux density\nKm= Michaelis-menten constant.\nWhat are the jobs of inhibitors in facilitated diffusion?\nInhibitors; bond to the transporter, does not get transported, blocks transporter operation, their structure is similar to the transported molecules.\nExplain co-transport facilitated diffusion.\nThe transport of 2 substances by one transporter.\nThe transport of one substance depends on the other.\nThe diffusion of the solvent(water) across a membrane separating areas with different concentrations of the solute.\nWhat is the formula for osmotic pressure(pi)\ni= number of particles obtained from the dissociation of one molecule of the solute.\nc= solute concentration mol/m^3\nGive the 3 forms of isotonicity.\nIsotonic solutions have equal osmotic pressure.\nHypertonic solutions have a higher osmotic pressure.\nHypotonic solutions have a lower osmotic pressure.(Cells expand)\nPassive transport of the solvent acrosss a membrane due to hydrostatic pressure gradient.\nExplain the conjugate process.\nIf the membrane is soluble to both the solvent and solute, the water flux changes the conc gradient and influences the solute flux.\nThe diffusing solute flux effects the osmotic pressure and influences the water flux.\nThe processes are conjugate as they both influence each other.\nIt is osmosis under the influence of an electric field. This osmosis can change the rate and even the direction of ordinary osmosis.\nWhat is streaming potential?\nA reverse phenomenon of electroosmosis caused by the ion flux conjugated to the water flux.\nIt is defined as the filtration of an electrolyte through a membrane results in a potential difference across the membrane.\nWhat causes transport of water across membranes?\nosmosis and electroosmosis.', 'Difference Between Osmolality and Osmolarity\nOsmolality vs Osmolarity\nOsmolality and osmolarity are units of measurement. Osmolality is the number of osmoles of solute in a kilogram of solvent, while osmolarity is the number of osmoles of solute in a litre of solution. An osmole is one mole of any non-dissociable substance. It will contain 6.02 x 1023 particles.\nOsmolarity is the concentration of an osmotic solution. This is usually measured in osmoles. Osmolarity is also used to determine certain medical conditions, like the dissolved particles in urine. The volume of a solution will change with the addition of solutes, and also with any change in the temperature or pressure. Therefore, osmolarity is sometimes difficult to determine.\nOsmolality deals with the concentration of the particles that is dissolved in a fluid. In medical science, osmolality is used to determine several conditions like diabetes, dehydration and shock. For the detection of these conditions, the osmolality of the serum is checked, and is known as plasma osmolality. The concentration of the substances like chloride, sodium, potassium, glucose and urea are calculated.\nThe volume of a solvent remains the same regardless of any changes in pressure or temperature, so it is relatively easier to determine the osmolality. Owing to this fact, osmolality is the common method of measurement in Osmometry.\nOsmolality measures the number of particles in the unit weight of a solvent, and is independent of the shape, size or weight of the particles. The properties based on which the particle concentration is measured are known as Colligative properties. The properties are vapour pressure depression, freezing point depression, boiling point elevation, and osmotic pressure.\nUsually osmolarity is expressed as Osm/L, and osmolality as Osm/Kg. To measure osmolality an instrument known as an osmometer is used, and it works by using the method of freezing point depression.\nThe difference between the calculated osmolarity and measured osmolality is known as the osmolar gap. The values are presented in different units, and this is due to the difference in the method of the calculation and measuring. The abbreviation for measured osmolality is MO, and that for calculated osmolarity is CO. The osmolar gap is represented as OG. If the concentration of solutes in the given fluid is very low, then osmolality and osmolarity are considered to be equivalent.\n1. If osmolality is the number of osmoles of solute in a kilogram of solvent, then osmolarity is the number of osmoles of solute in a litre of solution.\n2. Osmolarity deals with the concentration of an osmotic solution, while osmolality deals with the concentration of particles in a fluid.\n3. It is easier to determine the osmolality than the osmolarity.\n4. Osmolarity is expressed as Osm/L, and osmolality is expressed as Osm/Kg.\n5. Osmolality is used to determine medical conditions like diabetes, shock and dehydration, while osmolarity is used for the detection of the concentration of dissolved particles in urine.\n6. Osmolality is the commonly used method of measurement in Osmometry.\n7. When the concentration of solutes is very low, the osmolality and osmolarity are similar.\nSearch DifferenceBetween.net :\nEmail This Post : If you like this article or our site. Please spread the word. Share it with your friends/family.\nLeave a Response']	['<urn:uuid:9b9b7bca-694b-4797-ae46-9f1d02753c68>', '<urn:uuid:48ed026a-3bbe-4602-b7f0-c926ed334b05>']	open-ended	with-premise	verbose-and-natural	similar-to-document	comparison	novice	2025-05-13T06:27:57.068978	30	96	1125
55	How do beneficial bacteria in our gut and the bacteria used in hot composting help break down organic materials?	Both gut bacteria and composting bacteria break down organic materials but in different ways. In the human digestive system, billions of beneficial bacteria (known as microflora or gut flora) break down undigested food remains, prevent harmful bacteria from invading the body, and produce vitamin K for blood clotting. The gut microflora consists of 400 different species of bacteria maintaining a crucial balance between beneficial and harmful types. In hot composting, bacteria work alongside other organisms in an aerobic process to break down organic waste at high temperatures (49°C – 77°C). This composting process requires specific conditions including equal parts of green and brown materials, proper moisture levels, and regular turning to introduce oxygen, ultimately transforming organic matter into dark, crumbly compost over about a month's time.	"[""Previously, different types of microbes and the ways they reproduce were discussed. Some microbes are free-living organisms and others are parasites. Even though the words 'microbe' and 'bacteria' are associated with disease for most people, not all microorganisms are 'bad guys'. This topic looks at the interactions between microorganisms and the human body. Microorganisms can be harmless, beneficial or pathogenic, which means harmful. This chapter looks at the beneficial types of microorganisms.\nWhat are beneficial microorganisms?\nApparently, harmless and beneficial bacteria far outnumber the harmful varieties. Microbes are vital to the environment because they participate in the Earth's element cycles like the carbon and nitrogen cycles. Microorganisms are involved in the production of oxygen, biomass control and 'cleaning' the Earth of remnants of dead organisms.\nSome microbes also lead a symbiotic type of lifestyle in most multicellular organisms. The community of beneficial microoraganims living in human intestines is called microflora.\nBecause microorganisms are capable of producing so many enzymes necessary for the building up and breaking down of organic compounds, bacteria are widely 'employed' by humans.\nNitrogen is a very important chemical element of all living matter. It is an essential part of amino acids - the building blocks of proteins. Nitrogen in its gaseous form (N2) makes up 78% of the atmosphere, but it cannot be absorbed and used as a nutrient by plants and animals. It must be converted by nitrifying (nitrosomonas) bacteria, so that it can enter food chains as a part of the nitrogen cycle. The nitrogen cycle is the cyclic movement of nitrogen in different chemical forms from the environment to organisms and then back to the environment. The nitrogen cycle consists of several different processes: nitrogen fixation; ammonification (decay); nitrification; and denitrification. See image 1.\nThe nitrogen cycle is also used in agricultural practices for soil enrichment.\nMicrobes 'clean up' waste products and remnants of dead organisms in a process called decomposition. The decomposition or stabilisation of organic matter by biological action is as old as life itself. The controlled microbial decomposition of organic matter is called composting. The final product of composting is called compost. There are two types of composting:\n- Aerobic- with oxygen.\n- Anaerobic - without oxygen.\nIn these processes, bacteria, fungi, moulds, protozoa and other saprophytic organisms feed upon decaying organic materials initially. In the later stages of decomposition, mites, millipedes, centipedes, springtails, beetles and earthworms further break down and enrich these composting materials.\nThe industrial application of living organisms is called biotechnology. Humans have been using microorganisms for centuries. Today, biotechnology is a fast-developing industry.\nBioremediation is the use of living organisms for cleaning up oil spills and soil and water pollutants. Sewage treatment techniques are based on biofiltration of some toxic organic material by converting it into something that can be safely discharged into the environment. Bacteria that break down environmental pollutants are sometimes called biofilters.\nSome microbes are used for medicinal production. One of the most important groups of medicines, antibiotics, is produced by fungi and bacteria. The name antibiotics means 'against life'. It is appropriate, because they attack bacteria and other unicellular organisms that are pathogenic for humans. Most antibiotics used today were found originally in fungi. Fungi are saprophytes, meaning that they get their nourishment from dead animals or plant matter. See image 2.\nBillions of bacteria live in the human digestive system. They form over a kilogram of our body weight. These bacteria are referred to as microflora, or gut flora. These bacteria break down food remains that have not been digested earlier in the digestive system. They stop harmful bacteria and fungus from invading the body. The 'gut flora' also produces vitamin K, which is essential for normal blood clotting.\nHuman microfolora consists of 400 different species of bacteria. Some of these are beneficial and others are potentially harmful. A balance between the two is vital for human health and wellbeing.\nOne way of maintaining a balance between the beneficial and harmful bacteria in our intestines is to eat the types of food that contain beneficial bacteria. Beneficial bacteria that can be introduced into the digestive system through food are called probiotics. Most commercially-promoted fermented milk products with probiotic properties contain Lactobacillus bacteria or Bifidobacteria. Natural yogurts and Yakult, a fermented milk product, are examples of foods which contain probiotics.\nFermentation is the process that produces alcoholic beverages or acidic dairy products. On a cellular level, fermentation is a way of obtaining energy without using oxygen. Fermentation involves the breaking down of complex organic substances into simpler ones.\nFood like cheese, pickles, olives, sausages, chocolate, bread, wine, beer and soy sauce are all made with the help of different types of bacteria and yeast. In most of these food products, bacteria play a major role because they produce lactic acid. See image 3.\nAs bacteria can multiply and mutate easily, some of them are commonly used for scientific research in genetics and molecular biology. Bacteria and viruses also make good 'vehicles' for engineered genes that are inserted into the recipient's DNA."", 'Creating Hot Compost – A Temperature Guide\nA hot topic today is waste, food waste specifically. Did you know that approximately one third of the food produced in the world for human consumption every year — roughly 1.3 billion tonnes — gets lost or wasted. Fruits and vegetables, plus roots and tubers have the highest wastage rates of any food. All of which can very easily be composted, a fantastic and natural way to get rid of excess food waste. Once the composter is doing it’s job you an even spread the finished result onto your flowerbeds, improving soil quality and reducing the need to use chemical fertilisers and pesticides.\nThere are two different methods of composting: Vermicomposting and Hot Composting. Both methods are very effective and great for the environment however today we will be discussing Hot Composting.\nHot Composting involves throwing organic waste into a large bin or pile. The material then starts to break down using an aerobic process. This method can only really be done outdoors and can handle any amount of organic material. A hot compost pile can easily reach temperatures of 49°C – 77°C in a matter of days, this can produce compost in around 4 weeks if done correctly. You could even use the high temperatures to heat your water, home or greenhouse. Monitoring the temperature of the hot compost pile is a very key step because remaining at a temperature of 65°C or higher for more than a few hours will kill off beneficial microorganisms that add to your compost.\nWhat You Need:\nEqual parts green and brown materials. Fresh grass clippings are great for your first try because they’re already in small pieces, and are full of moisture.\nA compost thermometer ( we recommend the ETI Compost Thermometer, a bi-metal dial compost thermometer incorporating a colour-coded, easy to read dial)\nA fork or shovel for turning\nA tarp (optional)\nA bin/container (optional)\n- Ensure that all the organic matter you are using is chopped into small pieces and combine with brown and green materials as well, You should also add in around a shovelful of pre-made compost or soil, this will be full of microorganisms which will help to jumpstart the process.\n- As the pile starts to build, sprinkle it with some water to keep the organic matter moist.\n- The pile should be roughly one cubic metre in size. Too much larger and the moisture and heat levels will be wrong for a speedy and efficient decomposition. At this stage you could cover the pile with a breathable tarp to maintain moisture, but this isn’t necessary.\n- Over the course of the next month or so you will need to monitor the temperature of your Hot Compost pile daily with your Compost Thermometer. In the first five days the temperature of the pile should rise, between 49°C and 77 °C. The temperature will depend on moisture levels, the size of your organic matter and the size of your pile.\n- Once the temperature begins to cool to below 43°C (usually around 5-7 days) you will then need to turn over the organic matter to introduce oxygen, this will then heat the pile up again.\n- When turning the pile ensure that you push the exterior material into the interior, enabling everything to be broken down evenly.\n- You will need to continue to monitor and record the temperature of the pile everyday and turn the pile every 4-5 days, you can moisten the pile with some water if needed. After roughly one month you should have turned the pile four times.\n- At this point most of the Hot Compost pile will be a dark, crumbly compost and the temperature should have decreased below 29°C.\n- Now you need to let the compost ‘cure’ for a few weeks before using it. Perfect for using on your flowerbeds.']"	['<urn:uuid:716c1fb6-704d-41e3-99be-b51552003f30>', '<urn:uuid:a0a5d61a-687e-4fb6-bfb5-b595ce8fac18>']	open-ended	direct	verbose-and-natural	similar-to-document	comparison	novice	2025-05-13T06:27:57.068978	19	126	1487
56	What are the four standards for UNICEF Rights Respecting School Award?	The four standards are: A) Rights Respecting values underpin school leadership and management, B) The whole school community learns about CRC, C) The school has a Rights Respecting Ethos, D) Children are taught to become active listeners and learners.	['UNICEF and Rights Respecting Schools\nAt Audley Primary School we have UNICEF ambassadors, who work hard to help others in the school learn all about the important work of UNICEF. The UNICEF ambassadors have now been appointed and are busy completing a number of tasks throughout the school year.\nRights Respecting School\nAudley Primary School is proud to be part of the UN Convention of the Rights of the Child, where every child is valued, cared for and developed to their full potential.\nOur aims, values and pledge to the UNCRC awarded us the UNICEF Recognition of Commitment to the Rights Respecting Schools Award. We are now on our journey to becoming a rights-based community in which children are valued and where they are able to thrive. We reflect the belief that the United Nations Convention of the Rights of the Child (CRC) “… gives young people the best chance to grow into respectful, active and resilient citizens.”\nUNICEF (United Nations International Children’s Emergency Fund)\nUNICEF is a worldwide organisation that was founded after the World War 11 in December 1946, to help children that faced famine and disease. It has been working to improve and protect the lives of children and their rights ever since. In 1989, countries across the world adopted UNICEF’s principles of equality, dignity, respect, non-discrimination and participation.\nWhat is a Rights Respecting School?\nA rights-respecting school places the UNCRC at the heart of a school’s planning, policies, practice and ethos.\nA rights-respecting school is a community where children’s rights are learned, taught, practised, respected, protected and promoted. The school community models rights and respect in all its relationships: between teachers / adults and pupils, between adults and between pupils.\nTo achieve the UNICEF UK Rights Respecting School Award, Silver: Rights Aware; we are required to implement four evidence-based standards.\nStandard A: Rights Respecting values underpin the leadership and management of the school\nStandard B: The whole school community learns about CRC\nStandard C: The school has a Rights Respecting Ethos\nStandard D: Children are taught to become active listeners and learners\nWhat are the benefits?\nOn the school\nAudley Primary believes that the principals and values of RRSA, has an undeniably positive impact on the ambience of the learning environment. It supports the school’s collaborative and inclusive approach. Relationships within the whole school community are enhanced from the shared values and the Rights – Respecting Language.\nIncreased levels of respect for each other, leading to improved relationships within the school community\nImproved self- esteem and confidence as a result of knowing they have a voice and are listened to.\nChildren’s engagement in the school and their own learning is enhanced; thus attainment improves.\nChildren feel safe and secure from the consistent practice of rights-respecting language guided by the CRC.\nThere is a reduction in bullying and discriminatory behaviour among children.\nChildren develop a deeper understanding of the diversity of the wider world.\nSupports and promotes a more unified approach across the school.\nThere is greater consultation between adults and children.\nSchool community facilitates participation and discussion between teachers, parents and carers.\nAdults have a shared understanding and commitment towards a common goal.\nSchool community fosters a nurturing approach that aspires to meet the needs of all its children.\nEach class has a Class Charter. These support the philosophy of ‘Everyone has a right…..Everyone has a responsibility’.\nThe RRSA Ambassadors have created a Rights Respecting Lunch Hall Charter to remind all pupils of our expectations:']	['<urn:uuid:a4647458-7523-4b28-8250-6deaba9153e9>']	factoid	with-premise	concise-and-natural	similar-to-document	single-doc	novice	2025-05-13T06:27:57.068978	11	39	579
57	mediterranean style homes vs spanish construction materials used build compare	Both Mediterranean and Spanish style homes utilize stucco walls in their construction. However, while Spanish style homes traditionally used adobe or mudbrick walls (though now mainly use stucco), and feature distinctive red clay or terracotta roof tiles and exposed wooden beams called vigas, Mediterranean style homes are typically built with stuccoed walls and are characterized by their massive, multi-story design with rectangular floor plans and low-pitched roofs. Mediterranean homes tend to be more spacious and likely to have a second floor, while Spanish style homes are often single-story structures.	['Spanish style homes are a familiar sight in warm, coastal regions of the Southwest. They offer a rustic yet elegant look reminiscent of the early Colonial dwellings built by the first Spanish settlers. As Spanish style homes continue to gain popularity in the real estate market, more and more people are wondering just what sets Spanish style homes apart from the rest.\nClick here to learn about other House Styles.\nThe History of Spanish Style Homes\nSpanish style homes have their root in architecture that first came into style hundreds of years ago. Colonists from Spain first brought their architectural style with them across the ocean when they began to emigrate to the U.S. in search of wealth. Catholic missions of the time also helped to create modern Spanish style homes.\nTo this day, many homes in the Southwest of the United States are fashioned in the Spanish colonial style. They’re especially predominant in areas that historically have a heavy colonial influence, such as California and Florida. However, thanks to their popularity, you can find Spanish style houses throughout the world.\nWhy are Spanish Style Homes Gaining Popularity?\nSpanish style homes have a unique charm that attracts people from all walks of life. They speak to a simpler time, with a design resembling ancient wattle and daub structures and a layout reminiscent of the Colonial era.\nMany Spanish style homes are still to this day built of local materials. This helps to benefit the local community, especially local artisans and craft workers. Since construction material is readily available locally, Spanish style homes can also be easier and cheaper to repair.\nBecause they’re typically built in warmer regions, Spanish style homes have perfected natural cooling and airflow. Even without the AC on, many houses are made to keep air flowing and prevent heat from building up indoors.\nMost Spanish style homes feature windows throughout the house to keep a healthy breeze flowing through. Spanish style homes also avoid carpets and heavy draperies that may end up raising internal temperatures. Instead, flooring is usually hardwood or tiling, at least in main living room spaces.\nThe roof is the key to natural climate control within Spanish style homes. Most are made clay or terra cotta, which has natural insulative and reflective properties. The shingles are also designed in a half-moon shape, which further helps to promote airflow and allows rising heat to escape.\nSpanish Vs. Mediterranean Style Homes\nMediterranean and Spanish style homes tend to be very similar in appearance, and it can be easy to get the two confused. Both are inspired in part by Colonial Spanish architecture, with arched windows and doors, stucco walls, red clay roofs, and plenty of outdoor space.\nWhile they might share similarities, however, the two styles are also vastly different. Spanish style homes embrace banks and curves, often with an asymmetrical facade. Mediterranean homes, on the other hand, tend to have straight, clean lines and rely on symmetry. They don’t feature the same curved walls and turrets that grace the facades of many Spanish style homes.\nUnlike Spanish style homes, most Mediterranean houses have an open floor plan. They’re often more spacious. While many Spanish style homes have just a single floor, Mediterranean homes are likely to have a second.\nChoosing Between Different Types of Spanish Style Homes\nThere’s no single style that ultimately defines all Spanish style homes. Often, the term encompasses a wide range of architectural styles. Though the different types of dwellings are similar in design, they all boast key differences that may make certain Spanish style homes a better choice for some than others.\nInspired by the Spanish missions of the 17th and 18th centuries, this style has some of its roots in the oldest Spanish architecture. These homes often somewhat resemble a monastery, with a smooth, flat facade, arched walkways, and even bell towers.\nMission revival designs are often more ornamental than other Spanish style homes. They typically feature trimming and carved accents, often made of terracotta, to match the roof. These houses may also feature extensive stone or masonwork, especially outside.\nSpanish Colonial Revival\nInspired by the work of prominent architect Bertram Goodhue in the early 1900s, Spanish colonial revival homes offer a new take on the classic colonial look. They often feature many ornamental and decorative elements and may take influence from multiple cultures in their design.\nThe colonial revival home itself is also often designed to be both fashionable and functional. Often, designs feature spiral columns, heavy, carved doors, and trimmed tiles, which aren’t often seen in other Spanish style homes.\nPueblo Revival homes embrace simplicity. They’re modeled after the houses of poor Spanish colonists as opposed to wealthy settlers. They often feature little ornamentation, instead opting for a smooth, stark facade.\nInstead of stucco, the walls of Pueblo revival homes are often made of either real or fake adobe. If the walls are painted, it’s usually in earth tones. Edges around the building are rounded to give it a soft, natural look.\nAs the name suggests, this type of house came about during the days when New Mexico was just a U.S. territory. It features influences from Eastern U.S. architecture of the time, including double-hung windows and brickwork.\nMonterey Revival homes are popular in California, especially in Southern regions. They’re often larger than typical Spanish style homes, with many boasting two floors. A second-story balcony is a common fixture in the Monterey Revival style.\nWhat Makes a House Spanish Style?\nIt’s fairly easy to identify Spanish style homes. They have several distinctive design features that make them stand out from the surrounding architecture, including both exterior and interior spaces.\nOutside, the clearest identifier of Spanish style houses is the roof. Most have a bright red, rust-colored roof thanks to using clay or terracotta tiles, though some newer houses may have shingles made of concrete instead. Often, patios, courtyards, and the interior living spaces of Spanish style homes use tiling made of the same reddish material.\nWhile traditional Spanish style homes had walls made of adobe or mudbrick, nowadays, most are made of cheaper, lighter, and more durable stucco. While some houses leave the stucco bare for a rustic look, many homes have facades painted in light, neutral colors.\nInstead of sticking to straight, simple walls, many Spanish style homes incorporate curves into their design. It’s not uncommon to see a house boasting an asymmetrical tower or turret along the side.\nOne of the most striking features found in many Spanish style homes today is the exposed wooden beams known as vigas. The ends of these beams are exposed along the edge of the roof, creating a unique, eye-catching pattern.\nInitially, these were an integral part of the construction of Spanish style homes. Back when they were made of heavyweight adobe, wood beams were used to add extra support around the roof. Nowadays, however, vigas beans are primarily used for aesthetics.\nDoorways and windows are typically arched in Spanish style homes. Windows are usually small but numerous to allow plenty of light and air into the house. The most ornate outer decor is reserved for areas around doors and windows, leaving the rest of the facade looking clean and unadorned.\nInside, Spanish style homes are usually small and cozy. They’re often just a single story high, though they may be larger in rare cases. The interior usually has a color scheme similar to the facade, with plenty of bright, neutral colors.\nSpanish style homes offer a uniquely rustic charm reminiscent of the homes of the very first Spanish settlers. From Mission revival houses to Monterey style dwellings, Spanish style homes are a Southwestern classic on the real estate market.', 'Bungalows can typically be identified by their single story and spacious design. The use of a veranda, or large, open yet covered porch, is another significant identifying feature.\nCalifornia bungalows are almost always single story. Usually equipped with large pillars supporting a veranda. Often this is complemented with a brick chimney on a low pitch roof and tied together with a gable.\nThe craftsman is a modern version of the Californian bungalow. An elegant, sturdy structure built using a large variety of materials and decorative features. The roof is low pitched, and gabled with a porch under the projection of the roof.\nBay villas are extravagantly designed 3-4 bedroom homes with at least one bay window at the front of the house with a gable roof above. Bay villas have high ceilings and a front veranda often decorated with detailed fretwork.\nA cottage is a small modest home. Cottages are designed to be cozy and will usually have a simple rectangular shape.\nThe Bach is a basic structure built for holiday accommodation. They are typically constructed of local, inexpensive materials and have a mono pitch roof.\nColonial style refers to many styles of homes built during that period. They are known for being symmetrical with slimmer side windows on either side of the door. Usually a pair of chimneys will accent these homes.\nVictorian homes are another style of home named for the period of time in which the style began. They will have steep roofs with textured shingles and a partial asymmetrical porch.\nArt Deco designs have stucco walls and stylized facades. The style originated in the nineteen twenties and the houses are known for their geometric vertical design.\nA contemporary home will generally have over-sized windows and modern shapes. Contemporary style houses are modern and constructed of modern materials.\nThe Town House style of architecture describes a row of very similar or identical houses immediately adjacent to each other. They typically share interior walls.\nCommonly recognized for its lancet, or pointed arch, the English style of architecture is very elegant. Easily recognizable by its lack of massive pillars and use of groups of smaller shafts around a central pillar.\nFeatures found on a Tudor style home are quite distinctive. Stone and brick construction, exposed timbers, and steep cross gables are used in this type of house.\nSpanish-style homes are marked by their prodigious use of stucco, chimneys, and tile roofs. The interiors of these homes feature arched passageways and exposed beams.\nMediterranean-style architecture features multi-story, massive design with symmetrical facades. Typically these structures have a rectangular floor-plan, low pitched roofs, and stuccoed walls and are accented around the doors.\nThe Ranch-style home originated in the US and was first seen in 1920’s. Unique styles of the architecture are single story, low profile, and easily adaptable floor plans.\nModern architecture refers to the absence of historical forms or styles. Most often these homes are unadorned with decoration, and are almost mechanical in their aesthetics.\nModern traditional design is an updated version of ranch style houses from the 60’s, 70’s and 80’s. Typically built with brick walls and a hip or gable tiled roof.\nThis style is molded from modern materials: steel, concrete, and glass. These houses are often dramatic, with smooth façades and ground to ceiling plate glass windows.\nItalian-style architecture can be classified by the low pitched or flat, often hipped, roof. Generally it will consist of angled bay windows and glazed doors. Attics with a row of windows between the eave brackets are a notable characteristic.\nUsually constructed using a heavy timber frame of logs, vertically aligned on a sill the French-style will generally have a raised basement and exterior stairs, leading to a full-length porch on the front façade.']	['<urn:uuid:a0d21630-222f-499f-9287-a32e2c40a730>', '<urn:uuid:0a59e348-3dc3-47f6-bb1c-491081155629>']	open-ended	direct	long-search-query	distant-from-document	comparison	novice	2025-05-13T06:27:57.068978	10	89	1904
58	I'm checking out the Visual Studio Test Explorer window, and would like to know how test results are displayed and what execution options are available to run the tests?	In the Test Explorer window, tests can be run individually, all at once, or arranged in playlists using the menu at the top. When a test passes, it will be marked with a green checkbox along with the execution time. Failed tests are marked with a red 'X' and also show their execution time.	['Testing in Visual Studio PrimerDave\nVisual studio offers a variety of tools to perform tests against your application. The tests available range from unit tests to load tests. This article is a primer for using the unit test framework in Visual Studio.\nStrictly speaking, a unit test aims to test a single unit of a code base. Typically, this unit corresponds one-to-one with a class. However, there is nothing in the Visual Studio unit test framework that prevents a developer from testing more than a single ‘unit’. For example, various types of integration tests can also be scripted within the unit test framework. MSDN has frameworks and recommendations for performing various kinds of tests. For a MSDN guided approach, see “Creating System Tests Using Visual Studio”.\nThis article will focus on simply setting up tests within the VS unit test framework. The actual flavor of testing performed within the framework is up to the reader.\nVisual Studio provides a Unit Test project for creating and managing unit tests. The project type can be selected when creating a new project:\nA unit test class is created within the test project by default:\nUsing this default class is a good way to become familiar with the basics of the framework.\nA unit test class is simply a normal class with a few annotations. The [TestClass] annotation flags the complier to (among other things) look for tests within this class. Tests are defined at the method level. A single test corresponds to a method within the test class. Methods intended to be ran as a test are marked with the [TestMethod] annotation. A solution can have any number of test classes each with any number of test methods.\nTo create a test, simply populate a test method. A common approach to creating a test is to script the intended test steps using the Arrange, Act and Assert (AAA) methodology. AAA defines 3 broad steps to scripting a test.\nArrange: Query resources and services. Initialize objects. Essentially, put everything in place needed to test.\nAct: Execute the tests. Coordinate and direct the objects in question to perform the required test.\nAssert: Examine the result of the test and verify the application state is as expected. Test will fail if criteria is not met.\nAs an example, consider the following test:\nILogger logger = newMockLogger(); //Create mock logger\nTestObject to = newTestObject(logger); //Instantiate object to be tested, injecting logger dependency\nto.RunAction(); //Run the desired actions\nAssert.IsTrue(to.StateIsValid()); //Validate application state\nThis a simple yet standard unit test.\nThe domain has been created with maintainability and extensibility in mind. Inversion of control has been implemented using dependency injection to encourage maintainability and extensibility. As a side effect, the domain is easily tested with unit tests. Units are easily isolated for testing by injecting mock objects for dependencies.\n- In the Arrange step, we create a mock logger object. We then inject the mock logger into the object being tested using constructor injection. (Note: Dependency injection is by no means required to run tests, it is in this example simply to help illustrate the Arrange step and follow common conventions for unit testing).\n- We want to test the RunAction() method on TestObject. So, we execute the RunAction() method in the Act step.\n- In the Assert step, we examine the tested object and verify it is in a valid state. We perform these verifications using the unit test Assertobject. The Assertobject provides methods to evaluate conditions. Here we evaluate the conditions IsTrue, however many other evaluations are available such as IsFalse, IsNotNull, AreEqual, AreSame and so on. If the condition being evaluated returns false, the test fails.\nDuring compilation, all the tests in the solution are accessible through the Test Explorer window:\nThe tests can be run individually, all at once, or arranged in playlists using the menu at the top of the Test Explorer window.\nIf a test passes, it will be marked with a green checkbox along with the execution time:\nIf a test fails, it will be marked with a red ‘X’ along with the execution time:\nMany more features are available in the test framework, the above description was provided as a brief overview to quickly become familiar with the test framework in Visual Studio. Even with this simple example one can begin to see the power and utility of the test framework.']	['<urn:uuid:46e5aaa2-f3ef-4837-a9d9-620843caeab0>']	open-ended	with-premise	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-13T06:27:57.068978	29	54	730
59	need to clean outside wall before painting what steps remove moss algae	You need to first remove any moss and algae from the wall. Then clean the rest of the wall using a high-pressure cleaner. Finally, remove any remaining dust with a soft brush to ensure the wall is clean for painting.	['Paint the wall and looking for tips and ideas? With our wide range we are happy to help you gain inspiration, although of course we can also explain how you can best approach this.\nRoughly you can choose from two different techniques for the wall: painting or spraying. Painting the wall is not difficult, you use a roller for the large parts and a brush for the edges. Alternatively, you can spray the wall, for which you naturally need a paint sprayer. It provides a nice smooth result, but also requires some experience and skill with the device.\nIdeas for painting the wall\nDo you decide to paint the wall and are you looking for useful tips? First look carefully at the surface. Is there stucco work? Then use a different roller and brushes than when you want to paint on drywall.\nIn any case, it is important to tap the floor and turn off the power, if there are sockets on the wall that you want to paint. Depending on the surface you choose, it is important to degrease it (stucco wall) or first focus on the existing kit (drywall). In both cases you can sand the wall with some sandpaper around a sanding block, so that you make the right preparations.\nTip: Has stucco been recently applied to the wall and has it not been painted over? Place the wall in the primer to prevent the sucking effect. It is the best tip to prepare the surface for painting on, without the paint being sucked into the wall and you cannot get a tight result.\nThere are of course all kinds of ideas for painting the wall, for example in a specific color or with a beautiful pattern. Let your creativity run free, for example by using two colors or by painting a large surface on the wall that attracts attention. It can be a nice frame for a painting or other beautiful object in your interior.\nWe are happy to give you useful wall paint tips and help you gain inspiration with the different brands. Discover the wall paint from Sikkens , Sigma and Flexa, for example, which you can choose from online. Browse at your leisure through our extensive range. And have you found the paint you want to work with? Tell us which color (RAL code) you are looking for, then we can mix it nicely for you.\nPaint exterior wall\nPaint the outside wall and wonder how you can best handle it? It is important to buy good paint for the outside wall and make the right preparations. Order your paint from Sikkens, Sigma or one of the other A-brands, which we of course have in stock for you.\nPainting with exterior wall paint ensures a beautiful and sleek result. You work on a fresh and well-kept appearance of your house, so that you immediately receive appreciation for your work. And just as important, by painting the outside wall you protect the material against moisture breakdown.\nPaint the outside wall step by step\nDo you want to paint the outside wall and are you curious how you approach that? We list the important steps for you:\nTreating the wall : removing moss and algae Are there any algae or moss on the wall? It is important to remove them first, before you start painting with the outside wall.\nCleaning the outside wall Then\nclean the rest of the wall. You can use a high-pressure cleaner for this. You remove dust with a soft brush so that the wall is clean for painting.\nChecking and repairing joints\nCheck the joints of the wall and repair where necessary. You can scratch out a little crumbly joint, but with more damage you first have to re-joint.\nCovering the floor\nWith this step you are almost ready to paint the outside wall. Cover the top with construction film, so that the brush does not end up in the soil when you start painting the bottom layer.\nPlease note: is there untreated brick? Pre-iron it with a primer for outdoor use. Allow the primer to dry for 12 hours so that you can paint well afterwards.\nYou can get started with the paint on the outside wall. Start with the primer or primer, which is best applied with a block twitter or a fur roller.\nPaint wall by surface You can paint on the outside wall by doing it neatly by surface. Work in areas of approximately one square meter. Paint the edges of the wall and the connections with the frames. Use a brush for this, so that you can then color the ‘surfaces’ with a roller.\nTip: Work from top to bottom and then from left to right. Do that ‘wet in wet’, by letting the surfaces overlap well.\nDots on the ‘i’ with a brush\nAre there any nasty dots and corners left? Use a brush to put the dots on the ‘i’. Tip: prevent the wall from getting dirty quickly? Use a dark color for the bottom 30 cm of the wall. Mud and earth are then less visible, for example due to splashing during a heavy rain shower.…']	['<urn:uuid:f4ad4565-715e-42e6-bf4a-f42a082dbc8c>']	factoid	with-premise	long-search-query	similar-to-document	single-doc	novice	2025-05-13T06:27:57.068978	12	40	864
60	who mixed religion with greek thought	Thomas Aquinas combined Aristotelianism with Christian theology to create a comprehensive philosophical system that had a lasting impact on Western thought.	['Aristotle’s philosophy and science played a significant role in leading to the scientific revolution. His ideas and theories influenced many great thinkers who contributed to the development of modern science. Aristotle was a Greek philosopher who lived more than 2000 years ago, yet his legacy continues to influence the world of science today.\nThe Influence of Aristotle’s Philosophy\nAristotle believed that knowledge could be obtained through observation and experimentation. He emphasized the importance of empirical evidence in understanding the natural world. This approach became known as Aristotelianism and was adopted by many scholars throughout history.\nAristotle’s philosophy on causality was also influential to the scientific revolution. He believed that everything in nature had a cause or purpose, and that understanding these causes would help us understand how things work. This idea laid the groundwork for modern scientific inquiry, which seeks to explain natural phenomena through causal relationships.\nThe Influence of Aristotle’s Science\nAristotle’s scientific works covered a wide range of topics, including biology, physics, and astronomy. His ideas were groundbreaking for his time and paved the way for future discoveries.\nOne of Aristotle’s most significant contributions to science was his classification system for living organisms. He developed a hierarchical system based on shared characteristics, which is still used today in modern taxonomy.\nAristotle also made important observations about motion and gravity. Although his theories were later disproven by scientists like Galileo and Newton, they still paved the way for future discoveries in these fields.\nThe Impact on Renaissance Thinkers\nDuring the Renaissance period, Aristotelianism experienced a revival among scholars who sought to reconcile ancient philosophy with Christian theology. These thinkers believed that Aristotle’s ideas could help them better understand God’s creation.\nOne such thinker was Thomas Aquinas, who combined Aristotelianism with Christian theology to create a comprehensive philosophical system that had a lasting impact on Western thought.\nAnother Renaissance thinker influenced by Aristotle was Francis Bacon, who believed in the importance of empirical evidence in scientific inquiry. He saw Aristotle’s emphasis on observation and experimentation as a precursor to modern scientific methodology.\nThe Scientific Revolution\nThe Scientific Revolution was a period of great innovation and discovery that took place in the 16th and 17th centuries. It was characterized by a shift away from traditional Aristotelianism towards a more empirical approach to science.\nThe works of Galileo Galilei and Isaac Newton, in particular, were instrumental in this shift. They challenged Aristotelian ideas about motion and gravity, paving the way for modern physics.\nDespite this shift away from traditional Aristotelianism, his philosophy and science continued to influence scientific thought throughout history. His ideas about causality, observation, and classification continue to be relevant to modern science.\nIn conclusion, Aristotle’s philosophy and science played a crucial role in leading to the Scientific Revolution. His emphasis on empirical evidence and causal relationships laid the groundwork for modern scientific inquiry.\nHis ideas about classification and taxonomy continue to be used today, while his theories about motion and gravity paved the way for modern physics. Although his ideas were later challenged by other great thinkers, his legacy continues to influence scientific thought today.']	['<urn:uuid:6ca00908-b2e0-4795-bcab-14e2a83d2b03>']	factoid	direct	short-search-query	distant-from-document	single-doc	novice	2025-05-13T06:27:57.068978	6	21	516
61	firearm declaration time requirements us airlines british airways	For U.S. airlines, you must declare firearms upon check-in at the counter. For British Airways, you must notify them at least 72 hours before your flight if you intend to travel with firearms, and you must arrive at check-in at least 2 hours before your flight (or 3 hours if traveling with 10 or more firearms).	"[""Handguns & Weapons on US Airline Travel\nThe rules regarding carrying weapons on an airplane in the United States are simple: Unless you are a law enforcement official, you can´t. Regulations are more complicated for weapons in checked baggage, being a mixture of Transportation Security Administration (TSA) rules and individual airline policies.\nNo Weapons in Carry-On Luggage\nCarry-on luggage has by far the most restrictive set of regulations for U.S. air travel; the only people allowed to carry weapons aboard U.S. airplanes are law enforcement officers. TSA regulations ban all weapons, as well as most tools and sporting items, from carry-on luggage. Even toy and replica firearms are specifically banned. Indeed, just trying to get on a plane with a carry-on weapon of any kind will likely result in your being detained and questioned during the security screening at the airport.\nFirearms of all types, including handguns, may be stowed as checked baggage under certain conditions. TSA requires that a weapon be packed unloaded and in a hard-sided container that is properly locked. You must declare upon check-in that your luggage contains firearms, and you may also be required to fill out a Firearm Unloaded Declaration form at the counter.\nTSA bans from checked baggage the black powder and percussion caps that are commonly used with antique firearms, as well as explosives, flares and fireworks. Past that, whether ammunition is permitted and how it is to be stowed as checked baggage is up to the individual airline. While all six of the major U.S. airlines permit ammunition, their specific requirements vary; check with the airline prior to packing for your flight.\nMost other items that can be used as weapons, such as swords, clubs and spear guns, are permitted as checked baggage. Typically, they can be stowed just as any other form of luggage might be--although fishing spears, archery gear and similar equipment may require special packing, according to a specific airline's regulations. Other items based on chemicals are more complicated. TSA regulations permit pepper and mace sprays to be stored as checked baggage with some restrictions, but not flammable substances or materials containing poisons such as chlorine, and things like spray paint. So, anything involving fire is banned, and a good rule to follow is that any other item involving chemicals that is not specifically allowed is also banned.\nLocks are required on checked baggage for all firearms. TSA recommends that you use one of its approved locks, which can be opened with a master key carried by TSA security personnel. If you use a lock that cannot be opened by a master key, inspectors will cut off and destroy it if you are not present to provide the key. In the case of firearms, if TSA cannot open the container for an inspection, you will be summoned to open it. As this will pose a serious inconvenience, if you are traveling with firearms you should absolutely either use a TSA-approved lock or simply give the lock's combination or key to TSA security personnel after declaring the firearm.\nLeaf Group is a USA TODAY content partner providing general travel information. Its content is produced independently of USA TODAY."", ""Banned and restricted items\nBanned, restricted and dangerous goods are articles or substances that are capable of posing a risk to health, safety, property or the environment. If you wish to carry or transport any such goods, you should be aware of the regulations and any action you might need to take.\nIf you are in any doubt, please contact British Airways for advice before booking.\nItems forbidden for carriage on British Airways by passengers and crew\nThe following list covers all those items that are forbidden to be carried anywhere on British Airways flights:\nDisabling devices - mace, pepper spray, stun guns, tasers, etc.\nExplosives - fireworks, flares, detonators, fuses, dynamite, etc. (except small arms ammunition - see 'Restricted Items' below.)\nSecurity-type attach é cases containing dangerous goods - pyrotechnic devices, etc.\nElectro shock weapons - e.g. Tasers, containing dangerous goods such as explosives, compressed gases. lithium batteries, etc.\nBlunt instruments capable of causing injury\nStrike anywhere matches\nFlammable gas cylinders\nFlammable liquids - paint, petrol, lighter refills, solvents, varnish, etc.\nFlammable solids - firelighters, Chinese lanterns, etc.\nSubstances liable to spontaneous combustion - Phosphorous\nSubstances that emit flammable gases in contact with water\nOxidising materials - bleach, peroxides, some fertilisers, etc.\nCorrosives materials - acids, alkalis, wet cell batteries, etc.\nToxic (poisonous) substances - weed killer, insecticides, etc.\nPlease note: If you're departing from non-EU countries then prohibited items may vary. If in any doubt, please check with the relevant airport authorities in advance.\nRestricted items requiring notification to British Airways\nThe following list covers the items that may be carried on flights with British Airways but require the airline's approval prior to flying and where quantities or regulation of the items are restricted:\nObjects with a sharp point or sharp edge - knives with blades of more than 6cm, axes, swords and other similar implements. Small knives and scissors can be packed in your checked in baggage.\nFirearms and/or Ammunition - see Carriage of Firearms and Ammunition below.\nCamping stoves and fuel containers\nSolid carbon dioxide (dry ice)\nHeat-producing articles - underwater torches, soldering irons, etc.\nMercury-filled items - barometers, thermometers, etc.\nAvalanche rescue pack\nLife jackets - containing non-flammable gas cylinders\nChemical agent monitoring equipment\nInsulated packages containing refrigerated liquid nitrogen\nPortable medical electronic devices - automated external defibrillators (AED), nebulizers, Continuous Positive Airway Pressure (CPAP) containing lithium batteries.\nLithium ion batteries - with a Watt-hour rating exceeding 100 Wh but not exceeding 160 Wh.\nOxygen and other small cylinders for medical use\nWheelchairs and mobility aids - powered with either non-spillable, spillable or lithium batteries\nIf have any of these restricted items, you should contact British Airways:\nat the time of booking\nat least 24 hours prior to departure\nRestricted items needing no notification\nThe following list covers all items that may be carried on British Airways flights but are still restricted to specific limits on quantities or dimensions:\nSmall knives and scissors can be packed in your checked in baggage\nAerosols - non-flammable for sporting and home use\nNon-radioactive medicinal or toilet articles - hairsprays, perfumes, colognes, medicines, etc.\nNon-flammable, non-toxic gas cylinders - e.g. for operation of mechanical limbs, bicycle tyre inflation devices (max. capacity 50ml)\nDevices containing lithium cells or batteries - laptop computers, cameras, camcorders, etc.\nSpare lithium batteries (less than 100 Wh)\nA few simple measures can be taken to ensure that spare batteries are carried safely:\n- Always pack spare batteries in your cabin baggage.\n- Where possible keep spare batteries in their original retail packaging (e.g. cardboard/plastic blister packs) which ensure that the terminals are protected.\nIf the original packaging is not available, insulate the battery terminals so they cannot come into contact with any metallic objects:\n- by packing each battery in its own protective plastic bag (e.g. sturdy freezer or sandwich bag)\n- by covering the terminals with insulation tape.\nIt is strongly recommended that both the above measures are taken for batteries with protruding or sharp terminals.\nHair-curlers containing hydrocarbon gas\nRadio-isotopic cardiac pacemakers\nCarriage of Firearms and/or Ammunition\nRestrictions and limitations\nAll firearms (including replica and decommissioned) and ammunition are restricted under UK law.\nAmmunition (cartridges for weapons, small arms) in Division 1.4S (UN 0012 or UN 0014 only), must be securely packaged and in quantities not exceeding 5 kg (11 lb) gross weight per person for that person's own use, excluding ammunition with explosive or incendiary projectiles. Allowances for more than one passenger must not be combined into one or more packages.\nNotify us before you fly\nYou must call one of our contact centres at least 72 hours before your flight if you intend to travel with firearms and/or ammunition. This is to ensure compliance with UK government (or other local government) embargoes and restrictions. Failure to comply with this notification requirement will result in refusal of carriage.\nNotification must include:\n- Type (handgun, rifle, shotgun)\n- Quantity (weight) and calibre\nTravelling on British Airways flights operated by other airlines\nIf you are planning to make a booking on ba.com that includes a flight operated by an airline other than British Airways, please contact us before booking to check that the other airline is able to carry your firearm.\nPlease note: You will not be able to take any firearms, including sporting rifles, on any flights operated by Comair.\nAll passengers intending to travel with firearms and/or ammunition must ensure they have the required documentation and licences for their firearms and ammunition. This includes export/import licences and authorisation from local and national authorities.\nWhen you travel with firearms and/or ammunition you must be at check-in at least 2 hours before your flight, to allow sufficient time to process the paperwork prior to clearing security.\n(Note: groups or individuals travelling with 10 or more firearms or boxes of ammunition must be at check-in at least 3 hours before their flight.)\nChecking in at London Heathrow\nTo check in, proceed to the Assistance Desks located at the end of Zones B/C/D/F/G in Terminal 5 or in Zone G at Terminal 3. Customers in First, Club World and Club Europe should continue to use the respective First and Club check-in zones in Terminals 3 and 5.\nTransferring through London\nIf you are transferring through London, you must allow a minimum connecting time of 3 hours between flights.\nEach case containing firearms and/or ammunition is subject to a £50 each way charge at check-in. Firearms and ammunition are handled by a specialist third party agent on our behalf; this charge covers their costs.\nFirearms and/or ammunition will be accepted provided they are packed in an appropriate carriage case, or if this is not possible, packed securely inside a suitcase with your personal effects. If the firearm and/or ammunition is carried in addition to your free checked baggage allowance, extra bag charges will also apply.\nPacking requirements for South Africa or Italy\nFirearms and ammunition are not allowed in hold luggage with general personal possessions.\nAll firearms have to be packed separately from the ammunition and must be in a locked firearms case.\nThe ammunition must be separate and in its own locked bag/container.\nIn these instances you will not be charged for the extra bag(s) but will be subject to the appropriate handling fee(s).\nPreparing firearms for travel\n- Each firearm carried must be accompanied by the appropriate firearms certificate.\n- The firearm must be unloaded.\n- There will be no additional cost for the carriage of ammunition packed with the firearm*.\n- Ammunition must be packed in either its original packaging or in a suitable container that prevents movement between shells or cartridges, i.e. loose ammunition is not permitted.\n- Bags with ammunition must not bear 'explosives' labels.\n- The Heavy Bag Charge will apply to all bags over 23kg.\n*If ammunition is carried on its own without a firearm, the £50 charge will still apply as special handling for the item is still required.""]"	['<urn:uuid:f071069c-a856-43f6-8700-0635e9c29e06>', '<urn:uuid:da0e7f04-91dd-4452-ae6e-20d42c502aba>']	factoid	with-premise	short-search-query	similar-to-document	comparison	novice	2025-05-13T06:27:57.068978	8	56	1849
62	Which is more common in older people, visual impairment or cognitive impairment?	Cognitive impairment is more common than visual impairment in older people. According to the 2017 statistics, 13.5% of people over 75 had cognitive impairment compared to 9.3% who were visually impaired. The prevalence of cognitive impairment increases even more with age, with about 25% of people over 85 years having both cognitive impairment and depression.	"[""Visually, Cognitively, and Mobility Impaired Numbers\nDelivered July 16, 2019. Contributor: Shannon L.\nTo better understand the primary demographic of those who are visually impaired, cognitively impaired, and have impaired mobility among people aged 75 to 100, and to determine how that demographic changes over time.\nPreliminary research indicates that most statistics on visual, cognitive, and mobile disabilities are aggregated for people over the age of 75. The U.S. Census' oldest age bucket is 75+ and nearly all other studies use this same bucket. We found the following information that may be useful:\nUsing American FactFinder, we can find visually impaired statistics for 2017 for people who are 75 years old and older, but there is no breakdown above that. A screenshot of the data can be found here.\nThe percentage of visually impaired people over the age of 75 compared to the general population as of 2017 is 9.3%.\nCharts on the Vision Atlas provide moderate-to-severe visual impairment (MSVI) statistics broken down by age to 90+ on a global basis.. Using the data found for the U.S. and the data found globally, there may be a way to triangulate the estimated number of people with MSVI in the U.S. for people ages 75, 80, 85, and above 90.\nUsing American FactFinder, we can find cognitively impaired statistics for 2017 for people who are 75 years old and older, but there is no breakdown above that. A screenshot of the data can be found here.\nThe percentage of cognitively impaired people over the age of 75 compared to the general population as of 2017 is 13.5%.\nThe Alzheimer's Disease Facts and Figures report for 2018 contains numbers of people with Alzheimer's-related impairment by state.\nThere are global statistics for people who are 85 years old with mild cognitive impairment (MCI) (37%), which may be used to triangulate an approximate percentage of people in the U.S. who are 85 years old and have MCI (using global proportions and applying them to U.S. numbers). Upon further research, there may be statistics for other ages as well.\nFor instance, the same report notes that 6% of the global population in their 60s has MCI. Since the data is available for the U.S. population in their 60s, it may be possible to use the percentage increase from the global figures and apply that to the U.S. figures as well.\nUsing American FactFinder, we can find ambulatory difficulty statistics for 2017 for people who are 75 years old and older, but there is no breakdown above that. A screenshot of the data can be found here.\nThe percentage of people with ambulatory difficulty over the age of 75 compared to the general population as of 2017 is 31.8%.\nA study conducted in 2017 shows that the prevalence of gait disorders in people between the ages of 60 and 69 is 10%, but that increased to 60% by age 80. Again, with more research, data for other ages may be available, but it will likely need to be compiled from several different reports and studies.\nREPORTS THAT MAY CONTAIN DISABILITY STATISTICS\nWe found a list of reports that may contain statistics on disabilities in the U.S., but a spot check shows they are all based off the American FactFinder census data that is mentioned above.\nOnly the project owner can select the next research path."", 'Depression and Cognitive Impairment in Older Adults\nDepression and Cognitive Impairment in Older Adults\nDepression is primarily a mood disorder, but it can also be viewed as a cognitive disorder for many older adults. In community samples, the co-occurrence of depression and cognitive impairment doubles every 5 years after the age of 70 years, and they are estimated to co-occur among at least 25% of persons older than 85 years.1 One of the clinical implications of the co-occurrence of depression and cognitive impairment is that there is a higher risk of adverse outcomes for physical health, functional status, and mortality than from each condition alone.2 Moreover, research suggests that depression in late life may be a prodromal symptom of Alzheimer disease3,4 or a risk factor for dementia in general.5-7\nThe clinical challenge of treating geriatric depression with cognitive impairment is determining the extent to which cognitive changes are caused by depression versus underlying brain pathology. With the growing aging population in the United States and many other countries, it is important for mental health professionals to develop skills to diagnose and treat cognitive impairment in older patients with depression.\nFor the purposes of this article, our use of the term ""depression"" refers primarily to symptoms that occur in major depressive disorder (MDD), which is defined as 1 or more episodes of neg-ative mood and sadness sufficient to interfere with daily living.8 The prevalence of depression is nearly twice as high in women as it is in men.9 Community-based studies estimate that 30% of individuals first experience depression in later life (at approximately age 60 years), 40% first experience depression earlier in life, and 30% are difficult to categorize reliably because of problems with retrospective recall of past depressive symptoms.10\nLate-onset depression is more frequently characterized by medical comorbidities, greater apathy, greater cerebrovascular pathology,11,12 more extensive cognitive impairment, and a stronger association with dementia.3 Early-onset depression is more frequently associated with psychiatric comorbidities, family history of mood disorder,13 and volume loss in the hippo-campus when untreated or recurrent.14,15\nAlthough the assessment of cognitive impairment in geriatric depression is predicated on an accurate assessment of depression itself, a full discussion of the clinical assessment of depression is beyond the scope of this article. Table 1 provides a list of elements that are important to a comprehensive evaluation of geriatric depression. In this article, we focus on interviewing and screening for depression, the influence of medical comorbidities on cognitive impairment and depression, and the differentiation of cognitive impairment secondary to depression from comorbid depression and Alzheimer disease.\nThe neurobiology of depression\nResearch on the neurobiology of depression has provided important insights into the interrelationship between dysfunctions in mood and cognition. One neurobiological model proposes that a ventral neural system functions to guide affective responses based on the emotional significance and reward value of a stimulus, while a dorsal neural system functions to analyze, monitor, and regulate affective responses to internal thoughts and external events that have high emotional valence.16,17\nThe ventral system includes the ventral regions of the anterior cingulate gyrus and prefrontal cortex, the amygdala, insula, and ventral striatum; the dorsal system includes the dorsolateral and dorsomedial prefrontal cortices, the hippocampi, and the dorsal anterior cingulate gyrus. Abnormality or damage in the ventral system can lead to decreased motivation and lack of reinforcement from positive experiences, whereas abnormality or damage in the dorsal system can produce dysregulation of emotional responses and exacerbation of negative affect. This broad neural system receives projections from 3 key neurotransmitters linked to depression: serotonin, dopamine, and noradrenaline.18 Emotional and cognitive processes are regulated by both systems, and dysfunction in one system may produce dysfunction in the other.\nWhile many persons with depression experience slowed thinking and concentration difficulties, the presentation of cognitive deficits is more heterogeneous among older adults. Depressed elderly persons typically perform worse than nondepressed elderly on neuropsychological measures of informa- tion processing speed19,20; cognitively demanding processes of selective attention, response inhibition, and performance monitoring (otherwise known as executive functions)21,22; and the ability to learn and recall new information.22,23 In many cases, these underlying deficits are reflected in a patient\'s subjective complaints (Table 2).\nNeurocognitive deficits involving processing speed and executive functions are more common when first onset of depression occurs in late life, and even more so when apathy is a prominent symptom.21,24 In many cases, the combination of slowed processing, executive dysfunction, and apathy are associated with underlying cerebrovascular pathology involving frontal and subcortical brain regions.25,26 Other research suggests that older adults with a history of early chronic depression have a more selective deficit in memory,27 probably caused by reductions in hippocampal volume.14,28,29\nEven though elderly persons who are depressed tend to demonstrate more cognitive deficits than nondepressed elderly, a smaller proportion of depressed individuals have impaired cognitive function. Mild cognitive impairment was first proposed to characterize a state of abnormal cognition with a high risk of progression to Alzheimer disease,30 but it is increasingly used in depression to characterize depressed individuals with comorbid cognitive impairment in the absence of dementia.\nThe prevalence of mild cognitive impairment in depression ranges from approximately 25% to 50%,31-33 which is substantially higher than the 3% to 6% prevalence of conventional mild cognitive impairment in studies of individuals who are not depressed where memory is the focal deficit.31,34 An important clinical implication is that mild cognitive impairment or other cognitive impairment during an episode of depression may persist after improvement from the depression symptoms themselves, ranging from one third of individuals with persistent multiple cognitive deficits 1 year after the onset of depression35 to a 4-fold likelihood for impairments in memory to persist 1 year later among individuals who are in remission.33\nWith or without cognitive impairment, the occurrence of depression in later life is a clinical concern because it may be either a risk factor for or an early symptom of dementia. Several studies have found a higher risk of dementia among persons with a remote history of depression (10 to 25 years before onset of dementia),7,36,37 but they also reveal an increased risk for dementia with decreased time between depression onset and dementia diagnosis, which suggests that onset of depression in later life is either a prodromal symptom or that it creates susceptibility for later dementia.\nSymptoms consistent with a major depressive episode range from 10% to 30% in patients with mild and moderate Alzheimer disease,38,39 with an additional 20% to 30% of individuals having other depression syndromes.40 Higher rates of depression are seen in patients who have vascular dementia.41 It is likely that depression is a dementia risk factor for some individuals, while for others it is an early sign of dementia, particularly when the first onset of depression occurs later in life. The key question is which features of affect and cognition best identify which of these respective groups depressed patients fall into.\nDiagnosing depression and cognitive impairment\nClinical screening questionnaires should not be used to formally diagnose depression, but they do provide important information to help identify at-risk individuals by characterizing the nature and extent of symptoms that are associated with depression. The Geriatric Depression Scale (GDS) was developed and validated for use with older adults; as such, it avoids somatic and sexual symptoms, surveys subjective experiences of cognitive impairment, and uses simple yes/no items that decrease cognitive burden.42,43 A 15-item version of the GDS requires 5 to 10 minutes to complete and is satisfactory for most screening purposes,44 with a depression cut-off score of 5 or more.']"	['<urn:uuid:296f78a5-ded7-4cfe-b9a8-fe10f3feb26e>', '<urn:uuid:1a72d931-a862-4781-8db4-c8c6514d227e>']	factoid	direct	concise-and-natural	similar-to-document	comparison	novice	2025-05-13T06:27:57.068978	12	55	1805
63	what is the meaning of lymph node in anatomy transparent fluid knots	A lymph node is an organ that filters lymph (transparent fluid) and produces lymphocytes. They were first described as lymph glands.	"['Histology Glossary - L\n|Embryology - 28 Oct 2020 Expand to Translate|\n|Google Translate - select your language from the list shown below (this will open a new external page)|\nالعربية | català | 中文 | 中國傳統的 | français | Deutsche | עִברִית | हिंदी | bahasa Indonesia | italiano | 日本語 | 한국어 | မြန်မာ | Pilipino | Polskie | português | ਪੰਜਾਬੀ ਦੇ | Română | русский | Español | Swahili | Svensk | ไทย | Türkçe | اردو | ייִדיש | Tiếng Việt These external translations are automated and may not be accurate. (More? About Translations)\nA Glossary of Histological and Micro-Anatomical Terms\n|Histology Glossary: A | B | C | D | E | F | G | H | I | J | K | L | M | N | O | P | Q | R | S | T | U | V | W | X | Y | Z|\n|Including historical origins and eponyms compiled by Dr Brian Freeman, Department of Anatomy, School of Medical Sciences, revised 2000.|\n|ANAT2241 Support | Histology | Histology Stains | Historic Terminology | Embryology Glossary\n|Abbreviations: ( ) plural form in brackets, A. Arabic, abb. abbreviation, c. circa =about, F. French adj. adjective, G. Greek, Ge. German, cf. compare, L. Latin, dim. diminutive, NA. Nomina anatomica, q.v. which see, OF. Old French|\nlabial adj. L. labialis = of the lips, L. labium = lip, rim of a vessel.\nlabyrinth G. labyrinthos = maze; canals (bony labyrinth - Fallopius, c. 1550) and ducts (membranous labyrinth) of inner ear; renal labyrinth = mass of convoluted tubules of the kidney cortex; hepatic labyrinth = all sinusoidal spaces in liver.\nlacis cells polkissen cells, q.v.\nlacrimal adj. L. lacrima = a tear-drop.\nlacrimal caruncle caruncle found on the conjunctiva of the inner canthus of the eye.\nlacteal L. lac = milk ( lacteus = of milk, lactare = to suckle); intestinal lymphatic, containing chyle after a fatty meal.\nlactiferous L. "" + ferre = to carry.\nlacuna (-ae) L. = a pit, a small hollow space, a dimple, dim L. lacus = lake.\nlagena L. lagynos = a flask; closed apex of cochlear duct.\nlamella (-ae) L. = a little plate, a scale, dim. L. lamina .\nlamellar bone secondary bone; of collagen & osteocytes arranged into Haversian systems & interstitial laminae.\nlamina (-ae) L. = plate or layer; hence adj. laminated.\nlamina propria (-ae -ae) L. "" + propria = belonging to; layer of connective tissue under epithelium.\nLanger, Carl Ritter von Edenberg. 1819-1887 Vienna anatomist; L.\'s lines = natural cleavage lines of skin due to pattern of fibres in dermis (1862).\nLangerhans, Paul. 1847-1888 Freiburg anatomist & pathologist; islets of L. = endocrine tissue in pancreas (1869); L. cell = a cell type of epidermis.\nLanghans, Theodor. 1839-1915 German anatomist & pathologist; L. layer = cytotrophoblast layer of chorionic villi.\nLanterman, A. J. (no dates) American anatomist at Strasbourg; clefts of Schmidt-Lanterman = oblique clefts in myelin sheath (1877); internodes of L.; cf. Schmidt.\nlanugo L. = down (from L. lana = wool); downy hair of body, especially cheeks; hair of fetus from fifth month of development.\nLeeuwenhoek, Antony van. 1632-1723 Dutch draper, civil servant & amateur microscopist; perfected the simple microscope with a single glass bead as a lens; described accurately the form of spermatozoa; described striations in skeletal muscle, bacteria, dental canals, bony canals, optic nerve fascicles, etc.; L.\'s canals = Haversian canals (Havers, q.v.).\nLeishman, William B. 1865-1926 British medical officer; L.\'s stain for parasites, and blood films.\nlens L. = a lentil; referring to shape of crystalline structure in the eye.\nleptomeniges (pl.) G. leptos = thin + menix = a membrane; pia mater & arachnoid taken together (opposite to pachymenix, q.v.)\nleucocyte G. leukos = white + kytos = hollow vessel; white blood cell (also leukocyte).\nleucopoiesis G. "" + poiein = to make; production of white blood cells.\nLeydig, Franz von. 1821-1908 Würzburg, Bonn histologist; a founder of comparative histology; L. cells = interstitial cells of testis.\nLieberkühn, Johann Nathanael. 1711-1756 Berlin anatomist & physician; crypts of L. = simple tubular intestinal glands (1745).\nlien L. = the spleen (? from G. leios = soft, smooth).\nligamentum nuchae L. ligamen = a bandage + -mentum = a suffix denoting an instrument of the action + corruption of A. nukha = upper end of spinal cord (medulla oblongata), later the neck itself; the dense elastic ligament found in neck of grazing animals, e.g., cattle.\nlimbus L. = border, edge; e.g., limbus of the cornea at its junction with sclera; spiral limbus, q.v.\nlimen L. = threshold, a still; limen insulae = medial part of apex of insula; limen nasi = ridge marking entrance to nasal cavity.\nlingual adj. L. lingua = tongue.\nlipofuscin G. lipos = fat + L. fuscus = brown; yellow-brown intracellular pigment accumulating in old muscle cells & neurons.\nliquor folliculi L. = fluid of a follicle (ovarian).\nLissauer, Heinrich. 1861-1891 Breslau physician; L.\'s tract = marginal zone of dorsal horn of spinal cord.\nLittré, Alexis. 1658-1726 Paris anatomist & surgeon; glands of L. = mucous glands in penile urethra (1700).\nlobule L. lobulus = a small lobe, dim. L. lobus = lobe, from G. lobos .\nlocule L. loculus = a small place; dim. of L. locus ; a cavity or chamber; used to describe unilocular & multilocular adipocytes.\nlocus cinereus L. locus = a place + cinereus = grey; a pigmented area in superior part of floor of 4th ventricle; also called locus coeruleus (L. coeruleus = dark blue).\nLower, Richard. 1631-1691 London physician; experimeted with blood transfusion; described vortex of cardiac muscle; L.\'s tubercle = a crest between the inferior and the superior venae cavae in the posterior wall of the right atrium.\nlumen L. = light; space enclosed by tubular or vesicular structure; hence luminal.\nLuschka, Hubert. 1820-1875 Tubingen anatomist; foramina of L. = two lateral apertures of fourth ventricle (1855, 1863); glands of L. = glomus coccygeum, q.v.; tonsil of L. = pharyngeal tonsil.\nlutein cells L. luteus = yellow; cells of corpus luteum containing much lipid and appearing yellowish.\nluteum L. luteus = yellow; cf. corpus luteum.\nLuxol fast blue stain for myelin sheath of nerve fibres.\nlymph L. lympha = pure spring water, transparent fluid; found in lymphatics (appears milky in intestinal lymphatics).\nlymph node L. "" + nodus = knot; first described as lymph glands; organs filtering lymph and producing lymphocytes.\nlymphatic adj. L. lymphaticus = frantic, panic-stricken (related to rabies or hydrophobia); now related to lymph; also a lymphatic capillary.\nlymphocyte L. lympha = transparent fluid + kytos = hollow vessel; a type of white blood cell, found in tissues and organs, also found in blood and lymph.\nlymphoid adj. L. lympha + G. -oeides = form of.\nlymphokine L. "" + G. kinesis = movement; chemotactic substance produced by T-lymphocytes attracting macrophages to site of infection.\nlysis G. = dissolution.\nlysosome G. "" + soma = body; membrane-bound cell organelle, part of intracellular digestive system.\n- Histology Glossary: A | B | C | D | E | F | G | H | I | J | K | L | M | N | O | P | Q | R | S | T | U | V | W | X | Y | Z | ANAT2241 Support | Histology | Histology Stains | Embryology Glossary\nCite this page: Hill, M.A. (2020, October 28) Embryology Histology Glossary - L. Retrieved from https://embryology.med.unsw.edu.au/embryology/index.php/Histology_Glossary_-_L\n- © Dr Mark Hill 2020, UNSW Embryology ISBN: 978 0 7334 2609 4 - UNSW CRICOS Provider Code No. 00098G']"	['<urn:uuid:4bb5ffc0-0615-4493-bf36-ae5f037230ca>']	factoid	with-premise	long-search-query	similar-to-document	single-doc	novice	2025-05-13T06:27:57.068978	12	21	1279
64	environmental changes tibet southern china comparison	Tibet and southern China underwent significant but different environmental changes over time. Tibet experienced a shift from a warm, humid period with extensive forests and lakes to a colder, drier climate during the New Ice Age, resulting in saltier lakes, declining peat bogs, and a transition from forests to steppe and desert steppe. Meanwhile, southern China transformed from an arid/semi-arid environment with drought-resistant vegetation in the Paleocene-early Eocene to a humid monsoon climate by the middle Eocene, marked by the development of subtropical wet evergreen and deciduous broad-leaved mixed forests.	"['By Yeshe De Project, Yeshe De Project Staff\nOctavo. colour illustrated wraps. xi, 371 pp, illustrations. close to effective.\nRead Online or Download Ancient Tibet : research materials from the Yeshe de Project. PDF\nBest india books\n""Rare Animals of India"" is a different e-book that offers the organic and ecological bills of the least identified animal species of India in a single entire quantity. The ebook provides finished ecological bills supported with info tables on infrequent and particular animal species of India and discusses the foundation for his or her rarity and their conservation.\n21 riveting tales from the battlefield approximately how India’s optimum army honour was once won\nThe courageous takes you to the hearts and minds of India’s bravest infantrymen, all of whom gained the Param Vir Chakra, India’s maximum army honour. With entry to the military, households and comrades-in-arms of the warriors, Rachna Bisht Rawat paints the main vibrant portrait of those males and their outstanding deeds.\nHow demanding is it to struggle at 20,000 ft in sub-zero temperatures? Why did Captain Vikram Batra say ‘Yeh dil maange more’? How do other halves and girlfriends of squaddies who don’t go back cope? What occurs while the enemy is somebody that you\'ve knowledgeable? How did the Charlie corporation thrust back the marauding chinese language? How did a villager from Uttar Pradesh develop into a expert in destroying tanks?\nBoth gripping and encouraging, The courageous is the final word publication at the Param Vir Chakra.\nWritten through a extremely popular pupil within the box, this can be the 1st released learn at the Greek kingdoms of Bactria and India that treats them as Hellenistic states. The ebook starts with an summary of the Seleucid cost, supplying a heritage to the kin among Greeks and Asiatics after the dying of Alexander the nice.\n- Another Reason: Science and the Imagination of Modern India\n- Geek Nation: How Indian Science is Taking Over the World\n- Origins and Migrations in the Extended Eastern Himalayas\n- Surviving Bhopal: Dancing Bodies, Written Texts, and Oral Testimonials of Women in the Wake of an Industrial Disaster\n- Credit, Markets and the Agrarian Economy of Colonial India\n- Darkest India\nAdditional resources for Ancient Tibet : research materials from the Yeshe de Project.\nThe far north was still quite cold and not so moist as the south and east, which were more humid and more heavily forested than today. Many lakes and swamps dotted the landscape, and the climate was tropical enough around Chab-mdo for ferns and brake to grow. C. a cold period, known as the New Ice Age, set in a:r:ound the world. Rapidly the climate in Tibet became drier and harsher, similar to the present. Lakes diminished and became saltier, while peat bogs and marshes declined. Forests shifted toward steppe, and steppeland shifted toward desert steppe.\nThe climate became even warmer and more humid than it is now; vegetation was more lush, and glaciers were no greater in extent than they are at present. New lakes formed from melting glaciers, and older lakes became fresher and deeper. Forests of pine and birch grew around many lakes, even in the Himalayas. The far north was still quite cold and not so moist as the south and east, which were more humid and more heavily forested than today. Many lakes and swamps dotted the landscape, and the climate was tropical enough around Chab-mdo for ferns and brake to grow.\n46 The Land The Ice Age lasted until 14,000 years ago, but was punctuated by many warmer periods called interglacials that might last 10,000 years or more. As the climate shifted between glacial and interglacial, the vegetation on the Tibetan plateau shifted back and forth between forest and steppeland. In glacial times, the forests receded from mountain slopes; sometimes sparse spruce and fir forests would survive in sheltered valleys, but much of the landscape was treeless, shrubby grassland and steppe.', 'The modern environment of southern China is dominated by a humid monsoon climate, and presents a striking contrast to the widespread deserts found at similar latitudes elsewhere. The formation of a monsoon climate marks a major environmental shift in southern China during the Cenozoic; however, the origin and possible driving mechanism of the climate transition remain unclear. A detailed comparison of Paleogene palynological records and an investigation of the temporal evolution of palynoflora during the Paleogene, especially the Eocene, would provide helpful insights into the evolution of climate patterns and the initiation of the monsoon in southern China.\nIn this paper, they concentrate on the Paleogene palynological records from seven basins (Fig. 1) throughout southern China. The Paleogene palynoflora reveals two completely different vegetation and climate patterns: the Paleocene to early Eocene was characterized by a relatively high abundance of xerophilous Ephedripites and drought-resistant Pterisisporites, suggesting an arid/semi-arid climate; while the middle Eocene to Oligocene was composed of subtropical wet evergreen and deciduous broad-leaved mixed forest characterized by a significant increase in broad-leaved, coniferous taxa, and the almost complete disappearance of xerophilous taxa, together indicating the emergence of a warm-humid climate at this time.\nThey summarize the evolution of climate patterns in southern China during the Paleogene using paleoenvironmental maps for five different time intervals, based on palynological records and other geological indicators, and reveal that the major environmental transition occurred roughly around the middle Eocene (Fig. 2); this transition may mark the establishment of the monsoon climate. Furthermore, the middle Eocene climatic parameters obtained by the Coexistence Approach (CA) were compared with those of modern sites under individual climate regimes; the reconstructed climatic parameters were most similar to those of the modern EAM climate in South China, while being distinct from those of modern Indian monsoon or Inter-Tropical Convergence Zone (ITCZ) monsoon (Fig. 3). These results further support the previous view that an EAM, similar to that of the present, has prevailed in southern China since as early as the middle Eocene.\nThe evolution of the Paleogene palynoflora in southern China is largely consistent with global climate change. They infer that the enhancement of the East Asian winter monsoon during the middle Eocene was closely related to long–term global cooling, while the intensified East Asian summer monsoon was primarily caused by the northward drift of the Indian Subcontinent and the uplift of the Tibetan Plateau (Fig. 4).\nThis work has recently been published in Review of Palaeobotany and Palynology, entitled “A major environmental shift by the middle Eocene in southern China: Evidence from palynological records”. The authors include Dr. Yulong Xie, Prof. Fuli Wu and Xiaomin Fang (from Institute of Tibetan Plateau Research, Chinese Academy of Sciences). This work is supported by the Strategic Priority Research Program of Chinese Academy of Sciences (XDA20070201), the Second Tibetan Plateau Scientific Expedition and Research (2019QZKK0707), CAS “Light of West China” Program, Basic Science Center for Tibetan Plateau Earth System (CTPES，No. 41988101-01) and the National Natural Science Foundation of China (41620104002).\nFig. 1. Map showing the geographic location of southern China and the position of the seven basin study sites.\nFig. 2. Paleogene environmental patterns in southern China. (a) Paleocene; (b) Early Eocene; (c) Middle Eocene; (d) Late Eocene; and (e) Oligocene.\nFig. 3. (a) Comparison between estimated temperature regimes in the middle Eocene (pink) at four study sites and modern sites in different monsoon areas. (b) Comparison between estimated precipitation seasonality and MAP in the middle Eocene (pink) at four study sites and modern sites in different monsoon areas.\nFig. 4. Comparison of Paleogene palynological records of southern China, with global climate change expressed by deep-sea δ18O records (modified from Zachos et al., 2001) and tectonic events (Wang et al., 2008, 2014; Molnar and Stock, 2009; Copley et al., 2010).']"	['<urn:uuid:eb77ccb3-1d3d-4830-8bd3-a21b4c1d049b>', '<urn:uuid:0f748631-9f99-47d1-9336-e3dc5ad2d295>']	open-ended	direct	short-search-query	similar-to-document	comparison	expert	2025-05-13T06:27:57.068978	6	90	1284
65	How do Zagreb's modern cultural institutions like the National Library and Green Pavilion Restaurant balance their service capacity with environmental considerations in their architectural design?	These Zagreb institutions demonstrate careful balance between service capacity and environmental considerations. The National Library serves over 19,360 registered users in its purpose-built facility, offering extensive collections across 36,478m2 of net floor area with specialized services like reading rooms and digital archives. The Green Pavilion Restaurant, while serving 1,500 meals daily, was specifically designed to preserve existing trees and incorporate sustainable features like natural ventilation and a heat-regulating vegetative canopy. The restaurant's design includes regular shapes inspired by plant growing plots and communication paths, while the Library provides extensive user facilities including 1,100 seats and specialized collection areas. Both institutions exemplify modern architectural approaches that prioritize both service capacity and environmental responsibility.	"['Perpustakaan Negara dan Universiti di Zagreb\n|National and University Library in Zagreb|\n3 million items\nYes, since 1816\nBil. populasi diberi khidmat\n718,850 online (2011)\n|Pengarah||Dr Ivanka Stričević|\nNational and University Library in Zagreb (NSK) (Bahasa Croatia: Nacionalna i sveučilišna knjižnica u Zagrebu, NSK; formerly Nacionalna i sveučilišna biblioteka u Zagrebu, NSB) is the national library of Croatia and central library of the University of Zagreb.\nThe Library was established in 1607. Its primary mission is the development and preservation of Croatian national written heritage. It holds around 3 million items.\nSince 1995 the NSK has been located in a purpose-built cubical building in central Zagreb.\nServices[sunting | sunting sumber]\nServices provided include lending and reference services (bibliographic-reference and catalogue information, subject search, science citation index search); interlibrary loan; national bibliographic database; IT services (reprographic services, microfilming, digitization, use of computer equipment); and learning programmes for users. Exhibitions are mounted, and parts of the Library’s premises may be leased.\nStatistics[sunting | sunting sumber]\nThe Library houses approximately 3 million volumes, on 12,900m of shelving in open-access reading rooms and an additional 110,000m of mobile shelving in closed stacks. The net floor area is 36,478m2, and the gross floor area 44,432m2.\nAcquisitions under legal deposit total 18,194 monographic publications and 3,625 serial publications. There are 1,030 foreign serial titles and 4,865 foreign books. The holdings in the special collections number 11,430 items. There are 7,281 items of non-book materials, and 986 items of electronic materials.\nIn 2011 there were 19,360 registered users and 357,291 visitors to the Library, of whom 22,445 used late hours study services. In the same year there were 718,850 online visitors. For users, there are 1,100 seats, with an additional 64 seats in the Reading Rooms and 150 seats in the evening hours study room. The Special Collections are provided with 8 audio booths, 7 individual and 2 group work study rooms, and there are 10 reading-and-study compartments. There is a 100-seat conference room.\nThe Library’s tasks[sunting | sunting sumber]\nSome of the principal tasks of the Library are:\n1. the assembling and organizing of the Croatian national collection of library materials and the coordination of the acquisition of international scientific works at both the national and the University level,\n2. the preservation and restoration of library materials in the context of the international Preservation and Conservation programme (PAC),\n3. the promotion of Croatian printed and electronic publications,\n4. the integration of the Library’s bibliographic activities and information services into international programmes,\n5. the organization of the Library as the centre of the library system of the Republic of Croatia and the University of Zagreb,\n6. scientific research in the field of library and information sciences,\n7. publishing and various promotional activities and the organization of exhibitions.\nCollections[sunting | sunting sumber]\nDigital collections[sunting | sunting sumber]\n- Digitized Heritage\n- Historic Croatian Newspapers\n- Old Croatian Journals\n- Croatian Web Archive\n- Digital Academic Repository Diarkibkan 2013-06-06 di Wayback Machine\nSpecial collections[sunting | sunting sumber]\n- The Manuscripts and Old Books Collection\nThe Collection assembles, preserves, processes and makes available the items from the richest Croatian collection of national manuscripts and old books, as well as the manuscripts and numerous rare and old books belonging to other cultures.\nThe Manuscripts and Old Books Collection contains a vast legacy of manuscripts – correspondence including nearly 100,000 letters and 3,670 call numbers for individual manuscripts (1,720 in Croatian, 920 in Latin, 454 in German, 230 in Italian, etc.). The Collection also includes the photographic collection containing 865 items. In total the Collection contains 9,236 items (10,295 volumes).\n- The Print Collection\nValuable drawings and prints have constituted a significant part of the holdings of the National and University Library in Zagreb since the foundation of the Library four hundred years ago, while the Print Collection, as a separate organizational unit of the Library, was established in 1919. Apart from being the oldest Croatian collection of this type, the Print Collection of the National and University Library in Zagreb is also the largest print collection in Croatia. In addition to the works by many great names of the Croatian visual arts, the holdings of the Collection include works by numerous leading world artists.\n- The Map Collection\nThe Collection assembles, preserves, processes and makes available all types of maps and atlases. Special attention is given to older and more valuable cartographic items, national cartographic materials and the control of legal deposit procedures. The members of the Collection supply users with information in the field of cartography and provide professional assistance for researchers and students in the preparation and writing of their papers, articles or theses.\nThe Collection comprises nearly 42,000 maps, almost 1,500 atlases, and approximately 600 books in the accompanying reference library.\n- The Music Collection\nThe Collection assembles, processes, archives and makes available sheet music, the rich legacy of Croatian composers as well as a large stock of sound recordings. All materials in the collection are available to the users of the National and University Library in Zagreb and they include nearly 17,000 printed music scores, 3,000 manuscript scores, 23,600 gramophone records, 5,700 cassettes, and 7,447 CDs.\nReading rooms collections[sunting | sunting sumber]\n- Reference Collection\n- LIS Collection\n- Doctoral and Master’s Theses Collection\n- Homeland War Book Collection\n- Official Publications Collection\nHistorical overview[sunting | sunting sumber]\nIn 1607 the Jesuit order established itself in Zagreb. In addition to founding a grammar school, the Jesuits founded a Jesuit College with an accompanying library. By 1645 the library was housed in a special hall, it had a librarian and rules were established regarding the preservation and lending of books. In 1669 the Jesuit College acquired the status of an Academy by the Charter of King Leopold I and became Academia Zagrabiensis. The library and its holdings were moved into an old building of the abandoned Dominican monastery in today’s 5 St. Catherine’s Square in the Old Town of Zagreb.\nThe Jesuit order was disbanded in 1773. The College continued with its provisional activities until 1776, when the library became part of the Royal Zagreb Academy of Sciences (Regia Academia Zagrabiensis) as an academy of law, philosophy and theology. The following year the library received a bequest containing historical material from the clergyman Adam Baltazar Krčelić, with a stipulation that this material be made available to the wider public.\nAs a result of legal deposit regulations introduced in 1816 bearing on the University of Pest, the library\'s national importance began to increase. Such legal deposit regulations were extended to the whole territory of Croatia and Slavonia in 1837. Antun Kukuljević, politician and the founder of the Croatian educational system, changed the name of the library to the Latin name, Nationalis Academica Bibliotheca, highlighting the dual nature of the library’s educational and national functions, which it has jointly developed since then and symbolically preserved in its name to this day.\nThe Franz Josef I Royal University in Zagreb was founded in 1874, and the Academy library (Bibliotheca Regiae Academiae Zagrabiensis) became part of the University and changed its name to University Library, increasing its significance and role in higher education.\nIn 1913 the library with its approximately 110,000 volumes moved from the building of the present-day Rector’s Office into an impressive Art Nouveau edifice located in 21 Marko Marulić Square, the first building built specifically for the purposes of the library. As it was designed to house 500,000 volumes, its premises soon become inadequate for the library’s 2,500,000 volumes – books, journals, newspapers and the particularly valuable items of the library’s special collections. A new library building, the Pantheon of the Croatian Book, was commissioned: its foundation stone was laid in 1988 and the building opened on 28 May 1995 as part of the celebration of the fifth anniversary of Croatia’s independence. This modern edifice was designed by Croatian architects Velimir Neidhardt, Marijan Hržić, Zvonimir Krznarić and Davor Mance.\nReferences[sunting | sunting sumber]\n- Aleksandar Stipčević (2007). The National and University Library in Zagreb 1607-2007: On the Occasion of the 400th Anniversary. National and University Library.\n- ""Manuscripts and Old Books Collection"". National and University Library in Zagreb Web Site. Dicapai pada 2018-01-04.\n- ""Print Collection"". National and University Library in Zagreb Web Site. Dicapai pada 2018-01-04.\n- ""Map Collection"". National and University Library in Zagreb Web Site. Dicapai pada 2018-01-04.\n- ""Music Collection"". National and University Library in Zagreb Web Site. Dicapai pada 2018-01-04.\n- David H. Stam (8 January 2016). International Dictionary of Library Histories. Routledge. m/s. 457. ISBN 978-1-136-77785-1.\n|Wikimedia Commons mempunyai media berkaitan Perpustakaan Negara dan Universiti di Zagreb|', 'Green Pavilion Restaurant, Zagreb Building, Croatian Architecture, 3LHD Design\nGreen Pavilion Restaurant, Zagreb\nBuilding design by 3LHD architects in Zagreb, Croatia, south east Europe\n12 Apr 2011\nGreen Pavilion Restaurant Zagreb\nLocation: Forest Park Maksimir, Zagreb, Croatia\nDesign: 3LHD architects, Zagreb\nGreen Pavilion Restaurant in Zagreb\nThe most important element and the inspiration for this project is the location itself, with extremely high quality existing vegetation, which is densely distributed throughout the plot and gradually diluted out toward the eastern edge.\nThe idea of the new Pavilion / Restaurant is to construct a space by mapping the area of high quality trees and to define the remaining territory for construction. By raising this “cut” green territory in the air the space “below” is created. The basic formal and functional element and a seasonal regulator of light is so-called “vegetative” canopy that has been formed along the entire roof edge.\nOpen atrium spaces which let the light enter all parts of the building and provide visual and physical connections with the natural environment are created to enhance transparency in the area around the trees. The large entrance atrium is the main entrance Plaza, a meeting place, an open terrace and a main entrance to all building spaces. Two main restaurants (canteen and a’la carte) are located next to two main building atriums. The canteen space is oriented to the Forest Park and the sliding doors enable its expansion to the outside environment. The Students association offices and the multifunctional Hall are part of the eastern volume, thus allowing the pavilion to be built in phases.\nThe small temporary buildings and greenhouses that have always been present throughout the campus as part of the faculty culture have served as inspiration for the accommodation units with ten apartments which have been incorporated into the project concept. The apartments are designed as freestanding volumes raised on the roof for privacy. Zones with different plants which may also serve educational purposes were formed around the apartments, on the roof surface.\nThe idea is to create a sustainable house, which will contribute to the environment in every respect – with building materials, construction and structure. In designing, a special significance is given to natural lighting and natural space ventilation, which further reduces the energy requirements for artificial lighting, heating and cooling. The roof and its oversized vegetative canopy are excellent regulators of heat, a thick protective cover that keeps the house from cold in winter and heat in summer.\nThe landscape design is an integral part of the basic architecture concept and the whole plot. The largest part of the roof surface is covered with succulents typical for roof gardens; other areas are organized into regular shapes inspired by plant growing plots. Communication paths and small leisure zones for guests and canteen users are created between the regular shapes.\nIn the restaurant kitchens approximately 1500 meals will be prepared and served daily. All working and service spaces are organized on one level – the ground floor, to enable the ideal functionality and access to all units. One of the specifics of the kitchen is full contact with the outer space.\nGreen Pavilion Restaurant – Building Information\nProject name: Green Pavilion_Restaurant\nFull Title: Canteen of Agriculture and Forestry University in Maksimir\nProgram: public, culture, education, leisure, housing\nProject start date: 30 Aug 2010\nProject end date: 1 Dec 2010\nAddress: Tvrtko Milos Street, Faculty of Agriculture and Forestry campus\nGeolocation: 45°49’41” N, 16°1’47” E\nType: invited competition\nCompetition prize / date: first / 14 Dec 2010\nSite area: 4536 sqm\nSize: 1600 sqm\nFootprint: 1702 sqm\nElevation: 130.20 m\nBudget: 1,700,000.00 EUR\nClient: University of Zagreb, Faculty of Agriculture and Forestry\nProject team: Sasa Begovic, Marko Dabrovic, Tatjana Grozdanic Begovic, Silvije Novak, Paula Kukuljica, Nevena Kuzmanic\nProject team collaborators: Leon Lazaneo, Eugen Popovic, Anna Kocsis\nInes Hrdalo – landscape design, Boris Goreta – 3D, Nikola Miletic (KAP4 (Miletić)) – structural engineering, Zoran Divjak (Dekode d.o.o.) – specialist design, Mario Lukenda (Ured 3T) – HVAC, Slavko Simunovic (Hit Projekt) – plumbing and drainage, Zlatko Galic (Nova-lux d.o.o.) – electrical engineering, Josip Karaman – cost consultant, Mediha Ahmetovic – cost consultant\nGreen Pavilion Restaurant images / information from 3LHD Architects\n3LHD : Architect Profile\nLocation: Forest Park Maksimir, Zagreb, Croatia, south east Europe\nContemporary Croatian Architectural Projects\nBuildings by 3LHD architects – Selection\nGrand Park Hotel Rovinj, Rovinj, Croatia\nphotos courtesy of architects\nGrand Park Hotel Rovinj by 3LHD Architects\nResoLution Signature Restaurant, Rovinj, Croatia\nphoto : Jure Živković\nResoLution Signature Restaurant Interior\nComments / photos for the Green Pavilion Restaurant Croatia Architecture page welcome']"	['<urn:uuid:2562fa82-9f83-40a7-9d7f-dcec2584c8eb>', '<urn:uuid:9ed39961-60bd-4db2-a1e8-8c2db572c2ae>']	open-ended	direct	verbose-and-natural	similar-to-document	three-doc	expert	2025-05-13T06:27:57.068978	25	112	2200
66	I need to give my concert tickets to my friend since I can't make it to the show anymore. Is there any way I can transfer the tickets to someone else's name?	Yes, but there is only one official way to transfer tickets to another name - through a platform called 'Twickets'. Other than this, tickets are strictly not transferable. This policy is in place to prevent resale at inflated prices by ticket touts and to ensure fans have the best chance to get tickets for shows.	['Noel Gallagher has issued a warning after a number of fans were refused entry to his UK tour shows after purchasing tickets from secondary ticket sites.\nFor his current run of dates, fans attending the former Oasis star’s arena shows with the High Flying Birds are required to bring photo ID – with a name matching the one printed on the ticket from the individual who purchased it. This has left many fans in the cold after buying them from touts.\n“It was supposed to be a good night for me and my friend and it was nearly a disaster,” Lisa Stars from Kincorth told the Press And Journal after having her Viagogo tickets refused when attempting to attend Gallagher’s Aberdeen gig earlier this week. “It was quite embarrassing as people were watching us.”\nAfter paying £186 for a pair of tickets (nearly double the £49.50 face value), Miss Stars said that the secondary ticket company had awarded her some compensation after venue staff advised her to buy another two new tickets from the box office.\n“Viagogo has given us a full refund and sent us compensation but it was vouchers to buy another ticket from them,” she said. “We are never lining their pockets again.”\n“Fans attending Noel Gallagher’s High Flying Birds UK Arena tour dates are reminded that there will be strict photo ID checks on all tickets to get in to the show,” a Gallagher spokesman said in a message to fans this week.\n“To try to ensure fans had the best chance to get tickets for this show and to prevent their resale at inflated prices by ticket touts the ticket purchaser’s name is printed on all tickets. If it’s your name printed on the tickets you must bring matching photo ID and make sure that all your ‘guests’ (accompanying ticket holders) arrive with you at the same time. They will not be let in without you. Also please make sure you and your guests are aware of the show’s age restrictions and bring ID proving age if necessary.”\nThey added: “If for any reason you are unable to attend the only place that tickets can be transferred to another name is via “Twickets“. Other than this tickets are strictly not transferable.”\nNME has approached Viagogo for a response.\nSimilar headlines emerged last year when hundreds of ticketholders were denied entry to a Foo Fighters gig at The O2 for failing to present a photo ID which matched their booking.\n“Foo Fighters, SJM and The O2 are frustrated and saddened that despite their best efforts tickets for last night’s show at the O2 fell into the hands of unscrupulous secondary ticket agencies,” said the band in a statement. “Unfortunately, this meant a small number of fans purchasing bogus tickets from these unscrupulous outlets did not get into the sold out show.\n“Foo Fighters, The O2 and SJM strongly advise and sincerely hope that in the future ALL fans buy tickets only from legitimate sites to ensure they are not defrauded out of their hard earned money.”\nEarlier this year, the government introduced new legislation to prevent secondary ticketing sites from buying tickets in bulk using automated ‘bots’ – while Google now requires all websites to make clear that they are second hand tickets sellers in their advertising after being forced to carry a disclaimer.\nAsked if the Government would ever consider a ban on tickets being sold above a certain percentage of their original value,Minister For Digital MP Matt Hancock said told NME: “We don’t rule anything out, but there are advantages to fans being able to sell on tickets that they don’t want. Venues can choose not to allow re-sale above face value, and some do. As we found in the Waterson Review published last year, fans overwhelmingly want the chance to re-sell a ticket if they can’t use them and have a functioning secondary market.\n“What we need is a secondary market that is fair – not skewed.”\nNoel Gallagher tour dates and tickets\nGallagher’s remaining UK and Ireland tour dates are below. For tickets and information, visit here.\nFriday 27 – LONDON SSE Arena, Wembley\nMonday 30 – NOTTINGHAM Motorpoint Arena Nottingham\nTuesday 1 – BIRMINGHAM Arena Birmingham\nThursday 3 – NEWCASTLE UPON TYNE Metro Radio Arena\nFriday 4 – MANCHESTER Arena\nSaturday 5 – ABERDEEN Cafe Drummonds\nSunday 6 – CARDIFF Motorpoint Arena Cardiff\nMonday 7 – LEEDS first direct Arena\nWednesday 9 – BELFAST SSE Arena Belfast\nThursday 10 – DUBLIN 3Arena\nSunday 27 – WARRINGTON Victoria Park\nFriday 15 – WOODSTOCK Blenheim Palace\nFriday 6 – SCARBOROUGH Scarborough Open Air Theatre\nSaturday 7 – LONDON Old Royal Naval College\nThursday 19 – EDINBURGH Edinburgh Castle Esplanade\nSaturday 1 – BRISTOL Clifton Downs']	['<urn:uuid:9e90d905-2acb-4d4e-9347-a9594cbba7c9>']	open-ended	with-premise	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-13T06:27:57.068978	32	55	792
67	customer service comparison business district improvement vs disability accommodation	BIDs focus on supplemental services like street cleaning, public safety, and business development to attract customers, while disability accommodations focus on physical access requirements like removing entrance barriers and maintaining clear pathways. BIDs aim to create cleaner and more attractive districts, while disability accommodations tap into the largest minority group in the U.S. with significant consumer spending power.	['Business Improvement District FAQs\nWhat is a BID?\nA Business Improvement District (BID) is a public / private partnership in which property and business owners elect to make a collective contribution to the maintenance, development and promotion of their commercial district.\nThe idea for BIDs is modeled on the shared maintenance program of many suburban shopping centers. Malls are typically single properties, managed by one entity that sublets the retail space to multiple tenants. Tenants pay a common area maintenance fee to underwrite services that enhance the appearance of common areas and provide cooperative advertising for the mall and its stores.\nA BID works in much the same way. However, because the BID is set in an urban context, multiple property owners agree to the extra fee (assessment). Thus, stakeholders in a commercial district can align themselves in much the same way to improve their area.\nWhat does a BID do?\nBusiness Improvement Districts deliver a range of supplemental services in coordination with municipal services and invest in the long-term economic development of their districts.\nWhat is a Special Service District (SSD)?\nA special service district is “a defined area within the city where special services are rendered and the costs of the special services are paid from revenues collected from service charges imposed within that area.” An SSD may be established anywhere in a city but only business property (i.e., commercial, industrial, utility, or land zoned for commercial or industrial use) will be subject to the service charge. SSDs are commonly used in areas with a concentration of retail stores.\nHow is a BID different from an SSD?\nBIDs are able to determine what contractor will be used for desired services; this is not the case in SSDs. For example, BIDs may also opt to hire non-city operated (third party) service providers. This may save the BID money overall.\nWithin SSDs, the city chooses which types of services may or may not be rendered. For example in Minneapolis, SSDs cannot spend assessed dollars on marketing or special events. Therefore, business owners have more of a say on the services provided within the BID over the SSD.\nHow is a BID operated?\nBIDs are governed and operated by a board of directors that works for the businesses and with the city government. The board may be made up of various representatives of the businesses, residents, and city officials. BID members vote for directors. The majority of directors are typically property owners.\nWhat services are provided by the BID?\n- Street / sidewalk cleaning\n- Graffiti removal\n- Public Safety / Hospitality\n- Public safety officers\n- Visitor assistance\n- Business Development\n- Commercial vacancy reduction\n- Business mix improvement\n- Special events\n- District public relations\n- Promotional materials\n- Holiday decorations\n- Capital Improvements\n- Improved streetlights\n- Custom trash receptacles\n- Directional street signage\n- Custom newsboxes\n- Flower boxes\n- Planting trees/flowers\n- Treepit maintenance\n- Community Service\n- Charitable events\n- Homeless and youth services\nHow much is the additional tax?\nGenerally, the tax is assessed on the amount of frontage (along the main street) that the property has, it can also be assessed based on the square footage of the building, or the assessed value of the property. The tax is also levied according to the budget implemented by the BID operators. Overall, depending on the services that the businesses are in need of and/or willing to pay for.\nDoes the assessment increase every year?\nThis depends on the services that are needed within the BID. If the businesses within the BID feel they want/need more services, the budget will need to increase. Likewise, if it is felt that fewer services are needed, then the levied tax may remain the same or lowered.\nWhat are the advantages that may result from this arrangement?\n- a cleaner, safer and more attractive business district\n- a steady and reliable funding source for supplemental services and programs\n- the ability to respond quickly to changing needs of the business community\n- the potential to increase property values, improve sales and decrease commercial vacancy rates\n- a district that is better able to compete with nearby retail and business centers\nDo different properties pay different assessments based on property type?\n- Occupied commercial or industrial properties are assessed and pay the commercial rate\n- Not–for-profit owned and occupied properties generally do not pay an assessment\n- City, State and/or Federal government occupied properties do not pay an assessment\n- Residential properties generally pay reduced assessments\n- Vacant properties generally pay reduced assessments\nWill city services be reduced if the BID is offering similar services?\nNo. The services provided by the BID are supplemental to the services provided to the district by the City. For example, if a BID provides sanitation services, it will still receive the same level of service from the Public Works as it did before supplemental services were added.', 'You are running a little late for your early Monday morning meeting regarding how to attract new customers. The fresh blanket of snow is beautiful but has not been removed from your business parking lot. You navigate to a place near the front door and park. Getting out of the car puts your shoes six inches in to the snow so you jump up over the curb and the step to the front door, unlock the door, push the recently delivered boxes to the side and start your day.\nBusiness has been slow this winter and your meeting involves brainstorming how to attract and increase the flow of new customers through the door. Your advertising and marketing plans are on track but you feel there is something within your grasp that would increase the flow of customers to your business, but what is it? A van pulls in your parking lot, hesitates for a moment, and then leaves. Your staff discusses why that potential customer did not come in and what could be done so they would have come in to do business? This entire morning you were looking at the situation but did not see it.\nThe potential customer in the van was an individual who used a wheelchair to transport himself through his day. What did he see that same morning? The new blanket of snow was beautiful but needed to be removed from the parking lot to give him any chance to get in to your business. There was a car parked halfway in the handicapped spot and the curb cut was not shoveled. Even if the snow was removed the step to the front door would inhibit him from entering. This individual wanted to do business with you but you did not see any of those barriers.\nThere are 54 million individuals in America who have disabilities, making them the largest minority in the U.S. The National Organization on Disability reports that this group represents $1 trillion in annual aggregate consumer spending.* All of these people are your potential customers! Are you aware of the guiding principles to create equal access for all individuals to get in to and throughout your place of business? If your potential disabled customer did get in your door would he have been able to navigate past the boxes?\nThe Minnesota State Council On Disabilities (www.disability.state.mn.us) provides businesses with literature and advice on how to make their place of business accessible to consumers and employees. According to the Americans With Disabilities Act (ADA) Title III public accommodations must comply with basic nondiscrimination requirements that prohibit exclusion, segregation, and unequal treatment. Even if your business does not fall under Title III making your place of business accessible, and marketing that accommodation, will provide you the opportunity to tap in to this very large population of consumers.\nYour desire to increase the flow of new customers to your business may start with a few minor adjustments to make your business accessible AND remembering how important it is to maintain these accommodations. Look around and see how these adjustments can allow that van to park instead of pull away.']	['<urn:uuid:ba3d4ca6-5ac6-4a43-8282-b3c1a3c6b3e4>', '<urn:uuid:a057e860-3ccb-45ee-8a8c-803dbb48e523>']	factoid	direct	long-search-query	distant-from-document	comparison	novice	2025-05-13T06:27:57.068978	9	58	1348
68	indo european language family structure mixing	The Indo-European language family consists of two major groups: the Eastern (Satem) group with 5 languages and the Western (Centum) group with 4 languages. However, unlike biological evolution where genetic mixing is rare, languages within this family can extensively borrow features from unrelated languages and even form hybrid languages. For instance, Cappadocian Greek shows significant mixing with Turkish, having borrowed sounds, vowel harmony, and SOV word order, making it difficult to classify definitively within the Indo-European family. This demonstrates how language families show lines of partial descent rather than pure lineages.	['AKSHIRAA COACHING CENTRE\nPOLYTECHNIC TRB EXAM\nfor the post of\nLecturers in Government Polytechnic colleges\n- Well Trained Professor\n- Excellent Coaching\n- Unit wise Materials\n- Model Exams\n- All Previous TRB Questions\nUnit – VIII English Language and Linguistics\n|01||Family of Indo-European Languages||03|\n|02||Characteristics of the Germanic Language||07|\n|07||Growth of Vocabulary||19|\n|08||Change of Meaning||25|\n|13||Perspectives of Linguistics||63|\n|23||Phrase and Structure||110|\n|24||Transformational Generative Grammar||114|\n|26||Theories of Language Acquisition||117|\n|27||Listening, Speaking, Reading, Writing (LSRW)||120|\n|29||Methods of Teaching||129|\n1. Family of Indo European Languages\nFamily of Indo-European Languages: (9)\n- It is called as Indo – Aryan or Indo Germanic.\n- It was spoken during 3500 BC to 3000BC.\nEastern Group: (5)\n- It is called “Satem Group” and it has 5 languages.\nWestern Group: (4)\n- It is called “Centum Group” and it has 4 languages.\n- Primitive Germanic or Primitive Teutonic\n- The language is found in south of the Caucasus Mountains and the eastern end of the Black sea.\n- It has Persian influence\n- It was spoken in northwest on Greece and east coast of the Adriatic sea.\n- Sanskrit was spoken during 1500 BC.\n- Panini who was the great grammarian of 4th century gave a fixed literary form for Sanskrit.\n- Paliis the language of Buddhists.\n- A dialect of Hindi with a good mixture of Persian and Arabic is known as Hindustani.\n- Iranian was spoken in the north-western India.\n- It has its origin in Eastern parts of Europe.\n- Greek or Hellonic:\n- It was spoken in Greece, Aegean and the coast of Asia Minor.\n- Homer’s Iliad and Odyssey were existed in 8th century B.C.\n- The important dialect is Attic (Athens).\n- Latin or Italic:\n- It is the language of Italy.\n- It includes…..\n- Dante’s Divine comedy\n- Virgil’s Aeneid\n- Petrarch, Boccacio, Cicoro (Roman Orator)\n- It is called as Romanic Language.\n- The language of the Celts in Gaul is called as Gaelic.\n- It is called as Primitive Germanic or Primitive Teutonic.\n- It has three divisions.\n- East Teutonic\n- North Teutonic\n- West Teutonic\n- It was spoken in central and Northern Europe from 2000 to 1000 BC.\n- The principal language of East Teutonic is Gothic.\n- The earliest work was the Bible Translation by Bishop Ulfilas in 4th Century.\n- It was found in Scandinavia and Denmark\n- Scandinavian is called as Old Norse.\n- It is divided into two categories.\n1. Low German\n2. High German\n- Luther’s translation of the Bible was first printed in High German\n- The Low German Languages are Old Saxon, Old Low Franconian, Old Frisian, and Old English.\n1. Family of Indo European Languages\n- The family of Indo-European languages has _________ major groups.\n(A) 2 (B) 4 (C) 7 (D) 9\n- Who is 4th century BCE Indian grammarian, wrote a formal description of the Sanskrit language?\n(A) Bhartrhari (B) Panini (C) Pingala (D) Vararchi\n- What is the principal language of East Teutonic?\n(A) Gothic (B) Scandinavian (C) Danish (D) Old Norse\n- English belongs to the _____________ group.\n(A) East Teutonic (B) West Teutonic (C) North Teutonic (D) South Teutonic\n- Which of the languages is not under group of Centum in Indo-European Family?\n(A) Greek (B) Latin\n(C) Indian (D) Primitive Teutonic\n- Which of the languages is not under group of Satem in Indo-European Family?\n(A) Armenian (B) Albanian (C) Indian (D) Celtic\n- English descended from the Western set (group) of the Indo-European family languages which is also called ________ (PG – 2015)\n(A) Centum (B) Satem (C) Armenian (D) Albanian\n- The ultimate origins of the English language lie in which language family?\n(A) Indo-European (B) Indo-Anglican (C) Latin (D) Greek\n- Which is not a regional group into which Germanic languages are divided?\n(A) North Teutonic (B) South Teutonic (C) East Teutonic (D) West Teutonic\n- Which of the following is not a result of the Viking invasion of England?\n(A) the addition of “sk” words to the English vocabulary\n(B) the addition of third person personal pronouns to the English language\n(C) the destruction of Christian churches, schools and monasteries\n(D) the influxion of French culture and French literature into England\n- Which old English dialect became the direct ancestor of modern literary English?\n(A) Mercian (B) West-Saxon (B) Northumbrian (D) Kentish\n- Which of the following is belonged to the group of West Germanic language?\n(A) Gothic (B) Old Norse (C) Icelandic (D) Frisian', 'Linguistic Phylogenies Are Not the Same as Biological Phylogenies\n(Note: This post is jointly written by Martin Lewis and Asya Pereltsvaig)\nA key assumption of Bouckaert et al. is that the diversification and spread of languages operates so similarly to the diversification and spread of biological organism that the two processes can successfully be modeled in the same manner. The parallels between organic and linguistic evolution are indeed pronounced. Both processes entail replicating codes that continually change, giving rise to novel varieties that increasingly differ from their progenitors over time. As a result, “phylogenetic trees,” showing descent from common ancestors, are a common feature of both evolutionary biology and linguistics.\nBut despite their similarities, organic evolution and linguistic evolution are in many ways highly dissimilar. Encoding information for communication is not the same as encoding information that generates life: language is vastly more fluid and complex than the genetic code; individual languages are much less clearly differentiated from each other than are species; and language is a social phenomenon, given to influences largely irrelevant for biological evolution. The key differences can be summarized as follows: biological evolution is unconstrained but governed by natural selection (any mutation can happen, but which mutations remain in the pool depends in large part on natural selection), whereas linguistic variation (seen in terms of deep grammatical properties) is constrained by a system of parameters but is not subject to natural selection. As a result, the branching trees of linguistic descent are merely analogous to the phylogenetic diagrams of biological evolution, and do not indicate the same kind of relationships.\nAlthough organic evolution operates through a much more restricted set of message-carrying units than does human language, it nonetheless produces diversity at a much deeper level. Given the biological constraints of the human brain/mind (as of yet less than fully understood), there are only so many ways in which any given language can be structured. To be sure, the number of possible human languages, both extant and extinct, as well we those that may arise in the future, is vast, but all human languages appear to be “variation on a theme,” guided by the same parameters. Some languages have as few as two vowels (Ubykh, Northwest Caucasian) and others as few as six consonants (Rotokas, North Bougainville); other languages may have as many as 20 vowels (e.g. the Taa language, spoken in Botswana and Namibia, is reported by some sources to have as many as 20 or even 30 vowels, depending on analysis) and as many as 84 consonants (as in Ubykh; the Taa language is reported to have 87 consonants under one analysis, 164 under another). But crucially, all languages differentiate vowels from consonants and use both. Some languages put verbs before subjects and objects, while others place them at the ends of sentences, but all languages have verbs, subjects and objects.* Some languages can build sentence-long words packed with of numerous prefixes, infixes, or suffixes, while others use stand-alone, stripped-down words to do the grammatical work of expressing tense, number etc., but all languages make words from morphemes—and all construct sentences. As a result of this limited space of possibilities, completely unrelated languages evolving on their own often come to share major grammatical traits.\nLinguistic evolution, unlike that of the biological realm, moves at a rapid clip. In non-literate societies, words change so quickly that after some five to eight thousand years not enough cognates can be traced back to establish linguistic relatedness. In the same time span, grammatical structures can undergo wholesale transformations, and sound inventories can change drastically as well. As a result, even clearly related languages can have next to nothing in common with each other, and can only be linked through investigations into their ancestors. Hindi and English, two of the three most widely spoken Indo-European languages, are dissimilar in almost every respect.** On casual inspection, Hindi would seem to have more in common with the non-Indo-European languages of the Indian sub-continent than it does with English.\nThus, relatedness at the family level and overall linguistic similarity often fail to correspond. Maps showing major language patterns typically bear little if any resemblance to maps depicting linguistic families. Even something as seemingly basic as word order correlates poorly with lines of descent. For example, Indo-European languages can be SVO (subject-verb-object; marked by red dots on the map to the left), such as English, Romance, and most Slavic languages (but Sorbian, a Slavic language, is SOV); SOV (marked by blue dots), such as the Indo-Iranian languages (yet Kashmiri is SVO); or VSO (marked by yellow dots), such as the Insular Celtic languages (yet Cornish is SVO). Some other families, such as Austronesian, have an even greater variability in the basic word order: Niuean is VSO, Malagasy is VOS, Rotuman is SVO, and Tuvaluan is OVS.\nSimilarly, features of morphological typology (how words are formed from morphemes) often cross-cut connections established by common descent. Whereas Proto-Indo-European, like most of its daughters, was a synthetic language (building words from multiple non-root morphemes), English and Afrikaans are relatively analytical (with low ratios of morphemes to words), which gives them a certain affinity with Mandarin Chinese (a highly analytical language). As discussed in an earlier GeoCurrents post, isolating languages are found in Africa (Hausa, an Afroasiatic language), Asia (Vietnamese, Austroasiatic), Oceania (Rapanui, Austronesian), and the Americas (Kipea, Kiriri). In phonology as well, similar patterns obtain, as sound inventories often fail to show systematic correspondences with language families. The Indo-European languages of South Asia, for example, are in many respects more phonologically similar to the Dravidian languages of the same region than they are to most other IE language. One of the characteristic phonological markers of the region, the rich inventory of retroflex consonants, is also scattered across the rest of the world, found in about 20 percent of all languages belonging to a wide variety of families.\nOne of the best ways to appreciate the relative insignificance of language families in regard to the global distribution of such features is to explore the maps that can be generated on the WALS website, such as the one reproduced above. Few if any of these maps bear much resemblance to the familiar depiction of the world’s major language families.\nAgain, the contrast with biological evolution is stark. The farther removed organisms are from each other on the tree of life, the fewer genes they necessarily share. Even when convergent evolution results in similarities between distantly related organisms, the parallels are relatively superficial. As a result, modern genetic inquiry can establish precise levels of biological relatedness, a process that has revolutionized taxonomy over the past few decades. In the biological realm, moreover, the farther one moves up different branches of evolutionary descent, the more distinctive the organisms found along it generally become. Chordates (the phylum that includes vertebrates) share a distant common ancestor with echinoderms (sea stars and their relatives), and some tunicates, primitive members of phylum Chordata, might be mistaken by unschooled observers for sea lilies in phylum Echinodermata. (Tunicates more generally look like unrelated jellyfish and other cnidarians; a few could be mistaken for rocks, but such rocks disconcertingly bleed when cut open.) But no one would ever mistake any mammal with a sand dollar, a sea cucumber, or any other echinoderm, animals characterized by radial rather than bilateral symmetry. The two phyla have simply evolved in strikingly different directions. If linguistic evolution worked in the same manner, it is questionable whether translation between distant languages would even be possible. Moreover, the disparate patterns of spatial distribution of deep grammatical properties, such as the ones illustrated by the WALS maps, would not be found.\nIn language, deep grammatical properties can radically change, often taking on the same forms as those encountered in wholly unrelated tongues. As a result, linguistic relationships are often anything but obvious, and can only be discerned though intensive study; significantly, such hidden connections can hold true even for relatively recently emerged languages. A fluent speaker of the major Germanic languages, for example, might be nonplused to learn that Frisian is more closely related to English than it is to Dutch. Yet according to some specialists, even Low German is “phylogenetically” closer to English than it is to (High) German—even though Low German is generally regarded as a mere dialect (or group of dialects) of German!\nLinguistic evolution is only vaguely analogous to organic evolution for a variety of reasons, but a crucial factor is the fact that vastly less sharing occurs across biological lineages. We now know that genes can jump from one species to another, but the process is relatively rare; in this realm, change generally occurs as a result of random mutations acted upon by natural selection, not from the borrowing of elements from other species. When it comes to languages, however, sharing is ubiquitous. Languages are almost always borrowing words, and sometimes they adopt grammatical properties of other languages as well. At times, two completely unrelated languages essentially merge to create a hybrid tongue. To be sure, linguists are almost always able to determine which language contributed more elements and more basic structures, and hence should count as the parent tongue. (It should be noted that the use of the terms “parent” and “daughter” in relation to languages is misleading since, unlike in the biological realm, where individual organisms are discrete, the transition from “parent” to “daughter” language is always gradual.) When it comes to creole languages, however, such determinations are not always easy. In regard to grammar, different creoles of completely different parentage are often more similar to each other than they are to any of their source languages. In some instances of mixed languages, admixtures of vocabulary, grammar, and phonology run so deep that linguists abandon the quest for unambiguous classification. Cappadocian Greek, for example, is slotted by the Wikipedia into the seemingly impossible “Greek-Turkish” language family. Does Indo-European therefore encompass this language? Other sources, such as the Ethnologue, place this language in the Greek branch of the Indo-European family, but Turkish influences on Cappadocian Greek are pronounced: it has certain sounds that have been borrowed from Turkish, as well as vowel harmony; it has developed agglutinative inflectional morphology and lost (some) grammatical gender distinctions; and its basic word order is SOV. And Cappadocian Greek is by no means the only example of such a thoroughly “mixed language.” In the biological realm, in contrast, such mixtures are so obviously impossible that they have generated their own nonsense genre, as exemplified by Sara Ball’s delightful flip-book, Crocguphant.\nLinguistic family trees must therefore be taken as often showing lines of partial descent, unlike the phylogenetic diagrams of organic evolution. To gain a more complete understanding of linguistic relatedness, it is necessary to complement language families with other kinds of connections. The various languages of a Sprachbund, or a linguistic convergence area, for example, derive from different families, yet nonetheless come to share many features through long histories of mutual interaction. One must also consider linguistic strata, which take into account the influences imposed by one language on another. The role of a linguistic substratum, derived from a previously existing language that was later supplanted by another tongue, can be profound. In many cases, such linguistic substrates were instrumental in generating subfamilies; the Germanic languages, for example, are distinct from other Indo-European languages not merely because they drifted in their own particular direction, but also because that acquired a major substrate from another (unknown) language family. Sometimes, the ghostly presence of a long extinct language or language family can be detected through such substrates. Vedic Sanskrit, for example, was definitely an Indo-European language, but it was influenced not only by the preexisting Dravidian and Munda languages of the Indian subcontinent, but also by an unknown substrate deemed by Colin Masica “Language X.”\nA useful alternative to the linguistic tree is the so-called wave model, or Wellentheorie, originally devised to explain some of the characteristics of the Germanic languages that seemed to defy the phylogenetic approach. In wave theory, fluid dialect continua replace the stable, geographically bounded languages required by models predicated on direct descent from ancestral tongues. Here, innovations can occur at any points within a dialect continuum; such changes then spread outward in a circular manner, eventually dissipating as the distance from the innovation center increases.*** If a bundle of innovations substantially overlap and become entrenched, a new dialect, or even language, can be said to have emerged. But according to wave theory, such a “language” is still best viewed as an “impermanent collection of features at the intersections of multiple circles.”\nWave theory does recognize, however, the fact that a single language/dialect can appropriate an entire dialect continuum, subordinating more localized speech forms and eventually driving them into extinction, as indeed was the case in regard to Standard German over most of Germany. Such a process, however, generally requires the power of the state or of some other overarching institution. Such geographically expansive and culturally potent organizations, however, are a feature of the relatively recent past; for most of humankind’s existence, the institutions necessary for producing linguistic standardization over broad areas were lacking. We are so used to the modern world of mass communication over vast distances and of language-standardizing governments and educational systems that we easily forget that in earlier times, and in many remote areas to this day, different linguistic environments prevailed. Overall, we suspect that for most of human history, the wave theory more accurately captures the process of language change than does the standard phylogenetic model. Yet in the most general terms, the two models complement each other relatively well.\n*Debate does rage, however, about whether the so-called “non-configurational languages” such as the Australian language Warlpiri, have subjects and objects in the same sense as the more familiar, “configurational” languages like English or French. The reader is referred to Baker (2001) for evidence of subject-object asymmetries in such non-configurational languages.\n**For example, Hindi makes a phonemic distinction between aspirated and unaspirated voiced stops, has fusional case/number morphology, subject-object-verb word order, postpositions, and uses the ergative-absolutive alignment in the preterite and perfect tenses; English, in contrast, has no aspirated voiced stops (and does not use aspiration phonemically at all), has largely abandoned fusional morphology, has lost the case system except with pronouns, employs a subject-verb-object word order, uses prepositions rather than postpositions, and is characterized by nominative-accusative alignment.\n***Ironically, the diffusion analogy of Bouckaert et al. may be best suited to describing dialectal continua rather than divergence and expansion of languages and language families; we shall return to this point in a forthcoming post.\nBaker, Mark C. (2001) The Natures of Nonconfigurationality. In Mark Baltin and Chris Collins (eds.) The Handbook of Contemporary Syntactic Theory. Oxford: Blackwell. Pp. 407-438.\nFind this post valuable? Please pay it forward by sharing it with others:']	['<urn:uuid:25428dc9-c4a5-456f-9d69-f853f4de2907>', '<urn:uuid:0959cf51-db21-4eab-b91f-9acf332eb87f>']	open-ended	with-premise	short-search-query	distant-from-document	multi-aspect	expert	2025-05-13T06:27:57.068978	6	91	3226
69	Was Hungary's ambassador to the US involved with music?	Yes, the Ambassador was an accomplished blues guitarist and had previously been a member of several Hungarian rock groups.	"['bq. ""The wind of change Blows straight into the face of time Like a stormwind that will ring The freedom bell for peace of mind Let your balalaika sing What my guitar wants to say..."" - The Scorpions, ""Winds of Change"" Mike Daley sends this irresistable tidbit along. Apparently, tonight will feature a very special speech at the Rock and Roll Hall of Fame by Hungary\'s ambassador to the United States. To quote from the Hall of Fame\'s official news release:\n""Mr. Simonyi will discuss his personal experiences with rock music and the impact that it made in Communist-ruled Hungary and other Soviet Bloc countries. The free flow of American and British rock music – and the revolutionary ideas it represents – over the airwaves in Central and Eastern Europe was instrumental in loosening the Communists\' grip on power and contributed to the eventual downfall of dictatorships in that area of the world. Ambassador Simonyi’s speech is entitled “Rocking for the Free World: How Rock Music Helped Bring Down the Iron Curtain.” The Ambassador, an accomplished blues guitarist himself and formerly the member of several Hungarian rock groups, will be introduced by Jeff “Skunk” Baxter, former lead guitarist with the Doobie Brothers and Steely Dan.\nAs I think back over the last 20 years and remember what the world used to be like, I believe the appropriate expression for occasions like this is ""Fuckin\' A!"" We live in wonderful, dangerous times - and the one does not negate the other. bq. ""Not only for me but also for other Hungarians of my generation, this became the stuff that really linked us to the free world,"" he said. ""As I listened to this kind of music, I felt I was part of the free world myself."" Back in May of 2002, my blog essay ""G-d Gave Rock N\' Roll To You..."" explained why Rock, Jazz, and other forms of Western music are so inherently dangerous to certain regimes and ideologies, and why that still mattered. From Arab News to McCoy\'s B-52s, from C.P. Freund to Neal Stephenson, it ties them all together, relates these ideas to present events, and makes the case for giving our bastard cultural children Jazz, Blues and Rock n\' Roll their due. For Hungary is not the first society rocked to freedom by this music. America is. The music embraced America long before America embraced its players, and Americans accepted it in their ears before they accepted its true message in their hearts. It was sorrow, and endurance, and joy. It took old lines and boldly crossed them, and its mix shook the world. It dared its listeners to define themselves. It set them free. That\'s what this music means - and what America means, too, in its best moments. Rock n\' Roll America, beacon of freedom. Or, as Lileks puts it, ""we\'re The Axis of Elvis."" Amen. The black artists who made jazz, blues and rock possible brought forth a great gift out of a great injustice, and helped define America to the world. Their gift goes on giving, in America and beyond. Here\'s the full series:\nWinds Prologue: The Axis of Elvis | Hall of Fame Speech Part 1: Jeff \'Skunk\' Baxter | Part 2: Ambassador Andras Simonyi | Part 3: Baxter & Simonyi Q&A Session\nIn the words of Ambassador Simonyi\'s favorite artist, Stevie Winwood:\n""Many a mile to freedom, many a smile to tell Ask my bluebird to sing you, from the heart of a wishing well Call all my reindeer to graze here, call all my grain to grow Then together we flow like the river Then together we melt like the snow... ...A few more miles to go Miles to freedom."" - Stevie Winwood, ""Many a Mile to Freedom""']"	['<urn:uuid:49a50fbf-8426-4ec0-8ff4-4498b769c939>']	factoid	with-premise	concise-and-natural	similar-to-document	single-doc	expert	2025-05-13T06:27:57.068978	9	19	628
70	How do franchise exhibitions compare to online research methods for finding opportunities, and what key financial considerations should be evaluated when selecting a franchise?	Franchise exhibitions offer unique advantages over online research as they provide direct interaction with potential franchisors and give a personal 'feel' for the people behind the franchise. However, online resources have become the most commonly used method, offering extensive information and replacing traditional specialist magazines. Regarding financial considerations, potential franchisees must evaluate several key aspects: initial fees typically ranging from $10,000 to $30,000, ongoing royalties of 3-6%, additional marketing fees of 1-2%, equipment costs, real estate expenses, and build-out cost ranges as detailed in Item 7 of the UFOC. The total investment range can vary significantly, from $150,000 to $375,000, and franchisees must consider their ability to obtain financing through banks or other sources.	"['Where to find examples of franchise opportunities?\nWhen deciding to buy a franchise potential franchisees fall into three broad categories, those who know exactly which business they want to buy, those who know the sector that they want to operate in (such as fast food, pet care etc.) and those who simply know that they want to own a franchise but have no definitive idea of which type of franchise they wish to own. The starting point for all three categories is research, which brings us to the question “Where is the best place to find examples of franchise opportunities?” There are three main avenues open to you in order to research your options.\nPublications: Various ‘specialist’ franchise magazines are published throughout the year including Business Franchise (The Official magazine of the British Franchise association) The Franchise Magazine, What Franchise and Making Money. All of these publications contain adverts for variety of franchises, editorial from franchisors and franchisees as well as background information and advice about franchising in general.\nExhibitions: Exhibitions remain a tried and tested way to find out what franchise opportunities are available. There are major exhibitions held every year in London, Manchester and at Birmingham NEC which historically is the largest in the UK. Additionally there are various smaller regional exhibitions often held in function suites at sports grounds. The advantage that an exhibition has over a magazine is that you get the opportunity to talk to your potential future franchisor and ask questions. You also get a ‘feel’ for the people behind the franchise which is important as you will be working closely with them to build a successful business.\nWebsites: In the same way that ‘online directories’ have replaced hard copy versions, the internet has become the most commonly used method of finding examples of and researching potential franchise opportunities. Google ‘pet franchises’ and you get the option of six named brands on the first page, which is all well and good if you know that you want a pet franchise. If however you are simply looking to see which franchises are available then a good starting point is the British Franchise Association’s official website www.thebfa.org. All the franchised businesses listed here are members of the bfa so you can be assured that they comply with the necessary criteria needed to be a member of the industry’s governing body. Commercial websites such as the one you are looking at currently www.whichfranchise.com (who also only accept entries from bfa members) are also a means of research and to a great extent have replaced the ‘specialist franchise magazines’ method of finding a suitable franchise opportunity. Websites contain a wealth of information not only on individual franchises but also by providing advice on diverse topics ranging from the legal implications of the franchise agreement through to advice from High Street Banks regarding raising finance. Commercial websites normally also provide links to individual franchise websites.\nIrrespective of which method you choose (and most people do a combination of all three) take time to weigh up your options. Franchising requires you to be committed to what you do, so it is worth the effort and time at the outset to make sure that you make the right choice of franchisor for you.', 'Now You\'re Cooking\nChoosing from among the thousands of franchise opportunities available to investors is not unlike walking into a large grocery store. There\'s lots to buy, but you can spend every dime you have and still not go home with what you need to make dinner. Selecting the right franchise requires that you have a detailed shopping list and a clear idea of the end product. It\'s best to start with a recipe for the dish you\'re making and a list of the ingredients you\'ll need, and work from there. Try doing it the other way around--walking into the store with no idea what you need--and what happens? You forget a key ingredient. The soufflÃ© falls flat, the lasagna goes limp, or the cake craters.\nIt takes hard work, thought and planning to find the right investment. And while the ingredients may change from person to person, the process for finding the right franchise investment is essentially the same for everyone.\nA Picture Is Worth a Thousand Words\nIt starts with your dream. Where do you want to go with this venture? In five years, where do you want to be? If you were making a fancy meal featuring coq au vin, you\'d start with the picture in a cookbook illustrating the succulent sautÃ©ed chicken glistening in a red wine sauce. This is where you want to end up. This is why you\'re going to the grocery store in the first place. This is your goal.\nAll successful business ventures start with a personal vision, a fundamental plan, a goal or an objective. Selecting the right franchise should start with some sort of personal plan and goal-setting exercise. Know where you want to go in your business. Know the general type of work you prefer. Know what really fires you up and gets you excited about business.\nThe Shopping List\nNext, make a list of your assets, personal strengths, resources and limitations. What money do you have in the bank? Is your credit report in good shape? Do you think you\'ll qualify to borrow the investment capital you\'ll need? Do you have friends or family members who are in a position to invest in a promising business venture?\nExpect to have these resources tested during your search for the right franchise. Prepare a current financial statement, and obtain references from your bank and your major creditors, like a landlord or a credit union.\nIf you go into the investment without your list, you could end up forgetting a crucial part of the preparation.\nNever Shop When You\'re Hungry\nIf you shop when you\'re hungry, you end up buying food you don\'t need and probably shouldn\'t eat. In franchising, you must be prepared to resist making impulsive decisions. The field of franchising is populated with some of the most talented salespeople in business. They offer lots of sizzle, and they\'re careful students of the psyche of the hungry prospective entrepreneur. Before you know it, they\'ve got you excited about the unlimited potential of their opportunity, they\'re urging you to get in on the ground floor, and they\'re telling you the territory is going fast and you must decide now. Your job in this process is to separate the sizzle from the steak and stick to your list.\nRead the Labels\nYou have an advantage over most other investors. As a prospective franchisee, you\'ll receive a detailed, extensive report about the franchisor, the franchise being offered and the franchise system. This document is known as the Uniform Franchise Offering Circular, or UFOC.\nThe UFOC is one of the most detailed ingredient labels you\'ll ever come across. Like food packaging labels, the UFOC\'s format is established by federal law, and it\'s designed to deliver key information about the franchise investment. You\'ll find 23 items of information, all of which are important to your investment decision. If there\'s one piece of advice you shouldn\'t ignore, this is it: Read this document carefully. Sure, it may read like an insurance policy in places, but it\'s a treasure trove of details for alert investors. The good news: All UFOC documents must be written in plain English. No Latin phrases. No ""hereinafters"" or ""whereinbefores."" No run-on sentences only a lawyer could love.\nPay special attention to key UFOC sections that describe the franchise program. Some sections give you information about the franchisor, its financial standing and litigation background; some outline the franchise investment itself; and others fill you in on the network of existing franchise owners. Taking all three areas into consideration is crucial when making your investment decision.\n1. The franchisor. Items 1, 2, 3 and 4 tell you who the franchisor is, how long it\'s been in business, its key executives\' experience, its litigation or arbitration history, and whether there are any bankruptcies in its background. The key information here is the litigation background. If the company is involved in numerous lawsuits with its franchisees, find out why.\nYou also want to know about the financial stability of the franchisor. Item 21 requires a franchisor to attach three years of audited financial statements to the UFOC. This gives you a great snapshot of the franchisor\'s recent financial history. You want to know if this company is going to be around for the long haul; after all, your franchise agreement can run 20 years or longer. Its value as an investment is greatly diminished if the franchisor is on shaky financial ground.\nThe same can be said about the principal trademark licensed to you. Confirm in Item 13 whether the mark is federally registered with the U.S. Patent and Trademark Office and whether the franchisor will stand behind you if the mark is ever challenged by a third party. If the mark isn\'t federally registered or if you\'re not entirely comfortable with the legal obligations in the event of a challenge, talk to your attorney (an important advisor in this process) and know the legal risks going into the situation.\n2. The franchise investment. Items 5 and 6 lay out the fees you must pay the franchisor. Usually, franchisees pay a substantial initial fee plus ongoing royalties expressed as a percentage of the business\'s gross sales. Initial fees typically range from $10,000 to $30,000, royalties from 3 to 6 percent. Look for other fees as well, such as a marketing or advertising fee, which adds approximately 1 to 2 percent to the monthly royalty payment. Item 6 lists other incidental fees, such as transfer fees, renewal fees, audit expenses and additional training fees.\nItem 7 is very important in a successful franchise recipe. It presents, in chart form, the franchisor\'s best estimate of the total expenses involved in opening a franchise. Equipment costs are estimated, as are real estate and build-out cost ranges. Use this item to compare the real costs of the program to your budget. If you find a total investment range of $150,000 to $375,000, you\'ll know roughly how much you\'ll have to spend or raise if you want to get one of these franchise recipes off the stove and onto the table.\nOther disclosure sections tell you about the restrictions placed on your product supply sources (Item 8), your obligations under the franchise agreement (Item 9), any franchisor financing programs available to franchisees (Item 10), and the franchisor\'s contractual obligations to provide services, training and assistance (Item 11).\nIf your first question is ""How much money can I make with this franchise?"" you\'ll find an answer (if the franchisor chooses to offer it) in Item 19. Most franchisors don\'t provide performance data. They leave it to would-be franchisees to make their own projections and assumptions about the potential of the business.\nAnyone seriously considering buying a franchise should interview as many existing owners in the system as possible. You\'ll find a list of owners in Item 20. Ask them how their units perform and whether they\'re satisfied with the training program and their business\'s performance. Not only will this information provide an invaluable reality check, but it will also help you with your business planning and financial projections.\n3. The network. Turn to the charts and lists shown in Item 20 for a systemwide snapshot of the franchise program. The charts are designed to reveal a three-year summary of the growth--or contraction--of the national franchise system and the franchisor\'s expansion plans during the coming 12 months.\nGenerally, two lists are attached to Item 20. The first is a list of existing owners, organized by state. The law requires merely that the franchisor list at least 100 franchisees in your state and adjacent states. Also attached to Item 20 is a list of the names, addresses and telephone numbers of franchisees who have left the system for any reason in the past year. Talk to these former franchise owners to find out why they left and whether it was related to shortcomings in the program.\nTalk to Professional Chefs\nIf you\'re serious about being in business, you\'ll need a good accountant and an experienced attorney on your team. Your accountant will perform an essential function: helping you review the financial statements presented in the UFOC and using the cost projections in Item 7 to help you create your own projections and break-even analysis. Where serious dollars are concerned, you can\'t afford to miscalculate the capital needs and potential return on investment of your new business.\nYour attorney will advise you on the franchise agreement, your lease and any ancillary contracts. These are perhaps the most complicated legal obligations you\'ll encounter as an entrepreneur. The franchise agreement often runs more than 50 pages in length and is not required to be presented in plain English. After all, this contract conveys trademark rights and complex know-how, appoints the right to operate a franchise unit, details the conditions of renewal, specifies fees to be charged, promises services, imposes the obligations to comply with the franchise system, addresses the right of transfer, and tackles the always-difficult topics of termination conditions and post-termination obligations. And that\'s before it gets to the ""boilerplate"" provisions of indemnification, dispute resolution and independent contractor status. Stretch these topics to apply over a five-, 10- or 20-year relationship that\'s bound to change during that time, and you start to get an idea of the agreement\'s complexity.\nThis is no time for a do-it-yourself, cursory review. Neither is it time to consult your niece or nephew who happens to be a first-year law student. Find a good attorney with solid experience in advising small businesses who is comfortable reviewing a franchise offering.\nFollow the Recipe\nThe recipe analogy is apt for franchising because many franchisors insist that franchisees follow their recipe for success without deviation. Make sure you like the business of the franchise and that you\'re prepared to follow the franchisor\'s approach to management. Many systems leave no leeway for individual variations on the core elements of the franchise program, so owning a franchise is not for everyone.\nThis may not be the time to adhere to the old saying, ""If you can\'t stand the heat, get out of the kitchen."" It\'s certainly going to get hot in this kitchen, but it\'s all part of a great small-business investment. Get used to it. Savor it. If you\'re organized, relentlessly follow the recipe and choose wisely among the available franchises, you\'ll deliver a seven-course meal of extraordinary franchise success.\nReady, Set, Cook!\nOnce you\'ve chosen a franchise, you\'ll be your own master chef. Then it\'s time to make a success of the recipe and bring your own energy, joy and hard work to the mix.\n- Watch your pennies. Franchise specialists will tell you that most franchises, like most small-business operations, run on narrow profit margins. Success lies in your willingness to immerse yourself in the control of the expense side of the business.\n- It\'s people, people, people. Location is important, but if you\'re running a retail franchise, your biggest challenge may be finding people to fill the working crew. Economic prosperity and low unemployment mean everyone is looking for solid employees. It\'s an economic season of high turnover. Offer competitive wages and strong benefits.\n- Sweat the small stuff. The real magic of retail marketing takes place at the counter, the point of sale. Small things like eye contact, a cheerful greeting, a smile, and a subtle sales spin that promotes specials and larger orders can nudge the narrow margins into clear profitability. The best franchise programs insist on attention to detail at the front counter. The solution: ongoing training of counter or sales crew.\n- Connect with the customer. Outreach programs are the hot topics among franchisees these days. Direct-mail promotions bring \'em into the store: coupons, punch cards, discount specials, and even programs allowing the counter staff to learn and remember the names of regular customers are drawing new attention from franchisees in an increasingly crowded and competitive marketplace.\nAll The Fixings\nPart of the task of finding the right franchise for your interests involves investigating resources to help with your search and evaluation. Check out the following government and private resources:\n- The Federal Trade Commission (FTC) has regulated franchise sales since 1979. Its Franchise Rule requires franchisors to deliver a comprehensive disclosure document to all prospective franchisees at the earlier of 1) the first face-to-face meeting for the purpose of discussing a franchise sale or 2) at least 10 business days before you pay money or sign a binding contract for the purchase of the franchise. Franchisors are not required to file copies of their disclosure documents with the FTC, but you can get general advice and guidance by phone from the FTC\'s Consumer Response Center at (202) 326-3128, on the Internet at http://www.ftc.gov or by writing to the Federal Trade Commission, Washington, DC 20580.\n- Your state. If you live in one of the 13 ""registration states,"" you can feast on disclosure documents as part of the public record. Contact the agency in parentheses in these states: California (Department of Corporations), Hawaii (Department of Commerce and Consumer Affairs), Illinois (Office of the Attorney General), Indiana (Secretary of State, Securities Division), Maryland (Office of the Attorney General), Minnesota (Department of Commerce), New York (Department of Law), North Dakota (Office of the Securities Commissioner), Rhode Island (Division of Securities), South Dakota (Division of Securities), Virginia (Corporation Commission, Division of Securities and Retail Franchising), Washington (Department of Financial Institutions, Securities Division) and Wisconsin (Commissioner of Securities). If you don\'t live in one of these states, contact your state\'s consumer protection agency for general investment information.']"	['<urn:uuid:745cca7d-b767-40e8-87ce-11ab800a802f>', '<urn:uuid:ecc8ea0a-62eb-420e-83e5-908bbbead29d>']	open-ended	direct	verbose-and-natural	similar-to-document	multi-aspect	expert	2025-05-13T06:27:57.068978	24	114	2968
71	what causes stomach fat buildup and insulin problems connection	Belly fat consists of visceral fat cells that pump out hormones and chemicals affecting health. These chemicals travel through the portal vein to the liver where they can cause insulin resistance. This is particularly concerning as insulin resistance is a key characteristic of type 2 diabetes. Risk factors for developing both belly fat and type 2 diabetes include physical inactivity, genetic predisposition, and obesity. Between 80-90% of people with type 2 diabetes are considered overweight or obese.	['Amy Campbell, CDE, is a registered dietitian and the author of several books about diabetes, including 16 Myths of a Diabetic Diet and Staying Healthy with Diabetes: Nutrition and Meal Planning.\nWith winter winding down and swimsuit season right around the corner, our thoughts often turn to the few pounds that we may have put on since the holidays. And if you’re like many people, those few pounds may be clinging to your middle just like, well, a spare tire. Even if you’re not overweight or looking to lose weight, you may have noticed (especially if you’re a menopausal woman) that your weight has shifted and that your midsection is thicker than it used to be. Self, meet belly fat.\nWhat is belly fat? And why does it matter?\nBelly fat is just what the name implies. It’s fat that piles on around your waist and in your abdominal section. The good news, if you want to view it as such, is that everyone has some belly fat—even supermodels and physically fit people. However, unlike fat in other areas of your body, such as your arms, thighs, or under your chin, belly fat is deeper and more serious in terms of its health implications.\nAnother term for belly fat is visceral fat. Visceral fat is not your run-of-the-mill type of fat. Rather, it’s a vicious type of fat that wraps itself around the internal organs. Subcutaneous fat, on other hand, is a layer of fat that lies just beneath the skin. It’s annoying for sure, but it’s pretty harmless compared to visceral fat.\nUnlike fat in other areas of your body, belly fat is more serious in terms of its health implications.\nKeep in mind that belly fat is generally a combination of both subcutaneous and visceral fat. While there’s no easy way to know how much of each you have (short of having a CT scan or an MRI), grab a tape measure and check your waist circumference. Women with a waist circumference greater than 35 inches and men with a waist circumference great than 40 inches likely have a fair amount of visceral fat.\nWhat’s bad about belly fat?\nAs annoying as it is that you can barely button your jeans or zip up your skirt, the real concern about too much belly fat is that it can spell some serious health issues. These include a higher risk for:\n- Heart disease\n- Insulin resistance\n- Type 2 diabetes\n- High blood pressure\n- High cholesterol\n- Breast cancer\n- Colorectal cancer\n- Gallbladder disease\n- Premature death\nAccording to a recent study of almost 162,000 women age 50 to 79 who were part of the Women’s Health Initiative, the risk of dying was higher in women who had a waist circumference of more than 31.5 inches; for those with a waist measurement of more than 35 inches, the risk was considered to be “extreme.”\nSo why is belly fat so toxic? It has to do with fat cells. Don’t be fooled—fat cells are stealthy. They seem like harmless blobs, but like other organs in the body, they quietly keep busy, pumping out hormones and other chemicals that negatively affect health. In addition, belly fat is situated right near the portal vein that moves blood from the gastrointestinal tract to the liver. The chemicals from visceral fat are transported via the portal vein to the liver where they can affect the production of blood lipids and also cause insulin resistance.\nHow do you get rid of belly fat?\nThere’s good news and not-so-good news. First, the good news: you can shrink your belly fat. You won’t get rid of it completely, because, again, everyone has belly fat. But reducing it can be done. Now, the not-so-good news? It will require some effort and dedication. Here’s how:\n- Get— and keep—moving. According to a Duke University study, aerobic exercise, such as walking, swimming, or bicycling, is the best type of exercise to get rid of your belly bulge, as opposed to resistance training, because it burns more calories. Work up to exercising 30 minutes a day, most days of the week.\n- Work on losing weight. Losing weight isn’t always easy to do. Yet, losing just five to 10 percent of your body weight can help banish belly fat. Aim to lose weight gradually—say, one or two pounds per week. You’ll stand a better chance of keeping it off longer.\n- Squeeze in soluble fiber. Soluble fiber is the gummy type of fiber that can help lower cholesterol and blood sugar levels. As it turns out, it might also shrink your belly. A study out of Wake Forest Baptist Medical Center found that eating soluble fiber from beans, fruits, and vegetables helped to reduce belly fat. In fact, for every 10-gram increase in soluble fiber, visceral fat decreased by almost four percent over five years. How can you get 10 grams of soluble fiber? One cup of beans has close to five grams; a bowl of oatmeal has three grams; and an orange has about two grams.\n- Get some sleep, but not too much. Constantly shortchanging yourself of sleep can eventually catch up with you in more ways than one. According to one study, adults under the age of 40 who got five or fewer hours per night or more than eight hours per night increased their visceral fat.\n- Quit smoking. There aren’t enough bad things to say about smoking. Add this one to the list: smokers tend to have more visceral fat than non-smokers. In addition, smoking increases insulin resistance and the risk of type 2 diabetes.\n- Go for the (whole) grain. According to a study out of Tufts University, visceral fat was 10 percent lower in people who reported eating three or more servings of whole grains per day and who also limited their intake of refined grains to less than one serving per day. Examples of whole-grain foods include steel-cut oats, brown rice, quinoa, and whole-wheat bread.\n- Cook with canola oil. Canola oil has less saturated fat than most vegetable oils. In one study, people who replaced their usual cooking oil with canola oil had a quarter pound less of belly fat after just four weeks.\nIf you have concerns about your weight—specifically, your belly fat—talk with your doctor and maybe your dietitian. Work out a plan to whittle your middle and reduce your risks of future health problems.\nHave you tried to reduce belly fat? What worked (or didn’t)? Share what you’ve learned by commenting below.', 'Exercise as it relates to Disease/Is aerobic exercise the best form of training for preventing/reducing effects of type II diabetes?\n- 1 Background\n- 2 Effects of Type II Diabetes Mellitus\n- 3 Current Rehabilitation Methods\n- 4 Exercises and their ability to either prevent or reduce effects of type II diabetes\n- 5 Recommendations for Effective Exercise Rehabilitation\n- 6 Further reading\n- 7 References\nIn adults, type II diabetes mellitus (t2d) accounts for 90-95% of all diagnosed cases of diabetes. Of these individuals, 80-90% of them are considered overweight/obese. Type II diabetes is and will continue to be a major health care burden, by the year 2030 the number of people who have this disease is estimated to more than double in compared to the 2000 statistics where there were 171 million reported cases in America. Right now this disease effects 346 million people world wide.\nType II Diabetes Mellitus DefinedEdit\nThe initial/early characteristic of this disease is an onset of insulin resistance in body cells. T2d is known as a progressive disorder of glucose metabolism, therefore indicating that the individual may have a decreased β-cell function which would cause less insulin secretion.\n- Insulin resistance, genetic predisposition, obesity and physical inactivity.\n- Dysfunction in skeletal muscle and bone.\n- Genes can increase the likelihood of excessive weight gain when an individual has 1st degree family history of t2d.\n- Environmental factors and weight gain.\n- High levels of sedentary behavior are associated with increased risk of having t2d.\nEffects of Type II Diabetes MellitusEdit\n- Inability to control metabolic pathways and blood glucose levels.\n- Increased chances of getting coronary heart disease.\n- Low cardiovascular fitness found in patients with t2d increases their risk of developing a cardiovascular disease.\n- Bone quality is reduced thanks to a decrease in osteoblast cell growth, bone fractures are higher in individuals with t2d then those who have osteoperosis.\nCurrent Rehabilitation MethodsEdit\n- Follow the 2008 Physical Activity Guidelines.\n- Engage in some form of general exercise is recommended via American Diabetes Association, American College of Sports Medicine, and American Heart Association. Physical activity increases glucose transport and skeletal muscle insulin sensitivity.\nExercises and their ability to either prevent or reduce effects of type II diabetesEdit\n|Aerobic Exercise (AB)||Resistance Training (RT)||Anaerobic/Interval Training (AIT)||Sedentary Behavior (SB)|\nUsing larger muscle groups over extended periods of time, and doing so with a high volume of repititions.\n♦Improves functional capacity of cardiorespiratory system, decreases the onset of t2d.\n♦Improves glycemic control, body composition, vascular and ventricular function.\n♦No benefit when it comes to improving metabolic control.\nMovements of high loads using resistance from either machines or weights, generally a small number of repititions.\n♦Weight bearing exercises are key to improve bone health, therefore RT results in an increase of bone mass density.\n♦Does not improve aerobic capacity (AE).\nExercising at a high intensity for short bursts of time (example could include interval training), ensuring use of either phosphocreatine or glycolysis energy systems.\n♦Regular intervals help to increase sensitivity of insulin receptors helping to control ones blood glucose levels.\nActivities that are done sitting or in reclining posture that expend less than 1.5 times the basal metabolic rate, distinctly different than physical inactivity.\n♦Your body is automatically more vulnerable to diseases.\n♦SB impairs physiological functions and causes the body to be more susceptible to oxidative stress.\nRecommendations for Effective Exercise RehabilitationEdit\n|Exercise||Recommended Activity to Either Prevent or Reduce Effects of Type II Diabetes Mellitus|\n|Aerobic Exercise||30–60 minutes of exercise, 7 days a week, ensuring to reach 60-70% of heart rate max|\n|Resistance Training||Participate in a full body strength training program at a minimum of 3 days a week|\n|Anaerobic/Interval Training||Ensure intensity of workout is either: VO2 max= 40-59 & 60-84% or heart rate max= 50-69 & 70-89% |\nEnsure that all individuals complete a prescreening evaluation before they undergo any testing/physical exercise.\n- American Diabetes Association recommendations for treatment and prevention\n- American Heart Association general information\n- American College of Sports Medicine exercise and t2d\n- Videos: Combination of RT and AE benefits, Aerobic and Anaerobic blood glucose and diabetes and Type II Diabetes no case is the same\n- Wood, R.J., et al. (2012). ‘Resistance training in type II diabetes mellitus impact on areas of metabolic dysfunction in skeletal muscle and potential impact on bone’. Journal of Nutrition and Metabolism, pp. 1 - 13. doi:10.115/2012/268197\n- Jenkins, A. B., et al. (2013). ‘Segregation of a latent high adiposity phenotype in families with a history of type 2 diabetes mellitus implicates rare obesity susceptibility genetic variants with large effects in diabetes-related obesity’. PLoS ONE, Vol. 8, pp. 1 - 9.\n- Kadic, D., et al. (2013). ‘Function of β-cells and insulin resistance in long-standing type II diabetes mellitus’. Script Medica, Vol. 44, 79 - 82.\n- Lakerveld, J., et al.(2013). ‘The effects of a lifestyle on leisure-time sedentary behaviors in adults at risk: The Hoorn Prevention Study, a randomized controlled trial’. Preventative Medicine. Vol. 57, pp. 351 - 356.\n- Kiyatno. (2010). ‘Interval exercise with 1:1 work/rest ratio decreases the risk factors of type-2 diabetes mellitus and coronary heart disease’. Folica Medica Indonesiana, Vol. 46, pp. 229-232.\n- Johannsen, N. M., et al. (2013). ‘Categorical analysis of the impact of aerobic and resistance exercise training alone and in combination, on cardiorespiratory fitness levels in patients with type 2 diabetes’. Diabetes Care, Vol. 36, pp. 3305-3312.\n- Belli, T., et al. (2011).’Effects of 12-week overground walking training at ventilatory threshold velocity in type 2 diabetic women’. Diabetes Research and Clinical Practice, Vol. 93, pp. 337 - 343.\n- Brassard, P., et al.(2007). ‘Aerobic exercise training reverses diastolic dysfunction in uncomplicated well-controlled type 2 diabetics’. Diabetes. Vol. 56.\n- Kafkas, M. E., et al.(2013).‘The effect of aerobic and anaerobic swimming exercises on mda, sod and gsh levels of elite swimmers’. Health Med, Vol. 7, pp. 2459 - 2565.\n- Belli, T., et al.(2007).‘Lactate and ventilatory thresholds in type 2 diabetic women’. Diabetes Research and Clinical Practice, Vol. 76, pp. 18 - 23.\n- Radak, Z., et al.(2008).‘Systematic adaptation to oxidative challenge induced by regular exercise’. Free Radical Biology and Medicine, Vol. 44, pp. 153 - 159.']	['<urn:uuid:fbc82937-7a2d-4379-8bf4-3716f4b4b704>', '<urn:uuid:dea5012a-1059-479b-ae5a-4606ae5638cc>']	factoid	with-premise	long-search-query	distant-from-document	multi-aspect	novice	2025-05-13T06:27:57.068978	9	77	2124
72	drums history modern festivals evolution	Drums have an ancient history dating back to at least 6000BC, serving ceremonial and communication purposes across cultures worldwide, including talking drums in Africa and frame drums for shamans in Asia. In modern times, drums continue to evolve and are celebrated in festivals like the Dobršská brána International Music Festival, which in 2021 spotlighted drummers including Anika Nilles, Anne Paceo, and Pavel Fajt. The evolution of drums saw major developments in the 1800s with the first drum kits, followed by innovations in the 1920s jazz scene with additions like tom-toms and hi-hat cymbals, leading to today's diverse percussion landscape.	['The Dobršská brána International Music Festival keeps to its tradition and ambition with another year of first-rate musicians from across Europe including the Czech Republic. Each year’s festival has a focus on an instrument; as last year’s was the Accordion, 2021 will spotlight the power of the Drums.\nIn the jazz pantheon, the list of legendary drummers is formidable including Art Blakey, Buddy Rich, Max Roach, Elvin Jones, Philly Joe Jones, Tony Williams, Billy Cobham, and on and on. However, there have not been many women on the list until recent years with the inclusion of Cindy Blackman Santana followed by Terri Lynn Carrington. Following hard on bass-drum pedals is Anika Nilles (born 1983), a fiery drummer from Germany leading her group Nevell (a jazz-funk-rock-pop fusion trio), and Anne Paceo (born 1984 in France), who is a drummer, composer and leader of the Circles project.\nAnika Nilles Nevell performs on the opening night of the festival, which runs for two days/evenings in various venues throughout the quaint hillside village of Dobrs, in South Bohemia’s Sumava foothills.\nAnother highlight of the first day is Pavel Fajt (born 1957 in Brno), a veteran avant-garde drummer percussionist initially noted for his collaborations with the experimental vocalist and violinist Iva Bittová. Fajt is an esteemed figure in the Czech experimental music scene from the 1970s into the current times. In 2001, Fajt released Drum Trek, displaying this master as a soloist with electronics.\nThe roll call of most noted drummers & percussionists on the main day includes Bodek Janke, Cyril Atef, Klaus Kugel and the final headliner Anne Paceo.\nBodek Janke performs his project SONG2, an experimental blend of pop songs from across decades under his jazz-improvisational arrangements and sung by the smooth and fragile-voiced Namibian vocalist Shishani Vranckx. Their repertoire includes jazz ballads “I Fall in Love Too Easily” (Chet Baker), along with 80s and 90s pop radio hits “What is Love” (Haddaway), “Rhythm is a Dancer” (Snap!), “Take on Me (A-ha), and “Eye of the Tiger (Survivor), to list only a few retro-pop nuggets.\nJanke (born 1979, Warsaw) is a Polish-Russian mostly raised and currently based in Germany. He has been schooled in classical conservatories (Karlsruhe) and jazz academies or specialty programs–the Academy of Music Cologne, and City College New York City (MA in Arts & Music Performance). SONG2 also features Estonian pianist Kristjan Randau, and British bassist Phillip Donkin.\nCyril Atef is a French-Persian percussionist and composer and he will bring his project Bumcello with Vincent Segal, who is handy on a wide variety of instruments. Their performances are multimedia and the high-tech visuals are essential to enhance their psychedelic-hypnotic groove with its exotic and experimental twists and turns. Their downtempo electronica is both modern-day primal and futuristic.\nAtef was born in Berlin (1968) then moved to Los Angeles, California, at the age of ten. In the mid-1980s he studied at the Percussion Institute of Technology and at the end of the 80s at Berklee College of Music in Boston. He has been based in Paris since 1990. The other half of Bumcello, Vincent Segal, was born 1967 in Reims, France, and he commands the stage on electric cello and as the lead vocalist.\nConcluding the festival is Anne Paceo, who has been awarded the Victories de la Musique (Jazz Artist of the Year in 2016) and Jazz Discovery of the Year in 2011. Her project Circles is a modern fusion jazz quartet with an uplifting female vocalist-rapper (Camille Durand) and sound-wise, they are a roaring thunder of drums & percussion thanks to Paceo along with saxophone (Christophe Panzani) and keyboards (Tony Paeleman). The roar of drums should be heard loudest of all and far and across the nearby valleys and mountains of South Bohemia for the concluding evening of this year’s festival.\nThe remaining artists/groups on the program include Klaus Kugel, a German master drummer from Munich, who has been a leading figure on the modern jazz scene in Central Europe. Then from the Czech Republic, JeN Hovorka (voice) and Marek Urbanek (drummer) combine urban beat rapping with funky drumming, and the MaBaSo Trio, featuring Czechs Daniel Soltis (drummer) and Michael Baranski (bassist) with Polish vibraphonist Bernard Maseli play a funky 70s jazz art-rock-fusion.\nThe only group in the festival sans drummer is Romanovská Tichý Hrubý & Blažíková. Yet, this group is a nod to the original orientation of the festival combining improvisational and classical musicians for the most curious of outcomes. In this case, the improv trio of classical violinist and koto player Anna Romanovská, classical and jazz double-bassist Peter Tichý, and the free jazz improviser saxophonist-clarinetist-flutist Michal Hrubý will be joined by the soprano and harpist Hana Blažíková, who is a most highly-regarded soprano on the Czech/European classical scene. Hrubý was also an initial organizer of this festival, in its first edition, so this group marks a return to the festival’s roots.\nDespite its size, in the village of Dobrš, this festival offers in this part of Europe the most eclectic first-rate international musicians performing experimental contemporary jazz, classical and pop music. Besides the main outdoor stage, smaller concerts are held in a Baroque church, a shady lawn beside a Gothic tower, and if necessary due to the weather, a barren pub makes for a cozy performance space.\nThe Fifth Annual Dobršská brána International Music Festival 2021 will be on August 13th & 14th. More Information can be found on their website here.\nLast modified: August 18, 2021', 'No instrument has longer history than the drums. Drums are found in almost every culture worldwide and are known to have existed since at least 6000BC. Drums have strong ceremonial, sacred and symbolic associations. Drums have in the past been used for signalling of meeting, dangers sending messages etc… The talking drums of Africa imitate pitch patterns of language and can transmit messages over many miles. Shallow frame drums serve as ritual instruments for shamans throughout Central Asia, Siberia and some native tribes of North America. In Europe, The Timpani were associated with royalty as late as the 17th Century. The Tambourine was traditionally a woman’s instrument in Islamist cultures, ancient and prehistoric times and in medieval Europe. The snare (side drum) was and still is used in European infantry regiments however, it used to be used not just as an instrument but to code instructions to soldiers during battles.\nThe first drum kits were assembled in the 1800’s when the development of the bass drum pedal enabled all of the basic percussion instruments (snare, bass drum and cymbals) to be played simultaneously by a single person. In the late 1920’s jazz drummers in the nightclubs of New Orleans began using the drum kit to provide creative accompaniment for other jazz musicians. The set expanded with tom-toms, Turkish and Chinese style cymbals, and the hi-hat cymbal which to this day remains one of the most important innovations.\nOver the years many new techniques have been developed by different artists, for example:\nGene Krupa – Jazz drummer who featured tom-toms predominantly in his playing during the 1930’s and established drums as a solo instrument.\n- Max Roach – Another great jazz drummer who tuned his drums higher and emphasized rhythm with use of cymbals (particularly the ride) rather than the bass drum thus, allowing more flexible use of the rest of the kit.\n- Louis Belson – Jazz drummer who established/revived the use of the two bass drums (double kick) in the 1950’s.\n- Through the 60’s and 70’s recording techniques improved with greater amplification of instruments from rock music enabling drum kits to be played louder without overpowering other instruments. Drums were made of stronger materials and drum heads were made more durable with plastic replacing calf skin. More modern kits began to emerge which were bigger consisting of four or more toms as well as a variety of auxiliary percussion instruments.\n- The 80’s brought electronic drums (or MIDI drums) which are now more often used for recording or low volume practice.\nFor this weeks composition only drums were used. The piece starts out fairly minimal but builds up energy as it progresses and more layers of drums are introduced. In all, we hear 3 different drum kits in the piece (3 instances of EZdrummer – 2 drumkits from hell and 1 standard rock kit) which are all playing together towards the end of the piece.\nDrumkit from Hell (left) and Standard Rock Kit (right)\nAlso, there are some sampled world percussive drums (Darbuka and Indian Tabla) which are played through NI’s Kontakt and a TR909 kick which comes in from 01:24 just to beef it up some more.\nDarbuaka (left) and Indian Tabla Drums (right)\nThe piece is mainly in 4/4 time signature from beginning to end although some polyrythmical elements are introduced at 01:24 (snare, stick and hi hat) layered over the main underlying time signature of 4/4. The drums are mainly programmed using a midi keyboard and edited, although a hi-hat loop was used for the hi-hats which we hear from 00:21. On these Hi-hats which we hear from 00:21 til the end of the piece there is a live performance element in the form of a sweeping EQ effect which was done using live automation of a ‘notch’ on the EQ of the Hi-Hats.\nBelow is a link to this weeks piece:\nChatto, A (1996). Brief History of Drumming. http://www.cadre-online.ca/drumhistory.html – accessed 25/03/2014.\nRandall, JA. (2001). “Evolution and Function of Drumming as Communication in Mammals”. American Zoologist 41 (5): 1143–1156. doi:10.1668/0003-1569(2001)041[1143:EAFODA]2.0.CO;2.\nReed, Ted (1997). Progressive Steps to Syncopation for the Modern Drummer, p.33. ISBN 0-88284-795-3.\nToussaint, Godfried (2013). The Geometry of Musical Rhythm, Chapman & Hall/CRC.\nWolfe, J (2011). History of Drumming. OC Drum School. http://ocdrumschool.com/history-of-drumming – accessed 26/03/2014.']	['<urn:uuid:2645e746-dc9f-4c18-a842-f4b578b0aff6>', '<urn:uuid:d30f7970-7c75-47a5-8754-effc5002d37d>']	open-ended	direct	short-search-query	similar-to-document	multi-aspect	novice	2025-05-13T06:27:57.068978	5	99	1624
73	when start national bullying month hispanic heritage month	National Bullying Prevention Month and Hispanic Heritage Month overlap in October, with Hispanic Heritage Month running from September 15 to October 15, while National Bullying Prevention Month takes place during October.	"['October is National Bullying Prevention Month, a time dedicated to raising awareness of the devastating effects of bullying and the power of prevention.\nWith bullying in the spotlight, this can be a good time to start a conversation with your kids and other adults about bullying, or to think about your own role in bullying prevention. Our Preventing Bullying website can help parents, educators, and community members learn about bullying and find tools to prevent it before it even starts.\n""...when parents, teachers, and community members work together, we can take the first step toward making bullying a distant memory for our children.""\nThe Need for Bullying Prevention\nThe effects of bullying in our country are widespread, with 1 in 4 children reporting being bullied at school in the last year. Bullying is detrimental to both the bully and the victim, and its effects can last beyond childhood.\nBut there’s also some good news. Research shows that bullying prevention programs are successful—and a key component of bullying prevention programs is awareness. When children and adults alike know what bullying is and understand that it is not to be tolerated, they begin to take action to prevent it.\nTo aid in fostering awareness, PACER’s National Bullying Prevention Center started Bullying Prevention Month in 2006, and recently we joined them as collaborators in their efforts. Originally a week-long event, the now month-long campaign seeks to engage children and adults across the country in an effort to spread a single, clear message: The end of bullying begins with me.\nWe at PromotePrevent echo this sentiment of personal responsibility to eradicate bullying from children’s lives—and we have some useful tools and resources to help you do so.\nFor more than 10 years, we worked with more than 300 communities across the country through a federal initiative that aimed to create safer schools and healthier students.\nWhat did we learn from our years of experience? We found that successful bullying prevention programs are a team effort, requiring the support of parents, educators, community members—and children themselves—to work together to understand and prevent bullying, and to intervene when it occurs.\nOn the Preventing Bullying site, we use this guiding principle—understand, prevent, and intervene—to turn research-based practices into practical, useful tools that you can use to address bullying. We focus on three key areas: Cyberbullying, Early Childhood, and School and Community.\nDefined simply as “bullying that occurs through digital technology,” cyberbullying is in the headlines and on the minds of many parents and educators. As the number of children, tweens, and teens with access to mobile devices and the Internet increases, so does their risk of being involved in digital abuse. Our site offers 6 interactive scenarios that help parents and educators talk to children about what it means to be a digital citizen and how they can keep themselves safe online.\nBullying behaviors emerge even in preschool settings, but with proper tools, early childhood educators and parents can work together to stop bullying before it even starts. Our site offers a 13 chapter toolkit on preventing bullying in early childhood. The toolkit includes a number of activities for adults to conduct with young children, helping them build their social skills in the areas of empathy, assertiveness, and problem-solving.\nSchool and Community\nNo community is “safe” from the devastating effects of bullying—but when parents, teachers, and community members work together, we can take the first step toward making bullying a distant memory for our children. Learn from the successes of our partner communities in the Real Stories, as they share their personalized strategies for bullying prevention. Then try Voices Against Violence, a unique tool to help schools and communities understand the importance of speaking up when you see something wrong at school, including bullying and school violence.\nWe hope that through these interactive tools and resources, you can accept PACER’s call to action—the end of bullying begins with me—and spread the message of this important month.\nWhat are the greatest challenges you face in preventing and addressing bullying? Does our new preventing bullying website help you overcome these challenges? We’d love to hear what you think! Please add your thoughts and comments below.*\n*E-mail addresses will be kept confidential.', 'Are you looking for a way to celebrate Hispanic Heritage Month? The literature, art, food and music from over 20 Spanish-speaking countries provide so much inspiration for special events, lesson plans or activities. Even if your family or students are not Hispanic or Latino, this national observance is an opportunity to learn about this rapidly growing population’s traditions, contributions and history.\nDYK: According to the US Census Bureau, the Hispanic population in the United States was 62 million in July 2021, making people of Hispanic origin the largest racial or ethnic minority at 18.9% of the total population.\nHistory of Hispanic Heritage Month\nBefore planning your celebration, let’s take a moment to review the history. Celebrated from September 15 until October 15, this national observance started in 1968 when President Lyndon B. Johnson designated a week to recognize the contributions of Hispanic Americans. In 1988, President Ronald Reagan expanded the weeklong observance to a month. It was subsequently enacted into law on August 17, 1988. The start date of September 15 was significant because it’s also the anniversary of independence for the Latin American countries of Costa Rica, El Salvador, Guatemala, Honduras and Nicaragua. Mexico, Chile and Belize’s independence days are September 16, 18 and 21. Columbus Day or Día de la Raza, is on October 12. Thus, the national observance in the U.S. extends until October 15.\nHispanic Heritage Month Celebrations at Home, School or Program\nDiscover the arts, crafts, book recommendations, virtual tours, music and more of Hispanic and Latino cultures. The following list of fun and creative ways to celebrate Hispanic Heritage Month will bring vibrant colors, rich history and tradition to life for all ages at your home, school or program.\n- Host a Fabulous Frida Decorating Contest. Featured on U.S. stamps, calendars and postcards, the Mexican artist Frida Kahlo’s self-portrait has also landed in schools and programs nationwide. Make it a program or school-wide contest to create Fabulous Frida bulletin boards or classroom doors for Hispanic Heritage Month. Discover decorating ideas on DIY websites such as Pinterest and Spanish Mama. This downloadable resource is available for $4 on the Teachers Pay Teachers website.\n- Make the Perfect DIY Piñata! Decorating and filling this paper-mâché figure with fruit, candy or toys is only half the fun. The best part of this festive Latin tradition is breaking it open. Get instructions from the Kids Activities website.\n- Read Books Featuring Hispanic and Latino Authors. From picture to poetry, fiction and non-fiction books, celebrate the contributions of Hispanic and Latino authors with a storytime, book club or read-a-thon. Try 11 Picture Books Celebrating Hispanic Heritage Month or Books for Hispanic Heritage Month for the little ones. Also, check out 6 powerful books to read during Hispanic Heritage Month for yourself and your kids, 12 Hispanic Authors Who Target Young Adults and Teens or YA Books by Latino Authors for the older ones.\n- Make and Shake Mini Maracas. Kids Activities will help you create beautiful music with beans, empty film canisters, craft sticks and colored vinyl tap. Kinder Art offers a recycled version using water bottles. A staple of Latin music, a maraca is a rattle usually made from a gourd used as a percussion instrument. Just grab the handle and shake for sound.\n- Savor the Flavors. Host a taste-testing, lunch or dinner featuring the savory flavors of traditional dishes such as flan, pupusas, enchiladas, Arroz con pollo, empanadas and paletas. Celebrate Hispanic Heritage Month with 25 recipes from Mexico, Puerto Rico, Spain and more or 40 Latin-inspired Meals Kids will Love. Let your little chefs help prepare the meals.\n- Paint Ponchos. All it takes is paper, paint, glue and yard to recreate this traditional colorful Mexican sleeveless garment. Deep Space Sparkle says it takes about 40 minutes for children to make the famous Mexican poncho, also called a serape or jorongo.\n- Take a Virtual Tour of the Molina Family Latino Gallery. Take a trip to the Somos Theater or Learning Lounge with this interactive map. Learn about the features in the Molina Family Latino Gallery and content from the ¡Presente! Exhibit right from your classroom or home.\n- Learn Latin American Geography. Young children can color pre-printed maps or flags from Spanish Mama to decorate the classroom. Education.com recommends a map challenge that requires students to research different cities in South America for middle and high-school children.\n- Binge-Watch Spanish Movies. Teachers Pay Teachers recommends the Disney Pixar movie Coco for young children. There are also a variety of Spanish-language films featuring Hispanic and Latino entertainers on Netflix and other streaming services.\n- Make a Mayan Pyramid. The myths surrounding the Maya ruins at Uxmal (pronounced oosh-mawl) have captured the imagination of both young and old for its mystical murals, carvings and sculptures found in the grand architecture of pyramids. Inspired by Family can help you share the legends of the Mayan people with children two and older.\n- Visit the Smithsonian’s Latino Center. In 2020, Congress enacted legislation establishing an American Latino Museum in Washington, D.C. In the meantime, you can visit the Smithsonian’s Latino Center.\n- Step to Salsa. Incorporate a math lesson into your Hispanic Heritage Month celebration as children count the six steps to the salsa. Like the mambo, salsa is a Latin dance with over eight music counts. It’s also an opportunity to shake off stress, get exercise and build motor skills. Music is important for school readiness and social and emotional development. Add other dance moves such as the mambo, merengue and cha-cha. Invite a dance instruction to the classroom or visit YouTube for virtual lessons.\n- Fall for a Fiesta. Conclude Hispanic Heritage Month with a Fall Fiesta. Use the recommendations above to decorate your home, program or classroom. This celebration is an opportunity to showcase your month-long projects, share your knowledge and display your new dance moves. Also, check out the Fiesta Del Sur at William Beans Community Center or the 14th annual Latino Festival of Frederick.\nCheck out the MFE events section of the website that features a variety of local Hispanic Heritage Month events and activities. Share your creative ideas, photos and videos of Hispanic Heritage Month celebrations on Facebook, Twitter and Instagram @MDEngageEarly using the Hashtag #HispanicHeritageMonth.']"	['<urn:uuid:207797c0-7c3b-4770-9c53-038185fa112e>', '<urn:uuid:e9e4913e-69f1-478d-85b8-211aeb5d85a4>']	factoid	direct	short-search-query	distant-from-document	comparison	novice	2025-05-13T06:27:57.068978	8	31	1746
74	How do storage requirements differ from emergency response procedures?	Chemical storage requires appropriate containment to prevent spills, leaks, and breakages, focusing on regulatory compliance and risk reduction. In contrast, emergency response procedures involve immediate actions like evacuation, medical intervention, and decontamination, with specific requirements for different protection levels and certified personnel. Both aspects must comply with health and safety legislation while protecting staff and students from hazardous exposure.	"['Using chemicals safely\nThe safe management of chemically-based materials during purchase, storage, use and disposal is outlined here.\nThese resources are relevant to laboratory workers and anyone working with a chemically-based substance including paints, glues and cleaning fluid who must assess whether hazardous chemicals are being used:\n- in sufficient concentration or quantity\n- in a way that poses a significant risk to either health, environment or property.\nPurpose: Guidance on the purchase, use and storage of named drug precursors. The University of Bristol has duties imposed by the Home Office under the various European regulations with regard to the monitoring of trade in drug precursors within the EU and between the community and third countries.\nHow to use: Licenses are needed to demonstrate proper control, and establish efficient two-way reporting mechanisms, within users and between the Home Office and the University.\nRelevant for: Schools that may use or wish to use category 1 drug precursors for any reason within the usual bounds of research and teaching.\nFurther guidance on less sensitive precursors and other specifically controlled substances may be found in other guidance from Safety and Health Services.\nHazard warning signs\nPurpose: Since the COSHH Regulations were introduced in 1988 there has been an increasing demand for standardised hazard information; this is needed to assist users downstream of the chemicals’ manufacturer or supplier to be able to clearly recognise their hazardous properties. In turn, that helps the user to estimate the potential risks that those substances present.\nThe lack of quality in safety data sheets and the international non-uniformity of labelling have led to many revisions. This briefing note clarifies the current situation and describes some expected developments in the near future.\nResource: Hazard warning signs guidance\nLaboratories and control of hazardous chemicals\nPurpose: Providing University laboratory users with the essential basic knowledge and practical advice needed to work safely in a laboratory environment.\nHow to use: This set of resources is intended to complement the health and safety guidance issued by the University of Bristol, which should be adhered to at all times. Modules covering different aspects of the Control of Substances Hazardous to Health (COSHH) consist of tutorials and assessments, as well as some links to video demonstrations, worked examples and other resources. If you are unfamiliar with COSHH, work sequentially through each of the modules. Before moving on to the next module, complete the assessment and check you have understood and can apply the contents of a module.\nResource: Guidance modules\nProduced by: Royal Society of Chemistry\nRelevant for: All University laboratory users, but particularly applicable to Principal Investigators and postgraduate students and researchers.\nThis resource has been developed from existing good practice guides produced by the Royal Society of Chemistry and material kindly supplied by UK University Chemistry Departments. Any advice given has been carefully formulated but is necessarily based on the information available, and the RSC and cannot be held responsible for accuracy or completeness. In this respect, the RSC owes no duty of care and shall not be liable for any resulting damage or loss.\nFurther information about working safely in a laboratory environment\nThe guidance from the Health and Safety Executive means you will normally be doing enough to comply with the law. Health and safety inspectors seek to secure compliance with the law, and may refer to this guidance as illustrating good practice.\nSafe storage of chemicals\nPurpose: Advice on appropriate measures to take to ensure their chemicals are stored correctly, safely and in compliance with regulatory requirements.\nHow to use: The safe management of hazardous chemicals includes storing these substances in an appropriate manner to reduce the risk of injury or physical damage from unintended exposure, spills, leaks or breakages.\nResource: Safe storage of chemicals guidance\nRelevant for: Individuals who may handle or are responsible for the use and storage of hazardous substances.\nGuidance on the management and use of fume cupboards\nPurpose: The University has a responsibility under health and safety legislation to provide and maintain plant and systems of work, which are safe and without risk to health. Hence there is a duty to ensure that fume cupboards used within the University effectively protect staff and students from exposure to substances that may be hazardous to their health.\nResource: Laboratory fume cupboard guidance\nTransporting chemicals for events\nPurpose: It is often necessary to move chemicals around for the purposes of lectures, demonstrations, competitions or other hands-on practical activities. The Royal Society of Chemistry has published guidance on the hazards of transporting small quantities of chemicals and the appropriate measures to follow to ensure this is done safely and in compliance with legislation.\nProduced by: The Royal Society of Chemistry\nPurpose: Guidance for establishing a safe workplace and good safety practice when working with particulate nanomaterials. This is applicable to a wide range of nanomaterials, including:\nThe guidance also recognises previous and current uncertainty in developing effective risk management when dealing with nanomaterials and advocates a precautionary strategy to minimise potential exposure.\nWaste and spills\nChemical waste disposal route\nThe chemical waste disposal route is managed by staff from Sustainability. Contact them for further information and documentation, including the waste disposal form.\nResource: Sustainability chemical waste route\nProduced by: Rose Rooney, Sustainability, University of Bristol\nChemical waste guidance\nPurpose: Laboratory waste is considered hazardous when it contains properties that are harmful to human health and to the wider environment. This resource provides guidance on chemical and laboratory waste.\nResource: Chemical waste guidance\nChemical spill guidance\nPurpose: This framework for chemical spill response planning is designed to prepare staff for spill clean-ups. It provides an overview on handling spill incidents from planning through to using spill equipment correctly.\nResource: Guide for Chemical Spill Response Planning in Laboratories\nProduced by: American Chemical Society\nRisk assessments and checklists\nRisk assessments templates\nPurpose: Example risk assessment forms and templates for work involving hazardous chemicals.\n- COSHH chemical risk assessment form\n- COSHH chemical risk assessment example 1\n- COSHH chemical risk assessment example 2\nProduced by: Andy Macquiban\nChemical risk assessment video\nPurpose: This short video provides an overview of the reasons why conducting a risk assessment of laboratory work is so important for maintaining situational awareness as laboratory work proceeds.\nResource: Lab risk assessment video\nDSEAR classification checklist\nPurpose: A checklist for dangerous substances and explosive atmospheres area classification.\nThe DSEAR risk assessment template and checklist should be used when assessing fire and explosive hazards posed by the use and storage of flammable and explosive substances and gases. This is an additional assessment that should be carried out where a general risk assessment identifies there is potential for flammable or explosive atmospheres to develop as a result of the activity.\nResource: DSEAR risk assessment form\nRisk assessment for working with allergens and sensitizing substances\nPurpose: This template outlines the considerations that should be discussed with individuals who have declared atopic allergy or a specific known allergy to the sensitising substances or allergens they may be handling as part of their work.\nRespiratory Protection Equipment (RPE)\nRPE is used in many work situations to protect wearers from exposure to hazardous substances such as:\nRPE comes in many different types and must be the right one for the substance, task and work environment to provide adequate protection.\nHSE and Healthy Working Lives have developed the RPE selector tool to help users select the most appropriate type of RPE for their requirements.\nRead the policy on hazardous chemical management.\nChemical hazard information\n- HSE: Labelling and packaging\n- HSE: Control of Substances Hazardous to Health (COSHH)\n- HSE: COSHH essentials\n- ChemSpider: Chemical structure database\n- INCHEM: Internationally peer reviewed chemical safety information\n- ECHA: Information on chemicals\n- IFA: GESTIS Substance Database\n- CCPS: Chemical Reactivity Worksheet', 'Division: Public Safety\nClassification: FINANCE & ADMINISTRATION\nContact Phone Number: 503-838-8481\nContact Email Address: email@example.com\n|Hazardous Chemical Spill/Exposure Response|\n|RESPONSIBLE OFFICER||UNIVERSITY CONTACT|\n|Vice President for Finance and Administration||Campus Public Safety|\nThe purpose of this policy is to respond to chemical spills and/or exposures through emergency response that provides priorities to life safety, preservation of property and restoration of academic programs.\n|WOU campus community|\n|FULL STATEMENT OF AUTHORITY|\nIt is the policy of Western Oregon University to comply with OAR 437 and 29 CFR 1910.1200 in responding to hazardous chemical spills and exposures. Emergency response consists of responding, identifying, alerting, evacuation, medical intervention and decontamination. This policy is in conjunction with WOU’s ""Emergencies, Natural Disasters"" procedure in the event a chemical spill or exposure should become a disaster.\n1. Hazardous Chemical Exposure or Spills may consist of:\n* Chemical Release into the environment above the manufacturer’s suggested level of safety. The same chemical(s) may not pose a threat in low concentrations; however, in large concentrations the exposure may be harmful or fatal.\n* Fume/vapor exposure may occur and cause a sense of burning or irritation to the mouth, nose, throat, chest or eyes; dizziness; nausea; or presence of a strong odor may exist.\n* Unconsciousness of a person in or around chemicals. This area should not be entered into until the cause of unconsciousness is determined, proper personal equipment is used and appropriate emergency personnel notified to respond.\n* Skin/eye contact - with a hazardous chemical should be treated as described on the first aid section of the Safety Data Sheet (SDS).\n2. Reporting Hazardous Chemical Spill/Exposure - In the event a hazardous chemical spill or exposure occurs the following should take place:\n* Leave the area immediately;\n* Alarm - alert others of potential hazard;\n* Call Campus Public Safety at 8-9000 to respond and provide:\na. location of building, room, landmark\nb. description of chemical, if known\nc. number of persons exposed to a hazardous chemical and potential first aid needed\nd. your name and phone number for call back\n* Secure the area by preventing persons from entering until Campus Public Safety arrives\n3. Campus Public Safety Response to Chemical Spill or Exposure - When Campus Public Safety responds, the following will occur:\n* Analysis - Public Safety officers will, as a first responder, analyze the chemical spill.\n* Evacuate - Public Safety officers will evacuate all persons to a safe area.\n* Additional Resources - Public Safety officers will determine what resources are required, including medical assistance, fire and life safety support, hazardous response team, etc.\n* Secure Scene - The exposure area will be secured to prevent unauthorized entry.\n* Provide First Aid - First aid will be provided to victims to reduce exposure, which may include water dilution, ventilation, etc.\n4. Remedial, Cleanup - In the event a chemical spill or exposure occurs requiring remedial cleanup, the following must occur:\na. Site Evaluation:\n1) Identify the hazardous chemical(s) through monitoring SDS and control chemical spill or exposure from enlarging.\n2) If the chemical cannot be identified and/or containment cannot be made, Polk County Fire District #1 will be requested to respond.\n3) Level of Protection - All persons who perform site evaluation or decontamination are required to wear the level of protection of A, B, C or D, depending on the hazardous chemical:\nLevel A - Self-contained breathing apparatus with fully encapsulating suit\nLevel B - Self-contained breathing apparatus and chemically resistant suit\nLevel C – Full-face piece respirator and chemically resistant clothing\nLevel D - No respirator required. Boots, gloves and coveralls are required\nb. Remediate Hazardous Chemical(s) - If a hazardous chemical can be remediated by Western Oregon University staff, two certified hazardous waste site operations personnel from Campus Public Safety/Physical Plant will perform the following per 29CFR1910.120:\n* Site characterization and analysis\n* Site control\n* Container handling\nIn addition, the site operations personnel are required to have in place prior to hazardous chemical response:\n* Certification card\n* Safety and health program\n* Medical surveillance\n* Engineering controls, work practices, personal protective equipment and employee protection program\n* Information programs\n* Emergency response plan\n* Illumination of chemical response site\n* Sanitation of chemical response site\n* New technology programs\nc. Unable to Remediate Chemical(s) - If Western Oregon University personnel are unable to remediate a chemical spill, Campus Public Safety will request through Polk County Fire District #1, Salem Haz Mat Team or a safety consultation company, a hazardous materials response team to assist in remediation of the hazardous chemical.\nd. Decontamination - If a chemical spill can be decontaminated by Western Oregon University certified hazardous waste site operations personnel, the following will occur:\n* Proper personal protective equipment must be used;\n* Decontamination zones will be established;\n* All hazardous chemical waste and cleanup residue will be disposed of properly;\n* A written plan of decontamination will be in place prior to executing the cleanup.\ne. Unable to Decontaminate - If Western Oregon University is unable to decontaminate a hazardous chemical spill, assistance will be requested through a safety consultant company or Polk County Fire District #1.\nPersons may be allowed to return to a decontaminated area when a certified hazardous waste coordinator declares the site as safe. - At no time is an employee, agent, student or other person to approach a hazardous waste spill or exposure unless they are trained in accordance with CFR 1910.120 and this procedure.\n|REFERENCED OR RELATED POLICIES|\n|RELEVANT DOCUMENTS AND LINKS|\nLAST UPDATED: 08/11/2016\nHISTORICAL DETAIL NOTES:\nSOURCE: Previously Referred to as: FA-CPS-006\n|FOR POLICY WEBSITE INPUT (public audience keyword search)|\n|Hazardous Chemical, Exposure, Spills|']"	['<urn:uuid:c8cf1ff6-e4f0-4398-857c-a496593cab94>', '<urn:uuid:2f525ff8-40e0-4229-9bba-bb41329a2ea0>']	factoid	with-premise	concise-and-natural	similar-to-document	multi-aspect	expert	2025-05-13T06:27:57.068978	9	59	2236
75	natural law ethics universal rules principles moral philosophy explain core ideas	The universal ethic based on natural moral law consists of three basic rules: 1. Acts which are welcomed benefits are good, 2. All acts, and only those acts, which coercively harm others are evil, 3. All other acts are neutral. This ethic is founded on Lockean premises derived from human nature, specifically the concepts of human independence and equality, which recognize that there is no inherent master-slave relation among humans and that all people have equal moral worth.	['The proposition in argumentation ethics is that “arguing for any political position other than libertarian anarchism is logically inconsistent”.1 This proposition was set forth in 1988 by Professor Hans-Hermann Hoppe of the University of Nevada at Las Vegas. The basic idea is that the non-aggression principle is a premise implied in every argument, and so it cannot be logically denied in any doctrine. The concept of argumentation or discourse ethics had been developed by several German philosophers, such as Jürgen Habermas.\nThe non-aggression principle is that aggression—the initiation of force or fraud against a person—is morally evil. The argumentation proposition is that non-aggression is a presupposition of every argument, and so the concept cannot be logically denied within an argument. If a person argues that slavery is justified, the contradiction is that by engaging in argument with another person, he is implying that they are both seeking to arrive at truth by persuasion as equal independent non-slave parties. Since the person who argues for slavery is not using force to make the other person a slave, that implies that he is thereby rejecting slavery. It is then logically and performatively inconsistent for him to argue that enslaving any other person would be justified.\nThe prevailing argument for a libertarian ethic, based on natural moral law, is based on human nature applied to human action, rather than argumentation. The two premises set forth by John Locke in his Second Treatise of Governmentare human independence and equality.\nEquality means that human beings have an equal moral worth, which is the basis of Jefferson’s statement that we are created equal, and is the basis of equality before the law. The equality premise is based on the observation that there is no inherent master-slave relation among human beings, and so equality is more consistent with human biology than any inherent moral superiority of any race, sex, or culture.\nIndependence is the biological statement that persons think and feel as independent beings. Equality means that human beings have an equal moral worth, which is the basis of Jefferson’s statement that we are created equal, and is the basis of equality before the law. The equality premise is based on the observation that there is no inherent master-slave relation among human beings, and so equality is more consistent with human biology than any inherent moral superiority of any race, sex, or culture.\nHoppe states that concept of human nature is too diffuse to provide a determinate set of premises for natural law. Locke’s premises of independence and equality indeed have fuzzy edges, such as for beings not yet born, but they seem to be clear enough for practical purposes. Libertarians have no consensus on issues such as abortion, capital punishment, land value subsidies, the use of the military, and the justification of imposed government, but argumentation does not resolve such issues either. One needs additional premises to solve issues such as personhood, e.g. under which conditions is a human organism a person with rights. After all, one cannot have discourse with a newly born baby.\nThe concept of argumentation ethics has been rejected by several libertarian scholars, for example the article in The Journal of Libertarian Studies (Spring 2006) by Robert Murphy and Gene Callahan.2 They point out that at most, argumentation establishes self-ownership only to one’s mind and mouth, and only during the argument. A slave owner can argue with a slave while the slave is in chains, and then murder the slave. The superiority of the slave owner is not refuted by the owner’s asking the slave whether he prefers to be strangled or shot with a bullet.\nAs pointed out by Murphy and Callahan, a statist may believe that under particular conditions, the initiation of force is justified, even though when this is discussed, the parties are equally in their ability to argue.\nAnother refutation was made by Jason Brennan in “Hoppe’s Argumentation Ethics Argument Refuted in Under 60 Seconds.” Brennan first presents two definitions. “A liberty right is something that grants me permission to do something. A claim right is something that entails others have obligations, responsibilities, or duties toward me.”\nHe then writes: “all I need to avoid a performative contradiction here is for me to have a liberty right to say, ‘I propose such and such.’ I need not presuppose I have a claim right to say ‘I propose such and such.’ Instead, at most, I presuppose that it’s permissible for me to say, ‘I propose such and such’. I also at most presuppose that you have a liberty right to believe what I say. I do not need to presuppose that you have a claim right to believe what I say. However, libertarian self-ownership theory consists of claim rights... Hoppe’s argument illicitly conflates a liberty right with a claim right, and so fails.”\nYet another refutation of argumentation is made in “Justopia” by Justin. “That flaw is revealed by showing that intent matters. This flaw eliminates the performative contradiction aspect because one cannot, without further information, determine whether many of the statements that Hoppe would claim are performative contradictions actually are performative contradictions”.3\nThe universal ethic has three basic rules:\n1. Acts which are welcomed benefits are good.\n2. All acts, and only those acts, which coercively harm others are evil.\n3. All other acts are neutral.\nThe Lockean foundation for natural moral law does not suffer from such flaws. Based on its premises from human nature, the universal ethic has three basic rules:\nActs which are welcomed benefits are good.All acts, and only those acts, which coercively harm others are evil.All other acts are neutral.\nIt is curious why some natural-law libertarians have not accepted Locke’s libertarian ethic and have instead turned to German discourse philosophy. Perhaps the answer involves psychology and sociology rather than pure philosophy. At any rate, argumentation ethics is not the answer.\nThank you! Your submission has been received!\nOops! Something went wrong while submitting the form\nFRED E. FOLDVARY, Ph.D., (May 11, 1946 — June 5, 2021) was an economist who wrote weekly editorials for Progress.org since 1997. Foldvary’s commentaries are well respected for their currency, sound logic, wit, and consistent devotion to human freedom. He received his B.A. in economics from the University of California at Berkeley, and his M.A. and Ph.D. in economics from George Mason University. He taught economics at Virginia Tech, John F. Kennedy University, Santa Clara University, and San Jose State University.\nFoldvary is the author of The Soul of Liberty, Public Goods and Private Communities, and Dictionary of Free Market Economics. He edited and contributed to Beyond Neoclassical Economics and, with Dan Klein, The Half-Life of Policy Rationales. Foldvary’s areas of research included public finance, governance, ethical philosophy, and land economics.\nFoldvary is notably known for going on record in the American Journal of Economics and Sociology in 1997 to predict the exact timing of the 2008 economic depression—eleven years before the event occurred. He was able to do so due to his extensive knowledge of the real-estate cycle.']	['<urn:uuid:72663927-7ccc-44e6-bb75-c09853c47b23>']	open-ended	with-premise	long-search-query	distant-from-document	single-doc	expert	2025-05-13T06:27:57.068978	11	78	1172
76	monopoly poker tournament rules time limits speed modifications how make games faster	Both Monopoly and poker have implemented modifications to control game duration. In Monopoly, a red speed die was introduced to significantly shorten playtime during matches. For poker tournaments, time management is handled through structured formats - Sit & Go tournaments start immediately when the required number of players is reached, while other formats like Freeze-out tournaments naturally progress as players are eliminated. Multi-table tournaments keep things moving by balancing tables and moving players around as others are eliminated. Both games have evolved to include features that help maintain appropriate pacing and prevent games from dragging on too long.	"[""Under the Boardwalk: The Monopoly Story Parent Guide\nParent Movie Review\nSome people like board games and then there are those who take a friendly competition to a whole new level. On the 75th anniversary of the iconic game Monopoly, the documentary Under the Boardwalk: The Monopoly Story introduces viewers to some of the participants from around the world who are wrangling for the title of Monopoly champion.\nAmong those contending to represent the U.S. at the quadrennial international event is the current champion Matt McNally, lawyer Richard Marinaccio and teacher Tim Vandenberg, who incorporates the board game into his sixth grade mathematics curriculum.\nNarrated by Zachary Levi, the film also recounts the history of the game that began with an anti-capitalist agenda and ended up being about crushingyour opponent while amassing the most money, homes and hotels. However during WWII, the board was used to smuggle vital information into POW camps.\nComplete with interviews from board game designer, author and Monopoly tournament judge Phil Orbanes, the film shows just how serious some people are about winning the top prize (which includes a moment in the spotlight with Mr. Monopoly himself). There are even records for the longest continuous game, both above water and below. But for some players, their passion comes at a cost in other areas of their lives.\nEven if you’ve never contended over a game token (the race car is the favorite) or flipped the board in frustration, this documentary will open your eyes to all kinds of new insights on the game. For instance, there really are times when being in jail is a good idea. Playtime can also be significantly shortened with the introduction of a red speed die.\nPlayed around the world and showcased in Hollywood films like Patriot Games, Spanglish and One Flew Over the Cuckoo’s Nest, the game is licensed in 103 countries and 37 languages. But even if your family isn’t ready to ramp up for a serious tournament, this film may encourage audience members to pull out one of the hundreds of available versions and play an in house match.Directed by Kevin Tostado. Starring Zachary Levi, Philip Orbanes, Ken Koury. Running time: 88 minutes. Theatrical release March 3, 2011. Updated July 17, 2017\nUnder the Boardwalk: The Monopoly Story\nRating & Content Info\nWhy is Under the Boardwalk: The Monopoly Story rated G? Under the Boardwalk: The Monopoly Story is rated G by the MPAA\nViolence: A competitor accuses others of cheating.\nSexual Content: Dancing girls are seen in costume along with a large, outdoor poster of the posterior of a dancer wearing a thong.\nLanguage: None noted.\nAlcohol / Drug Use: Old photograph shows men smoking.\nPage last updated July 17, 2017\nMore parents' guide for Under the Boardwalk: The Monopoly Story after the break...\nUnder the Boardwalk: The Monopoly Story Parents' Guide\nElizabeth Magie invented The Landlord’s Game that became the precursor to Monopoly. The game was designed to point out the flaws of land grabbing and instead promote social and economic justice among players. What do you think caused a change in direction in Monopoly?\nWhat is your favorite game piece and why?\nDo you think that the addition of a red speed die improves the game? Why or why not?\nThe most recent home video release of Under the Boardwalk: The Monopoly Story movie is February 13, 2012. Here are some details…\nHome Video Notes: Under the Boardwalk: The Monopoly Story\nRelease Date: 14 February 2012\nUnder the Boardwalk: The Monopoly Story releases to home video on DVD. Bonus extras include:\n- 2009 World Championship Final Game\n- The Methods, Math & Myths of Monopoly\n- Narrator Zachary Levi Outtake Reel\n- Extended Scenes\n- Interactive MONOPOLY quiz"", 'Tournaments Types and Features\nIf more than one table is needed to accommodate the number of registered players in a tournament, it is known as a multi-table tournament. During a Multi-table tournament, as players are eliminated, players will be moved randomly from one table to another in order to keep the number of players at each table as balanced as possible. Although we try to be fair and move players in relation to their position with the dealer button, a player may end up moving from their blinds and move to a blind position again.\nSit & Go\nSit & Go tournaments are events that do not have a scheduled start time. They start when the needed number of registered players is reached. When the prearranged number of competitors is reached each participant is notified that the tournament is about to start. Example: A No Limit Hold’em one table Sit & Go will start as soon as ten players are registered.\nWhen a contest is between 2 players only, it is referred to as Heads-up. Heads-up Shoot-out tournaments are a good way to improve your winning game, as you will end up facing one opponent most of the time to win any tournament. The rules are the same with Heads-up play with the exception that the player with the ""dealer button"" posts the small blind and will act first pre-flop then last for the remainder of the hand. The player who posts the big blind is dealt first.\nRe-buy & Add-on Tournament\nSome tournaments allow for players to conditionally Re-buy & Add-on during a predetermined time period in the tournament. They allow for players to continue in the tournament and still have the opportunity to win the tournament for a Re-buy or with one available Add-on. Re-buy & Add-on tournaments are a great way to increase the prize pool and the number of players who will qualify for prizes. All Re-buys & Add-on monies are included in the prize pool.\nIn a Freeze-out tournament players make a single Buy-in and upon losing all their chips, will be eliminated from the tournament. As players become eliminated the tables are combined with other tables until there is a final table and ultimately there is one player left with all the chips.\nA Shoot-out tournament consists of a limited number of players competing on different tables. In round 1, players compete until there is one player left at each table with all the chips. In round 2 the winners from round 1 are then combined at other tables and they again play until there is one player left with all the chips. A Shoot-out tournament can have between two (Heads-up) to ten players on each table competing over 1 or more rounds. The number of rounds and players per table varies and can be found in the tournament lobby.\nSatellite tournaments are events where prizes are entries into other larger tournaments. A satellite could award the winner(s) entries into other satellites. All satellite tournaments end when all players have won or qualified for their prizes.\nIn Euro Club Poker Bounty events, we\'ve put a price on your head and every player seated in the tournament. Take them out and cash in. But remember, it works both ways. The beauty of the Bounty tournament is that players have the opportunity to cash in along the way - regardless of a final table showing or making it to the money.\nEuro Club Poker regularly offers tournaments that require no Buy-in or registration fees, no risks or conditions. These true freerolls are our way of giving back to our players.']"	['<urn:uuid:47ee9f8b-295f-42f9-ad26-ff78e59a7ea9>', '<urn:uuid:e0770ae4-7c18-4785-ab7b-769c73b037ca>']	open-ended	with-premise	long-search-query	similar-to-document	multi-aspect	novice	2025-05-13T06:27:57.068978	12	98	1227
77	How do attention-building activities help ADHD symptoms, and what comorbidities often accompany it?	Attention-building activities like board games (Parcheesi, chess, Uno) and puzzles help develop crucial attention management skills by teaching children to take turns, follow strategies, and work toward clear goals rather than seeking instant gratification. These activities help strengthen attention, which is a developable skill rather than a fixed characteristic. Regarding comorbidities, ADHD rarely occurs alone - individuals with ADHD are more likely to experience mental health problems like anxiety and depression, behavioral issues such as oppositional defiant disorder (ODD), specific learning difficulties like dyslexia, and autistic spectrum disorder, making treatment and management more complex.	"['The teacher is talking to you about your child‘s attention problem … visions of Ritalin dance in your head … but wait. Before jumping to conclusions, take a look at what you can do to help your child naturally.\nOnly a few years ago, you could pick up any newspaper or magazine and find an article about children with attention problems (“Little Johnny is always daydreaming!”) All the buzz was attention deficit disorder (ADD), or, add another letter and the plot thickened – attention deficit hyperactivity disorder (ADHD) and “Little Johnny cannot sit still!” It seemed everyone was talking about it – and how to nip it in the bud with stimulant medications like Ritalin or Adderall. And while attention problems have not gone away, it’s safe to say that the over-zealousness for medicating inattentive children is out. But perhaps your own child’s teacher or coach has hinted that your child needs improvement in the attention category. Perhaps you’ve been told to “watch it closely” or even had someone suggest that you have your child evaluated by a professional. You are concerned and rightly so. In the classroom, once your child has been “tagged” as an attention problem, his behavior will be scrutinized to find significance in every squirmy morning, misunderstood direction or incomplete assignment. So now it’s your turn to pay attention.\nThe American Academy of Pediatrics says that an estimated 4 to 12 percent of school-age children are affected by ADHD, a condition of the brain that makes it difficult for children to control their behavior. It is one of the most chronic conditions of childhood. So while parents may worry that too many children are labeled and medicated for attention problems, teachers, on the other hand, encounter many children who lack basic attention skills expected in a typical classroom such as taking turns, listening when others speak, concentrating on the task at hand or completing assigned work. Before jumping immediately to ADHD, first make every effort to help your child learn to manage his attention.\nFirst Things First\nLet’s look at what attention is, first. It is NOT a fixed, unchangeable characteristic. It is a skill that develops and is influenced by a variety of things, including the child’s age, what he is asked to do, where he is asked to do it and what interesting things are around him. Attention can also be strengthened or weakened by factors in the child’s environment and experiences that the family provides. With children growing up surrounded by fast-paced mass media, a culture of quick fixes and instant gratification, it is the rare child who is content to be alone with his thoughts with no external stimulation for any length of time. Rarer still is the child who is able to persevere and sustain concentration on a difficult or uninteresting task. Yet, to succeed in school, and in life, the ability to focus attention and thought is crucial. Children of all ages can benefit from this help. It is never too early – or too late – to start.\nHelp children develop attention management skills in three concrete ways:\n- Establish routines\n- Provide attention-building activities\n- Model attention skills\nWhen it appears a child is not paying attention, he is often confused about exactly what he is supposed to do. Sometimes expectations change in unpredictable ways. Routines help remove uncertainty for the child. As adults, we get dressed and undressed in much the same way every day, go to work on a regular basis and typically follow daily routines to accomplish these goals. We don’t have to pay much attention to “getting it right.” When we teach children routines to deal with repetitive parts of their day, we help them free their attention for more interesting and challenging parts of the day.\nFor parents of school-aged children, a regular morning routine is a good place to begin. Establish a specific time for your children to wake up. Schedule getting dressed, eating breakfast, brushing teeth, packing the backpack, leaving for the bus and any other tasks to be done at the same time and in the same order each day. Younger children may need reminders and prompts to keep things moving. A checklist on an erasable board accomplishes the same thing for older children while instilling a sense of responsibility and independence. Keep the same routine on weekends so children know what they’re expected to do each morning.\nAn after-school routine works well, too. It is important to have a place for children to deposit their school-related paraphernalia when they come home. Then, when they need to do homework or pack up in the morning, everything is available. Schedule your child’s snack, playtime, after-school activities, dinner, homework and bedtime to suit your family’s schedule. The more predictable and consistent the routine is day-to-day, the easier it will be for children to understand what’s expected of them.\nOften, in school, children with diagnosed attention problems, including ADHD, receive classroom accommodations as a part of their treatment or behavioral management program. These accommodations typically include sitting near the teacher, sitting in a quiet place away from distractions, having frequent breaks with an opportunity to stretch or move around, breaking long assignments into smaller pieces, and mixing easier or more interesting assignments with the harder or more tedious ones to break up things and hold the child’s interest. For your attention-challenged child, put home accommodations in place, too. Homework should be done in a quiet place away from distractions, preferably in the same place very night. Help your child organize his work into time and subject segments. If he’s a whiz at spelling but hates math, let him do half his math, then spelling, to build confidence and break the tedium, then have a snack and finish the math. A homework routine goes a long way to keep peace and help your child develop lifelong attention and concentration skills.\nProvide Attention-Building Activities\nAnother way to develop attention skills is to encourage attention-building activities such as board and car games. In these activities, children have to take turns, attempt to reach a goal and develop a strategy. They learn to pay attention in order to follow what is happening and to become more proficient. Parcheesi, Crazy Eights or Uno are examples. More complex board games – such as checkers, chess and Scrabble – become appropriate as attention spans increase. Additionally, activities that direct a child’s involvement toward a clear goal help build attention-management skills. For example, a jigsaw puzzle does more to develop attention skills than playing with action figures or dolls, which require involvement but not always a clear goal. Exposure to these types of activities from an early age will help children build attention skills and teach the importance of seeing a task through to the finish rather than settling for instant gratification.\nModel Attention Skills\nA third way to develop attention skills is to model them yourself. Parents are their children’s first teachers and role models. If parents do not manage their own attention well, children won’t either. The hurried lifestyle families live today is not conducive to giving children undivided attention, but unless they receive it, they are unlikely to learn this important skill. A relaxed, conversation-rich family dinner is a good place to start. When family members tell each other about their day and listen to what others have to say in an unhurried way, taking turns is modeled. A benefit is, that when your turn comes, everyone will listen to you. Likewise, when you give your child undivided attention, he learns the importance of doing one thing at a time. Similarly, finishing what you start teaches the child the importance of following through on tasks. You model divided attention when you listen to your child while doing something else.\nChildren’s skills in attention management are developed over time. Parents who provide a predictably structured environment, choose appropriate activities and model attentive behavior in their own lives can do a great deal to help their children develop these skills. All children need this sort of help, and parents who provide it are less likely to see their children labeled ADHD or referred to specialists for attention difficulties.\nPatricia Schwert and Lucia French, both mothers, are professors of early childhood education. French collaborated on developing an early childhood curriculum that fosters the development of attention skills.', ""The following is a brief introduction to ADHD. You can find out more via our useful links page.\nWhat is ADHD?\nAttention Deficit Hyperactivity Disorder is a neuro-developmental disorder which affects the executive functioning of the brain. Executive functioning is like the management system of the brain – it helps us to plan, juggle or organise different tasks, remember things, prioritise what to think about or what to do, pay attention, manage frustration and regulate our emotions. Executive functioning also helps us to use information and experiences from the past to solve current problems. All of these things can be affected in ADHD.\nIf you are new to ADHD, we recommend watching the 28 minute primer video to the right by Dr Thomas Brown.\nMost estimates around the world suggest that around 1 to 2 in every 100 children have significant levels of ADHD, but many more than this have milder problems. In 2012, the Services Over Scotland report on ADHD showed that around 0.6% of the under 18 population (1 in every 167 children) in Scotland is being treated for ADHD. The latest data for 2016/17 shows that this is now closer to 1%.\nADHD rarely comes on its own, and people with ADHD are more likely than others to have other difficulties including mental health problems like anxiety and depression, behavioural problems like oppositional defiant disorder (ODD) , specific learning difficulties like dyslexia, and autistic spectrum disorder. These additional problems can make being a parent to a young person with ADHD complex and challenging.\nHow is ADHD diagnosed?\nIn the UK, ADHD can only be diagnosed by a specialist doctor - a consultant psychiatrist or paediatrician. If you think your child may have ADHD, your first port of call should be your GP. They should rule out other things which can lead to similar problems such as difficulties with sleep, hearing and vision. They may then refer your child to one of the psychiatrists within the Children and Adolescent Mental Health Service (CAMHS) teams based around the city.\nUnfortunately, there’s no simple test for ADHD like a blood test or a brain scan. To make a diagnosis, the specialist will ask lots of questions and take a thorough history. They may use standardised questionnaires for both parents and teachers to fill in independently, and they may visit your child's school to observe them in the classroom. The diagnosis process can take some weeks or months, as it’s really important to get it right.\nThe official list of symptoms which doctors use to diagnose ADHD are based on two internationally recognised classifications of diseases - the American Diagnostic and Statistical Manual of Mental Disorders (DSM) and the International Classification of Diseases (ICD10), produced by the World Health Organisation (W.H.O.). Although there are some slight differences in the definitions, the two guidelines agree on a number of things:\nThe core symptoms of ADHD are:\ninattention (difficulty in concentrating, short term memory difficulties)\nhyperactivity (disorganised, excessive levels of activity)\nimpulsive behaviour (acting without thinking)\nOf course all children display these characteristics to some extent, but in ADHD the levels are above and beyond what you would expect given the age of the child.\nIn order to meet diagnostic criteria it is essential that symptoms:\nhave started before the age of 12 years (many children and adults are diagnosed older than this, but the signs will have been there since early childhood.)\nhave lasted for at least six months\nare present in more than one setting, e.g. home, school and social situations\nhave caused significant ‘functional impairment’ (i.e. problems)\ncan’t be better explained by other conditions (e.g. pervasive developmental disorder, schizophrenia, severe sleep problems, depression or anxiety) - the assessing doctor will want to rule out these other problems first.\nMore details of the diagnostic criteria for ADHD are given on the ADDISS website.\nYou can also read a discussion of the difference between the old diagnostic criteria in the DSM IVth edition and the new criteria in the DSM Vth edition, which was published in 2013, here.\nNext - What helps with ADHD.... Click to continue""]"	['<urn:uuid:683b2e06-1174-464d-8d1a-d7026beae8fa>', '<urn:uuid:7965cf49-ec56-4f2d-a363-0c696568bfcf>']	open-ended	with-premise	concise-and-natural	similar-to-document	multi-aspect	expert	2025-05-13T06:27:57.068978	13	94	2081
78	what reference measurements calculations determine adequate face up size round diamonds	For Round diamonds, adequate face-up size is determined by comparing the diamond's face-up area to a reference diamond of the same carat weight. A diamond is considered adequate if its face-up area is within 5% lower to 3% higher than the reference diamond area. For example, a 1-carat Round reference diamond measures 6.5 mm in diameter with a face-up area of 33.18 mm². Any 1-carat Round diamond with an average diameter between 6.34 mm and 6.6 mm (or face-up area between 31.52 and 34.18 mm²) would be considered adequate.	"[""Evaluating Diamond Size\nThe Accuracy Of Face-up Size Evaluation\nThis page will try to explain how diamond size evaluation works on this site. In short: a diamond face-up area is compared to a face-up area of a reference diamond, which is calculated differently for each diamond shape. Based on a deviation from reference diamond area, an evaluation of whether or not a diamond is of adequate face-up size is made.\nHow accurate is this evaluation? It depends on a diamond shape. It's accurate for Round cuts and approximately accurate for fancy shapes. The system was calibrated and tested against a database of 700,000 real world diamonds. Details are explained below.\nWhy Is Face-up Size Important?\nDiamonds are sold by weight, which means diamond cutters, in order to maximize their profits, try to retain as much weight from the rough as possible. If a diamond is cut to ideal proportions, it will exhibit the most brilliance and sparkle, however, this means that the yield from the rough will be lower (translation: lower carat weight, less profit for the cutter). Therefore, diamonds tend to be cut in a way to retain as much weight from the rough, sacrificing beauty for weight.\nOne way to determine if a diamond is cut properly is to check its face-up size. Two diamonds of the same shape can be exactly the same weight, but one can look bigger than the other.\nFor example, 1 carat Round should have a diameter of about 6.5 mm. If a diamond is cut too deep, its diameter might be 6.1 mm or even lower. But it's not only smaller size that is the problem, the diamond will also have non-optimal light performance, i.e. – it will be less brilliant and sparkly, less beautiful that an ideal cut stone. The same thing happens, if a diamond is cut too shallow (e.g. 1ct Round with 6.7 mm diameter).\nFace-up size is a crucial diamond characteristic and one should always make sure that a stone looks its weight. Here is how this site evaluates face-up size:\nEvaluating Round Cuts\nWhen you enter a diamond of arbitrary weight and size, the application calculates the face-up area of the entered diamond and compares it to the area of the reference diamond of the same carat weight. Diamonds can be evaluated as Adequate, Borderline, or Inadequate:\n|Diamonds with face-up area of within 5% lower and 3% higher than reference diamond area are considered to be of adequate face-up size.|\n|Diamonds with face-up area of 5-7% lower or 3-5% higher than reference diamond area are considered to be borderline.|\n|Diamonds with face-up area lower than 7% or higher than 5% than reference diamond area are considered to be of inadequate face-up size.|\nExample: 1 carat Round reference diamond measures 6.5 mm in diameter and has a face-up area of 33.18 mm². Any 1ct Round with an average diameter between 6.34 mm and 6.6 mm (or a face-up area between 31.52 and 34.18 mm²) would be considered adequate.\nEvaluating Non-Round Diamonds - Fancy shapes\nFor fancy shapes, approximation formulas are used to calculate the size of the reference diamond and then estimate the face-up area. Area estimation is based on empirical analysis. I've tried to come up with geometrical formulas but they were more inconsistent then the empirical approach.\nHere's what I did: I looked for photos of diamonds and then calculated the percentage difference between the area of a rectangle obtained by multiplying the length and the width of a diamond and the actual surface area of the diamond's outline. This was done with Photoshop by counting pixels in the photos. This method is actually very accurate.\nFor each diamond shape, I analyzed around 30-50 photos. I looked for normally shaped diamonds in terms of outline as well as the extremes. This gave me a range of area differences and based on this analysis I was able to make an informed decision about the area adjustment factor that I will use for a particular shape.\nTo indicate the precision of these approximations, a plus or minus (±) sign is stated next to the face-up area of fancy shapes (e.g. ±5%). I would say that the vast majority of real world diamonds would fall into these ranges.\nBecause of all this, the evaluation of fancy shapes is not as strict as with rounds. It depends on a shape, but for a diamond to be considered adequate its estimated area would usually need to be within 9% compared to reference diamond area (9-12% is borderline, greater than 12% is inadequate).\nFor Round cuts, you can pretty much rely on it. For fancy shapes, it's not as accurate, but if nothing else it can help you sift out the really poor cuts, keeping you from making bad purchasing decisions.\nI would generally advise against buying diamonds evaluated as inadequate. Borderline stones can sometimes still be a good choice, but that's your call.""]"	['<urn:uuid:2d391a78-7966-4174-b83c-227c4d82b8ec>']	open-ended	direct	long-search-query	similar-to-document	single-doc	expert	2025-05-13T06:27:57.068978	11	89	822
79	Which uses more technology: soundwalks or fuzz effects?	Fuzz effects use more complex technology. While soundwalks like the 2013 Campus Soundwalk at University of Texas simply require notebooks to record observations of environmental sounds, fuzz effects involve sophisticated electronic components - specific transistors (made of either silicon or germanium), capacitors, resistors, and specialized circuits. The Maestro FZ-1 Fuzz-Tone alone required three transistors and multiple other electronic components to function.	"['Five Liminal Soundscapes — Sound Installation (2018)\nConception and sound editing\n5-channel installation on acoustic liminality, part of the “Liminality” art exhibit — November 12-15, LAAH 110 (College Station, TX).\nTexas Sonar — Radio Show (2017- )\nConception, content, and curating\nCollaborators: KEOS 89.1 FM Brazos Valley community radio (broadcasting) and Texas A&M undergraduate students (content)\nTexas A&M University Soundmap Project (2016- )\nConception and curating\nCollaborators: Texas A&M University undergraduate students (content) and the Cushing Library and Archives (content)\nThe central idea of this project is to map out and study Texas’ acoustic history and diversity. Click here to visit the TAMUSP.\nSEM Sounding Board — Sound Art Exhibit (2015)\nConception and curating\nThe SEM Sounding Board sound exhibit showcased the creative work of scholars attentive to the spatial and ethnographic potential of sound. It ran in parallel with the Society for Ethnomusicology Annual Meeting in Austin, TX. The Sounding Board included nine works that explored sonic in-placements (water and wind), sonic displacements (the telephone, the radio, and the microphone), sonic emplacements (the acoustic territories of urban Taiwan, the Brazilian hinterlands, and West Texas), and sonic mix-placements (in Mexico City and Havana).\nSalsa Casino — Interactive Audiovisual Installation (2015)\nConception, audio curating, and video direction\nCollaborators: Dr. Jeff Morris (conception and programming) and graduate student Mayra Valle (conception, dance direction, and content)\nI designed this interactive installation in collaboration with my colleague Jeff Morris and graduate student Mayra Valle, who created the choreographies based on her research on the Salsa Casino in Cuba. Valle’s choreography highlights the dance’s fluid relationship with the Cuban socialist government, Afro-Cuban religion, and African-American pop culture.\nThe installation includes one opening dance and three dances showing varying degrees of influence from Santeria rituals. The kiosk has a 5.1 surround system, a footboard that vibrates with low frequencies, and a camera that interacts with the user’s movements. The installation starts the opening dance whenever someone approaches the kiosk and then moves randomly to the other dances. During the audiovisual performance, the users are immersed in music (we recorded different instruments across the 5.1 surround spectrum). They are encouraged to explore their own body by following the rhythms and gestures of the performance. The amount of movement captured by the camera determines the texture (more or fewer instruments) of the music being played.\nAffective Oscillations — Sound Installation (2015)\nConception and content\nCollaborator: Dr. Jeff Morris (conception and programming)\nI designed this audiovisual installation to encourage my Performing the City students to approach urban space and history from an experiential perspective. The installation uses sound recordings (a collage from archives, my personal field recordings, YouTube, and SoundCloud) made in five American cities in moments of collective celebration and drama. By exploring city sounds in moments of mourning and commemoration and the affective infrastructures they set in motion, the installation brings together sound studies, architecture, urban/sensory sociology, and ambient music.Talk-presentation of the installation at the Center of Digital Humanities Research at Texas A&M University.\nCampus Soundwalk (2013)\nOn March 27, 2013, I took my Intro to Sound Studies students for a soundwalk across the University of Texas campus. We started in the classroom in the School of Music Building (east side of campus) and ended at the entrance of the Radio-Television-Film Building (west side of campus). I was interested in how people in the same acoustic environment share patterns of filtering certain sounds and paying closer attention to others. The purpose of the soundwalk was to consider this filtering activity not only considering loudness, but also with “moods,” mindsets, tastes, and expectations. To compare filtering processes, I gave each student a small notebook and asked them to write down whatever they “heard” as we walked. The results of the most mentioned sounds are available here (indoors) and here (outdoors).\nSão Paulo Soundscapes — Workshop (2012)\nWhile doing fieldwork in São Paulo for my doctoral dissertation, I approached the SESC (Social Service of Commerce) to propose a workshop on the sociality of everyday sounds. The SESC is a popular public-private enterprise present in several districts across São Paulo. It has been an important cultural, educational, and recreative institution in the city, offering to the local community a range of activities at an affordable cost.\nI conducted the workshop at SESC Vila Mariana between July and August. I provided sound recorders and asked the participants to record sounds that were present in their day-to-day activities. Each participant (myself included) used the recordings to create a sonic collage-narrative, which was presented and discussed during the workshop. By discussing the collages we uncover disagreements about city life. We reflected on the blurry line separating sound as an event that informs how the listener navigates the environment and sound as a point of attraction — an action that pushes the person to frame his or her experience as a listener.\nDavid Hendy used one of my recordings in his series Noise: a Human History aired on BBC Radio 4.\nBelow, some of the collages created during the workshop.', 'A look at the evolution of the technologies that give rock its signature sound\nFifty years ago, a faulty connection in a mixing board gave birth to fuzz, which is a term of art. Although it came to define the sound of rock guitar, fuzz appeared first in neither guitar nor rock, but in the bass solo of country singer Marty Robbins on ""Don\'t Worry."" The band and producers debated whether to keep the weird sound or record another take. It stayed, and the song entered the Top 40 in February of 1961 and remained for 12 weeks. In an otherwise sweet and mostly acoustic tune, those incongruous 19 seconds of buzzing presaged decades of distorted guitar to come. The fuzz kicks in at the 1:39 mark:\nPart of the fun of discussing early distortion is finding ever earlier examples of it. ""Rocket 88"" by Jackie Brenston & his Delta Cats (it was actually Ike Turner and the Kings of Rhythm backing Brenston) from 1951, the Memphis recordings of Howlin\' Wolf (1951-52), Johnny Burnette\'s ""Train Kept A-Rollin"" (1956) and Link Wray\'s ""Rumble"" (1958) all hold a special place in the distortion lover\'s heart. In the taxonomy of distortion, most early guitar grit is considered classic overdrive -- that\'s when the input from the guitar exceeds the capacity of the amplifier\'s vacuum tubes. Depending on where the volume dials rest, sounds range from a gentle rasp to a serious bite. It\'s a warm, earthy species of distortion.\nBut fuzz was different from those tube-driven sounds. Transistors boosted and then severely clipped the guitar\'s signal, creating a buzzy, not-quite-of-this-world timbre. It sounded kind of synthetic, and far from warm or earthy. It was perfect, though, for a world still dreaming of the cosmos -- the first manned space flight would occur a few months after the release of Robbins\' song -- but not quite ready for the purely electronic tones to come.\nAccidents account for many of the great sounds on early rock records. The grunge of Willie Kizart\'s guitar on ""Rocket 88"" came from the damage of a speaker that either fell off a car\'s roof or got left out in the rain, depending on who\'s telling the story. There was purposeful damage, too, like the holes Link Wray pierced in his speakers to get the crunch of ""Rumble,"" causing a sound so bad-ass that it\'s probably the only instrumental banned by U.S. radio stations. Years later, Dave Davies of the Kinks would visit similar violence upon his guitar speakers for ""You Really Got Me.""\nThe fuzz produced by Grady Martin\'s bass on ""Don\'t Worry"" was also happenstance, but it earns a place in the annals of distortion because its makers captured what would otherwise have been a fluke. Recording engineer Glenn T. Snoddy tells Gary Gottlieb in his book ""How Does It Sound Now?"" that he figured out the faulty circuit so he could recreate ""this awful sound"" for other musicians. His master stroke, though, was replicating the sound with what would be the first commercially available fuzzbox. The Maestro FZ-1 Fuzz-Tone allowed guitarists to change their tone from clean to dirty with a tap of the foot, thanks to a rather simple circuit of three transistors and some capacitors and resistors. Initial sales lagged (due, perhaps, to marketing; ads promised that it would make guitars sound like saxophones and orchestra strings). But when the Rolling Stones used it on ""(I Can\'t Get No) Satisfaction,"" everyone wanted fuzz. (Other early, though less influential, adopters were the writers of the ""Green Acres"" theme song.)\nThe Fuzz-Tone stompbox also spawned the avid community of guitar effects aficionados. Their reverence for the Tone Bender, the Big Muff and the TS-808 Tube Screamer have driven vintage pedals values skyward. The Honus Wagner of effects, the rarely sighted EMS Synthi-Hi Fli, can fetch thousands of dollars on e-Bay. Like the shop talk of wine enthusiasts, discussions among distortion cognoscenti on nuances of tone can baffle outsiders. Some differences are obvious, but many aren\'t. Debate rages over whether the JRC4558 op amp chip in overdrive pedals is truly superior. Similar arguments erupt over whether fuzz sounds better with transistors made of silicon or the much rarer germanium. Tom Hughes, author of ""Analog Man\'s Guide to Vintage Effects"" uses those two elements (14th and 32nd on the periodic table, respectively) as the dividing line of Jimi Hendrix\'s career.\n""Early Hendrix, that was a germanium Fuzz Face, right up to ""Are You Experienced?,\'"" he says. ""When he got to the Band of Gypsies, that was silicon.""\nGuitar distortion is a triumph of the counterintuitive. Earlier in the 20th cenury, sonically adventurous folks like Luigi Russolo and John Cage spent years promoting the idea that noise in music was good, but it took Keef and a sharp-eared recording engineer to prove it.\nTo make a rather sweeping statement, the existence of rock \'n\' roll rests pretty heavily on distortion. Music historians talk up the genre\'s origins as a blend of musical traditions, its challenge to cultural mores, etc. But, really, without at least a bit of crunch, rock wouldn\'t have a lot going for it. There\'s some satisfaction in this; rarely is the crux of an art form so precisely identified.\nWhat was once revolutionary is now taken for granted. Great as Hendrix was, we rarely hear of Roger Mayer, a techie who honed his engineering chops in the British military. He served as Hendrix\'s personal guitar effects tinkerer. Mayer\'s most famous creation, the Octavia, created and threw an additional octave into the mix of thick fuzz.\nDistortion\'s not always a rabble-rouser. Fuzz brings a certain sweetness, for instance, to the Jesus and Mary Chain\'s ""Just Like Honey."" Indeed, without the Shin-ei fuzz pedal that drenches their 1985 debut Psychocandy, the Jesus and Mary Chain might have been just another British pop band.\nAnd it needn\'t be confined to the guitar. Distortion has made the term ""cello metal"" possible. Applied to the humble thumb piano, it made unlikely stars of the fantastic Konono No. 1 from the Democratic Republic of Congo:\nSo what is it about distortion that so draws us in? Zachary Vex, owner of Z. Vex Guitar Effects in Minnesota, has a theory.\n""Our own voices distort when we yell or sing intensely, so a distorted guitar also reminds us of the human voice at it\'s most exciting point,"" he says in an email. ""Most audio stuff that affects us emotionally is a result of pretty primal factors.""']"	['<urn:uuid:3babd970-6c42-4b8a-a67d-73d292cdd78b>', '<urn:uuid:112dc058-34f9-4dde-813d-e71446f7302c>']	open-ended	direct	concise-and-natural	distant-from-document	comparison	novice	2025-05-13T06:27:57.068978	8	61	1917
80	ways catnip use home	Catnip can be used in several ways: as a treat for cats, to make or refresh cat toys, rubbed on scratching posts to encourage cats to use them instead of furniture, as ground cover in gardens (though it needs to be contained as it spreads easily), and it can attract birds, butterflies, and bees to your garden. It can also be consumed as tea, which is said to have a calming effect and may help with intestinal discomfort, colds, and flu.	"['For Fun Or Profit\nGrowing catnip for fun, profit, or your cat\'s enjoyment is pretty easy. It\'s a fairly hardy plant, so, with a little pruning work and some watering, you should be blooming in no time.\nCatnip (Nepeta cataria), whether dried, fresh cuttings, or the full plant, can provide hours of entertainment for you and your cat.\nI\'ve always found it very gratifying to give catnip as a treat, or refresh the sisal rope or cat toys and watch the kitties gather together and go crazy over the \'nip.\nCultivation And Growing Conditions\nCatnip plants grow under various conditions, including indoors (with sun) and hydroponics. They prefer sun, but will grow in partial sun or even shade.\nPlants will propagate from seeds, root cuttings, or stem cuttings.\nHere\'s some good, practical information (with photos) on ""how to grow killer catnip bud"" by a true cat lover.\nAccording to this experienced catnip grower, the key is in giving the plant lots of water, as well as proper pruning.\nIn addition, be sure to view the photos of the Himalayan kitty cat Stella Blue as well, and read Wally\'s account of her story. His writing says a lot about his relationship with her.\nHere are some simple tips and advice from the Gardener\'s Network on growing catnip, including soil choice, harvesting, and drying.\nHerbgardening.com has information on how to grow catnip as well.\nCatnip is a perennial plant, and a member of the mint family. It also is referred to as cat mint (or catmint, or cat-mint).\nAs a crop it is considered to be fairly short-lived though, and most commercial growers will treat catnip as a 2 to 3 year crop.\nThe plant is not only sold for the benefit of cats and their owners, however, as it has been used for many years for medicinal purposes.\nCatnip tea is available at health food stores and is said to have a calming effect and may soothe intestinal discomfort. It\'s also known as a remedy for colds and flu.\nTo get started growing catnip (either commercially or for ""purrsonal"" use), and for more information as well as purchasing seeds, try Richters.\nIf you\'re thinking about becoming a commercial grower, do your homework first. Being a crop growing farmer is not a task to be taken on lightly. You could grow indoors, in a greenhouse, or outdoors in certain areas with the right climate.\nYou could start your commercial growing enterprise small, and supply area stores and companies with your crop. Get high quality plants and seeds in order to distinguish your product line.\nIn any case, growing catnip commercially (or any crop) can be a difficult business. Expect and plan for setbacks, loss of crops, and lots of hard work!\nThings To Do With Catnip\nWhat to do with your catnip?\nAs a treat: Give it to your cat of course!\nCat toys: Dry it and make catnip toys or freshen up the toys you have.\nScratching post: Is your cat scratching or climbing the furniture? Rub it on a sisal scratching post or board to encourage your cats to use that instead of your nice leather furniture.\nAs ground cover: Catnip grows to about 3 to 4 feet or so. Catnip may take over an area as it spreads quite easily if left to its own devices. If you grow it outdoors, it\'s best to create a defined bed to contain it, or grow it in containers.\nBird attractor: Catnip may attract birds, butterflies, and bees. I\'m sure your cat will appreciate the birds and the butterflies, but I\'m not so sure about the bees!\nThe Catnip Response\nIf genetically predisposed, a cat will find catnip hard to resist.\nIf you\'re growing catnip outdoors, cats may dig it up, eat it, and roll in it, destroying the plants.\nSome cats may ignore it, however, until the skin of the plant is broken or bruised, releasing the oil.\nOthers will begin to nibble on the plant anyway, and then go from there.\nNepetalactone is the chemical in catnip oil that makes cats respond the way they do. Nepetalactone is a cat attractant, so don\'t grow it unfettered outdoors and expect a feline-free yard.\nNot all cats have the gene that makes them respond to the nepetalactone in catnip, but most do (about 75 to 80 percent or so, down to 50% depending upon which source you trust). Although the gene is not sex-dependent, males are said to respond more strongly to it.\nKittens under three months will not respond at all, so you can\'t tell if a kitten will do the dance as an adult.\nI have read that feline bloodlines in Australia are less likely to have the ""catnip gene,"" so a lower percentage of cats ""down under"" will respond to it.\nI haven\'t confirmed this, and I know that breeders often import cats from other countries to mix up the bloodlines (although the quarantine makes this difficult). Also, purebred and feral or non-purebred domestic cat bloodlines are obviously very different.\nI don\'t have any data on the prevalence of the gene or the effects of catnip across different cat breeds, but that might be an interesting research project.\nThe nepetalactone in catnip oil also affects insects, and repels mosquitoes, termites, and cockroaches. This opens up an opportunity for commercial catnip growers to create, among other things, catnip-based mosquito repellent.\nGrowing catnip for use as a non-toxic pest control sounds like a good idea for a green business. Organically grown \'nip is supposed to be high quality as well, so that would tie in with the green idea.\nThe Bird Cage Hypothesis\nIf you\'re concerned about your plants being destroyed, this is where a bird cage can come into play (ironic that a bird cage would be the solution to a problem with dealing with cats and plants\nOne of our readers was having a problem with her cat using the neighbor\'s yard as a toilet.\nI suggested that she place a catnip plant inside a bird cage in the yard to encourage her outdoor cat to stay close by more often.\nThis is a trick I\'ve seen written up in a few different places in order to protect the plant, but give your cat access to the leaves.\nYou could also grow it indoors inside the bird cage as well. Just make sure you secure the cage so that your cat doesn\'t push it around the house.\nIf you have a plant eater around the house (you know who you are), it can be difficult to keep flowers or plants indoors without having them all chewed up.\nWith the \'nip around, your other plants may get less attention. Growing catnip in a bird cage indoors may give your cat both a plant eating fix and a catnip high.\nSee Fern\'s blog for more advice on how to keep your cats from eating your plants and lots of other container gardening tips as well.\nJump from Growing Catnip back to Cat FactsJump from Growing Catnip back to the home page of Cat Lovers Only']"	['<urn:uuid:99c28b61-dbe9-4d88-a239-40e59e263373>']	open-ended	with-premise	short-search-query	distant-from-document	single-doc	novice	2025-05-13T06:27:57.068978	4	81	1184
81	In my research on climate dating methods, I've noticed some interesting patterns about carbon isotopes and ocean currents. How do variations in carbon-14 to carbon-12 ratios affect marine dating accuracy, and what role do these variations play in monitoring changes in the thermohaline circulation?	The ratio of carbon-14 to carbon-12 atoms affects marine dating accuracy because human activities have altered these ratios - industrial CO2 emissions have increased C-12 levels while nuclear testing has increased C-14 levels, requiring corrections to obtain accurate dates. For monitoring thermohaline circulation, scientists must account for these carbon ratio variations while gathering data through a global network of instruments that measure currents, temperature, and salinity. This data collection is essential because the thermohaline circulation is sensitive to changes in water density and could be disrupted by factors like freshwater influx from melting ice sheets.	['Carbon is indispensable to biological life. All life on Earth is based on it. If it weren’t for the amiability of carbon, simple organic matter couldn’t have evolved to achieve the extraordinary, inscrutable complexity it now boasts: the complexity to develop a system to sense, to breathe, to digest, to excrete and in a lean, hairless primate, even a system to think.\nHowever, a tiny percentage of this carbon is radioactive! Measuring the quantity of this radioactive carbon in organic matter allows us to determine its age; the method of doing so is called radioactive carbon dating or, simply, carbon dating. Here’s how it works.\nCarbon has a twin brother that only a few know about. Our planet is constantly pelted with high-energy cosmic rays hurled by the sun. These rays, which teem with neutrons, react with the nitrogen in our atmosphere to produce carbon-14 or C-14 atoms, an isotope of the carbon-12 or C-12 atom.\nAn element and its isotope exhibit the same electric properties, but different physical properties. This is because both elements comprise the same number of protons and electrons, but a different number of neutrons. The twins are then identified by different denotations, highlighting the number of neutrons, which is appended to the element’s symbol. C-12 has 12 neutrons, while C-14 has 14 neutrons; both, however, have 6 protons and electrons.\nThe key things about C-14 are that it is radioactive, that it is unstable, which forces it to emit particles and therefore decay over time.\nThe Principle of Carbon-Dating\nThe radioactive carbon will react with oxygen in the atmosphere to produce radioactive carbon dioxide. This radioactive carbon dioxide is breathed in and stored by plants, which are consumed by herbivores, who are preyed on by carnivores or omnivores, such as humans. The carbon content of every organism under the atmosphere therefore is composed of mostly C-12 atoms and a minuscule number of C-14 atoms.\nThe organisms, while they do consume carbon, also expel it when they exhale. The transaction or the cycle of producing, consuming and expelling C-14 atoms occurs in a way that, even though the amounts of C-12 and C-14 atoms in the environment and in an organism may vary, their ratio will remain the same. This is the working principle of carbon dating: despite the transactions, a living organism maintains the same ratio of C-14 to C-12 atoms as found in the environment.\nHowever, when an organism dies, it ceases to consume carbon. Now, because C-14 is radioactive, it begins to decay. The ratio of C-14 to C-12 atoms in the organism now decreases. The older the organism, the more C-14 is decayed, so the smaller the ratio. This ratio is used by archaeologists to date, say, a tree or a fossil.\nThey refer to the following equation to measure a sample’s age:\nThe equation dictates the decay of a radioactive isotope. Here, Nᵒ represents the number of atoms of the isotope in the sample at t=0 or when the organism, a part of whom now forms the sample, died, while N represents the number of atoms left after time t has passed.\nRemember that the ratio of C-14 to C-12 atoms in the organism and the environment is the same when it is alive. The knowledge of this ratio, which we already possess, allows us to obtain the value of Nᵒ, the original number of C-14 atoms. The current value N, however, must be measured. The C-14 atoms in the sample are counted by delicate instruments, such as beta-counters and mass accelerator spectrometers.\nλ is an element constant whose value for C-14 is 8,267. The time t that has since passed or the age of the sample can be obtained by rearranging the equation:\nIs Carbon Dating Reliable?\nThe radioactivity of an element is measured in terms of its half-life: the time it takes to decay half of its constituents. The half-life of C-14 is 5,370 years, which means that it becomes half of what it originally was in 5,370 years, one-fourth in 10,740 years, one-eighth in 16,110 years and so on.\nExtend the trend and one discerns that accurately measuring that the entirety of the atoms decays or, at least the percentage below which they become undetectable, after around 50,000 years. Consequently, dating a sample older than 50,000 years may produce erroneous results.\nComposite techniques have been devised that combine carbon dating with techniques to calibrate and extend its scope, but even those techniques are inherently fallible. Carbon dating is therefore only unquestionably accurate for a few thousand years; any results beyond that frame is questionable. This is the major limitation of carbon dating.\nWhat’s more, carbon dating seems to be based on a fallacy. It is fundamentally based on the assumption that the ratio of C-14 to C-12 atoms in the environment has always been the same throughout each and every Age.\nThis is certainly not true. Since the Industrial Revolution, in particular, we have diluted the amount of C-12 atoms in the environment by shamelessly dumping into it an alarming quantity of carbon dioxide, produced by the burning of fossil fuels. An increase in C-12 means that the ratio is now reduced, which means that the age of a sample will measure to be older than it really is!\nConversely, nuclear explosions produce tremendous amounts of C-14, so the plethora of nuclear tests we have conducted has increased its amount in the atmosphere. This increases the ratio, causing the age of a sample to measure younger than it really is.\nStill, with the knowledge of the amount of deviation that an increase or decrease in C-14 atoms will cause, we can account for these discrepancies by simply subtracting or adding the error from or to the apparent age to obtain the real age. Again, carbon dating might not be unquestionably accurate, but it’s good enough.', 'By Edwin Schiele\nOcean surface currents redistribute heat around the world and have a profound effect on the world’s climate. Nowhere is this clearer than in the North Atlantic Ocean. The Gulf Stream and the North Atlantic Current ferry huge volumes of warm salty tropical water north to the Greenland coast and to the Nordic Seas. Heat radiating off of this water helps keep the countries of northwest Europe, which are at the same latitude as Labrador and Greenland, relatively comfortable places to live.\nMany scientists, however, are warning that the North Atlantic might cool down, perhaps by the turn of the century. Paradoxically, global warming would be to blame. Rising temperatures may trigger events that could not only slow the supply of tropical water flowing north, it could disrupt the entire ocean circulation pattern.\nThis scenario has led to wild talk of the start of a new ice age, a notion that climate scientists universally dismiss. Still the impact on the world’s climate could be profound. Scientists are therefore scrambling to gather data on ocean circulation and the forces that drive it.\nOcean circulation is comprised of a global network of interconnected currents, counter-currents, deepwater currents, and turbulent eddies. From this complex circulation, an underlying transport pattern emerges. Water cycles from surface currents to deepwater currents then back to the surface again in what scientists liken to a giant conveyor belt. Scientists call this global conveyor belt the meridional overturning circulation.\nThere are two major forces driving the meridional overturning circulation. First there is the wind. The wind, in combination with the Earth’s rotation, generates the gyres that circle the major ocean basins. Turbulent swirling packets of water called eddies, many of which are hundreds of kilometers in diameter, spin out of these wind-driven currents and carry the water trapped inside them to other parts of the ocean.\nThe second force is tied to differences in the density of water. Temperature and salinity independently affect water’s density. The colder and saltier the water, the denser it becomes. As water becomes denser, it sinks.\nThis is where the Atlantic Ocean plays a pivotal role. Again, the Gulf Stream and the North Atlantic Current carry warm salty tropical water up into the Labrador and Greenland Seas. Frigid Arctic winds cool this water, increasing its density. The water then sinks, feeding deepwater currents. This same density driven creation of deepwater also takes place in the frigid Ross and Weddell Seas off the coast of Antarctica, and to a lesser extent in the salty Mediterranean Sea.\nScientists call this density-driven component of the meridional overturning circulation the thermohaline circulation; thermo meaning heat and saline meaning salt. Without this density-driven process, deepwater currents would no longer be created. The global conveyor belt would grind to a halt.\nScientists are using observations and models to trace the complex pathways of the meridional overturning circulation and determine its strength. It’s an overwhelming task. Maps charting the circulation’s course are still evolving. Deeper currents and upwelling in particular are extremely difficult to measure. But some patterns are becoming clearer.\nStarting off the Greenland coast, the newly created deepwater slowly drifts south along the western margin of the Atlantic basin. It then crosses the equator and mixes with the deepwater currents circling Antarctica. Models suggest that some of this water resurfaces in this area. Much of it, however, spreads north into Indian and Pacific Oceans where it mixes with warmer water and resurfaces.\nTo close the loop of the conveyor belt, surface water flows from the Pacific and Indian Oceans back into the South Atlantic then heads north. Some cold water enters the South Atlantic from the Pacific around the southern tip of South America. The Agulhas Current in the Indian Ocean is another important source. This fast-moving current, the Indian Ocean’s equivalent of the Gulf Stream, flows down the southeast coast of Africa and past the tip of South Africa then takes a sharp turn to the east. Large eddies called Agulhas Rings spin off this bend and carry huge bundles of warm salty Indian Ocean water west into the South Atlantic. Currents carry much of this Indian Ocean water north to the equator where the sun heats it further. Eventually this water enters the Caribbean and is swept into the Gulf Stream.\nScientists believe that these Agulhas Rings are critical sources of the salty water that drives the formation of deep water up north. Eddies spinning out of the Mediterranean Sea and net evaporation in the tropical Atlantic also contribute salty water.\nDespite its enormous scope, the meridional overturning circulation is vulnerable. Places where deepwater currents are created comprise less than one percent of the ocean’s surface area. Should the temperature or salinity in these limited areas change, the creation of deep water could slow or even stop.\nThere is strong evidence that such a shutdown has happened in the past, drastically altering the world’s climate in just a matter of years. Eleven thousand years ago, ice age glaciers were retreating. In central Canada, an immense glacial lake called Lake Agassiz occupied an area larger than all the Great Lakes. Suddenly the dams holding Lake Agassiz collapsed. The contents of the entire lake rushed into the North Atlantic by way of the St. Lawrence River. This massive infusion of fresh water diluted the polar seas to the point where the water was no longer dense enough to sink. The meridional overturning circulation likely ground to a stop. Called the Younger Dryas, this one thousand year period saw the temporary return of the ice age.\nWe may soon face a similar although far less drastic situation. Scientists are predicting that rising temperatures will melt the Greenland ice sheet. Models suggest that the resulting influx of fresh melt water into the polar sea could weaken the meridional overturning circulation, although not as drastically as the events thought to have triggered the Younger Dryas period. Still it could slow enough to reduce the flow of warm tropical water north into the polar seas. Temperatures over northwestern Europe could drop as much five degrees Celsius.\nPredictably, talk of such a scenario has led to some big misconceptions. First, a slowdown or even a stoppage of the meridional overturning circulation would NOT spell the end to the Gulf Stream. Wind and large-scale turbulence drive the bulk of the Atlantic Subtropical Gyre, of which the Gulf Stream is a part. The Gulf Stream would, however, draw significantly less water from the tropics.\nSecond, unlike during the Younger Dryas, a weakening of the meridional overturning circulation will NOT trigger another ice age. Rising temperatures due to global warming would offset most of the temperature drop. Armadas of icebergs floating off the New Jersey coast are just Hollywood fantasies.\nBut even in the absence of these most extreme scenarios, any disruption of the meridional overturning circulation can have far-reaching consequences. Models and paleoclimate data suggest that as less warm water flows north across the equator, the southern oceans will warm. The thermal equator (band of highest temperatures) would therefore likely shift south. The tropical rain belts would follow, altering rainfall patterns. Decreased downwelling would deliver less oxygen to the deep ocean, and decreased upwelling would carry fewer nutrients up from the bottom, potentially devastating ocean ecosystems.\nMonitoring the meridional overturning circulation and identifying changes in the thermohaline circulation is daunting. To separate real trends in ocean circulation from natural variability, scientists require huge volumes of data gathered over a long period of time. A global network of surface and deep profiling ARGO drifters that measure currents, water temperature, and salinity form the backbone of this effort. Moored buoys measure the southbound deepwater currents at strategic locations in the Atlantic. Satellites measure wind, sea surface temperatures, and sea surface height, and programs such as OSCAR calculate surface currents based on these measurements. In 2010, a new satellite, Aquarius, will begin to measure surface salinity throughout the ocean. These observations already form the foundation for global ocean circulation and climate models that are helping scientists predict how the oceans and climate will respond as the Earth warms.']	['<urn:uuid:ac8c9ace-89e9-410c-8ce5-7c20a828f2d7>', '<urn:uuid:fea69aba-bfd8-4845-9bab-d7e44bcba03d>']	factoid	with-premise	verbose-and-natural	similar-to-document	multi-aspect	expert	2025-05-13T06:27:57.068978	44	95	2328
82	compare elevation characteristics western ghats mountain range versus lowari pass hindu kush	The Western Ghats have an altitude of 900-1100 meters, while Lowari Pass in the Hindu Kush reaches an elevation of 10,230 feet (approximately 3,120 meters) and is situated between snowpeaked mountains that tower thousands of feet higher.	['UPDATED: Now with map!\nBecause every unfamiliar setting deserves one. 🙂 Passages in blockquote are from the book.\nNOT QUITE A HUSBAND starts in Rumbur Valley, on the North-West Frontier of British India (today’s North-West Frontier Province, Pakistan) Rumbur Valley is one of the three valleys known as the Kalash Valleys, so called because of their unique Kalasha population. The Kalasha are a tribe of pagans who worship a pantheon of gods. They believe themselves to have descended from the soldiers of Alexander the Greek–and it is not unusual to find among the Kalasha fair hair and blue/green eyes. Unlike the Kafirs of Afghanistan who were forcibly converted to Islam in mid-1890s by the Amir of Kabul, the Kalash Valleys happened to fall on the British side of the Durand Line, and the Kalasha were allowed to continue in their ancient beliefs first under the British, then later under the constitution of Pakistan.\nAcross the stream, fields glinted a thick, bright gold in the narrow alluvial plain—winter wheat ready for harvest. Small, rectangular houses of wood and stacked stone piled one on top of another along the rising slope, like a collection of weathered playing blocks. Beyond the village, the ground elevated more rapidly, a brief stratum of walnut and apricot trees before the bones of the hills revealed themselves, austere crags that supported only dots of shrubs and an intrepid deodar or two.\nLOL, this is not the exact same village, so it looks a little different. 🙂 But it is still a fairly recognizable as a Kalasha village.\nHe watched her wend her way past women in vibrantly embroidered black robes guiding water into the irrigation canals that supplied the fields of wheat, women in vibrantly embroidered black robes shaking ripe mulberries from trees onto blankets, women in vibrantly embroidered black robes cutting hay to make winter fodder.\nKalasha women’s costume is quite distinctive: black robe exuberantly embroidered, thick strands of beaded necklace, and headdress decorated with cowry shells.\nOnce Leo convinces Bryony to come with him, they leave the Kalash Valleys. The Kalash Valleys are lateral valleys cut into the mountains to the west of Chitral Valley. Chitral is a strategic forward hold for the British, who feared that the Russians could sweep down any moment and contest their crown jewel, India.\nChitral Valley is dominated to the north by the Tirich Mir, the highest peak of the Hindu Kush. Leo and Bryony, however, would only see the Tirich Mir when they look backward, as they are headed not north, but south, toward the plains of India.\nTo get out of Chitral Valley, Leo and Bryony brave Lowari Pass, elevation 10,230 ft.\nIt took dozens of one-hundred-eighty-degree turns for the road to zigzag up the steep slope leading toward Lowari Pass, ten thousand feet above sea level, a narrow gap in snowpeaked mountains that towered thousands of feet higher to either side. From the top, looking down at the way she’d come, Bryony thought the dirt path resembled so many hairpins that a careless goddess had dropped. The mountains, like a choppy sea, stretched blue and jagged toward the horizon.\nThe above image actually shows the descent side of the pass, which is not as steep and dramatic as the ascent side.\nOnce they have crossed Lowari Pass, they move ever closer to Swat Valley.\nSwat Valley is called the Switzerland of Pakistan–please do yourself a favor and look at these spectacular pics here. Yet Swat Valley was nothing less than spectacularly dangerous in the summer of 1897. Inspired by the exhortations of a certain Mad Fakir, its population rose in a swift, powerful rebellion that caught the local British garrison by the short hairs.\nRoute Map (Or whatever I could get off Google Earth):\nTheir journey started in the Kalasha village of Balanguru. Nowshera is where they could get on the train. The yellow line is the Afghanistan boundary. The red line is the boundary between NWFP and FANA.\nAnd here’s an aeriel view of the ascent toward Lowari Pass. Notice all the zigzags.\nI wish I could show you more pics, but it’s hard to find good pics either in the public domain or in the creative commons. So I guess this will have to do. 🙂 I hope you have enjoyed your mini-tour and I hope you enjoy NOT QUITE A HUSBAND.', 'Q1. which two forces are responsible for shaping the present landform features of India?\nAns. Divergence and convergence cause two continental plates to fracture and fold. The movements of these crustal plates have changed the position and size of the continents over millions of years.\nthe present landform features or relief of India isa part of this process.\nQ2. What are tetonic plates?\nAns. Radioactive decay in the interior of the earth produces heat which escapes towards surface producing convection currents in the molten rocks. Rising currents tear the crust apart, dividing it into large fragments called tectonic plates or lithospheric plates.\nQ3. Which continents of today were part of the Gondwanaland?\nAns. South America,Africa, Australia and Antartica were a part of Gondwanaland.\nQ4. What is the Bhabar?\nAns. A narrow belt covered with pebbles lies along the foot of the Shivaliks from the Indus to the Tista. They are laid down by the numerous streams descending down the hills. The pebbled beds are parallel to the slope of the river bed. This belt is about 8 to 16 km in width and is known as the Bhabar.\nQ5. Name the three major divisions of the Himalayas from north to south?\nAns. The three major divisions of the Himalayas are the Himadri, the Himachal and the Shiwaliks.\nQ6. How was the Arabian sea formed?\nAns. When the Himalayas were being formed an extensive volcanic eruption took place in the north western part of the plateau. Besides, the western part of the plateau subsided. The Indian Ocean advanced to occupy this depression and thus the Arabian sea was formed.\nQ7. Why are Shiwaliks prone to landslides?\nAns. The Shivaliks are made up of unconsolidated sediments and hence are prone to landslides.\nQ8. Name two passes of the Eastern Himalayas?\nAns. Some of the passesof the Himalayas are Shipkila, Nathula and Bomdila.\nQ9. Which plateau lies between the Aravalli and the Vindhyan ranges?\nAns. The Malwa Plateau lies between the Aravalli and the Vindhyan Ranges.\nQ10. Name the island group of India having coral origin.\nAns. Lakshadweep island group of India is having coral origin.\nQ 11. Name the Physiographic divisions of J & K State.\nAns. The physiographic divisions of J & K State are Jammu(Sub-Himalayan), Kashmir(Himalayan) and Ladakh ( Trans Himalayan).\nQ 12. What is LOO?\nAns. Hot wind blowing from\nQ 13. Name the range of mountain where K2 is located?\nAns. K2 is locatedin the Great Himalaya range or the Himadri.\nQ14. Name the famous glaciers of Karakoram range?\nAns. The famous glaciers of the Karakoram range are Baltoro and Saichin.\nQ 15. Which areas a part of the outer plains of J & K State?\nAns. The outer plain is an extension of Great Indian Plain and is alluvial in nature. It stretches from river Ravi to River Chenab. Akhnoor, Ranbirsinghpora, Samba and Kathua are the main areas of outer plains. Itis locally known as Anderwah and Bajwat.\nQ2. Distinguish between\na) Converging and diverging tectonic plates.\nWhen two plates are pushed together they are converging\nWhen two plates are moving away from each other is called diverging.\nConvergence can cause the land form to fold to form mountain range\nDivergence can cause the land form to fracture.\nWhen they converge, they can collide and crumble and may slide under other.\nWhen they diverge they can also move horizontally past each other.\nb) A delta and a estuary.\nWhen the river joins the large water body, it deposits sediments at the mouth causing small islands called the Delta\nWhen the river rushes to join the large water bodies, the sediments are not deposited at the mouth and no small islands are formed is called a estuary.\nThe islands that are formed at the Delta are rich in sediments and alluvial soil\nThe sediments are spread over a large area in the largewater body.\nc) A tributary and a distributary.\nA tributary is sometimes a small river which joins the main river\nA distributary is when the river distributes itself to make way for itself when sediments form islands on its path.\nA tributary mainly joins the river through its course\nA distributary mainly is formed at the mouth when the river joins the larger water bodies.\nd) Khadar and the Bhangar\nThe younger alluviam of the flood plains is known as the khadar\nThe older alluviam is known as the Bhangar\nThe Khadar gives one harvest after the floods i.e. rice\nThe Bhangar gives more than one harvest and needs constant manuring.\ne) Western Ghats and the Eastern Ghats\nThe western ghats spread uninterruptedly along the Arabian Coast.\nThe Eastern Ghats are discontinuous hill ranges\nThe western ghats are higher with a altitude of 900 – 1100 meters\nThe eastern ghats are hill ranges with the maximum altitude of 900 meters.\nf) A Plateau and a Karewa\nA Plateau is a table land\nThe Karewas are lacustrine deposits and are the unique features of the kashmir valley.\nThe plateau has a general elevation of 600-900 meters\nThe Karewas occupy about 50% of the valley floor.\nQ3. Describe how the Himalayas were formed?\nAns. Millions of years ago India was a part of an ancient super continent called the Gondwanaland. This was located in the southern hemisphere. The convection currents of the mantle fractured it into a number of pieces. The Indo – Australian plate after getting seperated from the Gondwanaland drifted slowly towards the north. It collided with the much larger Eurasian plate in the northern hemisphere approximately five crores of years ago. The northern edge of the Indo-Austrialian plate was pushed under the Eurasian plate. Under the impact of this collision, the sedimentary rocks of the enclosed ocean were folded to form the mountain system of central Asia including the Himalayas.\nQ4. Which are the main physiogaphic division of India? Contrast the relief of the Himalayan region with that of the Peninsular Plateau.\nAns. The Physiographic divisions of India are\n1) The Great Mountains of the North.\n2) The North Indian Plain.\n3) The Peninsular Plateau\n4) The Coastal Plains\n5) The Islands\nThe land of India is characterised by a great diversity in its relief or physical features. In the north, there is a vast expanse of rugged terrain made of sedimentary rocks and metamorphic rocks. Series of mountain chains with lofty peaks, enclosed plateaus, and narrow and deep valleys are the characteristic features of this part. In contrast, the North Indian Plain, drained by the Indus, the Ganga,and the Bramhaputra is made up of the alluvium. It is an area of low relief and level or featureless surface. In south, the peninsular plateau is made of igneous and metamorphic rocks which contain valuable minerals. It is the oldest landmass of the country. It has remnants of the old mountain ranges and dissected plateaus. In some areas, the plateau rises in the form of staircase. It is bordered by coastal plains to its east and west.\nQ5. Give an account of the northern plains of India.\nAns. When the Himalayas rose in the north, plains were formed soon after the rising land. The rivers that took birth in the glaciers started depositing rich alluvium into the plains. The rivers being perrinial had water alround the year and thus the northern plains are one of the richest plains of the world. These plains extend between the mouths of the Indus and the Gangal-Brahmaputra covering a distance of about 3200 KM. These plains are broadly divided into the Indus river system in the west and the GangaBrahmaputra river system in the east. The Indus and its tributaries flow westward after taking birth in the Himalayas and flow through Pakistan and reach Arabian sea. This plain is fed by 5 rivers and hence is called Panch+ab meaning Punjab. The Ganga flows eastward and the Brahmaputra enters India from Arunachal pradesh and joins the Ganges in Bangladesh and both flow south under the name Meghna and join the Bay of Bengal and form one of the world’s largest and fastest growing deltas of the world.\nQ6. Write Short Notes on\na) The middle Himalayas. They are also called Himachal and lie south of Himadri. They consist of Pir Panjal, the Dhaoladhar and the Mahabarat ranges. Some of the important hill stations of north India arefound in these ranges namely Dharmshala, Dalhousie, Shimla, Mussorie and Darjeeling.\nb) The Central Highlands. The northern part of the plateau consists ofa number of plateaus, denuded mountain ranges and low hills. They are made up of igneous rocks. The Aravalli hills which border the plateau']	['<urn:uuid:400e80c8-d761-4673-87d4-c95b61f9c199>', '<urn:uuid:5f1564d8-f37b-4131-9141-8259752ed281>']	factoid	direct	long-search-query	similar-to-document	comparison	expert	2025-05-13T06:27:57.068978	12	37	2159
83	How did supply chain bottlenecks impact different manufacturing sectors' export performance in the euro area during early 2022?	In the first quarter of 2022, industries that faced longer average supplier delivery times experienced larger declines in exports compared to the same quarter in the previous year, with a correlation coefficient of 0.70. The computer and electronical equipment sector and the machinery sector were among the most affected by supply bottlenecks. The motor vehicle exports weakness was particularly related to longer delivery times for components, especially in the car subsector. However, by the second quarter of 2022, supply bottlenecks eased somewhat and became less significant in explaining export performance. During this period, quarterly extra-euro area export growth turned positive for the computer and electronics sector and stabilized for the machinery sector, while wood and paper exports continued to decline as supply bottlenecks eased only slowly.	['Published as part of the ECB Economic Bulletin, Issue 7/2022.\nThis box provides an assessment of recent trends in goods trade and the tourism sector in the euro area based on the Purchasing Managers’ Indices (PMIs). Both sectors have been severely affected by the economic fallout from the coronavirus (COVID-19) pandemic. Regarding goods trade, our analysis shows that bottlenecks in the supply chain have historically preceded upward pressures on import prices, especially for intermediate goods. These pressures are now slowly easing as export demand weakens and supply chains adjust. As regards trade in services, a surge in extra and intra-euro area demand for tourism (which accounts for 19% of services exports and has been one of the sectors most affected by the pandemic) during the summer of 2022 pushed up prices in the tourism and recreation sector. Waning pent-up demand for travel, falling real incomes, rising uncertainty and higher prices may start to dampen overall demand for European tourism services in the coming months.\nSupply chain bottlenecks in goods trade are easing\nUpward pressures on input prices associated with supply-side bottlenecks seemingly diminished in mid-2022 but remain elevated. The PMI indicators for manufacturing export orders, suppliers’ delivery times and input prices tend to be highly correlated and show a consistent lead pattern for turning points. Changes in export orders have historically preceded movements in input prices by two months with a correlation coefficient of 0.70, while changes of supplier delivery times have previously led input prices by one month with a correlation coefficient of 0.84. Turning points in export orders and suppliers’ delivery times lead input prices by one to two months on average (Chart A). By mid-2022 suppliers’ delivery times started to decline, gradually falling from historically high levels but remaining elevated. Following this easing, input price pressures, as reported by the PMI, have decreased somewhat.\nEuro area manufacturing sector PMI\nGrowth in extra-euro area import prices for intermediate goods has been slowing since mid-2022. The PMI indicator for total input prices started declining towards the end of 2021 while remaining at an elevated level, suggesting that the growth in import prices for intermediate goods may also slow somewhat, as these variables tend to be closely related (Chart B). Both variables exhibit a correlation coefficient of 0.80, with the PMI indicator leading intermediate import prices by two months. However, the high level of the PMI input price indicator for September 2022 and the continued weakness of the euro suggest that price pressures in manufacturing will remain high.\nPMI input prices and intermediate goods import prices\nSector-level trade data suggest that longer delivery times were associated with weak exports in early 2022. Industries faced with longer average supplier delivery times in the first quarter of 2022 experienced larger declines in exports compared with the same quarter in the previous year (Chart C). This is illustrated by the downward-sloping line, which reflects a correlation coefficient of 0.70.\nEuro area extra-export growth and suppliers’ delivery times by sector in the first quarter of 2022\nAmong the exporting sectors most affected by supply bottlenecks were the computer and electronical equipment sector and the machinery sector. The weakness in motor vehicle exports in the first quarter of 2022 is a reflection of longer delivery times for components, especially in the car subsector, while for basic metals suppliers’ delivery times eased somewhat. In the second quarter of 2022 supply bottlenecks eased somewhat and became a less significant explanatory variable for the export performance of the sectors in question. Amid easing bottlenecks, quarterly extra-euro area export growth turned positive in the second quarter for the computer and electronics sector and stabilised for the machinery sector. Wood and paper exports declined further, while reported supply bottlenecks eased only slowly. The very recent easing of bottlenecks has been accompanied by weaker demand for durable goods, a moderation in demand for technological goods and an improvement in the supply of traded goods.\nThe recovery of the tourism sector is slowing amid high price pressures\nTurning to services, the strong dynamics in the tourism and recreation sector observed over the spring and summer have started to weaken. Bookings, which were proxied by PMI new orders, tend to lead prices in the tourism and recreation sector with an average lead of one to two months. The PMIs for the price series are generally quite stable in this sector compared with, for example, the more volatile manufacturing sector, despite some earlier fluctuations related to higher uncertainty surrounding international travel (Chart D). As the tourism and recreation sector in the euro area gradually re-opened after each wave of the COVID-19 pandemic, input price cost pressures and an exceptionally strong recovery of demand for tourism and recreation services increasingly pushed up output prices in this sector.\nEU tourism and recreation PMI\nEnergy is one of the factors driving movements in input prices in the tourism and recreation sector. Energy import prices are strongly correlated with the movements of the PMI indicator for input prices. The former can therefore be regarded as a major driving factor behind the increase in input prices in tourism and recreation (Chart E, panel a). Labour cost developments in this sector are less synchronised with the evolution of the PMI tourism and recreation input prices.\nEU tourism and recreation PMI prices versus energy and accommodation prices\nTourism and recreation output prices peaked earlier this year, suggesting that consumer price dynamics for accommodation services may start to slow, although they will remain strong. The HICP for accommodation services tends to lag somewhat behind the price increases in tourism and recreation reported by purchasing managers (Chart E, panel b). At the current juncture, both measures indicate that price pressures may have reached their peak.\nWaning pent-up demand for travel, falling real incomes, rising uncertainty and higher prices may start to dampen demand for tourism and recreation services in the coming months. All the indicators shown in Chart D reached a local maximum in May 2022 and have been declining in line with the lower demand expectations of travel agencies. The deterioration of the economic outlook has been accompanied by other factors, such as the waning pent-up demand for travel, falling real incomes and rising uncertainty mentioned above. Overall, this points to high but gradually stabilising price pressures in the tourism and recreation sector.\nWhile a direct mapping of tourism activities in the balance of payments is not straightforward, its share in total services exports could be approximated to 19% in 2019. Tourism includes passenger transport services and travel-related services such as accommodation and food, with the exceptions being purchases of goods and services of seasonal and cross-border short-term workers. For additional details see the box entitled “Impact of the COVID-19 lockdown on trade in travel services”, Economic Bulletin, Issue 4, ECB, 2020.\nIn Chart A we inverted the reported numbers for “Manufacturing suppliers’ delivery times” to illustrate their co-movement with the other series. In this case a higher reported number implies longer delivery times. The development from 2019 to 2022 is highlighted given the focus of this box on the economic fallout from the COVID-19 pandemic.\nSee the box entitled “The impact of supply bottlenecks on trade”, Economic Bulletin, Issue 6, ECB, 2021, which shows the pattern of high export demand leading to tighter bottlenecks in the initial phase of the recovery.\nSee the box entitled “Motor vehicle sector: explaining the drop in output and rise in prices” in this Economic Bulletin issue.\nIn addition to tourism services, the tourism and recreation PMIs include recreation, and thus domestic, activities.\nData suggest that profit margins in this sector have also come under pressure.\nFor more details on the methodological background of the PMIs, see the box entitled “PMI survey data on producer input and output prices”, Monthly Bulletin March, ECB, 2005.']	['<urn:uuid:166c0d95-8905-4783-a7f7-32c6281acd5b>']	open-ended	direct	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-13T06:27:57.068978	18	126	1298
84	manufacturing boxes compare materials wood plastic fiberglass price durability food safety	The three main materials used for shipping pallets each have distinct characteristics regarding price, durability, and food safety. Wood pallets are the most economical option but have significant food safety concerns due to their ability to harbor bacteria, mold, and pests, especially when exposed to moisture. Plastic (HDPE) pallets cost 2-3 times more than wood and can only support loads up to 1,500 pounds, but they're cleaner and more weather-resistant. However, they can become brittle and may require carcinogenic fire-retardant treatments. Fiberglass composite pallets offer superior hygiene properties - they're non-porous, naturally antimicrobial, don't produce debris, and maintain structural integrity for about 150 uses. They also meet food safety standards without requiring toxic treatments and can be safely cleaned using standardized processes.	['Special thanks to Source One Management Services for this guest post\nWhen you think of cost savings opportunities in critical supply chain categories, the first spend area that comes to mind is generally not pallets. Typically the focus for “big hit” cost savings opportunities in manufacturing operations stems from categories such as Power Transmission Supplies, Electronic Components, Industrial Supplies and so on. Pallets fall within the sub-category of secondary packaging (which includes dunnage, shrink wrap, packing tape and other tertiary packaging components). Oftentimes, this spend area goes unchecked by sourcing managers and – because of this – it is a good area to get a quick win, if examined holistically. There is more to pallets than meets the eye.\nThe basics to sourcing pallets starts with data collection. Suppliers need to know your specifications in order to give you a quote. Comprehensive wooden pallet specifications come in a PDS (Pallet Design System) file format – a tool developed as an engineering reference to store specs for wooden pallets. Specifications include wood material composition, nails size specifications, load capacity, moisture content, board configuration, general dimensions (both top deck and bottom deck), transport and storage requirements, and more. As far as putting a bid package together for your current specs, the PDS files are your most important component to facilitate quick and easy supplier reference guides for quote. Combine your PDS files with annual volume requirements for each pallet type, a detailed qualitative questionnaire, and an instructional RFP doc and you have your complete bid package. Sourcing your current pallet specifications with incumbent and alternate suppliers is an extremely effective savings lever to test the market.\nPlastic pallets are similar in terms of what you need for sourcing except instead of PDS files you would use CAD drawings for any custom pallet design. Plastic pallets are typically offered as off-the-shelf products and have specific advantages and disadvantages as compared to wooden pallets. Plastic pallets are most commonly injection molded; however, thermoforming, compression molding, rotational molding and structural foam molding are also common manufacturing methods. Due to the manufacturing process and higher cost of PP or HDPE material, plastic pallets are generally two to three times the cost of traditional wooden pallets. Additionally, they can only support shipments weighing less than ~1,500 pounds, whereas wooden pallets can support twice that weight. However, they have a much longer useful life as compared to wooden pallets. In general, plastic pallets are also cleaner, more durable, weather resistant and generally easier to handle.\nWhen selecting which pallet options you can feasibly use in your manufacturing operation, first consider the application of each pallet, as well as the total cost of purchasing and replacing pallets. If the rate of pallet return to your facility is high – or you are using them in a closed loop capacity at the same facility – plastic pallets represent a financial benefit and you should opt for a plastic pallets purchasing program. Though if you are shipping internationally and therefore rate of pallet return is low, wood pallets will be much cheaper in the long run since they are the inexpensive option.\nUsing a few different examples on how to choose the right pallet mix:\n- If the pallets are exposed to inclement weather, plastic pallets are the better choice as they are more weather resistant.\n- For heavier shipments, as previously mentioned, wood pallets may be required to support the max load.\n- If you are shipping fragile items, smooth plastic pallets may be the best option since wooden pallets can be abrasive to cargo, especially with loose or broken nails. Per the previous example, you must evaluate the cost of damaged goods to see if that is higher than the total increase in pallet cost by switching to plastics. Slip sheets can be added to wood pallets to mitigate this risk, but also adds cost to transporting your shipment.\nOverall, many factors must be weighed to determine the best pallets to use to support your operation considering the total cost over the lifetime of each pallet.\nOften, manufacturing operations either use pallets that are “overkill,” where they can cut back on the specification and total materials used to save cost, or they are under spec’d and are spending more time fixing pallets than sending them out the door. Choosing the optimal pallet type for their application is the most overlooked savings lever.\nOther savings levers include evaluating the location of your suppliers in proximity to the pallet destination locations. Freight can represent upwards of 20% of the unit cost of each pallet depending on load size, fuel pricing and overall distance travelled. The optimal choice is to utilize a national player with many distribution locations available to support your facilities. The biggest mistake in this respect would be to use suppliers that travel long distances to support your pallet needs; this almost certainly adds a 10-20% premium on the cost of service.\nFinal considerations when optimizing your pallet portfolio include making sure you are abiding by regulatory requirements. The FDA for example can impose penalties for non-compliance related to sanitary conditions of pallets transporting food products. For example, it is a best practice (depending on the industry you are serving – Pharma to Food Industry) to utilize heat treated pallets to remove any possibility of organism infestation, especially in international transport.\nOverall, there are many factors to consider when looking at pallet spend in manufacturing operations. This category is way too often left behind when it comes to cost savings initiatives but as you can see, there many areas for budget optimization. With a clear understanding of your packaging requirements and specifications, pallet strategic sourcing can deliver a quick cost reduction win.', 'In supply chains with high sanitation requirements, such as food manufacturing and pharmaceuticals, pallets can be a major concern. Although pallets are not primary packaging in these industries—meaning they do not come into direct contact with the products they carry—they can still pose significant contamination risk to the facilities and products for which they’re used. Wood pallets, in particular, have come under intense scrutiny many times over the last decade as the cause of various FDA recalls. As a result, many food and pharmaceutical manufacturers as well as retailers began looking for non-wood pallet materials to avoid the risk of contamination, and the pressure to convert to more hygienic pallets continues to mount. Here, we examine the various types of contamination hygiene-sensitive pallet users must avoid, and compare the level of risk that wood, HDPE plastic, and fiberglass composite pallets pose to users.\nForeign Material Risk from Pallet Debris\nIn 2019, the U.S. Department of Agriculture’s (USDA) Food Safety and Inspection Service (FSIS) began developing guidelines for meat and poultry industry operators after noting a significant increase in the number of recalls for contamination with foreign materials. The meat and poultry industry is certainly not alone in this challenge, as foreign materials in finished products is one of the top drivers of consumer complaints across all sectors of the food industry.\nThe risk posed by foreign materials is not limited to inclusion in finished product. Broken pieces of wood or plastic pallets can tear open soft primary packaging such as boxes and bags, as can nails or other fasteners used to manufacture these pallets. Damage to the primary packaging leaves the product inside vulnerable to contamination by any number of substances during distribution, even if the piece of pallet material or fastener does not end up inside the finished product. Spills of damaged product create additional hygiene issues if the product leaks in storage or during transportation. In the case of food products, spills can also provide an attractive food source for pests within the facility or truck. Managing this risk when using wood pallets or older plastic pallets that have become brittle is a significant challenge for food safety and quality assurance professionals across the food sector.\nWhen discussing foreign material risk, wood pallets deservedly receive the majority of scrutiny. But HDPE plastic pallets present a similar risk as they age or are exposed to temperature extremes in the cold chain. The plastic becomes increasingly brittle with use and exposure, and more susceptible to breakage and splintering.\nIn contrast, fiberglass composite pallets are made from a non-shedding material that does not produce dust or debris, eliminating risk of foreign material from the pallets themselves. Even at the end of the useful life (around 150 uses), fiberglass composites have been shown to maintain structural integrity in independent testing by Virginia Tech1. This composite, called Fiberglass Reinforced Plastic (FRP), is a very common material used to manufacture items that must withstand heavy weight, wide temperature fluctuations and impact without splintering. The material is commonly used in bath tubs and shower stalls, doors, composite decking, swimming pools and hot tubs, boats, snow and water skis, to name a few.\nThe (Mostly) Unseen Pallet Hygiene Threats: Toxicity, Pathogens and Pests\nWhen discussing pathogens and pests, it should come as no surprise that wood presents the biggest challenge. Its absorbent nature allows wood to become an attractive host for bacteria, mold, and other microorganisms once it absorbs moisture, a common occurrence in food and pharmaceutical supply chains. Not only can visible liquids such as water from melted ice or even liquid products seep into the wood, swings in temperature and humid environments can create invisible condensation within the wood fibers. Also, users attempting to clean visible debris from wood pallets by spraying with water inadvertently create a host environment for invisible pathogens and mold spores.\nToxic liquids from previous users may be absorbed into wood pallets, with future users none the wiser. In many cases, these chemicals such as anti-fungal treatments are intentionally placed on the pallets in order to decontaminate them or prevent contamination. Wood pallets are both hard to clean and simple to accidentally contaminate, which is why many users seek pallets made from alternative materials, such as plastic or fiberglass composite. Both HDPE plastic pallets and fiberglass composite pallets are made from non-porous materials, which is a huge advantage over wood pallets from a hygiene perspective. However, although plastic pallets do not absorb moisture or chemicals, they cannot match the fiberglass composite pallet’s inherent antimicrobial properties.\nThe RM2 BLOCKPal is fully encased in a polyurethane composite which is impervious to bacterial contamination and meets the ASTM G21 anti-fungal standard and are ISPM-15 exempt. Further, many plastic pallets must be treated with carcinogenic fire-retardant chemicals in order to meet the FM 4996 fire safety standard, whereas fiberglass composite pallets are naturally fire retardant and require no additional carcinogens or neurotoxins to meet the FM 4996 standard. In fact, even though pallets are not required to meet the standards of food contact packaging, RM2’s fiberglass composite pallets are certified by the NSF to meet the standards for FDA GRAS and EU Food Contact materials.\nTaking Action: Pallet Cleaning and Sanitation\nWith all the hygiene risks outlined above, it’s no wonder many pallet users want to clean their pallets before use. Unfortunately, in the case of wooden pallets, washing can remove visible debris but increase likelihood of other contamination. In addition to adding moisture, high pressure sprayers can compromise the integrity of the wood surface, making it even more susceptible to pathogens, pests, and mold. The use of sanitizing chemicals can present the same issues, as well as contaminate the wood with unsafe chemicals for future users.\nBoth fiberglass composite pallets and plastic pallets can be sprayed down with water or sanitizing chemicals to remove debris and eliminate surface pathogens, using an appropriate cleaning agent. However, users who choose to sanitize pallets themselves bear the risk if pallets are not cleaned properly. Unfortunately, plastic pallet poolers typically do not offer sanitization services, and thus users are forced to try to clean to strict standards themselves.\nFortunately, RM2 offers pallet cleaning services for hygiene-sensitive users. The company operates three strategically located pallet cleaning facilities in the United States, each with the capacity to wash over one million RM2 pallets each year. The pallets are washed in standardized machines in an automated two-step process that ensures consistent cleaning and drying of the pallets, including 140° F water with high-pressure jets located at the top, middle, and bottom of each pallet, using environmentally-friendly, non-toxic Simple Green detergent. The pallets are rinsed in clean water using additional high-pressure jets to remove any detergent residue, then dried with mechanical blowers prior to exiting the machine. After the wash process is complete, pallets are swabbed to confirm acceptable ATP readings.']	['<urn:uuid:6447bf74-e895-4dc2-9400-bf3099fb3bf8>', '<urn:uuid:4a08e89f-014a-453c-ba8a-671a36bd3202>']	open-ended	with-premise	long-search-query	distant-from-document	multi-aspect	novice	2025-05-13T06:27:57.068978	11	122	2093
85	Why can't two computers just connect directly online?	Direct connections are often impossible in the modern internet due to NATs and firewalls that filter packets. These protective measures on many devices make it necessary to use special mechanisms to establish connections. This is why signaling servers are needed to help coordinate communication between peers and navigate through these internet security barriers.	"['What is WebRTC Signaling?\nWebRTC signaling refers to the process of setting up, controlling, and terminating a communication session. In order for two endpoints to begin talking to one another, three types of information must be exchanged:\n- Session control information determines when to initialize, close, and modify communications sessions. Session control messages are also used in error reporting.\n- Network Data reveals where endpoints are located on the Internet (IP address and port) so that callers can find callees.\n- Media Data is required to determine the codecs and media types that the callers and callees have in common. If endpoints attempting to start a communications session have differing resolution and codec configurations, then a successful conversation is unlikely. Signaling that exchanges media configuration information between peers occurs by using an offer and answer in the Session Description Protocol (SDP) format.\nWhy Are Signaling Servers for WebRTC Needed?\nWhen WebRTC applications are said to operate entirely ""in-browser,"" the perspective is taken from the end user\'s point of view. Yes, WebRTC app users require nothing beyond their browsers; but underneath the hood, developers must craft server-side solutions to get peers (i.e. browsers) to communicate with each other. This is how the infrastructure of a communication platform, such as the OnSIP Communications Platform as a Service (CPaaS), becomes useful.\nIn a nutshell, WebRTC signaling allows for users to exchange metadata to coordinate communication. RTCPeerConnection is the API WebRTC uses to establish peer connections and transfer audio and video media. In order for the connection to work, RTCPeerConnection must acquire local media conditions (resolution and codec capabilities, for instance) for metadata, and gather possible network addresses for the application\'s host. The signaling mechanism for passing this crucial information back and forth is not built into the WebRTC API.\nWebRTC Signaling and NAT Traversal\nThe task of getting the initial signaling data from one peer to another seems like it should be a simple process. Perhaps in a perfect world, a WebRTC signaling mechanism would be able to connect peers directly, without any detours or sidetracking. But the modern internet is structured in such a way that makes this sort of easy relay impossible. NATs of all varieties, and firewalls on many devices, will often erroneously filter packets that are not primed to deal with ALGs and other protective measures. Outside of generating the SDP packet itself, the signaling mechanism is also crucially responsible for ensuring that these signaling messages can be shared between peers in the first place.\nSo, how does a WebRTC signaling mechanism negotiate the perilous maze of the internet? The answer is simple in theory: it utilizes a versatile framework known as ICE. The efficiency of ICE allows it to calculate, with a mere three methods, the quickest and easiest NAT traversal route for a packet to reach its destination. The first method used, and the least likely to occur, is when ICE tries to make a UDP connection using the host address obtained from a device’s operating system and network card. This will inevitably fail on devices behind NATs, and so there are two remaining methods for ICE to employ: a STUN server or a TURN relay server.\n86% of all WebRTC calls are established via STUN servers 1. A STUN server operates STUN servers check the IP address and port of incoming requests, and it then sends that address back to the device’s WebRTC application as a response. The WebRTC application thus uses a STUN server to ascertain its own IP port address from a public perspective. This allows the application to offer a publicly accessible address, which is then passed to another WebRTC-enabled peer via the signaling mechanism.\nIf both methods fail, the final method employed by ICE is a TURN relay server. TURN servers are used to stream audio, video, and other real-time data between peers. Technically speaking, it does not relay signaling information, because it enables actual real-time data exchanges between peers. TURN servers have publicly available addresses, so peers can connect to them even if they are behind NATs and firewalls. TURN servers are costlier to maintain than STUN servers, because they are actually streaming media rather than connecting peers.\nA fully functioning WebRTC application requires all of ICE’s capabilities to operate smoothly and effectively. But purchasing and maintaining numerous servers at a significant cost is simply not a feasible option for developers who are looking to make sound economic and personnel decisions. This is why OnSIP\'s platform is perfect for developers who are looking to harness the power of WebRTC. Our pre-designed, mature SIP network, ensures that developers do not have to build complex server-side architectures to solve basic WebRTC signaling problems. Instead, they can harness the power and reliability of our redundant SIP platform to scale WebRTC applications, bridge compatibility gaps between endpoints, broker connections behind firewalls, and track and report communications with ease. Let us deal with the groundwork, so you can focus on making in-browser applications that are innovative, convenient, and expansive for your users.']"	['<urn:uuid:48a30926-3d64-4ce5-bc30-65de487f0d16>']	open-ended	direct	concise-and-natural	distant-from-document	single-doc	novice	2025-05-13T06:27:57.068978	8	53	836
86	What's an effective method for choosing which plants to put next to each other in a garden?	The method involves selecting plants based on matching colors. Start with a focal plant, then choose companions that share one of its colors (from leaves, flowers, seed heads, or emerging growth). Continue this process to create waves of color that move the eye from one area to the next. However, plants must also share the same cultural requirements.	['Drive down any suburban street across the country, and you’re likely to see the same old thing: lawn, lawn, lawn, spruce tree, lawn. This would be a dream come true for early landscape architects, like Frederick Law Olmsted, who saw a nonstop sea of grass as a way to bind houses together in a parklike setting. Since those early days, the lawn has been seen as a way of establishing an instant relationship with the neighbors—a relationship built on our mingling turfs. A nice lawn can be a beautiful thing, but if you are a gardener, like our friend Faye Beck, this monotony is not a dream but a nightmare.\nSet your site apart: Although Faye and her neighbor own lots that are similar in size and shape, Faye’s front yard undeniably stands out. Irregularly shaped garden beds fill most of the space, although a few patches of grass remain to visually connect her property to the property next door.\nMost gardeners want an exuberant front yard that is overflowing with plants. This, unfortunately, would surely make their landscape stick out like a sore thumb from their neighbors’. So how can gardeners set their residence apart without making it look like a rowdy front-yard circus with no connection to its surroundings? Faye’s 5,000-square-foot garden is the perfect example of a successful design that embraces the middle ground. By using three specific strategies, Faye formed a unique front-yard landscape that manages to say, “Yes, a gardener does live here—but I still fit in.”\nKeep just enough grass for effect\nTired of looking at and caring for her high-maintenance front lawn, Faye decided to install several garden beds. During their installation, she wanted to get rid of the lawn completely. But ripping out all of the turf was too drastic and would have put her front landscape at odds with the rest of the neighborhood. Faye, instead, left a few areas of grass along her front curb and along the property lines she shares with neighbors. These grassy spots help maintain a connection to the surrounding homes and are easily mowed with a string trimmer.\nTurf plays a small but important role. Because most of the neighborhood has a traditional front lawn, keeping a little grass along the edge of the garden beds was crucial so that this property didn’t seem foreign in its surroundings.\nThe best part for Faye is that the lawn sections are visible only from the street. She doesn’t have to look at them from her front door, but passersby on the street think that there are more areas of turf beyond the eye’s reach. This makes Faye’s yard seem less out of place in her turf-heavy neighborhood. As a bonus, Faye no longer needs to worry about fighting lawn weeds or diseases. She even plans to replace the remaining patches of turf with dwarf mondo grass (Ophiopogon japonicus ‘Nana’, USDA Hardiness Zones 7–10), which will look like lawn but will not have to be mowed, fertilized, or treated with herbicides.\nForget about straight lines. When designing a small space, curved beds make a garden seem large and, in turn, full. This planting, which stretches between the front walkway and the house foundation, doesn’t appear to end when it is actually only 25 feet long.\nIrregularly shaped beds give the illusion of more space\nLawns, like the ones all her neighbors have, generally feel and look spacious, so Faye needed to avoid creating a garden that looked and felt claustrophobic. She initially built long, traditional borders in her front yard but then decided to slowly expand them into irregularly shaped, slightly bermed islands. Expanding the beds not only provided room for more plants but also gave the front yard a greater sense of space. Straight lines tell the eye to stop, whereas curved lines trick the eye into thinking that the expanse goes on indefinitely. To give the beds distinct edges, which can sometimes be a challenge with curved beds, Faye used fieldstone and river rock.\nAlthough Faye’s front garden is only 5,000 square feet, visitors are always amazed by the variety of views they experience while traveling the paths between her beds. Everywhere you look, you try to anticipate what Faye has hidden around the deliberate curves. The nonlinear shapes of the beds also lend a sense of informality to the garden, allowing Faye an almost limitless plant palette. Placing large plants in the middle of the beds—instead of off to one side—allows visitors to enjoy them from every angle because they must walk around the perimeter to take it all in.\nColor helps move the eye. Plants with similar hues, like this black-eyed Susan (Rudbeckia cv., Zones 3–11), coleus (Solenostemon scutellarioides cv., Zone 11), and ‘Fireworks’ fountain grass (Pennisetum ‘Fireworks’, Zones 9–10), give a design fluidity.\nPlant in blocks of color\nBeing a savvy gardener, Faye created a mixed garden by filling in her beds with a little of everything: dwarf conifers, trees, shrubs, ornamental grasses, perennials, tropicals, bulbs, and annuals. But her approach to blending different plant materials together was guided by color. As she slowly extended the footprint of her beds, she selected companions that would allow her to create drifts of color. If, for instance, a canna (Canna spp. and cvs., Zones 8–11) were firmly established in a bed, she selected a companion that possessed one of the canna-leaf hues. Then she isolated a different color aspect of the companion plant to find a buddy for it, planting the buddy to one side.\nThis method of combining plants created waves of colors in Faye’s garden that help move the eye from one area to the next and give the front garden a sense of continuity. Every part of a plant is fair game for color matching: leaves, seed heads, flowers, and even emerging growth or fading blossoms. Faye points out, however, that you can’t just combine plants that look great together; they have to share the same cultural requirements.\nAs visitors pass by Faye’s front yard, they know instantly that a gardener lives on the property. And although it is not the typical landscape in her neighborhood, it still belongs, which makes Faye—and her neighbors—happy.\nConnect the colors\nWith thousands of plants to choose from, we wondered how Faye selected the ones for her beds. Her process involved, first, picking a focal plant, then creating waves of color echoes based on that plant. Here’s how the process works:\n➊ ‘Australia’ canna (Canna ‘Australia’, Zones 8–11)\nThis canna is the starter plant—a towering clump that is the main focal point of the bed.\n➋ ‘Religious Radish’ coleus (Solenostemon scutellarioides ‘Religious Radish’, Zone 11)\nThe bright red tip of the coleus leaves perfectly matches the flowers of the nearby canna.\n➌ ‘Tomato Soup’ coneflower (Echinacea ‘Tomato Soup’, Zones 4–9)\nThe center cones of these blossoms echo the deep burgundy of the canna leaves.\n➍ ‘Flamenco Samba’ cuphea (Cuphea llavea ‘Flamenco Samba’, Zones 8–10)\nThis cuphea is a self-sower that surrounds the coneflower, and its blossom color is just a shade lighter than that of ‘Tomato Soup’.\n➎ Margaritaville™ yucca (Yucca recurvifolia ‘Hinvargas’, Zones 7–11)\nDrawing inspiration from the vibrant green foliage of the cuphea, Faye planted a variegated yucca next to it because of its distinctive green leaf margin.\n➏ ‘Dwarf Bright Gold’ Japanese yew (Taxus cuspidata* ‘Dwarf Bright Gold’, Zones 5–7)\nThe golden needles of this conifer complement the subtle yellow tones of the yucca blades.\n➐ ‘Solfatare’ crocosmia (Crocosmia ‘Solfatare’, Zones 6–9)\nWhen in bloom, the honey-colored flowers of this perennial are even more eye-catching with the golden-leaved yew as a backdrop.\n➑ Leatherleaf sedge (Carex buchananii, Zones 6–9)\nThe brown leatherleaf sedge picks up the smoky bronze tones of the sword-shaped crocosmia leaves.\nMake the space exciting but not peculiar. The goal of creating a distinctive front garden is for it to look like the colorful cousin of the neighborhood. The garden should relate to the community as a whole without abandoning any of the garden’s flair.\nTo identify many of the plants shown in this article, visit FineGardening.com/extras.\nSue Hamilton is an associate professor of horticulture at the University of Tennessee in Knoxville and director of the University of Tennessee Gardens. Andy Pulte is an arborist and horticulture instructor at the University of Tennessee.\nPhotos: Danielle Sherry. Illustration: Grace S. McEnaney']	['<urn:uuid:070af334-5108-4c1f-a51c-fe199c588a28>']	factoid	direct	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-13T06:27:57.068978	17	58	1390
87	feeding schedule rat snake ball python	Both ball pythons and rat snakes should be fed approximately once per week. Ball pythons start with half-grown mice as hatchlings and progress to adult rats, while rat snakes should be fed appropriately sized prey that matches the widest part of their body, with younger snakes being fed slightly more frequently than adults.	"['Royal (Ball) Python Care sheet\nThis article is reproduced with kind permission of Bob Clark of www.bobclark.com , Mr Clark is a legend in the world of pythons and Boas, he was the first person to breed albino burmese pythons in captivity and has created a huge variety of colour morphs within the python species.\nBall Python Primer\nAnswers to your keeping, feeding and breeding questions\nBy: Bob Clark\nIn the last several years, the popularity of ball pythons (Python regius) has skyrocketed. It\'s not surprising; the snakes have broad appeal. Their color, pattern, proportions and disposition make them one of the most commonly kept reptiles, and tens of thousands of them are exported every year from Africa. The snakes can endure some husbandry mistakes, and any first-time snake keeper should be successful with them.\nThe needs and requirements of animals in captivity are the same as their wild counterparts. However, it is impossible to duplicate the natural habitat of a wild animal with all the variables that the real world presents. Instead, we must focus our efforts on those requirements that are absolutely necessary for the animal\'s health and well being\nConsidering the huge geographic area in which python species are found, it\'s a little surprising that their requirements in captivity are so similar. Some are terrestrial, others are arboreal; some are from wetter areas, others frequent more arid areas; but most thrive in captivity under similar conditions. For that matter, most of the tropical boas do as well. Therefore, providing for the basic needs of a ball python is fairly simple, but it requires several pieces of equipment.\nIn The Cage\nThe first and most important item is the cage or enclosure itself. Its primary purpose, of course, is to safely contain the snake. Remember, the little guy has a lot of time on his hands, and if there\'s a way out, he\'ll find it.\nMy own cages began as an assortment of cracked aquariums with screen tops weighted down by books and bricks. Today, you can buy a variety of ready-made cages. It\'s also fairly easy to build an enclosure for your ball python or to convert a readily obtainable container into a cage.\nWood, plastic and glass are all acceptable materials for cage construction. I now use cages constructed of ABS plastic with sliding glass fronts. These cages have a nonporous finish that allows for easy cleaning and sterilization. All corners and edges are rounded, leaving no difficult-to-clean areas. The cages are lightweight and have glass fronts for easy viewing. Best of all, someone else made them already!\nBall pythons are terrestrial animals that rarely, if ever, climb. Floor space is more important to them than the height of the cage. A baby ball python can be kept comfortably in an enclosure the size of a shoe box. The largest ball python can live its life in a cage measuring 18 by 30 inches. These suggestions for cage sizes will meet the snake\'s minimum requirements. Larger cages are acceptable, but very large enclosures may cause some difficulties during feeding; sometimes it\'s difficult for the snake to find its food in a large cage. Also, it is more difficult to maintain proper conditions in a larger area.\nWhile the main purpose of a cage is to contain the snake, it must also enclose a suitable environment for its inhabitant. Proper temperature and humidity levels are essential for maintaining a healthy ball python. The ball python comes from a more arid environment than most pythons. Even so, it still requires a fairly high level of humidity. Ball pythons spend most of their time in burrows where it\'s more likely to be a little damp. When they leave, it\'s usually at night when temperatures are cooler and the level of moisture in the air is greater. The wild snakes do not expose themselves to the dry conditions that their natural environment presents. In captivity, when given a choice, they will do the same.\nBecause ball pythons are tropical animals, they prefer temperatures that are higher than most of us feel comfortable with in our homes. This makes it necessary to provide supplemental heat for the snake\'s cage. Temperatures in the 80s (Fahrenheit) are ideal.\nYou can provide heat in several ways. I use heat tape or place a heat pad under the cage. Light bulbs or ceramic heaters also snakes are color blind and that they might not be able to see the light from light bulbs with a red painted coating. I think the snakes are aware of the light, but at least they are not exposed to a 24-hour-long day (as they would be under a glaring white bulb). Heat pads and ceramic heaters do not emit light and are more efficient at converting electricity to heat.\nAt first, it might seem that providing an even level of heat throughout the cage would be most desirable, but it is not the case. In the wild, snakes have the opportunity to choose the conditions that they prefer or need at the time. We can provide some of these choices in captivity by placing the heat source on one end of the cage. This provides a range of temperatures for the snake. The temperature will be warmest next to the heat source and will become cooler as the snake moves further away. By giving the snake this gradient, it will have the opportunity to choose the temperature it needs at the time. A temperature range of 80 to g0 degrees Fahrenheit is ideal. The temperature of the heat source itself can exceed this range if the temperature range is otherwise satisfactory.\nTemperatures in the snake\'s natural habitat drop at night when the sun goes down. A small fluctuation at night is acceptable, even desirable, especially when breeding the snakes. When using an under-the-enclosure heater, make sure that it covers no more than 1/4 to 1/3 of the floor area. The snake must be able to move back and forth from the heat to the cooler areas of the cage. If you notice that the snake spends all of its time on one side of the cage or the other, the gradient may need some adjustment.\nThe temperature of the ball python cage can be controlled by a thermostat, a dimmer switch or just by matching the proper heater to the size of the cage. A thermometer is essential in monitoring the temperature of the cage. I get many calls from snake keepers experiencing problems with their snakes who do not even know the temperature of their snakes\' enclosures.\nThe temperature registered by the popular adhesive strip thermometers do not accurately register the temperature of the enclosure; instead, they measure the temperature of the wall itself. The wall or glass side of the cage is influenced as much by the temperature outside the cage as it is by the temperature inside the cage. The thermometer should be placed so that it gives the temperature in areas where the snake spends its tune. For ball pythons, this is at floor level. Temperatures in other locations are less relevant. If you do not use a thermostat, be aware that fluctuations in the temperature of the room where the snake is kept will cause a corresponding change in the temperature of the cage.\nThe amount of heat required to obtain the proper temperature depends on several variables, most notably the size and construction of the enclosure, and the placement and size of any vents. Larger cages will obviously require more heat, but there are also other considerations. Cages constructed of plywood retain heat more efficiently than those made of plastic or glass.\nSome ventilation is necessary, but both heat and humidity can be conserved by reducing the amount of ventilation in the enclosure. Vent placement is important. Because heat rises, vents placed on the top of the cage will allow more heat loss. This will require the heater to work harder to heat the enclosure and will reduce the humidity as the added heat dries the cage. Ideally, vents should be fairly small and placed on the sides of the cage. A glass aquarium with a commercially produced screen top, although commonly used to house other reptiles, can be a problematic enclosure in which to properly maintain a ball python.\nThe snake should have access to water at all times. Heavy ceramic bowls are difficult to tip. Those with larger surface areas help contribute to the cage\'s humidity level through evaporation. Place the water bowl on the warm side of the cage to enhance evaporation. The warm temperatures of the cage also promote bacteria growth, so it is important to keep the bowl clean and to change water regularly.\nThere are several acceptable substrates for ball python enclosures. I use newspaper because it is inexpensive, absorbent, relatively sterile and readily available. Some shredded wood products strike a better balance between utility and aesthetics. Aspen and pine are available in many pet stores, but you should avoid cedar. Cedar shavings, frequently used for rodents, may be toxic to some reptiles. Astroturf and similar products are easy to clean and sterilize and can be cut to the appropriate size. Naturally planted vivaria can be beautiful, but they are difficult to maintain and keep clean.\nChoose Your Captive\nIdeally, ball pythons should be purchased as captive-born hatchlings from breeders. As a breeder, myself, its a little self serving for me to say this, but it is still the best course of action. Animals produced in captivity do not deplete the wild populations and disrupt the natural system from which they were taken. Captive-born animals do not have the acclimation problems that wild animals often have. This transition can be especially difficult for adult ball pythons. Captive-born animals are free from parasites and the scars and injuries that come from living in the wild. They have avoided time in the care of exporters, importers and dealers that may not have given them proper care.\nBaby ball pythons are one of the most available reptiles in the market today and most of these are bred in the wild. In late April and May, babies are hatched from eggs collected from wild females in Ghana, Togo and Benin. These babies are exported in huge numbers. Even though they are bred in the wild, the eggs are hatched in captivity. Most are exported within days of birth. If they have been well cared for, they make perfectly good pets. The first-time snake buyer is most likely to encounter these snakes.\nWhen selecting a baby ball python, the snake should have good body weight and muscle tone. It should appear well hydrated and be free of remnants of the last shed. If possible, confirm that the snake has been feeding. Ball pythons are tremendously undervalued in the market today and, as such, are not always treated with the care and respect they deserve. If it\'s not possible to get a snake that has been properly cared for, at least get one that is ""fresh.""\nSome adult ball pythons imported from the wild have a difficult time acclimating to captivity. Often, they refuse food for extended periods. Ball pythons are long-lived animals. Their longevity record in captivity is nearly 50 years. This may or may not be typical, but it is possible that some of the wild-caught adults in the pet trade may be very old. The transition can be long and difficult for these animals. It is not hard to imagine the shock of a wild snake that finds itself in an aquarium in the bedroom of a 13-yearold in Cincinnati.\nNearly every one of these stubborn snakes eventually feeds. Several things can be done to help the snake acclimate. First, make sure the temperature and humidity are within an acceptable range. Next, give the snake a place to hide. Remember, these animals live in burrows in the wild. The ideal hide box should have a fairly small opening, be dark and allow the snake to feel hidden. This will reduce much of the stress in its life. The container should be small enough that the snake can feel the sides of it when inside.\nUnderstand that in the wild the snake would rarely be seen out in the open, where it is vulnerable to predators. In the snake\'s mind, you are a predator! Do not handle the snake until it has begun to feed regularly. Handling will extend the period of adjustment.\nIf the snake wont eat a mouse, try offering a rat. If a rat doesn\'t work, gerbils seem to entice many stubborn feeders. Remember that although the snake may have been feeding on mice and rats in the wild, our rodents are different species and might seem totally foreign. Many captive snakes learn to eat dead food, but it is rarely encountered in the wild. Try to feed the snake weekly; more often is counterproductive. Be patient. Some snakes may fast for a year or more.\nBaby ball pythons will feed readily on half-grown mice. The hatchling pythons are small and many first time keepers feel that smaller food items are appropriate. Although some will eat pinkie mice, a larger more active mouse is more likely to trigger a feeding response in a snake that has never eaten. Larger snakes can take larger mice, two mice, small rats and eventually adult rats. I have one large ball python that eats small rabbits on occasion.\nFeed the snake once a week. A little more or less is also good. I keep records of each snake\'s activities, noting feeding, shedding and breeding activity. These kinds of records can be used to help better understand or illustrate the snake\'s behavior over a period of time.\nSome ball pythons, especially wild caught animals, will fast from time to time even though they had been feeding regularly. This is not usually cause for alarm. Make sure all the cage parameters are correct, continue to offer food weekly, and be patient. Most resume feeding after a while.\nMost captive-raised ball pythons are willing breeders. Breeding can be encouraged by allowing the nighttime temperatures to drop into the 70s in the fall. Pairs will often breed soon after this temperature drop. Copulation occurs over a period of several weeks. Females develop follicles, ovulate and lay eggs over the next three to four months. Clutch sizes range from three to 12 eggs, and average about seven. Eggs can be incubated by the female or artificially in an incubator. At 90 degrees Fahrenheit, eggs will hatch after about 55 days.\nThere is little variation in the color and pattern of wild ball pythons, although there are some notable exceptions. Several of these have proven to be genetic. These traits are now bred and available to collectors. Many are highly sought after and carry high prices. Most have been bred from one, or just a few, wild-caught individuals. Because ball pythons have small numbers of offspring and breed once a year at most, it takes a long time for these new traits to become established and readily available. Several interesting types are currently available, and new ones continue to occur, although infrequently.\nThe ball python, because of its appeal, availability and price, has become one of the most commonly kept reptile pets today. They are docile, undemanding and thrive in captivity. In fact, I\'ve been keeping ball pythons for nearly 30 years, and they are still one of my favorites.\n(c) Bob Clark,', 'Rat Snake Care Sheet for Most North American Species\n© 2015, Brandon Cornett | All rights reserved\nWelcome to the rat snake care sheet. On this page, you\'ll learn almost everything you need to know about keeping rat snakes as pets. We will talk about caging, heating, feeding and more.\nThere are dozens or rat snake species that can be found all over the world. In this care sheet, we will focus on those snakes that are native to the United States. This information contained in this care sheet applies to the following animals:\n- Black rat snakes\n- Texas rat snakes\n- Trans-Pecos rat snakes\n- Other types of rat snakes, including corn snakes\nWhile these animals can be found in a variety of habitats throughout the United States, their care requirements are very similar. So let\'s talk about those requirements...\nIn a Nutshell: This rat snake care sheet contains a lot of detailed information. But that doesn\'t mean these snakes are hard to care for in captivity. On the contrary, they are some of the easiest snakes to keep as pets. All you need is an appropriately sized cage, a temperature gradient of 75 - 85 degrees (F), a couple of hiding places, a water bowl, and a steady diet of frozen / thawed rodents.\nChoose the Right Cage for Your Rat Snake\nTo begin our rat snake care sheet, let\'s talk about the fundamental piece of the habitat. Let\'s talk about the cage itself. The good news here is that you have plenty of cage options to choose from. A rat snake will thrive in a wide variety of cage setups. You can use a glass terrarium, a plastic reptile cage, or a homemade cage of your own design.\nI recommend one of the first two choices. In order to build your own cage, you would have to know a lot about (A) rat snakes and (B) carpentry -- if you wanted to build a proper cage, at least. Why go through all the trouble when you can buy a suitable cage for less than a hundred bucks?\nIf you have the money, and you want a beautiful and highly functional cage, I recommend buying one from Showcase Cages (www.showcasecages.com). I don\'t work for them, nor am I getting paid to plug their products. They just make a really nice product! Check out their website and see for yourself. They\'ve truly thought of everything when designing their reptile cages.\nIf you have a small budget, you can buy a glass terrarium at your local pet store. They come in a variety of sizes, and they\'re much cheaper than the plastic reptile enclosures mentioned above.\nIf you choose, you can use a smaller cage for the baby snake, and then upgrade to a larger cage as the snake grows. An adult rat snake will need a cage that\'s about three feet long by two feet deep. Rat snakes can be pretty active, and this amount of floor space will give them plenty of room to move around.\nIf you\'ve read other care sheets for rat snakes (or any pet snake for that matter), you\'ve probably heard about the importance of cage security. If your snake\'s enclosure has any gaps or weaknesses, the animal will get loose. A small rat snake only needs a hole the size of a nickel to escape -- or even smaller. And once they\'re out, they can be very hard to find. So make sure your cage is 100% escape proof. This is one of the reasons I recommend buying a cage, as opposed to making your own. A store-bought terrarium will usually have security features built in, such as a locking lid.\nLet\'s continue on with our rat snake care sheet to discuss another important cage consideration. Let\'s talk about how you can heat your cage -- and why you need to.\nHeat the Cage Properly\nSnakes need some form of supplemental heat in order to survive. By ""supplemental,"" I mean heat that is provided by some external source outside of their bodies. Your rat snake cannot warm itself from within, the way humans can. It relies on its environment for heat. In the wild, the snake would bask in the sun to warm its body. So when you keep a rat snake as a pet, you must duplicate this in some way. You must provide some kind of heat source that allows your pet snake to regulate its body temperature (i.e., thermoregulate). This is another important element of rat snake care, and it will help you keep your pet healthy for years to come.\nThere are many reptile products on the market today that can help you heat your snake cage. You can choose from a wide variety of heat lamps, ceramic heat emitters, and under-the-tank heating pads and tapes. How you choose to heat your rat snake cage will largely depend on the type of cage you\'re using. For my baby snakes, I like to use small glass terrariums with a single heat lamp on top, offset toward one side of the cage to create a temperature gradient. For my adult snakes, I use plastic cages with a similar heating setup.\nHow you control the temps in your snake\'s cage is not that important, as long as you achieve the proper temps in the cage. All of the North American rat snakes can be kept in the same temperature ranges. Aim for a thermal gradient between 75 degrees (Fahrenheit) on the cooler side and 85 degrees (F) on the warmer side. Maintaining a gradient like this is important for rat snake care. It allows your pet snake to choose the temperature it needs, the way it would in the wild.\nOffer Some Hiding Places\nUp until now, our rat snake care sheet has focused on the cage itself and how you would heat it. Let\'s talk about some of the things that will go into the cage, starting with the hides.\nIn the wild, snakes spend most of their time hiding in holes or under things. If you want your pet rat snake to be as healthy as possible, you need to duplicate this within the captive environment. You need to provide some hiding areas where the snake can retreat to when it feels overexposed or stressed.\nI\'ve written an entire article on the subject of snake hides, so I don\'t plan to repeat it all here. You can read this article to learn how to create suitable hiding areas for your pet snake.\nGive Your Pet Snake a Light Cycle\nI\'ll keep this section short and sweet, because there\'s not much to it. In the wild, snakes have a natural cycle of day and night -- light and darkness. So you should give your rat snake the same thing in captivity. If the room where the cage sits gets a lot of natural light from windows, this might be all you need. If the room doesn\'t get a lot of natural light, you can use a fluorescent light on the cage. You can even put it on a timer so that it comes on for about ten hours a day. Easy!\nYou don\'t need to buy any special UVB bulbs for your rat snake. Lizards and turtles need this kind of UV exposure, but snakes don\'t. They might benefit from such exposure, but they don\'t necessarily need it to survive. Of course, if you\'re like me and want to recreate the natural world for your snake as closely as possible, then you might want to use a UVB light bulb. It\'s optional.\nFeed Your Snake Every 7 - 10 Days\nLet\'s wrap up the rat snake care sheet with a topic of great concern for first-time snake keepers. Feeding.\nAs a general rule, you can feed your pet snake one appropriately sized meal every week. You can feed babies a little more often, and adults a little less often. Snakes need more food when they are growing, and they grow fastest during the first two or three years of life. So you can slow down the feeding program after that rapid-growth period.\nWhen I refer to an ""appropriately sized"" meal, I\'m talking about a mouse or rat that\'s about the same width as the widest part of your snake. Your snake is widest in the middle of its body, so try to offer rodents that are about the same girth, or slightly larger than that. If you offer a meal like this every seven days or so, you\'re in good shape.\nIt\'s also a good idea to wait until your rat snake poops from the first meal before offering another. This marks the end of the digestive process. Snakes usually poop once after a meal. So the pattern would go like this. Feed the snake. The snake poops a few days later. Wait a couple of days and then feed it again. This is the pattern I\'ve been using for many years. It works.\nIn most cases, captive rat snakes will generally accept frozen / thawed prey. This makes life a lot easier for you, as the keeper. Live rodents can be dangerous in a captive environment. Rodents can easily turn the tables and bite your pet snake -- especially rats. In the wild, a snake that\'s not in the mood to eat can avoid hungry and aggressive rodents. But inside a cage, there\'s nowhere for the snake to ""run."" So it can easily get bitten and injured. Rodent bites can be nasty, and they usually lead to infection. I think I\'ve made my point. Offer frozen / thawed rodents. They are easy to store, easy to thaw, and easy to offer. Just make sure they are completely thawed before you feed them to your pet rat snake. I put my frozen rodents in a small tub of warm water for 20 - 30 minutes. Then it\'s feeding time.']"	['<urn:uuid:026ca672-08a8-4fd0-95fe-1804b8efda11>', '<urn:uuid:8e0f238a-d060-41b4-a043-92fbbadb1a77>']	factoid	direct	short-search-query	distant-from-document	comparison	novice	2025-05-13T06:27:57.068978	6	53	4244
88	difference between generic drug approval normal drug approval	Regular drug approval through a New Drug Application (NDA) requires extensive clinical trials and complete documentation of drug safety, effectiveness, and manufacturing processes. In contrast, generic drug approval through an Abbreviated New Drug Application (ANDA) does not require preclinical and clinical data to establish safety and effectiveness. Instead, ANDA only needs to demonstrate that the generic product delivers the same amount of active ingredients into the bloodstream in the same time as the reference marketed drug (bioequivalence). This makes the generic drug approval process significantly less complex than regular drug approval.	"['New Drug Application\nThe Food and Drug Administration\'s New Drug Application (NDA) is the vehicle in the United States through which drug sponsors formally propose that the FDA approve a new pharmaceutical for sale and marketing. Some 30% or less of initial drug candidates proceed through the entire multi-year process of drug development, concluding with an approved NDA, if successful.\nThe goals of the NDA are to provide enough information to permit FDA reviewers to establish the complete history of the candidate drug. Among facts needed for the application are:\n- Patent and manufacturing information\n- Drug safety and specific effectiveness for its proposed use(s) when used as directed\n- Reports on the design, compliance, and conclusions of completed clinical trials by the Institutional Review Board\n- Drug susceptibility to abuse\n- Proposed labeling (package insert) and directions for use\nTo legally test the drug on human subjects in the U.S., the maker must first obtain an Investigational New Drug (IND) designation from FDA. This application is based on nonclinical data, typically from a combination of in vivo and in vitro laboratory safety studies, that shows the drug is safe enough to test in humans. Often the ""new"" drugs that are submitted for approval include new molecular entities or old medications that have been chemically modified to elicit differential pharmacological effects or reduced side effects.\nThe legal requirement for approval is ""substantial"" evidence of effectiveness demonstrated through controlled clinical trials. This standard lies at the heart of the regulatory program for drugs. Data for the submission must come from rigorous clinical trials.\nThe trials are typically conducted in three phases:\n- Phase 1: The drug is tested in 20 to 100 healthy volunteers to determine its safety at low doses. About 70% of candidate drugs advance to Phase 2.\n- Phase 2: The drug is tested for both efficacy and safety in up to several hundred people with the targeted disease. Some two-thirds of candidate drugs fail in Phase 2 clinical trials due to the drug not being as effective as anticipated.\n- Phase 3: The drug is typically tested in several hundred to several thousand people with the targeted disease in double-blind, placebo controlled trials to demonstrate its specific efficacy. Under 30% of drug candidates succeed through Phase 3.\n- Phase 4: These are postmarketing surveillance trials in several thousand people taking the drug for its intended purpose to monitor efficacy and safety of the approved marketed drug.\nThe legal requirements for safety and effectiveness have been interpreted as requiring scientific evidence that the benefits of a drug outweigh the risks and that adequate instructions exist for use, since many drugs have adverse side effects.\nMany approved medications for serious illnesses (e.g., cancer) have severe and even life-threatening side effects. Even relatively safe and well understood OTC drugs such as aspirin can be dangerous if used incorrectly.\nThe actual applicationEdit\nThe results of the testing program are codified in an FDA-approved public document that is called the product label, package insert or Full Prescribing Information. The prescribing information is widely available on the web, from the FDA, drug manufacturers, and frequently inserted into drug packages. The main purpose of a drug label is to provide healthcare providers with adequate information and directions for the safe use of the drug.\nThe documentation required in an NDA is supposed to tell the drug’s whole story, including what happened during clinical tests, what the ingredients of the drug formulation are, results of animal studies, how the drug behaves in the body, and how the company manufactures, processes and packages it. Currently, the FDA decision process lacks transparency, however, efforts are underway to standardize the benefit-risk assessment of new medicines. Once approval of an NDA is obtained, the new drug can be legally marketed starting that day in the U.S.\nOnce the application is submitted, the FDA has 60 days to conduct a preliminary review, which assesses whether the NDA is ""sufficiently complete to permit a substantive review."" If the FDA finds the NDA insufficiently complete (reasons can vary from a simple administrative mistake in the application to a requirement to re-conduct testing), then the FDA rejects the application by sending the applicant a Refuse to File letter, which explains where the application failed to meet requirements.\nAssuming the FDA finds everything acceptable, they decide if the NDA needs a standard or accelerated review, and communicates acceptance of the application and their review choice in another communication, known as the 74-day letter. A Standard Review implies an FDA decision within about 10 months while a Priority Review should complete within 6 months. The decision comes in a Complete Response Letter.\nRequirements for similar productsEdit\nBiologics, such as vaccines and many recombinant proteins used in medical treatments are generally approved by FDA via a Biologic License Application (BLA), rather than an NDA. The manufacture of biologics is considered to differ fundamentally from that of less complex chemicals, requiring a somewhat different approval process.\nGeneric drugs that have already been approved via an NDA submitted by another maker are approved via an Abbreviated New Drug Application (ANDA), which does not require all of the clinical trials normally required for a new drug in an NDA. Most biological drugs, including a majority of recombinant proteins are considered ineligible for an ANDA under current US law. However, a handful of biologic medicines, including biosynthetic insulin, growth hormone, glucagon, calcitonin, and hyaluronidase are grandfathered under governance of the Federal Food Drug and Cosmetics Act, because these products were already approved when legislation to regulate biotechnology medicines later passed as part of the Public Health Services Act.\nMedications intended for use in animals are submitted to a different center within FDA, the Center for Veterinary Medicine (CVM) in a New Animal Drug Application (NADA). These are also specifically evaluated for their use in food animals and their possible effect on the food from animals treated with the drug.\n- ""The Drug Development Process"". U.S. Food and Drug Administration. January 4, 2018. Retrieved May 1, 2018.\n- ""The Drug Development Process. Step 4: FDA Drug Review"". U.S. Food and Drug Administration. January 4, 2018. Retrieved May 1, 2018.\n- Commissioner, Office of the. ""Public Health Focus - FDA and Marijuana"". www.fda.gov. Archived from the original on April 28, 2018. Retrieved April 30, 2018.\n- ""The Drug Development Process. Step 3: Clinical Research"". U.S. Food and Drug Administration. January 4, 2018. Retrieved May 1, 2018.\n- ""The Drug Development Process. Step 1: Discovery and Development"". U.S. Food and Drug Administration. January 4, 2018. Retrieved May 1, 2018.\n- Food, Drug, and Cosmetic Act, Section 505; 21 USC 355]\n- 21 CFR 201.5: Labeling Requirements for Prescription Drugs and/or Insulin\n- ""Daily Med:Current Medication Information"". Archived from the original on November 12, 2008. Retrieved October 10, 2007.\n- Liberti L, McAuslane JN, Walker S (2011). ""Standardizing the Benefit-Risk Assessment of New Medicines: Practical Applications of Frameworks for the Pharmaceutical Healthcare Professional"". Pharm Med. 25 (3): 139–46. doi:10.1007/BF03256855. Archived from the original on February 6, 2012.\n- Kathie Clark (December 15, 2009). ""Updates from the Regulators:FDA"". The eCTD summit. Archived from the original on July 16, 2011.\n- ""Merck KGaA Receives Refuse To File Letter From FDA On Cladribine Tablets New Drug Application"". medicalnewstoday.com. Archived from the original on March 5, 2010. Retrieved April 30, 2018.\n- ""Archived copy"". Archived from the original on March 8, 2010. Retrieved February 23, 2010.CS1 maint: Archived copy as title (link)\n- ""Cadence Pharmaceuticals Announces Priority Review and Acceptance of NDA Submission for Acetavance for Treatment of Acute Pain and Fever"". drugs.com. Archived from the original on July 11, 2017. Retrieved April 30, 2018.\n- ""FDA, CDER Office of Generic Drugs"". fda.gov. Archived from the original on May 28, 2009. Retrieved April 30, 2018.\n- ""C&EN: COVER STORY - BEYOND HATCH-WAXMAN"". pubs.acs.org. Retrieved April 30, 2018.\n- Henninger, Daniel (2002). ""Drug Lag"". In David R. Henderson (ed.) (ed.). Concise Encyclopedia of Economics (1st ed.). Library of Economics and Liberty.CS1 maint: Extra text: editors list (link) OCLC 317650570, 50016270, 163149563\n- Chapter 11: Prescription Drug Product Submissions in: Fundamentals of US Regulatory Affairs, Eighth Edition 2013', 'There are two broad application categories for drugs and biologics regulated by the United States Food and Drug Administration (FDA):\n- requests for authorization for clinical investigations\n- requests for marketing approval\nThe Investigational New Drug (IND) application falls into the first category, while the New Drug Application (NDA), Abbreviated New Drug Application (ANDA), and Biologics License Application (BLA) fall into the second category. Over-the-Counter (OTC) drugs are regulated slightly differently, either by conformance with an established OTC drug monograph or via the NDA process. Here we describe the differences between these application types and some of the regulatory processes and considerations associated with them.\n1. Investigational New Drug Application (IND)\nThe IND is the launching point for clinical investigations in the United States and is an essential step along the path toward getting a new drug on the market. From the FDA’s perspective, the primary purpose of an initial IND submission is to ensure, as much as possible, the safety and rights of clinical trial participants.\nBesides allowing clinical investigations, the IND also performs an additional legal function. Because federal law states that only marketed drugs are permitted to be transported across states lines, the IND provides a legal framework that allows Sponsors to transport their investigational products to clinical investigators in different states.\nINDs may be categorized as either commercial or research. Commercial INDs allow for the development of a drug or biologic with the goal of ultimately submitting a marketing application. Research INDs involve therapies that are not intended for commercialization but are being investigated strictly for research purposes (e.g., to generate a publication or evaluate a potential mechanism).\nIn addition to these two primary designations, emergency INDs (a type of expanded access IND application) may be submitted by physicians to allow treatment of immediately life-threatening conditions when no standard acceptable treatment is available and insufficient time exists to receive Investigational Review Board (IRB) approval. Emergency INDs act upon a different timeline than other types of INDs.\nRegardless of the type of IND, all IND applications must include information about the quality and nonclinical safety of the investigational product as well as the proposed clinical protocol and investigator.\n2. New Drug Application (NDA)\nThe goals of the NDA are to provide enough evidence to support the safety and effectiveness of the drug and to show that the benefits of its use outweigh the risks. In addition, the FDA will review the proposed labeling for the drug (i.e., package insert) and determine if the manufacturing methods maintain the drug’s identity, strength, quality, and purity.\nData collected during the IND phase of the development program will become part of the NDA. However, the NDA is much more comprehensive than the IND and is expected to provide very detailed information about the drug. This includes primary data, reports, and summaries of the results of the nonclinical and clinical studies, analyses related to the body’s effect on the drug and the drug’s effect on the body (PK/PD), characterization of the drug’s ingredients and impurities (including any potential toxicities), and a description of all manufacturing processes and quality control parameters.\n3. Biologic License Application (BLA)\nJust as an NDA does for a small molecule drug (and select other classes), the BLA is a request for permission to introduce, or deliver for introduction, a biologic product into interstate commerce. BLAs are typically regulated by FDA’s Center for Biologics Evaluation and Research (CBER).\nSimilar to an NDA, the BLA contains specific and detailed information on the manufacturing processes, chemistry, pharmacology, clinical pharmacology, and the medical effects of the biological product.\nExamples of biological products that would be subject to BLAs include monoclonal antibodies for in vivo use, cytokines, growth factors, enzymes, immunomodulators, thrombolytics, therapeutic proteins, and non-vaccine immunotherapies.\n4. Abbreviated New Drug Application (ANDA)\nAn ANDA is submitted to the FDA for the review and approval of a generic drug product. ANDAs are regulated by FDA’s Office of Generic Drugs (OGD) and are considered abbreviated, as they generally are not required to include preclinical (animal) and clinical (human) data to establish safety and effectiveness.\nInstead, an ANDA only needs to demonstrate that the generic product performs in a similar manner to the reference marketed drug (commonly referred to as the Reference Listed Drug [RLD]) that appears in FDA’s Orange Book. Specifically, the generic drug must deliver the same amount of active ingredients into the bloodstream in the same amount of time as the reference product (this is known as bioequivalence) or it must demonstrate therapeutic equivalence if not bioavailable.\nOnce approved, an applicant may manufacture and market the generic drug product to provide a safe, effective, low-cost alternative to the branded product.\n5. Over-the-Counter (OTC) Application\nOver-the-counter (OTC) drugs are defined as drugs that are safe and effective for use by the general public without needing a prescription from a health care professional. FDA’s review of OTC drugs is primarily handled by FDA’s Office of Nonprescription Drugs (ONPD).\nThere are two pathways by which marketing of OTC products may be achieved:\n- Compliance with an OTC drug monograph\n- Approval under an NDA or ANDA\nAn OTC monograph is a set of regulatory standards for different therapeutic drug classes that includes acceptable ingredients, doses, formulations, and labeling requirements. If the standards of an applicable OTC monograph are met, marketing pre-clearance is not required by the FDA. If the OTC drug deviates from the final monograph, however, a formal marketing application (e.g., NDA) or citizen petition may be used to request approval.\nIt is important to understand the various types of drug applications and when each application is necessary. Nuventra consultants have extensive experience across the various application types and approval pathways for a wide variety of drugs and biologics. If you aren’t sure which application you need or if you need help authoring, reviewing, or submitting an application – we can help. Contact us today to see how we may assist with your drug development needs!']"	['<urn:uuid:533abac9-692c-499a-87d7-9a087ebf7ea3>', '<urn:uuid:152d5745-3cc0-4d9e-9ce7-7df7ade1c417>']	open-ended	direct	short-search-query	distant-from-document	comparison	novice	2025-05-13T06:27:57.068978	8	91	2350
89	What security measures are used for WordPress websites?	Several key security measures are used: renaming the default 'admin' account to reduce automated attacks, setting up individual personalized accounts with activity logging to create audit trails, installing plugins that encourage strong password use, and avoiding services that manage multiple websites from one account since that creates a single point of failure. Additionally, regularly updating WordPress and its plugins is critical since out-of-date sites are at high risk of being hacked through unpatched vulnerabilities.	['Rocket Lift Security\nPutting Security into Practice\nRocket Lift believes in taking security on the Internet very seriously.\nSecurity is hardly the same thing as, and is often quite in opposition to “secrecy”. This is one reason why we value “Openness”, which means we promote open technologies, open data, and operational transparency. This allows the effectiveness of our security procedures and tools to be independently verified. By being open about how we work, we put this value into practice, and we even invite scrutiny from you — our friends, competitors, and customers — to improve how we work.\nFrom Rocket Lift’s inception — years before Edward Snowden’s revelations about widespread U.S. government surveillance of internet traffic — we have treated our clients’ information as top secret. The integrity of our own systems directly impacts that of your systems, which in turn directly impacts the safety and security of every one of your users, viewers, or customers.\nWe bend over backwards to protect sensitive information from loss at our hands, to reduce the risk of a cascading breach that effects not just you, but everyone who depends on you. And we don’t want you to “just trust us”. We want you to be able to verify that trust yourself.\nProtecting the Keys to your Kingdom\nAlways discouraging people from sending us confidential information by unsafe means.\nIntercepted passwords are the easiest way to have your site hacked and sensitive information stolen. We discourage sending passwords via plaintext email, instant message, text message, or verbally over the telephone, as it is easy for such information to be intercepted and recorded. We work with you to make sure you have the tools necessary to communicate with us as securely as possible.\nSecure Instant Messaging\nFor instant messaging, we use the XMPP/Jabber open standard, with SSL/TLS connections to the Jabber server and verified OTR sessions between individuals.\nDecentralized P2P and/or Self-Hosted Internal File-sharing\nOur sensitive company and client records are not stored using third party “cloud” service providers (such as Dropbox), because they cannot realistically guarantee that their staff do not have access to senstive data stored with them or that they have not provided a backdoor for government agencies.\nWe currently use a private encrypted peer-to-peer file sharing system that gives us the benefits of remote team file sharing. We do not know of any independent security audits of the protocol or of its clients, so we won’t publish the name of the specific service. If you are aware of research into the security of encrypted peer-to-peer file sharing services, we would love to hear about it.\nNon-logged, Self-destructing Private Messages\nWe use self-destructing, self-expiring messages provided by Lockify to share sensitive information even over encrypted channels, so that nothing is stored in anyone’s message logs (which if accessed later would defeat encryption). Even Lockify staff are unable to access content in these messages, and the messages require you to prove your identify to access them.\nEncrypted Password Databases\nOur team stores all sensitive data in encrypted databases, protected by ludicrously long passwords, and encrypted using open industry standards configured to run enough “rounds” of encryption that even our most modern computer hardware pauses for a moment while attempting to authenticate and access their information. The database software is also completely separate from the software that maintains our company’s shared file systems, so even if the file system’s network were compromised, third parties would still not have access to password data.\n100% Unique, Randomly-generated Passwords\nEvery password we ever create is randomly generated and unique. If the password to one of our accounts for a client became known, access to other services for that client, and to other clients’ services, would remain protected.\nWe group private information in small lockers that are accessed one at a time, so accessing any private data locker only exposes a small amount of information. This limits the impact of a data breach, so even if an attacker gains some of our information, most of it is still locked. We employ this data “compartmentalization” at every practical level, with only those who require it having access to various things. This creates some routine inconvenience and extra configuration work for ourselves, but we’ve embraced that. We believe it is worth shouldering some extra burden to maintain the principle of “least privilege”, whereby our staff and contractors only have the privileges they absolutely need to do their work, in order to limit access, and thus risk.\nSeparate Accounts for Every Client\nWhenever possible, we access systems and resources using individual accounts, access control lists, and/or key files — rather than sharing account names or passwords. Similar to compartmentalization, this limits the impact of a data breach, so that a successful attacker is limited in what they have access to.\nWe have procedures in place to change passwords whenever they are potentially compromised, including when we’re alerted by our service providers of a potential data breach, and whenever one of ours staff or contractor team members leaves Rocket Lift.\nKeeping Ears to the Ground\nNothing is perfectly “secure” or “insecure”. Security is not black and white, but quite complicated, and better thought of as a spectrum from “less secure” to “more secure”. We follow developments in the security research community and regularly evaluate new services and practices that can improve our position on that spectrum.\nContinual Training and Education\nSecurity conscientiousness is part of our culture. Our team members and contractors receive regular trainings beginning the day they start with us.\nEvery WordPress release includes patches to fix recently identified security vulnerabilities. Out of date WordPress sites are ticking timebombs, with a high risk of being hacked through their unpatched vulnerabilities. We highly recommend keeping WordPress and its plugins updated. (Our services include assisting with this, including identifying and fixing update compatibility issues, to ease the pain a bit).\nMany small “safes” instead of one large one.\nWe avoid using services that manage access to a bunch of separate websites from one account, such as managewp.com, which allows you to upgrade multiple WordPress websites from one dashboard. These types of services amount to a single point of failure. If an attacker gained access to our master account with these services, she would then have full access to do damage to any client sites we manage.\nWe prefer to “sandbox” access to our client sites, so that if one site is compromised, they aren’t all affected. You can think of this as using many small safes, instead of using one large safe with everything precious inside. If the large safe is lost, so is everything precious. Many small safes spreads this risk around and minimizes any harm.\nRenaming the Default User Account\nWordPress sites are under constant attack by armies of enslaved computers (called “botnets”) attempting to guess their way into the backend with random combinations of usernames and passwords. One of their simple tricks is to attempt to log in as “admin”, guessing common passwords. By renaming this default account, we reduce this threat.\nWe set up individual personalized accounts for our clients — e.g. “Jayne” instead of “admin” — and use activity logging plugins that create an audit trail of each user’s activity. In the event a user account is compromised, this allows us to isolate and re-secure it. We’re also able to detect and block repeated attempts to guess passwords.\nEncouraging and Enforcing Strong Passwords\nThe weakest spot in any WordPress website’s armor is an easily guessed password. So, we install plugins that encourage the use of strong user passwords, and provide education about why this is important and how to make it easier to create passwords that are both easy to remember and secure. Where appropriate, we can also require the use of strong passwords.\nOptions to Easily Restore Broken or Hacked Sites\nWe prefer plugins that are actively-maintained, scrutinized by the development community, and popular. These are less likely to have unpatched vulnerabilities. When our budgets permit it, we subject third-party plugins to code review and submit fixes back to the plugin authors.\nAdapting and Evolving\nThe adage that “the only constant is change” is one that we acknowledge and embrace. We know that nothing is perfect, nothing is absolute, and that there is always room to improve. We’re also deeply aware of how quickly the software world advances, how quickly web and internet technologies change, and how something that was considered “safe enough” today could very well be horribly broken tomorrow. We keep our eyes on current events in the cryptography and information security worlds, do our best to learn from everyone’s mistakes and examples, and greet each shiny new thing with healthy doses of both hope and skepticism.']	['<urn:uuid:8f7acc37-3261-4504-990f-d91ba89d047b>']	open-ended	direct	concise-and-natural	distant-from-document	single-doc	novice	2025-05-13T06:27:57.068978	8	74	1453
90	How do tax planning strategies help Americans working overseas save money, and what role do electric vehicles play in reducing their environmental impact abroad?	Tax planning helps Americans working overseas save money through various mechanisms like the Foreign Earned Income Exclusion, which can exclude up to $112,000 of foreign earned income, and the Foreign Tax Credit, which provides a dollar-for-dollar offset against U.S. income taxes. Regarding environmental impact, electric vehicles are increasingly adopted worldwide as part of efforts to reach net-zero emissions under the 2015 Paris Agreement. EVs help combat climate change by reducing carbon emissions from transportation, with projections indicating electric passenger cars will reach 200 million by 2030.	['People rarely think of taxes, and it’s safe to assume that there are even fewer people that plan for them. However, tax planning is just as important as tax filing.\nTax planning allows you to be more strategic when filing your taxes as an expat while ensuring you’re not paying more than you need in a foreign country or the U.S. On the other hand, putting off tax planning may lead to confusion, mistakes, and missed deductions.\nThis article will discuss tax planning in-depth to help you better understand the benefits of tax planning and avoid costly mistakes that can lead to tax penalties and more.\nWhat is Tax Planning for Expats?\nTax planning refers to analyzing your financial situation and developing strategies for proper tax management. Here, tax preparation services can help reduce your tax liability and maximize your tax advantages. Tax planning also prevents you from being taxed twice for the same income.\nFor instance, tax planning can help you qualify for tax exemptions that exclude all or part of your foreign-earned income if you meet statutory foreign residence or physical presence abroad tests.\n4 Types of Tax Planning\nTax planning is not a one-size-fits-all strategy. It will ultimately depend on the purpose, income, or assets involved, and tax savings and benefits you may potentially enjoy.\n- Purposive Tax Planning\nPurposive tax planning involves using tax-saver instruments to obtain the maximum benefit from any investment. The key is making correct investment selections, scouting for suitable replacements for your assets, and diversifying business and income assets based on your residential status.\n- Permissive Tax Planning\nPermissive tax planning is when you make permissible plans under different laws’ provisions. Your strategy may focus on how to earn income, take advantage of various incentives and deductions, avail of other tax concessions, etc.\n- Short-Range Tax Planning\nShort-range tax planning refers to the process you undergo at the end of the fiscal year. This is where you legally search for ways to limit your year-end tax liability. Although this method does not cover long-term commitments, it can still provide immediate and considerable tax savings.\n- Long-Range Tax Planning\nWith the long-range tax planning method, you draw your plan at the beginning of the fiscal year and follow it throughout the year. This method will benefit you in the long run. However, unlike short-term tax planning, it does not offer immediate tax benefits.\nTax Planning for Expats 101: How to Be in Control of Your Taxes When Working Abroad\nRegardless of your tax planning method, you must follow essential steps to get your taxes done as an expat.\n1. Identify the filing requirements\nThe first step to being in control of your taxes is knowing the tax filing requirements for U.S. expats. American citizens and alien residents in foreign countries must follow the standard rules and tax forms when filing U.S. income tax returns.\nYou must generally file a return if your gross income exceeds the filing requirements. In addition, remember that all compensation you earn abroad is included in your gross income when determining your tax amount.\nFurthermore, you must file a tax return even when your foreign deductions equal or exceed your gross income or when credits, such as the foreign tax credit, eliminate your U.S. tax liability. So, you also have to know what your foreign exclusions are.\n2. Special foreign exclusions\n- Foreign Earned Income Exclusion: These are wages, salaries, professional fees, or compensation paid to you for personal services you have rendered. These can be excluded from your income up to an amount adjusted for inflation.\n- Foreign Housing Expense Deduction: These deductions can be taken from your gross income if your tax home is in a foreign country.\n3. Moving and travel expenses\nReimbursements for your move to a foreign country will generally be considered foreign-source income. Hence, it will qualify for FEIE.\nIn addition, reimbursement for travel expenses to move back to the U.S. can also be considered a foreign-source income. This is possible if a written agreement between you and your employer states that they will reimburse such expenses whether or not you continue working for them.\nFurthermore, if you have sold your principal address in the U.S. as a result of being transferred abroad, you may be able to receive additional tax exclusions.\n4. Principal residence\nIf you are unmarried, you can exclude up to $250,000 from your earned income if you have gained from the sale of your principal residence. Your tax exclusion can be up to $500,000 if you’re married.\nTo qualify for this exclusion, you must have owned and occupied your primary residence for at least two years preceding the sale. However, taxpayers who fail to meet the two-year requirement because of unforeseen circumstances may still be eligible for a portion of the exclusion.\n5. Alternative minimum tax\nThe alternative minimum tax (AMT) prevents taxpayers who earn substantial economic income from using excessive deductions, exemptions, and credits. AMT is considered a separate tax levied on certain income and deductions, and you must pay it if it exceeds the regular threshold.\nAMT can significantly affect U.S. expats that exceed the exclusion amounts. This provision may entitle you to a foreign tax credit, which can reduce your U.S. tax dues.\n6. AMT credit\nOnce you pay AMT, it may be allowed as a credit against regular tax in later years, but this will only provide temporary relief on your regular tax.\nFurthermore, AMT credits and foreign income tax deductions provide nearly the same tax deduction opportunities. So, in the years you are subject to AMT, it may be better to elect a foreign tax credit.\n7. Foreign tax credit\nAs a U.S. expatriate, you can deduct foreign income taxes when computing taxable income or claim them as a credit against your U.S. income tax. Moreover, using a foreign tax credit often results in lower taxes than deductions from foreign income taxes, as a foreign tax credit permits a dollar-for-dollar offset against U.S. income taxes.\nWith this provision, you can credit the taxes imposed by a foreign country or its political subdivisions. As a result, you must either deduct all foreign income taxes or take credit for them each year. You could switch between taking deductions one year and then taking credits the following year if you do it before the allowable period lapses.\n8. Tax equalization policies\nTax rates significantly vary worldwide. For instance, in Germany, the highest rate for individuals is 45%, while in other countries, the overall rate generally never exceeds 25%. On the other hand, a few nations, such as Saudi Arabia, have no personal income tax at all.\nNot knowing the tax policies of a foreign country may increase your uncertainty and indecision when determining whether to accept the assignment or include a deduction or credit.\nFortunately, many U.S. companies with operations abroad have adopted tax equalization policies for U.S. employees on foreign assignments. Under this policy, your employer will assume responsibility for your U.S. and foreign income taxes. However, in exchange, you pay the company a speculative tax equal to the amount you would have paid in U.S. income tax.\nTypically, you will pay an amount similar to what you have withheld. However, this rule has notable exclusions, which you can learn by diving into payroll taxes and special situations.\n9. Payroll taxes and special situations\nGenerally, a U.S. employer must withhold income taxes from U.S. citizens regardless of where they perform their services.\n5 Benefits of Tax Planning for Expats\nTax planning has multiple benefits. Going through the whole process allows you to see every aspect of your taxes as an expat. Here are some tax planning benefits:\nOne of the benefits of tax planning is tax deductions. Tax deductions are usually expenses you incur throughout the year. These are expenses you can subtract from your total income, allowing you to reduce your taxable income.\nFor example, a Foreign Housing Deduction can increase your exempted income by the amount of your qualified housing expenses for U.S. expatriates. Likewise, a Tax Treaty Deduction can prevent the U.S. government from taxing foreign-sources dividends, interest, or royalties income already taxed in your resident country.\nRebates are forms of refunds that transpire after a retroactive tax reduction. For example, Congress occasionally offers rebates to help stimulate the economy during financial recessions or uses rebates to incentivize environmentally friendly company practices.\nFor example, the U.S. government launched a recovery rebate available for the 2020 and 2021 tax years. They issued this rebate for any amount of Economic Impact Payments or Stimulus Relief Payments you were eligible for but didn’t receive.\nCredits will allow you to subtract from the total tax you owe. If you are a student, have children, or are from a low-income household, you may qualify for a tax credit.\nAn excellent example of credit for expatriates is the foreign tax credit. You can use the foreign tax credit if you work abroad and pay income tax in your local jurisdiction. This will help you avoid paying the same income twice.\nA tax concession is when a government reduces the amount of tax a particular group of people owes. Governments usually use these concessions to incentivize specific behavior.\nFor example, the Saver’s Credit incentivizes people to save money. This provision allows working-class Americans who manage to put together some savings to have a tax break when they fill out their returns.\nExemptions can reduce or eliminate your responsibility to pay taxes. For example, for 2022, the FEIE may exclude up to $112,000 of your foreign earned income if you qualify for the Physical Presence Test or Bona Fide Residence Test for living outside of the U.S.\n5 Possible Pitfalls When Tax Planning\nFor you to have a solid tax plan, keep an eye out for these possible tax mistakes or issues you might encounter:\n1. Not maximizing the provided tax deductions\nNot maximizing your tax deductions is one mistake you can make when tax planning. Contributions to charity are an excellent example of tax deductions you might forget to consider.\nFurthermore, you can track out-of-pocket expenses you incur while doing charitable activities. For example, you can include the cost of food preparation, the cost of delivering your donations, etc. Then, you can add those costs to your cash contributions when computing for your deduction.\n2. Thinking that all tax plans are the same\nThinking that all tax plans are the same is not unusual in tax planning. However, falling into this pit may cost you some valuable deductions and exemptions.\nFor instance, if you plan to maximize the benefits you get from your investments, you could leverage purposive tax planning. This will help you make the proper investment selections, asset replacements, and income diversification to save you plenty in taxes in the long run.\n3. Feasibility of the tax plan\nThe feasibility of your tax plan is among the most crucial factors to the success of your tax planning. If your tax plan is not feasible, chances are you won’t get the benefits of your tax plan. Even worse, it may cost you more.\nFor instance, if you are leaning toward a permissive tax plan but don’t or can’t qualify for the requirements of the loopholes, then your tax plan is not feasible and may cost you valuable money and time.\nLikewise, if you are looking to use a purposive tax plan but are not liquid enough to make suitable investments, you won’t be getting the most benefit from your assets or none at all.\n4. Ignoring tax plan loopholes\nSome expats ignore tax planning loopholes that can provide them with essential deductions, exclusions, and credits.\nAgain, you can counter or erase your U.S. income taxes with the following:\n- Foreign Earned Income Exclusion\n- Foreign Tax Credit\n- Foreign Housing Exclusion\nAs a general rule, don’t pay tax on your income twice! If you get taxed twice on the same income, you could look into possible loopholes that can save you money from taxes.\n5. Trying to do it all yourself\nIt might be tempting to do all your tax duties yourself to save money. You can opt to do everything from tax planning and computing to filing returns and making payments, but if you don’t know the ins and outs, it could cost you exponentially more than what you would save if you were to do it yourself.\nRather than braving taxes yourself, getting tax preparation services can ensure that you have a good tax planning strategy before tax time. That way, you can dodge the possibility of any costly mistakes.\nStrategic Saving with Expat Tax Planning\nExpats have numerous factors to consider when doing their taxes, and it doesn’t help that these elements are both overwhelming and confusing.\nIf you’re not used to doing your taxes, it’s easy to miss a deduction or exclusion that could have saved you thousands of dollars. Likewise, it’s also just as easy to make a wrong tax plan and jeopardize your filing for the fiscal year.\nFortunately, you can evade these possible headaches by contacting a tax resolution partner such as Tax Samaritan, a best-in-class U.S. expat tax services provider for Americans abroad.', 'Utilities in the age of electric vehicles\nUtilities in the age of electric vehicles\nUtilities in the age of electric vehicles\nThe impact of vehicles on the environment has driven regulatory mandates to adopt a more sustainable way of commuting. As a result, electric vehicles (EVs), and the necessary infrastructure to operate them, has changed the automobile and utility industries over the past decade.\nElectric vehicles are powered by a charged battery pack and can be separated into two categories:\n- Battery Electric Vehicles (BEVs): These EVs are purely electric with lithium ion batteries suitable for short to medium distances.\n- Plug-In Hybrid Electric Vehicles (PHEVs): Electric vehicles with an internal combustion engine (ICE) with support from a small electric motor.\nWhy Electric Vehicles?\nThe 2015 Paris Agreement has challenged countries to reduce their carbon emissions to “net zero” over the coming years. This international treaty has prompted governments around the world to phase out gas and diesel powered vehicles, shifting instead to EVs:\nSales of electric vehicles have grown steadily over the last decade. The following chart from the International Energy Agency shows China leading market share at 47%. Twenty other countries have reached a market share of above 1%: emissions. As a segment, the automobile industry can tout sustainability and the environmental benefits of emerging technologies to entice consumers to buy EVs.\nAccording to a study by IRENA (International Renewable Energy Agency) on EVs:\n- Electric passenger cars will reach 200 million by 2030\n- Electric two-wheeled and three-wheeled vehicles could outnumber four-wheeled vehicles, with as many as 900 million on roads by 2030\n- Electric buses and light-duty vehicles could surpass 10 million by 2030\nFactors Contributing to EV Adoption\n1. Consumer Interest:\nEco-friendly consumers who want to decrease their carbon footprint prefer to buy EVs. Transportation around the globe is one of the biggest contributors of carbon emissions. As a segment, the automobile industry can tout sustainability and the environmental benefits of emerging technologies to entice consumers to buy EVs. A 2019 international electric vehicle consumer survey (of 7,600 consumers in seven regions) shows consumer interest in electric vehicles is high. 50% of consumers say they’re interested in owning an EV and 28% say they’ll purchase one as their next vehicle.\nConsumer benefits to owning electric vehicles:\n- Reduced operating costs, lower charging prices and simpler maintenance\n- Quieter driving experience\n- Exemption in Clean Air Zones – areas that charge fees to vehicles that pollute the environment\n- Government subsidies that make EVs cheaper than ICE vehicles\n- Preferential parking permits in dense urban areas\nEV technology has vastly improved. Range limitations and charging times have been addressed, alleviating concerns and increasing purchase momentum. Consider these three, top selling EV models in the world in 2020:\n3. NetZero Target:\nIn support of the 2015 Paris Agreement, utility and automobile companies are working to achieve net-zero emissions. To do this, they’re offering customers low-carbon products such as renewable electricity and electric vehicles. By taking advantage of these offerings, individual consumers can reduce their carbon footprint. Businesses can reduce their overall cost of fleet ownership, and organisations can reduce fuel costs, reap tax benefits and take advantage of government incentives.\nChallenges for Utilities:\nEVs help combat climate change. However, barriers to adoption exist:\nCharging Pricing: An increase in the number of electric vehicles can lead to disorganised charging. This makes peak shaving difficult, creates incremental costs for generators, increases transmission and distribution pressures and reduces grid reliability and security. It also degrades power quality and increases the harmonics of the grid. Ultimately, an unreasonable pricing structure can lead to its failure. A dynamic pricing strategy can help utilities overcome the challenges of EVs and can reduce the burden of power on a grid.\nComplex Billing: EVs also present billing challenges for utilities:\n- Number of Stakeholders: Charging hosts, charging point operators, eMobility service providers, roaming network providers, etc. are all involved in the billing process. These stakeholders have to manage multiple plans – pre-paid, postpaid, ad hoc, group plans, etc.\n- Customer Type and Charging Location: Plans offered will vary based on customer type such as individual, fleet, business, public and private. They’ll also vary based on location, including home, office, fleet charging center, parking lot, multi-tenant unit, municipal location and more.\n- Price Per Charge: The customer can be charged based on charge point, price per kWh or by minute/ hour (flat fee). The charging session may include ancillary fees such as a connection fee or a waiting fee for staying connected after reaching a full charge.\nCharging Infrastructure: The mechanics of charging pose challenges to utility companies:\n- Network: Availability remains limited\n- Technology: Fast-charge still in its initial stage and widely unavailable in the network\n- Customer Experience: Unpredictable charging experience negatively affects customer opinion\nService and Maintenance: Electric vehicles require specialised mechanics who are still difficult to find. According to a study done by UK’s Institute of the Motor Industry (IMI), 97% of today’s mechanics aren’t qualified to work on electric vehicles. Of the 3% of mechanics who do qualify, many work directly for EV dealerships, limiting service options for general EV buyers.\nHigher Upfront Investment: Higher manufacturing costs vs. the cost to make a combustion engine vehicle make EVs more expensive to buy. This sticker shock feeds consumer doubt about the long-term economic benefits of an electric vehicle. Government subsidisations help alleviate that doubt, but total consumer buy-in will take time.\nThe Utility Opportunity\nAs more people switch to electric cars, the impact of EV charging loads on generation, transmission and distribution networks translates into more energy and more revenue opportunities for utility companies.\n- Charging Infrastructure: Utilities can play a vital role in modulating charging rates and shifting charging times to provide grid services that support supply and demand. Consider these energy giants already investing in charging infrastructure:\n- Shell recently announced the rollout of 500,000 electric charging stations over the next four years.1\n- Ecotricity a “Big Six” UK energy supplier, partners with Moto, RoadChef and Welcome Break to offer 45-minute fast-charge stations. They call the network “The Electric Highway.”2\n- In the UK, companies like Centrica are building out their EV charging capabilities by acquiring smaller independents. Centrica invested in Driivz, a software company that manages EV fleets and charging networks, to create Centrica Electric Vehicle Services (CEVS) 3\n- New EV Tariffs: Consumer tariff structures (e.g. time-of-use tariffs) reward consumers who slow-charge during off-peak hours. These tariffs, which reduce consumer bills and prevent overloads on the grid, help influence EV drivers to shift their charging behavior. By partnering with EV manufacturers, utility companies can create custom electricity tariffs that can be bundled into the purchase of an electric vehicles. Energy suppliers in the US, UK and other European countries have already begun offering EV energy tariffs.\n- Improved Customer Experience: Careful planning, phased execution and synergy with non-utility businesses can help electric utilities facilitate a smooth transition to EV adoption. With the right customer relationship management (CRM) platform in place, utilities can offer consumers “charging ecosystems” – chargers, charging plans, etc. - for their vehicle. This positive consumer experience, combined with the financial upside of aligning with non-utility companies, translates into increased revenue for the utility company.\n- Vehicle-to-Grid (V2G): While EV tariffs can prevent overloads by shifting charging behavior, they also present challenges. If too many EV drivers charge during off-peak times, it can spike load levels and lead to grid congestion. To counter this, vehicle-to-grid (V2G) enables energy to be pushed back to the power grid from the battery of an electric vehicle. This helps balance the variations in energy production and consumption. Furthermore, V2G can support the integration of renewable energy resources into the grid.\n- AI Driven EV Marketing: With electric vehicle purchases on the rise, utilities must position themselves at the forefront of energy innovation to ensure brand credibility. AI-driven marketing helps identify crucial digital touchpoints for targeted messaging.\n- Data Advantages: Utilities can use data analytics and data science tools to develop services, applications and hyper-personalised product offerings. They can also leverage the data to expand into non-core markets. This allows for:\n- Joint offerings with automotive companies\n- After sales services in conjunction with car dealerships\n- Installation of charging stations at locations where customers park electric vehicles for more than an hour\nGlobally the uptake of electric vehicles is leading to the transportation and electricity sectors becoming increasingly connected.\nEven though barriers to EV adoption exist they are phasing out due to technological advancements. Innovation is the key in identifying opportunities to minimise costs and reducing pain points.\nFor utilities the biggest challenges is to ensure grid reliability and resilience. Providing a successful infrastructure for EV adoption will require coordination among various parties - Vehicle & charging manufactures, Electricity service providers, Distribution network operators, and Regulatory authorities\nIn the long run - Utilities that invest in electric vehicle infrastructure and technology will be well-equipped to offer solutions that benefit future customers.\n2Ecotricity and Nissan install UK electric-car-charging network | Guardian sustainable business | The Guardian\nEXL Utilities Academy']	['<urn:uuid:574f89d1-d63f-46fe-a5d2-b33fb9f074df>', '<urn:uuid:dc7f0a0b-46cd-416c-b618-7a830371a8fd>']	factoid	direct	verbose-and-natural	distant-from-document	multi-aspect	novice	2025-05-13T06:27:57.068978	24	86	3720
91	I'm researching historical slap bass patterns and their terminology - could you explain how Nicolas defines and differentiates between the various slap patterns in his playing?	Nicolas defines several distinct slap patterns: 'simple slap' is when slapping the bass just with the fingers; 'double slap' involves hitting the fingerboard with the palm once between two notes; 'triple slap' means hitting twice between notes; 'quadruple slap' involves three palm hits between notes; and 'drag slap' creates a quick triplet effect. He also uses a 'pull-slap' pattern, which is a variation of drag slap with an open G that adds a velocity effect. Additionally, he employs a 'quadruple drag' pattern that starts with the back of the pinky, then uses thumb and palm at the end.	['After putting Atomic Boogie, my promo video at the time, on YouTube, I began receiving a lot of emails from fellow slap bassists. The email that stood out the most was sent to me by French bassist Nicolas Dubouchet.\nFrom the email, I immediately noticed that Nicolas and I share a passion for the playing of another great slap player – Gilles Chevaucherie. I was especially interested to hear Gilles’ early recordings, so Nicolas mailed me a CD. He also modestly sent me a few recordings of his Rockabilly band Charlaz. I was immediately blown away by his technique and musicality, but what impressed me the most was his unique style. I had to wonder why no one ever talks about this guy, considering his great chops and sound. As a matter of personal taste, he happens to have recorded one of the best versions of “Big Noise from Winnetka” that I’ve ever heard!\nOver time, Nicolas and I stayed in touch and become good friends. I’m proud to present to you here, on the Art of Slap Bass, for the first time ever:\nDjordje: Salut Nicolas!\nWhen did you start and what inspired you to play double bass?\nNicolas: Hi Djordje!\nI started when I was about 12 years old, and because of two big events. First, during my summer holidays I used to see traditional jazz band named “Les Haricots Rouges”. At first I was into trumpet but when I heard a big slap solo on doubIe bass I realized that was it! Second, the first album I bought was the first Stray Cats record. Then it got under my skin. My parents bought me an electric bass, but I put a big stick on it’s bottom and played it as a stand up bass. After a year and a half of little work, I was able to buy a real one. I was about 14 back then.\nDjordje: How did you learn to play?\nNicolas: The rock’n’roll way! I mean, I’ve never taken any lessons because no one was able to teach slap in my little town back in those years. I learned by listening records with friends, trying to reproduce them. Gene Vincent, Bill Haley, Elvis… I found a Memphis Slim & Willie Dixon record in my old aunt’s house. What a fortune! It was impossible to find any instructional videos in France during the 80’s. The first one I saw was Lee Rocker’s in 1998.\nDjordje: What are your instruments?\nNicolas: I got two Engelhardt EM1s. I’m a big fan of Kay double basses, but I think I will never have the chance to play a vintage one, because I’m left handed. If anyone knows anything about old lefty Kays, please contact me! The first bass I got was Favino and later a Rubner, but that wasn’t the sound I was looking for. Engelhardt made me a real left handed one and I’m very happy with it.\nDjordje: You’ve been using weed wacker strings for a long time now. How do you keep them in good shape and what are the advantages of those strings over the others in your opinion?\nNicolas: I played steel strings for a long time with magnetic pick-up and piezo under the fingerboard for the “click”. It had a very big sound, but not the real acoustic one. Above all, I was looking for the slap sound from my old records. So, as I started to play much more acoustically I decided to make a change. I tried a lot of strings with the help of my friend Ivan Souverain (The Backleg Breakers) and finally put these weed wacker strings on my bass. It wasn’t easy! These strings were green and flubby, but sound like I want them to. We did a lot of experiments with different chemicals on them and found a secret to solve those problems. Now I got a good tension, a big sound and nice gut tone that I like. I play guts sometimes, but I have to take very good care of them. My weed wackers are unbreakable, they stay in tune and they’re very cheap. These days I’m trying something new. I put an A Pirastro Oliv’ detuned to E and It works pretty good. That’s a good solution for the E string problem that weed wacker and gut strings have. I would like to thank Pirastro for their contribution.\nDjordje: What came first, pizzicato or slap and how did you learn the slap technique?\nNicolas: Slap came first. I was immediately fascinated with it. As I already said, I learned by listening records. I was lucky to live during the 80’s rockabilly revival here in France. During that era there would sometimes be a rockabilly band on TV, but you know, the camera was much more on the leopard-creepers than the hands of the bassist! At that time, I didn’t have a VHS recorder, so I had to remember as much as possible and try to imitate it afterwards.\nDjordje: I noticed that historically there is a lot of confusion about names for different slap patterns (read more about it here). I personally prefer to count both slaps of the string and the palm. Some people count just slaps of the palm. What are the names that you use and what kind of different slap patterns do you use in your playing?\nNicolas: I agree with you. When I slap a bass just with the fingers, I call it a “simple slap”. “Double slap” when I hit the fingerboard with the palm once between two notes, a “triple slap” (or triplet) when I hit it twice between the notes, a “quadruple slap” for three palm hits between the notes and a “drag slap” for the kind of a quick triplet. I use all these patterns in my playing plus the one I named a “pull-slap”. It’s a kind of a drag slap with an open G that adds a velocity effect. I also use a pattern that I call “quadruple drag” that starts with the back of my pinky, then I use thumb and the palm at the end. Always experimenting…\nDjordje: Who are your slap influences?\nNicolas: My slap influences are the same as for many other slap players:\nWillie Dixon – we got a live CD here in France “Live aux Trois Maillets” with Memphis Slim, where you can hear Dixon perhaps at his best.\nSlam Stewart – I like his easy and lazy way of playing, specially with Slim & Slam.\nBob Haggart – for his version of “Big Noise from Winnetka”.\nMilt Hinton – like everybody!\nFor blues: Ransom Knowling and Ernest Crawford.\nLouis Vola – his duo with Django “You, Rascal You” is a very good example for his playing.\nI think I missed someone… but, generally speaking, I like this whole era. I also like New Orleans jazz slappers.\nDjordje: Do you like any other slap players nowadays?\nNicolas: Yes, sure! Jimmy Sutton plays in a pretty good vintage way. Kevin Smith and Beau Sample are very good in the Texas style. I like Mark Winchester’s work with the Brian Setzer Orchestra. There is also a guy who has a big solo on YouTube called “Atomic Boogie”…do you know him?\nI like very much the way Vlad Viorel slaps in the Balkan style. I have seen some Eastern European guys with three strings basses that are very good, but I don’t know their names. In France we have a guy named Gilles Chevaucherie who has a pretty unique technique and had a chance to play with Memphis Slim and Slim Gaillard among others.\nDjordje: You’re the only guy that I ever met who is as big fan of Gilles Chevaucherie as I am. Is slap bass tradition strong in France?\nNicolas: It depends on the style of the era. During the eighties, every village had their rockabilly band with a slapper. Nowadays a slap upright bassist is more like an UFO! I’m kidding, but it is almost like that. In the eighties, there were many slappers in New Orleans jazz style as well.\nWhen other bassists see a slapper, they want to slap too. They often don’t even start, because of the adjustment of their instruments. The problem they meet is the height of the strings. I think that it shouldn’t be a problem – look at Milt! As a conclusion, you either play be-bop or rockabilly, nothing in between. Anyway, nowadays in France, you can see slappers in New Orleans jazz style and in rockabilly bands that still exist.\nDjordje: In the last few years, I had a chance to play all the Djangofests in the US and one thing I noticed is that bassists never use slap. That was a bit of a surprise for me, because Luis Vola (Django’s original bassist and the guy that discovered him) as well as Tony Rovira, played slap on a regular basis. Nowadays it seems that short pizzicato sound has become the stylistic way of playing Gypsy Jazz. This music genre originates in France, so it would be interesting to hear your opinion about it.\nNicolas: It is the same thing here and in the entire Europe, I think. In fact, bassists are getting better and better. Sometimes they even play like guitarists and forget what their place in the band is. I don’t want to ever forget that I am an accompanist. Slam Stewart’s playing on the album “Fish-scales” is a very good example. Every time after his fantastic bow job (ha,ha), he plays pizz in a very simple way, just enough that other musicians hear the chord progression. That’s what the job of the bassist is for me. We are accompanying and sometimes soloing, but not both at the same time. Our duty is to make the song swing with or without slapping. That’s my opinion, but perhaps I’m a “has-been” and too much old-fashioned! Anyway, we have to be careful with slap in jazz music. We have to slap more quietly in order not to disturb a soloist.\nDjordje: Who are you playing with these days?\nNicolas: I’ve been playing with my band “Charlaz” for ten years. It’s a kind of a rockabilly trio. I mean it’s not pure rockabilly, because we add other things we like in our music. We are currently recording our fifth album. I also play with “Sweet-Dixie”, a vintage swing jazz band. The first album is coming out soon. I play blues with the association named “Marine-Band-Club” (most of the time with Anthony Stelmaszack on guitar and vocals) and Rockabilly with guitarist and singer Francky Gumbo. I also play Gypsy Jazz with the quartet “Swing 33” and guitarist Geoffroy Boizard.\nDjordje: How do you like to record your bass?\nNicolas: I used to record myself in my home studio with an Audio-Technica AT4033A that I’d put about 50cm (20”) from the bridge. It makes a good combination of a good bass tone and slap. For my DVD I used a Rode tube mic for the whole band. I think that sounds better, but it’s not mine! I record acoustically, I never use an amp or a pick-up on my recording sessions. My dream is to try one day the Western-electric mic Willie Dixon used.\nDjordje: I’m glad you explained Dixon’s way of playing a quadruple slap (the one that can be heard on Memphis Slim’s “Rockin the House” and many Big 3 Trio songs) on your DVD. Your way of playing it sounds the closest to the man as I ever heard. Our readers can hear it here on “Dixon’s Boogie” as well. How did you come up with playing that way?\nNicolas: It took me a lot of time. In the 90s I was able to play all the other slaps, but not the Dixon’s quadruple. I had many records with that riff in his solos, but no videos, so I had to imagine once again… In order to hear all details I slowed it down with a tape recorder and that’s when I really heard “poum, pa pa pa, poum”. At that point I was really sure that was a bass slap and not a “slap-box” like it was mentioned on some roots records. Then I was looking for better way to play three slaps between two notes with this velocity. Doing that I discovered another quadruple and a quadruple drag that I will explain on Slapology vol2. So, one night, I woke up and said “Eureka!”. It’s just 2 double slaps with second tone muted! To be clear, you have to play 1-2-3-4, 2-2-3-4 etc (1 is actual note/tone, 2 and 4 are the slaps/hits, 3 is played like a note, but muted with left hand). It’s very important to play the same attack on each slap. That’s why I slap on the same place of the fingerboard. I think that the explanation is much more clear on the DVD.\nDjordje: I enjoyed watching your instructional DVD very much. You plan to do another one?\nNicolas: Yes, I think I will record Slapology vol2 next year. I will assume that everybody who buys it already knows how to play every slap pattern I explained in the vol1. And then I’ll start to explain how to build solos in different styles: swing, gypsy jazz, rockabilly, trad jazz etc and how to accompany the soloist. The first DVD is just about slap technique. I will explain two other ways of playing a quadruple as well. This time I’ll make sure that there is a version in English!\nDjordje: What songs that you recorded would you recommend to bass players that are interested in your slap technique?\nNicolas: You can hear “Slapology” and “Stray Cat Strut” on the Charlaz album “Alive & a live” or you can watch “Avalon” and “Dark Eyes” on my myspace page and YouTube. I also play some solos on upcoming Charlaz and Sweet Dixie records. And of course “Dixon’s Boogie” that I recorded specially for you and “The Art of Slap Bass”.\nDjordje: Are there any touring plans outside of France?\nNicolas: I haven’t played abroad at all in the recent years. I’m busy playing French west-coast and my daughter also needs her daddy! There are no plans for touring outside of France in the near future, but we would like to do it someday.\nDjordje: What are your preferences for amps and pickups?\nNicolas: I play with an Ampeg B2 head plugged in a Fender 15″ cab. My pickup is a vintage Barcus Berry named “the Clamp”. It’s very easy to install it and it has no feedback at all! I think that’s enough for clubs. On the bigger stages I use the same gear and I also send a signal to the PA. When I play jazz or gypsy I don’t use amp, just a regular Shure SM58 or 565 fixed on the bridge. That’s better way to keep a natural sound. If I don’t have my mic with me, I use what ever the engineer gives me.\nDjordje: What do you suggest to younger players to practice on a daily basis?\nNicolas: First, a big coffee with or without iodine in it. Then they should try to play very simple stuff in all keys. Blues is a good example. They can try to improve it with different substitutions once they feel more comfortable with it. This exercise is kind of a warm up. You are practicing and warming up at the same time. While changing the keys, they should also try to explore the whole fingerboard, even if they don’t use it on stage. For the slap technique it is very important to use a metronome and not lose the beat. Play a bass line with pizz and then slap it. After that, try to add double, triple and quadruple slap. You can also mix them all in the same bass line. Try to reproduce the riffs you like on your favorite records and create some new ones as well.\nDjordje: Thank you for finding time to do this interview and hope to see you play sometime soon!\nNicolas: I thank you and Rockabillybass.com for making slap bass more popular.\nIf you want to ask Nicolas Dubouchet a question, you can do that on our forum.']	['<urn:uuid:35497993-b748-4352-8ee7-1371e44eb9d8>']	open-ended	with-premise	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-13T06:27:57.068978	26	98	2724
92	What role do branchpoints play in genetic splicing, and how does this relate to the treatment approach for vitamin D overdose?	Branchpoints are crucial locations where genetic lariats form loops during splicing, and their position helps predict where splicing will occur with 95.6% accuracy. Mutations in these branchpoints can lead to diseases by interfering with lariat formation. When treating conditions like vitamin D toxicity, which can affect these cellular processes, the approach includes hospitalization with IV saline to protect the kidneys, monitoring calcium and phosphorus levels, and administering medications like furosemide to promote calcium excretion.	"['The lasso-shaped genetic snippets — they are called lariats — that the Brown team reports studying in the June 17 edition of Nature Structural & Molecular Biology are byproducts of gene transcription. Until now scientists had found fewer than 100 lariats, mostly by poring over very small selections of introns, which are sections of genetic code that do not directly code for proteins, but contain important signals that direct the way protein-coding regions are assembled. In the new study, Brown biologists report that they found more than 800 lariats in a publicly available set of billions of RNA reads derived from human tissues.\n""We used modern genomic methods, deep sequencers, to detect these rare intermediates of splicing,"" said William Fairbrother, associate professor of biology and senior author of the study. ""It\'s the first ever report of these things being discovered at a genome scale in living cells, and it tells us a lot about this step of gene processing.""\nThat specific step is known as RNA splicing. Like film editors splicing together movie scenes, enzymes cut away the introns to assemble exons that instruct a cell\'s ribosome to make proteins. The body often has a choice of ways and places to make those cuts. Most of what is known about splicing has come from studying these spliced instructions, said Allison Taggart, a graduate student who is lead author of the study. What\'s been missing is the data hidden in the lariats, which fall apart shortly after being spliced out, but turn out to predict the body\'s splicing choices.\nThe key information uncovered in the study, Taggart said, is the location of so-called ""branchpoints"" on the lariats. Physically, the branchpoint is where the lariat closes on itself to form a loop during the first step of splicing, but its position and proximity to possible splice sites, the researchers learned, reliably relate to where splicing will occur.\nAfter studying the sites of these branchpoints and their relationship to splice sites, the researchers created an algorithmic model that could predict splice sites 95.6 percent of the time. The value of the model is not in identifying splice sites — those are already well known, Fairbrother said. Instead, the model\'s accuracy shows that, with the new data from the lariats, scientists have gained a more general understanding of how the body chooses among alternative splicing sites.\n""What it does tell us is sets of rules defining the relationship between branchpoints and the chosen splice sites, which gives clues about how the splicing machinery makes decisions,"" Taggart said. ""Certain branchpoint locations can enforce specific splicing isoforms.""\nConnections to disease\nIn addition to ferreting out the mechanisms of alternative splicing, the team also studied the connection between branchpoints and disease. They looked through the Human Gene Mutation Database for disease-causing mutations found in introns and compared their newly found branchpoint sequences to those mutations. They found that many relate specifically to branchpoints.\n""We saw a sequence motif that looked exactly like a branchpoint sequence motif,"" she said. ""What this tells us is that these mutations are forming at branchpoints and are leading to disease, presumably through causing aberrant splicing by interfering with lariat formation.""\nIn other words, Fairbrother said, it could well be that a consequence of mutations in branchpoints could be disease.\nIn addition to Taggart and Fairbrother, other authors include Alec DeSimone, Janice Shih, and Madeleine Filloux.\nThe National Science Foundation and Brown University funded the research, which was performed in part on the OSCAR supercomputing cluster at the University\'s Center for Computation and Visualization.\nDavid Orenstein | EurekAlert!\nBacteria as pacemaker for the intestine\n22.11.2017 | Christian-Albrechts-Universität zu Kiel\nResearchers identify how bacterium survives in oxygen-poor environments\n22.11.2017 | Columbia University\nThe WHO reports an estimated 429,000 malaria deaths each year. The disease mostly affects tropical and subtropical regions and in particular the African continent. The Fraunhofer Institute for Silicate Research ISC teamed up with the Fraunhofer Institute for Molecular Biology and Applied Ecology IME and the Institute of Tropical Medicine at the University of Tübingen for a new test method to detect malaria parasites in blood. The idea of the research project “NanoFRET” is to develop a highly sensitive and reliable rapid diagnostic test so that patient treatment can begin as early as possible.\nMalaria is caused by parasites transmitted by mosquito bite. The most dangerous form of malaria is malaria tropica. Left untreated, it is fatal in most cases....\nThe formation of stars in distant galaxies is still largely unexplored. For the first time, astron-omers at the University of Geneva have now been able to closely observe a star system six billion light-years away. In doing so, they are confirming earlier simulations made by the University of Zurich. One special effect is made possible by the multiple reflections of images that run through the cosmos like a snake.\nToday, astronomers have a pretty accurate idea of how stars were formed in the recent cosmic past. But do these laws also apply to older galaxies? For around a...\nJust because someone is smart and well-motivated doesn\'t mean he or she can learn the visual skills needed to excel at tasks like matching fingerprints, interpreting medical X-rays, keeping track of aircraft on radar displays or forensic face matching.\nThat is the implication of a new study which shows for the first time that there is a broad range of differences in people\'s visual ability and that these...\nComputer Tomography (CT) is a standard procedure in hospitals, but so far, the technology has not been suitable for imaging extremely small objects. In PNAS, a team from the Technical University of Munich (TUM) describes a Nano-CT device that creates three-dimensional x-ray images at resolutions up to 100 nanometers. The first test application: Together with colleagues from the University of Kassel and Helmholtz-Zentrum Geesthacht the researchers analyzed the locomotory system of a velvet worm.\nDuring a CT analysis, the object under investigation is x-rayed and a detector measures the respective amount of radiation absorbed from various angles....\nThe quantum world is fragile; error correction codes are needed to protect the information stored in a quantum object from the deteriorating effects of noise. Quantum physicists in Innsbruck have developed a protocol to pass quantum information between differently encoded building blocks of a future quantum computer, such as processors and memories. Scientists may use this protocol in the future to build a data bus for quantum computers. The researchers have published their work in the journal Nature Communications.\nFuture quantum computers will be able to solve problems where conventional computers fail today. We are still far away from any large-scale implementation,...\n15.11.2017 | Event News\n15.11.2017 | Event News\n30.10.2017 | Event News\n22.11.2017 | Business and Finance\n22.11.2017 | Physics and Astronomy\n22.11.2017 | Physics and Astronomy', 'Reference, full author’s credit and bibliography: https://www.iowaveterinaryspecialties.com/student-scholars/vitamin-d-toxicosis\nVitamin D Toxicosis\nWritten by: Lena R.\nA 7 year old, female spayed, 62lb Labrador Retriever named Maple presented for ingestion of 20 gel caps of Vitamin D-3 supplement of unknown concentration- either 400IU or 5,000IU per cap. Maple had vomited three times at home, with some of the caps contained within the vomitus, and the owners called Pet Poison Helpline.\nOn physical exam, Maple appeared healthy, her abdomen was not painful on palpation, and her heart rate was within normal limits. She was not lethargic or depressed at that time.\nDid Maple consume enough of the supplements to cause clinical signs? Symptoms of Vitamin D toxicosis can be seen with doses as low as 0.1mg/kg, and a lethal dose in a mature dog can be as low as 2mg/kg (4). Maple weighed 28kg on entry. 1IU = 0.025mcg, and 1mcg = 0.001mg (3).\nIf the gel caps were 400IU: 400IU x 0.025 = 10mcg x 0.001 = 0.01mg. If she ate 20 gel caps, the total dose she consumed would be 0.2mg. For a 28kg dog, that dose would be non-toxic at 0.007mg/kg.\nIf the gel caps were 5,000IU: 5,000IU x 0.025 = 125mcg x 0.001 = 0.125mg. If she ate 20 gel caps, the total dose she consumed would be 2.5mg. For a 28kg dog, that dose would be non-toxic at 0.08mg/kg.\nHowever, with the impossibility of knowing exactly what Maple consumed, the safest choice was to hospitalize her with presumed Vitamin D toxicosis.\n- Hospitalize for 72 hours with IV saline to diurese the kidneys.\n- UAA gel with sorbitol.\n- CBC, blood chemistry panel, iStat to check free calcium, and urinalysis.\n- Recheck iStat free calcium and phosphorus every 12 hours.\n- Recheck CBC/chem every 24 hours to monitor renal values.\n- Oral medications: furosemide, to promote calcium excretion by the kidneys (2), and famotidine, as a gastrointestinal protectant.\n- Optional: adding oral prednisone (a corticosteroid), to reduce bone reabsorption of calcium and decrease absorption of calcium in the GI tract (3).\nMaple was hospitalized on IV fluids for 72 hours. Her total calcium and phosphorus levels remained within normal range for the duration of her treatment, and her renal values (BUN and creatinine) were within normal limits on exit. She was discharged with the recommendation to recheck renal values after an additional 48 hours, to ensure there would be no lasting effects from the incident.\nVitamin D toxicosis is a potentially life-threatening condition that causes increased reabsorption of calcium leading to renal damage. Clinical signs include abdominal pain, renal pain on palpation, depression, bradycardia (increased heart rate), vomiting and diarrhea (1). Once blood work is performed, findings include hypercalcemia, hyperphosphatemia, hypokalemia, and azotemia.The most common cause of vitamin D toxicity in dogs is ingestion of cholecalciferol rodenticides (4).\n- Tilley, Lawrence P., Francis W. K. Smith, and Lawrence P. Tilley. “Vitamin D Toxicity.” Blackwell’s Five-minute Veterinary Consult: Canine and Feline. Ames, IA: Blackwell, 2007. 1317-319. Print.\n- Plumb, Donald C. “Furosemide.” Plumb’s Veterinary Drug Handbook. Stockholm, WI: PharmaVet, 2011. 454-57. Print.\n- “Cholecalciferol: Rodenticide Poisoning.” Veterinary Manual. Mereck, Oct. 2014. Web. 02 Aug. 2016.\n- Peterson, Michael E., and Patricia A. Talcott. “Chapter 38: Cholecalciferol.” Small Animal Toxicology. St. Louis, MO: Saunders/Elsevier, 2006. 489-98. Print.\nEnter your email address for a free PDF of this article including its images.Enter your Email Address\nMy Favorite Amazon Recommendations\nItems and content will not show in ""Reader View"" check your browser.\nPraziPro for Flukes\nBuy Some Good Koi?\nBest Food, Ever\nPro Air 60 Aerator is a VERY high output air pump pushing my whole fish room (17+ drops), and I have one at home driving everything there, and I have one as a back up.\nTopical For Koi and Pond Fish Ulcers\nKoi Health & Disease\nI have over ten of these Titanium Heaters in my fish room and at home. They\'re a paradigm shift in aquarium heating. They\'re titanium and 400W for under $30! Whaaaaaaaaat?\nCyroPro by Hikari is safe and easy for Anchor Worms and Fish Lice.\nWhatever heaters you use, back yourself up with a temperature controller, it\'ll turn on, and off your heaters. If your heater seizes ""on"" at least the thermostat will stop a tragedy.\nLifeGuard by Tetra is a tablet version of a tame \'chloramine-t\' or \'halamid\' compound that\'s easy to get and good on bacterial infections, in baths.\nFor me, filtration-of-choice\nRubber sided, round, nettable tanks\n1200 Watt heater, on a thermostat held securely above the waterline, works GREAT as a large tank heater. That\'s all I\'ll say because there\'s risk of electrocution and all that. But then, even in a bucket you could get killed. Sound like fun?\nWhat Does Ajax Eat?']"	['<urn:uuid:0f0c359d-644a-4d3f-8ae2-24412295cd36>', '<urn:uuid:a40821cc-bd77-4e4d-88c2-e7b180d8a4e9>']	factoid	direct	verbose-and-natural	similar-to-document	multi-aspect	novice	2025-05-13T06:27:57.068978	21	74	1920
93	china city parks mental health benefits migrant birds protection	City parks provide crucial mental health benefits, with studies showing that visits to green spaces decrease mental distress and increase vitality, especially in urban areas. Additionally, in places like Cape Nanhui in Shanghai, these areas serve as critical stopover points for tens of thousands of migrating birds on the East Asian-Australasian Flyway, demonstrating both human and ecological benefits of urban green spaces.	"['Editor’s note: This tranquil scene is from Iron Track (31.003613, 121.907883), home of Reed Parrotbill and dozens of other species, and part of the large reed beds on the Dazhi River at Cape Nanhui. In the face of manic development, and in spite of being under no protection, Cape Nanhui conserves the best reed beds on the Shanghai Peninsula as well as mudflats critical to tens of thousands of migrating shorebirds. To save these treasures, Shanghai people must act now.\nby Craig Brelsford\nWho will save Cape Nanhui? Not foreigners like me, but the people of Shanghai. We foreigners are numerous in Shanghai and are disproportionately represented among the birders here. We can offer valuable perspectives. But if the people of Shanghai themselves do not wish to ensure a bright natural future for Cape Nanhui, then there is little that anyone can do.\nI think that the people of Shanghai are ready for real conservation on the Shanghai mainland. Basic conservationist ideas have broad appeal, and an easily accessible, world-class, “people’s wetland reserve” at Cape Nanhui is a basic conservationist idea.\nIf I were Chinese and were arguing for a people’s wetland reserve for Cape Nanhui, then I would bring to light the following points.\nSHANGHAI IS NOT A CITY IN THE CONVENTIONAL SENSE\nShanghai “市” isn’t really a city or a “municipality,” as 市 is often translated. It is a city-province, accountable to no government but the national government. The city-province is vast, covering an area greater than the U.S. states of Delaware and Rhode Island. Shanghai is twice as big as Luxembourg, half as large as Northern Ireland, and a third the size of Wales.\nFrom a conservationist’s perspective, it is important to view Shanghai as a province and not a city, because cities are not usually thought of as being responsible for maintaining large nature reserves within their borders. Provinces, by contrast, are large enough to accommodate nature reserves.\nI propose that, where workable, we stop referring to Shanghai as a city or municipality and start applying to it the more accurate label of city-province.\nSHANGHAI OCCUPIES LAND UNUSUALLY IMPORTANT TO CONSERVATION\nAny jurisdiction covering an area the size of a small country would be expected to conserve substantial amounts of its area. In the case of Shanghai, the call to conserve is even louder, because the area it occupies is unusually important for conservation. The Shanghai Peninsula is situated between the mouth of Asia’s greatest river and Hangzhou Bay. It is on the East Asian-Australasian Flyway and attracts tens of thousands of passage migrants representing a few hundred species.\nCape Nanhui is the tip of the Shanghai Peninsula and attracts passage migrants and winter visitors such as the Endangered Black-faced Spoonbill. Its large reed beds are the final stronghold on the Shanghai Peninsula of Near Threatened Reed Parrotbill, a candidate for Shanghai Provincial Bird, as well as Near Threatened Marsh Grassbird.\nCape Nanhui is completely unprotected; indeed, an attempt at a small wetland reserve has been shut down. The boardwalks and signs of the defunct reserve are crumbling, and the backhoes are standing by, waiting for the green light to smash what remains.\nSHANGHAI, AN ENVIRONMENTAL UNDER-PERFORMER\nNo one is saying that Shanghai, a city-province of 26 million people, needs to create a Yellowstone. Any reasonable person understands the pressures the huge population of Shanghai puts on its natural resources.\nAlso, it must be pointed out that in the far-flung areas of the city-province, Shanghai has made an attempt at conservation. Chongming Dongtan preserves the eastern nub of Chongming Island, and Jiuduansha covers intertidal shoals near Pudong Airport.\nBut Shanghai under-performs overall. Nowhere is the poor conservation performance more evident than in Pudong, the coastal city-within-a-city. Pudong is nearly double the size of Singapore and is half the size of Hong Kong. Yet the district contains zero wetland reserves on its mainland. Both Singapore and Hong Kong manage to hold in reserve significant portions of their territory.\nThe southeastern tip of Pudong is Cape Nanhui, a place that despite being under no protection still brims with natural treasures. No place on the Shanghai Peninsula has as many reed beds. The projection of land attracts birds making the long journey across Hangzhou Bay and the wide mouth of the Yangtze.\nMoreover, Cape Nanhui is easily accessible to common people. It would be the perfect place for a world-class wetland reserve on the model of Sungei Buloh in Singapore and Yeyahu National Wetland Park in Beijing.\nOn shanghaibirding.com I have addressed the issue of conserving Nanhui:\n— Save the Nanhui Wetland Reserve! (cri de coeur plus call to action)\n— Remnants (preparation for probable demise of Cape Nanhui)\n— Reed Parrotbill, Symbol of Shanghai (naming Reed Parrotbill Provincial Bird of Shanghai will send a message about the importance of the reed beds such as those at Cape Nanhui)\n— Spoon-billed Sandpiper at Nanhui (proof of yet another endangered species using the defunct wetland reserve at Nanhui)\n— Will the Spoon Survive? (Nanhui is not the only area under threat. You ought to see the mess at Yangkou, Jiangsu. Conserving Nanhui will offset the losses elsewhere on the Chinese coast and will put a conservationist feather in Shanghai’s cap)\n— Meet Kai Pflug, Nanhui’s Mr. Clean (tribute to a birder doing his small part)\nWe foreigners have had much to say about the future of Nanhui. I would like to hear more from Chinese. Is the case for a world-class wetland reserve at Nanhui convincing to you? If so, then what do you propose to do to bring it about?', ""10 reasons urban green spaces are now more crucial than ever\nThere is an undeniable allure when it comes to natural green spaces, and it’s been shown that simply viewing vegetation positively effect mental and physical responses. Urban green spaces are a hot topic in city planning and we gathered evidence to show how extremely relevant this is today, and how these spaces can transform city centers to benefit the environment, human mental health and social health.\nThere is an undeniable allure when it comes to natural green spaces, and it’s been shown that simply viewing vegetation can produce beneficial psychological and physiological effects on people. The relevance has never been more important as it is estimated nearly 70% of the world’s population will be urban dwellers by 2050.\nHistorically, green spaces have been identified as a component of public health and a refuge from overcrowding and the proliferation of disease. Jones (2018) extracted an example from French history in which Henry IV “established the Place Royale (now Vosges) in 1605 out of concern that the people of Paris needed a place to promenade as they were closely pressed together in their houses” exemplifying the view of green spaces as healthy and restorative (p.44). This sentiment is extremely relevant by virtue of climate change, increasing urban density, and rising mental health concerns.\nGreen infrastructure cools cities, manages water, reduces heat stress, noise and more.\nGreen infrastructures such as green roofs, vertical greening, city parks, and urban gardens are an approach to help mitigate urban heat island effects (UHI) in the summer. UHI is a microclimate, which explains the temperature in cities being hotter than the surrounding regions, due to lack of green space, dark and impermeable materials, and the infrastructure of the city; energy consumption from fossil fuels, roads, parking lots, sidewalks, buildings, and rooftop materials. An enormous amount of urban landscapes consist of impermeable and dark materials which absorb energy from the sun and create heat, which contributes to higher heat stress among urban dwellers compared to rural dwellers (Aram et al., 2019).\nIn contrast to UHI, other microclimates such as Green Space Cool Island (GCI) and Pocket Space Island (PGS) have been identified as possible strategies to mitigate urban heating. These refer to the ability of large green spaces with trees, grass, shrubs, and water bodies (GCI) and small pocket spaces, such as a small city park (PGS) to create a cooling dome cooler than the surrounding areas. Studies have shown reductions in air temperature in these green microclimates compared to the surrounding city temperatures (Aram et al., 2019, Wu et al., 2021).\nUrban greening offers shade for residents and workers to retreat and cool down. Think of how people flock to the shade of a tree or to lay on the grass in a city park-it’s a resource in combating the heat. Green infrastructure also provides rainwater runoff management. Soil is permeable and helps filter water, allowing plant roots to absorb water through evapotranspiration, and then releasing water back up through vapor which cools the surface and air temperature.\nThere’s even more benefits-urban greening can produce and protect biodiversity, air purification, and provides a habitat for wildlife, birds, insects, butterflies, and bees. And vegetation, such as trees and shrubs provides noise reduction.\nUrban green space supports social and mental health.\nConnection with nature is an important aspect of our health and well-being. Nature connectedness means the relationship we have to the natural environment, and this can be increased by our positive experiences with nature, and the more positive nature connectedness one has, the more likely they will make pro-environmental decisions.\nWe are very much a part of nature and not distinctly separate, however, our increasing urbanization and degradation of natural environments are cutting generations apart from a relationship and appreciation for the natural world. An increasing number of studies have found that people associate mental health and their general health with nature connectedness, and identified associations with mental distress decreasing with increased visits to green and blue spaces.\nWhite et al. (2021) found that “greater nature connectedness was positively associated with positive well-being and negatively associated with both mental distress and depression medication use” (p. 7). Nesbit et al. (2020) found that respondents who lived near high-density tree canopies reported more vitality and reported less mental distress. Research from Mittermüller et al. (2021) recommended cities to implement “visual green elements at eye level (e.g., green facades, shrubs, or planters) to increase the “naturalness” of stressful urban settings, since our results showed positive psychological benefits achieved by urban greenery” (p.49).\nOne can always refer to the landmark research from Ulrich (1984) that found patients recovered from surgery faster and used less pain medication when their hospital room had a window with a natural landscape view, compared to those who had a window view of a brick wall.\nThe disconnect to nature is more prominent for urban dwellers where accessibility to green spaces may be low, and urban stressors such as noise, pollution, traffic, high temperatures, and social density stress. There is promising research demonstrating how beneficial urban green spaces are for mental and social health. The WHO report on urban green spaces and health included the positive association of quality green spaces and social connection in the community. Urban green spaces can be potential grounds for developing social cohesion, such as civic engagement such as volunteer opportunities, citizen-initiated projects such as the local, free and open to all exercise and healthy cooking program Fürth Bewegt, citizen science projects, and community gardening.\nThink of how often safe, visually appealing, and properly maintained parks are the hub for social activity and recreation-from family picnics, to the stage for local plays and performances, the location for festivals and dance classes, a go-to for walks with friends, a spot for walking and socializing at the dog park, and a popular choice for physical activity, group exercise classes, and playground ventures for the kids. Inclusive access to safe and appealing green spaces is critical for urban residents, as it is uncommon they have access to a private garden, thus relying on city green spaces for recreation, leisure, and shade during hot days.\nGreen urban space examples-Tempelhof and rewilding projects in German cities.\nUrban spaces can be transformed into inclusive public green spaces for activity and leisure. A perfect example of this comes from Berlin, where the decommissioned Tempelhof Airport consisting of 358 hectares was transformed in 2010 into a public open green space Tempelhofer Feld. Rather than selling the massive vacant space to developers, it was transformed into a sprawling public space for leisure and sport, including gardening projects, miniature golf, walking paths, sports designated areas, and protected wildlife areas for the endangered species, such as the skylark.\nStädte Wagen Wildnis is a government-funded project with local university partners dedicated to rewilding empty spaces in the German cities of Dessau-Roßlau, Frankfurt am Main, and Hannover. The rewilding projects have transformed deserted lots into thriving wildflower meadows rich in biodiversity. The care of these spaces has a more hands-off approach because organizers decided not to impede the reclamation of nature, thus seeking the opportunity to learn more about rewilding processes.\nInterested in learning more about urban green spaces and recommended approaches for integration of urban green spaces? Read the German Federal Government 2017 White Paper: Green Spaces in the City-for a more liveable city' from the Federal Ministry for the Environment, Nature Conservation, Building, and Nuclear Safety.\nAram, F, García E, H, Solgi, E, Mansournia, S. (2017). Urban green space cooling effect in cities, Heliyon, Volume 5, Issue 4, e01339, ISSN 2405-8440, https://doi.org/10.1016/j.heliyon.2019.e01339.\nJones, Karen. (2018) 'The Lungs of the City': Green Space, Public Health and Bodily Metaphor in the Landscape of Urban Park History. Environment and History. 24. 39-58. 10.3197/096734018X15137949591837.\nMittermüller, J., Erlwein, S., Bauer, A., Trokai, T., Duschinger, S., & Schönemann, M. (2021). Context-specific, user-centred: Designing Urban Green Infrastructure to effectively mitigate urban density and heat stress. Urban Planning, 6(4), 40–53. https://doi.org/10.17645/up.v6i4.4393https>https://doi.org/10.1126/science.6143402https\nWhite, M.P., Elliott, L.R., Grellier, J. et al. Associations between green/blue spaces and mental health across 18 countries. Sci Rep 11, 8903 (2021).\nWu C, Li J, Wang C, Song C, Haase D, Breuste J and Finka M. (2021). Estimating the Cooling Effect of Pocket Green Space in High Density Urban Areas in Shanghai, China. Front. Environ. Sci. 9:657969. doi: 10.3389/fenvs.2021.657969""]"	['<urn:uuid:0856d994-40f1-4437-ad8e-572ec9d7725a>', '<urn:uuid:ffa08e9f-e6ca-48ba-a9bf-91ea16c6e84f>']	factoid	direct	long-search-query	distant-from-document	multi-aspect	novice	2025-05-13T06:27:57.068978	9	62	2322
94	What separates bush flying operations from agricultural aviation work, and how are safety measures implemented in these specialized fields?	Bush flying involves transporting people and cargo in remote locations requiring high proficiency due to challenging conditions, while agricultural operations focus on spraying fields with chemicals and pilots often own their businesses. Both operations must follow strict safety regulations including regular inspections - busy planes are inspected multiple times daily while occasional flyers are checked weekly or monthly. Any aircraft failing inspection is immediately grounded until repairs are completed, with minor maintenance done monthly and major maintenance every two months.	"[""Career in Aviation\nIf you are thinking about launching a career in aviation, the professions listed below will help you make a better choice. It is also possible that as you advance in aviation, you will be moving from one kind of flying to another. Sometimes, the nature of this career demands that you acquire flight hours in simpler kinds of flying before moving on to the more complex ones. Good luck!\nFlight Instructor. Responsibilities include preparing students for knowledge and practical tests for different certificates and ratings. It can also include development of lesson plans and training techniques. Work day is irregular. It can include nights and weekends. Except for being qualified in the aircraft and a maximum of 8 hours of flight training given in the preceding 24 hours established by the FAA, there are no other limitations.\nPart 135 Cargo Operations. Transportation of small to medium cargo within either one region for smaller operations or worldwide for major carriers. For smaller companies, work days are usually Monday-Friday sometimes including night shifts.\nPart 135 Charter Operations. Transportation of passengers on demand on small propeller airplanes or business-class jets.\nPart 121 Passenger Operations. All scheduled regional and major airlines fall into this category. This is the segment of aviation that we most frequently use as passengers while traveling. Hours of work and rest are strictly regulated by the FARs.\nPart 91 Corporate Operations. Many large corporations own business jets. Pilots are employees of the company in this case. Flights are always on demand. Work schedule can be something like this: 4 days of travel around the country with 3 days off and other combinations up to 7 days on, 7 days off.\nAgricultural Operations. Spraying fields with various chemicals. In many cases, the pilot is also the owner of the business.\nAerial Photography. Taking pictures of the earth’s surface for cartographical, real estate, or advertisement companies. As in the previous case, the pilot can also be a business owner.\nTraffic/News Reporting. Taking reporters to particular events or places on the ground. It might be done with the help of both helicopters and airplanes.\nLaw enforcement. Adrenalin elevating aerial chases, of course, are included in this kind of flying as are more “boring” things such as transportation of cargo and people upon request of various government agencies, enforcing speed limits on the roads, etc. Both helicopters and airplanes are used.\nWildlife Services. Airplanes are indispensable in remote places for studying migrations of wild animals, for controlling their count, and for collecting scientific data about flora and fauna.\nAerial Firefighting. Dispensing fire-suppressing agents from the air when conventional ground-based fire fighting methods are ineffective.\nBanner Towing. This is mostly a seasonal job in warmer months. It includes picking up and carrying a banner along a beach or a sports event for advertisement.\nSight-seeing Tour Operations. In some regions, these services are provided by flight schools, but in some others like Grand Canyon, there are companies doing nothing but aerial sight-seeing tours.\nBush Flying. Transportation of people and cargo in remote places. This kind of flying requires high degree of proficiency because it is conducted in challenging conditions.\nFactory Test Pilot. Testing new models of aircraft for manufacturers. Besides high pilot proficiency, it requires a bachelor’s degree or higher in engineering. The pilot tests aircraft in different flight modes and works closely with designers and engineers to improve the aircraft’s flying characteristics.\nAircraft Appraisal. Just like in real estate, buying and selling aircraft requires their appraisal considering year of manufacture, total time flown, installed equipment, and many other factors. Even though an aircraft appraiser is more a businessperson than a pilot, serving customers demands a lot of travel.\nAircraft Mechanic. This is not a flying job, but it's included here, because currently, there is a shortage of qualified aircraft mechanics in the USA. Sometimes mechanics can work as pilots in the same company."", 'Safety while flying elicits a lot of attention from all those who venture to fly. As much as statistics show that travelling by cars is more dangerous than aircrafts, flying is more feared due the loss of control that people feel as a result of being suspended in the air. Many regulatory bodies look at aviation safety seriously as much as passengers. These bodies are tasked with the enforcement of rules and standards that address safety of the passengers while on board a moving aircraft from liftoff up to landing.\nThe aviation industry is one of the most highly regulated. All players from the manufacturers of the giant jumbos to the suppliers of the smallest parts are required to adhere to a wide range of standards. Each part that is made is tested so as to verify whether it is compliant with predetermined tolerance limits failure to which it must be done away with. There are approved third parties who are empowered to certify companies that engaged in the aircraft industry (Krause, 2003).\nAll companies that are involved in air travel are closely monitored to ensure they are competent. This is not only expected of manufacturers of parts but also those companies that assemble aircrafts. After the assembly every plane is tested so as to ascertain whether it complies with regulatory requirements. The tests include flying so as to establish whether it is operating properly and safely (Krause, 2003).\nDuring a test flight only a small portion of the crew is taken on board. New models are examined through a battery of tests that are designed to simulate real flight conditions. This process can take over a year to be completed. Production runs of a particular model are also subjected to lesser demanding tests but test flights are always conducted on every produced unit. Regulations are also enforced when a plane is in service. Actually, the rules become stricter through a schedule of maintenance and inspections before every flight (Stolzer & Goglia, 2011).\nIf an aircraft deviates from a set-out schedule it may be grounded. Every busy plane is usually inspected for more than one occasion every day. Those that fly occasionally are inspected after a few days or weekly. If a plane fails an inspection it is immediately grounded until all required repairs are completed. Minor maintenance procedures are done at least one time a month or after a few days. On the other hand major maintenance is done as required or at least one time after every two months. The regulations that govern how safe aircrafts are also applied to the crew.\nAs far as the crew is concerned, the major bone of contention is the number of crew members that are included in each flight as well as how experienced they are and for how long that they have flown. This is extended to how much sleep pilots have before entering into a cockpit every time. As much as most people worry about how safe they are aboard an aircraft is one of the safest activities that anyone can engage in (Krause, 2003). Rules and procedures are enforced so as to reduce the number of airborne accidents to the minimum by ensuring that all aircrafts are in proper working order at all times.\nEvery passenger who boards a plane always expects that it is well equipped with devices for utilization during an emergency situation. In many modern aircrafts such devices extend beyond procedures for ensuring that passengers are safe to warning systems that are designed to avoid accidents. These systems have to be correctly installed and constantly maintained (Stolzer & Goglia, 2011). Devices that are considered as basic for ensuring that each and every flight is safe are standards that must be adhered by each plane whether it is the smaller planes to the huge commercial jets. Large jets have a deployable slide that is used to evacuate passengers from the sides very quickly in case of an emergency. If such devices are not there, evacuation may not be feasible which portends that a jet would hit the ground while passengers are aboard which would lead to catastrophic results (Rodrigues & Wells, 2012).\nParachutes are a primary requirement in the smaller aircrafts. This device is one of the foremost precautions that is available in every plane and should be maintained adequately to ensure that it is in proper working condition and it can be deployed without damaging the parachute. Parachutes are rarely used during an accident but they still remain an option that is considered seriously (Huang, 2009).\nThere are computerized equipments that are installed in aircrafts and calibrated to avoid occurrence of accidents altogether. These are recent developments and pilots consider them as important ways of controlling planes and helping them to understand problems as they develop during a flight, thereby giving them sufficient time to appropriately react.\nThe aircraft industry has seen the enforcement of so many standards that are geared towards ensuring that all flights are safe. Companies have to hire highly experienced personnel to fly and manage their planes. Such personnel should have an established record of safety as well as in implementation of best practices. One of the most basic ways of ensuring that a plane flies and lands without interruption is that every cockpit must have two pilots just in case one of them becomes deactivated during a flight.\nStatistically the number of aircraft accidents is low as a result of developments that have enhanced the performance of aircraft through superior engine design as well as adequate training of pilots which are deemed to be the focal points of ensuring that each plane lifts off and lands without any incidences. International organizations that govern manufacture and management of aircrafts always recommend that all national authorities should implement safety regulations.\nSince the advent of flying planes have crashed leading to very serious results. This is a result of the flight nature which is unforgiving as a small medium is suspended in air to support a large mass whose failure does not give an option but quick descent with catastrophic eventualities (Stolzer & Goglia, 2011). Due to this planes are designed with an emphasis of reducing the chances of mechanical malfunctions and pilots are intensively trained.\nIn the earlier developments in aircraft technology there were those who have been of the view that a plane should be designed with consideration of how it would endure an accident. However, such a design would lead to the manufacture of the very heavy model that would be more susceptible to crash as a result of the added weight. As a result of this it is not uncommon to find the nonstructural parts of planes, especially the small ones are very light and when such planes crash devastating results follow.\nFlying in private jets is more dangerous in comparison to the scheduled flights. This is partly attributable to less maintenance and training. In most cases privately owned aircrafts do not have system redundancy to be utilized if a system failure occurs. Therefore it can be presupposed that it is safer to fly using commercial airlines (Rodrigues & Wells, 2012).\nAir traffic can be considered to be intense as there are usually ten thousand planes in flight at the same time. Despite this accidents are rarely sighted given the high number of operations. Statistically flying by scheduled airlines in the developed world is at least ten times safer than driving. However, this is not the case in many African nations and Russia. Plane accidents make headlines throughout the world when they occur (Rodrigues & Wells, 2012). The perceived impact of such accidents has magnifying effect. The main reasons that lead to the airborne accidents are flaws in the design, pilot’s errors and improper maintenance procedures.\nThere are inspectors whose sole mandate is to ensure that regulations regarding performance and quality of aircraft including personnel are adhered to. These professionals are specialized in the inspection of either single or multiple engine aircrafts or commercial carriers. Other inspectors perform inspections on the operation of airlines where they evaluate commercial carriers as well as air operations. In addition inspectors also certify flight instructors, pilots as well as ensure verification of flight training facilities and programs.\nThe aeronautical profession is very dynamic and highly technical. There are numerous technologies that emerge with a view to improve travelling through airborne means. Every flight implies that many lives are at stake at any one time which places a very high demand on the crew and pilots to be highly trained and constantly updated with new developments (Rodrigues & Wells, 2012).\nThe training of pilots must be very intensive so as to ensure that the passengers aboard their aircraft are safe. Prior to being allowed to fly an actual aircraft an aviator is required to hone his skills using simulators that emulate real flight conditions. This is intended to prepare the pilots to deal with many types of scenarios that may present themselves while in flight mode. A pilot is certified after amassing a certain number of flight hours.\nPilot trainers are also constantly put to speed with every new development so that they pass on the knowledge to their students. Aircraft mechanics and engineers are also required to be equally competent as pilots and are held responsible in case a plane develops mechanical problems while in flight (Huang, 2009). This is intended to ensure that they carefully do their work so as to prevent aircraft accidents that usually cause multiple deaths.\nPlanes do not fly a lot during winter. However, the importance of proper winterizing a plane should not be understated as it is a matter of safe flying as well as enhancing the useful life of an aircraft. Manuals usually spell out how a plane should be winterized. One basic thing that should be done is to cover the canopy, windows, prop blades and the horizontal tail as these are the most crucial external parts. Covering reduces damage that is caused by snow, ice, rain and cold which are experienced during winter.\nIn order to enhance the welfare of all passengers it is important for a pilot to be very observant about pressure and oil temperature while flying in cold conditions as such features oscillate significantly when in flight as well as while not in flight. Repairs should be immediately done in case an oil cooler bypass occurs (Stolzer & Goglia, 2011).\nOne of the most basic things to do so as to ensure that flight is completed successfully is checking that the fuel tank is full and that the valves are properly closed. Emptiness in the fuel tank of a plane leads to condensation during winter which may cause corrosion that leads to complications during flight. When flying during cold weather, a pilot should establish whether his plane requires the use of isopropyl alcohol that is added to the fuel while operating in low temperatures.\nMany regulations in aircraft management are usually precipitated by catastrophic events. Such rules have gone long way in preventing other air disasters. The ability of a pilot is one of the most crucial factors during the occurrence of accidents. Pilots are properly evaluated so as to ensure that accidents do not occur as a result of easily avoidable things like fatigue. Aviation safety will continue to be an important matter for all national and international air travel regulators. This will ensure that travelling by air continues to be the safest mode of transport in comparison with others like motor vehicle transportation (Huang, 2009).']"	['<urn:uuid:e99527f3-9b1a-4d33-a868-2e85a79a7a12>', '<urn:uuid:a11a4a5c-c4dd-4710-a236-e71f5f39cb79>']	factoid	direct	verbose-and-natural	distant-from-document	multi-aspect	expert	2025-05-13T06:27:57.068978	19	80	2577
95	What are the main differences between how bounce codes are handled in email systems versus how exceptions are managed in document production systems?	In email systems, bounce codes are handled through a complex set of rules with varying interpretations across different providers, requiring automated rule sets like the Adaptive Email Network with over 3,000 rules to classify bounces. In contrast, document production systems handle exceptions primarily through a closed loop process where damaged pages are immediately ejected and returned to the print queue for reprinting, while electronic delivery failures are kept in a suppressed print queue for potential physical mailing if electronic delivery fails.	['Many organizations routinely send out hundreds of thousands — or more — documents to their clients and customers. These documents (which can include statements, bills, invoices, sales and marketing material, and correspondence) are issued by a variety of enterprises from many vertical markets. In addition, digital technology has added another dimension to the term “sending out” documents. It no longer refers only to printed and mailed hard copy, but to documents and/or notifications transmitted via email, websites, smartphones, and other devices.\nWhile the digital revolution has made it possible to compose, print, insert, re-print/resend (when necessary), and sort this high volume of documents in a single production run, the overall process is made up of several steps that have the potential for breakdowns in accuracy, efficiency, and cost-effectiveness. The challenge is how to combine these steps, which often involve different hardware and software, into a smooth workflow to ensure that all pages are printed properly and they go to the correct recipient through the preferred channel in a timely manner. This is no small task. However, identifying the potential gaps in the production process and installing measures to prevent them is a key step in ensuring a seamless workflow. Here are five of the top gaps we all can relate to:\nGap #1 — Composition Composition of documents is typically done upstream before a job reaches the printer. However, composition can be key to accurately tracking and monitoring the whole production process if, for example, barcodes or other types of coding are used to match the pages of a document. Yet, in many cases, the people who compose the documents have little to no understanding or capability for using barcodes or other identifying markers.\nGap #2 — Document Information For many printing operations — both in-house departments and third-party service providers — the print file arrives with few if any indicators about what’s inside, such as: How many pages? How many pages per envelope? How many documents for electronic versus print distribution? Where a page count is provided, this is the only information the printer has available to track and monitor the job as a whole.\nGap #3 — Accuracy After the pages are printed, they move to insertion, and many printers rely on this stage to confirm the accuracy of the printing. This requires simple arithmetic: We have 10,000 total pages in the file; 9,000 are for mailing and 1,000 are for electronic distribution. Do we have 9,000 inserted envelopes? Do we have 1,000 documents ready for electronic transmission? Not only should an accurate count be maintained, but ensuring that the correct documents are inserted into the right envelopes must also be verified, ideally through a cost-effective process. If this is all happening, great. If not, what’s missing, and how do we reconcile any discrepancies and guarantee document integrity?\nGap #4 — Exceptions Reprints can include pages skipped or damaged in prior production steps, and now they also can include those intended for electronic delivery that bounce back when the recipient has changed their email or SMS text address. Damaged hard copy is, of course, usually easy to identify and can be reprinted on the spot. Bounce-backs need to be discovered as quickly as possible and, as a last resort, printed and mailed. This is often done manually and can mean lost time in getting the document to the recipient.\nGap #5 — Delivery Sorting for delivery is generally done either in-house or by an outside service provider. This step is where the USPS becomes involved in the process, both in the use of the USPS-provided barcodes that direct a piece of mail to the correct address and/or by the USPS providing some quality assurance when a job arrives at one of its service centers.\nInstalling Stop-Gap Measures\nStarting upstream, many organizations have found it useful to invite document designers to at least tour the production floor to gain a realistic understanding of how the production process works, as well as what is and is not possible in a high-volume, high-speed print production environment. Appropriate design is very effective in preventing problems as the job is produced.\nStill, perhaps the most common problem through the printing stage is missing pages, and the method used most often to track pages occurs at the insertion stage, when the number of documents is reconciled with the number of envelopes plus the number of documents tagged for electronic distribution. As mentioned earlier, some production operations may use barcodes on the pages to identify and track them, but this requires investing in technology to read the barcodes. While this can seem like a costly proposition upfront, it may return the investment in improved efficiency and reduced waste of time and materials.\nRegarding reprints, a closed loop process works best. In this process, when a page or a document is damaged as it’s inserted, it’s ejected and immediately goes back into the print queue for reprinting and inserting. Additionally, it’s advisable to keep the documents that are marked for electronic delivery in the print queue, but with the actual print step suppressed. That way, if electronic delivery fails and the email bounces back, the document can be printed and mailed with little delay.\nAt the sorting phase, and circling back upstream, the mailing list has hopefully been purged of items returned earlier as undeliverable to save the wasted time and expense of mailing to non-existent or wrong addresses, and the USPS’s IMb barcodes have been accurately applied.\nFinding a Holistic Approach\nPerhaps the most effective option is to fully automate the workflow with software that can track and monitor the job as it moves through all the stages of production. Currently, several types and brands of these solutions are available to suit the needs of specific production environments. Some of these solutions may work only on certain steps of the production process and/or may be proprietary to the brand of hardware in use.\nOther, more sophisticated workflow solutions provide a dashboard that gives production personnel visibility into the status of the print job throughout the entire process, as well as providing options for moving or redirecting certain functions as the job runs. Managers should examine their specific environments to decide which types of solutions would work best for them.\nWhile digital technologies have made it possible to deliver all types of communications to a greater number of recipients — and faster than ever before — the new processes come with challenges of their own, chiefly upholding a standard of accuracy throughout the various steps in the overall production process. The number of communication channels currently available and customer expectations and preferences for these channels only add to the task.\nWhat’s required is a holistic view of the various steps in production, with providers looking both upstream and downstream for solutions that can contribute to the quality of the print run as a whole. Production managers and personnel should already be familiar with common ways to keep the work flowing smoothly, but in dealing with high-speed, high-volume production runs, the most effective way to ensure accuracy and solve the problems of today’s automation may just be adding a little more automation.\nAn electronic document industry pioneer, Ernie Crawford is President/CEO and founder of, based in Toronto, ON. One of only a small number people worldwide with M-EDP (Master Electronic Document Professional) designation, Ernie has more than 30 years of senior marketing and management experience in the high-volume electronic printing market.\nClick here to return to the Document production and printing topic page.', 'Navigating Bounce Codes in the Wild West of Email\nGiddy-up partner! We got varmints out yonder! Just kidding… but in all seriousness, bounce codes are a little like the wild west. They’re uncertain, fraught with danger, and should be approached with healthy amounts of respect and caution.\nBefore getting into the meat of bounce codes, let’s review the basics. There are two basic bounce that RFC 1893 defines (and in case you didn’t know, RFC’s are the standards that describe internet technologies and are maintained by the IETF, also check out RFC 5248):\n- Transient bounces (also known as soft bounces) are defined as temporary failures or conditions that once they change will allow for the delivery of the message. There’s a numeric code that is attached, or used to define the temporary failure. We refer to this code as a 4.x.x (the x’s are variables).\n- Permanent failures (also known as hard bounces) are just that, permanent failures that will prevent the message from being delivered to the intended recipient. These bounces are classified with a 5.x.x (again the x’s are variables).\n- A sample bounce code might look something like this:\nSMTP error from remote mail server after end of data:\nhost example.domain.com [2a00:1450:4013:c01::1b]:\n550-5.7.1 [2a01:5b40:0:252::55 12] Our system has detected that this message is likely unsolicited mail. To reduce the amount of spam sent to DOMAIN, this message has been blocked. Please visit postmaster.example.domain.com\nIn addition to these numeric designations, extended descriptors shed more light on why messages aren’t being delivered. Email admins review these text strings, and their corresponding bounce codes to determine where problems occur – either on the sender’s side or the receiver’s. With this information in hand, an email admin makes the necessary changes on their end and can “be the town’s sheriff”. Ultimately affecting positive change, and altering the disposition of the message from bouncing to placement in the inbox.\nThis would be a perfect world.\nHowever, we don’t live in that world. I wish we did, but we don’t.\nLike the old west, not everyone uses words the same way. In the real world there’s a little problem with the seemingly innocuous binary construction of bounce codes and their corresponding description strings. While the RFC defines the two flavors of bounce code, there’s no blanket rule or set of strings that must be employed in the bounce to inform a sender on why delivery fails. A postmaster can, in all truth, write whatever he or she wants into the extended description making the job of the recipient infinitely more difficult. A sample bounce could then look something like this…\n- SMTP error from remote mail server after end of data:\nhost example.domain.com [2a00:1450:4013:c01::1b]:\n550-5.7.1 Spammer go die! No seriously, take a long walk off a short pier!\nImagine, every domain has their own set of unique bounce codes and extended descriptions that don’t conform to the simple binary construction defined by RFC. Well you don’t have to imagine it, that’s about the state of bounces all over the world… *deep deep sigh* it’ll be ok.\nHard vs. Soft\nUnfortunately for you and me, the world isn’t a neat place where everything is black and white. There isn’t really a universal agreement on what a permanent vs. temporary failure code means. Although a 5.x.x should be ‘user doesn’t exist’ or ‘domain name doesn’t exist’ etc. that’s not always the case. Certain domains believe that if someone is blocked for spamming, or for including a URL (knowingly or otherwise) in the body of the email that’s on a URL blocklist, then that constitutes a permanent failure and will bounce it back with a 5.x.x. As a long time proponent and advocate of Best Common Practices around messaging, I can see how you might want to permanently fail a sender’s messages for spamming or looking like spam.\nHowever, in reality, one man’s spam is another man’s ham. Spammy messages or poorly targeted campaigns are rectifiable situations. Maybe you didn’t think about the implications of sending to people who haven’t received your email in years, so they ran up the spam complaints and your message went to junk or was blocked. These are things that happen on occasion, prompting work to resuscitate your reputation. This may require enlisting the help of deliverability experts like the ones that work here at SparkPost, but nonetheless, it’s resolvable. Again, the problem is that every ISP and mailbox provider does it differently. There’s no true consensus, despite the RFC, on what goes into an extended description, what constitutes a hard bounce vs. a soft bounce or how to go about remediating.\nDon’t believe me? Check out this list of postmaster pages and the varying degrees they provide:\n- AOL Error Codes\n- Microsoft (Hotmail/Outlook.com/Live.com) Postmaster Page\n- Gmail SMTP Error Reference (which happens to live under google apps) and is different than the Postmaster Tools for bulk senders\n- Comcast SMTP error codes\n- Yahoo! SMTP Error codes\n- Even the US Postal Service got into the SMTP error code game!\nConfused yet? Don’t worry, we have your back! Although these are just a few of the numerous flavors of error code out there, the domains in the list above represent a lot of mail boxes. If you’re industrious and efficient, you solve for the lowest hanging fruit first. You can do this in a few steps. First, tackle the biggest domains. Incorporate those rules and learn them. Then, adjust sending volume, speed and connection rates. These are all in response to the kinds of errors that are being spit back from the domain’s mailbox provider’s MTAs. This helps to achieve righteously high inbox placement. Rest assured SparkPost does all of this.\nSince 25% of the world’s legitimate and non-spam email traverses our software, we see a lot of email. As a matter of fact, we’ve been able to solve the bounce problem for more than the handful of domains I’ve listed above. SparkPost’s automated rule set, the Adaptive Email Network, employs over 3k rules that help us classify a vast majority of the bounces that currently exist in the wild.\nSynchronous vs. A-Synchronous Bouncing\nHere’s where your eyes might glaze over a bit. Bounces return in a couple of different ways. The most common is for the mail server to reject a message from a connecting IP and issue the bounce outright. This is called synchronous as it happens in synch with the conversation. A-synchronous bounces are what you and I see as users. You send an email to your uncle Joe but mis-type his address and receive an email back from Yahoo! saying the message cannot be delivered. The bounce email that you receive is sent back after the bounce, hence it doesn’t happen at the same time you try to deliver the email. The two different conditions change how and where you go looking for the bounces and your reaction to the situation.\nBut nothing is quite so simple. Have you gotten that feeling? A-synchronous bounces can happen in bulk. They aren’t the most common of bounces as it’s more efficient to send synchronous bounces vs. burning up your back end cycles trying to deliver email and then sending email back in response, but they do happen. Senders of bulk email need to deal with this situation in addition to processing bounces handed to them directly by the connecting mail server. Wild west, remember?!\nWhat does this mean for you?\nSimply put, when you know what a bounce code means you can take the appropriate actions to ensure your reputation doesn’t suffer and you’re able to reach the inbox. For example: a 421 from Yahoo! is sometimes called a gray listing and the appropriate action is to pause sending for 4 hours and retry. The only way you know this is to capture the bounce, read its contents and then apply automation rules to ALL outbound email. This puts you in compliance with the domain’s stipulated guidelines. Like I said, we got your back!\nSparkPost’s vast rule set was built over 16 years of operation. Our deliverability team captures and evaluates the occasional bounce that we can’t classify, and then creates a rule to account for it in the future. Yep, we do that. Now do you believe me when I say we have your back?\nBounces are messy. Knowing what to do with them is complicated and requires the experience and ability to scale appropriate responses in real-time. That’s what we do for our clients, which makes them incredibly successful. More of our clients’ wanted email reaches their customers’ inboxes, that’s the SparkPost advantage. Come check it out, or let us know about your bounce woes. We are happy to help you out.']	['<urn:uuid:a0a2a7b2-cfad-47bd-ae34-8d1a81075597>', '<urn:uuid:4257400a-5360-440f-8f54-60aa0d531867>']	factoid	direct	verbose-and-natural	similar-to-document	comparison	expert	2025-05-13T06:27:57.068978	23	81	2714
96	what time start planning home garden	Late winter and early spring is the perfect time to start planning for the upcoming growing season, as it gives you time to research and prepare for your gardening needs.	['After watching their garden beds get buried in snow once again, many gardeners are likely getting eager for winter to fade into spring. If you are new to gardening, it may seem extreme to have it on the brain so soon, but it’s actually the perfect time to start dreaming up your plans for the upcoming growing season.\nAlthough a lot can be grown during the first frost this period, the season is maximized by early preparations such as germinating seeds and starting plants indoors. Planning in late winter and early spring gives you time to research and prepare for your gardening needs. Here are some basic considerations to make if you are a beginner gardener looking to start planning for the upcoming growing season.\nTo start, it is very helpful to understand more about your local climate and geography. This will inform you as to what you can grow where you live, how well it will grow when to start growing and precautions you need to take during the growing season to keep your plants healthy. Determine which hardiness zone you live in by referencing the USDA Plant Hardiness Zone Map. You can find this online at planthardiness.ars.uda.gov. Hardiness zones are classified by their average annual extreme minimum temperatures.\nOnce you know what plants thrive in your area, you then want to consider the growing space you have available. Whether you have a large outdoor yard space or just a small patio or window, evaluate how much of it sees sun during the day and how much of it is shaded. Check for other features such as flatness and potential protection from wind. Don’t get discouraged if your space isn’t ideal. Urban gardening has become increasingly popular and you can find a lot of innovative ideas for gardening in small and odd spaces online. If you don’t have any access to your own outdoor area, try researching local community gardens that you can grow in.\nIf you have a lot of good options, try to choose an area you know you will visit frequently and not neglect.\nNow that you have a grasp on the properties of your available space, use this as a guide to determine what you want to grow. If you want to grow vegetables, then you need a space that gets a lot of sunlight, ideally 6 to 8 hours per day. However, many vegetables thrive in partial shade or sun. Plants that can wilt in full sun and extreme heat such as leafy greens or delicate herbs do well in the sun. Many vegetable plants are shade tolerant, but they just won’t have as plentiful of a harvest compared to when they are grown in full sun. Consider what you are interested in growing, what will thrive in your available conditions and how much work you are willing to put into watering, weeding and harvesting.\nAfter becoming familiar with what plants you want to grow, it is time to get down to the nitty-gritty. Determine what method you want to use for gardening. You can go the traditional route with single-row gardening directly into the ground. If you are interested in maximizing space, working with the natural characteristics of plants, you may want to plan a more intricate permaculture garden. If you’re short on space or can’t dig into the ground, raised bed or container gardeners make great options. The type of gardening method you choose will influence a lot, including layout and necessary supplies.\nAll of this planning can be done while the ground is still frozen solid and should keep you pretty busy while waiting for spring.\nThis article is written by Rachel Baker from The Spokesman-Review and was legally licensed via the Tribune Content Agency through the Industry Dive publisher network. Please direct all licensing questions to email@example.com.']	['<urn:uuid:e9d02495-a7f4-4dd4-b90e-93cbbac45b4c>']	factoid	with-premise	short-search-query	distant-from-document	single-doc	novice	2025-05-13T06:27:57.068978	6	30	637
97	prevent low calcium naturally or with supplements risks benefits	Low calcium can be prevented naturally through a balanced diet including dairy, legumes, eggs, nuts and broccoli, along with outdoor exercise for vitamin D synthesis. While calcium supplements can help treat low levels, they should only be taken with doctor authorization as they can cause side effects like digestive issues and, if overused (over 2,500mg daily), can lead to dangerous elevated calcium levels with symptoms like increased heart rate and weakness.	"['The Main Symptoms of Hypocalcemia\nA medical professional diagnoses you with hypocalcemia when your blood calcium levels are low. Now, to understand why this occurs and how it affects your health, you need to understand some important aspects.\nBelow, we’ll review in greater detail the importance of calcium in the body, what hypocalcemia consists of, and its causes, main symptoms, prevention, and treatment, among other important information to make sure you’re well-informed.\nHow does calcium affect health?\nCalcium is a mineral that helps the body to perform multiple basic and essential functions for your health and well-being. Contrary to popular belief, you don’t only need it for strong bones and teeth.\nIn general, calcium is essential because it:\n- Favors vitamin B12 absorption.\n- Allows blood to clot.\n- Is important for the transmission of nerve impulses and muscle contractions.\n- Contributes to the activation of many basic body enzymes.\n- Also, it aids the internal tasks of cell membranes, favoring the exchange of oxygen and nutrients.\n- In addition, calcium helps certain hormones fulfill their functions in the kidneys and intestines.\nWhen there isn’t enough calcium in your blood, your health suffers and various changes begin to manifest in your body, some more forceful than others.\nThis article may interest you: How to Choose a Calcium Supplement\nWhat are the causes of hypocalcemia?\nAccording to Dr. James L. Lewis, hypocalcemia can result from a disorder of the parathyroid glands, as well as diet, kidney disorders, or certain drugs.\nHere are other causes of hypocalcemia:\n- DiGeorge syndrome.\n- Kidney failure.\n- The consumption of certain drugs (such as anticonvulsants, bisphosphonates, and some antibiotics, among others).\nHowever, the most common causes are:\n- Vitamin D deficiency (due to lack of sun exposure or poor diet).\n- Inadequate calcium intake.\n- Disorders that reduce calcium absorption.\nThe main symptoms of hypocalcemia\nAlthough it doesn’t manifest with strong symptoms at first, as time passes (and there’s no treatment or improvements in diet or other lifestyle aspects), various discomforts appear, such as muscle cramps in the back and legs.\nPeople with hypocalcemia may have dry, flaky skin, as well as weak and brittle nails, in contrast to thicker hair.\nIn advanced cases, hypocalcemia can cause a tingling sensation. In addition, it can affect the brain and cause confusion, trouble concentrating and remembering, delirium, depression, and hallucinations. Nevertheless, we should note that these symptoms disappear once the blood calcium levels are restored.\nA medical professional can diagnose hypocalcemia with a simple blood test.\nHow’s hypocalcemia treated?\nTreatment of hypocalcemia varies depending on the underlying cause and the patient. However, it’s common for doctors to prescribe calcium supplements and, in some cases, vitamin D supplements.\nCalcium supplements are taken orally with the goal of normalizing blood calcium levels. Along with this, doctors often make diet recommendations.\n- Not only dairy products are rich in calcium. Also, you can find it in legumes, such as lentils or chickpeas.\n- Eggs, nuts, and broccoli are also very suitable foods to include in your diet.\n- Hypocalcemic patients should avoid excessive consumption of beverages that contain caffeine, as they can interfere nutrient absorption.\n- The key is to follow a balanced diet, which includes all the food groups in enough quantities.\nCan it be prevented?\nYes, it’s possible to prevent hypocalcemia. How? Following a healthy lifestyle and getting periodic medical checkups.\nThe best thing to do to prevent hypocalcemia is to follow a balanced diet. This way, your body can get everything it needs to work properly.\nWhile diet plays a key role, you should also exercise outdoors, as it has health benefits. Therefore, it’s advisable to take walks and take advantage of the sun’s rays to synthesize vitamin D.\nFinally, regarding the prevention of hypocalcemia, it’s important to clarify something. You should never take calcium supplements without your doctor’s authorization, as it can be counterproductive.It might interest you...', 'Viactiv Calcium Soft Chews are an over-the-counter supplement that contains two forms of calcium: elemental calcium and calcium carbonate. This calcium supplement can be used by people over the age of four who do not receive adequate amounts of calcium from their daily dietary intake. You should be aware of Viactiv Calcium Soft Chew side effects prior to using this supplement.\nVomiting or Nausea\nYou may experience vomiting or nausea after taking a dose of Viactiv Calcium Soft Chews, Kaiser Permanente warns 1. This calcium supplement may irritate your digestive tract, especially if it is taken on an empty stomach. Stomach irritation can lead to a temporary loss of appetite if you are affected. If these side effects persist or become severe, you should consult a physician for further evaluation and care.\n- You may experience vomiting or nausea after taking a dose of Viactiv Calcium Soft Chews, Kaiser Permanente warns 1.\n- Stomach irritation can lead to a temporary loss of appetite if you are affected.\nBowel Movement Changes\nSide Effects of Calcium Hydroxyapatite 1000 mg\nWhile taking this type of calcium supplement, you may experience bowel movement changes. You may have difficulty producing a bowel movement or may produce unusually small, solid stools. This side effect, called constipation, may also contribute to additional abdominal side effects, including bloating, gas, pain or cramping. If you develop prolonged periods of constipation while taking Viactiv Calcium Soft Chews, you should seek care from a doctor.\n- While taking this type of calcium supplement, you may experience bowel movement changes.\nConsuming more than 2,500 milligrams of calcium each day you may be at risk of developing hypercalcemia, a condition characterized by unusually high levels of calcium in the blood, the University of Maryland Medical Center reports 2. Overuse of Viactiv Calcium Soft Chews may cause weight loss, increased heart rate, weakness, increased thirst or urination, headache or muscle aches. If you experience these side effects while taking this calcium supplement you should receive care from a medical professional.\nSide Effects of Calcium Hydroxyapatite 1000 mg\nCalcium Supplements If Allergic to Shellfish\nThe Side Effects on the Stomach of Calcium & Vitamin D\nCan Excess Calcium Cause Dizziness?\nCan Too Much Calcium Carbonate Have Side Effects?\nDoes Calcium Cause Headaches?\nZinc Citrate Side Effects\nBurdock Root Side Effects\nThe Side Effects of the Vitamin D 1.25 mg Soft Gel\nSide Effects of Calcium Sandoz\n- Kaiser Permanente: Viactiv Oral Tablet\n- University of Maryland Medical Center: Calcium - Precautions\n- Bolland, MJ, et. al. Calcium supplements with or without vitamin D and risk of cardiovascular events: reanalysis of the Women\'s Health Initiative limited access dataset and meta-analysis. BMJ. 2011 Apr 19;342:d2040. DOI: 10.1136/bmj.d2040\n- Reid IR. The roles of calcium and vitamin D in the prevention of osteoporosis. Endocrinol Metab Clin North Am. 27: 389-398. DOI:10.1016/s0889-8529(05)70011-6\n- Chen M, Pan A, Malik VS, Hu FB. Effects of dairy intake on body weight and fat: a meta-analysis of randomized controlled trials. The American Journal of Clinical Nutrition. 2012;96(4):735-747. DOI:10.3945/ajcn.112.037119\n- Williams V, Rawat A, Vignesh P, Shandilya JK, Gupta A, Singh S. Fc-gamma receptor expression profile in a North-Indian cohort of pediatric-onset systemic lupus erythematosus: An observational study. Int J Rheum Dis. 2019;22(3):449-457. doi: 10.6061/clinics/2012(07)22\n- Reid IR, Birstow SM, Bolland MJ. Calcium and Cardiovascular Disease. Endocrinol Metab (Seoul). 2017;32(3):339-349. doi: 10.3803/EnM.2017.32.3.339\n- MedlinePlus Medical Encyclopedia, ""Milk-alkali syndrome""\n- Bolland MJ, Grey A, Avenell A, Gamble GD, Reid IR. Calcium supplements with or without vitamin D and risk of cardiovascular events: reanalysis of the Women’s Health Initiative limited access dataset and meta-analysis. BMJ. d2040-d2040. DOI:10.1136/bmj.d2040\n- Chan Soo Shin, et. al. Endocrinol Metab (Seoul). 30(1): 27–34. DOI: 10.3803/EnM.2015.30.1.27\n- Linus Pauling Institute. Calcium.\n- National Institute of Health Office of Dietary Supplements. Calcium.\n- Weingarten MAMA, Zalmanovici Trestioreanu A, Yaphe J. Dietary calcium supplementation for preventing colorectal cancer and adenomatous polyps. Cochrane Database of Systematic Reviews 2008, Issue 1. Art. No.: CD003548. DOI: 10.1002/14651858.CD003548.pub4\n- Zemel, MB et. al. Calcium and dairy acceleration of weight and fat loss during energy restriction in obese adults. Obes Res. 2004 Apr;12(4):582-90. DOI: 10.1038/oby.2004.67\nRae Uddin has worked as a freelance writer and editor since 2004. She specializes in scientific journalism and medical and technical writing. Her work has appeared in various online publications. Uddin earned her Master of Science in integrated biomedical sciences with an emphasis in molecular and cellular biochemistry from the University of Kentucky College of Medicine.']"	['<urn:uuid:af7d85fd-d5db-482b-b4f9-75962b6ca9e1>', '<urn:uuid:d27ba4b6-e85a-4a9d-8cab-6e7ebaae199b>']	factoid	with-premise	long-search-query	similar-to-document	multi-aspect	novice	2025-05-13T06:27:57.068978	9	71	1393
98	What are the three categories of violations that food inspectors look for when evaluating both Foodborne Illness Risk Factors and Good Retail Practices?	Food inspectors categorize violations into three types: Priority, Priority Foundation, and Core. Priority items are violations that can directly contribute to foodborne illness if not controlled, such as not cooking chicken to 165 degrees. Priority Foundation items are violations that could lead to Priority violations if not controlled, like not having a calibrated thermometer. Core violations relate to general sanitation, operational controls, facilities, equipment design, or maintenance, such as having a dirty floor.	"[""Food Establishment Inspections\nThe new food safety inspection system enacted on July 1, 2018, follows best practices in food safety and falls in line with national standards, creating more uniformity in inspections. The system moves away from the older, traditional 100-point scoring system and toward a risk-based inspection approach. This puts an emphasis on Foodborne Illness Risk Factors - the violations which are more likely to lead to consumers getting sick. The CDC has identified 5 major risk factors which contribute to foodborne illness. They are:\n- Improper hot and cold holding temperatures.\n- Improper cooking temperatures.\n- Poor employee health and hygiene.\n- Contaminated utensils and equipment.\n- Food from unsafe sources.\nFood Establishment Inspection Look-Up Available\nPlease be advised that inspections only provide a snapshot of a food establishment's practices, as they are based on what is seen at the time of the inspection. If an establishment does not do well during an inspection, Health Department Staff work to educate the food establishment workers to assist with preventing repeat violations.\nFood establishments in Peoria County are inspected routinely and unannounced depending on the risk assessment classification (PDF) assigned to each food establishment. Risk assessments are based on the State of Illinois Food Service Sanitation Code (PDF) and the Food Safety Code of Peoria County (PDF), and other applicable food safety regulations.\nThe general yearly inspection schedule is as follows:\n- Category I — 3 inspections\n- Category II — 2 inspections\n- Category III — 1 inspection\nCompliance and follow-up (recheck) inspections are conducted as needed in addition to the routine inspections. During any type of inspection, Health Department Staff work to educate food establishment employees as to why certain practices are not acceptable and how these practices can contribute to food-borne illness.\nThere are 58 items or categories under which violations may be written when conducting a food inspection. These violation categories are divided into Foodborne Illness Risk Factors and Good Retail Practices.\nFoodborne Illness Risk Factors are those violations which have a higher likelihood of contributing to a foodborne illness such as improper cooking and hot/cold holding temperatures and poor employee hygiene.\nGood Retail Practices are violations of basic operational and sanitation conditions such as leaking faucets, missing light shields, etc.\nRisk Factor violations and Good Retail Practice violations are also divided into three categories: Priority, Priority Foundation, and Core.\nPriority items are violations that can contribute directly to foodborne illness if not controlled. For instance, not cooking chicken to 165 degrees.\nPriority Foundation items are violations that could contribute to Priority violations if not controlled such as not having a calibrated metal stem thermometer to take the temperature of the chicken.\nCore violations relate to general sanitation, operational controls, sanitation standard operating procedures (SSOPs), facilities or structures, equipment design, or general maintenance. For instance, the floor that an employee is standing on to take the temperature of the chicken is dirty.\nThere is no score. Food Establishments will be given the number of Risk Factor Violations and Risk Factor Repeat Violations.""]"	['<urn:uuid:6a09f544-a584-4aca-9fce-05cce38dd30c>']	open-ended	direct	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-13T06:27:57.068978	23	73	506
99	What should people keep in mind about food, safety, and entertainment when spending a whole day at the New Orleans Jazz Festival?	For a safe and enjoyable Jazz Fest experience, several aspects need attention. For safety, the NOPD advises carrying wallets in front pockets and purses across the torso, staying alert to surroundings, and avoiding distractions from phones. Never leave drinks, food, or property unattended. Regarding food, it's important to start with a good breakfast and stay hydrated as it's likely to be very hot. The festival offers numerous food options, including Cuban dishes like tostones con mojo and various Creole and Cajun delicacies. For entertainment, the festival provides a mobile app with the complete music lineup and food options to help plan your experience. Additionally, many city venues host special nighttime shows featuring festival artists after hours.	['The New Orleans Police Department would like to advise the public of some safety tips when attending this year’s New Orleans Jazz & Heritage Festival presented by Shell. In dealing with festivities of this magnitude, the NOPD solicits the cooperation of the public, which is essential for a safe and orderly season.\n- Stay hydrated, as it is likely to be very hot.?\n- Personal property should not be left in unattended vehicles. ?If no alternative depository is available, personal property should then be locked in the trunk of the vehicle prior to parking.?\n- Prior to parking your vehicle on the street, ensure you are not attempting to park in a residential or restricted area, or blocking a driveway, crosswalk, fire hydrant, etc.?\n- Be mindful of where you park your bicycle; utilize the Jazz Fest bicycle parking area, if possible.?\n- Make a note of where you parked, including street names and nearby landmarks.?\n- Parking during the Jazz Fest is usually extremely limited, so it is strongly suggested citizens utilize carpools, taxicabs or other forms of public transportation.?\n- Illegally parked vehicles are subject to be ticketed and towed. ?\n- It is illegal to purchase or sell tickets in or around the Jazz Fest.?\n- Be mindful of the large amounts of pedestrian traffic in and around the Jazz Fest.?\n- Carry your wallet, money, credit cards, etc., in your front pockets.?\n- Purses should be carried across the torso or on the shoulder, clutched tightly next to the torso, whenever possible.?\n- If you will be consuming alcohol, utilize a designated driver.?\n- Never leave drinks, food or property unattended.?\n- Make sure your child knows his or her name and phone number. Write that information, along with the parent’s name on a piece of paper and place it in the child’s pocket, in case of separation.?\n- Introduce children to a nearby officer, so they know what uniform to look for and advise them to give the officer that information sheet, if they get lost.?\n- When exiting the Jazz Fest, stay alert and be mindful of your surroundings.?\n- Don’t become distracted by cellular devices, cameras, MP3 players, etc.?\n- If you observe anything suspicious or out of the ordinary, notify the police.\nPolice officers will be visible inside and outside of the festival grounds, before, during and after the event. Uniformed officers will engage in crowd control and plainclothes officers will be among the spectators for detection of crimes.\nThe New Orleans Jazz & Heritage Festival is an event enjoyed by thousands, and the NOPD will utilize all resources to assure that it is as safe as possible for all to enjoy.\nHere are some bicycle safety tips we strongly encourage you to observe and practice.\n- Control Your Bicycle. Always ride with both hands on the handlebars. Carry Jazz Fest items in a bicycle carrier or backpack.?\n- Watch for and Avoid Road Hazards. Be on the lookout for potholes, broken glass, gravel, puddles, leaves, and dogs.?\n- Lookout for NOPD Orange Traffic Cones Signaling Road Hazards.\n- Go With the Traffic Flow. Ride on the right in the same direction as other vehicles. Go with the flow of Jazz Fest traffic– not against it.\n- Obey All Traffic Laws. A bicycle is a vehicle and you’re a driver. Obey all traffic signs, signals, and lane markings.\n- Yield to Traffic When Appropriate. Slow down and look to see if the way is clear before proceeding.?\n- Yield to Pedestrians in the Crosswalk.?\n- Be Predictable. Ride in a straight line, not in and out of cars. Signal your moves to others.?\n- Stay Alert at All Times. Use your eyes AND ears. Watch out for potholes, road cracks, wet leaves, storm grates, or anything that could make you lose control of your bike. You need your ears to hear traffic and avoid dangerous situations; don’t wear a headset when you ride.?\n- Look Before Turning. When turning left or right, always look behind you for a break in traffic, then signal before making the turn. Watch for left- or right-turning traffic.\n- Watch for Parked Cars. Ride far enough out from the curb to avoid the unexpected from parked cars (like doors opening, or cars pulling out).\n- Listen to and Follow Directions of NOPD.', 'After Mardi Gras season is past and springtime is in bloom, the party’s just getting started in south Louisiana, with dozens of festivals that celebrate the music, food and culture of the region running throughout April and May.\nFrom the legendary New Orleans Jazz & Heritage Festival to the rapidly growing Baton Rouge Blues Festival to the eclectic and infectious musical energy of Lafayette’s Festival International in the heart of Cajun country, there’s something for everyone looking to experience a slice of Louisiana culture.\nOr, if all-day music festivals aren’t your cup of tea, head over to southwest Louisiana for the long-running Contraband Days Louisiana Pirate Festival. See Jean Lafitte force the mayor to walk the plank into Lake Charles or catch a parade of cannon-firing pirates at this family-friendly May festival.\nIf you’re not sure where to begin when choosing a spring festival or two, New Orleans is always a good start. There are more than two dozen festivals between March and June in the Big Easy alone.\n“Spring in New Orleans is the peak of festival season,” says Kristian Sonnier, vice president of communications at the New Orleans Convention and Visitors Bureau. “It’s a time when locals and visitors join together to celebrate the city’s spirit of hospitality through unique cuisine and live music at fun, outdoor venues that each showcase different elements of New Orleans’ culture.”\nWhatever festival route you take, a little preparation can transform your trip into an experience of a lifetime. Read on for tips on how to make the most of your Louisiana festival experience.\nStart with a Good Breakfast\nAll-day festivals can be physically taxing, so make sure you’re equipped to meet that challenge by starting your day with a quality breakfast. Consider kicking things off with a great cup of Community Coffee to get you in the spirit of the day.\nThe sheer amount of music acts and other attractions at festivals can be overwhelming, so you have to plan ahead to make sure you don’t miss out on your favorites. Luckily, technology makes it easier than ever to organize your experience.\nThe New Orleans Jazz & Heritage Festival, a.k.a. Jazz Fest, offers a mobile app with the complete music lineup and a list of food options, as well as the ability to create your own custom lineup. Lafayette’s Festival International de Louisiane, an international celebration of world music from primarily French-influenced cultures, also has an app with multiple features.\n“If you go and favorite what bands you want to see it actually puts a calendar event in your phone so you get your 15-minute reminder so you don’t miss any of the bands you want to see,” says April Courville, marketing director for Festival International.\nBe Ready to Eat\nFestivals are a magnet for food trucks and other vendors making some unique dishes every bit as memorable as the musicians on stage. Explore the Cuban food booth at Jazz Fest featuring tostones con mojo (fried green plantains with garlic sauce), sample a complete range of Creole and Cajun delicacies, or fill up on classic (and innovative) fried fair foods.\nFestival International features a Louisiana Craft Beer Garden, a growing list of international food vendors and more Louisiana dishes than any one person could tackle in a single festival. “You can trip or fall and land on someone serving Cajun food,” Courville says.\nPrepare for the Weather\nDuring an all-day outdoor event, even moderate heat can present a challenge to festival-goers. When the late-spring Louisiana is unleashed in May and June, it can be downright dangerous without a few precautions.\nBe sure to apply sunblock regularly and wear appropriate clothes that offer protection from the sun (large hats are popular at Jazz Fest, where shade can be in short supply). It’s also a good practice to drink plenty of water and pace yourself if you’re enjoying an adult beverage or two.\nBut remember that spring in Louisiana can be unpredictable. A cool snap or rain showers are both real possibilities, especially in April, so consider carrying a poncho or umbrella, as well as shoes that work well in the mud.\nLook Outside the Festival Gates\nThe spectacle of these festivals often extends beyond the boundaries of the events themselves. Be on the lookout for connected functions outside the festival gates, often at night. Check the city’s entertainment calendar or the festival’s web page for special happenings or unofficial shows prompted by the main event.\nFor example, during Jazz Fest the city’s music venues are well-known for hosting amazing small nighttime shows of major artists booked for the festival. In Baton Rouge, Blues Fest holds a special kickoff event the night before the official weekend begins, with a performance by a festival artist that is more intimate than the full-scale event allows.\n“That’s what I love as a person who enjoys going to festivals,” says Chris Brooks, a Baton Rouge Blues Fest board member and director of business development at Launch Media. “Sure, the festival is great, but so are the things going on around it.”']	['<urn:uuid:c1e1859c-e7f6-47ab-bc8f-d073821bdedb>', '<urn:uuid:7d0c7550-795a-4ab4-9760-a637c6124470>']	open-ended	direct	verbose-and-natural	distant-from-document	three-doc	novice	2025-05-13T06:27:57.068978	22	116	1569
100	How does PayGo help poor families in Africa?	PayGo Energy allows households that cannot afford upfront LPG costs to have gas cylinders and use clean burning LPG by paying in small daily, weekly or monthly installments, helping them avoid harmful fuels like charcoal and kerosene.	['PayGo Energy, a smart-meter pay-as-you-go LPG provider has raised US $1.43M in Series Seed debt and equity financing led by Novastar Ventures, Energy Access Ventures and Village Capital with participation from Global Innovation Fund and Global Partnerships/Eleos Social Venture Fund to support the expansion of its team and customer base in Nairobi, the development of its software platform and next generation smart meter.\nTargeting to provide clean cooking fuel for the mass market, PayGo Energy allows households which cannot afford upfront LPG costs to have the cylinders and use the clean burning LPG yet pay in small daily, weekly or monthly installments.\nAccording to PayGo Energy’s CEO Nick Quintong, “A billion households are forced to cook with dirty fuels everyday, which is not only a serious development challenge, but also a significant market opportunity. This financing will allow us to invest deeply in our technology, build a service that our customers love and prepare for commercial roll-out.”\nLaunched in pilot in 2016, PayGo Energy has developed a steady customer base in Nairobi that has welcomed the innovation of pay-per-use cooking via mobile money. The company currently has an international team committed to launching PayGo’s hardware and software technology across the region. By revolutionizing the distribution of cooking gas for as little as $0.50/day, PayGo Energy helps households to get rid of harmful fuels like charcoal and kerosene, that expose households to health and safety risks and instead use cleaner Liquefied Petroleum Gas (LPG) which is currently beyond their economic reach.\nPayGo Energy impressed Mark Zuckerberg, on his visit to the country and he said: “It’s inspiring to see how engineers here are using mobile money to build businesses and help their community.”\nAs one of the investors, Novastar Ventures believes that PayGo has the potential to transform the way urban Africa cooks—leapfrogging the need for expensive fixed infrastructure to access cooking gas by using pay-as-you-go technology and an innovative operating model to shift households away from the use of charcoal and kerosene to clean, efficient LPG. These views are shared by Energy Access Ventures, a venture firm that focuses on investing in the growing number of dynamic and innovative companies that are taking on the challenge of energy access in Africa.\n“EAV is delighted to be part of PayGo’s round. We are excited by the tremendous potential the company’s technology has to significantly increase uptake of LPG in the home outside of wealthy, urban areas in Sub-Saharan Africa in a way that is highly impactful and commercially promising. In addition, we were most impressed with the Paygo team, who have consistently shown entrepreneurial drive coupled with a passion for making a difference.” – Dr Michael Gera, Managing Partner of EAV.\nThe Global Innovation Fund (GIF), a nonprofit innovation fund that invests in the piloting, rigorous testing, and scaling of innovations targeted at improving the lives of the poorest people in developing countries is proud to support PayGo Energy in providing a supply of affordable, clean gas to their customers, with the aim of reducing the use of cheap but potentially more dangerous fuels such as charcoal and kerosene, which have been linked to a range of health risks such as burns, respiratory diseases, and cataracts.\nIn Kenya, Global Partnerships/Eleos Social Venture Fund has also invested in Eneza Education, Penda Health and Sanergy.']	['<urn:uuid:98d48d91-ff27-4217-a0c2-e8d773f25a1d>']	factoid	direct	concise-and-natural	distant-from-document	single-doc	novice	2025-05-13T06:27:57.068978	8	37	552
