qid	question	answer	context	document_ids	question_factuality	question_premise	question_phrasing	question_linguistic_variation	question_multi-doc	user_expertise-categorization	generation_timestamp	question_length	answer_length	context_length
1	Which needs more frequent watering: Jelly beans plant or baby rubberplant?	The baby rubberplant needs more frequent watering. It should be watered when the top inch of soil is dry, while the Jelly beans plant only needs moderate watering to maintain its plump appearance.	['Succulents That Look Like Green Beans? Yes, they exist! Find out the varieties that resemble your favorite veggie below!\nThe world of succulents is full of surprises, but none quite as delightful as Succulents That Look Like Green Beans. Their bean-like appearance adds a playful touch to garden landscapes and indoor plant displays alike.\nFind Out the Succulent Plants That Look Like Roses here\nSucculents That Look Like Green Beans\n1. Senecio antandroi\nBotanical Name: Senecio antandroi\nEndemic to Madagascar, Senecio antandroi boasts long, green bean looking succulent foliage on a single, erect stem. Its shape and hue create a striking effect. Bright light, well-drained soil, and occasional watering bring out the best of this plant.\n2. Happy Bean Succulent\nBotanical Name: Peperomia ferreyrae\nWith elongated plumpy leaves, the Peperomia ferreyrae is one of the best succulents that look like green beans. Its glossy, bright green foliage looks joyful and inviting. This plant prefers bright, indirect light and well-drained potting medium. Water this succulent when the top inch or two of the soil is dry.\nBotanical Name: Sedum Morganianum\nSedum morganianum, or Burro’s tail, features trailing stems with chubby, blue-green leaves. The overlapping leaves and pink or red star-shaped flowers make it a captivating addition to the succulent garden. Burro’s tail enjoys bright light to full sun and well-drained soil.\n4. Jelly Beans Plant\nBotanical Name: Sedum rubrotinctum\nThis green jelly bean succulent showcases foliage that mimics the appearance of green beans. Its leaves get a red hue in the summer season. This succulent needs well-draining soil and moderate watering to maintain its plump appearance.\n5. Blue Chalksticks\nBotanical Name: Senecio Serpens\nFeaturing elongated cylindrical blue-green, upward-curving foliage that looks quite identical to green beans and fingers. The hue and shape of its leaves make this botanical beauty a unique addition among succulents that look like green beans.\n6. Pickle Plant\nBotanical Name: Delosperma echinatum\nNative to South Africa, delosperma echinatum features spiky leaves resembling pickles and green beans. This intriguing succulent thrives in full sun, well-draining potting mix, and minimal watering. It can tolerate some light shade but hates wet soil.\n7. Narrow-Leaf Chalksticks\nBotanical Name: Senecio Vitalis\nThe Senecio vitalis share similarity with green beans through its slender, elongated leaves. Its gray-green hue adds a serene touch to gardens. This succulent is great for rock, succulent, and Mediterranean gardens. Keep this botanical wonder in full sun and well-draining soil.\n8. Cocoon Plant\nBotanical Name: Senecio haworthii, Caputia tomentosa\nKnown as the cocoon plant, this eye-grabbing succulent boasts tubular, silvery-white foliage reminiscent of beans and cocoons. Give this lovely plant full sunlight and well-drained soil but avoid overwatering.\n9. Woolly Senecio\nBotanical Name: Senecio scaposus, Caputia scaposa\nWooly senecio displays slender, bean-like green foliage covered in silvery hairs. This flowering succulent enjoys full sunlight, a well-drained potting medium, and infrequent watering.\n10. String of Bananas\nBotanical Name: Curio radicans, Senecio radicans\nAs one of the succulents that look like green beans, Curio radicans bring an exotic touch to the garden. The trailing, curved leaves mimic miniature bananas as well. This easy-to-grow succulent is ideal for newbie gardeners.\nCheck Out the Stunning Succulents With Pink Flowers here', 'The baby rubberplant (Peperomia obtusifolia) is a cheerful houseplant with thick, rounded leaves. It’s easy to care for at home, as long as you meet its needs. One of these needs is a soil mix that holds some moisture yet allows excess water to escape. Read on to learn more about how to select the best soil mix for your Peperomia Obtusifolia (Baby Rubberplant).\n- The Best Soil Mix for Peperomia Obtusifolia – The Essentials\n- Why Soil Choice Matters\n- What Are the Primary Components Used in a Potting Mix?\n- Common Signs You’re Using the Wrong Soil Mix for Peperomia obtusifolia\n- The Importance of Well-Draining Potting Soil for Peperomia obtusifolia\n- What Soil pH Levels Are Best for Peperomia obtusifolia?\n- The Ultimate Peperomia obtusifolia Plant Potting Mix Home Recipe\n- The Best Pre-Mixed Soils for Peperomia obtusifolia\n- Soil Mix for Peperomia Obtusifolia FAQs\n- Wrapping Up\nThe Best Soil Mix for Peperomia Obtusifolia – The Essentials\nBaby rubberplants prefer a loose, well-draining soil mix with moderate water-holding capacities. The soil should have a pH between 5.5 and 7.0. A mix made from two parts peats moss, one part perlite, and one part compost will work well for baby rubberplants.\nWhy Soil Choice Matters\nWhile you may think all soil is the same, this isn’t the case. Both naturally-occurring soils and manmade potting soils vary in terms of physical, chemical, and biological composition.\nAll types of soil provide numerous benefits to plants. However, plants may not experience these benefits if they’re planting in the wrong type of soil.\nThe right soil:\n- Provides a place for plants to anchor.\n- Allows for gas exchange.\n- Holds moisture for plants to take up.\n- Retains nutrients until plants need them.\n- Provides a habitat for beneficial microorganisms.\nNaturally occurring soil is classified based on its physical composition. Soil is composed of three inorganic particles (sand, silt, and clay) as well as organic matter.\nSandy soils are well-draining, but they don’t hold much water or nutrients.\nLoamy soils are composed of relatively equal amounts of sand, silt, and clay. Therefore, they have a good balance of moisture retention and drainage.\nClay soils are composed of small particles that easily pack together. They hold water and nutrients well, but they often drain poorly.\nSoils rich in organic matter have a mixture of water holding and drainage. They are also often rich in nutrients.\nWhat Are the Primary Components Used in a Potting Mix?\nMost potting mixes aren’t made from soil removed from the outdoors. Instead, they’re composed of various organic and inorganic materials. The following materials are often used in potting mixes.\n- Compost is decomposed organic matter. It can add some nutrients to a potting mix, but it mainly increases nutrient-holding and water-holding. It can also add a boost of beneficial microorganisms.\n- Sphagnum peat moss is a slightly acidic natural material that is formed when vegetation decomposes under wet and anaerobic conditions. It increases nutrient holding and water holding capacities.\n- Coco Coir is made from coconut husk. It is often used as an alternative to peat moss.\n- Vermiculite is a type of expanded rock that helps with moisture retention as well as drainage.\n- Pine bark fines are small pieces of pine bark that help hold moisture while also increasing drainage.\n- Pumice is a type of volcanic rock with many small pockets. It increases drainage and aeration.\n- Perlite is an expanded rock that resembles small pieces of styrofoam. It helps increase aeration and drainage.\n- Sand is the largest naturally occurring soil particle. It improves aeration and drainage.\n- Soil activators contain beneficial microorganisms that help transform nutrients into forms that plants can take up.\n- Rocks and Pebbles increase drainage.\nCommon Signs You’re Using the Wrong Soil Mix for Peperomia obtusifolia\nUsing the wrong soil can negatively affect your baby rubber plant in multiple ways.\nThe biggest concern with baby rubber plant soil is that it doesn’t drain well enough. If your soil is too high in clay or organic matter, excess water will have trouble draining. Therefore, your plant’s roots will end up sitting in moist soil.\nOver time, this can lead to a fungal condition known as root rot. As plant roots become slimy and rotted, they are unable to properly take up water and nutrients. This can lead to wilted and/or discolored plants.\nAnother thing to look out for with Peperomia obtusifolia soil is compaction. Compaction is more common if your mix is low in larger particles such as sand, perlite, and pine bark fines.\nIf soil is compacted, plants will be unable to exchange gasses and transport water and nutrients. This can result in stunted and discolored plants.\nIf soil contains too much sand and/or perlite, it will not be able to hold much water. Therefore, plants may become wilted.\nThe Importance of Well-Draining Potting Soil for Peperomia obtusifolia\nThanks to their thick, fleshy leaves, baby rubber plants can retain a good amount of moisture. This means they can withstand a few days of dry soil. However, they can not tolerate consistently moist soil.\nIf soils don’t drain excess water, plant roots can drown or rot. Both of these will cause issues with water and nutrient uptake.\nWell-draining soils will allow excess water to escape. Larger particles such as sand and perlite increase drainage.\nYou should also make sure to use a pot with drainage holes.\nWhat Soil pH Levels Are Best for Peperomia obtusifolia?\nMost types of peperomia plants prefer neutral or slightly acidic soil. Look for a soil mix with a pH between 5.5 and 7.0.\nThe Ultimate Peperomia obtusifolia Plant Potting Mix Home Recipe\nA great baby rubber plant potting mix will hold moisture for a few days but allow excess water to escape. It should also hold nutrients while also allowing for good aeration and gas exchange.\nTo create a great soil mix for baby rubber plants, thoroughly combine the following:\n- two parts peat moss or coco coir\n- one part perlite\n- one part compost\nThe peat moss/coco coir will retain water and nutrients while providing air pockets. The perlite will increase drainage and aeration. The compost will provide nutrients and will also increase water and nutrient retention.\nMake sure to thoroughly combine the components before adding the mix to a pot.\nThe Best Pre-Mixed Soils for Peperomia obtusifolia\nIf you’re looking to buy premixed potting soil rather than making your own, you’re in luck. The following products will work well for baby rubber plants.\n(Editors Note: Petal Republic participates in partnership programs with Amazon and other merchants to help connect readers with relevant products and services we may recommend).\nSoil Mix for Peperomia Obtusifolia FAQs\nHow Often Should I Switch Soil for My Peperomia obtusifolia?\nYou’ll only need to change potting soil when you repot your Peperomia obtusifolia plant. Since these plants like being a bit rootbound, you’ll only need to repot every three to five years.\nIf you see signs of root rot or soil-borne disease, you should switch your soil immediately.\nCan I Use Cactus Soil for Peperomia obtusifolia?\nWhile cactus soil may be okay for baby rubber plants, it isn’t ideal. If you want to use cactus soil, mix one-part soil with one part peat moss or coco coir.\nDoes Peperomia obtusifolia Like Wet or Dry Soil?\nPeperomia obtusifolia doesn’t like wet or dry soils. Rather, they prefer slightly moist soil. A good practice is to water your plants when the top inch of soil is dry.\nWhat are the Primary Considerations for Soil When Repotting Peperomia obtusifolia?\nWhen you repot your baby rubber plant, you’ll want to swap out the old soil for new soil. Make sure to choose a well-draining potting mix and avoid compacting the soil.\nDoes the Size of the Plant Affect the Soil Mix for Peperomia obtusifolia?\nNo, the size of your plant does not affect the soil mix. All sizes of plants prefer similar potting soils.\nDoes the Potting Container Influence the Type of Soil Mix for Peperomia obtusifolia?\nA pot’s size and the material do not impact the type of soil you should choose. However, soil in terra cotta pots might dry out quicker than soil in ceramic or plastic pots.\nDoes Peperomia obtusifolia Need Deep Potting Containers?\nNo, Peperomia obtusifolia does not require deep containers. Their short roots are happy in medium to shallow pots.\nNow that you know about the proper soil mix for the Peperomia obtusifolia plant, you can give your plant a good place to root. Remember to choose a well-draining and well-aerated mix that holds a bit of water.\nFor more, see our guide to the best plant shops shipping Peperomia obtusifolia plants nationwide throughout the United States.\nBriana holds a B.S. in Plant Sciences from Penn State University. She manages a small market garden where she grows vegetables and herbs. She also enjoys growing flowers and houseplants at home.']	['<urn:uuid:df7cd97c-227a-4119-8a58-264de3ca6990>', '<urn:uuid:6d8bbdc6-8537-4dc3-b132-577e3b7ba692>']	factoid	with-premise	concise-and-natural	similar-to-document	comparison	novice	2025-05-13T03:20:41.944655	11	33	2021
2	foreign adoption recognition rules wisconsin vs oregon	In Wisconsin, if a resident adopts a child born outside the United States and presents proof of birth to the state registrar, the registrar will prepare a birth certificate indicating the child's date and place of birth, adoptive name, and adoptive parents' names. In Oregon, a foreign adoption that is valid and legal in the nation where it occurred will be automatically recognized as valid and legal for all purposes, and upon request, the state registrar will prepare and register a 'Record of Foreign Live Birth' showing the actual country of birth.	['As a hopeful adoptive parent or pregnant mother considering adoption in the Badger State, you may feel overwhelmed by adoption processes, laws and qualifications. If you live in Milwaukee, Madison, Green Bay, or anywhere else in the state, read on to learn how to adopt or place a child for adoption in Wisconsin.\nLaws, Rules and Qualifications for Adopting a Child in Wisconsin\nEvery state has laws regulating the adoption process, from who can adopt to allowable adoption expenses. The following section provides information on basic laws and guidelines for adopting a baby in Wisconsin.\nWhat are the laws and qualifications for adopting a child in Wisconsin?\nAn unmarried adult, stepparent or husband and wife jointly may adopt in Wisconsin.\nWhat adoption expenses can be paid by adoptive families in Wisconsin?\nAdoptive families are permitted to pay the actual cost of the following:\n- Birth parent counseling\n- Maternity clothes up to $300\n- Transportation for the birth parents related to the pregnancy or adoption\n- Medical and hospital care in connection with the pregnancy and birth\n- Medical and hospital care received by the child\n- Legal services for the child and/or birth parents\n- Living expenses up to $5,000 if necessary to protect the health of the birth mother and baby\n- Birthing classes\n- A gift to the child’s birth mother, not to exceed $100 in value\n- The actual cost of services provided by a licensed child welfare agency\n- The cost of the home study investigation\nThe Department of Children and Families may charge a $75 fee to review, certify and approve foreign adoption documents.\nAn accounting of expenses must be provided to the court at the time of the hearing on the adoption petition. The report will include an itemized list of all transfers of anything of value made or agreed to be made in connection with the adoption. The list will show the goods or services for which each payment was made, as well as the date of each payment and the name and address of each attorney, doctor, hospital, agency or other professional receiving payment.\nWhat are the laws to become a foster parent in Wisconsin?\nProspective foster parents in Wisconsin must meet the following minimum qualifications:\n- Be at least 21 years old\n- Have sufficient income to cover your financial needs\n- Have enough room for the child\n- Complete training\n- Pass criminal background checks\n- Be in good physical and mental health\nFor more information about foster care in Wisconsin, visit the Wisconsin Department of Children and Families.\nWhat are the requirements to finalize an international adoption in Wisconsin?\nIf a Wisconsin resident adopts a child born outside of the United States, and if the adoptive parent presents proof of the facts of birth to the state registrar, the registrar will prepare a birth certificate for the adopted child indicating the child’s date and place of birth, adoptive name, the adoptive parents’ names and the source of information of each of these facts.\nIs it legal to use advertising or facilitators to adopt in Wisconsin?\nOnly the following may use advertising in connection with adoption:\n- The department, a county department or licensed child welfare agency\n- A person or agency providing information through the state adoption information exchange\n- A foster care and adoption or post-adoption resource center\n- An adoptive parent who has received a favorable recommendation from the department, a county department or licensed child welfare agency\n- A person seeking to place a child for adoption\nIt is a felony to place or agree to place a child for adoption in exchange for anything exceeding actual authorized costs. It is a felony to solicit, negotiate or arrange the placement of a child in exchange for anything of value. Adoptive parents may only pay the actual cost of legal and other services connected with the adoption in order to receive a child for adoption.\nLaws, Rules and Qualifications for Placing a Baby for Adoption in Wisconsin\nThere are many Wisconsin adoption laws in place to protect birth parents’ rights throughout the adoption process. If you are considering adoption for your child, it is important to understand the basic rules and regulations of placing a baby for adoption in Wisconsin.\nWhen and how can birth parents consent to the adoption?\nIn Wisconsin, birth parents must file a petition for voluntary termination of parental rights. A hearing will be held within 30 days of filing the petition, but not before the birth of the child. If the child is of Indian heritage, consent cannot be executed prior to or within 10 days after birth.\nThe parent must personally appear at the hearing to give his or her consent to termination of his or her parental rights. The court may also accept written consent given before an embassy official, military judge or a judge of any court. A birth father may consent to the adoption by signing a written, notarized statement saying he has been informed of and understands the effect of termination of parental rights and voluntarily relinquishes any rights he has to the child.\nIf the child is of Indian heritage, consent must be executed in writing, recorded before a judge and accompanied by a written certification by the judge that the consequences were fully explained in English or interpreted into a language that the parent understands.\nWho must consent to the adoption?\nThe child’s parents may consent to a voluntary termination of parental rights. The following people must be notified of any hearing for termination of parental rights:\n- The parent(s) of the child, unless the child’s parent has waived the right to notice\n- A man who has filed an unrevoked declaration of paternal interest before the birth of the child or within 14 days of the child’s birth\n- A man alleged to be the father based on information presented to the court, unless he has waived the right to notice\n- A man who has lived in familial relationship with the child and may be the father\n- The guardian or legal custodian of the child\nIf the child is age 12 or older, he or she must be notified to attend his or her adoption hearing.\nWhen is consent not needed?\nNotice of a hearing to terminate parental rights does not need to be sent to a man who may be the father of a child if he meets all of the following requirements:\n- He is not married to the child’s mother\n- His paternity has not been established\n- He failed to establish his right to notice\nIn addition, consent is not required from a parent whose rights have been terminated involuntarily. A parent’s rights may be terminated if the parent has abandoned or abused the child, the parent has failed to assume responsibility for the child or establish a relationship with the child, the parent caused the child’s conception as a result of incest or sexual assault, etc.\nWhen does the birth parents’ consent become irrevocable?\nA parent who has given consent may file a motion within 30 days of the entry of judgement or order terminating parental rights to withdraw consent based on the following grounds:\n- Mistake, surprise or excusable neglect\n- Newly discovered evidence that entitles the parent to a new trial\n- Fraud or misrepresentation\n- A voided judgment\n- A prior judgement upon which the judgment is based has been reversed or vacated\nWhat rights does the father of the baby have in Wisconsin adoptions?\nA man is considered to be the parent of a child if he is a biological parent, a husband who has consented to the artificial insemination of his wife, or a parent by adoption. A man is presumed to be the natural child of a father if he and the child’s mother have acknowledged paternity.\nAn unmarried man claiming to be the father of a child may file with the department a declaration of paternal interest. A declaration may be filed any time before the birth of the child or within 14 days after the child is born.\nHome Study and Post-Placement Requirements in Wisconsin\nOne of the most important steps for prospective adoptive and foster parents in Wisconsin is the home study. The home study determines whether prospective parents are able to provide a safe, nurturing home to a child. The following section answers common questions about the Wisconsin home study process.\nWhat is included in the Wisconsin home study process?\nThe Wisconsin home study includes the following:\n- Criminal background checks\n- Child abuse registry checks\n- Pre-adoptive training\nWho is included in the home study process?\nThe Wisconsin home study includes the adoptive parents and any other adults residing in the home.\nWho will conduct the home study?\nIf an agency has guardianship of the child, the agency will conduct the home study. In a relative adoption in which an agency does not have guardianship of the child, the department, a county department or a licensed child welfare agency will complete the home study. If the child is a foreign citizen and is under the guardianship of an individual, the agency that conducted the home study prior to the child’s entry into the United States will conduct the home study.\nOn what grounds will the home study not be approved in Wisconsin?\nThe home study may not be approved if the petitioner has been convicted of murder, homicide, battery, sexual assault or exploitation, child abuse or neglect, incest, child prostitution or child pornography.\nWhen should the home study be completed?\nThe court will order a home study investigation after an adoption petition is filed. The agency conducting the home study must file its report at least 10 days before the hearing on the petition.\nWhat are the post-placement study requirements for Wisconsin?\nThis issue is not addressed in Wisconsin adoption laws.\nWhat are the home study requirements for stepparent or relative adoptions in Wisconsin?\nIn a stepparent adoption, the department, a county department or a licensed child welfare agency will conduct an interview with the petitioner and check the petitioner’s background through public records, including those maintained by the department or any county department.\nWhat are the home study requirements to adopt a child from another state?\nIf a child born in Wisconsin is being placed in an adoptive home outside of the state, an appropriate agency in that state must complete the home study and ensure the adoptive placement meets the criteria established by that state’s laws. Any interstate placement is subject to the provisions of the Interstate Compact on the Placement of Children (ICPC).\nWhat are the requirements to adopt a child that is currently in my care?\nIf the adoptive parents have previously completed the home study and foster care licensing process, the agency will obtain criminal history and child abuse and neglect records checks.\nTo start the home study process, contact one of these trusted Wisconsin home study providers:\n- Adoption Choice\nAdoption Choice Inc. is a Wisconsin licensed nonprofit child placing agency with offices in Green Bay, Milwaukee and Madison. The agency provides services for international, domestic, independent, out-of-state, relative and stepparent adoptions.\n- Adoptions of Wisconsin\nAdoptions of Wisconsin, Inc. (AOW) is a full-service licensed adoption agency providing services for interstate, independent, stepparent, relative and LGBT adoptions, as well as home studies for embryo adoption.\n- Adoption Babylink (WI)\nAdoption Babylink is a licensed child-placing agency in Wisconsin and Georgia. The agency assists families with domestic and international home studies, home study updates and post-placement reports.\nVisit 1800HomeStudy.com to learn more about Wisconsin home study providers.\nWisconsin Adoption Professionals\nFor more information about adoption in Wisconsin or to begin the adoption process, contact one of these local adoption professionals:\nFor more information about foster care in Wisconsin, visit the Wisconsin Department of Children and Families.\nThings to do in Wisconsin\nWhether you find yourself in the Badger State for visits with prospective birth parents or you’re waiting for ICPC approval, here are a few fun places for adoptive families to visit in Wisconsin:\n- Olbrich Botanical Gardens (Madison)\n- Wisconsin State Capitol (Madison)\n- Peninsula State Park (Fish Creek)\n- Devil’s Lake State Park (Baraboo)\n- Harley-Davidson Museum (Milwaukee)\n- Bay Beach Amusement Park (Green Bay)\n- Cave Point County Park (Sturgeon Bay)\nMore information about visiting Wisconsin is available at http://www.travelwisconsin.com/.', 'If you are an Oregon resident considering adoption, either as a prospective adoptive parent or a woman facing an unplanned pregnancy, you are likely wondering: How does adoption work in my state? This guide provides all the Oregon adoption information you need, from qualifications for adoptive parents to the laws for placing a child for adoption in Portland, Salem, Eugene and beyond.\nLaws, Rules and Qualifications for Adopting a Child in Oregon\nAdoption laws may seem overwhelming, but if you are considering adopting a child in Oregon, it is important to understand adoption qualifications, processes and procedures in your state. The following information details the rules and regulations for adopting a child in Oregon.\nWhat are the laws and qualifications for adopting a child in Oregon?\nAny person may adopt as long as at least one party in the proceeding has resided in Oregon continuously for at least six months.\nWhat adoption expenses can be paid by adoptive families in Oregon?\nAdoptive parents may pay legal, medical, living and travel expenses if they are included in a written disclosure statement, which must accompany the adoption petition and include an itemized accounting of all fees paid in connection with the adoption.\nWhat are the laws to become a foster parent in Oregon?\nOregon foster parents need to be at least 21 years old and be financially able to support themselves and a child.\nWhat are the requirements to finalize an international adoption in Oregon?\nA foreign adoption that is valid and legal in the nation where it occurred will be recognized as valid and legal for all purposes in the state of Oregon. Upon request of the court, the parents or the adopted person (once he or she is 18), the state registrar will prepare and register a record of foreign live birth. The record will be labeled “Record of Foreign Live Birth” and will show the actual country of birth.\nIs it legal to use advertising or facilitators to adopt in Oregon?\nIt is unlawful for any person to advertise that a child is available or wanted for adoption. This law does not apply to the state Office for Services to Children and Families or licensed Oregon adoption agencies that have a contract authorizing such actions. People who have successfully completed the home study or their attorney or uncompensated agent may also advertise for adoption.\nLaws, Rules and Qualifications for Placing a Baby for Adoption in Oregon\nEvery state has laws and regulations in place to protect birth parents’ rights throughout the adoption process. If you are living in Oregon and are considering placing your baby for adoption, this section will give you the information you need about executing consent, birth father rights, and more.\nWhen and how can birth parents consent to the adoption?\nConsent must be executed in writing and attested to by the court or an authorized person. A birth parent executing consent must be notified of their right to receive three prepaid adoption-related counseling sessions prior to relinquishment and three sessions after relinquishment. This notice must be given in writing and provided by the birth parent’s attorney, adoptive parents’ attorney or the agency representative taking the consent.\nWho must consent to the adoption?\nConsent is required of the child’s parents, the child’s guardian if there are no living parents, the next of kin if there is no living parent and no guardian, or some suitable person appointed by the court if there is no living parent, guardian or next of kin qualified to consent. If the child is age 14 or older, the child’s consent is also required.\nWhen is consent not needed?\nConsent is not necessary when:\n- A parent has been adjudged mentally ill or deficient\n- A parent is imprisoned and serves a sentence of at least three years\n- A parent willfully deserts or neglects the child without just and sufficient cause for one year prior to filing the adoption petition\n- The mother was married at the time of conception or birth, but her husband at the time was not the father of the child; in this case, his consent is not required\nWhen does the birth parents’ consent become irrevocable?\nA person giving consent may agree that the consent is irrevocable and waive their right to a personal appearance in court by a duly signed and attested certificate. In this case, the consent may not be revoked unless fraud or duress is proven.\nWhat rights does the father of the baby have in Oregon adoptions?\nA man is presumed to be the father of a child if he and the child’s mother were married at the time of the child’s birth, even if the marriage is void; or if he and the child’s mother were married and the child was born 300 days after the termination of the marriage.\nAlternatively, paternity may be established as follows:\n- By marriage after the birth of the child when the parents have filed a voluntary acknowledgement of paternity\n- By filiation proceedings\n- By filing a voluntary acknowledgment of paternity in Oregon or another state\n- By paternity being declared by another provision of law\nHome Study and Post-Placement Requirements in Oregon\nFor many adoptive parents in Oregon, the home study is one of the most stressful steps of the adoption process. The following information will help calm your fears and answer your questions about what to expect during your Oregon home study.\nWhat is included in the Oregon home study process?\nThe Oregon home study includes the following elements:\n- Financial information demonstrating the adoptive parents’ ability to meet the needs of the family and a child\n- Medical information current within the past 24 months\n- Mental health information when applicable\n- Copies of important documents such as marriage certificates, divorce verification or death certificate of a spouse\n- Criminal records and child abuse registry checks for each member of the household age 18 or older\n- Four references\nWho is included in the home study process?\nAll adult residents of the home are included in the home study.\nWho will conduct the home study?\nThe home study will be completed by the Department of Human Services or a licensed adoption agency.\nOn what grounds will the home study not be approved in Oregon?\nThe home study may not be approved if:\n- There is sufficient information to determine that the applicant cannot meet adoption home standards\n- An applicant’s license or certificate to provide services to the children, the elderly or people with disabilities has been or currently is denied, revoked or suspended\n- Information is falsified or omitted\n- The applicant does not respond to requests for information within the timelines established by the department\n- The applicant does not submit the required information\nCriminal convictions may disqualify a subject from being an adoptive parent. The home study will not be approved if an individual has been convicted of a felony involving:\n- Violence including rape, sexual sault or homicide\n- Intentional starvation or torture\n- Child abuse or neglect\n- Spousal abuse\n- Aiding, attempting or conspiring to cause the death of a child\n- Sexual abuse\n- Any crime that involves a child as the victim, including child pornography\nThe home study may not be approved if an individual has been convicted in the past five years of a felony involving physical assault, battery or a drug-related offense.\nWhen should the home study be completed? When must the home study be renewed?\nThe Oregon home study must be written or updated within 12 months prior to the placement selection.\nWhat is a post-placement study in the adoption process? What are the post-placement study requirements for Oregon?\nIn Oregon, post-placement supervision includes face-to-face contact with the child, assessments of the child’s safety and wellbeing, services and support to assist the adoptive parents and documentation from the supervision worker that includes a recommendation regarding finalization of the adoption.\nWhat are the home study requirements for stepparent or relative adoptions in Oregon?\nUpon request by the prospective adoptive parent, the department may waive the home study and post-placement requirements for stepparent adoptions.\nWhat are the home study requirements to adopt a child from another state?\nAny interstate placement of a child is subject to the Interstate Compact on the Placement of Children (ICPC).\nWhat are the requirements to adopt a child that is currently in my care?\nA foster parent may request consideration for adoption when adoption is the child’s identified permanency plan, the child has been in the foster parent’s custody for 12 consecutive months, the foster parent is willing to be considered as an adoptive resource for the child’s siblings whose goal is also adoption, and a relative placement is not available.\nTo start the home study process, contact one of these trusted Oregon home study providers:\n- All God’s Children\nAll God’s Children International is licensed to perform home studies in Oregon for families adopting through any adoption agency.\n- Holt International\nHolt International provides home study and post-placement services for families in Oregon.\n- Christian Family Adoptions\nChristian Family Adoptions offers home study and post-placement services for independent adoptions, infant adoptions and state foster care adoption programs in Oregon.\nVisit 1800HomeStudy.com to learn more about Oregon home study providers.\nOregon Adoption Professionals\nFor more information about adoption in Oregon or to begin the adoption process, contact one of these local adoption professionals:\n- American Adoptions\n- Adoptions of Southern Oregon\n- Christian Family Adoptions\n- Open Adoption & Family Services\n- Journeys of the Heart\n- Tree of Life Adoption Center\nFor more information about foster care in Oregon, visit the Oregon Department of Human Services.\nThings to do in Oregon\nIf your adoption journey leads you to meet prospective birth parents or wait for ICPC approval in the Beaver State, be sure to take advantage of all it has to offer:\n- Columbia River Gorge National Scenic Area (Hood River)\n- Crater Lake National Park\n- Haystack Rock (Cannon Beach)\n- Multnomah Falls (Bridal Veil)\n- Cape Perpetua Scenic Area (Yachats)\n- Smith Rock State Park (Redmond)\nFind more information about visiting Oregon at http://traveloregon.com/.']	['<urn:uuid:0112c321-06d1-4d04-b178-6ae1aae877a7>', '<urn:uuid:251450e8-fc44-4110-a8e7-359b7a95f180>']	open-ended	with-premise	short-search-query	distant-from-document	comparison	novice	2025-05-13T03:20:41.944655	7	92	3773
3	ship mail delivery service detroit water pollution effects	The Detroit River Mail Boat provides essential services to ships, delivering mail, supplies, and facilitating crew transfers since 1895. Operating from April to mid-December, it maintains the unique distinction of being the only postal unit worldwide dedicated to serving moving vessels. However, these ships contribute to environmental concerns through ballast water discharge, which the International Maritime Organization regulates due to its potential to transport harmful organisms, including cholera, invasive mussels, and toxic algae, causing ecological damage and health risks. The economic impact of invasive species introduction through ballast water costs the U.S. more than $6 billion annually just from pest mollusks alone.	"['On June 17, 1895, under Postmaster John J. Enright, a postal service was inaugurated in Detroit with the first delivery made on June 19th. There is no evidence of a special cancel available for that first delivery since a two-week trial had been agreed on..... but, it was unique then, as it is today.\nThe Detroit River Post Office Station is the ONLY postal unit known in the world devoted exclusively to the delivery of mail to vessels that are UNDER WAY.\nDuring the months when the Detroit River is navigable (from the first week in April to mid-December), the Mail Boat, operating out of the River Station at the foot of 24th Street, delivers mail addressed to those on board passing ships and picks up outgoing mail from them., The little Mail Boat rides alongside the big ships as they move up or down river. Mail from the ships is lowered to the Mail Boat in a pail fastened to a rope; deliveries made to the ships are hauled aboard using the same process.\nDuring the WWII years, station numbers were assigned to all stations to help facilitate mail sorting by the inexperienced clerks ,who replaced regular workers ,due to the draft, etc.. Detroit River Station received #22. When ZIP CODES were introduced in 1963, the River Station was assigned it’s own exclusive ZIP CODE – 48222. The Detroit River Station was a fully functioning post office; it had a Superintendent and up to eight “carriers” assigned on a full-time seasonal basis. Since ships pass at all times of the day or night and every day of the week, The Station was manned seven days a week and 24 hours a day or “24/7” in today’s parlance.\nThe Mail Boat is not owned by the USPS. It’s services are obtained by government contract with private owners. The first mail boat, in 1895, was the “FLORENCE B”- owned and operated by Charles F. Bielman. At that time, the Mail Boat operated from the foot of Bates Street, one block east of Woodward Avenue. The DETROIT MARINE STATION was housed in a building used by the Detroit & Windsor Ferry Company. Here, the mail was processed for delivery to ships as they passed.\nIn the days of the “FLORENCE B”, mail was delivered somewhat differently than at the present time. Deliveries were not made directly from the Mail Boat. Instead, the “FLORENCE B”, when it went out to contact a passing vessel, towed a man in a rowboat directly into the path of the oncoming ship…and left him there. Using oars, the carrier in the rowboat avoided being run down but stayed close enough so that as the ship passed, he could throw a line aboard. This was made fast and the rowboat was jerked along against the ships’s side. Mail was then transferred up in a bucket on a line. Outgoing mail was lowered in the same pail; the rowboat was cast loose. The “FLORENCE B” came around to pick it up. Today, the Mail Boat snuggles up to a ship’s side, maintaining the same speed, while transfers are made.\nThe “FLORENCE B” was in operation from 1895 to 1907 and then followed by the “C.F.BIELMAN” until 1932. In those days, contracts ran from July 1st of one year through June 30th of the next year. The “G.F.BECKER” assumed the job and carried mail from 1932 – 1936. Next came the “O.F.MOOK” from 1936 to 1946. When Mr. Mook died in an onshore accident, the “G.F.BECKER” took over until the contract expired in 1948.\nIt was on July 1, 1948 that the J. W. Westcott Company won the contract using the “J.W.WESTCOTT” as the Mail Boat. In 1949, the company replaced her with a new craft, the “J.W.WESTCOTT II”. As of this writing, she is still operating as Detroit’s Mail Boat.\nDuring 1900, the MARINE STATION was moved from it’s original location to the foot of First Street, in a part of the old Michigan Central building. About five years later, the office was moved across the street to the old Wayne Hotel overlooking the river. In 1928, the operating point was moved to the foot of 12th Street. It remained there until 1948. It was during this period…1928 to 1948…that mail was actually sorted on the boats and the Mail Boat became a truly “FLOATING POST OFFICE.”\nIn 1948, the RIVER STATION was moved back to the foot of First Street near the WESTCOTT Co. headquarters, when they took over the mail contract. The station moved again in 1954, for a brief period, into the fireboat station at the foot of 24th Street. Finally, in 1955, new quarters were built next door and mail was no longer sorted on the boat itself, but was readied in advance at the station for delivery. The same procedure is followed now.\nIn it’s first year of operations, the Mail Boat handled 47,000 pieces of mail/parcels. By the mid 50’s, the total was up over 2,000,000 pieces a year. What with larger ships (fewer total); smaller crews; modern ship-to-shore telecommunications and on-board computers, the volume is down to one-tenth of what it was.\nOver the years, the distinctive Mail Boat has gained an international reputation and attracts visitors from near and far. The service it provides is considered to be in the finest tradition of the U.S. Postal Service. The Detroit Post Office is very proud of the Mail Boat’s long record of achievement and the cry, “Here comes the Mail Boat” will continue to be heard for years to come on passing vessels plowing their courses up and down the Detroit River.\nIn 1962, The MOTOR CITY STAMP & COVER CLUB prepared cachets for the Mail Boat’s Season Opening Day ceremonies. It replicated a cachet sponsored by the Detroit Chamber of Commerce and the Michigan Stamp Club…in 1932…the first official philatelic recognition awarded to the Detroit River Station and it’s Mail Boat.\nEach year since 1962, the MCSCC has sponsored covers for both OPENING and CLOSING DAY ceremonies. (The station doesn’t actually close. It remains open on reduced hours. Only ship operations cease until the river is ice free).\nThe MCSCC is recognized by the J.W.WESTCOTT Co. as their official cachet sponsors, even though other groups have sponsored cachets on an irregular basis. The company has adopted one of our cachets as their logo and uses it on the company stationary. A complete collection of covers, produced by the MCSCC in honor of this unique mail service, is displayed at the River Station.\nThe MCSCC is proud of the role they have played in continuing to familiarize this mail delivery service. The USPS has provided more prestige by providing special pictorial cancels authorized for use only on Opening and/or Closing Days.\nUnder the General Managership of James Hogan (Grandson of the founder), the station provides a wide range of services, as well as delivering the mail. It is a common sight to see ship stores, food, spare parts, laundry, tobacco products, candy, lake and river charts, postal stamps and stationery, oil and lubricants, equipment needing repair, household goods…even pets being put on board ships. As a transfer point, seamen on leave embark or disembark via a Jacob’s ladder. Great Lakes pilots, required on all foreign vessels, also use it as a transfer point. All in all, the Detroit River Station is a very busy place.', 'Ballast water discharge and the environment\nBallast water discharges by ships can have a negative impact on the marine environment. The discharge of ballast water and sediments by ships is governed globally under the Ballast Water Management Convention, since its entry into force in September 2017. It is also controlled through national regulations, which may be separate from the Convention, such as in the United States.\nCruise ships, large tankers, and bulk cargo carriers use a huge amount of ballast water, which is often taken on in the coastal waters in one region after ships discharge wastewater or unload cargo, and discharged at the next port of call, wherever more cargo is loaded. Ballast water discharge typically contains a variety of biological materials, including plants, animals, viruses, and bacteria. These materials often include non-native, nuisance, exotic species that can cause extensive ecological and economic damage to aquatic ecosystems, along with serious human health issues including death.\nThere are hundreds of organisms carried in ballast water that cause problematic ecological effects outside of their natural range. The International Maritime Organization (IMO) lists the ten most unwanted species as:\n- Cholera Vibrio cholerae (various strains)\n- Cladoceran Water Flea Cercopagis pengoi\n- Mitten Crab Eriocheir sinensis\n- Toxic algae (red/brown/green tides) (various species)\n- Round Goby Neogobius melanostomus\n- North American Comb Jelly Mnemiopsis leidyi\n- North Pacific Seastar Asterias amurensis\n- Zebra Mussel Dreissena polymorpha\n- Asian Kelp Undaria pinnatifida\n- European Green Crab Carcinus maenas\nBallast water issues by country\nThe ballast tanks in New Zealand carry animals and plants that kill ecosystems. Ballast tanks are only used in cargo ships there. Ballast water is controlled under the Biosecurity Act 1993.\nThe zebra mussel, which is native to the Caspian and Black Seas, arrived in Lake St. Clair in the ballast water of a transatlantic freighter in 1988. Within 10 years it had spread to all of the five neighbouring Great Lakes. The economic cost of this introduction has been estimated by the U.S. Fish and Wildlife Service at about $5 billion.\nBallast water discharges are believed to be the leading source of invasive species in U.S. marine waters, thus posing public health and environmental risks, as well as significant economic cost to industries such as water and power utilities, commercial and recreational fisheries, agriculture, and tourism. Studies suggest that the economic cost just from introduction of pest mollusks (zebra mussels, the Asian clam, and others) to U.S. aquatic ecosystems is more than $6 billion per year.\nCongress passed the National Invasive Species Act in 1996 in order to regulate ballast water discharges. The Coast Guard issued ballast water regulations in 2012. Under the authority of the Clean Water Act, the Environmental Protection Agency (EPA) published its latest Vessel General Permit in 2013. The permit sets numeric ballast water discharge limits for commercial vessels 79 feet (24 m) in length or greater. EPA issued a separate permit for smaller commercial vessels in 2014.\nAmong 818 ports in the Pacific region, Singapore alone accounts for an estimated of 26 percent of cross-region (long range) species exchange. Via targeted ballast management on Singapore and a few other ""influential"" ports, cross-region species exchange to/from the Pacific region can be combinatorially reduced.\nTo react to the growing concerns about environmental impact of ballast water discharge, the International Maritime Organization (IMO) adopted in 2004 the ""International Convention for the Control and Management of Ships\' Ballast Water and Sediments"" to control the environmental damage from ballast water. The Convention will require all ships to implement a ""Ballast water management plan"" including a ballast water record book and carrying out ballast water management procedures to a given standard. Guidelines are given for additional measures then the guidelines.\nThe goals of the convention are to minimise damage to the environment by:\n- Minimise the uptake of organisms during ballasting.\n- Minimising the uptake of sediments during ballasting.\n- Ballast water exchange while at sea (the ship should be minimum 200 nautical miles from shore with a depth of minimum 200 metres and can use the flow through or sequential method). At least 95 percent of the total ballast water should be exchanged.\n- Treatment of the ballast water by chemical or mechanical influences (UV-radiation, filter, deoxygenation, cavitation, ozone…)\nControl measures include:\n- International Ballast Water Management Certificate\n- Ballast water management plan\n- Ballast water record book\nThe IMO convention was ratified by enough countries and entered into force on September 8, 2017.\n- ""International Convention for the Control and Management of Ships\' Ballast Water and Sediments"". International Maritime Organization.\n- Living Beyond Our Means: Millennium Ecosystem Assessment, 2005. Statement from the Board.[full citation needed]\n- Statement of Catherine Hazlewood, The Ocean Conservancy, “Ballast Water Management: New International Standards and NISA Reauthorization,” Hearing, House Transportation and Infrastructure Subcommittee on Water Resources and Environment, 108th Cong., 2nd sess., March 25, 2004.\n- David Pimentel, Lori Lach, Rodolfo Zuniga, and Doug Morrison, “Environmental and Economic Costs Associated with Non-indigenous Species in the United States,” presented at AAAS Conference, Anaheim, CA, January 24, 1999.\n- United States. Pub. L. 104-332. October 26, 1996.\n- U.S. Coast Guard, Washington, D.C. ""Standards for Living Organisms in Ships’ Ballast Water Discharged in U.S. Waters."" Federal Register, 77 FR 17254, 2012-03-23.\n- ""Vessels Incidental Discharge Permitting"". National Pollutant Discharge Elimination System (NPDES). Washington, D.C.: U.S. Environmental Protection Agency (EPA). 2015-12-09.\n- EPA (2014-09-10). ""Final National Pollutant Discharge Elimination System (NPDES) Small Vessel General Permit for Discharges Incidental to the Normal Operation of Vessels Less Than 79 Feet."" Federal Register. 79 FR 53702.\n- Xu, Jian; Wickramarathne, Thanuka L.; Chawla, Nitesh V.; Grey, Erin K.; Steinhaeuser, Karsten; Keller, Reuben P.; Drake, John M.; Lodge, David M. (2014). ""Improving management of aquatic invasions by integrating shipping network, ecological, and environmental data"": 1699–1708. doi:10.1145/2623330.2623364.\n- ""Ballast Water Convention to Enter into Force in 2017"". Maritime Executive. 8 September 2016. Retrieved 14 September 2016.\n- Buck, Eugene H.(2012). ""Ballast Water Management to Combat Invasive Species."" U.S. Congressional Research Service. Report No. RL32344.']"	['<urn:uuid:7b798ee3-e4f1-47d4-8e0a-889cf02b4200>', '<urn:uuid:e9749ea3-2ea0-436c-95fd-f59b7fb5adc2>']	factoid	with-premise	long-search-query	distant-from-document	multi-aspect	novice	2025-05-13T03:20:41.944655	8	102	2236
4	roman ruins hadrians wall vs pantheon which older	The Pantheon and Hadrian's Wall are both Roman structures from different parts of the Empire. The Pantheon was built by Emperor Hadrian in 125 AD and remains standing as the world's largest unreinforced concrete dome. Hadrian's Wall in England's Northumberland was also constructed during the first century AD, containing architectural remnants and artifacts of Roman presence that tell a two-thousand year old story. The evidence shows these structures were built around the same historical period under Emperor Hadrian's rule.	['Heaney composes a love poem to Marie years after they visited Hadrian’s Wall in England’s Northumberland. His particular interest in the architectural remnants and artefacts of Roman presence uncovered a two-thousand year old story bristling with poetic and emotional charge. Water is very much the unifying factor.\nPersonal exile added to the intensity of the poem: Heaney fulfilled a series of part-year contracts at Harvard University in the United States that took him away from wife, home and family for prolonged periods.\nHeaney weaves the tale of a legionary soldier living at the northern limit of the vast Roman Empire (far from home) whose pain of exile and loneliness drove him to construct a sanctuary dedicated to a Romano-Celtic water goddess (altar to Coventina). Stylised inscriptions visible on the site are as Heaney witnessed them (in her right hand a waterweed … in her left a pitcher spilling out a river).\nReminders of the soggy conditions around Hadrian’s Wall (running water) that suited Grotus (he felt at home) plus his identity carved into her memorial (the stone where he cut his name) were enough to reduce the battle-toughened Mediterranean legionary (some dried-up course beneath his breastbone) to tears of despondency (pouring and darkening).\nMmm … thinks Heaney … in matters of devotion and emotional staying power, Grotus, you and I have things in common. Crude though your mucky old sanctuary (stunted altar) might be it is enough to stir a poet’s creative juices (works on me)!\nThe love poem that results unfolds around an early-days, wet-behind-the-ears episode in Glanmore – the cottage’s underground supply of fresh water was suddenly cut (our electric pump gave out). His and Marie’s efforts to revive it were amateur (priming it with bucketfuls) and increasingly frustrated (our idiotic rage) – finally came shame-faced appeals (hangdog phone-calls … please) to their rural neighbours (farm next door).\nThe sound of the pump bursting back to life (hammer on again) brought exultant cheers (jubilation); drips and dribbles were consigned to the past (the tap’s full force), replaced by the genuine article (sheer given fact of water).\nHeaney’s feelings for the woman he loves are triggered by her almost childlike guilty resolve henceforth to conserve water (never waste one drop), never again to take it for granted (its worth better always).\nHeaney confirms his marriage vows: his and Marie’s rightness for each other merits a re-discovery of their temps perdu – ‘ let’s go back, Marie Heaney and do it all again (run through all that one more time) … I have just the roles for us’ (I’ll be Grotus, you be Coventina).\nHeaney commented to DOD (294) In a museum on the Wall, I saw a couple of images of this lovely little creature, recumbent on her elbow; under the other elbow, she had a pitcher that poured out a steady stream of water … I visited her shrine. This was only a couple of hundred yards from the Wall itself, in the soggy, rushy corner of a field that could have been the corner of a field at home, one of those mucky old sanctuaries down overgrown lanes, far from the road and the house. Back in the museum, I saw what the display card called an ‘altar’ dedicated to Coventina by one of the legionaries – a little stunted brickbat of a thing, with the name ‘Grotus’ cut into it in very crude letters. … it was a ‘votive object’, but it was also like a girl’s name cut into a desk or written on a wall.\n- home: a Roman soldier from present-day central Italy with its Mediterranean climate serving on Hadrian’s Wall (built to defend Britannia against Pictish tribes to the north in present-day Scotland) at the northernmost reaches of the Roman Empire in the first century AD;\n- pitcher: earthenware jug;\n- spill out: issue;\n- dried-up: depleted of water;\n- course: water course; stream;\n- darken: show sorrow or unhappiness;\n- stunted: low-key, meagre (reference to plants, trees prevented from growing properly)\n- altar: flat topped block serving for worship;\n- pump: mechanical device for raising water;\n- give out: break down, die;\n- prime: prepare for action;\n- rage: extreme, loud anger:\n- hangdog: dejected, shame-faced;\n- fix: repair;\n- hammer: sound of piston moving up and down;\n- jubilation: exultation;\n- force: bore;\n- sheer: utter, unmitigated;\n- 2 stanzas (8+10) in 6 sentences; unrhymed; very variable line length 10-17 syllables;\n- rich use of enjambment; 2 questions and final couplet addressed lovingly to Marie;\n- indirect speech recording Marie’s response to the problem;\n- assonant effects:[a:] far…altar…started…darkening; [əʊ] Grotus…holds…Grotus…home…stone…bone…phone; [i] in…pitcher … spilling…electric…idiotic…fix it; [ʌ] Grotus…looked… running…cut… stinted… pump…bucketfuls …somebody…come…full; [ɔː] waterweed…water.. water…course…pouring…more…calls…door… for…force… water…all…more; [e] dedicated…left…felt…breastbone…less… remember… electric…felt…never…better; [ei] name…way…gave… rage…again…jubilation; [u] jubilation…you…you’d…through…you;\n- alliterative chains: front of mouth [l] [w][h]; reprises of alveolar [t/d], bilabial [p/b], velar [k/g] nasals [m/n], sibilants [s/z/sh], labio-dental [f/v];\n- Heaney is a meticulous craftsman using combinations of vowel and consonant to form a poem that is something to be listened to.\n- the music of the poem: fifteen assonant strands are woven into the text; Heaney places them grouped within specific areas to create internal rhymes , or reprises them at intervals or threads them through the text;\n- syllables without highlight are largely the unstressed sound as in common, little [ə]\n- alliterative effects allow pulses or beats, soothings or hissings or frictions of consonant sound to modify the assonant melodies; this is sonic engineering of the first order;\n- a full breakdown of consonant sounds and where in the mouth they are formed is to be found in the Afterthoughts section;', 'Our Home in Rome is the Dome\nBy Kara Gustafson\n“There is something in the immensity of the Pantheon that makes me fall silent. Standing beneath its dome as it soars above me, I marvel at its perfection. How did ancient man form these perfect recessed squares in the cement of the dome? How could it have been done aloft, and not on the ground, the dome turned on its back like a great turtle while humans scuttled around inside it like so many ants? It defies description; my words fail me, and rather than use paltry and insufficient ones, I prefer just to stand in awe and look”Christine Engelen, student 2019\n“When I walked into the Pantheon for the first time I was absolutely amazed. The architecture, art, and colors inside are absolutely stunning”Emily Nardone, student 2019\n“I don’t think anything will top dancing around the Pantheon at 3 AM in the pouring rain”Marlena Giannone, student 2019\nTop Left to Right: Students dancing in the night downpour from the steps of the Pantheon, lightning illuminating everything ; Carmyn G lovingly embracing a granite column ; The inside of the Pantheon including the oculus\nBottom: View of the Pantheon during night thunderstorm with lightning behind\nI did not know what the Pantheon was. From the revered way it was mentioned, I knew that it was an impressive part of the city. On our first walking tour of Rome, we paused at an important elephant statue we discussed in our film class. Then, Julia pointed to a building that made up the next corner.\n“There it is! The Pantheon!”\nUnassuming and fading into the background of the surroundings were the brick sides of a curved building. As we slowly made our way to the front, my eyes grew wider and my mind ceased normal function. From what seemed to be an ancient pile of rubble grew dense granite columns stretching sky high, and rich marble floors leading our way into the sacred area. The long doors that open into the building seemed grand by themselves, and the light from outside bounced off of the marble surrounding the entrance. As we walked into the building, it felt as though a portal into another dimension had sprung out of thin air.\nEncompassing like a large egg, the building stretches upwards, intricate symmetrical marble decorating every surface. The ceiling is mesmerizing with rectangular recesses cut geometrically around the domed ceiling. In the center of the dome is a wide hole, letting in a beam of sunshine, lighting the inside of the building.\nNothing has ever taken away my breath so fully. For the time that we were inside, the outside world was stripped away, and we were left standing in awe. The history of the building felt like it crept up the domed walls and compressed in on me. The intense presence of the building was suffocating. Every time that we have returned, it pulls us in.\nThe Pantheon is the home of Rome to us, and no matter where we are wandering, we always end up turning a corner and stumbling upon it. From finding it flocked with tourists to spending long pensive afternoons staring upwards, it is the center of my adventures. From learning more about the history of the building to dancing in a downpour in the shadow of the pillars, it has marked our memories forever.\nThe site of the Pantheon was planned far before the current building was standing. It underwent multiple cycles of being built, catastrophically burnt, and then rebuilt again. The final form was built by Emperor Hadrian, known as Hadrian the Architect, in 125 AD (Low, 2). The name, Pantheon, is developed from the original dedication to many ancient gods. Pan, meaning “all”, and Theos, meaning “gods”. After Rome changed from polytheism to Christianity, the Pantheon was not used until the 600s, when it was reopened as a Christian church, where it still has mass.\nThe Dome’s Influence\nThe dome of the Pantheon, the part that makes it memorable to all who visit, has been immensely influential on other architects around Italy and the world. For example, the Duomo in Florence, making up the very recognizable silhouette of the city, was created by Brunelleschi and was inspired by the creation of the Pantheon. Another example of a notable Italian dome is Saint Peter’s Basilica in Vatican City. As a group when we received a tour of the museum and Basilica, our lovely tour guide explained that the lead architect, a well known man, Michelangelo, did not want to overshadow the prowess of the Pantheon, and therefore creating the Basilica to be one meter shorter than originally told, one shy of the height of the Pantheon (Low, 2).\nUntil the 20th century, the Pantheon was the largest concrete structure in the world. Despite being built in 125 AD, 1,893 years before this blog was published, it is still the world’s largest unreinforced concrete dome (Low, 2). What makes the Pantheon’s architecture so majestic? Standing in the middle of the room, it feels almost as if no one but the many gods of old could have created such a masterpiece.\nRoman cement is typically called Roman Pazzolana. This cement is different from the norm of mixing limestone and sand which requires to be dried. Pazzolana is instead made by using similar chemical bonding methods to commonly used modern Portland cement (Mark and Hutchinson, 3). The Pantheon was built with different layers of cement, growing lighter as the structure got taller. This allowed the weight to be lessened. Towards the top of the structure, volcanic pumice, a light and strong rock, was used. Below is a figure showing some of the different layers of cement.\nFigure 1: Masi (5)\nThe basic structure of a dome can be seen as a simple arch that has been spun around to create a dome shape. Due to gravity and weight issues when creating this perfect unsupported dome, the top of the arch, called the keystone, must be removed, therefore creating the oculus in the Pantheon’s dome. The fundamental forces within a dome are called the meridional and hoop forces. The meridional forces work longitudinally while the hoop forces are laterally (Low, 2). These forces are key in keeping domes standing, and an understanding of how their basic principles work is necessary to analyze the structure. The meridional and hoop forces especially allow domes to be built ring by ring from the bottom towards the top.\nFigure 2: Mark and Hutchinson (3)\nFigure 3: Low (2)\nDue to the building’s age, it is not perfectly built. There are signs of wear and fatigue on the structure, resulting in cracks running vertically on the dome. These cracks are thought to be caused by the shrinkage of the cement. Another conclusion presented by Mark and Hutchinson in an early yet remarkable analysis of the building is that the cracks spreading upwards along the dome were unavoidable. The Romans built this structure after trial and error over millennia of past experience. They knew that with the cement, shape, and size, that the cracks would appear. The architects compensated by knowing that this would force the dome to be intrinsically a set of half arches (Masi, 5). The study on the development of the cracks spreading through the dome is a substantial field, as more analytic techniques are discovered using 3D modeling and force calculations. These studies are aimed at understanding the life of a structure such as the Pantheon as it is the oldest and largest, and applying these findings to current day modeling.\nSymbology & Architecture\nThe physical structure of the building is impressive. One of the most remarkable qualities is that it contains almost a near perfect sphere, one of the most universally loved and romanticized shapes. This symbol can be traced to represent the world in its spherical shape. The only source of light is from the oculus, the circular opening at the top of the dome, possibly representing sun and moonlight. The dome can be broken into 5 rings, each with 28 coffers, the rectangular recesses to lessen the weight of the dome. This can be linked to the 28 phases of the lunar cycle (Fletcher, 1). The possible geometry mixed with symbolism continues when considering the ancient celestial objects: Sun, Earth, Moon, Mercury, Mars, Venus, Jupiter, and Saturn. This representation of eight is seen geometrically throughout the building with a fundamental positioning of concentric circles and squares. Below is a figure showing this placement. For more reading, see Rachel Fletcher, (1).\nFigure 4: Masi (4)\nFigure 5: Fletcher (1)\nAs one could imagine, the technical planning that must go into any sound structure is mind boggling. Especially when analyzing historical landmarks, it is difficult to theorize a story of the building. How was the Pantheon built exactly? Why did the cracks form? The analysis of the building has changed over time from speculation, to 3D modeling, to laser analysis of the building. Here I only briefly skimmed over the tip of what is a deeply rooted and intensely studied area. The articles I referenced go into much more depth about the subject, and are where I borrowed all figures from. All the credit belongs to the rightful owners of the figures, as well as the ideas referenced. The Pantheon has been considered by many to be the core of Rome. I understand this now. The Pantheon with its warm whispers and resonance of history is the beating heart of Rome. And to us Ragazzi in Rome, it has become a home.\nAbout the Author\nKara Gustafson is a Mechanical Engineering major at Colorado State University with a minor in History. Originally from Boulder, Colorado, she enjoys being in nature and studying the mechanics behind it. During her summer in Rome, she was entranced by the Pantheon and many other ancient buildings. She wants to thank her family for supporting her passions in every way possible, and her friends for being by her side through it all. The crowded trams, scramble to bag at the market, Flike dogs, smooth cappuccinos, Roman memes, and hang drying laundry in the Roman sun on the patio created a new routine for her, and she will always have Rome and her time here in her heart.\n(1) Fletcher, Rachel. “Geometric Proportions in Measured Plans of the Pantheon of Rome.” Nexus Network Journal: Architecture & Mathematics, vol. 21, no. 2, Aug. 2019, pp. 329–345. EBSCOhost, doi:10.1007/s00004-018-00423-2.\n(2) Low, Kristina N. “Engineering the Pantheon – Architectural, Construction, & Structural Analysis.” We’re Never Far from Where We Were, Brewminate, 5 Dec. 2017, brewminate.com/engineering-the-pantheon-architectural-construction-structural-analysis/.\n(3) Mark, Robert, and Paul Hutchinson. “On the Structure of the Roman Pantheon.” Art Bulletin, vol. 68, no. 1, Mar. 1986, pp. 24–34. EBSCOhost, doi:10.2307/3050861.\n(4) Masi, F., et al. “A Study on the Effects of an Explosion in the Pantheon of Rome.” Engineering Structures, vol. 164, June 2018, pp. 259–273. EBSCOhost, doi:10.1016/j.engstruct.2018.02.082.\n(5) Masi, F., et al. “On the Origin of the Cracks in the Dome of the Pantheon in Rome.” Engineering Failure Analysis, vol. 92, Oct. 2018, pp. 587–596. EBSCOhost, doi:10.1016/j.engfailanal.2018.06.013.']	['<urn:uuid:d76c50f4-9891-4655-bc4b-fe8b3ffa6c22>', '<urn:uuid:939d78da-88f1-415e-b894-7b847d7c1bf7>']	open-ended	with-premise	short-search-query	distant-from-document	comparison	novice	2025-05-13T03:20:41.944655	8	79	2799
5	How does the cleaning and waste management work in these mobile sheep milking systems when they're being used out in the field?	The system has a well-designed cleaning process. The effluent is managed using a perforated sheet that sheep stand on, positioned over a collection tray. This tray is sloped to a recessed collection point with a drain port that empties into an effluent tank. The collected effluent, which is minimal, can be mixed with approximately 120 litres of washing water and sprayed out onto a paddock. Clients have reported that sheep rarely urinate or defecate while on the trailer, and the cleaning system after milking has proven to work well.	['Portable milking systems.\nReads engineer, focus on designing and building ergonomic milking systems for the farmer and their livestock. By maintaining regular contact with our clients and industry networks, in turn, ensures our strategic alliance with any transformations that occur within the agricultural sector. By keeping up with market-led research Reads have identified an increased demand for smaller scale milking units specifically designed for sheep, goat, and recently deer.\nIn collaboration with our client’s concept and Reads design capabilities our latest innovation is a portable 20-bail sheep milking unit. The sleek design encompasses an all component milking unit on a galvanised trailer. This has been the third portable sheep milking unit our clients have had commissioned by Reads, upgrading the unit size each time. Reads first design was an 8-bail unit to test the design and suitability. With successful use of the 8-bail unit, our clients business growth demanded a larger 16-bail portable unit. Subsequently, the 16-bail unit currently milks 300 sheep and its qualified to do so at the level bound by the validation programme.\nReduce the need to invest in traditional bricks and mortar.\nOur clients have found that incorporating a stepping stone approach to business has been an efficient and effective way to grow. Furthermore, the price they are currently receiving for sheep milk is reasonable at $15 – $17 a kg for milk solids. Since the review of the sheep milking industry in 2015, the sheep milking industry is grown at a significant rate.\nReads newly designed portable 20-bail milking unit was at the show for public viewing, at the 50th annual Mystery Creek field days 2018. The innovative product has been well received with worldwide interest.\nSmaller scale milking systems are used as a stepping stone to enter a new market. For those opposed to investing in the standard farming model of bricks and mortar dairy. The portable unit reduces the risk of investment by owning an asset that is resalable.\nWork smarter, not harder.\nFurther advantages of a portable unit are that it can harvest milk from sites within one farm. So long as the farm is registered with the Ministry of Primary Industries to use the portable milking plant. Consequently, the trailer is registered for road transportation.\nThe portable unit is designed to be towed behind the bulk milk tank on a truck. With the portable trailer housing its own generator, cooler unit and CIP recycled hot water washing system. The trailer unit encompasses everything you would find in a standard milking shed. The component layout of the system is based on the ergonomics and optimal systems layout to minimise waste. The ergonomics of the system are required to milk the sheep efficiently with minimal discomfort for the operator.\nCompact thoughtful design.\nThe milking unit itself has sorting gates and railings to orient the sheep on the platform while milking. Materials are food grade, with non-slip footing. Entry and exit are achieved by fold down access ramps, strategically placed. Clients have found that sheep are easy to train to run on and off and adds they very rarely urinate or defecate while they are on the trailer. Cleaning the system after milking works well and has proven to be well designed. The effluent is collected in a tank under the trailer and can be mixed with the washing water – about 120 litres – and sprayed out on to a paddock. The effluent of the system is managed using a perforated sheet, which the sheep stands on, over a collection tray. The collection tray is sloped to a recessed collection point with a drain port that empties into the effluent tank for disposal. We are advised the quantity collected is minimal.\nThe teat cups, although similar to those found in a cow dairy shed, pulsate at a much faster rate and emulate the drinking pattern of lambs. The clusters are specifically designed for sheep and have an automatic shutoff valve that automatically shuts off the cluster vacuum when not in use. As the cluster automatically shuts off the amount of air that is admitted into the milk line is reduced. Therefore, reducing instances of slug flow within the milk line, foreign matter entering the cluster, and cluster drop-off of nearby stalls caused by insufficient vacuum pressure caused by the air admission.\nBring the plant to the livestock.\nThe portable milking unit even provides a feed system as additional nutritional support for the animal, as well as providing an incentive to let down. The sheep are enticed on to the trailer by a small amount of feed and a quick-release exit system frees them rapidly while keeping the flow through the milking stand going.\nFurthermore, the portable milking trailer increases the accessibility of the milking plant to the stock, compared to traditional milking sheds reducing the time for the stock to travel to and from the milking platform. An additional advantage is the portable milking platform can transport the milk temporarily in the rear of the vehicle in a cooling storage vat.\nThe 20-bail unit is the first prototype Reads have built at this size, and it may need the odd minor tweak, however, so far, it’s proving to be a great success. Read milking systems can be modified to suit the individual needs for milking and diverse types of livestock in turn providing our customers with ergonomic systems.']	['<urn:uuid:3ab5b154-ef81-45ce-bfa1-8f6d538d809f>']	open-ended	direct	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-13T03:20:41.944655	22	89	895
6	My daughter got sick yesterday with diarrhea and stomach cramps after eating at a restaurant. When should I be worried enough to take her to the doctor?	You should seek medical advice immediately if your daughter shows any of these concerning symptoms: signs of dehydration (such as thirst, decreased urination, lethargy, dry mouth, or feeling faint when standing), severe abdominal pain, or bloody diarrhea. For children, foodborne illness symptoms can appear anywhere from 1 hour to over a week after eating contaminated food. Young children are among the most susceptible to severe infections, so it's particularly important to monitor them closely. While symptoms often resolve within a few days, proper hydration is crucial - oral rehydration solution is highly recommended for children with mild to moderate dehydration and is available at pharmacies.	"[""Campylobacter infection - including symptoms, treatment and prevention\nCampylobacter infection (campylobacteriosis) is a bacterial infection which most commonly causes gastroenteritis (also known as 'gastro') but may also cause illness affecting the entire body.\nCampylobacter infection is a notifiable condition1\nHow Campylobacter infection is spread\nEating contaminated food is the most frequent cause of this infection. Campylobacter is commonly found in raw or undercooked poultry meat. Occassionally other sources of infection include:\n- infected individuals, particularly infants\n- household pets, especially puppies and kittens\n- domestic stock\n- raw milk\n- contaminated water.\nSigns and symptoms\nSymptoms may include:\n- diarrhoea which may sometimes be bloody\n- stomach cramps.\nVomiting is not common. The most severe infections occur in the very young, the elderly and malnourished people.\nRarely, Campylobacter infection may lead to Guillain-Barré syndrome, a condition which causes muscular paralysis.\nDiagnosis is made by growing Campylobacter bacteria from a faecal specimen or by detecting the bacteria in a faecal sample using a PCR (polymerase chain reaction) test in a pathology laboratory.\n(time between becoming infected and developing symptoms)\nUsually 2 to 5 days, with a range of 1 to 10 days.\n(time during which an infected person can infect others)\nA person is infectious for as long as the Campylobacter bacteria are in their faeces, which may be for an average of 2 to 3 weeks after symptoms are gone. The risk of infecting others decreases when diarrhoea is no longer present.\nAntibiotic treatment is not usually needed for Campylobacter infection. Recovery from symptoms usually occurs within a few days.\nThe following are general recommendations for the treatment of gastroenteritis:\n- Give plenty of fluids. Oral rehydration solution is highly recommended for children with mild to moderate dehydration. It is available at pharmacies and should be administered following the instructions on the packaging.\n- Mildly unwell children should be given their usual fluids more often. Carbonated (fizzy) drinks or undiluted juice should be avoided.\n- Medicines to prevent vomiting or diarrhoea should not be given (especially in children), except where specifically advised by a doctor.\n- Breastfed babies should continue to be breastfed throughout their illness.\n- Children on formula or solid diets should restart their normal diet (including full strength lactose containing milk) following rehydration with oral rehydration solution.\n- Children who are hungry or ask for food should be given small portions of their usual foods, but avoid foods high in sugar or fat.\nWhen to seek medical advice\nSeek medical advice if there are any of the following symptoms:\n- Signs of dehydration, such as thirst and decreased urination, lethargy, dry mouth, feeling faint on standing\n- severe abdominal pain\n- bloody diarrhoea.\n- Signs of dehydration, such as thirst and decreased urination, lethargy, dry mouth, sunken eyes, feeling faint on standing\n- abdominal pain\n- bloody diarrhoea\n- any symptoms in a child less than 12 months of age.\n- Exclude people with Campylobacter from childcare, preschool, school and work until there has been no diarrhoea for 24 hours. If working as a food handler in a food business, the exclusion period should be until there has been no diarrhoea or vomiting for 48 hours.\n- Infants, children and adults with Campylobacter infection should not swim until there has been no diarrhoea for 24 hours.\n- Wash hands after handling raw meat, especially poultry, and keep food preparation areas clean.\n- Wash hands after gardening or touching animals.\n- Meat, particularly poultry, should be thoroughly cooked.\n- Do not store uncooked poultry or other meat near foods which will be eaten raw, such as salad items.\n- If pets are sick with diarrhoeal illness, have them treated.\n- Babies and small children without diarrhoea who are not toilet trained should wear tight fitting waterproof pants or swimming nappies in swimming pools and be changed regularly in the change room. When faecal accidents occur, swimming pools should be properly disinfected\n- Hand hygiene\n- Keeping areas clean\n- Exclusion periods from childcare, preschool, school and work\n- Preventing food poisoning at home\n- Collecting a faecal sample\n- Pasteurised milk v's raw milk\n- When you have a notifiable condition\n- Thawing, cooking, cooling and reheating food\n- Shopping and storing of food at home\n1 - In South Australia the law requires doctors and laboratories to report some infections or diseases to SA Health. These infections or diseases are commonly referred to as 'notifiable conditions'."", 'Learn these quick and easy tips for food safety to keep the whole family safe when preparing foods at home!\nThe Food and Drug Administration defines foodborne illness as a sickness that occurs when people eat or drink harmful microorganisms (such as bacteria, parasites, viruses) or chemical contaminants found in foods or drinking water. According to the Centers for Disease Control and Prevention, over 76 million people in the United States suffer from a foodborne illness each year, with the most susceptible being young children, older adults, pregnant women, and individuals with a compromised immune system.\nYou can help reduce the risk of contracting foodborne illness at home by taking a few simple precautions. Below is a list of helpful definitions, identifiers, and practical tips to make your kitchen safe and food friendly.\nWhat are symptoms of foodborne illness?\nIt depends on which type of foodborne illness you’ve contracted, but common symptoms include (but are not limited to) nausea, vomiting, diarrhea, abdominal cramps, aches, dehydration, and fever.\nHow quickly will symptoms appear?\nAgain, it depends on the type of foodborne illness, but symptoms can appear in as little as 1 hour or up to a week or more. The best thing to do is to contact your health care provider if you suspect the onset of foodborne illness.\nWhat causes foodborne illness?\nImproper food handling:\n- Raw food that has been contaminated via processing, storage, transportation, or preparation can be a carrier.\nIncorrect cooking/reheating time:\nMany times, the outer appearance of food doesn’t change, even when bacteria is multiplying within! The key to stopping growth is to fully cook or reheat the food. Refrigeration and freezing will slow, but not prevent, the growth of harmful bacteria.\nInappropriate holding times:\nAt home, it’s crucial to keep food out of the “danger zone” where bacteria multiply most rapidly. Bacteria grow best at temperatures above 40 ° F and below 140° F, so to keep you and your family safe, be sure to keep your refrigerator set to 40 ° F or lower and cook foods to 140° F or higher.\nWhat are the preventative measures you can take to prevent foodborne illness at home?\nRemember the 4 step method- Clean, Separate, Cook, Chill.\n- Don’t wash produce until right before it’s to be used.\n- Wash everything that the raw food item comes into contact with\n(hands, utensils, cutting boards, etc.) with hot water for at least 20 seconds.\n- Post-prep, sanitize counters and utensils with a bleach solution.\n- Keep food groups separate during prep- don’t place ready to eat food next to the raw ingredients.\n- Use a different colored cutting board and utensils for each food group.\n- Example: Red for meats, green for veggies, and white for fish\n- Invest in and use a food thermometer to make sure internal temperatures are out of the danger zone. These are the minimum temperatures that your meats should be cooked at:\n145°F– Roasts, steaks, chops of beef, veal, and lamb\n160°F– Pork, ground veal, ground beef\n165°F– Ground poultry\n180°F– Whole poultry\n- Also, remember to throw away foods that have set out at room temperature for over two hours.\n- Freeze or refrigerate leftovers immediately after consuming.\n- Check the temperature of your refrigerator and freezer regularly.\n- The refrigerator should be no warmer than 40° F, and the freezer should register 0° F.']"	['<urn:uuid:ea7c3be3-d964-4fbc-b2e8-6e1512d52dcd>', '<urn:uuid:85118753-454c-4cdf-aa35-88d338f226e2>']	open-ended	with-premise	verbose-and-natural	similar-to-document	three-doc	novice	2025-05-13T03:20:41.944655	27	105	1304
7	In my role overseeing restaurant operations, I need to understand the relationship between food safety inspections and inventory control - what specific areas should be monitored regularly, and how do these aspects impact overall restaurant performance?	Regular monitoring should focus on both inventory counts and safety compliance. For inventory control, if food costs are too high, increase counting frequency from monthly to weekly counts. For safety inspections, key areas to monitor include food preparation surfaces (which must be smooth, washable, and non-toxic), proper sanitization procedures, and regular cleaning of all equipment and surfaces. Regular third-party inspections are recommended to examine kitchen compliance. Poor performance in either area can seriously impact the restaurant - food safety violations can shut down operations, while inventory issues like chronic waste or lost sales can significantly affect food cost percentages. Both aspects require consistent documentation - temperature logs for food safety and inventory counts for cost control.	"[""If you find your self explaining away two consecutive months of poor food cost results, you need to dig into the numbers and locate the problem. Persistent performance problems can point to a serious issue.\nIn calculating your food cost percentage, there are three factors: sales, purchases and inventory change. Many operators focus entirely on the inventory change when they look for solutions.\nWhile inventory calculation errors are common, a complete focus on the inventory figure can become a distraction. Lost sales, chronic waste, inconsistent portions and ordering too much food are major problems which need to identified quickly. The end of period inventory figure needs to be eliminated as a factor.\nThe best way to eliminate inventory errors from your food cost formula is to increase the frequency of inventory counts. If your food cost percentage is too high, switch to weekly inventories if you currently count monthly.\nIn a typical kitchen, you will find two weeks of usage in the inventory. If you had to discard your entire stock, the loss is roughly 4% of the entire year's food cost. You may have a chronic waste issue with perishable protein items. In an operation with protein items accounting for 40% of the food cost, a 10% waste problem is the same as discarding your entire inventory once a year.\nThe point is you shouldn't always look for food cost problems in your ending inventory calculation.\nCheck your labor cost percentages as a check for lost revenue. If you have a problem with food and beverages being served to guests without a POS system order, you will find both food and labor cost percentages over budget. Make sure complimentary food and beverages are entered in the POS system with the comp used as a payment method (approved by a manager). Eliminate the service of desserts, soups, coffee and tea without a documented order.\nHonest waste and spoilage winds up in your garbage. The garbage can also gives feedback on customer satisfaction. One of the most costly tactics commonly used in casual dining restaurants involves selling an over stocked protein item which is past peak quality. These menu items are found in the specials. The POS system will point to a low number served to guests in relation to the line production. Now the raw ingredient which was over stocked has been transformed into a finished menu item which has been over produced.\nEventually, the walk-in cooler will contain several pans full of these mistakes. How will this food leave your restaurant?\nGenerally, leftover food will be served to employees, discarded or reinvented as a new special of the day. The last option is the most risky tactic. First, the demand for the protein item was incorrectly estimated. This error caused the raw ingredient to hit the specials board. The company loses the wages paid to prepare the original portions which make it back to the refrigerator.\nA second use of kitchen staff to create a new special adds to the labor cost. Any over production on the second round needs to be discarded. If any of the unsold food is served at a later date, the chance for food poisoning increases. Even if no one gets sick, the quality of the meal will be low. You can lose valuable customers.\nWhen you find your food cost percentage is too high, remember to count more frequently, check for a higher labor cost and always check your garbage cans and walk-in coolers.\nLogos, product and company names mentioned are the property of their respective owners."", 'As a restauranteur, food safety must be part of your core values. Good food hygiene ensures that your food is safe to eat so guests don’t contract a food-borne virus and shut down your dream. Food safety and sanitation are a legal requirement, but they also help your restaurant establish a good reputation.\nTaking the plunge can feel overwhelming, but we’ve got your back. Here are eight safety and sanitation tips to prevent any hiccups.\n1. Prevent Cross-Contamination\nIf you wonder “what is the best way to ensure food safety at a food facility?”, the HACCP is a great place to start.\nHACCP (Hazard Analysis Critical Control Point) is internationally recognized for reducing the risks of safety hazards in foods during specific points in the process, from conducting a hazard analysis to identifying critical control points. These benefits will reduce any potential health risks, such as cross-contamination.\nCross-contamination occurs when harmful bacteria or microorganisms transfer from one object to another. The results can be dangerous to unaware consumers.\nRaw meat, seafood, poultry, and eggs can be the source of deadly bacteria such as salmonella. To avoid a catastrophe, ensure there are separate chopping boards and cutlery for each food group. For example, only use a red chopping board when handling raw meat to avoid cross-contamination.\n2. Personal Hygiene\nFood sanitation rules are paramount in the kitchen. Ensure your staff is following a strict dress code so the workspace remains sterile and no food gets contaminated.\n- Wear suitable clothing including gloves, hair covering, and closed-toe footwear\n- Not touch ready-to-eat food with bare hands\n- Cover hair\n- Not wear watches or jewelry\n- Not touch face or hair when handling food\n- Wash hands after handling raw meat or waste or going to the toilet\n- Not handle food when ill (e.g. diarrhea or vomiting)\nUpholding good personal hygiene will vastly improve food safety and sanitation standards and is good practice for when the health inspector visits.\n3. Keeping Food out of the “Danger Zone”\nThe “danger zone” for food falls between 41 and 135 degrees. Meat, poultry, eggs, and dairy must be stored either above or below the danger zone to prevent contamination.\nStore cold foods below 41 degrees and hot foods at 140 degrees or above. As a general rule, temperature-sensitive foods must not stay in the danger zone for over 2 hours otherwise bacteria can grow and spread.\nKeep daily temperature logs to stay organized. Ask employees to take the temperature of foods at specific intervals (e.g. upon arrival) and make record-keeping part of their routine.\n4. Use Proper Sanitation Techniques\nDuring food prep, sanitize and clean all surfaces including cutting boards and equipment. It’s important to remove food residue, dirt, and germs from surfaces so they don’t come in contact with food.\nEmployees should follow a daily sanitation procedure as they prepare food. For example:\n- Clear away any food debris\n- Clean the surface with hot soapy water\n- Rinse the area with water and wipe with a clean cloth\n- Spray the surface with a sanitizer\n- Let the area dry\nA clean work station is a secret to practicing good food safety habits. Doing this will stop a foodborne illness outbreak and ensure your restaurant stays in business.\n5. Follow Food Allergy Protocol\nAll employees must have food safety training so they understand food allergies. If your employee is preparing food for a food-allergic guest, ensure they double-check ingredients, use separate equipment and prepare food in an allergy-friendly area. Following these practices will prevent cross-contamination, which could end up being fatal.\n6. Conduct Regular Inspections\nAlways check-in with your kitchen to ensure everything is up to par. Kitchens should be sanitary and food safety rules must always be followed. Consider hiring third-party inspectors to examine your kitchen to ensure your employees aren’t violating any commercial food sanitation rules. Feedback from a third-party can help avoid food-borne illnesses and health violations.\n7. Design of Food Preparation Areas\nYour facility’s design can have a major impact on food sanitation rules. It’s essential that the kitchen’s design encourages good food hygiene practices.\nFood safety legislation has requirements for food preparation areas, such as:\n- Floors: Must be an easy-to-clean material so it’s safe to walk on and in good condition\n- Walls: Must be a durable material that is washable, non-toxic and easy-to-maintain\n- Ceilings: Overhead fittings (e.g. lighting) should prevent the accumulation of dirt and risk of contamination\n- Surfaces: Must be smooth, washable, non-toxic, and made of a corrosion-resistant material\n- Doors: Should be easy-to-clean and made from a non-absorbant material\n8. Pest Control\nHiring suitable pest control to uphold kitchen sanitation is a wise decision. Pests include mice, cockroaches, ants, and flies, which all can spread harmful diseases to food. If there is an outbreak of pests, be wary as they may carry and transmit diseases such as salmonella and listeria.\nNot only will pests repulse guests, but they will cause a ‘Fail’ on your health inspection and close your business. Educate yourself and employees on which pests are most common in your area so you know which pest control methods to use.\nAgain, cleaning and sanitizing surfaces often will stop pests from inhabiting your establishment. But also pay close attention to food preparation areas, trash cans, floor drains, and storage areas.\nFood Safety and Sanitation Is the Secret Ingredient, But Is It Yours?\nAs a restauranteur, you’re promising guests a night filled with laughs and delicious food, so it’s your duty to keep them safe. Food safety and sanitation is the blueprint of any food establishment, and there’s a reason for that. Food-borne illnesses and unhygienic kitchens can be detrimental to your guest’s health and your restaurant’s reputation, so you must uphold them to keep your dream alive.\nIf you love business and want to stay updated on business-related news, make sure you check out more of our blog!']"	['<urn:uuid:d02d6a5f-5281-4da5-9aa5-993d8d7cd140>', '<urn:uuid:28155e8c-a0f7-4ab6-87a3-b6c3c271efa2>']	factoid	with-premise	verbose-and-natural	similar-to-document	multi-aspect	expert	2025-05-13T03:20:41.944655	36	116	1582
8	signs early late kidney problems dogs	Early signs of kidney problems in dogs include excessive thirst, frequent urination with diluted urine, fatigue, loss of appetite, and weight loss. Late or more serious signs include mouth ulcers, blood in urine, pale gums, and stumbling, which indicate a medical emergency. Regular veterinary check-ups and bloodwork can help identify kidney disease early, and maintaining good dental health is crucial as dental problems are a main cause of kidney disease in older dogs.	['Park Ridge, NJ: What Are the Signs of Kidney Failure in Dogs?\nOlder dogs are amazing companions: you’re past the housebreaking phase, they know your personality and routine, and their personalities are established and you’re both in sync. As your pup ages, you notice they’re slowing down a little or seem slower getting up in the morning.\nJust like in humans, dogs can show signs of age in their joints from arthritis. Other concerns can pop up as well, including kidney disease, which is a common concern with dogs, especially as they start to get older. You want to keep your best friend happy and healthy as long as you can, so what signs should you look for regarding kidney disease? We’ll go over what kidney failure in dogs is and what signs to look out for in Park Ridge, NJ.\nWhat is kidney failure in dogs?\nThe kidneys are two organs in the lower abdomen that work to filter the blood and help maintain normal water and salt levels in the body. They also help regulate blood pressure and prevent the build up of substances in the body that can be toxic in large amounts. Normally, these substances are harmlessly excreted in the urine before they can build up and cause damage.\nWhen kidney function is impaired (this can be acute or chronic, more on that in a minute), potentially toxic substances begin to build up in the body instead of being excreted out. This can cause illness. Acute kidney failure happens quickly: from the dog drinking antifreeze or eating a toxic substance, from an accident or traumatic injury, from a bad infection, or even from certain medications.\nChronic kidney disease occurs slowly (this is usually what we see when dogs get older). The main cause of kidney disease in older dogs is from dental problems or disease. Bacteria from the mouth enters the bloodstream and causes organ damage (this is why vets stress brushing your pup’s teeth and dental screenings, it really does keep them healthy and happy in the long run!).\nUnfortunately, with chronic kidney disease, symptoms are slow to develop and you may pass them off as part of the aging process. Bloodwork as part of a routine vet exam can help identify kidney disease (or other potential problems) early on and will give you the best chance to treat it early on. If identified quickly, sometimes a special diet only can keep kidney disease at manageable levels for years.\nWhat are some symptoms of kidney failure in dogs?\nOne of the first things you may notice is your dog drinks a lot of water and they always seem thirsty. If you seem to be refilling the water bowl a lot, it may be time to head to the vet. Increased drinking can be a serious sign of other diseases or problems in addition to kidney disease, so it’s always a good idea to get this checked out before things get worse.\nIf you pup is drinking a lot of water, they will be producing more urine. If you notice your dog asking to go outside a lot or start to notice accidents in the house, his could be another sign of kidney trouble. When you’re cleaning up accidents, try to note if the urine looks “normal” or yellow, or if it looks really pale (“dilute”).\nDilute urine is a classic sign of kidney disease, as the kidneys aren’t filtering the blood well. This means urine becomes less concentrated and has less color and begins to look more like regular water. Again, dilute urine is a sign of other concerns in addition to kidney disease, so always get this checked out.\nYour vet will take a urine sample and check its specific gravity, which measures dehydration or if your dog is drinking too much water or has kidney disease (this is done in addition to checking for a urinary infection and other urine factors).\nYour Dog Seems More Tired Than Usual\nWith kidney disease, your pup may also seem really tired or even depressed. Again, you may think this is part of the aging process and it is normal for everyone to slow down as they age. But if your dog doesn’t seem to care when you rattle their leash when they used to at least perk up their ears of if they’re sleeping through meals, it may be a sign of something more than getting older.\nIf their favorite things don’t seem to excite your dog anymore, checking in with your vet is always a good idea to get them feeling better.\nYour Dog is Skipping Meals\nSkipping meals or not really wanting to eat can also be a sign of kidney disease, too. It is important to also note that if your dog does need a special kidney diet, it may take some trial and error to find a prescription diet they will like. As kidney diets are low in sodium, they sometimes aren’t as appealing to dogs.\nWork with your vet, there are many different brands and flavors of kidney foods now, and many manufacturers will give money-back guarantees if your dog won’t eat it. Having your dog on a kidney diet is essential for their health, so it’s worth working through several kinds to find one they like and will eat.\nVomiting/Strange Odor in Breath\nVomiting can be another sign of kidney disease, as well as a strange odor to your dog’s breath. If you notice changes like this, note it and ask your vet. Keeping a list of signs and symptoms will help your vet determine what is causing these issues, whether it is kidney disease or something else.\nYour Dog is Losing a Lot of Weight\nDogs normally tend to lose muscle mass as the age, but if it seems like your pup is getting really skinny or just looks different than they used to, it may be a good idea to get regular weights.\nYou can do this at home or vets also love regular check ins just to get a weight (they don’t charge for these, but they can note the weight in the medical record and keep track themselves). Weight loss can be a sign of kidney failure.\nOther Serious Signs of Kidney Failure in Dogs\nSome more serious signs of kidney disease are mouth ulcers, blood in the urine, or pale gums. Mouth ulcers and pale gums can be signs of late kidney disease. Blood in the urine can be seen with a bad urinary tract infection or later-stage kidney disease.\nAny of the above symptoms should be addressed with your vet, but if you see pale gums or stumbling in you pup, take them to an emergency room or vet as soon as you can. These indicate a medical emergency.\nDon’t Hesitate to Bring Your Dog to Your Vet in Park Ridge, NJ\nThe words “kidney disease” can be scary and cause a lot of worry for your dog and their health. Regular check ups with your vet can help you have the best chance of catching kidney disease early on and give your pup the best outcome. Keeping their teeth clean is also important: if your dog hates having their teeth brushed, they may prefer dental chews which will also help prevent dental disease.\nIf you notice any strange symptoms or behavior in your older dog, never hesitate to call your vet just to ask questions It’s always best to keep them up to date on what’s going on to help your pup stay happy and healthy!\nShare This Post\nAbout Park Ridge Animal Hospital\nProgressive Medicine, Heartfelt Care.\nAs your one-stop-shop veterinarian in Park Ridge, NJ, we make it easy for pet parents to access full-service, high-quality, less-stress pet care all in one visit. Tailor your pet’s stay with us!', 'Overview of Canine Pyelonephritis\nPyelonephritis is an inflammation of the kidney. We generally refer to pyelonephritis as a bacterial infection of upper urinary tract including any part of the kidney. Pyelonephritis is often referred to as a “kidney infection”.\nGeneral Causes of Pyelonephritis in Dogs\nAscending urinary tract infections (originating from the lower urinary tract) caused by bacteria\nHematogenous (from the bloodstream) seeding of infection is much less common\nWhat to Watch For\nSigns of pyelonephritis in dogs may include:\nExcessive drinking and urinating\nAbdominal or back pain\nStraining to urinate\nLoss of appetite\nDiagnosis of Pyelonephritis in Dogs\nBaseline tests to include a complete blood count, biochemical profile, and urinalysis are recommended in all patients. Although often within normal limits, there may be changes consistent with kidney failure or urinary tract infection. Additional tests may include:\nA bacterial urine culture to check for associated infection\nAbdominal radiographs (X-rays) to rule out calculi (stones) and other diseases that might mimic pyelonephritis\nAbdominal ultrasound to visualize the urinary tract (in particular, the renal pelvises) and other abdominal structures\nExcretory urography (a dye study of the upper urinary tract including the kidneys and ureters)\nTreatment of Pyelonephritis in Dogs\nIt is most important to determine whether the patient’s condition warrants admission to the hospital for treatment or treatment at home as an outpatient. Treatment may include:\nDietary modification in those patients with concurrent renal (kidney) failure or urinary calculi\nAntibiotic treatment, based on urine culture and sensitivity\nAdminister all medication and diet as directed by your veterinarian. Return for follow up as recommended and notify your veterinarian if any change is noted in your pet’s condition.\nIn-depth Information on Pyelonephritis in Dogs\nPyelonephritis is an inflammation of the kidney, and is most often due to a bacterial infection that has made it’s way from the lower urinary tract (urinary bladder) to the kidney. There may be factors that enhance the susceptibility to infection such as congenital abnormalities, metabolic disorders or systemic immunosuppression; however, no underlying disorders need exist.\nThe clinical signs associated with pyelonephritis may be mild, or may even go unnoticed, although pyelonephritis can lead to kidney failure, sepsis (infection throughout the bloodstream) and even death, if not addressed. Depending on the specific case, certain diagnostics and therapeutics are usually recommended and tailored to each individual.\nSeveral diseases or disorders can present similarly and need to be differentiated from pyelonephritis. These include:\nUrolithiasis (stones) anywhere throughout the urinary tract\nLower urinary tract infection\nChronic kidney failure\nBacterial prostatitis (inflammation of the prostate)\nMetritis (inflammation of the uterus)\nOther causes of fever and painful abdomen such as pancreatitis (inflammation of the pancreas) or peritonitis (inflammation of the abdominal cavity), as a percentage of animals with pyelonephritis present for abdominal pain\nOther causes of increased thirst and increased urination include hyperadrenocorticism (Cushing’s disease), diabetes mellitus, kidney disease and liver disease\nIn-depth Information on Diagnosis\nCertain diagnostic tests must be performed to diagnose pyelonephritis definitively and to exclude other disease processes that may cause similar symptoms. A complete history, description of clinical signs, and thorough physical examination are all an important part of obtaining a presumptive (probable) diagnosis of pyelonephritis. In addition, the following tests are recommended:\nA complete blood count (CBC) may be within normal limits, but an elevated white blood cell count may be present.\nA biochemical profile may be within normal limits, but it may reveal elevations in kidney enzymes or electrolyte abnormalities.\nA urinalysis may reveal blood, white blood cells, protein or bacteria in the urine. The absence of any or all of these does not rule out pyelonephritis.\nA bacterial urine culture is performed to confirm a urinary tract infection, however may be negative in some cases of pyelonephritis.\nAbdominal radiographs (X-rays) are an important part of any baseline work-up. Although they may be within normal limits, they may reveal changes in kidney size, urinary calculi, or help to rule out other diseases and causes of the patient’s clinical signs.\nAbdominal ultrasound is recommended in most cases suspect of having pyelonephritis. It is helpful in evaluating the kidney and potentially differentiating between upper and lower urinary tract infection. There are characteristic changes seen within the renal pelvis (inside of the kidney) that are consistent with pyelonephritis. Kidneys may be enlarged in acute (sudden onset) cases, and small in chronic (long term) cases. Ultrasound is also helpful in evaluating for the presence of stones throughout the urinary tract. It is a noninvasive procedure that often necessitates the expertise of a specialist and/or referral hospital.\nYour veterinarian may recommend additional tests to exclude or diagnose concurrent conditions. These tests are not always necessary in every case, although they may be of benefit in certain individuals, and are selected on a case-by-case basis. These include:\nExcretory urography. This intravenous dye study “lights up” the upper urinary tract (kidneys and ureters) and is helpful in documenting pyelonephritis. It also helps detect stones in the urinary tract, and may identify other abnormalities, such as ectopic ureters. An ectopic ureter is a congenital abnormality in which the ureter (the tube that drains the kidney into the bladder) joins the bladder in an abnormal position, causing a host of clinical signs, most commonly, urinary incontinence (leaking) and recurrent infections.\nA bacterial culture of the renal pelvis. With the guidance of abdominal ultrasound, this test may be particularly important in the patient who has a negative urine culture obtained from the bladder.\nKidney biopsy. In a few cases, this invasive procedure may be of benefit in diagnosing pyelonephritis and may necessitate exploratory surgery in certain cases.\nIn-depth Information Therapy\nStable dogs can be treated as outpatients as long as they are monitored closely. With appropriate therapy, most patients do quite well, and can expect to see a full recovery. In more chronic cases, response to therapy can take longer and occasionally response may be poor. It is important that you follow all recommendations by your veterinarian very closely, and that you address any questions or concerns that arise during the treatment protocol immediately.\nCorrection of any underlying predisposing factors such as ectopic ureters, urolithiasis or prostatitis is imperative to treatment.\nAntibiotic therapy selected on the basis of bacterial culture and sensitivity of the urine or renal tissue is the most important part of therapy. It is important to administer all medication as directed by your veterinarian. Usually, a treatment protocol of at least four to six weeks is indicated.\nDietary modification is recommended in animals with concurrent kidney failure or urolithiasis.\nHospitalization, intravenous fluid therapy, and antibiotic administration may be necessary in certain cases of pyelonephritis.\nSurgical intervention may be necessary in cases of pyelonephritis that are associated with or secondary to urinary calculi.\nFollow-up Care for Dogs with Pyelonephritis\nOptimal treatment for your dog requires a combination of home and professional veterinary care. Follow-up can be critical, especially if your pet does not rapidly improve.\nUnresolved pyelonephritis may lead to kidney failure; therefore, diagnostic follow-up is important to document the resolution of pyelonephritis. Administer all prescribed medication as directed. Alert your veterinarian if you are experiencing problems treating your pet.\nRepeat the urine culture and urinalysis approximately seven to ten days into treatment, and one to two weeks after the entire course of treatment has been completed. It is important to obtain urine cultures every two to three months until three negative cultures are obtained. If at any point the culture is positive, an additional course of antibiotics, often longer than the original course, is generally recommended. Infection may persist in some animals despite appropriate, repeated courses of antibiotics.']	['<urn:uuid:f72eb4c5-114e-4482-84bb-292e32cc7c89>', '<urn:uuid:f9328f69-c17c-4d3a-ab9b-a4f8729f9723>']	factoid	direct	short-search-query	distant-from-document	multi-aspect	novice	2025-05-13T03:20:41.944655	6	73	2570
9	store frozen regular bread vs store frozen sprouted bread which keeps fresh longer	Both regular commercial bread and sprouted bread can be stored frozen for extended periods. Commercial bread stays good for about 3 months when frozen, while Food for Life sprouted breads are guaranteed for 12 months when kept frozen at 0°F from the production date.	"['Questions? Baked in Answers.\nFrequently Asked Questions.\nQ: What is the difference between ""Enriched"" White Breads and Sprouted Food for Life Breads?\nA: ""Enriched"" White Breads are made from the starchy ""endosperm"" of the wheat kernel (the inside portion), which contains few vitamins and minerals (mostly carbohydrates). The milling of grain into white flour requires the removal of the bran and the germ. During this process, important natural fiber and bran are lost (including 21 vitamins and minerals). 5 vitamins and minerals (thiamine, riboflavin, niacin, calcium and folic acid) are added back into the flour and are thus, called ""enriched"". By contrast, Food for Life sprouted breads are made from freshly sprouted grains, which contain all of the fiber, bran, vitamins and minerals of the original grain plus a sizeable increase in those nutrients.\nQ: How can Food for Life make bread without flour?\nA: We start with whole, certified organically grown grains, beans and seeds, and sprout them in water. Then, we take the freshly sprouted live grains and slowly mash them, mix them into dough in small batches and slowly bake into bread.\nQ: Are Food for Life sprouted grain foods ""gluten free""?\nA: No. Food for Life breads contain naturally occurring gluten. However, our unique sprouting process activates enzymes, which naturally metabolize starch, carbohydrates and gluten protein. This may explain why so many gluten sensitive people may tolerate sprouted grains.\nQ: What does the term: ""certified organically grown"" mean when referring to the grains in Food for Life foods:\nA: ""Certified organically grown"" assures you the grains have been grown and processed without the use of spray fertilizers, chemicals or pesticides and the land (where the grains were grown), has not been sprayed for at least 3 years (including current year\'s harvest). Certified organically grown grains are 3rd party verified by certifying agencies National Organic Program (NOP).\nQ: I purchased my Food For Life bread frozen, and it has no expiration date. How should I store it and what is the shelf life?\nA: All Food For Life products are stamped with a 5 digit code indicating a Julian calendar date. The code can be found on the “kwik lok”® (plastic clip) for most bread and English muffins, ink jet printed on the tortilla packaging, and on a sticker for the Yeast Free breads. The following are (2) examples on how to decipher Food For Life codes:\nAdd the last digit to the first three digits: N (represents 2013)\nO (represents 2014)\n= 331 (331st day of the year 2013) = November 27, 2013\nAdd the last digit to the first three digits:\n= 032 (32nd day of the year 2014) = February 1, 2014\nThese codes indicate the date of production and are used to track product for production and quality control purposes. We guarantee these products for 12 months when kept frozen from this date.\nThese codes are not to be confused with expiration dates. Food For Life products are marketed on a frozen basis to the natural food marketplace and shelf life will depend upon the date products are thawed. These products should be dated based on the date the product is thawed and according to the guidelines below:\nLife Expectancy: Frozen (0°F) - 12 months\nRefrigerated (45°F) - 2 weeks\nFresh (75°F) - 5 days\nIf products are purchased within these time periods from either the date of production or the date thawed, we recommend refrigerating or freezing for longer periods of keeping.', 'We’ve all been there: That moment you want to put the kibosh on all your take-out, but haven’t been to the grocery store in a while. You try to scrounge up the ingredients you do have into something tasty and healthy, just like the chefs on Chopped. The thing is, if you haven’t been keeping an eye on expiration dates, that pasta sauce and parmesan cheese hiding in the back of your fridge might not be your best bet — and that sell-by date might not tell the whole story.\nWhile sell-by dates do serve a purpose — to inform stores how long to display food items — once a customer purchases the product, it’s up to them to determine how long it lasts. And the problem there: Consuming perishable foods after they spoil leads to one of the most prevalent cases of food poisoning, warns Joe Kivett, co-author of The Food Safety Book: What You Don’t Know Could Kill You.\nTo help you steer clear of any sickness, we talked to food experts to find out exactly how long you can keep your favorite kitchen staples.\nRELATED: Can Fast Food Go “Farm to Table?”\nFood Safety: How Long Your Favorite Foods Really Last\nTypical Shelf Life: Three to five weeks for fresh and about seven days for cooked\nThankfully, for omelet lovers and healthy bakers, eggs typically last a month in the refrigerator. Pay attention to sell-by and expiration dates, but if your carton doesn’t have one of those, look for a three-digit stamp instead. This stands for the date in which the eggs were washed, graded and packed and it’s required for USDA Grade eggs (while explicit sell-by and expiration dates aren’t). “This date appears as a three-digit code representing the day of the year, beginning with 001 (January 1) and ending with 365 (December 31),” Kivett explains.\nRemember to refrigerate eggs in their original package in the coldest part of the refrigerator. Have a bunch of hard boiled eggs in your fridge from meal prep Sunday or a batch of egg muffins? They’ll last about a week from when you cooked them, when stored in the fridge.\nTypical shelf life: About a week past the sell-by date\nThe general rule of thumb for cow’s milk is refrigerating it for no more than five to seven days past the sell-by date. But the real key is storing it properly. “Keep milk towards the back of your fridge — never on the door, because the temperature changes when you open and close it,” says Eliza Savage, registered dietitian at Middleberg Nutrition. “With dairy milk, you will know it’s gone bad by a sour smell, yellowish tint or change in texture towards thick and clumpy,” she says. The same goes for lactose-free milk.\nNut milks usually last seven to 10 days once opened. Store unopened almond milk in the fridge to maximize shelf life, and toss at least one week after the date on the box. Amidor even suggests tossing soy or nut milks before the use-by date (keep an eye out for changes in scent or texture), as that date signifies how long the closed container lasts.\nTypical shelf life: Six weeks for regular; three weeks for grated\n“Hard cheeses [like parmesan and pecorino] will last the longest, followed by semi-hard cheeses, such as cheddar, swiss and gouda,” explains Savage. “Sliced cheese or shredded cheese will mold or expire quicker, as there is a larger surface area for the bacteria and air to be exposed to.” Good news: Most hard cheeses will last six weeks longer than the printed date, Savage says. But shredded hard cheese, when opened, can only last for about three weeks. In general, if you see mold, toss it.\nTypical shelf life: Two days for fish and poultry, about five for red meat and two weeks for unopened processed meats; two months to a year in the freezer\nThe U.S. Department of Health and Human Services has very specific recommendations for storing various types of meat. (Check out foodsafety.gov for details.) Fish, like cod, flounder and tilapia, lasts only one or two days in the fridge, but about six months in the freezer. (Pro tip: Write the date you’re freezing them on the package, so you know when to toss.)\nWhen it comes to raw poultry, it’ll only last in the fridge for a day or two, but up to a year if you store it in the freezer. As for cooked poultry, keep it in the fridge for three to five days, and use your best judgement to determine whether or not it’s still good.\nRaw red meat and pork has a longer shelf life. Store these cuts up to five days in the fridge, or in the freezer anywhere from four months to a year. Cooked red meat lasts three to four days in the cold.\nProcessed meats are a different ball game. Cold cuts typically last two weeks if they’re unopened. (This isn’t always the same for the fresh slices you get at the deli stand — subtract a few days to be safe.) Hot dogs are only good for a day or so in the fridge, but can last up to two months in the freezer.\nTypical shelf life: About a week\nWhen it comes to fruits and veggies, how long they’ll stay edible depends on the type. “Some produce is best stored at room temperature, like garlic, potatoes and onions, which can last a few weeks or more. Meanwhile others, like tomatoes and avocados, have about a week-long shelf-life when kept at room temperature,” explains Toby Amidor, MS, RD author of The Healthy Meal Prep Cookbook: Easy and Wholesome Meals to Cook, Prep, Grab and Go. “You can also store whole fruit like melons at room temperature, but once you slice them open, store them in the fridge.”\nOther fruits and vegetables — including apples, potatoes, ripe bananas and tomatoes — contain a naturally occurring plant hormone called ethylene gas. In general, fruits that contain this invisible and odorless gas (harmless to humans) continue to ripen even after being picked. But if you store them near the produce that’s sensitive to this gas (specifically, bananas, carrots, lettuce, pears and strawberries) it could cause them to spoil quicker. Store your fruits and veggies in separate containers or drawers, and you’re good to go.\n6. Frozen produce\nTypical shelf life: Six to 10 months in the freezer\nWhile it’s still safe to munch on frozen vegetables after 10 months, you’ll might sacrifice flavor and texture. “Frozen vegetables will remain fresher longer and preserve their taste if they are stored in freezer-safe containers at 32 degrees or less,” Savage says. Frozen fruits generally last anywhere from six to nine months if kept constantly cold.\nTypical shelf life: One week after the best-by date (two weeks in the fridge)\nThe biggest predictor in determining the shelf life of bread is whether it’s commercially produced or baked fresh. “Commercial bread will last as long as long as seven days past the ‘best by’ date when stored on the shelf, as long as 14 days when stored in the refrigerator, and three months when frozen,” says Kivett. “Bakery bread may last only two days beyond the ‘best by’ date when stored on the shelf.” But you can extend that by placing it in the freezer, too.\nTypical shelf life: Anywhere from two months to two years\nAmidor suggests keeping mustard in the fridge for 12 months, ketchup for about six, barbecue sauce for four and opened commercial mayo for about two months. For those stored at room temperature, toss Worcestershire sauce after 12 months, baking powder after 18 months (if sealed) and un-opened vinegar and maple syrup after two years. “Once opened, these last up to 12 months,” Amidor says.']"	['<urn:uuid:b426a773-1ad6-45d0-beac-52b32340b18c>', '<urn:uuid:fdb556a7-61f8-498f-891b-550216cb0d53>']	open-ended	with-premise	long-search-query	distant-from-document	comparison	novice	2025-05-13T03:20:41.944655	13	44	1884
10	researching historic trade policy when did president gain power negotiate trade deals without congress	In 1934, the Reciprocal Trade Agreements Act gave the President the power to levy tariffs and negotiate bilateral trade agreements without congressional approval, though these agreements were later amended to have a three-year expiration date.	['by Sean Wright\nIn his Farewell Address, George Washington wrote: “Even our Commercial policy should hold an equal and impartial hand: neither seeking nor granting exclusive favors or preferences; consulting the natural course of things…in order to give trade a stable course.” Considering Washington’s famed protectionism when it came to foreign affairs, it makes sense that he would encourage natural free trade without the use of international trade agreements. In present-day America, Washington’s words are still very relevant. After a long period of pioneering trade agreements, the United States may be trending towards a policy of isolationism, as evidenced by their recent decision to abandon the Trans-Pacific Partnership, a controversial 12-nation agreement that would create a trade network similar to that of the European Union.\nFor over 130 years, American leaders generally followed Washington’s advice regarding international trade. However, this policy was abandoned after the disastrous Smoot-Hawley Tariff of 1930. Smoot-Hawley raised tariffs considerably, against the pleas of a large majority of economists at the time who said that it would be detrimental for the nation’s economy. Predictably, they were correct, as imports and exports fell by over 50%, starting a calamitous period that many economists today consider a cause of the Great Depression.\nOnly four years after the passage of Smoot-Hawley, the Reciprocal Trade Agreements Act marked a new era of United States trade policy. For the first time, the President was given the power to levy tariffs and negotiate bilateral trade agreements without congressional approval. This was essentially so that the President could hastily renegotiate all of the trade deals that had been soured by Smoot-Hawley, without having to be saddled by an obligation to Congress. Critics said that the bill gave the President too much power, and it was eventually amended so that trade agreements created under these terms had a three-year expiration date.\nIn 1947, the United States furthered extended its commitment to international trade agreements by involving itself in the General Agreement on Tariffs and Trade. The body conducted eight rounds of talks, over the course of almost 50 years, addressing various trade issues and resolving international trade disputes. The Uruguay Round of 1993 created the World Trade Organization, which to this day provides a forum for 117 countries to negotiate additional tariff reductions, settle disputes, and enforce rules.\nPresently, the United States has the 2nd largest export economy and 5th most complex economy in the world. Its top exports are refined petroleum (7.1%), cars (4.2%), and planes (3.7%). The top imports are crude petroleum (11.1%), cars (7.1%), computers (4.2%), and vehicle parts (2.9%). These statistics are reflective of the US’s general policy of importing raw materials and exporting finished products, a policy that has been embraced by its top trading partners: China, Canada, Mexico, Japan, and Germany. Canada and Mexico are both involved in a large trade agreement with the United States, the North American Free Trade Agreement (NAFTA) that has shaped much of the countries’ economic policy since its inception in 1994. NAFTA eliminated almost all tariffs between the three nations, which has greatly increased trading levels. However, the agreement also makes it easier for companies to move operations from the United States to Mexico, as evidenced by Carrier Corporation’s production move earlier this year.\nThe United States currently has trade agreements in place with over 20 countries, including Australia, Chile, Israel, and Singapore. This global involvement represents a massive deviation from the protectionist tariffs that dominated American trade policy up until the 1930s. Recently, however, a movement of isolationism has been gaining momentum. The American Recovery and Reinvestment Act of 2009 is an example of this protectionist push. The act prohibits the use of recovery funds for work on a public building, unless all of the steel, iron, and manufactured goods used on the project are from the United States. This legislation clearly encourages the production and sale of American-produced goods over foreign products. Even more indicative of this new wave of isolationism are the anti-trade sentiments expressed during the 2016 U.S. presidential election campaign. Presidential candidates Donald Trump and Bernie Sanders, who are by no means political allies, both railed against free-trade agreements past and present throughout their campaigns. Trump, the eventual winner and president-elect, has sworn his administration will tear up deals like NAFTA, which he blames for the loss of American jobs and prosperity.\nAnother deal loathed by the incoming president-elect is the Trans-Pacific Partnership. Twelve countries, including the United States, Japan, and Peru, signed TPP in February 2016. The partnership aims to increase economic activity between the countries through the reduction of more than 18,000 tariffs. The potential members make up 40% of the world’s economy, meaning that the deal would be the largest of its kind in over two decades.\nThe agreement, which is essentially an extensive loosening of trade barriers and business regulations, would be a dream come true for the profit-maximizing producer. They would have access to a single market that would allow their goods to reach far more consumers, enabling them to achieve lower per-unit production costs. Some experts predict that TPP would increase American exports by 9.1%. The decline in prices of imported raw materials, caused by a mass lowering of import tariffs, would further decrease production costs. These conditions would result in a large increase in production, which would allow producers to specialize in what they produce, leading to more efficiency and a higher production capability.\nAnother benefit that producers would receive has become a controversial sticking point for the agreement. Investment-state dispute settlement, or ISDS, would create an international tribunal court of sorts, allowing producers to appeal policies made by foreign governments that hurt their profits. It permits corporations to challenge any governmental decision—whether it be a law, regulation, or judicial ruling, among others—in front of a panel of three “neutral” corporate lawyers. A similar institution created by NAFTA has yielded troubling results, exemplified by Metalclad v. Mexico, a case in which Mexico was ordered to pay $16.7 million in damages to a toxic waste company. The presence of this sort of institution in TPP has caused lots of public outcry, and this clause alone has provoked opposition to the entire agreement.\nAmerican laborers will likely see far more negative consequences from TPP than positive ones. The international labor pool will become far more competitive as a result of the deal, thanks to lower wages and far less regulations. Additionally, TPP includes investment rules that make it easier to invest overseas, which would encourage more foreign rather than domestic investment by American corporations. This could consequently cause some companies to move production away from the United States in search of cheaper labor. It’s the basic rules of supply and demand: Option A (domestic labor) becomes far less desirable when producers are presented with a cheaper Option B (foreign labor). Demand for American labor will decrease, but the supply will remain the same, leading to a surplus of labor, otherwise known as an increase in unemployment. A wide-scale shift in production away from the United States would lead to the loss of millions of manufacturing jobs, crippling many middle-class families and damaging the entire American economy.\nTrump and Sanders are right: as currently written, the Trans-Pacific Partnership will not, and should not, be passed. There are far too many controversial measures that simply will not succeed under the same umbrella. However, the TPP should not be completely scrapped. Instead, sensible changes should be made to the agreement so that it is the most beneficial that it can be to all parties involved.\nFor example, the investor-state dispute settlement (ISDS) needs to be removed from TPP. It is a corrupt, unjust system of conflict resolution that favors the corporations and circumvents the countries’ authorities. Judgments like that of Metalclad are harmful to investor-state relations because it develops an attitude of mistrust, and it is unfair that a government should have to pay millions in damages and legal defense for proceeding according to their own law.\nAnother change that must be made to TPP is the addition of incentives for companies to maintain production in the United States. The labor forces of other countries will become more competitive under TPP with lower wages and less working regulations, so it is important that the U.S. keeps its workers competitive. By adding a small incentive for companies to keep production in the United States, such as a minor tax break, the government will be able to minimize the amount of jobs leaving the country. This will allow the country to reap the benefits of TPP, while keeping American jobs intact.\nObviously, these changes would have consequences. Most notably, the policy tweaks would potentially irritate the other nations involved in the deal. Countries seeking to create a more business-friendly environment would balk at the proposition of removing ISDS, and countries looking to cultivate a more competitive labor force would be irked by the addition of incentives for American companies to keep production domestic. However, as displeased as they may be, there is a large possibility that they agree to the new terms. This is because the Trans-Pacific Partnership needs the United States in order to be successful. Without the strength of the world’s largest economy, the trading bloc created by the agreement would be too weak to be sustainable. Donald Trump, the incoming president-elect, has vowed to never sign the TPP, leading the current Obama administration to announce that they are abandoning the deal. At this point, after public acknowledgment that the current form of TPP will never be passed, it is worth it for the U.S. to at least propose these changes that would lead to more favorable terms for the United States. If the other countries involved want a serious chance at making this deal happen, they should consider the new terms proposed by the United States. With these changes, the Trans-Pacific Partnership would be a trade agreement for the people, not the corporations, and could potentially become the driving force behind a period of American economic prosperity.']	['<urn:uuid:46285e7d-16b4-4483-8bec-224df2a50c92>']	factoid	with-premise	long-search-query	distant-from-document	single-doc	expert	2025-05-13T03:20:41.944655	14	35	1673
11	eye drops bacteria growth safety measures	Eye drop dispensers use a combination of hydrophobic and hydrophilic filters to prevent bacterial growth without preservatives, which can be toxic to eye cells. For safety during manufacturing, facilities must maintain controlled environments with different cleanliness grades (A through D), ensure proper air filtration, require personnel to wear protective equipment like hair covers and overshoes, and implement regular cleaning and disinfection protocols.	"['US 4938389 A\nA multidose liquid dispenser for maintaining the sterility of solutions without a preservative has been developed. The dispenser includes a filter assembly having a hydrophobic filter and a hydrophilic filter in tandem with the hydrophobic filter located near the dispensing tip. The use of the hydrophobic exterior filter and the hydrophilic interior filter permits excellent liquid flow while precluding the growth of bacteria on the filter. The inability of the bacteria to attach to the exterior hydrophobic filter prevents clogging of the pores.\n1. A liquid dispenser for dispensing sterile liquids comprising:\na reservoir compartment adapted for storing sterile liquids;\na tip adapted to dispense said sterile liquids;\na flow passage providing fluid communication between said tip and said reservoir; and\na filter assembly, said filter assembly being sealed in said fluid passage so that it extends across the entire expanse of said flow passage to prevent fluid and air flow except through said filter assembly, said filter assembly comprising a hydrophilic filter and a hydrophobic filter arranged in fluid communication serially along said flow passage so that said hydrophilic filter is nearer to said reservoir than said hydrophobic filter, said hydrophobic filter and said hydrophilic filter each having pores sufficiently small to act as microbial filters.\n2. The liquid dispenser of claim 1 wherein said hydrophobic filter and said hydrophilic filter are separated in said filter assembly.\n3. The liquid dispenser of claim 2 wherein said hydrophobic filters and said hydrophilic filters are separated by a support ring.\n4. The liquid dispenser of claim 3 wherein said filter assembly comprises a plurality of support\n5. The liquid dispenser of claim 1 wherein said filter assembly is located in said flow passage such that said hydrophobic filter is substantially at said liquid dispensing tip.\n6. The liquid dispenser of claim 1 wherein said filter assembly is sealed in said flow passage by an adhesive.\n7. The flow dispenser of claim 1 wherein said filter assembly is sealed in said flow passage by ultrasonic sealing.\n8. The liquid dispenser of claim 1 wherein said filter assembly is sealed in said flow passage by heat sealing.\n9. The liquid dispenser of claim 1 wherein said liquid dispenser comprises a multidose dispenser.\nThe present invention concerns a liquid dispenser for sterile solutions. More particularly, the present invention relates to a multidose dispenser for sterile solutions, particularly in a dropwise form, which keeps the solutions aseptic without the use of preservatives.\nA number of solutions which are sold and administered as over-the-counter (""OTC"") and/or prescription preparations must be kept sterile to prevent bacterial or other microbial growth. The conventional means of Preventing microbial growth is to add a preservative or other antibacterial agent to the solution during packaging. Although these preservatives keep the enclosed solution sterile, the bottle itself may harbor external bacterial growth which is carried along with the outflow of fluid. In addition, the preservatives themselves are often toxic not just to bacteria but also to the cells which are being treated by the bottled preparation. For example, the preservatives used in most eye drops are toxic to goblet cells and other cells in the eye. Because of this toxicity level, continued use can cause more long term problems then the solutions solve.\nFilter bottles have been used to store the solutions in aseptic condition after cold sterilization for many years. Antimicrobial filters, e.g., 0.2 micron filters, are often used for this purpose. However, in many of these previous designs, removal of the fluid required removal of the filter. In other cases, the limitations of flow caused by the small pore size of the microbial filters are not important because the solution is not dispensed through the filters or high pressures are available for dispersing. Because of these and the other problems with filter bottles, the use of preservatives or single dose packaging have been the rule in dispensing OTC and other liquid products such as eye medicants or drops.\nAccordingly, an object of the invention is to provide a multidose liquid dispenser which can keep solutions aseptic under prolonged use without the use of an antibacterial or antimicrobial additive.\nA further object of the invention is to provide a filter bottle for use in cold sterilization processes which provides good flow properties and protection against bacterial contamination.\nAnother object of the invention is to provide a bottle which can be used for eye drops and similar solutions which do not contain preservatives.\nThese and other objects and features of the invention will be apparent from the following description and the drawing.\nThe present invention features a multidose dispenser for sterile liquids which provides antimicrobial action without need for preservatives or other antibacterial additives. The invention is based, in part, on a dual filter assembly which provides good flow rate of fluids, protection against contamination after filter breakage, and assists in prevention of bacterial growth on the external dispersing tip of the bottle.\nThe liquid dispenser of the present invention, which is particularly useful for dispensing sterile liquids or solutions, has a reservoir compartment adapted for storing the sterile solutions. The reservoir is in fluid communication, through a flow passage, to a tip adapted to dispense the sterile solution. A filter assembly is sealed across the entire expanse of the flow of passage to prevent fluid delivery except through the filter assembly. The filter assembly contains both a hydrophobic and a hydrophilic filter, the filters being arranged such that the hydrophilic filter is closer to the reservoir while the hydrophobic filter is closer to the liquid dispensing end of the tip. Both the hydrophobic and hydrophilic filters have pores which are of a size sufficient to prevent bacteria from traversing the filter, e.g., the pores act as microbial filters.\nIn preferred embodiments of the invention, the filter assembly has the hydrophobic and hydrophilic filters separated, e.g., by a support ring. A more preferred embodiment has a filter structure whereby there are a plurality of support rings between, and on opposite sides of, the filters to provide structural support and filter separation. In the most preferred embodiment, the filter assembly is located in the flow passage such that the hydrophobic filter is substantially at the dispensing end of the liquid dispensing tip. The filter assembly can be sealed in the flow passage by any means. Preferred methods of sealing the filter assembly in the flow passage are non-flaking adhesives, ultrasonic sealing, and heat sealing.\nThe sole figure of the drawing shows a cut-away view of a liquid dispenser of the invention.\nThe present invention features a multidose dispenser for sterile liquids which is capable of preserving sterility of the contained solution without the use of chemical preservatives or antibacterial additives. The dual filter assembly of the present apparatus provides excellent flow properties, inhibits bacterial contamination of the bottle, and preserves the sterility of the contained solution.\nThe sole figure of the drawing more clearly illustrates that present invention. Flexible squeeze bottle 10 has a reservoir chamber 20 connected by flow path 30 to tip 40. Standard dispersing bottles with removable tip, e.g., low density polypropylene such as those made by Wheaton Scientific, Melville, N.J. can be used. The bottles were modified by addition of filter assembly 50 located across flow path 30 near tip 40. Filter assembly 50 contains a hydrophobic filter 52, for example a TF (PTFE) 0.2 micron pore size filter such as is obtainable from Gelman Sciences, Inc., Ann Arbor, Mich. Hydrophilic filter 54 is a microbial filter, preferably having a pore size of 0.2 microns or less. The FP Vericel filter, also obtainable from Gelman Sciences, Inc., is exemplary of this type of filter. The hydrophilic filter may have a laminated polypropylene web support on one side for reinforcement and durability. Support disks 56 are placed to further support and separate filters 52 and 54. Silicone rings punched from Silicone sheeting, e.g., Silastic Brand Sheeting from Dow Corning, Midland, Mich., can be formed into a preferred ring for use to provide both support and separation functions. The rings are bound to the filters, and to the plastic of the bottle, by standard techniques, e.g., ultrasonic binding, heat sealing, or adhesive sealing. If an adhesive is used, it must be non-flaking. A preferred adhesive is Silastic Brand Medical Adhesive Silicone-type A, also from Dow Corning. The adhesive must be kept off the active portions of the filters to prevent contamination and maintain flow.\nThe dual filter assembly of the invention has a variety of purposes. First, if there is a break in either filter, sterility is maintained by having two distinct filters. Second, the hydrophobic filter does not retain water so bacteria are inhibited from growing on the outside surface of the filter assembly. Third, the hydrophilic filter closer to the reservoir wets better than the hydrophobic filter, and since flow rate is improved by better wetting, the use of the hydrophilic filter permits a higher flow rate from the bottle without high pressure.\nThe following non-limiting Examples further illustrate the efficacy of the invention.\nThis Example, 15 ml Wheaton bottles with snap-tips are fitted with filter assemblies of the invention. This filter assembly has a 0.2 micron FP Vericel Membrane Filter (Gelman Sciences, Inc.) glued between two punched Silastic rings using Silastic Brand Medical Adhesive Silicone-type A (Dow Corning). The filter disks are 8 mm in diameter and Silastic support rings are also 8 mm disks of Silastic Brand Sheeting (0.02 inches) (Dow Corning) with 5.5 mm essentially central holes punched-out. The assembly further includes a 0.2 micron PTFE membrane filter (Gelman Sciences, Inc.) which is bonded between one of the Silastic rings and a third Silastic ring. The assembly is glued to the snap-tip dropper such that the Silastic support ring is bonded directly to the dispensing end of the snap-tip dropper and the Vericel filter is closest to the solution in the bottle.\nFive bottles made with the filter assembly and another bottle, identical except lacking the filter assembly, were filled with substantially the same amount of a test solution under cold sterilization procedures. The solution is an eye drop solution such as described in U.S. Pat. No. 4,775,531, issued on an application of the present inventor. All the bottles were used to dispense fluid to the eyes of human volunteers between one and two times daily for one month, excluding weekends. At the end of the period, the snap-tip assembly was removed and 1 ml of the remaining fluid was placed in fluid thioglycollate broth for fourteen days at 30-35° C. An additional 1 ml of the remaining fluid was placed in soybean-casein digest medium for fourteen days at a temperature of 20-25° C. After the fourteen days, the fluid thioglycollate broth was plated out on soybean-casein digest medium and incubated at 20-25° C. for an additional fourteen days.\nAt the end of the period, all of the solutions contained within the bottles having the filter assembly were sterile. However, the solution from the bottle without the filter system was contaminated with bacteria as indicated by turbidity of the thioglycollate broth. Further investigation indicated that the bacteria was pseudomonas.\nFor this Example, forty-nine filter bottles were made using the filter assembly described in Example 1. The bottles were all filled with the same eye drop solution. Eleven patients were given the bottles at separate time intervals as needed. The patients were instructed to use the drops contained at least six times a day. The bottles were returned with a portion of the solution remaining and compliance was monitored by measuring the volume remaining upon the return of the bottles. Mean duration of usage was 23.4+/-1.2 (SEM) days. Twenty-three of the bottles were used for twenty-eight days or longer. Upon return, all forty-nine solutions tested sterile by USP guidelines, using the testing described in USP XXI, Section 71.\nAs is clearly indicated by the Examples, the present invention provides a means of maintaining the sterility of solutions without the use of additives such as preservatives or other antibacterial agents. Because of the toxic effects of such agents on certain cells, this has numerous advantages.\nThe invention is not limited by the foregoing Examples but may be practiced in other obvious variations. Such other variations of the claimed invention are included within the following claims.\nCitations de brevets', ""Safety of the researcher, environment, manufacturer and the consumer is of utmost importance in each of the processes from strain development experiments to manufacturing and packaging of the final product. To ensure the same, consideration of all the precautions and safety measures must be taken to make the work environment, manufacturing environment and consumer product safe and to prevent any hazardous situations. Material safety data sheets for all reagents should be kept handy (List of reagents used have been given in the handbook).\nFigure 1: Safe chassis bacteria\nOur entire project requires a Biosafety Level 1 (BSL-1) laboratory. This is because our project has proposed the use of Biosafety level 1 bacteria (Escherichia coli DH5alpha and Escherichia coli Nissle 1917) as our probiotic chassis iGEM - safety risk groups and therefore we consider our project to be harmless to researchers in this aspect. None of the designed experiments are expected to increase the pathogenicity of the bacteria.\nThe bacteria Escherichia coli Nissle 1917 is an extremely well studied probiotic strain with no known negative effects on health Pradhan, S., & Weiss, A. A., 2020. It does not have the ability to become an aerosol and has no known pathogenic effects on animals and plants as well. It is responsible for producing fitness factors called ‘colicins' that are toxic to other Escherichia coli strains. In our case, it would be an advantage as we want our bacteria to compete while it stays in the gut. Furthermore, its ability to form biofilms increases its long-term persistence in the gut.\nWe would not reveal important information like activation mechanisms, etc to ensure that dual use does not occur (unless it has all the required clearances).\nBiosafety & Biosecurity\nFigure 2: Dual Use\nTeam Bielefeld-CeBiTec 2015 proposed a detailed analysis of biosecurity, particularly the dual use issue, with respect to the iGEM competition in which they have mentioned several aspects and questions to be considered Bielefeld-CeBiTec, 2015. Some of the questions which we have answered are given below (More can be found in the handbook).\nCan you imagine any malevolent use of the knowledge and sequences published on your team's wiki? Could the knowledge you provide be used for the creation of products or organisms that pose a danger to humans or the environment?\nOur project involves the release of an anti-inflammatory cytokine (IL-10) whose release is regulated by a control mechanism involving SoxS and SoxR genes. The SoxR gene is also regulated to be released only in the presence of methylmercury using the MerR-PmerT mercury responsive genes.\nSelective mutation of any of these control mechanisms could lead to release of IL-10. This could lead to reduced immune response to pathogens. IL-10 also down regulates transcription and secretion of IL-1β, IL-6, IL-8, TNF-α, and G-CSF by activated monocytes and macrophages. This could lead to cancer Schreiber S, 1997. IL-10 upregulates ICAM-1 within neural tissues. This promotes massive macrophage influx, demyelination due to inflammation and subsequent loss of neural tissue, resulting in muscle weakness and paralysis Dru S., 2009.\nWho will use your product? If your product is successful, who will receive benefits and who will be harmed?\nOur product if successful will be used by people who are at risk for methylmercury poisoning. We have made sure to not use any allergens or preservatives which could potentially harm consumers.\nWHO also has a self-assessment questionnaire to ensure that good quality, ethical research activities are conducted in safe and secure facilities. Some of the important question relevant to biosecurity and biosafety aspects have been answered below (more in handbook) WHO - Responsible life sciences research for global health security :\n|Pillar 3: BIOSAFETY AND LABORATORY BIOSECURITY|\n|An assessment of the risk associated with research activities is conducted||Yes. The team has documented a Safety Handbook that covers various safety aspects and a detailed risk assessment for each experiment|\n|Risk assessments are able to identify requirements for risk reduction measures including the level of containment required||Yes. The Safety Handbook covers not only the risk reduction measures but also the level of containment required for each stage of the research that will be conducted.|\n|Legislation/regulations regarding hazardous waste disposal are followed||Yes. The team will strictly follow the regulations pertaining to hazardous waste disposal. (No Lab Experiments were performed this year)|\n|Valuable biological material is safely and securely stored||Yes. The team will ensure that the valuable biological material is safely and securely stored for future use. (No Lab Experiments were performed this year)|\nFigure 3: Methylmercury is extremely toxic.\nAll forms of mercury, both organic and inorganic are highly toxic. Exposure to mercury even in small amounts can causes severe health issues and can even affect the development of the child in utero and early in life WHO - Mercury and health.\n- To avoid mercury poisoning by accidental inhalation, ingestion, injection or absorption through the skin while working with it, the use of appropriate type of gloves (Nitrile (8 mil) over Silver Shield) and other essential lab attire like Chemical goggles/face shield, lab coat with full sleeves, full-length pants, and closed toe shoes must be ensured.\n- Mercury spill kits must be kept handy in the lab in case of an emergency.\n- All mercury containing waste must be disposed of separately by packing in a container with a hazardous waste label and chemical name on it.\n- We have taken into consideration all the hazardous waste disposal laws in India and have also enlisted the ones in the US for reference in our safety manual.\nIn the USA: Paraquat is categorized under ‘restricted use' by the US Environmental Protection Agency. Only those with a license are allowed to use this chemical. A blue dye and sharp odor are added as a warning, and another agent is added to induce vomiting in case of ingestion Paraquat dichloride-EPA.\nIn India: CIBRC (Central Insecticide Board and Registration Committee) has categorized paraquat dichloride as highly toxic Conditions of paraquat use in India - Pan-India.\nTo ensure safety while handling paraquat protective clothing, including gloves, safety glasses, respiratory equipment, full-sleeved lab coat, full-length pants, and closed-toe shoes must be worn. During disposal, suitable incineration and chemical treatment in accordance with local regulations must be followed (by a licensed professional).\nFigure 4: Gloves\nTo maintain aseptic conditions, all experiments must be performed inside the laminar flow chamber while ensuring the UV light doesn't cause any problems to the person performing the experiment.\nPrecautions must be taken while working with the autoclave and handling of hot autoclaved equipment must be done using appropriate heat proof gloves. Aseptic conditions must be maintained in order to prevent contamination by unwanted DNA or organisms. Gloves must be used not only for handling hot equipment and chemicals but also for cold samples taken out of the freezer to avoid cold burns. The stains and other hazardous substances should be handled with care during gel electrophoresis, sonication and gas chromatography.\nLabs must be equipped with an emergency shower, eyewash station, and a first aid kit and workstation must be cleaned. Disposal of all waste materials must be done properly.\nIsolation of all electronic components from any conducting media should be ensured. All wiring connections should be insulated properly, and care must be taken to avoid spilling or leakage of chemicals or fluids onto the motors.\nAfter experiments which involve methylmercury and paraquat, the dialysis tube must be discarded and other equipment components should be thoroughly cleaned following the handling protocols. Any leakage into the incubator should be prevented by placing the entire set up in a closed air tight container. All of the components used in the design are checked for temperature and pH resistance.\nFigure 5: Specialized disposal\nAll the experiments designed are relatively safe. The bacteria used should be highly tested for any safety concerns. However, any unexpected results or modifications must be handled with extreme care.\nGrowth Media experiments which utilize hazardous substances like mercuric oxide, concentrated HCl etc. must be handled in the fume hood in rooms with adequate ventilation. Protective equipment must be worn at all times. Disposal of inorganic peroxides and oxidants as well as bromine and iodine should be done by rendering them harmless by reducing it with acidic thiosulphate solution. Disposal of contaminants should be done separately with adequate labeling.\nInitially, we identified the worst cases in pharmaceutical cleaning validation Identification of worst case in cleaning validation- Pharmaceutical guidelines.\n- Potency of product\n- Solubility of Active Pharmaceutical Ingredient (API) in water\n- Toxicity of API\n- Concentration of API\n- Contact surface area\n- Product excipients\n- Manufacturing process\nThe quality and quantity of the API (bacteria) must be maintained at recommended safe levels (CFU count) ensuring optimal potency. The water released during drying or other process must be sterilized before discarding. The API in our case is Escherichia coli Nissle 1917 which is a non-pathogenic known probiotic strain. The API concentration must be at recommended levels for a probiotic. The equipment used must have minimum surface area and should be sterilized regularly with non-harmful substances. The excipients used must not contain any known allergens as well as preservatives. Contamination of the product must be prevented by repeated cleaning and sterilization of all components including air, equipment, media etc.\nSince the volume of the microorganisms present in bioreactors is much larger, extreme care must be taken to prevent the contamination of the bioreactor itself and also the surrounding environment.\nThere are possibilities of liquid spills and aerosol formation for some widely used bacterial chassis. However, the bacteria we have proposed is Escherichia coli Nissle 1917 which is a risk 1 non-pathogenic organism and does not have the capability to form aerosols.\nThe proximity of large volumes of liquid and mains electrical equipment (eg, from heaters, aerators, sensors, etc) presents a hazard. Commercially-designed equipment from a reliable source should prevent access to live conductors.\nIn case of any gas production, the gases must be vented out to prevent high pressure build up, and it should be kept away from fire.\nThe quality and safety of the manufactured product should be a key concern in order to ensure the client's safety Prevention of microbial contamination during manufacturing- Pharmaceutical guidelines.\n- Air filtration and air change rates must be set and done regularly.\n- In case of contamination in one area, the plant should have a HVAC system which would remove and prevent contaminants from spreading to other areas.\n- Ventilation dampers should also be positioned away from the production area for maintenance purposes.\nFigure 6: Personal Protective Equipment\n- The personnel handling the production must be trained on the importance of hygiene and it should be ensured that they would wear protective clothing such as hair cover, overshoes, over garments, beard covers, etc. to prevent any sort of contamination.\n- It is required to ensure that direct contact with the product or an equipment which comes in contact with the product is avoided.\n- Cleaning agents must be of a suitable grade to minimize any health risks. Cleaning and disinfection should be done regularly. Rotation of different disinfectants should be done to prevent any resistance development. The disinfectant must be sterilized using a 0.2 micron membrane filter in sterile conditions. The hold time of the disinfectants must also be validated.\n- The equipment for cleaning should not have direct contact with the pharmaceutical product.\n- The cleaning practice must be validated.\nEquipment maintenance and cleanliness must be ensured and all guidelines must be followed.\nA controlled area for pharmaceutical manufacturing would be maintained. Any harm to the manufacturers due to dust particles or micro-organisms should be avoided by providing quality equipment, adequate hygiene training and regular cleaning and sterilization. The capsule integrity and sterility must be ensured during filling. Quality control of capsules should be done at each key stage. Different processes must be performed at different sections of the plant to prevent contamination.\nThere are four different levels at which a sterile pharmaceutical company should grade its control production: A B C and D. Grade A should be the zone for high risk operations like filling zone and zone for making aseptic connections; this zone should have laminar airflow systems with homogeneous airspeeds. Grade B is the background environment for grade A that allows for aseptic preparation and filling. Grade C and D are classified areas that handle the less critical stages of SPM Controlled areas in sterile manufacturing - pharmaceutical guidelines.\nFigure 7: Packaging\nBlister punching machine is closed at the manufacturing part, thus remaining tamper resistant. The packaging must maintain the integrity and safety of the product.\nWaste Management & Recycling\nPharmaceutical waste is categorized into 2 categories An overview of waste management in pharmaceutical industry - pharma journal\n- Hazardous waste (any contaminants or chemicals).\n- Non-hazardous waste\nAn important method of waste management is the prevention of waste material being created, also known as waste reduction. Before processing, any unnecessary waste generation must be checked and adequate measures should be taken.\nRe-use means the use of a product on more than one occasion, either for the same purpose or for a different purpose, without the need for reprocessing. Re-use avoids discarding a material to a waste stream when its initial use has concluded. The integrity of the product or equipment must not be sacrificed.\nRecycling involves the treatment or reprocessing of a discarded waste material to make it suitable for subsequent reuse either for its original form or for other purposes. Unused or haphazardly filled capsules should be recycled keeping in mind sterility. Discard water must be sterilized and used for some other purposes.\nPlease refer to the full safety handbook for all details.\nThe Safety Handbook includes detailed and complete safety considerations of every reagent, process, experiment, device, equipment, etc described in the other handbooks as well as biosecurity and biosafety issues of our project.\nTo download this document, click here.""]"	['<urn:uuid:8c289904-cfdb-4267-8ef8-f1f9628a5c37>', '<urn:uuid:2a27203c-a30b-4801-918b-3b46181abf4a>']	factoid	with-premise	short-search-query	distant-from-document	multi-aspect	novice	2025-05-13T03:20:41.944655	6	62	4368
12	brain damage reading problems types treatment	Reading disabilities can result from brain injury, stroke, or progressive illness, particularly affecting the left parieto-occipital region and angular gyrus. In phonological dyslexia, patients can read familiar words but struggle with new or non-words, often maintaining good reading ability if they had large pre-injury vocabularies. Treatment approaches include hyphenation, which has shown to improve reading ability in some cases. Early, intensive instruction in language and reading aspects is crucial for improvement. Different types of deficits exist, including phonological processing deficits (70-80% of cases), orthographic processing deficits (10-15%), and comprehension deficits (10-15%), with some patients showing multiple impairments.	"['Ad blocker interference detected!\nWikia is a free-to-use site that makes money from advertising. We have a modified experience for viewers using ad blockers\nWikia is not accessible if you’ve made further modifications. Remove the custom ad blocker rule(s) and the page will load as expected.\nIndividual differences |\nMethods | Statistics | Clinical | Educational | Industrial | Professional items | World psychology |\nPhonological dyslexia is a reading disability that is a form of Alexia (acquired dyslexia), resulting from brain injury, stroke, or progressive illness and that affects previously acquired reading abilities. The major distinguishing symptom of acquired phonological dyslexia is that a selective impairment of the ability to read pronounceable non-words occurs although the ability to read familiar words is not affected. It has also been found that the ability to read non-words can be improved if the non-words belong to a family of pseudohomophones.\nDeep and phonological dyslexiaEdit\nIndividuals who suffer from phonological dyslexia have the opposite problem to surface dyslexics. These individuals are able to read using the whole word method. However, they struggle when it comes to sounding words out. Phonological dyslexics are able to read familiar words, but have difficulties when it comes to unfamiliar words or non-words that are pronounceable. Several studies have found that many phonological dyslexics have a good reading ability if the individual has developed a large vocabulary prior to suffering from brain damage. These individuals seem to stop developing their vocabulary post-brain damage, which affects their reading capacity.\nPhonological dyslexia is a reading disorder in which the patient has impaired reading of nonwords. The symptoms of phonological dyslexia are very similar to those of deep dyslexia. The major difference between these two dyslexias is that phonological dyslexics do not make semantic errors associated with deep dyslexia. Beauvois and Dérouesné (1979) studied the first case of phonological dyslexia and came up with this term. The problem people with phonological dyslexia have is that they are able to read words using the whole word method; however, they are not able to sound words out. This means that they are able to read familiar words, but have difficulties reading new words.\nInitially it was believed that the factor causing phonological dyslexia was lexicality; however, other factors such as imageability and concreteness also play a critical role in reading. A study done by Crisp and Lambon Ralph concluded that imageability has a significant effect on phonological dyslexia. The study found that eleven out of the twelve patients had more accuracy when reading words with high imageability. In that study, the patient who was the exception was the least severely damaged, contributing to a view of phonological dyslexia and deep dyslexia as points on a continuum rather than discrete disorders.\nSeveral studies have found that different levels of brain damage can lead to the occurrence of varying forms of non-word reading disorders. It has been found that during certain tasks, dyslexics had activated one of two regions of the brain: the Broca\'s area, which is responsible for speech, or the Wernicke\'s area, which is responsible for forming and understanding. Both areas were seldom active together. This study has led to the conclusion that there exist neural connection breakdowns between the language centers that may be causing dyslexia.\nAn investigation conducted by Harley, T. A., and O\'Mara, D.A. (2006) found that hyphenation significantly improved a participant`s reading ability. The subject suffered from phonological dyslexia that was due to a deficiency in graphemic parsing. The study suggested that hyphenation might be generally useful as a strategy to assist phonological dyslexics.\nA study was done by Beauvois and Dérouesné on a 64-year-old man. The individual is described as right-handed, a retiree, and having formerly been an agricultural machinery representative. The individual had had surgery for a left parieto-occipital angioma. Scans showed a lesion at the left angular gyrus, the posterior part of the second temporal convolution, the inferior longitudinal fasciculus, the geniculostriate fibres and tapetum. The patient was also found to be suffering from neurological defects such as right inferior quadrantanopia, mild memory deficit, mild calculation impairment, minimal constructional apraxia, and astereognosia. It was found that the patient did not suffer from motor or sensory defects. He had been obliged to retire as the phonological dyslexia disrupted his ability to work. He had previously enjoyed reading, but was now unable to read his own or other pieces of writing. The diagnosis was confirmed with the Alouette reading test, which concluded that the patient suffered from a reading disability. He was found to have the reading ability of a 6-year-old child, which is considered to be the lowest reading level. The level of reading was not determined from the speed, rather from the fact that the patient was not able to read more than 62 of the stimuli presented in three minutes, while 40% of the represented stimuli were either read incorrectly or left unread. The reading errors included adjectives, possessive adjectives, conjunctions and verbs.\n- ↑ Cherney LR (2004). Aphasia, alexia, and oral reading. Top Stroke Rehabil 11 (1): 22–36.\n- ↑ 2.0 2.1 Dérouesné J, Beauvois MF (December 1979). Phonological processing in reading: data from alexia. J. Neurol. Neurosurg. Psychiatr. 42 (12): 1125–32.\n- ↑ (1995). Three routes from print to sound: Evidence from a case of acquired dyslexia. Cognitive Neuropsychology 12 (2): 113–147.\n- ↑ 4.0 4.1 Beauvois MF, Dérouesné J (December 1979). Phonological alexia: three dissociations. J. Neurol. Neurosurg. Psychiatr. 42 (12): 1115–24.\n- ↑ 5.0 5.1 5.2 Welbourne S.R.; Lambon Ralph M.A. (2006), ""Phonological and Surface Dyslexia in a Single PDP Model of Reading"", Proceedings of the 28th Annual Conference of the Cognitive Science Society, Mahwah, New Jersey: Lawrence Erlbaum Associates, pp. 2359–64, ISBN 9780976831822, http://csjarchive.cogsci.rpi.edu/proceedings/2006/docs/p2359.pdf\n- ↑ Berndt, R.S., Hawndiges, A.N., Mitchum, C. C., & Wayland, S.C. (1996). An investigation of nonlexical reading impairments. Cognitive Neuropsychology, 13, 763-801.\n- ↑ Dérouesné, J ; Beauvois, M F. (1985). ""The “phonemic” state in the non-lexical reading process: Evidence from a case of phonological alexia"" Surface dyslexia: neuropsychological and cognitive studies of phonological reading, 399–457, Hillsdale, N.J: Lawrence Erlbaum Associates.\n- ↑ Lishman WA (December 2003). Developmental dyslexia. J. Neurol. Neurosurg. Psychiatr. 74 (12): 1603–5.\n- ↑ (2006). Hyphenation can improve reading in acquired phonological dyslexia. Aphasiology 20 (8): 744–761.\n- Rohrer JD, Knight WD, Warren JE, Fox NC, Rossor MN, Warren JD (January 2008). Word-finding difficulty: a clinical analysis of the progressive aphasias. Brain 131 (Pt 1): 8–38.\n- Sato H, Patterson K, Fushimi T, Maxim J, Bryan K (2008). Deep dyslexia for kanji and phonological dyslexia for kana: different manifestations from a common source. Neurocase 14 (6): 508–24.\n- Tree JJ, Kay J (2006). Phonological dyslexia and phonological impairment: an exception to the rule?. Neuropsychologia 44 (14): 2861–73.\n- Tree JJ (June 2008). Two types of phonological dyslexia - a contemporary review. Cortex 44 (6): 698–706.\n- Phonological dyslexia: past and future issues.\n- Are there orthographic impairments in phonological dyslexia?\n|This page uses Creative Commons Licensed content from Wikipedia (view authors).|', 'Whether it be through doctors, charts, blogs or magazine articles, first-time parents are told of the milestones their children should be reaching and when they should be reaching them. Although there are developmental milestones, once your child enters into elementary school there are academic milestones. It is often unclear whether your child is in fact on track with others in the same grade. If your child is below average and struggling with reading skills, it is common to ask yourself if your child is simply just not grasping a concept or if it is in fact a specific learning disability (SLD) in reading.\nLiteracy development encompasses a number of skills required to be able to read. These skills include recognizing letters, calling on experiences and language skills. Many children with speech and language disorders should be carefully monitored as they are at increased risk for experiencing reading challenges. It is important to identify children at risk for reading difficulties at an early age. This is due to the fact that literacy skills take years to build up and for a reading impaired child it takes even longer. The brain is a muscle and the sooner your child’s brain starts to train in the specific way they need, the sooner they will remember how to use these skills on a regular basis and become better readers.\nThere are several different types of deficits and reading disabilities. I wanted to touch upon each in order for you to understand where your child may possibly fall. Labels for reading disorders include dyslexia, reading disability, specific reading disorder, and specific reading comprehension deficit. For purposes of this post, “reading impaired” children shall be those who score below the 30th percentile in basic reading skills. Although the different types of reading deficits are listed separately, individuals can experience deficits in multiple areas. When children have deficits in both phonological and orthographic processing, it is known as the dual-deficit model. These children typically take longer in their reading intervention process.\nAbout 70-80 percent of children with a reading disability have trouble with accurate and fluent word recognition and poor spelling and decoding abilities. These difficulties cannot be explained by general developmental skills or lack of instruction. In other words, a child’s reading skills are poorer than expected and, despite having had proper instruction in reading, the child still has a difficult time reading compared to their achievements in other subjects.\nMore often than not, trouble with word recognition is due to a weakness in phonological processing. Reading accuracy, or phonological processing, deficits tend to arise when a child struggles to break down the sounds of spoken language or “sound out” words (also called decoding). These children find it incredibly challenging to spell, match sounds with written symbols, sound out words and understand written words. The term dyslexic applies mainly to this group.\nOne can detect deficits in phonological awareness during early childhood because to have phonological awareness, you must have the pre-requisite skills in phonemic awareness. Phonemic awareness is the foundation of phonological awareness. It is the understanding and ability to process individual speech sounds, so that they can be broken down (segmented), blended together (decoded) and rearranged or substituted (manipulated). Children who struggle with phonemic awareness should receive extra supports for these skills as early as possible.\nMost studies of word reading focus on accuracy, not speed. But speed can be a reading disability on its own. 10-15 percent of children with a reading disability appear to have accurate word recognition but are extremely slow in recognizing words and automatic recall of word spelling. This group has difficulties with the visual print structure of the language and regularly struggle with letter reversals such as b/d/p/q. These children are often unable to look at letters and quickly recognize what that letter (or letter group) is in order to pair a sound. Letter groups such as t, th, tch, or tion can frequently confuse children with an orthographic deficit. Once a child is able to recognize letters, the next challenge for these children is processing words quickly enough to complete the literacy process with speed and accuracy. The term dyslexic sometimes applies to this group as well.\nThese children have trouble developing automatic recognition of words by sight and tend to spell phonetically but not accurately. In spite of these weaknesses however, children with an orthographic deficit have relative strengths in phonological processing and phoneme awareness. The nature of a deficit in the speed of word recognition is still being debated by reading scientists. Some argue that the problem is primarily one of timing or processing speed, and others propose that there is a specific deficit within the orthographic processor that affects the storage and recall of exact letter sequences.\nAnother 10-15 percent of children with a reading disability are able to decode words better than they can comprehend the meaning of those words. One can distinguish these children from dyslexic readers because they can read words accurately and quickly and they can spell. This type of reading deficit is caused by disorders of social reasoning, abstract verbal reasoning, or language comprehension. Children who struggle with reading comprehension may have difficulty with word meanings, tying information together, making inferences and remembering what they have read. Deficits in comprehension often coincide with the phonological deficits and fluency, but specifically are found in children with social-linguistic disabilities (e.g., autism spectrum), vocabulary and/or working memory weaknesses, generalized language learning disorders, and learning difficulties that affect abstract reasoning and logical thinking.\nIt is extremely common for children with a reading disability to also experience related and coexisting disabilities including but not limited to:\n- faulty pencil grip and letter formation;\n- attention problems/ADHD;\n- task avoidance;\n- weak impulse control;\n- problems with comprehension of spoken language; and\n- confusion of mathematical signs and computation processes.\nRemember that early, intensive instruction in language and different aspects of reading is the best way to improve reading skills. The most appropriate treatment strategy depends on the needs of the individual. With early intervention, children with these disorders can overcome specific problems, learn to read, and improve fluency and comprehension with proper instruction.']"	['<urn:uuid:2d4db57b-d191-40a7-a98f-0bc206bb1dc1>', '<urn:uuid:f07be127-9095-4c4b-9859-e2c3c963a2fa>']	open-ended	with-premise	short-search-query	distant-from-document	multi-aspect	expert	2025-05-13T03:20:41.944655	6	97	2199
13	performance space types audience interaction comparison	Different types of performance spaces offer varying levels of audience interaction. Traditional theatrical spaces maintain a clear separation between performers and spectators, whether through formal elements like proscenium arches or informal gestures. In contrast, modern virtual reality installations can create hybrid spaces where audience members become integral parts of the experience. For example, in VR environments, visitors can interact through shared handrails and cast shadows into other visitors' immersive spaces, creating intimate moments between strangers. Traditional theater spaces can adapt to different venues while maintaining their theatrical conventions, while VR installations specifically design their spaces to break down barriers between participants and challenge the notion of private versus communal experience.	"['Bryn Mawr Classical Review 2004.07.61\nDavid Wiles, A Short History of Western Performance Space. Cambridge: Cambridge University Press, 2003. Pp. 316. ISBN 0-521-01274-0. $24.00 (pb).\nReviewed by Dana F. Sutton, The University of California at Irvine (email@example.com)\nWord count: 1244 words\nIn writing a book, one way to get in trouble is to have a change of mind in mid-course about what you are attempting to do, which is what seems to have happened in this case. David Wiles, Professor of Theatre at Royal Holloway, The University of London (henceforth W.), adopts a taxonomy of spaces divided into Sacred Space, Processional Space, Public Space, Sympotic Space, The Cosmic Cycle, The Cave, and The Empty Space, and, to judge by W.\'s introductory Chapter I, his focus is primarily on dramatic performance. Nothing in his ensuing chapter on Religious Space alters this impression. The first chapter creates expectations that we are dealing with a book of special interest to classicists because he has a fair amount of illuminating observations about Greek and Roman theaters (although it may be anticipated that few classicists will be convinced by what he writes about the physical alignment of the Theater of Pompey to the Temple of Venus on p. 37). Readers familiar with W.\'s important 1997 Tragedy in Athens: Performance Space and Theatrical Meaning will imagine we are going to be treated to further work along the same line, extended to subsequent Western dramatic traditions.\nBut when we turn to his third chapter, on Processional Space, we are in for a surprise, because he begins with the highly politicized parades in modern Northern Ireland, and goes on to write about such things as the procession along the Sacred Way at Delphi, the entry of Henry VII into York, the Medieval York Corpus Christi pageants, a 1615 Brussels procession honoring the Archduchess Isabella (memorialized in a painting by Denis Van Alsloot), the 17th century May Day processions at Wells and the more modern processions at Lewes. Suddenly the definition of ""performance"" has been drastically and inexplicably expanded to embrace a wide variety of activities which are, to be sure, performative in the sense that they involve performers and spectators, but which scarcely qualify as theater.\nFor true theater to occur, there must be a clearly understood demarcation between the dramatic space occupied by the actors and the everyday space occupied by the audience . This is equally true no matter what shape this fictive space may assume, whether the demarcation is achieved by something as formal as a proscenium arch or as informal as the sweep of an actor\'s hand. Several years ago I sat in an aisle seat during a performance of Twelfth Night where an actor stood in the aisle next to me delivering his lines: we were separated only by a few inches, and yet I had no difficulty in accepting the fact that the actor inhabited his kind of space, and I inhabited my own very different one.\nPhenomenologically speaking, dramatic space displays various kinds of behavior that everyday space does not. The most important of these is that, like the actors it encloses, it assumes fictive identities, and it also serves as a container for dramatic time, which takes on fictive identities of its own and can behave with unrealistic elasticity (by moving faster or slower than real time, by jumping forward or backward, and so forth). According to the artificial conventions of the theater, dramatic space can display more particular forms of non-natural behavior (for example, an audience may be required to believe that one actor cannot overhear another within the context of dramatic space, even if in everyday space one individual standing at the same distance could easily hear another speak).\nReal theater can only occur within the context of this dramatic space (and when similar conventions regarding time and performers\' identities are operative). With the conceivable exception of the York Corpus Christi performances (although some argumentation would be required to make this case), the kinds of activity involving performers and spectators that W. writes about in his Processional Space chapter and the remainder of his book, as well as a large number of varieties he does not consider (including such things as athletic competitions, courtroom trials, and public executions), can of course easily acquire what we might care to identify as a ""theatrical"" quality, but only metaphorically so. Surely it is important to differentiate theater from ""theater.""\nSo some important distinction-drawing seems in order and some fundamental questions need to be asked. The first is whether all the kinds of spaces in W.\'s taxonomy are really capable of accommodating dramatic space. This seems particularly questionable regarding Processional Space, in which some or more likely all of the activities he describes are at best pageants.\nAlso, W. never addresses the question of how tightly theatrical performances need to be tied to the particular kind of space in which they occur. Since theater can happen only if an audience accepts the premise that dramatic space can adopt fictive identities, it would seem that, to one degree or another, an audience is required to ignore the identity of the real-space context in which performance occurs. Also, the question arises whether the quality of a performance is appreciably altered as it occurs in different spatial contexts. There is considerable reason for doubting this is necessarily so. Because of the architecture of purpose-built theaters such as the Globe Theater, for example, W. discusses Shakespeare in his chapter on the Cosmic Circle. But Shakespeare\'s company, the King\'s Men also performed at Court, at the Inns of Court (one such performance is noted in his chapter on Sympotic Space, pp. 147ff.), and in such impromptu settings as the courtyards of inns when they toured the provinces. So even in the playwright\'s own lifetime Shakespearean drama, far from being tied to any one form of dramatic space, was characterized by considerable flexibility in being adapted to a variety of venues that were spatially organized in different ways.\nThese observations are all rather elementary. W. is a sophisticated enough theatrical historian that they must have occurred to him, and the reason he ignores them is most likely that in writing this study he had some other purpose in mind. At the point where he seems to radically redefine his notion of what constitutes ""performance,"" his book becomes impossible to review: when a reviewer is so unsure what this book is really about, he could all too easily (and maybe with justice) be accused of misunderstanding W.\'s intentions. One possibility, as suggested above, is that as W. wrote his conception of ""performance"" progressively expanded and the range of performative activities he chose to consider was enlarged proportionally. Another is suggested by a number of rather Neo-Marxist observations on ways in which different kinds of performance space are coordinated with different social structures, that his interest is in studying his sevenfold spatial taxonomy from the standpoint of audiences at least as much as that of performances. But, absent a clearer statement of purpose, it is impossible to grasp precisely why he adduces many of the examples he does or what exactly they are meant to illustrate, and so at this point I am obliged to break off.\nIf this is a perplexing book I do not mean to imply that a student of ancient drama can derive no profit from it. W. is an important enough theater historian that one cannot afford to neglect anything he chooses to publish. And it is worth concluding with the observation that he has the uncommon virtue of being able to discuss and employ modern critical theories without murdering the English language, for which we should be duly grateful.', 'Never Here, Always There is a deconstructed virtual reality environment: an immersive abstract space that examines the notion of virtual reality as a purely ‘private’ or disconnected space, instead inviting opportunities for intimate connections between strangers. Rather than using a traditional VR headset, visitors are invited into a room surrounded by projectors and are outfitted with wireless headphones and a translucent plastic mask that completely blocks their field of vision. The mask, which hovers several centimeters away from the face, becomes a 360° projection screen when illuminated by the surrounding projectors. Intense soundscapes in synchronicity with abstract line, color, and texture projections submerge the audience into a pure field of light and sound. Placed into individual rows separated by handrails, audience members can wander back and forth, exploring and interacting with the audiovisual experience. These shared handrails serve two purposes: to give each audience member their own space, but also to act as the gateway between the physical and virtual world, becoming the connective tissue within which audience members inevitably interact through the touching of hands. By deconstructing the apparatus of the VR headset into disparate elements, the work allows the visitor to enter the virtual space, physically. As such, each audience member becomes an integral part of the VR experience, casting shadows into other visitor’s immersive space, touching each other, and breaking the “fourth wall” of virtual reality. These jarring yet intimate moments between strangers breaks through the immersive, injecting communal experience into the ‘private’ virtual.\nNever Here, Always There has been presented as a work-in-progress, and accidental discoveries into the nature of immersion have led to the current proposal. Initially, audience members were invited to wander freely in a room full of projections, but I discovered people were hesitant to wander in an unfamiliar room while masked. Installing handrails quickly became an essential part of the work as the rails provided a sense of spatial security, which gave them confidence. Seemingly contradictory, a more solid grounding in the physical world allowed audiences to engage and immerse themselves more readily in the virtual world. In this proposed version of Never Here, Always There, I am interested in this grounding as not just a space of security, but as a space within which to explore the nature of security and the possibilities of physical connection within the virtual. By creating an almost womblike VR experience, but with these points of disruption, the work is able to question the ways in which we give trust and experience virtual reality.\nABOUT DORON SADJA\nDoron Sadja is an American artist and electronic musician whose work explores modes of perception and the experience of sound, light, and space. “Difficult, powerful, intense and delicate – all at the same time” Sadja stages epic performance works that immerse the audience into a futuristic landscape of pure sound and light. At times bordering on painful, at other times like bathing in a sea of lush harmonies, Sadja melds pristine electronic tones with romantic synthesizers and dark noise to construct hyper-emotive sonic architecture. Although each of Sadja’s works are striking in their singular and focused approach, his output is diverse: spanning everything from 250 speaker Wave Field Synthesis works to kinetic sound sculptures capable of moving sound and light in 3 dimensions, blindfolded light projection pieces, and large scale immersive sound and light environments.\nSadja has performed and exhibited throughout Europe and the US, including Atonal Festival and Hamburger Bahnhof in Berlin, PS1 MoMa Museum in NYC, Norberg Festival in Sweden, and the Institute for Electronic Music and Acoustics in Austria. Sadja has collaborated with Tony Conrad, Aki Onda, Audrey Chen, Nenad Popov, and Mario Diaz de Leon amongst others.']"	['<urn:uuid:2107b6af-b281-4a7f-9756-c9941dbdc637>', '<urn:uuid:505c4340-dad3-404b-9a53-1ebf883c5e4d>']	open-ended	direct	short-search-query	similar-to-document	multi-aspect	novice	2025-05-13T03:20:41.944655	6	110	1897
14	river restoration manual stream channel southwest wa compared to northwest forest plan northern spotted owl range which area covers larger region	The Northwest Forest Plan covers a larger geographical region, as it encompasses Oregon, Washington, and northern California (the entire range of the northern spotted owl). In contrast, the River Restoration Manual specifically focuses on waterways in Western Australia's south-west region.	"[""River Restoration Manual\nThis series of guidelines provides a guide to the nature, rehabilitation and long-term management of waterways in Western Australia. The chapters of the series collectively form the River Restoration Manual. The manual is based on the teachings of the successful river restoration courses, which have been run for river managers in the past (between 1996 and 2010).\nThese guidelines are intended to be used by river restoration group coordinators and other people who are actively involved with river restoration. For more general information on waterways management topics, the relevant Water notes are recommended.\nThe manual currently consists of 18 sections which can be downloaded individually (from links in right hand column) or the entire publication is available on disc from the Department of Water library.\nIntroduction - Provides an introduction to the contents of the Manual, how to use it and why. It also provides a brief account of the nature of the rivers of south-west WA, typical problems and the need for restoration.\nCatchment Processes - Stream and Catchment Hydrology - Describes and explains climate, the water cycle, how water Catchment Hydrology runs off a catchment and how we can measure this.\nStream Channel Processes\nFluvial Geomorphology - Discusses how the forces in flowing water shape a stream channel - how banks erode, how meanders form and the influences of the stream bed and its vegetation. Explains the basic physics and mathematics of water movement in a stream channel.\nRecognising Channel and Floodplain Forms - Describes local to sub-catchment scale channel and floodplain forms, identifies the factors that influence these forms, and comments on why forms change over time. It provides suggestions on how to recognise sedimentary forms in your river, any changes in form, and how to apply this knowledge to improve river health\nStream Channel and Floodplain Erosion - Discusses the connection between the power of flowing water, its natural tendency to follow a winding path, and some of the specific erosion features we see along our rivers. It covers bed, bank and floodplain erosion and explains the characteristics of bends in streams and how erosion plays a natural part in their development. Understanding erosion and sedimentation processes helps us manage rivers better.\nStream Channel Analysis\nStream Channel Analysis-- Discusses surveying, collection of data and assessment of river channels, calculation of flow velocity and discharge and stream power to understand the form of a stream channel and the force of the water that shapes it.\nStream Ecology - Provides an introduction to some of the important ecosystem processes that 'drive' the structure of stream communities and highlights some of the pressures that threaten stream ecosystems in WA.\nRevegetation of Riparian zones in south-west WA - Outlines the riparian zone and the process involved to revegetate it with native species. It gives a brief background of the general structure and importance of the riparian zone before moving onto site planning, weed control, species selection, plant establishment then finally monitoring and maintenance of the site.\nRevegetatoin case studies from south-west WA - The case studies outline the processes, management, cost and general success of previous revegetation projects.\nUsing rushland sedges in revegetation - Describes the common species of rushes, sedges, bulrushes and submergents of the south-west of WA, the aim of revegetation, revegetation techniques and weed control.\nStream Stabilisation - Outlines techniques to control the riverbed, stabilise channel alignment, protect stream banks and rebuild habitat. Provides guidelines on managing erosion and sedimentation problems and practical techniques to integrate channel stabilisation engineering and ecological restoration.\nPlanning and Management\nForeshore condition assessment in urban and semi-rural areas of south-west WA - Outlines a simple stream assessment method (modified from Pen and Scott 1995) for use in semi-rural and urban areas. It includes the assessment of instream habitat, foreshore vegetation, presence of dominant species (native plants and weed species), channel stability, areas suffering or prone to bank erosion and disturbance to the riparian zone as a result of the surrounding intensive landuse.\nForeshore condiiont assessment in farming areas of south-west WA - Outlines a simple stream assessment method (modified from Pen and Scott 1995) for use in farming areas of south-west Australia. The methodology looks at the overall foreshore health - and grades the foreshore at various stages from pristine with good vegetation to a ditch or drain with weed infestation or no vegetation.\nPlanning for waterways management: An overview - Provides an outline of the principles by which planning for waterways management should occur and is the background to more detailed documents.\nGuidelines for preparing a regional strategy for naturual resource management - Discusses regional planning, integrated catchment management, natural resource management, development of regional strategies, components of regional strategies and the incorporation of waterways management issues.\nGuidelines for preparing a Waterways Management Program/Catchment Plan - Recommends a planning process, content and structure for waterways planning documents that focus at the catchment scale. Principally aimed at Waterways Management Authorities developing Waterways Management Programs, but the approaches and structures that are recommended are equally relevant to the development of catchment management plans.\nGuidelines for preparing a River Action Plan - A guide to preparing a River Action Plan for community groups and people involved in on-ground river restoration activities. It assists the process of planning river restoration activities at the local level by outlining the major steps and actions required to develop a River Action Plan.\nDetermining foreshore reserves - Describes how to determine the extent of a foreshore reserve using biophysical criteria and the step by step process that will define and protect it. Also provides two case studies of the Hill River and the lower Collie and Brunswick Rivers."", 'Land and Resource Management Plan and Final Environmental Impact Statement Documents\nThe Shasta-Trinity National Forest’s guiding strategy is laid out in our Land and Resource Management Plan for the forest. Each national forest is required by law to develop a Forest Plan to integrate a mix of management activities that allow use and protection of forest resources, meet the needs of guiding legislation, and address local, regional, and national issues. In addition to the plan itself, each Forest is required to assess the environmental impacts of the plan. This assessment of environmental impacts is contained in an accompanying document, the Final Environmental Impact Statement. Access the complete text of these documents. [Select to access]\nNorthwest Forest Plan, 1994\nThe purpose of the Northwest Forest Plan (NWFP) is to adopt coordinated management direction for the lands administered by both the USDA Forest Service and the USDI Bureau of Land Management, within the range of the northern spotted owl, a bird listed as Threatened under the Endangered Species Act. The northern spotted owl inhabits Oregon, Washington, and northern California; all national forests and BLM units within this range are managed to meet Northwest Forest Plan direction. The management of these public lands must meet dual needs: the need for forest habitat and the need for forest products. The NWFP also dictated adoption of complementary approaches by other Federal agencies, such as the National Park Service, within the owl’s range. Access the NWFP fact sheet.\nApart from the conservation direction for the northern spotted owl, the NWFP also created other important conservation guidelines for aquatic systems and old-growth associated species. These are called:\nForest Wide Late Successional Reserve (LSR) Assessment - August 26, 1999\nThe Record of Decision on Management of Habitat for Late-Successional and Old-growth Forest Related Species Within the Range of the Northern Spotted Owl (ROD) established a network of Late Successional Reserves (LSRs), accompanied this by a set of management standards and guidelines. The network of reserves are intended to provide old-growth forest habitat, provide for populations of species that are associated with late-successional forests, and to help ensure that late-successional species diversity will be conserved. The management objective within LSRs is to protect and enhance conditions of late-successional forest ecosystems, which serve as habitat for late-successional and old-growth related species including the northern spotted owl (USDA, USDI 1994b). Protection includes reducing the risk of large-scale disturbance, including stand-replacing fire, insect and disease epidemic, and major human caused impacts. The purpose of this Forest-wide assessment is to develop management strategies for the LSRs, determine their sustainability, and provide information to decision makers for managing LSRs to meets Forest Plan goals and objectives.\nHayfork Adaptive Management Area Guide - 10-12-2004\nAppeals and Litigation Information\nShasta-Trinity National Forest managers make many resource management decisions, which may be subject to appeal (request to a higher authority for administrative review of a decision). [Select to Access]\nForest Level Management Indicator Assemblage Monitoring Report - February 22, 2011\nThis report provides decision makers on the Shasta-Trinity National Forest with a report of management indicator assemblage habitat status and trends at the National Forest scale. This report fulfills the Shasta-Trinity Land and Resource Management Plan monitoring requirements for management indicator assemblages, and contributes to fulfilling the National Forest Management Act requirement to provide for a diversity of plant and animal communities on National Forest land (National Forest Management Act of 1976, 16 U.S.C. 1600). This report will be updated every 3 to 5 years. [Access the Report]\nMonitoring and Evaluation Reports\nBest Management Practices Monitoring\nRedband Trout Conservation Agreement - 1998 Edition\nRoad Analysis Report\nThe Forest-level roads analysis (RAP) focused on the major roads or the ""backbone"" of the Forest transportation system. The roads analysis report documents the existing road system, risks and benefits evaluation of major Forest roads, and recommendations for future actions on these roads that will reduce risks of unacceptable environmental disturbance and increase the benefits provided by these roads.\nFour major findings came from the Forest-level roads analysis. They are:\nExisting major roads do not pose an unacceptable risk to the sustainability of ecosystems.\nThe highest risk ratings from existing major roads relate to water quality, hydrologic process, and the aquatic or riparian ecosystems.\nThe highest need is to replace and, in some cases, increase the size of culverts and other road-related drainage structures.\nThe highest potential economic benefit to local communities is gained from use of major roads for commodity production from public and private lands within the Forest boundary.\nThis Forest Scale Roads Analysis Report, completed in 2002, provides an analysis of the major network forest roads, a risk/ benefit anlaysis, and priorities for future road management activities.\nWatershed Analysis\\Assessment Reports']"	['<urn:uuid:065b21a1-0855-4565-8a2e-c772099221a5>', '<urn:uuid:23224131-f049-44b6-8a03-c7bd76240d94>']	factoid	with-premise	long-search-query	similar-to-document	comparison	expert	2025-05-13T03:20:41.944655	21	40	1724
15	What were the desired ranges and altitudes for the Nike missile?	The Nike missile was required to operate effectively at altitudes up to 60,000 feet and at ranges of 50,000 yards.	"['Nike Missile Development Overview\nThe first-generation Nike missile, the Aiax. was designed to intercept and destroy Soviet manned bombers. In the event that the Cold War turned hot, Nike missiles could provide the lash line of defense for the Nation\'s population and industrial centers. Although the U.S. Army did not build the first Nike missile batteries until 1953, research and development of the defensive antiaircraft weapon systems began during World War II.\nAs the United States entered World War II, its antiaircraft arsenal included .50 caliber machine guns, 37mm guns, 40mm ""Bofors"" guns, fured and mobile 3"" guns. and 90mm guns. The 9Omm gun was the major heavy antiaircraft weapon used by the United States during the war years. In 1938. the United States initiated development of an integrated antiaircraft defense system. That investment resulted in the development of the 90mm gun, standardized in February 1940. Using the M-9 director radar system. the 90mm gun could hit aircraft flying at 30,000 feet, and the combination of the 90mm gun and M-9 radar proved successful in World War II against the German V-1 rockets. The War Department also developed a 120mm antiaircraft gun, but its large size limited mobility.\nBy the close of the war, advances in air warfare made it plain that even the latest anti aircraft weapons were not capable of countering future air threats. Guided missiles capable of striking high-flying aircraft were necessary. The B-29 atomic bombing mission of Hiroshima and Nagasaki in August 1945 vividly demonstrated the destructive power of high-altitude heavy aircraft. As World War II drew to a close, America\'s military planners began planning for air defense systems that could counter these new offensive weapons. In response to potential threats from the air, the Army began developing two separate, but related, pieces of equipment: the M-33 integrated fire control system and what would become the Nike missile.\nIn 1944, the U.S. Army contracted with Bell Telephone Laboratories to develop a fully integrated radar/computer antiaircraft fire control system. The result was the M-33 system. Earlier systems, such as the M-9, while successful, were a collection of individual equipment elements from various sources that were organized into working units by the military. The M-33 system. however, offered a complete radar computer system. This system, which would later operate with the Nike Ajax missile, provided the basis for a significantly improved fire control system.\nOn August 17,1944, Army Lieutenant Jacob W. Schaefer submitted a memorandum proposing a new antiaircraft weapon system. The heart of this proposed system was a rocket guided from the ground that would work in conjunction with two radars linked to a computer. One radar would track incoming enemy aircraft, transmitting current location points to the computer. The computer would then calculate future target positions and be able to relay to the missile, through the other radar, any course corrections needed to intercept the enemy aircraft. The Army sent copies of Lieutenant Schaefer\'s technical proposal to Radio Corporation of America (RCA) and Bell Telephone Laboratories (BTL) for their consideration.\nIn May 1945. Bell Laboratories presented a verbal report to the Army on ""Project Nike"" (named after the winged goddess of victory in Greek mythology). A written report, ""A Study of an Antiaircraft Guided Missile System,\' was released the following July. The report, which was the work of a group of Bell Laboratories scientists and engineers that included W.A. McNair, H.W. Bode, G.N. Thayer, J.W. Tukey, and B.D. Holbrook, stressed swift deployment of a weapon system that could combat high-speed, high-altitude bombers. The engineers recommended a weapon that was derived, to every extent possible, from existing technology. In order to save time and money, the engineers also recommended that the missile be as simple as possible. Bell Laboratories\' engineers also urged that the more expensive and complex equipment, such as the radar system, remain on the ground where it could be re-used and have the benefit of routine maintenance.\nThe Bell Laboratories\' report recommended that Project Nike be comprised of a supersonic rocket missile vertically launched under the thrust of a solid-fuel booster, which would drop on completion of its function. The launched missile would be propelled by a liquid-fuel motor. and guided to a predicted ""intercept point."" The commands for missile detonation would he controlled from the ground - and transmitted by radio signals from a ground-based computer and radar system that would track both the target and the missile in flight.\nA few months later. the Antiaircraft Artillery Board published a report that listed more specific, desired characteristics of the proposed Nike missile. The board wanted a missile that had: 1) the ability to operate effectively in high altitudes up to 60,000 feet and at ranges of 50,000 yards; 2) the ability to destroy large bombardment-type aircraft when detonated within 60 feet of the airplane; 3) a self-destruction feature; 4) the highest degree of security against interference or enemy electronic countermeasures; 5) the ability to be transported by motor vehicle; and 6) an assembly period of no more than three hours.\nIn June 1945, the Rocket Branch of the Army Ordnance Corps (co-sponsored by a division of the Army and the Air Force) assumed full responsibility for Project Nike, and named Western Electric and Bell Laboratories as the prime contractors for development of the radar system. As designed by Bell Laboratories and Western Electric, the missile command and control radar system incorporated characteristics of the M-33 antiaircraft fire control system, saving both time and money on research ad development, production. logistics, and personnel training. The Army selected Douglas Aircraft Company (later the McDonnell Douglas Astronautics Corporation) as the major contractor, for the design of the missile, booster, and launcher. In turn, Douglas Aircraft contracted with the Aerojet Engineering Corporation to design the liquid-fuel rocket motor and solid-fuel booster rockets. Following the start of the Korean War in 1950, the Department of Defense asked the contractors to produce a working version of the Nike system as soon as possible. This first missile was the Nike Ajax.']"	['<urn:uuid:f802ca20-f870-4c14-9bbd-9bafc5601b63>']	factoid	with-premise	concise-and-natural	similar-to-document	single-doc	expert	2025-05-13T03:20:41.944655	11	20	1001
16	looking for info about diversity in society what are the three main levels where it happens	Diversification in society occurs on three levels: 1) At the societal level, there is a multitude of cultural/social groups, 2) At the group level, there is intersectionality of individual belongings, and 3) At the individual level, there is mobility of individuals' minds between different references of identification.	['What Happens When a Society is Diverse?\nExploring Multidimensional Identities\nSicakkan, Hakan G.\nLithman, Yngve G.\nWith its interdisciplinary and multi-paradigmatic approach, this book aims to bring our thinking about diversity one step further towards making coexistence and politics in diverse societies possible. Diversification in our societies takes place on at least three levels. On the societal level, one can speak of a multitude of cultural/social groups. On the group level, the multitude and intersectionality of individual belongings comes to the fore. On the individual level, the mobility of individuals’ minds between different references of identification becomes a crucial element in theorizing the diverse society. What happens in society, politics, and communicative public spaces when the society is diverse in these terms?\nMuch of the recent intellectual and policy work has not been able to comply with societies that are increasingly diverse and groups/individuals whose relations with political institutions are becoming more complex than ever. By focusing on social groups and individuals with multidimensional and shifting identities, which are structured along the intersections of gender, sexuality, ethnicity, religion, ideology, physical disability, generation, mobility and migrancy, this volume aims to increase the understanding of the complex relations in diverse societies between humans, social groups, and political institutions. The different chapters of the book bring into focus an array of experiences with diversity and, taken together, they contribute to an understanding of the complex realities of living in diversity.\nTo provide a solid interdisciplinary basis for theorizing diversity, the book brings together the conceptual and methodological tools of political theory, social theory, history, political science, sociology and social anthropology. In this book, scholars with unique competencies share their knowledge on the topic and provide novel angles for thinking about coexistence and politics in diverse societies.\n“At first glance, one might think that the interdisciplinarity of the scholars in this volume would be too diverse a mix to yield benefits, despite their scholarly interest in topics related with identity and diversity. However, when finishing reading this volume, the productive results are obvious, as researchers from diverse sets of orientation are brought together in an organized way towards a common goal. While each chapter is a ‘stand-alone’ contribution to the literature, the breadth and depth of the topics covered demonstrates both the opportunities and challenges that lie ahead as we attempt to gain a better understanding of diversity in contemporary society, and how multidisciplinary approaches can yield synergistic effects. The result in this book is a capturing robustness of the debate surrounding diversity and state practices.” – (from the Commendatory Preface) Professor James S. Frideres, University of Calgary, Canada\n“The resurgence of immigration in the late 20th century and the political emergence of gender groups, gays, indigenous groups and people with disabilities have posed serious questions about who belongs where. For example, is it necessary that a migrant or gay in the 21st century conform to a prior collective identity to belong? Or can political action by a disenfranchised minority help shape the nation states identity? ... Academics, students and policy makers now can inform themselves about the roles of identity politics, the politics of identity and modes of belonging by reading a series of cogently written essays in this volume which reach across the 19th to the 21st century in both European and North American contexts.” – Professor Don J. DeVoretz, Simon Fraser University, Canada\n“This is a well-edited and timely collection, addressing political, social and cultural problems in today’s world that are of primary significance both to individuals, groups and political regimes: problems pertaining to how and why people identify, construct their belongings (or have them constructed for them), take advantage of their citizenship status, are marginalized or recognized, and, not least, try to deal with the constraints politically imposed on their frequently multiple and variable senses of belonging by shaping new, composite and boundary-transgressing identities for themselves ... This book helps both political actors, individuals concerned with perceived disjunctures between citizenship and belonging, and scholars in a variety of disciplinary fields to think differently, more imaginatively about these core issues – and hopefully to develop a more sophisticated semantics for coping with them, practically and theoretically.”– Professor Ulf Hedetoft, Aalborg University, Denmark\nTable of Contents\nList of Figures and Tables\n1. Introduction: Diversity and Multidimensional Identities – Yngve G. Lithman and Hakan G. Sicakkan\n2. Identity and Sociology – Hildur Ve\n3. Ethnic Entrepreneurs: Identity Politics Among Pakistani Students in Norway – Mette Andersson\n4. Beyond “Man”: In Defense of Multidimensional Identities – Randi Gressgård and Christine Jacobsen\n5. Deaf Identities: Visible Culture, Hidden Dilemmas and Scattered Belonging – Jan Kåre Breivik\n6. Glocal Spaces as Prototypes of a Future Diverse Society: An Exploratory Study in Six European Countries – Hakan G. Sicakkan\n7. McJihad: Globalization, Radical Transnationalism, and Terrorism of the Diaspora – Yngve Georg Lithman\n8. The Struggle for Recognition – A Conceptual Framework – John Erik Fossum\nISBN10: 0-7734-5877-8 ISBN13: 978-0-7734-5877-2\nhors série Number: 0\nSubject Areas: Cultural Studies,\nEthnic and Immigrant Studies,\nSociology & Social Sciences,\nImprint: Edwin Mellen Press\nUSA List Price: $139.95 UK List Price: £ 94.95\nDiscounts: Discounts are available. Please\nRegister, or if you have already registered, Sign In, to view your personalized prices.']	['<urn:uuid:6296f5c4-7d77-4db7-8f50-8a5b05f73479>']	factoid	with-premise	long-search-query	distant-from-document	single-doc	novice	2025-05-13T03:20:41.944655	16	47	871
17	How do Neanderthals and mammoths relate to DNA preservation?	Both Neanderthals and mammoths have provided important ancient DNA samples, though with different preservation challenges. Mammoth DNA has been recovered from 20,000-year-old remains preserved in tundra, allowing scientists to consider de-extinction possibilities. For Neanderthals, DNA analysis has been particularly challenging because their DNA degrades over time and can be contaminated by modern human DNA. Scientists have managed to sequence both mitochondrial and nuclear DNA from 38,000-year-old Neanderthal specimens, though all DNA typically becomes destroyed within 100,000 years after death.	"['A B C D E F G H I J K L M N O P Q R S T U V W X Y Z\nBring Back Extinct Animals! Sort of.\nResurrect extinct mammals? You bet, says Beth Shapiro, an expert in ancient DNA and a biologist at the University of California, Santa Cruz. Mostly.\nHow long before de-extinction is a reality?\nThe answer depends on what you\'re willing to accept as ""de-extinction."" If you mean a pigeon born with some passenger pigeon traits, or an elephant born with mammoth-like traits, it could happen within a few years to a decade. Longer for mammoths, for the reasons Iíve already mentioned and because elephants have a two-year gestation period. If you mean 100-percent mammoth, with all mammoth genes and behaviors, that will never happen...\nBecause there are so many steps along the way to de-extinction, there is no particular species that is an ideal candidate for being brought back to life. The best choice would be an animal that could not only inspire people to be interested in science and technology but that also would have a net positive impact on the environment. In my mind, the mammoth is a great choice for both of these reasons.\nProblematically, mammoth de-extinction would necessarily involve working with and manipulating female elephants. We would need elephant eggs, elephant maternal hosts and elephant surrogate families to raise the unextinct mammoths before releasing them into the wild. Before mammoth de-extinction proceeds beyond the first stages of sequencing and manipulating genomes, we need to know much more about how to perform these later steps in ways that are not harmful to elephants.\nScience fiction author David Brin thought about this, and let us look over his shoulder in Earth, his 1990 novel full of interesting ideas and inventions:\nBaby\'s brow fur was long and oily, and gave off a pungent, tangy, yet somehow pleasant odor. The worldwide network of genetic arks had a surfeit of pachyderms, even this new breed - ""Mammontelephas"" - with half of its genes salvaged from a 20,000-year-old cadaver exposed by the retreating Canadian tundra.\n(Read about David Brin\'s Mammontelephas)\nPretty fun article with lots of good quotes at SmithsonianMag.\nScroll down for more stories in the same category. (Story submitted 4/3/2020)\nFollow this kind of news @Technovelgy.\n| Email | RSS | Blog It | Stumble | del.icio.us | Digg | Reddit |\nyou like to contribute a story tip?\nGet the URL of the story, and the related sf author, and add\nComment/Join discussion ( 0 )\nRelated News Stories -\nBaubotanik - Construction Botany - Builds Bridges\n\'A dwelling must be all of a unitóthe walls, the drainage, the decor grown in!\' - Jack Vance, 1954.\nMice Gestate In Mechanical Womb\n\'... in the Decanting Room, the newly-unbottled babes uttered their first yell of horror and amazement.\' - Aldous Huxley, 1932.\nWorlds With Underground Oceans More Conducive To Life\n\'There is life on Europa.\' - Arthur C. Clarke, 1982.\nMonkey Gets A Bigger Brain, Thanks To Human Gene\n\'It\'s a madhouse! a madhouse!\' - Planet of the Apes, 1968.\nTechnovelgy (that\'s tech-novel-gee!)\nis devoted to the creative science inventions and ideas of sf authors. Look for\nthe Invention Category that interests\nyou, the Glossary, the Invention\nTimeline, or see what\'s New.\nLonestar Offers Lunar Storage For Ultimate In Security\n\'Scarif, the off-site backup of all the secret knowledge of the Empire\nEnvisioning Starship Earth Travel - In 1930 By Max Valier\n\'Why must we travel ever faster in a seemingly insatiable desire to conquer space and time?\'\nMan\'s Marriage To Hologram Ruined By Software Glitch\nTill \'NETWORK ERROR\' do us part.\nCarbon Robotics: War Of The Worlds As A Metaphor For Weed Control\n\'It was as if some invisible jet impinged upon them and flashed into white flame.\'\nPathways Language Model (PaLM) Is No Joke\n\'Electronic differentiation of the grotesque, as it says in the specifications - in man, a sense of humor.\'\nMOOSE: Man Out Of Space Easiest or Manned Orbital Operations Safety Equipment\n\'And as the ball bulleted downward on a screaming slant, it shrank!\'\nLiquid Lenses Adjust Automatically, Not Quite Dune Binoculars\n\'Hufhuf oil held in static tension... within a viewing tube...\'\nYour Martian Dream Home, Made By Fungi\n\'... it was the cheapest building material known.\'\nThe Dune Ornithopter, Movie And Book\n\'The wings were at full spread-rest, their delicate metal interleavings extended.\'\n100X Improvement In DNA Information Storage\n\'A record that wouldn\'t get lost and couldn\'t be destroyed.\'\nNASA \'Holoports\' Doctor Onto Space Station\nStar Trek Voyager Emergency Medical Hologram\nShould We Train AIs To Imagine A Future Of Horrific Disasters\n\'LET ME TELL YOU HOW MUCH I\'VE COME TO HATE YOU SINCE I BEGAN TO LIVE.\'\nMouth Haptics Invented By Frederik Pohl In 1965, CMU Now Has Prototype\n\'What he got was indeed a kiss. It was disconcerting. No kissing lips were visible.\'\nTwo Towns Linked By Sculpture Portal In Real Time\n\'I am the Guardian of Forever.\'\n3D Printed Robotic Tentacles\n\'... articulate ropes of steel dangling\'\nUpdate: Musk Doubles Down On Optimus Prime Humanoid Robot\n\'I shall introduce myself. I am R. Daneel Olivaw... I am a robot. Were you not told?\'\nMore SF in the News Stories\nMore Beyond Technovelgy science news stories', ""- Human Evolution Research\n- Climate and Human Evolution\n- Asian Research Projects\n- East African Research Projects\n- Human Origins Program Team\n- What's Hot In Human Origins?\n- Fossil Forensics: Interactive\n- E. A. Mammal Dentition Database\n- Human Evolution Evidence\n- 3D Collection\n- Human Fossils\n- Human Family Tree\n- Timeline Interactive\n- Human Characteristics\n- About Us\nSequencing Neanderthal DNA\nChallenges in Extracting Ancient DNA\nWorking with ancient DNA is very challenging, both in terms of finding sufficient material to work with after decomposition has occurred, and in terms of eliminating modern human contamination. Distinguishing between modern human and ancient genetic material is particularly difficult when the ancient DNA comes from close relatives of modern humans.\nOrganisms decompose after death. Water, oxygen and microbes break down DNA. Within 100,000 years, all DNA is destroyed. Ancient DNA tends to be found in small quantities. The DNA that is extracted is generally fragmentary and damaged. Some damage results in changes to the DNA sequence. Cytosine can change to uracil, which is read by copying enzymes as thymine, resulting in a C to T transition. Changes from G to A also occur. DNA errors are very common at the ends of molecules.\nContamination by modern DNA is a particularly difficult problem to solve. Labs and chemicals may be contaminated by the DNA of the people working in them, while many fossils have been handled by researchers for years. Contamination is difficult to detect because Neanderthals and humans share much of their genetic material, making some DNA sequences indistinguishable. Researchers have developed ways to analyze the results of ancient DNA sequencing efforts to determine whether contamination is likely and how much has occurred. Analysis of the results and efforts to keep labs and specimens free of modern DNA is very important as some researchers believe that the early studies of Neanderthal DNA included modern contaminants.\nSequencing the Complete Neanderthal Mitochondrial Genome\nAfter successfully sequencing large amounts of DNA and devising strategies to deal with potential contamination, a team led by Svante Pääbo from the Max Planck Institute, reported the first complete mtDNA sequence for a Neanderthal (Green et al. 2008). The 0.3 gram sample was taken from a 38,000 year old Neanderthal from Vindija Cave, Croatia. Complete Neanderthal mtDNA sequences give researchers more information about the relationship between modern humans and Neanderthals, as well as information about Neanderthal population size.\nThe complete mtDNA sequence shows that Neanderthals were outside the range of modern human mtDNA variation. Researchers compared the mtDNA sequence with that of modern humans. They compared sequence changes that resulted in nonsynonymous amino acid changes with synonymous changes. They found a larger number of nonsynonymous changes in the Neanderthal lineage, possibly implying that Neanderthals had a small population size with weaker purifying selection (Green et al. 2008).\nLater, Svante Pääbo’s lab sequenced the entire mitochondrial genome of five Neanderthals (Briggs et al. 2009). Sequences came from two individuals from the Neander Valley in Germany, Mezmaiskaya Cave in Russia, El Sidrón Cave in Spain and Vindija Cave in Croatia. Though the Neanderthal sample comes from a wide geographic area, the Neanderthal mtDNA sequences were not particularly genetically diverse. The most divergent Neanderthal sequence came from the Mezmaiskaya Cave Neanderthal from Russia, which the oldest and eastern-most specimen. To look at whether age or geographic location contributed to genetic differences, the team sequenced part of the DNA of another Mezmaiskaya Cave Neanderthal that dated to 41,000 years ago. This more recent specimen grouped with the other Neanderthals, possibly showing that age was the cause of the sequence differences (Briggs et al. 2009). Other studies show the existence of eastern, western and southern groups of Neanderthals (Fabre et al. 2009).\nOn average, Neanderthal mtDNA genomes differ from each other by 20.4 bases and are only 1/3 as diverse as modern humans (Briggs et al. 2009). The low diversity might signal a small population size, possibly due to the incursions of modern humans into their range (Briggs et al. 2009).\nSequencing the Neanderthal Nuclear Genome\nRecently, there have been efforts to sequence Neanderthal nuclear genes. Two studies, one by Svante Pääbo’s team and one by Edward Rubin, have sequenced large amount of Neanderthal nuclear DNA using different methods. Their results were announced in 2006. Given their success in sequencing some nuclear DNA, both labs launched projects to sequence the entire Neanderthal genome. Nuclear genomic sequences from Neanderthals show differences between modern humans and Neanderthals, and illustrate aspects of Neanderthal biology.\nOne Million Base Pairs of the Neanderthal Sequence\nSvante Pääbo’s team from the Max Planck Institute for Evolutionary Anthropology in Germany announced the sequencing of one million base pairs of nuclear DNA of a Neanderthal specimen in 2006 (Green et al. 2006). After a long search for specimens with a sufficient amount of undamaged DNA to sequence and for the ones with the least evidence of contamination, they focused on Vindija 80, a Neanderthal discovered in Croatia in 1980 that is approximately 38,000 years old.\nThey estimated that 7.9% of the changes in human DNA compared with that of the chimpanzee occurred after the split with Neanderthals. They dated the split between the ancestors of modern humans and Neanderthals to 465,000 to 569,000 years ago. They also found that the effective population size of the Neanderthals was small. Their success in sequencing this amount of DNA indicated that a large-scale project to sequence the Neanderthal genome is possible.\nRubin's Neanderthal Nuclear DNA\nEdward Rubin’s team from the Lawrence Berkeley National Laboratory in California also sequenced Neanderthal nuclear DNA (Noonan et al. 2006). They sequenced about 65,000 base pairs from the 38,000 year old Vindija, Croatia specimen. The technique used here produces a copy of the Neanderthal sequence that can be retained forever, reducing the need for repeated destructive sampling. The DNA is then cloned in bacteria.\nThe average split time between the Neanderthal and modern human populations was around 370,000 years ago. They used the sequence to look at the possibility of interbreeding between Neanderthals and moderns. Admixture would be seen as derived alleles that are found in Neanderthals and in low frequencies among modern humans. They did not detect this in their sample. A simulation to test the Neanderthal contribution to the human genome found a 0% chance of Neanderthal input with a 0% to 20% confidence range. With this data, the authors cannot definitively rule out admixture (Noonan et al. 2006).\nSome aspects of the two sets of nuclear DNA do not fit together, possibly because of contamination and sequencing errors, especially in the Green et al. (2006) study (Wall and Kim 2007). This has led the researchers to develop new methods of detecting and preventing contamination to ensure that only ancient DNA is being sequenced.\nA Draft Sequence of the Neanderthal Genome\nIn 2010, Svante Pääbo’s lab announced a draft sequence of the Neanderthal genome (Green et al. 2010). This new study has produced evidence consistent with interbreeding between Neanderthals and anatomically modern Homo sapiens and points to aspects of the human genome that may have changed since the split between humans and Neanderthals.\nDNA was extracted from three Neanderthal bones from Vindija Cave, Croatia. By comparing sequences from their mtDNA and their nuclear DNA, scientists determined that the three bones came from different individuals, although two of them might be related on their mother’s side. The researchers used several methods to ensure that the DNA they were sequencing was derived from the Neanderthal specimens rather than from contamination by modern humans in the lab.\nThe Neanderthal sequence was compared to those of five modern humans from France, China, Papua New Guinea, as well as Africans from the San and Yoruba groups. Tests indicated that Neanderthals shared more derived alleles with non-African modern humans than with African modern humans. They compared parts of the Neanderthal genome with pairs of modern humans. While the European and Asian pairs had similar amounts of derived material compared with the Neanderthal, Neanderthals had more similarities with non-African humans than with Africans. The simplest explanation for these results is gene flow from Neanderthals into modern humans. Gene flow could also have occurred from modern humans into Neanderthals. Interbreeding events between Neanderthals and modern humans might be obscured if the modern human population was large.\nNeanderthals have contributed approximately 1% to 4% to the genomes of non-African modern humans. This evidence of interbreeding sheds light on how we think of the expansion of modern humans out of Africa. It refutes the strictest scenario in which anatomically modern humans replaced archaic hominins completely without any interbreeding. However, even with some interbreeding between moderns and archaic hominins, most of our genome still derives from Africa.\nThe data also points to the time when interbreeding might have taken place. Since the Neanderthal DNA was equally related to that of the modern samples from France, China and Papua New Guinea, admixture between moderns and Neanderthals must have occurred before the Eurasian populations split off from each other. Remains of both modern humans and Neanderthals dating to around 100,000 years ago have been found in the Middle East. A few interbreeding events during this period could have produced the results found in this study.\nThe sequence of our close hominin relative also shows us how humans are unique. Researchers found 78 sequence differences that would have affected proteins in which Neanderthals had the ancestral state and modern humans had a newer, derived state. Five genes had more than one sequence change that affected the protein structure. These proteins include SPAG17, which is involved in the movement of sperm, PCD16, which may be involved in wound healing, TTF1, which is involved in ribosomal gene transcription, and RPTN, which is found in the skin, hair and sweat glands. Scientists do not know the function of the CAN15 protein, which was also one of the differences. Other changes may affect regulatory regions in the human sequence. Some changes are in regions that code for microRNA molecules that regulate protein manufacture.\nThe comparison also pointed out regions that might have been under positive selection in modern humans. Though some of the genomic areas that may have been positively selected for in modern humans may have coded for structural or regulatory regions, others may have been associated with energy metabolism, cognitive development and the morphology of the head and upper body.""]"	['<urn:uuid:06f82c22-0430-485e-8c51-302834db51bd>', '<urn:uuid:8078d8a5-0700-4b28-bdd5-663c2c173c71>']	open-ended	direct	concise-and-natural	similar-to-document	multi-aspect	novice	2025-05-13T03:20:41.944655	9	79	2610
18	what causes impact decline duck numbers north american boreal forest	In Canada's western boreal forest, several factors are impacting waterfowl populations. The region is experiencing rapid development and fragmentation due to resource exploitation, including timber harvesting, natural resource extraction, road construction across wetlands, and water diversion for industrial use. Additionally, climate change is affecting the region's ecology - for instance, melting permafrost has led to significant wetland losses. The combination of industrial activity and climate change may be particularly harmful, as removal of forest cover can accelerate permafrost melting. These habitat changes can result in fewer waterfowl settling in affected areas, and those that do may experience lower survival or reproduction rates.	"['Waterfowl in a Changing Land\nIn the early days of waterfowl management, the boreal forest remained largely a pristine wilderness with little need for active conservation\n. This is no longer true in many areas. The boreal forest has rich natural resources—oil, natural gas, timber, minerals, rivers that can generate hydropower, and in the south arable land—and these resources are now being exploited at a rapid rate. In Canada, portions of the western boreal forest are being developed or fragmented at a pace that far exceeds land-conversion rates in some Third World countries. Trees are being harvested for timber and pulp, and land is being cleared for the extraction of a variety of natural resources. Roads are being built across wetlands, which can also impact downstream habitats. And water is being diverted and pumped from lakes, rivers, and aquifers for industrial use. Between 1966 and 1994, agriculture in parts of the southern boreal forest expanded three times faster than the global rate. Development has now impacted more than 87 million acres—an area equal in size to the state of New Mexico—in the Canadian western boreal forest alone.\n""Twenty-five years ago, the boreal forest was barely on maps of important waterfowl areas in North America—just a few scattered sites. That\'s changed,"" says Jeff Nelson, CEO of Ducks Unlimited Canada\n. ""It\'s not that the number of ducks here has grown dramatically over that time; we\'ve just come to better recognize the continental significance of this area and the growing threats there to duck habitat\nPopulation trends among waterfowl species vary substantially across the boreal region. In Canada\'s western boreal forest, populations of scaup, mallards, American wigeon, and scoters have recently declined below North American Waterfowl Management Plan (NAWMP)\ngoals. In Alaska, however, populations of these same birds are near or above NAWMP objectives. The reasons for this variation are largely unknown, but landscape changes may be contributing factors.\nWhile forests can regenerate over time with sound management, the current scale and rate of cumulative landscape change in the boreal forest may reduce the region\'s ability to sustain historical waterfowl populations. Climate change also threatens the boreal forest\'s fragile ecology. Recent studies suggest that in parts of Alaska melting permafrost has resulted in wetland losses of 30 percent. The combined effects of climate change and industrial activity are not fully known, but some evidence suggests that the removal of forest cover accelerates the melting of permafrost, which could result in increased wetland losses. The implications of ongoing habitat loss and degradation are that fewer waterfowl may settle in impacted areas, and those that do settle in these areas will experience lower survival or productivity.\nSustainable Land Use in the Boreal Forest With industrial development occurring on millions of acres in Canada\'s boreal forest, Ducks Unlimited and its partners are actively working to foster public land-use policies and industrial practices that conserve waterfowl habitat. Specifically, DU and its partners are working to accomplish the following goals:\n- Convince key audiences that conserving waterfowl habitat in the boreal forest is important.\n- Invest in science to better understand the potential impact of industrial activities on wetlands and waterfowl.\n- Partner with forward-thinking companies that wish to include habitat conservation in their sustainable development initiatives.\n- Demonstrate how habitat conservation can help companies achieve their business objectives.\n- Guide development of industrial practices that conserve waterfowl habitat.']"	['<urn:uuid:1c2ca47e-ef0e-4ec0-a4e6-429aec8443e1>']	open-ended	with-premise	long-search-query	distant-from-document	single-doc	novice	2025-05-13T03:20:41.944655	10	102	562
19	What defines Appreciative Inquiry's approach to change, and how is it applied in forest conservation?	Appreciative Inquiry is a collaborative process that focuses on discovering the best of 'what is' to pursue possibilities of 'what could be,' rather than problem-solving. It searches for strengths and life-giving forces within systems. In forest conservation, it's specifically used by the Silva Forest Foundation to help communities develop positive, practical visions for relating to Earth and each other, creating ecosystem-based conservation plans by building on what works well rather than fixing what's wrong.	['Compiled by Kendy Rossi\n· A strategy for intentional change that identifies the best of “what is” to pursue dreams and possibilities of “what could be”; a cooperative search for the strengths, passions and life-giving forces that are found within every system and that hold potential for inspired, positive change.\n· A process of collaborative inquiry, based on interviews and affirmative questioning, that collects and celebrates “good news stories” of a community; these stories serve to enhance cultural identity, spirit and vision.\n· A way of seeing which is selectively attentive to — and affirming of — the best and highest qualities in a system, a situation, or another human being;\nan appreciation for the “mystery of being” and a “reverence for life.”\n(phrases from Cooperrider and Srivastva, 1987)\n· Mission Statement/Vision Development\n· Strategic Planning\n· Organizational/System Redesign\n· Process & Service Enhancement\n· Improvement Initiatives\n· Group Culture Change\n· Civic/Community Development\n· Umbrella for Multiple Change Initiatives in a System\nConditions for Use\nIdentified need or desire for:\n– Heart-felt inquiry, discovery & renewal\n– Positive, grass-roots revolution\nSystems & situations in which there is (are):\n– Support for full voice participation at all levels\n– Commitment to change as an ongoing process, not a one-time event\n– Leadership belief in the positive core and affirmative process as a viable change driver\n– Structures/resources to encourage sharing of “good news stories”\nand to support creative action\nSituations in which:\n– Predictable, linear process & outcomes are required\n– Problem-identification/problem-solving is the preferred method for change\n– There is lack of support for passionate dreaming & inspired self-initiative\n· Change in basic orientation from problem-focused to possibility-focused\n· Clarified or enhanced sense of identity, shared values & culture\n· Established climate of continual learning & inquiry\n· Renewal of group energy, hope, motivation & commitment\n· Increase in curiosity, wonder and “reverence for life”\n· Whole system changes in culture & language (increase in cooperative practices & decrease in competition; increased ratio of positive: negative comments; increase in affirmative questions and/or narrative-rich communication)\n· Improved working relations/conflict resolution\n· Decrease in hierarchical decision-making; increase in egalitarian practices & self-initiated action\n· Successful achievement of intents listed above (see “Potential Uses”);\nKey Principles & Assumptions\nFour Guiding Principles:\n1. Every system works to some degree; seek out the positive, life-giving forces and appreciate the “best of what is.”\n2. Knowledge generated by the inquiry should be applicable; look at what is possible & relevant.\n3. Systems are capable of becoming more than they are, and they can learn how to guide their own evolution — so consider provocative challenges & bold dreams of “what might be.”\n4. The process & outcome of the inquiry are interrelated and inseparable, so make the process a collaborative one.\nAbout Reality. . .\n· We co-create reality through our language, thoughts, images and beliefs\n· The act of asking a question influences the system’s reality in some way\n(i.e. questions are a form of intervention).\n· The types of questions we ask determine the types of answers we receive; and “the seeds of change are implicit in the very first questions we ask.”\n· We manifest what we focus on, and we “grow toward what we persistently ask questions about.” (both quotes from Cooperrider & Whitney, 1999)\nKey Principles & Assumptions, cont.\nAbout Problem-Solving. . .\n· AI is distinctly different from problem-solving: AI focuses on a desired future or outcome, built on strengths/passions of the past and present.\n· Problem-solving attempts to analyze deficits, identify root causes, then fix problems or correct errors; because it searches for problems, it finds them.\n· AI doesn’t ignore problems — it recognizes them as a desire for something else, then works to identify & enhance the “something else.”\nConstructionist Principle: we construct realities based on our previous experience, so our knowledge and the destiny of the system are interwoven.\nPrinciple of Simultaneity: inquiry and change are simultaneous.\nPoetic Principle: the story of the system is constantly being co-authored, and it is open to infinite interpretations.\nAnticipatory Principle: what we anticipate determines what we find.\nPositive Principle: as an image of reality is enhanced, actions begin to align with the positive image.\nOther related research/theory:\nSports psychology re: visualization; educational research re: Pygmalion effect; medical research re: mind/body health, placebo effect, etc.; spiritual practices of meditation and visualization.\n· Story, metaphor, image, and dialogue are powerful change agents.\n· AI reveals common ground (shared values & dreams).\n· AI reveals higher ground (the most compelling, desirable possibilities).\n· Affirmative competence (ability to recognize & affirm the positive) is a skill that can be practiced and learned.\n& Types of\n“Everyone” who is within the system or touched by it in some way;\nthose who hold images and have stories about the system\n20 – 2000 or more, involved in interviews, meetings and collaborative actions\nAI Summit: large scale meeting that “gets the whole system into the room;”\nlasting 1 – 6 days\nNon-conference Design: interviews and dialogue that spread “web-like” throughout\nthe system; timeframe indefinite\nSteps of Implementation\nThe process usually takes participants through the stages of\nThe 4-D Cycle: Discovery — Appreciating & Valuing the Best of “What Is”\nDream — Envisioning “What Might Be”\nDesign — Dialoguing “What Should Be”\nDestiny — Innovating “What Will Be”\nAI Principles are adapted and customized to each individual situation; the\nFull AI process typically includes:\n1. Selecting a focus area or topic(s) of interest\n2. Interviews designed to discover strengths, passions, unique attributes\n3. Identifying patterns, themes and/or intriguing possibilities\n4. Creating bold statements of ideal possibilities (“Provocative Propositions”)\n5. Co-determining “what should be” (consensus re: principles & priorities)\n6. Taking/sustaining action\nCreator(s) & Creation Date\nDavid Cooperrider, Suresh Srivastva in 1987\nwith colleagues from Case Western University & Taos Institute\nReferences Used for this\nCooperrider, David L. & Srivastva, Suresh (1987). “Appreciative Inquiry in Organizational\nLife.” In Pasmore,W. & Woodman, R. (Eds.), Research in Organizational Change and\nDevelopment, Vol. 1, p. 129-169. Greenwich, CT: JAI Press.\nCooperrider, David L. & Whitney, Diana (1999). Appreciative Inquiry. In Holman, P.& Devane,\nT. (Eds.), Collaborating for Change. San Francisco, CA: Berrett-Koehler Publishers, Inc.\nHammond, Sue Annis (1998, 2nd edition). The Thin Book of Appreciative Inquiry. Plano, TX:\nThe Thin Book Publishing Co.\nHolman, Peggy & Devane, Tom (Eds., 1999). The Change Handbook – Group Methods for\nShaping the Future. San Francisco, CA: Berrett-Koehler Publishers, Inc.\nKelm, Jackie (1998). “Introducing the AI Philosophy.” from Hammond, Sue Annis & Royal,\nCathy (Eds., 1998). Lessons From the Field: Applying Appreciative Inquiry. (p. 161-172).\nPlano, TX: Practical Press Inc.\nPinto, Michael and Curran, Mary. (1998) “Laguna Beach Education Foundation, Schoolpower.”\nfrom Hammond, Sue Annis & Royal, Cathy (Eds., 1998). Lessons From the Field:\nApplying Appreciative Inquiry. (p. 16 -47). Plano, TX: Practical Press Inc.\nWhitney, Diana & Cooperrider, David L. (Summer, 1998). “The Appreciative Inquiry Summit:\nOverview and Applications.” Employment Relations Today, p. 17-28.', 'The Silva Forest Foundation acts as innovator, facilitator, and catalyst for changes through applying an ecosystem-based approach for the conservation and ecologically responsible use of forests and related ecosystems throughout Canada and in other parts of the world. We focus on solutions. We provide mapping and analysis tools, education and training. We work cooperatively with communities, First Nations, and conservation organizations. We help to build bridges between divergent interests. In the midst of polarized debates, we provide workable, ecologically and culturally responsible options.\nSFF Work in Brief\nThe Silva Forest Foundation believes that in order to create positive change in how humans use Earth, we need to implement ecosystem-based approaches across the landscape and throughout society. This can best be accomplished by creating and affirming models, and by building change from the grassroots up through information, education, and training. Changes to policy and legislation will result when enough people adopt and promote ecosystem-based approaches.\nSFF’s work seeks to implement the change to ecosystem-based approaches. Our work:\n- focuses on the protection and/or restoration of natural ecosystem integrity as the first priority;\n- is grounded in leading-edge science and management practices;\n- is practical and provides tools that are useful to a wide variety of people, including scientists, professionals, conservationists, and local people;\n- includes a wide spectrum of interests;\n- develops and promotes on-the-ground models.\nOur work includes:\nEcosystem-based conservation planning and stewardship—empowering communities with options. SFF partners with communities to develop ecosystem-based conservation mapping, analysis, planning, and operations from the large landscape level to operational human uses such as tourism and timber management. Our GIS (geographic information systems) maps and economic analyses empower communities with information and provide models of ecological, social and economic sustainability. We work with rural and First Nations communities across Canada and elsewhere in the world. The mapping, ecosystem analysis, planning, and economic analysis can be applied to any kind of ecosystem and any community. Our work frequently includes capacity building through training and participation of community members in all phases of a project.\nAppreciative Inquiry: SFF provides facilitation using Appreciative Inquiry (Ai) for communities wanting to develop ecosystem-based conservation plans, or for any group wanting to define a positive way forward. Appreciative Inquiry assists communities to develop a positive, practical vision for how they want to relate to each other and to Earth.\nAppreciative Inquiry is the cooperative search for the best in people, their organizations, and the world around them. It involves systematic discovery of what gives a system ‘life’ when it is most effective and capable in ecological, social, and economic terms. The basic idea is to build effective organizations and programs around what works, rather than trying to fix what doesn’t. It is the opposite of problem solving. Instead of focusing on fixing what’s wrong , Ai focuses on how to create more of what’s already working well. Ai aims to create meaning by drawing from stories of concrete successes. Ai is a powerful tool that focuses on the positive and creates tremendous energy within a group.\nEducation and training—building the momentum and capacity for an ecosystem-based future: If ecosystem-based approaches are to be implemented, people must understand what this means and be able to do the ecological landscape to site, and operational planning. SFF develops and delivers workshops to professional and technical people, as well as to rural and First Nations communities. Each workshop is custom designed to meet the needs of the audience.\nWorking for ecosystem-based approaches in Russia: Since 1993, SFF has worked with Pacific Environment in various parts of Siberia and the Russian Far East to introduce ecosystem-based conservation planning and to assist local communities in applying EBCP. We have also hosted Russians in Canada. Many of SFF’s documents have been translated into Russian.']	['<urn:uuid:24f2a582-5e40-44e8-a9b8-dde4008640d7>', '<urn:uuid:514ff6e3-1af7-47e9-91ca-07f7f1a23a7e>']	factoid	with-premise	concise-and-natural	similar-to-document	multi-aspect	expert	2025-05-13T03:20:41.944655	15	74	1788
20	How do wind conditions and weather affect crop spraying, and what precautions should be taken during application?	Wind conditions and weather significantly impact crop spraying effectiveness and safety. Spraying should be avoided when wind velocities exceed 5 m/s, and it's best to spray during calm hours like early morning or early evening. As wind speeds increase up to 17 mph (3 m/s), spray pressure should be reduced and nozzle size increased to create larger droplets that are less prone to drift. Temperature also plays a crucial role - spraying shouldn't be done during the warmest hours of the day to prevent rapid droplet evaporation, and special care is needed when temperatures exceed 77°F/25°C with low relative humidity. For safety, it's essential to wear protective equipment including breathing masks, safety glasses, hearing protection, gloves, and boots. Additionally, never spray toward people, animals, or inhabited places, and maintain appropriate buffer zones from sensitive areas.	['During my travels, at the end of the field demonstrations with the mist sprayer, one of the most common questions that people ask (except for how much is the machine) is the following:\nWhat is the difference between the mist sprayer and the knapsack pump?\nAlthough the purpose of both machines is the treatment with phytosanitary products, their functioning is very different.\nThe knapsack pump (both manual and engine version) generates a pressure inside the tank which pushes the product, through an exit pipe, towards the nozzle that sprays on the crops to be treated. The treatment called high volume occurs with drops not uniform and with big dimensions 200-400 microns; they covers only a part of the leaves because the drops too heavy fall to the ground.\nThe mist sprayer is equipped with a fan that generates a great volume of air that is conveyed, through a pipe, to the exit nozzle at the bottom of the throwing pipe; thanks to its high speed (125 meters/sec, about 450 km/h), the product is nebulized in drops of an average size of 90 100 microns (one micron = 0,001 millimeters) and carried towards the crops. This system called low volume allows to obtain a treatment with greater protection, because the uniform micronization of the drops, combined with the action of the air that moves the leaves, creates a patina of product in the upper and lower part of them.\nDuring the demonstrations in the field, to verify the distribution, some hydro-sensitive paper is placed between the leaves: this paper has the property of changing color with the contact of water, showing the distribution obtained.\nThe mist sprayer also allows to work with a more concentrated product (therefore using a fewer quantity of water).\nFor example, treating one hectare of cultivation with the knapsack pump need approximately 400 liters of water, with the mist sprayer is possible to perform the same work with a quantity which can vary from 100 to 150 liters; of course these values are purely indicative because they may change depending on the type of crop, its inflorescence, type of the ground, etc..\nFurthermore the Cifarelli mist sprayer, using the great speed of the air flow, obtains a valid covering (98%) of the leaves up to a distance of 10/11 meters, horizontally and / or vertically.\nThe mist sprayer is more effective in applications of phytosanitary products in agriculture and insecticides treatments in public hygiene.\nThe knapsack pump is suitable in the herbicide treatment, because the size of the drop is appropriate to penetrate the ground and to attack the roots of infesting grasses.\nHow to use the mist sprayer?\nThe mist sprayer is placed on shoulders, adjusting the length of the shoulder straps, so that the machine is well adherent to the back and shoulders.\nThe throwing tube has to be addressed towards the parts to be treated, regulating the liquid cock and the revolutions of the engine (rpm) to obtain the dimension of the drops you need:\n- use the wide spray jet to obtain a large range;\n- use the spray jet (without wide spray jet) to obtain a long range.\nHow to address the product flow?\n- By executing an elliptical rotation from right to left side while treating in open field (vegetables, potatoes, salad, etc.).\n- By executing an “U” while treating plants, espalier cultivations and walls for disinfestations.\nHow to adjust the product flow?\n- The quantity of product distributed is adjustable by regulating the 5 positions of the cock presents on the throwing tube (position 1 of the cock delivers 0.14 L / min while in position 5 are 3.60 L / min, speaking of a mist sprayer without booster pump ). Greater is the amount of product, bigger will result the drops:\n- position 1 – maximum acceleration: smaller drops;\n- position 2,5 – ¾ of acceleration: medium drops (100-120 microns).\nBefore leaving, I remind that there are some recommendations to follow while working with a mist sprayer (and knap sack pump):\n- safeguard your person by wearing a breathing protection mask, safety glasses, hearing protection systems, gloves and protection boots;\n- avoid treatments in presence of strong wind;\n- it’s not recommended the treatment in the warmer hours of the day, to avoid the rapid evaporation of the drops;\n- never point the throwing tube toward people, animals or inhabited places;\n- at the end of the treatment wash yourselves and the clothes worn.\nFor the mist sprayer exist accessories for adjusting the amount of product dispensed, inclined grids, double output and other devices that will be described soon.', 'When applying crop protection chemicals, spray drift is a term used for those droplets containing the active ingredients that are not deposited on the target area. The droplets most prone to spray drift are usually small in size, less than 200 µm micron in diamter and easily moved off the target area by wind or other climatic conditions. Drift can cause crop protection chemicals to be deposited in undesirable areas with serious consequences, such as:\n- Damage to sensitive adjoining crops.\n- Surface water contamination.\n- Health risks for animals and people.\n- Possible contamination to the target area and adjacent areas or possible over-application within the target area.\nCauses of Spray Drift\nA number of variables contribute to spray drift; these are predominantly due to the spray equipment system and meteorological factors.\n- Droplet Size\nWithin the spray equipment system, drop size is the most influential factor related to drift.\nWhen a liquid solution is sprayed under pressure it is atomized into droplets of varying sizes: The smaller the nozzle size and the greater the spray pressure, the smaller the droplets and therefore the greater the proportion of driftable droplets.\n- Spray Heights\nAs the distance between the nozzle and the target area increases, the greater impact wind velocity can have on drift. The influence of wind can increase the proportion of smaller drops being carried off target and considered drift.\nDo not spray at greater heights than those recommended by the spray tip manufacturer, while taking care not to spray below the minimum recommended spray heights.\n- Operating Speed\nIncreased operating speeds can cause the spray to be diverted back into upward wind currents and vortexes behind the sprayer, which trap small droplets and can contribute to drift.\nApply crop protection chemicals according to good, professional practices at maximum operating speeds of 4 to 6 mph / 6 to 8 km/h (with air induction type nozzles - up to 6 mph / 10 km/h). As wind velocities increase, reduce operating speed.*\n*Liquid fertilizer applications using the TeeJet tips with very coarse droplets can be performed at higher operating speeds.\n- Wind Velocity\nAmong the meteorological factors affecting drift, wind velocity has the greatest impact. Increased wind speeds cause increased spray drift. It is common knowledge that in most parts of the world the wind velocity is variable throughout the day (see Figure 1). Therefore, it is important for spraying to take place during the relatively calm hours of the day. The early morning and early evening are usually the most calm. Refer to chemical label for velocity recommendations. When spraying with the traditional techniques the following rules of thumb apply:\nIn low wind velocity situations, spraying can be performed at recommended nozzle pressures.\nAs wind velocities increase up to 17 mph (3 m/s), spray pressure should be reduced and nozzle size increased to obtain larger droplets that are less prone to drift. Wind measurements should be taken throughout the spraying operation with a wind meter or anemometer. As the risk of spray drift increases, selecting designed to more coarse droplets that are less prone to drift is extremely important. Some such TeeJet nozzles that fit into this category are: DG TeeJet, Turbo TeeJet, AI TeeJet, Turbo TeeJet Induction, and AIXR TeeJet.\nWhen wind velocities exceed 5 m/s, spraying operation should not be performed.\n- Air Temperature and Humidity\nIn ambient temperatures over 77°F/25°C with low relative humidity, small droplets are especially prone to drift due to the effects of evaporation.\nHigh temperature during the spraying application may necessitate system changes, such as nozzles that produce a coarser droplet or suspending spraying.\n- Crop Protection Chemicals and Carrier Volumes\nBefore applying crop protection chemicals, the applicator should read and follow all instructions provided by the manufacturer. Since extremely low carrier volume usually necessitates the use of small nozzle sizes, the drift potential is increased. As high a carrier volume as practicial is recommended.\nof wind velocity,\nand relative air\nApplication Regulations for Spray Drift Control\nIn several European countries, regulatory authorities have issued application regulations in the use of crop protection chemicals to protect the environment. In order to protect the surface waters and the field buffer areas (examples are: hedges and grassy areas of a certain width) distance requirements must be kept because of spray drift. Inside the European Union (EU) there is a directive for the harmonization of crop protection. In this respect the procedures that have been implemented in Germany, England, and the Netherlands will be established in other EU countries in the coming years.\nTo reach the objectives for environmental protection, spray drift reducing measures have been integrated as a central instrument in the practice of risk evaluation. For example, buffer zones may be reduced in width if certain spraying techniques or equipment is used that have been approved and certified by certain regulatory agencies. Many of the TeeJet nozzles designed for reducing spray drift have been approved and certified in several EU countries. The certification of those registrars fits into a drift reduction category, such as 90%, 75%, or 50% (90/75/50) control of drift. This rating is related to the comparision of the BCPC reference nozzle capacity of 03 at 3 bar (43.5 psi).\n*Dv0.1 of the\nNozzles for Spray Drift Control\nDrift potential can be minimized even when it is necessary to use small size nozzles by selecting the appropriate style. Nozzles such as the Turbo TeeJet (TT), Air Induction TeeJet (AI), and the Drift Guard TeeJet (DG) produce medium to coarse sprays even in the smaller sizes. Large size droplets are much less susceptible to drift, but in some cases target coverage may be reduced due to a reduction in the number of drops. This needs to be taken into account, especially when using contact crop protection chemicals.\nWide angle flat spray nozzles with pre-orifice technology can achieve a larger drop size range at equal pressures without a reduction in flow rate. The DG, AI, TT, TTI, and AIXR incorporate pre-orifice technology, which performs the primary flow metering function. THe larger exit orifice provides secondary metering and pattern formation (see Figure 2).\nVenturi-type nozzles, such as the AI, TTI, and AIXR, use a pre-orifice to create a high velocity liquid stream and then draw air into the stream through a side opening. This mixture of air and liquid is then discharged at a low exit velocity thus creating very coarse droplets with air inclusion. However, air-filled droplets only occur with chemicals containing a sufficient concentration of surfactants.\nFigure 3 demonstrates the difference in droplet sizes between the TeeJet XR, DG, and TT nozzles on the basis of VMD. From this figure, the following conclusions can be drawn:\n- The DG nozzle in comparsion to the XR achieves 30% higher VMD (Dv0.5) values. However, as the pressure increases, the percentage difference decreases.\n- The TT nozzle achieves about 10-20% higher VMD (Dv0.5) values than the DG at equal pressures.\n- The VMD (Dv0.5) values for the TT nozzle at 15 psi (1.0 bar) pressure is about 70% higher than the XR.\nDrift can be managed successfully with the right knowledge of the equipment and the factors influencing drift. Every application must be balanced between managing drift and maintaining effective crop protection. Below is a list of factors that must be considered to ensure a safe, accurate spray application.\n- Spray Pressure\n- Nozzle Size\n- Application Rate\n- Spray Nozzle Height\n- Operating Speed\n- Wind Velocity\n- Air Temperature and Relative Humidity\n- Buffer Zones (safe distances from sensitive areas)\n- Instructions from the Crop Protection Chemical Manufacturer\nHaving taken into account all the variables that can have an impact on the drift potential, it may still be necessary to consider the use of drift control nozzles, such as the AI, TTI, or AIXR.']	['<urn:uuid:5a627165-0962-43d8-aec6-6bfa4ce608ee>', '<urn:uuid:323f3f3a-a44a-474b-a499-a83ae9513410>']	open-ended	direct	verbose-and-natural	similar-to-document	three-doc	novice	2025-05-13T03:20:41.944655	17	135	2072
21	Hi, I'm curious about food shopping habits - do rich people and people living in rural areas shop for groceries in similar ways or are there differences in what's available to them?	Rich people and rural residents have significant differences in their grocery shopping patterns. Rich people are very selective in their purchases, shop at specialized stores with pleasant environments that offer high-quality products, and spend substantially on luxury goods. In contrast, rural areas often only have small corner grocery or convenience stores with limited variety of fresh foods, higher prices, and reduced availability of fresh fruits, vegetables, meats and dairy products compared to large supermarkets. This is because rural stores operate at lower volume and higher costs than large supermarkets.	['Subculture is a part of culture containing the important features of the main culture. Culture includes what we have learned, our history, values, morals, customs art and habit. Marketing takes place within a given culture requiring different marketing programs. Not everyone in the same country or society shares the same behavioral pattern of the dominant or main culture. It clearly indicates that there are subcultures. The identification of a subculture may provide a firm with a segment of a market that it can develop. For example, products have been developed in great quantity for the teenage subculture and advertising has been directed to these consumers. Each subculture like a larger culture has distinctive values, beliefs and attitudes that the marketer must understand if he is effectively to exploit them.\nEvery culture contains subculture, defined as a group that share the values and artifacts of the larger society, but also have distinctive practices, preferences and beliefs. Again, subculture can be defined as patterns of behavior which contains important characteristics of the dominant society but provides values and life styles of its own.\nMajor sub-cultural categories:\nEthnic (based on the ancestors birthplace)\nEnglish, Chinese, Arab\nMuslim, Hindu, Christian\nNorthern, Southern, Central\nTeen, Middle aged, Elderly\nTeachers, Doctors, Engineers\nUpper, Middle, lower\nThe ethnic subculture is based on the nationality of one’s ancestors who have migrated to a new country .Ethnic subculture is usually found in affluent countries where people migrate from other parts of the world with the hope of a better life and livelihood. Though ethnic groups may lose their nationality over time, but in fact ethnic identification is held from one generation to the next through a number of institutions. As people migrate to another country leaving their home country, they slowly accept the new culture as their own over time. But they frequently exhibit the culture of their ancestors. This ancestral pride is manifested most strongly in the consumption of ethnic foods, in travel to homeland and in the purchase of numerous cultural artifacts (ethnic clothing, art, music, foreign-language newspapers). For example, in UK, there are many Bangladeshi immigrants who have now become British citizens, but they display consumption behavior in many occasions that resembles with that of someone living here in Bangladesh. They buy and use Bangladeshi foods, wear “lungi” & “sharee” & go to mosque on Fridays. This is a glaring example of how ethnic subculture affects consumer behavior.\nEach of the ethnic subculture has unique traditions and behaviors that have potential influence on product preferences and consumption behavior. A particular market consisting of ethnic subcultures may be the focus of a marketer. But it is not very easy to reach effectively a particular ethnic subculture with a particular type of products. The reason is that not everyone in the same ethnic subculture will consume the same type of product nor will lead the same life style. So a marketer living in cosmopolitan city should realize the ethnic group and should further segment this group on the basis of demographic and other aspects and different offers should be made for different sub segment.\nReligious subculture based on people’s religious beliefs. Some may be very pious and some may be relax. Members of a particular religion constitute religious subculture. Religious beliefs rituals may dictate the use of certain items and may discourage the consumption of others. For example, Islam discourages its followers the consumption of certain items such as alcoholic beverages, pork etc. An individual’s religious affiliation influences to a great extent his consumption pattern. It is expected that the members of a particular religious subculture will display similar behavioral patterns in their purchases and consumption. But differences may be found among the members of a particular religious subculture in terms of their consumption and lifestyle. A devout member of “Islam” may consider it immoral to be materialistic, where another member of the same religion may find nothing wrong in becoming materialistic. A marketer of cine-magazine will have no problem in reaching the later person, where it will be almost impossible for him to penetrate the market consisting of people of the other mentality and religious beliefs. Marketers should be tactful when considering religious subculture in their marketing strategies. As people are emotionally charged by their religion, so marketers should consider religious thinking of people in their marketing strategies.Marketers should not hurt the religious beliefs rather every marketing policies should keep consistence with religious beliefs of the people to get success in business.As most of the people in Bangladesh are muslim, they prefer purity in each item. That’s why “AROMATIC” soap became successful with the idea of halal soap when it was introduced. As Bangladesh is religious neutral country, marketers should not take any extreme policy.\nThe way people lead their lifestyle may also vary according to where they live or from which pat of the country they have moved to the other part of the country. People from a particular part of the country or people living in a particular part constitute what we call regional or geographic subculture. On this basis there could be two type of regional or geographic subculture. One could be based on geographic region of the county and other could be based on urban, suburban or rural distinction. Different geographic area of the country poses different climatic conditions which influences home construction, clothing requirements and recreational opportunities. In addition, different regions of the country have different age distribution and different social histories. These variables in combination with the climatic variables have produced differing values and lifestyles which newcomers to a region generally acquire after a period of time. These regional variation influences of the particular media, the types of products used and the product attributes considered important as well as they are produced and used. Bangladeshis, for example, live in the hill district display different patterns in food consumption, housing & recreation than those of the people living in other parts of the country. The people of Chittagong region of Bangladesh prefer hot & spicy food, where as people living in other parts may not like it. Again, fish is consumed by everybody here in Bangladesh, but dry fish is consumed heavily by people living in the southern and coastal areas of Bangladesh.\nRegional subcultures clearly influence many aspects of consumer behavior. The consumption process also is influenced by the urban, suburban and rural distinctions. The urban and suburban people prefer ready food, prefer eating out and enjoy their leisure in a way different from rural people. So marketers should consider regional subculture specially when they operate the business region wise, as people of different region show totally different consumption Pattern.\nSubculture based on age:\nSubculture may also be based on age differences of people living in the same country and belonging to the same main culture. It I likely that those who belonging to the teen age group will behave quite differently than those of middle age or elderly. Because the outlook, experiences, attitudes and other aspects are likely to vary. The teenagers are more materialistic in their lifestyles. The youth market is very lucrative for the marketers, as they start their carrier in this age are flaunt with more luxury items. Since they have little obligation in this stage, they can spend whatever they are. Their consumption patterns lean toward personal care & luxury items.\nThe middle age groups, on the contrary are matured, worried about the future, they are likely to be conservative in buying many material goods and are found to spend money on protective investments.\nThe elderly people who have gone on retirements or whose regular income generating activities have ceased display quite different consumption behavior. Most of them live with their children, their health condition gradually deteriorate, have emotional difficulties, have minimum amount of money to spend, are price/value conscious, are deal prone, like to shop as it has special meaning, are tuned in to the mass media, and read direct mail, package labels and package inserts. These few characteristics make them behave quite differently than other groups.Because of their differences with other groups; they also need different types of products.\nThe elderly people, because of deteriorating health, will require more fat free foods, tonic item, medical advices and medication as well as hospitalization. Since they have limited incomes, they prefer comparison shopping. Because of their maturity and different attitudes, they are skeptical of advertising claims and are influenced more by informed sources. The emergence of elderly market has created a need for many different types of products such as old people’s home, health clubs and a number of other products and services. Marketers face lot of problems and challenges in reaching elderly market. The communication strategy for elderly market should be well thought. The most successful communications are those that show a mixture of age groups using the products. Smart marketers have been attuned to the needs of elderly consumers &have been quickest to realize their value as customers. As demand of people of different age are different, so marketing policies to reach each group of people should be different.Marketers should offer their product considering the needs of each groups and in the way they want to. Single subculture:\nThe single subculture consists of unmarried as well as individuals who were married before but are now divorced or separated or widow and live independently. This subculture is found to be increasing particularly in urban and semi-urban areas. The size of this subculture is gradually becoming prominent to call a special marketing attention. The singles have some special needs, which can’t be met through normal social interaction. Marketers who can recognize their specific needs and can develop products aimed at meeting those specific needs can reap a considerable benefit. Single night clubs exotic telephone talk services, dating services, bachelor hostels/mess, convenience foods, restaurants, sports equipments etc. could be some of examples of products & services aimed at the subculture of singles. In our country single subculture is growing prominent in the urban areas and a result lot of hostels for both males & females have been established aiming to provide accommodation services to singles.\nSubculture based on gender differences:\nSubculture may also be formed based on gender difference, such as subculture of males & subculture of females. They are likely to behave differently, consume different types of products & respond differently to marketing appeals. Men for example are influenced more by aggressiveness, competitiveness, independence, self-confidence and masculinity. Women on the other hand, are influenced by neatness, gentleness, tactfulness, talkativeness and feminity. There are products which are equally used by men & women, but different appeals are needed for these groups. Cosmetics, perfumes, clothing, bicycles etc. are used both by men & women. But different designs, colors, sizes, shapes & fragrances are provided for by the marketers to appeal people of different sex. Bicycle, for example, is designed differently for men & women. Again, among females, those who are professionals, behave differently than those of non-professional. The working woman, particularly those, who are married, will again require different types of products and services that may not be bought by unmarried working women. The shopping patterns of these two groups will also vary. Since characteristics, attitude and needs vary between these two groups they may be considered as two different market segments.\nPeople display different patterns of purchase behavior according to their occupational involvement. People of different occupations may constitute occupational subcultures, such as subculture of the doctors, subculture of the lawyers, subcultures of the teachers, subcultures of the engineers, subculture of the defense personnel. A defense officer, for example, will show different behavior than someone belonging to the civilian’s society. Doctors for example may look at the nutritional aspect while baying a food item. Marketers should recognize the difference in attitude and behavior among people of different occupations and formulate marketing strategies accordingly to be successful in each specific subculture.\nSubculture of social class:\nSocial class may be used as a determinant of sub cultural differences. There could be subculture of the well-offs, subculture of the middle class & subculture of the poverty. People belonging to the subculture of the rich will display different buying behavior than those of the middle class & poor. Rich people are very selective in their purchase, people of the middle class will have substantial control over their consumption decisions; poor on the other hand will be very careful & cautious in taking their purchase decisions. Rich people are conscious about quality & uniqueness when purchasing a product but poor is not. They spend huge amount of money on recreation & luxury goods. They go selective shops for their purchasing where they get quality goods at pleasant environment. Subculture of the poverty consists of those people who live below the poverty level. One important characteristic of such people is that they spend significant portion of their money on basic necessities. Most of them are very price sensitive. So they avoid pre-packed, instant frozen food items as they are costly. As they have limited educational opportunities, they develop different attitudes, outlooks and motivation resulting in different buying behavior. They spend only small portion of their income on clothing, transportation, recreation, and luxury. They basically look at low cost items, favor shops where they get credit facilities & are attracted by different inducements offered by the marketers. To reach the rich, marketers should supply quality product & better environment where as they should try to keep the price low to get the poor customers. Conclusion:\nAny culture is again divided into many subcultures. These subcultures posses some distinct characteristics. As there can be broad differences between the cultures of various societies, there can also be differences within the same culture. Every culture, Contains subcultures, defined as groups that share the values and artifacts of the larger society, but also have distinctive practices, preferences & beliefs. Because of the important differences within any culture, marketers must be aware of diverse subcultures. Marketers must recognize that even though their operations are confined to a particular country or a division or district or even to one city, sub cultural differences may dictate considerable variations in what, how and when people buy. To deal with these differences effectively, marketers may have to alter their product, distribution system, price or promotion to satisfy members of particular subcultures. A particular subculture takes on importance in marketing if it constitutes a significant part of the population & specific purchasing patterns can be identified with it. Marketers need to be aware of how sub cultural characteristics influence buying behavior. Moreover, they should also bear in mind that one sub cultural background may interact with other aspects such as social class, personality, life-style & so on during the buying decision process. Marketers should also keep in mind that, like culture, subculture also changes. Therefore, continuous monitoring of sub cultural characteristics may help marketers bring appropriate and timely changes in their marketing strategies to make them more market oriented.', '- Grocery store availability. As the population density in urban and rural communities has decreased, large grocery stores have moved out. Often, only smaller stores are available to the community. These small corner grocery or convenience stores offer less variety of fresh foods and healthy items (Morland, 2002).\n- Quality of healthy foods. Urban and rural grocery stores operate at a lower volume and higher cost than large supermarkets. As a result, there is a reduced availability of fresh fruits, vegetables, meats and dairy products. In addition, the prices for the fresher foods are often higher (Zenk, 2005).\n- Access to nutrition education. Many nutrition concerns in rural America stem from the lack of proper education and available dietitians. In addition, schools may lack resources for adequate nutrition interventions (Tai-Seale, 2003).\n- Socioeconomic status. The socioeconomic status of individuals living in urban and rural communities might explain differences in healthy food intake (Drewnowski, 2004).The per capita income in rural areas is lower than in urban and suburban areas. Also, individuals living in these areas are more likely to live under the poverty level. For minorities, the disparity in income is even greater (NRHA, 2005).\n- Higher fat intake. Studies show that rural residents have a higher fat and calorie intake than others (Tai-Seale, 2003).\n- Sedentary lifestyles. Rural youth may spend more time watching television than their urban peers. This leads to an increase in snacking, increased desire for highly advertised foods, and less time participating in calorie-expending activities (Tai-Seale, 2003).\nStrategies to address these considerations\n- Improve availability of affordable, healthy food choices. Work with local community- and faith-based organizations, businesses, and governmental leaders to increase the healthy options available at existing markets and restaurants (Zenk, 2005). Some communities have offered grants, loans, and tax benefits to stimulate the development of neighborhood groceries, farmers’ markets, community gardens, and farm-to-cafeteria programs (IOM, 2005). A larger supermarket will carry more fresh items at lower prices (Zenk, 2005).\n- Improve access to healthy food choices. Creating a network that includes community groups, local government, nonprofit organizations, local farmers and food processors can help expand accessibility (IOM, 2005). It may be useful to work with city officials, urban planners, transportation departments, and faith-based organizations to develop city- or county-wide strategies related to land use planning and transportation so as to provide equal access to healthy food choices (Yancey, 2004).\n- Improve access to nutrition information. It may be useful to work with registered dietitians, school and worksite personnel, and community-based organizations and community members to ensure that the messages, content, format and placement of educational materials are appropriate for the population of interest. It may also be useful to work with healthcare providers in rural and urban settings to enhance their ability to convey appropriate nutritional counseling (Tai-Seale, 2003).\n- Use established settings. Strategies should maximize participation in the nutrition education intervention by having meetings or events at convenient locations and times (Bank-Wallace, 2002). It may be useful to schedule intervention activities with other church or community social events.\n- Convenient dissemination of nutrition information. Correspondence or web-based courses may prove useful in overcoming barriers to meeting places and times in rural areas (Tai-Seale, 2003).\n- Increase usage of supplemental food and nutrition information programs. Helping individuals get to the right place at the right time, and with necessary information, to enroll or participate in food and nutrition assistance programs can increase usage of food assistance programs (Strasser, 1991). Case management has also been suggested as a mechanism to help individuals overcome barriers and increase use of food assistance programs (Heslin, 2003).\n- School/Worksite Environment. Many successful interventions have focused on making more healthy choices available in schools and worksites as well as incorporating nutrition education and time for physical activity (Tai-Seale, 2003).\n- Involve the priority populations. It is important that individuals who are from the community of interest take an active role in planning, implementing and evaluating interventions (Bank-Wallace, 2002).\n- Engage community stakeholders. Leadership and active participation by community members, especially health care providers and community and religious leaders, can strengthen the credibility of and respect for the intervention (Bank-Wallace, 2002).\nPrint this window']	['<urn:uuid:ef39bb00-4fa4-4832-8c26-ed8ff610e62c>', '<urn:uuid:cd1cb9e4-296e-47b4-bdfe-6727a3fb0b35>']	factoid	with-premise	verbose-and-natural	distant-from-document	comparison	novice	2025-05-13T03:20:41.944655	32	89	3189
22	As someone studying ancient philosophy, I'm curious about how Aristotle's concept of God differs from the biblical God. What were the main characteristics of the divine being in Aristotle's theology?	Aristotle's unmoved mover had three main characteristics: infinite power (capable of moving the heavens for infinite time), transcendence (being the only unmovable being), and intelligence (ability to think and will). While this divine being was considered a God due to being eternal and happy, it was not a creator God like in the Bible. Aristotle's God was discovered through philosophical reasoning rather than divine revelation.	['1 Science and the Future of Mankind Pontifical Academy of Sciences, Scripta Varia 99, Vatican City THE RELATIONSHIP BETWEEN SCIENCE, RELIGION AND ARISTOTELIAN THEOLOGY TODAY 1. The Relationship between Science and Religion Many scientists, philosophers and theologians maintain that there exists a relationship of consonance between science and religion today, and that this is not based, as in the past, on the fact that there may be some problems which have as yet not been solved by science and which might have a religious solution. They think that through the methods of contemporary science it is possible to admit, in a probable, if not in a necessary way, the existence of God and the creation of the world by Him. This is the case, for instance, of Richard Swinburne, who thinks that the existence of God, from the point of view of the calculus of probabilities, is the simplest and therefore the most probable hypothesis for the explanation of the world, as it is known by science. 1 In an analogous way, John Polkinghorne thinks that the world s creation by God is compatible with a physical theory of the stationary universe as well as with a scientific conception of its origin, both where this origin is conceived as involving an initial big bang and where it is conceived as involving a quantistic fluctuation of an inflated vacuum. Moreover, Polkinghorne believes that the apparently anthropic direction of evolution can also be explained by a scientific theory of an informational, not energetic, agency of God. 2 Some of the contents of Christian faith, indeed, cannot be explained from a scientific point of view. Furthermore, they cannot be accepted by 1 See R. Swinburne, The Existence of God (Oxford University Press, 1979). 2 See J. Polkinghorne, Belief in God in the Age of Science (Yale University Press, 1998).\n2 THE RELATIONSHIP BETWEEN SCIENCE, RELIGION AND ARISTOTELIAN THEOLOGY TODAY 229 science because they seem to contradict the laws of nature, even where these are conceived in an indeterministic or a probabilistic way. I am thinking, for instance, of the resurrection of Jesus Christ, or of the virginity of Mary and her maternity in relation to Christ, which seem to contradict the laws of biology, and also of many other miracles. In these cases it is not enough to appeal to a simple act of faith, because Christian faith, as the Pope said in his last encyclical Fides et Ratio, cannot be faith in the absurd, i.e. in the impossible. Even those scientists and theologians mentioned above admit that between science and religion there must be a relationship of consonance, i.e. of compatibility. And the existence of any contradiction would violate this relationship. In order to eliminate these contradictions, and to ensure the compatibility of science and religion, it is necessary to admit the dependence of nature on an absolute power which can make exceptions to the laws of nature, i.e. the same kind of dependence which is involved in the notion of creation, as stated by the Bible. Now, the concept of creation, considered in the sense of a total dependence of the universe on a transcendent God, even purified of those mythical characters which are described in the Bible, can certainly be accepted by an act of faith, but this presupposes some necessary conditions. And the absence of these conditions makes faith absurd and unacceptable from any point of view. 2. The Conditions of Consonance In my opinion, these conditions are the following: 1. The existence of an absolute, i.e. infinite, power, which does not depend on any other being and on which every other being depends; 2. the transcendence, i.e. the difference, the complete heterogeneity, of a being which possesses such a power in relation to nature, i.e. in relation to the universe, including mankind, with its history, its culture, its science, and its technology; 3. the characteristic of intelligence of this being, which gives him the capacity to think, will, and act. The first of these conditions, i.e. the existence of an absolute power, is necessary in order to explain the exceptions to the laws of nature because only the power that created these laws can violate or suspend them. But this means that there must be something, or someone, which or who is\n3 230 superior to nature because it or he is not subject to its laws. This means, therefore, that nature, or the universe, or the infinite multiplicity of worlds in other words the reality which is the object of our scientific investigations is not the whole of reality. There must be something else upon which that reality which is the subject of science depends. Obviously, I am not claiming here that this something else does necessarily exist (this is a philosophical problem and would need a wider discussion) but I am saying that its existence is necessary in order to ensure a consonance between science and religion. The second condition, i.e. the transcendence of a being who possesses absolute power, is necessary because if the power capable of making exceptions to the laws of nature was immanent, i. e. internal, to nature, it would be a part of it, and therefore the same nature would on the one hand be governed by some laws and on the other hand it would be capable of making exceptions to them, and this would be a contradiction. It is true that for some scientists many events in nature, even biological evolution, depend only on chance. But in this case chance would itself be a law of nature, and in this respect the events mentioned above the resurrection of Christ, the virginity of Mary would be exceptions and therefore impossible. I do not believe, in fact, that those scientists who believe that natural phenomena are due to chance would admit the possibility, through chance, of miracles. Even if we imagine an immense human power, capable of going beyond the laws of nature that we know so far, this power would be a part of nature and would be subject to its general laws. Thus, even this immense power could not explain the events which are apparently in contrast with the general laws. If it could, it would be a magical power incompatible with science. The third condition, i.e. the intelligence of a being provided with absolute power, is the most evident, because only an intelligent being capable of thinking and willing can act on nature and on history in an intentional way, in a way which is required to explain the events mentioned above. On the other hand, every kind of religion (at least religions inspired by the Bible) believes in the existence of an intelligent and willing God, but the condition for this belief, which is faith, is the possibility of conceiving of such a being in a rational way, or at least in a way which is not in contrast with reason. All these conditions and this is my point are not a question of religion (i.e. of faith in divine revelation, because these conditions are also the conditions for the possibility of revelation itself), or of science, because they go beyond the field of scientific investigation.\n4 THE RELATIONSHIP BETWEEN SCIENCE, RELIGION AND ARISTOTELIAN THEOLOGY TODAY 231 Therefore, they are part of a discourse which is neither religion nor science, a discourse which we can refer to by no other name than philosophy, or better, a particular type of philosophy metaphysics or better still a particular type of metaphysics, i.e. the metaphysics of transcendence. 3. Aristotelian Theology As a matter of fact, all these conditions were arrived at by a philosopher who did not know the Bible and who was not influenced by it in any sense Aristotle. He arrived at these conditions through a process which he claimed to be rational, i.e. philosophical. This process may be criticised from a philosophical point of view, or, in contrary fashion, it may be accepted as a valid philosophical demonstration. This is an open question at the level of philosophical discussion. But, whatever the case, this process was historically located within a philosophical context and it was totally uninfluenced by any kind of religious faith. In the view of philosophers who have believed in religions based upon by the Bible Jews (such as Avicebron and Maimonides), Muslims (such as Alfarabi, Avicenna, and Averroes) and Christians (such as Albert the Great and Thomas Aquinas) Aristotle s formulation of these conditions was a necessary premise to religious faith. A necessary premise from a logical point of view and not from a psychological point of view, although obviously it was not a sufficient premise. The unmoved mover (whether one or more than one), whose existence Aristotle tries to demonstrate in the twelfth book of his Metaphysics (i.e. through so-called Aristotelian theology ), has an infinite power because as Aristotle explicitly affirms it has the capacity to move the heavens for an infinite time (cp a 8-9); it is transcendent in relation to every other being because it is the only unmovable being, whereas all the other beings are moved (1071 b 17-20); and it is intelligent because it thinks (the act of thinking is its self being, it is its self essence) and it wills (as is proved by the fact that, according to Aristotle, it is happy). It also has the capacity to act because as I have tried to demonstrate in many works it is not only a final cause but also an efficient cause of the movement of the heavens. 3 3 See E. Berti, Da chi è amato il motore immobile? Su Aristotele, Metaph. XII 6-7, Méthexis. Revista Argentina di Filosofia Antigua, X, 1997, pp ; De qui est fin le moteur immobile?, in M. Bastit ed J. Follon (eds.), Essais sur la théologie d Aristote (Louvain-la- Neuve, 1998), pp. 5-28; The Unmoved Mover as Efficient Cause in Aristotle s Metaph. XII, in M. Frede and D. Charles (eds.), Aristotle s Metaphysics Lambda (Oxford, 2000), pp\n5 232 Therefore, according to Aristotle, he we can now use the personal pronoun because we are speaking about a person is a God, and this is a consequence of the fact that he is eternal and happy (these are the characteristics that ancient Greeks attributed to gods), even if he is not a creator God (1072 b 26-30). Obviously, I am not claiming that Aristotle s unmoved mover is the same as the God of the Bible: as I have already observed, he is not a creator God. For Aristotle he is just a mover, even if by moving the heavens he is the cause of every generation and corruption on the earth, i.e. of the life and death of every living being. And he has not revealed himself to man: Aristotle is not aware of divine revelation. Perhaps but this is not certain he does not know or love man. In some passages Aristotle seems to think that God knows and loves only himself, but at other points he affirms that wise men are loved by gods. Therefore Aristotle s God does not have sufficient characteristics to be the same as the God of the Bible. But the characteristics he does have, i.e. transcendence, intelligence, infinite power, are necessary to being the God of the Bible in the sense that they are the necessary conditions for a creator God. From a philosophical point of view, it is important to add that Aristotle s unmoved mover has an advantage that the God of the Bible does not have i.e. he was not known because of an act of revelation but was discovered by a philosopher through human instruments alone, i.e. observation, reflection, and reasoning. 4. The Necessity of Metaphysics My aim here is not the defence of Aristotelian theology as it was historically developed. Nevertheless, I believe that in order to ensure compatibility between science and religion it is necessary to have a form of metaphysics of the kind to be found in Aristotelian theology i.e. a form of metaphysics which admits the transcendence of the Absolute. This theology, or rather, this form of metaphysics, is termed Aristotelian perhaps because Aristotle was the only philosopher who was not influenced by the Bible and yet reached the idea of a transcendent God by rational paths. This form of metaphysics does not seek to demonstrate the validity of the contents of religious faith but it does allow us to establish the logical conditions for their possible existence, i.e. to create a sort of space which goes beyond science. Without this space religion would be impossible. In order to believe in religious meaning it is not necessary to profess this form of metaphysics\n6 THE RELATIONSHIP BETWEEN SCIENCE, RELIGION AND ARISTOTELIAN THEOLOGY TODAY 233 explicitly, but this kind of metaphysics is necessarily involved, from a logical point of view, in every authentic act of religious faith. This is a very poor form of metaphysics because it does not include the whole of natural theology as developed by Christian (but also by Jewish and Muslim) philosophers during the Middle Ages (but also during the modern age). This kind of metaphysics could be defined weak metaphysics from an epistemological point of view, i.e. in the same sense in which scientific theories with a poor cognitive content are called weak theories. The fundamental idea of this form of metaphysics, in fact, is based on the idea that the world of our experience, which forms the object of our scientific investigations, does not coincide with the whole of reality. For this reason, the world of the experience is not an absolute world, it is not self-sufficient, and it does not have within itself everything that is necessary for its explanation. We would say that this metaphysics only creates a space. But, precisely in virtue of its weakness, this form of metaphysics is very strong from a logical point of view because it is extremely difficult to refute it. In order to refute it, in fact, it would be necessary to demonstrate that the world of our experience can be completely explained by some factors which are immanent to it, i.e. that it is an absolute a result that a scientific theory could hardly aspire to obtain. To tell the truth, at the end of the twentieth century the main alternative advanced by scientists to the metaphysics of transcendence, i. e. to theism, is not a metaphysics of immanence, of the same kind of positivism, or materialism, as was evident in the nineteenth century. At the end of the twentieth century a large proportion of scientists think that the alternative to metaphysics is an appeal to pure chance. This is the thesis that the whole universe, with its present structure and order, including the existence of life and man, is the result of an infinite series of changes which are exclusively due to chance. This position seems to me to be an abandonment of an exhaustive explanation rather than a claim to a perfect explanation of the universe through reference to its internal factors. But, in fact, if chance is considered the only possible explanation for the universe, it becomes an exhaustive explanation, i.e. an explanation which considers the universe as perfectly self-sufficient and does not admit further research, an explanation which is completely self-sufficient. This kind of approach, it seems to me, is the negation not only of the philosophical spirit but also of scientific research and in general of any critical sense. The existence itself of science and philosophy, and their continual and perhaps infinite desire for knowledge is the best refutation of\n7 234 this approach. This never satisfied desire for knowledge, like the awareness of an incomplete and inadequate explanation of the universe, is not only a requirement of human reason, but in a realistic perspective, which is the prevailing attitude of scientists it corresponds to a real feature of the universe itself, i.e. to its inability to explain itself completely, to having within itself all those factors which are necessary to its complete explanation. In this way, the metaphysics of transcendence turns out to be not only the necessary condition for compatibility between science and religion, but also the necessary condition for a genuine scientific approach towards the universe, i. e. a fair admission of the problematic character of our experience of the world.']	['<urn:uuid:33161f8a-843f-44db-94b5-350c647c7507>']	factoid	with-premise	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-13T03:20:41.944655	30	65	2730
23	arbitration enforcement rules supreme court role india china compare	In India, the Supreme Court established that arbitral awards can be executed in any court where assets are located, as clarified in the Sundaram Finance Ltd. v. Abdul Samad case. In China, the Supreme People's Court issued a Notice requiring lower courts to report jurisdictional disputes affecting award validity or enforcement to them, specifically to achieve uniform case law in disputes between CIETAC and its former sub-commissions.	['November 9, 2023\nArbitration is a form of alternative dispute resolution (ADR) that allows parties to settle their disputes or claims without resorting to litigation. Arbitration is governed by the Arbitration and Conciliation Act, 1996 in India, which is based on the UNCITRAL Model Law on International Commercial Arbitration. One of the key aspects of arbitration is the arbitral award, which is the final and binding outcome of the arbitral process.\nThe Arbitration and Conciliation Act, of 1996 does not provide a clear definition of “award” in its provisions. However, it can be inferred from the context that an award is the final decision or determination of a dispute or claim that has been submitted for arbitration by the parties. The award can either be monetary or non-financial, such as a cessation of a particular act or an addition of employment. The award can also be interim or final, depending on whether it resolves some or all of the issues in dispute.\nThe jurisdictional issues related to the award are addressed in Section 42 of the Act, which states that “Not withstanding anything contained elsewhere in this Part or in any other law for the time being in force, where with respect to an arbitration agreement any application under this Part has been made in a Court, that Court alone shall have jurisdiction over the arbitral proceedings and all subsequent applications arising out of that agreement and the arbitral proceedings shall be made in that Court and in no other Court.”This means that once an application related to an arbitration agreement is made in a court,that court will have exclusive jurisdiction over all matters arising out of that agreement and the arbitration proceedings. This provision is intended to avoid a multiplicity of proceedings and conflicting decisions by different courts. However, this provision does not apply to execution applications when it comes to the enforcement of an award through its execution.\nThe execution of an award is the process of giving effect to the award by ensuring that the party who has won the award receives what they are entitled to. The execution of an award can be done either voluntarily by the losing party or compulsorily by the intervention of a court. The execution of an award is governed by Section 36 of the Act, which states that “Where the time for making an application to set aside the arbitral award under section 34 has expired, or such application having been made, it has been refused, the award shall been forced under the Code of Civil Procedure, 1908 (5 of 1908) in the same manner as if it were a decree of the Court. ”This means that an arbitral award can be executed as a decree of a court after the expiry of the time limit for challenging the award or after the dismissal of such challenge.\nHowever, unlike Section 42, Section 36 does not specify which court will have jurisdiction to execute the award. This issue was clarified by the Supreme Court in Sundaram Finance Ltd. v. Abdul Samad, where it held that an arbitral award can be filed for execution in any court whereas sets are located, irrespective of which court passed the award or decree. This decision was reiterated by the Allahabad High Court in Cheran Properties Ltd v. Kasturi and Sons Ltd, where it held that there is no need to obtain a transfer of decree from one court to another for executing an arbitral award. It is important to note that Section 32 of the Act states that arbitral proceedings stand terminated by the final arbitral award, and execution can only be sought after the final award is rendered. Therefore, an execution application can be filed by an award holder before any Indian court where the award is enforceable, without the need to obtain a transfer of decree from the court that passed the award or decree.\nThe Arbitration and Conciliation Act of 1996 provides a comprehensive framework for arbitration in India. It covers various aspects such as definition, jurisdiction, and execution of arbitral awards. The primary goal of the Act is to promote arbitration as a speedy and effective mode of dispute resolution. It also aims to ensure minimal judicial intervention and maximum party autonomy. Furthermore, the Act seeks to align Indian arbitration laws with international standards and best practices.', 'by Jennifer Bryant\nBeijing vs. Shanghai: CIETAC Arbitration-Dispute settled?\nThe China International Economic and Trade Arbitration Commission (CIETAC) located in Beijing appears to be the leading officially registered arbitral institution in China dealing with domestic as well as international arbitration proceedings. According to Chinese law, domestic arbitral awards are only recognized if the arbitration proceedings are administered through an officially authorized arbitral institution. With respect to such official authorization, Art. 10 of the Arbitration Law of the People’s Republic of China (PRC Arbitration Law) which has entered into force on 1 September 1995 provides that “commissions may be established in the municipalities directly under the Central Government, in the municipalities where the people’s governments of provinces and autonomous regions are located or, if necessary, in other cities divided into districts.” CIETAC itself was founded and authorized by the Government Administration Council of the Central People’s Government on 6 May 1954. Even though CIETAC’s authorization took place long before Art. 10 of the PRC Arbitration Law came into force, even measured by this present standard, CIETAC is duly authorized. Until 2012, the sub-commissions of CIETAC in Shanghai, Shenzhen, Tianjin and Chongqing also benefitted from CIETAC’s official recognition.\nThe entering into force of the revised CIETAC Arbitration Rules on 1 May 2012, however, led to a dispute between the CIETAC headquarters in Beijing and its sub-commissions in Shanghai and Shenzhen. CIETAC suspended the sub-commissions’ authority which CIETAC had previously only granted to these sub-commissions on the basis of their relation to CIETAC as CIETAC’s sub-commissions. CIETAC declared that these sub-commissions in Shanghai and Shenzhen were no longer entitled to accept and administer arbitration proceedings under the CIETAC Rules. As a consequence, the former sub-commissions in Shanghai and Shenzhen declared their independence from CIETAC in January 2013. For this purpose, both established their own arbitral rules and drafted their own model arbitration clause. In addition, the two former CIETAC sub-commissions changed their names to Shanghai International Arbitration Centre (SHIAC; also known as Shanghai International and Economic Trade Arbitration Commission) and Shenzhen Court of International Arbitration (SCIA) respectively.\nAs a result of the withdrawal of authority by CIETAC, uncertainty arose as to the issues of jurisdiction as well as whether arbitral awards rendered in proceedings administered by the SHIAC and the SCIA could be recognized and enforced in China. Jurisprudence, inter alia by the Intermediate People’s Court of Suzhou, even deepened uncertainty in that regard. The court in Suzhou denied recognition and enforcement of an arbitral award that was rendered as part of arbitration proceedings administered by the SHIAC. The court made that decision on the basis of an assumed lack of jurisdiction by the SHIAC. Furthermore, on 4 September 2013, the Supreme People’s Court issued a Notice to the lower instance courts setting rules for interpretation and resolution of such jurisdictional disputes. According to this Notice, disputes arising from ‘old clauses’ stipulating jurisdiction of one of the former sub-commissions of CIETAC were to be reported to the Supreme People’s Court where the dispute affected the validity of the arbitration agreement, the setting aside or the enforcement of arbitral awards. The reasoning for this Notice was to settle the dispute in respect of the jurisdiction of CIETAC or the former sub-commissions respectively and to achieve uniform case law in that respect.\nTwo recent decisions of 31 December 2014 and 6 January 2015 of Chinese Intermediate People’s Courts now may contribute to the resolution of this issue of competence:\n- In the first decision mentioned, the No. 2 Intermediate People’s Court of Shanghai Municipality ruled on 31 December 2014 („(2012) Hu Er Zhong Min Ren (Zhong Xie) Zi Di 5 Hao“) that the Shanghai International Arbitration Center (SHIAC) is an effectively founded independent arbitration commission that was approved by the responsible administrative authorities (Bureau of Justice of Shanghai Municipality as well as Shanghai Municipal Government und Shanghai Commission for Public Sector Reform). As an authorized arbitration commission, SHIAC is considered to be the competent institution to administer arbitration proceedings on the ground of respective arbitration clauses. The basis of this case was an old arbitration clause providing for the ‘CIETAC Shanghai Sub-commission’ to be the competent arbitration institution as to all disputes arising out of the contract. Initially, the claimant under the arbitration proceedings (who was then the defendant to the court proceedings) had filed an application for arbitration with CIETAC. Reacting to the application for arbitration, the respondent in the arbitration proceedings (who became the plaintiff to the court proceedings) immediately raised a claim with the No. 2 Intermediate People’s Court of Shanghai Municipality requesting for the ascertainment of the lack of jurisdiction by CIETAC. Upon that claim, the No. 2 Intermediate People’s Court of Shanghai Municipality confirmed the SHIAC to be competent arbitration commission while indeed establishing a lack of jurisdiction of the CIETAC.\n- The second dispute mentioned was tried before the Intermediate People’s Court of Shenzhen. Like the No. 2 Intermediate People’s Court of Shanghai Municipality, the Intermediate People’s Court of Shenzhen also denied jurisdiction of the CIETAC. In its judgment of 6 January 2015 („(2013) Shen Zhong Fa She Wai Zhong Zi Di 133 Hao“), the court confirmed competence of the former sub-commission of CIETAC in Shenzhen, now the Shenzhen Court of International Arbitration (SCIA). According to the court’s ruling, the SCIA’s registration at the Guangdong Bureau of Justice resulted in the foundation of a lawful arbitration commission under the PRC Arbitration Law. The case was based on an arbitration clause according to which an arbitration was to be brought to the ‘CIETAC South China Sub-commission’. Contesting the validity of that arbitration clause, the plaintiff raised a claim with the Intermediate People’s Court of Shenzhen for the ascertainment of the invalidity of that arbitration clause as well as the determination that the plaintiff was no longer bound by that allegedly invalid clause. The court, however, denied such ruling based on the aforementioned reasoning.\nIn addition, the SHCIA has recently reported in its Arbitration Newsletter, Issue 1, 2015, that the No. 2 Intermediate People’s Court of Shanghai Municipality has rendered 12 additional rulings confirming SHCIA’s jurisdiction. The SHCIA, however, has not yet published the full texts of these court decisions.\nAll these recent court decisions have led to at least a bit more certainty as regards the fate of arbitration clauses which were agreed upon prior to the independence of the Shanghai International Arbitration Center and the Shenzhen Court of International Arbitration, and still refer to the former CIETAC sub-commissions. Unlike assumed initially, these recent decisions by the courts of Shenzhen and Shanghai give rise to the assumption that such arbitration clauses do not have to be considered as per se invalid. In fact, the SCIA and the SHIAC apparently are both – under their respective new names – competent to administer both domestic and international arbitrations. Ultimately, however, it remains to be seen how other Chinese courts will deal with these jurisdictional conflicts. This should as well be of particular importance with respect to the recognition and enforcement of arbitral awards rendered under the respective rules of SHIAC and SCIA in the international context. Since any such jurisdictional disputes should generally be reported to the Supreme People’s Court based on its Notice of September 2013, it can at least be assumed that the Supreme People’s Court has acknowledged the latest decisions by the Intermediate People’s Courts in Shanghai and Shenzhen.']	['<urn:uuid:a6546db7-80b1-4933-bee9-560e385639db>', '<urn:uuid:b7820baa-fde9-4947-bed4-a0bddbd8556a>']	factoid	direct	long-search-query	similar-to-document	comparison	novice	2025-05-13T03:20:41.944655	9	67	1956
24	What is the biggest misconception about hearing aids?	Hearing aids are not a cure-all - they only amplify sounds to make speech clearer at shorter range. They actually amplify background noises more, causing more distraction than for people with normal hearing.	"['How Do You Do That? Demystifying People With Disabilities\nNearly all employers and human resource professionals are aware of the Americans with Disabilities Act (ADA). Yet, how often do you, your colleagues, or the average individual have contact with someone who is visually impaired/blind, using a wheel chair, or profoundly deaf? When you do, how do you react? Interact? Ignore? Assist? Marvel at their ability to move through their environment living full and productive lives?\nWhat can you do to put yourself and the person with a disability at ease? Well, this is our purpose here. It is not to attempt to answer all your questions. Rather, to discuss appropriate methods for interacting with individuals who are disabled while squelching many myths and misconceptions. You\'ll learn what to do and not do, techniques and technologies used for employment as well as in daily living.\nHow many times have you heard the preferred or proper method for interacting with someone with a disability? Probably never, if at all. In fact, the average individual rarely has any contact with someone who is blind, deaf, or mobility impaired. Therefore, you will be exposed to common courtesy rules governing your interactions with these individuals.\nHow does someone who cannot see a computer monitor or manipulate the keyboard use this most valuable technological tool of the coming century? Techniques of daily living such as setting the alarm clock, cooking on the grill, and the simple task of matching your wardrobe are tasks most of us take for granted. Yet, how would you perform these simple jobs from a wheelchair, without your eyesight, or hearing? You\'ll learn about specialized tools, adaptive electronic equipment, and techniques used to live a full and productive life.\nCommunicating - Putting one another at ease\nWhen you meet or come in contact with an individual who has a disability, don\'t be ill at ease. If you are uncertain how to assist or interact, always speak directly to the individual. After all, they are the experts! You can never go wrong by asking. The experience will be more pleasant for all by remembering and following some simple points of courtesy.\nWhen conversing with a person who is mobility impaired, speak directly to the individual rather than to their companion. People who use wheelchairs are particularly sensitive to this type of treatment. If your conversation goes on for more than a few minutes or is expected to do so, consider sitting to be ""eye-to-eye"" while talking. It can be uncomfortable to look straight up for an extended period when seated.\nDon\'t be reluctant to use words like ""Walk"", ""Run"", or ""Stand"" when talking with a mobility-impaired person. Wheelchair users and people who are otherwise mobility impaired use these words, too.\nAs with all people with disabilities, don\'t ask their spouse or companion what they may want. Speak directly to the individual - just as you would anyone else in a similar situation. It isn\'t necessary to raise your voice or address them in a child-like manner.\nMany blind people have excellent voice recognition. However, just as a sighted person may remember a face, yet forget a name, the same can occur with voices. Always introduce yourself by name? ""Hi Mary! It\'s Fred!"" This simple courtesy will avoid embarrassment for both parties. On a similar note, it\'s nice to know who\'s in the room with you. Please speak when you enter and exit. It\'s helpful if others with you are introduced. Additional information is also beneficial such as knowing if there are children, dogs, or cats in the room.\nHearing Impairment is usually divided into two basic groups: the deaf and the hard of hearing. Individuals who are deaf fall into one of two categories - cultural or oral. Those persons who primarily rely on sign language for communicating are in the cultural category. In contrast, people whose preferred method of communicating is lip reading or speech reading are in the oral category.\nYou may have noticed that the speaking voices of people who are deaf can often sound different from the voice of someone who has normal hearing. Without the ability to hear their own voice as well as that of others, modulating tones are difficult for someone with a hearing impairment. If you cannot clearly understand a person\'s speaking voice, do not hide it. Admit that you are having difficulty and use pen and paper if necessary.\nOn the other hand, many hard of hearing people have trouble discriminating between words with similar sounds. Just as some words may sound alike, they can have very different meanings. For example, ""sale"" and ""sail"" have identical sounds, but totally different meanings. While ""pen"", ""men"", and ""bend"" are not close in meaning, they can sound the same to a hard of hearing individual. Thus, comprehending your message requires serious concentration.\nIf you are familiar with American Sign Language (ASL), by all means use it. Those you are communicating with will be most appreciative. Deaf/blind individuals can spell out words that do not have a given sign by using a technique known as ""Finger Spelling"".\nMobility - Moving THROUGH YOUR environment safely\nPeople with disabilities want to be treated the same as anyone else. Never rush up and startle someone with a disability by grabbing him or her. Your best approach is to assume he or she is independent. If the individual is in need of assistance, they will ask for help. You will never go wrong by asking first, rather than making assumptions!\nYou are most likely familiar with dogs used as guides by blind individuals. However, a service dog assists some mobility-impaired people. Remember? interaction with the service animal is permissible only with the expressed permission of the handler.\nThere are many people who use a wheelchair or motorized scooter to get from point A to point B; many other mobility-impaired people use crutches, canes, leg braces and/or walkers. If you should observe someone using one of these devices approach an entrance to a building, you may wish to offer assistance. DO NOT automatically rush to open the door at the instant you see someone approaching in a wheelchair, using crutches or a walker. Rather, calmly walk to the door and offer assistance allowing the individual to accept or reject the offer. DO NOT be insistent, and DO NOT wait until the person is about to fall before offering your help.\nBe aware of slippery floors and ramps, which can cause these devices to easily lose traction and slide on wet surfaces. A service dog assists some mobility-impaired people. These animals have full access to businesses and all public places. They are working animals, not pets. Distractions such as petting, whistling, clicking, and even establishing eye contact are not acceptable.\nThree (3) basic mobility options are available to blind or visually impaired travelers - sighted guide, white mobility cane, or a dog guide. Combinations of the last two are also commonly used in specific situations.\nWhen walking with someone visually impaired, don\'t grab his or her arm. Allow them to take yours grasping gently at your elbow. In this manner, they will keep a half step behind you. Your body movement will communicate information about the travel environment. Following along with you in this manner, curbs and steps can be easily negotiated. It is very helpful if you alert your traveling companion to these changes as well as announcing if an Entry/Exit door is being held open. This avoids confusion and embarrassment for all.\nThe use of a mobility cane is the first major step to travel independence for a blind person. Utilizing all available sensory input (smell, sound, and touch), the traveler has a greater opportunity for proper orientation to their environment. Orientation and Mobility Specialists teach techniques for proper use of a white mobility cane. This occupation requires a Masters degree from a university. Governmental agencies, rehabilitation centers, schools for the blind, and some public school systems offer this training.\nFor many people a dog guide brings a great sense of independence. Hundreds of people who are blind and visually impaired are trained with well disciplined and dedicated dogs as guides each year. It is important that all people know something about the way a dog guide team works and how to act when encountering one of these guides.\nIf a person who is using a dog appears to be in need of some assistance, approach him or her on their right side. The dog guide will usually be on the left. Do not touch or take the person by the arm without first asking if you can assist them. Under no circumstances, should a person take hold of the dog guide or the harness, this will confuse the dog and startle the individual. If assistance is accepted, offer your left elbow by brushing it against their arm as explained in the sighted guide technique.\nIn some instances, the person may choose not to make use of the sighted guide system. Instead, they may instruct the dog to ""Follow"" you. (Since experience with this command varies, so does the quality of the team\'s performance.) If this is the case, walk ahead of them at a normal speed letting the person know when they are approaching turns, doorways, stairs, and drop-offs. If the person is seeking assistance for a street crossing, walk with them completely across the street and up on the opposite curb. The dog guide will again resume its duties once on the sidewalk.\nThe most common mistake many people make is touching, calling, clicking, or whistling to a working dog. Absolutely Do Not pet or distract a dog guide when it is in harness or when working. Always interact with the person and not the dog.\nMoving around in their environment presents some problems for deaf and hearing-impaired people. Sounds and movements out of their field of vision can create hazards. They may not be aware of traffic and emergency vehicles approaching from behind. Hearing aids will amplify these sounds, but direction may be difficult due to distortion.\nTools & Technology - Enhancing quality of life\nMany of the chores and routine tasks associated with daily living can be frustrating to individuals with disabilities. Thankfully, specialized tools, equipment, and devices have been developed to help alleviate this frustration and enhance the quality of life with increased independence. Local agencies, rehabilitation centers, and libraries are excellent sources for more information. However, one of our best resources is the Internet. Online catalogues provide details about each item in stock while explaining its function.\nWhen we think of a person with a mobility impairment most of us immediately envision someone in a wheelchair. For sure, this is the most common, but mobility impairment involves much more than that. While there are many people using wheelchairs or motorized scooters, other impairments may necessitate the use of tools or devices such as crutches, canes, leg braces and/or walkers.\nTechnology is providing assistance in ways other than mobility devices. Some individuals who are unable to manipulate a computer keyboard now rely on voice recognition software to operate personal computers and other tools to make their lives easier and more productive.\nElectronics have opened up a new world of independence for visually impaired people living alone. Talking devices like clocks, thermometers, blood pressure cuffs, and computers have brought blind people into the 21st Century.\nIn fact, computers with screen reading software have opened new areas of employment never considered viable for workers with vision difficulty. Scanners convert printed text into voice output or Braille on a refreshable display. Documents can be printed in text or Braille, or transmitted electronically for co-workers. Surfing the net, reading and writing email, as well as managing personal and business finances are now nearly as easy for the blind as it is for the sighted.\nTo be sure, there are many challenges. Yet, progressive minded technicians are moving forward with improvements at a rapid rate. Micrometers, levels, and tape measures are available which emit electronic tones or have tactile markings. With specialized training, workers who are blind operate equipment like table saws, stamping machines, and manufacturing tools. Unfortunately, not enough of these individuals are working in mainstream jobs usually due to unfounded fears over safety issues.\nFrequently, people think a hearing aid is a ""cure-all"". It is not. These devices do not function like normal hearing. Rather, they amplify sounds. A hearing aid mainly helps to make speech clearer and understandable at a shorter range. This will help avoid raising your voice while communicating. Unfortunately, background noises are more amplified and cause more distraction than it would to a person with normal hearing. Amplification devices are available for Telephones & other office equipment. TDD equipment allows total deaf individuals the ability to communicate via the telephone. Lights can be installed on devices to signal when a tone is present. Examples might be alarm clocks, doorbells, and telephones.\nIt is incumbent upon us to adhere to and follow the simple rules and guidelines presented here. Remember, people with disabilities are people just like you. They don\'t want pity or condescending treatment. Their sense of smell, touch, or hearing did not improve when they lost their vision. They simply rely on them more and may get more information through those senses than you do.\nThe development of specialized tools and devices has opened up a new world of independent living for people with mobility, vision, and hearing impairments. Simple jobs and ordinary task no longer require an assistant. Electronic devices and computers have broaden employment opportunities and enhanced quality of life for many.\nIt is important for you to know the correct procedure to offer assistance while not interfering with their independence.\nFinally, remember that while individuals with disabilities appreciate attention the way we all do, he or she wants their friends, and others, to act natural with them and not overly solicitous. Most will discuss their disability with you if you\'re curious, but it\'s an old story to them. They have as many other interests as you do.\nCopyright 2001 www.DrivingVision.com"">http://www.DrivingVision.com - All Rights Reserved\nIn 1972, Larry C. Colbert\'s life changed suddenly and dramatically. He was diagnosed with retinitus pigmentosa, a degenerative eye disease, and learned he would soon be blind. But, as Larry\'s eyesight gradually faded, his insight deepened. Now he\'s a motivational speaker who travels the world sharing humorous stories about dealing with change, overcoming adversity, and promoting diversity.\nIn his first book, ""Insights from an out-of-sight guy"", Colbert shares the poignant story of his deep personal struggle with blindness, and the fear that kept him from embracing change. With remarkably frank dialog, and powerful and humorous examples from the best of his keynote speeches, Insights reveals Colbert\'s intimate 30-year process of coming to ""see"" self, and provides practical and meaningful help for learning to cope with constant change, as well as managing the ideas, emotions, and attitudes that affect us all.\nWarning: fopen(https://www.realwire.com/rss/?id=488&row=&view=Synopsis) [function.fopen]: failed to open stream: HTTP request failed! HTTP/1.1 400 Bad Request\nin /var/www/sidrac.com/lincolnhsbrooklyn.com/inc/rss.inc on line 81\ncould not open XML input']"	['<urn:uuid:fdffcf65-c5c9-415c-8852-760873c70af4>']	factoid	direct	concise-and-natural	similar-to-document	single-doc	novice	2025-05-13T03:20:41.944655	8	33	2516
25	plywood poplar mdf water resistance compare	Plywood and MDF have different properties when it comes to water resistance. Plywood is naturally resistant to moisture, though it can get heavy and suffer permanent damage when exposed to water over time, such as from leaks. MDF, on the other hand, can swell when exposed to water, which is particularly problematic in kitchens where water exposure is common. As for poplar plywood specifically, untreated poplar is not rot-resistant and requires treatment for any applications where it might be exposed to moisture or elements.	['There are several choices when it comes to materials, with differences in price, durability, density and other features. The grain and colour will have a big impact on the final product. Since you are making custom cabinets, you can even use some materials for certain parts and different materials for others. The right choices will give you long lasting cabinets that look like a million bucks.\nDifferent Kinds of Wood\nEspecially if you want people to see the natural wood, you can choose a wood that looks right and has the right qualities for your ideal kitchen.\n- Maple — This kind of wood is popular because it’s light, easy to stain and looks smooth. Its consistency alone makes it a great choice.\n- Cherry — Known for its durability and strength, cherry can stand up to most normal household abuse. It’s also a really pretty colour, light red or brown, though it tends to darken over time.\n- Ash — Often known as the material used for baseball bats and tool handles, ash has a clean, even look and can provide a unique, modern look.\n- Pine — This is a softwood, so it isn’t as durable, and you will be able to see the knots in the wood. However, you may choose it because of the distinctive, old-fashioned look.\n- Birch — Extremely durable and beautiful, birch is smooth and if you stain it right, it looks really expensive.\n- Oak — White oak is stronger and more old-fashioned looking, while red oak is more versatile and traditional looking.\nThis kind of material can be made from cedar, spruce, fir, pine, or redwood, so there is potentially a wide variety to choose from. It can be thick, thin, flexible, and can even vary as far as the kinds of adhesives used, some of which have different properties like a greater resistance to heat and humidity.\nPlywood is a popular choice because of its low cost, but it has several other natural advantages too. The material is naturally resistant to moisture and has greater stability than some other kinds of wood. Plywood is actually made of multiple layers of wood veneer glued and pressed together. Plywood is often more stable because of its ability to hold fasteners, like screws and bolts.\nWhile its layered design gives plywood a surprising amount of strength and flexibility, it does have its disadvantages. The layers can make it difficult to cut, and the edges can get splinters. Plywood can get heavy when exposed to moisture, especially when the exposure happens over time like with a leak. That can lead to permanent damage.\nMedium Density Fiberboard\nMade by breaking down hardwood or softwood residuals into wood fibres, Medium Density Fiberboard is then combined with wax and a resin binder to make the final product. This is formed into panels which can then be used for your construction projects. If it was low density it would be particle board, which shouldn’t be used for the main parts of the cabinets because it isn’t very strong but can be used for the outsides to save money. High density is strong but can be expensive.\nMedium Density Fiberboard often referred to as MDF, is dense and heavy. MDF is often used in popular products like IKEA furniture because it is smoother than plywood and resistant to cracking and peeling. That means you can paint over the colour easily when you want to update your kitchen. MDF won’t expand and contract with heat because it’s not made of solid wood.\nMDF can be hard to repair, even if you are just dealing with something small like a chip or crack. Water can make MDF swell, and kitchens are places with lots of exposures to water. There is no grain on MDF because of the way it is made, but you can cover it with veneer to get the texture and look you need.\nMost people don’t think of stainless steel first when designing new kitchen cabinets, but it is a popular option for people who want the kitchen to have a modern, contemporary look. You’ve probably seen this style on television if you watch cooking shows because some professionals choose stainless steel for their cabinets.\nThe most obvious reason to build stainless steel cabinets is that you can match them to your appliances. It would also be hard to find another material stronger than stainless steel, making them more durable than other materials. If you use it just in certain places, you can take advantage of its properties; for instance, stainless steel countertops will be durable and heat resistant. You can take a pot off the stove and place it directly on the stainless steel countertop without harming it.\nWith the great look and shiny surfaces comes the obvious problem of fingerprints and smudges. If you want an immaculate kitchen, you will find yourself constantly wiping down the surfaces. Also on the cosmetic side, if you overuse the stainless steel, your kitchen will look more like a factory than a home kitchen. The surface itself can be noisy and easy to scratch, and the material itself may be costly.\nThe Choice is Yours\nWhen it comes to building your own custom cabinets, you don’t just have a lot of choices; you can make multiple choices. You can choose the material you think is the prettiest, or the least expensive, or the strongest, and you can use different kinds of materials for different parts of the project. And to make it even harder to choose, you can always replace all or part of it later.', 'Renowned for its durability as well as its bending strength, poplar plywood comes in a variety of grades and thicknesses suitable for interior and exterior applications. In this article, we answer all the most common questions about this versatile forestry product, from “What is poplar plywood used for,” to in-depth queries about poplar vs. Luan. Let’s get started!\nPoplar Plywood Features\nThere are a variety of poplar plywood products available. Fine Italian poplar plywood, for example, is often sold in thin sheets that are suitable for laser cutting. White poplar plywood and black poplar plywood come in a variety of grades for projects such as cabinetry, furniture, and outdoor projects. It’s worth noting that plywood marketed as yellow poplar is actually sourced from a magnolia species – but like its cousins, it offers some desirable features.\nIn general, poplar plywood offers pale coloration, tight, beautiful grain, and a wonderfully consistent appearance with minor pin knots visible. In AB grade poplar plywood, these pin knots typically measure a few millimeters in diameter. Barely visible, they do not detract from to the wood’s naturally pleasing aesthetic. The surface of course depends on grade, so it’s a good idea to check the manufacturer’s details while deciding which poplar plywood weight and type is best for the project at hand.\nPoplar vs. Birch Plywood\nWhen comparing poplar plywood vs birch plywood, it’s important to consider grade first and foremost. Both products are versatile, and both come in a variety of different thicknesses to satisfy the needs of model builders, contractors, and furniture makers alike.\nColor Variation: Poplar typically displays less color variation than birch.\nKnot Size: Poplar typically displays smaller knots than birch.\nQuality: Overall, poplar plywood quality and birch plywood quality vary widely depending on the source, the manufacturer, and the grade. It’s a good idea to weigh your options carefully when deciding on the best plywood for your project as no two products are exactly alike.\nHardness: Birch plywood is harder than poplar plywood.\nPoplar Plywood Uses\nWhat can you use poplar wood for? As it turns out, there are many poplar plywood applications. As you decide whether poplar is the best plywood for your project, ensure that you select treated wood for exterior applications. Untreated poplar is not rot-resistant, and it will not stand up to the demands of exposure to the elements.\nBecause poplar’s color is pale and its grain is fine and even, it can be finished to mimic the look of costlier woods this makes poplar plywood a cost-conscious and attractive choice cabinetry. If, for example, you’d like to construct cherry or maple cabinets for your kitchen but you find the cost of hardwood prohibitive, you can easily build cabinets with poplar plywood and stain them to give the appearance of cherry or maple. While it’s not as hard as actual hardwood, it is strong enough to provide a durable finished product that also happens to look fantastic while helping homeowners and contractors stick to their projects’ budgets.\nYou might be wondering if you can build furniture with poplar plywood. The answer depends on the finish you’d like to have. Because birch is harder, it’s a better choice for projects you intend to stain. If you intend to paint your furniture with good oil-based paint, then poplar plywood is likely to work well for your project. Oil-based paint does a good job of strengthening poplar so that it resists common flaws like scratching and denting.\nIf you’re looking for a cheap trim product, you may want to consider poplar plywood. Again, this works best if the plywood is painted with oil-based paint. Poplar plywood trim is best for areas that receive low to no impacts – think crown molding and other out-of-the-way applications.\nWhere to buy Poplar Plywood\nDepending on your region, you may be able to find poplar plywood at home improvement stores. While there are exceptions, these large retailers tend to offer good prices on bulk poplar plywood. Quality does depend on grade – the higher the grade, the better product you will receive. There are certainly exceptions but in general, better quality poplar plywood can usually be found at specialty stores, including online sources.\nPoplar Plywood FAQs, Plus Answers to Questions About Whitewood & Blondewood\nReady for more poplar plywood info? You’ve come to the right place.\nQ: Is poplar a hardwood or a softwood?\nA: Poplar plywood may be classified as both hardwood and softwood, depending on the species and the manufacturer’s literature. It’s the hardest of all “soft” woods, including pine and birch. Both classifications are considered to be correct.\nQ: What is poplar plywood weight?\nA: The weight of poplar plywood may vary greatly depending on the specific product in question. Overall, poplar plywood’s weight includes the weight of the wood itself, the weight of any moisture in the wood, and the weight of the adhesive that holds the layers of wood together.\nQ: What is blondewood plywood?\nA: Blondwood plywood is a nickname or marketing term that is used for light-colored plywood. You may hear poplar plywood being referred to as blondewood. It’s a good idea to check for specific content before purchasing plywood labeled as “blondewood.”\nQ: What is whitewood plywood?\nA: Just like blondewood, whitewood is a term that describes color rather than content. There are many different types of wood that can be described as whitewood, including poplar, cottonwood, pine, lodgepole, and spruce.\nQ: What is luan plywood? Is it poplar?\nA: Luan is a thin plywood made with luan or lauan hardwood, which comes from a tropical tree that grows in the Philippines. Hobbyists often ask about the differences between luan and poplar for model building. Both materials are soft and light. Both are strong, but not quite as strong as birch plywood when it comes to model airplane crash survival.\nQ: What is furniture grade plywood?\nA: You may be wondering whether all poplar plywood is furniture grade. The short answer is “no.” Furniture grade plywood isn’t a specific species – instead, it is grade A plywood of any species (including poplar) with minimal knots, gaps, patches, and other inconsistencies. Grade A poplar plywood is good for building furniture and cabinets.']	['<urn:uuid:c01c79ad-475b-41cf-b465-196043104224>', '<urn:uuid:92b3c800-60da-4631-a1b7-4076e8a4f750>']	open-ended	direct	short-search-query	distant-from-document	comparison	novice	2025-05-13T03:20:41.944655	6	84	1971
26	What features help with long-duration monitoring, and how to prevent being monitored?	For long-duration monitoring, dual eyepiece configuration reduces eye fatigue by allowing natural two-channel visual processing, while variable interpupillary distance (56-71mm) and rechargeable batteries providing up to 8 hours of operation enhance comfort. To prevent being monitored, experts recommend shielding paperwork or keypads from view using your body or cupping your hand, being cognizant of your environment, and stopping typing immediately if someone is watching your confidential information.	['How can shoulder surfing be prevented?\nShoulder surfing is using direct observation techniques, such as looking over someone’s shoulder, to get information. … To prevent shoulder surfing, experts recommend that you shield paperwork or your keypad from view by using your body or cupping your hand.\nWhat is a defense against shoulder surfing?\nNowadays, to defend against shoulder surfing attacks, one must be cognizant of their environment at all times. Threat actors don’t just shoulder surf by standing behind you at an ATM, but also use video cameras, binoculars, and other image magnification methods.\nWhich of the following is the best description of shoulder surfing?\nShoulder surfing occurs when someone watches over your shoulder to nab valuable information such as your password, ATM PIN, or credit card number, as you key it into an electronic device. When the snoop uses your information for financial gain, the activity becomes identity theft.\nWhich scenario is an example of shoulder surfing?\nSome scenarios where shoulder surfing may occur are: Entering your PIN at the cash point or ATM. Using your credit or debit card to pay for an in-store transaction. Logging onto a banking application or website, either on the laptop or your mobile device, using your username and password.\nWhat is your response if someone is watching your password behind your shoulder while you are typing it?\nOptions: I Quit typing as soon as you notice the situation. I Proceed typing as fast as you could finish it. I would Tell the person to leave immediately.\nFive Ways to Protect Yourself:\n- Delete any request for personal information or passwords. Nobody should be contacting you for your personal information via email unsolicitedly. …\n- Reject requests for help or offers of help. …\n- Set your spam filters to high. …\n- Secure your devices. …\n- Always be mindful of risks.\nWhat is the difference between tailgating and shoulder surfing?\nWhat is the difference between tailgating and shoulder surfing? Tailgating means following someone else through a door or gateway to enter premises without authorization. Shoulder surfing means observing someone type a PIN or password or other confidential data.\nHow common is shoulder surfing?\nShoulder surfing happens to a substantial amount of people even if it’s not for malicious purposes. A recent study found that 73% of survey respondents indicated they had seen someone else’s confidential PIN without them knowing. Shoulder surfing can happen anywhere, especially at ATMs and kiosks.\nShoulder surfing is actually a form of social engineering. It basically means an unauthorized third party is able to view a screen and any confidential data displayed on an electronic device. … Also, shoulder surfing risk is not limited to public environments.\nWhat is the possible defense against dumpster diving?\nTo prevent dumpster divers from learning anything valuable from trash, experts recommend that businesses establish a disposal policy where all paper — including printouts — is shredded in a cross-cut shredder before being recycled, all storage media is erased and all staff is educated about the danger of untracked …\nWhat is spear phishing attempt?\nSpear phishing is a phishing method that targets specific individuals or groups within an organization. … While phishing tactics may rely on shotgun methods that deliver mass emails to random individuals, spear phishing focuses on specific targets and involve prior research.\nWhere should I save my passwords?\nStore it in your wallet, or in an unmarked folder in your filing cabinet. You might want to consider keeping two different piece of paper: one at home that has every password, and a second one in your wallet that just has the passwords you need every day.', 'ACCOLADE thermal imaging binoculars are designed for various areas of application including night hunting, observation, trail orienteering, rescue operations etc.\nHigh display resolution\nThe high 640x480 pixel resolution ensures all objects within the field of view have the highest level of detail. High resolution makes the smallest objects, i.e. branches, leaves, body extremities of an animal, appear exceptionally crisp and clear against the background.\nLong detection distance\nDetecting object at long distances are an important feature for optics users in outdoor environments. Optic quality and the best thermal imaging sensor available make a unique combination designed to deliver the longest detection range possible.\nSmooth and incremental digital zoom\nIncremental zoom is a perfect solution to quick, on-the-fly zooming. When time is not a limiting factor but slight details are, the device’s smooth zoom is the better option.\nComfortable for long observation\nThe dual eyepiece configuration reduces eye fatigue during longer viewing and enhances the natural look of objects. The human brain is pre-conditioned to receive visual information from two channels simultaneously. The brain then combines the information into a single image. When one eye is used to observe, the brain only receives information a single input. The increased effort from the brain to override the standard algorithm of visual perception can quickly lead to the observer feeling fatigued and uncomfortable.\nVariable interpupillary distance\nThe ability to adjust the distance between eyepieces allows the user to best position the optic for individual needs. Interpupillary distance differs from person to person. Adjusting for individual fit dramatically improves viewing comfort and quality, and eliminates the potential for double-imaging.\nHigh refresh rate 50 Hz\nHigh Image frequency is important when shooting at moving targets. A high refresh rates ensures motion is fluid and in real-time, allowing more accurate speed assessment and shot placement.\nBuilt-in video recorder\nThe Built-in video recorder is a great asset when it comes to filming or taking photos of once-in-a-lifetime experiences. One press of the REC button captures footage that can be shared easily with colleagues, friends and family\nLive internet video sharing\nConnecting the device with a smartphone or tablet allows a user to access the internet and live-stream video directly to YouTube.\nFrost resistant AMOLED display\nThe device is designed for flawless operation in extreme weather and temperature conditions. Whether the environment is freezing cold or blistering hot, the image retains its contrast and vivid colors without loss of frame rate. The high-contrast, color AMOLED display uses top technology to ensure stable, high-quality imaging in virtually any weather conditions.\nThe stadiametric rangefinder helps to estimate range to an object based on its size. The device’s advanced, proprietary, rangefinding interface provides important ranging information within seconds.\nQuick-change long-life rechargeable battery packs\nThe device’s innovative battery-release mechanism ensures fast, flawless battery changes. Rechargeable IPS5 battery packs provide up to 8 hours of continuous operation in Wi-Fi mode.\nFully waterproof IPX7\nRain, snow, fog, high waves or waterways, the IPX7 waterproof rating ensures the device won’t fail in even the toughest wet weather conditions. The IPX7 rating means the device has been manufactured and rigorously tested to withstand extreme natural weather conditions, even submersion to a depth of 1 meter for up to 30 minutes.\nPicture-in-Picture provides a second, magnified reticle-area image to help the observer see magnified target details without loss of the field of view.\nThe 8-color palette enhances viewing in varying conditions. While the classic “White Hot” mode is exceptionally versatile, “Hot Black” is often favored for detecting wildlife at night. Red monochrome helps to reduce or prevent bright backlight from exiting the eyepiece. Sepia often improves long-range observation while “Red Hot”, “Rainbow” and “Ultramarine” enhance temperature differences of various object attributes. Violet helps to identify objects faster.\nFrame Rate, 50 Hz\nMicrobolometer resolution, 640x480 pixels\nPixel Pitch, 17 µm\nDisplay type AMOLED\nDisplay Resolution, 640x480 pixels\nBuilt-In Video Recorder Availability yes\nBuilt-In Memory, 8 Gb\nFormat of video clip .avi\nResolution of video clip 640x480 pixels\nFormat of photo files .jpg\nResolution of photo files 640x480 pixels\nUSB, type microUSB\nOperation modes 3\nIntegrated Wi-Fi module yes\nMagnification, 2.5 x\nDigital zoom, 2x; 4x; 8x\nObjective Lens F50/1.2\nExit pupil, 5 mm\nInterpupillary distance adjustment, 56-71 mm\nDiopter adjustment, dptr. ± 5\nClose-up distance, m 3\nRange of Detection, m\nRange of detection, (object high*width = 1,7*0,5m) 1800 m\nPower Supply, 3.0 - 4.2 V\nBattery type B-Pack (Li-ion)\nBattery Life, 7 hours\nExternal Power Supply 5V - USB\nPhysical & operational characteristics\nOperating Temperature, - 25 … +50 °С\nLevel of Protection (acc. to IEC 60529) IPX7\nDimensions, 164x130x64 mm\nWeight (without batteries), 0.6 kg']	['<urn:uuid:ab7ed661-e15a-43f4-903a-e52727a33ee4>', '<urn:uuid:84224683-8673-4203-aed3-c1f17f19e50e>']	open-ended	with-premise	concise-and-natural	similar-to-document	multi-aspect	expert	2025-05-13T03:20:41.944655	12	67	1377
27	I'm interested in coastal cities and their development. What are the economic activities that make coastal regions attractive for development, and what environmental challenges do these activities create?	Coastal regions are attractive for various economic activities including fisheries, aquaculture, coastal tourism, marine transport, and activities based on marine sciences and maritime technologies. However, these development-related activities threaten almost 50% of the world's coasts. The environmental challenges include municipal, industrial and agricultural wastes affecting marine environments, impacts on water quality, physical alterations to the coastal zone, and negative effects on coastal biodiversity.	"['Looking for the Core of a Knowledge-based Sea Cluster: A Social Network Analysis in a Maritime Region\nFor more than two decades cluster policies have emerged as a central focus for decision-makers trying to instigate territorial development. The benefits, especially in terms of collective learning, knowledge sharing and other types of agglomeration economies and spill-over effects, are well stressed in the regional science literature. Today the relevance of maritime activities and marine resources to economic development is acknowledged. For several European countries, the Atlantic Ocean is part of their common history, identity and potential for developing advanced economic niches of excellence. There is no surprise that several regions are trying to implement their development strategies based on a broad Sea Cluster notion that encompasses a diversity of economic activities such as fisheries and aquaculture, coastal tourism, marine transports and activities based on marine sciences and maritime technologies. Based on the results of a trans-regional evaluation performed for the Atlantic Area under project KIMERAA, this paper evaluates the consolidation of the Sea Cluster in the Algarve, a Portuguese region internationally known by its coastal tourism. The region has also been experiencing a growing capacity in economic activities linked to marine sciences. This regional cluster did not emerge spontaneously and there are several initiatives to promote it. Interviews to regional actors showed light on two important issues. i) Which organization should be the main mediator to bridge science to market? ii) Who is the actor that is in a better position to assume a pivotal role in the formal consolidation of the cluster? Using social network analysis the main knowledge transfer mediator and the central actors are identified. Their roles and specific policy implications are underlined.\n|Date of creation:||Sep 2011|\n|Date of revision:|\n|Contact details of provider:|| Postal: Welthandelsplatz 1, 1020 Vienna, Austria|\nWeb page: http://www.ersa.org\nPlease report citation or reference errors to , or , if you are the registered author of the cited work, log in to your RePEc Author Service profile, click on ""citations"" and make appropriate adjustments.:\n- Michael Fritsch & Martina Kauffeld-Monz, 2010.\n""The impact of network structure on knowledge transfer: an application of social network analysis in the context of regional innovation networks,""\nThe Annals of Regional Science,\nSpringer;Western Regional Science Association, vol. 44(1), pages 21-38, February.\n- Michael Fritsch & Martina Kauffeld-Monz, 2008. ""The impact of network structure on knowledge transfer: An application of social network analysis in the context of regional innovation networks,"" Jena Economic Research Papers 2008-036, Friedrich-Schiller-University Jena.\n- Andre Torre & Alain Rallet, 2005. ""Proximity and Localization,"" Regional Studies, Taylor & Francis Journals, vol. 39(1), pages 47-59.\n- Doloreux, David & Shearmur, Richard, 2009. ""Maritime clusters in diverse regional contexts: The case of Canada,"" Marine Policy, Elsevier, vol. 33(3), pages 520-527, May.\n- Michael Porter, 2003. ""The Economic Performance of Regions,"" Regional Studies, Taylor & Francis Journals, vol. 37(6-7), pages 549-578.\n- Anne Ter Wal & Ron Boschma, 2009. ""Applying social network analysis in economic geography: framing some key analytic issues,"" The Annals of Regional Science, Springer;Western Regional Science Association, vol. 43(3), pages 739-756, September.\nWhen requesting a correction, please mention this item\'s handle: RePEc:wiw:wiwrsa:ersa11p510. See general information about how to correct material in RePEc.\nFor technical questions regarding this item, or to correct its authors, title, abstract, bibliographic or download information, contact: (Gunther Maier)\nIf references are entirely missing, you can add them using this form.', 'Throughout history, people have settled on coasts to take advantage of the amenities the oceans offer – a food supply, a source of transport, a defensible position and a healthy location. However, as coastal cities grow, they become detached from their environmental surroundings, while still requiring services from their local ecosystem. The demands placed on the host ecosystem threaten the viability of the cities themselves. Today, it is estimated that almost 50 per cent of the world’s coasts are threatened by development-related activities. Municipal, industrial and agricultural wastes and run-off, as well as atmospheric deposition, affect the most productive areas of the marine environment, including estuaries and near-shore coastal waters. Physical alterations to the coastal zone also threaten the marine environment .\nCharacteristics of coastal cities\nThe urbanization of coastal zones has divided them into two main categories: Coastal areas characterized by high density of land uses and those with low building and population density. Their main difference lies in their economic performance. A new urban sprawl is normally developed, spatially following in a linear direction from the coast. This phenomenon is a direct effect of the improvement of transport systems, the increase of living standards and the importance of tourist activities and has led to negative effects on coastal biodiversity, a steady increase on demands for water resources and an increase of waste production and pollution . Urban sprawl has also negatively affected the urban coast’s quality of life, creating a population density that leads to problems concerning employment and exploitation of natural resources .\nMain characteristics of coastal cities include:\n- Tourist services\n- A street pattern related to the landform and the surrounding natural features\n- A direct relationship to the foreshore and a wide choice of uses associated with the coastal edge\n- An extensive range of edge conditions, such as parks, beaches and waterfront promenades\n- A range of smaller suburbs and suburban centers surrounding the city centre\n- A full range of residential building types\n- A full range of building heights from low scale to tall \nCoastal Management and Urban Planning\nCoastal management and urban planning seem to act in different contexts without a common ground for an integrated perspective of coastal cities. In particular, urban planning often ignores environmental issues that characterize a coastal ecosystem, creating land use conflicts and environmental aggravations. It is essential for an urban coast to offer a good quality environment for the users avoiding issues such us:\n- Destroying the quality of coastal resources that offer the city its distinct characteristics\n- Impacts on water quality\n- Decrease of opportunities for new urban infrastructure\n- Degraded public spaces\n- Privatization of open spaces and foreshores\n- Lack of planning integration .\nCities in coastal areas require a special interest as they constitute important growth poles and gates to the hinterland as well as centers of economic growth involving human activities such as tourism, transport and fishing and sensitive environments and ecosystems .\nThe problems that coastal cities have to face might appear similar to the ones that most cities are also trying to overcome. The elements that make coastal cities different are:\n- The complexity of the activities that constitute a coastal city coming from the hinterland, creating (most often) conflicts and influencing their economy in a local and supra local level\n- The planning issues of coastal cities that involve a more integrated approach between urban planning and environmental management (coastal management) .\nBy including coastal zone issues in the city’s development plans, an integrated approach could be generated taking into account all the essential matters for the achievement of effective policies for both coastal/marine and urban activities. For example, the joint UN-HABITAT/UNEP Sustainable Cities Programme (SCP) provides support to many coastal cities world wide in their efforts to integrate coastal management into city development strategies .\nBest practices for coastal cities\n- Protecting the most attractive quality elements of a coastal city\n- Optimizing the efficient land use to minimize impacts on the surrounding urban and natural environment\n- Maintaining the natural geography of the coast\n- Maintaining the coast in connection to the inland (perhaps the city centre)-(best access to the coast, quality of streets etc.)\n- Protecting coastal waters through modern ecological methods\n- Providing sustainable transport systems \n- Regulations governing the industrial, municipal and agricultural pollution \n- Preserving the historic and cultural resources through the process of waterfront/urban regeneration \n- Planning for the waterfront considering it as a part of a coastal (eco)system\n- Optimizing coastal cities as a separate entity of the region that requires a more complex approach, including environmental policies/aspects\nCoastal Cities Challenges\n- Increase in population. Sixty percent of the world’s population already lives in coastal areas, while 65 percent of cities with populations above 2.5 million are located along the world coasts\n- Seaward widening of the waterfront. Recent experience has proved that even artificial islands hosting human activities can be built out of nothing\n- Changes in waterfronts (regeneration) could lead to upgrading ports and coastal areas and reduce or enlarge the range of economic inter-regional and international relationships of the city port \n- Confrontation of service issues (e.g. transportation)\n- Predictions about natural risks\n- Urban sprawl control/restrictions\n- Integration of urban planning with the concept of Sustainable Development\n- Integration of urban planning with Integrated Coastal Zone Management (ICZM)\n- Co-operation between private and public sector\n- Protection of ‘hot spots’\n- Protection of coastal resources \n- Innovative approaches to existing policy areas\n- Laboratory of Environment and Spatial Planning (2005)Towards an Urban Regeneration Policy in Coastal Mediterranean Cities, University of Thessaly-General Secretariat for Research and Technology, Ministry of Development, 23-5\n- Laboratory of Environment and Spatial Planning (2005)Towards an Urban Regeneration Policy in Coastal Mediterranean Cities, University of Thessaly-General Secretariat for Research and Technology, Ministry of Development, 28\n- Ministry of Physical Planning, Environment and Public Works (2003) Planning for Coastal Areas and Cities in Europe, International High-level Conference, Hellenic Presidency of the European Union, Hersonissos, Crete-Greece\n- Nanouri E. (2003) Coastal areas and cities- A Common Approach of the UDG Members Initiated by the Greek Presidency, Ministry of Physical Planning, Environment and Public Works, Hellenic Presidency of the European Union\n- Vallega A. (2001) Urban Waterfront Facing Integrated Coastal Management, Ocean and Coastal Management, 44, pp.399\n- Vallega A. (2001) Urban Waterfront Facing Integrated Coastal Management, Ocean and Coastal Management, 44, pp.398-400\n- Laboratory of Environment and Spatial Planning (2005)Towards an Urban Regeneration Policy in Coastal Mediterranean Cities, University of Thessaly-General Secretariat for Research and Technology, Ministry of Development, 30-1\nPlease note that others may also have edited the contents of this article.']"	['<urn:uuid:56238ae3-6782-4a4c-9a68-ba394d694ad9>', '<urn:uuid:2ec9eca6-a25e-44aa-8b50-ed4aae1a78ca>']	factoid	with-premise	verbose-and-natural	similar-to-document	multi-aspect	novice	2025-05-13T03:20:41.944655	28	63	1677
28	Looking for a lighter wood for my custom guitar, what properties does swamp ash have?	Swamp ash is a light-weight wood with large open pores, making it resonant and sweet sounding. It offers great highs, solid well-defined midrange, and a strong low end. The wood has beautiful grain patterns perfect for transparent or lightly colored finishes. Its sound is articulate, with a great balance between brightness and warmth. Due to its open grain and varied grain structure, two swamp ash bodies may differ tonally from each other. It's commonly used in guitar bodies and is often constructed by gluing two or three pieces together, though single-piece bodies are also available.	['Many different woods are used in building electric guitars. We discuss what you need to know here.\nWhen you’re studying the specs of an electric guitar or bass, you will almost certainly see the kind of body wood, neck wood, and fingerboard wood used. With some very notable exceptions, just a few mainstay woods have been used for fashioning electric instruments: for bodies, primarily alder and ash in the Fender world, and mahogany and maple in the Gibson world; for necks, primarily maple necks with maple or rosewood fingerboards (in the Fender world), and mahogany necks with rosewood fingerboards in the Gibson world. We will discuss these woods in depth.\nLike alder, swamp ash is a classic solid body guitar wood.\nThere are many kinds of ash trees. For use in electric guitar bodies, the American ash species – Fraxinus Americana – is the one in prominent use. American Ash is a native North American hardwood found on the eastern half of the continent. The wood is strong, dense, straight-grained and light in color. In addition to guitar bodies, ash is used for flooring, furniture, baseball bats, and many other items.\nFor guitar bodies, two sub species are used: northern ash and southern or “swamp” ash.\nNorthern ash is harder and heavier. As a guitar body, it produces more treble and sustain, with less warmth than other guitar woods. In some cases it makes for bodies that are quite heavy! These bodies have a brighter sound that might be more useful when sharper tones are desired.\nSwamp ash is lighter in weight. Typically, the wood is taken from the lower portions of wetland trees that have root systems below water level. The wood has beautiful grain that is perfect for transparent or lightly colored finishes that let the wood grain show through. The wood is light in color, highlighted by brown grain patterns. This wood looks awesome with natural finishes and transparent colors.\nSwamp ash wood has large open pores, making it resonant and sweet sounding, with great highs, solid well-defined midrange, and a strong low end. Swamp ash sound is articulate, with a great balance between brightness and warmth. In contrast to alder’s even and consistent tonal properties due to its tight, consistent grain, the open grain and varied grain structure of swamp ash means that two swamp ash bodies may differ from one another tonally.\nSwamp ash is often used for guitar bodies for its sonic characteristics and for its light weight. For these reasons, it is more commonly used than any other ash species. Often, two or three pieces are glued together to make an instrument body, although there are single-piece bodies (we offer them at Alloy Guitars!).\nBasswood is affordable and abundant. It has become particularly associated with mid- or budget-level guitars. Basswood was particularly popular in the 1980s. Basswood is a good tonewood and many guitar makers have had excellent results using it. It is a very light and soft wood, and it is light in color. It has minimal grain. Solid basswood bodies have a fat, well-balanced tone. There’s a muscular midrange. On a well-made guitar, basswood can yield good tone and dynamics, with good definition. It may be less expensive than its big brothers (alder and ash), but that doesn’t mean that it shouldn’t see more use!\nMahogany is a wood that became popular primarily in the electric guitar world due to being used on Gibson guitars since the 1950s. (It is also used heavily in acoustic instruments.)\nThere are many species of tree that are called “mahogany” (some accurately, some not so much). Typically, in guitar construction, mahogany means Central American Honduran mahogany or African mahogany.\nMahogany is a dense, medium weight wood that yields a wide range of guitar body weights, depending upon the source of the wood. Medium brown in color with a red or orange hue, this mid weight wood has a mild grain pattern that looks great with many transparent finishes.\nMahogany’s tone is warm and a bit soft, but overall is well balanced. There is usually good depth to the sound, with full but not especially tight lows, and appealing if unpronounced highs. Its tone is thick and concentrated with a forceful midrange.\nMahogany is a classic ingredient in slab, carved top, and laminated bodies. It is also a common neck wood (see below). Mahogany is used in single-wood bodies, too. Gibson Les Paul Jr., Les Paul Special, and SG were made of solid mahogany, and guitar builders have used the wood in many solid and semi-solid designs over the years.\nMahogany with Maple. This is the most popular laminated or carved-top body type. Adding a maple top to a solid mahogany back yields a guitar body that exhibits many of the best tonal properties of both woods. The mahogany and maple body is rich, warm, and resonant with mahogany’s lows and good sustain, augmented by the maple top’s clarity and definition.\nLESS COMMON WOODS\nPine, particularly knotty pine, can make for dramatic looking guitars. Fender has made knotty pine Telecasters on occasion and they are striking.\nThese heavier woods have been successfully used in some guitars. They make for interesting looking instruments. Generally, these woods are not used alone in a guitar body due to the weight of the resulting body. Some interesting instruments include those made from oak barrels.\nSPRUCE, CEDAR, REDWOOD\nThese woods can make for some very beautiful bodies! These are not used regularly, however.\nA large variety of exotic woods are used either alone or in combination to produce striking results. Koa, Tigerwood, Zebrawood, Teak, Purpleheart, Limba and many other woods are used as accent or top material on many custom or designer guitars.\nNECK AND FINGERBOARD WOODS\nNecks are usually composed of two parts – the neck proper and the fingerboard – that may be the same or different woods. In many cases, the neck and fingerboard will be different pieces of wood, even if they are the same species. However, a single piece of wood is used for both the neck and fretboard – these are called “one piece”. Many different woods are used for both parts. We will detail just a few of the common combinations here: maple and mahogany necks, with maple, ebony and rosewood fingerboards.\n|Maple. Maple is often used in Fender and many other manufacturers instruments. In some cases, a solid, one-piece neck with integral fretboard of maple is used. In other cases, the maple neck is topped with a fretboard of a second type of wood (often rosewood). Maple necks add tightness and cutting tones to a guitar. It is a characteristically bright neck wood choice.|\n|Mahogany. Mahogany necks are often coupled with a mahogany or mahogany/maple body, such as on Gibson’s instruments. Mahogany is more porous and open than maple, and does not have maple’s hardness, strength, or stability. Mahogany is not suitable as a fretboard material, so it is generally topped with Ebony or Rosewood.|\n|Ebony. A popular neck upgrade option, the ebony fretboard provides more tightness, clarity, and definition, as compared to rosewood fingerboards. It is a very dense, hard wood, providing for a fast attack from the instrument. It offers a muscular, controlled bass, and snappy, sizzling highs. With a mahogany back contributing some warmth and openness to the brew, this can be a very appealing pairing. Ebony wears well. It doesn’t wear away after years of finger and string contact nearly as easily as rosewood does.|\n|Rosewood. Along with maple, rosewood is the one of the most common fingerboard woods.When paired with a mahogany neck, which has a warm, mellow tone, the rosewood fingerboard contributes to complex highs, thick and creamy lows, and an appealing midrange.\nWhen paired with maple necks, rosewood fretboards change the maple neck’s bright characteristic tonal properties to become a little warmer and sweeter. The maple provides sparkle in the highs with the rosewood mellowing the tone and thickening the lows. In addition to the tonal characteristics that the fingerboard imparts, it also changes the feel of the neck. A player’s choice of a maple fingerboard or rosewood fingerboard may be as much about feel or appearance as it is about tone.']	['<urn:uuid:e9dec11f-70f0-4826-adcd-118399216442>']	open-ended	with-premise	concise-and-natural	distant-from-document	single-doc	expert	2025-05-13T03:20:41.944655	15	95	1366
29	How does the timing of bud break affect frost vulnerability in vineyards, and what recent historical examples demonstrate this risk?	During bud break, young growth is very vulnerable to cold temperatures and frosts. The March 2017 false spring demonstrated this risk when temperatures dropped to 23-28 degrees for 1-3 nights in Maryland, though grapes were fortunately not far enough along to be affected. In the past ten years, the Eastern US has experienced three devastating false springs: 2007, 2012 and 2017.	['Bud break is truly a magical time in the vineyard. It occurs when grapevines that have been dormant all winter long awaken, and the new growth that will become leaves, shoots, and, most important, this year’s grapes, emerge.\nThe specific day that bud break occurs is dependent on the temperatures in the vineyard. Multiple days reaching fifty degrees will get the sap flowing from the roots and truck it up into to the canes (growth from the prior year). On those canes will be little bumps, called nodes. Those nodes will push out and become buds, so the prior year’s growth sets up for the next year’s crop.\nOver the winter, the vineyard staff will do winter pruning and will cut back the canes. In the context of vine maturity, a cane is a mature shoot from last year’s growth that has developed a layer of bark, and no longer has leaves. The vineyard manager and winemaker do not want all the nodes on all the canes to become buds, as it would take too much energy out of the vine, and not produce the best-quality grapes. At the time of pruning, the decision is made on how many canes to leave on each vine, and how many nodes per cane. The numbers vary by vineyard manager, and is based on past experience, the specific grape and how prodigious it is, and the climate in the particular vineyard.\nNow that winter pruning has been completed and the temperature has reached fifty or higher degrees many times, the sap starts flowing into the remaining canes and can be seen at the cut ends as a drop of liquid. This is called “weeping” or “crying.” Following that,, the nodes on the canes will become swollen and become known as buds. Inside that bud are all the structures for that year’s growth. There are different phases to bud development before they burst open, and when it does, it is truly spectacular. You see tiny leaves, shoots, and the flower formations that will become grape clusters.\nIt is during this time that the young growth is quite vulnerable to cold temperatures and frosts. If any of you have been watching the local Virginia news, as well as photos and reports coming out of Chablis, Burgundy, and other winegrowing regions around the world, you know that frosts have been hitting vineyards hard. Last year, we posted a blog about frost and frost mitigation. Late frosts in Virginia have occurred as late as Mother’s Day in past years.\nBarring lost bud growth to frosts, those shoots, leaves, and flower formations will push their way out and open wide. Growth occurs rapidly at this point. Depending on the way the vineyard allows the vines to grow, the shoots may be tucked in between wires. This allows flow of air, which helps reduce molds and mildews on the clusters and warmth from the sun to help ripen the grapes over the next few months.\nLet us all cheer to this magical time in the vineyard, and the birth of the next crop!', 'February 2017 was the second warmest in history—as warm as the average March in our region. Grass greened up, it felt like spring, and many plants started to break dormancy. Everything was great until things went back into the deep freeze from March 20-22, when many locations in Maryland had night temperatures between 23-28 degrees for 1-3 nights. This is what climate scientists call “false spring”—very warm weather that seems like a welcome end to winter, just to be followed by a hard freeze later in March or April. In the past ten years, the Eastern US has experienced three devastating false springs: 2007, 2012 and 2017.\nThe extent of agricultural damage after the freeze during this year’s false spring depends not just on the developmental stage of the crop, but on a number of other factors—when the weather began to warm, how long it stayed warm, whether development was slowed by subsequent cooler weather, how far along crops had gotten by the time the freeze hit, air speed and humidity, how cold it got and for how many days the cold weather lasted. Because these factors can vary widely across a region, it isn’t surprising that the damage seen after the March 2017 freeze depended on location.\nMaryland farmers were lucky—although the earliest blooming fruits like apriums and apricots were heavily damaged in central Maryland, grapes, apples and blueberries were not far enough along to be affected, and strawberries were still weeks from breaking dormancy.\nAt Swann Farm in Calvert Co., it originally appeared that up to 85% of peach blossoms had been lost. However, more extensive sampling of blossoms revealed that early and late blooming peach varieties sustained only 25-50% damage, while the mid-summer varieties were at their most vulnerable at the time of the freeze, and were 100% destroyed for the year. Swann Farms published some useful pictures that show how to determine damage to a blossom by pulling off the damaged bloom to see if there is a tiny peach underneath (see white structure under the word “Peach” in this photo).\nFarmers to the South of us weren’t so lucky. In central Virginia, peaches, nectarines and cherries were damaged, and some plum orchards were lost entirely. Fortunately, most apples bloomed after the freeze, though some crabapples used for pollination of apples were damaged. South Carolina lost 90% of their peach crop, and Georgia peaches and blueberries were severely damaged. Some North Carolina farmers were able to save their strawberries by pulling out the row cover—using two layers in some cases.\nSo, when we get a spring freeze, is it just bad luck we can chalk up to typical weather variability? Maybe not– climate scientists have shown clearly that spring is coming earlier these days. The 2014 National Climate Assessment showed that the Northeast (which includes Maryland in the eyes of climate scientists) now experiences an average of 10 fewer frost free days than we did between 1901-1960. Studies of plant populations show that many plants are blooming earlier in response. Scientists from Cornell showed that apples in upstate New York are blooming an average of 8 days earlier than in the 1960s, while grapes are blooming 6 days earlier. When Smithsonian scientists analyzed 30 years of data on bloom times of common plants in the DC area, they found that 89% are blooming earlier now than in 1970 by an average 4.5 days.\nBy far the most amazing demonstration of earlier blooming is shown in a study of bloom dates of cherry trees in Japan, which have been monitored since 800AD. Despite a lot of noise due to weather variation, the bloom times remained within a fairly narrow window until about 1875, when the trend line shows a sharp decline in flowering date, leaving that historical range. This is just what we would expect if the earlier flowering is a response to global warming, which started during the Industrial Revolution in the mid-1800s.\nHow does the flowering time shift of the cherries in the DC Tidal Basin compare with that seen in Japan? Jason Samenow of the Washington Post’s Capital Weather Gang explored this and found that although the DC trees flower a few days earlier on average than the trees in Japan, both populations have shifted at approximately the same rate. This is good evidence that the cause of the shift is the same in both locations– warmer and earlier springs due to climate change.\nAlthough spring is coming earlier, temperature variability has remained the same or even increased, so those spring freezes we are used to in March and April remain highly probable. Any way you look at it, earlier spring coupled with a continued or even increased probability of March and April frosts means that the threat of freeze damage to spring crops is likely to be a problem that farmers on the East Coast will face more and more often.\nHow can you protect your fruit crops from false spring and damaging late freezes? The experience at Swann Farms illustrates one of the best ways to minimize freeze risk—plant multiple varieties that break dormancy and/or flower at different times. If varieties are at different stages when a freeze occurs, only part of the overall crop will be damaged. Fortunately, many farmers already plant several varieties in order to market a given crop over a longer period of time.\nUME Extension Specialist Joseph A. Fiola has a number of good articles on detecting and preventing freeze damage in grapes. Links to basic freeze protection techniques that can be modified for other fruit crops can be found on his webpage Timely Viticulture. One clever method from Michigan State that might be useful in particular situations involves improving air flow through orchards by removing vegetation in key locations; additional information about basic freeze protection is also available at that link.\nIf you have comments or experiences with false springs you’d like to share, please email me at email@example.com.']	['<urn:uuid:373a79f5-61c8-4b48-857d-c5e00498391f>', '<urn:uuid:64ba5f89-1a89-466e-8df8-c5d604cc0ba6>']	factoid	direct	verbose-and-natural	distant-from-document	multi-aspect	expert	2025-05-13T03:20:41.944655	20	61	1507
30	As an experienced canyoneer, what are the key technical skills needed for Gem Canyon?	For Gem Canyon, all group members must be proficient in navigation, map reading, and able to climb 5.6 pitches with minimal protection. Essential skills include rope ascension, rappelling, and especially knowledge of natural anchoring. The canyon requires using two 60-meter ropes, a 30-meter rope, and at least 60 feet of slings with 8-10 rapid links or rappel rings.	"['Little Gem Canyon is located is the San Rafael Swell in east central Utah. This page describes the Middle Fork. Click HERE\nto view the page on the West Fork. Each fork in this complex is highly worthy of a trip. These canyons are in the least touched and most isolated part of the San Rafael and is in one of the least explored regions of the United States. It is certainly the essence of the wild and unexplored. The first recorded descent of this canyon did not occur until March 2004. Only a handful of people have seen this spectacular and magnificent canyon. Just to demonstrate how rugged this country is consider that the car shuttle between 63 miles consisting of mostly rough 4wd roads. When looking at the map, notice that the straight line distance between the two trailheads was only two miles! It will take at least ten hours of hiking and four hours of driving to cover those two straight-line miles!\nThis is an incredibly rugged technical adventure. The trip is not for beginners. Just finding the trailhead is a serious test of navigation. Climbers and canyoneers should go well prepared before considering this trip.\nSteve Allen (author) coined the name ""Little Gem Canyon"" for this drainage because the canyon is a nice little hike of twenty minutes up from Muddy Creek, but there is much to be seen above the fartherest point that you can hike up from the bottom. The canyon is huge above the drop and is laced with huge falls and geologic features, thus the name ""Little"" could be dropped. The canyon is un-named on all the topo maps.\nThe Getting There and Route Description sections are meant to be brief as everyone heading out into this wild area must be self-sufficient.\nErosional features and streaked walls in Middle Fork Gem Canyon.\nThere are several possibilities for starting the trip. For simplicity, I will use the same description as the one for the West Fork of Gem Canyon. I must admit that last time I was there we missed the junction with the hill and cairn mentioned below and we were lost for a little while. A GPS is highly recommended if not absolutely necessary. The maps do not show the roads, but at least you will know where you are!\nA journey to out in the middle of no-where............\nAs mentioned, just finding the trailhead is a navigational challenge. You must do the vehicle shuttle the day before the trip as it will be a long day just getting through the canyon. You absolutely must have the 7.5 minute quads (maps) Big Bend Draw and Ireland Mesa for the drive to the trailhead. Even then, the maps are inaccurate especially near the trailhead. A 4wd is also required. The 63 mile shuttle took us 3.5 hours, but we already knew how to get there, having been to the head of the canyon before. Expect to take longer.\nTo get to the trailhead at the head of the canyon, drive west from Green River, or east of the Emery area along I-70 to exit 108. You must carefully follow the topo maps for the remainder of the drive. Take the southbound gravel road and veer right after a short distance. Stay on the main road until you reach Kimball Draw at an intersection with a sign. This is at about co-ordinates N38*47\'16.47"" W111*5\'52.69"". Turn left onto the dirt road signposted for Copper Globe. After following the bottom of the wash for a while, you will reach an intersection (no sign and it can be hard to spot) at about co-ordinates N38*47\'4.42"" W111*4\'34.19"". Turn right onto a seldom used track. Follow the track in and out of several drainages until you reach an intersection at a top of a hill at about co-ordinates N38*46\'24.02"" W111*3\'57.04"". Turn right here.\nThe road weaves in and out of drainages and scenic and colorful badlands and is one of the most interesting pieces of road construction I\'ve ever seen. There are some sections of the road that pass through sparkling gypsum beds. Not too far after the road climbs out of Dizzy Trail Canyon (see the topo map), you will reach a junction next to a small hill with a cairn (pile of rocks) on top. From here on, the topo map is inaccurate as far as showing the many tracks go, so pay attention closely to the topographic features on the map. There are many routes to the trailhead, but here\'s the route we took. Turn right at the junction with the hill and cairn. You will cross a few very rough spots in the road while crossing two washes. After the second wash, make a very sharp left turn onto a track that heads east [update: this track was just about invisible when we were here in 2007, so see the alternate route below]. The trailhead and where you\'re aiming for is very near the 6350 elevation marked on the Ireland Mesa quad NW of the word ""DIKE"" on the map. Park here.\nNote #1: In 2004, I found an alternate route to the trailhead. The road is not as rough from this alternate route, but the trailhead can be harder to recognize from this direction, as this route has no landmarks near the trailhead. At the hill with the cairn, continue straight instead of right. Look for a faint track to the right not far beyond the hill with the cairn. This road leads to the trailhead, but it’s hard to recognize. Hopefully the cairn I left will still be there!\nNote #2: The main track that continues left/straight from the junction mentioned in the paragraph above dead ends at Horizon Arch. This is a scenic place and if you hike over the hill and slickrock, you will have an incredible view of the San Rafael Swell.\nThe trailhead is very hard to find. If the scene looks like this, you\'re close!\nUnless looping out via Dizzy Trail Canyon or Poncho Wash, you must also leave a vehicle at the exit trailhead. You must also have a map to drive to this trailhead. Perhaps the best map is the Trails Illustrated-National Geographic Map San Rafael Swell. Another good map is the one in DeLormes Utah Atlas. Briefly put, you will exit I-70 at exit 131 and head south on gravel roads while following signs to Tomsich Butte and Muddy Creek. Most intersections are marked with signs.\nFrom exit 131 on I-70, follow the southbound gravel road. The road first heads west and then south. Stay on the main road at all junctions for the first 9.9 miles. At 9.9 miles turn right on the road marked Reds Canyon. Continue on the most used track to another junction at mile 13.5. This is a loop road and either fork will get you to the trailhead and both forks are about the same distance. Follow the road and map to Tomsich Butte. On the north side of Tomsich Butte, you will notice a faint track heading west. This is the best route to the trailhead. The track is a very rough 4wd track and you may prefer to walk. Follow the track west to its end. There is an old mining cabin near the end of the track. Park here. Notice your surroundings so you will recognize the place when you reach it on foot at the end of your trip. Hint: Notice the ""layer cake rocks"".\nMake sure to leave Green River or Castle Dale with a full tank of gas! This area certainly is out in the middle of no-where!\nNameless tower near the lower trailhead.\nThis is meant to be an overview only. For more details, and important co-ordinates and map references, see the ROUTE PAGE\nFrom near pt. 6350, there is no one route, nor an easy way to describe a route. Prepare to get lost, at least for part of the time! There are several routes and you must follow the map carefully through the maze of drainages. Notice the small drainage just northeast of point 6675. This is your route to the bench below. After reaching the bench, contour around the cliffs until you can follow the bench west and slightly north for over a mile to two little buttes which you will pass just north of at N38*43’7.005” W111*1’30.130”. After passing to the north of the buttes, contour south along a precarious route until you can descend into the canyon bottom. We found a place with only a 30’ rappel. Continue down canyon. The slot has several 5th class drops, but we managed to down-climb all but the final 30 foot overhanging drop. After a fairly easy and pleasant section, you will find yourself at the big drop of the canyon. The drop to the first drop of the two-tiered Bighorn Falls is 50m(165\'), mostly overhanging and followed by an overhanging 9m (30\') drop. After bighorn Falls are a few short falls that can be bypassed, and then hiking the canyon is fairly easy until the confluence with the West Fork. The next section of the canyon is also spectacular and contains a nice surprise. The final obstacle is a 15 foot rappel over a flowing waterfall (which may dry up at times). Follow Gem Canyon down to Muddy Creek. There are fantastic erosional features. When you reach Muddy Creek, head down stream. It is then a pretty easy walk down along Muddy Creek down to Tomsich Butte. See the route page for a lot more detail.\nAfter completing the canyon there are four options.\nThe easiest option is to hike down Muddy Creek to Tomsich Butte, but as mentioned this requires a very long car shuttle.\nThere are two alternatives for those who don\'t want to do the long car shuttle, but it will take much planning and has special considerations.\nSee this route page for details\n. You could do the canyon as an over-night trip and hike up Muddy Creek and exit via Dizzy Trail Canyon and then hike back to the vehicle. See the route description posted for this alternate route. This will take two long days minimum (3 days may be better if you can pack very light). The problem with doing an overnight trip is that the slot section of the canyon is so narrow that it will be very difficult to take an overnight pack through. If you did attempt it, take as small as pack as possible (leave a tent and stove behind!) and expect some possible pack damage. The only water available for camping is in Gem Canyon near Muddy Creek and possibly the grungy pool near Scorpion Falls. Muddy Creek doesn\'t taste good, but could be used if you ran out of water (but treat the water!).\nYou could also do the canyon and hike up Muddy Creek to Poncho Wash and exit via a steep exit chute. This is the quickest way to do any of the entire Gem Canyon Forks without doing the very long car shuttle.\nDoing the entire Gem Canyon and looping via this exit route is a very long and tiring day. It took us over 12 hours, but we were really moving with few breaks. See the Route Page\n. The round trip distance is 17 miles and with the technical difficulties this makes for a very long day.\nA final option is to backpack down Gem Canyon, hike up Muddy Creek to Lone Tree Crossing and exit. Such a trip will take a minium of three days, but the car shuttle is much shorter than the one used by going down Muddy Creek to Tomsich Butte.\nDown-climbing a short 5th class pitch in the slot section.\nClean Canyoneering Ethics\nThe canyons in this area are very pristine. Bolts are not needed to descend this canyon, and would detract from the incredibly pristine setting of this wild canyon. We saw no signs of previous descent in March of this year. There are plenty of chockstones to wrap slings around for anchors. Try to leave as little behind as possible. This trip is certainly not for beginners; canyoneering techniques must be practiced before going on this trip.\nSetting up a natural anchor around a boulder. By using such natural anchors, you can avoid bolting the route. Natural anchors are plentiful in the canyon.\nSeveral slings (bring 60 feet minimum), 8-10 rapid links or rappel rings, two 60 meter (200 feet) ropes (warning, standard 50 meter ropes will be two short!!!), a 30m meter (100 foot) rope, and a climbing harness. A GPS is also required.\nLast rap in Gem Canyon.\nThe following skills are recommended for those planning a descent of the canyon. All members of the group should be proficient in navigation and map reading. All members should be able to up or down climb short pitches of 5.6 with little protection. All members should know how to ascend a rope and know how to rappel. The most important skill is the knowledge of natural anchoring. Make sure to learn all these skills before attempting a descent of the canyon!\nCanyon walls and huge Ponderosa Pines in Gem Canyon.\nNo permits are required.\nNo red tape here. No private land either. Just good times.\nWhen To Climb\nThe trailhead is not accessible between early December through late February in most years. Summer is extremely hot with temperatures exceeding 100F degrees (38C). Winter temperatures drop well below 0F (-18C). The best times of the year for this adventure are mid-March through May and then again in mid-September through mid-November. Muddy Creek can be very cold before April. There is some flash flood potential in the narrow sections, so have a good weather forecast before heading down the canyon.\nThis is a land of weather extremes. Temperatures in the nearest towns have ranged from -42F (-41C) to 112F (44.5C) at Green River and -35F( -37C) to 114F (46C) at Hanksville. On the day we went through the morning low was 29F (-2C) and the afternoon high was 86F (30C) in the shade. Sunny weather predominates and it only rains a few times a year, but when it does rain, it can really pour! Don\'t underestimate flash flood danger.\nSwiss cheese type rock in Gem Canyon.\nThere are good campsites near both trailheads as well as many scattered throughout this region. the nearest official campground is many, many miles from this canyon.\nCamping in the canyon requires special preparation. See the route description.\nMuch of the canyon doesn\'t have campsites.\nThis is the first time this canyon has never been published on a website or guidebook, so there are no links available. Even the topo maps are inaccurate in several sections of this canyon, so you must be self-sufficient.\nIn addition, you may email me with the address in my profile if you wish for more information or help with more details about the trip.\nWEATHER FORECAST FOR SAN RAFAEL SWELL\nWeather and climate data for the Hanksville is below. *National Weather Service Data 1912-2004.\n|MONTH||AVE HIGH||AVE LOW||REC HIGH||REC LOW||AVE PRECIP (in)|']"	['<urn:uuid:4765a37d-7df9-45d2-949b-c0fc9058d010>']	open-ended	with-premise	concise-and-natural	similar-to-document	single-doc	expert	2025-05-13T03:20:41.944655	14	58	2526
31	want to grow mint in backyard ground is it good idea	Growing mint directly in the ground is not recommended. While mint is very easy to grow, it is invasive and once established in the ground, it's near impossible to get rid of. It's better to grow mint in containers to control its spread.	['It doesn’t matter if you’re new to gardening or if you’ve been growing vegetables for years – growing your own herbs is easy and rewarding (especially come pasta night when that fresh basil on your windowsill is going to start looking especially great). Starting an herb garden gets your hands in the dirt and lets you witness the miracle that is plant life, and you can be sure that a little herbal greenery will add a fresh look to your home, whether it’s on your windowsill, incorporated into a flower garden, or a just-for-herbs bed in the middle of your yard. And believe us, once you start adding fresh herbs into your recipes – again, think about the pasta – you won’t ever want to return to dried, store-bought seasonings again.\nIf you don’t have a green thumb, don’t worry. These six herbs are easy to grow, easy to use, and great for beginners.\nIf you’re only going to grow one herb this year, make it basil. This easy-to-grow annual does well in both pots and in the ground, and its slightly spicy flavor is will make a welcome addition to any dish. Pick leaves from the growing tips, pinching them off near the stem. This causes the plants to branch, giving you even more leaves to choose from. You can also pinch off forming flowers, extending the life of the plant through summer. Basil is tasty mixed with fresh tomatoes and mozzarella, added to the top of your pizza, included in salads and sandwiches, and can even be thrown into a glass of ice water with some strawberries to make it a little more exciting.\nA cousin to onions, chives are a perennial herb that once you start using, you’ll want to use in everything you make. Chives can be grown in containers, added to a vegetable garden, or even placed in a flower garden, as they grow pretty pink or lavender flowers that attract bees and other pollinators. Chives grow quickly and can easily be split into multiple bunches. Cut the green stems close to the ground and chop into small pieces for cooking. They can replace onions in just about any recipe and make a great addition to baked potatoes, omelets, and soups. Chives are also great to mix with butter, giving a little kick to your cooking.\nAn Italian cooking staple, oregano is a perennial herb that has a strong, spicy flavor. It grows easily anywhere, including in a pot on your back porch or in the garden. Pick the leaves of the oregano plant before it goes to flower for the best flavor, and the herb can be used fresh or dried. While oregano can be used in many dishes, the most common include pasta and pizza, and it makes a great addition to fresh bread dough.\nEven if you think you can’t grow anything, chances are you can grow mint. While it’s a lovely herb to have in your yard, it is invasive so you shouldn’t put it in the ground unless you’re okay with it kind of taking over. Once it’s established, it’s near impossible to get rid of. Mint comes in a variety of flavors, including chocolate and apple, but peppermint and spearmint are by far the most popular. The herb is fragrant and can be added to cookies, fruit, or even homemade ice cream. The leaves can also be dropped into water for flavor and fresh mint makes any mojito taste better.\nA biennial herb, parsley is often found on dinner plates at restaurants and is a common flavor enhancer in cooking. It’s easy to grow, and is great for both traditional and container gardening. Pick fresh leaves from the outside of the plant and use it in dishes with potatoes and rice or toss it into salads. Parsley balances out the flavor of garlic and is a great palate cleanser. Chewing on a few parsley leaves can also freshen the breath, especially after a meal.\nAnother perennial herb, thyme has a unique, woody flavor and aroma and often becomes a favorite of herb gardeners. It thrives both in pots and in the ground, and is often used to flavor meats, including beef, chicken, and fish, and with root vegetables. When harvesting, use the leaves and the stems, as both hold the flavor and can be added to dishes.']	['<urn:uuid:839acb86-cc44-4834-9fba-3f6b5a47b45a>']	factoid	with-premise	long-search-query	distant-from-document	single-doc	novice	2025-05-13T03:20:41.944655	11	43	728
32	As an electrical engineer who works with both car audio and guitar amps, I've noticed that fuses often blow - what are the key differences between diagnosing blown fuses in tube guitar amps versus car amplifiers?	Diagnosing blown fuses differs significantly between these amp types. For car amplifiers, the first step is identifying if the power wire or amplifier is the source - you can test this by disconnecting the amp, insulating the wire end, and trying a new fuse with lower amperage. Common car amp issues include power wire grounding, faulty ground connections, and excessive resistance from undersized wires. For tube guitar amps, fuse issues are often related to tube wear and bias problems. Guitar amp diagnosis focuses more on tube maintenance - including regular replacement of output tubes every 6 months to 2 years, proper biasing after tube replacement, and ensuring matched tube sets are used when needed. While car amps may need professional repair for internal damage, guitar amp fuse issues can often be resolved through proper tube maintenance and replacement.	['If you play through a tube amp, here’s some upkeep knowledge to help in the quest of great tone.\nI always enjoy reading your column and I have a suggestion for a future Ask Amp Man. The subject would be the care and feeding of your tube amp—or something similar. I started working with tubes in the early ’60s in high school. I’m now a retired electrical engineer but still enjoy tinkering with and repairing tube amps (and of course playing through them). I still have my old RCA and GE tube manuals and two ancient tube testers. While there’s a lot of information available on the web, there is a lot of misinformation as well. Some questions you might answer:\nHow often should I replace the tubes?\nDoes the phase inverter need to be replaced when I replace the output tubes?\nIn a 100-watt amp, do I have to replace all four output tubes (or six, as in my Peavey Mace) with a matched set if only one tube is bad?\nDoes the grid bias need to be reset every time I replace the tubes?\nDo I need to replace them with the same brand tubes?\nHow can I tell if I have a cathode-biased amp?\nIs measuring the control grid voltage an acceptable way of setting the bias?\nMost guitarists I know play their amp until it sounds real bad or the fuse blows, and then turn it over to me. A little knowledge might help them avoid some trouble.\nKeep up the good work,\nThanks, Dave. I selected your question for this issue because I thought it might be timely. Some players may have gotten a new or used tube guitar amp from Santa, and it could possibly be their first foray into the wonderful world of tubedom. Knowing what you have and how to treat it can be a key factor in having the best possible experience, so with the help of your questions I’ll try to impart some good information for those in need. Let’s tackle them one at a time.\nHow often should I replace tubes? This is a great question that has no absolute answer. Regarding output tubes, I generally tell players the typical tube life for the glowing bottles produced today is approximately six months to two years, depending on use. How long and how loud you play will affect tube longevity, and some brands more than others. Larger bottle tubes—such as the 6L6, 6550, KT66, KT88, and EL34—tend to fall on the longer side, while smaller tubes like the EL84 and 6V6 tend to wear out sooner. It’s always a good idea to carry a spare set with you, as you never know when a failure may occur. With regards to preamp tubes, I feel it’s okay to run them until they start making noises that no longer resemble a guitar, but if you get to the point where they’ve been in the amp for five or 10 years, you might want to consider replacing them, too.\nDoes the phase inverter need to be replaced when I replace output tubes? Personally, I say no. The phase inverter does drive the output tubes, but it doesn’t suffer the wear and abuse that output tubes endure. I treat it like any other preamp tube. If it’s problematic, I replace it.\nDo I have to replace all output tubes in a 100-watt amp with a matched set if only one tube is bad? In a perfect world, I’d say yes. But I’m a practical guy and I always look at this on a case-to-case basis. If the tubes in the amp aren’t too terribly old or don’t have too many hours on them, you can opt for just replacing a pair. Just remember, most amps have what’s known as a push/pull output stage, where each side (either one tube, two tubes, or even three tubes in the case of your Mace) is amplifying half the signal, so you should replace the bad tube plus one from the other side, in order to keep the output stage as balanced as possible.\nDoes the grid bias need to be reset every time I replace the tubes? If you’re replacing all the output tubes, then yes, I would highly recommend it. Properly biasing output tubes will let your amp sound its best and can also extend tube life. If, as in the above answer, you’re replacing only some of the output tubes, then biasing all the tubes the same may not even be possible, as there is generally one bias adjustment that controls the bias voltage to all the tubes. As with any output tube replacement, I always recommend matched sets, as this helps keep the output stage balanced and will yield the least hum from the output stage.\nDo I need to replace old tubes with the same brand? If you’re replacing only some of the output tubes, then I highly recommend trying to find the same type of output tube that’s currently installed in the amp. This will give you the best chance of the new tubes running close to the bias current of the installed tubes. If you’re replacing all the tubes, then absolutely not. There are quite a few selections for each type of output tube, and tubes produced by different manufacturers in different countries sound different. If you have the luxury of auditioning different types of output tubes, do yourself a favor and experiment. You might find something that better suits your taste or expectations.\nPhoto by Andy Ellis.\nHow can I tell if I have a cathode-biased amp? Just by looking at the amp, you can’t. However, if you’re handy with a multi-meter, there is a way. You can measure resistance between the cathode pin of one of the output tubes and ground. On large octal sockets for most standard output tubes, this will be pin 8. On a 9-pin socket for an EL84-type tube, this will be pin 3. If you measure zero resistance, the amp is grid biased. If you measure in the area of approximately 50 to 250 ohms, the amp is cathode biased. Unless there is a problem with the amp, this should hold true, with the exception of some late-’60s Fender amps, which exhibit both grid- and cathode-bias characteristics.\nIs measuring the control grid voltage an acceptable way of setting the bias?No. Some schematics do show a bias voltage reading, but in almost all cases this is merely a reference for troubleshooting in order to determine if the voltage is in the ballpark. It’s always best to measure the actual bias current flowing through the tube at idle. Quite a few companies offer bias meters that include an assembly that is inserted between the tube and socket to measure the actual bias current. This procedure is irrelevant on cathode-biased amps, as these are also known as self-biasing and are generally not adjustable.Well, PG readers, there you have it. There can be exceptions, exclusions, and further explanations, but I hope this helps some of you understand a bit more about what to expect from your tube amp and what it expects from you. Let’s keep those tubes glowing!', 'The entire reason why you got an amplifier for your car is so that you can enjoy better quality sound systems! But if most of the time your common question is why does my Amp keep blowing fuses? when you start your car, or just does it all of a sudden — there could have been a couple of things that have gone awry.\nThe main reason for your Amp Blowing Fuses could be the power wire that is at fault or the Amplifier itself. You know the fault is in the power wire when the insulation has worn out, but the amplifier is usually at fault when the fuse does not blow out when the amplifier is not hooked up.\nWhy Does it Happen?\nFuses blowing out can generally happen when it was not installed correctly, and there is resulting internal damage inside the amplifier. It could also be that you used the wrong fuse size for the amplifier.\nIf you’re lucky however, the amplifier might be fine and you might need to only replace the power wire. With the power wire, there could be three main issues: the power wire grounding, faulty ground, or too much resistance.\nDiagnosing the Problem\nHere’s how you can go about diagnosing and fixing the problem with your amplifier blowing fuses. Your first step is to identify the source of the problem. This means understanding whether your power wire is at fault or the amplifier. Here’s how to figure it out!\nThis might sound painfully obvious: but there is nothing you can do if you don’t first figure out which fuse has blown. You will have to inspect all of the fuses to see which is the one that is blown. Then you will have to find out what the amperage rating is of the blown fuse and source a new one.\nImportant to Note: When you’re diagnosing the problem, there are many times that you will have to replace the blown fuse with a new fuse. While it might make sense to get another fuse with the same amperage rating as the previous one, it is actually safer for you and the amplifier if you use a fuse with a lower amperage rating.\nThe reason for this is that you have to consider that the amp has been supplying excess amperage to the fuse in the first place: which is why it blew up. If you put another fuse with the same rating, it can cause a malfunctioning car amplifier to draw even more of the amperage.\nNeedless to say, this would cause even more damage to your amplifier! That’s why you are better off with a fuse that has lower amperage!\nPower Wire Issues\n- You should first disconnect the amplifier from the power wire.\n- Then, grab some electrical tape and carefully insulate the amplifier’s end of the wiring. You are insulating it from the grounding which is against the body of your car.\n- Now, get another fuse. (Make sure it is the same kind of fuse, and the right size according to your amplifier, but a lower amperage) Take the other fuse and place it into your power wire.\n- If the new fuse that you placed blows as well, the problem is with your power wire.\n- If it doesn’t the issue might be with the amplifier, so skip to that section in that article.\nAlright, now we have diagnosed the first phase of the problem. We have understood that the issue lies with the power wire. However, what exactly is wrong with the power wire? There are three possible explanations for why your power wire is acting up: the power wire grounding, faulty ground or damaged wire, or too much resistance.\nTop 4 Reasons for Why Does My Amp Keep Blowing Fuses.\n1. Power Wire Grounding\nThis is one of the most common problems with a power wire. It may be grounding out. This may seem like a big annoyance but it is actually a blessing — since it protects your precious amplifier from getting damaged.\nIn this case, you will also generally see visible damage on your power wire. Look for the point where the power wire runs from the engine compartment into the interior of your car. Sometimes, during installation, the drilled hole is made without using a grommet. This means that it has sharp edges, and can break into the insulation of your power wire. You’ll notice visible damage with the bare wire sticking out.\nSolution: Patch up the visible damage with some electrical tape or heat shrink tubing. If this doesn’t work, you might have to purchase a new power wire.\n2. Faulty Ground or Damaged Ground Wire\nThis might happen when your ground wire is not properly connected or not fully connected. When the ground wire is not fully attached and is moving about a lot, it can cause the fuse to blow. Furthermore, the ground wire could be fully attached but damaged in some places. Look out for the spot where it is attached to the chassis. You might see fraying, or tears or indents. These are all signs of damage.\nSolution: In cases of kinks and tears, it might be best to replace your ground wire.\n3. Too much Resistance\nThis is one of the issues that arise when your power wire is too small in diameter. It causes too much resistance, which in turn creates a lot of heat. This heat will definitely damage the amplifier: and many amplifiers have some kind of self-defence where it pops the fuse before allowing the heat to damage itself.\nSolution: Getting a power wire that is larger in diameter will solve the issue of too much resistance. It should be at least 10 gauge in size.\n4. Your amplifier might be damaged\nRegrettably, the issue can also be with the amplifier itself. Here’s what could’ve gone wrong.\nYou will always see that the correct fuse size is listed in the amplifier. If you have used the wrong fuse size, it can cause internal damage.\nSolution: You will have to take your amplifier to a repair store or to a mechanic for this one, as internal damage usually means internal parts need to be replaced.\nSo there you have it: multiple ways in which you diagnose and solve the problem of your amp blowing fuses. For additional help in diagnosing your malfunctioning amplifier, click here. If you’re facing this issue, try out the solutions that we recommended to see for yourself if you’re able to solve it!']	['<urn:uuid:aef77782-d781-4daa-8f13-e3f2894d5f6c>', '<urn:uuid:d89a3de5-465a-4d37-bfb2-e1f5ce85a7bc>']	open-ended	with-premise	verbose-and-natural	similar-to-document	three-doc	expert	2025-05-13T03:20:41.944655	36	138	2296
33	I work in maintenance - are safety needs different for cleaning cooling towers vs general tasks?	Yes, cleaning cooling towers requires more specific protective equipment than general tasks. While general tasks may need basic PPE like gloves and safety glasses, cooling tower cleaning requires full-length protective clothing, boots, goggles, and a specialized mask with both high efficiency particulate air filter and chemical cartridges to protect against chlorine exposure up to 10 mg/L.	"['PROCEDURE FOR CLEANING COOLING TOWERS AND RELATED EQUIPMENT\n(Adapted from the Emergency Protocol in Control of Legionella spp. in Cooling Towers: Summary Guidelines.)\nI. Preparatory to Chemical Disinfection and Mechanical Cleaning\nA. Provide protective equipment to workers who would perform the disinfection, to prevent their exposure to (a) chemicals used for disinfection and (b) aerosolized water containing Legionella spp. Protective equipment may include full-length protective clothing, boots, gloves, goggles, and a full- or half-face mask that combines high efficiency particulate air filter and chemical cartridges to protect against airborne chlorine levels of up to 10 mg/L.\nB. Shut off cooling-tower.\n1. If possible, shut off heat source.\n2. Shut off fans, if present, on the cooling tower/evaporative condenser (CT/EC).\n3. Shut off the system blowdown (purge) valve. Shut off automated blowdown controller, if present, and set system controller to manual.\n4. Keep make-up water valves open.\n5. Close building air-intake vents within at least 30 meters of the CT/EC until after the cleaning procedure is complete.\n6. Continue operating pumps for water circulation through the CT/EC.\nII. Chemical Disinfection\nA. Add fast-release, chlorine-containing disinfectant in pellet, granular, or liquid form, and follow safety instructions on the product label. Examples of disinfectants include sodium hypochlorite (NaOCl) or calcium hypochlorite (Ca[OCl]2), calculated to achieve initial free residual chlorine (FRC) of 50 mg/L, i.e., 3.0 lbs (1.4 kg) industrial grade NaOCl (12-15% available Cl) per 1,000 gallons of CT/EC water; 10.5 lbs (4.8 kg) domestic grade NaOCl (3-5% available Cl) per 1,000 gallons of CT/EC water; or 0.6 lb (0.3 kg) Ca(OCl)2 per 1,000 gallons of CT/EC water. If significant biodeposits are present, additional chlorine may be required. If the volume of water in CT/EC is not known, it can be estimated (in gallons) by multiplying the recirculation rate in gallons/minute by 10, or the refrigeration capacity in tons by 30. Other appropriate compounds may be suggested by a water-treatment specialist.\nB. Record the type and quality of all chemicals used for disinfection, exact time the chemicals are added to the system, and time and results of measurements of (FRC) and pH.\nC. Add dispersant simultaneously with or within 15 minutes of adding disinfectant. The dispersant is best added by first dissolving it in water and adding the solution to a turbulent zone in the water system. Examples of low or non-foaming, silicate-based dispersants are: automatic-dishwasher compounds, such as Cascade* or Calgonite* or an equivalent product. Dispersants are added at 10-25 lbs. (4.5-11.25 kg) per 1,000 gallons of CT/EC water.\nD. After adding disinfectant and dispersant, continue circulating the water through the system. Monitor FRC by using an FRC-measuring device, such as a swimming pool test kit, and measure the pH with a pH meter every 15 minutes for 2 hours. Add chlorine as needed to maintain FRC at > or = 10 mg/L. Since the biocidal effect of chlorine is reduced at higher pH, adjust pH to 7.5-8.0. The pH may be lowered by using any acid (e.g., muriatic acid or sulfuric acid used for maintenance of swimming pools) that is compatible with the treatment chemicals.\nE. Two hours after adding disinfectant and dispersant or after FRC level is stable at 10 mg/L, monitor at 2-hour intervals and maintain FRC at 10 mg/L for 24 hours.\nF. After FRC level has been maintained at 10 mg/L for 24 hours, drain the system. CT/EC water may be safely drained to the sanitary sewer. Municipal water and sewerage authorities should be contacted regarding local regulations. If a sanitary sewer is not available, consult local or state authorities (e.g., Department of Natural Resources) regarding disposal of water. If necessary, the drain-off may be dechlorinated by dissipation or chemical neutralization with sodium bisulfite.\nG. Refill system with water and repeat procedure outlined in steps 2-6 in I-B above.', 'Personal Protective Equipment\nWhat is personal protective equipment?\nPersonal protective equipment, commonly referred to as ""PPE"", is equipment worn to minimize exposure to hazards that cause serious workplace injuries and illnesses. These injuries and illnesses may result from contact with chemical, radiological, physical, electrical, mechanical, or other workplace hazards. Personal protective equipment may include items such as gloves, safety glasses and shoes, earplugs or muffs, hard hats, respirators, or coveralls, vests and full body suits.\nWhat can be done to ensure proper use of personal protective equipment?\nAll personal protective equipment should be safely designed and constructed, and should be maintained in a clean and reliable fashion. It should fit comfortably, encouraging worker use. If the personal protective equipment does not fit properly, it can make the difference between being safely covered or dangerously exposed. When engineering, work practice, and administrative controls are not feasible or do not provide sufficient protection, employers must provide personal protective equipment to their workers and ensure its proper use. Employers are also required to train each worker required to use personal protective equipment to know:\n- When it is necessary\n- What kind is necessary\n- How to properly put it on, adjust, wear and take it off\n- The limitations of the equipment\n- Proper care, maintenance, useful life, and disposal of the equipment\nIf PPE is to be used, a PPE program should be implemented. This program should address the hazards present; the selection, maintenance, and use of PPE; the training of employees; and monitoring of the program to ensure its ongoing effectiveness.\nPersonal protective equipment is addressed in OSHA standards for Construction, General Industry, Shipyard Employment, Marine Terminals, and Longshoring. OSHA requires that many categories of personal protective equipment meet or be equivalent to standards developed by the American National Standards Institute (ANSI).\nHow do I find out about employer responsibilities and workers\' rights?\nWorkers have a right to a safe workplace. The law requires employers to provide their employees with safe and healthful workplaces. The OSHA law also prohibits employers from retaliating against employees for exercising their rights under the law (including the right to raise a health and safety concern or report an injury). For more information see www.whistleblowers.gov or Workers\' rights under the OSH Act.\nOSHA can help answer questions or concerns from employers and workers. To reach your regional or area OSHA office, go to the OSHA Offices by State webpage or call 1-800-321-OSHA (6742).\nSmall businesses may contact OSHA\'s free On-site Consultation services funded by OSHA to help determine whether there are hazards at their worksites. To contact free consultation services, go to OSHA\'s On-site Consultation webpage or call 1-800-321-OSHA (6742) and press number 4.\nWorkers may file a complaint to have OSHA inspect their workplace if they believe that their employer is not following OSHA standards or that there are serious hazards. Workers can file a complaint with OSHA by calling 1-800-321-OSHA (6742), online via eComplaint Form, or by printing the complaint form and mailing or faxing it to the local OSHA area office. Complaints that are signed by a worker are more likely to result in an inspection.\nIf you think your job is unsafe or if you have questions, contact OSHA at 1-800-321-OSHA (6742). Your contact will be kept confidential. We can help. For other valuable worker protection information, such as Workers\' Rights, Employer Responsibilities, and other services OSHA offers, visit OSHA\'s Workers\' page.\nIn Focus: Ebola\n- Eye and Face Protection. OSHA eTool. Provides a comprehensive hazard assessment, information about selecting protective devices for the workplace, as well as OSHA requirements.\n- Respiratory Protection. OSHA eTool. Provides information on the development of respirator cartridge change schedules. Addresses respirator selection and other requirements of the standard.']"	['<urn:uuid:91ce076a-f82b-46a3-89ef-f058a8788296>', '<urn:uuid:b4f03e72-e57a-4b81-9dc6-8edf55570221>']	factoid	with-premise	concise-and-natural	similar-to-document	comparison	novice	2025-05-13T03:20:41.944655	16	56	1255
34	advanced training need speed enhancement programs elite runner nutrition requirements glycogen replenishment protein intake	For speed enhancement, elite runners need proper warm-up routines and interval training focusing on stride length, stride frequency, and anaerobic endurance. For nutrition, competitive runners require 2.5 to 4.5g of carbs per pound of body weight for 1-3h endurance exercise, with protein needs of 0.6 to 1.0g per pound body weight. They should consume 20-30g protein per meal and focus on rapid refueling when training twice daily, though muscles stay in building mode for 24-48 hours after weight training.	"['We\'ve all heard it: the mantra that gets the truly dedicated out of bed in the morning and pushes them to crush that last rep or burn through that last sprint:\nBigger. Faster. Stronger.\nFor many, the ""bigger"" and ""stronger"" parts are easy enough. But, as a strength coach to hundreds of pro athletes, one question that is consistently asked of me is: How do I get faster?\nSpeed is crucial to achieve top athletic performance, but it remains a mystery for many otherwise impressive performers. Well, I\'m here to say you can dramatically increase your speed, as long as you apply the same dedication to it that you do to your other fitness goals.\nAs renowned coach Tom Shaw put it, ""You can gain speed, just as you can gain strength in the gym."" You just have to know the right way to do it. Here are my top five tips to achieve blazing speed and run like a pro.\nBefore every training session, warming up is a crucial step. Make no mistake: When it comes to sprinting, failing to warm up could lead to major injuries. The last thing an athlete needs is to be out of the game for weeks or even months simply because they failed to complete this vital step.\nA proper warm-up gets the blood flowing, delivers important nutrients and oxygen to the muscles, and delays fatigue so you get the most out of your training session. I recommend a dynamic warm-up lasting 10 minutes, including moves like skipping, take-offs, or an easy jog.\nAnyone can increase their basic speed by focusing on the three components that create it: stride length, stride frequency, and anaerobic endurance. Let\'s break this down further to understand what each component means:\nSpeed increases can only be achieved when each of these areas improves collectively. Interval training, and more specifically, A and B drills, are the best way to improve these three areas. There are many variations on these drills, but what they all share is that they isolate and rehearse the essential motions making up a full-stride sprint, so you can perfect the whole process and repeat it in action without having to think about it.\nA Drill: An A drill is like a march done at sprint pace. You take short, quick steps, emphasizing fast turnover, getting the knees high, and cyclical leg action. This forces your stride frequency up and maximizes balance and coordination.\nB Drill: In B drills, you get the knee high again, but then extend the knee forward and claw back at the ground. This mimics the motion and ground feeling of a long stride. Both are usually performed in 15-20-yard blasts or more, if you can work up to it.\nCombine A and B drills into a 15-20 minute series, like in the 40-yard-sprint section of our NFL combine trainer, and you\'ll test your anaerobic endurance to boot.\nDeveloping a high level of maximum strength is crucial to increasing speed, since it\'s the foundation from which all necessary strength qualities are built. Without proper body strength and flexibility, you\'ll never reach your full potential. A strong core helps with posture and endurance, strong arms help you pump faster (therefore increasing speed), and powerful legs are the heart of your muscular ""power center,"" namely the hips, glutes, quads, and hamstrings.\nStart with a strong focus on your core with a series of planks and side planks. For arms, use a combination of compound and functional exercises, such as hammer curls with heavy weight and fewer reps. This is the best combination for sprint training.\nLeg strength is critical because it increases the force with which you push off the ground. A weak sprinter won\'t be able to produce the amount of power with each step to reach his/her true speed potential. Deadlifts, squats, lunges, step-ups, and power step-ups are all great exercises to increase leg strength.\nPower and speed go hand-in-hand. As mentioned earlier, the amount of power you release directly impacts the force with which you explode from the ground, thus increasing your speed. But, explosive strength requires more than strength training.\nExplosive strength exercises are designed to achieve maximum force from a paused or stopped position, such as sprinting out of blocks, or across the line of scrimmage. These exercises add to the strength you build with regular weight training, which takes speed training to the next level.\nGreat examples of explosive strength exercises are box squats, paused jump squats, and on-box jumps. Power through your plyos!\nImproving speed endurance can be the key to gaining that all-important competitive edge. Speed endurance is the ability to maintain maximum velocity or a percentage of maximum velocity for a prolonged period of time, or in a fatigued state. Outlasting your opponent by avoiding fatigue can often be the difference between winning and losing.\nThe best way to achieve maximum velocity is to implement interval training specifically designed for speed endurance. This technique differs from regular speed training, in that it employs varied interval lengths and shortened recovery times to prevent complete recovery. A good rule of thumb is to keep a work-to-rest ratio of 5:1.\nLike all training goals, achieving optimal speed takes dedication, time, and hard work. By following these five tips, we guarantee you\'ll get there ""faster.""', 'So how do the nutritional needs of elite athletes differ to those of recreational competitors? A look at some of the considerations you\'ll want to consider to get the most out of your training and racing.\nMarch 20, 2019 | Nutrition|\nNancy, do you offer different nutrition recommendations for elite competitors compared to recreational athletes? I am highly competitive, work out intensely, and often wonder if I am eating to be the best athlete that I can be.\nAnswer: Sports nutrition recommendations are based on the assumption we all want to get the most benefits from our workouts so we can perform to the best of our abilities. Because every athlete is unique, a one-diet-fits-all approach doesn\'t work. Rather, all athletes want to be curious and experiment with a variety of fueling practices to learn what works best for their bodies. The following compares recommendations I might make for competitive vs. recreational runners.\nNote: Sports nutrition is a new science. In the near future, with the refinement of personalized nutrition based on genetics, sport dietitians will be able to offer individualized advice. Some runners and triathletes might perform better with more fat than carbs, or more beef than beans. Until then, here are today\'s science-based recommendations.\nIn this era that pushes fat and protein, carbohydrate deficiency is common. All runners and triathletes can improve their performance (and health) by consuming adequate ""high quality"" carbs (grains, fruits, veggies) to fuel muscles and prevent needless fatigue. While elite athletes might want to strategically withhold carbs before specific training sessions to trigger performance-enhancing cellular adaptations, recreational runners and triathletes want to focus on fueling well each day in order to have enjoyable workouts. A sport dietitian can help both elite and recreational athletes reach these carbohydrate goals:\nExample: For a 140-lb recreational runner who does a one-hour long run, carb goals are 350 g (1,400 calories) for the day. For the competitive marathoner who trains harder and longer (two to three hours), a good goal is 630 g carb (2,500 calories) on long-run days. Divide that into three meals (400 to 700 calories from carb per meal) and two snacks (100 to 300 calories from carbs per snack). Start reading food labels to see how well you do. You\'ll discover a spinach-cheese omelet doesn\'t hit the goal.\nAmount of exercise/day\ngram carb/lb. body wt.\ngram carb/kg body wt.\n1 hour moderate exercise\n2.5 to 3\n1-3 h endurance exercise\n2.5 to 4.5\n3.5 to 5.5\nA well-fueled competitive runner or triathlete with trained muscles requires a little less protein than a novice athlete who is building new muscle. The range of protein needs (0.6 to 1.0 g protein per pound body weight; 1.2 to 2.0 g/kg) tends to be moot, given most hungry athletes consume plenty of protein.\nMost competitive runners and triathletes can easily meet their protein needs by targeting about 20 to 30 grams protein per meal (a can of tuna) and 10 to 20 g protein per snack (a Greek yogurt). The protein in natural foods is preferable to protein supplements. Natural foods offer a complex matrix of nutrients that interact with a synergistic effect. Plus, they are unlikely to be spiked with illegal drugs and compounds that can lead to a failed drug test.\nCompetitive runners and triathletes lose lots of sweat when exercising for hours on end. But so can recreational athletes who are out of shape and working hard. That\'s why everyone who sweats heavily wants to learn his or her sweat rate. You can learn this by weighing yourself (without clothing) before and after an hour of exercise without drinking anything at X pace and in X degrees of heat or cold. For each pound lost, you are in deficit of 16-ounces of fluid. Drink enough during exercise to minimize this deficit. Throughout the day, drink enough to urinate every two to for hours. (Peeing every half-hour is excessive; no need to over-hydrate!)\nFueling during long runs\nFor competitive runners, a sport drink or gel is a convenient and precise way to boost energy during long runs. With a target intake of 60 to 90 g carb per hour of extended exercise, an elite runner generally prefers drinking a beverage than eating solid food. A casual runner might want some tastier orange slices or energy bar.\nElectrolytes (potassium, sodium, magnesium, and calcium) are readily available in standard pre- and post-exercise foods. Most recreational runners and beginner triathletes don\'t sweat enough to lose a significant amount of electrolytes. Highly competitive runners and more competitive triathletes who train and sweat for two to three hours in the heat should add extra salt to their pre-run food (helps retain water and delays dehydration) and consume sodium-containing foods and fluids (endurance sport drinks) during the long run. Afterwards, chocolate milk beats Gatorade for an electrolyte-filled recovery drink. Most sweaty athletes intuitively seek salty chips, soup, or salted foods in for their recovery meal. If you are craving salt, consume salt!\nRecreational runners and triathletes who train two to three times a week can easily recover by backing their workout into a balanced meal that contains carbs (to refuel) and protein (to build and repair) muscles, such as oatmeal + eggs; yogurt + granola; sandwich + milk; chicken + rice. Competitive runners and triathletes who train twice a day need to more rapidly refuel. The key is to plan ahead to have the right recovery foods and fluids ready and waiting. While a commercial recovery drink can be handy, a fruit smoothie (made with Greek yogurt) or some chocolate milk does an excellent job. Real foods work well for everyone.\nAfter lifting weights, no need for anyone to immediately slam down a protein shake. Muscles stay in building mode for the next 24 to 48 hours. Regular meals, with protein evenly spaced throughout the day, do the job.\nThe bottom line\nEvery athlete will win with good nutrition. The key is to be responsible and plan to have the best foods and fluids available at the right times. Here\'s to satisfying runs!\nNancy Clark, MS, RD counsels both casual and competitive athletes at her office in Newton, MA (617-795-1875). Her best selling Sports Nutrition Guidebook and Food Guide for Marathoners offer additional information. (See NancyClarkRD.com). For her popular online workshop, see NutritionSportsExerciseCEUs.com.']"	['<urn:uuid:cefafe9b-a7df-4dd5-9db5-4b7f3e2f6cd5>', '<urn:uuid:c0262c24-0a3b-465d-8cee-22aa4c943a61>']	factoid	with-premise	long-search-query	distant-from-document	multi-aspect	expert	2025-05-13T03:20:41.944655	14	79	1937
35	concussion clinic specialists patient tests needed	A comprehensive concussion care practice requires multiple testing components: neurocognitive testing (like ImPACT), balance and postural sway assessment, vestibular/ocular screening, and removal from activity screening tools. These tests are necessary because concussions can produce various symptoms and there is no single reliable diagnostic test. The practice should include different specialists like a concussion specialist team leader, athletic trainers, physical and occupational therapists, and other rehabilitation professionals to provide comprehensive care.	"['Why Baseline Testing?\nConcussions can produce a wide array of symptoms, which poses a challenge for coaches, trainers, parents, and health professionals involved in the care of an injured athlete. The time-course for recovery also varies widely from athlete to athlete, making it impossible to employ a “cookie-cutter” approach to concussion rehabilitation and return-to-play timelines. Currently, there is no reliable diagnostic test or marker that can be used to identify a concussion when it’s occurred, or similarly, determine when a concussion has resolved.\nFor this reason, a growing emphasis has been placed on objective baseline testing protocols that can be used to track an athlete’s recovery and serve as a tangible measurement for return-to-play readiness. By measuring an athlete’s “normal” level of functioning, we are better able to gauge the level of impairment that may exist post-injury by performing comparative testing. The Core believes this requires a multifaceted approach and that no single test should be used in isolation.\nThat is why the Shift Concussion Management Program at the Core offers several testing components designed to assess:\nNeurocognitive Performance (ImPACT)\nBalance and Postural Sway\nShift baseline testers also review and document previous concussive episodes and history of concussion-like symptoms to aid in individualized post-injury assessments should they be required.\nBaseline values can vary widely from one athlete to the next, and in young developing athletes, these measures can change dramatically from year to year. It is therefore important to have record of each player’s baseline level of physical and neurocognitive functioning before the start of each season. Should an athlete sustain a concussion during the season, Shift Practitioners have the ability to compare post-injury testing to baseline values. This allows for a more accurate and objective assessment an otherwise elusive injury, and provides important information when making return-to-play decisions.\nNeurocognitive Testing – ImPACT\nRecent advancements in concussion management have resulted in the widespread use of computer-based neurocognitive testing protocols, and evidence now shows that concussed athletes demonstrate subtle cognitive deficits that may persist beyond symptom resolution – emphasizing the fact that return to play once “symptom-free” is no longer an accurate measure of readiness.\nFor this reason, Shift employs computerized neurocognitive testing as part of all baseline and post-injury assessment protocols. This type of testing provides us with a snapshot of how an athlete’s brain is functioning both pre and post injury by measuring things like reaction time, processing speed, memory, and attention/concentration. These cognitive processes are often affected by concussive injury, and so this type of testing provides us with important information when managing an athlete’s recovery.\nNote: computer-based neurocognitive tests that are designed for concussion assessment (eg. ImPACT) are valuable and valid tools that provide objective information on various aspects of neurocognitive performance; however, these tests are not meant to replace a full neuropsychological assessment that would be provided by a qualified Neuropsychologist. When more complex or comprehensive testing is required, specialist referral may be indicated.\nIt is well known that neurocognitive performance may be impacted following a concussion, but other aspects of physical performance may also be hindered: e.g. balance and visual coordination skills. This type of testing is often overlooked during traditional baseline evaluations, but all Shift clinical sites offer these additional testing components to gain a more complete picture of our athletes.', ""CONCUSSION CARE 101 GUIDE\nFor healthcare professionals who want to set up a concussion care medical practice.\nHOW TO START A MEDICAL PRACTICE THAT SPECIALIZES IN CONCUSSIONS?\n- Find a concussion specialist to become your practice team leader.\n- Include other disciplines in your team: athletic trainer, physical and occupational therapists, and other rehabilitation professionals.\n- Define what tools your practice will need: removal from activity screening tools, neurocognitive testing, vestibular/ocular screening, balance screening, etc.\n- Decide what kinds of head injury you want to specialize in.\n- Establish a clinical workflow that makes sense for your practice.\n- Train your entire team to provide best-in-class service.\n- Promote your practice through community baseline testing, an extensive referral network, community educational resources, and digital marketing.\n- Recommend everyone in your community take a baseline test, so your patients can get a tailored treatment if they ever get a concussion.\nWHAT'S THE FIRST STEP IN SETTING UP MY CONCUSSION CARE MEDICAL PRACTICE?\nConcussions are a common injury that requires a complex treatment.\nBecause so many disciplines are involved in treating concussions (athletic trainers, clinicians, physical therapists, nurses, occupational therapists, etc.), the very first step is to determine who will be the concussion care team leader.\nIt is important to designate one person who can conduct initial assessments, coordinate referrals, and make return to activity decisions.\nIdeally, this person would be a Credentialed ImPACT Consultant (CIC) – a qualified healthcare provider who has been specially trained in the management of a concussion. This point person should be licensed to make return to play / return to activity decisions in the area in which you practice and should have good knowledge of a concussion. (Learn more about the CICs role in concussion care.)\nWHICH DISCIPLINES SHOULD BE INCLUDED IN MY CONCUSSION CARE TEAM?\nConcussions are a traumatic brain injury (TBI) that need a multi-disciplinary team working together to improve patients’ recovery processes. When you’re creating your concussion medical practice, it’s important to keep in mind the scopes of practice each professional covers to make sure there are no gaps in your team:\n- Point Person: a qualified healthcare provider who serves as the point person on the concussion care team and makes return to activity decisions;\n- Athletic Trainer: recognizes signs and symptoms of concussion at the point of injury and serves as the liaison between family members, school, and practice. Learn more about their role in concussion management;\n- Physical Therapist: works in vestibular therapy, active rehabilitation, or target specific deficits identified by the point person. Learn more about their role in concussion management;\n- Physiotherapists (outside the US): involved in concussion assessment, concussion treatment, and concussion rehabilitation. Their scope of practice depends on country laws;\n- Occupational Therapist / Optometrist: helps with activities of daily living and vision therapy;\n- School Nurse: helps students return to school safely and avoid activities they shouldn’t engage in. This person also pays attention to the appropriate academic workload;\n- Speech Language Pathologists, School Psychologists, other multi-disciplinary team members: may participate in return to school, anxiety/mood issues while recovering from a concussion, or other areas as needed.\nWHAT TOOLS DO I NEED IN MY CONCUSSION CARE MEDICAL PRACTICE?\nConcussion care and recovery require a multi-faceted approach. Here are some of the tools you need to help your concussion medical practice succeed:\n- Removal from Activity Screening Tools: Healthcare providers should use objective tools as well as a comprehensive exam to screen for concussions. ImPACT Quick Test is a screening tool that helps with removal from activity decisions and can be administered on an iPad immediately following a suspected injury at the competition site, workplace, or point of care.\n- Computerized Neurocognitive Testing: Neurocognitive testing offers an objective measure to track neurocognitive functioning. ImPACT and ImPACT Pediatric are cognitive tests that help healthcare providers assess concussions and make important care decisions.\n- Vestibular/Ocular Screening: Approximately 50% of post-concussion patients report vestibular symptoms. Vestibular Ocular Motor Screening Exam (VOMS) is a free, simple assessment that may help dictate treatment plans. The VOMS is included with ImPACT Quick Test.\n- Balance Screening: Balance can be an important measure of post-concussion status, especially shortly after an injury. The Balance Error Scoring System (BESS) is a straightforward test that requires only a stopwatch, a balance pad, and an assistant to act as a spotter. The BESS is included with ImPACT Quick Test.\nWHAT ARE THE GUIDELINES TO KEEP IN MIND WHEN SETTING UP MY CONCUSSION CARE MEDICAL PRACTICE?\n- There is no “one-size-fits-all” concussion clinic model: every program is different. Set up your practice in such a way that works for your patients and clinical workflow.\n- Concussion care is constantly developing. Make sure you and your medical professionals follow best practices and keep up on current research.\n- There is no “one stop shop” for concussion care. Look for tools to evaluate and measure brain function so you can have an objective picture of each traumatic brain injury you examine.\n- Most importantly, your concussion care medical practice should be a reflection of your passion. Strive to improve patient outcomes and reduce long term negative effects of a concussion.\n- A reliable treatment plan for a concussion requires interdisciplinary care. Partner with primary care, physical therapy, and sports medicine professionals to make sure you offer well-rounded concussion care.\nWHAT TYPES OF PATIENTS WILL MY CONCUSSION CARE MEDICAL PRACTICE SEE?\nThe types of patients you see will likely be determined by your geographic location. If you’re the only concussion care medical practice in your area, you can set yourself up to be the go-to provider for treating concussions.\nIf there are other practices in your area, you may consider specializing or offering a service your competitors don’t. You play a role within your community - find out what that role is!\nWhen deciding who your ideal patients are, it’s important to keep in mind the kinds of head injury you want to specialize in.\nDo you want to be known for sports concussion rehabilitation?\nAre you specializing in treatment of post-concussion syndrome?\nDo you want to be a jack of all trades?\nDo you want to do concussion diagnosis and treatment mainly for pediatric patients?\nAre you specializing in tailored return to work treatment for worker's comp cases?\nAfter you define your niche, you should create a strong mission statement to communicate your standard of care.\nA good mission statement might be:\n“Our practice strives to provide best in class concussion care for patients of all walks of life. Our mission is to improve patient outcomes following concussion by using best practices and current evidence.”\nBy sticking to your unique mission, your concussion care medical practice will be able to leverage the best available resources and research to help head trauma patients get better.\nHOW DO I DEVELOP MY CONCUSSION CARE MEDICAL PRACTICE WORKFLOW?\nAfter putting your concussion care team together and agreeing on your business goals, decide what parts of the concussion care process you want to handle. Steps include:\n- Concussion education: Provide education to students, parents, school staff, and general public on concussion basics, risk factors, diagnosis, and treatment. These resources can help get you started.\n- Baseline concussion testing: Promote baseline testing as a critical piece of concussion care. Baseline testing ensures that, in the event of a head injury, you have a clinical report to determine the patient’s “normal” neurocognitive functioning.\n- Point of injury evaluation: Become a go-to decision maker when it comes to removal from activity decisions. Get a tool to help you with screening athletes and patients.\n- Acute injury management: Be the centerpiece of concussion treatment. Have the tools, knowledge, and skills to help with concussion diagnosis. Know the first steps after a concussion is diagnosed.\n- Complicated concussion management: Have a referral network and tools to manage individualized, complicated concussions. 20% of concussion patients take longer than 3 weeks to recover from their TBI.\n- Return to activity clearance: Be familiar with the laws in your area and regulations surrounding return to play activity. In addition to return to play, have a process in place for how you'll manage return to learn and return to everyday activity such as driving, exercising, and recreational activities.\nHOW DO I TRAIN MY CONCUSSION CARE TEAM?\nCommunication with all the members of your concussion care team is crucial to the success of your patients’ recovery. To get your team on the same page, get training in the following areas of practice:\n- Point Person: training on concussion assessment and treatment decisions;\n- Athletic trainer: training on removal from activity, academic adjustments, and return to activity;\n- Physical therapist: training on concussion rehabilitation;\n- Physiotherapist: training on concussion rehabilitation and assessment (depending on location);\n- Occupational Therapist: training on functional activities and vision therapy;\n- Billing Staff: Proper billing and coding procedures for concussion care services;\n- School Nurse / School Staff: ImPACT onboarding training including administration instructions and a Customer Center walkthrough;\n- SLPs, Kinesiologists, other team members: training as needed to support concussion care team\nConcussions are best treated by a multi-disciplinary team working within their scopes of practice to improve outcomes and reduce patients’ recovery time. With the right training, team, and tools, you’ll be in the perfect position to provide best in class concussion care in your community.\nHOW DO I BILL FOR CONCUSSION CARE SERVICES?\nDepending on your practice’s setting and location, billing for concussion care services may vary. Learn about eligible CPT codes using the resources below to get reimbursed for using ImPACT, ImPACT Pediatric, or ImPACT Quick Test as part of your concussion evaluation.\n- Billing Guide\n- Billing and Coding for Concussion Care Course\n- Billing and Coding for Concussion Rehabilitation Course\nHOW DO I PROMOTE MY CONCUSSION CARE MEDICAL PRACTICE?\nAs a new practice, you’ll need to introduce your products and services to the community and build your practice as a go-to provider for concussion care. To supercharge your marketing, here are a few tips and resources:\n- Organize community baseline concussion testing: This is a fantastic way to show goodwill in your community, as well as educate students, parents, and school staff on concussions. You’ll also build relationships and in case of a suspected concussion, you'll be the top of mind person.\n- Build a referral network: Connect with providers in your area who offer services your clinic doesn’t, and make them aware of the services you provide. Improving patient outcomes is at the core of great concussion care - recognize your strengths and weaknesses and fill in the gaps as needed.\n- Create resources that educate your community: ImPACT Applications has a variety of resources available for you to use. Existing ImPACT Applications customers can also contact us to customize carefully selected community outreach materials with your clinic’s logo.\n- Inform parents and students: Share this Concussion 101 Guide with parents and students.\n- Invest in a digital marketing strategy: Understand who your target audience is. Make sure your clinic is active on social media and easily found on search engines, like Google and Bing. You can hire a full service online marketing agency to help you with your marketing efforts if you don’t have the time and skills.\n- Excel in customer service: Have the best human resources possible to make sure your patients are being treated fairly both online and offline.\n- Get one of your physicians trained as a Credentialed ImPACT Consultant to be your point person: Besides receiving best in class concussion training, CICs receive a featured listing on ConcussionCareProviders.com, showcasing your clinic as a go-to provider for concussion care.\n- Add ImPACT Trained Healthcare Providers to your team: ImPACT Trained Physical and Occupational Therapists receive a listing as rehab professionals on ConcussionCareProviders.com. ImPACT Trained Athletic Trainers have an additional listing, highlighting your team as trained in concussion care.\nConcussion is a complicated injury that requires proven and effective concussion medical practices, protocols, teams, and tools. With the right resources, you can make a lasting impact in your community and become known for providing best in class concussion care. Use this checklist to jumpstart your marketing efforts.\nHOW DO I MAKE SURE MY PATIENTS HAVE A BASELINE TEST BEFORE THEIR VISIT?\nThe best comparison of a patient’s cognitive status after a concussion is to their own baseline. Educate your community and recommend they take a baseline test at home at BaselineTesting.com. It’s another way of making sure you’re providing the best concussion care possible.""]"	['<urn:uuid:0a4065d7-060a-4f85-ba2b-834295222d3a>', '<urn:uuid:ec057b62-b52e-4b89-bd52-26f54828ba31>']	factoid	with-premise	short-search-query	distant-from-document	three-doc	expert	2025-05-13T03:20:41.944655	6	70	2631
36	As a neurologist studying pain management, I'm curious about how knee pain manifests during flexion and what brain changes occur during meditation-based pain management approaches. Can you explain the connection between these aspects?	Knee pain during flexion can manifest in several conditions: in osteoarthritis patients experience varying degrees of pain when flexing while standing or walking; in patellar tendinitis, particularly common in athletes, pain occurs with flexion with or without weight bearing; and in patellofemoral pain syndrome, pain worsens with flexion or after sitting for extended periods. Regarding meditation's effects on pain management, research shows that meditation causes several relevant brain changes: it decreases activity in the amygdala (reducing stress and anxiety responses), increases cortical folding for better brain effectiveness, and enhances axon density in the anterior cingulate (improving focus and self-regulation). These neurological changes can help in pain management by reducing stress responses and improving emotional stability.	"[""Knee pain is a common reason that people visit their doctors. The knee is the largest weight-bearing joint in the body and takes significant stress when an individual walks, runs, or plays sports. The knee has obvious actions, including flexion and extension or bending and straightening. But the knee also can slide and pivot slightly. Pain with bending the knee is a sign of injury or damage within the joint.\nSeveral types of arthritis can affect the knee. Doctors at Mayo Clinic believe that osteoarthritis is the most common type of arthritis affecting large joints, such as the knee. Other types that can potentially affect the knee include septic arthritis, rheumatoid arthritis and gout, also a form of arthritis. Individuals with arthritis experience varying degrees of pain when standing or walking, swelling, stiffness and loss of flexibility, including difficulty and pain with flexion. (Reference 1)\nVideo of the Day\nTendinitis is an irritation or inflammation of one or more tendons that support a joint. Often it is a result of overtraining or over use. According to Mayo Clinic, athletes are more prone to patellar tendinitis. The tendon connects the quadriceps muscle in the front of the thigh to the lower leg bone. Runners, skiers and cyclists depend upon this action to support their athletic performance, making them more at risk for over use. Sufferers experience pain with flexion, with or without weight bearing. (Reference 1)\nPatellarfemoral Pain Syndrome\nIndividuals with this condition have pain under or around the kneecap. The pain is worse with flexion or after sitting for a long period of time. The American Academy of Family Physicians recommends that individuals who are experiencing this overuse injury take a break from their activities, ice the knee several times per day and evaluate the type of footwear they use. Exercises can also help to strengthen the muscles around the kneecap and relieve the pain. (Reference 2)\nThis is an inflammation of the small sac of fluid that cushions the outside of the knee joint. According to Mayo Clinic, bursitis causes considerable pain with flexion while weight bearing, such as going up or down stairs. Individuals with bursitis may also experience redness, swelling, warmth or fever. (Reference 1)\nOsgood-Schlatter disease is an inflammation of the bone, cartilage and tendon at the top of the shinbone. According to Kids Health, only one knee is usually affected and adolescents who are active are more prone to the condition. It usually strikes during a growth spurt and more often to adolescents who play sports that involve twisting, running or jumping. The pain can be mild to severe and constant. It gets worse with exercise and flexion. (Reference 3)\nThis cyst is an accumulation of fluid that forms behind the knee. It can be caused by herniation of knee joint capsule or the tearing of the meniscal cartilage of the knee. The U.S. National Library of Medicine recommends that a ruptured Baker's cyst is quickly differentiated from a blood clot that can cause the same pain with flexion of the knee. A blood clot can represent imminent danger and requires immediate medical attention. (Reference 4)\nIs this an emergency? If you are experiencing serious medical symptoms, please see the National Library of Medicine’s list of signs you need emergency medical attention or call 911."", 'A previous post in March 2012, Meditation and Neuroplasticity, outlined research about meditation causing changes in the brain, including new brain cells, axons, dendrites and synapses. These studies showed dramatic brain alterations for all of the major traditions of meditation. A brief summary of that previous research follows.\nThis post will look at the most recent studies that continue to show new effects of meditation on the brain, as well as new applications.\nSome of the information summarized in the previous post appeared in a recent review article in the journal Nature Neuroscience. This article additionally describes that severe stress causes increase in some of the regions of the amygdala, (emotional center related to fear) and decrease in regions of the hippocampus (memory and learning), and pre frontal cortex (decision-making). It notes that meditation counteracts these stress related brain changes. Meditation decreases anxiety and fear, and increases memory and cognitive abilities.\nThis Neuroscience review reported additionally that compassion meditation (summarized in previous post and below) increased gamma oscillations and synchrony, as well as increased activity in brain regions related to empathy. It also emphasized that changes in the brain from mindfulness meditation can occur in just eight weeks.\nThe article raised the question whether meditation research is complicated by the fact that changes in the brain could also be from daydreaming, and self-reflection. Daydreaming has been recently linked to creativity (see research and discussion below) and self-reflection might also cause brain changes. Social learning in children, including self-reflection, significantly helped academic achievement.\nBrief Summary of Previous Meditation Post\nThe previously described brain changes for three major types of meditation are:\nCompassion: In meditation emphasizing a focus on compassion and “loving-kindness” there was increased concentration. There was also increased activity in frontal brain regions (positive emotions and self control) and thalamus (filters sensory- motor signals), and a decrease in the parietal region (visual and spatial).\nMindfulness: Mindfulness meditation showed increased neurons and connections in right frontal cortex, (concentration), insula (emotions) and right parietal and temporal (sight and sound). It showed a decrease in amygdala (stress), and increase in hippocampus (memory)\nTranscendental: Transcendental meditation showed more activity in frontal and parietal (attention), and decrease in thalamus, (sensory) and basal ganglia (choosing actions). The brain waves showed increased coherence and more synchronous oscillations throughout the brain.\nDefault Network: In all types of meditation a very important finding was that the Default Mode Network (DMN) was changed, briefly in novice meditators and permanently in experienced meditators. The DMN is the part of the brain that operates with non-focused internal thought and daydreaming (memories, future planning, wondering, thinking about others). This new default network caused by meditation now included new brain centers (dorsal anterior cingulate and dorsolateral prefrontal cortex) and was associated with increased control of behavior and thought.\nBasically, meditation of all types increased focus and self-monitoring of thought and emotion.\nWide Range of New Research\nAs the research into meditation has expanded, there are new findings in brain connectivity, neuroplasticity (brain changes and brain region growth), multitasking, and emotional monitoring. Other research has focused on the specific uses of meditation in cancer, cardiovascular disease, depression, and war related stress.\nAs these new results are incorporated into brain science, a broad question arises about the relation of meditation, daydreaming, sleep, physical exercise and creativity. These are discussed below.\nGeneral Brain Changes with Meditation\nGyri in the cortex are the folded regions of the cortex that allow for increased complexity and increased connectivity of the neurons. A recent study showed that with all of the different meditation techniques there are increased folding of the cortex, that is, increased “gyrification.” Significantly, the longer people had practiced the various forms of meditation, the more this effect of increased cortical surface area was evident. This correlates with increase brain effectiveness.\nIncreased Axon Density and Myelin\nA study using advanced diffusion tensor fMRI showed that one month of Chinese mindfulness training, called IBMT (Integrative body-mind training) increased the density of axons, which means more ability to signal and more connectivity (see post on Connectivity). These changes in the neurons of the anterior cingulate, a center for focus, attention, concentration, and self-regulation, also included an increase in myelin (myelin surrounds mature neurons and increases the speed of transmission of the signal). The increase in axons occurred after two weeks, and the increased myelin in one month. In early development axons also develop first, followed later by myelin.\nThis study of Chinese mindfulness meditation also found decrease in stress, measured by hormones in the blood. Other findings included less anxiety, depression, anger and fatigue. There was an increase in blood flow for the cingulate cortex after five days of 20 minutes meditation. The subjects had lower heart rates, decreased skin conductance, decreased breathing rates with increased belly breathing.\nStudy groups of meditators and non-meditators were given questions with multiple answers (for example, “Name one of the seasons”), then one of the correct answers was flashed on a screen either in a way that could be seen consciously or for only 16 milliseconds, a rate that is too fast to be consciously seen. The meditation group was able to see the subliminal, unconscious, words better. Either they were aware of unconscious material or their concentration was better.\nNew research with mindfulness meditation shows an improved ability to multitask after the meditation session. The study included simultaneous work with emails, calendars, instant messaging, telephone and word-processing tools to perform common office tasks. They measured speed, accuracy and the extent of switching between tasks. The meditation group showed an ability to stay focused on a task longer with less distraction. They were able to concentrate better, and switch less. They also had decreased stress, increased memory and equal or better productivity\nMeditation and Disease\nMeditation has now been used to help treat a variety of medical problems. The recent studies include anxiety from cancer, cardiovascular risk in teens, and depression.\nAn analysis of 22 studies involving 1400 patients from Denmark showed that cancer patients had less anxiety and depression with mindfulness meditation. The result lasted at least six months after the study period.\nCardiovascular Risk in Teens\nIn a study of 62 black teens with high blood pressure, meditation showed positive effects on their heart. With fifteen minutes of transcendental meditation a day, their heart’s left ventricle became smaller (an enlarged heart is a sign of weakness with an extra workload from the higher blood pressure). The deep rest of the sympathetic nervous system during meditation lowered blood pressure and heart size.\nAnxiety and Depression\nA new study shows meditation has long-term effects on emotional stability, and decreased anxiety and depression. As in previous studies there was a change in the default network related to daydreaming and self-oriented thought with long-term meditators. This new study of experienced and novice meditators showed weaker synchronization between two regions of the medial prefrontal cortex – the dorsal (cognitive) and the ventral (emotion, self evaluation). This correlates with improvement in depression, because depressed people have hyper connectivity between these two areas. There was also a greater synchronization to the right parietal lobe, which is related to attention. Consequently, research seems to suggest that when meditation is practiced alongside regular trips to one of the many mental health facilities out there for mental health treatments, then the symptoms of anxiety and depression can be improved.\nPhysical Exercise, Meditation, Sleep, Daydreaming, and Creativity\nThe complex relationships between physical exercise, meditation, sleep, and creativity are not yet fully understood, but are intriguing. Physical exercise and meditation are both noted to increase brain regions and increase new learning. Sleep is noted to increase learning and memory as well as creativity. Meditation is also shown to increase creativity. Are these similar or different mechanisms?\nPrevious studies have shown that sleep during the time of slow waves stimulates increased memory for learned material. This learning could include athletic skills. When exposed to sound and odor cues during sleep the memory of specific locations was increased. Sleeping and dreaming are also correlated with increased creativity. Just recently a tune was played to musicians during slow wave sleep and this enhanced their ability to play the tune when they awoke.\nDaydreaming and the Wandering Mind\nDaydreaming is important because it allows us to imagine future events, to flesh out ideas, and to create.\nA recent study asked subjects to list as many uses as possible for everyday objects such as toothpicks, clothes hangers and bricks. One group then did an undemanding task that encouraged daydreaming. Other groups did focused work, or nothing. The daydreaming group did much better on the next round of creative questioning.\nOther studies show that when a person’s mind is wandering they perform better in creativity, association and insight tasks. These include imagination games, original thinking and invention. A recent study showed that people report a wandering mind 47 percent of the time.\nTop Athletes, Musicians and Managers\nIncreased brain coherence is noted in meditation, but is also demonstrated in elite managers, musicians and athletes.\nTo measure exceptional performances with high brain integration a variety of measures are used. One measure of brain performance is increased coherence of brain waves measured by EEG (see post on Brain Oscillations). This measures how different parts of the brain are in sync with each other and work together. Another EEG measure, that of alpha waves, is related to alertness. The third is a measure of how efficient and effective the brain operates.\nBy these measures high-level managers, as well as elite professional and amateur musicians showed much more brain integration than less qualified managers and musicians. The most recent study shows that elite athletes also have this high brain integration by the three measures. They also shared a cluster of subjective experienced often referred to as “peak experience,” which includes inner calm, effortlessness, extreme wakefulness, ease of functioning, absence of fear, and a sense of perfection. Some athletes and musicians refer to this feeling as a performance “high”.\nIt remains for future studies to relate this “peak experience” to meditation states\nIn Elderly Tai Chi Increases Brain Size, Improves Cognition\nTai Chi is a meditative physical exercise, which is less aerobic than other forms of exercise. Research has already shown that exercise increases brain growth factors to make new cells. Seniors who engaged in Tai Chi three times a week for eight months had increases in brain volume, and better memory and thinking. One of the control groups that used lively discussions instead of the Tai Chi, showed some increase in brain size but less cognitive improvement. The other control group with no intervention had brain shrinkage. Previous trials showed increases in brain with exercise (new brain cells for new learning), increase in memory, but not as much cognitive improvement.\nNeuroscience, Meditation, Yoga, and Performance in War\nJust as the great American Indian warrior Crazy Horse did many years ago, the new soldier is learning to concentrate his mind for battle using meditative techniques. Martial arts, such as Tai Chi, Karate, and Kung Fu, have always used meditative techniques for superior focus, balance, power and muscular coordination.\nYoga and meditation are now being used in the military to help soldiers become calmer and better decision-makers in order to avoid trauma. Meditation is used before mock training that attempts to simulate the chaos of war scenes. While most military research has been related to brain injury and post traumatic stress, new brain studies, including brain imaging and blood tests for stress markers before and after simulated combat, are being done at the Warfighter Performance Lab to determine stress affects decision-making. Meditation techniques including breathing exercises are being applied to help the soldiers regain a state where good decisions can be made.\nThe psychological terms used in these military studies include “resiliency”, “psychological hardiness” or “mental toughness”. The new training called Comprehensive Soldier Fitness program increasingly includes these emotional, and psychological elements. Most soldiers have signs of stress, but only 20% have great difficulty in dealing with it. Training in elite forces, like the SEALS, simulate severe states such as near drowning to see who can tolerate this very high level of stress.\nThe most elite group remaining after very grueling SEAL training shows more activation in the insula, an area related to self-awareness, pain and emotion. The insula also helps relieve stress with awareness.\nOne early study, called the Trojan Warrior Project, included 10 days of meditation, yoga, and martial arts. After these sessions, soldiers performed much better in biofeedback tests of muscular and neurological reactions to stress. They were also able to learn a foreign language faster, learn complex technical weapons systems better and were better marksman.\nCurrently, SEALs are using meditation in training, based upon neuroscience data of increased gray matter volume and better synapses in the pre frontal cortex. These brain changes lead to improved ability to have attention control triggers of the amygdala fear responses. The Mindfulness Based Stress Reduction program showed decreased stress, and improvement in concentration, memory, performance of complex tasks, and regaining focus after stress.\nAnother meditation study for eight weeks, using fMRI, blood markers and saliva markers, showed a better recovery from stress. After the study period soldier’s brains were more likely to resemble the brains of elite SEALS and Olympians.\nPrevious posts have focused on how attention, and suggestion, as well as meditation, change the brain. The recent understanding is that the brain is much more “plastic” or changeable than previously thought and will change in any way that we choose to exercise it.\nIn normal function any mental event creates rapid changes in neurons, including building and rebuilding very complex structures almost instantly. (see post).\nMeditation is a specific training that builds a “muscle” of mental concentration with increased memory, creativity and cognitive abilities. These new abilities include being able to control the effects of severe stress and include a variety of different subjective internal states.\nAs mechanisms of these changes are elucidated in the future, hopefully the details of subjective meditative states can be correlated with molecular changes in the brain.']"	['<urn:uuid:a7c649ae-569a-46d3-948f-2114f5aa55be>', '<urn:uuid:425237aa-1a9b-43ba-8f34-1c263437e374>']	open-ended	with-premise	verbose-and-natural	similar-to-document	multi-aspect	expert	2025-05-13T03:20:41.944655	33	115	2896
37	Who created the art show using colored rope bundles?	Brazilian artist Frida Baranek created Reflections on the Horizon, which is composed of manila rope bundles affixed to colored, transparent and engraved acrylic disks.	['One thing we look forward to every year during Art Basel in Miami Beach is the fair’s Public Sector. This time around, the installation on Collins Park is curated by Philipp Kaiser, and includes work by Frida Baranek, Frida Baranek, Noël Dolla, Cyprien Gaillard, Jim Shaw, Daniel Knorr, Abraham Cruzvillegas, and more.\nWhitewall spoke with Kaiser about the exhibition, entitled “Territorial.”\nWHITEWALL: You’ve curated projects all around the world. How did the city of Miami Beach influence the project for Public?\nPHILIPP KAISER: I have always found Public to be a fascinating sector of the show in Miami Beach because of the opportunities it presents to artists and galleries to create large-scale site-specific, ambitious works that interact with the space of Collins Park and the broader Miami Beach community. The landscape of Collins Park certainly played a role in determining the projects for the sector, and also in how several of the artists themselves are approaching their works. One piece that particularly reflects this dialogue is Reflections on the Horizon by Brazilian artist Frida Baranek. The work builds upon the artist’s interest in the horizon line and is composed of several manila rope bundles that are each affixed to colored, transparent and engraved acrylic disks. Visitors are invited to pick up the disks and gaze through them, as each one generates a different perspective and sensation of Collins Park.\nWW: Can you tell us about the theme for the exhibition, “Territorial”? and how did you go about selecting artists for commissions?\nPK: “Territorial” focuses on works that claim space or territory through size, scale, intensity or sound, among other artistic practices. Centering on this genuine and ontological quality of sculpture, I have chosen to present 11 works, which will be ambitious in scale and reflect the great opportunity that Public offers to feature works of art on an institutional level. A centerpiece of the sector will be Daniel Buren’s Les Guirlandes. Standing 36 feet in height, the work will occupy a substantial amount of Collins Park and aims to redefine the space using both sound and motion. Additional highlights include a new large-scale installation by French artist Noël Dolla—his first project to be presented in the US—and a multimedia video piece by Cyprien Gaillard. Visitors will also be treated to a special presentation with the premiere of artist Jim Shaw’s progressive rock opera The Rinse Cycle, performed with the band D’red D’warf on Wednesday, December 6.\nWW: Are any of the artists involved creating a public work for the first time?\nPK: Most of the works have never been shown before in the Unites States and had to be adapted to Collins Park. I am especially excited that both Daniel Knorr and Abraham Cruzvillegas conceived new works for Public. Knorr’s humongous piercing in the main axis of The Bass is a critical nod to Piero Manzoni’s Socle du monde, 1961, and talks about its site, the center and the periphery, while Cruzvillegas is composing a temporary shelter.\nWW: As a curator, how do you approach a public project versus a museum exhibition? What sort of audience considerations are key?\nPK: The nature of the city and location of the work plays a very important role in both how an artist and a curator approach presenting a public work of art. A public installation is on view for everyone from every walk of life to see, and becomes part of the fabric of that community, so may reflect different techniques and themes than a work meant for a museum exhibition.\nWW: What are you looking forward to in Miami this year?\nPK: In addition to unveiling Public, I am really looking forward to seeing the exceptional artworks that will be on view on the show floor in the Miami Beach Convention Center, as well as the exhibitions at Miami’s local institutions—particularly the shows at the newly-renovated Bass and at ICA Miami’s new home in the Design District.']	['<urn:uuid:c3d46619-7b9f-4dc2-b79e-590afbe2517e>']	factoid	direct	concise-and-natural	distant-from-document	single-doc	novice	2025-05-13T03:20:41.944655	9	24	656
38	What are music festival waste problems and solutions?	Music festivals generate large amounts of waste, with 80% of trash left behind by campers including tents and camping gear, producing over 6 pounds of waste per person daily. Solutions include DGTL festival's zero-waste approach with circular systems for energy, resources, and food, plus their partnership with SkyNRG to reduce aviation emissions through sustainable aviation fuel.	['Summer just wouldn’t be the same without festivals. The music, the food, the people, the party—memories that last a lifetime, but fewer people remember the mess left behind after music festival. Once the party is over, not many people pay attention to the amount of rubbish left behind. All that trash just sits around until waste contractors collect it up and dump everything in a landfill.\nThe culture of music festivals is important to Australia, but so is the environmental impact of these festivals. As this music festival waste problem worsens, questions concerning the sustainability of it all and solutions for the waste have arisen.\nAre Music Festivals Environmental Disasters?\nMusic festivals are a lot of fun. Their curators are continuously expanding to meet the demands of festival-goers, but they don’t always make an effort to set up an eco-friendly festival. It’s estimated that 80% of trash from summer music festivals is generated and left behind by campers themselves, even including items like tents, sleeping bags, camp chairs, gazebos, clothes, rubber boots, and of course, leftover alcohol and food. Many of these items are used for a weekend and then dumped. Attendees are ruining the grounds they’re camping out on.Many sites don’t have enough trash cans, don’t have cleaning crews coming through, and have nowhere to throw their trash. Festival rubbish removal can be costly though, which can add to the ticket price and make the overall cost of the festival even more than it already is.\nEven if there are a few programs in place to attempt to handle this trash problem, there have still been issues with excess trash left behind as a result of the “drop everything” mentality some festival-goers have. Thankfully, there have also been increasing efforts on the festival scene to go green and improve sustainability.\nEnvironmental Sustainability and Live Music\nWith the Australian festival culture making it somewhat challenging to keep festival grounds clean, people wonder if it’s possible to practice environmental sustainability while still having a great time on the campgrounds. If you’ve ever lingered after a festival and watched the clean-up effort stepping around the abandoned food and items on the ground as you walk around, you might have pondered the possibility of sustainable waste management for festivals too.\nFestivals can produce the equivalent of over 6 pounds of waste per person per day, which is much more than you would typically produce at home or work. Six litres of diesel are used too just to power everything, generating tons of carbon emissions per year. For all the waste that’s produced though, only around 32% is recycled. On top of that, think of the damage all the foot traffic does to the environment itself, and the emissions that come from the vehicles people use to drive to the festival grounds.\nReducing Waste and Environmental Impact\nSo what kind of sustainable efforts have people been considering to reduce the environmental impact by festival rubbish? Many festival organisers are aware that they need to do something in order to limit the environmental impact, but in order for anything to change, festival-goers themselves have to be willing to participate.\nRecently, there have been programs set up to reduce the emissions from transport to the festivals, which make up a total of 80% of the overall emissions. Organisers have begun to reward people for using a lower-emission route, offering shuttle services, and providing rewards for people riding in cars with more than four people. There are even areas with bike parking lots to encourage people living close enough to leave their car at home and dedicated buses for people to shuttle over to festivals in mass.\nFestival organisers themselves have been working to increase their own sustainability by treating water on site and reducing waste with renewable fuels and new recycling efforts. They’ve even taken initiatives to provide locally-sourced organic food to reduce the carbon footprint of food provision as well and have made it easier to restore the environment after the festival ends too.\nEco-Friendly Festival Behaviour\nYou’ve seen how your organisers are trying to prevent the environmental disaster of festivals, but what can you do to reduce your footprint while you’re there? Instead of relying on greasy food stands set around or beverages in plastic bottles, you can buy some fresh fruit or organic meals set out right on the festival grounds. With green reusable cups, you can drink everything without leaving behind all the plastic trash festival goers have gotten far too used to seeing.\nThe waste produced at festivals has increasingly highlighted the negative impact of the festival industry prompting more eco-friendly behaviour from people who attend. More and more people are using low-emission transportation instead of travelling alone in their cars and choosing sustainable food options while at the festival grounds. All the food is sourced locally with a wide range of sustainable meals and reliable and natural origins to reduce the environmental damage.\nPlastic Recycling and Collection Can Help\nIn terms of plastic, reusable cups are being used to replace the plastic of the past, with some companies providing free water for those cups to reduce the plastic consumption overall. As for what you can do, consider bringing your own reusable materials too, like a water bottle, coffee cup, or plates. You can also try borrowing your camping gear instead of buying something cheap and leaving it behind. Event rubbish removal involves just taking all that left behind gear and throwing it away, so instead, borrow gear that’s likely higher quality than you would otherwise have, and save money while being environmentally conscious as well.\nMost importantly, remember to clean up after yourself. Many people just leave their trash around for others to clean up. It’s easy to bring your own garbage bag to set up with you. Try bringing eco glitter as well if you’re the glitter type. This glitter won’t harm nature when you use it or eventually end up hurting animals through the water, and you can still have a good time with it. The same goes for your clothing: don’t wear something you’ll have once and then throw it away. It’s all about sustainability.\nSkip Bin Solutions for Your Events\nIf you’ve ever been to a music festival, you may remember the overfull bins with trash piled on top of them and all around them when they get too full. People just leave the trash there, and even with increased festival rubbish recycling projects, there ends up being too much trash to handle at times. Instead of using classic bins though, consider using skin bin solutions for your events.\nEvent skip bin hire uses what’s known as a skin bin: a trapezoid shaped container for waste. You can find these bins in a range of sizes. They are able to hold a large amount of waste. Skip bins will keep all the trash in one place instead of you having to spread bins around. There will, of course, still be a large amount of waste, but your efforts at managing the water and handling the clean-up afterwards will be that much easier.\nHiring a Skip Bin to manage Music Festival Waste\nIf you chose to hire a skip bin, the first step is to decide how many of bins you’ll need and plan out where you want them to be placed so that people will use them instead of just throwing trash on the ground. Strategically place your bins, put up banners to direct people to them, and make sure people know exactly how to dispose of their waste. Come up with a plan to separate recyclable and non-recyclable materials, and place smaller bins near the exits to catch festival goers on their way out. Your skip bin hire provider can help with suggestions for this layout, and some placements may be limited by vehicle access, but bins can’t do all the work either.\nMake sure to keep an eye on how full your bins are too. If your bin is under-sized and becomes full, people may just begin leaving trash on the ground around it. This is an area where ensuring you’ve hired a good skip bin company matters. You want a provider with timely pickup schedules that applies good disposal practices. Most skip bin companies deliver all your music festival waste to a licensed sorting facility to figure out how to separate your trash for you.\nZero Waste Festivals\nIf you’re hosting an event or festival but want to do right by the environment in the process, consider hiring skip bins to remove waste. Eco-friendly festival rubbish solutions have been on everyone’s minds as of late. People want to make sure that while they’re having a good time at a music festival, they’re not destroying the environment in the process. Organisers have started sustainability efforts, and festival goers have become more committed to keeping the grounds clean themselves. Before you go to your next festival, think about what you might be able to do before you even arrive to keep everything looking great after the fun is over, and everyone needs to head on home.', 'In a world first, Dutch festival brand DGTL announced a partnership with SkyNRG, a global leader and pioneer in Sustainable Aviation Fuel (SAF), ensuring all artists to and from their international events reduce CO2 emissions from flying, by replacing fossil fuel with SAF.\nDGTL does everything it can to minimize air travel, but for journeys that are unavoidable, SAF will allow them to reduce their carbon footprint from flying to net zero, by replacing fossil kerosine with SAF. This innovation is the final piece in DGTL’s overall sustainability puzzle, with the organizers having already solved sustainability issues around energy, water & sanitation, food and commodities (waste) at their events. Tackling and unraveling the problem of mobility – often deemed a problem too far – means DGTL now has a firm handle on every aspect of their sustainability cycle. Working with SkyNRG, DGTL’s sustainability model once again provides a groundbreaking blueprint for other promoters and large-scale event organizers.\nOther circular systems at DGTL Festival (Amsterdam)\nEnergy: Completely on renewable energy, from 16,000 litres of diesel to 0 litres of diesel\nResources (formerly called ‘waste’): From 2.3 kg residual waste to 0kg residual waste per visitor\nFood court: 100% plant-based menu\nSanitation: Circular sanitation group, in which DGTL extracts nutrients from urine and faeces, to use them as soil improvers and fertilizers. From pee to tea\nDGTL’s Sustainability Coordinator Mitchell van Dooijeweerd commented: “We feel a responsibility to continuously improve and maintain our social and environmental impact on the globe and we are committed to leave the world a bit better than we found it. That’s why we are always researching and implementing innovative measures to progressively reduce emissions. But we’re looking beyond our own emissions too. Through this partnership with SkyNRG, we reduce CO2 emissions together with our artists and ensure that what we do inspires our surroundings. Replacing fossil kerosine with SAF is a huge step forward for unavoidable flights. Furthermore, it is a scalable solution that can reduce air travel emissions for other events too where air travel may be unavoidable. DGTL’s festivals have a huge reach, which is why it is important we lead by example and plant the seed for change.”\nSAF is fuel for aircrafts that is produced from sustainable resources, instead of being refined from petroleum, like fossil-based aviation fuel. SAF can significantly reduce CO2 emissions compared to fossil fuel, depending on the technology and feedstock used.\nSkyNRG’s Program Manager, Jef de Vries commented: “Although SAF has been in commercial use since 2011 and over 300,000 flights so far have been powered by it, it still makes up less than 1% of the overall fuel use in aviation. Therefore, SkyNRG scales up supply and demand by building new production capacity and forging partnerships with industry pioneers like DGTL festival.”\nExplaining how DGTL has collaborated with artists across its multiple global line-ups to drive the SAF initiative, festival booker Jelle Lobbes said: “When we reached out to the artists about this project, we found out most of them were already engaged in more sustainable travel. Agencies already implemented offset programs for their roster and really thought about their journeys. This showed we’re all on the same page and motivated us to join forces and take the next step forward.”\nSkyNRG uses a system for supplying SAF to DGTL called Book & Claim. With this system, SAF is not used on the aircrafts the artists fly with, but rather tanked into the fuel system of an airport close to the SAF production facility. The SAF produced and supplied is continuously tracked and the corresponding carbon emission reductions are then allocated to DGTL and the artists. The benefits of this system are that it reduces carbon emissions from fuel transport and uses existing supply chains. This system is also commonly used when purchasing green electricity. Green electricity is added to the overall grid by the person paying for it, without it being delivered to that specific person’s home, for example, thereby improving the overall sustainability of the grid.\nThe overall aim of the DGTL-SkyNRG partnership is to show the industry and all music fans – many of whom regularly use air travel – how they can reduce their own CO2 footprint by using SAF. To that end, DGTL and SkyNRG, together with climate tech builder CHOOOSE, will soon launch a leading-edge carbon emissions calculator that both the industry and general public can use to evaluate and reduce their CO2 footprint.\nThanks to their work with SkyNRG, more sustainable travel can now finally be ticked off DGTL’s sustainable ‘to-do’ list, making them true trailblazers in the world’s quest for achievable sustainability.\nFeatured Image Credit by: Kirsten van Santen']	['<urn:uuid:13edfd18-fdb0-4c6f-a664-82b019556e70>', '<urn:uuid:6a436441-71e2-41f3-be08-c1326b1d0c51>']	factoid	direct	concise-and-natural	similar-to-document	multi-aspect	novice	2025-05-13T03:20:41.944655	8	56	2300
39	australia concrete industry growth risks health precautions	The Australian concrete industry is poised for explosive growth, similar to where the US market was 10 years ago, with increasing demand for concrete benchtops but limited product availability and training. However, construction work comes with significant health risks, including chronic conditions like COPD, occupational deafness, and hand-arm vibration syndrome. These risks must be managed through proper risk assessments, protective equipment, and maintaining an open safety culture where workers can freely express concerns.	"['- Concrete Furniture Home\n- Concrete Furniture Photos\n- Concrete Furniture Types\n- Outdoor Concrete Furniture\n- Concrete Office Furniture\n- Concrete Storage Furniture\n- Design Ideas\n- Concrete Furniture Design Ideas: Behind-the-scenes info and photos\n- Free Concrete Furniture Catalog\n- Related Information\n- Learn How to Make Bent Concrete Furniture\n- Concrete Contractors: Find GFRC Mixes for Precast Concrete\nThe Ultimate Five-Day DeskStudents attending The Concrete Countertop Institute’s Ultimate training class were instructed to build a one-of-a-kind concrete desk in just five days. See the amazing results.\nProject submitted by Jeff Girard and Lane Mangum, The Concrete Countertop Institute, Raleigh, N.C.\nStarting with only dimensional design drawings and plans, these committed students attending a concrete countertop training class in Australia built an elaborate cantilevered concrete desk in just five days.\nDuring the intensive five-day session, students learned how to make forms, proportion concrete mix designs, cast the pieces, and then finish and seal them.\nAssembling the desk components.\nThe concrete sections of the desk are designed as floating cantilevers off a main spine of dark wood.\nA side view of the desk, which was made using a white GFRC premix.\nIf you think the amateur dancers who participate in ABC’s Dancing with the Stars have it tough, at least they are given a full week to master their routines before performing them live. For the students attending The Concrete Countertop Institute’s Ultimate training class, the challenge is even more daunting; they have only five days to learn every step of building both precast and glass-fiber-reinforced concrete countertops, including creating a project, from templating to installation, using from-scratch mixes.\nFor this particular class, held in Sydney, Australia, in February 2013, the challenge was to build an elaborate concrete desk. The piece was designed by CCI president and instructor Jeff Girard as one of the hands-on projects for the training session. “In the 5-day Ultimate class, we do a variety of projects showcasing precast and GFRC mixes and techniques. They are always unique. This was a particularly challenging project that Jeff dreamed up on the airplane on the way over,” says Lane Mangum, CCI’s vice president of business services.\nThe class was hosted by Domenic Scarpari, one of Girard’s former students. Scarpari is seeing a huge demand for concrete ""benchtops"" (as they call countertops in Australia). To help meet this demand, he wanted to give other students the chance to learn how to use the latest concrete countertop materials and techniques by hosting the Ultimate 5-day course in his shop.\n“Jeff and I were thrilled to be participating in this, and felt it would be a huge boon to the concrete countertop market in Australia,” says Mangum. “They are where we were about 10 years ago -- hardly any products available specifically for concrete countertops, hardly any training. They have all the internet information sources, but no local availability. So we all felt the Australian concrete countertop market was poised for explosive growth, once the availability was there.”\nBuilding the deskThe concrete sections of the desk are designed as floating cantilevers off a main spine of dark wood. The students were given dimensional design drawings and plans, and then they were tasked to figure out how to make the forms, proportion the mix, cast the pieces, and then process, seal and assemble them. One of the biggest challenges was forming the angles of the flared legs, which required cutting accurate bevels on a table saw.\nThe mix used was a white GFRC mix, with no pigment. The students did a light hand sanding of the exposed surfaces, and also honed and smoothed the underside of the desk where the exposed fibers created a rough surface. The desk was then sealed with a few coats of TK6 sealer from V-SEAL.\nAs the photos show, the students were up to the task, and quite proud of their accomplishment. Scarpari is now using the desk in his office.\nThe students who attend CCI’s Ultimate 5-day class vary widely in skill level. Some have made concrete countertops for years, and some have no concrete experience at all. “The most important skills are craftsmanship, attention to detail, the desire to create high-quality work and satisfy customers, and the desire to succeed in business. This is definitely not a class for hobbyists,” says Mangum.\nFor more information\nThe Concrete Countertop Institute (www.concretecountertopinstitute.com/australia)', 'Health and safety in the construction industry: what are the major risks?\nThe construction industry has the second-highest rate of fatalities across all industries in the UK according to the Health and Safety Executive (HSE) website statistics for 2019. Sadly, 30 people lost their lives during 2019 due to incidents on the construction site. With another 54,000 non-fatal injuries reported across the year, there is clearly a way to go when managing health and safety in construction to prevent further deaths and long-term conditions.\nThe construction industry is the European Union’s (EU) largest industry employer. A workforce of 18 million contributes to 9% of the EU’s gross domestic profit (GDP). This large and diverse workforce provides an invaluable service to society and the prosperity of each nation. So, why are there still so many incidents on construction sites and how can health and safety regulations work to protect our workers?\nTargeting the big five\nFive main categories of incidents are most common on construction sites:\n- Falls from height – which account for 49% of fatalities and 18% of non-fatal injuries (a number that is 10% higher than the statistics for all other industries)\n- Slips, trips or falls on the same level – accounting for 25% of non-fatal injuries\n- Being trapped by something collapsing or overturning – responsible for 14% of fatalities\n- Being struck by a moving, falling or flying object – the cause of 10% of fatalities and 12% of non-fatal injuries\n- Injured while handling, lifting or carrying – making up 20% of non-fatal injuries\nBesides these main issues, construction workers are at an increased risk from other serious and life-changing conditions. Conditions such as chronic obstructive pulmonary disease (COPD), occupational deafness, hand-arm vibration syndrome (HAVS) and asbestosis are serious and life-altering conditions that can be caused, or aggravated, by conditions on-site.\nHealth and safety legislation should be at the core of all construction businesses and every project, it should be a top priority for senior managers and it should be embedded into every plan, decision and activity. Read on for ideas on how to manage health and safety in construction, to ensure that your staff are safe, give confidence to your clients, maintain a flawless health and safety record and save time and money through introducing safety measures.\nAssess and avoid\nRisk assessments should be the first stage of all construction projects. Health and Safety teams should be involved in early planning to ensure that the health of workers is embedded in the project.\nAvoidance is the first key step. Is an activity deemed as dangerous? Can it be carried out in an alternative way that would avoid the danger? Can working at height be removed altogether or can fabrication be carried out on the ground and the structure lifted to height for fixing? Are hazardous chemicals essential to work, or can alternatives be found?\nIf time constraints or pressure from third parties will impact on the health and safety of your staff, these issues should be flagged to all stakeholders. If the risk can’t be removed, then safe working conditions should be made available through the correct equipment or protocols. If the situation can’t be made safe, then the group must work to change the working parameters. Time or client pressures should never impact the safety of workers on site. No project is that important.\nHealth & Safety: Do you have the skills on-site?\nOnce all stakeholders have understood and accepted the risk parameters for a project, plans must be put in place to reduce these risks. The main aim, and the measure of success for all health and safety teams, is for a project to run with zero reported incidents.\nChecking the qualifications and experience of all workers and supervisors is key. Workers must be able to perform tasks confidently and competently to reduce the risk to themselves and others. Construction Skills Certification Scheme (CSCS) card checks are a must in the UK and a full log of each card, every contractor and their competency to carry out a task must be documented. Where gaps in knowledge or experience are identified, training should be provided or new staff must be brought in to complete the task. If this can’t be done, then the task must be changed to accommodate the experience of the workers on-site, even if this does add extra time or cost.\nEnsure that qualified Health, Safety and Environment (HSE) officers are known to all workers and that all staff know how and when to report a dangerous situation. Whether you have a dedicated HSE officer on-site, site office staff logging incidents or an app-based solution everyone can access, it should be easy for anyone to report an incident.\nMake protective equipment a habit\nOnce you have the right workers with the correct experience, they must have access to the correct personal protective equipment (PPE) to carry out the job safely. Every person on site should understand the risks to themselves and those around them and know which equipment they need to complete the task safely. Wearing the necessary equipment should become second nature and this only happens if everyone adheres to the rules, if the equipment is missing, there should be a quick and easy way for staff to request it.\nManagers should model the behaviours expected of their teams. Everyone should be free to stop work and demand equipment if it is not available and to request that others in their team do the same.\nHealth and safety regulations become a habit when the culture enables team members to express their views openly. This open and honest approach rewards workers who show behaviours that protect their own safety and those of their colleagues.\nThe right tools for the job\nThis theme carries through to the suitability of equipment too. All equipment, from pneumatic drills and saws to large earthmoving machinery, should be assessed for its suitability and safety. Does the equipment pose a risk to the worker? Can a different piece of equipment give the same result with lower risk? If we do have to accept a risk, does the equipment minimise the risk in the best way? What other checks do we need to ensure zero incidents whilst using this equipment?\nChecks don’t stop when the equipment is in use. Maintenance schedules are essential to ensuring the safety of equipment and safeguarding those using it. A robust service and maintenance routine should be developed, assigned to an individual or team and monitored throughout the project, with any checks or maintenance work documented.\nIdentify issues, make changes and demonstrate the impact\nSoftware really can be a health and safety professional’s best friend. A good software package will allow easy data collection from multiple team members in multiple locations. Everyone should be able to easily report a health and safety concern, record standard health and safety data and complete assessments. The best software allows for collection through app-based systems, enabling any smartphone to become a data collection device.\nOnce data is recorded, software should help you to easily identify hazards and other issues, show where changes were made, demonstrate the impact of these changes and allow for easy reporting to senior management. This comprehensive and closed-loop data flow is essential for demonstrating regulatory compliance and for providing evidence during inspections.\nBy moving to a continuous improvement culture, issues that are flagged and dealt with on one project can be carried through as health and safety requirements for the next project. This process ensures that the same problem isn’t repeated and that everyone learns from previous mistakes.\nThe PlanRadar app is the perfect tool for completing comprehensive digital health and safety assessments through straightforward templates. Fire assessments and other specific templates can be designed, saved and adapted for future projects. And, most importantly, where plants require no transmitting appliances, PlanRadar can be used in an offline mode, automatically syncing information as soon as the device is reconnected to a network. This functionality can be essential to COSHH assessments.\nWork hard, but rest hard too\nWhen time pressures are mounting and the threat of late fines are looming, it’s tempting to cut corners and push to get a project done, but this should never be at the expense of health and safety. If changing plans impact on people, equipment or procedures, then risk assessments should be re-evaluated.\nAlthough contractors should expect high standards of work and output from their workers, rest is important too. Workers need to be highly alert to their surroundings and to help keep everyone safe; this is especially important when working at height, with hazardous material or in confined spaces. Workers should be given adequate time to rest and relax and not be pushed to work overly long hours, even if they request the overtime. Distraction and tiredness lead to mistakes and they can be serious and even life-threatening.\nIf in doubt, shout\nBusinesses that excel at managing health and safety in construction have safety at the very core of their work and everyone on-site sees the benefit of the precautions, follows the rules and enforces them within their teams.\nCommunication is key here. When an individual understands why a rule is in place or why something has changed, they are more likely to comply and enforce compliance from others. When you have zero incidents during a project, reward the team for achieving this. If a near-miss has occurred, communicate this to the team, help them to understand why it happened and how further incidents can be avoided. Be clear about the changes you’ve made to make ensure the incident doesn’t occur again and how others can contribute to this adjustment.\nHealth and safety in the construction industry is the responsibility of everyone on site. Put simple procedures in place so that construction workers can quickly and easily report an issue and instil a culture of responsibility. If a trip hazard is identified, encourage workers to remove it. If someone is in danger, encourage others to act. Dealing with an issue when it arises can help reduce immediate incidents that may follow.\nHealth and safety rules should be repeated at daily briefings and reinforced throughout the day. There are many ways to remind workers of their health and safety obligations, perhaps through posters displayed around the site or reminders on software tools.\nSeveral of the bigger construction companies have powerful slogans to help educate and engage all team members on-site.\nBalfour Beatty’s award-winning golden rules highlight core expectations and they are simple and easy to remember:\nMeanwhile, Amey’s Target Zero encourages workers to speak out and talk about health and safety issues so that problems can be identified and dealt with quickly.\nWe have all the tools to achieve zero incidents and to make the construction site a safe place for all workers. By taking a thorough approach to identifying risk, developing a culture of open and honest communication and ensuring workers have access to the safest tools for the job, we can reduce injuries on-site and achieve zero incidents.']"	['<urn:uuid:0e4e4d3b-e1a8-49ed-8ae8-2648055210ef>', '<urn:uuid:2aab1c69-8b42-4bc3-b9a1-8f308e254433>']	factoid	direct	long-search-query	distant-from-document	multi-aspect	novice	2025-05-13T03:20:41.944655	7	73	2569
40	What properties does dihydrogen have and how can it be produced from water?	Dihydrogen (H2) is a colorless, tasteless, and odorless gas at standard temperature and pressure. It is highly combustible and flammable, with a melting point of -259.16°C and a boiling point of -252.879°C. Its speed of sound is 1310 m/s. As for production from water, it can be generated through several methods: biological water splitting using photosynthetic microbes that use light energy, photoelectrochemical water splitting which achieves 12.4% solar-to-hydrogen conversion efficiency, and solar thermal water splitting using concentrated solar energy at temperatures between 1,000-2,000 degrees Celsius. Water electrolysis using renewable energy sources like wind and solar is another production method.	"['Last Updated on August 13, 2023 by Tabraiz\nTable of Contents\nWhat is Dihydrogen?\nDihydrogen, Two hydrogen atoms react to form the homonuclear diatomic molecule known as dihydrogen. It is represented by H2 which is its molecular formula and the bond between the two hydrogen atoms is a covalent bond that satisfies the required duet configurations of both the atoms. Hydrogen being the lightest of the element that is in the modern periodic table makes dihydrogen to be the lightest known molecule existed. The hydrogen atom has a standard atomic weight of 1.008 u whereas the dihydrogen molecule has a molecular weight of 2.016 (a.m.u) atomic mass units.\nThe dihydrogen at standard conditions of temperature and pressure (i.e., at STP) exists as a gas that is colorless, does not have taste, and is odorless. This gas is believed to be highly combustible and flammable in nature. This gas can be used for various purposes and the Renewable hydrogen is considered to be a safe fuel as the by-product is only water during its combustion.\nStructure of Dihydrogen\nThis molecule of Hydrogen consists of two hydrogen atoms covalently bonded. It consists of a linear shape and this molecule is nonpolar in nature. Both the hydrogen atoms that form the dihydrogen molecule are contributing one electron each for the formation of the covalent bond. Hence, all the requirements that are needed for this duet configuration of both the hydrogen atoms are satisfied. A figure showing the composition of dihydrogen is shown below:\nProperties of Dihydrogen\n- At the standard conditions of temperature and pressure, the dihydrogen molecule is in the gaseous state.\n- Dihydrogen molecule has a melting point of 13.99 K. On the Celsius scale, its melting point is as low as -259.16 ℃. The boiling point on the other hand is around 20.27 K and on the Celsius scale, it is 252.879 ℃.\n- The latent heat of fusion that is associated with the dihydrogen molecule is given to be 0.117 kJ per mole and the enthalpy of vaporization (also known as latent heat of vaporization associated with dihydrogen corresponds to around 0.904 kJ per mole.\n- Dihydrogen molecule has a heat capacity corresponding to roughly around 28.83 J per mole Kelvin.\n- When sound propagates via the gaseous dihydrogen, its speed of sound is around 1310 m/s.\nUses of Dihydrogen gas\nThe dihydrogen molecule has a lot of applications especially in chemical industries as well as the petroleum industry. There has been a demand for a large quantity of H2 in recent years for various purposes regularly.\n- Dihydrogen is widely used and is required in the refining process of various fossil fuels and also in the manufacturing of ammonia.\n- The petrochemical industry has become one of the main users of dihydrogen gas. It is being utilized in such industries for various chemical processes like hydrodealkylation, hydrodesulfurization, and also for hydrocracking.\n- Dihydrogen gas has an application as a fuel where it is needed for running electric vehicles and also in fuel cells. Dihydrogen gas is believed to be the next source of energy or energy carrier which is free and non-polluting.\n- For chemical preparation, this molecule can be used for the preparation of methanol which is required for various purposes.\n- Similarly, it can also become a source of hydrogen for the production of high-demand hydrochloric acid (HCl).\n- H2 or dihydrogen can be used as a reducing agent and is therefore helpful in the treatment of metallic ores.\nBiochemistry of Dihydrogen\nA dihydrogen molecule (H2) can be formed due to a certain form of anaerobic metabolism. This molecule can also be formed through various chemicals reactions by many microorganisms via a catalytic process using enzymes. The enzymes which are responsible for such catalyzed-biochemical reactions which lead to the release of dihydrogen are commonly called the hydrogenases, and these consist of Nickle or iron. These enzymes are capable of catalyzing a reversible redox reaction which contains two protons and two electrons on the reactant side and a dihydrogen molecule on the product side. During a pyruvate fermentation process, the dihydrogen gas is created after transferring the reducing equivalents to water. The term Hydrogen cycle refers to the natural cycle which involves the consumption and the production of hydrogen via various phases of the ecosystem.\nHazards that are associated with Dihydrogen\n- Dihydrogen or H2 can react with most of the elements behaving as oxidizing agents or have enough oxidizing power. It has the capability of reacting with halogens namely chlorine, fluorine not in a safe path but rather spontaneous and violently, even when the reactions are taking place at very low temperatures close about to room temperature.\n- The products that are formed after the reactions are mostly hydrogen halides such as hydrogen chloride and hydrogen fluoride respectively which are both considered potentially harmful acids.\n- Hydrogen is very difficult to store and hence difficult to be carried around.', ""Hydrogen Production and Delivery\nResearchers at NREL are developing advanced processes to produce hydrogen economically from sustainable resources.\nBiological Water Splitting\nCertain photosynthetic microbes use light energy to produce hydrogen from water as part of their metabolic processes. Because oxygen is produced along with the hydrogen, photobiological hydrogen production technology must overcome the inherent oxygen sensitivity of hydrogen-evolving enzyme systems. NREL researchers are addressing this issue by screening for naturally occurring organisms that are more tolerant of oxygen and by creating new genetic forms of the organisms that can sustain hydrogen production in the presence of oxygen. Researchers are also developing a new system that uses a metabolic switch (sulfur deprivation) to cycle algal cells between the photosynthetic growth phase and the hydrogen production phase.\nContact: Maria Ghirardi\nNREL scientists are developing pretreatment technologies to convert lignocellulosic biomass into sugar-rich feedstocks that can be directly fermented to produce hydrogen, ethanol, and high-value chemicals. Researchers are also working to identify a consortium of Clostridium that can directly ferment hemicellulose to hydrogen. Other research areas involve bio-prospecting efficient cellulolytic microbes, such as Clostridium thermocellum, that can ferment crystalline cellulose directly to hydrogen to lower feedstock costs. Once a model cellulolytic bacterium is identified, its potential for genetic manipulations, including sensitivity to antibiotics and ease of genetic transformation, will be determined. NREL's future fermentation projects will focus on developing strategies to generate mutants that are blocked selectively from producing waste acids and solvents to maximize hydrogen yield.\nContact: Pin-Ching Maness\nConversion of Biomass and Wastes\nHydrogen can be produced via pyrolysis or gasification of biomass resources such as agricultural residues like peanut shells; consumer wastes including plastics and waste grease; or biomass specifically grown for energy uses. Biomass pyrolysis produces a liquid product (bio-oil) that contains a wide spectrum of components that can be separated into valuable chemicals and fuels, including hydrogen. NREL researchers are currently focusing on hydrogen production by catalytic reforming of biomass pyrolysis products. Specific research areas include reforming of pyrolysis streams and development and testing of fluidizable catalysts.\nContact: Richard French\nPhotoelectrochemical Water Splitting\nThe cleanest way to produce hydrogen is by using sunlight to directly split water into hydrogen and oxygen. Multijunction cell technology developed by the photovoltaic industry is being used for photoelectrochemical (PEC) light harvesting systems that generate sufficient voltage to split water and are stable in a water/electrolyte environment. The NREL-developed PEC system produces hydrogen from sunlight without the expense and complication of electrolyzers, at a solar-to-hydrogen conversion efficiency of 12.4% lower heating value using captured light. Research is underway to identify more efficient, lower cost materials and systems that are durable and stable against corrosion in an aqueous environment.\nSolar Thermal Water Splitting\nNREL researchers use the High-Flux Solar Furnace reactor to concentrate solar energy and generate temperatures between 1,000 and 2,000 degrees Celsius. Ultra-high temperatures are required for thermochemical reaction cycles to produce hydrogen. Such high-temperature, high-flux, solar-driven thermochemical processes offer a novel approach for the environmentally benign production of hydrogen. Very high reaction rates at these elevated temperatures give rise to very fast reaction rates, which significantly enhance production rates and more than compensate for the intermittent nature of the solar resource.\nContact: Judy Netter\nRenewable energy sources such as photovoltaics, wind, biomass, hydro, and geothermal can provide clean and sustainable electricity for our nation. However, renewable energy sources are naturally variable, requiring energy storage or a hybrid system to accommodate daily and seasonal changes. One solution is to produce hydrogen through the electrolysis—splitting with an electric current—of water and to use that hydrogen in a fuel cell to produce electricity during times of low power production or peak demand, or to use the hydrogen in fuel cell vehicles.\nResearchers at NREL's Energy Systems Integration Facility and Hydrogen Infrastructure Testing and Research Facility are examining the issues related to using renewable energy sources for producing hydrogen via the electrolysis of water. NREL tests integrated electrolysis systems and investigates design options to lower capital costs and enhance performance.\nLearn more about NREL's renewable electrolysis research.\nContact: Kevin Harrison\nHydrogen Dispenser Hose Reliability\nWith a focus on reducing costs and increasing reliability and safety, NREL performs accelerated testing and cycling of 700 bar hydrogen dispensing hoses at the Energy Systems Integration Facility using automated robotics to simulate field conditions. View the video of the robot, which mimics the repetitive stress of a person bending and twisting a hose to dispense hydrogen into a fuel cell vehicle's onboard storage tank. Researchers perform mechanical, thermal, and pressure stress tests on new and used hydrogen dispensing hoses. The hose material is analyzed to identify hydrogen infiltration, embrittlement, and crack initiation/propagation.\nContact: Kevin Harrison\nHydrogen Production and Delivery Pathway Analysis\nNREL performs systems-level analyses on a variety of sustainable hydrogen production and delivery pathways. These efforts focus on determining status improvements resulting from technology advancements, cost as a function of production volume, and the potential for cost reductions. Results help identify barriers to the success of these pathways, primary cost drivers, and remaining R&D challenges. NREL-developed hydrogen analysis case studies provide transparent projections of current and future hydrogen production costs. Learn more about NREL's systems analysis work.\nContact: Genevieve Saur\nHydroGEN Energy Materials Network\nNREL serves as the lead laboratory for the HydroGEN Energy Materials Network (EMN) consortium.\nRemarkable Stability of Unmodified GaAs Photocathodes during Hydrogen Evolution in Acidic Electrolyte, Journal of Materials Chemistry A (2016)\nSolar to Hydrogen Efficiency: Shining Light on Photoelectrochemical Device Performance, Energy and Environmental Science (2016)\nReversible GaInP2 Surface Passivation by Water Adsorption: A Model System for Ambient-Dependent Photoluminescence, Journal of Physical Chemistry C (2016)\nCO2-Fixing One-Carbon Metabolism in a Cellulose-Degrading Bacterium Clostridium thermocellum, Proceedings of the National Academy of Sciences (2016)\nPhosphoketolase Pathway Contributes to Carbon Metabolism in Cyanobacteria, Nature Plants (2016)""]"	['<urn:uuid:7be4cc2d-d946-4eb5-874b-a5a475b6ddc8>', '<urn:uuid:13a02b09-8dfc-4538-bd22-78817cd111fe>']	open-ended	direct	concise-and-natural	similar-to-document	multi-aspect	novice	2025-05-13T03:20:41.944655	13	99	1783
41	What symbolizes life and death in Victorian poetry and reefs?	In Victorian poetry, the ancient pulse of germ and birth appears shrunken and dry symbolizing death, while in coral reefs, the symbiotic zooxanthellae represent life through photosynthesis, with their loss leading to coral death through bleaching.	"['The Darkling Thrush by Thomas Hardy: Summary and Analysis\nI leant upon a coppice gate\nWhen Frost was spectre-grey,\nAnd Winter’s dregs made desolate\nThe weakening eye of day.\nThe tangled bine-stems scored the sky\nLike strings of broken lyres,\nAnd all mankind that haunted nigh\nHad sought their household fires.\nThe land’s sharp features seemed to be\nThe Century’s corpse outleant,\nHis crypt the cloudy canopy,\nThe wind his death-lament.\nThe ancient pulse of germ and birth\nWas shrunken hard and dry,\nAnd every spirit upon earth\nSeemed fervourless as I.\nAt once a voice arose among\nThe bleak twigs overhead\nIn a full-hearted evensong\nOf joy illimited;\nAn aged thrush, frail, gaunt, and small,\nIn blast-beruffled plume,\nHad chosen thus to fling his soul\nUpon the growing gloom.\nSo little cause for carolings\nOf such ecstatic sound\nWas written on terrestrial things\nAfar or nigh around,\nThat I could think there trembled through\nHis happy good-night air\nSome blessed Hope, whereof he knew\nAnd I was unaware.\nStarting With the Poem\nWritten in 1899, The Darkling Thrush is very much a reflection of Hardy’s troubled conscience, torn between the insecurity posed by revolutionary religious assertions and a faint belief in the resurrection of mankind.\nThe poem marks the termination of two significant events – the decline of the Victorian age with its religious beliefs, agrarian society and the end of Hardy’s career as a novelist. The critical reception of two of his novels, “The Tess of the d’Urbervilles” (1891) and “Jude the Obscure” (1895), led Hardy turn towards poetry as means of self-expression. Moreover, the decay of agricultural society brought about by relentless Industrialization, along with the abatement of religious beliefs by Darwin’s revolutionary assertion on evolution, made him sceptical like his contemporaries, Mathew Arnold, and Tennyson. This explains the reason behind the other title, “By Century’s Deathbed,” the poem had, when it was published on December 29, by a weekly newspaper called “The Graphic.”\nLeaning “upon” a gate that opens into the woods (coppice gate), Hardy makes a short estimation of his surrounding; “Frost” appears “ghost-like,” the already waning day is rendered lonely (desolate) by the last bite of winter (winter’s dregs). Along with this, the rising stems of shrubs resemble the “strings” of a “broken” harp (lyre). He further observes that on such a frighteningly “haunted” night, all mankind seems to huddle beside their “household” fires. The barren landscape evokes a deathlike feeling and in tune with the rapidly closing century, appears as its corpse that lies (outleant), within a tomb (crypt) of overhanging clouds. With the wind singing a mournful elegy (death lament), there is hardly any note of rejuvenation, and even the seeds of spring, promising life, are shrunken hard. Consequently, the poet feels lifeless (fervourless). Suddenly the pervading gloom is interrupted by the vibrant (full-hearted) song of an aged and frail thrush. Since the bleak landscape could hardly be a source of inspiration for the bird’s “carolings,” the poet wonders what “blessed Hope” that he is unaware of, has inspired it.\nDesolation and Gloom\nRight from the very onset, the inescapable feeling is one of depression and loneliness. The landscape seems in anticipation of an impending doom, with “Frost” assuming the semblance of an unearthly spirit. It is a “haunted nigh,” and everyone is “fervourless.”\nHope amidst Despair\nThe thrush and its carefree song, embodying eternal hope, voice the poet’s belief in some betterment of the dreary situation.\nFour stanzas of eight lines\nThe rhyme scheme is ABABCDCD\nMood and Tone\nTill stanza 2, the poem bears a pessimistic tone, and the mood is meditative. With the emergence of the thrush in stanza 3, both the tone and mood become inspiring and hopeful.\nHardy is well-known for coining new words in his poems and several such “nonce words” that he create in this poem for maintaining its rhyme scheme, and meter are, “outleant,” “blast-beruffled,” and “spectre-gray.” Simultaneously, he also uses words of other poets such as “darkling,” (a term employed by Mathew Arnold In “Dover Beach” and John Keats in an “Ode to a Nightingale.” Besides these, the major portion of the poem is dominated by gloomy sounding words such as, “gray,” “dregs,” “desolate,” “broken,” and “haunted.” It is from stanza 3 that the words become a bit lively. For instance, in lines 5‑6 of Stanza 3, the domination of “b” sound in the words, “blast-beruffled,” intensifies the presence of the bird amidst the bleak surrounding.\n- The “aged thrush” symbolizes hope for the depressed mankind\n- The “tangled bine-stems” heighten the bleakness of the surrounding\nImage and Imagery\nIn the first half of the poem, most of the images are gray and grim. For instance, the lines, 3‑4, “And Winter’s dregs made desolate/The weakening eye of day,” create a picture of looming solitariness or the lines, 9‑12, “The land’s sharp features seemed to be/The Century’s corpse outleant,/His crypt the cloudy canopy,/The wind his death-lament.” establish an image of sorrow and futility. From stanza 3, the images tend to be bright as the poet remarks that the bird sings a “full-hearted evensong / of joy illimited.”\nFigures of Speech Used\n- In line 2, “Frost” is personified as someone having ghost-like features to develop the barren setting of the poem\n- In line 3, “Winter” is personified as someone responsible for increasing the isolation when the poet says,” And Winter’s dregs made desolate/The weakening eye of day.”\n- In line 10, the “Century” is personified as someone who’s dead, and his “corpse” is the arid land.\n- In line 31, “Hope” is personified to emphasize the ushering of something good despite morose circumstances.\n- In line 5,” The tangled bine-stems” are compared to “strings of broken lyres”\n- In line 15, “every spirit upon earth” is said to be as listless as the poet\nIn line 9 10, the “land” is said to resemble the “corpse” of the fast fading “Century.”\nIn lines 11‑12, the cloudy sky is said to be the tomb (crypt) of the “Century” and the winter wind is compared with the “death lament” sung for the departed “Century.”\n- Lines 1-2 – ‘At once, a voice arose among the bleak twigs overhead.’\n- Repetition of “k” sounds in the lines, Lines 1-7: “I leant upon a coppice gate … And all mankind that haunted nigh.”\nThe Darkling Thrush, apart from echoing the Victorian traits of being a lyric or having a moral objective, is also a fitting forerunner of Modernism, for, in dealing with loss, despair, and loneliness, it reflects a trend that was going to be explored more intensely by Eliot and Pound.\n- a note on critical analysis of the darkling thrush', ""Coral reefs are one of the ocean’s most astonishing sites. They are like modern day cities providing homes, food and protection to many different species of sea life. The reefs also provide erosion protection to the coastlines from battering waves. In addition, they contribute to local economies through fishing and tourism. The most beautiful coral reefs in the world have existed for thousands of years, such as, the Great Barrier Reef on the Australian Coast. Sadly, they are now being destroyed. “Researchers estimate that nearly 60 percent of the world's reefs are seriously threatened,” (Anonymous, 2001, 4) and “it is estimated that 30% of coral reefs have now lost >90% of reef-building corals and there is little to no prospect of recovery” (Trappon et. al., 2011, 2). There are many detrimental factors that affect the fragile corals. One of these is global warming. Climate change has caused increased water temperatures, sea level changes, ocean acidity, increased carbon dioxide levels and more. There are also many human related factors. Some of these factors are: water pollution, coastal development, destructive fishing practices, coral mining and careless tourism. All of these things are contributing to coral bleaching and other issues that kill the coral reefs.\nCoral reefs are called the rainforests of the sea because of their diverse ecosystem (Anonymous B, 1). “The ancient Greeks mistakenly believed that corals were plants. Corals are actually animals, related to anemones and jellyfish” (Woods 2003, 0). They consist of many colonies with each individual coral being called a polyp. The corals have hard skeletal structures that are made from calcium carbonate that is secreted by the polyps. The calcium carbonate builds up over time, continually adding to the size and shape of the structure (Anonymous B, 3). The corals have a symbiotic relationship with a single-cell allege called zooxanthellae. These algae live inside the coral. The coral provides a safe home for the zooxanthellae and zooxanthellae provide food for the coral from the sugar it produces through photosynthesis. In turn, the corals excrete nitrogen waste, which the alga consumes as food (Woods 2003, 1). The zooxanthella also gives the coral its vibrant color.\nCorals are sessile animals, which means they do not move, but are fixed in one place. (Anonymous B, 4) In order to survive, they live close to the surface so light can penetrate down to reach the corals for the purpose of photosynthesis. The water, in which the corals thrive, needs to be 68 -82 degrees Fahrenheit (Kalman 2008, 1). For these reasons, they live in shallow, tropical waters. The reefs are home to more than 25% of all marine life. They provide food, homes and breeding grounds for sea life that inhabit the area, which makes them a big part of the oceans' ecosystem (Kalman 2008, 1).\nIn addition, coral reefs provide many benefits to humans. The reefs contribute billions of dollars to local economies through the fishing and tourism industries. They also provide the main protein food source for many impoverished coastal lying countries (Glick 1999, 7). “More than 30 million people depend on coral reefs for their livelihoods” (Anonymous, 2001, 11).\nFor all of the beauty and benefits that the coral reefs provide, in return they are being destroyed. Corals are “often thought of as the ocean’s “canaries in a coal mine.”” This is because they are particularly sensitive to changes in their watery environment (Kalman 2008, 1). “Nearly one-third of the 704 species studied are listed as “Critically Endangered,” “Endangered,” or “Vulnerable.” (Kalman 2008, 5) So, what is it that is destroying these beautiful fragile reefs?\nCoral bleaching is one of the main complications for corals. This process happens when there is an increase in environmental stress (Kalman, 2008, 3). Causes of bleaching can include: increased water temperatures, increased water acidity, increased water levels, increased UV radiation, storms, chemical exposure, sediment covering the coral, chemical household products, and overload of nutrients and fertilizer (Woods 2003, 6).\nGlobal warming has had many affects on the oceans. One of these affects is the rising water temperatures. This increase of temperature causes the fragile corals to be threatened. Due to the increased water temperature, the photosynthetic process of the zooxanthellae is being disturbed. This causes a buildup of substances that are poisonous to the algae. In order for the coral to protect itself, it releases the zooxanthellae along with some of its own tissue. This process causes the coral to lose their color and become bleached (Woods 2003, 5). Bleached corals are weaker and more prone to disease. However, they can survive if conditions return to normal quickly (Anonymous C, 4).\nIncreased ocean acidity is also contributing to the killing of the coral reefs. The ocean’s acidity has been changing as the result of the astonishing increase of human produced carbon dioxide that has been released into the atmosphere over the past 250 years. This is because the waters absorb the carbon dioxide from the air, which benefits humankind by reducing greenhouse gasses in the atmosphere, but dramatically affects the waters (Anonymous C, 2). The dissolved carbon dioxide in the water lowers the oceans pH level. The decreased pH level causes a disruption of the corals calcification process and weakens the existing coral skeleton making it more vulnerable to disease, erosion, and damage from fishing and tourism. The reduced pH also affects other ocean life by reducing food levels and the calcification of shellfish (Springer-Verlag 2009, 5).\nOver the last century, the sea level has risen 20 cm. This is “due to thermal expansion and melting of land-based ice, and is projected to be another 60 cm higher by 2100” (Springer-Verlag 2009, 9). With the rising sea levels, the coral reefs can drown. This event occurs because it is difficult for corals to obtain the proper amount of sunlight at these deeper depths necessary for photosynthesis. Without photosynthesis, the algae will not be able to produce the food needed for the corals to survive (Knowlton 2001, 12). This will especially affect the slow growing corals and will cause a drastic reduction of this species (Anonymous A, 4).\nBeyond the environmental factors affecting the reefs, there are other human related factors. One of these is over-fishing. Coral reefs have an extensive amount and variety of seafood, which fishermen have long taken advantage of. Many fisheries, dependent on coral reefs, have harvested unsustainably and depleted the numbers of sea life faster than it can reproduce. As the fishermen continue to take from the reefs, the ecosystem becomes unbalanced. With this imbalance, the corals can be affected greatly by the consequences, such as, the overgrowth of algae, which can smother the reef. Also, the reefs are damaged by harmful fishing practices such as the use of cyanide. Cyanide is used to stun the fish prior to capture, but this harmful chemical is absorbed by the coral (Glick 1999, 11, 12). Other causes related to fishing practices are stick banging and the use of explosives, which damage the corals structure (Anonymous C, 9).\nAnother human related factor is coastal development. More and more of the world’s coastlines are being developed without any regard to the habitat of the coastal waters. Channels are being dug for safe ship passage, piers are being built on top of the reefs, and land is being paved allowing polluted water and silt to runoff into the oceans. “Rapid development over the past 50 years has contributed to excessive sewage runoff, which harms coral reefs by causing accelerated algae growth.” Other practices such as mining, farming, destruction of forests and the use of fossil fuels create air pollution and water run off pollution. These pollutants poison marine life. All of this is destroying the coral reefs and, in turn, endangering the coastline from the erosion that was being prevented by the coral reefs (Glick, 1999, 10).\nThere are also numerous threats to the coral reefs from tourism and coral mining. Although tourism generates millions of dollars to local economies, it can have a devastating affect to the coral reefs in two ways. First, sewage that is not properly contained or resorts that dump waste directly into the ocean hurt the coral reefs. Secondly, is the physical contact tourism brings to the reefs. Tourists swimming, diving, boating and fishing cause direct damage the corals by touching, kicking, grabbing, walking on or stirring up sediments. Boaters also drop anchors directly on top of the corals causing damage to their structure (Anonymous C, 11). Removal of coral through mining has also contributed to coral depletion. The corals have been mined for souvenirs to be sold in the tourist trade and for use in various types of construction (Anonymous C, 10).\nIn order to save the magnificent coral reefs, action must be taken. The reduction of greenhouse gasses must be reduced worldwide. This will require researchers to come up with better environmentally friendly technologies. In addition, water pollution, habitat destruction and harmful fishing practices must be controlled internationally. Funding for research on how the coral reefs are affected by different issues and how to protect the reefs from these issues is essential, as well as increased funding for reef restoration (Eakin, Kleypas, Hoegh-Guldberg, 2008, 4). Enlarging protected marine areas around reefs worldwide, to protect them from dangerous fishing practices and tourism related damage, would also aid in their survival. The reefs are minimally protected in this way now (Glick 1999, 13). “Some scientists have predicted that by 2030 massive and devastating coral bleaching events will occur every year” (Woods, 2003, 10). So, it is vital to take actions now to protect the fragile coral reefs.\nCoral reefs provide not only beauty, but contribute to the vast ocean ecosystem. They provide food, protection and breeding grounds to thousands of species of sea life. Human beings also benefit from these amazing reefs by their ability to contribute billions of dollars into the local economies through fishing and tourism. Coral reefs also provide a source of a food protein to impoverished coastal countries. Yet, these slow-growing magnificent structures of the ocean are being destroyed at an alarming rate. These fragile animals and their symbiotic partners, zooxanthellae, are greatly affected by global warming and its consequences, such as, increased water temperature, increased acidity levels, and increased water levels. These threats can cause devastating, mass coral bleaching events. In addition, human activities like destructive fishing practices, careless tourism, coral mining and coastal development are adding to the threats. In order to save these important and invaluable beautiful reefs, the world population must change their habits, improve technologies in order to reduce pollution and use environmentally friendly construction and development practices. If we do not take action, these beautiful life and economy sustaining structures will forever be lost for future generations. This would be a tragic event for the earth’s oceans and to the worldwide society.""]"	['<urn:uuid:e3f080d4-eeb2-41dd-9b54-5e993f24f6a4>', '<urn:uuid:d3a02c8a-7f47-422f-b8e8-a9e242d449d8>']	factoid	direct	concise-and-natural	similar-to-document	multi-aspect	expert	2025-05-13T03:20:41.944655	10	36	2919
42	subjunctive mood examples differences conditional clauses	The subjunctive mood has several key differences across conditional clauses. In hypothetical situations, like 'If I were at home, I wouldn't have to drive after dinner', the mode shifts into fantasy-land using the subjunctive form. In contrast, for real conditions like 'If I was at home, I ate dinner by five o'clock', the indicative mood is used. The subjunctive mood can express suppositional or desirable actions, with specific forms like 'be' for all persons in present tense and 'were' for past tense. Conditional sentences are classified into three types: first type for real suppositions, second type for improbable suppositions (using Past Indefinite in the subordinate clause), and third type for unrealizable past suppositions (using Past Perfect).	['Normally — meaning under the most usual readings — the first one would be wrong and the second right. There is a way to read it that makes the first one also correct, but it is a rare reading. Because English doesn’t have its notional tenses clearly marked as inflectional ones, I’m going to change the verb to be, which is the only place the distinction can be seen in the orthrography.\n- If I was at home, I ate dinner by five o’clock, but if I was at work, I never ate before seven o’clock.\n- If I were at home, I wouldn’t have to drive after dinner.\nThe difference is that in the first sentence, there is no question that the verb in the if clause is in the indicative. In fact, there you can change out the two instances of if for when or even whenever, because it represents customary or repetitive action. If this were a Romance language, one would use an imperfect tense not a perfect one, because the action in the if clause is continuous, not completed.\nIn the second sentence, the mode of the verb shifts into fantasy-land. It is a hypothetical. It no longer takes an indicative mode, but rather (in Romance terms, at least), a (past-)subjunctive one. And the corresponding then clause now takes a conditional tense.\nAlthough some people don’t like applying terms derived from Romance sequence of tenses to English, I think it can help clarify things. Just because you don’t have a visible inflection in most cases doesn’t mean that it is not a ‘tense’ or ‘mood’; those concepts do not require an orthographic shift in the verb’s inflection to have the sense of the clause shift from known, real, and true to some other situation.\nYou can make the sentences more complex by shifting the verbs into perfect tenses, but the essential indicative-vs-subjunctive nature, or if you must, real vs unreal, remains.\n- If I was at home that night, I must have eaten alone.\n- If I had been at home that night, I would have eaten alone.\nHere it is becoming less clear, but the same distinction still applies. One final possibility, which is the rare one, I think, is when both clauses are in the simple past indicative. Because English doesn’t distinguish completed action as clearly as Romance languages do, this can be a bit fuzzy to look at, but the idea is the same.\n- If I was at home, the office was dark.\n- If I ate early, you ate early.\n- If I called you, you answered right away.\n- If I gave you grief, you gave me cheers.\n- If I am at home, I always have a snack around o’clock.\n- If I am at home, I answer my own calls.\n- If I am at home, I will take out the trash before the garbage trucks arrive.\n- If he has shown up early, I shall not be pleased.\n- If he has shown up early, he can’t come in.\n- If he has shown up hearly, I’m leaving.\n- If I put down the pencil, will you stop nagging me?\nNone of those has any subjunctive or conditional in either clause. Even the last one has (what a classicist would call) the present perfect in the first clause and the future perfect in the other, but they are both still indicatives of one sort or another, not subjunctive or conditional. These, in contrast, are not:\n- If I were you, I would say nothing.\n- If I called, would you answer?\n- If I had called, would you have answered?\n- If I put down the pencil, work would grind to halt.\n- If I had put down the pencil, work would have ground to a halt.\n- Unless it were for a good cause, I would not donate my time and energy.\nThe only time you still have a mix of indicative and subjunctive is with a lest clause, which still demands a subjunctive mood in English.\n- He will say nothing at all, lest it be misconstrued as criticism.', 'Subjunctive (or conditional) mood\nNow we come to a very difficult set of problems, namely those\nconnected with the subjunctive (or conditional) mood.\nThe chief difficulty analysis has to face here is the absence of a\nmutual relation between meaning and form. Sometimes the same external\nseries of signs will have two or more different meanings depending on\nfactors lying outside the form itself, and outside the meaning of the\nverb; sometimes the same modal meaning will be expressed by two\ndifferent series of external signs.\nLet’s take, for example, the sequence we should come, which means\none thing in the sentence:\nI think we should come here again to-morrow (here we should come\nis equivalent to we ought to come); it means another thing in the\nIf we knew that he wants us we should come to see him (here we\nshould come denotes a conditional, i.e. an action depending on certain\nconditions), and it means another thing again in the sentence:\nHow queer that we should come at the very moment when you were talking\nabout us! (here we should come denotes an action which has actually\ntaken place and which is considered as an object for comment).\nThe second point may be illustrated by comparing of two sentences,\nI suggest that he go and he I suggest that should go, and we will for\nthe present neglect the fact that the first of the two variants is more\ntypical of American, and the second of British English.\nMatters are still further complicated by two phenomena where we are\nfaced with a choice between polysemy and homonymy. One of these\nconcerns forms like lived, knew , etc. Such forms appear in two types\nof contexts, of which one may be exemplified by the sentences, He lived\nhere five years ago, or I knew it all alone, and the other by the\nsentences, If he lived here he would come at once, or, If I knew his\naddress I should write to him.\nIn sentences of the first type the form obviously is the past\ntense of the indicative mood. The second type admits of two\ninterpretations: either the forms lived, knew, etc are the same forms\nof past indicative that were used in the first type, but they have\nacquired another meaning in this particular context, or else the forms\nlived, knew, etc. are forms of some other mood, which only happen to be\nhomonymous with forms of the past indicative but are basically\nSubjunctive mood may express suppositional or desirable action.\n1. The verb to be has in present tense the form be for all\nsingular and plural persons. The verb to be in the past\ntense has the form were for singular and plural persons (I\nbe, I were respectively).\n2. Forms be or were are used for formation of Present and Past\nSubjunctive mood in Passive voice (I be sent, I were sent\n3. All other verbs in subjunctive mood differ from indicative\nmood by the form of the third person of the Present time\nwithout ending –s.\nUsing of forms of Subjunctive mood.\nI. The forms of Present Subjunctive of the verb to be and of other\nverbs are used :\na) In subordinate clauses of subject, beginning with\nconjunction that after impersonal turns such as: it is\nnecessary (необходимо), it is important (важно), it is\ndesirable (желательно) and so on:\nEx. It is desirable that he be there at 5 o’clock.\n(Желательно, чтобы он был здесь в пять часов.)\nb) In subordinate clauses of object, expressing order, offer,\nresoluteness, accord – to order, to command приказать, to\nsuggest, to propose предлагать, to decide решать, to agree\nThe workers demanded that the law be put into effect.\nc) In subordinate clauses of purpose after conjunction lest:\nEx. They covered the goods with canvas lest they be damaged\nby rain. (Они покрыли товар брезентом, чтобы они не были\nPresent Subjunctive is used mainly in the USA, in England this\nform is remained only in official language (acts of the law,\ndocument); in a modern literary language and in a spoken language\nPresent Subjunctive is replaced by construction should with\nThe form of Past Subjunctive of the verb to be- were is used:\na) In a subordinate part of conditional sentences of the second\nEx. If he were here, he would help us. ( Если бы он был здесь, он\nпомог бы нам.)\nIf I were you, I would accept their offer. (Если бы я был на\nвашем месте, я бы принял их предложение.)\nb) In subordinate sentences of course of action (образа\nдействия), beginning with conjunctive as if:\nEx. He spoke as if he were a specialist on the subject. ( Он\nговорил, как если бы он был специалистом по этому вопросу.)\nc) In subordinate sentences of object with the verb to wish:\nEx. I wish he were with! (Как я хотела, чтобы он был с нами.)\nFrom all forms of Subjunctive mood the form were is the most\nspread, but it is often replaced by the form was in the first and\nthe third persons of a singular form. It is especially typical for\nEx. If he was here, he would help us.\nThus, those few forms of the Subjunctive mood that are preserved in\nthe modern language are gradually ousted from it.\nThe desirable and suppositional actions are expressed also by the\nfollowing combinations: should, would, may, might plus infinitive,\nwhich perform the functions of the Subjunctive mood.\nEx. There are some suggestions that might help in our work.\n(Имеются некоторые предположения, которые могли бы помочь в нашей\nConditional sentences are closely connected with subjunctive\n(conditional) mood. There are three types of conditional sentences.\nConditional sentences of the first type express entirely real\nand realizable suppositions and correspond in Russian language to\nconditional sentences with verbs in indicative mood. These\nconditional sentences mostly express suppositions referring to the\nEx. If the weather is fine to-morrow, we shall go to the\ncountry. (Если завтра будет хорошая погода, мы поедем за город.)\nThere is no necessity to further consider this type of conditional\nsentences as they do not conform to the theme.\nThe conditional sentences of the second type express\nincredible and improbable suppositions. They refer to the present\nor future and in Russian language agree with conditional sentences\nwith verbs in Subjunctive mood (i.e. in the form of past tens with\nthe particle бы in Russian language). In the conditional sentences\nof the second type in subordinate clause (in condition) there used\nthe form of Past Indefinite and in main clause (in consequence) – a\ncombination of should or would with Indefinite Infinitive:\nEx. If Helen knew** about Alice’s arrival (now), she would\ncall her up. (Если бы Елена знала о прибытии Алисы, она бы ей\n(Given sentence is incredible as Helen does not know about\nAlice’s arrival that is why she can not call her up.)\nEx. If my brother had** a time now, he would help them. ( Если\nбы у моего брата было время, он бы помог нам.)\n(This sentence is also impossible as the brother has not time\nnow that is why he can not help us.)\n** We have here Subjunctive mood which however coincides\nwith the form of Past Indefinite of Indicative mood.\nThe combinations such as:\n1. Should (with all persons) with Infinitive without particle to;\n2. Were (with all persons) with Infinitive with particle to.\nare used along with Past Indefinite in order to underline a small\npossibility of realization of a fact in future.\nEx. If I should see him to-morrow,\nI should ask him about it.\nIf I were to see him to-morrow,\nI should ask him about it.\n(Если бы я увидел его завтра, я спросил бы его об этом.)\nIn subordinate clauses there used sometimes combinations of\nwould with Infinitive. In this case the verb would is not an\nauxiliary verb but serves to show a request.\nEx. We should be obliged if you would acknowledge receipt of\nthis letter. (Мы были бы обязаны, если бы Вы подтвердили (были\nлюбезны подтвердить) получение этого письма).\nThe following examples of sentences may also be regarded as\nsentences of unreal conditions for the present and future:\n1. I wish I knew it. (Как жаль, что я этого не знаю).\n2. I fear lest he should be late. (Я боюсь, как бы он не\n3. He spoke as if he were a doctor. (Он говорил так, как-будто\n4. I suggest that he should go there too. (Я предлагаю, чтобы\nон тоже туда пошел).\n5. Knew Helen his address she would visit him. (Знай Елена его\nадрес, она бы навестила его).\n6. It is necessary that he should come. (Необходимо, чтобы он\nConditional sentences of the third type express suppositions\nreferring to the past and that is why they are unrealizable. Like\nthe Conditional sentences of the second type they correspond in\nRussian language to the Conditional sentences with a verb in\nSubjunctive mood (i.e. with a verb in the form of past tens with a\nparticle бы in Russian language).\nIn the Conditional sentences of the third type in the\nsubordinate clause (in the condition) there used the form of Past\nPerfect and in the main clause (in the consequence) there used a\ncombination would with Perfect Infinitive (without to).\nEx. If your instructions had been received** ten days ago, the\ngoods would have been shipped by the S.S “Svir” yesterday. (Если бы\nваши указания были получены десять дней назад, товар был бы\nотгружен вчера пароходом «Свирь»).\n** We have here the form of Subjunctive mood which coincides\nwith the form of Past Perfect of Indicative mood.\nThe unreal condition of the past moment can be expressed also\nby other ways:\n1. Without using of conjunction If:\nEx. Had I seen him yesterday I should have informed him.\n(Увидь я его вчера, я бы сообщил ему об этом.)\n2. By using of the model verb might:\nEx. He might have done it if he tried.\n(Он смог бы это сделать, если бы попытался).\n4. By using of the verb wish:\nEx. I wish(ed) I had known him then.\n(Как жаль, что я его не знала тогда).\nIt is worth while giving example of the case of using the\nConditional sentences of the mixed type:\nEx. If you had worked harder then you would know English\nbetter. (Если бы ты занимался усерднее (раньше, когда-то), (сейчас)\nты бы знал английский лучше).\nFinally, it is appropriate mention here those scholars who\ndevoted themselves to studying the problems of moods:\nM. Deutschbein (he proposed 16 moods);\nProf. Smirnitsky (he proposed the system of 6 moods:\nindicative, imperative, subjunctive1, subjunctive2, suppositional\nProf. G. Vorontsova;\nM. Gantina and N. Vasilevskaya and others.']	['<urn:uuid:a1de4bf0-cace-4ff9-b765-5727bd4a2d70>', '<urn:uuid:34486c71-19cd-466c-8940-8e3a28ae498f>']	open-ended	direct	short-search-query	distant-from-document	multi-aspect	expert	2025-05-13T03:20:41.944655	6	116	2484
43	bushes freezing damage prevention spring maintenance	To prevent and manage freezing damage in bushes, combine proper pruning timing with cold protection strategies. Prune early-blooming shrubs right after flowering, while summer/fall bloomers should be pruned in winter or early spring before growth begins. For cold protection, ensure proper watering before freezes, use protective coverings that reach the ground, and consider placing heat sources like 60-watt bulbs under covers during extreme cold. Additionally, proper plant nutrition helps them tolerate cold temperatures and recover better from damage.	['Shrubs will need to be pruned periodically to maintain or improve the plants health, form, and fruit or flower production\nDon’t feel that you need to prune just because you “should”. This shrub in its’ natural form is perhaps more appealing than after being trimmed. You need to do what you like\nThere is a lot of information involved in pruning shrubs, but the basics are really quite simple. When you take it one plant type at a time and think about why you are pruning it, it’s hard to make too many mistakes. And mistakes will heal themselves, so don’t worry about ruining your bush. Any pruning will generally benefit a shrub even if you don’t do it “right”.\nStarting simply, you need to prune for one or more of the following reasons:\n- Remove all dead, diseased, broken and weak branches to insects and disease don’t enter the plant.\n- Reduce the size of a shrub that has outgrown its’ space.\n- Thin to increase air circulation to reduce insect and disease problems.\n- Thin dense branches and foliage that prevent light from feeding the interior of a plant.\n- Thin to expose interest growth patterns in the trunk and branches, or to expose interesting bark.\n- Thin to reduce storm damage to dense shrubs or trees (if strong winds can blow through the shrub or tree, rather than blow against dense foliage, the less likely you will lose branches, or the entire tree).\n- Remove faded blooms and seed pods on plants that stop growth and flower bud production to produce seeds (see specific plant variety information). Additional flowering will be encouraged.\n- Hard prune and thin to rejuvenate an old shrub that is declining. New vigorous growth and flower production will result.\n- Prune to encourage denser form.\n- Shear or prune to form special shapes or topiary.\n- Cut back to encourage bushy growth.\nWhen to prune varies based on the plant, so be sure to see specific plant type information. General guidelines:\n- Shrubs that bloom early in the season, on last years growth, should be pruned immediately after flowering. Through the rest of the growing season the branches will grow and start flower bud production for next spring. The longer into summer you wait to prune, the more likely you will be to reduce flowering for next year.\n- Shrubs that bloom later, on new growth and last year’s growth, should be pruned either right after blooming, or before the growing season begins (ideally after the first freeze in fall, and before the ground gets warm in spring).\n- Shrubs that bloom in summer or fall, only on new growth, should be pruned in winter after the first freeze or in spring before the ground gets warm enough to start growth.\n- Shrubs that produce ornamental fruits should be pruned after the fruit drops or before growth begins in early spring.\n- Shrubs grown for fall and winter foliage color or colorful bark should be pruned early in spring before growth begins.\n- Holly and other deciduous evergreens that will be used for Christmas can be pruned in winter. Severe pruning should be done in early spring.\n- Heavy pruning in late summer should be avoided in general. New growth will not be mature enough to survive in cold climates.\n- Damage caused by storms should be pruned for repair as soon as possible no matter when it happens.\nDepending on the types of shrubs you have to prune and trim, there are tools you will need. The most important thing when selecting tools is to choose tools that are most easily handled by you. For example, if a hand sized pruning shear is to large for you to easily handle, you will not be able to administer a clean cut, and will damage the branch. It is also important that your tools be sharp enough to make a clean cut without twisting and damaging the branch. These are the tools used for various pruning and trimming chores.\n- Pruning shears for removing small to medium sized branches. A by-pass pruner (scissors style) will cut cleanly without crushing and damaging branches.\n- Lopping shears, a pruner with long handles, will reach into the center of a bush and give you better leverage for cutting larger branches.\n- Pruning saws are generally a long, curved, narrow saw compared to a standard carpenters saw, and has coarser teeth that are designed to cut on the pull stroke. The teeth are also designed to cut green wood without binding. A pruning saw is convenient for pruning large shrubs.\n- Hedge shears (large flat, scissors style shears) are designed to shear light new growth. Ideal for light shaping, trimming and heading.\n- Electric hedge trimmers are convenient for bigger jobs, where a manual hedge shear may get tiring. Cordless trimmers with rechargeable batteries make the job much easier, especially when the trimming job is a sizable distance from power.\nThe biggest confusion for gardeners even when they know why they need to prune is how to go about it, and how seriously to prune or shear. For the most part you should do what seems to make sense based on the needs of the shrub and your objective. Just don’t be afraid of doing it, pruning will nearly always do good things for your shrub. If you are concerned about butchering or killing a badly overgrown or out of control shrub, don’t be. There is a proper way to prune for that problem too.\n- The first step in every pruning project is to remove every dead, diseased, broken, damaged, weak and wayward branch. This will reduce the possibility of disease and insects entering the plant. Make sure your tools are sharp and clean. A pruner that has been in contact with disease will pass the disease to every plant you prune. Clean with a solution of 1 part alcohol, 9 parts water. And a dull blade will crush rather that cut the branches, leaving the branch damaged. Use your pruning shears, or loppers if the branches are large, to completely remove dead branches. Do not leave stubby branches, cut as close to the branch collar (the swelling where the branch joins the trunk) as possible without cutting the collar. This will promote quick healing. There is a chemical zone in the collar that inhibits the spread of decay, so you also do not need a tree wound dressing. If the branch is diseased, damaged or broken you can just cut back to healthy branch, which should not be black or discolored. If you have not removed back to healthy wood, the disease or decay will spread to the collar anyway, and the entire branch will later need to be removed. Make cuts just above an outward facing bud so that a new branch will grow out, rather than inward and crossing with other interior branches.\n- The preferred method of pruning is thinning, which is removing selected branches back to a side branch or the main trunk. It opens up the interior of the shrub to receive light, encouraging interior growth. Thinning will reduce the size of the shrub and result in fuller growth. It also helps to maintain the natural form of the shrub.\n- Heading is the removal of the end portions of twig branches randomly. Not to be confused with shearing, this is generally accomplished with a pruner to remove certain long, tall, or wayward branches. It is sometimes done to reduce the overall size of the bush, with the intention of maintaining its’ natural form, or moderately controlling its’ shape. Heading will stimulate growth of new shoots and encourage it to become more dense. Before making a cut, determine if a new shoot should be encouraged to grow outward or inward. Then cut just above an inward facing bud to encourage an inward branch, or an outward facing bud to encourage an outward branch. Do consider the natural form and how you can encourage select growth that will maintain that form.\n- Shearing (often called clipping) is removal of the growing points (that is just the tips of the branches) at an even level using a hedge shears or electric hedge trimmer. The shrub responds by increasing the growing points. Each branch will generally divide to form a dense top layer of growth. The shearing method is used to form hedges or topiary. It has become common to “shear” for general shaping of shrubs and informal hedges. Repeated pruning by this method will cause foliage growth to be concentrated on the outside of the the shrub, preventing light from entering the interior. Eventually the shrub will become completely bare on the interior. Radical renewal pruning will be necessary. Thinning and heading instead will maintain a healthy shrub much longer.\n- Pinching, in the same way we encourage an annual or perennial to grow lateral shoots to produce a dense plant, will also produce a denser shrub. Pinch the growing point between your thumb and forefinger and snap it off. Buds below the point will break dormancy and produce lateral shoots. This method can also be used to slow growth in a part of the plant, since the pinch also delays growth for a couple of weeks.\n- There are a couple different methods of renewal pruning, both are severe means of pruning, often called hard pruning, and are meant to rejuvenate an old or overgrown bush. If your bush is very old, poorly developed and seriously declining in health, your best course of action may be to cut the entire bush down to 6 to 12”. This must be done in very early spring before any growth begins. This hard pruning will very quickly encourage a lot of new growth which will be seriously damaged by a cold winter if you have hard pruned in fall. Done in spring, you will have abundant new growth by mid season. Once the new growth is 6 to 12”, begin pruning the tips to encourage lateral branches and compact growth. It is better to use a less severe means of renewing your shrubs over a long period before they get too large or overgrown. Each spring, remove the oldest branches, pruning them to the ground or to the base of the plant. You can remove up to one third of the old branches for seriously overgrown bushes. Also remove the thinnest branches, less than pencil diameter thick, as they tend to be weak. If you begin renewal pruning when a shrub is young and remove just a few of the oldest branches each year, your shrub could live indefinitely, requiring only select heading to control height and width.\nIs my bush dead?\nFirst, be patient if you are waiting for signs of life in spring. Some plants take a long time to break dormancy, especially if it went into winter stressed by drought. Or if your region experienced an unusually harsh winter some plants may have been damaged, or yes perhaps did not survive. Before you give it up for dead, you may want to try renewal pruning.\nThis Miss Kim Lilac has not show the tiniest sign of life on June 1. It was in perfect health last season and was well watered into winter. Our winter was unusually windy causing a lot of winter burn on the evergreens, but we had early snow cover. A Miss Kim is very hardy, to zone 3, and would be expected to live as long as 30 years. This is a mystery, but even though we have had a very late start to spring in the north, some sign of life should be seen by now. If the bush is in fact dead, it is too large to easily dig out without reducing the size, so a serious renewal pruning will either force the growth, or prepare it for removal. Even a shrub that normally does not respond well to renewal pruning should be cut down to try to force growth if it is likely dead - you have nothing to lose at this point!\nOn the chance that your shrub is not dead, cut back into a nice form. Allow for a basic structure to allow for good even branching. While cutting this back, some of the wood was dry and dead. But most of the branches showed some green, so I will hope for the best. If it revives, any remaining deadwood will need to be pruned out.\n** No sign of life several weeks later. But at least it is cut back for digging out, all those branches out of the way.', 'Protecting Plants from Cold Temperatures\nAlthough we live in the South, winter sometimes brings cold temperatures that can cause severe damage to many of our landscape plants. A late freeze after the temperature rises in January or February could be more injurious than the same cold temperature in winter when these plants have become dormant and more resistant to changes in temperature. An example is the sudden drop in temperature in April 2007 that killed or severely damaged many plants. It is important to protect plants from these cold temperatures.\nTemperature Changes and Plant Damage\nA plant’s ability to withstand cold temperatures depends on plant species, and how low and how fast temperatures decrease. When temperatures gradually decrease, a plant can acclimate, or adjust itself, to withstand colder temperatures better. Sudden decreases in temperature cause more damage in fall or early winter than similar low temperatures well into winter. If temperatures increase during the winter months, some plants may break dormancy, or deacclimate, and begin leafing out or flowering. Plants that break bud dormancy become more susceptible to late frost because of their new, tender growth.\nCold injury can occur to all parts of the plant (flowers, fruits, leaves, stems, trunks, roots, and buds). Fruits and flowers are the least tolerant of cold injury because they have little ability to adjust or build up tolerance to colder temperatures. Leaf and stem tissues are injured and damaged when ice forms within the plant’s cells, which typically occurs during a rapid freeze. When this happens, the plant’s tissue dies; this is often characterized by plant parts turning brown and mushy. When the temperature drops slowly, ice sometimes forms between the walls of the plant’s cells. Hardy or cold-acclimated plants can often withstand this type of ice formation.\nWindy conditions can also cause plant damage by desiccation, or the drying out of the plant. Desiccation causes marginal or leaf-tip burn or totally brown leaves in severe cases. Desiccation occurs when a plant loses more water than it absorbs, or takes up, by its roots, especially when the ground is frozen.\nHomeowners in Mississippi can enjoy a wide variety of plants. They can increase their choice of available plants by careful selection based on growing conditions and location in the landscape. By planting a combination of tender and hardy plants and by protecting plants susceptible to cold temperatures, homeowners can have landscapes that survive cold temperatures.\nProtecting Plants from Cold Temperatures\nPlant and Site Selection\nThe best way to prevent cold injury to plants is to choose plants that tolerate the cold temperatures in your area. Mississippi is in USDA Cold Hardiness Zones 7b, 8, and 9a. Northern regions of Mississippi are in Zone 7b, which means that plants need to be hardy to 5–10ºF. Northwestern and central regions of Mississippi are in Zone 8a (10–15ºF); southern Mississippi is in Zone 8b (15–20ºF); and the coastal tips of Mississippi’s three coastal counties are in Zone 9a (20–25ºF). Select plants that meet the minimum cold-hardy requirements in your area; for example, if you live in Zone 8a, choose plants that are hardy to at least zone 8a and preferably zone 7 to ensure they can better withstand any sudden cold dips in temperatures in your area.\nIn addition to proper plant selection, proper site selection is essential. Assess your property to determine the location of the coldest and the warmest spots. During the winter, the coldest spots are often found on the north and northwest parts of the property and in low areas where cold air settles. The warmest spots are usually on the southern part of the property.\nAssessing the microclimates of your property is also important. Elevation, landform, soil properties, canopy cover, and proximity to structures or other plants determine a microclimate. You can help protect plants by placing cold-sensitive plants near the part of the house that receives southern exposure or near larger plants or other structures.\nMaintaining proper plant nutrition also helps protect your plants from cold damage. Proper nutrition of plants is critical. A plant that has been given the appropriate nutrition tolerates cold temperatures, withstands sudden temperature drops, and recovers from cold damage better than plants that are nutritionally deficient.\nFertilizing plants at the proper time of year is also vital. Fertilizing plants in the fall (after August or September) with a fertilizer high in nitrogen can result in a flush of new growth that is more susceptible to cold temperatures.\nDuring the fall and winter months, most plants enter a dormant period when they need less fertilization. Winterizing-formulated fertilizers, which are high in potassium and low in nitrogen, may be used.\nCanopies and Shade\nTree canopies can reduce cold injury from radiational freezes. Radiational freezes occur on calm, clear nights when temperatures drop because of radiational cooling or heat loss from the earth and from the surfaces of objects. Canopies help reduce radiant heat loss from the ground to the atmosphere by raising the minimum night temperature beneath them.\nPlants that grow in shaded areas are less susceptible to winter desiccation, or drying out, than plants that grow in open areas. But plants that prefer full sun do not do well in the shade and will be unhealthy and less tolerant of cold temperatures if you plant them in the shade.\nWindbreaks such as fences, buildings, and temporary coverings can help protect plants from cold injury. Windbreaks are most useful in reducing injury resulting from cold winds and advective freezes (freezes that occur when temperatures drop because of the invasion of cold air masses into the area).\nCovering and Heating\nProtect plants that are in containers either by placing them inside a protective structure (house, garage, greenhouse, or shed) or by placing a protective covering over them. Container plants are more susceptible to cold temperatures than a similar plant growing in the ground. Their roots are more exposed because they are above the ground. Roots that are damaged by cold temperatures may not show immediate signs of damage, but these plants will show signs of stress when temperatures increase.\nPush together container plants that are left outside, and mulch or cover them to decrease heat loss from the sides of the containers. Wrap the bases of the containers in plastic, burlap, or blankets to reduce heat loss.\nPlants that grow close to the ground are usually protected by heat radiating from the soil. Plants that are tall and more open do not receive this radiating heat and are not as protected from the cold.\nRemember to mulch the soil. Mulching protects the roots of plants and helps reduce heat loss, thus minimizing temperature fluctuations. As with shrubs and trees, protecting the roots is necessary for them to survive the cold and come back in the spring.\nCovering your plants helps protect them from frost as well as from extremely cold temperatures. Covers that reach the ground and do not come in contact with foliage form a layer of insulation from the cold temperature. To prevent foliage breakage, avoid having the covers (sheets, blankets) touch the foliage. Remember to remove these protective coverings from the plant canopy after cold temperatures have passed.\nWhen extremely cold temperatures are predicted, place a light bulb (60-watt is sufficient) or other heat source under the cover to provide heat. Be very careful when using a bulb or other heat source, which can be a potential fire hazard. Do not let the bulb or heat source come in contact with the plant or the cover. Remove the cover and provide ventilation during the day to allow release of the heat that is trapped by solar radiation. This precaution is critical when using plastic covers.\nWater Needs before and after a Freeze\nWatering plants before a freeze can help protect them from cold injury. Soil that is well watered absorbs more heat and then reradiates heat, helping to increase the elevated temperature around the plants. However, poorly drained soils result in plants that have weak and shallow roots, which are more susceptible to cold injury. Use mulch to help retain soil moisture.\nCheck the water needs of plants after a freeze. After very cold temperatures, water that is in the soil may still be frozen and unavailable to the roots. If plants are transpiring (losing water from their leaves) and water is unavailable to the roots, plants may dry out. To provide water for plants, apply water to thaw the soil and the ice.\nPruning in late summer or early fall can result in new growth that is more susceptible to cold injury; so avoid pruning at this time of year.\nWait to prune plants until new growth appears in late winter or early spring. Cold damage will be more apparent, making it easier to remove the damaged portions of the plant. Severely injured plants may not break bud in the spring and may take on an overall weak appearance. Branch tips are more likely to suffer cold injury than older wood.\nTo determine if wood has been injured by the cold, check the cambium layer (layer directly under the bark). To do this, carefully scratch through the bark layer or carefully slice through this layer with a knife. Healthy, undamaged cambial tissue will be green; damaged will be brown or black. Prune this wood below the discoloration.\nTo determine if your fruit plants have been damaged by the cold temperatures, wait several days after a freeze and remove several flower buds from the plants. Use a sharp knife or razor blade to cut a cross section of the bud’s top. If there is any discoloration in the bud, the bud has been damaged and will not produce fruit. Damage may be localized, however, and not all buds may have been damaged. Check several buds from different areas of the plant to get a better assessment of the damage.\nPlants can be protected from cold temperatures by proper selection, placement, and care. Healthy plants are more resistant to cold injury than plants that are weakened by disease, by insect damage, or by improper care. You can take measures to protect plants during sudden and prolonged exposure to cold temperatures.\nPublication 2303 (POD-02-19)\nRevised by Jeff Wilson, PhD, Assistant Professor and State Master Gardener Coordinator, North Mississippi Research and Extension Center.\nThe Mississippi State University Extension Service is working to ensure all web content is accessible to all users. If you need assistance accessing any of our content, please email the webteam or call 662-325-2262.']	['<urn:uuid:9bb293cc-b555-40bc-a618-0d11c5eae687>', '<urn:uuid:cb84294a-c3a9-41fa-aa34-00ceac532c65>']	factoid	direct	short-search-query	distant-from-document	multi-aspect	expert	2025-05-13T03:20:41.944655	6	78	3867
44	commercial hoop house operations multiple structures benefits rotation limitations	Multiple hoop houses offer important advantages for commercial operations, particularly for crop rotation management. However, permanent hoop houses have the disadvantage of limited mobility, leading to short rotations or growing the same crop in the same location, which can cause yield reductions and soil-borne disease development. Despite these limitations, having multiple structures allows better crop rotation practices. For example, one farm successfully operates 7 unheated hoophouses plus one heated structure for transplant production, using multiple houses specifically to enable better crop rotation. The structures also require consideration of irrigation systems, with both overhead sprinklers and drip irrigation being utilized.	"['Growing for Market readers write about their experiences with hoophouse\nstructures — what kind they bought, whether they like it, and what they\nwish they had done differently. If you would like to add your opinion and advice, please email us and let us know it\'s okay to publish your comments.\n""We currently have 7 unheated hoophouses or high tunnels in use on our mixed vegetable and fruit farm and are adding an 8th structure this season. We also have one heated structure that we use for spring transplant production and early season potted tomato production.\nWe live on the south shore of Lake Superior where we get up to 120 inches of snow in the winter and can receive as much as 2 feet at a time during lake effect storms. We started out like many growers by building our own but after several flattened by snow and another picked up in a wind storm and deposited in a cherry orchard, we decided to look towards professionally manufactured structures. When we began researching hoop houses, we felt that strength was paramount. We looked at tube diameter, hoop spacing, truss systems, number of purlins, and end-wall design as important factors.\nIn the end, we chose the company Poly-Tex located in south-central Minnesota. They are among the beefiest structures that we\'ve seen, are very easy to work with, are cost comparative to other companies, and are for us, relatively local. We have 4 16x96\' and 2 16X60 foot Kool Houses which are a Quonset style structure. These shed snow very well. We went with their end wall kits. For side ventilation, we put the base that they give up at 3 feet along the entire length of the house and let the poly hang to the ground. We can then put sand bags or whatever along the edge to hold this flap down or roll the poly up and tie with twine to ventilate. We recently added a Poly-Tex PT-30, a 30X96\' Gothic style structure and treated the sides the same as the other houses. We are adding a 2nd PT-30 structure this season. We use 6 mil IR/AC polyfilm to cover our structures and have gone 7 seasons before replacement. Our heated structure is also made by Poly-Tex. Although there are a number of very good companies out there making high tunnels, we have been very satisfied with our structures.\nSeveral things that growers new to hoophouses will need to consider is crop rotation and irrigation. One reason why we use multiple houses is to better rotate crops. We also use both overhead sprinklers and drip irrigation.""\nLandis Spickerman Hermit Creek Farm High Bridge, WI\n""I have been growing in the ground in greenhouses for 11 years here in Az. I anticipate receiving a NRCS grant for my 3rd one. I have been very happy dealing with Mark Miller at G & M Agricultural Supply for my first 2 and will most likely again. He is quite knowledgable and ever helpful. We are looking at the Poly-Tex Field Pro which they now carry. My last hoophouse was an Agritech 20 by 96 which I am also quite happy with.""', 'By: Brad Bergefurd, MS, Horticulture Specialist and Extension Educator\nHigh tunnels, also called high hoops or hoop houses, are temporary structures used to extend the growing season of fruits and vegetables and are gaining in popularity with area farmers. These covered structures offer some environmental crop protection, but are highly management-intensive. Looking similar to greenhouses, high tunnels provide less climate control and rely on natural passive heating and cooling instead of heaters and cooling fans. High tunnels are constructed in the field to protect crops from the weather (rain, wind, cool or warm temperatures), as well as (in some cases) pests and are less expensive to construct and operate than traditional greenhouses.\nTypes of High Tunnels\nHigh tunnels are most often constructed of metal bows which are attached to metal posts, driven into the ground 3 to 4 feet. They are typically covered with one or two layers of 6-mil greenhouse-grade polyethylene, and are ventilated by rolling up or dropping down the sides. There are various designs each offering advantages and disadvantages. Due to their permanent nature, care should be given to siting the high tunnel properly.\nThe gothic style high tunnel is the most popular due to its peaked design which allows for greater height along the sides, making the sides of the high tunnel more useful for crop production and resulting in a 15% greater growing space than quonset-style tunnels. The peak also sheds snowfall, reducing the chance of collapse under a snow load.\nAdvantages of High Tunnels\nHigh tunnels have many uses on the farm. In cooler climates, they are used to elevate temperatures a few degrees each day, resulting in faster plant growth and higher yields. One main advantage of high tunnels is they allow farmers to produce crops outside of the normal growing season, thus meeting consumer demand on either end of the production season, typically when prices are higher. The modified climate inside the high tunnels also creates the opportunity to produce crops that can’t normally grow if unprotected, that may lead to a higher percentage to top-grade fruits and vegetables at harvest.\nOne of the primary disadvantages of the more permanent high tunnels is the fact that they are not easily moved. The result of this is that the same crop is grown in the same location every year, or a very short rotation is practiced. A short rotation or no rotation in vegetable production may lead to yield reductions and, depending on the crop, soil-borne disease development.\nAnother disadvantage to high tunnel production is the lack of exhaust fans for venting during hot weather. In most regions where tunnels are used, tunnels will overheat at some point during the crop production season unless manually vented as the temperature inside the tunnel rises. On warm sunny days, air temperatures in poorly vented tunnels can easily be 40o F greater than ambient outside temperatures.\nFor most farmers, the advantages of high tunnels outweigh the disadvantages. Thousands of fruit and vegetable farms in the U.S. successfully use high tunnels to extend the growing season. A farmer considering high tunnel production should first do some preliminary research and receive training in high tunnel production.\nTo teach Ohio farmers about high tunnel production and how they could adopt this new and emerging technology on Ohio farms, thanks to a USDA National Institute of Food and Agriculture grant, the Ohio State University South Centers hosted a high tunnel training program on April 27 and 28, 2015, at the Piketon Research and Extension Center in Piketon, Ohio. Individual trainings were tailored for the beginner and the advanced grower. This training included hands-on training on six local high tunnel farms and at the South Centers high tunnels.']"	['<urn:uuid:aee20c32-54e8-404d-9c33-f7cea4cf776d>', '<urn:uuid:288eff3f-6ed0-4c60-8f83-de4adf3d6d4f>']	open-ended	direct	long-search-query	distant-from-document	multi-aspect	expert	2025-05-13T03:20:41.944655	9	99	1146
45	brain activity copying other people movements	The mirror neuron system consists of two brain areas that are active both when we perform movements ourselves and when we observe others performing the same movements. This system is thought to enable a process of 'movement simulation' that helps us understand the meanings and goals of movements we observe in others.	"['A team of neuroscientists has found that the mirror neuron system, which is thought to play a central role in social communications, responds normally in individuals with autism. Their findings, reported in the journal Neuron, counter theories suggesting that a mirror system dysfunction causes the social difficulties exhibited by individuals with autism.\nThe mirror neuron system, the focal point of the Neuron study, is composed of two brain areas, which have a unique characteristic -- they are active both when we execute movements (e.g. grasping a cup of coffee) and when we passively observe other people executing those same movements. It has been known for many years that these brain areas are important for proper motor control because trauma to these areas causes movement deficits. Yet it has only recently been discovered that these brain areas respond when passively observing others. It has been proposed that this activity represents a process of ""movement simulation"" that enables us to understand the meanings and the goals of movements we observe.\nFor the simulation process to work properly, it is imperative that we simulate the exact same movement we are observing. This means that neurons within our mirror system must recognize movements and respond with a unique, movement-selective, response to each (or else we\'ll confuse different movements and attribute improper goals to the person we\'re observing).\nBecause individuals with autism have difficulty communicating socially and understanding the emotions and intentions of others, it has been hypothesized that they may have a dysfunction in their mirror neuron system. This hypothesis has received a tremendous amount of attention in both the popular and scientific literatures following a number of studies that reported weak mirror neuron system responses in individuals with autism. The issue of movement-selectivity, however, had not been addressed in these studies.\nTo further test this influential theory, the researchers asked individuals with autism and a control group to observe and execute different hand movements while being scanned with functional magnetic resonance imaging (fMRI). The fMRI measurements allowed the researchers to infer the strength of neural responses in mirror system areas of each group during movement observation and execution. Their results showed that mirror system areas of individuals with autism not only responded strongly during movement observation, but did so in a movement-selective manner such that different movements exhibited unique neural responses. The mirror system responses of individuals with autism were, therefore, equivalent to those commonly reported (and observed here) for controls.\nThese results, they conclude, argue strongly against the ""dysfunctional mirror system hypothesis of autism"" because they show that mirror system areas respond normally in individuals with autism. The authors, therefore, suggest that it may be more productive to re-focus autism research in more promising directions.\nThe study\'s co-authors are: Ilan Dinstein, a former graduate student at New York University and now a postdoctoral fellow at the Weizmann Institute in Israel; Cibu Thomas, Kate Humphreys, and Marlene Behrmann from Carnegie Mellon University; Nancy Minshew from the University of Pittsburgh; and David Heeger from New York University.\nThe study was supported by grants from the National Institutes of Health, Cure Autism Now, and the Pennsylvania Department of Health.\n- Dinstein et al. Cognition | Does Autism Reflect Mirror Neurons? Neuron, Volume 66, Issue 3, 461-469, 13 May 2010 DOI: 10.1016/j.neuron.2010.03.034\nCite This Page:']"	['<urn:uuid:e2518403-7e19-47db-aff9-abbc95fb2f51>']	open-ended	direct	short-search-query	distant-from-document	single-doc	novice	2025-05-13T03:20:41.944655	6	52	549
46	autoimmune diseases causes environment factors trigger	Autoimmune diseases have multiple potential triggers, with both inherited tendencies and environmental factors playing a role. While the exact causes are unknown, factors like infections and certain drugs may trigger these conditions. Environmental aspects have been particularly studied, especially in relation to geographic location and vitamin D levels. Research shows that people living farther from the equator (with less sunlight exposure and lower vitamin D levels) have a higher risk of developing some autoimmune conditions. Additionally, studies have investigated other environmental factors like smoking and various infectious agents, including viruses like measles, mumps, rubella, and Epstein-Barr, though clear links haven't been established.	['Autoimmune diseases are a broad range of related diseases in which a person’s immune system produces an inappropriate response against its own cells, tissues and/or organs. This results in inflammation and damage. There are over 80 different autoimmune diseases, ranging from common to very rare. These diseases can be localised to a single organ or tissue, or generalised (systemic), affecting many body organs and tissues.\nAutoimmune diseases include common and rare diseases\nAutoimmune diseases affect around 5% of people and are one of the most important health issues in Australia and New Zealand. Common autoimmune diseases such as thyroiditis, rheumatoid arthritis and diabetes affect more than 1% of people. SLE (lupus) affects less than 0.1% of people and is more common and severe in Indigenous Australians, Polynesians and those with descendants from South East Asia.\nWhat causes autoimmune diseases?\nThe causes of autoimmune diseases are unknown. In many cases it appears that there is some inherited tendency. However other factors such as infections and some drugs may play a role in triggering autoimmune diseases.\nHow are autoimmune diseases diagnosed?\nAutoimmune diseases are usually diagnosed using a combination of clinical history, blood tests (autoantibodies, inflammation, organ function) and other investigations such as x-rays. Sometimes a biopsy of affected tissues may be required for diagnosis.\nLocalised (organ specific) autoimmune diseases\nWhilst localised (organ specific) autoimmune diseases mainly affect a single organ or tissue, the effects frequently extend to other body systems and organs. These diseases are often managed by organ-specific medical specialists, such as endocrinologists, gastroenterologists, neurologists or rheumatologists.\nSystemic autoimmune diseases\nSystemic autoimmune diseases can affect many body organs and tissues at the same time. They can be broadly classified into rheumatological disease and vasculitis disorders (inflammation of blood vessels). These diseases are often managed by clinical immunology/allergy specialists and/or rheumatologists. Vasculitis disorders are relatively rare and result from inflammation of blood vessels. Information on vasculitis is available on the ASCIA website www.allergy.org.au/patients/autoimmunity\nExamples of localised (organ specific) autoimmune diseases\nAddison’s disease (adrenal)\nAutoimmune hepatitis (liver)\nCoeliac disease (gastrointestinal tract)\nCrohn’s disease (gastrointestinal tract)\nDiabetes Mellitis Type 1a (pancreas)\nGrave’s disease (thyroid)\nGuillain-Barre syndrome (nervous system)\nHashimoto’s thyroiditis (thyroid)\nMultiple sclerosis (nervous system)\nMyasthenia gravis (nerves, muscles)\nPernicious anaemia (stomach)\nPrimary biliary cirrhosis (liver)\nSclerosing cholangitis (liver)\nUlcerative colitis (gastrointestinal tract)\nExamples of rheumatological systemic autoimmune diseases\nAntiphospholipid antibody syndromes (blood cells)\nDermatomyositis (skin, muscles)\nMixed connective tissue disease\nPolymyalgia rheumatica (large muscle groups)\nPolymyositis (skin, muscles)\nRheumatoid arthritis (joints, less commonly lungs, skin, eyes)\nScleroderma (skin, intestine, less commonly lungs, kidneys)\nSjögren’s syndrome (salivary glands, tear glands, joints)\nSystemic Lupus Erythematosus (skin, joints, kidneys, heart, brain, red blood cells, other)\nTreatment options for autoimmune diseases\nCurrently there are no cures for autoimmune diseases, although there is a wide range of treatment options, which depend on the stage and type of autoimmune disease. The main aims of treatments for autoimmune diseases are to relieve symptoms, minimise organ and tissue damage and preserve organ function.\nTreatment options include:\n- Replacement of end organ functions (such as insulin in diabetes and thyroxine in autoimmune thyroid disease)\n- Non-steroidal anti-inflammatory medications (NSAIDS)\n- Corticosteroid anti-inflammatory medications (such as Prednisolone)\n- Immunosuppressive medications\n- Therapeutic monoclonals (such as TNF inhibitors)\n- Immunoglobulin replacement therapy.\nWhat happens if I have an autoimmune disease?\nThere are many different autoimmune diseases with different treatments and consequences for people with these diseases. It is important to find out as much as possible about your autoimmune disease by asking questions of your treating doctor.\nThere are also many patient support organisations and foundations that offer information and support.\nSome of these are listed on the ASCIA website www.allergy.org.au/patients/patient-support-organisations\nYou can learn about autoimmune disease from books and the internet, however you need to be aware that what is actually written may not apply to you, and you should always check the information with your doctor.\n© ASCIA 2017\nASCIA is the peak professional body of clinical immunology/allergy specialists in Australia and New Zealand\nPostal address: PO Box 450 Balgowlah NSW 2093 Australia\nThis document has been developed and peer reviewed by ASCIA members and is based on expert opinion and the available published literature at the time of review. Information contained in this document is not intended to replace medical advice and any questions regarding a medical diagnosis or treatment should be directed to a medical practitioner. Development of this document is not funded by any commercial sources and is not influenced by commercial organisations.\nContent updated 2017', 'How Does Environment Play a Role in MS?\nWhen discussing the role that environment plays in causing or contributing to the development of MS, a number of factors are considered. Environment can refer to where we live, what substances or organisms we come in contact with (including bacteria, viruses, dust, and pollutants), and what foods we eat and drink.\nSpecialized scientists, called epidemiologists, study patterns in the way diseases affect groups of people. For instance, epidemiologists are often called in to find out why an outbreak of a viral infection happens in a particular location or why one group of people may be more likely to get a certain type of cancer than another group.\nEpidemiologists have found that people who live in certain geographic locations (see the Map below) may be more likely to develop MS. Studies have shown, in general, that the prevalence of MS (the number of people who have MS at any point in time) is greater in higher latitudes, or those places farther in distance from the equator.\nIn other studies, epidemiologists have found that when young people born in a location where people are more likely to develop MS moved before the age of 15 to a different location (where people are less likely to develop MS), these young people no longer face the same increased likelihood for developing MS as do others who grew up in their same location of birth. This suggests that there may be something in the environment that people are exposed to at an early age (before puberty) that makes them more likely to develop MS.\nWhen people in a community who live close to one another develop MS, it’s natural to wonder whether MS resulted from common exposure to something in the local environment. Studies have been conducted to examine specific clusters of MS cases where there have been suspected common exposures.\nWhile cluster studies have been conducted in places including the Faroe Islands; Galion, Ohio; DePue, Illinois; Rochester, New York; El Paso, Texas, no true MS cluster has ever been confirmed and no environmental exposure, such as a hazardous substance or toxin, has yet been linked to MS.\nStudies of potential MS clusters are very difficult to carry out. However, such studies do have the potential to tell us whether something in our environment may trigger or contribute to the development of MS.\nScientists have looked at a number of substances, including foods and toxins, that we are exposed to in our environment to see if any can be linked to MS. Some experts think that low levels of vitamin D may be linked to the development of MS.\nVitamin D is produced naturally by the body when we are exposed to sunlight and plays an important role in strengthening our immune system. People who live nearer to the equator and get more sunlight year-round tend to have higher levels of vitamin D in the blood. Interestingly, we know that the closer you live to the equator early in life (and the more sunlight and vitamin D you get), the less likely you are to develop MS.\nSmoking and infectious agents\nScientists have also examined exposure to smoking and various infectious agents, including common viruses, to find out if any of these may play a role in increasing the risk for developing MS. However, results from studies have failed to show a clear link between these environmental exposures and MS. Several infectious agents that have been examined for a link to MS include measles, mumps, rubella, and the Epstein-Barr virus.']	['<urn:uuid:0958a839-9160-4cc7-8633-198854819f9e>', '<urn:uuid:56069b03-8ea8-43d8-be4a-04cbe3905306>']	open-ended	with-premise	short-search-query	similar-to-document	multi-aspect	novice	2025-05-13T03:20:41.944655	6	102	1341
47	set theory basics power what operations allowed create new sets first five axioms	The first five axioms of set theory define the basic operations allowed to create new sets: 1) Extensionality states two sets are equal if they have the same elements, 2) Empty Set ensures existence of a set with no elements, 3) Pairing allows creating a set containing exactly two given elements, 4) Union permits creating a set that combines elements from multiple sets, and 5) Power Set enables creating a set containing all subsets of a given set.	"[""This is a continuation of my earlier set theory post. In this post, I’ll describe the next three axioms of ZF and construct the ordinal numbers.\n1. The Previous Axioms\nAs review, here are the natural descriptions of the five axioms we covered in the previous post.\nAxiom 1 (Extensionality) Two sets are equal if they have the same elements.\nAxiom 2 (Empty Set Exists) There exists an empty set which contains no elements\nAxiom 3 (Pairing) Given two elements and , there exists a set containing only those two elements. (It is permissible to have , meaning that if is a set then so is .)\nAxiom 4 (Union) Given a set , we can create , the union of the elements of . For example, if , then is a set.\nAxiom 5 (Power Set) Given any set , the power set is a set.\nI’ll comment briefly on what these let us do now. Let , and recursively define . So for example,\nNow let’s drop the formalism for a moment and go on a brief philosophical musing. Suppose we have a universe (I’ll explain later what is) where the only sets are those which appear in some . You might then see, in fact, that the sets in actually obey all five axioms above. What we’ve done is provide a model for which the five axioms are consistent.\nBut this is a pretty boring model right now for the following reason: even though there are infinitely many sets, there are no infinite sets. In a moment I’ll tell you how we can add new axioms to make infinite sets. But first let me tell you how we construct the natural numbers.\n2. The Axiom of Foundation\nWe’re about to wade into the territory of the infinite, so first I need an axiom to protect us from really bad stuff from happening. What I’m going to do is forbid infinite chains.\nAxiom 6 (Foundation) Loosely, there is no infinite chain of sets\nYou can see why this seems reasonable: if I take a random set, I can hop into one of its elements. That’s itself a set, so I can jump into that guy and keep going down. In the finite universe , you can see that eventually I’ll hit , the very bottom of the universe. I want the same to still be true even if my sets are infinite.\nThis isn’t the actual statement of the axiom. The way to say this in machine code is that for any nonempty set , there exists a such that for any . We can’t actually write about something like in machine code (yet). Nevertheless this suffices for our axioms.\nThere’s an important consequence of this.\nTheorem 1 for any set .\nProof: For otherwise we would have which violates Foundation.\n3. The Natural Numbers\nNote: in set theory, is considered a natural number.\nNow for the fun part. If we want to encode math statements into the language of set theory, the first thing we’d want to do is encode the numbers , , in there so that we can actually do arithmetic. How might we do that?\nWhat we’re going to do is construct a sequence of sets of sizes , , and let these correspond to the natural numbers. What sets should we choose? Well, there’s only one set of size , so we begin by writing\nI’ll give away a little more than I should and then write\nNow let’s think about . If we want to construct a three-element set and we already have a two-element set, then we just need to add another element to that’s not already in there. In other words, to construct I just need to pick an such that , then let . (Or in terms of our axioms, .) Now what’s an easy way to pick such that ? Answer: pick . By the earlier theorem, we always .\nNow the cat’s out of the bag! We define\nAnd there you have it: the nonnegative integers. You can have some fun with this definition and write things like\nnow. Deep down, everything’s a set.\n4. Finite Ordinals\nWe’re currently able to do some counting now, because we’ve defined the sequence of sets\nby and . This sequence is related by\nSome properties of these “numbers” I’ve made are:\n- They are well-ordered by (which corresponds exactly with the which we're familiar with; that's a good motivation for choosing this construction, as the well-ordering property is one of the most important properties of , and using for this purpose lets us do this ordering painlessly). That means if I take the elements of , then I can sort them in a transitive chain like I've done above: for any and , either or . For example, the elements of are , , , and . It also means that any subset has a “minimal'' element, which would just be the first element of the chain. Here is the complete definition.\n- The set is transitive. What this means that it is a “closed universe” in the sense that if I look at an element of , all the elements of are also in . For example, if I take the element of , all the elements of are in . Looking deeply into won’t find me anything I didn’t see at the top level.\nIn other words, a set is transitive if for every , .\nA set which is both transitive and well-ordered by is called an ordinal, and the numbers are precisely the finite ordinals. But now I’d like to delve into infinite numbers. Can I define some form of “infinity”?\n5. Infinite Ordinals\nTo tell you what a set is, I only have to tell you who its elements are. And so I’m going to define the set\nAnd now our counting looks like this.\nWe just tacked on an infinity at the end by scooping up all the natural numbers and collecting them in a set. You can do that? Sure you can! All I’ve done is written down the elements of the set, and you can check that is indeed an ordinal.\nWell, okay, there’s one caveat. We don’t actually know whether the I’ve written down is a set. Pairing and Union lets us collect any finite collection of sets into a single set, but it doesn’t let us collect things into an infinite set. In fact, you can’t prove from the axioms that is a set.\nFor this I’m going to present another two axioms. These are much more technical to describe, so I’ll lie to you about what their statements are. If you’re interested in the exact statements, consult the lecture notes linked at the bottom of this post.\nAxiom 7 (Replacement) Loosely, let be a function on a set . Then the image of is a set:\nAxiom 8 (Infinity) There exists a set .\nWith these two axioms, we can now write down the first infinite ordinal . So now our list of ordinals is\nBut now in the same way we constructed from , we can construct a set\nand so on — all of these are also transitive and well-ordered by . So now our list of ordinals is\nWell, can we go on further? What we’d like is to define an “ or ”, which would entail capturing all of the above elements into a set. Well, I claim we can do so. Consider a function defined on which sends to . So , , . (Strictly, I have to prove that set-encoding of this function, namely , is actually a set. But that’s put that aside for now.) Then Replacement tells me that I have a set\nFrom here we can union this set with to achieve the set . And we can keep turning this wheel repeatedly, yielding the ordinal numbers.\nI won’t say much more about these ordinal numbers since the post is already getting pretty long, but I’ll mention that the ordinals might not correspond to a type of counting that you’re used to, in the sense that there is a bijection between the sets to . It might seem like different numbers should have different “sizes”. For this you stumble into the cardinal numbers: it turns out that a cardinal number is just defined as an ordinal number which is not in bijection with any smaller ordinal number.\n6. A Last Few Axioms\nI’ll conclude this exposition on ZFC with a few last axioms. First is the axiom called Comprehension, though it actually can be proven from the Replacement axiom.\nAxiom 9 (Comprehension) Let be some property, and let be a set. Then the notion\nis a set. More formally,\nNotice that the comprehension must be restricted: we can only take subsets of existing sets. From this one can deduce that there is no set of all sets; if we had such a set , then we could use Comprehension to generate , recovering Russel’s Paradox.\nSo anyways, this means that we can take list comprehensions.\nFinally, I’ll touch a little on why the Axiom of Choice is actually important. You’ve probably heard the phrasing that “you can pick a sock out of every drawer” or some cute popular math phrasing like that. Here’s the precise statement.\nAxiom 10 (Choice) Let be a set such that . Then we can define a function on such that for every . The function is called a choice function; given a bunch of sets , it chooses an element out of every . In other words, for any with , there exists a set\nwith for every .\nIn light of the discussion in these posts, what’s significant is not that we can conceive such a function (how hard can it be to take an element out of a nonempty set?) but that the resulting structure is actually a set. The whole point of having the ZF axioms is that we have to be careful about how we are allowed to make new sets out of old ones, so that we don’t run ourselves into paradoxes. The Axiom of Choice reflects that this is a subtle issue.\nSo there you have it, the axioms of ZFC and what they do.\nThanks to Peter Koellner, Harvard, for his class Math 145a, which taught me this material. My notes for this course can be downloaded from my math website.\nThanks to J Wu for pointing out a typo in Replacement and noting that I should emphasize how leads to the well-ordering for the ordinals.""]"	['<urn:uuid:2e266156-8d72-43af-a459-f81f0fdaf393>']	open-ended	with-premise	long-search-query	distant-from-document	single-doc	expert	2025-05-13T03:20:41.944655	13	78	1778
48	What are the essential elements to consider regarding light exposure and temperature management for successful pitcher plant cultivation?	Pitcher plants require moderate to bright light but must be shaded from direct sunlight at all times. Regarding temperature, they thrive in average to warm conditions of 75-85°F/24-29°C, though they can tolerate a minimum of 65°F/18°C. A heated sunroom or greenhouse with consistently warm conditions is ideal for these tropical plants.	"[""Botanical Name: Nepenthes species and hybrids\nPitcher Plant care is easy -- or difficult -- depending on the growing conditions you have available.\nUnlike many carnivorous plants that come from bogs and swamps and prefer wet, cool conditions, Nepenthes prefers tropical warmth and humidity. So unless you happen to live in the tropics, this epiphytic carnivore will need special accommodations.\nA heated sunroom or greenhouse, where the air is consistently warm and humid is the best place for your pitcher plant. Just keep it shaded from direct sunlight at all times. Put it in a hanging basket to show off those unusual and fascinating pitchers.\nThe glossy green leaves grow to 1 ft (30 cm) long and feature a tendril at the tip. Large, pendulous pitchers commonly grow at the tips of those tendrils and are topped with a lid to keep out the rain. Depending on the species or hybrid, the pitchers may be yellow-green or mid-green and splashed or spotted with purple or red.\nAbout those bug-eating pitchers... Because this epiphytic carnivorous plant is unable to get the nutrients it needs from soil, it has developed a way to attract, capture and ingest insects. Bugs are lured inside its pitchers with an intoxicating nectar. Once inside, the insects fall into the pepsin liquid where they drown and are digested.\nRepot in spring only when needed. Handle the roots carefully because they're delicate and break easily. Plant Nepenthes in a basket with drainage holes to prevent soggy medium, which can cause root rot.\nPrune it back in spring to keep Nepenthes a reasonable size. Older plants can be cut back harshly. Pruning encourages new growth so you'll get a fuller plant.\nSome popular Malaysian pitcher plants include:\nNepenthes 'Alata', one of the most common species cultivated, has pitchers heavily marbled with red. Nepenthes x coccinea, featuring yellow and red pitchers. Nepenthes 'Superba', a vigorous grower with yellow-green pitchers splotched with dark crimson. Nepenthes x hookeriana with large, pale-green pitchers marbled with red.\nOrigin: Borneo and Malaysia\nHeight: Climbs or trails to 10 ft (3 m)\nLight: Moderate to bright light, but no direct sun.\nWater: Keep soil evenly moist year-round, but not soggy which can cause root-rot. Because this plant is sensitive to chemicals in tap water, use only distilled or lime-free rain water.\nHumidity: Moderate to high (50-80% relative humidity) is a must for pitcher plant care. Mist the plant every day or use a cool-mist room humidifier. Pitcher plants grow best in a heated greenhouse.\nTemperature: Average to warm 75-85°F/24-29°C. It will tolerate a minimum of 65°F/18°C.\nSoil: Use a nutrient-poor medium because rich potting mix will harm its roots. You can plant it in live sphagnum moss, or if that is not available, mix 1 part peat moss with 1 part perlite or horticultural sand.\nFertilizer: Don't fertilize the plant. In spring and fall, drop a few insects into the pitchers occasionally if there are none flying around. Don't use bugs that have been treated with insecticide.\nPropagation: Take leaf cuttings in spring and root them in sphagnum moss. Use a heat mat. Mist every day with tepid water to keep the medium moist. Be patient -- rooting can take up to 8 weeks.""]"	['<urn:uuid:301d9842-1d5e-4f59-806c-afac87f42f6d>']	open-ended	direct	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-13T03:20:41.944655	18	51	538
49	basic principle making movies appear three dimensional	3D movies trick the brain by projecting two 2D images separately to the two eyes to recreate a 3D image in the brain. This works because our eyes naturally project a 3D image in the brain by seeing things from two different viewpoints due to the gap between our eyes.	"['Presentation on theme: ""Ng Boon Hian Physics behind 3D Movies. Case Study – 3D movies With 3D viewing technology offered in cinemas, many people are fast to snap up on the tickets.""— Presentation transcript:\nNg Boon Hian Physics behind 3D Movies\nCase Study – 3D movies With 3D viewing technology offered in cinemas, many people are fast to snap up on the tickets to 3D movies. I watched Alice in Wonderland in 3D version at Shaw Theatre recently and wondered what was the science behind the 3D glasses.\nHow do our eyes work Our eyes project a 3D image in the brain by seeing things from two different viewpoints as noted by the gap between our eyes and these 2 2D images are formed in the brain into 1 3D image. Thus, 3D images are formed and everything in the real world is 3D.\n2D Movies 2D movies work on a film being projected onto the screen. Everything is on the screen and in 2D. The light is unpolarized.\nPolarized light and Unpolarized ight Light is an electromagnetic wave Electromagnetic waves consist of electric and magnetic component Electric component (electric force field) moves up and down as the electromagnetic waves forward\nUnpolarized light From Sun, bulbs, candles No fixed plant of oscillation Yellow plane arrow changes angles but keeps direction of light Random changes in direction of light 3D animation\nPolarized Light Filtered Light Fixed plane of oscillation Half of the intensity of unpolarized light\nUnpolarized VS Polarized For unpolarized light, no matter how the arrow turns, electric forces are always perpendicular to ray direction Polarized lightUnpolarized light\nPolarizers Filters out the unpolarized light into single light planes Have lines aligned in 1 direction and only allow 1 plane of light to pass Circular polarization and linear polarization\nCircular polarizer and linear polarizer Circular polarizer used for 3D glasses\nCircular polarizer and linear polarizer Circular polarizer is just a quarter wave plate in addition to the linear polarizer Linear polarized 3D glasses will work with all the old stereo projectors, StereoJet prints, and modern projector systems with linear polarizers attached Circular polarized 3D glasses are specifically for the StereoGraphics Z-Screen and some 3-D digital projection systems.\nCircular polarizer and linear polarizer Not much difference as both saturates colors and eliminates reflections from water and windows for cameras Circular polarizers are more expensive but can eliminate possible metering errors while linear polarizers are unable to\nFilters to transform unpolarized light to polarized light Polaroid filter Enables only 1 polarization of light to pass through.\n3D Movies Eyes are two inches apart, two different angles on viewing the same things creates a 3D image 3D movies trick the brain by projecting two 2D images separately to the two eyes and recreate a 3D image in the brain\n3D Movies 3D movies not viewed with the glasses are very fuzzy and eye-straining to look at The same scene is projected simultaneously from two sources Previous 3D movies used colour as filter but polarization is used\nColour and Polarization Colour 3D uses contrast of colours An anaglyph image is formed Each lens is made up of a chromatically different colour – blue and red Colour used to provide separation Red part allows blue light to enter while blue part allows red light to enter\nColour as filter A severe disadvantage is that film cannot have much colour as colour is used as filter in this case Stereo Monochrome image\nPolarization Two synchronised projectors project two respective views, each with a different polarization Each side of the glasses allows 1 plane of light to enter\n3D Movies Due to the 3D effect, viewers can feel the thrill of being in the movie themselves and get really close to the characters\nBites 3D glasses if not cleaned properly can pass on eye infections to others Can cause headaches and blurred vision Forces viewers to focus on things in the foreground (which causes eyes to converge) and distance (which causes them to separate) simultaneously Vergence accomodation conflict\nBuild your own 3D glasses activity Cardboard Scissors Tape Red and Blue acetate (Available from art store)\nBuild your own 3D glasses activity Trace a pattern on the paper of the three parts of spec mainly the two sides and a middle portion Place them on the cardboard and cut out the shapes Cut eyeholes Tape the blue and red acetate separately on the two eyeholes and you have a 3D glasses\nOther Facts 3D glasses used will not produce a 3D effect on home TV as light is unpolarized']"	['<urn:uuid:34fca2a6-2600-4dd8-9de2-e1e3fc03f95c>']	factoid	direct	short-search-query	distant-from-document	single-doc	expert	2025-05-13T03:20:41.944655	7	50	760
50	I've never used an impact driver before and want to avoid damaging screws - what's the most important thing to know about using the bits with these tools?	The most important thing is that the bit you're using must be a perfect match for the fastener. If there's even the smallest amount of looseness in the fit, either the bit or the fastener will almost always get rounded and ruined as the tool spins rapidly while the fastener doesn't move.	['I can understand your skepticism. Some people just want every new shiny object that hits the marketplace. This disease afflicts both women and men equally, I feel.\nThe good news is that your husband is hankering for something that’s more than just moderately useful. I own more than one impact driver, and this tool is absolutely one of the top five power tools the average homeowner should own. I only wish they were available decades ago, when I was still building 60 hours a week. My productivity would have gone through the roof!\nIf you’ve never used or held an impact driver, the best way to picture one is to think about the tool that auto mechanics use to remove the lug nuts from a car wheel. Have you ever heard that high-pitched whiz and rat-a-tat-tat as the lug nut spins off or is tightened by the air-powered impact driver? This reliable technology, which has been around for years, was transferred to the pro and DIY power-tool marketplace not too long ago.\nThese marvelous tools can be used for so many things, as long as you get the right one. Even though many look the same, there are significant differences between some of these tools. I prefer the cordless impact drivers, because they’re so versatile. Who wants to drag around a power cord if it’s not needed?\nMy favorite impact driver is made by Milwaukee. It’s got a brushless motor, a 1/4-inch hex drive and three torque settings, the latter of which range from 200 to 1,600 inch-pounds of torque. Believe me, that’s more than enough to drive giant 3/8-inch long lag screws into hard yellow pine!\nDifferent voltages are available for cordless power tools. I happen to be a fan of 18-volt devices, but I probably expect more out of my tools than a casual weekend warrior. There are 12-volt impact drivers that deliver plenty of punch and will drive or remove many fasteners with just one charge of the lithium-ion battery.\nHere’s a partial list of some of the jobs this tool will accomplish. I recently used mine to remove screws that held a deck railing in place. The tool also did a remarkable job of removing large lag bolts that held the railing posts in place. And I used the driver to install giant five-inch-long timber screws in solid lumber.\nMy impact driver works well for smaller fasteners, too. When you need extreme control to drive small hidden fasteners between expensive composite decking, then come and borrow my impact driver. I just finished driving hundreds of tiny stainless-steel screws that are part of the hidden fastening system for my Trex decking. Using the No. 2 torque setting delivered the perfect amount of torque so as not to snap the screws.\nThe hex drive system allows you to use the tool with any number of fasteners. Imagine if you need to drive Phillips-head screws. How about hex-head screws? Do you have to drive Torx screws or square-drive fasteners? Each of these can be expertly driven into wood, steel or any other material with precision using a high-quality impact driver and an assortment of hex-shaft bits.\nDon’t try to compare an impact driver with a screw gun. The inner mechanics of each are radically different. Impact drivers deliver tiny bursts of power that make a much bigger difference in trying both to drive and remove fasteners.\nWhen using an impact driver, it’s really important that the bit you’re using is a perfect match for the fastener. If there’s the smallest amount of slop in the fit, either the bit or the fastener will almost always get rounded and ruined as the tool spins rapidly while the fastener doesn’t.\nIf your husband has not used an impact driver, I feel it’s best to have him practice driving different fasteners in scrap lumber to really get a feel for how the tool works. It’s important not to over-drive certain fasteners. He’ll also discover that when driving into wood, the wood species makes a big difference, as harder woods can cause fasteners to snap with little warning.\nI urge you to try the tool, too. I believe once you see how amazing an impact driver is, you’ll be glad you approved the purchase. It saves so much work and takes so much stress off your wrists and hands. Keep in mind that the more-expensive impact drivers usually have better parts, better engineering and can last for generations if cared for.\nNeed an answer? All of Tim’s past columns are archived for free at www.AsktheBuilder.com. You can also watch hundreds of videos, download Quick Start Guides and more.']	['<urn:uuid:e84f10ac-462c-43c5-a944-5f5fd803a37f>']	factoid	with-premise	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-13T03:20:41.944655	28	52	775
51	roman coin found hungerford field details mint mark emperor date	A Roman coin was found showing Emperor Constantine I on the obverse side. The coin had a mint mark PLN indicating it was made in the first workshop of the Londinium (London) mint in the summer of AD307.	"[""It’s seven weeks until this year’s excavation team lands in Somerset.\nIn Newcastle all sorts of behind the scenes preparations are happening. The minibus is booked, lists of equipment are being drawn up and we’re all thinking hard about exactly where we should dig this year and why.\nOur grant from Brympton Parish council has also arrived (a big thank you to everyone in Brympton for their support).\nIn week or so the students (Adam, Eleanor, Dave, Georgia, Johanna, Kevin, Lucy and Danni) will have their final briefing and be issued with kit lists. Some of them are currently thinking about exams so I expect the dig seems a long way off.\nEvery field in the land has a name and many of these names are recorded on Victorian Tithe Maps. Copies of these documents for Somerset are held by the Somerset Records Office. As part of the project we’ve been looking at the field names recorded on the Tithe Maps for Lufton and the surrounding parishes.\nThe names given to fields by people who worked them in the past often reflect something important about those pieces of land. They might tell us who owned the land (Ball’s Mead), they might describe the piece of land (Three Cornered Field), or they might tell us about the history of the piece of land. Chester would indicate a Roman site, Blacklands a site that might have been occupied intensely in the past. So far our work hasn’t turned up any of these names but there are an interesting group of fields over in Odcombe.\nJust north of the village of Odcombe are a series of fields with ‘Englands’ names. This name is likely to derive from inland and this term is often associated with parts of early medieval estates that were under direct lordly control. Two recent pieces of archaeological fieldwork on fields with ‘Englands’ names in Charleton Horethorne and Sparkford have demonstrated that both of these sites were occupied in antiquity. The fields in Odcombe might also contain similar evidence.\nEnglands Field Names near Odcombe © The Lufton Project and Andrew Agate\nA short article on this discovery will be published in the journal of the Medieval Settlement Research Group.\nWe completed the survey of Hungerford and realised that the settlement continued further to the south. So we carried on surveying and in 2010 and 2011 covered two smaller fields known as Danscombe and Mr Unwin’s Field.\nGeophysics of Danscombe © GeoFlo and The Lufton Project\nDanscombe was particularly interesting because just before the magnetometer survey was carried out the landowner manured the field with ‘green waste‘. This is the composted hedge clippings and other stuff collected from householders by the council. Theoretically it shouldn’t have an impact on the survey but at Danscombe we discovered that the ‘green waste’ had a lot of many metal contaminants. These had a negative impact on the survey (compare image above with the one below) and this problem is currently being studied by Alissa, an MA student at Newcastle.\nFor all of the problems caused by the ‘green waste’ we could see that the ancient settlement continued into this field. The big line running across the image is a modern pipeline (A).\nThe Mr Unwin’s Field (to the east: below) was also surveyed and contained further anomalies associated with the settlement (A). We also identified a round anomaly (B) that we thought might be the remains of a roundhouse or barrow. This is where we decided to dig in 2012.\nGeophysics of Mr Unwin's Field © GeoFlo and The Lufton Project\nExcavation is a small part of the archaeological process. We dig for a little while but spend much longer trying to figure out what our discoveries mean. Finds analysis is a big part of the post-excavation work. Our flint assemblage was looked at by Dr Rob Young and this post is based on his analysis.\nFlints were used by prehistoric peoples for tools. They worked (or knapped) the flint to produce edges that were sharper than surgical steel. A wide variety of prehistoric stone tools are known but the object illustrated below is a heavy and thick end scraper of Neolithic or Bronze Age date. It is roughly contemporary with the ring-ditch we dug in 2012.\nFlint scraper of Neolithic/Bronze Age date © Rob Young and the Lufton Project\nThe third and final week saw the trench extended and a lot of work to investigate the ditches and sort some modern features (including a septic tank outfall pipe) from the ancient features.\nExcavating in Week 3 © The Lufton Project\nAs archaeological excavation is destruction it was important that everything was properly recorded. A lot of drawings, photographs and paperwork were completed.\nDanni Recording © The Lufton Project\nTowards the end of the excavation Mr Unwin (the landowner) came to look at our trench, He was a very genial and tolerant host and the project is very grateful to Mr Unwin and his family for the support they are giving to this work.\nJames shows Mr Norman Unwin the trench © The Lufton Project\nAt the end of the week we had some help from Jamie and Carole Pullen. They lent us a digger and driver to backfill our trench! Then we put the turf back and headed back to Newcastle.\nBackfilling the trench © The Lufton Project\nOver the weekend we talked to lots of visitors at the open day. Then on Sunday our prayers were answered. The heavens opened and it rained.\nJames surveying a wet trench © The Lufton Project\nSome water in the soil meant that we could see the archaeology and that the digging was a bit easier.\nThe ring-ditch is revealed as we begin to define and excavate features © The Lufton Project\nWe worked hard to define and begin to excavate the features. We were rewarded with some tiny pieces of Early to Middle Bronze Age pottery from the ring ditch and some Iron Age pottery from the big ditch.\nKristjan and Fraser working hard © The Lufton Project\nWe made good progress in Week 2. The water bowser that seemed so important to have in the dryness of Week 1 was a bit redundant…\nWe went into Week 3 feeling pretty happy with what we’d discovered.\nIn 2012 we carried out a three week excavation to investigate geophysical anomalies identified in Mr Unwin’s Field. One of these anomalies was circular (B on the graphic below) and such features are usually termed ‘ring-ditches‘, the other was a linear anomaly that was likely to be a ditch (A on the graphic below). The excavation was designed to work out whether the ring-ditch was a part of a burial mound or a prehistoric house and whether it came before or after the ditch.\nGeophysics of Mr Unwin's Field © GeoFlo and The Lufton Project\nThe trench was laid out as a 10m x 10m square and excavated by hand. We started by removing the turf and then, in what was about the only hot and dry week of the Summer, we started excavating.\nCutting the turf © The Lufton Project\nWe removed ploughsoil and subsoil to a depth of about 0.4m. If a cubic metre of sand weighs about a tonne, we shifted about 40tonnes of spoil by hand! At 40cm deep we were on top of a layer archaeologists call ‘the natural’. This is a geological deposit (in our case a nasty clay) that pre-dates all human activity. Cut into the natural were some features. These included the ditch and arc of the ring-ditch we were looking for. These features were filled with a slightly darker and moister sediment than the surrounding natural and are visible in the following photos as dark stains.\nNewcastle Students Kate and Ellie along with local volunteers Pete and Robin have found the ring ditch (visible as a dark arc in the deepest part of the trench). © The Lufton Project\nThe week was really dry and by the end of it the clay had baked hard. The dried out features had all but disappeared from view. We prayed for rain…\nBrown, brown and brown. The trench has dried out and the archaeology's invisible © The Lufton Project\nWe’re pleased to announce that the big army tent has arrived and been tested by our friends in SSARG.\nThe Tent Erectors from SSARG © The Lufton Project\nLast year we didn’t have much shelter on site (well, we had a couple of gazebos that couldn’t cope with a light breeze). So the tent is a welcome addition to the project. It’ll be shelter on rainy days (many of those I expect), shade on hot days (not many of those!) and a place to keep our kit and most importantly do the paperwork.\nIt’s all a reminder that the excavation is coming soon…\nFollowing the geophysical survey of the area around the villa we took a decision to survey the big field to the south. This piece of land is known as ‘Hungerford’, a fieldname that usually denotes poor land. In the nineteenth century this big field was a number of smaller fields some of which were named ‘Little’ and ‘Lower Danscombe’.\nThe geophysical survey was undertaken between 2009 and 2011 and revealed an astonishing archaeological landscape. It is of many phases but includes a large and almost circular enclosure and a settlement with trackways and enclosures. This ancient settlement was a new discovery. We had no idea it was there and it came as quite a surprise.\nThe settlement probably dates to the Iron Age and Roman periods. Some of the geophysical anomalies are likely to be contemporary with the villa – it may be where the agricultural workers and tenants lived.\nGeophysics of Hungerford © GeoFlo and the Lufton Project\nThe small-scale metal detecting survey recovered a small number of Roman coins as well as the coin of Henry VIII.\nThis is one of the Roman coins. The obverse (heads) shows the Emperor Constantine I. He was elevated to the imperial throne at Eburacum (York), became the first Christian Roman emperor and established Constantinople (Istanbul). The reverse shows the Genius of the Roman people (surrounded by the legend GENIO POP ROM). At the bottom of the coin (in the exergue) is a mintmark PLN, which tells us that the first (Prima) ‘workshop’ of the mint at Londinium (London) made this coin in the summer of AD307(RICVI (London), 88).\nThis coin could have been dropped by one of the villa’s inhabitants!\nObverse: head of Constantine, Reverse: GENIO POP ROM // PLN © The Lufton Project© The Lufton Project""]"	['<urn:uuid:da0c588c-3e20-49a8-ad78-454c7cd0b24e>']	factoid	with-premise	long-search-query	similar-to-document	single-doc	expert	2025-05-13T03:20:41.944655	10	38	1775
52	How do the stadiums of Ancient Messene and Messina differ architecturally?	Ancient Messene's stadium, discovered through recent excavations, features a Doric style Propylon entrance in its northwest corner, with halls on three sides over 110 meters, and a grass-covered southern stand without seats. The Stadium in Ancient Messina has 18 stands with 18 rows of seats in its northern section, is surrounded by Doric stoas, and forms an architectural ensemble with the Gymnasium, featuring a double-form northern arcade and simple east and west forms.	"['Ancient Messini is one of the most significant ancient cities in terms of its size, structure and state of preservation and still has much to be discovered. Along with the sanctuaries and public buildings it has imposing fortifications, dwellings and burial sites. It has, amongst other things the rare advantage of never having been destroyed or covered by later settlements and sits in an unspoiled inland site in a natural Mediterranean environment. This natural environment combines the mountain grandeur of Delphi and the low riverside serenity of Olympia, the dominating bare limestone mass of Mount Ithome, the ancient acropolis and the low fertile plain spread below the ancient city.\nOne can easily reach the site by road from Athens along the Corinth - Tripoli - Megalopolis - Kalamata highway or via the Corinth - Patra - Pyrgos - Kyparissia Meligalas highway. From Olympia the site is about an hours drive.\nThe Stadium and Gymnasium of Ancient Messina\nThe Stadium and Gymnasium are amongst the most impressive and well preserved buildings on the site. The northern part of the horseshoe-shaped stadium contains 18 stands with 18 rows of seats separated by stairways. Surrounded by Doric stoas, whose columns are standing mostly in place. The northern arcade is double in form, whereas the east and the west are simple in form. The colonnades belong to the Gymnasium which together with the Stadium formed one single architectural ensemble. The western stoa terminated at the end of the track at a length of 110 meters from the northern end. At this point a Doric peristyle court is located which is identified as the palaistra.\nPedestals with honorary inscriptions, are located between the columns of the western stoa and used to hold the statues of gymnasiarchs (Gymnasium officials). Other inscriptions have also been found bearing lists of ephebes (youths). Behind the western colonnade was the sanctuary of Heracles and Hermes with their cult statues.\nThe Ancient Theatre of Messina\nThe first monument to be seen when descending from the museum to the archaeological site is the theatre. It was used for mass political gatherings. In this theatre the meeting was held between King Philipp V Macedon and Aratos the Sikyonian in 214B.C, the day following the revolt of the Messinian people. According to the testimony of Livius (39.49.6-12), many residents of Messina gathered in the theatre of the city and demanded that the great general of the Achaean League, Philopoimen from Megalopolis captured by the Messenians in 183B.C., be transferred there and exposed in plain view. The auditorium is based on an artificial embankment composed of a strong semi-circular retaining wall.\nThe fort like impression is emphasized by the arched entrances and ascending stairways. These elements and the fact that the retaining wall of the cavea is visible and accessible from the outside make the Theatre of Messene an exceptional building predictive of the theatres and amphitheatres of the Roman period.\nA large part of the western retaining wall of the cavea survives. The wall is interrupted at regular intervals (by about 20 meters), by entrances with pitched arches which led via stairways to the upper corridor; from there, other stairways provided access to the orchestra and also defined the wedge-shaped divisions of seats. The exterior of the retaining wall is built in exactly the same way as the fortification walls and towers of the city.\nThe Palace of Nestor\nThe agricultural town of Hora, located 50 km from Kalamata, is known to all visitors as the archaeological area where the Upper Egklianou palaces of King Nestor were discovered (many compare them with Ancient Mycenae and Tiryns). Close by is the tholos tomb attributed to Nestor and his heir Thrasymidi. Findings from the palace and surrounding region that came to light by the excavations (approximately 4000 years of archaeological finds) can be found in the Archaeological Museum of Hora.\nOn the Upper Egklianou hill, 4 kilometres south of Hora, the palace was found that is said to be the Palace of Nestor. The excavations started in 1939, and were completed after the Second World War, brought to light earlier ruins from the Palace. The city and the Palace were destroyed in 1200 B.C., probably during the invasion of the Dorians.\nThe Palace of Nestor just14 km from Pylos, is among the most important monuments of Mycenaean Greece, because it is the only Mycenaean Palace which is in such good condition. The palaces were built in the 13th century B.C. by King Nestor (son of Neleus) who took part in the Trojan War with ninety ships. Ancient Pylos was the second biggest city of the Mycenaean world, after Mycenae, and King Nestor is portrayed as one of the most respected characters in the Homeric epics. The surrounding landscape was calm and the the Palace was not fortified, unlike the other Mycenaean settlements. The palace was almost completely destroyed in the early twelfth century, by fire and never reconstructed. The fire had an extremely positive result; it baked many ceramic tablets thus saving approximately 1200 texts with rare information on the economy, society, worship etc. of the Mycenaean times.\nHeinrich Schliemann had made inquiries in the area in 1888, but didnt manage to find the palace of Nestor. In 1912 and 1926 the archaeologist Kountouriotis discovered two Tholos tombs that Carl Blegen felt were royalist. In 1939 Kountouriotis identified the location of the prehistoric royal Palace and the excavation was continued and completed by the American archaeologist Carl Blegen. For 10 days they made excavations in 8 locations and found Mycenaean vases. On the 4th of April they had already found parts of murals, tablets with Linear B (these tablets, which are reminiscent of palm leaves, 1250 in total, were decoded in 1952 by the architect Michael Ventris and the classical scholar John Chadwick, giving us practical information on life in prehistoric Pylos), and one meter thick walls This stage of the excavations continued until 10th May, revealing much of the Palace.\nBy studying the texts of more than 1100 tablets of Linear B, that were found in the palace complex, the decryption of the Linear B script by Michael Ventris gave abundant evidence of the strong industrial and commercial activity of the area with the Palace at its centre.\nThe excavations were stopped at the start of the Second World War until 1952. The palace complex consists of four main buildings, which have dozens of partitions. After the discovery of the throne room, Blegen called the site the Palace of Nestor. Gradually the ruins of a wealthy 2 floored edifice came to light and other two auxiliary buildings, spread half way over the plateau of Egkliano. Around the Palace Tholos graves have been excavated with remarkable objects, the closest being found at a distance of 80 metres from the Central Palace.\nThe Palace is a complex of buildings with a total of 105 ground floor apartments and other public spaces. It consists of four main buildings (western, central, northeast & wine warehouse), as well as some smaller buildings. The most important part is a large rectangular Crown Room"" with a circular hearth, also the bathroom with its clay bathtub and warehouses with numerous storage vessels.\nTemple of Apollo Epikourios\nOn the bare rocky slopes of Mount Kotilio stands one of the most important and imposing temples of antiquity, dedicated to Apollo Epikourios (""Apollo the Helper"").. The temple is situated in a prominent position and is on the U.N.E.S.C.O. list of World Cultural Heritage sites along with the Egyptian Pyramids, the Parthenon and other monuments worldwide.\nThe Temple of Apollo Epikourios is one of the best surviving monuments of classical antiquity. In particular, it is the best preserved after the Temple of Hephaestus\'s in Athens. Of all the temples in the Peloponnese, after the Temple of Tegea, it could take first place for the quality of its marble and its harmonious ensemble.\nThe temple was dedicated to Apollo Epikourios by the inhabitants of Figalia because they overcame a plague epidemic. The inhabitants of Figalia had erected a temple in honour of Apollo Vassita in the 7th century B.C., and worshipped him with the name Epicure supporter in war or illness. He was given the name Epicurean during the wars against the Spartans around 650 B.C. The final Temple was built during the second half of the 5th century BC (420-410) by Iktino who was also the architect of the Parthenon and for this reason is sometimes referred to as the Parthenons Twin.\nThe construction managed to combine many iconographic characteristics that showed the conservative religious tradition of the Acadians embracing the new features of the classical era. Characterised by a multitude of both original outer and internal fittings which make it a unique monument in the history of ancient Greek architecture. Is has a Doric pavilion from local limestone. The columns combine the harmony of all the known styles of antiquity (Ionic, Corinthian, Doric) and the frieze of the temple is a real masterpiece, with plain metopes and triglyphs (part of which was broken up in 1814 and is now exhibited at the British Museum in London) is the work of the sculptor of antiquity, Alkamenes.\nThe temple has been preserved since the beginning of the century by the department of Archaeology. Since 1965, and systematically since 1982, the Ministry of culture has taken on the difficult task of maintenance and protection of the monument. The canopy, which protects the sensitive building materials from the extreme weather conditions in the region, the anti-seismic scaffolding and other facilities are intended to be temporary but will stay in place as long as required by the rescue work.\nThe imposing temple measuring 2,075m lies in the centre of the Peloponnese, in the mountains between Ilia, Messinia and Arkadia. Situated 14 km south of Andritsena and 11 km northeast of Perivolia. The archaeological area of the temple can be easily reached:\n-From the provincial road that connects Kalamata with Diavolitsi (after Diavolitsi you come to the village Kato Melpia, where signs show that the temple is a further 40km. Following a captivating journey you are directed to the village of Sklirou near the temple.)', ""Messene#by P. Diem\nText and all pictures by the author, 2008\nMessene (Greek: Μεσσήνη Messini), officially Ancient Messene, is located some 30 km north of the city of Messini near Kalamata. Intensive research in the old site was only started recently. It is now one of the major archeological excavation sites in Greece.\nMost of the area of Ancient Messene contains the ruins of the large classical city-state of Messene re-founded by Epaminondas in 369 BC, after the battle of Leuctra that ended Sparta’s military domination of large areas of Greece. Epaminondas invited all the families that had gone into exile from Messenia during its long struggle with the military state of Sparta to return to their native land. This new Messene, today's Ancient Messene, was constructed over the ruins of Ithome, an ancient city originally of Achaean Greeks (one of the four major tribes of ancient Greece) that had been destroyed earlier by the Spartans.\nIn the center of this old city there are the remains of the theater, the 40 m wide house with the wells of Arsione who – according to legend - was the daughter of the Messenian king Leukipp and mother of the god Asklepisos. Adjacent to it a part of a hall has been excavated, probably the northern part of the agora. The city walls had an original length of 9 km and a height of 9 m, fortified by 30 square or horseshoe-shaped guard towers with doors admitting passage to a protected walkway on top of the wall. They city walls were probably erected when the city was re-founded. They belong to some of best preserved city walls of ancient Greek buildings.\nThe most important building complex is the Aslepieion, usually thought to be built in 215 BC. There is also an impressive ring-shaped temple (Periptros) in Doric style with 12 columns. An altar room in front of the temple is in a 66 by 72 m rectangular yard. This yard is surrounded on all sides by two-span halls with 21 or 23 columns, and additional columns further inside. The columns bear fascinating capitals with motives ranging from erotic, to flower garlands, swags, to heads of animals.\nThe halls are extended by additional rooms. In the east, next to the main entrance (Propylon) there is an assembly room ((Ekklesiasterion) and two further large halls. In the west there are a number of smaller rooms, often wide open to the main hall (Exedren). In these rooms a number of statues are found. One room was used to worship Artemis. About 200 m downhill recent excavation unearthed a huge stadium, now the most impressive ruin of the city. One enters the stadium in its northwest corner through a Doric style Propylon. Directly outside the entrance a number of graves of obviously important persons have been found. The norther part of the stadium is bounded over a length of 110 meters on all three sides by halls: many columns have been restored in this sections. The northern part of the running track is bordered by steps of stone arrange in a horse-shoe form. The stand from where events were watched is located in the south and had no seats. Today (2008) it is covered (and protected) by a layer of grass. On the other side, near the starting area is a heroon, a shrine for heroes.""]"	['<urn:uuid:4acf7039-cf3f-4023-b609-ed3565fd24f5>', '<urn:uuid:f813c08f-59ea-4e2e-8888-c0e96e94c5ee>']	open-ended	direct	concise-and-natural	similar-to-document	comparison	expert	2025-05-13T03:20:41.944655	11	73	2253
53	What maintenance issues affect water heating systems' longevity?	For tankless systems, service requirements are lower than traditional tank heaters, though they need proper sizing and installation by qualified plumbers. Boilers typically require yearly inspections to check for issues like cracked heat exchangers that could leak toxic gases. The mix of water and fuel in boilers can cause component corrosion over time. While tankless units last 2-3 times longer than tank heaters, boilers can last 15-40 years or more with proper maintenance. Common boiler repairs cost $300-500 and may involve replacing heat exchangers, burners, chimneys or lines.	"['Tankless or on demand water heaters are a fantastic option to traditional tank water heaters. They supply limitless, constant warm water and remove inefficient reheating of hot water kept in a tank. Tankless water heaters need less area, less service and less energy than old style tank water heaters. A tankless system can be set up as a replacement an old tank water heater and are easily installed as a part of a remodel or in new building.\nWhether you are thinking about a tankless water heater to lower your energy bills, for ecological issues, to supply more hot water for your household or you simply desire the luxury of long, long, hot showers, a tankless water heater might be in your future. Long popular in Japan and Europe, need water heaters are acquiring appeal in the U.S. Old misconceptions are being dispelled and legions of “converts” recommend.\nA tankless water heater heats up water very quickly, on demand. When a warm water tap is turned on, water starts to flow and is detected by the water heater. A pipes winds back and forth through the heat exchanger and water swiftly reaches the wanted temperature. As soon as hot water starts flowing, it will certainly continue till the warm water tap is shut off. This is how unrestricted hot water is provided. With a traditional tank design water heater, 40 to 50 gallons of water is kept hot up until it is required. When warm water is used, it is drawn from the storage tank. The heater likewise begins heating water, but it can not heat up water as rapidly as it is being made use of. So, once the saved supply is consumed, the water temperature level drops substantially.\nSave Money and Save the Environment\nDue to the fact that demand water heaters do not heat water up until water flow is spotted, no energy is lost keeping water hot. Tank style heaters save warm water and regularly fire up to reheat water, day and night. This continuous reheating of water is really inefficient. A demand water heater can decrease utility expenses while reducing the emission of carbon monoxide and other pollutants.\nThere is another factor to consider, if you have limitless warm water, will you start taking longer showers? Many of us are made use of to taking a shower of 5 minutes or so, due to the fact that after that the water begins to get cold. If you aren’t forced out by cold water, will you stay for an extra minute or two? An additional 2 minutes, contributed to a 5 minute shower, lead to 40 % more water usage and the energy required to heat the water. In shorts, you could wipe out any utility savings simply by remaining in the shower. On the other hand, heating water day and night creates a great deal of waste, so a little extra time in the shower might not wipe out all the savings. Specific numbers rely on the hot water use patterns in your home and the efficiency (or inadequacy) of your tank style water heater.\nRealities and Misconceptions about Tankless Water Heaters\nOld myths about tankless water heaters persist and inhibit some individuals from ever considering one for their home. Let’s clear up some false impressions. First, demand water heaters are sometimes called rapid water heaters. The name results in a typical misunderstanding, that warm water comes out of the tap quickly. Not real. Just as with a tank water heater, warm water should travel through your home’s plumbing system before it reaches the tap. If it takes 60 seconds for hot water to reach your tap with a tank heater, it might take 70 seconds for a tankless heater. The extra few seconds is the time it takes a tankless device to sense warm water need, ignite the burner and bring the very first little bit of cold water approximately the needed temperature. There are means to obtain immediate hot, including the use a recirculation pumps, finding the water heater near where the water will be used or with likewise named item which is usually made use of only with a sink.\nAnother myth is that tankless water heaters can not actually supply all the hot water that they claim. This myth comes from the fact that tankless water heaters require a lot more thought when selecting. With tank style heaters, you simply choose the tank size that a lot of carefully matches anticipated need. In fact, they are frequently rated and picked based upon the number of individuals living in a household. Tankless water heaters need that other factors be considered, including the starting cold water temperature and the gallons per minute (GPM) of simultaneous demand. When the proper sized system is picked and correctly installed, it can deliver all the continuous hot water you need.\nTankless water heaters are too expensive. While they are more expensive than tank design heaters, they likewise last 2 to 3 times longer than tank heaters. When you take their life span into consideration, they are really competitive with tank heaters. Contribute to that lowered energy costs, the elimination of service expenditure to set up 1 or 2 replacement tank heaters over 20 years and the all the perks of constant warm water and they are definitely not more expensive over the long term.\nLastly, tankless water heaters have a credibility that they can provide only lukewarm water to the tap at a sink. This reputation is not entirely precise but it can be a weak point with tankless water heaters. Initially, let us consider how the unit works. As we described earlier, they pick up water flow and then ignite to warm the water. Nevertheless, they require a minimum flow rate prior to they will begin heating. This is good due to the fact that it means they don’t operate when a tap is dripping or someone leaves the tap on a little bit. However if you turn on the tap for just a gentle flow, it might not suffice to initiate heating. Add to this the additional couple of seconds it considers the system to fire up and produce hot water, quick use of hot water at the sink could be lead to little or no hot water. The problem can be solved by utilizing hot water at full flow and/or by enhancing the warm water supply with a small, regional heater at the sink. Hot water distributing systems also can get rid of the problem.\nPicking the Right Tankless Water Heater\nIf you have actually chosen to set up tankless water heating in your home, you have some options. The best thing you can do is involve a plumbing technician who has experience with tankless water heaters. Some makers may be able to suggest authorized installers in your area. A plumbing professional who has nothing excellent to state about tankless water heaters is either inexperienced with tankless water heaters or unqualified, in either case avoid such plumbers.\nWhen identifying the devices you will utilize, a certified plumbing professional can help you choose whether to make use of just one water heater for your whole home, to plumb two devices together in parallel, to set up smaller systems closer to the point-of-use and even to create a hybrid system utilizing little tank water heaters to speed hot water shipping and tankless water heater to sustain shipping. They can likewise advise you on whether a warm water recirculation system would be a great solution for your home. Another factor to consider is whether to utilize gas or electrical heaters. Solar pre-heating systems can even be incorporated to further improve system efficiency.\nTake a look at our article on water heater temperature settings too.\nIn the Gainesville FL area, visit our friends here: gainesville.hotwaterheatermedic.com.', ""Boilers are an energy efficient and environmentally friendly mode of heating. They work by cycling cold water through a series of heated pipes before distributing it throughout your home as either hot water or steam.\nDetermining the cost of installing a boiler is complex and can be tough for homeowners to figure out. There are also plenty of factors you’ll need to consider before installation. Before you start, read up on the repair and replacement costs and additional related information.\nIf you have a boiler installed or replaced, you might pay anywhere between $3,122 and $7,192. On average, homeowners tend to pay $5,108. These prices are highly dependent on the type of boiler you choose. There are several styles on the market. High-efficiency models help you save on energy bills in the long run, but they have a higher initial investment. Sealed combustion boilers draw air from the outdoors for combustion instead of indoor air. This eliminates back-drafting, which can release potentially toxic amounts of carbon monoxide into your home. There are gas models and oil models to consider as well.\nThe combination boiler, or Combi, is very popular in small residences like apartments or studios. A Combi doesn’t include a storage tank, as it receives water from the water mains. A small tank can be added, however, and many homeowners who have the space pursue this customization. This is called a Combi-storage boiler.\nCombi boilers provide hot water and heat on demand with no wait time. They work best with low-occupancy residences, such as a home with a couple and one small child. Using multiple taps at once can cause a drop in water pressure. The average price for a combination boiler is $1,300.\nSystem boilers are also called sealed-system boilers. They maintain water pressure to ensure fast delivery and to allow simultaneous use of multiple taps. They store water in a cylinder, where they heat the water before sending it out to taps or to be converted into steam for heaters.\nSealed-system boilers work well in most average-sized homes. Since they keep the water pressurized, there is very little drop in water pressure when multiple taps are opened at once. They deliver heat quickly but not instantly, so there is a brief waiting period. If the cylinder runs out of hot water, the wait time increases slightly as fresh water heats up again. The average cost for a system boiler is $1,500.\nStandard boilers are also known as conventional boilers. They heat water rapidly in the pipes that run through the tank and send hot water out to taps as necessary. Larger homes and buildings most often use standard models. These units are also popular for floor heating systems and other larger scale tasks. The average cost for a standard boiler is $3,500.\nA boiler and a water heater, while similar in function, are not identical. Essentially, a water heater is a storage tank with heated tubes that keep the water at a certain temperature. When hot water is needed, the unit siphons hot water from the top of the heater. It then replenishes its supply by heating cold water and moving the freshly heated water to the top.\nA boiler can deliver hot water, but it can also boil water to deliver steam. This is a particularly effective way to move heat for two reasons:\nSteam is denser than air and can hold more heat than air alone.\nSteam is lighter than water and takes less energy to move.\nBoilers are more energy-efficient, but they also save money in another way. By using a boiler instead of a water heater, you can dispense with a traditional furnace, since you’ll have one device that can do the job of two.\nFuel Type: Boilers are also differentiated by their fuel type. Most run on natural gas or liquid propane. Oil-fired models are also common. Boilers can also be fueled by wood, electricity or geothermal energy. Of all of the options, wood pellet burning is gaining popularity as the exhaust is cleaner and fewer particulates are vented. The cost of these alternative fuel systems varies widely, but it averages around $2,300.\nMost boiler issues come down to weighing the costs and benefits of repair versus replacement. epairs typically cost between $300 and $500, which can involve replacing key elements like heat exchangers, burners, chimneys or lines. Over time, the mix of water and fuel can have an effect on the boiler’s components, possibly inducing corrosion.\nThe cost for replacing a standard gas boiler is about $4,000. A high-efficiency model costs about $7,500. This cost estimate usually includes removal and disposal of the old unit, as well as all necessary lines, ducts and wiring needed for the new system to run properly.\nReplacing an oil-fired boiler is typically a bit more expensive. The oil tank itself occasionally needs replacing, and other factors can add significantly to the project cost. Potential costs include:\nThe cost for replacing the boiler itself averages $7,000.\nThe tank must be tested for leaks or other problems. This costs about $500. If the tank needs to be replaced as well, that can add another $1,000 to $2,000 to the cost if it’s above ground. The cost is closer to $3,000 or more if the tank is below ground.\nBefore a tank can be replaced, however, the soil must be tested to see if the tank had leaked. This can cost another $300 to $500.\nIf a cleanup is necessary, the average cost ranges from $2,500 to $10,000 for minor environmental cleanup. The average cost for this is $3,500 to $4,600.\nMajor ground contamination can cost from $15,000 to $100,000 or more depending on the extent of the damage.\nNew tanks are made of corrosion resistant materials and usually have an expected lifespan of about 30 years. Removing and replacing an oil tank requires permits, which your local fire department usually issues Be sure to document this process thoroughly with notes and photographs. Since the tank is installed underground, there’s no other way to verify information about the unit or its installation without digging it back up again.\nChanging Boiler Types\nGas boilers are the most efficient style on the market. With this information in mind, you might decide to change your oil-fired model over to a gas-fueled unit. Replacing the old and swapping in the new is no easy task, though. There are several costs to consider before you go this route.\nGas-fired equipment costs less than oil-fired equipment. In some cases, the difference is as much as $5,000.\nOil has to be delivered to your house by truck. Gas is piped in directly from the city.\nIf you don’t already have a gas hookup, your local utility company will have to install one. This involves digging a trench and running the line to your house and installing a meter. The average cost for this is $1,000 to $1,500, though your utility company may offer a discount to win you over as a customer.\nA contractor will have to hook up the gas lines between the meter and your house. This normally costs around $500 to $1,000.\nYour chimney will most likely need a new liner to accommodate the gas boiler exhaust. This can cost between $750 and $2,000.\nThe cost of removing an old oil tank depends on where it’s located. If it’s in your basement, removal can cost from $500 to $1,500. If the tank is buried in your yard, the excavation and removal can cost from $1,500 to $3,000. You can decommission a tank by contracting a service to drain the oil and fill it with an inert substance, but the cost of this varies quite a bit and depends on numerous environmental factors.\nWhile it seems like a lot of money to switch from oil to gas, it should be noted that oil heating could cost as much as double the price of gas heating. Oil is a particularly volatile commodity, and the price can skyrocket or plunge based on global events and instability. For environmentally conscious homeowners, gas boilers have a lower carbon footprint than oil-fired units.\nIf you're replacing an old heating system with a new boiler, then the cost to install might increase. One reason is that you might have to install a chimney liner. The liners for gas models are cheaper than those for oil models, so make sure to figure that into the cost of your replacement budget. You'll also need to consider the cost of removing your old system when you calculate your budget.\nReplace or Repair?\nBoilers, like everything else, don’t last forever. With good maintenance and care, they can last a very long time. There are gas units still humming after 40 years and a coal-fired steam boiler still functioning after 134 years.\nThe typical boiler has a life expectancy of 15 years. Has yours been thriving for 20 years? As long as it’s still functioning at comfortable temperatures, you may want to ask yourself whether or not it even needs replacing or other drastic action.\nHow often has it needed repairs?\nIf this is your first repair, your boiler may not need replacing just yet. Compare the cost of the repair to the cost of replacing. A repair averages between $300 and $500 for most common issues. A replacement can cost between $3,000 and $5,000 for the new equipment installation, inspections and removing the old system. During installation, you’ll be without heat for a couple of days or even a week if complications arise.\nHas it been working fine otherwise?\nIf your boiler has been providing comfort at appropriate levels and you’ve been maintaining your home’s insulation and seals at doors and windows, then there’s probably no need to replace it. If you have made additions to your house that have increased the floor space, your old boiler may not do the job anymore. There’s most likely nothing wrong with the unit, it just might not be powerful enough to meet the new load that your home requires.\nHave you been inspecting it?\nA yearly inspection is recommended by most professionals in the industry, and that’s not just so they can have repeat business. A crack in the boiler’s heat exchanger can allow poisonous gases to leak into your home. If you haven’t had it inspected, you should do so immediately. If multiple issues are found during an inspection, you should think about replacing your system if it’s out of warranty.\nReplacing your boiler can be an expensive prospect, depending on your location and the extent of the job. Before you begin, be sure you understand all of the factors involved, as well as the options available for new boilers. New technology and materials help ensure that your new system will provide comfort, efficiency and plenty of cost savings for years to come.\nEach boiler unit comes with an AFUE (annual fuel utilization efficiency) rating. The higher the rating, the more efficient a boiler will be. The models that are the most energy efficient tend to have the highest upfront cost attached. Models with a rating of 90 or higher will reduce home heating costs by 30 percent or more overnight when replacing an older unit.\nThermal efficiency is a rating based on the unit’s operation under ideal conditions. It is often higher than the AFUE rating because all variables are minimized. This gives the manufacturer and testing agency an idea of how much energy is expended and produced from input to output.\nAFUE is the rating that consumers need to know. It reveals how much energy is actually being converted into useable heat during real-world conditions. While thermal efficiency focuses on ideal conditions, AFUE tells you how well it can be expected to perform against temperature swings, extremes, sudden cold snaps, energy surges and other variables. A boiler may have a thermal efficiency rating of 78 percent, but may have an AFUE rating of 64 percent when faced with real-world test conditions.\nHigh efficiency units have an AFUE of 90 percent or higher. These are increasingly becoming available only as condensing boilers. They trap much of that heat waste and use it to preheat the water, which ensures that the system runs on less energy. A condensing model often loses only about 2 to 3 percent of its heat when all is said and done. However, the trapped heat doesn’t count towards the AFUE.\nFactors That Affect AFUE\nSometimes your boiler doesn’t provide enough heat. Though it may be properly sized for your home, but the temperature remains chilly. Before blaming your boiler, check the following:\nInsulation: poor or damaged insulation can cause your home to lose heat through its walls and ceilings.\nWindows and doors: windows and doors that don’t close properly or that have lost their seals can cause heated air to leak out. Warm air will always rush towards cooler air, so if you encounter this situation, you’ll lose a significant amount of heat through these leaks.\nDuctwork: as ductwork goes through warm and cool temperatures, it expands and contracts. This can cause weakness and erosion at the joints. Improperly hung ductwork can restrict airflow, and ductwork without insulation can cause a great deal of heat loss. This can amount to anywhere from 10 to 50 percent or higher in wasted energy.\nIt's important to install the right size boiler for your home. If your unit is too big or small, then you won't reap the energy savings benefits, regardless of the AFUE rating. To determine what size boiler you need, you should be aware of two calculations. One is a simple guideline that will give you a ballpark idea of what size you need. The second is an extended calculation that will tell you almost precisely what size you need. Most homeowners use the simple calculation because the other one can take two hours or more.\nTo figure out the simple calculation, first confirm the square footage of your home. If you don’t know it, multiply the length and width of each room and then add those results together. Then multiply that result by the following based on your average climate:\nWarm:30 to 35\nCold: 50 to 60\nIf you live in a house that’s 20 years or older, use the higher number. If you live in a newer house, use the lower number. The result tells you roughly what size boiler to get. This is an imperfect way to calculate your AFUE, but it will keep you from buying a 125,000 BTU boiler when all you need is a 75,000 BTU one.\nManual J Calculation\nThis is the calculation that a professional wills. A contractor may include it in his or her estimate, but you can also have it done independently for around $100. This calculation takes into account the following:\nDesired interior temperature\nDirection the house faces\nConstruction materials used to build the house\nLandscaping that affects how much sun or wind hits the house\nThere is nothing to stop you from doing a Manual J calculation yourself, and there are many places that will provide online calculators for free. Most homeowners are content to leave it to a professional who may spot minor problems that will affect the calculation, such as an inability to put ductwork in an ideal spot to most efficiently heat a room.\nMany locations require permits to replace your heating system. Talk to your local pro to learn more about local regulations, and make sure to check with your local municipality as well. Permits are not prohibitively expensive. Depending on where you live they cost between $50 and $300.\nSome local governments also require a fire inspection before heating system replacements. The fees for these are dependent on the size of the boiler and tend to run between $40 and $75.""]"	['<urn:uuid:ff89fce3-a931-4f11-b700-3eaec93fe102>', '<urn:uuid:878a73e7-5d75-4cfd-8a5a-d16fcd1bfe66>']	factoid	direct	concise-and-natural	distant-from-document	three-doc	expert	2025-05-13T03:20:41.944655	8	88	3946
54	Why did some people think the Apostles were drunk at Pentecost?	The Apostles appeared to be intoxicated because they were filled with the 'wine of the Spirit'. According to St. Cyril of Jerusalem, observers were correct in noticing their drunken-like state, but mistakenly thought it was from alcohol. In reality, it was a 'sober intoxication' caused by the Holy Spirit that gave them courage, helped them remember Christ's teachings, and enabled them to speak in languages that people from all over the world could understand.	['The journey through life of the G-Man. His trials, tribulations, and how he rediscovers the Catholic Church.\nSunday, May 31, 2020\nReflection for Today\nINTRODUCTION The term ‘Pentecost’ is derivative of the Greek terminology Πεντηκοστή (Pentecoste) which simply means ‘fiftieth’. In its religious usage, it is originally the Jewish festival of Shavuot; seven weeks after the Passover celebration of which the name ‘festival of the weeks’ come from: “You shall count seven weeks…and you will celebrate the feast of the weeks (Deuteronomy 16: 9-10). It is an agricultural festival, the festival of the ‘first fruits’ and the offering of the first bunch of wheat. It however reminds us of the historical event of the gift of the law at Mount Sinai. Thus Shavuot is the conclusion, the end of the Passover festivities. It is in fact to give Israel the ‘Law’ that God made him come out of Egypt since a true law must be lived in freedom and true freedom consist in accepting to follow the Law of God (Fr. A. Kadavil). Pentecost for Christians is the completion of the Easter season after fifty days of contemplation of the mystery of the resurrection. But it equally reveals the face of the Third Person of the Blessed Trinity (the Holy Spirit) and manifests his operative power as He initiates the third moment of the tripartite moments of the revelation of God. It indeed happened as a strange event. It is the event of wind and fire. The sound of the wind stirred up the whole of Jerusalem and set its inhabitants in confusion and in uproar. Those who felt they were strangers to God eventually discovered they were no more strangers because the Spirit spoke their languages. They felt the heat as the fire of the Spirit was burning in the Apostles. That is Pentecost, and that is what we celebrate today.The Apostles who were in quarantine of fear have been set free. The Spirit blows again today. The situation of our world gripped by fear and living in the hiding will surely return normalcy. The Psalmist sings it as a praise. God sends his Spirit to renew the face of the earth.\nFIRST READING: Acts 2:1-11 THE WAVE OF THE SPIRIT AND THE TONGUE OF FIRE The use of natural elements such as water, fire, air and earth was very common in the cosmogony (the origin of things) of the ancient world and the conclusions were often mythological. For example, most of the Persian, Babylonian, Greek and Asian thoughts conceived those natural elements as deities or the manifestation of the deities. Meanwhile, the interaction of these cultures and philosophies with the ancient Hebrews left a traceable mark in the biblical tradition. Many passages of the Old Testament describe the revelation of God as being accompanied by fire, cloud and even breeze (Ex. 3:2-3; 13: 21; 14:24; 19:18; 40:38; Nb. 9:15-16; 14:14; Dt. 1:33; 4:12.15.30; 5:4.22; 9:10; 10:4; Neh. 9:9.22; 1 Kgs. 19:12; Ps. 10:39; 76:14; Is. 4:5). The New Testament recorded few pages of such revelation; the transfiguration of Christ at Mount Tabor (Mt.17:1-13) and in the Apocalypse of St. John (Rev.1:4-8; 10:1 etc). THE EXTRAORDINARY WING OF THE SPIRIT Luke describes the coming of the Spirit as that of a rush of a mighty wind. What is so extraordinary about the wind since people in that environment were used to the rushing wind? It was the of the Spirit sending message to every corner of Jerusalem and to the people of the world in their own languages, summoning them to the great event of the manifestation of the Spirit in the upper room. The people responded to the invitation. And Luke counted the number of the invitees as coming from sixteen different geographical regions representing the people on the face of the earth. The wave of the Spirit invited them to witness the miracle of tongues that set the people free from the old age confusion of tongues caused by the same God at the event of the Tower of Babel (Gen. 11). Those who were once scattered in Babel now gathered in Jerusalem. The Babel of division came to meet the Pentecost of unity whereby they no longer admire their tower of pride but instead the wonders of God. The old man of Babel, the man of pride is now intoxicated by the Spirit of God. This outpouring of the Holy Spirit became a creation of a new world, the perfect completion of God’s creative, redemptive and sanctifying work. The Spirit hovered over the disciples whose faith at this point was still ‘shapeless’ like the shapeless world of Genesis 1:2. Yes, they received a new life in the Spirit, just like the first moment when God breathed life in man (Gen. 2:7), and their ‘bones’ which were dead in fear was fleshed up by the Spirit as in the days of Ezekiel (37:9-10). THE UNCONTROLLABLE POWER OF THE SPIRIT The wine of the Pentecost made the disciples to be dazed in the Spirit. It was a new wine pressed from the ‘True Vine’ who is Christ (Jn 15:5).Those who did not taste it felt it was an alcohol. St. Cyril of Jerusalem puts it beautifully that those who thought that the Apostles were drunk at Pentecost (Acts 2:13) were correct in their observation, but they mistook their drunkenness as coming from alcoholic. This wine of the Spirit was so strong that they were uncontrollably intoxicated. It was a sober intoxication that destroyed sin and brought about new life in the Spirit. It loosened them from memory loss and made them recall all that the Lord taught them. The tongues of fire loosened their tongues of speech. The heat of the fire boiled their heart to an unimaginable degree of courage. The door that locked them away for fear of those who killed their master became an access door leading them to the people. The Spirit concluded their period of retreat and empowered them for mission. They came out well recharged. And instead of speaking incoherently in fear, they rather spoke in languages that people from every part of the world were able to understand, the language of love and faith in God made manifest in the person of Christ.\nSECOND READING: I Cor 12:3-7, 12-13 The second reading is the message of Paul to the Christians of Corinth reminding them that faith in Christ is made possible through the power of the the Holy Spirit Who enriches the Church with varieties of gifts.These gifts are activated in every believer by the same Spirit uniquely for the service of the community and not for the glorification of the individuals. Secondly, Paul insists that these gifts of the Spirit, ‘Charisma’ are equal and serve the same purpose which is the edification of the Church. Evidently, this letter is meant to criticize the pride of action going on in the community of Corinth. The existing tendency was such that claims one gift as superior to the other. Those who had the gift of prophesy or gift of healing felt themselves more relevant in the community than those who probably had the gift of teaching. And using the analogy of the body, the Apostle underlines that every gift is indispensable (the body will certainly lose its complete nature if it is deprived of the hand, and the leg can never be called hand nor replace it). Finally, St. Paul clarifies that the Spirit is never partial in the dispensation of his gifts. He blows wherever He wants and to whoever He wants. Thus, whether Jew or Gentile, they all drink from the same fountain of the Spirit. GOSPEL: John 20:19-23 The Gospel gives us an account of what the French people call an “avant-goût”. It is a foretaste of the great event of Pentecost. The risen Lord anticipated the coming of the Holy Spirit, the completion of the three great moments of divine revelation. Standing before his Apostles who were gradually shrinking away in fear, He breathed upon them saying, “Receive the Holy Spirit.” This was meant to sustain them to see the day of Pentecost, and to remind them that the Holy Spirit that will eventually come will be the gift of the Father to them and in his name. John conjugates the power of the Spirit as indispensably linked to the mission of the disciples when he says:“Receive the Holy Spirit. If you forgive the sins of any, they are forgiven; if you retain the sins of any, they are retained.” It suggests that the sacramental confession is a search for the Holy Spirit, because sin has the power to put the soul to death and it is only the breath of the Spirit that can restore this life through reconciliation with God. It is equally a reminder to the Apostles that though the redemptive work has been completed on the wood of the cross which was meant to cancel the gap between man and God, but then individual weaknesses will always crucify people on the wood of sin. However, the coming of the Holy Spirit is to keep sanctifying creation already redeemed.\nLIFE MESSAGE 1. THE WIND OF THE SPIRIT STILL BLOWS The Pentecost makes us to understand that the workings of the Spirit can come like the rush of a mighty wind (Acts 2:2) that immediately produced an effect on the disciples. We have often longed for the immediacy of the action of the Spirit in our rough situations, and instead of the cool breeze of his presence, we get hot air that keeps suffocating us. We can identify the hot air when we are weighed down by sickness and old age thinking of how to survive them. It blows real hot when we lack Job opportunities and means of survival. What of shattered relationships and divided families? What of when we watch people deny us our rights and treat us as less human and kill us? Yes it’s damn hot. It is hotter when the fear of death creeps in. The message of Pentecost is a message of hope. The Apostles were not breathing a good air. They were suffocating in fear. They faced dangers and threats, but they were hopeful. They kept the faith and their constancy in prayer activated the power from above that released the rush of a mighty wind. Let us not lose hope when it blows hot because heaven has a reservoir of refreshing wind that will restore our suffocating situation. Whichever way it has been, we can be assured that there is a life changing Spirit that blows today.\n2. DO NOT ALLOW THE FIRE TO DISAPPEAR The fire of the Spirit was a new baptism received by the disciples on this day. It was a fire that purified and empowered them for the mission because they cooperated with it. We have all received the Spirit through the sacraments of baptism and its fullness in the sacrament of confirmation and it is made available to us in all the sacraments. How active is the Spirit in our lives? We must be sure of the fact that the Spirit like fire can purify and also destroy. It purifies us when we are dispose to cooperate with Him. He builts us. He empowers us and makes us ablaze with the power of God. But it becomes destructive when we abuse the grace and opportunities that God gives to us through constant submission to sin and inability to accept our faults and to change. Let us make effort to keep the fire of the Spirit burning because that’s the only way we can be identified as the followers of Christ in the midst the world of differences. Yes people gathered because they noticed something from the disciples, they noticed miraculous tongues of fire.\nPRAYING WITH THE SEQUENCE\nCome, O Holy Spirit, come! From Your bright and blissful Home Rays of healing light impart. Come, Father of the poor, Source of gifts that will endure Light of ev’ry human heart. You of all consolers best, Of the soul most kindly Guest, Quick’ning courage do bestow. In hard labor You are rest, In the heat You refresh best, And solace give in our woe. O most blessed Light divine, Let Your radiance in us shine, And our inmost being fill. Nothing good by man is thought, Nothing right by him is wrought, When he spurns Your gracious Will. Cleanse our souls from sinful stain, Lave our dryness with Your rain, Heal our wounds and mend our way. Bend the stubborn heart and will, Melt the frozen, warm the chill, Guide the steps that go astray. On the faithful who in You, Trust with childlike piety, Deign Your sevenfold gift to send. Give them virtue’s rich increase, Saving grace to die in peace, Give them joys that never end. Amen. Alleluia.']	['<urn:uuid:cf23452b-8428-4f33-b2c4-793c467e63a9>']	open-ended	with-premise	concise-and-natural	similar-to-document	single-doc	novice	2025-05-13T03:20:41.944655	11	74	2145
55	looking for ways to tell if child has adjustment disorder or anxiety want to know how parenting style affects mental health	To identify these disorders, look for distinct symptoms. Adjustment disorder shows through sadness, negative thoughts, and lack of appetite, while anxiety disorder manifests as excessive sweating, heavy breathing, rapid heartbeats, and panic attacks. Parenting style significantly impacts children's mental health - authoritative parenting, which balances high standards with emotional support, leads to the best outcomes. Children of authoritative parents show less anxiety, depression, and suicidal thoughts. They develop better emotional regulation and social skills because their parents are responsive to their needs while maintaining consistent boundaries. These children are also more likely to be happy, independent, and successful academically.	"[""Authoritative parents usually set high standards for their children, but is this style of parenting really healthy for their children?\nA Brief History\nDiane Baumrind, a clinical and developmental psychologist, first defined authoritative parenting style in a system that classifies how parents raise their children. According to Baumrind, parenting has three major approaches, which are:\n- Permissive Parenting, where parents do not establish certain standards or rules for their children.\n- Authoritarian Parenting, where parents demand unquestionable or complete obedience from their children.\n- Authoritative Parenting, where parents take a moderate approach. Authoritative parents impose a set of rules, explain the reason behind these rules, as well as seek the opinion of their children.\nAuthoritative parents set high standards, but also acknowledge their children's emotional needs. They are usually very consistent with their boundaries as well. Authoritative parents are characterized as nurturing, warm, and responsive, and expect high levels of maturity and independence from their children.\nThese parents would:\n- Encourage independence and allow autonomy\n- Give reasons or justifications for a particular action\n- Set effective limits for children's behavior\n- Implement positive discipline instead of punitive punishment\n- Earn children's respect, not demand it.\nTraditionally, authoritative parenting has been found to be the most effective. According to studies, children that are raised by authoritative parents are happier, more self-confident, and more independent.\nParents who practice authoritative parenting discipline their children in a fair and consistent manner, especially when their children break the rules. However, they also listen to their children and give time to explain the cause and effect of their children's actions. This parenting style is quite flexible, mainly because the parents would also consider their child's behavior and situation before implementing any discipline.\nIs authoritative parenting healthy?\nOf all the parenting styles, experts have concluded that authoritative parenting is the best one as it has the best outcome in children. Researchers have observed that preschool children raised by this style are:\n- Happy and satisfied\n- Independent and self-reliant\n- Cooperative and warm with peers\n- Not afraid of exploring a new environment\n- Assertive and competent\nIn older children, researchers observed that they:\n- Have higher academic success\n- Participate in school activities\n- Have less anxiety, depression, and suicidal thoughts\n- Are less prone to alcohol or drug abuse and delinquency\n- Have effective social skills and interaction with peers\n- Are less violent\nSo, why is this really the best style of parenting? There are a few reasons:\n- Authoritative parents are nurturing: In authoritative parenting, a child’s emotional and developmental needs are nurtured and attuned because the parents are very supportive. Research has shown that there is a development of a secure attachment between the parent and child if there is also a high level of responsiveness.\n- They are responsive to their children's needs: A child is able to succeed in life if his or her emotions are regulated. They can develop great self-regulated skills, if they have attentive and supportive parents.\n- These parents are very supportive of their children: It's a pattern, isn't it? Authoritative parents are more supportive of their children than other parents. They are more likely to be a part of their child's school, and monitor their homework. Parent involvement actually has a positive impact on academic achievement.\n- Authoritative parents are open-minded: In authoritative parenting, parents are collaborative and open-minded. To foster individuality, they use explanation, proper communication, and reasoning to help their children develop effective social skills later in life.\n- They also have high standards: They would check their child's behavior from time-to-time, according to the high standards set by them.\n- They implement discipline: According to studies, these parents would enforce limits that are more consistent than any other style. For good behavior, consistency is one of the most important factors. Children are less likely to internalize and externalize their problems if their parents are consistent with their discipline.\n- Authoritative parents are non-punitive: Authoritative parenting does not use punitive punishment to teach their children a lesson. This, in turn, promotes honesty in children. When it comes to discipline, authoritative parents are firm, but also kind.\nThere needs to be a balance between behavioral and psychological control, and this balance is met by authoritative parenting. It achieves the best outcome because it lies between two extreme parenting styles.\nDoes authoritative parenting suit every child?\nIt has been found that children of different temperaments benefit from authoritative parenting, especially for children who are prone to temper tantrums. However, every child is different. According to the Goodness of Fit, every child needs to have a specific parenting style.\nA child will flourish if there is a goodness of fit between the personalities and attitudes of parents, the practices of parents, and the temperament of the child. However, the child suffers if the fit is poor. Also, parenting style and parenting practices are not the same. Parenting style refers to the emotional climate a child is being raised with, while parenting practices are the parents' actions with their children.\nDoes authoritative parenting work?\nIn authoritative parenting, parents act as role models for their child and behave in a way they would expect their child to behave. Children exhibit the behavior that they internalize from their parents, and they also learn what is expected of them due to consistent rules and disciplinary measures.\nParents also understand the emotions of their child and exhibit good control. Their children are more understanding and sensitive toward other people's needs and gradually learn how to properly manage their emotions. Authoritative parenting also gives children the liberty to act independently. They are instilled with the feeling that they can accomplish their own tasks and be independent.\nHow to Show Children Authoritative Parenting\nWhen there is a balance between choice and responsibility, children feel empowered. Authoritative parents have high expectations with their children. However, they're normally flexible and are willing to reason with them.\nChildren will have the freedom to voice out their opinion and explain themselves, and parents are sensitive to the needs of their child and their emotions. Children tend to have a high self-esteem, become self-reliant, are academically successful and disciplined, and are open to discussion. On the other hand, children may become resentful, delinquent, act out their feelings, and develop bad habits if they are not provided the opportunities that an authoritative parent gives. Parents should do the following to implement authoritative parenting:\n- Show your child that you care\n- Praise your child for positive behavior and accomplishments\n- Set clear and fair expectations\n- Listen to your child\n- Practice consistency\n- Discipline your child by using choices and consequences\n- Consider the opinions of your child\n- Demonstrate your affection and show that you love your child\n- Let your child make choices\nSome parents by nature are more authoritative and less authoritarian or permissive. No matter what parenting style you practice, you can start adopting an authoritative parenting style at any time. To be an authoritative parent, you must be disciplined, consistent, and mindful of your own actions.\n- Authoritative parents set high standards for their children, but they also acknowledge their children's emotional needs.\n- Authoritative parenting incorporates clear limits, fair discipline, warmth, and support.\n- It has been found that children of different temperaments benefit from authoritative parenting."", 'Mental health is as important as physical because it can make a person physically weak. The modern lifestyle is getting more and more hectic where people do not have time to spend on things that they like. This careless behavior of people leads to several mental disorders such as adjustment disorder and anxiety disorder.\nAdjustment Disorder vs Anxiety Disorder\nThe main difference between Adjustment Disorder and Anxiety Disorder is that as an adjustment disorder the victim can not establish interaction with people. While anxiety disorder a person fears to make interaction and always feel paranoid. The symptoms of both adjustment and Anxiety disorder are very different from each other.\nAdjustment disorders are associated with conditions related to stress. A person who has this disorder finds it difficult to interact with people. Adjustment disorders can play a major role in creating problems in school, work, or more importantly in the relationship of that person. The level of stress gets higher in adjustment disorder.\nAnxiety Disorder is one of the most terrible disorders one can have. Anxiety can be triggered by tiny events but can result in serious physical and mental damage. Anxiety is a quite normal feeling that can be caused by events like speaking or dancing in front of people or before the most awaited results.\nComparison Table Between Adjustment Disorder and Anxiety Disorder\n|Parameters Of Comparison||Adjustment Disorder||Anxiety Disorder|\n|Meaning||Adjustment disorder can be described as the behavior of a person when he overreacts and overstresses.||Anxiety Disorder is described as the behavior of a person when he gets nervous and worried over little things.|\n|Duration||Adjustment disorder is considered to be the temporary state of stressful thoughts or depression that attacks suddenly.||Anxiety Disorder is an illness but is more like a habit that can be triggered by petite situations.|\n|Cause||Adjustment disorder can occur due to stressful lifestyles and traumatizing events that happened in one’s life.||A person can get anxiety disorder from his family roots, mental illness, depression, a particular situation that simulates it.|\n|Panic attack||If a person is suffering from adjustment disorder he might stress but he never gets panic attacks.||It is very common to get a panic attack if a person has an anxiety disorder.|\n|Symptoms||Adjustment disorder can be diagnosed by noticing symptoms like sadness, negative thoughts, lack of appetite and sleep, etc.||A person with anxiety disorder shows symptoms like excessive sweating, heavy Breathing, rapid heartbeats, nausea, tiredness, etc.|\nWhat is Adjustment Disorder?\nA person who suffers from adjustment disorder is liable to experience more stress than a normal person. It leaves a negative effect on the life of that person by bringing sudden changes in emotional behavior. The response to a stressful event or situation becomes excessive that can even influence the physical health of the person.\nHowever, adjustment disorder does not consider a mental illness instead it is described as a massive response to the situation which stressful. A person can get very sensitive and emotional when suffering from this disorder. The symptoms of adjustment disorder are also not easy to explore since they can be different from person to person.\nThis disorder typically changes the way of thinking when a tiny amount of stress seems to be a big mess. But to identify if the person is suffering from adjustment disorder, one can look for symptoms like if the person cries frequently if he’s having trouble sleeping and loss of appetite if he is facing problems doing normal activities or he is showing some kind of suicidal thoughts.\nPeople with this disorder become unable to enjoy things in their lives and get sad and stressed quite hurriedly. If a person notices such behavioral change in someone else or maybe himself, he should reach to friends and family, therapists, psychologists as soon as possible.\nWhat is Anxiety Disorder?\nA stressful period is known as anxiety and it is generally triggered by a lack of confidence or sometimes insecurities. It causes a person to have fears about certain things and most of the time, it is associated with overthinking and a common response of the brain towards stressful events. It is a function of the brain that is useful to alert the person from upcoming danger.\nWhen this feeling of anxiety becomes massive and out of control it is known as Anxiety Disorder. Common symptoms like increased heartbeat, fatigue, rapid breathing, sweating, shaking can be observed in the person with anxiety Disorder. Anxiety can be divided into parts such as panic disorder, phobias, social anxiety disorder, separation anxiety, etc.\nThis disorder can make a person worried and afraid of certain things. And when it gets more serious a person might face issues like shortage of breathing, lack of sleep, remaining still, difficulty in concentration, etc. A person with anxiety disorder can not be calmed down easily and he can even be nauseous.\nHis hands and body get shaky and his mouth gets all dry. The major causes of Anxiety Disorder according to experts can be genetics, abuse of a certain drug, environment, and some kind of medicine.\nMain Differences Between Adjustment Disorder and Anxiety Disorder\n- When a person suffers from adjustment disorder, by controlling his actions, he might hide them. While anxiety disorder is hard to disguise since it shows more physical symptoms.\n- Adjustment disorder does not necessarily result in panic attacks. On the other hand, anxiety disorder is most likely to lead to a panic attack.\n- A person with adjustment disorder might look physically fit while in anxiety disorder, the person can also get physically sick and weak.\n- Adjustment disorder occurs by a sudden change in normal lifestyle, for example, death or birth. While anxiety disorders are caused by depression and can be genetics.\n- Adjustment disorder can be shown in action from time to time since it is more irregular and associated with certain conditions while anxiety disorder can last longer and be more frequent.\nThe mental health of a person is consists of psychological and emotional behavior. It is something that influences the way a person talks, thinks, feels, and responds. Mental health is a vital factor to determine what decisions or choices should be made that are beneficial and healthy.\nBut just like disease and can affect physical health, similarly many mental disorders can damage the mental health of a person. Mental illness should never be avoided because it can result in many unexpected and painful events.\nIn modern times, many procedures are available to help a person retain and improve his mental health and live a normal life.']"	['<urn:uuid:1c65af06-e7d2-47d7-96db-573eb107e7d9>', '<urn:uuid:d1dba5ad-8f38-4971-9e4f-ea2cf2909dee>']	open-ended	with-premise	long-search-query	similar-to-document	three-doc	novice	2025-05-13T03:20:41.944655	21	99	2313
56	does migration speed up evolution process	The evolutionary dynamics do not depend on the immigration rate. Adaptation will proceed at the same rate regardless of how many immigrants invade the sink. This is because the impact of immigration on adaptation depends on the rate of immigration relative to the sink density, and this ratio is independent of immigration in a model where the sink is initially empty.	"[""- CIRB UMR 7241, CNRS, Paris, France\n- Evolutionary Dynamics, Evolutionary Ecology, Evolutionary Epidemiology, Evolutionary Theory\nWhen sinks become sources: adaptive colonization in asexuals\nFisher to the rescue\nThe ability of a population to adapt to a new niche is an important phenomenon in evolutionary biology. The colonisation of a new volcanic island by plant species; the colonisation of a host treated by antibiotics by a-resistant strain; the Ebola virus transmitting from bats to humans and spreading epidemically in Western Africa, are all examples of a population invading a new niche, adapting and eventually establishing in this new environment.\nAdaptation to a new niche can be studied using source-sink models. In the original environment —the “source”—, the population enjoys a positive growth-rate and is self-sustaining, while in the new environment —the “sink”— the population has a negative growth rate and is able to sustain only by the continuous influx of migrants from the source. Understanding the dynamics of adaptation to the sink environment is challenging from a theoretical standpoint, because it requires modelling the demography of the sink as well as the transient dynamics of adaptation. Moreover, local selection in the sink and immigration from the source create distributions of genotypes that complicate the use of many common mathematical approaches.\nIn their paper, Lavigne et al. , develop a new deterministic model of adaptation to a harsh sink environment in an asexual species. The fitness of an individual is maximal when a number of phenotypes are tuned to an optimal value, and declines monotonously as phenotypes are further away from this optimum. This model —called Fisher’s Geometric Model— generates a GxE interaction for fitness because the phenotypic optimum in the sink environment is distinct from that in the source environment . The authors circumvent mathematical difficulties by developing an original approach based on tracking the deterministic dynamics of the cumulant generating function of the fitness distribution in the sink. They derive a number of important results on the dynamics of adaptation to the sink:\nFrom the point where immigration from the source to the sink starts, four phases of adaptation are observed. After a short transient phase (phase 1), a migration-selection balance is reached in the sink (phase 2). After a while, thanks to the immigration of rare adapted migrants and mutation in the sink, a small fraction of the sink population exhibits a close-to-optimal phenotype. This small adapted fraction grows in frequency and mean fitness rapidly increases in the sink (phase 3). Finally, the population settles around the sink optimum (phase 4) and, hurray, the sink is now a source!\nInterestingly, in this model the evolutionary dynamics do not depend on the immigration rate. In other words, adaptation will proceed at the same rate regardless of how many immigrants invade the sink. This is because the impact of immigration on adaptation depends on the rate of immigration relative to the sink density. This ratio is actually independent of immigration in a model where the sink is initially empty, migration from the sink back to the source is negligible and without density-dependence in the sink.\nIn this model, mutation is a double-edged sword. Adapted phenotypes emerge from new mutations, and under this effect alone a higher mutation rate would translate into a shorter time to establishment in the sink. However, mutations may also have deleterious effects by displacing the phenotype away from the optimum. This mutation load will be greater when individuals need to simultaneously tune a large number of phenotypes. As a consequence of these two effects of mutations, time to establishment is minimal for an intermediate mutation rate. This result emerges from Fisher’s Geometric Model, but may hold more generally for biologically plausible fitness landscapes where mutations generates both beneficial (allowing adaptation to the sink) and deleterious genotypes.\nLastly, in Fisher’s Geometric Model, the time to establishment increases superlinearly with harshness of the sink when the sink is too harsh, and establishment may occur only after a very long time. In these harsh sinks, the adapted genotypes are very few and increase very slowly in frequency, making the second phase of adaptation much longer. Thus, and as a direct consequence of Fisher’s Geometric Model, adding a “stepping stone” intermediate environment would allow faster adaptation to the extreme environment.\nIn conclusion, this theoretical work presents a method based on Fisher’s Geometric Model and the use of cumulant generating functions to resolve some aspects of adaptation to a sink environment. It generates a number of theoretical predictions for the adaptive colonisation of a sink by an asexual species with some standing genetic variation. It will be a fascinating task to examine whether these predictions hold in experimental evolution systems: will we observe the four phases of the dynamics of mean fitness in the sink environment? Will the rate of adaptation indeed be independent of the immigration rate? Is there an optimal rate of mutation for adaptation to the sink? Such critical tests of the theory will greatly improve our understanding of adaptation to novel environments.\n Lavigne, F., Martin, G., Anciaux, Y., Papaïx, J., and Roques, L. (2019). When sinks become sources: adaptive colonization in asexuals. bioRxiv, 433235, ver. 5 peer-reviewed and recommended by PCI Evolutionary Biology. doi: 10.1101/433235\n Martin, G., and Lenormand, T. (2006). A general multivariate extension of Fisher's geometrical model and the distribution of mutation fitness effects across species. Evolution, 60, 893-907. doi: 10.1111/j.0014-3820.2006.tb01169.x""]"	['<urn:uuid:1d8f30ff-0a6b-4fdc-ba61-d0ae6619813c>']	factoid	direct	short-search-query	distant-from-document	single-doc	novice	2025-05-13T03:20:41.944655	6	61	896
57	I'm comparing different potato growing methods for my research - what are the five non-mechanized methods that are being tested in this agricultural study on potato cultivation?	The five non-mechanized potato-growing methods being tested are trenching (which serves as the control method), newspaper mulch, potato tower, container bag, and straw mulch.	['The institute is partnering with a group of independent market farmers to test potato-growing methods. We will be sharing the progress and results of this study on our digital platforms and providing logistical support to this citizen-science effort. Funding for the project has been provided by the USDA’s Sustainable Agriculture Research & Education organization.\nPotatoes are one of the most productive plants per area. They grow in poor soils and provide complete nutrition. Ancient and modern growers have devised strategies to maximize yield and simplify the growing process. Unfortunately these methods have not been subject to comparative study to separate the serious from the gimmicky.\nThis study will evaluate the relative performance of five nonmechanized, potato-growing methods: trenching (control), newspaper mulch, potato tower, container bag, and straw mulch. Each of the ten participants will cultivate potatoes holding all other variables equal: fertilizer, mulch, water, sun, plot size, and type and amount of seed potatoes. Data, segregated by method and collected throughout the season, will include local soil conditions, location-specific weather, labor, materials costs, weeding, and yield.\nThe outcomes of this study will support sustainable agricultural practices for market-scale growers. By identifying high-yielding methods, we reduce the amount of inputs (water, fertilizer, labor, materials) needed to grow a larger crop each year and increase profits over less-productive methods. By tracking the labor needed as well as yield, we can reduce the sometimes back-breaking labor of harvesting and cleaning potatoes. Finally, this information will be of interest to anybody who grows potatoes, not just market gardeners.\n- Identify five different garden potato-growing methods and recruit ten study participants.\n- Evaluate effectiveness of each method through side-by-side field trials in ten different locations.\n- Share results through website, social media, and articles submitted to trade publications.\nMost research on potatoes is focused on pest and disease prevention, maximizing yield versus resource use, and breeding, all in industrial contexts. Nevertheless, a search of the National Sustainable Agricultural Information Service, the American Journal of Potato Research, and the academic articles available on the University of Wisconsin–Madison and Washington University in St. Louis library databases, as well as industry publications (Spudman, Potato Country, and Potato Review) and Google Scholar did yield information related to this study. Each resource was searched for keywords such as “small-scale potato,” “container potato,” “garden potato,” “potato mulch,” “potato tires,” “potato growing methods,” “potato tower,” and “potato comparison.” It should be stressed, however, that the study proposed in this application has no direct antecedent in the academic or industry literature as far as could be found in this review.\nAlthough for industrial applications, a few studies did have information that can be applicable to our research design. In a side-by-side mulch comparison, straw mulch has been noted to increase potato size and yield as compared to manual weeding (Genger et al. 2017). Another study showed that in a side-by-side comparison of drip irrigation, above-ground drip irrigation was more beneficial in terms of water use and cost than below-ground drip irrigation (Ondera et al. 2005). Presprouted tubers were shown to give higher yields than nonsprouted tubers when the growing season was short but the same treatment resulted in a smaller yield with a longer growing season in another small study (Hagman 2012). A comparison between conventional and organic growing methods indicated that organic methods produced a lower yield but higher quality tuber in a Polish study (Flis et al. 2012). Another comparative study examined the effects of three irrigation amounts on industrial potato yields, suggesting that lower irrigation rates may be possible in some contexts (Erdem et al. 2006).\nSARE has previously supported fifty-eight studies with “potato” in the title. A few of these projects did have side-by-side comparisons of various potato-growing variables, but these compared a single variable (e.g., management practice, insecticide, cover crop) to a control and none of them discussed the small-scale market-gardener-friendly growing methods tested in this proposal. The closest studies compared three no-till methods to one another (FNE10-687), the effects of paper-mill-waste mulch on potatoes (FNE96-127), and fertilization methods (FNE14-792).\nI should note that Mother Earth News did have the most extensive information about the five different growing methods but had no side-by-side comparisons. A Google search returned many articles describing various growing methods but similarly no side-by-side comparisons could be found. Solicitations of potato-grower forums and the Kenosha Potato Project staff for any known studies of this type returned no positive responses.\nErdem, Tolga, Yesim Erdem, Halim Orta, and Hakan Okursoy. 2006. “Water-yield relationships of potato under different irrigation methods and regimens.” Scientia Agricola 63(3): 226–31. http://dx.doi.org/10.1590/S0103-90162006000300003\nFlis, Bogdan, Ewa Zimnoch-Guzowska, and Dariusz Mankowski. 2012. “Correlations among Yield, Taste, Tuber Characteristics and Mineral Contents of Potato Cultivars Grown at Different Growing Conditions.” Journal of Agriculture Science 4(7): 197–207. http://dx.doi.org/10.5539/jas.v4n7p197\nGenger, Ruth K., Douglas I. Rouse, and Amy O. Charkowski. 2017. “Straw mulch increases potato yield and suppresses weeds in an organic production system.” Biological Agriculture & Horticulture 1–17. https://doi.org/10.1080/01448765.2017.1371077\nHagman, Jannie. 2012. “Different pre-sprouting methods for early tuber harvest in potato (Solanum tuberosum L.).” Acta Agriculturae Scandinavica 62: 125–31. http://www.tandfonline.com/doi/abs/10.1080/09064710.2011.583935\nOndera, Sermet, Mehmet Emin Caliskanb, Derya Ondera, Sevgi Caliskanb. 2005. “Different irrigation methods and water stress effects on potato yield and yield components.” Agricultural Water Management 73(1): 73–86. https://doi.org/10.1016/j.agwat.2004.09.023\nEnvironmental, Economic, and/or Social Benefits\nThis study will evaluate the effectiveness of five potato-growing methods by measuring labor, cost of inputs, and yield. Accordingly, it will result in “improved income or profitability” by giving market gardeners the information needed to maximize the yield return on labor and/or assets. Similarly the study will “improve crop production and/or production efficiency” by identifying the highest yielding among the tested methods for improving crop production efficiency.\nLabor will be measured in hours worked per method throughout the growing season. To encourage careful documentation, participants will be paid according to hours recorded. Input costs will be simply computed by the cost of materials: compost, seed potatoes, mulch, and containers (if any). As all variables are kept consistent except growing method, the difference in yield (as measured by seed weight versus produced weight) can be computed as compared to the control plots. In addition, photos and impressions of the participants will be recorded every two weeks and may lead to further, unexpected insights.\nContributions to Sustainable Agriculture\nAny study that seeks to maximize the yield of a plant when compared to its inputs has implications for questions of sustainability. The most efficient method for producing a higher yield uses less resources and reduces the agricultural footprint on the environment. These methods of growing potatoes all involve mulching and amending the local soil, creating a better growing environment and increasing soil health. And of course, any method that can reduce the labor and/or expenses of growing a crop will make farmers lives easier and bottom lines more healthy.\nBy comparing these different growing methods, farmers in the north-central region (and beyond) will have baseline data about how much return on investment they may get for each growing method. If, for example, the most expensive growing method (“potato towers”) is the most productive method, but the cheapest (“trench and hill”) or least labor intensive (“straw mulch”) growing methods are only marginally less productive, a farmer can choose to save the money and still be confident in his or her choice. Additionally, by recording and publishing our methods and results, others can attempt to replicate the experiment or build off of it in a larger-scale study.\nNov. 2017–Mar. 2018 – Recruit 4 outstanding participants from local farmers’ markets\nApr. 2018 – Procure seed potatoes, fertilizer, straw, bags, newspaper, and tower segments\nMay 2018 – Install plots in ten locations. Each location will receive five, 8-×-8-ft plots: “control” (potatoes planted in a composted trench, hilled and mulched with straw after emergence), “straw mulch” (potatoes planted on composted ground, covered in straw mulch), “newspaper mulch” (same as “straw mulch” with two layers of newspaper below the straw to suppress weeds), “container” (potatoes grown in 55-lb woven grain bags with mixture of soil, compost, and straw, with more added as plant emerges), and “tower” (potatoes grown in a 2-×-2-ft wooden set of frames that stack and are filled with soil, compost, and straw as the plant grows). See attached diagram for details.\nMay–Sep. 2018 – Water, weed, and care for crops with photos and short updates recored every two weeks\nSep. 2018 – Harvest all plots and measure yield, gather final labor data, pay participants\nOct.–Dec. 2018 – Analyze data, prepare and publish detailed report, write and submit articles\nDissemination of Results\nApr.–Sep. 2018 – The project, its goals, and its methods will be shared online through the Low Technology Institute’s website (https://lowtechinstitute.org/), Facebook page (https://www.facebook.com/lowtechinstitute/), Twitter account (https://twitter.com/Low_Techno), and Instagram profile (https://www.instagram.com/lowtechinstitute/). Monthly updates sharing the data will be shared through these channels. Participants will be asked to share through their farm and/or personal websites and social media accounts, as they feel comfortable.\nSep.–Nov. 2018 – A detailed report will be made publicly available through the above-mentioned channels. A short video and podcast episode summarizing the study and its findings will be produced and shared online. Short summary articles will be prepared for and submitted to publications such as the following:\nOrganic Growers’ Publications\nAcres USA (https://www.acresusa.com/)\nOrganic Farming (https://www.soilassociation.org/)\nGrowing for Market (https://www.growingformarket.com/)\nThe sample size of this study may not be robust enough for an academic article, but the data will be freely available for any researcher to use in further research. Presentations of the study and results may be made at local or regional meetings for market gardeners or other small-scale growers. In addition, a short, one-page graphical summary (similar to a social media “meme”) of the study and its results will be shared online.\nAll disseminated information will be targeted at three audiences: market gardeners, small- to moderate-scale potato growers, and large-scale personal gardeners.\nStudy Participants: $20/hr × 5 hr/plot × 5 plots/participant × 10 participants = $5,000\nThe ten participants will carry out the day-to-day monitoring and work associated with the study. In addition to assisting with the planting of the five plots on each of their properties, the participants will be responsible for weeding, watering, and maintaining the plants, which may include monitoring for Colorado Potato Beetle. Every two weeks the participants will take a photo of each plot and make a few notes about their observations as well as log their time, which they will share with the project coordinator.\nEach of the plots requires different maintenance. The control plot requires initial trenching, composting, and planting. Once the plants have emerged they must be hilled and mulched with straw. The straw mulch plot requires composting and planting the tubers before being covered with straw mulch. The newspaper mulch plot is similar but also requires the layering of newspaper on the spaces between the rows before the application of straw. The container bags must be filled with a mix of topsoil, compost, and straw. As the plants grow, more of this mix must be made and added to the bags. The towers are similar to the containers, but on a larger scale: as the plants grow, new tower levels are added and filled with the topsoil-compost-straw mixture.\nAt the end of the season, the participants will help with the harvest and measuring of yield.\nStudy Organizer: $20/hr × ((1 hr/plot × 50 plots) + 80 hr organizing and analyzing) = $2,600\nThe organizer will spend lead-up time recruiting farmers to participate in the study. This will primarily be done through face-to-face solicitation at farmers’ markets and through contacting farmers by email found in online listings of market participants. Just before the planting starts, the coordinator will gather the materials: seed potatoes, mulch, bags, containers, and compost and then transport the materials to each participant’s farm.\nThe organizer will assist each participant with their planting to insure that each plot is created in a uniform way. Throughout the study period, the organizer will be in contact with participants through email and will compile the notes and photos into a small database. As the season ends, the organizer will again visit each participant to assist with the harvest and weighing of the potatoes, as well as getting the final labor totals and paying the participants.\nAfter all data have been gathered, the organizer will perform basic statistical analyses to determine various measures such as overall yield, yield versus cost, and yield versus labor, as well as create a narrative description of the results. All of this information and a description of the study will be prepared for trade publication and general audiences. The organizer will submit these articles (as discussed elsewhere) as well as provide all data online with open access.\nMaterials and Supplies\nPurple Cow Activated Organic Compost: (3 bags/plot × 50 plots × $7.86/bag) + $150 delivery = $1,329\nThis is the negotiated price for the recommended application rate, as determined in a recent discussion with a Purple Cow sales representative. By using one type of compost, it reduces the variability of using participant-generated compost across ten different grow operations.\nStraw: 2 small bales/plot × 50 plots × $3/bale = $300\nThe straw will be procured from sources suggested by participants and/or a local source known to the project organizer.\nSeed Potatoes: 21 seed potatoes/plot × 50 plots ÷ ca. 500 potatoes/bag ×$129/bag = $258\nWe will be growing Kennebec potatoes as this is the potato with which most participants have experience and prefer to grow (based on responses from participants). This variety has the added benefit of being a commonly grown potato and therefore the study can be easily replicated. We will use certified seed potatoes from a common source (Paradigm Gardens in Madison is the likely source and provided the above price quote) to reduce variability among plots and participants.\nMileage: 10 sites × 2 visits each × estimated 30 mi/visit × 53.5¢/mi = $321\nThis represents two trips to each of the ten participants for the project organizer to help plant and harvest the potatoes.\nOther Direct Costs (covered at 50 percent)\nGrain Bags: 20 bags/bed × 10 plots × $0 (free from local breweries) × 50 percent = $0\nGrain bags of woven polypropylene fabric will be used for the containers used to grow potatoes. This bag type will allow extra water to weep from the container instead of remaining soggy. The organizer recently obtained 500 of these bags for free from the Wisconsin Brewing Company and has secured a promise of 200 more bags to be donated for free to the project.\nNewspaper: 2 lb/bed × 10 plots × $0 (free from local source) × 50 percent = $0\nTwenty pounds of newspaper (plain newsprint, not magazine glossy) will be gathered to mulch under straw for one of the beds. This will either come from a local newspaper or the project organizer’s own newspaper pile.\nTower Frames: 5 frames/bed × 5 beds × 10 plots × $16 materials & labor × 50 percent = $2,000\nThe tower frames will be made of untreated pine wood screwed to interlocking corner posts.\nTotal Budget: $11,808']	['<urn:uuid:c37e036b-00b4-4a0d-b8d8-07b979987331>']	factoid	with-premise	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-13T03:20:41.944655	27	24	2515
58	female cognitive disease biological environmental vulnerabilities	Women face multiple biological and environmental vulnerabilities regarding cognitive diseases. Biologically, women are more likely than men to develop Alzheimer's disease due to longer life expectancy and hormonal changes, particularly the loss of estrogen during menopause. Environmentally, women historically received less education than men, which may have increased their risk since higher education helps build cognitive reserve and protects against dementia. Women are also more vulnerable than men to lung damage from inhaled smoke and pollutants, putting them at higher risk for chronic obstructive pulmonary disease. These vulnerabilities can be partially mitigated through preventive measures like exercise, healthy diet, limiting alcohol, getting adequate sleep, not smoking, and being socially engaged.	"['The actor Chris Hemsworth announced last week that he’s taking a break from acting to focus on his health. The news came after Mr. Hemsworth learned through genetic testing that he has two copies of the APOE4 gene variant, which is associated with increased odds of developing Alzheimer’s disease, the most common form of dementia. The 39-year-old star of “Thor” has not reported having any symptoms, but he told Vanity Fair that he wanted to focus on mitigating his risk as much as possible.\nShould you, like Mr. Hemsworth, undergo genetic testing to assess your risk for Alzheimer’s? And if you have the variant, what options are available to prevent or delay the condition? Here’s what to know.\nWhat is APOE4?\nThe APOE gene is important for the formation of a protein that helps carry cholesterol through the bloodstream. Nearly 30 years ago, scientists learned that APOE also influences a person’s chances of developing Alzheimer’s.\nThere are three variants of the gene, each conferring a different risk. People with the APOE2 variant appear to have a decreased risk of Alzheimer’s; the APOE3 variant — the most common type — is “neutral,” meaning it does not increase or decrease risk; and the APOE4 variant raises a person’s risk. Everyone has two versions of the gene, one inherited from their mother and one from their father.\nAbout 25 percent of people carry one APOE4, increasing their chance of developing Alzheimer’s by two or three times. Another 2 to 3 percent of people have two copies of APOE4, as Mr. Hemsworth does. This is associated with a roughly 10-fold higher risk. Having APOE4 is also linked to earlier onset of the disease.\nScientists aren’t exactly sure why a gene involved in capturing cholesterol plays such a large role in Alzheimer’s disease. It’s possible that changes in cholesterol can damage brain cells or cause inflammation in the brain, which could lead to dementia.\nHaving the APOE4 gene variant, either one or two copies, does not mean you will definitely get Alzheimer’s disease. Some conditions, such as Huntington’s disease, are directly caused by a specific gene mutation. Alzheimer’s disease and APOE4 don’t work like that. The gene is just one factor that contributes to people’s risk. Some people with the gene variant are never diagnosed with the disease, and many people without APOE4 develop Alzheimer’s.\nHow do you know if you have the APOE4 variant?\nIf you’re interested in knowing your status, you can ask your doctor or a genetic counselor about getting tested. You can also order a kit directly from 23andMe, which includes APOE4 on its health panel. However, Alzheimer’s experts are divided about whether testing for the gene is helpful for most people.\n“Generally, in my clinical practice, I dissuade people from getting the test and getting the information,” said Dr. Gary Small, chair of psychiatry at Hackensack University Medical Center in New Jersey. If you have a family history of dementia, you should assume you have an increased risk, he said, “so getting the genetic test is not going to tell you much more.”\nDr. Richard Isaacson, an adjunct associate professor of neurology at Weill Cornell Medical College, disagreed. “The reason that I believe in testing for APOE4 is that some people really want to know more about themselves, and it really democratizes the ability to learn about those risks,” he said. “Not about if they’re going to get the disease, but what we can do about it.”\nIf you do decide to get tested, Margaret Pericak-Vance, director of the John P. Hussman Institute for Human Genomics at the University of Miami Miller School of Medicine, said she would “suggest having a meeting with a genetic counselor afterward, because the risk is not straightforward.”\n“By having one copy or two copies, it gives you an important part of the picture, but it’s just one part of a very complex risk picture,” Dr. Isaacson said. “Genes are not your destiny. You can win the tug of war against your genes.”\nHow can you reduce your chance of getting Alzheimer’s?\nAll the experts interviewed for this article agreed that regardless of your genetic status, it is possible to reduce your overall risk of dementia, including Alzheimer’s. Studies show that tried and true healthy habits — exercise, eating well, limiting your alcohol intake, getting enough sleep, not smoking and being socially engaged — are key to fending off neurodegenerative disease.\nExercise, both endurance and strength training, helps the brain grow new connections between cells, particularly in the hippocampus, an area important for memory. Scientists think that building up more connections can be protective against memory loss. Dr. Small said that if you have the APOE4 variant, “physical exercise still can be helpful. There’s some studies showing that may even be more helpful for people with a genetic risk.”\nThere’s also evidence that a healthy diet, such as the Mediterranean diet, can be beneficial. In particular, it helps to eat fruits and vegetables, which are high in antioxidants, and fish, which contain omega-3 fats that can reduce inflammation. “These kinds of diets can have a tremendous effect on brain health,” Dr. Small said.\nWhile the importance of vitamins and healthy fats in your diet is clear, the case for taking supplements for brain health is weak. Dr. Isaacson said that a person’s genes may play a role in whether supplements can be beneficial. For example, research suggests that people with two copies of APOE4 can’t absorb omega-3 fats from their diet as well as people without the genetic variant. Taking an omega-3 supplement may be advantageous for that specific group of people, but likely isn’t helpful for others, he said.\nFinally, higher education has consistently been shown to be one of the best ways to lower a person’s risk for dementia. The hypothesis is that education helps people’s brains become more resilient, a concept known as cognitive reserve. Even if there are visible changes to a person’s brain, the more education they have, the less likely they are to display dementia symptoms. “If you look at numerous studies, level of education is correlated with lower risk, even within families,” Dr. Pericak-Vance said. “It all has to do with cognitive reserve. You build up more cognitive reserve the more schooling you get.”\nStudies on identical twins, who share nearly all the same genes, have shown just how much lifestyle behaviors influence brain health. In one of the largest studies of its kind, which looked at 392 pairs of twins aged 65 and up where one or both had Alzheimer’s disease, genes accounted for 58 percent of a person’s risk. The rest depended on lifestyle and environmental factors.\nWho else is at risk for developing Alzheimer’s?\nAge is the number one risk factor for Alzheimer’s disease. As we get older, chronic diseases associated with aging — such as high blood pressure, high cholesterol and diabetes — start to take their toll on the brain as well as the body.\nWomen are more likely than men to get Alzheimer’s, for multiple possible reasons. Women generally live longer than men, so they might have more time to develop the condition. Historically, women did not receive as much education as men, which experts surmise could have increased the risk for earlier generations. There also appears to be an interplay between the loss of estrogen during menopause and Alzheimer’s; research is ongoing into whether hormone replacement therapy could be beneficial.\nBlack and Latino Americans also have an elevated risk for Alzheimer’s — two- and 1.5-times higher than white Americans. One recent study found that the brains of Black Americans aged faster than white Americans’ brains, with more neurodegeneration at an earlier age, which could contribute to risk of disease. The authors theorize that one reason for these disparities is the additional stress Black and Latino Americans experience because of systemic racism.\nRace also appears to play a role in the risk associated with the APOE4 variant. People of Asian descent have the greatest increased risk of developing Alzheimer’s if they have APOE4, while people of African descent with APOE4 have the lowest elevated risk. Dr. Pericak-Vance said this is likely because of differences in the DNA that surrounds the APOE gene and influences how it acts.\nIf you think you have an elevated risk of Alzheimer’s, either because of your genes or other factors, Dr. Isaacson recommended talking to your doctor sooner rather than later. And regardless of your individual risk, everyone can benefit from incorporating more healthy habits, he said. “It’s almost never too early, in my opinion, to adopt brain-healthy choices.”', ""The biggest threats to women's health are often preventable. Here's what you need to know to live a longer, healthier life.By Mayo Clinic Staff\nMany of the leading threats to women's health can be prevented — if you know how. The top causes of death among adult women in the U.S. include heart disease, stroke, cancer, chronic lower respiratory disease, Alzheimer's disease, and unintentional injuries, according to statistics from the Centers for Disease Control and Prevention.\nTake control by talking with your doctor about your risk factors for these conditions. Then get serious about reducing your risk.\nIf you have health problems — such as high cholesterol, high blood pressure or diabetes — that increase your risk of heart disease and stroke, follow your doctor's treatment recommendations. Also, consult your doctor about when you should have mammograms and other cancer screenings.\nWhile you can't eliminate risk factors such as family history, you can control other risk factors for heart disease, stroke and cancer. For example:\n- Don't smoke. If you smoke or use other tobacco products, ask your doctor to help you quit. Avoid exposure to secondhand smoke.\n- Eat a healthy diet. Choose vegetables, fruits, whole grains, high-fiber foods and lean sources of protein, such as fish. Limit foods high in saturated fat, added sugar and sodium.\n- Maintain a healthy weight. Losing excess pounds — and keeping them off — can lower your risk of heart disease as well as various types of cancer.\n- Get moving. Exercise can help you control your weight and lower your risk of heart disease and stroke. It might also lower your risk of certain types of cancer. Choose activities you enjoy, from brisk walking to ballroom dancing.\n- Limit alcohol. If you choose to drink alcohol, do so only in moderation. For women, that means no more than one drink a day. A drink is one and a half ounces of standard 80-proof liquor, 12 ounces of beer, or a five-ounce glass of wine. The risk of various types of cancer — including breast and liver — appears to increase with the amount of alcohol you drink and the length of time you've been drinking regularly.\n- Manage stress. If you feel constantly on edge or under assault, your lifestyle habits might suffer — and so might your immune system. Take steps to reduce stress — or learn to deal with stress in healthy ways.\nA healthy lifestyle also might play a role in preventing Alzheimer's disease.\nWomen are more vulnerable than men to lung damage from inhaled smoke and pollutants. This puts women at increased risk of illness and even death from chronic obstructive pulmonary disease — which includes bronchitis and emphysema.\nYou can protect your respiratory health by not smoking and avoiding exposure to secondhand smoke. Try to minimize your exposure to chemicals and outdoor air pollution. Also, prevent respiratory infections by washing your hands often and getting a yearly flu vaccine. Ask your doctor whether you need a pneumonia vaccine as well.\nAnother common cause of death among women is motor vehicle accidents. To stay safe on the road, wear your seat belt. Follow the speed limit. Don't drive under the influence of alcohol or any other substances, and don't drive while sleepy.\nDon't feel overwhelmed by women's health risks. Instead, do whatever you can to lead a healthy lifestyle. Simple preventive measures can go a long way toward reducing your risks.\nJuly 28, 2016\n- Deaths: Leading causes for 2013. National Vital Statistics Reports. 2016;65:1.\n- Chronic obstructive pulmonary disease. Centers for Disease Control and Prevention. https://www.cdc.gov/copd/index.html. Accessed July 1, 2016.\n- Hennekens CH. Overview of primary prevention of coronary heart disease and stroke. http://www.uptodate http://www.cdc.gov/copd.com/home. Accessed July 1, 2016.\n- Goldman L, et al., eds. Psychiatric disorders in medical practice. In: Goldman-Cecil Medicine. 25th ed. Philadelphia, Pa.: Saunders Elsevier; 2016. http://www.clinicalkey.com. Accessed July 1, 2016.\n- Diet and physical activity: What's the cancer connection? American Cancer Society. http://www.cancer.org/cancer/cancercauses/dietandphysicalactivity/diet-and-physical-activity. Accessed July 1, 2016.\n- Tips to keep your lungs healthy. American Lung Association. http://www.lung.org/lung-health-and-diseases/protecting-your-lungs/?referrer=https://www.google.com/. Accessed July 1, 2016.\n- Powell ND, et al. Psychosocial stress and inflammation in cancer. Brain, Behavior, and Immunity. 2012;30:S41.\n- Park L. Preventive care in adults: Recommendations. http://www.uptodate.com/home. Accessed July 1, 2016.\n- Alcohol: A women's health issue. U.S. Department of Health and Human Services. http://pubs.niaaa.nih.gov/publications/brochurewomen/women.htm. Accessed July 1, 2016.\n- Taking her breath away: The rise of COPD in women. American Lung Association. http://www.lung.org/assets/documents/research/rise-of-copd-in-women-summary.pdf. Accessed July 1, 2016.\n- Prevention Alzheimer's disease. National Institute on Aging. https://www.nia.nih.gov/alzheimers/publication/preventing-alzheimers-disease/so-what-can-you-do. Accessed July 1, 2016.\n- Seatbelts: Get the facts. Centers for Disease Control and Prevention. http://www.cdc.gov/motorvehiclesafety/seatbelts/facts.html. Accessed July 1, 2016.\n- Alcohol and public health: Frequently asked questions. Centers for Disease Control and Prevention. http://www.cdc.gov/alcohol/faqs.htm. Accessed July 25, 2016.\n- Tobah YT (expert opinion). Mayo Clinic, Rochester, Minn. July 8, 2016.""]"	['<urn:uuid:f6be2078-7a88-4582-babb-8427185a4c8c>', '<urn:uuid:996ec587-dcda-42d1-9331-104fa4d95e3a>']	open-ended	with-premise	short-search-query	distant-from-document	multi-aspect	expert	2025-05-13T03:20:41.944655	6	110	2239
59	best gear bait location catch crappie summer deep water	For summer deep water crappie fishing, use soft plastic paddletails, grubs, and tubes on 1/32 or 1/16 oz jig heads rather than live bait. Fish can be found in healthy vegetation, particularly along weed edges at 8-20 feet deep, just above the thermocline. Use fast to extra-fast action rods paired with 1000 series reels and 3-6 pound line. Electronics like fish finders help locate schools near sunken structures and brush piles.	['Each and every spring, crappies seem to occupy the minds of nearly every fisherman in the Midwest. Springtime crappies pile into the shallows with intentions of creating the future generations. These mass schools of fish are followed closely by schools of fishermen with intentions of obtaining a few meals of fish.\nAs the season progresses, the drones of crappie fisherman quickly transition their efforts towards the toothier varieties of fish species. The challenge of summertime crappies can be a lot more rewarding than one might think. Based on personal experience, productive days during the the summer months will often yield much higher catch rates than those in the spring.\nRods, Reels, & Gear\nIf I could provide one piece of advice for summer crappies, or panfish in general, it would be, “Don’t waste your time with live bait.” Soft plastic paddletails, grubs, tubes and many others will out produce live bait applications throughout most of the summer months. Fish are extremely active during this period. One bait I always have tied on for summertime slabs, the Eurotackle B-Vibe. This bait alone accounts for more than 50% of my summertime panfish catches. Rigging plastics on a 1/32 or 1/16 oz jig head will cover almost all fishing conditions, depending on depth and weed cover. Opt for the former in shallow locations, or if there’s the likelihood to encounter thick weeds.\nHardbaits also have their place during the summer months. Micro crankbaits are great choice for covering water, especially when trolling on weed edges. A less common, but ultra effective presentation for weed oriented fish include micro jerkbaits, like the Eurotackle Z-Spender. This bait on reaches shallow depths, so it’s perfect for pulling over the tops of weed flats. Remember to pause on the retrieve — that’s usually when those fish will bite.\nFast to extra fast action rods are preferred for this type of fishing as they allow for quicker hook sets than typical moderate action panfish rods. Longer rods are also preferred for a number of reasons — casting distance and accuracy to name a few. Opt for an ultralight to light power rod as they’ll help keep fish pinned on their way back to the boat. My personal favorites come from St. Croix Rods lineup. If you’re looking for a budget friendly option the St. Croix Rods Panfish Series offers several great choices at a nice price. For certain applications, breaking out the lighter “walleye” rods can be beneficial.\nRods of this type should be paired up with a comparable size reel — 1000 series reels are what I opt for as they aid in casting and line management. Lines in the three to six pound class are preferred depending on the specific application. In my opinion, line type for this method of fishing is truly up to the discretion of the angler. Microbraids, monofilament, and fluorocarbon all have their advantages and disadvantages for summertime crappies.\nLocation, Location, Location\nAnglers often question where crappies move to after they wrap things up in the shallows. In all honestly, they likely didn’t move that far. Start near the areas they were located during the spawn. Day in and day out, lush, green vegetation adjacent to those spawning areas will typically have the highest productivity.\nCertain vegetation types will be more productive than others depending on a given body of water, but all weeds in general have the ability to hold fish. In this part of the country, everything from coontail to cabbage to lily pads are all fair game. Don’t be surprised if you find a rogue largemouth, pike, or walleye in your ventures, as they also tend to roam these same areas.\nFocus primarily on the weed edges during the summer months. Tools like side imaging technology help to pinpoint the edges, pockets, and changes in a hurry. You likely dropped some serious coin on that new unit, so it’s best to make sure you are using it to its fullest potential.\nOnce you’ve located some quality vegetation, start pitching the plastics to the weeds edges. Slowly roll the plastic over tops and edges of the weeds. On the initial casts, start reeling as soon as the lure hits the water. After a few casts let the lure sink a little before reeling. This method can help pinpoint the depths at which the fish are located. If you start getting bit, anchor up or spot lock, as there are likely more fish nearby. If you aren’t finding fish, keep moving.\nTrolling patterns are also extremely effective for summertime slabs. Micro crankbaits or soft plastics trolled along a weedline are hard to beat. Rely on your electronics to locate and follow the edges of the weeds. Trolling speeds vary depending on the situation and conditions, but typically occur between 0.75 to 2.0 mph. It’s sometimes necessary to move on top of the weeds, so pay attention to which speeds keep your lure just out of the weeds. Making sure you have enough distance between the boat and lure is imperative —sometimes being too close results in far less fish.\nCrappies are located in a wide variety of locations during this time of year, including deep water and submerged wood. However, personal experience has shown that healthy vegetation is often best for focusing your fishing efforts.\nGood luck out there!', 'Most anglers like to do their crappie fishing during the spring. This is largely due to their spawning, which makes the entire fishing experience fun with lots of action. However, it is a lot like shooting fish in a barrel, which makes it not challenging at all.\nIf you love a challenge, you will probably get bored in no time at all. You need to brush up on your deep-water crappie techniques and try to get them when they are in the deep. That means fishing for crappie during Fall, Summer and Winter!\nWhen temperatures hit the extremes, for example during summer or late fall, crappie tend to go deep. This is because conditions in deeper waters are much more stable than that of the waters above. Temperatures deep down tend to stay the same, whether it is cold, windy or rainy above, or even when outside temperatures are high.\nThis article I wrote covers the subject of the best time to catch crappie in-depth!\nThis unique behavior of crappie makes late Fall, Summer and Winter great times to fish, as long as you know how to fish deep. Here is the ultimate collection of deep water crappie techniques to help you catch like a pro in any season.\nAs always, please be a responsible angler and follow all state regulations. Here are the crappie size and bag limits for Texas. Make sure to look up your local regulations before heading out.\nLOCATE THE CRAPPIE\nThis is the first and most essential step. Locating the crappie can be quite difficult, especially when they are deep in the water. However, if you know what you are doing, you should be up to the challenge. You can locate the crappie using various methods, depending on your situation.\nIf you are on a boat, consider using electronics. It will make the entire process much faster and more efficient. Look for channels and drop-offs. You need to particularly look out for channels that are going from deeper to shallower, and look at around 30 feet. You should also look for brush and weed beds. Finally, keep in mind that during the fall, crappies school in huge numbers. This will look like a Christmas tree on your fish finder.\nIt is also important to note that during the high summer heat, they will go deep but not all the way to the bottom. Expect to find them just over the thermocline, generally at around 8 to 20 feet deep. The water is cooler above the thermocline, but it also has enough oxygen to sustain bait and other fish.\nCrappie tend to also spread out during very warm summers, making them harder to locate, especially in large lakes. A good trick to use is to search for them near sunken or submerged structures like trees and brush piles. Once you make a single catch, keep fishing at that depth because more crappie are definitely around there somewhere.\nDuring winter, use your fish finder and search for them at the deepest parts of the lake. The deep is warmer than the top, so they are attracted there. It may be a little difficult to find them at first, but because they are huddled together due to the cold, finding one will definitely mean you are going to reel in a huge catch. Just remember to fish slowly and pay 100% attention to the bites. Crappie bites, especially in winter, are very subtle and easy to miss if you look away.\nIf you are fishing from a barge, dock or from a bank, you need to look for structure. For the best results, fish close to piers and pylons. You should go to the bottom then reel up a couple of turns. Keep reeling up a few turns every 3 to 5 minutes until you locate the school. Check out this article I wrote, there is a section on finding the right depth.\nWhenever you can, bring a good updated topographical map of the area you are fishing in. Not only is this good practice, it is also just smart fishing. A good topographical map will have some indications of water depth and terrain altitude.\nSince finding the right depth is an essential part of crappie fishing, this information will go a long way in helping you figure out where to start your search. It will likely cut in half the time you would spend in finding the right place to fish. As far as maps are concerned, they can easily be found online. In fact, it is possible to stumble upon some really good topographical maps with local depths and indications of sunken structures, all for free. Download the ones of your fishing location and print them out before heading out. If you have a large sporting goods store, they will have excellent topo maps of all the lakes in your area. I know that Dick’s Sporting goods and Academy both carry them.\nAn understanding of crappie feeding styles is essential if you want to be even more effective in your fishing. Crappie only feed up, so this tells you that your bait must always be slightly above them. With the help of electronics, you can easily achieve this. However, if you are bank fishing or fishing from a pier, you need not worry. Click here for a proven technique that will help you find the right depth every time you fish.\nDuring the Fall and Summer months when crappie are deep, I have found that a 1/16 or a 1/32 jig head dressed with a 1 to 1.5-inch soft lure works best. You will realize that the crappie will start attacking the bait while it is still sinking.\nWhen you fish for deep water crappie, do not use an aggressive presentation style. All you need to do is drop the tip and let it rest for a while, repeating this process every once in a while. The important thing is to keep your trigger finger on the line, carefully watching for any slack or slight movement. It is possible to never feel a bite, which is why you need to pay close attention to the line. This is where High-Viz fishing line comes in handy! You can see it much more easily.\nHere is a video that I found on YouTube. The guy is not using a soft plastic but it shows vertical jigging pretty good. He is a bit too aggressive in his presentation to my taste but it works for him! This is really just to show you what vertical jigging looks like:\nMINNOWS – THE SECRET WEAPON\nThey should not be a secret weapon at all. They are an absolute all year round favorite of crappie. However, many people completely disregard minnows in the Summer and Fall months. This is especially true for the deep winter months because minnows do not last very long in the cold.\nAs a smart angler, you cannot disregard minnows, even during the fall, winter and summer months. Keep them alive in an insulated minnow bucket with an aerator. Here is the one I use:\nWhen you hook them, be careful to do it through the upper lip or behind the dorsal fin to prevent killing them. Then drop to the bottom and crank up the reel a few turns. This is how I hook them:\nPersonally, I usually have 2 or 3 poles tight-lined when I fish for crappie. However, this changes during Fall and Winter. During these months I only fish with one pole in hand. I make sure my trigger finger is on the line and my 100% attention is on the line. If you do not do this, you will likely walk away empty-handed time and time again.\nFinally, when it comes to minnows, there is one technique that I do not see used very much. The guys at the barge where I fish call it the “pinch-head”. It is actually quite simple; you need to take the head off a minnow and hook the minnow body to a 1/16 jig head, then fish it like you would a jig. When plastics and live minnows are not working, experience has proven that Jigheads can be surprisingly effective.\nWHICH PLASTICS WORK BEST?\nThis is a question that many people would like to know the answer to. I get asked about it all the time. However, it is quite difficult to answer. Crappies change their preferences almost daily. It is not uncommon to find that what worked yesterday no longer works today.\nHere is an article about crappie jigs\nGenerally, I have found that smaller plastics work pretty good in the fall. You will need to pair them with a small jig head for a slow fall. If you are fishing in darker and murkier waters, use darker colors. In clearer waters, use lighter colors that are brighter and stand out more. However, take this as a simple rule of thumb. It is always best to carry a variety of colors and color combinations to test what works and what does not. It will change daily!\nAnother pro tip here is to always make sure that you have Chartreuse, Pink and electric blue soft baits with you. I always start testing with those first, because they tend to yield the best results.\nCrappie fishing is amazing. You do not need to limit yourself to only fishing in the spring. You will be missing out in a massive way. Deep water crappie fishing is extremely fun and rewarding. Plus, if you want to catch your biggest crappie, you can only get them by fishing in the deep. The biggest slabs I have caught have been in deep waters in the cold October-Dec weather.\nDo not limit yourself. You need to set yourself free and explore the opportunities other seasons have to offer. With the techniques listed here, you will be well on your way to enjoy fishing all year round. I fish year round and I love it!\nI found some very unusual tips and tricks while scouring the internet for crappie fishing tips.\nLet me know below if you have some awesomely effective deep water crappie techniques.\nGood fishin’ to you']	['<urn:uuid:28f6a601-888b-4bd7-8073-258ba56988b0>', '<urn:uuid:9b6510be-00c1-4762-9db2-3779f204578a>']	factoid	direct	long-search-query	distant-from-document	three-doc	novice	2025-05-13T03:20:41.944655	9	71	2593
60	uv radiation immune system effects and gene editing	UV radiation has multiple effects on the immune system. Extensive UV exposure suppresses immune functioning, reducing the body's ability to repair damage. This is particularly concerning for people with already weakened immune systems due to conditions like leukemia or medical treatments. Regarding genetic interventions, while gene therapy can be used to edit immune cells to fight cancer, any germline modifications affecting the immune system would be passed down to future generations, raising serious ethical and safety concerns about long-term effects that might not be apparent until later in life or in future generations.	['Actinic Keratosis Risk Factors\nThe Risks. The Causes. What You Can Do.\nActinic keratosis (AK) is a very common skin precancer. Understanding your risk factors along with what causes AK can help you prevent it from developing. Being aware of your disease risk will also help you spot AKs early, when they are highly treatable. If left untreated, they can turn into squamous cell carcinoma, a type of skin cancer.\nThese factors increase your risk\n- History of unprotected exposure to ultraviolet (UV) radiation from the sun or indoor tanning. This includes people who work outdoors in the sun, people with a bald scalp or thinning hair and those who have had sunburns.\n- Geographic location: The closer to the equator you live, the more likely you are to have AKs.\n- Weakened immune system due to a medical condition or medications.\n- Fair skin: While anyone can develop AKs, they occur far more frequently in people with fair skin.\n- Age over 40: AKs are most common in people age 40 and older.\nUnprotected UV exposure\nChronic unprotected exposure to UV radiation is the leading cause of actinic keratosis, which is why AKs often appear on sun-exposed areas of skin.\nSun damage to the skin is cumulative. This means that the more time you spend in the sun over the years — even for brief periods — the greater your odds of developing one or more AKs. The UV rays emitted by indoor tanning beds are especially dangerous in raising your risk of developing AKs and all types of skin cancer.\nFind out more about the skin cancer risks associated with UV radiation here.\nLiving in a sunny climate close to the equator where the UV rays are strong most of the year means more exposure to the harmful effects of the sun. Thus, the likelihood of getting AKs is higher for people who live in regions close to the equator.\nRegardless of climate, anyone who spends a lot of time outdoors without protection risks developing one or more AKs. Even when it’s overcast, about 80 percent of UV rays can pass through clouds.\nWeakened immune system\nIf your immune system is weakened as the result of medical treatments, including chemotherapy or immunosuppressive therapy, or if you have a medical condition such as leukemia, lymphoma or HIV that reduces immune functioning, your risk of developing AKs is higher. Extensive UV exposure suppresses the immune system, reducing its ability to repair further damage.\nAge over 40\nBecause sun damage to the skin accumulates over time, the longer you live, the greater the total lifetime damage. This explains why AKs are increasingly more common in people over age 40.\nHowever, AKs also occur in young adults, especially people with fair skin and light eyes, and those who spend a lot of time outdoors.\nWhat you can do\nBe on the lookout: Perform monthly self-exams and visit your dermatologist annually for a thorough professional skin exam.\nProtect against UV rays: No matter your skin type, you can reduce your risk of getting AKs and skin cancer by taking simple, smart protective measures.\nLeonard H. Goldberg, MD\nMark Lebwohl, MD\nLast reviewed: May 2019', 'What is Human Gene Editing?\nGenome editing is a way of making changes to specific parts of a genome. Scientists have been able to alter DNA since the 1970s, but in recent years, they have developed faster, cheaper, and more precise methods to add, remove, or change genes in living organisms. Researchers are working to develop therapies that use gene editing to treat children or adults for a range of conditions, including sickle cell, hemophilia, and some forms of cancer and blindness.\nSince 2015, a few laboratories have been experimenting with a far more controversial use of CRISPR: editing the genomes of early human embryos, eggs, and sperm. If edited embryos are used to start a pregnancy, the changes affect every cell in the body of any resulting child, that child’s offspring, their offspring, and so on. Dozens of countries already prohibit any attempt to start a pregnancy with edited embryos, yet some scientists seem eager to proceed.\nIn November 2018, researcher He Jiankui from Shenzhen, China announced the birth of the first gene-edited babies: twin girls publicly referred to as Lulu and Nana. In a reckless and widely condemned experiment, He had edited the DNA of two embryos and used them to start a pregnancy. The babies were born prematurely and their current health status is unknown.\nThese utterly unethical experiments have pushed the issue of human genome editing to the forefront of media, scientific, and public discussion and debate. Any discussion of how we might use this technology in the future needs to consider the serious societal consequences of human genome editing. This includes examining the rise of vast economic inequalities and the resurgence of overt xenophobia and racism in many parts of the world. It also includes acknowledging our eugenic histories and the present-day systemic oppression of women, people of color, Indigenous people, LGBTQ people, and people with disabilities, particularly as they relate to reproduction and ideas about who is “fit” to reproduce.\nHuman genome editing is not just a scientific issue. It is a political and social justice issue that intersects with the concerns of multiple movements, including disability rights, LGBTQ rights, reproductive rights and justice, racial justice, environmental justice, and health justice. Read on to learn more about human genome editing and why everyone should have a say in the decisions we make about whether and how to use this powerful technology.\nGene Therapy: Changing genomes to treat disease\nThere are two distinct ways gene editing might be used in humans. Gene therapy, or somatic gene editing, changes the DNA in cells of an adult or child to treat disease, or even to try to enhance that person in some way. The changes made in these somatic (or body) cells would be permanent but would only affect the person treated. One way this is already being done is by editing a person’s immune cells to help them better fight cancer. Clinical trials will soon be underway to use CRISPR to edit blood cells as a treatment for sickle cell anemia and other blood disorders. Gene therapy raises many of the same social and ethical issues as other high-tech medical treatments, including ethical research practices, safety and effectiveness, unequal access to expensive treatments, and how we allocate resources, but is widely supported as a promising way to treat disease.\nGermline Editing: Changing the genomes of future generations\nBut there is a much more controversial way that human gene editing could be used. In germline modification, gene editing would change the DNA of embryos, eggs, or sperm. Because germline DNA is passed down to all future generations, any changes — whether they had beneficial or harmful effects — would be as well. Some have proposed that germline editing could be used to prevent inherited diseases, but this would carry unacceptably serious safety, ethical, and social risks. And it’s unneeded, since we already have safe and effective ways to prevent passing on an inherited disease. People at risk can use preimplantation genetic diagnosis (PGD), a way to screen embryos created through in vitro fertilization (IVF) and select one that is unaffected; this allows parents to have a genetically related child without passing on an inherited disease. PGD certainly raises its own ethical questions, particularly around disability rights and justice, but it poses fewer safety and societal risks than germline editing would.\nUnderstanding the Social and Ethical Risks\nNew technologies often raise ethical questions about their unknown risks and benefits. These questions become especially tricky — and essential — when we are talking about something like human germline editing, which affects future generations who obviously can’t consent to the changes being made to their DNA. What risks would women (who are rarely mentioned in discussions about human gene editing for reproduction) be subject to as the ones who would carry pregnancies started with genetically modified embryos and deliver the resulting children (for themselves or for others)? How could potential parents make informed decisions when there would be unknown health risks that might emerge during pregnancy for the woman and the fetus, epigenetic effects, and health issues that might not develop until adulthood or old age (or even in future generations)? It would be extremely difficult, if not impossible, to ethically conduct the kind of follow-up studies that would be necessary to say that human genome editing is safe enough to use in reproduction.\nBut focusing on these obvious safety risks takes too narrow a view and overlooks the many serious social and ethical risks that germline editing would pose. Imagine wealthy parents being able to purchase enhancements (real or perceived) for their children, and the kind of world that would result if children’s education and life chances were thought to be determined at birth by their DNA. Imagine the long-term consequences of imposing the preferences and biases we hold today on the genes of all future generations. Consider the potential effects on groups that have less power in society and are already discriminated against, including people with disabilities, people of color, and women. Ableism, racism, and reproductive injustices would likely be exacerbated by human genome modification, if it were ever allowed. These and other social inequalities that already shape our lives could rapidly grow worse, and new forms of inequality could be introduced, leading to a new form of eugenics.\nWhile it might seem possible to avoid such dire outcomes by limiting the use of germline gene editing to the prevention of serious diseases, this would be extremely difficult. The line between therapy and enhancement is fuzzy and would be nearly impossible to enforce. How would we determine which diseases are serious enough to edit out? And who would decide? There are many disabled people who value their differences as a form of human diversity and do not think they need to be “treated” or “cured.” Allowing just some uses of germline gene editing for reproduction would mean opening the door to all uses. For these reasons, over 40 countries have banned human germline modification.\nWho Gets to Decide?\nHuman germline editing is not just a scientific or technical issue. It affects how we understand ourselves as humans and what kind of future we want to build. It has implications for society as a whole, not just individuals. Therefore, decisions about whether to permit germline modification should not be made by small groups of scientists or bioethicists, by biotechnology companies, or by wealthy elites. Human germline editing is an urgent social justice issue; we need public discussions of it that are open to all.']	['<urn:uuid:7437c4f4-79f1-4f7d-9cb4-bc9dfeb7bd63>', '<urn:uuid:65197cfd-f25b-472d-b56a-e258a52f1514>']	open-ended	with-premise	short-search-query	similar-to-document	multi-aspect	expert	2025-05-13T03:20:41.944655	8	93	1786
61	mekong river fish species impact fishway construction	The Lower Mekong Basin has over 800 fish species, and research has shown positive impacts of fishway construction. At the Pak Peung wetland, a pilot fish passage was built for USD 156,000, and over 170 fish species have been documented using it. During peak migration periods, up to 100 kilograms of fish per day gained passage into the wetland, which was previously impossible. Local fishermen have even reported seeing fish species that hadn't been seen in the region for over 30 years.	['Lower Mekong Fish Passage Conference\n14-18 November, Vientiane\nOpening Remarks by John Williams, Australian Ambassador to the Lao PDR\nH.E. Dr Phouangparisak Phravongviengkham, Vice Minister of Agriculture, Forestry and Fisheries, Distinguished Guests, Ladies and Gentlemen. Friends of the lower Mekong, one and all!\nI am delighted to be able to join Dr Phouangparisak in welcoming you all to an event that will be important to the livelihoods and food security of tens of millions of people living in the lower Mekong Basin.\nThank you all for travelling to Vientiane for this week’s fish passage conference. I am looking forward to hearing your contributions, which will be important in our collective effort to share knowledge on fisheries sustainability in the region.\nWe can make a big difference this week to help the Lao PDR, and its neighbours on the lower Mekong, to progress their economic development, while also maintaining – and where necessary, restoring – healthy aquatic ecosystems.\nThe Australian Government is proud to support this conference. This is, I am certain, the first time this group of experts – from a range of relevant disciplines, and from a number of nationalities – has come together to collectively apply your skills and knowledge to protect one of the world’s great fisheries.\nI think we all have a sense of the challenges, and the numbers, as freshwater fish in the lower Mekong come under increasing pressure from riverine development.\nMy experts tell me the Lower Mekong Basin has over 800 fish species, and that 2% of all fish caught globally each year come from the Mekong River.\nI think we all understand too the importance of fish as a commodity and source of protein in this region. Fish, I am told, makes up nearly half of total protein consumption in Laos.\nBut the total fishery yield per family is declining. A result of enhanced fishing technology, growing food demand and infrastructure development - such as river regulation and extractive water use.\nThere are, however, practical solutions that can help address this decline.\nI am proud, in particular, that Australian fish passage technology offers one potential solution, thanks to a successful collaboration over recent years between Lao and Australian researchers, funded by the Australian Centre for International Agricultural Research, ACIAR.\nI know small weirs, irrigation dams and floodplain regulators are an important facet of the rural economy in Laos.\nThese structures provide irrigation water to boost rice production, and help prevent the inundation of rice fields during high river flows.\nBut, of course, they also represent an obstacle to the upstream and downstream migration of fish, and prevent fish from accessing important nursery and high growth habitats. In laymans terms, I think I’m correct in saying they prevent fish from breeding, feeding and resting.\nIn April this year, I travelled to Pak San, in Bolikhamsay province, 2 hours south of Vientiane, to open the next phase of this Australia-Lao research collaboration.\nOver the next five years, our research teams will work to strengthen understanding of the impact of fishway construction on fish populations in wetlands.\nAnd they will seek to evaluate different options for sustainable, low-cost fishways.\nMy 8-year-old daughter was confused when I told her I was going to Pak San to look at fish ladders. It’s probably not the correct scientific term, fish ladder, but nevertheless she delighted in conjuring images of a fish that could climb a ladder.\n[Incidentally, experts tell me there is one species of fish in the Mekong River with little hands and feet. I hope someone can show me a photo.]\nI was able to report back to my daughter that the fish passages, drawing on all Australia’s experience over recent decades in the Murray-Darling river basin, had been tested, and were working.\nOver 170 fish species had been using the pilot fish passage built at the Pak Peung wetland at a cost of around USD 156,000. During peak migration periods, up to 100 kilograms of fish had been able to gain passage into the wetland each day. That strikes me as a fair bit of traffic.\nPrior to construction, this was not possible.\nThe model, using fish ladders to help fish migrate, has great potential to increase fisheries production, improve biodiversity and raise local incomes.\nMost importantly, this can all be achieved with no impact on rice production.\nSupporting local communities\nThe interesting story in Pak Peung is, I think, as much about how the fish ladder has united a regional community, as it is about the fish ladder itself.\nLocal people have been engaged to assist our researchers, and to help construct the fish ladder, and remain a crucial source of advice on fisheries in the area.\nSix villages in the Pak Peung area are now united in the development of fisheries management strategies, to ensure fish recover, and that the fish ladder remains operational.\nAll of this has generated local excitement, and a sense of pride and real hope.\nLocal fishermen are also reporting fish that have not been seen in the region for over 30 years.\nWe are obviously delighted with this community-level impact, in addition to the obvious scientific ones.\nOn behalf of the Australian Government, I am delighted to declare this workshop open\nI wish you success in your discussions on how we can adapt and upscale these new technologies to best mitigate the impact on fish of an unprecedented boom in river development in the lower Mekong over recent years.\nThank you to Dr Phouangparisak and his Ministry colleagues for their leadership and support, to Dr Douangkham and his team at LARREC for hosting the conference. And to my colleagues from ACIAR, and our partners from USAID, for providing the funding to bring us all together in Vientiane to collectively workshop solutions.\nThank you all, and every success with this vital project for the Mekong.']	['<urn:uuid:306ffbe4-af4c-45c9-8ae4-3fcc194c3c38>']	open-ended	with-premise	short-search-query	similar-to-document	single-doc	expert	2025-05-13T03:20:41.944655	7	82	976
62	I'm fascinated by intricate metal crafting techniques - could you explain the ancient process used to create bronze sculptures and why it's considered so challenging?	The process used is the 5,000-year-old lost-wax process, dating back to the Mohenjodaro and Harappan civilisation. It's an arduous process where molten metal is poured into a mould created using a wax model. The process involves creating a wax shell filled with heat-resistant mixture, fitting wax tubes for pouring bronze, covering it in heat-resistant plaster, and heating it in an oven where the wax melts out. The plaster mould is then packed in sand and filled with molten bronze at around 900 degrees centigrade. Once cooled, the plaster is removed and final touches are added. The entire process is very demanding and time-consuming - it can take up to six months to create sculptures using this method.	['Artist Dimpy Menon uses bronze figures to display different emotions. Ayushi Sharma covers her artwork and her story.\nFrom emotions like joy to sorrow, aspiration to celebration, artist Dimpy Menon has tried to convey all aspects of humanscape in her works. With her elongated, elegant human forms that are sculpted in an acrobatic motion, she said that she conceived them as lyrical. “I have given the title as Breaking Bounds because it is basically about breaking boundaries and pushing limits. The forms in my works are very acrobatic and there’s a lot of movement in them. Although there has been a certain evolution over the years, the human form has remained central in all of my works,” said the sculptor.\nShe added, “I have used the 5,000-year-old lost wax process which has prevailed from the time of Mohenjodaro and Harappan civilisation. With progress and change, there has been a slight change in the treatment of the material. But otherwise the method is exactly same. It’s a long and gruelling process. One has to work at high temperatures. The metal will melt at about 900 degree centigrade. It’s a very arduous kind of job. It took me six months to create these sculptures.”\nLost-wax process is a method of metal casting in which a molten metal is poured into a mould that has been created by means of a wax model. After the removal of the mould, the resultant wax shell is filled with a heat-resistant mixture. Wax tubes, which provide ducts for pouring bronze during casting is fitted to the outside of the wax shell, which is then modelled by the artist. Next, the prepared wax shell is completely covered in layers of heat-resistant plaster, and the whole is inverted and placed in an oven. During heating, the plaster dries and the wax runs out through the ducts created by the wax tubes. The plaster mould is then packed in sand, and molten bronze is poured through the ducts, filling the space left by the wax. When it cools down, the outer plaster and core are removed and the bronze is given the final touches.\nIrony is evident in her works as she has used a tough medium of bronze to create the sculptures that appear weightless and in flight. It kind of defies the gravity of law. The artist said, “It is difficult using something that is so heavy to symbolise and capture the essence of lightness. It’s not an easy acceptance of the way I have used the material.”\nDimpy seeks inspiration from life. She believes that the resilience of the human form, both in terms of spirit and body, is inspiring. She said, “If we set our minds on something it can easily be achieved. We are the epitome of creation. And as I’m a figurative artist, I really like how the audience can effortlessly and immediately relate to a human form. That is the reason my sculptures are loaded with expressions and with great values of humans. With each work there is a different emotion and different content. I have used it, as one uses language to express oneself. It’s the form that I have very lovingly nurtured and broken my back over. I have also used a lot of other elements too but the crust of my work has always been the human form. It majorly revolves around the human form, the rest is all embellishments.”\nThe curator and founder of Art Pilgrim, Gayatri Singh, said, “Dimpy has created the work that truly integrates with the space it is built for and hence it is for both homes and public spaces. Her sculptures depict emotions through action and body language. It is absolutely amazing how she manages to make a 100 kg bronze figure appear so light.”\nWriter: Ayushi Sharma\nCourtesy: The Pioneer']	['<urn:uuid:d0404fee-dcb2-458c-9928-d8e4c555ee9a>']	open-ended	with-premise	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-13T03:20:41.944655	25	117	638
63	need calcium supplement comparison bearded dragon versus ex battery hen	Both animals need calcium supplements - ex-battery hens require oyster shell grit as a calcium source for strong eggshells and to prevent brittle bones, while bearded dragons need calcium powder supplements like Repashy's SuperCal HyD sprinkled on their insects to prevent Metabolic Bone Disease and strengthen their skeletal structure.	['If you are new to chickens or have simply never rehomed battery hens before then these Frequently Asked Questions about rehoming ex-batts are for you! From the practicalities of the size coop and run you need, what to buy before you get them and what to feed them to general care for them when you get them. This is a good starting place if you’re thinking of getting a few ex-batts…\nHow difficult is it to look after ex-battery hens?\nEx-Battery hens do require a little bit of extra care and attention during the initial couple of months that you get them until they have adapted to their new life and routine. At first, they may not put themselves to bed (but this is often the case with new chickens anyway) and may not lay their eggs in the nest boxes but with a little extra attention during the first couple of months, they will soon learn the routine. Once they have settled in, they aren’t much trouble at all and are easier to look after than many pure breeds of chickens.\nYou will need to make sure you have the time to give them fresh water and food every day and make sure you can lock them up at night safe from foxes. Automatic door keepers are a very worthwhile investment.\nAutomatic Door Closer\nYou can view automatic door keepers for sale here.\nKeeping chickens, like any animal does give you an extra tie if you want to go away. You will need to make suitable arrangements to make sure your hens are looked after properly when you are on holiday but neighbours and friends are usually willing, especially if they get to take home some eggs!\nWhat condition will the hens be in when I get them?\nSome battery hens can be poorly feathered when they come out from the farms, a few can be very sparsely feathered and can look almost ‘oven ready’ but the average hen will have just a few bare patches.\nHens will usually feather up within a few months and will then look far more like ‘normal’ hens. Hens will be pretty exhausted when you get them (as will the rescue co-ordinators after a pretty gruelling day getting the hens out and rehoming them).\nHow easily do battery hens adapt to a free range life?\nIt is a difficult time for a battery hen when she comes out of a cage, even though it is for a much better life. Hens are creatures of habit and anything different can cause them to be stressed and a little nervous. There are many things they will not understand at first, like being able to scratch the ground beneath their feet. This is one of the most natural behaviours for a hen though and will soon return. It is one of the most amazing sights seeing hens taking their first few steps out of their house. Within a few days they will be moving around, exploring their new home and enjoying a free range life. After a few weeks, their new feathers will start to grow, and within a couple of months, they will soon look like ‘normal’ hens again.\nHow many hens should I rehome?\nMost people will keep a minimum of 3 chickens. The main reason for this is that hens are social creatures that live in flocks. Battery hens are frail and if you lose one then you will still have 2, the minimum number of birds to keep so that they have company of their own kind. With ex-battery hens, they have had a hard life and there is an increased risk of losing one before they have had a chance to recover and settle in. It’s for this reason that we would really recommend you try to rescue a minimum of 4 hens although 3 is of course the bare minimum.\nWhat size coop and run do I need for ex-battery hens?\nWhen you buy a chicken house, the manufacturer will usually state how many chickens they can house. Some manufacturers will always go for a higher number than is comfortable so it’s always a good idea to stock your house with less hens than is recommended. The main requirement is sufficient perch space for the hens because normally they will be outside during the day. You need to allow 30cm of perch space per hen to make it comfortable for them. It is good to be able to have enough space in the chicken house to hang a feeder if you don’t have a covered run since you will want to keep their food dry and away from the wild birds who will soon empty an open feeder left outdoors. There is some guidance on cheap chicken houses here but do remember, you get what you pay for when it comes to wooden chicken houses.\nChicken runs come in many sizes but the more space you give the hens the better. If you have a very small run, they will get bored quickly and will soon pick up bad vices like feather pecking. There is more guidance on chicken run size and keeping chickens in small spaces in this article.\nWhat do I need to buy before I get my ex-batts?\nBefore you pick up your hens, you will need to get the following:\nA secure chicken house and run. Foxes are the number one predator to protect against but Badgers will also take chickens from time to time. Battery hens are used to sleeping on the floor so remove perches in their house for the first few weeks. If they do climb up on a perch, they can damage their bones when jumping off so exercise caution with perches until they are settled in.\nFood and water containers. Hang these inside their house at first so that they are close to the hens. They are not used to having to go far for their food or water so make sure they are within easy reach of your new girls. Some water containers come with a handle that allows them to be hung from above (hanging basket chains with a nice big hook on the end are useful for this) but remember you may not have somewhere to hang them once they eventually move outside. Some containers have plastic feet that keep them off the ground which are useful for this purpose.\nClick here to see a range of plastic water containers.\nDry layers mash (not layers pellets) – this is what battery hens are fed. In time, you can slowly change their diet to layers pellets if you wish but wait until they have settled in for a couple of months first. Alternatively, Smallholder Feeds make a special feed for Ex-Battery Hens that helps promote weight gain and feather growth and has been specially designed for the nutritional needs of the ex-battery hen. We have heard nothing but praise from this feed from both rehomers and rehoming charities.\nPoultry Grit – chickens don’t have teeth of course but do have a gizzard that grinds their food down using insoluble grit. Most free range hens will pick up enough grit from grazing but it is always wise to provide grit just in case. Soluble grit (Oystershell) can be provided mixed with insoluble (flint) grit. This provides calcium for the hens to produce strong egg shells. Commercial battery hens often have brittle bones since the calcium from their bones is taken to produce egg shells. Most commercial feeds these days provide sufficient calcium but again, it is a good idea to provide Oystershell grit ad-lib. A hen can then take it if she needs it. There is more information here on the types of poultry grit.\nDried cat food – yes, that’s right – cat food. Feathers are 80% protein. Chickens that are growing new feathers benefit from the animal protein in cat food so crushing up some dried cat food is an old poultry keepers trick that is used to help chickens through their moult. Do not use dog food because the protein in dog food is derived from cereals.\nA vitamin drink / supplement. Ex- battery hens will benefit from a vitamin supplement added to their drinking water or food to get back into condition. There are many different supplements available on the market, some more expensive than others. Whatever you chose to buy, it will not be wasted since birds can benefit from these vitamin supplements during the annual moult or during the colder winter months when greens are in short supply. Most of these come as a liquid that is diluted down and added to drinking water but there are a few that come as a powder and can be added to drinking water or to a wet mash mixture.\nA.C.V. – Apple Cider Vinegar. This is remarkably good for chickens in many ways but the best thing is scientific tests have shown it actually helps them to cope with stress and changes to their environment.\nApple Cider Vinegar\nYou can buy Apple Cider Vinegar here.\nWhat should I feed my ex-batts?\nBattery hens are used to being fed dry layers mash. Changes are stressful for chickens and ex-battery hens have enough to deal with coming out of their cages into a completely new environment so it is important for you to be able to continue feeding them layers mash until they have settled in for a few weeks, after which, you can gradually change their feed over to pellets if you prefer.\nTo digest their food, chickens must always have a clean / fresh supply of water at all times. During hot weather, this is particularly important when they will drink more. Chickens do not sweat and can only lose heat from their bodies by panting and drinking water that is cooler than their body’s temperature, it is for this reason their water container should be kept in the shade during very hot weather. Don’t forget chickens also need grit in order to digest their food correctly so they should always have (insoluble) flint grit available to them at all times for digestion. Oystershell grit or soluble grit is also important as this contains calcium which helps them source the calcium required to produce eggs. Chickens also love most fresh green vegetables and fruit. Corn on the cob, cabbage, broccoli, apple, strawberries, grapes, tomatoes are all appreciated and you can hang some of these in their run for them to enjoy.\nThere is more in-depth information on feeding chickens here if you are concerned.\nWill ex-battery hens lay lots of eggs?\nBattery hens are the result of many years of breeding and selection. They have been bred to lay the largest possible number of eggs in their first couple of years of their life. If you want ex-battery hens solely for eggs, then they aren’t really for you. Ex-battery hens should still have a large number of eggs to lay for you but keep in mind that commercially they are ‘spent’ hens and like any chicken will lay less and less every year, sometimes with a thinner egg-shell as they get to 3 or 4 years old. A very small number of hens that are rescued do not lay although most will usually start laying very quickly. Like all hens, expect them to lay most of their eggs during the spring and summer months and expect them to stop laying when they go into moult in the late autumn and when the daylight hours are reduced over the winter.\nWhere can I buy ex-battery hens?\nThere are a number of charities / rescue organisations in the U.K. that rehome ex-battery hens. Most of these require you to register with them so that they can allocate some hens to you from their next rescue in that area. They usually do not charge a set fee for hens, but they will ask you for a donation to help support their work and running costs. We would encourage you not to go straight to the farmer. The charities will check birds over for you and will often trim overgrown nails or beaks before giving your birds to you. A list of the rehoming charities can be found at the bottom of our article: Ex-Battery Hens For Sale\nDo I need to register with DEFRA?\nIn the UK, you do not need to register with DEFRA unless you are keeping 50 or more poultry. When you count your birds, you must remember ‘poultry’ doesn’t just mean chickens, you must include ducks, geese, guinea fowl, quail and so on. There is more information on the laws that concern chicken keepers on this page here.\nFinally… Once Ex Bats have settled in, they are just like other chickens and can be treated as such. There are lots of articles in our keeping chickens section that can help you to look after their needs. Most of all though, have some fun keeping them!', 'So you’ve just brought home your very first Bearded Dragon…Like many, you’re probably wondering wondering what to feed it, how much to feed, and how often to serve up meals.\nIt can be difficult and time consuming to scour the internet in search of the best articles and advice – so we took the liberty of gathering everything you’ll need to know about feeding bearded dragons. Keep reading for some of the best tips and recommendations you’ll need to keep your dragon’s diet and eating habits right on track.\nBaby Bearded Dragon Diet\nFor younger bearded dragons, it is very important to keep their diets omnivorous with the right balance of plant and animal matter.\nThis ratio will change as dragons grow and mature – for baby dragons, bigger portions of leafy salads and smaller amounts of insects like Dubia Roaches or Phoenix Worms should be fed daily.\nBest Insects for Baby Bearded Dragons\nAs we covered above, insects are the backbone of any baby bearded dragon diet. Here are a few types of insects that we recommend for baby beardies:\n- Dubia Roaches\n- Phoenix Worms\nBest Greens for Baby Bearded Dragons\nAlthough greens make up only 20% of a baby bearded dragon’s diet, they are still extremely important. Here are a few types of greed that we recommend:\n- Collard Greens\n- Turnip Greens\n- Dandelion Greens\n- Mustard Greens\nModifying Meals as Your Dragon Matures\nJust like any animal, a bearded dragons’ diets change as it matures. After all, humans don’t eat the same foods their entire life, right?\nThe ratio between insects and greens used to create a baby dragon’s diet will flip as they mature – adults will be better nourished by a diet consisting of 80% greens/veggies and 20% insects.\nLarge leafy salads and an assortment of veggies should be readily available to your bearded dragon every day (with a few worms or roaches added to the mix). Their eating schedule will also change with time, and we’ve got details below on what to expect and what to watch out for.\nBest Insects For Bearded Dragons\nIt is recommended that, when feeding a bearded dragon, each meal should consist primarily of fresh salads and live feeder insects (with some calcium sprinkled in and a multivitamin to top it all off). When looking for the right insects to feed your dragon, there is a wide variety of good staples to choose from.\n1. Phoenix/Repti Worms\nA top recommendation from many experts, Phoenix/Repti Worms are a healthy choice for feeder insects. They are the larvae of Black Soldier Flies (and though they are small in size, they make up for it with a hefty amount of calcium). Their shells are soft enough to make them easy to eat for bearded dragons young and old.\n2. Dubia Roaches\nOf a higher quality and nutritional value than crickets, Dubia Roaches (Blaptica dubia) and Discoid Roaches (Blaberus discoidalis) are both great choices depending on what’s available. These are definitely some of the healthiest options out there!\nCrickets definitely aren’t the best option – there’s nothing bad about them, they just aren’t the most nutritious insect to feed you bearded dragon. That said, crickets are readily available (at almost any pet store) and can made more nutritious by dusting them with calcium and multivitamins.\n4. Silk Worms\nThe nutritional benefits of the Silk Worm can be helpful for bearded dragons of any age. They are packed full of protein and low in unhealthy fats. It is also recommended that you feed your dragon gravid (pregnant) female worms when available for extra nourishment.\nVarious types of superworm include Hornworms, Butterworms, and Silk Worms (also listed above). Juvenile to adult bearded dragons can be fed any kind of superworm and enjoy them as treats with their meals.\nOther Common (and safe) Worm Options\nWax worms, King worms, and earthworms also make great snacks for your Bearded Dragon. They may not pack as much of a nutritional punch, but dragons love them and they make for a great occasional snack.\nFeeding the Proper Greens\nProviding daily salads full of dark, leafy greens is important in maintaining the health of your bearded dragon. Some recommendations for the most nutritional types of greens are\n- Mustard Greens\n- Collard Greens\n- Dandelion Greens\n- Turnip Greens\n- Escarole (Chicory Greens\n- Coriander (occasionally)\nYou can also include Romaine Lettuce if you like, though only sparingly, as Romaine is limited in its nutritional value. For a healthy supplement, sprinkle some Repashy’s Superveggie (the perfect dietary supplement for omnivores like your bearded dragon) over the salad and the other vegetables that accompany it.\nIn addition to the daily salads, your bearded dragon should also have a wide variety of vegetables made available to them every day. For younger bearded dragons, make sure that you chop up any vegetable really good – otherwise, you risk blocking up your pet.\nOlder bearded dragons should be able to handle slightly bigger chunks. Some of the best choices are green beans, acorn squash, butternut squash, yucca roots, konnayu (purple yams), and red peppers. With a sprinkling of Repashy’s Superveggie, any of the listed veggies will provide the perfect nourishment for your growing bearded dragon.\nOther Options (Raw Only): There are several other common options out there, but some must specifically be served raw to be safest for your dragon to eat. These include bell peppers, shaved carrots, cabbage, lentils, zucchini, asparagus, and okra. You may also consider leaving any yams raw when you feed your bearded dragon as the texture might be preferable this way.\nFruits – Yes or No?\nIt is important to note that many fruits are high in natural sugars, so it is recommended that you only include fruits in your bearded dragon’s diet as an occasional treat (or for training purposes).\nDo: It is safe to feed your dragon mango, papaya, grapes, or blueberries as a treat or reward, as long as it’s not too often and you don’t give them too many. It is also safe to include the occasional slice of melon or banana as a fruity treat. Apples, cranberries, strawberries, and watermelon are also safe options, should you wish to vary your bearded dragon’s treats from time to time.\nDon’t: Oranges, Lemons, Limes, and Tomatoes are highly acidic and, along with other citrus fruits (or even rhubarb), are not recommended as a staple of your dragon’s diet. Avocadoes are too high in fat and are technically toxic in nature, so it is not recommended that you feed your dragon these fruits, either.\nFoods To Avoid (At All Costs!)\nThere are some specific foods that you should never feed you bearded dragon. Here are a few that you should at all costs:\n- Avocados: High in fat and very toxic to bearded dragons.\n- Spinach: Inhibits the binding of calcium, which can lead to deficiencies in your bearded dragon.\n- Beet Tops: Can be toxic to bearded dragons.\n- Tomatos: To acidic for bearded dragons. Can be fed in moderation, but probably best avoided.\n- Lettuce: Not the worst food on our list, but offers zero nutritional value.\n- Rhubarb: Known to be toxic to bearded dragons.\n- Acidic fruits (Lemon, Oranges, Grapefruits, etc.): Can be toxic to bearded dragons.\n- Fireflies: Extremely toxic to bearded dragons! Avoid at all costs.\n- Wild-caught insects: Wild-caught insects can very easily infect your bearded dragon with parasites and diseases. You should never feed your beardie anything that you catch yourself.\nHow Often Should Bearded Dragons Eat?\nAs babies, bearded dragons will often eat multiple meals a day at pretty regular intervals. They tend eat less often as they age, sometimes choosing to eat only once every couple days. This is perfectly normal and nothing to worry about – though it is suggested that you make fresh salads available to them every day, should they need a little snack.\nTo summarize the image above, here is a rough guide for insect feeding intervals based on your bearded dragon’s age:\n- 1-4 Months Old: 3 feedings per day\n- 4-12 Months Old: 2 feedings per day\n- 12-20 Months Old: 1 feeding per day\n- 20+ Months Old: 1 feeding every other day\nOnce your bearded dragon is over two years old, you can even reduce feedings down to every 2 days. Once again, this is purely a rough guide – if your beardie really likes to eat, you can still feed every day/every other day (even in older age).\nIt is also important to keep in mind that dragons can be highly sensitive to changes in their diet, so as you’re shifting from the younger dragon’s diet to a diet more suitable for an older dragon, your dragon may not eat for a couple days. This isn’t detrimental to their health in any way, and can actually be quite common. If this is the case for your dragon, experts recommend giving your dragon a warm soak.\nAvoided Food-Related Health Issues\nMuch like the body of a human, the body of a bearded dragon can suffer from many diseases and ailments (such as liver failure, gout, cancer, or even periodontitis aka gum disease). Keeping their diets rich in nutritious alkaline foods (fresh greens and vegetables) will help keep your bearded dragon in optimal health.\nAs we have stated a few times above, it is also be beneficial to include a calcium supplement and a multivitamin to their meals – these can help strengthen their skeletal structure, prevent Metabolic Bone Disease, and improve their nervous system.\nBearded Dragons tend to be aggressive eaters and may consume dangerous/large objects, so it is your responsibility to make sure any potentially hazardous materials are kept out of reach of your pet.\nThe Importance of Calcium and Multivitamin Supplements\nIt is equally important to supplement your dragon’s diet as it is to get their diet right in the first place. Sprinkling their insects with a high quality calcium supplement such as Repashy’s SuperCal HyD or Nutrobal will be beneficial to their diets.\nYou may find that lightly misting the insects with water first will help the powder stick a little better. Including a multivitamin like Repashy’s Supervite a few times a week will provide the perfect nutritional boost to their meals.\nSoaking Your Bearded Dragon\nSoaking your dragon in warm water for just 10-15 minutes will help them to stay hydrated and relaxed. In addition, these quick soaks will also keep their digestive system running smoothly and help relieve constipation.\nRemember – Dry your bearded dragon thoroughly when they’ve finished their soak. Not drying your bearded dragon thoroughly can mess with humidity levels in your tank (which is something that you definitely want to avoid).\nHelpful Feeding Tips\nGetting your Bearded Dragon to eat isn’t always easy! Even if you have the perfect foods prepared, there’s a chance that your bearded dragon may be a bit stubborn. Here are some great feeding tips to keep in mind:\n1. Dizzy the insects before feeding\nWhen feeding baby bearded dragons, it is recommended that you dizzy the insects before feeding them to your pet. To do this, just recycle an old container (maybe a tubular cardboard oatmeal box or a large Ziploc baggie), toss the live feeder insects into this container with a dusting of calcium powder, and give them a little shake for a few seconds.\nKeep in mind that the insects should still be alive when you feed them to your dragon (so try not to shake them too hard).\nThis practice makes the insects much easier to catch, which can be very helpful for clumsy baby beardies.\n2. Control the portions\nAlso important when feeding your bearded dragon their insects is to limit the portions of insects. Only feed as much as your bearded dragon can eat in 5-10 minutes\nAt meal time, your bearded dragon should eat all live insects in a single setting. Don’t let a ton of insects swarm around your tank!\n3. Prepare foods correctly\nThere are some fruits and veggies that will require a little extra preparation before being fed to your bearded dragon. Taking the peels off vegetables or cutting them down into more manageable bite-sized pieces should make them safer and easier to eat. You really only need to do this if the peels are really tough/hard to digest.\n4. Moderation and diversification are key\nWhen building your bearded dragon’s meal plan, it is also important to remember to feed them everything in moderation. Rather than offering the same salad mix every single day, try alternating with an assortment of different veggies every couple weeks. This will get them used to eating different foods and help them adapt to other changes within their tank.\nAlso, in diversifying their vegetables, you will help your bearded dragon receive a good balance of all the necessary vitamins. Too much of one vegetable and not enough of certain others might lead to hyper or hypo-vitaminosis (which is a condition that occurs when dragons get too many or too few vitamins). Rotating their veggies will keep their vitamin intake at the right levels.\n5. Make greens more appealing\nAnother good feeding practice is keeping your bearded dragon’s meals full of fresh greens. Dried, bagged, or preserved foods lack the necessary nourishment to satisfy the dietary needs of your pet.\nIt is key that your greens are fresh – fresh and organic produce will help your bearded dragon receive the best percentage and concentration of essential vitamins, minerals, and key nutrients that are required to build up both their immune system (for fighting off infections) and their digestive system (which will effectively eliminate waste). The failure of either of these systems could result in disease, parasites, or other deteriorating health conditions (so it’s vital that you help your bearded dragon keep them up and running).\nTo make sure salads are appealing to your dragon, it can be a good idea to add different colors and textures to the mix. Fresh chopped green beans, Konnayu (purple yams), or shaved butternut squash can provide a colorful assortment and varied texture to their meal. If your dragon hasn’t been eating, it is also okay to drop in a few worms to coax your pet back into a more regularly timed feeding schedule.\nThings To Know About Feeder Insects\nEvery variety of feeder insects requires different care and handling. Consulting with your supplier will give you the opportunity to learn all you need to know about important aspects of the insects’ care (like the storage requirements of whichever type you’re working with). It is also necessary that you feed your bearded dragon live, “gut loaded” feeder insects.\n“Gut-loading” is the technical term referring to the process of feeding your insects in a healthy way so that your dragon can reap the dietary benefits (since your bearded dragon is essentially eating whatever your feeder insects are eating). Make sure to ask about the supplier of your feeder insects and the source of the food they have been/are eating.\nDepending on where you and your bearded dragon are located, the availability for specific types of insects can vary widely.\nIn Florida, for example, Dubia Roaches illegal to own. In Canada, you’ll run into the same problem, though both Canada and Florida should still allow the purchase of Discoid Roaches (a good alternative).\nTo find out more about what is offered in your community, just check with your local breeder or a reptile store in the area and ask if there are any restrictions or available alternatives that you should be aware of.\nCommon Feeding Mistakes\nHere are a few common mistakes that owners make when feeding their new bearded dragon:\nOnly Feeding Crickets\nWhile it is very common among bearded dragon owners to feed their pets crickets as a staple insect, they usually aren’t the absolute best option. Uneaten crickets can be loud, a bit smelly, and can potentially try to bite/chew on your bearded dragon if left in the cage.\nRoaches are the nutritionally superior option and usually far less likely to carry parasites (a single roach nymph is the equivalent of two crickets). Crickets should only be used as a staple if nothing else is available to you for the time being (or if your dragon is an especially picky eater).\nOnly Feeding Mealworms\nAnother common mistake is feeding bearded dragons mealworms as their staple insect. These worms are simply empty calories for your bearded dragon and can be difficult to digest with their hard outer shells. Overall, mealworms are not worth the time or effort it would take your bearded dragon to consume them.\nUsing The Wrong Substrate\nBearded dragons can accidentally ingest some of the substrate around the food they’re eating. It is more often a problem for younger bearded dragons, so it is not recommended that owners feed their smaller dragons in tanks with loose substrate (like sand).\nIf consumed, substrate can cause a build-up inside your pet because it can’t be digested (otherwise known as impaction). This often leads to a blockage that can be fatal. Older bearded dragons are usually more accurate eaters, but it is still recommended to use a safe substrate.']	['<urn:uuid:3b092688-d933-4545-aa04-f5a93d73d4ed>', '<urn:uuid:d313b761-6383-440b-b1ca-7be9cf8c56c1>']	factoid	direct	long-search-query	similar-to-document	comparison	novice	2025-05-13T03:20:41.944655	10	49	5042
64	For analyzing complex systems, why pick computer simulation over observation?	Computer simulations are chosen over direct observation because they allow study of processes that cannot be fully observed, such as galaxy collisions that occur over extremely long time periods, or the formation of early Universe structures. Additionally, they can extend sparse ocean observations in space and time, and help investigate future scenarios like climate change impacts that cannot be directly observed. Simulations also allow testing multiple scenarios with different conditions, though they require substantial computing resources.	['What is a numerical simulation?\nIn astrophysics most processes can be described by a set of equations. A simple example are the equations of motion, which describe how a body moves under the effect of forces that produce acceleration. Not all equations are easy to solve analytically, and some of them don’t even have analytical solutions, in which case we have to solve them numerically. To add more complications sometimes there are so many processes involved that is really hard to handle all equations. Here is where we appeal to numerical simulations. In simple words, a numerical simulation is a computational program that given an initial condition is able to solve the equations governing the problem and calculate the evolution of the system.\nWhy use simulations?\nIn principle the definition of numerical simulations may sound not too difficult, but in reality a system is determined by many equations that need to be solved at the same time. Things get more complicated if we want a better resolution and we use too many particles or too many grids. In practice super computers and multiple processors are needed to do a detailed simulation. The power of simulations resides on that they allow us to study processes that we are unable to observe. Reasons for that are many. For example some processes such as collision of galaxies take a long time and we are not able to watch the whole process with telescopes. Another interesting example is the formation of the first structures in the Universe. A very famous simulation of large scale structure is the Millenium simulation. In the context of shocks, give us insights on how shocks are formed, for example through AGN feedback or Supernovae explosions\nThere are two main techniques to develop a code:\n- Adaptive Mesh Refinement (AMR): Based in an Eulerian hydrodynamics method for solving equations, it consists of fixed grids sampling the spatial domain of the simulation. The properties of the fluid are stored in each grid according to their position in space. Grids can be subdivided in subgrids in order to get better resolution. This refinement technique can depend on various factors (e.g. reaching a density threshold) but the most important is the Truelove condition which says that the Jeans mass has to be resolved by at least four cells to avoid numerical fragmentation. In AMR codes the Euler equations are usually solved using finite-difference methods, but recent codes also include finite-volume and finite-element methods. Examples of AMR codes are Enzo (webpage,paper), Flash (webpage,paper), Ramses (webpage,paper), Orion (webpage), Athena (webpage,paper), Castro (webpage,paper)\n- Smoothed Particle Hydrodynamics (SPH): Based in an Lagrangian hydrodynamics method for solving equations, it consists in particles sampling the fluid. That means that particles move with the fluid, and hence their Lagrangian nature. Since there is only a limited number of particles the whole main is not covered. To extrapolate the fluid properties to regions that are not sampled by the particles a smoothing kernel is used. The resolution depends on the mass of each particles, the smaller the mass the better the resolution. Similar to the Truelove condition, in SPH the mass resolution has to be less than the Jeans mass to avoid numerical fragmentation. In SPH the fluid equations are solved based on the Euler-Lagrange equations . Examples of SPH codes are Gadget (webpage,paper), Gasoline (paper), Hydra (paper)\nRecently a third method has been developed called Moving Mesh, which is a mixture of AMR and SPH. We will not give details about the code since it is still private, but if you are curious you can read the paper that describes the code.', 'What are numerical models?\nNumerical ocean and climate models are physical equations (such as conservation of energy, mass, momentum, …) that describe the state of the ocean or the climate system. Changes of different variables (such as temperature, salinity, pressure, etc.) on a three-dimensional grid are calculated by supercomputers from time step to time step. Imagine the grid like pixels on a digital photo. Models provide a simplified image of reality. Nevertheless, they provide valuable insights about the impacts of natural as well as human influences on the climate system, and help to understand the underlying processes. For instance, model simulations have proven that global warming of the last decades is caused by human emissions of greenhouse gases.\nApplications of models\n- Simulating future changes\nThe application of models to simulate the future impacts of climate change is crucially important for society. Models can provide insights about sea level rise, about changes of the ocean currents, and impacts on marine ecosystems. Therefore, models are essential tools to develop adaptation strategies.\n- Understanding the ocean and climate system\nModels can be used to investigate processes and interactions in the ocean and climate system, as well as their causes and effects. Examples are the influx of meltwater of the Greenland ice sheet and the effect on the ocean currents, regional impacts of fluctuations of the ocean currents, or the role of changing greenhouse gas emissions for sea level rise.\n- Extending observations in space and time\nOcean observations are complex and expensive and therefore sparse. The Atlantic circulation is monitored since the 1990s at a few key areas with moored sensors. Models can extend the measured data in space and time, and therefore contribute to interpret the observations. This is how changes in the ocean over the last decades were detected.\n- Improving the reliability of models\nThe quality of model simulations can be tested and improved by modelling past conditions of the ocean and climate, and comparing the simulations with observational data. This is known as hindcasting. Only if a model provides simulations of past events that resemble reality, it can be assumed that the model will also give reliable projections of the future.\nHow does an ocean model work?\n1. An ocean model consists of physical equations of:\n- ocean-atmosphere and ocean-land interactions (such as incoming solar radiation and outgoing radiated heat, evaporation and precipitation, river runoff, wind generated waves and currents, …)\n- movements of the ocean (such as horizontal currents and vertical convection)\n- three-dimensional processes of mixing and dissipation ranging in scale from molecules to entire ocean basins\n2. Boundary conditions at the ocean margins:\nThe model equations are solvable inside the ocean margins. Boundary conditions determine how the ocean interacts with the environment outside its margins. The margins are:\n- ocean basin geometry\n- bottom topography\n- ocean surface as the interface to the atmosphere\n3. Initial conditions of the ocean:\nInitial values of temperature, salinity, and current velocity must be inserted into the model.\n4. Forcings changing the condition of the ocean:\nTo get to the next time step, the following forcings are applied to the initial conditions of the ocean:\n- Shortwave and longwave radiation as well as heat exchange between ocean and atmosphere at the ocean surface change the water temperature\n- Evaporation and precipitation at the ocean surface change the salinity\n- Land surface runoff (e.g. melt water, river water, rain water) at the margins changes the salinity\n- Wind moves surface currents of the ocean\n- Tides move the ocean\nThe newly calculated conditions of the ocean become the initial conditions for the following time step.\nThe climate system consists of five components interacting with each other:\n- hydrosphere (oceans, rivers, lakes)\n- cryosphere (all frozen components of the earth system)\n- land surface\n- biosphere (the space on planet earth that is inhabited by organisms)\nTo model the climate system, several component models are coupled with each other – typically an atmosphere model, an ocean model, a land model and a sea ice model.\nModels are generally used to simulate the future climate until 2100. However, the future state of the climate is largely dependent on the development of human greenhouse gas emissions. Climate projections of the Intergovernmental Panel on Climate Change (IPCC) therefore use model scenarios that include emissions and concentrations of greenhouse gases, aerosols and chemically active gases, as well as land use/land cover. These scenarios are called Representative Concentration Pathways – RCPs. They range from strong reductions of greenhouse gas emissions (RCP2.6) to continuously increasing emissions to the end of the 21st century (RCP8.5). The following projections of global warming were published in the Special Report on the Ocean and Cryosphere:\n|Scenario||2031 – 2050||2081 – 2100|\n|RCP2.6||1.6 (1.1 – 2.0)||1.6 (0.9 – 2.4)|\n|RCP4.5||1.7 (1.3 – 2.2)||2.5 (1.7 – 3.3)|\n|RCP6.0||1.6 (1.2 – 2.0)||2.9 (2.0 – 3.8)|\n|RCP8.5||2.0 (1.5 – 2.4)||4.3 (3.2 – 5.4)|\nLimitations of models\nSimulations of modern climate models require substantial supercomputing resources. Due to limitations in those resources, compromises must be made in three main areas:\n1. Model resolution\nThe spatial resolution of a model is the size of its grid cells, measured in degrees of latitude and longitude or in kilometers. The temporal resolution of a model is the time step. High resolution models provide much more detailed information and more realistic simulations, but they require a lot more computing resources. Every halving of the grid spacing requires about ten times as many computations. Climate models used by the Intergovernmental Panel on Climate Change have a resolution of 1 – 2 degrees for the atmosphere and of 1 degree for the ocean.\nProcesses like ocean eddies or clouds are too small to be resolved in climate models. These processes are “parameterized”, meaning their effect is represented by a simplified process in the model. Parameterizations are crucial for realistic model simulations. Without parameterizations, a model ocean with a weak ocean current could locally warm up more and more through heat uptake. In the real ocean however, turbulent diffusion would dissipate the heat.\nFor more realistic regional simulations of climate change, high resolution regional models are integrated into global climate models. Through continuous development, regional models become available for more and more regions.\n2. Complexity of the climate system\nThe significance of the numerous different processes in the climate system depends on the considered time scales. On short time scales, the climate is influenced by volcanic eruptions. On time scales of days to thousand years, the ocean and the atmosphere determine the climate. On time scales of millions of years, the location of continents and the shape of ocean basins play an important role on the climate. Increasing complexity of a climate model results in higher computational costs. Therefore, some processes of the real climate system have to be omitted in a model. However, through technical advancement, climate models become increasingly more complex.\n3. Ensemble simulations\nAn individual model simulation represents just one possible pathway that the climate system could take. Therefore, small deviations in the model formulation or in the initial conditions can have huge impacts. The mean value of a multitude of model runs often fits better to observations than the result of a single model run, because errors can cancel each other out. Therefore, it is necessary to calculate the mean value of multiple model runs with slightly varying initial conditions (such as slightly different temperatures). This method is called ensemble simulation. Alternatively, a series of simulations can be carried out with different models, and the results are averaged (multi-model ensemble simulation). Both methods increase the computational costs.\nOcean model requirements to get climate change right\nFor realistic climate projections, the ocean component of a climate model has to fulfill the following requirements:\n- correct heat and carbon dioxide uptake\n- good representation of the ocean currents including the Meridional Overturning Circulation\n- vertical mixing processes and deep water formation in small, local regions comparable to observations\n- good parameterization of small scale processes that are not resolved in most climate models, such as ocean eddies\nData assimilation is a technique to combine observational data and model simulations to produce an optimal estimate of the state of a system. The observational data is used to correct the model simulations. An analogy for data assimilation is: “Driving with your eyes closed: open eyes every 10 seconds and correct trajectory” (Alan O’Neill, ESA). Data assimilation was first developed for weather forecasts. For realistic forecasts, weather models require initial conditions resembling the current atmospheric conditions as good as possible. Now, data assimilation is also used to provide the best possible initial conditions for climate models.\nFuture projections of climate\nModel projections of the new Special Report on the Ocean and Cryosphere of the Intergovernmental Panel on Climate Change reveal the risks of delayed action to reduce greenhouse gas emissions. Global warming through greenhouse gas emissions has already reached 1°C above the preindustrial level, resulting in serious consequences for people and ecosystems:\n- The oceans are warmer, more acidic, and less productive.\n- Glaciers, ice sheets and permafrost are melting.\n- Rising sea levels are causing more severe extreme events at the coasts.\nThe impact of climate change depends on the future development of greenhouse gas concentrations. The model projections show the benefits of fast and effective action toward sustainable development. More info here']	['<urn:uuid:d6a5663a-8493-4bcc-8390-30ac097bcddd>', '<urn:uuid:14cd063f-159e-44ac-a581-532b0854ae40>']	factoid	with-premise	concise-and-natural	distant-from-document	three-doc	expert	2025-05-13T03:20:41.944655	10	76	2162
65	online gambling apps dangers mental health crime statistics risks	The rapid-fire nature of online betting apps enables repeated bets and chasing losses, which can lead to gambling problems. This is particularly concerning as gambling addiction is associated with serious mental health issues - 76% of pathological gamblers experience major depressive disorder, and problem gamblers have the highest suicide attempt rate (20%) among addictions. Areas with legalized gambling show 10% higher violent crime rates, and gambling addicts typically progress from losing their own money to taking money from family, friends, and eventually strangers.	['Authorized Sports activities Betting Has Began in Ohio. Now What?\nPosted by Ohio for Accountable Playing.\nSince Home Invoice 29 was signed into regulation in 2021, Ohio has been making ready for the beginning of authorized sports activities betting. With the growth of this new type of playing all through the state, it’s extra vital than ever to unfold accountable playing messages and sources.\nSports activities betting is already the most well-liked type of playing within the state, as a result of how straightforward it’s to entry and the pre-existing reputation of sports activities. Even earlier than legalization, sports activities betting ads already had a heavy presence throughout most televised sports activities occasions, directing viewers towards telephone apps, in-person sports activities books, and kiosks. And now that betting is authorized in Ohio, it’s simpler than ever for individuals who may by no means have gambled earlier than to attempt betting for the primary time, leading to extra folks fighting an issue with playing.\nThe rapid-fire nature of on-line sports activities betting additionally presents new challenges and dangers. With a majority of betting anticipated to happen by way of telephone apps and web sites, it’s simpler to put repeated bets, which might result in a sample of chasing losses and an issue with playing. Micro-bets additionally let gamblers wager on small components of the sport because it unfolds in actual time, which might result in the same cycle of repeated betting that may put folks in danger.\nWith these challenges — a bigger playing viewers and rapid-fire betting — in thoughts, Ohio accountable playing advocates have been planning for this second. Accountable playing organizations throughout the state are providing playing dependancy remedy, giving assist to those who want it, and spreading consciousness of accountable playing sources. Right here’s the way you and your group can get entangled:\nShare the Pause Earlier than You Play PSA & Sources\nIn anticipation of the beginning of authorized sports activities betting, Earlier than You Guess has launched a accountable playing sub-campaign targeted on sports activities betting referred to as Pause Earlier than You Play. The marketing campaign encourages everybody who may have interaction in sports activities betting to take a pause earlier than they play and set limits, acknowledge the danger, and know when to cease. The marketing campaign contains shareable and customizable digital belongings, fliers, and a video PSA to be used by area people teams.\nElevate Consciousness of the Downside Playing Helpline\nSports activities betting-related calls to Ohio’s Downside Playing Helpline elevated even earlier than the beginning of authorized sports activities betting, and the necessity is even better now that sports activities betting has formally kicked off. The Downside Playing Helpline is obtainable to those that are anxious about their very own sports activities betting and playing habits, and people who are involved about somebody they know. Educated, understanding specialists are standing by to reply the free and confidential Downside Playing Helpline 24/7 at 1-800-589-9966 or by texting 4HOPE to 741741. An awareness-raising toolkit of customizable and shareable social media posts, posters, fliers, and different belongings are additionally accessible to group teams.\nImprove Entry to Downside Playing Assist In Your Neighborhood\nOhio presents plenty of methods for individuals who may be fighting an issue with playing to get assist, together with the Downside Playing Helpline, on-line listings for remedy and peer help packages, and a two-minute quiz to assist gauge if somebody is in danger for an issue with playing. However different playing dependancy and drawback playing help organizations have a task too. There’s a nice want for individuals who will help those that may be struggling, on knowledgeable and volunteer foundation. Get entangled in your area people, and you can also have a task in decreasing the unfavourable impacts of playing in Ohio.\nDo you assume you or a liked one might have an issue with playing? Confidential and non-judgmental help is obtainable 24/7 by calling the free Downside Playing Helpline at 1-800-589-9966 or texting 4HOPE to 741741.', 'Problem & Disordered Gambling Initiative\nFor the general public:\nIf you or someone you know has a problem with gambling, please call the hotline at any of the following numbers:\nSymptoms of Problem and Disordered Gambling\n- Increase in the frequency and the amount of money gambled\n- The person gambles for longer periods of time with more money than originally planned\n- A large amount of time is spent gambling or obtaining money with which to gamble\n- The person gambles at the expense of personal or family time\n- The person will begin to borrow money to gamble, possibly taking out secret loans or maximizing credit cards\n- The person will begin “chasing” or have the urgent need to keep gambling, often with larger bets or taking of greater risks in order to make up for a loss or series of losses\n- The person spends the majority of their free time thinking about gambling\n- The person feels a sense of euphoria, arousal, or a high from gambling\n- The person uses gambling as a way to cope with unpleasant feelings\n- The person has frequent mood swings: higher moods when winning; lower moods when losing\n- The person brags about wins but omits their losses\n- The person continues to gamble despite negative consequences such as large losses, work or family problems caused by gambling\n- The person lies or has secretive behavior to cover up extent of their gambling\n- According to the National Council on Problem Gambling an estimated four percent of adults (8 million) in the United States either meet the criteria for disordered gambling, or would be considered problem gamblers.\n- The vast majority of gambling-related crimes are non-violent; embezzlement, check forgery, stealing credit cards, fencing stolen goods, tax evasion, insurance fraud, employee theft and fraud are common gambling-related crimes.\n- A major depressive disorder is likely to occur in 76 percent of pathological gamblers (Unwin Davis & Leeuw, 2000).\n- Problem gamblers who present for care have the highest suicide rate among addictions. Two of every ten gamblers (20%) attempt.\n- Violent crimes are 10 percent higher where legalized gambling exists.\n- During the first 15 years that Atlantic City had casinos, violent crime rose by almost 200 percent, and larceny increased 481percent.\n- Gambling addicts tend to progress from losing all their own money, then losing all they can get from their family, and friends, and finally to taking or stealing money from strangers.\n- Data gathered in Philadelphia in 2013 indicated a 50% prevalence of problem gamblers amongst the homeless population.\n- The percent of high school students who have ever gambled (87percent) exceeds the percent that have used alcohol or drugs (67percent).\n- Students who gamble excessively are more likely to abuse substances and vice versa.\n- The rate of problem gambling among high school students significantly exceeds the rate for adults.\n- Age 10 is the average age at which many adult problem gamblers had their first contact with gambling.\n- Four to eight percent of adolescents presently have a serious gambling problem. Another 10 percent to 14 percent of adolescents are at risk for developing a serious gambling problem.\n- A recent study found that more than 50 percent of young people who gamble reported problems like over-spending. Teens record that they can win/lose as much as $150 to $200 a night.\n- A recent nationwide study estimated 2.9 million young people are gambling by playing cards on a weekly basis.\n- 84 percent of parents do not object to their children gambling.\n- 61 percent of teens who gamble do with their parent’s permission.\n- Children of problem gamblers have been shown to have higher levels of use for tobacco, alcohol, drug use, and overeating than do their classroom peers (Gupta & Derevensky, 1997).\nOther Helpful Links\nIf you would like more information please contact Thomas E. Owens at Thomas.E.Owens@phila.gov.\n- Leadership Team\n- Community Behavioral Health (CBH)\n- Communications Office\n- Evidence-based Practice and Innovation Center (EPIC)\n- Fiscal Division\n- Intellectual disAbility Services (IDS)\n- Management Services Division\n- Network Improvement and Accountability Collaborative (NIAC)\n- Office of Addiction Services\n- Behavioral Health Special Initiative (BHSI)\n- Provider Development & Transformation Initiatives\n- BHSI Intensive Case Management Services\n- Philadelphia Prevention Partnership\n- Recovery House Initiative\n- Forensic Intensive Recovery/ Justice Addiction Treatment Initiatives\n- Problem & Pathological Gambling Initiative\n- Prevention Services\n- Drug Free Coalitions\n- Student Assistance Program (SAP) Services\n- Office of Mental Health (OMH)\n- Office of the Chief Information Officer\n- Office of the Chief Medical Officer\n- Strategic Planning and Innovation Division\n- Grants Opportunities\n- DBHIDS Study Tours']	['<urn:uuid:579bc1ef-b747-4667-b43a-57ad051a9656>', '<urn:uuid:e502309e-b0ec-44de-9e6a-a8faa3834a9b>']	factoid	with-premise	long-search-query	distant-from-document	multi-aspect	novice	2025-05-13T03:20:41.944655	9	83	1449
66	rain race control mental preparation techniques	In wet race conditions, like Senna's 1985 Portuguese GP victory where he led in treacherous conditions, success requires both physical skill and mental preparation. Top competitors use specific techniques including deliberate breathing control, breaking challenges into manageable pieces, and maintaining positive self-talk to stay focused and perform at their best even in difficult conditions.	"['Senna’s greatest race was in a Lotus\nRacing his Lotus type 97T in the 1985 Portuguese GP Ayrton Senna scored his first ever Grand Prix victory. Autosport magazine’s recent article ‘Ayrton Senna’s 10 greatest Formula 1 races’ selected this extraordinary performance as number 1, out of a predictably stellar Top 10.\nVictorious Ayrton being greeted by an ecstatic Team Lotus crew, dancing in the rain\nWe cannot disagree with Autosports decision, especially as Ayrton himself considered this win to be his greatest ever race. (8 years later it was suggested to Ayrton that the European GP at Donington was his greatest performance. Ayrton snorted in reply: “No way! I had traction control. O.K., I didn’t make any real mistakes, but the car was so much easier to drive. It was a good win, but compared to Estoril ’85, it was nothing….’)\nLotus featured twice in the Top 10, with Ayrton’s dramatically close victory at the 1986 Spanish GP racing 98T/3 – beating Nigel Mansell by just 0.014 seconds – coming in at number 9. (Slightly disappointing that neither of Ayrton’s wins in the active suspension type 99T made the cut.)\nFollow this link to read the article in full http://classicplus.autosport.com/premium/feature/9071/?_ga=2.174431138.1054140197.1559055976-1054995992.1559055976\nThe Autosport text relating to Estoril is as follows:\nThis race was a special one for Senna personally. Not only was it his first F1 world championship victory, it was scored in brilliant style in terrible conditions.\nHis 1993 European GP performance is more famous, but the win at Estoril was secured without traction control, with a difficult turbocharged engine, and there were more potential winners in the field. Only three teams won races in 1993, but five did so in 1985. And the 1985 Portuguese GP was only Senna\'s 16th F1 start.\nSenna led from pole on an appallingly wet track, completing the first lap 2.7s clear of team-mate Elio de Angelis. The two Lotuses pulled away, with Senna edging clear of de Angelis, before Prost\'s McLaren moved forward to challenge for second.\nJust before half-distance, the rain got so bad that even Senna - now 37s ahead - started gesticulating that the race should be stopped. It wasn\'t and Prost, who was still trying to pass de Angelis, simply aquaplaned into retirement on the main start/finish straight.\n""The big danger was that conditions changed all the time,"" said Senna, who admitted to surviving one grassy moment of his own. ""It was difficult even to keep the car in a straight line sometimes and for sure the race should have been stopped.\n""It was much worse than Monaco last year. Once I nearly spun in front of the pits, like Prost, and I was lucky to stay on the road.""\nOnly nine of the 26 starters were classified, around half of the retirements due to spins or crashes, and Senna lapped everyone except Alboreto\'s Ferrari, which finished 1m03s behind the Lotus. Senna\'s fastest lap was 0.7s quicker than anyone else\'s.\n""Senna\'s victory will be remembered as a classic,"" wrote Roebuck. ""It was a mesmeric performance. Without Senna, a lot of the drivers would have impressed with their ability and courage: as it was, they seemed inept, tentative.\n""Just occasionally comes a race when one driver makes the rest look ordinary, and this was one such. He was in a different class right from the green light.""\nClassic Team Lotus is proud to maintain 97T/2 – the race winning chassis - in the Works Collection, in running condition and in Estoril spec, even down to the EF4 specification Renault Turbo engine. Back in 1985, on the famous day, Chris Dinnage was number one mechanic on the car. Now, as Classic Team Lotus Team Manager, Chris gets to drive her; always a special moment for Chris and the team.', 'Mental Training Techniques\nby Joann Dahlkoetter, Ph.D.\nEven the finest competitive athletes occasionally find themselves struggling with negative attitudes, or becoming too focused on physical pain during training or racing. They strive, like the rest of us, to keep moving forward in spite of the negative beliefs and internal chatter that goes on inside the mind as they attempt to challenge their current limits. Their distinguishing quality, however, is in their highly refined skill at managing and controlling that energy. Top competitors have developed this ability to relax, to remain positive and focused even under tremendous pressure and physical challenge.\nPicture the scene at the Atlanta Olympics during the men\'s 100-meter finals. The world\'s top sprinters were subjected to immense pressure. At that moment, the athletes, who had trained for years, are primed to render their best performances, but they are met with a continual string of mishaps and distractions. They only have 10 seconds to give every ounce of anaerobic energy their bodies can produce, but three false starts begin to drain the strength in their legs, and for some the dream starts to drift away. Linford Christie makes his second false start and protests his disqualification in a lengthy tantrum with the judges and then begins parading around the track, causing 100,000 confused fans to boo and/or cheer. You see the growing frustration of the racers: anxious, angry, pacing back and forth, wondering how much longer this circus will go on. They\'re thinking: ""Which sprint will be the real one that we actually get to finish; the one that determines the gold medal and, perhaps, my future?""\nOne athlete was not pacing; he didn\'t appear at all disturbed by the whole fiasco. The camera flashes on Donavan Bailey, who was sitting calmly, smiling, and appeared to be meditating. He was not wasting time worrying about things he could not control. He was conserving energy and building inner strength while the others were depleting their resources. Sure enough, when the final sprint began, Donavan Bailey was ready, using the whole sequence of events to his advantage. He shot out of the starting blocks like a bullet and ran 9.84, setting a world record.\nHe had turned all of the distractions and external negative energy into the best possible outcome. No matter what your level of training is, or how refined your athletic skills become, you will inevitably encounter some training or racing situations that you perceive as physically painful or mentally challenging. The key is to recognize them early and to develop strong mental skills with which to intervene. First let\'s explore some primary warning signals:\nTypical Signs of Negative Energy or Pain:\n-Feeling anxious or fearful\n-Developing tunnel vision\n-Difficulty concentrating or thinking clearly\n-Diminished emotional control\n-Self-defeating beliefs and critical thoughts dominate the mind\n-Accelerated heart rate, with short, shallow breathing\n-General aching, or body pain\n-Legs or arms feeling weak and rubbery\n-Muscles becoming tense or cramped\n-Events appear in slow motion, or at an accelerated rate\nEveryone has probably experienced a few of these symptoms at some point during their training or competition. With regular practice and awareness, you can develop the ability to manage pain and let go of negative energy more effectively. You can control how deeply you feel things, and how long feelings and moods last. You can learn to re-direct negative emotions to more positive images and change your focus from physical or mental discomfort to the intensity and enjoyment of your sport.\nWhen managing pain, you need to first distinguish two different types: bad pain and good pain.\nBad pain can be potentially injurious. It is often a sharp pain in a joint area, like the knee, hip, ankle or back. If it persists, it should be checked out by a health professional.\nGood pain is the type that builds strength while not doing physical damage. It is the feeling of heart, lungs and muscles working hard and expanding their capacity. This is the type of discomfort you can work through using your mental training techniques.\nTools for Handling ""Good Pain"" and Bad Energy\n1. Relax mentally and physically.\nDeliberately slow down and deepen your breathing. This will help your muscles let go and you can relax through the pain. Say to yourself:\n-""I\'m breathing in inner strength; I\'m breathing out negative thoughts.""\n-""I\'m becoming more relaxed with each step.""\n2. Break the experience down into small, more manageable pieces.\nIf you\'re doing the Ironman, don\'t think of getting to the finish line from the gun. That\'s much too far away. Just say to yourself:\n-""I\'m now focusing on swimming to the turn-around point.""\n-""Just get to the first aid station on the cycling leg.""\n-""I\'ll hold this pace one more mile, then see how I feel.""\n3.Use the pain as feedback.\nYou can register it not as pain but as effort level. Say to yourself:\n-""Now I know exactly how hard I\'m working; I know how this pace feels.""\n-""My body is doing what it should be doing.""\n-""This is how I should be feeling in order to improve and go faster.""\n4. Redefine the pain as just a sensation.\nSay to yourself:\n-""Oh, I have felt this sensation before; this is familiar; I can handle it again.""\n-""This feeling is connected to doing my best and being focused.""\n-""Last time I felt like this I did a personal best.""\n-""I\'m experiencing the same sensations in this race that I have practiced in my training.""\n5. Put your pain in another context.\nDistance yourself from the sensation so the relationship you have to the pain can change. Imagine being an external observer watching yourself doing your sport. View yourself from a camera lens; you can zoom in or zoom out to distance yourself and make the discomfort seem less intense.\n6. Embrace the pain.\nRather than avoid the pain, you can draw it closer. Say to yourself:\n-""If I just hold on to this feeling a little longer, I can perform the best I ever have.""\n-""I am learning to enjoy this feeling of intensity; it helps me focus.""\nBe fully in the here and now, completely aware of your body and the task at hand. Do a body scan every few minutes to assess your form and technique. Ask yourself these questions: ""How are my legs feeling; what is my turnover rate?"" First contract and then relax any problem muscle groups.\nGo somewhere else in your mind. Do this when you are not at a critical point on the course where you need full attention. Imagine that you are swimming with dolphins or soaring like a bird. Visualize yourself doing another sport that you enjoy.\n9. Develop a self-chant or a mantra.\nCreate a simple set of phrases or words that you repeat to yourself to help you stay focused and prevent negative thoughts from entering. You can say:\n-""Smooth, easy, efficient.""\n-""I believe in myself; I am well prepared for this race.""\n-Count your breaths or footsteps.\n10. Create a sense of fun and enjoyment.\nRemind yourself of how much you enjoy doing your activity. If you can come from this perspective, the negative energy will quickly diminish. Say to yourself:\n-""I am doing exactly what I want to be doing.""\n-""My body is getting stronger and faster every moment.""\n-""I am in my element.""\nUse these tools regularly to effectively work through the tough spots in your training and racing, and challenge yourself to truly reach your potential.']"	['<urn:uuid:2f1414aa-a875-47ad-b8f6-8d1fcfdf0330>', '<urn:uuid:f66c8388-ea67-4b2d-ae93-8ebb55071f29>']	factoid	direct	short-search-query	similar-to-document	multi-aspect	expert	2025-05-13T03:20:41.944655	6	54	1880
67	vegas casinos gdpr data protection rules comparison house edge customer rights	There's an interesting parallel between casino odds protection and data privacy regulations. In American Roulette, the house maintains an edge through structural features like the zero and double zero, giving them control over probability outcomes. Similarly, data protection regulations like GDPR give organizations specific controls while protecting customer rights. Under GDPR, businesses must be transparent about data collection, minimize data collection to only what's necessary, and maintain security measures - just as casinos have strict controls over their odds systems. The regulations give customers specific rights over their personal information, including the right to know how their data is collected and used, similar to how casino odds must be transparent to players. Both systems involve careful balance between organizational control and customer protection.	['Probability Effect: “And may the odds be ever in your favor”\nLas Vegas is the city of lights and fun, but it is also the city of odds. Every game played has a set of probabilities describing the odds of the house winning vs. the player. Even though Vegas was built on losers, people continue to help Vegas become bigger and better. Some may make the trek to the desert because it is a form of entertainment, or their perceived gaming skill shifts the odds in their favor. Regardless of the reasoning, people continue to give their hard-earned money to the pockets of casinos even though the odds of winning are poor. This type of behavior defies the famous Vegas slogan “What happens in Vegas stays in Vegas” and trickles into daily decision making. Many don’t understand true probability or odds due to a variety of factors, which can negatively affect their overall financial picture.\nProbability is a difficult concept so, let’s first provide a definition. Probability is “the extent to which an event is likely to occur, measured by the ratio of the favorable cases to the whole number of cases possible.” For example, if there is a die on the table, what is the probability of rolling a six on the first try? 16.7% or a one in six chance. Conversely, the probability of not rolling a six is 83.3% or a five in six chance.\nLet’s take this a step further and use a popular casino game as our example: American Roulette. Sally walks into the casino and heads to the Roulette wheel. When she gets there, she sees the past five rolls have been red. Sally has $1,000. On the next roll, should she bet on red or black? Was your first reaction black? Most people say black because it must hit at some point, right? The thought that black would come next seems logical; however, what is missed is that rolling five previous red’s is independent of hitting black on the sixth turn. These events are independent of one another, meaning rolling a red before does not affect the odds of rolling a black next – the odd’s stay the same. If Sally were to bet on red she would have a 47.4% chance of winning and the same odds would apply to black regardless of what happened in the past.\nThe belief that if something happens more frequently than normal during a given period, it will happen less frequently in the future is known as the gambler’s fallacy. Amos Tversky and Daniel Kahneman proposed the gambler’s fallacy arguing that it is a cognitive bias produced by a psychological heuristic known as the representative heuristic. When people are presented with a probabilistic decision they categorize the situation from relevant experience or localized events. This creates an issue as this heuristic will typically avoid fundamental working of the odds as we witnessed in Sally’s example. As Tversky and Kahneman state “After observing a long run of red on the roulette wheel, for example, most people erroneously believe that black is now due, presumably because the occurrence of black will result in a more representative sequence than the occurrence of an additional red.”\nLas Vegas has caught on to our bias’s and has profited handsomely, but Sin City is not the only place where decision making comes down to odds. For example, when attempting to predict future stock market performance, analysts study past data. If one were to examine the S&P 500’s returns over the past 10 years, it would indicate strong performance, but that assessment would misrepresent all of the marketplace’s intricacies over those 10 years. This would be representative bias. Another example of representative bias is justifying an investment in a company due to your loyalty of their product(s) (ex. just because someone loves their Tesla, doesn’t mean Tesla is a good investment). Our propensity to see patterns in data that doesn’t represent the true population can lead us down an irrational path. To improve financial decision making, we must recognize the prevalence of irrational decision making. When presented with probabilistic decisions, we should ask ourselves what bias we have and how is it going to impact our decision making. This is no easy task; we must force ourselves to question our understanding and decisions. If we can do this, then the odds just may be “ever in our favor”.\n In American Roulette there is a zero and a double green zero. This tilts the odds toward the house.\n A heuristic is similar to “rule of thumb” - a set of simplistic rules which govern our decision making.', 'Businesses use consumer data to understand their customers’ needs and improve relationships.\nHowever, businesses should be aware that customers trust them to keep their data safe, and year after year customers’ interest in data safety grows.\nThis growing interest has seen many customers become more intentional about the personal information they share with businesses.\nMoreover, consumers are also taking steps to understand and learn about privacy policies, consent management, and other issues related to data privacy.\nBecause of the growing awareness of customer privacy issues, organizations have to do better when it comes to data and customer privacy.\nTo help ensure your customers’ information is safe, here are a few measures your company can take.\n1. Store the Data Safely\nA crucial way of ensuring your customers’ data is safe is to store it safely.\nPoor data storage increases the risk of it being accessed by people with malicious intent. Having a modern data infrastructure is one way to ensure data safety.\nAdditionally, putting in place data security measures such as Virtual Private Network (VPN), data encryption, and two-factor authentication can help keep the data safe.\n2. Be In Full Control of Your Data\nConsumers are becoming more interested to know how online organizations such as Google and Amazon use their data. Proper control of consumer data leads to the correct utilization of the data.\nYour organization will collect lots of customer data, but not everyone should access it. The organization needs to manage the people who can access the data. This protects the data from purposeful or accidental misuse.\nControl also relates to your ability to limit users’ access to sensitive data parts. You also need to have complete control when it comes to deleting data that is no longer in use.\nTo make it easier to control the use of your data, have a modern infrastructure that makes it easier to monitor the data every time, everywhere.\n3. Adhere to your Customer Privacy\nConsumer data is powerful, and organizations may be enticed to use it maliciously.\nHowever, remember your data points represent real people and disregarding their privacy may put their lives at risk.\nOrganizations that share data with third parties should be careful to ensure that the data they share doesn’t land in the wrong hands. To protect the privacy of their customers, organizations can remove all PII from the data before sharing.\nPersonal Identifiable Information (PII) is any information that can be linked to the data owner. Some PII examples include:\n- Phone number\n- Email address\n- Passport number\n- Bank account number\n- Social media handle\n- Social security numbers\nThe use of features such as de-identifying and data masks can allow for data collaboration without exposing your customers’ identities.\nFurther, organizations should be careful about the data they share. Confidential and sensitive information can be used for all kinds of harm if it lands in the wrong hands.\nTo prevent such happenings, companies should have an infrastructure that allows for the sharing of such data without the need to copy or move it.\n4. Be More Transparent with Your Customers\nConsumer awareness is growing on the amount of data that organizations collect and how they’re using it. The result is that more consumers are concerned about the safety of their data.\nIt has become harder for customers to trust that their data will be protected and used appropriately.\nThis concern has seen even governments get involved in data privacy issues. For instance, the EU has come up with the General Data Protection Regulation to protect the use and security of consumer data.\nThe regulation requires companies located in the EU to be transparent when it comes to collecting and using consumer data.\nBeing transparent with your customers will not only help you comply with data privacy regulations, but you will also earn their trust.\n5. Adhere to Data Privacy Regulations\nCustomer data privacy is a serious issue with legal repercussions. Get familiar with the laws and regulations that pertain to data privacy and adhere to them.\nSome of the most common consumer data privacy regulations and laws are explained below:\nGeneral Data Protection Regulation (GDPR)\nThis law applies to all organizations and persons with access to private data in the EU. The law requires that you be transparent in your data collection.\nYou must also collect a minimal amount of data to serve your needs. Organizations are also expected to keep their customers’ data accurate and up to date.\nThe organization should also have proper security measures to ensure confidentiality and integrity of data and not store data once it has served its intended purpose.\nAccording to this law, data handlers are also accountable in case of any breaches.\nCalifornia Consumer Privacy Act (CCPA)\nThis law gives California citizens four rights that relate to the collection and use of their data. They have a right to know when businesses collect their data and how it’s used and shared. Individuals also have a right to delete personal data that organizations collect.\nThe residents also have a right to opt out of the sale of their data. Lastly, they have a right against discrimination if they choose to exercise the above rights.\nHealth Insurance Portability and Accountability Act (HIPAA)\nHIPAA is a law related to medical data privacy. Organizations or individuals that handle medical data are expected to adhere to the guidelines of this law. This law helps control the access and use of individuals’ medical data.\nIn closing, every organization has a legal and moral obligation to protect their customers’ data. Adhering to the above measures will help your company uphold the safety and privacy of your customers’ data.']	['<urn:uuid:983d1b3c-6663-415f-b2d0-fd712e1894e6>', '<urn:uuid:26ce9902-0e33-4cf6-993a-d2cef5553b83>']	open-ended	with-premise	long-search-query	similar-to-document	multi-aspect	expert	2025-05-13T03:20:41.944655	11	123	1718
68	napa sonoma production growth rate	The North Coast region, which includes Napa and Sonoma Valleys, saw wine grape production increase by 128% during the survey period.	['The new issue of the Journal of Wine Economics (JWE) leads off with a fascinating article by Julian M. Alston, Kate B. Fuller, James T. Lapsley and George Soleas titled “Too Much of a Good Thing? Causes and Consequences of Increases in Sugar Content of California Wine Grapes.” It’s the kind of wine economics research that makes me smile: rigorous, clever, relevant — and it even includes a poem! What could be better!\nDemand-Side Explanations: The Parker Theory\nThe puzzle that the article examines is why sugar levels (measured in degrees Brix) have risen in California, taking wine alcohol levels with them. Sugar levels in white grapes grown in California increased 12% from 1980-84 to 2005-08, for example, with the average degree Brix rising from 20.7 to 23.2. Average Brix for red grape varieties increased from 22.2 degrees Brix to 24.3. Sugar levels in Cabernet Sauvignon grapes increased from 22.8 to 25.0 degrees Brix at harvest. Higher sugar levels mean higher alcohol levels, all else being equal.\nTwo simple explanations are usually cited to explain the rising sugar/alcohol trend. The first is based on changes in demand. Robert Parker (and some other powerful wine critics) are said to prefer a certain style of wine that is riper. Sugar and alcohol levels have increased as wine growers have worked to produce the grapes that make the wines that most please the Golden Palate of Robert P. (or that otherwise appeal to changing consumer preferences).\nSupply-Side Explanations: Chateau Al Gore\nI call the second theory the “Chateau Al Gore” hypothesis because Al Gore is associated in popular culture with global climate change and that’s what this theory is about. Rising temperatures, according to this line of reasoning, produce riper grapes pushing up sugar levels, boosting alcohol.\nIt is pretty easy to line up facts to make a persuasive case for Chateau Al Gore. Temperatures as measured by a heat index have been rising in California, according to the article’s authors. Sugar and alcohol levels have increased, too. Although additional sugar may be welcome (the Parker principle), there are indications that producers would prefer lower levels. A good deal of wine in California is partially de-alcoholized, for example. Alcohol is removed from a portion of the vintage (using reverse osmosis or the spinning cone method I am told) and then the treated wine is blended back, reducing overall alcohol levels and allowing winemakers the opportunity to find the “sweet spot” alcohol level for their wines.\nSome of the de-alcoholization may be motivated by federal taxes, which increase substantially on a per-gallon basis for wines that rise above the 14% ABV level. The extra 50 cents tax per gallon may not concern the makers of expensive wines like Screaming Eagle, but it can be a significant cost factor for bulk producters and thus worth the expense of alcohol reduction. In any case, the authors find that lower-priced grapes tend to have lower average Brix readings, which is consistent with the tax hypothesis but doesn’t prove it.\nIf alcohol levels of wine have increased even after partial dealcoholization, this suggests that rising sugar levels must be unwanted and this notion is at least partially confirmed by preliminary data reported here that many wineries under-estimate alcohol levels on product labels. The authors have obtained access to data from the Liquor Control Board of Ontario (one of the largest wine merchants in the world), which show that the average stated alcohol level of California wine exported to Ontario was 12.63 percent in the sample period while the actual level was 13.35 percent. The gap is clear, but the authors suggest that more work is needed to fully understand it. I’ll be interested to read their final report.\nThe Chateau Al Gore theory seems pretty persuasive. Ceteris paribus (holding everything else constant) it makes sense that sugar and alcohol levels would rise with average vineyard temperature. The fact that winemakers work to offset the alcohol boost and maybe fudge it a bit (within legal limits) on the label suggests that this is a climate change event that they struggle to contain.\nBut ceteris is seldom really paribus in wine. Employing multi-factor regression analysis, the authors find that the rising heat index is responsible for some of the increase in sugar levels, but not all of it. Put another way, climate factors alone are not sufficient to explain the total increase in sugar and alcohol. Other factors must also be at work.\nWhich pushes us back to the demand-side Parker Theory, but in a usefully complicated way. It is important to understand how much the California wine industry has changed in the last 30 years. The type of wine produced has changed, for example, with varietal wine (Chardonnay, Cabernet Sauvignon) increasing faster than production of generic wine (“Chablis,” “Burgundy”). Varietal wines accounted for 71% of California production in 2000, according to the authors, compared to just 19% in 1985.\nThe move upmarket required different grape varieties of higher quality from different production zones. Thus while total California wine grape production rose by 60% in the survey period, the biggest increase (+185%) was in the Delta region (including the Lodi AVA) with the North Coast (including Napa and Sonoma Valleys) increasing by 128%. Wine grape production in the San Joaquin Valley rose but by a much smaller amount. The southern San Joaquin valley accounted for just 30% of California vineyard acreage in 2008 (down from 50% in 1981), although it still produced more than 60% of wine grape tonnage because of higher yields.\nSo wine grape production has increased and also shifted in terms of desired quality, price per ton, grape variety and growing location. It is perhaps not surprising that average sugar levels would change too. Much of the growth in the California wine industry has thus been associated with the demand shift towards premium and ultra-premium wines and the rising sugar levels are to some extent associated with this “grape transformation” of the American palate. Robert Parker is part of this movement although I think it would be unfair to give him all the credit or blame for the changes noted here.\nGetting to the Root of the Problem\nSo the JWE article finds evidence for both the demand-side and supply-side theories of rising sugar levels. But wait, there is more, including rootstocks (this is the “real dirt” in the title of this post).\nPhylloxera struck California starting in the mid-1980s when the supposedly Phylloxera resistant AxR#1 rootstock was found to be susceptible to this root-sucking parasite. Eventually nearly all the vines affected were grubbed up and replaced with vines grafted to different (and hopefully more resistant) rootstocks. Several winemakers have suggested to me that the new rootstocks and associated changes in viticultural practices affect grape ripening — sugar levels peak before the desired flavor profile (phenolic ripeness) has been achieved. Longer hang times are needed to get the flavors right, leaving wine growers with the problem of too much sugar and so forth.\nThe rootstock hypothesis is beyond the scope of the JWE study, but it indicates how complicated it can be to explain seemingly simple questions in wine economics and how much wine remains an agricultural product after all.\nI don’t think I’ve done justice to this research so I hope you will click on the link in the first paragraph above and read the study yourself.']	['<urn:uuid:1c8a1c15-985f-4e57-8b58-5324461f9401>']	factoid	direct	short-search-query	distant-from-document	single-doc	expert	2025-05-13T03:20:41.944655	5	21	1231
69	Which international Japanese TV show has become one of Amazon Prime Video's most-watched shows in Japan and what's the concept behind it?	The show is called 'Documental' and its concept revolves around 10 comedians who battle to make one another laugh in an elimination-style competition. It ranks high among Amazon Prime Video's most-watched shows in Japan.	"[""If there’s a perfect example of Amazon Studios’ strategy with its local-language international TV content, Japan’s “Documental” would be it.\nThe series revolves around 10 comedians who battle to make one another laugh in an elimination-style competition. James Farrell, Amazon Studios’ head of international originals, said it was a good example of an unconventional idea from a local market that took off. “Documental” ranks high among Amazon Prime Video’s most-watched shows in Japan.\n“It was just so crazy, we took a flier on it,” Farrell said Monday during his keynote address with Georgia Brown, Amazon Studios’ head of European originals, on the opening day of the Mipcom confab in Cannes, which runs through Thursday. “It’s one of our top shows there.”\nAmazon’s headlong charge into vernacular production in big territories in Europe, Asia and elsewhere was underscored when Farrell and Brown turned their keynote address into a “help wanted” ad for scripted creative executives in Italy and Spain. They went so far as to flash their own email addresses and those of other Amazon executives in the call for job candidates, to the delight of the Mipcom crowd at the Palais.\n“We’re hiring if anyone is interested,” Brown told moderator Peter White, international co-editor of Deadline. “It’s a fantastic job. Feel free to email me.”\nAmazon at present has platforms and budding infrastructure in about 20 major countries. The international outposts of Amazon get about five to 10 shots a year at original series content so they have to be selective and strategic about what they greenlight, Farrell said. “It’s not a quantity play. It’s a quality play,” he said.\nThe big five markets outside the U.S. for Amazon are the U.K., Germany, Spain, Italy and France. Farrell and Brown said they look for “white space” in each region’s content mix where they can insert distinctive twists on familiar formats, like documentary series and reality shows as well as scripted series.\nBrown made a point of disputing the myth that algorithms and data drive programming decisions at digital streaming platforms. She said it’s as much about going with your gut and realizing that an Amazon show has to be utterly unique if it hopes to compete with well-established traditional networks.\n“People talk about ‘Oh, where’s your Big Red Button of data,’ and that’s just not how we work,” said Brown, who joined Amazon in 2017 from production and distribution powerhouse Fremantle.\nThe recent success of Phoebe Waller-Bridge’s “Fleabag” and other Amazon co-productions in Britain has been a sea change for the U.K. TV industry, Brown and Farrell observed. “Fleabag” and “A Very British Scandal” proved that well-made contemporary content with a British accent travels well, in addition to the period dramas of the Victorian and Edwardian eras.\n“The key for co-productions in the U.K. is that we’re looking for shows that absolutely have their beating heart in the U.K. and in their DNA feel very British because we know we’ve got a great customer base for those shows around the world,” Brown said.\nFarrell noted that it’s not just the Brit-TV productions that gain traction in far-flung markets. “‘The Marvelous Mrs. Maisel’ is our most pirated show in China,” he noted. “We’re past the point of asking, ‘Are we going to make this a global show, are we going to make it a local show?’ Now it’s just ‘Let’s make it great.'”""]"	['<urn:uuid:e98154e4-a8d1-48c3-8a6e-ffc2492df665>']	factoid	direct	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-13T03:20:41.944655	22	34	562
70	What's the connection between Amazon's EVs and prisoner rights?	There is no connection between Amazon's EV purchases and prisoner rights. While Amazon ordered 100,000 electric delivery trucks to become carbon-neutral by 2040, and habeas corpus is a legal right allowing prisoners to challenge unlawful detention, these are completely separate and unrelated topics.	['What is an example of writ of habeas corpus?\nWhat is an example of writ of habeas corpus?\nIn the opening example, John felt he was being detained (seized) wrongfully, because he was not read his Miranda Rights. An inmate has the ability to file a habeas corpus if he or she feels the arrest, search, or seizure was conducted inappropriately.\nWhat is a good sentence for habeas corpus?\nSome 5,000 bail applications were granted, but the authorities refused to implement them, and 500 cases of habeas corpus are outstanding. Any decision is appealable on a writ of habeas corpus. They give a man a right to habeas corpus, and prevent arrest and imprisonment without trial.\nWhat is habeas corpus in your own words?\nThe literal meaning of habeas corpus is “You shall have the body”—that is, the judge must have the person charged with a crime brought into the courtroom to hear what he’s been charged with.\nWhat is writ of habeas corpus kid definition?\nHabeas corpus is a legal rule that requires a prisoner be presented in court and that the arrester prove that there is proper cause for detaining the prisoner. Put simply, it means that if you are arrested, you have the right to make the government prove to a judge that your arrest and detainment are justified.\nWhat are the grounds for habeas corpus?\n(b) A writ of habeas corpus may be prosecuted for, but not limited to, the following reasons: (1) False evidence that is substantially material or probative on the issue of guilt or punishment was introduced against a person at any hearing or trial relating to his incarceration; or (2) False physical evidence, believed …\nWhat happens when a writ of habeas corpus is granted?\nWhen a petition for a Writ of Habeas Corpus is granted, it means you are granted another day in court. You are given one last chance to prove that you are being subjected to unconstitutional conditions while incarcerated.\nWhat is habeas corpus in simple terms?\nA writ of habeas corpus is used to bring a prisoner or other detainee (e.g. institutionalized mental patient) before the court to determine if the person’s imprisonment or detention is lawful. A habeas petition proceeds as a civil action against the State agent (usually a warden) who holds the defendant in custody.\nWhat is a synonym for habeas corpus?\nhabeas corpusnoun. the civil right to obtain a writ of habeas corpus as protection against illegal imprisonment. Synonyms: writ of habeas corpus.\nWhat is the purpose of writ of habeas corpus?\nService of Process. A writ of habeas corpus orders the custodian of an individual in custody to produce the individual before the court to make an inquiry concerning his or her detention, to appear for prosecution (ad prosequendum) or to appear to testify (ad testificandum).\nWhat happens when a Writ of Habeas Corpus is granted?\nHow do you explain habeas corpus?\nHabeas corpus, or the Great Writ, is the legal procedure that keeps the government from holding you indefinitely without showing cause. When you challenge your detention by filing a habeas corpus petition, the executive branch must explain to a neutral judge its justification for holding you.\nWhy would a writ of habeas corpus be denied?\nA Federal Writ must allege that a federal right was violated. The federal court will also usually reject a Writ of Habeas Corpus if the California Court denied the appeal or writ because of a procedural issue, such as if the defendant waited for too long to file the California Writ of Habeas Corpus.\nCan a person file a writ of habeas corpus?\nUnder U.S. law, a person held in custody by a state may challenge his conviction or sentence by seeking a writ of habeas corpus in federal court. A habeas corpus writ requires the release of a prisoner held without trial or lawful charge.\nHow was habeas corpus used in the Bushell case?\nIn Bushell’s case habeas corpus was used to release a juryman who had been gaoled for returning what the court regarded as a perverse verdict. Under U.S. law, a person held in custody by a state may challenge his conviction or sentence by seeking a writ of habeas corpus in federal court.\nWhat was the change in habeas corpus in 1789?\nHowever, their assumption was that the cause of imprisonment to be expressed in habeas corpus proceedings was to be specific, not general. This was a change from congressional legislation in 1789 that denied habeas corpus review in federal courts to prisoners held under state law.\nWho was president when writ of habeas corpus was suspended?\nSimilarly, with the passage of the Military Commissions Act of 2006, President Bush suspended the writ of habeas corpus, even as he came under criticism for signing the law, given the ambiguous nature of the law on who is and who is not an enemy combatant (Federman, 2010).', 'Electric vehicles (EVs) hold a lot of promise for the private sector — especially as consumers, who are increasingly aware of the relationship between emissions and climate change, are starting to demand eco-friendly delivery options. EV adoption, however, has been slowed down by a few different challenges — the US’s poor EV charging infrastructure in particular.\nNow, however, we’re beginning to see signs that major businesses are willing to buy into EVs, despite potential road bumps.\nHere are the businesses that are leading the way when it comes to EV adoption.\nAmazon and UPS Lead Way on EV Adoption\nTwo delivery giants — Amazon and UPS — have begun to aggressively add EVs to their delivery fleets.\nEarlier this year in January, Amazon ordered 100,000 electric delivery trucks from EV manufacturer Rivian, as well as 10,000 electric delivery rickshaws for their operations in India. Then, around the end of the month, UPS announced that it had ordered 10,000 electric trucks from the UK-based manufacturer Arrival Ltd., and would soon be teaming up with self-driving car manufacturer Waymo for a pilot test of self-driving delivery vehicles.\nThe moves are part of broader pushes towards carbon neutrality and self-driving delivery by the two companies. Last year, Amazon announced the company’s plan to be 100 percent carbon-neutral by the year 2040. UPS already offers carbon-neutral and carbon-offset delivery options.\nThe moves also come as more cities around the U.S., including New York and Philadelphia., have begun to adopt anti-idling laws that allow the city to fine companies over idling delivery vehicles.\nSome cities have even developed apps that allow citizens to report idling vehicles based on that vehicle’s DOT number — making these policies even more costly for delivery companies. Because electric vehicles produce no emissions, they’re typically free from being fined — meaning savings for businesses that adopt EVs for city deliveries.\nThe announcements are both historic. While other companies have announced EV purchases — like Lyft, which plans to deploy 200 EVs in Denver as part of its rental vehicle program there — there’s been nothing near scale of these announced by Amazon and UPS.\nWhile neither UPS nor Amazon has plans to go fully electric any time soon, the purchases are a welcome sign for the EV industry. Coupled with similar positive signals from the individual consumer side of the industry, they likely demonstrate that despite early growing pains, EVs may be on track for widespread adoption in the near future.\nChallenges Facing Further EV Adoption\nHowever, there still remain significant barriers that may slow or prevent full EV adoption, primarily the weak EV charging infrastructure in the US and limited number of charging stations — although this, too, seems like it’s starting to change.\nChargePoint, in coalition with the National Association of Truck Stop Operators (NATSO) has formed the National Highway Charging Collaborative, which plans to install new charging stations at more than 4,000 highway-side locations in the U.S., in order to increase the availability of EV charging stations in rural areas.\nAt the same time, legislative support for stronger EV infrastructure is beginning to build. In February, Democratic lawmakers in the House of Representatives announced a new bill that would create a nationwide EV charging network within the next five years.\nUpgrades to existing infrastructure would likely encourage further adoption. They may also be especially beneficial for businesses like Amazon and UPS, as both companies regularly make deliveries to rural parts of the country — areas that don’t always have the charging infrastructure needed to support EVs.\nThe Future for EVs in Business\nEV adoption in the private sector, which has lagged in the past, seems to be accelerating. Two major delivery companies have now announced that they will be adding significant numbers of EVs to their delivery fleets, with more likely to come in the near future as both pursue low-carbon delivery options.\nWhile challenges remain that may slow down EV adoption — primarily the nation’s weak EV charging infrastructure — the purchases are likely a good sign for the industry and the future of EVs in the private sector.']	['<urn:uuid:b97b0440-e893-420b-861d-64b03a8c6b4b>', '<urn:uuid:a3b2914f-bfcd-4107-a76d-db9ca5d880cd>']	factoid	direct	concise-and-natural	similar-to-document	multi-aspect	novice	2025-05-13T03:20:41.944655	9	43	1506
71	tools needed home drywall cutting	The manual tools needed for cutting drywall include cutting knife, tape measure, chalk line, 4 foot T square, jab saw, and keyhole saw. Power tools include circular saw and rotary tools.	['Any task can be a hard one if you don’t know how to get it done, and that includes cutting drywall as well. But following some techniques with proper tools, this job can be way easier than ever for anyone around. After finishing the cutting job, you will see how perfection took place here. Now the question is how to cut drywall perfectly?\nHere some super cool ways that are described that may be the easiest way for you as a beginner for cutting drywall.\nHow to Cut Drywall? 6 Ways\nIt is a fun job if you know how to cut drywall. It’s nothing like woodworking. To get a specific or proper cut on drywall, there are lots of things you must consider, like the design, size, and different shape. According to the design, cutting drywall is different, even the tools as well. There’s a variety of tools you’ll need to cut drywall. All the tools can be grouped into two sections.\nTools for Cutting Drywall:\nLet’s see the types of tools you’ll need if you want to know how to cut drywall.\nThere are a few tools for cutting drywall that need some power to operate. This is why they are named as power tools. To get some fantastic finishing with a particular shape and easy cut without getting any trouble, power tools became a blessing, especially when it comes to cutting drywall.\n- Circular Saw\n- Rotary Tools\nThe manual tool means those tools don’t need any power to run. It can be used by just using the hand. As an example, I can say about the knife, saw, etc. these tools help to cut drywall in a line. Power tools are the best to cut drywall, but what will you do in a remote area where electricity or power supply is unavailable. So, hand tools are great to work with some free space.\nThere are a few tools that you’ll also need to cut drywall that includes –\n- Cutting knife\n- Tape measure\n- Chalk line\n- 4 foot T square\n- Jab Saw\n- Keyhole saw, etc.\nTop 6 Ways to Cut Drywall:\n1. Cutting Drywall Without Any Fumble\nSome people get the wrong perception about the drywall when they don’t know the basic things for cutting it up. Here the most important 3 facts described for cutting drywall perfectly. Otherwise, you can cut it wrongly.\nFront and Back\nThe most confusing thing about the drywall is the front side and the backside. It’s a sheet that is almost flat on both sides. But it has a front side as well. Both sides are gray. But the lighter one is the right side, and the darker one is the backside. You can use tape, flush, or make some joint on the right side.\nCut at once\nYou cannot cut these things again and again. So, making the line for a cut is important with perfect measurement. If you need more time to measure it, then do it even if it needs twice to measure. After a cut, you hardly can change it.\nLaying it before the cut\nTo get the best shape after the cut, you must lay the board. It will give you more room. Laying the board will allow you to visualize the cut.\nSo let’s have a view over the ways and steps to cut drywall using various types of tools.\n2. Cut Drywall Using Cutting Knife\nFirst of all, you need some time to mark a line from where you are going to start cutting. The right measurement is the key to making the perfect cut. Following the line, there is less chance for any kind of misfit. While using a knife to cut drywall, you’ll need some protection. Otherwise, it can slip from your hand and make you injured. Hand gloves are the best of the protection over here. To use such a knife, you’ll need some space after placing the panel on any surface.\nA flat surface is best for cutting drywall. Now use the knife following the line you marked on the panel. Identify the backside and start the cut. After the cut, use sandpaper to ensure the perfect finishing of the edge.\n3. Cut Drywall Using a Jab Saw\nFor every type of cut on the drywall panel, you must mark the line. To use a jab saw, you must follow some instructions. On the edge of the line, make a small hole. Use a drill for such a hole. Through this hole, you need to use the Jab Saw for the cut. Get a better grip with the handle. This blade will cut smoothly if you hold it in a parallel way. Start to cut from the edge. You also need to make another hole on the other side of the line and cut it in the same way as the first hole.\n4. Cut Drywall Using Cut-Out Rotary Tool\nThis is one of the best power tools to cut the drywall, especially cutting holes. The professionals said that it is a great one to cut small holes. For the existing drywall, you have to be careful. There is maybe some electric wire passing behind the drywall. So, measuring the depth of the cutting becomes important.\nMake a line using the pencil for the desired cut. Now take some protection like wearing gloves and goggles. Take the perfect cutting bit and fix it with the tool. Choose the depth you want to cut. Connect the tool with the power supply line and turn it on. Now, point the bit to the center of the mark and hold it with both hands to give some force. Start to cut from the center and go for the rest of the cutting lines.\n5. Cut Drywall Using Circular Saw\nOne of the most used tools for cut Drywall. First of all, make a mark with the perfect measurement to cut. Using a legible pencil gives you a clear outline in a heavy dust situation. Now fix the cutting blade. You might need to adjust it according to the cutting depth.\nBefore you start to cut wear, use some protective gear like the ear protector and goggles. Turn on the saw. Push the blade down and start the cutting from the end of the line. Make sure that the blade is on the line you have marked.\n6. Way to Cut Complicated Portions in Drywall’s\nIt became common that people cut drywalls after installing the electric line and plumbing as well. So, this becomes sensitive when you are going to cut drywall’s over it. To make a perfect finishing, some portions of the drywall need to cut. To cut any kind of circle, you can use circle cutting tools. If you need a thin blade which is also long, then you must use a keyhole saw that is suitable to cut in the middle of the sheet.\nA light-duty electric router also perfect tools to cut drywall without facing any problem because the edge of this tool can guide you through cutting around sensitive areas like electrical and plumbing lines.\nTips & Warning\n- Most of the time, people break the edges. But leaving a small gap can solve the problem. So keep the gap between the sheets. From a distance, you measured, cut a little bit shorter to adjust the edge.\n- Try to wear goggles and hand gloves. Dust is a common problem when you cut drywall, especially using a router. To avoid it, goggles are the best solution.\nSometimes drywall can become a headache if you don’t know how to handle this thing for installing or cut. Maybe it is heavy to handle, but the process of cutting is easy.\nTo know how to cut drywall, this article may help you as a guideline to choose your way based on the design and position for installing the panel. If you are cutting drywall for the first time, then these tips are going to help you and save your valuable time.']	['<urn:uuid:9d16b654-7cfc-400f-b865-ee81c37daf6e>']	factoid	direct	short-search-query	distant-from-document	single-doc	novice	2025-05-13T03:20:41.944655	5	31	1344
72	As someone studying grid-scale energy storage systems, I'm curious about what makes vanadium flow machines unique compared to conventional batteries - what are their key distinguishing features?	Vanadium flow machines have two unique characteristics that make them suited to utility-scale storage. First, their power output is independent from energy storage capacity - output depends on the membrane stack size while energy storage capacity depends on electrolyte tank size. Second, power can flow undiminished as long as there is fresh electrolyte to circulate through the stack.	['The Energy Superhub Oxford is an ambitious £41m project\nOn 5 October, a Kensa heat pump was installed in the first of 60 homes in Blackbird Leys, Oxford. The heat pumps are connected to a series of boreholes incorporating communal ground arrays. These are the first of 300 homes and commercial premises in and around Oxford that will feature ground source heating as part of the Energy Superhub Oxford (ESO).\nThe ESO is an ambitious £41m project, part-funded by the UK government’s Industrial Strategy Challenge Fund, which – in addition to low carbon heating – will demonstrate grid-balancing hybrid battery technology and large-scale rapid electric vehicle (EV) charging.\nSmart software will manage the energy storage, EV charging and heat pumps to reduce strain on the grid and allow it to accommodate more renewables. The project is being led by Pivot Power, and when complete in 2022, it is predicted that it will eliminate 10,000 tonnes of CO2 emissions a year.\nHeating is the single biggest contributor to UK emissions. The domestic heating element of the project will demonstrate how ground source heat pumps (GSHPs) can help minimise the carbon associated with heating homes and businesses.\nIn advance of the heat pumps’ installation, housing provider Stonewater has upgraded the homes’ fabric through the addition of cavity wall and loft insulation, coupled with the installation of double glazing.\nHeat losses are generally between 4-5kW per home, so the majority of homes will be fitted with a 6kW heat pump. ‘Each home will have a heat pump connected to the shared outside infrastructure of pipes and boreholes,’ says Matthew Trewhella, managing director of Kensa Contracting.\nThe retrofit forms phase 1 of the project. Later phases will see up to 240 new-build homes fitted with GSHPs, and potentially various commercial properties too. Unusually, for the first phase the Oxford project has had to create six smaller communal arrays, one serving each cluster of homes, rather than use a single larger array. ‘Blackbird Leys is split into six smaller clusters because groups of houses are separated by roads, and so on,’ says Trewhella. Similarly, the area’s geology has necessitated a larger number of boreholes than usual for a scheme of this size. ‘Normally, we’d have gone with around 20 boreholes up to 220m deep, but because there is a layer of water about 100m below ground at high pressure, we’ve gone for 40 boreholes at about 96m depth,’ he says.\nThe ground array is simple; it comprises a piped water/glycol mix-filled circuit that operates at a temperature of between 0ºC and 12ºC to connect the homes to the boreholes. The homes are being fitted with dedicated heat pumps; these incorporate a circulating pump to pass the water/glycol from the ground loop through the heat pump at the appropriate flowrate.\n‘When a householder turns on the heating, the heat pump will chill the water/glycol mix and the unit’s circulating pump will pass this to the boreholes, from where it naturally comes back warmer,’ says Trewhella.\nThe ESO’s hybrid battery system is sited at the National Grid’s Cowley Substation\nThe heat pump absorbs heat and so reduces the temperature of the water/glycol mix by 5K before it returns to the boreholes, which enables it to supply the homes’ radiator circuit with water at 50oC, with a return temperature of 45oC. To heat the hot water cylinder, Trewhella says the ‘brakes are taken off’ to enable the heat pump off-temperature to rise to 65oC. ‘We limit the flow temperature of the heat pump to 45-50oC when it is running in heating mode. If we kept the heat pump at this flow temperature in domestic hot water mode, it would result in poor hot water performance and would not achieve sterilisation of the stored hot water. We, therefore, remove this limit when in hot water producing mode to allow the heat pump to heat the cylinder above 60oC,’ he says.\nThese will be the first of their kind in the UK, and the only major renewable heating solution capable of delivering domestic heating at a lower running cost than a traditional gas boiler\nThe homes’ heating systems are controlled using Switchee smart thermostats. These thermostats are capable of learning residents’ preferences – just using up and down temperature key presses. In previous projects (with gas boilers) Switchee found that around 30% of people are happy with the machine learning, but the rest opt for the thermostats to be programmed (which is normally done remotely while on the phone with a resident).\nThe thermostat’s inbuilt algorithm then learns how fast the temperature increases in the property when the heating is turned on, and how fast it drops when the heating is turned off, in order to optimise the heating control. Uniquely, this optimum start control will be linked to the cloud-based heat optimisation platform.\nOne of the project’s objectives is to show that a low carbon heating system can also be the cheapest to run. ‘We’re up against what physics will allow on the efficiency of the heat pump; some gains are expected, but they will be incremental compared with the potential for reducing electricity prices, so the next thing is to put in place measures to reduce the price of the electricity used,’ says Trewhella. To do that, tenants are being recommended to switch to a ‘dynamic’ electricity tariff with electricity priced in 30-minute intervals throughout the day. Dynamic electricity tariffs offer consumers cheap energy when electricity demand is low and renewable energy is plentiful, and higher prices when demand peaks.\nFigure 1: This graph from Kensa shows cost of electricity on different tariffs over a 24-hour period. The solid red line is the standard tariff, which is around 16p per kWh. The broken red line represents the six-monthly averaged dynamic electricity price, which shows that the dynamic tariff is cheaper than the standard tariff at most times of the day or night (except between around 15:30 to 19:00). The grey line is the carbon intensity of the grid\nThe dynamic pricing, available a day in advance, is used by the heat optimisation platform, which automates the load shifting; it takes occupancy information from the smart thermostat and combines it with the half-hourly electricity tariff information to optimise turn-on and turn-off times for the heat pump. This enables the occupants to take advantage of the dynamic tariff without having to change their behaviour.\nThe Kensa platform uses the heat-up and cool-down times determined by the Switchee algorithm as a proxy for the amount of thermal storage offered by each property. Working within the occupant’s comfort parameters, the heat optimisation platform will use the fabric of the property to store heat energy ahead of peak electricity times to raise the temperature of the building when electricity is cheap, so the GSHP can turn off when electricity is at its most expensive.\n‘If people want to be 21oC at 5pm, the regular algorithm would call for the heating to come on at 4pm, say, so that by 5pm the temperature is up to 21oC,’ says Trewhella. ‘However, we know electricity will be cheaper between 1pm and 4pm, so we might heat the property to be warmer than 21oC earlier – that might be 22oC or 23oC at 5pm – and the temperature could coast down over time.’\nThe plan is to run the heat pumps under normal control up to Christmas so that the system can learn the homes’ response characteristics before commencing active load shifting (see Figure 1).\nBy avoiding the high-cost period, occupants will also reduce the overall carbon intensity of the electricity they consume\n‘Our original thought when we were first involved with this demonstrator was that we would run the heat pump when electricity was cheap. However, it turns out from our modelling that we expect not to run the heat pump when electricity is expensive,’ says Trewhella.\nBy load shifting Kensa expects to reduce the cost of heating by up to 25%, compared with running the heat pump on a standard electricity tariff. By avoiding the high-cost period, occupants will also reduce the overall carbon intensity of the electricity they consume and will also help ease the strain on the grid. ‘Optimising the system on the price of electricity gives the highest consumer acceptance, but we could chose to optimise on any of these variables; whichever you select, you will benefit the other two,’ says Trewhella.\nOf the properties in the first phase, 56 are currently heated using electric night storage, while four are heated using gas. As part of the project, the University of Oxford is surveying the residents and obtaining historical bill data to set a baseline for how much they currently pay.\nTrewhella says it’s a difficult assessment because consumption will vary with the weather and because, in Kensa’s experience of social housing schemes, when people do have cheaper heat, they tend to keep homes a little warmer. Nevertheless, it is estimated that replacing the night storage heaters with a shared ground loop array and individual GSHPs will produce lifetime bill savings of £19,225 per property (based on a recent ECO3 submission).\nElectric vehicle charging infrastructure will be an integral part of the ESO project\nLifetime, as defined by Energy Company Obligation (ECO) – the government’s scheme to reduce carbon emissions and tackle fuel poverty – is 40 years. In reality, the boreholes have an expected lifetime of 120 years and the heat pumps 20-25 years, so 40 years is an average’ of the two main components to represent a ‘system lifetime’.\nWhen combined with a smart thermostat and the heat optimisation platform, the predicted lifetime bill savings per property are £31,575 for the night store properties. For the 300 properties in the ESO with GSHPs, total lifetime bill savings are expected to be £2-3m, as the electric heat pumps displace gas heating.\n‘These heating systems will be the first of their kind in the UK, and the only major renewable heating solution capable of delivering domestic heating at a lower running cost than a traditional gas boiler, with no local emissions and the lowest carbon intensity of any heating,’ says Trewhella.\n‘We’ve done a lot of modelling, and there is no question there will be cost savings on the homes with electric night storage heating – even without load shifting they can expect to halve their bills. For the gas-heated homes it will be tighter, but we’re still confident there will be cost savings,’ he says.\nBoreholes being drilled in Blackbird Leys\nStonewater will also be able to claim non-domestic Renewable Heat Incentive (RHI) payments for the project: ‘Because you are sharing the heat source, which ultimately is the ground, the system is classed as a district heating system, which is eligible for non-domestic RHI, providing a 20-year income for the property owner,’ he adds.\nThe GSHP is only one part of the ESO; the scheme also includes the UK’s first transmission-connected battery to enable load-shifting for the overnight charging of the council’s fleet of EVs and the opportunity to provide balancing services to the National Grid – and to trade on the Day Ahead and Intraday energy markets.\nCurrently, the GSHP element of the ESO is set up to operate as an independent entity. However, Trewhella says there are synergies to be had from linking the GSHP to the battery in the future. ‘There is no doubt that balancing the electricity supply grid generally with batteries while at the same time turning vehicle charging on and off and turning heat pumps on and off and treating the whole thing as a collective will have huge benefits,’ he says.\nWhat is a vanadium flow machine?\nInvinity Energy Systems’ energy storage machines employ vanadium ions in different oxidation states to store chemical potential energy.\nA conventional battery stores chemical energy within an electrolyte solution, while a vanadium fl ow machine contains two different electrolyte solutions, each in a separate tank.\nWhen the vanadium flow machine is charged, one electrolyte is positively charged and one is negatively charged. In order for the battery to provide power, the electrolytes flow through a fuel cell stack on opposite sides of a proton exchange membrane. Their opposite charges create a gradient that powers an external current.\nThere are two main characteristics unique to vanadium fl ow machines that make them suited to utility-scale storage. First, unlike conventional batteries, power output is independent from energy storage capacity.\nOutput depends on the size of the membrane stack (the engine), while the energy storage capacity depends on the size of the electrolyte tanks(the fuel). Neither constrains the other, although the ratio of storage to power determines how long the batteries can run without recharging. Power can flow undiminished as long as there is fresh electrolyte to circulate through the stack.\nThe ESO’s battery is sited at the National Grid’s Cowley Substation. It is a hybrid battery comprising a 50MW Wartsila lithium-ion battery and a 2MW Invinity Energy Systems vanadium flow battery, which does not degrade with use (see ‘What is a vanadium flow machine?’ panel, above). This combination of battery technologies has been designed to provide synergies to support the National Grid’s Fast Frequency Response (FFR) tenders, so the battery control system will attempt to use the full capacity of the vanadium flow battery first to reduce degradation in the lithium-ion unit. The lithium-ion batteries can then be saved for high value cycles, for which the vanadium batteries are less suited – for example FFR – where the income levels justify the degradation cost.\nThe final component of the ESO is an EV charging network, which is connected to the National Grid’s high voltage transmission network, bringing an unprecedented amount of power to Oxford for rapid vehicle charging and enabling the charging of big EV fleets, including that of Oxford City Council. This will provide up to 25MW for EV charging – enough power for well over 100 ultra-rapid chargers. The project will also explore the value to be gained by ‘smart’ charging, using variable time-of-day tariffs to pick the cheapest times to charge.\nJust as the heat pumps will use smart controls to optimise comfort and cost for residents, an optimisation and trading engine will underpin both battery activity and EV charging so they automatically use cheaper, cleaner electricity when available, and to help balance the grid as the supply fluctuates under the influence of renewables\nWork on the ESO was due to run until March 2022 but, as a result of Covid-19, the completion date has now been extended until June 2022, by which time 300 GSHPs will have been installed.']	['<urn:uuid:e3c6ab3d-93bb-44a0-8deb-2f5854b4e42b>']	factoid	with-premise	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-13T03:20:41.944655	27	58	2433
73	real estate investor need documents review checklist for commercial property due diligence what documents should seller provide	Documents to review during commercial property due diligence include: Accessibility surveys, Architectural Design plans, Certificates of Occupancy, Citations from Authorities, Emergency evacuation plans, Environmental studies, Electrical System Design plans, Fire-detection inspection records, Fire-door inspection reports, Fire-Protection System Design plans, Maintenance records, Building Permits, Previous inspection reports, Roofing System Design plans and Warranties, Safety inspection records, Seller condition disclosures, System Warranties, Service contracts, Evidence of current zoning, and As-built plans and specifications.	['The purpose of all Bartering Acreage Action Assessments (PCAs), ASTM accepted E2018, is to accomplish abiding that the acreage and architecture you accept you are purchasing or leasing is in actuality the acreage getting received. You will accept accomplished that decision, in part, from the advice accomplished via a able analysis and Acreage Action Address (PCR). Every absolute acreage transaction is altered and anniversary transaction has its own different set of considerations and altitude to validate afore finalized. The appliance of able third affair experts in the accurate acreage due activity action is analytical to the all-embracing accurateness and amount ability of your acreage transaction.\nThe Acquirement or Leasing of Bartering absolute estate, whether it be a basal bartering net lease, a bartering amateur net lease, the acquirement of a abbey facility, a retail outlet, or the acquirement of a actor aboveboard bottom office/warehouse, the -to-be client or aborigine actually accept to conduct an able akin of due activity if investigating the accurate superior of the bartering absolute acreage they are advance in.\nYou charge to apperceive not alone the accurate characteristics of the absolute acreage and barrio getting acquired, but the almost action and age, to appraise the acceptable with the bad, such that you can abundantly antithesis the risks and rewards getting offered in affiliation with your absolute acreage deal. The individual a lot of important allotment of the absolute acreage transaction process, abreast from the acquirement amount and advantage balance, is a well-documented analysis of the absolute accurate action of the absolute property. Otherwise, you could acquisition yourself the not so appreciative buyer of a bartering acreage that, doesn’t clothing your needs, costs added than you can acquiesce in upkeep, or the ultimate anguish for investors – basal expenditures are getting sunk into a acreage on a approved base that anyone abroad is utilizing and authoritative money off of, and you are not. Suddenly, that continued appellation charter with a solid ballast doesn’t assume so adorable anymore.\nThe action of bartering absolute acreage analysis begins afore the action to acquirement absolute acreage is drafted or signed, by visiting the website and discussing the accurate action of the acreage with the Buyer and absolute acreage brokers. This action should be advised invaluable to establishing relationships appropriate to access the advice that will be all-important to accurate your due activity with a Bartering Acreage Action Appraisal (PCA).\nDuring negotiations and drafting of the absolute acreage sales/lease arrangement it is important to admit agent or freeholder abhorrence to credibility such as the actuality and availability of important abstracts such as warranties, aliment contracts, architectural and engineering affairs and/or bounded city reviews and inspections. Negative acknowledgment to the appeal for absolution of these abstracts by agent or freeholder can betoken accessible deferred aliment and/or apathy accompanying to acreage and architecture condition(s) and analysis issues.\nOnce the bartering absolute acreage sales arrangement is active the due activity aeon begins, focus on maximizing ability of time and amount and prioritizing apropos to alpha blockage off the cher big admission items from the top down. Assuming able affidavit is furnished by the agent for review, able time should be allotted to verify the advice provided. Added accomplishment and monies that that will charge to be spent to accomplish up a shortcoming of accessible affidavit through added acreage action appraisal and added acreage inspections and/or experts should be advised capital and ample into the amount of the acreage transaction. Ask the agent for all abstracts and contacts the agent accustomed during his due activity action if he purchased the acreage to acceleration up actuality finding.\nReview of absolute acreage abstracts area accessible may include:\nAccessibility surveys, Architectural Architecture plans, Certificates of Occupancy, Citations from Authorities Having Jurisdiction, Emergency aborticide plans, Ecology studies, Electrical System Architecture plans, Fire-detection analysis and aliment records, Fire-door analysis reports, Fire-Protection System Architecture plans, Fire and Restoration records, Aliment records, Automated System, Architecture plans, Violation Notices from Authorities Having Jurisdiction, Architecture Permits, Plumbing System Architecture plans, Previous analysis reports, Roofing System Architecture affairs and Warranties, Safety analysis records, Agent action disclosures, Sprinkler System Analysis Records, Systems and Material Warranties, Accepted addressee information, Accepted action of appellation insurance, Notices of any ecology conditions, Notices of any new or appropriate assessments or taxes, Copies of all accepted bills for the property, Service contracts, Evidence of accepted zoning, As-built affairs and specifications, All architecture accompanying abstracts including warranties, All accomplished and present uses of the property, Third affair letters or inspections, Any surveys of the acreage and improvements in seller’s possession.\nOne of the best accoutrement accessible to the bartering acreage due activity aggregation is the account action which can alleviate a deluge of potentially advantageous advice apropos the accountable property.\nInterview of any accessible key cadre with specific ability of the acreage altitude may include:\nOwner, Tenants, Aliment Foreman, Apprenticed aliment casework cadre or added apprenticed companies that commonly plan on the acreage and/or building.\nProperty Inspection, Absolute Acreage Inspection, Architecture Inspection, Due Activity Survey, as they may be labeled in the due activity address is capital to ensure capability of architecture because the advised use of the occupants and the surrounding cartography and climate. The capacity of any accessible affairs and blueprint should be accessible here, but will not end the investigation. A accepted bartering acreage action appraisal should be done by a able third affair analysis aggregation accomplished in the blazon of acreage to be inspected. A ahead performed acreage action appraisal or analysis is about consistently furnished for the use of a individual affair in a individual transaction and is able beneath law and not reusable nor communicable to any added party. The focus of the analysis should be primarily on website action and architecture apparatus such as the website drainage, parking, architecture structure, automated and electrical systems and accepted accessibility and account of the property. Various climates and bounded regions will crave added specific analysis knowledge, appropriately hiring a bounded ambassador is consistently a acceptable abstraction if possible, in lieu of hiring a aggregation out of Wisconsin to accomplish due activity on a California high-rise architecture on a accountability line.\nSite Analysis and Walk-Through to Observe Absolute Altitude may include:\nGrounds and Topography, Parking, Paving, Access, Architecture Exterior and Façade, Architecture Interior, Roofing systems, Structural systems, Automated systems, Electrical Systems, Plumbing systems, Fire-protection systems, Vertical busline systems, and any amount of added specialty systems.\nThe 2010 Americans with Disabilities Act is the accepted guideline for accessibility standards civic and is a federal law, appropriately basal and to an extent, yes, it’s retro-active even for earlier bartering and accessible buildings. Abounding states aswell accept added and/or added acrimonious or specific accessibility standards as well. A lot of able acreage action appraisal and analysis companies can aswell accomplish both abbreviated and complete accessibility surveys as allotment of a absolute acreage transaction.\nBasic abbreviated and abounding acquiescence Accessibility surveys may include:\nAbbreviated analysis searching alone for basal ADA Accessibility apparatus arresting during the walk-through and accurate according to the ASTM abbreviated analysis anatomy and account gives a quick analysis as to the accepted cachet of compliance. Abounding acquiescence analysis involves accurate abstracts of distances, slopes, and push/pull armament appropriate aural the accessibility standards to acquiesce for a assertive akin of physically disabled being to be able to auspiciously cross a property, site, and building.\nEnvironmental Due Activity accepted as Ecology Website Appraisal (ESA) is the a lot of activated Ecology Analysis Report. The archetypal akin of address adopted by lenders to authenticate able due activity is alleged a Limited Phase I Ecology Transaction Screening ASTM accepted E1528. This explores the accomplished use of the acreage and the surrounding backdrop to analyze any abeyant onsite or adjoining ecology problems or approaching liabilities. These letters commonly crave a cogent budgetary investment and yield a amount of weeks to complete so they should be done as anon as you accept bent you will be affective advanced with your due diligence. The purpose of this analysis is to actuate if the acreage contains any chancy abstracts or poses a blackmail in any way to its surroundings. This could be acquired by underground accumulator tanks amid on the acreage or runoff from the acreage into the baptize table or any added amount of hazards listed by the Ecology Protection Agency. While the address is expensive, the amount of charwoman up an ecology hazard can be astronomical. While not every accord will crave you to access a Phase I Environment Website Assessment, abounding lenders will crave it as allotment of their accommodation guidelines. In case of a adequately new development with a apple-pie ecology almanac and no neighbors of an automated nature, a simpler beneath big-ticket and abundant quicker Ecology Transaction Screening ASTM accepted E1528 may amuse lender and acknowledged requirements.\nAny basal ecology due activity address may include:\nResearch of actual website usage, aeriform photography records, acreage transaction records, architecture records, architecture records, EPA mapping data, bounded city cartography mapping, and a through website walk-through to visually analyze abeyant ecology affair indicators.\nThe advice independent herein is absolutely able assessment and provided for accepted absolute acreage analysis advertence alone and is not advised in any way to be a absolute guide, nor a agreement of past, present, or approaching acknowledged or accompaniment or federal requirements, nor a admeasurement of achievement of any able casework company. Best of luck to you in all of your approaching property, absolute estate, and architecture dealings!']	['<urn:uuid:ca7b8d63-dce4-4ea6-861b-29febb8d0c9a>']	factoid	with-premise	long-search-query	similar-to-document	single-doc	expert	2025-05-13T03:20:41.944655	17	71	1574
74	family relationships ra thoth compared	Ra and Thoth had different family origins and relationships. Ra had multiple children and grandchildren, including his children Shu and Tefnut, who gave birth to Nut and Geb, who in turn had four children: Isis, Nephthys, Set, and Osiris. Ra's daughter with Nut was Hathor. In contrast, Thoth's family relationships are less clear - he was alternately described as self-created, born from Ra's lips, or born from Horus's semen through Set's forehead. Thoth's main consorts were Nehemetawy and Seshat, who was either his wife or daughter, but there is no mention of him having multiple generations of descendants like Ra did.	"['In Egyptian mythology, Ra was the god of the sun. He was the most important god in Ancient Egypt. He had many names, such as Amun-Ra, and Ra-Horakhty. It was said he was born each morning in the East, and died each night in the West. In the night he traveled through the underworld. This is why the west side of the Nile was known as the land of the dead. He was the king of the gods.\nName[change | change source]\nRa was thought to be the god of the sun and creation. Ra’s name came from Re and Amen. The name Re was from Upper Egypt and the name Amen came from Lower Egypt. When Upper and Lower Egypt came together they changed the name to Amen-Re. Over thousands of years the name Amen-Re evolved into Amen-Ra and then just to Ra. From then on people called him Re or Ra. Ra used to mean “mouth” in the Egyptian language. Some names are:Re, the Creator, Khepry, etc.\nLooks[change | change source]\nRa has many forms. His best-known form is the man with the head of a Hawk and the sun disk may above him. He may also be depicted as a scarab beetle or a man. One is Amun-Ra, which is a ram and the other, Ra-Hakorthaty which is a sky sun god.\nFriends and enemies[change | change source]\nSome time around the Middle Kingdom, Ra and Osiris became friends. This was unusual because Osiris lived in the Underworld and Ra lived in the Heavens. All the other gods wanted to be friends with Ra. They hoped that if they were friends with Ra, Ra would tell them his hidden name. But Ra did have some enemies. Seth was sometimes Ra’s enemy, but Seth did help Ra fight Apep, a snake god. The fact that Seth helped Ra reminded all of the gods that Seth was not all bad. Isis was another enemy of Ra, she had tricked him into giving her his hidden name so her husband Osiris could be king of the gods.\nWorship[change | change source]\nThe cult of Ra began to grow from around the time of the II Dynasty, establishing Ra as the sun god. By the IV Dynasty, the Pharaohs were seen as ""Sons of Ra"". His worship increased much in the V Dynasty, when he became a state deity. Pharaohs had pyramids, obelisks, and solar temples built in his honor.\nPowers[change | change source]\nRa was believed to be the greatest Egyptian god when it came to powers. His powers live in his hidden name. Only he knew his hidden name so only he could use the powers. It was said that he had the best powers throughout the land. He could make anything, he made people, he made the world, and he made the heavens. That is how great his powers were. One day Isis wanted to have his powers so she sent a serpent to poison him on his daily walk and when the pain was so bad, Ra gave in and told her his secret name of creation.Then Isis banished Ra to the Duat, (Spirit World), so Osiris her husband could be king.\nFamily[change | change source]\nRa\'s daughter with Nut (his grand-daughter) was named Hathor, the goddess of love. Ra had two children Shu, the god of air and Tefnut, the goddess of morning dew. They had two children named Nut, the goddess of the sky and Geb, the god of earth. They had four children named Isis, the goddess of home, Nephthys, the goddess of mourning, Set, the god of the desert, and Osiris, god of the afterlife. They paired up and had two more children, Anubis, god of embalming, and Horus, god of war and pharaohs.\nReferences[change | change source]\n- Remler, Pat, Egyptian Mythology from A-Z 180-181\n- Watterson, Barbara, Gods of ancient Egypt\n- Wilkinson, Richard, The Complete Gods and Goddesses of Ancient Egypt\n- John, Banes and Jaromir, Malek, The Cultural Atlas of the World: Ancient Egypt 173', 'Thoth is the Egyptian god of writing, magic, wisdom, and the moon. He was one of the most important gods of ancient Egypt alternately said to be self-created or born of the seed of Horus from the forehead of Set. As the son of these two deities, who represented order and chaos respectively, he was also the god of equilibrium and balance and associated closely with both the principle of ma\'at (divine balance) and the goddess Ma\'at who personified this principle (and who was sometimes seen as his wife). Another of his consorts was the goddess Nehemetawy (\'She Who Embraces Those In Need"") a protector goddess. In his form as A\'an, Thoth presided over the judgment of the dead with Osiris in the Hall of the Truth and those souls who feared they might not pass through the judgment safely were encouraged to call upon Thoth for help. The consort most often associated with Thoth was Seshat, goddess of writing, the keeper of books, and patron goddess of libraries and librarians who was alternately his wife or daughter.\nWorship of Thoth began in Lower Egypt most likely in the Pre-Dynastic Period (c. 6000-3150 BCE) and continued through the Ptolemaic Period (323-30 BCE), the last dynastic era of Egyptian history, marking Thoth\'s veneration as among the longest of the Egyptian gods or any deity from any civilization. His name was often taken by the kings of Egypt (example, Tuthmoses - ""Born of Thoth""), scribes, and priests. He is most commonly depicted as a man with the head of an ibis or a seated baboon with or without a lunar disc above his head. He was the patron god of scribes and it was said that scribes would pour out one drop of their ink in Thoth\'s honor before they began their daily work.\nName & Origin\nThoth\'s Egyptian name was Djehuty (also dhwty) meaning ""He Who is Like the Ibis"". The ibis was a sacred bird in ancient Egypt as well as a popular pet and associated with wisdom. Other forms of his name are Jehuti, Tahuti, Tehuti, Zehuti, Techu, Tetu, and Lord of the Khemenu (the later city of Hermopolis) which was his major cult center. Hermopolis was so named because of the Greek association of Thoth with their god Hermes and to the Greeks Thoth became Hermes Trimegistus (Thoth the Thrice Great often given as ""Three Times Great, Great""). He was also known as ""Lord of Ma\'at"", ""Lord of Divine Words"", ""Scribe of Ma\'at in the Company of the Gods"", and as a just and incorruptible judge.\nAccording to one story, Thoth was born ""from the lips of Ra"" at the beginning of creation and was known as the ""god without a mother"". In another tale, Thoth is self-created at the beginning of time and, as an ibis, lays the cosmic egg which holds all of creation. He was always closely associated with Ra and the concept of divine order and justice. In a third story, The Contendings of Horus and Set (an Egyptian manuscript from c. 1190-1077 BCE), when Horus and Set are fighting for the right to rule, Thoth is said to have been created from the semen of Horus which was accidentally swallowed by Set during the struggle. Thoth was born from Set\'s forehead and, in some versions, then mediated the struggle between the gods (in other versions the battle between Horus and Set is resolved by Neith and, in others, by Isis). In every version, Thoth is the scribe who records the events of the contest and offers advice to the gods. He heals both Horus and Set at different times in their battle in order to make sure that both sides are equally capable and none can gain advantage over the other so that the contest will be fair. In this same way, Thoth presided over justice on earth among human beings. Egyptologist Geraldine Pinch writes:\nThoth set a divine example as a just judge and an incorruptible official. He lifted Ma\'at, the goddess of justice, to her father, Ra. Thoth was responsible for framing and enforcing the laws of ma\'at. In this role he could be either a gracious peacemaker or a merciless executioner (210).\nAs Thoth was credited with the creation of a number of branches of knowledge (law, magic, philosophy, religion, science, and writing) he was thought to be an infallible judge capable of rendering completely just decisions. The Greeks admired him so greatly that they credited him as the originator of all knowledge on earth and in the heavens. He was so important to the gods, and especially to Ra, that he was the god chosen to retrieve Ra\'s daughter from the distant lands she sometimes fled to.\nThoth & The Distant Goddess\nThe motif of The Distant Goddess appears in a number of Egyptian myths but always has the same meaning no matter who the specific goddess is or where she has gone: Ra\'s daughter disagrees with him on some matter and leaves him to vanish into some far off land and someone has to be sent to bring her back; upon her return she brings some sort of transformation to the people. The Distant Goddess story also always involved the Eye of Ra, the all-seeing eye, which Ra needed on a daily basis; it was therefore imperative that the goddess be brought back quickly and the eye returned but she was too powerful to be forced and the task called for subtlety. Geraldine Pinch writes:\nRa chose Thoth to fetch this Distant Goddess back from a remote desert. Disguised as a baboon or monkey, Thoth accomplished his task through humility, cunning, and perseverance. According to one account he had to ask the goddess to come home 1,077 times (210).\nAs a reward for his services, Thoth was given the goddess Nehemtawy as his consort who, Pinch claims, was ""a pacified version of the Distant Goddess"" (210).\nThoth was also instrumental in the birth of the original five gods of Egypt. When Nut became pregnant by Geb at the beginning of the world, Ra (also known as Atum) was so angry he decreed she would not give birth on any day of the year. Thoth gambled with Iah, the moon god, for five days\' worth of moonlight. He won the gamble and divided Iah\'s moonlight into five days of sunlight which were not part of the year as decreed by Ra. Nut was then able to give birth to each of her children (Osiris, Isis, Set, Nephthys, and Horus) on each of the days. Even though Ra had been angry with his daughter, Nut, he relented and honored Thoth for his part in getting around Ra\'s decree. Thoth was given a seat of honor in the sky boat which crossed the heavens by day and, by night, Thoth helped to drive away the serpent Apophis who sought to destroy the sun god. His participation in the overthrowing of Apophis linked him to the cycle of day and night and so intimately to the lives of human beings.\nThoth & the Written Word\nThoth created the written word people used to record their history and keep track of their daily lives. According to some stories, Thoth invented the word and gave it to humanity while, in others, Thoth was the creator and his consort Seshat gave words to the people. In still other variations, Thoth was the creator but Osiris or Isis gave words to humanity. In every case, Thoth is the creator of written language and the literary arts both for humans and the gods. Geraldine Pinch writes:\nThoth, the ""excellent of understanding"", observed and wrote down everything that happened and reported it to Ra every morning. As the record keeper of the gods he was paired with the librarian Seshat. Thoth and Seshat knew the future as well as the past. They inscribed a person\'s fate on the bricks on which their mother gave birth and the length of a king\'s reign on the leaves of the ished tree (210).\nThoth was therefore linked with the concept of fate even though this responsibility was shared, in different variations of the myths from different eras, with the Seven Hathors or other deities. As the record keeper of the gods, Thoth also kept account of the days of human beings. He is seen in a number of images keeping track of the days and numbering the years by which the Egyptian scribes were able to record the country\'s history.\nScribes, naturally, claimed Thoth as their patron and began each day honoring him. A statue from the 18th Dynasty shows Thoth as a baboon with the lunar disc on his head seated above a working scribe at his writing desk. The work of these scribes was, hopefully, approved of by Thoth who then gave leave to Seshat to house them in her immortal library and protect them in earthly ones. The concept of writing making the author immortal was well respected in Egypt as a scribe\'s work lived on after his death through the written words in books but was also known by the gods as Seshat kept the words in her heavenly books as well. Scribes had every reason to believe they would be welcomed warmly after death in the Hall of Truth and pass on to paradise in the Field of Reeds.\nThoth in the Afterlife\nThoth appears regularly at the side of Osiris and Anubis in the Hall of Truth as the scribe who has kept accounts of the life of the soul of the deceased and who records the outcome of the weighing of the heart against the feather of truth. Scholar Richard H. Wilkinson writes:\nIn vignettes of the Book of the Dead [Thoth] stands before the scales which weigh the heart of the deceased and record the verdict. This role gave Thoth a reputation for truth and integrity and is seen in the common assertion that a person had conducted his life in a manner ""straight and true like Thoth"" (216).\nHis home in the afterlife, known as the Mansion of Thoth, provided a safe place for souls to rest and receive magic spells to help them against the demons who would prevent them from reaching paradise. His magic was also instrumental in the revitalization of the soul which brought the dead back to life in the underworld. The association of writing with magic gave rise to the belief that Thoth had written magical treatises based on all he knew of the heavens, the earth, and the afterlife, and that these books were hidden away to be found by the initiates of later generations. Pinch writes:\nAll funerary spells could be regarded as works of Thoth. A tradition grew up that Thoth had written forty-two books containing all the knowledge needed by humanity. Some of this was occult knowledge to be revealed only to initiates who would not misuse the power it gave them. The Greeks identified Thoth with their messenger god, Hermes. The body of literature known as the Hermetica claimed to preserve the teachings of Hermes Trismegistus (Thoth the Thrice Great). Hermes Trismegistus was eventually reinterpreted as a great thinker who had lived thousands of years in the past (211).\nThis claim regarding Thoth and the 42 books was first made by the church father Clement of Alexandria (c. 150-215 CE) who recorded in his Stromata that they were written by the god Hermes. Hermes the god was later understood as Hermes the wise man and in largely this manner the Book of Thoth has come into modern day understanding. Fictional representations of the Book of Thoth - written either by the Egyptian god, the Greek god, or the Greek sage - have appeared in books and films throughout the past century. The continued fascination with Thoth and his far-ranging knowledge is a testament to his enduring popularity.\nWorship of Thoth & Legacy\nThoth\'s main center of worship was at Hermopolis but he was widely venerated throughout the land of Egypt. As with other gods, his temples and shrines would have served as a focal point for the community and a resource for counsel, spiritual advice, and general aid in procuring food or medical attention. The priests of Thoth were highly educated scribes and his cult was closely associated with the ruling class. It was not only the monarchy or the educated elite who admired Thoth, however, as Wilkinson points out:\nThoth\'s appearance in the names of several New Kingdom monarchs shows important royal acceptance and patronage of the god\'s cult, but earlier references to offerings made in private tombs on the festival of Thoth also show the importance of this god to non-royal individuals and his worship appears to have always had a wide base among ancient Egyptians...Amulets of the god as an ibis or an ibis-headed man - sometimes holding the divine wedjat eye occur, though those depicting him as a baboon were more common. These amulets were worn in life, many presumbably by scribes. The wisdon and magical powers ascribed to Thoth meant that he was naturally invoked in many spells utilized in popular magic and religion (216-217).\nHis cult center at Hermopolis was extremely popular. Mummified ibises and baboons were sold to pilgrims coming to the festival as votive offerings to the gods. Excavations of the nearby necropolis of Tuna el-Gebel revealed thousands of these mummified animals. Wilkinson writes, ""Another large burial ground for ibises and baboons was located at Saqqara and these catacombs well illustrate the continued widespread popularity of Thoth in the religion of the later periods (217). Thoth\'s enduring veneration is also recognized through the number of amulets to him which have been found from different time periods throughout Egypt\'s history.\nEven today, Thoth is recognized as an important spiritual entity. Aside from those in the New Age, Wiccan, or Neo-Pagan communities who revere the god, he is one of the better known Egyptian deities in popular culture. The University of Cairo features Thoth on his throne as their logo and statuary of the god remains one of the most popular and recognizable, after images of King Tutankhamun, Queen Nefertiti, and the goddess Bastet, in the modern world.']"	['<urn:uuid:49976b61-199d-4405-9bad-959e552e452d>', '<urn:uuid:81a8d991-e48d-4286-b03a-08a5f96054f9>']	open-ended	direct	short-search-query	similar-to-document	comparison	expert	2025-05-13T03:20:41.944655	5	101	3048
75	how did old textile factories protect workers safety what current rules exist for workplace protection	In the 19th century, textile mill workers had very little protection, working in dangerous conditions with minimal safety measures. Workers as young as nine years old worked up to eleven hours daily, and there were no age restrictions, fair wages, or health and safety provisions for dangerous machinery. However, workers united to force change - for example, at Islington Mill, workers supported the establishment of a Weavers Union in 1842 to better their conditions. Today, OSHA enforces strict workplace safety standards, including fall protection systems, hazard communication requirements, respiratory protection for air quality, machine guarding, and proper electrical wiring standards. These modern regulations aim to prevent workplace accidents and ensure worker safety.	['For this commission the artists have created a hanging timeline showing different ‘slices of history’.\nEach one of the fabric hangings represents a century and shows the occupations of the people inhabiting the mill at that time.\nThis interactive timeline has been produced to allow the viewer to see through and around it, showing different aspects depending on which way you look at it. The layers hung one to four are composed to reference the impact each century has had on the next.\nA room and power mill - A type of textile mill found in Lancashire in which small businesses paid rent for space and power.\nFabric 1: 18th Century\nThis print features a map of the local Salford area before Islington Mill was built. The cross marks the place where Islington Mill stands today.\nFabric 2: 19th Century\nThe cotton spinning wheels featured at the top of this piece represent the opening of\nIslington Mill in 1823. The mill was originally dedicated to cotton spinning, and was\ndesigned and built for this purpose by the Leeds-born architect David Bellhouse (1764–1840), who was commissioned by the industrialist Nathan Gough.\nIslington Mill was one of the earliest mill buildings in the wave of factory and mill\nconstruction that was central to the Industrial Revolution in Manchester.\nThe 19th century saw great upheavals in work and home life, urban living, industrial\ninnovation on a grand scale, with concomitant human exploitation and hardship.\nNathan Gough came from a large working class family in Holt Town, a factory colony in East Manchester. From the age of ten he worked at his brother’s cotton mill, eventually rising to the rank of manager at age seventeen.\nHe was self-educated and eventually ran his own factories.\nIn 1829 Nathan Gough moved away from traditional cotton spinning and took on a new\nventure in mechanical engineering. He began to design & manufacture steam engines, some of the very first of their kind. This created Islington Mill’s first transition and showed Nathan Gough’s ability to adapt to an ever-changing economy through technology.\nThe images at the bottom of this piece are taken from some of the designs produced by Nathan Gough.\nInside the mills, workers as young as nine years old would arrive on foot from the\nsurrounding cramped cottages and pitiful slums to enter into the gloomy factory at dawn and work for a solid hour on an empty stomach before taking breakfast and resuming work, in shifts that could last up to eleven hours in total. Nathan Gough would later suggest that anything less than sixty-nine hours a week should be considered “detrimental to trade.”\nThe Weavers Union:\nFactory and mill workers in this era enjoyed little protection in terms of age restrictions for workers, duration of working hours, fair wages and sick pay, or health and safety for working with dangerous machinery.\nMachine malfunctions, construction and debt issues caused many to lose jobs, become\ninjured and even lose their lives, but a sense of community was strong, perhaps\nengendered by these very conditions.\nIt was down to working people themselves to force change and workers of Islington Mill seemed to have been active in this area.\nRecords show that workers at Islington Mill made donations to their local hospital and to the Peel Park Memorial. In 1842, mill workers also supported the establishment of a Weavers Union, uniting\nworkers to better their conditions and their community.\nThe symbol for the Weavers Union is stitched into the centre of Fabric 2.\nChange did come, for example in 1844 laws were made guaranteeing safer factory\nAt the height of the Industrial Revolution in the mid nineteenth century, fortunes could be made and lost within a matter of a few years.\nAfter a prosperous period in Islington Mill’s history we see that in 1850 the mill fell into debt under the mismanagement of W. Morris due to defaults on mortgage payments.\nThis saw thousands of workers lose their jobs and all of the factory machinery sold off at auction.\nIn the centre of Fabric 2 we have added a thousand dashes to represent these abandoned workers. The dashes have been positioned in such a way as to look like the windows of a large mill, dramatising the link between the people who worked at the mill and the\nMills often employed people from the same family, with fathers, mothers and children all working together at the same machines.\nAn event like this would have had a huge impact on the community. With so many hands newly out of work it would have been very difficult to pick up new employment elsewhere with competition already being very high. Hardship no doubt followed.\nFabric 3: 20th Century\nDuring this century, Islington Mill evolved from fabric making to garment construction to wholesaling items, particularly from Germany.\nThis evolution accurately reflects the broader industrial changes that occurred over these years.\nBy the 20th century clothing manufacture had taken over from fabric manufacturing and Islington Mill was once again transformed to meet demands of the economic\nAs fabrics were being woven in India and Pakistan, many mills sold their equipment to companies overseas who used cheap labour to produce textiles. This model is still used today and caused a huge transformation in the clothing industry, paving the way for the import / export market.\nIn this era the consumption of clothing hugely increased as fashions were made more affordable.\nThis piece details the newspaper adverts from the companies that operated from\nduring the 20th century.\nEmbroidered over the print are the sewing pattern pieces for a man’s shirt, which was the main item being produced at the mill at this time.\n1902 - 1909 - T.J Wood and Co wanted Hank winders and yarn sorters.\n1916 - 1918 - W.H Lee and co LTD Wanting: Night fireman, cinder wheeler,\nCotton doubler clerk, cop winder and clearer winder.\n1951 - 1954- Hussar Shirts CO LTD : Machinists required for Company\nCutters, collar makers, shirt makers , banders, pressers and folders £12-£13 per week.\n1955 1958- Sylvan sportswear / Sylvester & CO Female cutters and outdoor machinists for jackets.\n1958 - wholesalers wanted.\n1960s - Islington mill fashions\nChanges from garments made in the mill to importing them from Germany.\nFabric 4: 21st Century\nThroughout the mill’s history up until current times the building has always been filled with people sharing space in which to create.\nThis final piece pays homage to some of the current residents at Islington Mill whose logos have been combined to create an original pattern design.\nEmbroidered onto the fabric are two crowd scenes from The Burrow, the club that used to be housed here at the Mill, plus a soundwave taken from ‘Bad Apple’ from the band GNOD, who played there many times.\nThe busy interconnected pattern was created to show the varied and bustling\nenvironment that we have at the Mill. Although we may not all know each other we are all connected and share a commonality in our love of our space and the\ncommunity that we have built here together.\nThe mill provides a safe place that is home away from home for many people. It is home to painters, musicians, small businesses, performers, educators, drag artists, curators, writers, and many many artists working in every conceivable medium from video to textile, performance to clay, and beyond.\nThe connectivity between us enables us to collaborate and draw on each other’s\nspecialisms for ideas and projects, allowing us to push our work further.\nSt Philip’s Primary School:\nSt Philip’s Primary School sits just across the road from the Mill on James Street.\nWe were excited to spend a day there with the children of Year 5 and 6 exploring the theme of constructed and deconstructed garments.\nThe young people learned about the people who had worked at Islington Mill in the past, and the different kinds of jobs they did.\nThe students made their own mini raincoats inspired by the raincoats that Islington Mill was well known for in the 1960s & 70s.\nIf you look closely at the coats they have produced you can see that they are made from advertisements for jobs that were available at the mill.\nWith this project, we wanted to create something with the students working together to show that collaboration is still a huge part of our mill culture today.\nAs a full class we made collages containing visual elements from our heritage research.\nThe collages were then used to fill in shirt and jacket pattern pieces, linking directly back to the production of clothing past and present at Islington Mill.', 'Top 10 OSHA Standards Most Frequently Violated by Workplaces\nThe Occupational Safety and Health Administration (OSHA) enforces standards and regulations to ensure the safety of workplaces and the workers within them. It’s essential for offices and organizations to follow these regulations, but there’s a surprising amount of employers who simply aren’t aware that these standards and regulations exist, let alone that they’re not meeting them. Each year OSHA publishes a list of standards that workplaces most frequently violate. Make sure your workplace is not only safe, but meeting OSHA regulations. Don’t make the same mistakes other workplaces do and avoid these 10 most common violations.\n1. Fall protection: construction\nThe most frequently violated OSHA standard by a workplace is fall protection, particularly for the construction industry. This standard requires workplaces to provide fall protection systems. OSHA states, “Each employee on a walking/working surface (horizontal and vertical surface) with an unprotected side or edge which is 6 feet (1.8 m) or more above a lower level shall be protected from falling by the use of guardrail systems, safety net systems, or personal fall arrest systems.” If you have areas in your work environment that have exposed open edges, there must be something there to protect workers from falling.\n2. Hazard communication standard: general industry\nThis standard requires employers to outwardly and openly communicate any hazardous chemicals that exist within the workplace so employees and workers are aware of them. All communication about hazardous materials within the workplace must be transparent and clear for employees to understand.\n3. Scaffolding general requirements: construction\nOSHA requires that any scaffold in a workplace must be able to support its own weight and at least 4 times the maximum intended load applied to it. Many workplaces violate this standard as they’re unaware of exactly how much weight their scaffolding is capable of holding. It’s these small details that when paid attention to, can prevent accidents from happening and more importantly, keep workers safe.\n4. Respiratory protection: general industry\nIn particular work environments, air quality can be compromised by harmful dusts, fogs, fumes, mists, gases, smokes, sprays, or vapors. This OSHA standard sets out to provide workers with the proper respiratory protection that aids them in the exposure to air contamination. This ensures that employees can breathe safely in their workplace.\n5. Control of hazardous energy\nHazardous energy refers to sources of energy from electrical, mechanical, hydraulic, pneumatic, chemical, thermal, or other sources in machines and equipment that can be hazardous to workers. You can imagine the workplace emergencies and disasters that occur when machines malfunction, whether it’s electrical, chemical, or mechanical. This OSHA standard protects employees when these malfunctions happen.\n6. Ladders: construction\nIn order for workplaces to meet OSHA standards ladders have to be able to hold a certain amount of weight. This standard specifies that all ladders must be able to hold 4 times their intended load.\n7. Powered industrial trucks, general industry\nFor companies who have employees operating industrial trucks powered by electric motors or internal combustion engines, this standard protects workers from malfunctions within those vehicles. Whether those malfunctions occur because of design or upkeep in maintenance, The variety of accidents that can occur when workers aren’t protected properly are extremely dangerous. This standard insures that trucks are up to date on inspections and marked with the proper tags, plates, and decals that prove the vehicles to be completely safe for workers to use.\n8. Machinery and machine guarding\nHeavy machinery needs to be used by workers with the proper protection. To meet OSHA standards, workers operating machinery must be protected by a machine guard that keeps their body from coming in contact with sparks or scraps of material exerted from the machine during operation.\n9. Fall protection, training requirements\nAccording to OSHA, falls are the most common cause of injuries in the workplace. This standard sets in place the training requirements that employees must receive in relation to fall protection. Employers are required to provide workers who are exposed to fall hazards with the proper training courses.\n10. Electrical, wiring methods, components and equipment: general industry\nPoor electrical wiring can cause fires, sparks, and is an overall danger to employees and workplaces. This standard sets regulations that insure all electrical wiring is consistently safe throughout the entire workspace.\nOSHA creates these standards to keep workers safe. Make sure your workers feel protected and don’t make the same violations that most other workplaces do. Meet these 10 most frequently violated OSHA standards and give your employees the wonderful feeling of safety they deserve.']	['<urn:uuid:d550f157-8c59-4a53-b710-6f74518c3974>', '<urn:uuid:4f50e7c1-c61f-4793-87cd-8ecc4f3b0678>']	open-ended	direct	long-search-query	distant-from-document	multi-aspect	novice	2025-05-13T03:20:41.944655	15	112	2202
76	sarod string count total number	The sarod has 25 strings in total, with 18 sympathetic strings, 4 main playing strings, and 3 rhythm strings.	"['The classical tradition in Indian music dates back over 3,000 years to the Vedas, the earliest Hindu spiritual texts. The Sama Veda speaks of ""Nada Bramha,"" the concept that ""music is the language of God."" Based on the fundamentals of Raga (melody) and Tala (rhythm) the music has developed continuously through ancient and medieval times into a system capable of expressing the finest shades and degrees of color and emotion. Indian classical music utilizes the same 12 note scale as is used in the West, except that the notes are used in just (pure) intonation rather than the equal temperament developed in Europe. The existence of ""microtones"" between the standard notes is also recognized.\nA raga is formed from a series of ascending and descending notes selected from a given music scale. Within this skeleton, the musician brings out the melody that gives a particular raga its character and mood: joy, sadness, romance, or a combination of these and other basic emotions.\nIn a classical performance, the raga is presented in two sections. In the first part, called alap , the musician plays unaccompanied and presents the notes contained within the raga, proceeding until all the notes and their interrelationship are explored. This allows the character of the notes and the raga to be shown in a framework free of a fixed rhythmic structure.\nThe second section, gat, is marked by the entrance of the accompanying table player. From this point the raga is presented within a rhythmic cycle, having a specified number of beats, called the tala. The most common cycles contain 16, 10, 7, or 6 beats, subdivided into blocks of 2,3, or 4 beats. The music takes the form of theme and variation with the tabla maintaining a fixed pattern while the instrumentalist solos, and improvising in turn when the instrumentalist returns to the initial theme. The interplay or musical exchange between the instrumentalist and the accompanying tabla player revolves around showing the sam, the downbeat of the cycle. The speed and energy of the exchange increases throughout the composition building to a climax at the end of the piece.\nThe sarod evolved into a classical instrument about 150 years ago, an expression of the combination of the classical, court-based tradition of the Moghul Empire with instruments derived from the folk-based traditions of Central Asia. The body of the sarod is carved from a single piece of teak covered with a skin head. The steel fingerboard is fretless, permitting the use of the slides, ornaments, and microtones characteristic of Indian music. The brass bell at the end of the instrument acts as a resonator. The sarod has 25 strings, 18 of which are sympathetic. Four main playing strings produce the same note range as a viola. Three rhythm strings are tuned to the tonic note.\nThe tabla is the classical drum of North India, used to accompany classical vocal or instrumental music since its development in the 18th century. It consists of two small hand drums, the right hand drum is made of rosewood, the larger left hand drum of copper or brass. Both are covered with heads made of multiple layers of goatskin. The black circle of paste and iron filings in the center permits the drum to be tuned precisely to a particular note. The drums, played separately and together, are capable of a wide variety of specific sounds or syllables which are combined into characteristic patterns and compositions.\nThe tanpura, usually played in the background during a classical concert, provides the tonic drone essential to classical Indian music.']"	['<urn:uuid:0961e6b6-dc62-4234-8edc-a877ce05c14c>']	factoid	with-premise	short-search-query	similar-to-document	single-doc	expert	2025-05-13T03:20:41.944655	5	19	594
77	looking to improve air quality at home what differences between humidifier and air purifier price range and main benefits	Humidifiers and air purifiers serve different purposes and have different price ranges. Humidifiers add moisture to dry air and typically cost between $15-$500 for portable models, while whole-house systems can cost up to $1,000. Air purifiers remove pollutants like dust, pollen, and smoke, and generally cost between $100-$1,000 for standard models. Humidifiers help with dry skin, sore throat, and congestion, while air purifiers improve air quality by removing contaminants and allergens.	['Although air purifiers and humidifiers have a massive impact on your home’s air quality, they affect it differently. Each has its unique benefits, and many people often have both for use in different situations.\nBut, if you are not sure which one you need between these two, here we look at them side by side to highlight how they differ and the best situations to use either.\nAir Purifier vs. Humidifier\n1. Application: Air Cleaning vs. Moisturizing\nWhile these two tools are meant to improve your home’s air quality, they do it differently. The air purifier’s primary purpose is to make the air cleaner by removing common pollutants. Also, many types can improve the smell by eliminating foul odors.\nAir humidifiers add much-needed moisture to your air to ensure you do not breathe in dry air, which can have adverse health effects. Dry air can be very problematic, especially for individuals with chest or nasal congestion.\nAdding some moisture to your air raises humidity levels and provides relief to these issues. Hence, as the air dries out in the cold winter months, a humidifier is always a handy home appliance to have around.\n2. Types: Variety of Options to Choose from for Both\nBoth air purifiers and humidifiers use different technologies, so they are available in various types, which you should know when deciding what to choose.\nFor air purifiers, the types typically depend on the filter type the machine uses. Here the most common options are HEPA, activated carbon, ultraviolet, and negative ion.\nHEPA air purifiers use filters to trap contaminants, which are in many instances at least 99.97% effective at trapping 0.3-micron size contaminants. Activated carbon ones are for odor removal, ultraviolet kills bacteria and viruses, while the negative ion purifiers will trap fine particles as small as 0.1 microns.\nWith the air humidifiers, the main types are warm mist, cool mist, and ultrasonic. Warm mist humidifiers heat up water to produce a warm mist that is pumped into the air while cool mist evaporates cool but invisible moisture into the air. On the other hand, the ultrasonic humidifiers use a metal diaphragm to create water droplets that are then pushed into the air by a fan.\n3. Removes: Air Purifiers Remove Much More from the Air\nWhen it comes to removing things from the air, purifiers do much more than humidifiers. While a humidifier’s primary and perhaps only role is to remove the dry air by adding moisture, a typical air purifier can remove dust, pet dander, pollen, smoke, and a wide variety of other airborne allergens or pollutants.\nSome air purifiers also come in a hybrid design that allows them to both clean and humidity the air. These models are highly convenient and can help you save money since you will not need to buy two separate tools for the different functions.\n4. Cost: Humidifiers are Typically More Affordable\nHumidifiers are relatively simpler tools, given they perform a much simpler task than air purifiers. Hence, they tend to be more affordable as you can get one for as little as $15, and the price for most portable standalone models hardly goes past $500.\nHowever, the whole house humidifiers can cost up to $1,000 or more. Prices for good air purifiers range between $100 and $1,000, but you can still get a few models that will be a little cheaper than this. Also, the whole house air purifier system can set you back thousands of dollars.\nAir purifiers and humidifiers are two essential tools for improving your air quality, but they do it differently. Therefore, if you have dry air in winter or live in an arid climate, a humidifier is the best for you. However, if you want to remove pollutants and contaminants from your air to make it cleaner or have a respiratory condition that worsens from breathing polluted air, go for an air purifier.', 'As global concerns around air quality grow, it’s not surprising that people want to know how best to keep their indoor air clean and their loved ones safe.\nThere is quite a broad and diverse range of devices available on the market today, all of which aim to help improve air quality in your home or office. Humidifiers and air purifiers are two devices specifically designed to enhance breathing spaces.\nCan you use a humidifier and air purifier in the same room? Yes, you can safely and effectively use a humidifier and an air purifier at the same time and even in the same room without any major issues. While one affects the level of moisture in the air, the other affects the quality of the air.\nIn this article, we will explain the roles of each and what options might be best for you and your specific needs.\nWhat Does a Humidifier Do?\nIf you’ve ever lived near the coast or traveled around South East Asia during the summer months, you are probably no stranger to humidity.\nEven if you have never experienced such extremely high levels of humidity, you are still probably familiar with that balmy, uncomfortable feeling that you sometimes get in the summer.\nHumidity is merely the amount of moisture in the air. While humid conditions can be quite uncomfortable, the absence of moisture can be equally so.\nIn the winter months, as it gets colder, the air tends to get drier. This, along with factors such as indoor-heating and reduced ventilation, can leave your house with very low moisture levels (source).\nThis aridity is where a humidifier comes into play. This device helps to dispel dry air by adding moisture to a room.\nSo if you do find that the air in your home gets too dry, then you may consider investing in a humidifier.\nHumidifiers and Health Benefits\nHumidifiers have a number of health benefits that can counter the adverse reactions brought on by dry air.\nA lack of moisture in the air invariably leads to a lack of moisture in your body, which can cause symptoms such as a sore, scratchy throat, nose bleeds, and itchy eyes.\nHumidifiers can help keep airways in the body functioning correctly. When our airways dry out, their functions are compromised, as the mucus membranes need to remain moist.\nA decline in moisture can affect both the hair and the skin. As our skin is over 60% water and needs to absorb moisture from the air, excessive aridity can cause the skin to crack and hair follicles to break (source).\nIn addition to helping keep our airways moist and our skin hydrated, humidifiers can aid with the following conditions:\n- Sinus-related issues such as congestion and runny nose.\n- Dry skin and itching.\n- Allergy-related symptoms: hay fever, sneezing, & itchy sinus passages.\n- Nose bleeds caused by dry air.\n- Sore and dry throat.\n- Ease the symptoms of colds and flu.\nHow Do I Know if I Need a Humidifier?\nYour decision to invest in a humidifier or not will depend on the humidity levels in your home, as well as your body’s response to moisture decline.\nThe EPA (Environmental Protection Agency) recommends that you keep the humidity levels between 30%-50% (source).\nIf you live in a frigid, dry area, you may struggle to maintain this level of moisture without a humidifier, especially in the winter months.\nOne way of checking the humidity levels in your home is to buy a hygrometer, which is a specially-designed device for measuring the moisture in a room (source).\nSome humidifiers come with a built-in hygrometer. A hygrometer is something to look out for when purchasing a humidifier because you don’t want to let a room get too humid. High humidity can cause problems such as mold, bacteria, and dampness.\nOn a separate note, if you do have problems with high humidity levels, you can look into a dehumidifier, which reduces moisture.\nIf you don’t feel the need to invest in a hygrometer, then you can look out for other signs. The presence of static electricity and peeling wallpaper are both indications that the humidity levels in your home may be too low.\nHumidifiers and Health Concerns\nBoth the EPA and the CPSC (Consumer Product Safety Commission) have conducted studies on the health concerns of humidifiers.\nAs humidifiers do increase moisture in a room, they can also encourage the presence of microscopic organisms, which include things such as mold, bacteria, minerals, and allergens.\nThe EPA and CPSC have found that while all types of humidifiers have the potential to emit harmful particles into the air, two kinds of humidifiers are more likely to do so: namely, the ultrasonic humidifier and impeller humidifier.\nUltrasonic humidifiers generate a mist by releasing ultrasonic sound vibrations. While impeller humidifiers, also known as “cool mist” humidifiers, create a cool mist utilizing fast rotating disks.\nThese humidifiers are more of a risk because of how they create the “cool mist.” The mechanisms essentially pound the water into mist. However, these same mechanisms cannot discern between water and particles such as minerals, mold, and bacteria (source).\nWhile the water is aerosolized to create a fine mist that we breathe in, so are the harmful pollutants, resulting in potential respiratory problems.\nIf you do own a humidifier, you may have noticed a fine white powder in your home. The minerals in the water cause this, and that’s why it’s important to be mindful of the water you are using in your humidifier.\nIf you are concerned about the risks of running a humidifier in your home, there are a few things that you can do to help ensure that you don’t experience any health problems.\n- Only use your humidifier when absolutely necessary\n- Do this by keeping a watchful eye on the humidity levels in the room\n- Try to only use distilled and demineralized water in your humidifier\n- Boiled water is also safer than plain tap water\n- Change the water in your humidifier frequently\n- Clean your humidifier twice a week with natural detergents\n- Use the manufacturer’s guide to install and maintain the device\nWhat Does an Air Purifier Do?\nUnlike humidifiers, which control the level of moisture in the air, an air purifier controls the quality of the air. They can clean the air of any unwanted substances that may be polluting your home.\nThey work in two ways, either by purifying the air through the use of a filter system or by using another method such as ionization, UV, or ozone (source).\nAir purifiers help to eliminate contagions such as mold, dust, spores, and other harmful particles that are circulating in the air. Purifiers that use filter systems simply filter the pollutants out while the methods are a bit more complicated.\nDo I Need an Air Purifier?\nThere are several reasons you may wish to invest in an air purifier. One reason may be that you have a high level of pollutants in your home.\nOther reasons you may be considering an air purifier is if you have indoor pets, if your house is poorly ventilated, or if you are in the vicinity of paints/chemicals.\nIt’s important to remember that the reach of an air purifier does not extend further than the space in which you place them. Hence, it’s a good idea to consider several units throughout the house or to place them strategically in the common areas.\nHumidifier or Air Purifier: Do I Have to Choose?\nAs you can have a humidifier and an air purifier working in the same room at the same time, you don’t really have to make the hard choice. However, it may be prudent to consider whether you need them both.\nUnlike humidifiers, air purifiers can be used all year round. It is only when the air in your home is dry that you really need a humidifier.\nHowever, based on the potential health risks of having a humidifier, the addition of an air purifier may help to ensure that the humidified air gets cleaner and any pollutants are removed.\nWhile they both have very different functions, they make quite a good team. Air purifiers filter the humidified air and can help to remove the aerosolized pollutants that were released by the humidifier.\nWhat Type of Humidifier Do I Need?\nIf you’ve decided in favor of a humidifier, here are the options available to you. We can largely divide these into two categories: central humidifiers and console/portable humidifiers.\nA central humidifier system is a fancier and pricier option. It is very convenient as HVAC technicians build these into your home’s central system.\nAs such, you can have total control over the humidity level in your home without worrying about separate units for each room. They also pose a lower risk of harmful contaminants such as molds and also require less cleaning (source).\nConsol and Portable Humidifiers\nConsol and portable humidifiers are a more practical option if the cost is an issue for you. Unlike a central system, console and portable humidifiers require that you move them around from room to room.\nThey can be cumbersome if they are large; however, with a portable humidifier, you don’t have to worry about humidity levels in a room where you don’t want any extra humidity, such as the bathroom.\nYou can break the types of humidifiers down even further into four sub-categories.\nThis system works by pushing air through a wet filter or belt. People in the market for a humidifier frequently seek out this model because they are more affordable.\nEvaporators are only available as consol/portable models and so have to be moved from room to room.\nAs discussed, this humidifier produces a “cool mist” by rotating disks. Like the evaporator models, impeller humidifiers are popular because they are reasonably priced.\nImpeller humidifiers come as console/portables, and you can also use them in a single room at a time.\nThis humidifier system uses electricity to generate steam, which then cools down before it dispels it into the air. These humidifiers are affordable and run a low chance of producing mold.\nYou should always use stem humidifiers, if bought as a portable or console device, with caution. The hot water inside, which makes the steam, can be dangerous for pets and small children (source).\nAlso, because it uses steam, it runs the risk of over-humidifying a room and requires more frequent cleaning.\nThis humidifier generates a cool mist through ultrasonic sound waves. They are affordable and safe for households with pets and children.\nHowever, they do require frequent cleaning and run a higher risk of dispersing pollutants into the air.\nAll of these humidifier options have their pros and cons. It really depends on your budget, time, and household situation.\nIf you’d like to know more about humidifiers in today’s market, Consumer Reports has put together a convenient guide to buying a humidifier.\nWhat Type of Air Purifier Do I Need?\nIf you live in an area with high humidity and do not require a humidifier, then you may only want to invest in an air purifier.\nIn addition to the two main methods of air purification, there are five other models available on the market today.\nFilter Air Purifier\nFilter air purifiers use HEPA filter technology. HEPA stands for High-Efficiency Particulate Air filters. The standards define these filters by their ability to filter out 99.97% of particles bigger than 0.3 microns (source).\nThe filter can last up to 4 years before you have to replace it, and it is a very effective air purifying system. However, it is quite heavy on energy.\nIf you are interested in the various types of air filters and their abilities, you may like to read about the benefits of a MERV 8 filter.\nCarbon Air Purifier\nA carbon air purifier uses a carbon filter to purify the air, and activated carbon has a long history of use for purification purposes.\nCarbon filters do their best work when it comes to foul odors, cigarette smoke, and unfavorable gases. The downside of the carbon air filter is that they aren’t very effective at filtering out allergens and other microorganisms.\nIonic Air Purifier\nThe ionic method of air purification is a bit more scientific. It involves a negatively charged ion that uses a kind of magnetism to attract particles such as dust and spores (source).\nHowever, ionic air purification cannot eliminate germs or foul smells, and they run the risk of re-contaminating a room. As such, this method is a less effective method of air purification.\nOzone Air Purifier\nThe ozone air purifier method of air purification involves the production of a chemical called ozone. Ozone air purifiers are very good at removing odors.\nHowever there is some debate around the safety of ozone air purifiers as ozone, in large quantities, can be quite dangerous to human health.\nIt may cause adverse reactions such as coughing and also aggravates asthma. Some countries have even gone so far as to ban the use of ozone air purifiers (source).\nUltraviolet Light Air Purifier\nUV light works to kill bacteria and other germs. However, these air purifiers work best in conjunction with another method, preferably filter, as UV light cannot target odors or allergens.\nAir purifiers all have their strengths and weaknesses. It really just depends on what you are looking for and what kinds of pollutants you want to target.\nIf you’d like to see which air purifiers are available on the market right now, Consumer Reports has made a list of the Best and Worst Air Purifiers of 2020.\nHumidifier/Air Purifier Combos\nSince the demand for humidifiers and air purifiers has grown, a recent development on the market has been a humidifier/air purifier combo device. If you are looking to invest in both, then why not consider getting them in one convenient unit?\nChoosing to buy a combination system can help save on cost, space, and energy usage (source). It can also help ease respiratory issues and make your living space a lot more comfortable.\nOne further point in favor of the combination option is that their separate parts perform together cohesively.\nIf you do decide to have two separate units, you need to make sure that one doesn’t negatively impact the function of the other. For example, you wouldn’t want the air filter to get damp because it is too close to the humidifier.\nWhat Factors to Consider When Buying a Humidifier or an Air Purifier?\nWe’ve discussed the various options available on the market concerning the different kinds of humidifiers and air purifiers. Now let’s look at some of the factors to take into consideration before going out and buying one.\nAs with most things in life, the cost is often a significant factor. If you are looking to install both devices, then it may be a smart idea to invest in a combo system as it will most likely work out to be cheaper.\nYou also need to consider which devices use more energy. Air purifiers that use a HEPA system can draw quite a bit of power. Consider looking at energy-efficient models that will save you money in the long run.\nWe’ve discussed the health benefits and possible side effects of both humidifiers and air purifiers. In the end, it may be wise to forgo cost in terms of the healthy options for you and your family.\nNoise is a significant consideration, especially if you have a baby or small child who is sensitive to sound.\nMake sure that the system you decide to buy isn’t too noisy; white noise can be pleasant, but something that wakes up a sleeping baby is a definite no-no.\nAs with health, safety should be a priority. If you purchase a portable system, make sure that it is in a secure place and cannot be knocked over by an animal or child.\nAlso, be aware of factors, such as hot water, concerning humidifiers, and even electrical cable. Make sure you take all the proper precautions and ensure you install the units properly.\nWe are all busy, so you may not want to add another job to the already long list. It may be tempting to look for a machine that doesn’t require too much maintenance/cleaning.\nHowever, bear in mind that these machines do need regular cleaning to work correctly and not cause any adverse effects. Always follow the manufacturer’s instructions to ensure that you clean the system frequently and adequately.\nAll units require frequent cleaning; however, you may be able to purchase a model that is easier to clean, thus saving you time.\nIf a central-system isn’t in your budget, you need to consider the kind of coverage that you will get from a console/portable device.\nThis means factoring in the size of the room as well as how many rooms in your house you think would require a humidifier and air purifier.\nHumidifiers and air purifiers can work alone or together to improve the overall quality of the air inside your home.\nWhile they do work well as individuals, together, they can act to improve respiratory problems, eliminate harmful pollutants, and make your living space much more comfortable.']	['<urn:uuid:4fbb38f9-a7b7-45a7-ba4d-04dcdbaf8bbe>', '<urn:uuid:1c84f16c-b413-4947-b7e0-52afe24b3969>']	factoid	with-premise	long-search-query	similar-to-document	three-doc	novice	2025-05-13T03:20:41.944655	19	71	3525
78	looking for benefits of being bilingual in old age brain health research findings	Research shows that bilingual seniors tend to stay mentally sharp as they age, are more likely to recover from a stroke, and show signs of dementia and Alzheimer's four to five years later than people who speak only one language.	"['James A. Garfield ranks among the less remarkable U.S. presidents, owing largely to the fact that he was assassinated just 200 days into his first term. For that reason, Garfield is less remembered for his policy achievements than for his personal quirks.\nThe president was both bilingual and ambidextrous. It\'s rumored that he entertained guests by writing in Greek with one hand and Latin with the other simultaneously. Garfield was also known for his wisdom and restraint. ""Right reason is stronger than force,"" he once said. He wasn’t the kind to lose his cool. As it happens, research suggests these characteristics are related—learning a second language can improve self-discipline. Studies show that bilingualism is associated with better executive function, a term used to describe several higher-order cognitive skills, including the ability to control our own behavior. Executive function allows us to play a game of chess or follow the plot of “Mad Men”, but it’s best understood as what allows us to make plans, get organized, and stay on task. Learning a new language can help cultivate these skills. “I speak Korean and English,” says Yang Hwajin, a professor of psychology at Singapore Management University. “When I speak English, I have to inhibit thoughts about Korean grammar and focus on English grammar, as the two languages do not share any grammatical structure. Speaking these two languages has trained me to inhibit distractions and focus better.""\nThis skill, known as task switching, is related to executive function. To do it well, one ought to focus on one task (speaking English) and then another (speaking Korean), ideally without jumbling words or syntax between the two different languages. This entails working in one mode and then the other. Infants reared in bilingual households often see greater cognitive development. Even very young children who grow up hearing two different languages are able to sort one from the other—a difficult mental task. These benefits are apparent as children continue to grow and evolve. Students in dual-language classrooms, for example, tend to perform better in some areas in school. “What we have found in the last three decades is that bilingualism has substantial impact on cognitive function—the way that we think, make decisions, perceive things, solve decisions, and so on,” Hwajin says. It’s worth noting that some of this research is contested. Scientists have yet to reach a consensus on how bilingualism shapes cognitive development, but they generally agree that learning a new language is a workout for the brain. And this reaps measurable benefits well into old age.\nLearning a new language tones the brain by strengthening neural networks. While some parts of the brain control a specific task—the visual cortex processes sight, the auditory cortex processes sound—there is no part of the brain that specifically controls language. Speaking a language—even just one language—is such a complex task that it engages the entire brain. One must understand the meaning of thousands of words, the way they fit together, and the cultural context that offer weight and meaning. These processes must happen simultaneously and in conjunction, each a moving part in a complex machine. Learning a new language tightens the gears. Bilingual seniors tend to stay sharp as they age, are more likely to recover from a stroke, and have shown signs of dementia and Alzheimer’s four or five years later than their monolingual peers. The bilingual brain features stronger connections between disparate parts, allowing bilingual seniors to harness resiliency others may lack. These benefits are immensely valuable, and speaking additional languages can come in handy. It allows you to communicate with a wider range of people, navigate other parts of the world, and better understand different cultures. It’s useful anywhere, from the bodega to the boardroom. More than half the population is onto this. “One language sets you in a corridor for life,” says psycholinguist Frank Smith. “Two languages open every door along the way.”']"	['<urn:uuid:eede8854-4ded-49e3-b370-0947a4b246f8>']	factoid	with-premise	long-search-query	similar-to-document	single-doc	novice	2025-05-13T03:20:41.944655	13	40	650
79	what is largest amount of burgoo gustave jaubert ever prepared single event	The largest recorded amount of burgoo prepared by Gustave Jaubert was 6,000 gallons, which he made for the Grand Army Veterans in Louisville.	"['I s it a soup or a stew? A BUR-goo or a bur-GOO?\nAlthough the dish has been a Kentucky crowd-pleaser for more than 150 years, few culinary historians, indeed few Kentuckians, see eye-to-eye on the who, what, when, where, and why of burgoo. And how could they? With so much speculation surrounding burgoo\'s origin and its exotic name, who\'s to know what\'s fact and what\'s fiction? Get a taste of some hypotheses:\n- Does the word burgoo (and possibly the recipe) originate from the bulgur porridge that sustained sailors on long sea voyages back in the 1700s?\n- Is burgoo a contraction of barbecue and ragoût, two filling but frugal Kentucky dishes prepared in feed-an-army batches that were often served in tandem?\n- Were early burgoos, stirred up in giant iron cauldrons at work camps scattered across the Bluegrass State, such a hodgepodge of game and game birds—""whatever walked or flew,"" someone joked—they were also called ""road-kill stews""?\n- Is burgoo a Kentucky spin-off of Brunswick stew, an equally controversial, early, catch-all ""critter"" stew? Virginians and Georgians both claim to have created Brunswick stew and still squabble over bragging rights.\n- Did French chef Gustave Jaubert, while serving Confederate general John Hunt Morgan in 1860, create the first Kentucky burgoo by loading one of those wan work-camp stews with blackbirds? And might ""burgoo"" be how that Frenchman pronounced bird stew?\n- Was the secret ingredient in Jaubert\'s burgoo, the one that mellowed its unseemly mishmash, a black snake that splattered into the pot from a tree directly above?\nSo many questions with so few answers. What is known is that shortly after the Civil War, Frankfort\'s Buffalo Trace distillery hired Jaubert to cook for its employees. (Two of his big iron burgoo kettles are still on view at the distillery\'s Burgoo House.) Before long Jaubert, now called ""the Father of Burgoo,"" was catering events of one sort or another across the state. On November 7, 1897, The New York Times reprinted a Louisville Courier-Journal account of a Jaubert feast that included the serving of both burgoo and barbecue—a culinary tradition that lingers to this day.\n""The making of good burgoo,"" the article declared, ""is even more difficult than the roasting of the meat and requires more time.…Its ingredients are 400 pounds of beef, six dozen chickens, four dozen rabbits, thirty cans of tomatoes, twenty dozen cans of corn, fifteen bushels of potatoes, and five bushels of onions."" With ten cooks assisting him, Jaubert slow-simmered 1,000 gallons of burgoo, the story notes. Piece of cake compared to the 6,000 gallons he\'d reportedly bubbled up two years earlier for the Grand Army Veterans in Louisville.\n""Colonel Thomas H. Sherley thought it would be impossible for me to cook on such an immense scale,"" Jaubert said of that event, ""but I told him if he would furnish the provisions I would prepare a meal for one million people. I got through without any trouble."" Little wonder that Jaubert, though never officially crowned, is considered Kentucky\'s first ""Burgoo King,"" a title now reserved for the rock-star chefs that headline burgoo cook-offs and festivals in Kentucky as well as in Illinois, Indiana, and West Virginia.\nNo two burgoo meisters— indeed, no two cooks—make burgoo the same way, and all are fiercely protective of their recipes. Some like it hot (no stinting on chile peppers in their renditions), others prefer a burgoo so thick a spoon will stand straight up in the pot, and still others fire up their burgoos at dusk and keep them at a gentle simmer for 24 hours. What most burgoos do have in common, however, are platoon-size proportions as well as some secret something—a hefty splash of bourbon, maybe some innards (kidney or liver, say) for enrichment, or a few trotters, perhaps—and invariably some unexpected, unidentifiable mix of herbs and spices.\nEver since Jaubert, burgoos have been de rigueur at political rallies, church suppers, and family reunions in Kentucky. More important, they\'re as integral to the Kentucky Derby as the singing of ""My Old Kentucky Home"" and a parade of Thoroughbreds. In 1932, a Bluegrass colt named Burgoo King—yes, Burgoo King—won both the Derby and Preakness, two of the three legs that make up Thoroughbred racing\'s Triple Crown.\nAccording to Charles Patteson\'s Kentucky Cooking (1988, HarperCollins), ""Burgoo…midway between a hearty soup and a stew…succeeds the juleps in the guests\' cups as a first course."" At the Kentucky Colonels\' barbecue the day after the Derby, those would be silver Mint Julep cups, a far cry from the battered tin mugs used to scoop up burgoo back in work-camp days.\nAnd a final word about the pronunciation of burgoo: The country club and horse-y sets, I\'m told, favor BUR-goo, while almost everyone else accents the last syllable.\nBurgoo photo: Kriech-Higdon Photo\nSee More on the Kentucky Derby:\n- Complete Kentucky Derby Package ›\n- The Secrets to a Perfect Mint JulepRecipe Included ›\n- A Guide to Bourbon and Our Favorite Bottles ›']"	['<urn:uuid:cb711d58-614b-4179-8931-3d4ed88db0c2>']	factoid	direct	long-search-query	similar-to-document	single-doc	expert	2025-05-13T03:20:41.944655	12	23	831
80	What support do schools give to mentally disabled children?	Schools provide comprehensive support for students with intellectual disabilities through Individualized Education Plans (IEPs). These plans are developed by a team including the student, parents, principal, and teachers to determine necessary services and supports. Support includes individualized instruction, peer tutors, and various assistive technologies like picture-based learning materials, digital recorders, and communication devices. The IDEA requires schools to keep these students in regular classrooms with non-disabled peers whenever possible, while providing appropriate accommodations to help them access the curriculum at their own pace.	"['Individuals with Disabilities Education Act (1975)\nIn 1975, the United States Congress passed the Individuals with Disabilities Education Act, referred to as the IDEA, which codified the right of all American children to a free and appropriate public education regardless of disability status. The IDEA requires all public schools that accept federal funds to provide education that meets the needs of students with disabilities at the public expense. Prior to IDEA, many students with disabilities went without any educational opportunities, and many faced confinement in institutions. The IDEA enshrined the right to education for children with disabilities, allowing millions of children to learn in a public-school classroom by setting guidelines for accessibility and the instruction of students with disabilities in American public schools.\nDuring most of the twentieth century, children with disabilities frequently faced discrimination in public education either through the lack of appropriate accommodations or complete exclusion from local schools. At the start of the 1970s, only about twenty percent of children with disabilities attended a public school. Often, instead of attending local schools, children who were blind, deaf, had physical disabilities like cerebral palsy, or had intellectual disabilities like Down syndrome were sent to institutions with little to no educational instruction. Parents and disability activists at the time called for an end to forcing children with disabilities into separate learning facilities.\nThe IDEA came about after decades of civil rights struggles involving the American education system. In the 1954 case Brown v. Board of Education, the US Supreme Court found that racial segregation of students in public schools violated the Equal Protection Clause of the Fourteenth Amendment. The Equal Protection Clause requires all people to be subject to equal treatment under the law. Following the end of segregation based on race, disability advocates began to file lawsuits of their own against the continued segregation of students with disabilities in public education. Two 1972 federal court cases, Pennsylvania Association for Retarded Citizens (PARC) v. Pennsylvania, hereafter PARC, and Mills v. Board of Education, hereafter Mills, ended with the decision that schools are required to provide education to fit the needs of students with disabilities. Despite the judicial victory, there was still a lack of a federal standard for special education programming, and enforcement of accessibility requirements, so disabilities advocates pushed for a federal law enshrining education rights.\nThe legislative history of the IDEA began in 1960 with the Elementary and Secondary Education Act of 1965, which was the first time the federal government allocated direct aid to states for public education. A portion of the money included funding for state-run institutions for the Blind, Deaf, and people who were, at the time, called mentally retarded, a term which is unacceptable for describing people with disabilities as of 2022. The following year, Congress amended the Elementary and Secondary Education Act to create the Bureau for the Education of the Handicapped. A few years later, Congress passed the Education of the Handicapped Act of 1970, or the EHA, which expanded the grant offerings by the federal government for special education programming in state public schools. After the decisions in PARC and Mills, Congress amended the EHA to allow states to receive federal funds only if they implemented policies to fully integrate students with disabilities in their schools.\nIn 1975, Congress passed Amendments to the EHA called the Education for All Handicapped Children Act, or the EAHCA. The EAHCA included a bill of rights for students with disabilities that specified the right to access a free and appropriate public education, or FAPE. FAPE includes special education programming designed to meet the individual needs of a student at no cost to their family. In 1990, the EAHCA was amended once again and renamed the Individuals with Disabilities Education Act. The 1990 amendments included several changes, including the addition of autism and traumatic brain injury as eligible for IDEA benefits.\nCongress once again reauthorized the IDEA in 1997, under President William Clinton. The 1997 amendments to the IDEA included allowances for disciplinary actions schools can take with students with disabilities. Among the provisions was the right for a school to remove a student from the school for up to forty-five days if they are involved with drugs or weapon use. Additionally, the amendments codify the right of students with disabilities to continue to receive educational services even when they are expelled or suspended.\nThe most recent reauthorization as of 2022 occurred in 2004 under President George W. Bush with the Individuals with Disabilities Education Improvement Act of 2004, or IDEA 2004. Several of the amendments in IDEA 2004 involved learning disabilities, including requirements for states to develop criteria for identifying and assessing students with learning disabilities, along with a requirement that the criteria cannot include a discrepancy in intellectual ability and achievement. Additional changes required special education teachers who teach core subjects to their students to be highly qualified, which requires a bachelor’s degree, state licensure, and satisfactory completion of appropriate state examinations. The 2004 reauthorization of the IDEA established the National Center for Special Education Research within the Department of Education, which examines and improves the implementation of the IDEA and special education programs.\nIDEA is divided into four sections, labeled parts A, B, C, and D. Part A defines terms used throughout the IDEA and mandates the formation of the Office of Special Education Programs, which monitors special education funding to states. Part B outlines the requirements for schools to educate students from ages three to twenty-one as well as ensures federal funding. Additionally, Part B codifies the rights to FAPE, student evaluations for disability, input by parents and students, and learning in a least restrictive environment, which means students with disabilities should learn in settings with non-disabled peers as much as possible. Another component of Part B is individualized education plans, or IEPs. IEPs are developed in coordination with the school, parents, and the student to specify what actions the school will take to achieve a child\'s development goals. Finally, Part B mandates that children and parents are entitled to due process rights to determine if the child is receiving the proper services.\nParts C and D expanded the programing offered by the IDEA. Part C focuses on early intervention for infants and toddlers with disabilities from birth to two years of age. Similar to IEPs, Part C requires states that receive federal funds from IDEA to develop Individualized Family Service Plans, or IFSPs, to clarify resources and goals for families with physically or developmentally disabled children. Part D provides resources for national activities intended to improve education outcomes for students with disabilities. Some Part D expenditures include improving the training for qualified special educators, translating academic research into practical tools in special education, and funding research and deployment of assistive technologies for students with disabilities.\nIDEA enforcement has primarily occurred through federal oversight and parents filing lawsuits against school districts that fail to meet their child\'s needs, however, the effectiveness of that enforcement came under threat at the start of the 1980s. Initially, in 1981, the newly elected Ronald Reagan administration declared plans to eliminate IDEA in its entirety to reduce the size of the federal government by ending the oversight required to ensure students with disabilities received FAPE. However, public outcry led them to attempt to less overtly curtail some of the rights outlined in the IDEA. One proposed change was to reduce or eliminate many of the oversight measures on school districts to reduce the burden on schools. Another proposed change was to reduce the number of students who would qualify for services by narrowing the definitions of handicaps under the law. Under such a change, simply having a disability would not necessarily deem a child eligible for services under IDEA. The administration also sought to reduce the ability of parents to challenge changes to their child\'s education plans and IEPs. Schools would no longer be required to consult parents to change an IEP. Finally, the proposed changes would have nullified all mandates for students to learn in a least restrictive environment not explicitly outlined in the IDEA itself. Overall, the proposed amendments would have reduced federal spending on special education services under IDEA by thirty percent by drastically cutting educational resources for children with disabilities.\nThe Reagan Administration\'s proposed changes to IDEA and attempts to revoke implementation of other disability legislation like Section 504 of the Rehabilitation Act of 1973, which forbade organizations that accepted federal funds from discriminating against people with disabilities, drew responses from tens of thousands of concerned parents and disability activists. Disability activists, primarily Patrisha Wright and Evan Kemp, organized a national letter-writing campaign that collected over 40,000 letters from concerned Americans, dropping off hundreds of bags containing pleas to keep the IDEA and Section 504 intact at the White House in protest. Wright and Kemp were both disabled self-advocates with decades of leadership experience in the disability rights movement. Additional protests included thousands of parents and disability community advocates attending public hearing events held throughout the country. By 1983, the administration relented, with Vice President George H. W. Bush writing a letter to Kemp saying that the IDEA and Section 504 would remain unchanged. Bush cited the outpouring of opposition from community members and parents, especially the personal stories of the people facing the loss of necessary services, as the reason for the change in policy direction.\nThe IDEA served as a clear acknowledgment of the inadequacies of American public education in service to students with disabilities. After several decades of legal development and policy implementation, nearly all children with disabilities in the United States have access to accessible education as of 2022. The US Department of Education reported that 7.5 million students with disabilities received services under the IDEA during the 2018 to 2019 school year. Millions of children who would have otherwise received little to no formal education are fully integrated into public school classrooms across the United States. While disparities in graduation rates and post-secondary education attainment persist between disabled and non-disabled students as of 2022, implementation of the IDEA continues to close the gap by ensuring students with disabilities have the opportunity to learn in public school classrooms with their non-disabled peers.\n- American Psychological Association. ""Individuals with Disabilities Education Act (IDEA)."" American Psychological Association. https://dictionary.apa.org/individuals-with-disabilities-education-act (Accessed October 4, 2022).\n- Anderson, Susan Heller. ""Goals on Handicapped Meet Wide Resistance."" New York Times, November 14, 1982. https://www.nytimes.com/1982/11/14/education/the-reagan-effect-goals-on-handicapped-meet-wide-resistance.html (Accessed October 4, 2022).\n- Brown v. Board of Education, 347 U.S. 483 (1954) https://scholar.google.com/scholar_case?case=12120372216939101759&q=Brown+v.+Board+of+Education,+347+U.S.+483+(1954)&hl=en&as_sdt=806 (Accessed October 4, 2022).\n- Education for All Handicapped Children Act, 20 U.S.C. section 1471 (1975).\n- Education of the Handicapped Act Amendments of 1986, 20 U.S.C. section 1471 (1986).\n- Education for All Handicapped Children Act of 1975 Pub. L. No. 94-142 89 Stat. 773 (1975) https://www.govinfo.gov/content/pkg/STATUTE-89/pdf/STATUTE-89-Pg773.pdf (Accessed October 4, 2022).\n- Foster, Susan G., and Martha Matzke. ""Deregulation Efforts Proceeding Rapidly: Disputes Expected."" Education Week, February 24, 1982. https://www.edweek.org/education/deregulation-efforts-proceeding-rapidly-disputes-expected/1982/02 (Accessed October 4, 2022).\n- Individuals with Disabilities Education Act, 20 U.S.C. section 1400 (1990).\n- Individuals with Disabilities Education Act Amendments of 1997, 20 U.S.C. section 1400 (1997).\n- Individuals with Disabilities Education Improvement Act of 2004, Pub. L. No. 108-446 (2004) https://www.govinfo.gov/content/pkg/PLAW-108publ446/html/PLAW-108publ446.htm (Accessed October 4, 2022).\n- Katsiyannis, Antonis, Mitchell L. Yell, and Renee Bradley. ""Reflections on the 25th anniversary of the Individuals with Disabilities Education Act."" Remedial and Special Education 22 (2001): 324–34.\n- Mills v. Board of Education of Dist. of Columbia, 348 F. Supp. 866 (D.D.C. 1972). https://scholar.google.com/scholar_case?case=16525133616378659396&q=Mills+v.+Board+of+Education+of+Dist.+of+Columbia,+348+F.+Supp.+866+(D.D.C.+1972)&hl=en&as_sdt=806 (Accessed October 4, 2022).\n- Nolan, Joseph E. ""The US Individuals with Disabilities Education Act (IDEA): Tracing Inclusion and Exclusion of the Disabled from Ford to Bush II."" Paper presented at the Society of History of Education conference in Dublin, Ireland, November 25, 2004. https://files.eric.ed.gov/fulltext/ED490776.pdf (Accessed October 4, 2022).\n- Pennsylvania Association for Retarded Children v. Commonwealth of Pennsylvania, 343 F. Supp. 279 (E.D. Pa. 1972). https://scholar.google.com/scholar_case?case=13899614143166836081&q=Pennsylvania+Ass%27n+for+Retarded+Children+v.+Pennsylvania,+343+F.+Supp.+279+(E.D.+Pa.+1972)&hl=en&as_sdt=806 (Accessed October 4, 2022).\n- Pear, Robert. ""Reagan Suspends Benefits Cutoff."" New York Times, April 14, 1984. https://www.nytimes.com/1984/04/14/us/reagan-suspends-benefits-cutoff.html (Accessed October 4, 2022).\n- Shapiro, Joseph P. No Pity: People with Disabilities Forging a New Civil Rights Movement. New York City: Broadway Books, 1994.\n- Yell, Mitchell L. ""Special Education in the United States: Legal History."" In International Encyclopedia of the Social & Behavioral Sciences (Second Edition), ed. James D. Wright, 219–24. Amsterdam: Elsevier, 2015.\n- Zettel, Jeffrey J., and Joseph Ballard. ""The Education for All Handicapped Children Act of 1975 PL 94-142: Its History, Origins, and Concepts."" Journal of Education 161 (1979): 5–22.\nHow to citeRoss, Nathaniel, ""Individuals with Disabilities Education Act (1975)"". Embryo Project Encyclopedia (2022-10-06). ISSN: 1940-5030 http://embryo.asu.edu/handle/10776/13354.\nPublisherArizona State University. School of Life Sciences. Center for Biology and Society. Embryo Project Encyclopedia.\nCopyright Arizona Board of Regents Licensed as Creative Commons Attribution-NonCommercial-Share Alik 3.0 Unported (CC BY-NC-SA 3.0) http://creativecommons.org/licenses/by-nc-sa/3.0/', ""The Individuals with Disabilities Education Act (IDEA) protects students with intellectual disabilities in the classroom. IDEA defines intellectual disabilities as 'significantly sub-average general intellectual functioning, existing concurrently with deficits in adaptive behavior and manifested during the developmental period, that adversely affects a child's education performance.' You will notice that students in your classroom with intellectual disabilities usually struggle with social skills, taking care of themselves, and communication. Their limitations in mental functioning usually result in slower learning. This means that they may learn to walk, talk, use the bathroom, eat, later than their non-disabled peers.\nStudents with intellectual disabilities that qualify for special education are put on an Individualized Education Plan (IEP). The IEP team - which includes the student, his/her parents, the principal, and both the regular and special education teachers - work together to determine what services and supports this individual child needs to be successful. Often times, the use of assistive technology is necessary and will be written into the IEP. They also determine which classroom setting is most appropriate for each student.\nKeeping students with disabilities in a regular classroom environment with their non-disabled peers is always the goal in special education. The widely accepted philosophy is that if a student with disabilities can progress and meet the IEP goals in his/her regular classroom, that is the most appropriate place for him/her. Students with intellectual disabilities may not perform at the same speed and level as their peers, but with assistance, they can access the general curriculum. Assistance can come in the form of individualized instruction, peer tutors, accommodations, and assistive technology.\nAssistive technology can be any object or device that provides a student with more access to the curriculum. Let's look at some of the ways Suzie, a student with an intellectual disability, struggles in the classroom and how assistive technology can help. Keep in mind, it would be unusual for one student to require all of these devices and supports. Also, each student is unique and requires their own individualized plan. The list here is extensive to give you a variety of ideas as you consider your own students and their needs.\n- Pictures: Suzie's speech is unclear, which makes it difficult for teachers and friends to understand what she is saying. With the help of an augmentative and alternative communication device, Suzie is able to express herself in a way others can understand. She uses picture cards and word strips to show others while she is talking.\n- Electronic devices: Certain devices, such as a tablet or ipad, use special text to speech software to act as a communication device. Suzie can select pictures or words and the device will say her message out loud. This device acts as her voice if and when she needs it.\n- Digital recorders: Suzie does not have a good memory. She has a hard time paying attention in class for a long period of time and will sometimes miss out on the instructions given for homework or projects. When she uses a digital recorder, she can take it home and listen to instructions again. With the support of this device and her parents, Suzie is able to follow instructions and turn in homework and projects along with her classmates. Keep in mind that she completes her work with accommodations.\n- Graphic organizers: Suzie is working on being able to summarize stories that are read to her. Graphic organizers give Suzie a visual prompt for the important parts of the stories and specific places to write them. As Suzie listens to a story, she can write (or draw pictures) in designated boxes on her graphic organizer. This allows her to see if she is missing anything or what she needs to listen for next. For example, she will listen for the main characters, the setting, and three main events that happened in the story.\n- Books on CD: Suzie is behind grade level in reading, and can not keep up with her class. However, she still needs to learn how to listen to a story and be able to retell and summarize what happened. She uses books on CD so she can hear the story and focus on listening rather than worrying about reading the words right.\n- Picture cookbooks: One of Suzie's goals is to learn independence. The IEP team has included goals that will prepare Suzie for semi-independent living. She practices cooking and following basic recipes that use pictures to show the instructions. The picture instructions eliminate the need for Suzie to be able to read all of the words and terms associated with food and cooking.\n- Grasping devices: Due to limitations with motor skills, Suzie has a difficult time grasping objects. This makes it difficult for her to hold objects like pencils or utensils. This little device slides onto her hand and attaches to an object to simulate the grasping position.\n- Bluetooth headsets: Being able to use a cell phone will have a significant impact on Suzie's ability to be independent. Smartphones can be an effect tool for Suzie, but it may be difficult for her to hold the phone up to her ear without pressing buttons and talk at the same time. Suzie practices making a phone call to her parents once a day during school to help her get used to using a Bluetooth earpiece.\nIntellectual disabilities affect an individual's cognitive, motor, communication, and social skills. All students with disabilities should be included in the regular classroom environment to the greatest extent possible. With the help of individualized instruction and assistive technology, students with intellectual disabilities have a better chance of accessing academic content. Assistive technology also helps students gain more independence, which prepares them for life after school.\nTo unlock this lesson you must be a Study.com Member.\nCreate your account\nRegister to view this lesson\nUnlock Your Education\nSee for yourself why 30 million people use Study.com\nBecome a Study.com member and start learning now.Become a Member\nAlready a member? Log InBack\nResources created by teachers for teachers\nI would definitely recommend Study.com to my colleagues. It’s like a teacher waved a magic wand and did the work for me. I feel like it’s a lifeline.""]"	['<urn:uuid:c581c3d6-75e3-4401-923e-287aae459a0a>', '<urn:uuid:370ffa12-a1d7-46ad-a720-d5143d92642e>']	open-ended	direct	concise-and-natural	distant-from-document	three-doc	novice	2025-05-13T03:20:41.944655	9	83	3175
81	How can the environment and care practices of domesticated horses contribute to the development of hoof problems that we don't see in wild horses?	Navicular conditions generally aren't seen in wild horses because their frogs are on the ground and their heels remain spread. In domesticated horses, improper horseshoeing can restrict the hoof and cause the heels to become contracted. This is particularly common in gaming horses, reining and cutting horses, where horseshoes are fitted close to prevent them from being pulled off during activities. Additionally, horses left untrimmed and in confined spaces can grow long hooves that can become contracted, especially in upright shouldered horses. Horses landing toe-first will grow longer heels that can become contracted.	['A Navicular Story\nPeople throw the term “Navicular” around an awful lot. Few people understand exactly what it is, how it happens or what it entails. Basically, there are two “naviculars”. There is “Navicular Syndrome” where the heels are contracted and the horse exhibits signs of Navicular lameness: showing lameness while turning or reluctant to cross one front leg in front of the other while turning. The more advanced of this is “Navicular Disease” which can only be diagnosed through radiographs. In this case, the Navicular bone has deteriorated causing bone spurs which aggravate the flexor tendon as it tries to slide over the bone while flexing the hoof. I’m not the expert on this and there is plenty of more detailed (and accurate) information out there, but I am pretty good at simplifying things. The flexor tendon runs down the back of the leg and attaches to the bottom of the coffin or pedal bone. When the muscle above pulls on this tendon it causes the hoof to lift the heel and go up on its toe and enables forward motion for the leg. As the flexor tendon curves around the heel the Navicular bone acts as a type of floating fulcrum to help it make the turn. In front of the Navicular bone is a gel filled bursa which helps it float and absorb shock. The Flexor tendon is a wide flat strap when healthy. So, what happens when the hoof gets contracted is that wide flat flexor tendon is squeezed into a narrower rounded shape. This puts more pressure on the Navicular bone and causes more pressure inside the hoof. The contracted heels restrict blood flow causing the Navicular bone to deteriorate causing spurs which tear at the flexor tendon as it tries to slide past to the coffin bone. Navicular of any kind generally isn’t generally seen in wild horses. Their frogs are on the ground and their heels are spread and stay that way. Improper horseshoeing can restrict the hoof and cause the heels to become contracted. This often happens with gaming horses, reining and cutting for example, where the horseshoes are fitted close so they aren’t stepped on and pulled off during activities. I heard from a Reining breeder and trainer that young horses shod this was are unable to compete much past 5 years old. Horses left untrimmed and in confined spaces can grow long hooves that can get contracted, particularly with upright shouldered horses. Horses coming down toe first for whatever reason will grow a longer heel and can become contracted. These photos show the contracted hoof on the left and the more normal hoof on the right. The right one also has a coating of Hoof Armor (which has nothing to do with Navicular, except that it doesn’t restrict the hoof) making it look shiny. My experience has been that Navicular Syndrome can be reversed by removing the horseshoes or cause of toe landing and, with proper trimming emphasizing the heels and frog, allowing the heels to expand. Navicular Disease, where there is bone deterioration, can’t be reversed.']	['<urn:uuid:31490acd-e54f-4350-9e31-6bfec66782c2>']	open-ended	direct	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-13T03:20:41.944655	24	93	517
82	How do archers protect themselves, and what weapons do they carry?	Archers protect themselves with layers of stuffed, quilted deer hide or cast-off pieces of armor from fallen foes. They also use leather bracers (arm guards) made of top quality, supple 2.5 to 3mm thick leather to protect their arms from bowstrings. For weapons, each archer carries a sword and a long wooden stake which they drive into the ground at an angle and sharpen to protect against mounted charges. They also carry 60-72 arrows into battle.	"[""A selection of hand tooled and plain leather archery bracers (arm guards) to suit all styles of archery.\nI offer five distinct styles of archery bracer (see below) each bracer style is quite different and designed to apeal to specific types of archer. Fortunately, archers aren't all the same and we tend to look for different features such as a 'quick release' hook and elastic fastening system for club shooting and leather lace or buckle fastening for traditionalists and re-enactors.\nOne thing always stays the same:Top quality, supple, 2.5 to 3mm thick leather\nSquire style bracer:\nThis is our 'standard' laced arm bracer and fits all sizes of archer.\nFastened with a stout leather lace (supplied) this inexpensive and virtually indestructible arm bracer suits all sizes of archer including teenagers and smaller adults. These bracers are cut from superb quality veg-tan leather and finished with a water-resistant wax.\nSquire style bracer with elastic fastening:\nIdeal for clubs, Scouts & Guides and youth organisations\nThis is the bracer you are most likely to see at any shooting ground. Exactly the same shape as the standard Squire bracer but fitted with good strong metal 'quick release' hooks and elastic loops. This will fit also teenagers and smaller adults. NOTE: These bracers are very popular with clubs, Scouts and Guides and youth groups as they offer a high level of protection along with speed and ease of removal - that means sharing kit is easier. Very tough and hardwearing too!\nCastle style bracer:\nA smaller sized bracer ideal for children.\nDesigned to fit smaller wrists and offer lots of protection. Distinctive 'castle battlement' tabs for lace holes. Fastened with a leather lace (supplied).\nFull length elastic style bracer:\nProbably our best seller.\nThis is a 'long line' bracer which extends from the wrist to just below the elbow, providing maximum protection from errant bow strings. Fastened with elastic 'loops' onto 'quick-release' metal hooks, this bracer is very comfortable, easy to use and quick to put on and remove.\nTraditional style bracer:\nDesigned for e-enactors and LARPers\nCut from best quality supple vegetable tanned leather, tooled or plain to suit, hand dyed and then carefully hand-finished with a water-resistant wax. Fastened with a leather lace (supplied) to present a traditional and authentic appearance for re-enactment, live action roleplay (LARP) or pageant.\nLongbow style bracer\nA copy of a Victorian design\nThis gorgeous bracer is made from a single piece of vegetable tanned leather and has three solid brass buckles to fasten it. These are not suitable for children or those with very slim wrists or short arms. They are designed for big people who shoot traditional longbow or war bow. They can't be altered to fit small sizes.\nAll my bracers are made in my Herefordshire workshop. When you buy from me you are buying directly from the person who made the item and directly supporting the British economy. I really appreciate that. Thank you!\nOrigin of the word 'Bracer': From around 1350–1400; Middle English / Anglo-French; Old French braceure. Meaning to brace arm."", 'Weapon Files – The Longbow\nAn insider’s look at the weapon that ended the mounted knight’s reign\nThis Welsh-English weapon’s lethality and rate of fire made it the “machine gun” of the medieval battlefield, yet only England trained thousands of men to use it. King Edward I, who reigned 1272-1307, created his own large corps of longbowmen after suffering the devastating effects of the weapon when in the hands of Welsh archers.\nTechnology and Training\nMeasuring up to six and a half feet in length, the longbow normally was made of yew wood, the drying and shaping of which could require up to four years. Its 30-inch ash-wood arrows, fletched with goose feathers and tipped with four-sided metal “bodkin” points, could penetrate a knight’s armor at 60 yards or more.\n- Subscribe to Armchair General Magazine\n- Subscribe online and save nearly 40%!\nThe longbow’s draw (pull weight) was 60-120 pounds. Archers had to be highly trained and well conditioned to sustain the strain of firing up to 15 times per minute in battle. Although claims that longbowmen could put an arrow through a helmet visor at 200 yards may be exaggerated, the weapon’s true battlefield advantage was its ability to create a deadly hailstorm of arrows – 5,000 longbowmen could rain down 30,000-75,000 missiles per minute on their opponents.\nArchers carried 60-72 arrows into battle, less than 10 minutes’ worth of ammunition. Young boys, therefore, scurried back and forth among the archers to keep them resupplied during combat.\nThe crossbow, more popular than the longbow among most European armies, had greater range, up to 350 yards versus the longbow’s 280 yards. However, the crossbow could only fire once or twice per minute.\nEngland’s Weapon of Choice\nEnglish longbowmen under King Edward III dueled with skilled Genoese mercenary crossbowmen at Crecy (1346) and quickly routed them, then decimated charging French knights. The English lost about 100 men while inflicting an estimated 10,000-20,000 casualties.\nNear Agincourt , France (1415), English King Henry V’s archers replicated Edward III’s lopsided victory, slaughtering a numerically superior French force. Opposing artillery fired only a single volley before being driven off by a storm of arrows.\nHenry V’s confidence in the longbow was demonstrated by the fact he invaded France with only 2000 men-at-arms and knights plus some 60 artillery gunners, yet he brought 8,000 longbowmen. He mounted them on horseback for rapid deployment, though they fought dismounted. Henry forbade subordinates from attacking without longbow support.\nTo protect themselves from mounted charges, each archer carried a sword and a long wooden stake, which he drove into the ground at an angle in front of him and then sharpened the point. Bowmen armored themselves with layers of stuffed, quilted deer hide or cast-off pieces of armor from fallen foes.\nThe longbow remained medieval warfare’s most effective missile weapon until superceded by gunpowder weapons around the 16th century.\nGerald D. Swick is a writer and historian whose works have appeared in “The Encyclopedia of World War II: A Political, Social and Military History,” “ Lincoln Lore,” and other publications.\n• High rate of fire\n• Good penetration of knight’s armor\n• Required extensive training\nThe Crooked Stick: A History of the Longbow by Hugh D. H. Soar. Westholme, 2004.\nWebsite with the history of the longbow: www.bbc.co.uk']"	['<urn:uuid:1ec4dd31-fa21-444e-a084-e6f72cff5b2d>', '<urn:uuid:89979212-8421-4696-a05f-cba8799c40f9>']	open-ended	direct	concise-and-natural	distant-from-document	multi-aspect	novice	2025-05-13T03:20:41.944655	11	76	1059
83	What types of jet fuel are used today, and how do they impact climate change?	Commercial and military aircraft use several types of kerosene-based jet fuels. The main commercial types are Jet A (used in US), Jet A1 (used worldwide), and Jet B (for cold weather). The military uses variants like JP-5, JP-7, and JP-8. These aviation fuels contribute significantly to global warming - in 2005, aviation accounted for 4.9% of global warming despite producing only 2.2% of carbon dioxide emissions. This is because aircraft fuel generates other climate pollutants besides CO2. By 2018, aviation was responsible for approximately 2.6% of human-made CO2 emissions.	['Of all the questions asked by airplane enthusiasts, one of the most basic and most interesting questions is, what type of fuel does an airplane use? After all, it can’t run on regular gasoline like cars do – or can it? If you’ve ever been curious about the type of fuel that is needed to operate an airplane, wonder no more, because following is a description of all of these types to answer this question.\nTable of Contents\nWhat Affects the Type of Fuel Used in an Airplane?\nIf you’re curious about what determines the type of fuel used by an airplane, the answer is simple: the fuel type is a direct result of the type of engine used in that plane. Simply put, commercial and fighter planes tend to use kerosene-based fuel, but certain products are usually added to the fuel. This includes antifreeze, hydrocarbons, metal deactivators, and antioxidants, all of which prevent corrosion and freezing at higher altitudes, to name a few.\nAlthough there are blends and mixtures of airplane fuel, it all begins with three basic types, and they are described below.\nKerosene-Based Aircraft Fuels\nKerosene-based fuel for airplanes is usually broken down into various types, according to physical qualities and certain specifications. These types include:\n- Jet A:\nOnly available in the United States, Jet A fuel was developed to be heavy, with a higher flash point and higher freezing point than standard kerosene. This fuel has low vapor pressure and a flash point that is roughly 110ᵒ Fahrenheit.\n- Jet A1:\nMost turbine-engine aircraft use this type of fuel. It has a flash point of 100ᵒ Fahrenheit and a maximum freeze point of -52ᵒ Fahrenheit. It is an easy fuel to find if you’re located outside of the United States.\n- Jet B:\nAlso called wide-cut fuel because it is a combination of kerosene and gasoline, it is used mostly in areas that experience very cold weather, in part because its freezing point is around -76ᵒ Fahrenheit. Its vapor pressure is somewhere between that of gasoline and kerosene.\nThere are eight different types of military-based airplane fuel, as described below.\nThis fuel is pure kerosene and has a freezing point of -76ᵒ Fahrenheit. Even though it was efficient fuel, it was soon replaced by other types of wide-cut jet fuel, including fuels made from kerosene-naphtha and a kerosene-gasoline mixture.\n- JP-2 and JP-3:\nJP-2 was originally developed to replace JP-1 fuel and was rarely used. JP-2 fuel had a high freezing point, but was eventually replaced by JP-3, which was more volatile and was supposed to improve the former. However, because both of these fuels had high vapor loss and were unstable, neither are being used today.\nThis type of fuel is flammable and transparent, with a clear or straw color and a smell similar to kerosene. In addition, the JP-4 fuel floated on water and easily evaporated. It had such a low flash point (0ᵒ Fahrenheit) that a match dropped in it would not ignite, and its maximum water temperature was 6,670ᵒ Fahrenheit.\nThe JP-5 fuel is yellow in color and contains ingredients such as hydrocarbons, naphthenes, alkenes, and aromatic hydrocarbons. It has a high flash point of 140ᵒ Fahrenheit and a freeze point of -51ᵒ Fahrenheit, and it contains no antistatic agents.\nThis fuel was developed specifically for the General Electric YJ 93 Jet Engine associated with the XB-70 Valkyrie Supersonic Aircraft, a high-altitude bomber plane. It was similar to the JP-5 fuel except its freeze point was -65ᵒ Fahrenheit. It also had better thermal oxidative stability than the JP-5.\nThis fuel copes well with the heat and stress associated with high-speed supersonic flights, in part because of its high flash point. It was specifically developed for the twin Pratt & Whitney J58 Turbojet/Ramjet engines of the SR-71 Blackbird.\nThe JP-8 fuel is similar to the A1 fuel utilized by many commercial airlines, and it has been widely used by the U.S. military. Ingredients were added to it for corrosion barrier and anti-icing purposes, and it has a freezing point of -52ᵒ Fahrenheit, as well as a flash point of 100ᵒ Fahrenheit.\nThis is a very popular type of airplane fuel that is often used by small piston-powered aircraft. It is specifically used for tasks such as crop-dusting and for private flying, flying clubs, and even flight training.\nAvGas fuel works on these planes because their pistons work much like those in car engines, and the fuel itself works much like gasoline does on these systems, although the two fuels themselves are different.\nAvGas fuel is a safe, stable, and predictable fuel that promises great performance regardless of the conditions, and its formulation is a bit different than the regular gasoline that is used in most cars.\nIt comes in many different grades and normally has octane ratings that are much higher than those of regular gasoline.\nWhen Producing Aviation Fuel\nWhen aviation fuel is developed, it normally falls into one of two categories – fuel suitable for turbine engines and fuel suitable for internal combustion engines. For each of these types, there are international specifications required.\nFor instance, in both turboprop and jet aircraft, jet fuel is used because it has low viscosity at low temperatures and burns clean, is limited in density and calorific value, and remains stable even when heated to high temperatures.\nAll of these characteristics are crucial when it comes to the right aviation fuel.\nAvGas, which stands for aviation gasoline, is made from a very refined type of regular gasoline. It is pure, has anti-knock properties, and minimizes fouling of the spark plugs.\nIn addition, this type of gas has both the right mixture condition for takeoff power settings and the leaner mixture condition needed for the cruise phase when reduced fuel consumption is important.\nAs a general rule, much less AvGas is sold than jet fuel, although a lot of independent aircraft carriers use it.\nConversely, large aircraft companies, including commercial airlines and the military, tend to use jet fuel instead of AvGas.\nThe Wave of the Future\nIn addition to these types of airplane fuel, research is promising to produce newer and even better types of fuel in the future. This is partly because most fuels are fossil-based and, therefore, not sustainable or clean.\nIn fact, a more sustainable type of fuel for both airplanes and vehicles is the goal of many of these research companies, and below are a few of the more promising developments.\nThese include fuels made from the biomass-to-liquid method and encompass certain sustainable aviation fuel (SAF) and even vegetable oil.\nSome advantages associated with SAF include the fact that when used, there is little to no changes required to the aircraft itself.\nSome SAFs include small amounts of fossil fuels mixed into them, and they offer lower GHG and particle emission levels.\nHowever, most biofuels are higher in price than other types of aviation fuel, and they face enormous economic and political complications that hinder their use.\n- Compressed Natural Gas/Liquefied Natural Gas:\nBoth compressed natural gas (CNG) and liquefied natural gas (LNG) have low specific energy, making them a disadvantage for flight applications.\nStill, some aircraft – including one used by NASA’s N+4 Advanced Concept Development Program – were made specifically to use one or more of these types of natural gas.', 'Project Drawdown defines the efficient aviation solution as the increased use of technologies to reduce aircraft fuel burn. This solution replaces conventional aircraft with existing global fleet-wide fuel efficiency.\nIn 2005, all of aviation’s share of global warming was 4.9 percent despite being only 2.2 percent of carbon dioxide emissions in that year. This is due to aviation’s generation of other climate pollutants besides carbon dioxide that also cause warming. Considering aviation fuel consumed in 2016, and all global carbon dioxide emissions in 2016, all aviation is estimated to have caused approximately 2.6 percent of manmade carbon dioxide emissions in 2018. Growth in aviation’s share is causing increasing alarm. Airplane fuel efficiency efforts aim to reduce fuel use per passenger-kilometer of air travel. Though freight-only aircraft fuel efficiency is not analyzed here, part of the impact on air freight fuel use is accounted for in the large fraction of total air freight that is carried in the belly of passenger aircraft.\nThere are numerous technologies and operational approaches for reducing airplane fuel use; only the most impactful technologies in use today to improve fuel efficiency were included in this study. Therefore, well-publicized but noncommercial technologies such as aviation biofuels were excluded.\nThis analysis includes the newest, most fuel-efficient aircraft (called “intermediate generation”), as well as the use of fuel efficiency retrofits to existing aircraft. Intermediate generation aircraft are expected to be 15–20 percent more fuel-efficient than earlier models, in part as a result of more fuel-efficient engines, new wingtip devices, and light weighting approaches. Research suggests that the combination of these three technologies in a retrofit would amount to efficiency improvements comparable with a newer aircraft model. In this study, new and retrofitted aircraft are compared to conventional aircraft with the existing global fleetwide fuel efficiency.\nTotal Addressable Market\nThe total addressable market for efficient aviation is measured in terms of total interurban passenger travel by air, projected for every year of analysis (2020–2050), in billion passenger-kilometers. Current adoption was taken as the total passenger-kilometers provided by existing intermediate generation aircraft, in the single-aisle and twin-aisle categories.\nProjected adoption of fuel-efficient aircraft was based on the expected production of intermediate generation aircraft, according to published delivery rates of major suppliers. Delivery rates were assumed fixed for each aircraft type.\nImpacts of increased adoption of efficient aviation from 2020 to 2050 were generated based on two growth scenarios, which were assessed in comparison to a Reference Scenario where the existing fraction of higher-efficiency aircraft remains constant.\n- Scenario 1: Fuel burn is improved by 13 percent, Boeing and Airbus supply aircraft at their published rates, and an additional supplier starts adding comparably efficient aircraft to market. One hundred aircraft are retrofitted annually.\n- Scenario 2: Fuel burn is improved by 18 percent. Aircraft delivery rates, retrofitting, and retirement are similar to the Scenario 1. Global load factors increase to 83 percent (U.S. average).\nEmissions for each scenario were estimated using the fuel emissions factor taken from the Intergovernmental Panel on Climate Change (IPCC) guidelines, and applied to fuel consumption data from the International Council on Clean Transport (ICCT).\nCosts of adopting the intermediate generation aircraft are reported as the additional cost compared to adopting aircraft with average fleet efficiency. For each intermediate generation aircraft, an equivalent conventional aircraft was priced and the price difference was derived. The average difference for single-aisle aircraft was around US$11 million, and that of twin-aisle was US$40 million. Operating costs, which included fuel costs, were derived using historical data from the International Energy Agency (IEA). The solution’s operating costs were reduced by the efficiency improvements noted above.\nTo prevent double-counting, steps were taken to ensure that the total travel demand of all non-urban passenger Transport Sector solutions remained below the projected total non-urban travel demand.\nIn Scenario 1, a potential reduction of 6.3 gigatons of carbon dioxide-equivalent greenhouse gas was found from 2020 to 2050, which corresponds to an 80 percent adoption rate by 2050. Net costs over that time would be US$863 billion above the conventional approach. Efficiency improvements are estimated to bring lifetime operating savings of US$2.5 trillion, however. For the Scenario 2, the emissions avoided amounted to 9.2 gigatons with 85 percent adoption.\nThe use of more efficient aircraft is desirable for airlines in times of higher fuel prices. It would have direct bottom-line impacts, as fuel often represents a third of operating costs. Since 2015, however, fuel prices have been relatively low, and there is no assurance that prices will return to their previous levels of almost three times higher. At these lower fuel prices, the financial attractiveness of these aircraft efficiency improvements is not great, and in some cases result in negative net present values for airlines according to our calculations. However some of this may change with the coming implementation of the Carbon Offsetting and Reduction Scheme for International Aviation (CORSIA) program. To some extent, inclusion of fuel switching approaches such as aviation biofuels can help reduce the need for aircraft technology improvements.\nThere are limitations to this approach. For example, the potential of other technologies being implemented was excluded in this study. Also, the Reference Scenario conservatively assumes fixed fleet efficiency. These limiting assumptions were made to show the impact of existing technologies on the airline industry. The results indicate that airlines have a role to play in the planet reaching the point of drawdown.\n Lee, D. S., Fahey, D. W., Forster, P. M., Newton, P. J., Wit, R. C., Lim, L. L., ... & Sausen, R. (2009). Aviation and global climate change in the 21st century. Atmospheric Environment, 43(22-23), 3520-3537.\n From OECD/IEA (2018) World Energy Balances 2016, OECD/IEA, Paris\n According to Airbus, belly freight is about 52 percent of all air freight.\n Including the 787, 777X, and 737MAX family of Boeing, and the A320neo family, A330neo family, and A350XWB of Airbus.\n Also called “winglets” or “sharklets”, these devices cannot be installed on all older aircraft due to lack of sufficient wing strength and other limitations.\n For more on the Total Addressable Market for the Transport Sector, click the Sector Summary: Transport link below.\n Current adoption is defined as the amount of functional demand supplied by the solution in 2018. This study uses 2014 as the base year due to the availability of global adoption data for all Project Drawdown solutions evaluated.\n Delivery of a single-aisle aircraft is assumed to provide 247 million passenger-kilometers, and a twin-aisle aircraft 840 million passenger-kilometers, of adoption.\n This additional manufacturer can represent any or all of numerous nascent options, such as COMAC of China or the UAC of Russia. It produces around 5 percent of all efficient aircraft annually.\n For instance, the Airbus A320neo was considered a more efficient replacement for the A320, and the Boeing 777X-9 was considered a replacement for the 777-300ER. These relationships were determined through web searches for each efficient model.\n All monetary values are presented in 2014 US$.\n It is assumed that this differential represents the retrofit costs for each aircraft type, and acknowledged that airlines often pay different prices than the list prices due to negotiations that occur with the manufacturers.\n The fuel prices (2007–2018) were averaged, and this fixed average was used for the future projections.\n The net operating savings for the full lifetime of all units installed during 2020–2050.\n The potential for open rotor engines could be large, but estimates seem to indicate availability in the 2030s onward.']	['<urn:uuid:4fbd1956-5127-4603-bc13-a38be06184f4>', '<urn:uuid:034d41d9-10c6-4686-b3da-477b79d07814>']	open-ended	with-premise	concise-and-natural	similar-to-document	multi-aspect	novice	2025-05-13T03:20:41.944655	15	89	2456
84	decorative wall design entire room stencils chair rail moulding which gives more coverage	Stencils offer more coverage as they can be used to decorate an entire wall, for example creating a patterned tile effect. In contrast, chair rail molding is typically installed as a horizontal band around the room at a height between 30 to 42 inches above the floor, providing more limited coverage.	"[""Inspirational quotes, children's names, silhouettes, abstract shapes and characters, are all stenciling ideas to apply to your walls as a painted finish. Stenciling is a great option for adding unique character to your home's decorative scheme and provides an individual touch that defines a space as yours. Use stenciling as a continuation of your color story or as a complete contrast.\nUnique Stenciling Ideas\nThe sky is the limit when it comes to this versatile painting technique. Stencils are usually associated with edging and borders, such as chair rails or small decorative panels, but they can also be used over an entire wall. Apply stenciling to a traditional setting or even a modern interior. This decorative application is great for nurseries and children's rooms, bathrooms, and laundry rooms.\nWith so many stenciling options, narrow them down by determining what theme or mood you want to create and who will be occupying the space. Here are a few design themes and stenciling ideas to help make the decision process a little easier.\n- Geometric shapes such as squares, cubes and stars\n- Organic shapes such as circles, bubbles, rings, polka dots and swirls\n- Worldly animals such as lions, zebras, giraffes and elephants\n- Sea creatures such as fish, dolphins, shells, starfish and sea horses\n- Domestic pets such as cats, dogs, birds and horses\n- Creatures such as butterflies, lizards, and bugs\n- Trees such as cherry blossoms, bamboo, palm trees, oak trees and fruit trees\n- Ornate swirls and curly cues\n- Faux chandeliers, pictures frames and headboards\n- Flowers such as roses, daisies, hibiscus, roses, and vines\n- Different styles such as fantasy, realistic, retro and whimsical\n- Sports such as baseballs, basketballs and footballs\n- Nautical such as sailboats, sea creatures, lighthouses, surfing and rubber ducks\n- Inspirational Quotes\n- Famous phrases from celebrities\n- Writers, songwriters and poets\n- Baby's name, family members, initials and monograms\n- The alphabet\nUnusual Finishes or TexturesIn addition to the typical stenciling ideas, a couple fresh and innovative alternatives involve different textures and finishes that give stenciling a modern twist. For example, chalkboard paint, which can be found at your local home improvement store or paint dealer such a Home Depot or Benjamin Moore. A large, over scaled stencil pattern works best in this situation. Use a silhouette of an elephant for instance. Its large body works great as a writing surface, or perhaps a large silhouette of a tree where the trunk is a child's growth chart and its leaves map out your families ancestry. Another fun stenciling idea for children or adults is glow in the dark paint found at a number of online stores such as Glo Inc. Stencil a rocket on the wall that is on a mission to outer space with the solar system on the ceiling, or for more simplistic stenciling projects paint a border of shining stars or glowing fireflies.\n- Additional chalkboard stenciling ideas\n- Map of the United States\n- Rectangles with blank mathematical equations such as addition, multiplication subtraction and division\n- Blank music chart\n- Additional glow in the dark stenciling ideas\n- Cow jumping over the moon or other nursery rhymes\n- Counting sheep\n- Scary phrases\n- Night eyes\nBorders and Chair RailsStenciling can create an enjoyable effect in an otherwise boring situation. It can enliven a plain colored wall, highlight the ceiling and outline areas such as doorways and windows. As a chair rail, stenciling can be a decorative divider between two paint colors. This type of stenciling goes well with just about any style of decor.\nStencil to Decorate an Entire Wall\nStencils can decorate an entire wall, for example, a patterned tile effect. Be sure to use a sealant with an exterior quality varnish to waterproof your design if applied to a wet location such as a bathroom or kitchen. Choose a tile design and size, then draw it onto stencils, one for each color, and mark the tile size as black outlines. Draw the tile size in grid format on the walls with a waterproof marker and then stencil the design onto the tile grid, completing one color before beginning the next. To complete the look and add a dramatic touch, redraw over the tile grid using a matching color to create faux grouting, use painters tape to stencil a straight horizontal line.\nSeveral websites provide additional stenciling ideas, helpful tips, advice and even detailed how-to videos on stenciling. Even though paint is inexpensive, it is important to do your research before making any decisions, because your time and efforts are valuable.\n- Stencil material\n- Tracing paper\n- Pencil/waterproof marker\n- Snap-blade knife\n- Stencil paints\n- Stenciling brush\n- Painter's Tape"", 'All about chair rail molding\nThe original purpose of chair rail molding was to protect walls from being damaged by chair backs. Today, this chair rail molding is a fast way to stylishly define a dining room, living room or entry hall, especially when used to separate wallpaper from paint, or between two different colors of paint.\nThis article will show you how to install chair rail molding, with tips to make the job go faster and easier and with less wasted material. Chair rail is available in a variety of woods and styles, from inexpensive paint-grade pine to large, very expensive hardwood profiles. You can also make your own chair rail molding with standard trim or clear “1-by” material. The special-order cherry molding we used cost $5 per ft.\nTo cut the chair rail, you’ll need a miter saw and a coping saw with extra blades (they break easily). A finish nailer isn’t absolutely necessary but will give you faster, better results.\nMake a sketch, then go shopping\nSketch out the floor plan of the room, noting the exact length of each section of wall. Add a foot to each length for waste to get the minimum size you need for each wall. Once you decide on a style, you’ll need to do some juggling to make the standard lengths that the lumberyard sells fit the lengths that you need. The best way to keep track of what piece goes where and avoid wasting expensive wood is to make notes on the sketch. Here are some shopping tips:\n- When possible, buy pieces of chair rail molding long enough to span the entire wall; otherwise, you’ll have to splice\nsections (Photo 7).\n- If you plan to stain and varnish the chair molding, select pieces with similar grain pattern and color.\n- Check each piece for flaws such as splits and tear-out.\n- To avoid heavy sanding, select pieces that have a smooth surface. Watch out for deep “chatter marks” (a wavy surface left by the milling machine).\n- Home centers only carry a few pine and oak chair rails. For a larger selection, ask about special-order chair railing profiles or visit a lumberyard that caters to professional contractors.\n- Many types and combinations of moldings can be used as chair rail, even if they aren’t called chair rail.\nAlso use your sketch to plan the location of coped cuts, so that you don’t end up with pieces that have to be coped at both ends. If possible, locate coped pieces on walls where the non-coped end can be marked in place. That way you can shave the coped cut down, or even recut it if you have to, before you cut it to length. Even pros have to tweak their cuts, so leave yourself a little extra wood to work with.\nGet Better Results With an Air Nailer\nUntil the 1990s, air nailers were so expensive that many carpenters didn’t use them. They’re a whole lot cheaper now; even if you do only occasional carpentry, they’re well worth the investment. Not only can you nail trim faster and easier, but you’ll get better-looking results. The skinny nails are less likely to split wood, and they leave smaller holes that are easier to hide. Hammer dents and bent nails are no longer a concern.\nPrepare the walls\nPhoto 1: Mark studs\nLocate studs and mark them with masking tape. If new wallpaper or paint is part of the project, complete those jobs before you install chair rail.\nApply wallpaper or paint high enough (or low enough) for the chair rail to cover the edge. Chair rail is usually placed 36 in. above the floor but can be installed anywhere from 30 in. to 42 in. up, with wallpaper either above or below.\nLightly mark the bottom of the chair rail every 3 ft. around the perimeter of the room. Measure from the baseboard, the ceiling or the floor—whichever is most consistent. Find and mark all the studs (Photo 1).\nSplit the Difference\nIn older houses, where level floors and ceilings may be only a distant memory, perfectly level chair rail can actually look crooked. The best solution is to ignore the level and follow a compromise line halfway between level and the closest visual reference point—usually the baseboard. If in doubt, tack up a test piece or a piece of tape, then stand back and see if it looks right.\nPrefinish for a faster, neater job\nPhoto 2: Finish before installing\nPrefinish the chair rail molding for less mess and smoother results. Apply the final coat after installing the chair rail and filling nail holes.\nFor a job with sharp, crisp edges, stain and varnish (or paint) the chair rail before nailing it up (Photo 2). Before the first coat, sand all the chair rail lightly but thoroughly with 180-grit sandpaper. Test the finish on scrap pieces to make sure the color looks right. To match existing trim, you’ll have to experiment on scraps of chair rail. Don’t assume that stain colors will look the same on your chair rail as they do on store displays.\nCope corners for a perfect fit\nPhoto 3: Cope cuts\nCope inside corners by cutting along the profile left by a 45-degree miter cut. Hold the coping saw at an angle to “backcut” the chair rail.\nPhoto 4: Fine-tune the cut\nPerfect the fit of coped ends with a file, rasp, utility knife or sandpaper. Don’t try to shave off thin slices with a coping saw.\nPhoto 5: Solve problems with hidden shims\nClose a gap with a shim. Slip the shim under the uncoped end to force it against the coped end. This only works if the gap is along the lower half of the chair railing joint.\nWall corners are almost never perfectly square, but coped joints cover this problem by fitting tightly against the adjoining piece even if the corner is a few degrees off.\nCut the piece for the first side of the corner at 90 degrees and nail it in place—but keep the nails a foot back from the corner for now. Cut the coped end of the next piece and tweak it until the joint is tight (Photos 3 and 4).\nHere are some tips for making smooth, accurate cope cuts:\n- Make sure the saw teeth point toward the handle. That way, the blade will cut smoothly on the pull stroke.\n- Practice on scraps. You’ll be surprised at how much your copes improve after a couple of practice cuts.\n- Clamp the chair rail to a solid work surface. Cuts are smoother and easier if the molding can’t\nshift or wiggle.\n- Don’t force the saw forward. Make smooth, even strokes, applying light forward pressure.\nIf the first wall isn’t perfectly plumb, you may need to glue a thin shim under the bottom edge to tighten the joint (Photo 5). Don’t cut off the shim in place—you may damage the wall. Instead, mark it, and then pull it out\nto cut it.\nOnce the coped joint looks right, hold it in place and mark the cut at the other end. Only one end should be coped. The other end will always be either an outside corner or a 90-degree cut. Here’s more on creating coped corners.\nTest outside corners for a tight fit\nPhoto 6: Use scraps for test cuts\nFind the miter cut angle on outside corners with an angle finder or just by cutting and recutting test pieces until they form a tight corner.\nOutside corners often flare out slightly, so that the chair rail needs to be cut at more than 45 degrees. To get the exact angle, cut two scrap pieces at 46 degrees, then adjust the angle of the cut until the joint is tight (Photo 6). Both sides should be cut at the same angle.\nSpread wood glue on one of the ends before nailing the chair railing pieces to the wall. Don’t nail within 2 in. of the end unless you’re using a brad nailer or predrilling, to avoid splitting the wood.\nCreate a “Return” at an Archway\nTo end chair rail at an archway or corner, form a return an inch from the corner. When you cut the return, leave the saw blade down until the blade stops spinning to avoid nicking the return as it falls away from the blade.\nFirst, cut a return piece the width of the chair rail. Clamp a 1×4 to the fence so the saw blade won’t mangle the return.\nNext, push the return into place with a little wood glue and hold it for a minute until the glue starts to set. Don’t nail the return—it’s too small.\nSplice long runs of chair rail\nPhoto 7: Scarf joint\nJoin sections of chair rail with a 30-degree “scarf” joint at a stud. For a strong joint, use glue in addition to nails.\nIf your wall is too long for a single piece of chair rail, you can inconspicuously join two pieces by cutting the ends at 30 degrees and gluing them together (Photo 7).\nSelect two chair railing pieces with similar grain. Measure and cut the two pieces so that the splice occurs on a stud. Position the top piece so that all the edges line up, then nail it to the wall. Wipe away glue drips and touch up with filler and additional finish if necessary.\nCut a “Bevel” at Thin Window Casing\nSome types of chair rail molding are thicker than window and door casing. To solve this problem, bevel-cut the chair rail as shown in the photo with a shallow 45-degree bevel cut. Apply finish to the cut before you nail it up to avoid getting finish on the casing.\nFill nail holes\nPhoto 8: Fill holes\nFill nail holes with colored putty. Blend different colors of putty to perfectly match the color of the wood. Then apply the final coat of clear finish.\nBefore applying the final coat of finish, fill all nail holes. Use colored wood putty—either oil or water-based—to fill holes in natural woodwork (Photo 8). If you don’t have the right shade, blend different colors with your fingers for a better match. Wipe away excess filler with a rag dipped in thinner for the oil-based putty, or water for the water-based product.\nUse spackling paste for painted chair rail molding. Sand it flush, spot-prime the nail holes, then repaint.\nFigure A: Plate or Chair Rail Design\nThe techniques used to install a chair rail molding can also be used to make a plate rail or a heavier, built-up chair rail. In addition to being visually interesting, a built up chair rail molding like this can be used to display photos, artwork and knickknacks. Plate rails are usually installed about five feet above the floor.\nRequired Tools for this Project\nHave the necessary tools for this DIY chair rail molding project lined up before you start—you’ll save time and frustration.\n- Air compressor\n- Air hose\n- Block plane\n- Brad nail gun\n- Coping saw\n- Cordless drill\n- Miter saw\n- Orbital sander\n- Painters tape\n- Pry bar\n- Putty knife\n- Safety glasses\n- Stud finder\n- Utility knife\nRequired Materials for this Project\nAvoid last-minute shopping trips by having all your materials ready ahead of time. Here’s a list.\n- 1-1/2-in. brad nails\n- Chair rail\n- Colored wood putty or filler\n- wood glue\n- Wood shims']"	['<urn:uuid:7105a3fd-25a2-47b5-8a6f-e3392a5be889>', '<urn:uuid:4d8636f4-17c3-4b85-ba7f-f52403c34783>']	factoid	direct	long-search-query	distant-from-document	comparison	novice	2025-05-13T03:20:41.944655	13	51	2708
85	What's the main difference between owning a physical thing like a car versus owning something you created like a song or a book?	Real property refers to physical things we own like cars, which is straightforward to understand and can be sold, rented, or leased. Intellectual property is more complex - it requires turning an idea into an original work (like a film script), and once created, it is automatically copyrighted in most countries. This copyright gives the creator control over how their work is copied, adapted, sold, or used by others.	['What we usually mean by property – physical things which we own – is called real property to distinguish it from intellectual property. Real property – things that actually exist, like cars and sandwiches – is easy enough to understand, and we’re mostly familiar with the ways its ownership can be transferred: it can be sold outright, sold in part, rented or leased (you wouldn’t want to rent a sandwich, but legally there’s no reason why you couldn’t.) Intellectual property, on the other hand, is more complicated. For one thing, not everything we can think of or imagine can be intellectual property. An idea, for instance, is not yet property; we have to take the time and effort to turn that idea into some kind of product. This does not have to be a finished product – a film script is intellectual property, even if the film doesn’t ever get made – but it needs to show that the creator has made an original work. This is a key point, because in most countries all intellectual property is automatically copyrighted.\nWhat does that mean? It means that it has become property that the creator owns. That creator now can control what is done or not done with the property – whether and how it is copied, adapted, sold, etc. – and can sell or lease any or all of those rights as he or she chooses. Each time something substantially new is done to the property, so long as it is done with legal right, a new property is created and a new copyright established.\nMost countries have their own laws relating to copyright, but nearly all also follow the Berne Convention for the Protection of Literary and Artistic Works. The Convention requires member nations to recognize copyrights that are established in other members’ countries (so you don’t have to establish a separate copyright in each country in the world), makes copyright automatic (so copyrights do not have to be registered, although some countries such as the United States provide added protection to registered copyrights) and sets fifty years as the minimum time before a copyrighted work can pass into the public domain. \nThe most significant national laws relating to copyright are Title 17 of the United States Code which lays out American copyright law, and the Copyright Act, which defines copyright in Canada. Both of these laws cover:\n- what kinds of works can be copyrighted\n- legal protections for copyrighted works\n- differences in how copyright applies to different media\n- how copyrights can be sold or assigned\n- what government bodies administer copyright\n- when copyrighted works pass into the public domain\nAs well, many copyright laws (including the Copyright Act) give moral rights specifically to the creators of a work. Unlike other aspects of copyright, these moral rights do not automatically pass on to the new owner of a copyright: in Canada they include the right to have your name or chosen pseudonym associated with the work and the right to protect the integrity of the work. (For instance, the artist Michael Snow was able to prevent the Eaton Centre from adding scarves to a sculpture of geese he had sold them.) \nGenerally, if you want to do anything with a copyrighted work beyond its intended use, you need to get the permission of the copyright holder or someone acting on his or her behalf. (For example, you do not need permission to read a book, but you do need it to turn the book into a play or a movie; you don’t need permission to listen to music, but you do need permission to play it in a public place.) However, there are important exceptions: fair dealing (in Canada and other Commonwealth countries) and fair use (in the United States) grants certain rights to use copyrighted works without needing to get permission from the copyright owner. Both fair use and fair dealing are affirmative defences in law, which means that neither one can prevent the owner of a copyright from suing you for infringement: if you are sued, you have to prove in court that your work falls under your country’s definition of fair use or fair dealing.\nOf course, the owner of a copyright may release the work to the public domain at any time he or she chooses. Copyright owners can also release works under licenses that are less restrictive than copyright law: for instance, there are a variety of Creative Commons licenses that let creators grant permission to copy or transform their work without giving up copyright, and may also place limitations on that use (for instance, that they be listed as the creator of the original work, or that all use of the work be for non-commercial purposes.)\n*Note: This information is NOT intended as legal advice. If you are facing a legal issue dealing with intellectual property law, consult a lawyer.\n Berne Convention for the Protection of Literary and Artistic Works. World Intellectual Property Organization, 1979. http://www.wipo.int/treaties/en/ip/berne/trtdocs_wo001.html\n Trosow, Samuel E. “The copyright policy paradox: Overcoming competing agendas in the digital labour movement,” Ephemera 10, 2010.']	['<urn:uuid:6dd71c94-00ad-4783-a2fd-6705af8fd387>']	open-ended	direct	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-13T03:20:41.944655	23	69	855
86	science museum tsunami features safety	The Museum of Science and Industry features an interactive tsunami exhibit where visitors can unleash waves across a 30-foot wave tank, and displays a DART buoy that was used for detecting tsunamis. For tsunami safety, the National Weather Service's TsunamiReady program helps communities prepare through education, awareness, and emergency response plans. Communities must meet specific guidelines including establishing warning systems, creating evacuation routes, and conducting public awareness programs to protect their residents from tsunami hazards.	"['NATURAL PHENOMENA TAKE GUESTS BY STORM AT MSI\nLearn about the amazing science behind nature in Science Storms at the Museum of Science and Industry, Chicago\nCHICAGO (March 18, 2010)—Be blown away by a 40-foot tornado swirling before you. See bolts of lightning crack over your head. Trigger an avalanche. Unleash a tsunami wave.\nIt’s all possible in Science Storms, an unprecedented and dramatic permanent exhibit in Allstate Court that reveals the extraordinary science behind some of nature’s most powerful and compelling phenomena—tornados, lightning, fire, tsunamis, sunlight, avalanches and atoms in motion. Science Storms was awarded the Excellence in Exhibition award in 2011, the top honor by the American Association of Museums.\n“Creating transformative experiences that get people excited about the world around them is what the Museum of Science and Industry does best, and exhibits like Science Storms are our most powerful teaching tools,” said David Mosena, president and CEO of the Museum of Science and Industry.\nInside the 26,000-square-foot exhibit, you’ll investigate the basic principles of chemistry and physics that are responsible for nature’s biggest wonders, while you get a hands-on, up-close look at these wonders themselves. Science Storms puts you in the middle of the action and lets you search for answers as to how and why things happen in nature.\n- Immerse yourself in a 40-foot tornado to experiment with air pressure and wind speed inside a towering vortex of vapor.\n- Create a high-voltage lightning storm by discharging volts of energy from a giant Tesla coil, 20 feet in diameter, to discover electricity and magnetism.\n- Ignite and control fires within a glass cube to witness the flame’s behavior and reaction to different conditions.\n- Make your own giant rainbows with optical prisms, recreating Newton’s famous prism experiment to observe the physical nature of light.\n- Transform water into vapor, then into ice and back to water again to explore states of matter.\n- Trigger a 20-foot avalanche to reveal the beauty of granular dynamics.\n- Discover the power and motion of waves by unleashing your own tsunami across a 30-foot wave tank.\nAs you investigate each of these forces of nature, you’ll experience dynamic media presentations that explore the science behind the phenomena—featuring leading researchers and scientists from NASA, NOAA, the United States Geological Survey, Harvard University, the University of Chicago and many more. Interspersed throughout the exhibit are important artifacts that help you to further understand the various scientific principles at work. Among them, you’ll see:\n- The oil drop apparatus that Robert Millikan used in his 1923 Nobel prize-winning experiment to measure the charge of a single electron for the very first time.\n- A giant Deep Ocean Assessment and Reporting of Tsunamis (DART) buoy used for detecting tsunamis and transmitting warnings. The buoy, decommissioned by the National Oceanic and Atmospheric Administration (NOAA) in 2008, recorded a tsunami resulting from an 8.3-magnitude earthquake in the Kuril Islands in Russia.\n- A light bulb that was used at the historic 1879 New Year’s Eve demonstration of the Edison Lighting System in Menlo Park, New Jersey. This was the first time light bulbs were lit for the public.\nScience Storms is brought to you through the generosity of The Allstate Corporation, The Allstate Foundation, Mr. and Mrs. David W. Grainger and The Grainger Foundation. Additional major funding is provided by the U.S. Department of Energy.\nScience Storms is included in Museum Entry.', 'TsunamiReady is an initiative that promotes tsunami hazard preparedness as an active collaboration among Federal, state and local emergency management agencies, the public, and the NWS tsunami warning system. This collaboration functions for the purpose of supporting better and more consistent tsunami awareness and mitigation efforts among communities at risk. Through the TsunamiReady program, NOAA’s National Weather Service gives communities the skills and education needed to survive a tsunami before, during and after the event. TsunamiReady was designed to help community leaders and emergency managers strengthen their local tsunami operations. (NOAA, N/D)\nThe TsunamiReady program is based on the NWS StormReady model (which can be viewed by accessing http://www.stormready.noaa.gov/). The primary goal of TsunamiReady is the improvement of public safety during tsunami emergencies. As stated above, TsunamiReady is designed for those coastal communities that are at known risk of the tsunami hazard (tsunami hazard risk maps can be seen by accessing http://www.pmel.noaa.gov/tsunami/time/).\nTraditionally, tsunami hazard planning along the U.S. West Coast and Alaska has been widely neglected because of the statistically-low incidence of tsunamis. As result of that perceived ‘rarity’, many individuals and communities have not worked to become as ""tsunami-aware"" as they could and should be. Among those communities that are considered to be prepared, that level of exhibited preparedness varies significantly (NWS, N/D).\nHowever, as is true with the earthquakes and other rare events that generate tsunamis, avoidable casualties and property damage will only continue to rise unless these at-risk communities become better prepared for tsunamis. As previously mentioned, readiness involves two key components: awareness and mitigation. Awareness involves educating key decision makers, emergency managers, and the public about the nature (physical processes) and threat (frequency of occurrence, impact) of the tsunami hazard, while mitigation involves taking steps before the tsunami occurs to lessen the impact (loss of life and property) of that event when it does occur. Like is true with earthquakes, there is no question tsunamis will strike again.\nThe National Weather Service (NWS) TsunamiReady program was designed to meet both of the recognized elements of a useful readiness effort: it is designed to educate local emergency management officials and their public, and to promote a well-designed tsunami emergency response plan for each community.\nTsunamiReady promotes tsunami hazard readiness as an active collaboration among Federal, state and local emergency management agencies, the public, and the NWS tsunami warning system. This collaboration supports better and more consistent tsunami awareness and mitigation efforts among communities at risk. The main goal is improvement of public safety during tsunami emergencies. To meet this goal, the following objectives need to be met by the community:\n- Create minimum standard guidelines for a community to follow for adequate tsunami readiness\n- Encourage consistency in educational materials and response among communities and states\n- Recognize communities that have adopted TsunamiReady guidelines\n- Increase public awareness and understanding of the tsunami hazard\n- Improve community pre-planning for tsunami disasters\nThe processes and guidelines used in the TsunamiReady program were modeled to resemble those of the National Weather Service “StormReady” program. TsunamiReady established minimum guidelines for a community to be awarded the TsunamiReady recognition, thus promoting minimum standards based upon expert knowledge rather than subjective considerations. Communities that accept the challenge to become TsunamiReady, and are deemed to have met these requirements set by the NWS TsunamiReady program, are designated as “TsunamiReady Communities.” Guidelines to achieve TsunamiReady recognition are given in the following table, and discussed in detail in the pages immediately following. Four community categories (based upon the population of the community, and provided in the table’s heading) are used to measure tsunami readiness.\nNote the Guideline 3 has been skipped as it refers exclusively to the StormReady program, which shares these guidelines with the TsunamiReady program. This is a key factor to consider, as it ensures by default that all communities that are StormReady will also be TsunamiReady (as of 2002). As such, all communities being certified for TsunamiReady also must pass all StormReady criteria. StormReady requires access to local weather monitoring equipment (Guideline 3) and some further administrative requirements (Guideline 6). Other than that, the requirements are identical.\n|< 2,500||2,500 - 14,999||15,000 - 40,000||>40,000|\n|1: Communications and Coordination|\n|24 hr Warning Point (WP)||X||X||X||X|\n|Emergency Operations Center||X||X||X|\n|2: Tsunami Warning Reception|\n|Number of ways for EOC/WP to receive NWS tsunami messages (If in range, one must be NWR with tone-alert, NWR-SAME is preferred)||3||4||4||4|\n|4: Warning Dissemination|\n|Number of ways for EOC/WP to disseminate warnings to public||1||2||3||4|\n|NWR tone-alert receivers in public facilities (where available)||X||X||X||X|\n|For county/borough warning points, county/borough communication network ensuring information flow between communities||X||X||X||X|\n|5: Community Preparedness|\n|Number of annual tsunami awareness programs||1||2||3||4|\n|Designate/establish tsunami shelter/area in safe zone||X||X||X||X|\n|Designate tsunami evacuation areas and evacuation routes, and install evacuation route signs||X||X||X||X|\n|Provide written, locality specific, tsunami hazard response material to public.||X||X||X||X|\n|Schools: encourage tsunami hazard curriculum, practice evacuations, and provide safety material to staff and students||X||X||X||X|\n|Develop formal tsunami hazard operations plan||X||X||X||X|\n|Yearly meeting/discussion by emergency manager with NWS||X||X||X||X|\n|Visits by NWS official to community at least every other year||X||X||X||X|\nGuideline 1: Communications and Coordination Center\nIt is well known that key to any effective hazards management program is effective communication. This could not be truer when considering tsunami-related emergencies, since the arrival of the giant waves can occur within minutes of the initial precipitating event. These so-called ""short-fused"" events, therefore, require an immediate, but careful, systematic and appropriate response. To ensure such a proper response, TsunamiReady requires that communities establish the following:\n- 24-Hour Warning Point. It is the NWS, not the community, which determines a Tsunami threat exists. Therefore, in order to receive recognition under the TsunamiReady Program, an applying agency needs to establish a 24-hour warning point (WP) that can receive NWS tsunami information in addition to providing local reports and advice to constituents. Typically, the functions of this type of facility are merely incorporated into the existing daily operation of a law enforcement or fire department dispatching (Emergency Communications Center (ECC)) point.\nFor cities or towns without a local dispatching point, a county agency could act in that capacity for them. In Alaska, where there may be communities that have populations of less than 2,500 residents and no county agency to act as a 24-hour warning point, the community is required to designate responsible members of the community who are able to receive warnings 24 hours per day, and who have the authority to activate local warning systems. Specifically, the warning point is required to have:\n- 24-hour operations.\n- Warning reception capability.\n- Warning dissemination capability.\n- Ability and authority to activate local warning system(s).\n- Emergency Operations Center. Agencies serving jurisdictions larger than 2,500 people are required to have the ability to activate an emergency operations center (EOC). It must be staffed during tsunami events to execute the warning point\'s tsunami warning functions. The following list summarizes the tsunami-related roles required of the EOC:\n- Activate, based on predetermined guidelines related to NWS tsunami information and/or tsunami events.\n- Staff with emergency management director or designee.\n- Establish warning reception/dissemination capabilities equal to or better than the warning point.\n- Maintain the ability to communicate with adjacent EOCs/Warning Points.\n- Maintain the ability to communicate with local NWS office or Tsunami Warning Center.\nGuideline 2: Tsunami Warning Reception\nWarning points and EOCs each need multiple ways to receive NWS tsunami warnings. TsunamiReady guidelines to receive NWS warnings in an EOC/WP require a combination of the following, based on population:\n- NOAA Weather Radio (NWR) receiver with tone alert. Specific Area Message Encoding (SAME) is preferred. Required for recognition only if within range of transmitter.\n- NOAA Weather Wire drop: Satellite downlink data feed from NWS.\n- Emergency Managers Weather Information Network (EMWIN) receiver: Satellite feed and/or VHF radio transmission of NWS products.\n- Statewide Telecommunications System: Automatic relay of NWS products on statewide emergency management or law enforcement system\n- Statewide warning fan-out system: State authorized system of passing message throughout warning area\n- NOAA Weather Wire via Internet NOAAport Lite: Provides alarmed warning messages through a dedicated Internet connection\n- Direct link to NWS office: e.g. amateur or VHF radio\n- E-mail from Tsunami Warning Center: Direct e-mail from Warning Center to emergency manager\n- Pager message from Tsunami Warning Center: Page issued from Warning Center directly to EOC/WP\n- Radio/TV via Emergency Alert System: Local Radio/TV or cable TV\n- US Coast Guard broadcasts: WP/EOC monitoring of USCG marine channels\n- National Warning System (NAWAS) drop: FEMA-controlled civil defense hotline\nGuideline 4: Warning Dissemination\n- Upon receipt of NWS warnings or other reliable information suggesting a tsunami is imminent, local emergency officials must be able to communicate this threat information with as much of the population as possible. This is fundamental to making the preparedness program effective. As such, receiving TsunamiReady recognition requires that communities have one or more of the following means of ensuring timely warning dissemination to their citizens (based upon population, as described in the table above):\n- A community program that subsidizes the purchase of NWR. (NWR receiver with tone alert. SAME is preferred. Required for recognition only if within range of transmitter.)\n- Outdoor warning sirens.\n- Television audio/video overrides.\n- Other locally-controlled methods, e.g. local broadcast system or emergency vehicles.\n- Phone messaging (dial-down) systems.\n- It is required that at least one NWR, equipped with a tone alert receiver, be located in each critical public access and government-owned building, and must include 24 hour warning point, EOC, School Superintendent office or equivalent. Critical public access buildings are defined by each community\'s tsunami warning plan. Locations that are recommended for inclusion by the NWS include: all schools, public libraries, hospitals, fairgrounds, parks and recreational areas, public utilities, sports arenas, Departments of Transportation, and designated shelter areas. (SAME is preferred. This is required for recognition only if the community exists within range of a transmitter.)\n- Counties/Boroughs only: a county/borough-wide communications network ensuring the flow of information among all cities and towns within those administrative borders. This would include provision of a warning point for the smaller towns, and fanning out of the message as required by state policy.\nGuideline 5: Community Preparedness\nPublic education is vital in preparing citizens to respond properly to tsunami threats. An educated public is more likely to take the steps required to receive tsunami warnings, recognize potentially threatening tsunami events when they exist, and respond appropriately to those events. Therefore, communities that are seeking recognition in the TsunamiReady Program must be able to:\n- Conduct or sponsor tsunami awareness programs in schools, hospitals, fairs, workshops, and community meetings (the actual number of talks that must be given each year is based upon the community’s population).\n- Define tsunami evacuation areas and evacuation routes, and install evacuation route signs.\n- Designate a tsunami shelter/area outside the hazard zone.\n- Provide written tsunami hazard information to the populace, including:\n- Hazard zone maps\n- Evacuation routes\n- Basic tsunami information\nThese instructions can be distributed through mailings (utility bills, for example), within phone books, and posted at common meeting points located throughout the community, such as libraries, supermarkets, and public buildings.\n- Local schools must meet the following guidelines:\n- Encourage the inclusion of tsunami information in primary and secondary school curriculums. NWS will help identify curriculum support material.\n- Provide an opportunity biennially for a tsunami awareness presentation.\n- Schools within the defined hazard zone must have tsunami evacuation drills at least biennially.\n- Written safety material should be provided to all staff and students.\n- Have an earthquake plan.\nGuideline 6: Administrative\nNo program can be successful without formal planning and a proactive administration. The following administrative requirements are necessary for a community to be recognized in the TsunamiReady Program:\n- A tsunami warning plan must be in place and approved by the local governing body. This plan must address the following:\n- Warning point procedures.\n- EOC activation guidelines and procedures.\n- Warning point and EOC personnel specification.\n- Hazard zone map with evacuation routes.\n- Procedures for canceling an emergency for those less-than-destructive tsunamis.\n- Guidelines and procedures for activation of sirens, cable TV override, and/or local system activation in accordance with state Emergency Alert System (EAS) plans, and warning fan-out procedures, if necessary.\n- Annual exercises.\n- Yearly visits or discussions with local NWS Forecast Office Warning Coordination Meteorologist or Tsunami Warning Center personnel must be conducted. This can include a visit to the NWS office, a phone discussion, or e-mail communication.\n- NWS officials will commit to visit accredited communities, at least every other year, to tour EOCs/Warning Points and meet with key officials.']"	['<urn:uuid:015410dd-3d5f-4187-8089-602e4135331f>', '<urn:uuid:f0cd3e58-5862-462d-99bf-a9755b131d74>']	open-ended	direct	short-search-query	distant-from-document	multi-aspect	novice	2025-05-13T03:20:41.944655	5	75	2674
87	What kind of special dogs are being raised to help protect farm animals in Namibia?	Anatolian shepherds and Kangal dogs are bred at the centre as part of the Livestock Guarding Dog program.	['The CCF Bushblock Woodland Management Plan (WMP) aims to provide a management framework for the biomass operations of the CCF BUSH (PTY) Ltd. It strives to promote Namibia’s vision 2030 through the sustainable utilisation and management of natural resources in accordance with the Forest act 2001, and the Namibia forest development policy of 1998.\nThe plan prescribes methods of harvesting, suggest harvesting targets, multiple monitoring programs (ecologic, & socio-economic), and land use objectives. By selecting monitoring targets, a business subjected to adaptive management conditions can be developed. Policies related to the WMP (harvesting, fire, land use objectives, permits, were developed as control measures to prevent counter productive activities, and ensures that harvesting is conducted in accordance to the expectations of the CCF BUSH PTY Ltd.\nCCF BUSH (PTY) Ltd develops annual operations plans (AOP). The annual operations plan streamlines the WMP and specifies potential areas for harvesting, targeted areas for harvesting, estimated biomass production, time frames for harvesting. This approach is important for the achievement of management objectives, and ensures that resources (economic, human, mechanical & other) are allocated strategically, and enhances the activities of the WMP.\nTo be an internationally recognized centre of excellence in research and education on cheetahs and their ecosystems, working with all stakeholders to achieve best practice in the conservation and management of the world’s cheetahs.\nOwnership and Management\nCheetah Conservation Fund (CCF) is the owner of CCF Bush Pty Ltd.\nCCF’s base of operations is in Namibia, which has the largest and one of the few sustainable populations of free-ranging cheetah in the world. The cheetah’s survival depends on a total ecological system of farmland management, prey species management, and habitat stability.\nCCF’s Namibian focus is to work with livestock farming communities in order to develop ways to reduce conflict. This is achieved by devising a conservation plan that secures habitat for the species, while still accommodating farmers’ land use needs. CCF carries out scientific research programs in areas such as cheetah population biology, cheetah ecology, cheetah health and reproduction, and human impacts on the cheetah. CCF researchers develop, test, and promote alternative land-management practices such as conservancy development, non-lethal predator control, relocation of problem cheetahs, and eco-tourism.\nAdditionally, CCF conducts both Namibian and international education programs to raise awareness of the cheetah’s endangered status. These illustrate ways in which the species can be protected and encourage worldwide support.\nCCF’s Model Farms\nThe Model Farms have been developed to research and display predator friendly and commercially viable livestock and wildlife programs. During 2003, the CCF bush PTY Ltd developed 50 economic plots (1 ha each = 50 e farm). These plots were used to assess the bush biomass yield per hectare, species composition, and stem densities of the tree/shrub species and the production potential. Educational groups and visiting farmers have the opportunity to see first hand that farmers and cheetahs can coexist. The farms also researches and display innovative business initiatives such as: Bushblok compressed fuel log, made from invasive thorn bush, and Cheetah Country products, an eco label for Namibian beef and other products that would allow cheetah friendly farmers to sell at a premium price nationally and oversees.\nThe Elandsvreugde farm consists of a 1600 ha grass field (22% of the total area size) which supports hay production, and ecotourism activities. Ongoing ecological research activities are conducted on regular basis especially monthly game counts which were designed to study the trends in population structure and habitat use of different wildlife species on the farm. Smallstock farming is practiced consisting primarily of goats. In addition, Anatolian shepherds and Kangal dogs are bred at the centre as part of the Livestock Guarding Dog program. No large stock farming is practiced on the farm. Wildlife farming is the most dominant form of land use on the farm. This is the site of the main CCF campus and the Biomass Technology Demonstration Centre with the BUSHBLOK factory.\nFarm Cheetahview contains accommodation facilities available to visitors, students and researchers. Both wildlife and livestock farming is the most dominant form of land use type. Various biodiversity studies were conducted on the farm as part of the projects of the CCF BUSH PTY Ltd since 1998. The farm also contains accommodation facilities for the farm workers staff.\nFarm Boskop contains accommodation facilities for CCF professional staff, and farm worker staff. Both livestock and wildlife farming are the most dominant form of land use type.\nCCF manages seven other farms. Two (Osonanga Reserve and Osonanga Farming) are ecological reserve lands and five (Padberg, Otjenga, Bynaadar, Bellebenno, and JanHelpman) are cattle ranches. CCF Bush (Pty) Ltd will not undertake activities on those farms and has no responsibility for those farms.\n- CCF Bush Pty Ltd will conduct operations as allowed on Cheetah Conservation Fund forest lands in the long term in ways compatible with FSC Principles and Criteria. “Forest Lands” in this context are lands which are managed to some extent for production of biomass.\n- CCF Bush Pty Ltd will insure that forestry practices do not interfere with the research and farming activities on CCF farms. This involves consultation with relevant projects and requires that consideration be given to fostering grass growth. Thus, large amounts of felled wood may be left un-chipped as protection for seedlings. Run-off of rainwater into dams is to be encouraged.\n- CCF Bush Pty Ltd will assist cheetah census activities by reporting any sightings and/or locations of cheetah tracks, and by clearing sightlines around cheetah “playtrees” to encourage their use.\n- CCF Bush Pty Ltd may harvest roadsides and fence lines to facilitate research/farm operations even if the wood will not be used in the factory.\n- CCF Bush Pty Ltd is a demonstration project: it may incur an ongoing annual loss and may undertake activities that have a negative effect on profitability of the company.\n- CCF Bush (Pty) Ltd will produce and market compacted wood fuel briquettes (BUSHBLOK), or other biomass products, derived from thinned indigenous invader species (bush encroachment). The products may be sold locally and internationally.\n- The raw product will be harvested from three farms owned by the Cheetah Conservation Fund (Farms Cheetahview, Boskop, and Elandsvreugde). These mixed-use farms are contiguous and adjacent to a main class “D” road: it is most economical to harvest from them. The total area of the farms is 17,445Ha.\n- Only bush harvested according to FSC™ principles and only originating from those three farms may be incorporated into the CCF BUSH Pty Ltd Chain of Custody (COC) scheme (CCF’s FSC™ license number FSC-C004580). This is our Forest Management Unit (FMU).']	['<urn:uuid:378633ef-928d-4d70-b4cc-7c92b04bb97b>']	factoid	direct	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-13T03:20:41.944655	15	18	1096
88	How do modern sustainable kitchen designs compare with John K. George's historic renovation approach in terms of maintaining air quality and using recycled materials?	Both approaches emphasize environmental consciousness but differ in their specific methods. John K. George's historic renovation focused on salvaging and reusing existing materials like vintage church light fixtures, antique wood for coffered ceilings, and porcelain sinks, primarily for aesthetic and historical authenticity. Modern sustainable kitchen design, while also promoting recycling, puts greater emphasis on air quality through specific material choices, requiring no-VOC or low-VOC products for cabinets and countertops to prevent off-gassing. Both approaches incorporate recycled materials, but modern designs are more systematic about ensuring materials are certified environmentally safe, such as using Greenguard-certified products, while George's approach was more focused on architectural preservation while achieving environmental benefits.	['You are here\nBefore-and-After Showhouse Kitchen\nA 1913 Tudor-style kitchen gets a respectful renovation\n- « prev\n- next »\n- 1 of 15\nFrom porch posts to ornate iron brackets, other people’s castoffs are John K. George’s inspirations. For more than 25 years—long before others were recycling—this college history major turned interior designer has been salvaging and reusing materials in his design projects. “My love of history is interwoven with a strong respect for well-built and well-designed historic buildings,” George says. “Plus, as one of five kids raised in a very frugal family, I have practiced green remodeling, salvage, and dumpster diving since before they were considered virtues.”\nThe Virginia designer demonstrated his respectful approach when renovating the kitchen of a 1913 Tudor-style home for the Richmond Symphony Showhouse. Originally built by a family to honor its Scottish heritage, the house features a brick-and-timber exterior, wood-paneled interior walls, and other details typical of a British country house.\nThe kitchen, however, was all-American, circa 1970s, with vinyl floors and blue plastic laminate countertops. “The original kitchen was a large room with great windows but the finishes and appliances were very tired,” the designer says. “I wanted to show how we could create an attractive and beautiful space without the conventional gut-and-start-over approach.”\nGeorge’s first chore was peeling away multiple layers of vinyl and linoleum flooring. “It took a lot of muscle and elbow grease, but it was well worth it,” he says. “We easily sanded and finished the original pine flooring, which was absolutely beautiful, with watermarks and stains that made for an incredible patina.”\nThe designer preserved most of the kitchen’s cabinets but bumped up their historic charm by adding moldings on door fronts, vintage-looking bronze hardware, and fresh coats of paint in a muted green. A previously humdrum built-in china hutch was painted red using a dry-brush technique to simulate a timeworn patina, and it now looks like a cherished antique.\nThe ceiling also got a makeover. George tapped a Richmond reclaimed-lumber business, E.T. Moore, to install a coffered ceiling using salvaged antique wood.\nAntique Gothic porch posts and brackets that George found at Caravati’s—one of his favorite Richmond salvage dealers—flank the new range and are a nod to the house’s Tudor styling.\nAnother find at Caravati’s was a turn-of-the-20th-century porcelain sink, which George upgraded with a new faucet in an oil-rubbed bronze finish. Slate countertops around the room’s perimeter replaced the blue plastic and are another period- and status-appropriate material for the home.\nVintage light fixtures recycled from a church were encircled with hand-forged bands to create a one-of-a-kind pot rack and light fixture above the wood-topped island. The table-style island is also a study in recycling—made of old, wormy pine beams wrapped with hobnailed iron banding.\nGeorge incorporated 21st-century technologies, including energy-efficient appliances, compact fluorescent lightbulbs, and a water-conserving faucet, proving preservation and progress can beautifully cohabit.\nPhotography: Ron Blunt\nProduced by Eileen A. Deymier\nRichmond Symphony Showhouse\nInterior designer: John K. George, John K. George & Co., 3000 W. Clay St., Richmond, VA 23230; 804/560-1717.\nSink (porcelain); architectural fragments for range surround; island/dining table (fabricated from wormy pine beams and hobnailed iron banding); materials for pot rack/lighting fixture: Caravati’s Inc. Architectural Salvage, 804/232-4175, caravatis.com.\nWood plank-and-beam ceiling: E.T. Moore Mfg. Inc., 804/231-1823, etmoore.com.\nSlate countertops: Virginia Slate Co., 804/282-7929.\nCountertop fabrication: Park Stone Granite and Marble, 804/755-6888.\nFaucet (vintage-style water-saver bridge faucet): Moen, 800/289-6636, moen.com.\nCeramic tile: Morris Tile Distributors, 804/353-4427, morristile.net.\nRe-fashioning cabinet doors; cabinet moldings (custom): Siewers Lumber & Millwork, 804/358-2103, siewers.com.\nCabinet color (“Homestead Green” #AC-19): Benjamin Moore & Co., 888/236-6667, benjaminmoore.com.\nCabinet hardware (solid bronze): Emtek, 800/356-2741, emtek.com.\nCabinet shelving (recycled plate glass): 4-D Discoveries Glass Co., 804/897-6340.\nGas range; vent hood; dishwasher: Whirlpool, whirlpool.com.\nAccessories: Anne Marie Elles, Trappings, 804/353-5378, trappingshome.com. Flooring (restored original pine flooring, finished with soybean poly): Costen Floors, 804/527-2929, costenfloors.com.\nCeramic subway tile and accessories: American Olean, aotile.com.\nTile installation: CL Jones Tile & Marble, 804/514-9233.\nRetro blue countertops and outdated appliances show that this kitchen was crying for an update. Designer John K. George maintained the layout of the original kitchen while breathing fresh new life into it with a richer palette and environmentally sound amenities. Details on the following slides.\nPerimeter molding was applied to the existing cabinets, which were painted and glazed for an aged look. New Emtek bronze hardware completes the transformation.\nThe ceiling commanded no attention in the original kitchen; combined with the blue walls, it only served to make the room icier.\nThe striking new coffered ceiling was fabricated from salvaged materials, reflecting the house’s historic features while adding eye-catching texture and design elements.\nSalvaged porch posts and brackets were installed on either side of the new range. The Gothic arches reflect the Tudor styling of the house and give the range wall added importance. Adding a simple black frame to the backsplash with diagonal tiling helps it stand out against the surrounding brick pattern.\nA single light fixture casts a lonely glow on the kitchen island, with the chilly palette interrupted by the avocado refrigerator, an artifact from the disco days.\nA new energy-saving, stainless refrigerator replaces the former, whose hue moves to the cabinets to complement the rich tones of the remodeled kitchen. Lofty twin light fixtures warm the space and provide an overhead focal point. Details on the following slides.\nRefrigerator: Whirlpool, whirlpool.com.\nVintage church light fixtures and hand-forged iron straps were combined to make a distinctive and functional pot rack and light source.\nDecorative iron brackets with timeworn finishes support the island’s salvaged pine-beam countertop and add texture and character to the kitchen.\nThe table-style island was crafted from salvaged wormy pine beams and wrapped with hobnailed iron banding. The island’s top is mounted on a trestle table base that was finished with a glaze to replicate an aged patina.\nDesigner John K. George saw merit in the design and function of the china cabinet, but its colors were off-putting and lackluster.\nNondescript cabinets were painted red to create a focal point breakfront in the renovated kitchen.\nBreakfront color (“Caliente” #AF-290, applied with dry brush technique over white): Benjamin Moore & Co., 888/236-6667, benjaminmoore.com.\n“I don’t like doing anything cookie-cutter,” designer John K. George says, “And one-of-a-kind vintage pieces give a house authentic character.”', 'Green kitchen design has come a long way in a short time. Only a few years ago, when “green” was at its buzzword peak, using sustainable materials here and there satisfied many homeowners. A truly green kitchen, however, features careful holistic design that enables a healthy family lifestyle along with saving energy and the planet. Nontoxic materials and finishes are of utmost importance. And they’re no longer novel. “Formaldehyde-free, low-VOC materials are common these days,” says Stephanie Horowitz, architect and managing director of ZeroEnergy Design in Boston. They are what consumers should demand, “especially in the kitchen, where families spend so much time and where the surfaces of countertops and cabinets really shouldn’t off-gas or leach.” She adds, “People expect green design — or should expect it.” To help you get there, here are 25 ideas, tips, and product picks from local kitchen designers.\nTHE BIG PICTURE\n1. Take Your Time Planning\n“To create a green kitchen, thoughtful and enduring design and products must take precedence over size and trendy features,” says Elizabeth Herrmann, president of Elizabeth Herrmann architecture + design in Bristol, Vermont. “Kitchens need to function well, wear well, and not go out of fashion. They should evolve to meet the changing needs of clients.” Lisa Green, owner of Green Design Group in Concord, agrees that careful planning is crucial, making it more likely that you’ll do things right the first time. And that’s key to sustainability.\n2. Make It Ageless\nRipping out one green kitchen and putting in another one every few years is a waste of energy and resources. “To be truly green, a kitchen not only has to have energy-efficient appliances and planet-friendly features, it must be designed to withstand the test of time,” says Lisa K. Tharp, founder of Boston’s K. Tharp Design and designer of the Concord Green Healthy Home, a showcase for sustainable design principles.\n3. Ask Questions, Lots of Questions\nIf you decide to enlist a designer’s help, make sure that person truly gets your needs and what it means to be green. Tharp says a kitchen designer should be able to answer the following questions: “What is your process to deeply understand and distill my wants and needs into a successful kitchen design? How will you ensure that the design honors the architecture of my home and is timeless enough to last? What are fundamental design principles that you incorporate into your kitchen projects? In your experience, what palette of materials, finishes, and products are proven to deliver a healthy and sustainable space? How will you avoid fads that do not hold up?”\n4. Consider the Air\n“The single thing most people overlook is what exactly is lurking in the products they choose. And it’s not their fault — regulation on chemicals in products is antiquated,” says Kelly Taylor, the LEED-accredited founder of Kelly Taylor Interior Design in Providence. Taylor, who is pursuing a master’s degree in sustainable design, explains that resins in composite products for cabinetry, countertops, moldings, furniture, shelving, flooring, and textiles “often contain much added urea formaldehyde, which, as it off-gases, is a dangerous human health concern. Other volatile organic compounds are in nearly every kind of glue, sealant, paint, and coating. The EPA is behind on placing restrictions or simply banning toxic chemicals, like added urea formaldehyde, so it’s important that homeowners understand this is something they need to avoid.” Taylor points out that all “green” products are not created equal. She believes the best indicator that something won’t detract from indoor air quality is Greenguard certification. “Some brands will make up a ‘green’ or ‘eco-friendly’ label, and consumers need to be smart enough to see past that. Make sure you know what’s in your products, why they claim to be green, and most importantly, that they won’t emit toxic chemicals into your air.”\n5. Say No to VOCs\nVolatile organic compounds (VOCs) are chemicals that off-gas (release into the air) at room temperature, and they can pose long-term health problems. “Make sure all products you’re using are no-VOC, if possible. Only accept low-VOC when no-VOC is unavailable,” Taylor says. “Why settle for some toxins when you can have none?”\nAccording to the Environmental Protection Agency, indoor air may be two to five times more polluted than outdoor air, and we spend 90 percent of our time inside. Therefore, Taylor says, “the design of your kitchen should include sources for energy-efficient natural ventilation that will replace indoor air with fresh air from outside.”\nWHAT’S OLD IS NEW\n7. Reduce, Reuse, Recycle\n“Salvaging and re-purposing older items adds patina and style to a new kitchen,” says Tharp. There are many local sources for used stone countertops, doors, hardware, plumbing, cabinetry, and even appliances. She cites Portland Architectural Salvage (207-780-0634; portlandsalvage.com) in Portland, Maine, and Nor’east Architectural Antiques (603-394-0006; noreast1.com) in South Hampton, New Hampshire, as favorite sources for doors, hardware, and more. Olde Bostonian (617-282-9300; oldbostonian.com) and Boston Building Resources (617-442-2262; bostonbuildingresources.com), both in Boston, are worth checking out, too, she says.\n8. Rethink the Island\nIslands do not have to be built in, Tharp says. “Re-purposing a fabulous piece of furniture, such as a worktable, as a kitchen island is a wonderful way to add character and flexibility.”\n9. Light It Up\n“Get creative with lighting, and try something reclaimed or retrofit — from antique library sconces to factory and ship lights, or even upside-down baskets,” Tharp suggests. “Re-purposing items in creative ways inspires us to think about reuse and reminds us to keep things simple with humble materials like baskets and twine, which are often made with fewer toxic materials and have a lighter impact on the earth.”\n“Although it can be hard to spend money on things no one will notice, such as new windows and wall insulation, the rewards go beyond energy efficiency and ‘saving the planet,’ ” Taylor says. “Thermal comfort is really important to human health and happiness. So if you’re opening up walls in order to renovate, definitely insulate tightly while you have the walls open. Replace old windows, and seal all the air gaps.”\n11. Bring the Heat, Quickly\nZeroEnergy’s Horowitz is a fan of induction cooktops, which she says are “speedy and efficient at transferring heat and produce extremely even temperatures.” She especially likes Wolf’s unframed version.\n12. Brighten With LEDs\nLight-emitting diodes “have come a long way in the past few years, and now the only type of recessed lighting I specify is LED,” Taylor says. “If you must use the screw-in LED replacements, that is fine, but I much prefer the recessed lights that have an LED module with a nice glass diffuser on the bottom. For one, you no longer have to look up at a dusty light bulb. But more importantly, the light output is so much more pleasant.” Taylor suggests adding 10 percent to 15 percent more lights if you’re using LEDs, because the LED output is somewhat less than that from standard incandescent recessed lights. One of her go-to brands is Lightolier.\n13. Buy Stars\nWhen choosing big-ticket items, Taylor says, “don’t underestimate the power of Energy Star appliances. Energy Star has fun simulation calculators for many products on its website, and it’s cool to go in and see just how much you will save by buying appliances that don’t hog so much power.” Try it out at energystar.gov.\n14. Plan for a Power Strip\nPlugging several countertop appliances into a single power strip allows you to turn them off easily before leaving the house. “You use so much energy just by leaving them plugged in,” Taylor says. “If they are all connected to one switch, it’s way easier to turn them off, and you might actually do it.”\n15. Shop Local\nEven the greenest materials require a lot of fuel to ship across the country (or around the world). “I like to use new green materials but like to pair them with handmade and local materials,” Herrmann says. Not only does this save energy and resources, but those products also “tend to be better loved, and may be less likely to be discarded in a few years.” One of Taylor’s favorite sources of local kitchen goods is Stock (401-521-0101; stockpvd.com) in Providence, which carries pepper grinders and oyster platters from Maine, wine openers from Connecticut, knives from Massachusetts, cutting boards and rolling pins from Vermont, and ceramics by Rhode Island potter and RISD instructor Anna Galloway Highsmith. It also has islands made from Rhode Island trees by Hope’s Woodshop. “When the city cut down a 100-year-old maple at my house,” says Stock owner Jan Dane, “I called Hope’s Woodshop to come get it. That’s local!”\n16. Clear Clutter\nKeeping a kitchen clean is a big part of being green. A messy kitchen, Horowitz says, is an impediment to actually using that kitchen. Which means less cooking of organic food, less blending of fruits and veggies, less of so many factors that contribute to a healthy lifestyle. “Clutter can inhibit our behavior,” she says. “Ultimately, we want to design a kitchen that’s enjoyable to use, and a kitchen is much more enjoyable to use if things have a proper place.”\n17. Park Appliances\nWhen planning the design of a kitchen, Horowitz says, it’s key to consider which countertop appliances are in most frequent use, and find a space for those. If there are tall appliances, such as blenders, in heavy rotation, they need to fit under the cabinets. Horowitz strongly recommends an appliance garage for keeping things tucked away — she likes the Box Milano by Hafele — or creating space on a pantry shelf for less-used items. “In my opinion, the most overlooked element of kitchen design is smart storage,” Concord’s Green says. Beyond appliances, “it’s important to take a look at all the options for dishes, cutlery, pots, and pans, as well as decorative items, and make a plan.”\n18. Ditch Paper Towels\nInstead of using disposables to wipe up messes, use towels. To make that easier, Horowitz says, incorporate a place where plenty of towels can be stored — and a place for them to be discarded when they are ready for the laundry.\n19. Hide the Compost\nAn in-counter compost bin, which is tucked beneath an opening in your countertop into which you drop scraps, is “a huge improvement to the old, messy countertop compost bucket,” Herrmann says. “It is concealed but handy and makes cleaning very easy.” Both Herrmann and Horowitz recommend the Blanco Solon compost system. While you’re at it, make sure you have a convenient setup for recycling, too.\n20. Make Space for Green Food\n“Think about what you need to store more fresh local produce, proteins, herbs, and spices, and maybe even an indoor garden,” Green says. The refrigerator should have plenty of room for veggies, and you should have a dark, low-moisture spot for potatoes and onions. For DIY herbs, Green recommends a locale that gets at least four hours of sunlight and using a clay or ceramic pot with good drainage.\n21. Plan Backsplashes Wisely\nSeveral designers recommend skipping tiles for the backsplash and choosing a smooth surface for easier cleaning instead. (Tharp also notes that a tiled backsplash can “date quickly and add a lot of visual complexity.”) Herrmann suggests a single piece of stainless steel or specialty-finish metal, reclaimed stone or concrete slab, Fireslate, or painted planking that is easy to wash. Horowitz likes to keep outlets off the backsplash — to simplify cleaning — and to move them up under the cabinets.\nMORE PRODUCT PICKS\n22. Consider a Superior Tile\nTaylor and Green both love Fireclay Tile. “It’s a handmade, sustainably produced product that contains a significant amount of postindustrial and post-consumer waste,” Taylor says. “Aside from using trash to create beautiful tile, the company also makes every tile to order, so there is no added waste from throwing away unused stocks of previously produced tile.”\n23. Choose Top Counters\nWhen it comes to quartz counters, Green prefers Cambria: The stone is primarily mined in North America, Cambria recycles all of the water in its fabrication facilities, and scrap material is collected for use as road base. One of Taylor’s favorites is Richlite, made from a paper-based composite material that is quite durable, heat-resistant up to 350 degrees, and impact-resistant. “It’s extremely strong, so you can have long cantilever overhangs without adding support brackets or steel,” Taylor explains. “It is easy to cut with a variety of tools, but it can also be threaded, so it’s easy to work with. The company uses only sustainably derived resources, like FSC-certified paper pulp, and low-emitting binders, the resins that hold the pulp together.”\n24. Seek Good Wood\nFor countertops and other wood paneling, Green likes TorZo. “It features sustainably harvested and recycled content, and it’s beautiful,” she says. The company’s newest product is Blue Stain pine panels and planks. “Due to the devastation caused by the mountain pine beetle, many pines are left to rot in the forest, and they have a blue tinge to them. TorZo has found a way to salvage this wood so we can use it in commercial spaces as well as our homes.” Herrmann uses Valchromat, a recycled wood composite material, for cabinet doors and drawers.\n25. Finish Strong\n“ECOS Organic is my go-to line of 100 percent nontoxic finishes,” Tharp says. “It includes floor varnishes, paints, and specialty finishes. ECOS color-matches all the major brands, and pricing is reasonable. The line originated in the UK, but now it’s made here on the East Coast, and it can ship within 24 hours.” Green also recommends Mythic Paint and WOCA Oil, a VOC-free vegetable-oil base that “creates a lovely, subtle finish for wood floors.”\nMore coverage:“Green Chic” and the author and illustrator of “Tap the Magic Tree.” Send comments to firstname.lastname@example.org.']	['<urn:uuid:39e6c162-b6f1-48c7-84b8-e9d7f59d5113>', '<urn:uuid:1f78e713-5175-4287-9dd7-5f620def5cc3>']	open-ended	direct	verbose-and-natural	similar-to-document	comparison	expert	2025-05-13T03:20:41.944655	24	108	3352
89	which one more expensive build landfill waste energy plant	Waste-to-energy facilities are significantly more expensive to build than landfills. The cost of construction for a new waste-to-energy plant often exceeds $100 million, with larger plants requiring double or triple that amount. For example, the Newhurst energy-from-waste facility in Leicestershire is expected to cost £285-295 million to construct. In contrast, landfills are far less expensive, which is why the U.S., with its surplus of available land, often chooses this more financially viable option.	['Rising rates of consumption necessitate an improved approach to resource management. Around the world, from Europe to Asia, governments have adapted their practices and policies to reflect renewability. They’ve invested in facilities that repurpose waste as source of energy, affording them a reliable and cheap source of energy.\nThis seems like progress, given the impracticality of older methods. Traditional sources of energy like fossil fuels are no longer a realistic option moving forward, not only for their finite nature but also within the context of the planet’s continued health. That said, the waste-to-energy sector is subject to scrutiny.\nWe’ll detail the reasons for this scrutiny, the waste-to-energy sector’s current status within the United States and speculations for the future. Through a concise analysis of obstacles and opportunities, we’ll provide a holistic perspective of the waste-to-energy progress, with a summation of its positive and negative attributes.\nStatus of Waste-to-Energy Sector\nThe U.S. currently employs 86 municipal waste-to-energy facilities across 25 states for the purpose of energy recovery. While several have expanded to manage additional waste, the last new facility opened in 1995. To understand this apparent lack of progress in the area of thermochemical treatment of MSW, budget represents a serious barrier.\nOne of the primary reasons behind the shortage of waste-to-energy facilities in the USA is their cost. The cost of construction on a new plant often exceeds $100 million, and larger plants require double or triple that figure to build. In addition to that, the economic benefits of the investment aren’t immediately noticeable.\nThe U.S. also has a surplus of available land. Where smaller countries like Japan have limited space to work within, the U.S. can choose to pursue more financially viable options such as landfills. The expenses associated with a landfill are far less significant than those associated with a waste-to-energy facility.\nPresently, the U.S. processes 14 percent of its trash in waste-to-energy (WTE) plants, which is still a substantial amount of refuse given today’s rate of consumption. On a larger scale, North America ranks third in the world in the waste-to-energy movement, behind the European nations and the Asia Pacific region.\nFuture of WTE Sector\nCertain factors influence the framework of an energy policy. Government officials have to consider the projected increase in energy demand, concentrations of CO2 in the atmosphere, space-constrained or preferred land use, fuel availability and potential disruptions to the supply chain.\nA waste-to-energy facility accounts for several of these factors, such as space constraints and fuel availability, but pollution remains an issue. Many argue that the incineration of trash isn’t an effective means of reducing waste or protecting the environment, and they have evidence to support this.\nThe waste-to-energy sector extends beyond MSW facilities, however. It also encompasses biofuel, which has seen an increase in popularity. The aviation industry has shown a growing dedication to biofuel, with United Airlines investing $30 million in the largest producer of aviation biofuel.\nIf the interest of United Airlines and other companies is any indication, the waste-to-energy sector will continue to expand. Though negative press and the high cost of waste-to-energy facilities may impede its progress, advances in technology promise to improve efficiency and reduce expenses.\nPositives and Negatives\nThe waste-to-energy sector provides many benefits, allowing communities a method of repurposing their waste. It has negative aspects that are also important to note, like the potential for pollution. While the sector offers solutions, some of them come at a cost.\nIt’s true that resource management is essential, and adapting practices to meet high standards of renewability is critical to the planet’s health. However, it’s also necessary to recognize risk, and the waste-to-energy sector is not without its flaws. How those flaws will affect the sector moving forward is critical to consider.', 'Biffa is set to develop its first energy-from-waste incinerator in the UK after achieving financial close on the Newhurst energy-from-waste (EfW) facility in Leicestershire, the company announced today (February 11).\nThe plant is being developed alongside joint venture partners Covanta, the energy-from-waste specialist, and the Macquarie’s Green Investment Group (GIG), after the companies teamed up in 2017 (see letsrecycle.com story).\nStrategically located just off the M1 motorway in the East Midlands, the Newhurst EfW facility is expected to cost £285-295 million to construct and will have the capacity to treat 350,000 tonnes of residual household and commercial waste a year. It will also produce 42 megawatts of electricity.\nCovanta and GIG will together own 50% of the facility, with Biffa, the primary waste supplier for the facility, owning the remaining half.\nA spokesman for Biffa confirmed that, while the company has a number of anaerobic digestion facilities in the UK, the Newhurst plant would be its first energy-from-waste incinerator.\nBiffa currently controls more than 1.7 million tonnes of residual waste suitable for EfW facilities but has historically sent much of this in the form of RDF to energy-from-waste plants in Europe.\nHowever, the company said it did not want to be too reliant on European facilities and wanted to address the shortage of EfW facilities in the UK.\nMichael Topham, Biffa chief executive, said: “Biffa has a leading role to play in developing the recycling and energy from waste facilities that the UK needs if it is to become a low-carbon, resource-efficient economy.\n“Reaching this milestone at the Newhurst facility, along with our ambitious investments in recycling, are vital steps in the delivery of our strategic investment plans. We look forward to working with our partners to further reduce the UK’s reliance on landfill or export for managing its non-recyclable waste.”\nConstruction of the Newhurst facility is expected to take just over three years to complete and will be led by EfW engineering specialist Hitachi Zosen Innova (‘HZI’) under a turnkey Engineering, Procurement and Construction (‘EPC’) contract. Over 300 jobs are expected to be created during the construction period.\n“Reaching this milestone at the Newhurst facility, along with our ambitious investments in recycling, are vital steps”\nBiffa will provide 70% of the fuel for the facility from its existing local waste collection services, and Covanta will supply technical oversight during construction in addition to operations and maintenance of the facility for an initial 20-year term.\nCovanta chief executive and president, Stephen J. Jones, said: “The Newhurst EfW facility will provide important sustainable waste treatment capacity in the drive to move non-recyclable waste away from landfill and combat climate change.\n“Today’s announcement marks our third of four initial development projects to reach financial close with Green Investment Group and our first project with Biffa. Together, we have created a powerful partnership that will provide meaningful returns in our pursuit to protect tomorrow.”\nPlanning permission for the Newhurst facility was granted by the Secretary of State in 2012 and Biffa applied to increase the plant’s capacity in 2018 (see letsrecycle.com story).\nThe Newhurst facility is one of two EfW projects currently being proposed by Biffa, Covanta and GIG. The joint venture is also proposing a 400,000 tonne-per-annum capacity plant at the Protos energy park near Ellesmere Port in Cheshire.\nHowever, Biffa revealed that this facility had been delayed.\nIn a statement, the company said: “Whilst the project is well progressed, the development process is taking longer than anticipated and has resulted in a delay to financial completion. A further update on this process will be provided in due course.”\nInfrastructure will be on the agenda at the Resource Infrastructure Conference, to be held on 24 March. More information can be found here.']	['<urn:uuid:aaa5844b-d53c-467d-b7ea-69e0f3deb9df>', '<urn:uuid:2ca9b00a-dfa8-4e73-9d5d-4aa4b53973d4>']	factoid	direct	long-search-query	distant-from-document	comparison	novice	2025-05-13T03:20:41.944655	9	73	1244
90	What are the specific plans for creating a new public space along the River Clyde as part of the St Enoch district regeneration project?	The plans include creating a world-class linear public space called the river park along both banks of the River Clyde. This continuous urban park would transform the river, kick-start development and become a key destination and attraction within the city centre while creating a quality public space with cultural activities for all ages.	['Ambitious plans to transform the banks of Glasgow’s River Clyde in a bid to connect key parts of the city will be unveiled this week.\nA £900,000 public consultation on the future of the St Enoch district which starts at the junction between Saltmarket and Clyde Street near Glasgow Green and includes the cross-roads between Argyle Street and Buchanan street in the city centre, is expected to launch this Friday and run for eight weeks.\nThe St Enoch district has been described as a dynamic area of Glasgow which connects the city centre, the areas benefiting from regeneration south of the river as well as Merchant City.\nLeader of the Council, councillor Susan Aitken said in a report: “The [St Enoch] district is a dynamic city quarter with a diverse and distinctive amenity and community.\n“The riverside location is also a clearly under-utilised asset that must be redefined and reconfigured to attract footfall and investment.\n“The regeneration of Glasgow City Centre and the River Clyde Corridor should both be considered national priority projects. The St Enoch district has a central role in both.”\nConstruction work on a nine-screen cinema complex with nine new restaurants which is part of a £40 million leisure development is already underway at St Enoch Shopping Centre and will add 30,000 sq ft to the building.\nThe enhanced offer at the shopping mall is expected to attract an additional two million people per year and, once completed, St. Enoch will have the largest consolidated catering offer in the city.\nThe council is now looking to increase the level of public transport making public spaces along the under-utilised river more accessible. It is hoped steps taken to attract footfall and investment in that part of the city will be successful.\nGlasgow’s City Centre original five-year strategy went live in April 2014 with 55 ambitious plans announced for nine city centre districts.\nWork throughout the first district Sauchiehall and Garnethill is underway while public consultation on the second district – Broomielaw is complete and a report expected to be presented to the city administration committee on Thursday.\nThe St Enoch District is the third of nine regeneration plans for the city centre to be brought forward following discussions with the local community and stakeholders.\nA new consultation period will offer further opportunities for residents to have their say on the proposals and an action plan produced following the public meetings.\nSix Strategic themes have been developed to improve the area. Objectives must be met if Glasgow it to compete as a leading European city.\nThe public will be encouraged to give feedback on the proposed river park which aims to create a world-class linear public space along both banks of the River Clyde.\nThe continuous urban park would transform the river, kick-start development and become a key destination and attraction within the city centre while creating a quality public space with cultural activities for all ages.\nNew development in the area will be required to respect Glasgow’s historic built heritage and incorporate the characteristics of important buildings. An official planning application to transform Custom House Quay, which is part of the St Enoch District, is expected to be made to the council in due course.\nSteps will be taken to address the shortage of quality green and public spaces while enhancing the city centre’s public transport and active travel networks to create a sustainable and walkable city.\nIt is hoped proposals will encourage more people to live in that part of the city boosting the night-time economy as a result.\nGlasgow City Council has confirmed it will engage with stakeholders and partners to develop a masterplan strategy for both sides of the river.\nThe final four city centre regeneration frameworks – Cowcaddens, Merchant City, Townhead and the Learning Quarter are expected to be commissioned late 2019 early 2020.\nWant all the latest Glasgow news delivered to your phone? Then sign up for our new WhatsApp alert! Text NEWS to 07899711574 and then add the number to your contacts as ‘Glasgow Live’ for a daily dose of the good stuff ...']	['<urn:uuid:7b9b2013-1ce6-4fad-9289-439d16054bca>']	factoid	direct	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-13T03:20:41.944655	24	53	682
91	tyvek patch porosity measurements specs	Tyvek porosity is measured using the Gurley Hill porosity measurement, which is defined as the time required for 100 cubic centimeters of air to pass through one square inch of material under approximately 4.9 inches of water pressure. The porosity of Tyvek varies both between and within batches. Based on detailed studies, the supplier-provided minimum Gurley Hill porosity specification can be reliably used when calculating gas flow exchange factors (GFEFs).	['An algorithmic method has been created to evaluate the sterilization potential of various Tyvek header package designs in a defined EtO cycle.\nAn ethylene oxide (EtO) sterilized medical device must be sealed in a carefully designed gas-permeable package that enables the EtO gas to enter. This package must meet a variety of engineering, regulatory, and marketing requirements. In use, a sterile package is opened, the sterile device is dispensed, and the opened package is then disposed into the hospital’s waste stream. Sterile packaging is a cost driver at every step in a product’s life cycle.\nSmaller is better when it comes to sterile device package design. The EtO package design is generally either a Tyvek lidded thermoform tray, a Tyvek-poly film pouch, or, for moisture- and oxygen-sensitive products, a barrier pouch with an added Tyvek header patch that ultimately gets sealed and trimmed off. The challenge for designers is to determine optimal package dimensions for Tyvek header pouches. As with most engineering tasks, designing a sterile package is a balance of many factors. Often the only way to absolutely determine whether a package design is capable of being sterilized is through reiterative sterilization testing. Sterilization testing techniques, such as reduced cycle testing, determine whether a package design can be sterilized. However, reduced cycle testing does not provide enough feedback to optimize iterations of a design.\nTo add some clarity to EtO-specific package design requirements, the package design group at Ethicon Inc. has developed an algorithmic method to determine the likelihood that a particular package design will pass EtO sterilization testing. This methodology enables the Ethicon team to design packages more efficiently, minimizing the use of packaging materials along with the associated costs and environmental burden.\nThe gas flow exchange factor (GFEF) is a relative number based on an estimate of the number of times the gas volume within a device package can be exchanged during each step of the sterilization process. The GFEF method relies on the combined gas law that describes the behavior of gases and uses a formula involving the pressure, temperature, and volume of a system. The equation is represented as follows:\nwhere P = pressure, V = volume, and T = temperature.\nThe combined gas law can be used to calculate a specific device package’s GFEF related to a specific EtO sterilization cycle. The GFEF methodology takes into account four major variables in an EtO sterilizable package design as follows:\nGFEFs can be generated for both existing package designs sterilized in existing processes and new package designs or sterilization processes. For example, the GFEFs calculated for a new design can be compared to a database of GFEFs for existing validated packages. Doing so gives the packaging engineer either some indication about whether the new design can pass sterilization validation, or algorithmic support that the new package can withstand an existing sterilization validation.\nThe GFEFs can also be applied toward developing sterilization cycle changes by identifying the optimum candidate packages for the validation testing. They can also help the engineer understand whether any proposed cycle changes can significantly influence the current packages being processed, and, if so, which packages would be most impacted.\nTo calculate the GFEFs, one must calculate the volume of the EtO package at ambient pressure as well as the maximum theoretical package volume. For a Tyvek header pouch package, this is the volume of the pouch if it could be maximally inflated. This can be calculated using a 3-D modeling program such as SolidWorks or in the lab by measuring the maximum containable amount of water the pouch can hold.\n|Table I. An example of Tyvek header patch pouch under GFEF calculations. The process pressures, temperatures, and times shown in this table are for purely example purposes and do not represent an actual sterilization specification.|\nThe engineer must also know both the area and porosity of the Tyvek patch on the prescribed header pouch. The porosity of the Tyvek is defined by its Gurley Hill porosity measurement. Gurley Hill porosity is the time required for a given volume of air (100 cm3) to pass through an area of material (1 sq in.) under a pressure of approximately 4.9 in. of water.1\nThe porosity of Tyvek intrinsically varies from batch to batch as well as within each batch. Ethicon performed detailed studies of this variation and concluded that the supplier-provided minimum Gurley Hill porosity specification could be relied on when calculating GFEFs.\nThe pressure and temperature at each step of the target sterilization process must also be known.\nTable I illustrates the typical input values. The pressure and temperature in the sterilization chamber at the beginning of each step in the process are entered into the table as P1 and T1 respectively. The end pressure and temperature are entered into the table as P2 and T2. The end pressure and temperature for each step become the initial pressure and temperature for the subsequent step. The temperatures and pressures are eventually used to calculate exchange volumes of sterilizing gas.\nThe initial volume (V1) of the pouch at the beginning of the sterilization cycle is the volume at ambient pressure. V2 is then calculated for each step using the combined gas law. V2 becomes V1 for subsequent steps.\nThese calculations provide the theoretical change in volume of the gas within the pouch through each step of the sterilization process. The change in pouch volume affected by pressure changes at each process step is represented by |V2 – V1|, which is the theoretical volume of gas that passes through the Tyvek header during each step of the sterilization cycle.\nIn Table I, this absolute volume of gas that passes through the Tyvek header patch during each step is then used to calculate the GFEF for each sterilization process step. To complete the GFEF for each sterilization process step, the overall porosity of the Tyvek header is calculated using the supplier-provided minimum Gurley Hill porosity specification adjusted to 1 sq in. expressed in seconds/100cm3 multiplied by the overall size of the header patch (sq in.), not including the sealed or obstructed areas of the Tyvek. This is effective Tyvek header patch area (THPA).\nFinally, the theoretical volume of gas passing through the header patch, multiplied by the minimum Gurley Hill porosity supplier-provided specification, divided by the effective Tyvek patch area (ETPA), yields the period of time in seconds required for the gas to move through the pouch header patch during each step in the cycle for the prescribed pouch.\nDividing this product by the individual EtO process step time (in seconds) yields the GFEF factor. The GFEF is a safety factor of the number of times the package volume could be filled, in theoretical terms, understanding that obviously the pouch is filled (or evacuated) only once per each sterilization step. Each EtO process step for each unique package design will have its own unique GFEF.\nThe GFEF can be used in a variety of ways. However, it is a relative number, and it needs to be used in the context of an organization’s existing packaging and sterilization processes.\nTherefore, the best way to start using the GFEF is to calculate it for a representative sample of existing validated package designs. Ethicon has found that the GFEF for EtO exposure and recovery steps can generally be in the range of hundreds and thousands.\nOnce the GFEF has been calculated for a number of existing designs, the packaging engineer can perform an analysis on the data to determine a range of GFEFs with a high confidence of passing a sterilization validation. These data can provide guidance when designing new packaging or when choosing an existing package for a new product. GFEF findings can also be used to set and optimize new and existing packaging designs to potentially define the Tyvek type, Tyvek header area, and overall pouch package volume associated with the package for a defined EtO cycle. Alternatively, package designs on the lower end of the range of GFEFs may be good candidates for validating new sterilization cycles.\nDesigning packages for EtO sterilization is a challenging process. Further, common methods to ensure sterilizability of thermoform trays, for example, is reiterative and expensive. Using an algorithm to determine how a package will handle sterilization could enable more-efficient package design, that enables smaller packages, thereby reducing materials, associated costs, and environmental burden.\n1. Test Method: TAPPI T460 om-06, Air Resistance of Paper (Gurley Method), September 13, 2006.\nDenise Dacey is principal packaging engineer at Ethicon Inc. a Johnson & Johnson company. She is based in Somerville, NJ.']	['<urn:uuid:148bb52a-b120-4d9c-adf4-9995fbccac3f>']	open-ended	with-premise	short-search-query	distant-from-document	single-doc	expert	2025-05-13T03:20:41.944655	5	70	1426
92	How has the GRACEnet project contributed to greenhouse gas mitigation science since its establishment, and what are its key publication outputs?	Since 2002, the GRACEnet project has significantly expanded greenhouse gas mitigation science through the work of 70 ARS scientists who have published over 250 research articles. The project's findings have been synthesized in a book containing 29 chapters, which covers regional analyses of soil organic carbon and greenhouse gas dynamics across various agricultural land uses, along with summaries of key activities such as modeling, method development, economic outcomes, adaptation research, and international collaboration.	['SOIL AND GAS FLUX RESPONSE TO IMPROVED MANAGEMENT IN COLD, SEMIARID AGROECOSYSTEMS\nLocation: Northern Great Plains Research Laboratory\nTitle: Managing agricultural greenhouse gases: Coordinated agricultural research through GRACEnet to address our changing climate\nSubmitted to: Book Chapter\nPublication Type: Book / Chapter\nPublication Acceptance Date: April 25, 2012\nPublication Date: June 8, 2012\nCitation: Liebig, M.A., A.J. Franzluebbers, and R.F. Follett (Editors). 2012. Managing agricultural greenhouse gases: Coordinated agricultural research through GRACEnet to address our changing climate. San Diego, CA:Academic Press. 547 pp.\nInterpretive Summary: In 2002 the USDA Agricultural Research Service (ARS) developed a coordinated national research project called GRACEnet (Greenhouse gas Reduction through Agricultural Carbon Enhancement network) to provide information on soil carbon (C) dynamics and greenhouse gas (GHG) emissions in agricultural systems in different agroecological regions throughout the US, and evaluate how conservation management practices in these regions could reduce net GHG emissions. ‘Managing Agricultural Greenhouse Gases: Coordinated Agricultural Research through GRACEnet to Address our Changing Climate’ synthesizes recent research findings generated from more than 30 ARS locations participating in the GRACEnet project. The book, consisting of seven sections and 29 chapters, addresses major themes associated with current soil C sequestration and GHG mitigation research from across the US. Although GRACEnet is an ARS project, the reported findings have broad natural resource implications on a national level, as well as important international applications given the similarity of environmental conditions to other parts of the world.\nGlobal climate change presents numerous challenges to agriculture. Concurrent efforts to mitigate agricultural contributions to climate change while adapting to its projected consequences will be essential to ensure long-term sustainability and food security. To facilitate successful responses to climate change, relevant and timely research will be critical to ensure appropriate application of novel management practices and technologies on agricultural lands throughout the U.S. Such research should provide a mechanistic understanding of underlying processes affecting natural resources, be scalable to provide useful predictions for select management scenarios, and be translated in such a way that it effectively supports informed decision making. It is under this broad rubric of research goals that the USDA-ARS GRACEnet (Greenhouse gas Reduction through Agricultural Carbon Enhancement Network) project is based. Since 2002, 70 ARS scientists involved in GRACEnet have published over 250 research articles, and in doing so, have significantly expanded greenhouse gas mitigation science. Incumbent to disseminating GRACEnet information is the need to provide integrative syntheses to foster the communication of research accomplishments in a broad context. ‘Managing Agricultural Greenhouse Gases: Coordinated Agricultural Research through GRACEnet to Address our Changing Climate’ addresses this need. The book consists of 29 chapters that provide regional syntheses of soil organic carbon and greenhouse gas dynamics across a broad portfolio of agricultural land uses, as well as summaries addressing key activities central to GRACEnet (e.g., modeling, method development, economic outcomes, adaptation research, and international collaboration). The book is envisioned to support ARS’s goal of providing knowledge and information to better implement scientifically-based agricultural management practices from field to national policy scales.']	['<urn:uuid:f37b2b71-a311-4833-81b6-87e82a5c8065>']	open-ended	direct	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-13T03:20:41.944655	21	73	500
93	landscape features natural formations ancient mining shafts timna national park description	Timna Park features dramatic purple and pink cliffs, with Mount Timna at its center and colorful mushroom-shaped sandstone formations. The site includes Solomon's Pillars, which are the oldest sedimentary rocks in Timna, deposited 530 million years ago. The park contains about 10,000 'saucers' (unused mine shafts filled with sand and rocks), and an 'Open Mine' shaft as deep as a 12-story building, where ancient mining tools left diagonal chisel marks and carved niches for climbing.	['Ask Hagit Gal why 2011 was the year historic Timna Park got earmarked for a multimillion-dollar facelift, and she chuckles. “It’s about time!” the park manager tells ISRAEL21c.\nThe park’s story began 6,000 years ago, when the world’s first copper mines were dug here. In the early 1980s, the Jewish National Fund (KKL-JNF), the Eilot Regional Council and the Ministry of Tourism established a tourist park at this unique UNESCO World Heritage Site, which is rich in both history and natural beauty.\nIt’s become modestly successful, attracting some 150,000 visitors per year — 20,000 of them Israeli schoolchildren – but clearly it is not nearly as well known as its closest neighbor to the south, the Red Sea resort city of Eilat. Hoping to give this unique site its due, in June the KKL-JNF unveiled major improvements financed by donors in the United States and Germany.\n“We have learned what Timna needs, like a teenager that now has to know what to do when it grows up,” says Gal. “We put a lot of money in upgrading the electricity and water systems and bike paths. We changed all the signage.”\nHundreds of shade trees and pergolas are going up to shield tourists from the hot desert sun.\nThere is talk of a new hotel and a new international airport, which would be situated near Timna and also serve the large tourist trade to Eilat, 16 miles south.\nA new visitors center is under construction, and Gal would like to commission an updated version of “The Mines of Time,” a 360-degree 3D show (available in six languages) giving visitors a glimpse into the prehistoric periods leading up to the times of the Egyptian New Kingdoms in 12-14 BCE, when copper mining began.\n“There is nothing like Timna in the world,” says Gal. “The copper mines that the [ancient] Egyptians dug here is the story of Timna.”\nArcheologists first began investigating the horseshoe-shaped Timna Valley in 1845, discovering evidence of copper refining operations that had come and gone over thousands of years. At first it was believed that most of the mining and smelting was done in the 10th century BCE during the reign of the Israelite King Solomon.\nAlthough the copper used in the Temple built by Solomon in Jerusalem probably did not come from this area, and later research showed that the initial estimation was off a bit, the site became known as King Solomon’s Mines, and the natural red rock columns along the walls of the cliffs are still known as Solomon’s Pillars.\nThese pillars are actually the oldest sedimentary rocks found in Timna, deposited as long as 530 million years ago. If you look closely, you can see the individual grains of sand that make up the texture of the rock. In the cracks, you can see different sizes and colors of sand in the various layers of sandstone.\nThe valley is bordered by dramatic purple and pink cliffs, punctuated by Mount Timna rising up at its center and colorful mushroom-shaped sandstone formations all around.\nAlong with the pillars and mushrooms, Timna has about 10,000 “saucers” — unused mine shafts that had filled up with sand and rocks over many years.\nTourists can explore the “Open Mine,” a shaft that goes down as deep as a 12-story building. You can still see the niches carved into the sides of the shaft for climbing, along with diagonal chisel marks made by the dull stone tools of miners long ago.\nThe Miners’ Temple, originally a sanctuary to Hathor, the Egyptian goddess of mining, is another popular stop along the visitors trail. Ancient Midianites later transformed the space into their own sanctuary. The two peoples left behind clay vessels, votive offerings made of stone and alabaster, faience beads, seals and scarabs bearing the names of the pharaohs who sent delegations to Timna, as well as tablets and figurines of Hathor, copper animal figurines, jewelry and shells from the Red Sea.\nBike it, with 100 new cycles\nTimna Park has 25 hiking routes, and four new bike paths built by KKL-JNF. KKL-JNF in Germany donated 100 new bicycles for visitors. Paved paths lead to the main seven sites, including ancient smelting furnaces and work camps for Egyptian copper miners and loggers who prepared acacia wood for charcoal fuel. The trees still provide shelter and nutrition to the resident ibexes and gazelles.\nThe manmade Timna Oasis Lake, the recreation area of Timna Valley, draws from the groundwater found in the layers of sandstone below. You can rent a pedal boat and picnic at shaded tables and benches – even stay overnight at a newly renovated camping site.\nTimna’s Challenge Site, at the foot of the red sandstone cliffs, offers rappelling, a climbing wall, archery, children’s creative activities and even a “treatment tent” where you can get a massage or do tai chi.\nGal is optimistic that these efforts will increase traffic to Timna Park, as will a new full-size bus line from Eilat that will be a vast improvement over the weekly shuttle bringing tourists to Timna from its better-known neighbor.']	['<urn:uuid:c6b2b13c-bc0e-4f92-90db-ae1dfd8cb333>']	open-ended	with-premise	long-search-query	distant-from-document	single-doc	expert	2025-05-13T03:20:41.944655	11	75	848
94	what is meant by fight or flight response	The fight-or-flight response is a physical stress response where the body releases hormones when perceiving a threat. This response causes physiological effects including elevated heart rate, increased energy, increased focus, and increased blood flow to muscles for more power. This biological response was particularly useful for our prehistoric ancestors when they needed to either fight against or run away from predators.	['What stress can do to your body\nWhat was your New Year’s resolution? If it was to join a gym or try to eat more fruits or vegetables, then kudos to you, but you may be neglecting one of the most beneficial things you can do to improve your health: You should be trying to limit (or at least manage) your stress.\nAn expert from the Texas A&M College of Nursing talks about why your stress can be derailing your health.\nWhat is stress?\nStress is a physical response to a perceived threat, which may or may not be real. The stress response causes the body to release hormones that have physiological effects, such as elevated heart rate, increased energy, increased focus and increased blood flow to your muscles—giving you increased power.\nThis biological “fight-or-flight” response came in handy whenever our prehistoric ancestors sensed a predator looming and they had to tap into some stored energy to fight back or make a quick getaway.\nYour (modern) body under stress\nHowever beneficial these effects may be in the short term, constant responses to stress can use up that same stored energy, and that is where the problems begin. “Chronic stress can cause physiological problems,” said Nicola Contreras, MSN, a registered nurse and clinical assistant professor with the Texas A&M College of Nursing. “Lasting stress can lead to headaches, muscle soreness and other chronic complications.”\nWhen a person is stressed, the body releases a hormone called cortisol, and elevated cortisol can be the start of a variety of issues. It can cause cognitive problems, such as interfering with mood and memory, and it can also increase weight gain, blood pressure and cholesterol.\nIf you begin feeling ill after a particularly long and stressful few days, that likely isn’t a coincidence. Elevated cortisol can tank your immune system, or it may manifest as symptoms that make you contact your health care provider.\n“Sometimes people will go to their provider with gastrointestinal problems, like constipation or diarrhea, that are brought on by stress,” Contreras said. “In other cases, stress could weaken the immune system and make you more susceptible to illnesses, like the cold or flu.”\nStress, the public health crisis\nData from the American Psychological Association (APA) showed that over 60 percent of Americans have significant stress from either money, work or politics. After a 2010 survey of more than 3,000 American adults, the APA even called it a “public health crisis.”\nMost Americans are suffering from moderate to high stress, and 44 percent of people reported that their stress levels increased over the past five years. Also, stress isn’t just an adult problem. Almost one-third of children reported that they had experienced a physical health symptom related to stress.\nRemember in the beginning when we talked about self-care being a priority as a New Year’s resolution? Well the same data showed that only 40 percent of Americans rate their health as very good or excellent. While 54 percent agreed that physical activity was very or extremely important, for example, only roughly a quarter of respondents were happy about their own level of exercise.\n“People with chronic stress will have irregular eating and sleeping patterns,” Contreras said. “They may eat too much food, or have no appetite at all. They also may not be able to get the appropriate amount of sleep, or may even be sleeping too much.”\nData from the APA agrees with Contreras: Many American adults are indulging in unhealthy behaviors to cope with stress. Almost a third of adults say they skipped a meal because of stress in the past month. Two-fifths reported overeating or eating unhealthy foods because of stress, and more than 40 percent reported that they stayed awake at night due to stress.\nContreras also noted that having high amounts of stress can lead to anxiety or depression or drug and alcohol abuse. “People respond to stress differently, whether that is being more irritable or experiencing other changes in personality, or possibly drinking or taking drugs to try and handle the stress better,” she said.\nHow to deal with stress\nJust as stressors are unique to individuals, there is no tried-and-true way to relieve stress once and for all. However, health experts will point to exercise as a good starting point.\n“Exercise counteracts some of the impacts of stress,” Contreras said. “It can be as simple as walking or swimming or dancing, but exercise has been shown to improve health and raise endorphins to fight stress.”\nDeep breathing and meditation can also help relieve stress. According to the American Institute of Stress, to effectively combat stress, we need to actively relax—which means to take deep abdominal breaths for 20 to 30 minutes and not just watch television in your sweatpants.\nIf you believe that stress has interfered with your daily routine, you shouldn’t hesitate to tell your provider. “Talk to your provider about stress and stress management,” Contreras said. “They could tell you about what changes need to be made to help improve your health and limit long-term damage from stress.”']	['<urn:uuid:99149bb2-8631-427c-9820-0e23d94ff9d3>']	open-ended	with-premise	short-search-query	similar-to-document	single-doc	novice	2025-05-13T03:20:41.944655	8	61	845
95	I'm curious about how 3D printing actually works in construction - could you explain the basic process of how buildings are printed and what materials are used?	In construction 3D printing, the process starts with creating a 3D digital model of the building using computer-aided design (CAD). The printer then reads this design and lays down successive layers of material to create the structure. For construction specifically, companies typically use quick-drying cement mixtures or concrete as the printing medium. For example, some systems spray a mixture of quick-drying cement and recycled raw materials, laying them in layers to form the structure. The process can form either complete structures on-site or create blocks that are later assembled into buildings. The printer usually operates on rails or a gantry system spanning the building site, with a computer-controlled nozzle delivering the building material layer by layer.	"[""- Project plans\n- Project activities\n- Legislation and standards\n- Industry context\nLast edited 10 Oct 2020\n3D printing in construction\n3D printing (sometimes referred to as Additive Manufacturing (AM)) is the computer-controlled sequential layering of materials to create three-dimensional shapes. It is particularly useful for prototyping and for the manufacture of geometrically complex components.\nIt was first developed in the 1980s, but at that time was a difficult and expensive operation and so had few applications. It is only since 2000 that it has become relatively straightforward and affordable and so has become viable for a wide range of uses including product design, component and tool manufacture, consumer electronics, plastics, metalworking, aerospace engineering, dental and medical applications, and footwear.\nA 3D digital model of the item is created, either by computer-aided design (CAD) or using a 3D scanner. The printer then reads the design and lays down successive layers of printing medium (this can be a liquid, powder, or sheet material) which are joined or fused to create the item. The process can be slow, but it enables almost any shape to be created.\nAccuracy can be increased by a high-resolution subtractive process that removes material from an oversized printed item. Some techniques include the use of dissolvable materials that support overhanging features during fabrication.\nIn the construction industry, 3D printing can be used to create construction components or to 'print' entire buildings. Construction is well-suited to 3D printing as much of the information necessary to create an item will exist as a result of the design process, and the industry is already experienced in computer aided manufacturing. The recent emergence of building information modelling (BIM) in particular may facilitate greater use of 3D printing.\nConstruction 3D printing may allow, faster and more accurate construction of complex or bespoke items as well as lowering labour costs and producing less waste. It might also enable construction to be undertaken in harsh or dangerous environments not suitable for a human workforce such as in space.\nIn 2014, engineers at Arup used 3D printing to fabricate a steel node for a lightweight structure. Salomé Galjaard, team leader at Arup said, 'This has tremendous implications for reducing costs, cutting waste and enables a very sophisticated design…'\nProfessor Behrokh Khoshnevis at the University of California has developed a process of 'contour crafting' using concrete to produce small-scale models of the external and internal walls of houses and is testing a giant transportable 3D printer that could be used to build the walls of a house in 24 hours. The robotic system requires a flat ground slab with underground services in place. Rails are installed either side of the footprint to take a gantry crane that spans the building. A nozzle, driven by a computer-controlled crafter then delivers layers of concrete. The layers build up to form an inner and outer skin for each wall, leaving them to be filled later with insulation or concrete.\nShanghai firm WinSun Decoration Design Engineering has used large 3D printers to spray a mixture of quick drying cement and recycled raw materials (ref. BBC). This has enabled them to construct 10 small demonstration 'houses' in less than 24 hours. They have suggested that each house can be printed for less than $5,000. Their system fabricates blocks off-site by layering the cement mix in a diagonally reinforced pattern. The blocks are then assembled on site. Winsun believes it will be possible to use the technique to build larger houses or even skyscrapers in the future. In 2015, they announced they had printed and entire villa and a five-storey apartment building. (Ref. Global Construction Review 21 January 2015.)\nIn July 2014, Chinese company, Qingdao Unique Products Develop Co unveiled the World's largest 3D printer at the World 3D Printing Technology Industry Conference and Exhibition in Qingdao. Its first job will be to print a 7 m-high Temple of Heaven. (Ref. Construction Manager 1 July 2014.)\nIn November 2014, Skanska and Loughborough University signed a deal to develop what they describe as the world's first commercial concrete printing robot. (Ref. Construction Enquirer, Skanska to print 3D concrete products.)\nIn Spain, the first pedestrian bridge printed in 3D in the world (3DBRIDGE) was inaugurated on 14 December 2016 in the urban park of Castilla-La Mancha in Alcobendas, Madrid. The 3DBUILD technology used was developed by ACCIONA, who was in charge of the structural design, material development and manufacturing of 3D printed elements. The bridge has a total length of 12m and a width of 1.75m and is printed in micro-reinforced concrete. Architectural design was done by the Institute of Advanced Architecture of Catalonia (IAAC).\nThe 3D printer used to build the footbridge was manufactured by D-Shape. The 3D printed bridge reflects the complexities of nature’s forms and was developed through parametric design and computational design, which allows optimising the distribution of materials and maximising the structural performance, being able to dispose the material only where it is needed, with total freedom of forms. The 3D-printed footbridge of Alcobendas represented a milestone for the construction sector at international level, as large scale 3D printing technology has been applied in this project for the first time in the field of civil engineering in a public space.\nSee also: 3D printing construction market.\nClearly all of these projects have enormous potential. There are questions about how Construction 3D printing can be integrated with other building components, and how they will incorporate services and reinforcement, but in the long term, they should produce better, faster and perhaps lower-cost buildings.\nHowever, systemised construction is not something we have taken to in the UK. There was a brief boom in panelised systems for high-rise apartment blocks following the Second World War, but many of the resulting buildings were monotonous and ugly, often with condensation problems. There is a resurgence of interest in the UK regarding panelisation and prefabrication, however market share remains low.\nAll of these innovations require complex equipment, and whilst it is possible to envisage using some simplified version to manufacture specialist components on a more industrial scale, it is questionable whether this will replace bricks and mortar.\nAn alternative approach to digital fabrication of buildings is being developed with the 2D 'WikiHouse' project. WikiHouse, is not an additive process, but an open-source set of construction information for building components which can be downloaded, manufactured and assembled using local, commonly-available materials and equipment. This is low-tech prefabrication which requires little training.\nA WikiHouse plugin for Google SketchUp enables users to generate cutting files for components which can be manufactured from standard sheet materials such as plywood using a CNC (computer numerical control) machine. The components are then assembled, with joints formed using pegs and wedges. The resulting frames can be raised and assembled by hand and then cladding panels attached and services and windows installed. It is claimed that the 'chassis' for a single-storey house can be built in a day.\n Related articles on Designing Buildings Wiki\n- 3D concrete printer.\n- 3D concrete printing market.\n- 3D printed bridge.\n- 3D Printed Office Dubai.\n- 3D printing construction market.\n- 3D printing Michelangelo's David in concrete.\n- Advanced construction technology.\n- Advanced manufacturing.\n- At a glance - 3D printing.\n- Building information modelling.\n- Computer aided manufacturing.\n- Digital techniques for heritage restoration.\n- Innovation - the key to success.\n- Offsite manufacturing.\n- Printing 3D models of buildings.\n External references\n- EPSRC, Centre for Innovative Manufacturing in Additive Manufacturing.\n- BBC, How Dutch team is 3D-printing a full-sized house 3 May 2014\n- Contour Crafting.\n- MSN, The 3D printer that can build a house in 24 hours, 20 November 2013\n- Discover Magazine, The Whole House Machine, 28 April 2005.\n- BBC, China: Firm 3D prints 10 full-sized houses in a day. 25 April 2014.\nFeatured articles and news\nFrom inns and coaching houses to boutiques.\nSurvey reveals green skills gap.\nAmerica's economic collapse produced scores of PWA Moderne projects.\nThe benefits of glowing aggregates and cement.\nUrgent need for open communication to address mental health issues.\nGuidance offered on COVID-19 green recovery, building safety and more.\nProviding strength and support above the joists.\nEnforcer will test and investigate product safety.\nUnderfloor air conditioning comes to 24 St James's Square.\nConsultation on public right to buy unused public property.\nIHBC resource offers improved consistency.\nNew laws to ‘retain and explain’ historic statues.""]"	['<urn:uuid:751e840e-ed06-40c8-99e9-28b8f0656103>']	open-ended	direct	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-13T03:20:41.944655	27	116	1400
96	Do both styles prefer ground-level or elevated viewing?	French formal gardens are specifically designed to be viewed from elevated positions like terraces, walls, or second-story windows to appreciate their geometric patterns and symmetry. English gardens, however, are meant to be experienced at ground level, with intimate spaces like dooryard gardens and mixed borders that welcome visitors with up-close views of abundant plantings.	['The French formal garden was, and still is, intended to inspire a sense of awe and wonder in the visitor in much the same manner as the façade of a grand, elite chateau would produce in the viewer. Its carefully sculpted and tightly controlled vegetation becomes a form of organic architecture, and its tight, linear control of all plant life emphasizes man’s complete dominance of nature.\nThe French garden is built around a sheer passion for rigid geometry that emerged out of 17th Century discoveries in optics and perspectives. The disciplined symmetry of this form is one of the precise in the world in terms of planning and layout, with carefully trimmed plants and trees that run along long axes that inspire the viewer with a sense of sublime infinity.\nIdeally, French formal gardens work best with French or traditional style houses that are two stories or more in height. This is because the original French gardens were built to be enjoyed from an elevated vantage point such as a terrace, the top of a wall, or a large window that overlooked the countryside.\nSuch a sense of sublime vantage can also be achieved from a home on the Houston landscape, which shares a similarly flat terrain to that of much of French. French are easy to duplicate here because of this, and any balcony, second story window, or even terraced rooftop can become the vantage point from which to enjoy the parterres and axes of the garden.\nHowever, this is not a hard fast rule. The form can be customized to fit the dimensions and perspectives of a single story residence as well. Elevated decks, pergolas, and even kitchen windows can provide superb vantage points over smaller parterres and axis that mimic their larger equivalents.\nThe French formal garden uses the home itself as the garden focal point. Trees are planted in straight lines that run away from the home in order to give it special emphasis. Near the home, the parterres and bushes are trimmed lower to the ground to lend greater emphasis to the house.\nThe central access of the garden is built perpendicular to the house. This normally runs opposite the front entrance and moves either in the direction of a horizon point or a classical statue. This main axis is typically made of gravel and is lined by trees. Perpendicular axes cross the main axes in order to provide aesthetic balance and human transit points.\nThe geometric patterns of the parterres themselves can be square, circular, oval, or scroll-like in shape. They are set against the home in such a manner so as to compliment the architectural motifs that distinguish its build out. These parterres near the house are normally built with low boxwoods that hug the ground. As the linear progression of the French formal garden moves away from the home façade, the hedges rise proportionally. In larger gardens, trees are planted in larger gardens to enhance the sense of heightened perspective and drama.\nWater features are among the most important elements of a French formal garden. It is common for professional landscapers to incorporate canals, basins, custom fountains, and waterfalls that lend not only a touch or elegance, but also create a mirror-like effect that makes the garden appear larger than it actually is.\nIt is also common practice to place classical sculpture is normally placed at the intersections of axes or by water features to contribute to the sense of elegance and order for which the French garden has become world famous.', 'The English Style Garden:\nFor many, an English style garden is the pinnacle ofÂ landscape art. Whether it is due to the reputation of the English people for gardening expertise and design or for the sheer breadth of landscaping features, this is one of the most beloved expressions of the gardener’s craft.\nWhat is the Typical English Garden Style?\nYou might describe it as country parkland surrounding a great estate.Â Or you might think of the intimate and overflowing gardens of a thatched cottage. Surprisingly both of these scenes are typical of one style.\nFor some, “garden rooms”, like those installed in many of the best private British gardens (now public destinations), best represent the ideal.\nManyÂ historical styles may be described as “English”. However, the national flavor is best thought of as a set of characteristic factors that compose a garden “in the English style”.\nCharacteristics of an English Style Garden\nOne of those factors is a feeling of abundance, whether seen in lush grass, stands of carefully chosen tree specimens and combinations, or floriferous borders. The climate is given to a fullness of burgeoning growth, although it takes a lot of work and planning to give the best gardens their seemingly unstudied artistic abundance.\nWilliam Robinson, in advocating a more informal, permanent planting of hardy and native plants called his flower gardens “English”1.\nÂ Thus introducing another identifier of the English style garden: theÂ more naturalisticÂ look with plants that appearÂ at home in their various locations.\nMarina Schinz, in her book ‘Visions of Paradise‘, put it this way:\nThe key to the image of profusion and luxuriance that is the quintessence of the English garden is the extraordinary variety of plants – the flowering shrubs, the herbaceous perennials, the herbs, the annuals, the bulbs, the wild flowers, and the ground covers.\nFeatures of this Look\n- Richly layered planting\n- Full of flowers\n- Many details from weaving Â and vining plants, and containers of flowers\n- Great variety\nEven within Tudor knot gardens you may see a lush flowering vine peeking over a wall.Â Glorious shrubs within a border, or perhaps only an urn that threatens to overflow with its exuberance of planting are not uncommon. These details say “English” to us, rather than Italian or French.\nBut I think it is this great love of flowers, difficult to contain and restrain, which is the soul of English garden style.\nIs It the Landscape Style or the Cottage Style?\nWhen deciding how to arrange plantings and bring the look to our home gardens, which will become our inspiration? The evocative and picturesque look of the “Landscape style”? Or the rustic and intimate feel of Cottage gardens?\nThe Cottage Garden is probably the favorite variation of the English style garden. We areÂ completely enamored with Cottage gardening in the United States. Dripping with roses, overflowing with clematis vines, bunches of daisies, pinks, and spikes of delphiniums is the picture in our mind’s eye.\nThe exuberant planting of Englands cottages isÂ one of the most iconic images of the land. Even if a landscape is not given the full blown treatment of the style, details are borrowed for their inviting look.\nFurther explore the details and features of this form:\nThe ‘Landscape Gardening’ ModeAmericans have borrowed heavily from such famous landscapers as Repton and Capability Brown toÂ createÂ the parkland feel, complete with expanses of greenswards.ground that is covered with green grass, like a lawn\nUsing this style as a base for our own New World spaces, we have also evolved in adapting our gardens to our own native plants and climate regions. Â This developed into what is identified now as “The New American Garden“. It was the necessary evolution forÂ our difference in climate and the modern-day lack of garden laborers.\nWhichever design direction we take, one thing is sure:\nThere will always be a place in our gardens for the English style to be a choice. However it mightÂ be tempered with realistic notions of what time, space, and interest will allow.\nEnglish gardenÂ styleÂ will always require constant attention to a carefully cultivated landscape. That is what makes it so beautiful and intensely personal a style of design.\nThose English Roses\nFurthermore, our entire idea of the perfect rose garden depends heavily on traditional English garden examples. Â Both design and the plantings themselves take on the customary legacy of Gertrude Jekyll’s advice and the plant forms she favored.\nToday, heirlooms and their modern equivalents bring strong, shrubby presence, and fragrant full bloomsÂ into both contemporary and historical flower garden plans.\nDesigning An English Style Garden\nPerennial Borders Are A Famous Feature\nWell KnownÂ British Garden Designers\nOne of the most loved and appreciated components of the English Garden Style was the development of the flower border.\nIts epitome of form was probably embodied in Gertrude Jekyll’s designs, but there are modern day masters of this gardening feature. Many of them have written marvelous books with lessons from their magnificent gardens,\n- Christopher Lloyd –The Well-tempered Garden\n- Rosemary Verey – English Country Gardens\n- Beth Chatto, Graham Stuart Thomas, and more.\nI have to confess that my favorite is Beth Chatto, for her sublime combinations.\nThe English gardeners have written prolifically on the details of what they consider the nuances of their gardens, and of their structure.\nA very important concept is the idea of a skeletal foundation to the garden as a whole, “the bones” of the garden. This is the hardscape and the visually stronger planting of trees, shrubs, and hedges.\nThere are details such as “weaving” in which vining or sprawling plants lead the eye through the plantings and give depth.\nLong range views consisting of “drifts” of plants.Â Planting large enough numbers of the same plant to give the effect of aÂ natural mass of growth. In small spaces this could be five to seven, in large areas, possibly a hundred!\nAll these elements are steps in creating the full and generous delight of the English style of gardening.\nÂ English Style Garden Features\nThe characteristics cover the broadest definition possible, because, in fact, there are many kinds of landscapes and gardens in this style.\nWhat are some of the types you may see?\n- Tudor Knot Gardens\n- Edwardian Perennial Borders\n- Cottage Yards\n- Estate Landscapes\n- Mixed use, mixed borders\n- Kitchen and Cloister (herb) gardens\nPerennial FlowerÂ Color Schemes\nThe English flower border was made up, originally, of mainly perennial flowers. It is quite a feat to accomplish the look of full abundance in threeÂ seasons while adhering to a specific color scheme.\nUsually a perennial border is designed with either pale colors that Jekyll described as “tender”, or some combination of brights.\nIn her book “Colour Schemes for the Flower Garden“, Miss Jekyll described,plans in some detail which used gradations of both types of colors.\nShe also pioneered the idea of mono-colored themes and advocated those for particular seasons of bloom.How To Create A White Garden\nThe difficulty of creating beauty for the entire growing season and the importance of winter interest lead to the evolution of this form to a style incorporating all sorts of plantings, including small trees, shrubs, vines, and annuals along with the perennial plant choices.\nThis method of combining many types of plants is labeled “mixed garden borders”.\nMixed Garden Borders For All Seasons\nMany more modern garden experts suggest “mixed” garden borders inspired by her advice. These are rooted in the English garden style, but American gardeners such as Tracy DiSabato-Aust have developed the idea in inspirational ways.\nThis is the style of border that I have most gravitated towards in my own gardens. It gives the garden its “bones” to have a mix of stronger plants such as shrubs, and extends the seasons range. It also lends itself well to the American “wide open spaces”.\nDooryard gardens are also a feature of English gardening, with an intimate space of plantings that welcome visitors to house entryways. If there are no other areas of flower gardening, a doorway with a vine or containers flanking the steps, or a lacing of flowers along foundation shrubs, all can give the charm of English gardening genius without lots of garden effort that full blown borders would require. It is the luxurious abundance that overflows and greets the eye that marks this style of the gardener’s taste.\nRelated: A Look-Into Garden\nCountry Garden Plants\nTypical English Garden Plants, for American gardens. Country gardens located in rural areas may have very different needs from those in urban settings. It is all a matter of location and local challenges, as well as surrounding view/landscape. The same may be said of plant choices. American climate covers a large range, but very few of those climate characteristicsÂ equate with those of Great Britain.\nThe style may be borrowed, but the suggested perennials and other plantings must be tailored to ones site.\nArticles of Interest on English Gardening …\n- A White Garden\n- Look-Into Garden\n- Sissinghurst Castle\n- Historical Herb Gardens\n- Medieval Gardens\n- A Berkshire yard that recalls poetry, fiction, and drama\n- Perennial flowers\n1ibid. ‘Visions of Paradise‘ by Marina Schinz']	['<urn:uuid:6feede11-aa4a-4380-9844-9b20812f4148>', '<urn:uuid:6739d707-aa8a-464d-b6b4-46efabbb081a>']	factoid	direct	concise-and-natural	distant-from-document	comparison	expert	2025-05-13T03:20:41.944655	8	54	2129
97	australia climate zones temperate tropical desert characteristics	Australia has diverse climate zones with distinct characteristics. The largest portion is desert or semi-arid. The south-east and south-west corners have temperate climates with moderately fertile soil, exemplified by regions like New South Wales and Victoria. The northern part has a tropical climate that varies between grasslands and desert. Using Köppen's classification principles, these zones can be categorized based on temperature and precipitation patterns, with Type B (dry) climates dominating much of the continent, Type A (tropical) in the north, and Type C (temperate) in the coastal regions.	['Most empirical classifications are those that seek to group climates based on one or more aspects of the climate system. While many such phenomena have been used in this way, natural vegetation stands out as one of prime importance. The view held by many climatologists is that natural vegetation functions as a long-term integrator of the climate in a region; the vegetation, in effect, is an instrument for measuring climate in the same way that a thermometer measures temperature. Its preeminence is apparent in the fact that many textbooks and other sources refer to climates using the names of vegetation—for example, rainforest, taiga, and tundra.\nWladimir Köppen, a German botanist-climatologist, developed the most popular (but not the first) of these vegetation-based classifications. His aim was to devise formulas that would define climatic boundaries in such a way as to correspond to those of the vegetation zones that were being mapped for the first time during his lifetime. Köppen published his first scheme in 1900 and a revised version in 1918. He continued to revise his system of classification until his death in 1940. Other climatologists modified portions of Köppen’s procedure on the basis of their experience in various parts of the world.\nKöppen’s classification is based on a subdivision of terrestrial climates into five major types, which are represented by the capital letters A, B, C, D, and E. Each of these climate types except for B is defined by temperature criteria. Type B designates climates in which the controlling factor on vegetation is dryness (rather than coldness). Aridity is not a matter of precipitation alone but is defined by the relationship between the precipitation input to the soil in which the plants grow and the evaporative losses. Since evaporation is difficult to evaluate and is not a conventional measurement at meteorological stations, Köppen was forced to substitute a formula that identifies aridity in terms of a temperature-precipitation index (that is, evaporation is assumed to be controlled by temperature). Dry climates are divided into arid (BW) and semiarid (BS) subtypes, and each may be differentiated further by adding a third code, for warm (h) or cold (k).\nAs noted above, temperature defines the other four major climate types. These are subdivided, with additional letters again used to designate the various subtypes. Type A climates, the warmest, are differentiated on the basis of the seasonality of precipitation: Af (no dry season), Am (short dry season), or Aw (winter dry season). Type E climates, the coldest, are conventionally separated into tundra (ET) and snow/ice climates (EF). The midlatitude C and D climates are given a second letter, f (no dry season) or w (winter dry) or s (summer dry), and a third symbol—a, b, c, or d (the last subclass exists only for D climates)—indicating the warmth of the summer or the coldness of the winter. Although Köppen’s classification did not consider the uniqueness of highland climate regions, the highland climate category, or H climate, is sometimes added to climate classification systems to account for elevations above 1,500 metres (about 4,900 feet).\n|A||temperature of coolest month 18 degrees Celsius or higher|\n|f||precipitation in driest month at least 60 mm|\n|m||precipitation in driest month less than 60 mm but equal to or greater than 100 – (r/25)1|\n|w||precipitation in driest month less than 60 mm and less than 100 – (r/25)|\n|B2||70% or more of annual precipitation falls in the summer half of the year and r less than 20t + 280, or 70% or more of annual precipitation falls in the winter half of the year and r less than 20t, or neither half of the year has 70% or more of annual precipitation and r less than 20t + 1403|\n|W||r is less than one-half of the upper limit for classification as a B type (see above)|\n|S||r is less than the upper limit for classification as a B type but is more than one-half of that amount|\n|h||t equal to or greater than 18 degrees Celsius|\n|k||t less than 18 degrees Celsius|\n|C||temperature of warmest month greater than or equal to 10 degrees Celsius, and temperature of coldest month less than 18 degrees Celsius but greater than –3 degrees Celsius|\n|s||precipitation in driest month of summer half of the year is less than 30 mm and less than one-third of the wettest month of the winter half|\n|w||precipitation in driest month of the winter half of the year less than one-tenth of the amount in the wettest month of the summer half|\n|f||precipitation more evenly distributed throughout year; criteria for neither s nor w satisfied|\n|a||temperature of warmest month 22 degrees Celsius or above|\n|b||temperature of each of four warmest months 10 degrees Celsius or above but warmest month less than 22 degrees Celsius|\n|c||temperature of one to three months 10 degrees Celsius or above but warmest month less than 22 degrees Celsius|\n|D||temperature of warmest month greater than or equal to 10 degrees Celsius, and temperature of coldest month –3 degrees Celsius or lower|\n|s||same as for type C|\n|w||same as for type C|\n|f||same as for type C|\n|a||same as for type C|\n|b||same as for type C|\n|c||same as for type C|\n|d||temperature of coldest month less than –38 degrees Celsius (d designation then used instead of a, b, or c)|\n|E||temperature of warmest month less than 10 degrees Celsius|\n|T||temperature of warmest month greater than 0 degrees Celsius but less than 10 degrees Celsius|\n|F||temperature of warmest month 0 degrees Celsius or below|\n|H4||temperature and precipitation characteristics highly dependent on traits of adjacent zones and overall elevation—highland climates may occur at any latitude|\n|1In the formulas above, r is average annual precipitation total (mm) and t is average annual temperature (degrees Celsius). All other temperatures are monthly means (degrees Celsius), and all other precipitation amounts are mean monthly totals (mm).\n2Any climate that satisfies the criteria for designation as a B type is classified as such, irrespective of its other characteristics.\n3The summer half of the year is defined as the months April–September for the Northern Hemisphere and October–March for the Southern Hemisphere.\n4Most modern climate schemes consider the role of altitude. The highland zone has been taken from Trewartha (1968).\nThe Köppen classification has been criticized on many grounds. It has been argued that extreme events, such as a periodic drought or an unusual cold spell, are just as significant in controlling vegetation distributions as the mean conditions upon which Köppen’s scheme is based. It also has been pointed out that factors other than those used in the classification, such as sunshine and wind, are important to vegetation. Moreover, it has been contended that natural vegetation can respond only slowly to environmental change, so that the vegetation zones observable today are in part adjusted to past climates. Many critics have drawn attention to the rather poor correspondence between the Köppen zones and the observed vegetation distribution in many areas of the world. In spite of these and other limitations, the Köppen system remains the most popular climatic classification in use today.\nA major contribution to climate grouping was made by the American geographer-climatologist C. Warren Thornthwaite in 1931 and 1948. He first used a vegetation-based approach that made use of the derived concepts of temperature efficiency and precipitation effectiveness as a means of specifying atmospheric effects on vegetation. His second classification retained these concepts in the form of a moisture index and a thermal efficiency index but radically changed the classification criteria and rejected the idea of using vegetation as the climatic integrator, attempting instead to classify “rationally” on the basis of the numerical values of these indices. His 1948 scheme is encountered in many climatology texts, but it has not gained as large a following among a wide audience as the Köppen classification system has, perhaps because of its complexity and the large number of climatic regions it defines.\nWhile vegetation-based climate classifications could be regarded as having relevance to human activity through what they may indicate about agricultural potential and natural environment, they cannot give any sense of how human beings would feel within the various climate types. Terjung’s 1966 scheme was an attempt to group climates on the basis of their effects on human comfort. The classification makes use of four physiologically relevant parameters: temperature, relative humidity, wind speed, and solar radiation. The first two are combined in a comfort index to express atmospheric conditions in terms perceived as extremely hot, hot, oppressive, warm, comfortable, cool, keen, cold, very cold, extremely cold, and ultra cold. Temperature, wind speed, and solar radiation are combined in a wind effect index expressing the net effect of wind chill (the cooling power of wind on exposed surfaces) and addition of heat to the human body by solar radiation. These indices are combined for different seasons in different ways to express how humans feel in various geographic areas on a yearly basis. Terjung visualized that his classification would find applicability in medical geography, climatological education, tourism, housing, and clothing and as a general analytical tool.\nMany other specialized empirical classifications have been devised. For example, there are those that differentiate between types of desert and coastal climates, those that account for different rates of rock weathering or soil formation, and those based on the identification of similar agricultural climates.', 'The largest part of Australia is desert or semi-arid. Only the south-east and south-west corners have a temperate climate and moderately fertile soil. The northern part of the country has a tropical climate, varying between grasslands and desert.\nWhat are the main climates in Australia?\nThere are six distinct climate groups; Equitorial, Tropical, Sub-tropical, Desert, Grassland and Temperate. The Temperate zone occupies the coastal regions of New South Wales (Sydney), Victoria (Great Ocean Road, East Gippsland, Phillip Island), Tasmania and most of South Australia (Kangaroo Island, Eyre Peninsula).\nWhat are the 3 main climate zones in Australia?\n- Hot humid – hot dry.\n- Warm – mild temperate.\n- Cool temperate – alpine.\nWhat are the main climate types?\none of five classifications of the Earth’s climates: tropical, dry, mild, continental, and polar.\nWhat are the 6 types of climates?\nThere are six main climate regions: tropical rainy, dry, temperate marine, temperate continental, polar, and highlands. The tropics have two types of rainy climates: tropical wet and tropical wet-and- dry.\nWhat is Australia’s climate and weather like?\nThe northern section of Australia has a more tropical influenced climate, hot and humid in the summer, and quite warm and dry in the winter, while the southern parts are cooler with mild summers and cool, sometimes rainy winters. … December and January are the hottest months in Australia, July and August the coldest.\nWhat type of climate is Melbourne?\nMelbourne, the state capital of Victoria and second largest city in Australia, has a temperate oceanic climate (Köppen climate classification Cfb) and is well known for its changeable weather conditions.\nWhat are the 8 climate types?\n- Winter dry (temperate climate)\n- Winter dry (continental climate)\n- Summer dry (continental climate)\n- Continuously wet (continental climate)\n- Polar ice caps (polar climate)\nWhat is a zone 7 climate?\nClimate Zone 7 is the southernmost coastal region of California. The warm ocean water and latitude make this climate very mild. The temperature of the ocean water affects the air temperature over it, and this in turn moderates temperatures over the coastal strip.\nWhat is Type B climate?\nType B designates climates in which the controlling factor on vegetation is dryness (rather than coldness). … Dry climates are divided into arid (BW) and semiarid (BS) subtypes, and each may be differentiated further by adding a third code, h for warm and k for cold.\nWhat are the three ways climates are classified?\nOverview. The Köppen climate classification scheme divides climates into five main climate groups: A (tropical), B (dry), C (temperate), D (continental), and E (polar). The second letter indicates the seasonal precipitation type, while the third letter indicates the level of heat.\nWhat are the 6 types of climates for kids?\nThere are five general types of climate: tropical, subtropical, temperate, polar, and highland.\nWhat is climate and its types?\nIn simple terms climate is the average condition for about thirty years. Climate and weather are different. Weather is the day to day conditions in the atmosphere. The types of climates are: Tropical, Desert/dry, Temperate, Polar, Mediterranean. … Tropical climates have warm temperature and only two seasons; wet and dry.\nWhat are the different kinds of weather?\nThere are five types of weather: sunny, cloudy, windy, rainy, and stormy.\nWhat are the 4 different climate zones?\nThere are 4 major climate zones:\n- Tropical zone from 0°–23.5°(between the tropics) …\n- Subtropics from 23.5°–40° …\n- Temperate zone from 40°–60° …\n- Cold zone from 60°–90°']	['<urn:uuid:0456738b-0f08-4307-b4d7-031d0aa357b6>', '<urn:uuid:6bae122c-952b-4452-800a-496d01140b6d>']	open-ended	with-premise	short-search-query	similar-to-document	three-doc	expert	2025-05-13T03:20:41.944655	7	88	2134
98	floating exchange rate system start date	The floating exchange rate system has been followed since March 1973 and was formally recognized by the Jamaica accord of 1978.	['Under this system, the external value of all currencies was denominated in terms of gold with central banks ready to buy and sell unlimited quantities of gold at the fixed price.This was the method employed by the Chinese government to maintain a currency peg or tightly banded float against the US dollar.\nIf you are going to sell base currency of the rate it is necessary for you to.In a reserve currency system, the currency of another country performs the functions that gold has in a gold standard.\nIn 1963, the Thai government established the Exchange Equalization Fund (EEF) with the purpose of playing a role in stabilizing exchange rate movements.Definition: Exchange rates are the amount of one currency you. The U.S. dollar has weakened because it can buy fewer yuan.Indicates the forecasted price movements for each of the eight currencies in the Currency Ranking service due to expected medium-term rate fluctuations.Exchange rates tell you how much your currency is worth in another currency.In the retail currency exchange market, different buying and selling rates will be quoted by money dealers.For example, a country that exhibits complete symmetry of shocks but has zero market integration could benefit from fixing a currency.Check our currency exchange rates. for British pounds at the sell rate. Buy. complaints about money transmission or currency exchange products and.As such, when the reference value rises or falls, it then follows that the value(s) of any currencies pegged to it will also rise and fall in relation to other currencies and commodities with which the pegged currency can be traded.\nThe supply of foreign exchange is similarly derived from the foreign demand for goods, services, and financial assets coming from the home country.What spread (buy vs sell exchange rate difference, %) can be typically expected in cash currency exchange booths in Belgrad airport, Terminal 2.\nAnother, less used means of maintaining a fixed exchange rate is by simply making it illegal to trade currency at any other rate.This is a situation where the foreign demand for goods, services, and financial assets from the European Union exceeds the European demand for foreign goods, services, and financial assets.This causes the price of the currency to decrease in value (Read: Classical Demand-Supply diagrams).Shock symmetry can be characterized as two countries having similar demand shocks due to similar industry breakdowns and economies, while market integration is a factor of the volume of trading that occurs between member nations of the peg.\nThe Balance of Payments, Exchange Rates,. a government must be willing to buy and sell currency in the foreign.This makes trade and investments between the two currency areas easier and more predictable, and is especially useful for small economies, economies which borrow primarily in foreign currency, and in which external trade forms a large part of their GDP.A market position where a trader has bought a currency she previously did not own.\nThe Balance of Payments, Exchange Rates, and TradeThe reserves they sell may be the currency it is pegged to, in which case the value of that currency will fall.CFDs, MT4 hedging capabilities and leverage ratios exceeding 50:1 are not available to US residents.Extrapolates the behavior of an element (such as volatility) from a certain time period to a full year.Trading Models follow and act upon the price quotes originating from these banks and financial institutions.\nAn exchange rate is the amount of a currency that one needs in order to buy.The earliest establishment of a gold standard was in the United Kingdom in 1821 followed by Australia in 1852 and Canada in 1853.Advise us of the currencies that you wish to sell, and buy (We will let you have the very best exchange rate at.Before now, while speaking about quotes, we intentionally used only Forex current (spot) exchange rates for simplification of understanding.Please inquire at your local bank or travel agency, or consult available travel guides for more information on specific commissions and special charges which may be charged for converting currencies.HSBC is recognised as one of the leading market makers and liquidity providers in foreign exchange (FX) derivatives. exchange rate on a specific. sell foreign.\nThe buying rate is the exchange rate at which a trader would buy a foreign currency.Typical time horizons presented by OANDA for its financial services are.Any deal which has not been settled by physical payment or reversed by an equal and opposite deal for the same date.\nUsing [email protected], you can buy the Travel Card or Foreign Currency at the click of a button and get it delivered at...What links here Related changes Upload file Special pages Permanent link Page information Wikidata item Cite this page.It fails to identify the degree of comparative advantage or disadvantage of the nation and may lead to inefficient allocation of resources throughout the world.\nAnnuities | Investor.gov\nTT Selling Rate: This rate is applied for all clean remittances outside India.Fixed exchange-rates are not permitted to fluctuate freely or respond to daily changes in demand and supply.Since March 1973, the floating exchange rate has been followed and formally recognized by the Jamaica accord of 1978.Under a floating exchange rate system, equilibrium would have been achieved at e.Moreover, a government, when having a fixed rather than dynamic exchange rate, cannot use monetary or fiscal policies with a free hand.\nFixed Exchange Rates and Foreign Exchange InterventionUnderstanding The Spread in Retail Currency Exchange Rates. the price at which a dealer will buy a currency and the price at which the dealer will sell a.\nFor example, a composite currency may be created consisting of 100 Indian rupees, 100 Japanese yen and one Singapore dollar.This diagram underscores the two main factors that drive a country to contemplate pegging a currency to another, shock symmetry and market integration.The exchange rate is used when simply converting one currency to.']	['<urn:uuid:507ebc1d-ee7c-41bc-bb81-97492cc3b890>']	factoid	direct	short-search-query	distant-from-document	single-doc	expert	2025-05-13T03:20:41.944655	6	21	966
99	chemical manufacture production setup compare cost effectiveness yield optimization methods	Industrial chemical production processes like the Haber process and Contact process demonstrate key methods for optimizing yield and cost-effectiveness. Both processes use moderate temperatures around 450°C as a compromise between reaction rate and equilibrium yield. However, they differ in pressure requirements - the Haber process uses high pressure (200-250 atm) while the Contact process uses low pressure (1-2 atm) since extra pressure isn't cost-effective. Both processes employ catalysts (iron for Haber, vanadium for Contact) to increase reaction rates while maintaining lower temperatures. Product removal is used in both cases to drive equilibrium toward products. The processes also manage reactant concentrations - the Haber process uses excess nitrogen (the cheaper reactant) to ensure complete consumption of hydrogen, while the Contact process uses excess oxygen to drive the equilibrium forward. These parameters are carefully balanced to maximize production efficiency while minimizing costs.	"['During 1885, a Gallic chemist by the name of Henri Louis Le Chatelier created a regulation for usage to foretell what effects occur in a reaction system when the reaction is at equilibrium. It stated that ; if a dynamic equilibrium is disturbed by altering the conditions, so the place of equilibrium moves to antagonize that alteration ( Clark, 2002 ) . This is straight applied to a broad scope of chemical reactions today, specifically industrial chemical science reactions, where the most efficient agencies of production must be used to understate disbursals. By utilizing this rule, industrial chemists are able to supply a changeless status for reactions that yield the highest possible sum of merchandises, while maintaining the cost to a lower limit. Throughout this article, equilibrium as a whole, both physical and chemical alterations, will be researched and applied utilizing the Haber procedure.\nThe Haber procedure is used to synthesize ammonium hydroxide by uniting both Nitrogen gas and Hydrogen gas. The Haber procedure straight links to Le Chatelier ‘s Principle via the demand to bring forth an efficient and cost effectual system for industrial manufacturers by agencies of temperature, force per unit area, and accelerators to change the equilibrium ( Clark, 2002 ) . The Haber procedure combines Nitrogen gas, extracted from the air, with Hydrogen gas normally obtained via Methane. The chemical equation for this system is shown below.\nThe above system produces heat as a merchandise, hence the system is considered to be exothermal, intending that as Ammonia is produced, so at the same time heat is given off as a byproduct. By mentioning to Le Chatelier ‘s Principle, it is shown that the heat produced by this system would drive the reaction backwards and hence off from the merchandises, and synthesising less Ammonia. Although this is a ruin, this heat alteration besides causes a faster rate of reaction through the system which is desirable to industrial chemists.\nIndustrial chemists that use the Haber procedure for the production of ammonium hydroxide are invariably seeking for ways to go economically efficient. That is to diminish the production clip and maximise net income. This is all done through the usage of Le Chatelier ‘s rule. One method by increasing the reaction clip is through the usage of a accelerator. An Fe based accelerator is the most normally used substance in the Haber procedure. This Fe based accelerator is really utile from economical and equilibrium points of position as the accelerator is non consumed by the reaction nor does it change the equilibrium invariable ( K ) , it merely speeds up the reactions of the system.\nBecause equal volumes of equal gases at the same temperature occupy the same infinite, harmonizing to Avogadro ‘s Law, it can be assumed that force per unit area will impact the equilibrium of a system incorporating merely gases, such as the Haber procedure ( Clark, 2002 ) . By utilizing the mole ratios of the Reactants in the Haber procedure, it can be deduced that the ratio of Hydrogen gas to Nitrogen gas is 1:3. This means that for every mole of Nitrogen gas there are three molecules of Hydrogen gas. This information is besides valuable to industrial chemists as it allows them to guarantee that the more expensive of the two reactants, in this instance Hydrogen gas, is wholly consumed by adding extra Nitrogen gas, the less expensive of the two reactants, into the system.\nIn order for industrial chemists to use Le Chatelier ‘s rule to the Haber procedure, they can alter, increase or diminish, one or more of three variables ; temperature, force per unit area, or concentration.\nIn order to change the equilibrium through the usage of a temperature alteration, an industrial chemist must happen the most efficient place, so that all of the reactants are consumed and bring forth Ammonia. Too much heat and the system will favor the contrary reaction, nevertheless excessively small heat and the rate of reaction wo n’t be high plenty. It is because of this, that a scope of 400-450A°C is used as a medium in order to maximize the sum of synthesised Ammonia through the system.\nIn order to change the equilibrium through the usage of a force per unit area alteration, there must be gases present in the system, which is fortunate for the Haber procedure, doing this method really valuable to industrial chemists. Le Chatelier ‘s rule provinces that if overall force per unit area is increased on a system, so the equilibrium will switch to favor the production of fewer molecules ( Clark, 2002 ) . The Haber procedure contains four molecules of reactants ( 1 Nitrogen gas and 3 Hydrogen gas ) and merely 2 molecules of the merchandise ( 2 Ammonia ) . This means that if the overall force per unit area on the system is increased, so the equilibrium will switch to favor the synthesis of merchandises. This force per unit area will besides do the rate of reaction to increase as the molecules are pushed closer together, leting for an easier reaction. This means that the higher the force per unit area that can be achieved, the better. However, in order to be more economically efficient every bit good as have the highest reaction rate as possible, the force per unit area of the system is recommended to be set at 200 ambiances ( Clark, 2002 ) . This via media force per unit area is the most economic for industrial chemists as higher force per unit areas require significantly more expensive pipes and vass in order to get by with higher force per unit areas and lower force per unit areas cut down the reaction rate.\nBelow is an illustration showing the affects that the above equalising method/s have when applied to the Haber procedure at the set temperature of 400EsC.\nIf the concentration of N gas is 3mol/L and the concentration of H gas is 4mol/L, the K value being, so the concentration of ammonium hydroxide would be:\nThis shows that 2.38 % of ammonium hydroxide is synthesised in the above system. In order to increase the per centum output of the same system, the pressure/concentration can be increased. Because the set force per unit area to be used on the Haber procedure is 200, we will alternatively look at the effects that altering the concentration of one of the species involved in the system has.\nThe concentration of N in the system is increased to 6.2mol/L, hence the Q value is calculated utilizing the stairss below.\nBecause the Q value of the system is smaller than the abovementioned K value, so the equilibrium will be driven towards the merchandises, in this instance the synthesis of ammonium hydroxide, and therefore bring forthing a larger output.\nThe information to this point has outlined the causes and effects that the emphasiss of Le Chatelier ‘s Principle have upon the Haber procedure. It is because of these effects that industrial chemists find it critical to equilibrium equations such as this. It allows them to foretell how the system can be made most efficient and in the most economic method, and besides allows them to repair possible jobs within the system or the environment environing it.\nComplication in the Manufacturing Procedure\nOne of the complications that industrial chemists may confront during the executing of the Haber procedure is the failure of a thermoregulator or temperature regulation system. This is an issue when it comes to efficiency of the system as this failure can do an addition or lessening in temperature and hence changing from the efficient set temperature of 400EsC. If a rise in temperature were to happen, so the reaction would be driven towards the production of the reactants, in this instance H and N gases, because the system will absorb the extra heat in order to modulate the temperature. If the temperature of the system were to diminish, so the reaction rate would diminish dramatically besides, nevertheless the theoretical output of the merchandises, in this instance ammonium hydroxide, would be high. The simplest method to reconstruct the system back to an efficient equilibrium would be to alter the temperature back to 400EsC, nevertheless, if there is harm to the temperature ordinance system/thermostat so this can non be achieved. The following advised method of reconstructing equilibrium is to change the concentration of N gas. Theoretically, increasing the sum of N within the system should drive the reaction towards the synthesis of merchandises. Proof of this is shown below.\nBecause the equilibrium invariable is unknown, it must foremost be calculated. The old sums of species in the system were noted prior to the break caused to the system and are shown in the tabular array below.\nTable 1.1 – An ICE tabular array demoing the concentrations of the species involved prior to the break\nIn order to one time once more increase the output of the system, the equilibrium invariable, or K value, must foremost be calculated.\nBecause the ideal per centum of ammonium hydroxide produced is 15 % , the per centum output of the system after failure is calculated.\nBecause the per centum output is merely 0.451 % , it can be seen that the sum of ammonium hydroxide produced has decreased as the temperature of the system increased. However, in order to decide this issue, a reaction quotient must be calculated. The industrial chemist will take for a reaction quotient, or Q value that obtains a suited output of 15 % ammonium hydroxide.\n2.4478 mol/L extra N2 is added to the system\nBecause the Q value is less than the K value, it proves that increasing the concentration of Nitrogen gas will drive the reaction towards the synthesis of merchandises, in this instance ammonium hydroxide. Further increasing the sum of N gas will besides increase the sum of ammonium hydroxide produced, nevertheless besides the force per unit area, which in this instance can non be done due to the 200 ambiances bound of the containment vas. Please note that this is merely a impermanent solution to the thermoregulator job. Once the thermoregulator is fixed, the temperature can be restored to 400EsC and the ideal output of 15 % re-established with more easiness.\nThe theoretical concentration of N gas required to make the ideal output, of 15 % ammonium hydroxide, can besides be calculated.\nBecause 0.0478mol/L is equal to 0.451 % output of ammonium hydroxide, the concentration of ammonium hydroxide at 15 % output is\nTherefore, in order to detect the concentration of N gas required, replace\ninto the below equation.\nBecause N and H are both gases, they are in proportion with each other and therefore the concentrations of each can be replaced with\nThis means that in order to drive the reaction frontward plenty, in this system, to make a output of 15 % ammonium hydroxide, the entire sum of N gas would necessitate to be about 32.5mol/L. nevertheless, because of the 200 ambiances bound of the containment vas, raising the output to this degree would be really impractical. It is for that ground that the concentration of N gas would be increased by a significantly lesser sum to that, and would merely be a impermanent hole to the thermostat issue.\nAlthough the intent has changed, the production of ammonium hydroxide is still executed to this day of the month through the Haber procedure. Le Chatelier ‘s rule enables industrial chemists to change the temperature, concentration and force per unit area, leting them to change the rate of reaction and the output of a coveted merchandise and, as shown above, can besides be used to happen impermanent holes to issues in the environment environing the system. The equilibrium invariable ( K ) and reaction quotient ( Q ) can be compared to each other, leting industrial chemists to find whether or non a alteration in the system will favor the synthesis of merchandises or reactants. Because of the broad assortment of industrial chemists using the Haber procedure, in the hereafter it will be improved so that the force per unit area bound of the containment vas additions and hence the full system can be made even more efficient and cost effectual.\nClark, J. , 2002. Le Chatelier ‘s Principle. [ Online ]\nAvailable at: hypertext transfer protocol: //www.chemguide.co.uk/physical/equilibria/lechatelier.html\n[ Accessed 24 Fabruary 2013 ] .\nClark, J. , 2002. The Haber Process. [ Online ]\nAvailable at: hypertext transfer protocol: //www.chemguide.co.uk/physical/equilibria/haber.html\n[ Accessed 26 February 2013 ] .\nDeb Smith, S. M. M. G. R. S. , 2006. Chemistry In Use Book 2. s.l. : McGraw-Hill Australia.\nMombourquette, M. , 2012. Chapter 12: Chemical Equilibrium. [ Online ]\nAvailable at: hypertext transfer protocol: //www.chem.queensu.ca/people/faculty/mombourquette/firstyrchem/equilibrium/\n[ Accessed 7 March 2013 ] .\nWallace, R. , King, J. & A ; Sanders, G. , 1983. In: Biosphere: The Realm of Life. New York: Oxford Uni Press, pp. 523-536.', ""2 Characteristics of Equilibrium Closed system – nothing in, nothing outForward and reverse reactions are occurring at the same rate – known as ‘dynamic equilibrium’Macroscopic properties (e.g. Colour, concentration, pH) remain constantChanges in temp, pressure, volume and concentration can change the equilibrium position. Catalysts do not.\n3 Equilibrium Graph - Concentration A BThis reaction starts with A only, with the [A] (concentration of A) at a maximum at Time = 0 s.As the reaction proceeds, A gets used up and [B] steadily increases until equilibrium is reached which can be seen as no change in either concentration.In this graph, [B] > [A] which means the forward reaction is more favoured than the reverse.What would the graph look like if the reverse was favoured?\n4 Equilibrium Graph – Rate of Reaction A BThis reaction starts with A only, so the rate of the forward reaction is at a maximum and slows down as [A] decreasesAs the reaction proceeds and [B] steadily increases, the rate of the reverse reaction increases until equilibrium is reached when the rates of the forward and reverse reactions are equal.\n5 Equilibrium constant - Kc productsreactantsIndices are from the coefficients in the balanced chemical equation\n6 Equilibrium constant - Kc Units for Kc will vary depending upon the reaction. In fact, there may be no units.The value of Kc for a particular reaction is only affected by changes in temperatureIn a homogeneous reaction, all of the states of matter are the sameIn a heterogeneous reaction, there are different states of matter. Solids do not take part in the equilibrium constant\n7 Equilibrium constant - Kc When Kc >> 1 When Kc << 1Equil goes far right (forward rxn almost to completion) Equil goes far left (forward rxn hardly proceeds)What happens when Kc = 1? Kc = 0?\n8 Le Chatelier’s Principle “An equilibrium system that is exposed to a stress will shift the equilibrium position to oppose that stress”Note: a stress can be a change in temperature, pressure, volume or concentration. Catalysts do not affect equilibrium; they simply affect the rate of the forward and reverse reactions.\n9 Le Chatelier’s Principle – Concentration Consider the following reaction:A + B C + DAdding a reactant:This will stress the systemTo relieve the stress, the system can produce more productsEquilibrium shifts rightAdding a product:This will stress the systemTo relieve the stress, the system can produce more reactantsEquilibrium shifts leftRemoving a chemical substance is a stress that is relieved by producing more of that substance, shifting the equilibrium towards that direction. For example, removing a product will shift the equilibrium towards the right, making more products.What happens if you remove some reactant or product?\n10 Le Chatelier’s Principle – Temperature (exothermic) Consider the following exothermic reaction:A + B C + D + heatIncreasing the temperature:This is like adding a productTo relieve the stress, the system can reduce the heat by producing more reactantsEquilibrium shifts leftDecreasing the temperature:This is like removing a productTo relieve the stress, the system can produce more productsEquilibrium shifts right\n11 Le Chatelier’s Principle – Temperature (endothermic) Consider the following endothermic reaction:heat + A + B C + DIncreasing the temperature:This is like adding a reactantTo relieve the stress, the system can reduce the heat by producing more productsEquilibrium shifts rightDecreasing the temperature:This is like removing a reactantTo relieve the stress, the system can produce more reactantsEquilibrium shifts left\n12 Le Chatelier’s Principle – Pressure Consider the following reaction:Assume all species are gases2A + B C + DNotice that there are 3 moles of gas on the left and 2 moles on the rightIncreasing the pressure:This means there is less room for the particlesTo relieve the stress, the system can reduce the pressure by producing less moles of gasEquilibrium shifts rightDecreasing the pressure:This means there is more space for particlesTo relieve the stress, the system can increase the pressure by producing more moles of gasEquilibrium shifts leftIncreasing the volume is the same as decreasing the pressure and decreasing the volume is the same as increasing the pressureWhat happens if you increase or decrease the volume? How does this relate to pressure?\n13 Le Chatelier’s Principle – Catalysts Consider the following reaction:A + B C + DAdding a catalystThis will not affect the equilibrium position or KcCatalysts reduce the activation energyThis speeds up the forward and reverse reactions equallyEquilibrium is reached fasterSource of graph:\n14 Production of Ammonia – The Haber process In 1912, German scientist, Fritz Haber developed a process for manufacturing ammonia from nitrogen and hydrogen.N2 (g) + 3H2 (g) 2NH3 (g) + 92kJSource:Notice that this reaction is reversible which can establish equilibrium. This means that Le Chatelier’s Principle applies to the chemistry of this process.Also, note that the forward reaction is exothermic\n15 Ammonia and Le Chatelier N2 (g) + 3H2 (g) 2NH3 (g) + 92kJUsing your knowledge of Le Chatelier’s Principle, describe what the optimum conditions (in terms of yield and rate) for this reaction will be in relation to the following:TemperaturePressureUse of a catalyst\n16 Optimum ammonia production RateYieldCostSource: Chemistry Contexts 2, 2006\n17 Conditions for Haber Process Pressure - high(250 atm) – to shift equilibrium right and increase rateTemperature – moderate (4500C) – low favours equilibrium, high favours rate. This temperature is a trade-offCatalyst – use of an iron catalyst helps to increase the rate and overcome the relatively low temperature required.Removal of ammonia – shifts the equilibrium towards the products.\n18 Production of Sulfuric Acid – The Contact Process Sulfuric acid is made in 3 steps:Diagram source:Steps to make sulfuric acidSulfur dioxide is madeSulfur trioxide is made from sulfur dioxideSulfuric acid is made from sulfur trioxide\n19 Contact Process Chemistry Step 1:Sulfur is roasted in oxygen to produce sulfur dioxideS(s) + O2(g) SO2(g)Step 2:Sulfur dioxide is reacted with oxygen using a Vanadium catalyst to produce sulfur trioxide in a reversible exothermic reactionSO2(g) + O2(g) SO3(g) + heatStep 3:Sulfur trioxide is converted to sulfuric acid through a series of reactionsSource of animation:\n20 Contact Process conditions Using Le Chatelier's principle, the equilibrium yield of sulfur trioxide (step 2) should increase when: - temperatures are low, since the reaction is exothermic; - pressure is high; - excess reactants are present.However the rate of the reaction is high when: - temperature is high, hence an obvious conflict exists with the equilibrium yield; - the pressure is high; - a catalyst is used.Predict the conditions that would be used in this process. Justify your answer\n21 Contact Process conditions Pressure - low(1-2 atm) – the process already favours the foward reaction. The extra pressure is not cost effectiveTemperature – moderate (4500C) – low favours equilibrium, high favours rate. This temperature is a trade-off same as HaberCatalyst – use of an vanadium catalyst helps to increase the rate and overcome the relatively low temperature required.Excess oxygen– shifts the equilibrium towards the products.""]"	['<urn:uuid:03a71070-d4dc-45ca-bbd3-927ea2c6147f>', '<urn:uuid:fbf9a4d8-1665-4b2e-9ca6-0b907cc9a975>']	open-ended	with-premise	long-search-query	distant-from-document	three-doc	expert	2025-05-13T03:20:41.944655	10	140	3289
100	Working in university research commercialization, I'd like to understand how Texas A&M balances academic and commercial interests in its international partnerships. How does their approach compare to other institutions' handling of commercialization and student-athlete rights?	Texas A&M approaches commercialization as a means to accomplish core academic goals of groundbreaking research and global impact, rather than just licensing technologies. Through OWIN, they connect researchers to international communities and match research initiatives with foreign investment sources. This balanced approach contrasts with broader tensions in university commercialization, as seen in cases like the NCAA's struggles with student-athlete likeness rights. While some leaders like Nebraska's Perlman argue for limiting commercialization to maintain educational focus, others push for more business-oriented models. The key is finding ways to advance both academic and commercial interests while maintaining institutional integrity.	['OWIN is always looking to connect with new partners and build high-value strategic collaborations to expand the network and help companies develop. Today, the network is present in Belgium, the US, China and Australia.\nWallonia in Belgium, Texas in the United States of America, Beijing in China and the state of Queensland in Australia are four regions that have great capabilities to stimulate the creation of innovation and help new technologies access markets faster.\nThe business of working internationally is nothing new for the Texas A&M University System; however, advancing that international view to commercialization opportunities is a new development model pioneered with AWEX. Successful programs require the right partners and we couldn’t have hand-picked better partners for OWIN than AWEX and Coway.\nBrett Cornwell – Executive Director, Texas A&M Technology Commercialization\nAWEX – The Walloon Exports & Foreign Investments Agency – is a government agency responsible for stimulating economic activity in the Wallonia region. As such, it maintains close international trade relationships with most major markets around the world. AWEX can serve as the vital partner for companies to establish their presence in the Walloon region of Belgium in order to access the entirety of the European Union.\nAWEX has a worldwide network of 105 Economic and Trade Commissioners and has been ISO 9001 certified since 2002. As a foreign trade agency, AWEX carries out a mission of promotion and information, benefiting both Wallonia and the foreign business community.\nAWEX partners with you on your project, working closely with European, Belgian, regional and local authorities. It will help you plan for any global move, taking charge of your basic and real estate needs (researching properties and land), financial and fiscal interests (financial and fiscal optimization), talent recruitment and continued training and development, and even your legal interests.\nUpon request, AWEX assists buyers, decision-makers, importers and foreign prospects by providing services, including:\n- Providing information on Wallonia, its companies’ products and services and exporters\n- Identifying companies in Wallonia for international partnerships\n- Assisting in the exporting process (information on foreign markets, market studies, planning of marketing activities, establishing contact, financial support, trainings in international career, etc.)\n- Help foreign investors by providing grants and adapted solutions, facilitating relations with public and private players, helping in the set-up process, explaining the regional business location policy and legal regulations\n- Provide information and advice to foreign companies looking to establish, expand or reorganize their European operations and who would consider Wallonia as their ideal strategic location\nWhy Wallonia ?\nBelgium is world renowned for beers, chocolate, comic books, diamonds… but not only!\nWith a population of about 3.5 million inhabitants, Wallonia, the Southern, French-speaking half of Belgium, truly is the heart of Europe, at the crossroads of the most advanced region of Western Europe. It has 9 major universities, 6 science parks, 300 research centers, one of the most business friendly tax policies of the world and more than 2% of the GDP is invested in R&D.\nRenowned for its coal and steel, Wallonia has experienced strong industrial growth since the Middle Ages. For many years, heavy industry was the driving force behind the region’s economy. Indeed, Wallonia was the birthplace of the industrial revolution on continental Europe.\nToday, the economic landscape has diversified considerably, and the main economic activities in the region are now centered on the industrial basins and the university centers. A region that naturally cultivates an international outlook, Wallonia takes pride in its know-how, quality products, modern communication and telecommunication infrastructures and its wealth of natural resources that have earned it its reputation. The export volumes are booming in all economic sectors and make the region one of the biggest per capita exporters in the world. Over the years, Wallonia has also proven to be a haven for international companies. The companies that opt to invest in Wallonia stand to benefit from these recognized skills and from a highly professional workforce whose productivity is 20% higher than the European average.\nHence, the Government of Wallonia labeled 6 poles:\n- Skywin (Aeronautics and Space Industry)\n- Biowin (Health)\n- WagrALIM (Agro-industry)\n- Logistics in Wallonia (Transport and Logistics)\n- MecaTech (Mechanical Engineering)\n- Greenwin (Environment and Sustainable Development)\nAWEX is a founder of OWIN and is a member since 2013.\n→ For more information on AWEX, visit its website: www.investinwallonia.be\nThe Texas A&M Technology Commercialization (TTC) is Industry’s Connection to the A&M System. For more than 20 years, TTC has been building bridges between academic research and business. It provides the link between the laboratories where innovative new technologies are being developed and industry partners that will bring them to fruition as a product.\nThe mission of Texas A&M Technology Commercialization (TTC) goes beyond simply licensing technologies developed by Texas A&M University faculty. We see commercialization as a means rather than an end unto itself. Ultimately, it’s a path to accomplishing two of the A&M System’s core goals: to do ground breaking research, impact education, and to make a significant contribution to the world we live in.\nThe TTC protects the new innovations, developed by A&M System researchers, through patents and copyrights and seeks to transfer the intellectual property to industry by royalty-bearing license agreements for commercial products that result in economic development and public benefit.\nThe TTC interacts with hundreds of companies each year as it seeks to find commercial partners to commercialize A&M System innovations. As a result, more than 1000+ license agreements have been executed since the TTC was established in 1992.\nWe look forward to working with you in commercializing new A&M system technologies.\nMatchmaking Made Easy: The Open Worldwide Innovation Network\nSince 2006, Texas A&M, The Walloon Exports & Foreign Investments Agency (AWEX), and the Research Valley Partnership (RVP) – which grows, expands and attracts business to the Brazos Valley – have worked together to create a best-practices model for developing international economic relationships. Through OWIN, we have connected Aggie researches to comminities abroad that can benefit from their discoveries. We have also matched A&M research initiatives with domestic and foreign sources of private investment to help fund them.\nThanks to OWIN, TTC is taking Aggie discoveries where they have most needed, to the farthest corners of the globe (including Europe and China). We are commercializing Texas A&M inventions in markets abroad and introducing Texas A&M University to entirely new groups of stakeholders. These potential private – and public – sector partners are excited about how the best and brightest minds at Texas A&M can benefit their local constituencies. They are sending research dollars back to Aggieland to fund new research initiatives. As you can see, TTC is expanding the Aggie family to include new partners who, like us, believe the pursuit of the public good is a noble endeavor.\nThe A&M System has been very lucky to find a partner like AWEX that sees the mutual local economic benefits of thinking internationally for commercialization opportunities from our respective universities.\nBrett Cornwell – Executive Director, Texas A&M Technology Commercialization\nThe TTC is a founder of OWIN and is a member since 2013.\n→ For more information on the TTC, visit its website: http://techtransfer.tamu.edu/\nCoway, established in 2002 by Tsinghua University – a top university and the premier engineering university in China – is a State-level technology transfer center recognized by the government and a supporting unit of international technology cooperation. As such they have close partnerships with Tsinghua University’s researchers and the Chinese government and can serve as your vital interface with Chinese industry and the government to ensure success in this dynamic country.\nCoway has years of experience in technology transfer and commercialization in China. With its broad, global network and extensive recourses, Coway devotes itselves to delivering professional services, including technology transfer, patent licensing, consulting, co-investment & technology incubation as well as public service. Coway is entrusted by Tsinghua University to commercialize Tsinghua University’s scientific and technological achievements, to carry out technology commercialization and technology management of International Technology Transfer Center (ITTC) of Tsinghua University.\nThe business scope includes project assessment, technical and economic analysis, technical assets management, technical agent and trade, regulations and product consulting, seek domestic and international partners, international exchange and training etc. More specifically, Coway is dedicated to technology commercialization and multinational technology transfer through providing the following services:\n- Technology promotion and technology transfer for both Chinese enterprises seeking desired technologies or suitable partners in foreign countries and foreign enterprises seeking technologies or partners in China through technology scouting and technology trade etc.\n- Technology consulting including market investigation, market analysis, partner matching, resource allocation, law and regulation consultancy etc.\n- GHG reduction project development consulting solutions for Chinese enterprises to save energy and conduct carbon credits transaction.\n- Technology incubation support to create start-up companies based on the technologies or products with great prospects identified and evaluated by ITTC.\nThe company is committed to providing customers with a full range of professional service based on the spirit of innovation and integrity.\nCoway is a founder of OWIN and is a member since 2013.\n→ For more information on Coway, visit its website: http://www.coway.com.cn/\nTrade & Investment Queensland is the Queensland Government’s global business agency, assisting exporters to break into emerging and established markets, and promoting Queensland as the perfect place for an Asia-Pacific headquarters.\nAcross the globe, you’ll find Trade & Investment Queensland’s representatives in 13 locations, and across the state, you’ll find Trade and Investment Advisers in major regional centers.\nQueensland is ideally positioned at the international crossroad of the Asia-Pacific. This gives proximity to the growth markets of the world, as well as strong advantages as an investment destination.\nThe dynamic and stable economy, highly skilled workforce, reduced government regulation and tax policies that encourage growth offer businesses the best climate to expand and prosper.\nQueensland is also the driving force behind export growth in Australia, with total merchandise exports accounting for about one fifth of the nation’s total.\nThe Queensland Government is a member since 2016.\n→ For more information on Queensland Government, visit its website: https://www.qld.gov.au/\n→ For more information on TIQ, visit its website: http://www.tiq.qld.gov.au/\nResearch Valley Partnership\nLocated in the center of the global mega region that is the Texas Triangle, Research Valley Partnership (RVP) serves as the catalyst of economic development in the Bryan and College Station region. The RVP works tirelessly uniting community, university and industry to facilitate innovation and rapid go-to-market strategies. RVP promotes strong business through prioritizing innovation, fostering a friendly environment, and building upon the foundation of Texas A&M’s global expertise in engineering, agriculture, animal health, energy and the biosciences.\nThe Research Valley Partnership operates the Research Valley International Gateway (RVIG), which helps businesses to rapidly and inexpensively enter the U.S. marketplace. The RVIG offers professional services and a premier executive office suite to early-stage established companies and has become the preferred soft landing zone for international companies wishing, in a first stage, to explore and capitalize on U.S. marketplace opportunities.\nThe RVP specializes in:\n- Efficient and effective economic development services for our community\n- Growing, expanding, and locating businesses in the Research Valley\n- A gateway connecting business with community and university\n- Focusing on innovative solutions and operating at the speed of business\n- “Going to market”\nHelping companies from Texas to expand in Europe and China, and offering Belgian and Chinese companies a gateway to the USA is really what we call a win win partnership!\nTodd McDaniel – President & CEO, The Research Valley Partnership Inc. © SPW\nRVP is an associate member of OWIN since 2013.\n→ For more information on RVP, visit its website: http://researchvalley.org/\nMadison County is a thriving research and innovation community with world-class capabilities in many areas including aerospace and biotechnology. Propulsion systems for the Apollo program and the Space Shuttle were conceived here, and now Madison County is poised to support efforts to explore Mars. The focus on space has given birth to many centers of excellence in fields such as propulsion, optics, and supply chain management for high tech projects, big data, solar winds, meteorology, satellites, and rotorcraft.\nThe University of Alabama in Huntsville is a highly ranked research university that anchors Cummings Research Park, the second largest park in the U.S. (fourth largest in the world).\nNotable agencies and companies established in Huntsville are:\n- NASA Marshall Space Center\n- U. S. Army Missile Command\n- U. S. Army Materials Command\n- Boeing Research (Headquarters)\n- Hudson Alpha center for Genomic Biotechnology\n- Lockheed Martin\n- Northrop Gunman\n- Teledyne Brown\n- A world-class ecosystem of some 400 small and mid-sized companies covering all areas defense, space related technologies, high-endmanufacturing, and commercial high- tech innovation.\nThe University of Alabama in Huntsville\nU.S. News & World Report rates The University of Alabama in Huntsville (UAH) as a Tier 1 institution while the Carnegie Foundation ranks UAH a “very high” research activity institution, on par with the Massachusetts Institute of Technology (MIT) or Stanford University.\nUAH is comprised of 7 colleges and 16 independent research centers, including diverse areas of expertise such as:\n- The only hypervelocity testing facility on a university campus.\n- Advanced Rotorcraft research center working on the future of vertical lift, safety, modeling, simulation, and cockpit design as well as drones (http://www.uah.edu/rsesc/capabilities).\n- Propulsion center that works closely with NASA’s local propulsion center (Apollo, Space Shuttle, and now mission to Mars).\n- Applied optics center supporting the International Space Station and the James Webb Telescope.\n- World leader in Satellite based Atmospheric research (developed the only system that actually predicts lightning).\n- World leader in solar winds and plasma research.\n- World leader in Supply Chain Management for High-Tech projects.\n- A very mature “Big Data” research facility through extensive collaboration with NASA.\n- Interdisciplinary Biotechnology research with Hudson Alpha (top 4 genomic research lab) that will likely lead to collaboration with NASA requirements.\nPerhaps unique to most universities, the University of Alabama in Huntsville is primarily funded through its extensive contract support to Department of Defense, NASA, and various other industries.\nWBI – Wallonie-Bruxelles International\nWallonia-Brussels International (WBI) is the agency in charge of the international relations of Wallonia-Brussels. WBI aims to foster contacts and to build partnerships between research and innovation actors of Wallonia-Brussels and other countries.\nWBI main activities are:\n- connect scientists, researchers, entrepreneurs with inspiring partners of excellence;\n- facilitate academic programs, global innovation strategies and knowledge exchange;\n- support internationalization efforts of Wallonia- Brussels academic institutions and companies, with a special focus on innovative start-ups and spin-offs;\n- inform on developments in science, technology and innovation policies.\nWBI creates and builds up international science, technology and innovation networks in an open innovation approach :\n- academia : the universities and higher education institutions, the funding agency for fundamental\n- business : the clusters and competitiveness clusters, the association of science parks of Wallonia\n(SPoW), the association of 22 applied research centers of Wallonia (WalTech), the National Contact Point for Horizon2020 (NCP-Wallonie)\n- public bodies : Innovation Agency (AST), Ministry of Research (DGO6), the Walloon Trade & Investment Agency (AWEX)\nWBI operates through a network of Diplomatic representations (Wallonia-Brussels Delegations) and Scientific Liaison Officers. We also work in close cooperation with the AWEX’s network of 108 Trade Commissioners based abroad.', 'There is a reason that reaching discovery is a major landmark in any legal case. At the start of a lawsuit, a plaintiff has only a theory of recovery. What appears in a complaint or pleading are just allegations. Discovery starts the process of testing that theory and finding out how many of those allegations are based in evidence. That applies especially to litigation that is not designed to recover damages for a single plaintiff, but to change how an institution operates going forward.\nUnsealed Documents Will Change Public Perception\nAs documents are unsealed in the lawsuit between former student-athletes and the NCAA and EA Sports over licensing of video game rights, aside from simply backing up or refuting allegations, will shape the public’s perception of the case. Suffice to say, the plaintiffs have already won such a critical battle that it means little if they ultimately lose the case.\nFirst, a quick word about dropping the term “student-athlete”. At this point, student-athlete is pretty loaded, either because of its history harkening back to defending athletic scholarships and preventing college athletes from being defined as employees or because of cases where it seems the moniker does not really fit (“athlete-student”). But it is also a term-of-art in NCAA regulation that has a very good connection with the term’s definition. They are students, as opposed to athletes who are not college students. And they are athletes, as opposed to college students who are not athletes.\nCalling them students requires the NCAA to redefine the word “student” for the purposes of NCAA regulations. So if the term student-athlete is considered offensive or outdated, it still needs to be replaced. And that replacement is likely to be very similar or it will not make sense. So it doesn’t matter if they are called student-athletes, college athletes, or something jargony like “full-time enrolled college students participating on teams” that NCAA members end up always calling FECSPOTs (“fec-spots”). What matters is the set of rights and responsibilities that attach to a person when he or she gets that moniker.\nThe NCAA Struggles to Deal with the Commercialism, Amteurism, and Student-athlete Likenesses\nThe other headline of the piece is that despite a strong and vocal legal defense, NCAA leaders—both on campus and at the national office—struggled with how to deal with commercialism, amateurism, and student-athlete likenesses. The implication is that because one specific definition of amateurism is not accepted as the gospel truth throughout the NCAA and its members, the whole notion of any limit is suspect.\nBut the fact that this battle is being fought both at the largest and most powerful athletic departments in the country as well as in the highest levels of the national office is great news. The NCAA should be wrestling with these issues constantly. Voices of dissent should be allowed, even if their ideas ultimately never make it into the Division I Manual. All of these questions are difficult and require balancing different interests. Unanimous rubber-stamping of the party line would be terrifying.\nEven more encouraging to NCAA reformers should be that someone as high up within the NCAA as Wally Renfro is trying to tackle the issue of how to separate amateurism from education so the two can be regulated (or not regulated) separately. The NCAA, always the middle ground and always the voice of compromise, has at least one person looking for a way to give both sides of the college athletics debate what they want. Success may be impossible, but knowing that will do much for pushing college athletics forward.\nPearlman Wants to Turn the Clock Back\nThis brings us back to Nebraska chancellor Harvey Perlman. Perlman was almost universally criticized for suggesting (threatening?) to roll the clock back rather than move forward with college football’s postseason. Perlman was the chief voice pushing back against more games, seeded playoffs, and selection committees. Perlman went so far as to suggest that even the BCS would be shuttered and college football would return to contractually determined postseason match-ups followed by voting on a national champion.\nThat seems consistent with Perlman’s objection to the NCAA getting involved in the licensing of student-athlete likenesses. It is a step too far, according to Perlman, from the educational mission of college to be selling the likeness of student-athletes. Note that Perlman is not objecting just to commercialization without compensating athletes, but excessive commercialization of college athletics itself.\nSo can a president who moved his school to a new conference with a more lucrative TV deal justify this stance? Absolutely. Televising games helps Nebraska’s academic mission by marketing the university, increasing applications, and helping with funding. Selling jerseys or getting extra money from video game licensing because the players look like the real thing does not. Feel free to debate how well Nebraska lives up to these ideals, but they are at least intellectually consistent.\nPerlman’s comments are contrasted against those of Texas director of women’s athletics Chris Plonsky. Plonsky’s comments are less about the individual issues and more about the underlying attitude. The NCAA in 2012 sits on the fence between being more or less a government agency and being a private organization. On the one hand, the NCAA and its members are subsidized in the form of tax-exempt status, receive both federal and state funding that support athletics, and carry out what is in many countries a government function.\nOn the other hand, the NCAA is a private, voluntary membership association. They have the Supreme Court case that says they are not an arm of the government. For a long time, the NCAA has enjoyed the benefits of both, and Plonsky’s comments reflect a desire to continue this hybrid model, referencing the need to raise funds (private) vs. the return athletes should get in the form of an education (public/government).\nThat balancing act is becoming increasingly untenable. At some point in the not-too-distant future, the NCAA and its members will be forced to choose a side, fall one way or the other, and embrace the challenges and difficulties that come with it. That could mean turning college athletics into a for-profit enterprise only loosely connected to academics. Or it could mean doubling down on protections for athletes and solving the hard questions of how to refocus on education rather than competition.\nPerlman and Renfro appear to fall on the side of being like a government entity, even as Renfro searches for a way to reconcile elements of professional athletics with that model. The plaintiffs in the video game cases fall clearly on the side of being a private business. The news is not that the plaintiffs are more likely to have the NCAA land on their side. Rather, the takeaway should be that the NCAA is a little more wobbly on the fence, but far better prepared to handle the fall than suspected.\nYou need to do your research if you want get recruited and earn a sports scholarship.\nMy high school coach is going to contact some colleges to help get me recruited. Should I do anything myself or just rely on my coach?\nHow long does it take to get recruited ? When should I start contacting college coaches?\nFirst contact with the college coach, what should I ask?\nTransferring to another college, What are the regulations?']	['<urn:uuid:6e6de160-a5a7-4e1b-adce-921471534405>', '<urn:uuid:79cefd03-1183-400b-9299-48b5b0b02624>']	open-ended	with-premise	verbose-and-natural	similar-to-document	three-doc	expert	2025-05-13T03:20:41.944655	35	97	3764
