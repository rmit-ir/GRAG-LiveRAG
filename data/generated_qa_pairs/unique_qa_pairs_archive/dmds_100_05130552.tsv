qid	question	answer	context	document_ids	question_factuality	question_premise	question_phrasing	question_linguistic_variation	question_multi-doc	user_expertise-categorization	generation_timestamp	question_length	answer_length	context_length
1	I've heard about different types of SL6 intake manifolds - which ones are actually suitable for adding fuel injection injectors?	The newer Clifford SL6 intakes are suitable as they have 'bosses' already cast into the ends of each runner - these just need the correct sized o-ring hole machined (.540). Cast Iron or Aluminum manifolds with .18 or greater wall thickness are also good options. However, the Die-Cast 2 piece & 'E-Beam Welded' SL6 intakes have really thin walls and are not good choices for this modification.	"['Lets review our options to setup an SL6 intake manifold for EFI injectors. As many people know, there are a number of different intake manifolds available for the SL6 and this boss mounting process will work for all of them. Please note that the newer Clifford SL6 intakes have ""bosses"" already cast into the ends of each runner. If you have one of these you can simply machine the correct sized o-ring hole (.540) right into the manifold and skip the separate boss ""insets"" installation process as outlined here. Also note that the Die-Cast 2 piece & ""E-Beam Welded"" SL6 intakes have really thin walls so these are not a good choice for this modification. This insert process will work for manifolds made in Cast Iron or Aluminum with .18 or greater wall thickness.\nIn general we want to get the injectors mounted into the SL6 manifold and then create a fuel rail to ""feed"" them. I will list a number of options for building the manifold and fuel rail(s) but will spend the most time on a ""low dollar, do-it-yourself"" procedure using junkyard parts. Another way to get this done is to simply send your manifold out to an FI shop and have them set it up for you. See www.rancefi.com or www.force-efi.com for more info and pricing. There are many web sites on Fuel Injection so take a look but expect to spend $500 to $1000 to have manifold and fuel rail(s) made by a shop. Complete EFI systems can run $2000 to $3000 and these will include all new parts (not used wrecking yard stuff!).\nI have outlined a way to get injector bosses into a common Cast Iron SL6 1 BBL intake. The ""missing link"" part that I ended up making myself were the screw-in bosses. I did this because the ones I found were either ""weld-in"" (3/4"" OD ""Tubes"", 1.5 inches long) or expensive ""screw-in"" type, with a ¾"" -16 UNF thread (www.emi.cc/home.htm or www.msdignition.com, listed under instructions - fuel management). What I did was modify a plumbing supply ½"" NPT OD x 1/8"" NPT ID x 1"" long ""adapter bushing"", machined into ""screw-in bosses"" ( ½"" NPT OD) and a stepped, smooth-wall ID, .437 through & a .540 to .550 (14mm) counter-bore (~ 9/16""). (**See Sketch**) Another good option for raw boss material is a ½"" ""flair plug"". These are a bit longer (1 ¼"") and made of brass. The bosses are installed into 45º angled tapped holes and sealed by using ""liquid steel"" type epoxy.\nThe tools I used to do this work\nincluded a ½"" chuck drill motor, a 3/8"", 14mm ""burr"" & .700\ndiameter drill bits, a ½"" NPT tap, a tape measure, center punch\nand other common hand tools. I started by marking the positions of\neach hole to be drilled. Use the center manifold mounting flange hole\nas your ""zero point"" and work out to both ends marking at 1"", 5"" and\n9"" inch points (4"" spacing). Locate your pilot hole right where the\nmounting flange tab slope goes completely flat onto the top surface\nof the manifold. Drill a 3/8"" pilot hole straight down. This is done\nto give the bigger drill bit a ""path"" to follow. I also drilled\nstraight down with the larger drill, then slanted the holes buy\npulling the drill sideways after it was through. In order to help me\nget the correct angle and be consistent hole to hole, I made-up a\nwooden block with a 45º angle cut on the end to act as a visual\nguide. Use a small carpenters square to keep the holes\nperpendicular to the front mounting surface. Re-check the\n""squareness"" as you tap out the holes. Doing this will maintain the\n4"" spacing between the installed injectors. Note that the middle two\ninjectors are spaced two inches apart, the rest are on the 4""\n(O -4""- O -4""- O -2""- O -4""- O -4""- O)\nThe actual ""bosses"" (bungs) are modified ""off the shelf"" plumbing fittings that cost about $1.30 each. It is best to do the re-machining on a tool room lathe but to be honest, this can also be done by hand with a drill motor. The first step is to open up the through hole to either 7/16"" or ½"" inch size. It is best to drill in from both ends in order to keep the hole ""centered"". I was able to find a ""rotary file"" (die grinding ""burr"") at the needed 14 mm size, so I used this to generate the slightly larger counter-bore (.545 diameter x .550 deep on a 1"" long bushing). Using this tool to make the counter bore took a little longer but left a really nice surface finish. I used a 45º countersink to put a ""lead-in"" at the entrance to the counter-bore and ""blended-in"" all the sharp edges to reduce the chance of a cut or nicked o-ring.\nThe next step was to ""fit-check"" the bosses into the manifold. I ground a small dip into the manifolds top runner surface to allow clearance for the bushings hex. The goal is to screw the 1"" long bushing in as far as possible. (The 1 ¼"" long ""flair plug"" is less of a problem here but it has a less common 7/8""-14 UNF thread size to contend with.) Once the bushings are installed as intended, mark the part of the bushing sticking down into the runner passage with dye or paint, then number each bushing to keep track of where they go. This is a good time to install some injectors and to measure the spacing and the height between them all. If you are using smooth sided bosses to be epoxied in, it is best to make up your fuel rail before doing the gluing in the bosses so the rail can hold and position all the bosses during the gluing step. This is your last chance to adjust the boss position(s) so doing this final fit check and making any adjustment(s) now will save you a lot of time later. Once everything is in the correct position, remove the ""bosses"" and grind off all that excess material you saw hanging into the runner passageways. Doing this saves a lot of ""inside the port"" grinding work after gluing.\nMake sure everything is clean and dry, and we are ready to glue! Mix the epoxy and apply it generously to both the boss and the threaded manifold hole, then screw the boss in tight. I worked quickly to get all the bosses installed first, then went back to wipe up all the extra epoxy. I left a ""fillet"" of epoxy under the hex of each boss to ensure a good seal. The same basic process can be done for screw-in or smooth sided bosses but use the fuel rail as a holding fixture if you are using smooth sided type. Once the epoxy is cured, you should finish grind the inside of the runner to remove any excess epoxy or protruding boss material. Congratulations, you now have a Fuel Injection Manifold for your Slant Six! My total ""out of pocket"" expense was $11.33 (bushings and some epoxy). Now lets make-up a fuel rail for it.\nTo be Continued...']"	['<urn:uuid:3d1da2f0-4bf0-43e6-9728-94914fa07b65>']	open-ended	with-premise	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-13T05:52:58.810667	20	67	1209
2	What keeps cities powered, and what can make it fail?	Cities are powered through the National Grid network, which consists of high-voltage power lines, gas pipelines, interconnectors and storage facilities that enable electricity distribution. Power stations can be located in remote areas, keeping pollution away from cities while still supplying them through the grid. However, this system can fail due to multiple threats: severe weather events can cause serious disruption and damage to the network, pandemics can affect the ability of maintenance staff to perform their duties, hazardous materials incidents can lead to infrastructure closure, and cyber-attacks can disrupt the operating systems and associated information technology infrastructure.	['How does the national grid work? The National Grid network is made of high-voltage power lines, gas pipelines, interconnectors and storage facilities that together enable the distribution of electricity. In addition to the costs of replacing and renewing aging assets to keep the National Grid up to date.\nHow is electricity stored in the National Grid? As of 2020, the largest form of grid energy storage is dammed hydroelectricity, with both conventional hydroelectric generation as well as pumped storage hydroelectricity. Two alternatives to grid storage are the use of peaking power plants to fill in supply gaps and demand response to shift load to other times.\nHow do National Grid make money? Distribution companies\nThese companies own the distribution network that connects households to the Power Grid. Distribution companies charge suppliers for using the network. Suppliers then pass this cost on to consumers through the standing charge on your energy bills.\nWhat is National Grid state its advantages? What are the benefits of the National Grid? The benefits of the grid are: Power stations can be based in less populous and remote areas of the country meaning pollution can be kept away from major cities. If one power station needs maintenance, consumers can still be supplied from others around the country.\nHow does the national grid work? – Related Questions\nWhat is the electricity grid and how does it work?\nThe electricity grid is a complex machine in which electricity is generated at centralized power plants and decentralized units and is transported through a system of substations, transformers and transmission lines that deliver the product to its end-user, the consumer.\nWhat happens to excess electricity in the grid?\nToo much electricity, low demand\nIf too much electricity is fed into the grid in relation to the quantity consumed, the electrical frequency increases. Since power plants are designed to operate within a certain frequency range, there is a risk that they will disconnect from the grid after a period of time. .\nHow is excess electricity stored?\nStorage systems for electricity include battery, flywheel, compressed air, and pumped hydro storage. Any systems are limited in the total amount of energy they can store. Pumped storage involves pumping water uphill to a reservoir from which it can be released on demand to generate hydroelectricity.\nWhat is National Grid called now?\nOn , National Grid Company was renamed National Grid Electricity Transmission plc, and on , Transco was renamed National Grid Gas plc.\nDoes National Grid own power stations?\nThe National Grid is Britain’s transmission system for electricity. In order to get from power stations to homes and businesses around the country, energy passes through the grid’s pylons and cables. It owns and maintains the high-voltage electricity transmission network in England and Wales.\nWhy would National Grid come to my house?\nNational Grid impersonators try to enter customer homes by asking to see their bills and/or meters, and may steal goods or demand money for their services.\nWhat are the disadvantages of the National Grid?\nA disadvantage of the National Grid is that power is wasted heating the power lines. A transformer changes the size of an alternating voltage. Transformers will not work with a constant voltage. One of the reasons we have an a.c. mains supply is that the voltage is alternating and can be changed using transformers.\nWhy do you want to work for National Grid?\nWhether you’re fresh out of university or a seasoned professional, a career at National Grid means a place at the forefront of technological evolution. It means thrilling potential, and access to industry-leading training and development. Because, as National Grid advances, our people will move forward too.\nWhat are three factors that can threaten the electric grid?\nIn this article, we are going to dive into the variety of threats that could affect a power grid such as conventional weapons, natural disasters, cyber attacks, grid failures, EMP attacks and even solar flares.\nWhy do we require grid for transmission of electricity?\nFlexibility: The electricity grid allows a power system to use a diversity of resources, even if they are located far away from where the power is needed. For example, wind turbines must be built where the wind is the strongest; the grid allows for this electricity to be transmitted to distant cities.\nWhat happens if the US power grid goes down?\nIf the power grid goes down, water and natural gas will fail soon thereafter, so planning is critical. As of 2021, the average age of the power grid is 31 years old. Power outages are over 2.5 times more likely than they were in 1984.\nWhere does electricity go if not used?\nThe power that they transfer gets dissipated as heat (wasted), light (e.g. display), kinetic energy (e.g. speaker), and so forth. Electricity doesn’t get used, instead energy is transferred using electrons. It is the energy that you are using.\nCan I disconnect from the electricity grid?\nA household can be disconnected from the grid at home, but those consumers will still use the grid when they drive down lit streets, go to work and school, shop and eat out. Being connected to and using the grid is not only okay – it’s essential.\nWhat happens when a large load is suddenly disconnected from the power grid?\nFor a really big power requirement, say a generating station suddenly goes offline, then the interconnect can drop out, leading to cascading blackouts. Eventually the engine or turbine controllers will detect the fall in speed, and increase fuel or water flow to match the output power required.\nWhy is storing electricity so hard?\nA general answer which is not of any particular use is that electrical energy, and the forms in which we store it, are typically very low entropy systems. The lower the entropy the more they “want” to dissipate and the harder it is to stop that tendency to turn into (ultimately) heat.\nWhy is storing energy so hard?\nWhy Is Solar Energy Storage So Difficult? Unlike fossil fuels and other energy sources, solar energy production is less predictable. Thus, we have had to devise systems for storing the energy that is produced during peak sunlight hours, so that we may access it later when the sun has gone down.\nWhat is the most efficient energy storage?\nPumped-storage hydropower (PSH) is by far the most popular form of energy storage in the United States, where it accounts for 95 percent of utility-scale energy storage.\nWhat type of energy is stored for later use in the body?\nEnergy is actually stored in your liver and muscle cells and readily available as glycogen. We know this as carbohydrate energy. When carbohydrate energy is needed, glycogen is converted into glucose for use by the muscle cells.\nWhat is electricity called when it is stored in one location?\nElectricity is a type of energy that can build up in one place or flow from one place to another. When electricity gathers in one place it is known as static electricity (the word static means something that does not move); electricity that moves from one place to another is called current electricity.\nHow much power is lost in the National Grid?\nCitizens Advice suggests that about 1.7% of the electricity transferred over the transmission network is lost, and a further 5-8% is lost over the distribution networks2. This is because transporting electricity via a lower current and high voltage causes lower network losses.\nHow much does it cost to connect to grid?\nDeep-connection costs vary, depending on the type of mini-grid and type of connection. Deep-connection costs can vary from hundreds of dollars (for a low-voltage DC connection to a pico-grid) to more than $1,000 (for a utility-grade connection to an AC mini-grid).', 'Security threats can be divided into those which:\n- have the capability to cause damage or disruption to the construction, operation or maintenance of the highway infrastructure (the physical infrastructure)\n- could damage or disrupt the infrastructure operating systems and associated information (the ITS infrastructure).\nThreats can also be unintentional, non-directed or unpredicted – for example:\n- severe weather events\n- incidents involving hazardous materials\n- road traffic collisions\n- fall-out from disruption to other transport modes\n- the jamming or interference with navigation signals caused by natural factors\n- malware infection on an IT system.\nThe potential level of impact will depend on the criticality of the asset, system or information affected. An example is shown in the photo below.\nDamage or disruption to the construction, operation or maintenance of the road infrastructure may arise from a number of threats.\nCivil protests and strikes\nCivil protests and strikes are most likely to arise from social unrest and civil disobedience. Sometimes this is in response to the construction of assets that are sensitive for environmental, social, economic or political reasons. They have the potential to disrupt or delay operations and can be expensive to manage – and expensive in relation to the final cost of the work being undertaken.\nA malicious attack can occur through a range of external and internal/insider threats. These include damage caused by malware, hackers, disaffected personnel or blast. The result of an attack – in relation to the construction, operation and maintenance of the road network – is likely to centre on physical damage/sabotage to the infrastructure, plant or equipment, or disruption to road users.\nSevere weather events\nSevere and adverse weather – such as periods of rain, flooding, hard frost, snow, prolonged dry weather, excess heat, high winds, dust storms and earthquakes can cause serious disruption and dangerous driving conditions – as well as considerable damage to the network, in particular:\n- the pavement surface condition and structural strength\n- the stability of surrounding and underlying ground and earthworks\n- sensors embedded within the network.\n- The risks of adverse weather can be mitigated to a degree by the installation of road sensor and weather stations at locations that have a high level of exposure. (See.Weather Monitoring)\nPandemics can affect humans, agricultural livestock and wildlife. They can impact on:\n- a population’s capability to travel and to access needed facilities\n- the willingness and ability of staff and external resources – such as contractors and maintenance staff – to enter an area to undertake work.\nTheft of equipment\nDepending on the type of equipment, theft can impact directly on traffic operations and on the ability of an authority, and the cost to it, of constructing, maintaining and improving transport infrastructure. It can also have a direct influence on road user safety – and the capability of an authority to manage traffic behaviour and enhance a network’s capacity.\nHazardous materials (solids, liquids and gases that can be flammable, corrosive or toxic) are frequently transported by road. They are also used within highway construction and management – and may be stored, processed, or used adjacent (or in close proximity) to the road network. An incident involving hazardous materials can lead to closure of the highway – or damage to it and its supporting systems.\nRoad traffic collisions can cause damage to:\n- pavement surface condition\n- structures such as bridges\n- infrastructure such as gantry signs and traffic management equipment\n- sensors embedded within the network.\n- Incidents can also lead to prolonged closure of the highway and have significant social and economic costs. (See Incident Response Plans)\nFall-out from disruption to other modes (rail, ports, airports)\nDisruption to other modes of transport can have a significant effect on road traffic. It can force users to make alternative travel arrangements or – where this is not possible or cost effective (for example, in the case of transportation of freight) – to wait until the disruption has been resolved. Contingency plans may be necessary for parking vehicles that are held up by disruption.\nGlobal Navigation Satellite Systems (GNSS)\nThe jamming of, or interference with, navigation signals may be caused by human factors, such as intentional or malicious acts/attack, or natural factors such as solar flares and disturbance to the ionosphere. It can result in the loss of precision location information, failure of in-vehicle navigation systems and/or loss of accurate timing signals for area-wide systems.\nDamage or disruption to the ITS infrastructure, operating systems and associated information may arise from:\n- similar threats to those facing the physical infrastructure – although with different impacts\n- and from threats directly associated with digital technology\nA malicious attack can occur through a range of external and internal/insider threats. For example, damage may be caused by malware, hackers or disaffected personnel. Physical damage may be caused to:\n- IT equipment and sensors within the highway boundary\n- communications infrastructure or processing systems located outside the highway boundary (such as control centres, data centres, etc.)\n- logical damage to system software, operating systems and stored data or information\n- road users\n- These attacks can lead to loss of communications or network connectivity – and the corruption or loss of information and traffic disruption.\nTheft of equipment\nTheft of IT equipment, sensors or cables within the highway boundary can lead to loss of functionality or system resilience. It can also impact on the ability of the infrastructure system to perform as efficiently as it would otherwise. Repair and replacement can be disruptive and problematic.\nCyber-threats can arise in several ways including:\n- eCrime – such as the interference with road charging or toll systems, can lead to loss, or corruption, of data on charging, revenue or usage\n- loss of communications and power supplies – which can be accidental or due to deliberate damage to cables and/or distribution system components within the highway boundary or supplying systems outside. The impact will be reduced performance of the infrastructure\n- loss or corruption of software systems – which can impact on the system’s availability or integrity, leading to loss of functionality and/or loss or corruption of data.']	['<urn:uuid:ef46af30-d9ea-4665-b9da-aac05cff4a68>', '<urn:uuid:b6075b45-b67f-4917-a717-ece1d197fa91>']	open-ended	direct	concise-and-natural	distant-from-document	multi-aspect	novice	2025-05-13T05:52:58.810667	10	97	2316
3	peruvian ceviche eating customs tradition	Ceviche, Peru's famous dish of raw fish marinated in lime juice with chili and onions, is traditionally only eaten at lunchtime by true Peruvians, not for dinner as tourists often mistakenly do. The dish is typically served alongside corn or boiled sweet potatoes.	"['Peru travel guide\nThe name \'Peru\' conjures up images of jagged mountain peaks circled by rare condors, the mysterious Nazca lines, sacred Lake Titicaca and its Aymara-inhabited floating islands, and one of the continent\'s biggest draws: Machu Picchu and the Inca Trail. It\'s easy to view a Peru holiday as a voyage into the lost Inca kingdom of the Andes, whose modern inhabitants - the Quechua - are living descendants of its pre-colonial past.\nThis epic nation is a South American microcosm, complete with all its most sacred and seductive riches.\nBut don\'t underestimate Peru\'s diversity. Over half of the country is blanketed by the Amazon, hosting some extraordinary species-rich environments, and its coastline is a 2,500km desert, with the highest sand dunes on earth. Its cuisine is influenced as much by its coastline as by its native potatoes and quinoa, and its cities are an energetic mix of the modern and the ancient, with Spanish architecture perched on top of Inca stonework, and glass-fronted buildings overlooking colonial plazas. Read on in our Peru travel guide.\nmuch more than just the Inca Trail. There are deserts, beaches and jungles...\nfor anyone who feels queasy at the sound of panpipes\nWhat we rate & what we don\'t\nFake Peruvian culture\nThe “poor man’s Galapagos”\nOur Peru Holidays\nFood, shopping & people\nEating & drinking in Peru\nTry a tangy Pisco Sour, made with Pisco, lemon juice and egg white.\nQuinoa is a tasty, protein-packed grain. The staple, sacred food of the Incas, it is native to the Andes.\nCeviche is Peru\'s most famous dish. Fresh, raw fish is marinated in lime juice and spiced with chilli and onions. Don\'t make the Gringo mistake of having it for dinner - true Peruvians only eat this at lunchtime.\nCuy is a Peruvian staple that may be less appetising to visitors - it\'s guinea pig. And it\'s usually served whole.\nPeople & language\nIf you knock on a Quechua door, you may hear ""Haykuykuy!"" - Come in!\nPeruvian culture varies by altitude. The highlands are the stronghold of the Quechua - descendents of the Inca - while the lowland forests have many smaller native groups. Peru\'s official languages are Spanish, Quechua and Aymara, but at least a dozen more languages are spoken in the Amazon.\nYou\'ll see the word ""Inti"" a lot. It means \'sun\' or \'Sun God\' in Quechua.\nLateness is a national trait - to try and encourage punctuality, emphasise the ""hora inglesa"" - \'English time\'!\nThe great Inca Empire was actually a mere blip on the continent\'s 5000-year cultural history - their rule lasted barely a century.\nIf you\'d like to chat about Peru or need help finding a holiday to suit you we\'re very happy to help.\nGifts & shopping\nAlpaca wool hats, jumpers, scarves, ponchos and blankets are ubiquitous in Peru. Knitted items here are high quality and wonderfully warm, but you get what you pay for - a ""bargain"" may well be fake.\nColourful textiles handwoven on traditional backstrap looms capture the vibrant spirit of Peru\'s indigenous people. Try and buy direct from craft cooperatives. Cheaper items on markets will be mass-produced, and possibly imported.\nPeru\'s jewellers use intricate filigree techniques, weaving and soldering thin gold and silver threads to create beautifully detailed earrings, bracelets and necklaces.\nThe humble potato originated in Peru - hence the local expression of national pride: \'I\'m more Peruvian than the potato!\'\nHow much does it cost?\nStandard train journey from Machu Pichcu to Cuzco: £55\nA whole, roasted guinea pig: £10.50\nCeviche in a restaurant: £5-£12\nLarge bottle of Cuzqueña beer: £1.40\nReal alpaca shawl or jumper: From £40\nMore about Peru\nFrom Cuzco and the Andes, to the Amazon and the coast, Peru has one of the most varied climates on earth. We help you choose the best time to go to Peru...\nOur Peru map and highlights will help you make the most of your holiday, whether you’re seeking classic highlights, an Inca trek or combining Andes and Amazon...\nIf you\'re hoping to rediscover Machu Picchu, explore the Amazon or get off the beaten track then read on for our top things to do in Peru...\nOur guide to Machu Picchu reveals the history of this sacred site, with tips on what to see, how to travel there and the best time to visit...\nPeru\'s Inca Trail is one of the highlights of a South America holiday. Discover the history of the trail, the best time to go and a sample itinerary...\nThere are several alternative Inca trails that lead to Machu Picchu, taking in cloud and rainforest, high passes and indigenous villages...\nWe explain why, when you cross the border at Lake Titicaca and see Bolivia and Peru together, you gain more than just an extra stamp in your passport...\nCommunity homestays, brightly woven handicrafts and spectacular island hikes are Lake Titicaca’s calling cards.\nThe Nazca Lines in Peru remain one of the country’s great mysteries. Find out about the lines’ history, and how to view them from land and from the air...\nTravelling in Peru with kids is a fabulous idea. Machu Picchu will delight children as much as parents, while long-lashed llamas are sure to enchant...\nOur Peru travel tips page is packed to the rafters with sound, practical advice from our South America experts as well as our independent traveller reviews...\nPorters\' rights are one of the most important Peru responsible tourism issues. We also share information on volunteering, homestays and the environment...\nFind all of our Peru guides in one place, for particular places in Peru such as Machu Picchu. Or perhaps you would like to know more about the different types of Peru holidays we offer such as culture or trekking the Inca Trail.', 'Peru boasts a diverse landscape spanning 1500 miles of endless Pacific coastline, subterranean jungles of the Amazon, and the magnificent Andes mountains featuring the Inca Trail which leads to the citadel of Machu Picchu in the Cuzco cloud forest. Visitors to this beautiful South American country will also experience culinary delights not found anywhere else in the world. Historic sites transport visitors back thousands of years to the ancient Incan civilization and the Spanish conquest of the 1500’s. Pack your hiking shoes, a good camera and plenty of memory discs and prepare to encounter countless photographic opportunities while traversing Peru’s awe-inspiring geography and multifarious terrain.\nThe Peruvian Cuisine\nThe Peruvian people are passionate about their indigenous cuisine. While Peruvian food consists primarily of maize (corn) dishes, rice, eggs, soups and stews, most of Peru’s 25 regions are also recognized for specific flavors and dishes.\n- Lomo Saltado – This is a very popular dish made with strips of steak which are sautéed in a blend of soy sauce, garlic, vinegar, onions, chilies, and tomatoes. The flavorful mixture is often placed on a bed of lettuce and served with chips (French fries).\n- Peruvian Ceviche –This beloved Peruvian dish is prepared with bites of fresh, raw white fish which have been marinated and ‘cooked’ in the acidity of lemon and lime juice, and blended with onions, Peruvian spices and chilies. Ceviche is served in a variety of ways, often alongside corn or boiled sweet potatoes.\n- Cuy – If you or your children have ever owned a pet guinea pig, you would perhaps choose to skip this dish. Cuy is the Peruvian translation for guinea pig. The Andean culture of Peru, Ecuador and other South American countries often raise the these animals in their homes; Cuy are considered an important part of the country’s food supply.\n- Pisco – This high-proof brandy is a favorite Peruvian alcoholic beverage. Often made in the wine-producing regions of Peru and Chile, Pisco is frequently mixed in cocktails such as an Algarrobina, Chicano de Pisco, or a Cupid’s Cup. A favorite beer among Peruvians is Cusqueña Premium Peruvian beer which is primarily produced in the town of Sacha near Arequipa, Peru.\nPeruvian Geography and Landmarks\nFrom the primeval Amazon Rain Forest to Machu Picchou, an ancient Incan city in the rugged Andes mountain range, to the narrow, arid plains lining the Pacific coastal region, Peru’s terrain is as diverse and interesting as the country’s ethnic and social demography.\nMachu Picchou – Peru’s most prominent attraction is Machu Picchou, a spectacular ancient city of the Incas which remained undiscovered by invading Spaniards in the 1500’s. This urban creation located in the Amazon Basin is a magnificent maze of giant walls, ramps and terraces. Machu Piccho is a UNESCO World Heritage site, and is listed as one of the New7 Wonders of the World. It is recommended to visit this ancient city early in the morning in order to capture premium photographs without the tourist throngs. Visitors can readily hire a guide at the entrance to enhance their grand and acquire historic and cultural facts on the city.\nMancora – A popular site for surfing lovers, Mancora is located on the north coast in Peru’s Piura Region and is considered the country’s trendiest beach. With over 30 resorts and numerous restaurants and nightclubs, this town of only 10,000 residents attracts thousands of sun worshippers, travelers and surfers each year.\nNazca Desert and Nazca Lines – This amazing series of immense line drawings was created between 200 BC and 700 AD. Located between Nazca and Palpa on the north coast, the drawings feature monkeys, fish, llamas, lizards, and humans. The observation tower along the Pan-American Highway provides visitors with an incredible view of three of the figures. The ideal way to see and photograph the lines is via one a Cessna Flight Tour, which can be booked at your hotel.\nThe Sacred Valley – Located in the beautiful yet daunting foothills of the Rio Urubamba Valley, the Sacred Valley is replete with ancient villages and historic lore. Located in the Cusco region near Machu Picchu, it was the primary area for corn (maize) production, and was once considered the heartland of the Inca Empire. Archaeology lovers do not want to miss a tour of the Sacred Valley.\nWith a history of civilizations that spans thousands of years, the Peruvian people have fastidiously preserved the cultural and geographic diversity which make this country so fascinating. Cobblestone streets designed by the Spanish Conquistadors have been protected and preserved for the future. The ancient city of Machu Pichu reminds travelers of the impenetrable Inca Empire. The mystical lines found in the Nazca Desert remain unexplained today. While Spanish is Peru’s primary language, the traditional dialect of Quechua is still utilized by the highland Indians of the Andes. And lying just outside of Puerto Maldonado in eastern Peru, the primeval habitats and natural resources found within in the subterranean jungles of the Amazon maintain an unrivaled biodiversity.\nIn the words of J.R.R. Tolkien, “not all those who wander are lost.” Peru truly is a magnificent travel destination for the wanderlust and those seeking diverse culture, rich history and stunning natural beauty in their travels. For complete information, please visit Peru’s official travel and tourism portal.\n[contact-form-7 id=”4″ title=”Contact form 1″]']"	['<urn:uuid:2ac31b37-3158-4a3b-b88d-2c763fc6beb4>', '<urn:uuid:deb6d218-ae57-4ed5-999e-4d48b75d780f>']	factoid	direct	short-search-query	distant-from-document	three-doc	expert	2025-05-13T05:52:58.810667	5	43	1848
4	sugar content measurement tool sugarbeets	Percent sugar is measured with an instrument called a polarimeter. This measurement indicates the percent of total weight that is sugar - for example, if beets have 17.00 percent sugar, that means there are 17.00 tons of sugar in each 100 tons of average cleaned beets.	['Basic Processing Overview\nThree flow diagrams are included in this basic processing overview. The simplified process flow diagram shows the path the beets take through the factory to become end products. It also shows where some of the other expensive raw materials and supplies are used. The diffusion flow diagram shows where the water insoluble nonsugars are separated from the rest of the beet. The sugar end flow diagram shows all the product flows on the sugar end.\nThe bar graph shows the composition of the beets, some intermediate products, and the end products, in terms of sugar, water, water soluble nonsugars, and water insoluble nonsugars. A nonsugar is any substance that is not sugar (sucrose) or water. Water soluble means that a substance will dissolve in water. Sugar is water soluble because it will dissolve in water. Sulfate, phosphate, sodium, and potassium will all dissolve in water, so they are water soluble nonsugars. Cellulose, a main component of sugarbeets, will not dissolve in water, so it is a water insoluble nonsugar.\nThe bar graph also shows how much intermediate or end product results from processing each 100 tons of beets. The bars for the intermediate products correspond directly with the lines between the processes on the flow diagram. For example, 100 tons of clean, sliced beets entering diffusion (along with several tons of water), yields two intermediate products, 44 tons of wet pulp and 110 tons of raw juice. As the wet pulp travels through the pulp presses, the pulp dryer, and the pellet mills, it becomes pressed pulp, dry pulp, and pellets. As the raw juice travels through carbonation and evaporation, it becomes thin juice and thick juice, which is the input for the crystallization process.\nMaking sugar from sugar beets involves four basic processing steps: diffusion, carbonation, evaporation, and crystallization. All of these steps are separation processes.\nDiffusion involves the separation of the water insoluble nonsugars from the rest of the beet. Most of the soluble components of the beet are dissolved in water and form raw juice. The raw juice is removed through a screen and what is left is the insoluble portion of the beet, the wet pulp.\nCarbonation involves the separation of some of the water soluble nonsugars from raw juice. Only about 28% of the water soluble nonsugars are actually removed in this step, but many others are destroyed or converted into compounds that are easier to process in later steps.\nEvaporation involves the separation of water from thin juice. Over 100 tons of water must be evaporated for every 100 tons of beets sliced. To evaporate that much water, tremendous amounts of heat must be supplied. The heat is supplied by coal and carried to the evaporators in the form of steam. The coal for evaporation costs the company more than any other process supply. The quadruple effect evaporator block diagram shows the evaporation process with thin juice entering the system and thick juice being the final product in this stage of operations.\nCrystallization involves the separation of sugar from the thickened juice. The juice left over after crystallization is called molasses. It contains the remaining nonsugars and about an equal amount of sugar, which, economically, is not feasible to remove.\nBecause these processes and products are referred to so many times in terms of the amounts of sugar, water, water soluble nonsugars, and water insoluble nonsugars they contain, special names have been given to the ratios of the amounts of one of these components to the other or others. Percent sugar is one of these terms and its name pretty much explains what it means. It is the percent of the total weight of a substance that is sugar. If the average percent sugar of beets is 17.00, that means there are 17.00 tons of sugar in each 100 tons of average cleaned beets. If pellets average 5.80 percent sugar, there are 5.80 tons of sugar in each 100 tons of average pellets produced. Percent sugar is measured with an instrument called a polarimeter.\nAnother important ratio is the percent of the total weight of a substance that is dry (not water). Depending on what substance is being tested and what method is being used to measure it, this ratio is called percent solids, percent dry substance, refractometer dry substance (RDS), or degrees Brix. When the dry substance of a juice is being measured, and all the solids are soluble, an instrument called a refractometer is usually used. Most juices’ dry substance are expressed in RDS. When measuring the dry substance of a material where the solids are not soluble, an evaporative method is usually used and the answer is expressed as percent solids or simply, dry substance. The evaporative method is used on pulp and pellets, and is performed by weighing a substance, evaporating all the water away, and then weighing the remaining dry substance.\nPercent moisture is the percent of the total weight of a substance that is water. It is measured by the same methods as percent dry substance and is equal to 100 minus the dry substance.\nPurity is the percent of the dissolved solids in a solution that is sugar. The key word in this definition is dissolved. Water insoluble nonsugars do not dissolve in water, so purity is not affected by water insoluble nonsugars. Purity then, is the ratio of the weight of sugar in a substance to the weight of sugar plus water-soluble nonsugars in the substance, expressed as a percent. If one hundred tons of beets contain 17.00 tons of sugar and 2.54 tons of water-soluble nonsugars, the purity is 17.00 divided by the quantity of 17.00 plus 2.54 or, 87.00 percent. The purity of a juice can be calculated if the RDS and the percent sugar is known. Since percent sugar indicates the relative weight of the sugar, and RDS indicates the relative weight of dissolved solids, purity equals the percent sugar divided by the RDS. An example is thick juice, which might be 50 percent sugar and have an RDS of 55. The purity is 50 divided by 55 or 90.9 percent purity.']	['<urn:uuid:9b4be01f-f207-4879-b2d4-21d71e2c4406>']	factoid	with-premise	short-search-query	distant-from-document	single-doc	expert	2025-05-13T05:52:58.810667	5	46	1022
5	plasmonic nanoparticles applications risks	Plasmonic nanoparticles have diverse applications including catalysis, hydrogen sensing, and gas sensors for urban air quality monitoring. However, these nanoparticles raise safety concerns as they can penetrate tissues more deeply than larger particles and display unexpected biological properties, requiring careful evaluation of their anatomic distribution and potential toxicity through both in vitro and in vivo studies.	['Single nanoparticle catalysis\nNanoparticles are the most important industrial catalysts and heterogeneity is a general feature among them. Recently, owing to the fascinating advances of shape-selected nanocrystal synthesis, particles with well-controlled size, shape and chemical composition have become available. Yet, even with shape-selection, structural and compositional heterogeneity prevails at the individual particle level. Therefore, even in ensembles of shape-selected nanoparticles, the sample heterogeneity problem cannot be completely avoided. This is hampering significantly the generation of deeper understanding of how catalyst particle size, shape and composition affect its activity and selectivity, as these parameters directly control the catalytic performance by determining which surface sites that are exposed to the reactants. Assessing the state, activity and selectivity of individual nanoparticles with high resolution is therefore vital to the development of efficient catalysts. Moreover, operating experimentally at the level of a single nanoparticle facilitates a unique and direct link between experiment and electronic structure-based theory. Therefore, in the ERC StG project SINCAT and the Knut and Alice Wallenberg Foundation project Single Particle Catalysis in Nanoreactors, we will develop an experimental platform to study individual catalyst nanoparticle in operando by combining plasmonic nanospectroscopy, mass spectrometry and fluorescence microscopy with nanofluidics. The KAW project is a team effort coordinated by us and carried out in collaboration with the groups of Fredrik Westerlund, Kasper Moth-Poulsen, Paul Erhart, Hanna Härelind, Henrik Sundén and Anders Hellman at the Biology, Chemistry and Physics Departments at Chalmers.\nHydrogen metal interactions at the nanoscale and hydrogen sensors\nIn a hydrogen economy fossil fuels are replaced by hydrogen as the clean and sustainable energy vector. For this scenario to become reality the development of safe, cost-effective, and practical means of producing, storing but also detecting hydrogen for safety reasons is crucial. The latter is of high urgency due to the market introduction of hydrogen powered fuel cell cars by, for example, Toyota and Hyundai, as well as the progress made in installing a hydorgen fuel station infrastructure in the World, in Europe and Sweden. Specifically, cheap, reliable hydrogen sensors are important because hydrogen in air, at concentrations above 4% is highly flammable, and above 18.3 % highly explosive. We exploit the optical changes in metal hydrides upon hydrogen sorption in combination with plasmonic antennas to develop efficient hydrogen sensing schemes. The optical detection of hydrogen is attractive because it does not involve any current leads, which makes it intrinsically safe as no sparks can be generated. In response to this challenge, we explore nanoplasmoinc sensing based solutions for next generation hydrogen sensors within the SSF RMA11-0037 project Functional Electromagnetic Metamaterials and Optical Sensing.\nNanoplasmonic gas sensors\nEnsuring a healthy and livable urban environment is a priority all over the world due to rapidly progressing urbanization. In cities, high concentrations of ground level emissions, mainly from combustion processes and transportation, cause alarming damage to both flora and fauna and human health. Consequently, a technological breakthrough enabling equally accurate but mobile, simple and spatially highly resolved air quality monitoring devices is urgently needed. Together with our industry partner Insplorion AB, we are developing a miniaturized and portable air pollutant sensor device based on optical plasmonic nanosensor technology. These efforts are funded by the Swedish Foundation for Strategic Environmental Research via their Mistra Innovation Programme.\nNanoantenna-enhanced photocatalysis by optical absorption engineering\nWe explore combinations of different metals in heterometallic plasmonic nanoantenna arrangements for optical absorption engineering. Since we are interested in the hot electrons generated by light absorption in these systems as mediators for catalytic reactions, we combine the strong surface plasmon excitations in Gold and Silver with the intrinsic catalytic activity of other metals. The latter are typically also characterized by large optical losses (=large absorption) at UV and visible frequencies due to their intrinsic electronic structure. By tailoring the mutual coupling between antenna elements consisting of different metals with different function we can engineer and significantly enhance light absorption in an element of choice and, consequently, boost hot electron formation to drive a catalytic reaction. This research is funded by my Swedish Research Council project 2014-4956.\nIn this project, funded by the Swedish Foundation for Strategic Research (SSF RMA15-0052 project Plastic Plasmonics) we are developing a new class of materials – Plastic Plasmonic Hybrids. They consist of plasmonic nanoparticle arrangements with tailored structural, optical and chemical properties, which are dispersed at the nanoscale in a polymer matrix for ease of processing into real devices by 3D printing or melt processing. In this way this project strives to deliver a breakthrougs for commercially viable functional plasmonic nanomaterials and their large scale processing into cheap devices. This project, coordinated by us, is a collaboration with the groups of Christian Müller, Kasper Moth-Poulsen, Paul Erhart and Anders Hellman at the Chemistry and Physics Departments at Chalmers.\nHeterogeneous catalyst sintering and deactivation\nMetal nanoparticles dispersed on high-surface-area support materials are widely used as catalysts in chemical synthesis, energy conversion, and environmental cleanup applications. The excess surface energy due to the large surface area of the catalyst nanoparticles renders them metastable, which means that they tend to coalesce into fewer but larger particles upon thermal activation. This process is known as catalyst sintering and it is a major cause of catalyst deactivation due to the loss of active catalyst surface area. The consequence is billions of dollars of extra cost associated with catalyst regeneration and renewal. Catalyst sintering also has a severe impact on the environment by, for example, deteriorating exhaust-cleaning catalysts in vehicles and increasing the use of raw materials and energy. We apply the INPS and other experimental techniques such as transmission electron microscopy to understand sintering mechanisms of catalyst nanoparticles and how metal-support interactions influence the latter. These efforts are a collaboration with the Competence Center for Catalysis at Chalmers.\nNanoplasmonic sensing for materials science applications\nWe develop and exploit nanoplasmonic sensing or “plasmonic nanospectroscopy” to probe a specific chemical or physical process of interest in a functional nanomaterial . The key benefits of using plasmonic nanoantennas as in situ probes for this purpose are their flexibility in terms of applicability to very different material systems and to harsh environments, the relative simplicity of the necessary optical and general experimental “hardware”, and their high local sensitivity at the nanoscale. Moreover, nanoplasmonic sensing employs low-power optical readout, which basically makes it non-invasive with minimal impact on the studied processes. Our “workhorse” is the NanoPlasmonic Sensing (NPS) platform, which also constitutes the patented proprietary technology of our spin-off company Insplorion AB. For the time being we specifically apply NPS to investigate the glass transition in thin polymer films used for organic photovoltaic devices (collaboration with the Müller group at Chalmers) and to characterize CO2 adsorption in micro and mesoporous materials for CCS applications (collaboration with Akzo Nobel and with Prof. Niklas Hedin at Stockholm University and the Berzelii Center EXSELENT).\nFundamental nanoplasmonics of new materials\nLocalized Surface Plasmon Resonances (LSPRs) are collective electronic oscillations that can be resonantly excited by external electric fields in any metallic nanoparticle. Traditionally, the focus has been almost entirely on Gold and Silver due to their favorable electronic properties at near-visible frequencies. We are specifically interested in mapping and understanding, at the fundamental level, how the significantly different bulk dielectric properties of other metals (compared to the classics Silver and Gold) as well as metal alloys, are reflected in the plasmonic response of their nanoparticles. As one interesting application of the above efforts we utilize the LSPR in a variety of metals to probe physical and chemical processes in the bulk or directly on the surface of the particles by using the LSPR as readout in what we coined “direct nanoplasmonic sensing” experiments.\nSize and shape dependence of nanoparticle – biomolecule interactions during biocorona formation\nBiomolecules such as proteins immediately adsorb on the surface of nanoparticles upon their exposure to a biological environment. The formed adlayer is commonly referred to as a biomolecule corona (biocorona) and defines directly the biological activity and toxicity of the nanoparticle. Therefore, it is essential to understand in detail the biocorona formation process, and how it is governed by parameters like composition of the biological environment, and nanoparticle size, shape and faceting. We deploy tailored surface-associated nanostrcutures with integrated plasmonic sensing function to assess the role of nanoparticle size and shape on the biocorona formation process as part of our efforts in the Mistra Environmental Nanosafety project funded by the Swedish Foundation for Strategic Environmental Research.', 'The Center for Nanotechnology and Nanotoxicology at the Harvard School of Public Health (Harvard NanoCenter) draws on decades of experience with environmental pollutants and the health effects of particles to address the unique environmental health and safety (EHS) concerns raised by engineered nanomaterials (ENMs) & nanotechnology applications.\nNanoparticles are integral to an increasing array of products, from sunscreen and cancer drugs to batteries and semiconductors. However, the rapid expansion of this technology raises safety concerns and calls for a better understanding of how nanomaterials affect biological and environmental systems. Specifically, we need to learn more about the bio-nano interactions at cellular/molecular, organismal, and environmental levels. Since nanoparticles often display unexpected biological properties, we need to discover new toxicologic priciples to understand their potential risks. This assessment is complicated by the fact that nanoparticles are able to penetrate tissues more deeply than larger particles, so careful evaluation of the dose and especially the anatomic distribution of nanoparticles is essential. It is also important to examine species differences, and differences between in vitro versus in vivo exposure. It is clearly imperative that the fields of nanotoxicology and risk assessment keep pace with nanotechnology and its expanding universe of applications.\nNew Technology Brings New Questions\nHow do we balance the potential of nanotechnology with the potential hazards from new and often inadequately characterized materials? The rapid expansion of nanotechnology is a powerful scientific and economic force. However, we need to match this progress with careful evaluation of the possible toxicity of nanomaterials and technologies. This process can be made more efficient by searching for fundamental principles that govern biological responses to nanomaterials, rather than assessing the toxicity of specific nanomaterials one at a time. How do we discover the rules of nanotoxicology? A promising approach is to examine families of engineered and rigorously characterized particles and to study the role of such factors as particle size and shape, composition, and charge. Our NanoCenter is generating these rational families of particles, holding some parameters constant while changing others systematically. We bring together modern in vivo and in vitro toxicologic approaches to carry out the biologic evaluation of nanomaterials. We also seek to advance methods needed to evaluate the safety of nanotechnology. Our NanoCenter combines excellence in material and exposure science with demonstrated skills in lung toxicology, pharmacokinetics, and biology. By developing and utilizing industrially relevant ENM generation systems that enable us to control the properties of “real world” nanomaterial exposures, we will better understand how particle dynamics and physical and chemical parameters alter both pharmacokinetics and the extent of possible injury. Correlations will be made between in vivo and in vitro methods, as well as between in vitro systems using rodent versus human cells. The center will study safer nanomaterial formulation concepts which can reduce the environmental and health implications of ENMs. The center will develop and deploy a variety of exposure assessment technologies to define human exposures to nanomaterials during their full life cycle (manufacture, use, and disposal). Using methods of lifecycle analysis (LCA), we will assess exposures to nanomaterials from “cradle to grave.” Finally, all these data will be integrated using methods of risk assessment and physiologically based pharmacokinetic models. The end result will be a science-based guide to appropriate standards for safety. We neither want to create human health hazards nor do we want to erect unreasonable barriers to the creative uses of nanomaterials in industry and medicine.\nThe Need: A New Generation of Scientists\nAs nanotechnology gives rise to new techniques and products, both scientists and the general public are becoming aware of its tremendous potential. It is surprising, therefore, that despite the burgeoning use of nanotechnology as well as concerns about its safety, the number of graduate and postdoctoral trainees in related areas remains small. To address this shortfall, it is vital to create opportunities for training and research in the field of nanotoxicology and risk assessment. The Harvard School of Public Health is poised to lead such efforts and contribute to the training of a new generation of environmental health nanoscientists, building on key strengths at Harvard and other institutions.\nOur research and academic activities, coupled with outreach activities, allow us to consult with and inform all stakeholders: the public, public agencies, and corporations. We seek to partner with the industry during the development of nanoproducts and promote the safer formulation of nanomaterials during the development phase.\nBy creating a Center for Nanotechnology and Nanotoxicology at the Harvard School of Public Health, we have an opportunity to foster world-class activities in nano-sciences. We are also able to take advantage of adjacent institutions such as Harvard Medical School and its teaching hospitals, the School of Engineering and Applied Sciences at Harvard, and MIT, which have considerable resources and interest in this field. The center is made up of three divisions, each of which already has considerable momentum. Importantly, these divisions interact with each other because of favorable geography and an environment that fosters productive conversations. Collectively, our multidisciplinary and cutting-edge research positions our center among the leading programs in the United States and throughout the world in this critical intersection of engineering, commerce, and public health.']	['<urn:uuid:53280d29-afc9-453a-8e20-9eae7443a6ac>', '<urn:uuid:8ad5a919-1713-4cd0-bcf4-a9834df9a056>']	factoid	with-premise	short-search-query	similar-to-document	multi-aspect	expert	2025-05-13T05:52:58.810667	4	56	2256
6	doing research on photochemistry what happens during ultrafast laser material interactions and how does it affect molecular energy conversion	"During ultrafast laser-material interactions, molecules undergo several processes of energy conversion following light absorption. Initially, electronic excitation occurs, followed by various potential pathways including electron transfer, mechanical motion, bond breaking and forming, fluorescence, and vibrational energy dissipation. The molecular response depends on structure and environment, which influence how the absorbed energy is directed through these different channels. At the materials level, these interactions can trigger photochemical and photomechanical effects at femtosecond timescales. Understanding these dynamics is crucial for controlling energy conversion processes, as molecules can ""choose"" among these potential paths based on their structure and surrounding conditions."	"[""Professor Cather Simpson\nCather Simpson joined the University of Auckland in 2007, with a joint appointment in Physics and the Chemical Sciences. She received her Ph.D. in the USA in Medical Sciences with a focus on the ultrafast vibrational dynamics of heme proteins. After a Department of Energy Distinguished Postdoctoral Fellowship, she joined the Chemistry Department at Case Western Reserve University as an Assistant Professor to pursue research in ultrafast energy conversion in molecules. After earning tenure and promotion at CWRU, she moved to the University of Auckland, where her research now spans fundamental spectroscopy to applied device development.\nResearch | Current\nUltrafast Spectroscopy and Quantum Chemistry. The ability of molecules to convert light into more useful forms of energy motivates our fundamental chemical physics research. How molecules direct the energy acquired in light absorption, and “choose” among potential paths (electron transfer, mechanical motion, bond breaking and forming, fluorescence, vibrational energy dissipation, etc.) is the focus of our studies on the dynamics of hemes, diphosphenes, red-lake art chromophores, porphyrin-fullerene complexes, and others. We use pump-probe spectroscopy (transient absorption, Raman) on the femtosecond to microsecond timescales to probe these molecular dynamics, and quantum chemical calculations (CASSCF, CASPT2, DFT, TDDFT) to understand them. Ultimately, we seek knowledge of how the structure and environment influence molecular “decisions” so that we can both predict and tailor photochemical and photophysical behaviour.\nPulsed Laser Micromachining and Microfabrication. Our interest in laser-matter interactions has led to major targeted research projects to exploit ultrashort laser pulses for machining. Femtosecond pulse durations lead to multiphoton excitations and temporal uncoupling of electron and phonon degrees of freedom, and offer smaller features, minimal heat affected zones, and breadth in materials suitable for processing. Unfortunately, femtosecond laser machining is still too slow to be of widespread industry use. I lead a multi-institutional team to overcome this challenge through tailored laser-matter interactions, materials synthesis, and laser development. Our lab focuses on the first of these, with temporal and spatial shaping, multi-pulsing, frequency sweeping, and other approaches. Our studies on metals, dielectrics, biomaterials and polymers, seek to illuminate and better exploit the mechanistic details of laser ablation. NZ and US commercial partners help target our research to meet commercially valuable challenges, so that we advance high-tech manufacturing by mobilizing new knowledge.\nSperm Sorting by Sex for Agriculture. Engender Technologies, Ltd., a spin-off company funded by venture capital and Auckland UniServices, commercializes our ideas for using microfluidic and photonic technology to improve sorting of sperm by sex for the dairy industry. I am the founding scientist and chief science officer. Our new technology (PCT published Jan 2014) will improve both efficiency of sorting and performance of sex-sorted sperm by avoiding electric fields and reducing shear stress on the sperm membrane during processing. All components have been proven in the lab, and the project is now in the last laboratory demonstration stage before commercialization. Engender recently signed a deal with one of the world’s largest AI companies. The deal provides Engender with crucial expertise in sperm morphology, viability and handling and in vitro validation and fertilisation testing of sperm sorted by Engender’s technology.\nTeaching | Current\nMy teaching philosophy is simple: my job as a university academic is to help students learn what they need in order to succeed in their own lives. Achieving this goal is my primary reason for building a career academia. Whether I am lecturing on chemistry or physics to a class of 500+ engineers or pre-medical students, on advanced quantum mechanics to 15 Ph.D. students, or on science and metaphor to arts and humanities students, this core value spurs me to always look for ways to help students perform to the best of their abilities. I strive for continued improvement in my courses with innovations based on sound pedagogical research, and have achieved success with collaborative learning, clear expectations, a focus on concepts rather than memorization, and by listening to the formative and summative feedback from students and colleagues. This philosophy extends to one-on-one research supervision, to curricular development, and to outreach to schools and the community. I am particularly keen to improve engagement with and outcomes for women and other underrepresented groups.\nCurrently, I lead an educational research project that examines student motivations, strategies for learning and study habits in large lecture “science major” and “service” classes that is directed at understanding how to better understand and foster success for both cohorts. I also chair a team of academic and professional staff who are implementing the new “Science Scholars Programme” in the Faculty of Science at the University of Auckland. Guided by international “best practice” in honours programs, we are designing an enriched science curriculum for NZ’s best science students, with diversity a key target at the outset. Our goal is to develop a community of scholars that fosters creativity, innovation, and achievement. The first Science Scholars will begin study in 2015.\nCURRENT OPENING: Photophysics of Molecular Dragons\nMolecules that can control the flow of excess vibrational energy after photoexcitation can be turned into molecular dragons: focusing their non-Boltzman relaxation energy towards therapeutic targets . Phthalocyanines and porphyrins are good candidates for molecular dragons because they have a large number of substitution sites that allows them to be tailored for these applications. The designs of these systems relies on a thorough understanding of the dynamics in the photoexcited state of the molecule, which can be studied using femtosecond time-resolved spectroscopy such as femtosecond transient absorption, time-resolved Raman and time-resolved fluorescence spectroscopy. The successful candidate will have a strong interest in photophysics, photochemistry, and free-space laser spectroscopy setups. The project will use all three of these methods to evaluate dragon-like behaviour in molecules synthesised by collaborators.\nCurrent PhD Students:\n- Sarah Thompson (Chemistry)\n- Julie Kho (Chemistry)\n- Andy Wang (Chemistry)\n- Nina Novikova (Chemistry; co-supervised with Prof. Penny Brothers)\n- Simon Ashforth (Physics)\n- Dijana Bogunovic (Physics)\n- Matheus Vargas (Chemistry)\nCurrent MSc Students:\n- Jake Martin (Chemistry)\n- 2013 National Tertiary Teaching Excellence Award, Ako Aotearoa National Centre for Tertiary Teaching Excellence (NZ).\n- 2013 Callaghan Commercialisation Fellowship, MacDiarmid Institute for Advanced Materials and Nanotechnology (NZ).\n- 2012 The University of Auckland Sustained Excellence in Teaching Award (NZ).\n- 2012 Dean's Award for Teaching Excellence, University of Auckland (NZ).\n- 1998 – 2004 F.I.R.S.T Award (R29), National Institutes of Health (USA)\n- 1999 – 2000 Glennan Fellow Award for Young Teacher Scholars, Case Western Reserve University (USA).\n- 1998 “Top Prof” Award, CWRU Mortar Board Society, Case Western Reserve University (USA)\n- 1994 – 1996 Department of Energy Distinguished Postdoctoral Research Fellow (USA).\n- 1989 – 1994 Howard Hughes Predoctoral Fellow (USA).\n- 1983 – 1986 Echols Scholar at the University of Virginia (USA).\nDirector, The Photon Factory. The Photon Factory is a state-of-the-art pulsed laser research facility in the Faculty of Science at the University of Auckland. The Photon Factory’s core mission is to enable the research of all New Zealand scientists – academic, industrial, and national research lab-based – through the advanced use of laser pulses to interrogate light-matter interactions and to manipulate and machine materials. Opened in 2010, we have grown rapidly to a now vibrant group of about 25 researchers that includes physics, chemistry and engineering students and staff working together to perform research of our own, and to undertake research for industry and collaborators. Since 2010, we have generated nearly $1.6M (NZD) in commercial contracts, completed or ongoing. Our external grant revenues are strong as well, with over $9M (NZD) in funding, most as principal investigators. Finally, we also actively reach out to schools with science projects with school students, school visits and tours, and with teachers through professional teaching societies and the Royal Society of New Zealand.\nCentres of Research Excellence. Dr. Simpson is a Principal Investigator in the MacDiarmid Institute for Advanced Materials and Nanotechnology and in the new Dodd-Walls Centre for Photonic and Quantum Technologies, where she also sits on the Executive Committee. She is also an Associate Investigator in the Medical Devices CoRE.\nSelected publications and creative works (Research Outputs)\n- Novikova, N. I., Lo, A. S. V., Gordon, K. C., Brothers, P. J., & Simpson, M. C. (2018). Diboron Porphyrins: The Raman Signature of the In-Plane Tetragonal Elongation of the Macrocycle. The journal of physical chemistry. A, 122 (23), 5121-5131. 10.1021/acs.jpca.8b01925\nOther University of Auckland co-authors: Penelope Brothers, Nina Novikova\n- Sullivan, M. P., Nieuwoudt, M. K., Bowmaker, G. A., Lam, N. Y. S., Truong, D., Goldstone, D. C., & Hartinger, C. G. (2018). Unexpected arene ligand exchange results in the oxidation of an organoruthenium anticancer agent: the first X-ray structure of a protein-Ru(carbene) adduct. Chemical communications (Cambridge, England), 54 (48), 6120-6123. 10.1039/c8cc02433b\nOther University of Auckland co-authors: Christian Hartinger, David Goldstone, Matthew Sullivan, Dianna Truong, Michel Nieuwoudt, Graham Bowmaker\n- Raos, B. J., Simpson, M. C., Doyle, C. S., Murray, A. F., Graham, E. S., & Unsworth, C. P. (2018). Patterning of functional human astrocytes onto parylene-C/SiO2 substrates for the study of Ca2+ dynamics in astrocytic networks. Journal of neural engineering, 15 (3)10.1088/1741-2552/aaae1d\nOther University of Auckland co-authors: Charles Unsworth, Brad Raos, Scott Graham\n- Zhou, Y., Cink, R. B., Fejedelem, Z. A., Cather Simpson, M., Seed, A. J., Sampson, P., & Brasch, N. E. (2018). Development of Photoactivatable Nitroxyl (HNO) Donors Incorporating the (3-Hydroxy-2-naphthalenyl)methyl Phototrigger. European Journal of Organic Chemistry, 2018 (15), 1745-1755. 10.1002/ejoc.201800092\n- Raos, B. J., Doyle, C. S., Simpson, M. C., Graham, E. S., & Unsworth, C. P. (2018). Selective PEGylation of Parylene-C/SiO2 Substrates for Improved Astrocyte Cell Patterning. Scientific reports, 8 (1)10.1038/s41598-018-21135-0\nOther University of Auckland co-authors: Brad Raos, Scott Graham, Charles Unsworth\n- Martin, J. W., Nieuwoudt, M. K., Vargas, M. J. T., Bodley, O. L. C., Yohendiran, T. S., Oosterbeek, R. N., ... Simpson, M. C. (2017). Raman on a disc: High-quality Raman spectroscopy in an open channel on a centrifugal microfluidic disc. Analyst, 142 (10), 1682-1688. 10.1039/c6an00874g\nOther University of Auckland co-authors: David Williams, Michel Nieuwoudt\n- Whitby, R., Ben-Tal, Y., MacMillan, R., Janssens, S., Raymond, S., Clarke, D., ... Simpson, M. C. (2017). Photoinitiators for two-photon polymerisation: Effect of branching and viscosity on polymerisation thresholds. RSC Advances, 7 (22), 13232-13239. 10.1039/c6ra27176f\nOther University of Auckland co-authors: Jianyong Jin\n- Nieuwoudt, M. K., Holroyd, S. E., McGoverin, C. M., Simpson, M. C., & Williams, D. E. (2017). Screening for adulterants in liquid milk using a portable Raman miniature spectrometer with immersion probe. Applied Spectroscopy, 71 (2), 308-312. 10.1177/0003702816653130\nOther University of Auckland co-authors: David Williams, Cushla McGoverin, Michel Nieuwoudt\n- Media Contact\nSCIENCE CENTRE - MATHPHYSIC\nLevel 6, Main reception\n38 PRINCES ST\nPrimary office location\nSCIENCE CENTRE 302 - Bldg 302\n23 SYMONDS ST"", ""3D Laser Microfabrication: Principles and Applications\nThe book also presents new theoretical material on dielectric breakdown, allowing a better understanding of the differences between optical damage on surfaces and inside the bulk, as well as a look into the future.\nChemists, physicists, materials scientists and engineers will find this a valuable source of interdisciplinary knowledge in the field of laser optics and nanotechnology.\n1 Introduction (Hiroaki Misawa and Saulius Juodkazis).\n2 Laser–Matter Interaction Confined Inside the Bulk of a Transparent Solid (Eugene Gamaly, Barry Luther-Davies and Andrei Rode).\n2.2 Laser–matter Interactions: Basic Processes and Governing Equations.\n2.3 Nondestructive Interaction: Laser-induced Phase Transitions.\n2.4 Laser–Solid Interaction at High Intensity.\n2.5 Multiple-pulse Interaction: Energy Accumulation.\n3 Spherical Aberration and its Compensation for High Numerical Aperture Objectives (Min Gu and Guangyong Zhou).\n3.1 Three-dimensional Indensity Point-spread Function in the Second Medium.\n3.2 Spherical Aberration Compensation by a Tube-length Change.\n3.3 Effects of Refractive Indices Mismatch-induced Spherical Aberration on 3D Optical Data Storage.\n3.4 Effects of Refractive Index Mismatch Induced Spherical Aberration on the Laser Trapping Force.\n4 The Measurement of Ultrashort Light Pulses in Microfabrication Applications (Xun Gu, Selcuk Akturk, Aparna Shreenath, Qiang Cao, and Rick Trebino).\n4.2 Alternatives to FROG.\n4.3 FROG and Cross-correlation FROG.\n4.4 Dithered-crystal XFROG for Measuring Ultracomplex Supercontinuum Pulses.\n4.5 OPAXFROG for Measuring Ultraweak Broadband Emission.\n4.6 Extremely Simple FROG Device.\n4.7 Other Progress.\n5 Nonlinear Optics (John Buck and Rick Trebino).\n5.1 Linear versus Nonlinear Optics.\n5.2 Nonlinear-optical Effects.\n5.3 Some General Observations about Nonlinear Optics.\n5.4 The Mathematics of Nonlinear Optics.\n5.6 Phase-matching Bandwidth.\n5.7 Nonlinear-optical Strengths.\n6 Filamentation versus Optical Breakdown in Bulk Transparent Media (Eugenijus Gaiz&acaron;uskas).\n6.2 Conical Waves: Tilted Pulses, Bessel Beams and X-type Waves.\n6.3 Dynamics of Short-pulse Splitting in Nonlinear Media with Normal Dispersion: Effects of Nonlinear Losses.\n6.4 On the Physics of Self-channeling: Beam Reconstruction from Conial Waves.\n6.5 Multi-filaments and Multi-focuses.\n6.6 Filamentation Induced by Conical Wavepacket.\n7 Photophysics and Photochemistry of Ultrafast Laser Materials Processing (Richard F. Haglund, Jr.).\n7.1 Introduction and Motivation.\n7.2 Ultrafast Laser Materials Interactions: Electronic Excitation.\n7.3 Ultrafast Laser-materials Interaction: Vibrational Excitation.\n7.4 Photochemistry in Femtosecond Laser-materials Interactions.\n7.5 Photomechanical Effects at Femtosecond Timescales.\n7.6 Pulsed Laser Deposition.\n7.7 Future Trends in Ultrafast Laser Micromachining.\n7.8 Summary and Conclusions.\n8 Formation of Sub-wavelength Periodic Structures Inside Transparent Materials (Peter G. Kazansky).\n8.2 Anomalous Anisotropic Light-scattering in Glass.\n8.3 Anisotropic Cherenkov Light-generation in Glass.\n8.4 Anisotropic Reflection from Femtosecond-laser Self-organized Nanostructures in Glass.\n8.5 Direct Observation of Self-organized Nanostructures in Glass.\n8.6 Mechanism of Formation of Self-organized Nanostructures in Glass.\n8.7 Self-organized Form Birefringence.\n9 X-ray Generation from Optical Transparent Materials by Focusing Ultrashort Laser Pulses (Koji Hatanaka and Hiroshi Fukumura).\n9.2 Laser-induced High-energy Photon Emission from Transparent Materials.\n9.3 Characteristics of Hard X-ray Emission from Transparent Materials.\n9.4 Possible Applications.\n10 Femtosecond Laser Microfabrication of Photonic Crystals (Vygantas Mizeikis, Shigeki Matsuo, Saulius Juodkazis, and Hiroaki Misawa).\n10.1 Microfabrication of Photonic Crystals by Ultrafast Lasers.\n10.2 Photonic Crystals Obtained by Direct Laser Writing.\n10.3 Lithography by Multiple-beam Interference.\n11 Photophysical Processes that Lead to Ablation-free Microfabrication in Glass-ceramic Materials (Frank E. Livingston and Henry Helvajian).\n11.2 Photostructurable Glass-ceramic (PSGC) Materials.\n11.3 Laser Processing Photophysics.\n11.4 Laser Direct-write Microfabrication.\n12 Applications of Femtosecond Lasers in 3D Machining (Andreas Ostendorf, Frank Korte, Guenther Kamlage, Ulrich Klug, Juergen Koch, Jesper Serbin, Niko Baersch, Thorsten Bauer, Boris N. Chichkov).\n12.1 Machining System.\n12.2 Beam Delivery.\n12.3 Material Processing.\n12.4 Nonlinear Effects for Nano-machining.\n12.5 Machining Technology.\n13 (Some) Future Trends (Saulius Juodkazis and Hiroaki Misawa).\n13.1 General Outlook.\n13.2 On the Way to the Future.\n13.3 Example: “Shocked” Materials.\n13.4 The Future is Here.\nSaulius Juodkazis is Associate Professor at the Research Institute for Electronic Science at Hokkaido University, Japan. He received his Physics Diploma in 1986 from Vilnius University, Lithuania, and was later confered a lecturer qualification in Physical Sciences. In 1997, he received his Ph.D. in Physics and Material Science jointly from Vilnius University and l'Universitä laude Bernard in Lyon, France, on the structural and optical properties of CdS doped waveguiding sol-gel films. From 1994, he worked as a researcher at the Semiconductor Physics Department, currently Institute of Material Science and Applied Research, of Vilnius University, and from 1997 to 2000 carried out post-doctoral research at Tokushima University, Japan. His current interests include space-time-spectrum-resolved characterization of light-matter interactions in micro-domains, nano-photonics/plasmonics, laser tweezers, and applications of ultra-fast laser pulses. He has published and co-authored more than 90 scientific papers.""]"	['<urn:uuid:5105490c-335b-4fa7-a376-6174d3914df3>', '<urn:uuid:6274837d-bb44-42e2-960e-9f5adcb3869f>']	open-ended	with-premise	long-search-query	similar-to-document	multi-aspect	novice	2025-05-13T05:52:58.810667	19	97	2517
7	I've been experiencing pain in my hip and my doctor mentioned something about arthroscopy - could you explain what this surgery is and why doctors use it?	Hip arthroscopy is a minimally invasive surgery where surgeons use a tiny camera and instruments inserted into the hip joint. It has become more popular over the past 20 years and is primarily used to remove loose bodies (small pieces of broken cartilage) that move around inside the hip joint. Surgeons also use this procedure to treat labral tears, injuries to the cartilage of both the ball and socket of the hip joint, and femoroacetabular impingement. The surgery is typically recommended when nonsurgical treatments have failed and symptoms are disrupting normal daily activities.	['Contributing physicians in this story\nHip arthroscopy has gained in popularity over the past 20 years due to the minimally invasive nature of the surgery and the ability to address different types of disease or injury. Surgeons primarily use arthroscopic surgery (tiny camera and instruments inserted into the joint) to remove loose bodies, which are small pieces of cartilage (tissue that covers the ends of bones) that have broken off and then move around inside the hip joint. Surgeons also use this surgery to treat labral tears, injuries to the cartilage of both the femoral head (ball) and acetabulum (socket), and femoroacetabular impingement (Fig.1).\nThe hip joint is a ball-and-socket joint that connects the femur to the pelvis (Fig. 2). There are different elements in and around the hip joint that can be a source of pain, such as damaged cartilage and ligament (tissue connecting 2 bones) tears. When the physician evaluates a patient, it is critical to determine whether symptoms are intra-articular (coming from within the joint itself), or extra-articular (around the joint). For conditions that arise within the joint, hip arthroscopy can be a possible solution to address these problems.\nDiagnosing hip pain\nYour physician will complete a thorough physical exam, record your health history, and order x-rays to determine the cause of your hip pain. X-rays are a good tool for evaluating the bony structures around the hip joint. Most patients with suspected intra-articular disease who do not have obvious arthritis on x-rays will also undergo a magnetic resonance imaging (MRI) scan. A MRI is especially useful to evaluate the soft tissue structures around the hip, such as the cartilage, labrum, and tendons, which may be injured.\nIf you have no mechanical symptoms, such as catching, popping, or a clicking sensation in your hip, your physician often begins with nonsurgical treatment. Nonoperative treatments can include resting the joint if you are involved in regular exercise or athletic activity, anti-inflammatory medications, physical therapy, and steroid injections. If these treatments fail to alleviate your pain and you continue to have difficulty either walking or standing, your physician may recommend hip arthroscopy.\nYour physician will discuss arthroscopic surgery with you if nonsurgical treatments have failed and your symptoms disrupt your normal day-to-day activities. Surgeons perform hip arthroscopy under general anesthesia and routinely use a special table to allow distraction (a gentle separation) of the ball from the socket to access to the intra-articular structures. Two common hip injuries treated arthroscopically are femoroacetabular impingement and labral tears (Fig. 3).\nFemoroacetabular impingement (FAI) is a disorder of the hip in which the femoral head and neck rubs or “impinges” on the acetabulum. There are 2 types of FAI: cam impingement refers to a femoral-based disorder and is often seen in young athletic males and pincer impingement refers to an acetabular or socket-based disorder usually seen in active, middle-aged women. For both of these impingements, pain results from the proximal, or top of the femur abutting the acetabulum during range of motion, especially while bending. Patients often present with symptoms that include activity-related groin pain, difficulty sitting, and mechanical symptoms that includes a catching, clicking, or popping sensation during movement. If your physician suspects FAI, he or she will order x-rays to determine the shape and contour of the femoral head and neck as well as look for any abnormalities of the acetabulum. Your physician will also order a MRI to evaluate further the soft tissue structures in and around the hip.\nAt the time of arthroscopic surgery, the surgeon introduces the arthroscope into the hip joint to perform an initial diagnostic examination. Once inside the joint, the surgeon will look for disease or damage, such as cartilage defects of the femoral head and socket, loose bodies, and tears of the labrum.\nThe labrum is a horseshoe shaped structure that lines the outer rim of the hip socket. It is made of fibrocartilage and dense connective tissue. Sometimes when femoroacetabular impingement occurs, the labrum is torn. This tear can lead to pain during movement and you may experience catching, snapping, or locking. You may also feel a vague pain in your groin. If your doctor suspects a labral tear, as with FAI, you will undergo a MRI of the hip for further evaluation to confirm the diagnosis.\nThere are 2 main treatments of labral tears in regards to hip arthroscopy, labral debridement and labral repair. Labral tears not amenable to fixation are usually debrided, or trimmed back, to a stable base to the point that the unstable piece of torn labrum no longer causes symptoms. Your surgeon will remove any inflamed tissue in the hip joint and address any other underlying problems during surgery as well. This usually involves shaving some bone off the femoral head-neck junction as well as the hip socket so the bones do not rub against one another.\nA labral repair often involves attaching the labrum back to its original site with the use of specialized anchors and sutures. Postoperatively, patients use crutches to aid in walking and are restricted to limited weightbearing and limited hip bending for approximately 4 to 6 weeks while the labrum heals.\nHip arthroscopy for either FAI or labral tears is not without complications, although the complication rate is low. Complications reported with hip arthroscopy occur at a rate between 1.3% and 6.4%. Most complications are minor and are often self-limiting, but there are several major complications that have been described in hip arthroscopy that the patient should be aware of. These include traction neurapraxia, where there is a temporary loss of motor and sensory function of nerves surrounding the hip. This occurs when traction is placed on the operative leg to help distract the hip joint in order to gain access for the arthroscope. This often resolves soon after surgery and most patients have a complete recovery. Damage to major nerves and blood vessel structures around the hip joint can also occur. Additionally, damage from instrumentation can happen; but with proper positioning and technique, the incidence of this complication is low.\nOn the mend\nAfter surgery, you will be given instructions to follow for the weeks and months following surgery, including returning to see your physician for follow-up to see how you are progressing. Some of these instructions will include how to care for your portal sites and when you can shower or submerge the incisions in water. Additionally, you will be give crutches to use. Depending on the extent and type of repair, you may be on crutches for days, weeks, or months. When the hip has begun healing and the time is appropriate, your physician will refer you to rehabilitation. You should follow your rehabilitation program as instructed at the physical therapist’s office and at home. Physical therapy is a part of your treatment; therefore, you should adhere to the rehabilitation regime to achieve your best possible range of motion and functional outcome.\nHip arthroscopy can be an effective procedure and the risk of complications is low, although they do occur. Most patients are pleased with their outcomes and have resolution of symptoms, which allows them to get back to a more active lifestyle.\nAuthor: Garland J. Gudger, Jr., MD | Columbus, Georgia\nLast edited on October 18, 2021']	['<urn:uuid:0df33e08-4a9c-4765-b63e-49cee223d707>']	open-ended	with-premise	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-13T05:52:58.810667	27	93	1208
8	I'm trying to prevent lawn diseases - what should I know about soil testing and fertilization, and how do these practices affect disease development in my lawn?	Soil testing is crucial as it can save time, money and prevent environmental stress. It's a free service through the North Carolina Department of Agriculture that helps determine proper fertilizer and lime amounts instead of guessing. Regarding disease prevention, proper fertilization is critical - over-fertilizing can actually make diseases worse. For cool season grass, use slow release nitrogen in spring and keep amounts moderate. Healthy vigorous turfgrass better resists diseases than unhealthy grass, while stressed and weakened grass from poor soil conditions or improper maintenance is more susceptible to diseases.	"['Gardeners should make resolutions, too\nHave you made your New Year\'s resolutions?\nThe annual gesture of self-improvement and moderation often fails quickly with the new year. Below are some resolutions that will improve the horticultural skills for home gardeners in Rowan County.\nHave your soil testedSoil testing is the most often overlooked service that can save time, money and undue stress to the environment. Most homeowners guess as to how much fertilizer and lime to put on lawns, shrubs and vegetable gardens. Soil sampling is a free service provided by the North Carolina Department of Agriculture. Soil sampling kits are available at the Extension Center. A soil samples can be mailed to Raleigh for less than $1.\nHave a plan\nImpulse buying and planting without a plan can produce nightmares later as the landscape develops. Overgrown plants, improperly spaced plant material, diseased, or non adapted plant material are typical problems associated with impulse planting. Solicit the help of reputable and qualified nurserymen or landscapers before initiation of a landscape planting.\nTry different varieties\nHome vegetable gardeners and flower gardeners often plant the same varieties each season. While it makes sense to ""stick with a winner,"" there are new varieties of vegetable and flowers that warrant a homeowner test. All-America Selections are usually a good choice, whether it\'s a vegetable, fruit or flower selection. Be sure to correctly label new varieties and make notes about growth, development and other pertinent characteristics during the growing season. These notes will be instrumental in selection of next season\'s crop.\nTake time this winter to maintain power equipment with an oil change or tune-up if needed. Sharpen mower blades. Sharp blades reduce engine wear and will improve the turf\'s appearance, reducing the incidence of disease. Jagged leaf blades look bad and increase incidence of foliar disease problems. Replace all seals and gaskets in hand pump sprayers now so you will be ready when the pests of Spring arrive.\nWatch the calendar\nLabel the calendar for gardening chores that must be done and follow them. Bulbs must be planted in October, pre-emergence weed control must be applied before March 15, the lawn is to be fertilized in February and September, etc. Some of ""the windows"" for these activities are quite narrow and must be followed in order to have a successful growing season. Keep this calendar handy for quick reference.\nCarry out an IPM program\nIntegrated pest management programs mean you should scout for insects and diseases on a routine basis. Can you live with the problem? Use pesticides only when needed.\nPrune for a reason\nMany homeowners prune fruit trees, vines and shrubs because ""it\'s the season to prune"" and for no other reason. Know why apple trees are pruned to a central leader and peach trees are pruned to an open vase shape. Correct pruning techniques can increase yields, produce better quality fruit and reduce pesticide sprays. Correctly pruned shrubs will produce more flowers and berries. Judicious pruning is mandatory for quality fruits and healthy shrubs.\nStart a file of garden tips and informationFile away bits and pieces of useful information. My neighbor has a file of information on successful rose pruning and bulb forcing techniques.\nThis is information she will need to be successful with these annual endeavors. Make the file readily accessible to periodically update or delete out-of-date information. Have it near the ""to do"" list.\nDarrell Blackwelder is an Extension Agent in horticulture at the Rowan County Center of the N.C. Cooperative Extension.Call 704-216-8970.', 'Cool Weather Lawn Diseases\nof Spring and Fall\nLawn diseases can be very troubling and even the best lawns can be affected. Many diseases begin in the cool weather of spring and fall. Knowledge is the key to preventing disease. This page gives specific information on cool weather diseases, how and when they start, and how to treat them.\nDiseases are common with virtually all grass types. Although they are naturally occurring, how damaging they are can depend greatly on how we manage our lawns.\nWe know that lawns must be carefully maintained. However, if done improperly, we can actually predispose our grass to diseases. Proper cultural practices that hinder disease development is your first line of defense against lawn diseases.\nMicroscopic living organisms are the cause of lawn diseases. They include bacteria, fungi, nematodes, phytoplasmas, and a few other organisms. However, pathogenic fungi are the cause of most lawn diseases. These fungi can remain dormant in the soil until environmental conditions favor an outbreak. Lawn Diseases can also be distributed by wind, splashing rain, foot traffic, equipment, etc. Since these fungi lack roots, stems, or chlorophyll, they get their nutrients from their host.\nPathogenic fungi penetrate the host plant when conditions favor the disease. An important note in diagnosing diseases is that an infected plant will display specific symptoms and damage characteristic of that particular pathogen.\nThree conditions must be met before lawn diseases can begin.\n- There must be a pathogen present in and around your soil.\n- Your grass type must be susceptible to that specific pathogen.\n- The environmental conditions must be right for the disease to develop.\nThe most important of these is the environmental conditions. It is an almost certainty that pathogens are constantly present in your soil. However, it is a necessity for the environmental conditions to be correct before anything will happen. Your best defense against lawn diseases is to perform cultural practices that discourage them. Read the section on\nMaintaining your lawn to Discourage Disease\nBelow are specific disease profiles of common cool weather diseases.\nHelminthosporium Leaf Spot and Melting Out Disease\nLeaf spot is a disease that appears during cool, drizzly, moist spring weather. Heavy, wet dews, high humidity on overcast days, watering at night, and frequent rain will encourage disease growth.\nThe disease over-winters in thatch, soil, or in lesions of infected grass. Just as soon as environmental conditions are right, the disease will appear.\nIn cool season grasses, helminthosporium leaf spot is a problem for all grasses. Tall fescue, Kentucky bluegrass, and ryegrass are most affected.\nIn warm season grasses, bermudagrass is most affected, although all warm season grasses are able to get the disease. Different species of the fungus will attack different types of grasses.\nThe disease has two stages. The first stage is the “leaf spot” stage. Small, purple spots appear on the grass blade. The spots vary in size from 1/32 to ¼ inch depending on the grass type affected. As the spots expand, the center of the spot becomes tan, but the outside edges will remain purple. The larger spots take on an hour glass appearance.\nThe second stage is the “melting out” stage. It occurs when the environmental conditions that favor the disease persist and the disease spreads to the grass crown. When that happens, the disease enters the melting out phase and the grass dies.\nThe leaf spot stage is less serious of the two. If while in the leaf spot stage, the environmental conditions change becoming drier, the disease will usually stop and the grass will grow out of it. If conditions remain the same, the grass will turn yellow to orange and die from the tip down.\nCultural Practices that Discourage Disease\nDo not over-fertilizer the grass. Be especially careful in early spring if you have had problems before. Succulent grass will only feed the disease making it worse. For cool season grass, use slow release nitrogen in the spring while keeping the amount per 1000/sq.ft. on the lean side. Do not starve the grass, however, but follow a balanced fertility program.\nFor warm season grass, do not fertilize before the grass breaks dormancy. It is best to wait until the temperatures warm significantly before the first application goes down. Do not fertilize in the fall since the disease can return in the cooler weather.\nMoisture is very important to the onset of the disease. Try not to irrigate unless the grass needs it. Also, do not irrigate in the evening or at night. Rather, water in the early morning when the dew is still on the grass. If you water after the dew has dried in late morning, it only extends the amount of time the grass and soil is wet.\nIf you have experienced disease problems before, removing heavy dew is important before disease symptoms appear. Use the hose or sprinkler to wash off the dew. Just a quick blast of water will do it. This washes off the guttation fluid (sugar secreted onto the grass surface) as well. This sugar is a food source for leaf spot and many other pathogenic fungi.\nDragging a hose over the grass is also effective in removing dew. Golf courses have practiced this for many years.\nHerbicide Use During Disease Activity\nAvoid the over use of herbicides during disease activity. If you need to spray for weeds, spot spray only. Dicamba, 2,4-D and other herbicides have been known to encourage leaf spot and other lawn diseases.\nFungicides are not needed if the disease doesn’t progress past the leaf spot stage.\nIf you believe that fungicides are warranted, they must be applied as soon as symptoms are observed. Once the disease reaches the crown, it grass affected will die.\nProducts such as Heritage, Compass, Disarm and Insignia are labeled for use on lawns. Be aware that fungicides containing “Chlorothalonil” is no longer labeled for lawn use at the time of this writing.\nRead the product label carefully and completely before use. Fungicides can be difficult to apply correctly and safely. Timing of the application is important. If you are uncertain about how to apply it after reading the label, check with the county extension office for further help. You may want to hire a licensed professional with experience in lawn diseases to apply the chemical for you.\nSpring Dead Spot\nSpring Dead spot is one of the most damaging disease of bermudagrass. There are a number of fungi that may cause the disease, but in the U.S. it is Leptosphaeria Korrae and Ophiospharella herpotricha. The disease generally attacks mature bermudagrass lawns that have been established for over three years.\nHealthy vigorous turfgrass better resist diseases than unhealthy grass. The most susceptible grasses are those that are stressed and weakened from growing in poor soil, has been poorly maintained, or when growing outside it climate zone.\nHow the Disease Operates\nThis lawn disease actually begins in the fall, but the evidence of the disease doesn’t appear until spring. In the fall, when the soil cools to 80 degrees, the disease becomes active and infects the roots. The disease in not noticed because the grass will soon start to go dormant. When spring approaches, the disease progression speeds up. The roots are not able to take up nutrients or break dormancy and the grass quickly dies.\nThe disease is noticed in spring as the grass is breaking dormancy and greening up. You will notice patches of grass that look sunken and have a dead, whitish look. (A different look from healthy dormant grass.)\nThe patches of dead grass are circular ranging from 6 inches to 3 feet in diameter. They will often coalesce leaving larger, more irregular shaped patches. The patches are dead and cannot be saved.\nEventually the grass will spread into the damaged area, but it will continue to have problems.\nCultural Practices that Discourage Disease Development\nIf you have had problems with the disease before, it is important to maintain potash (K) levels in the soil. (K) or Potash is also referred to a Potassium, represented by the third number on a fertilizer bag. Even small deficiencies in K lowers the grass’ resistance to the disease. Even if a soil test shows the level to be adequate, you still need to apply 1 lb of potash per 1000/sq.ft. to soil. However, not more than a pound per 1000/sq.ft. should be applied at one time. You can purchase fertilizer that contains only Potassium. It will look something like 0-0-15. The last number will depend on the percentage of K in the bag.\nMaintain the soil pH at 5 to 5.5. No one knows exactly why this helps, but it does. Either the grass’ resistance is raised or microorganisms that are antagonistic to spring dead spots are more active at that pH range.\nRaise the mower blade. Higher mowing heights means deeper roots and more blade for carbohydrate production. It may provide enough resistance if disease pressure is low.\nKeep thatch to acceptable levels of ½ inch. Use a dethatching machine if you have severe thatch problems. Annual core aeration works well to keep thatch levels within a desirable range.\nThis is one of the times when applications of ammonium sulfate fertilizers to help speed recovery of damaged areas. Make sure you water the fertilizer in directly after application to avoid burning the grass. Studies have shown that the grass responds better with ammonium sulfate than when using urea based nitrogen. In addition, the ammonical fertilizers do not remain in the root zone for as long as coated urea products. This is important because you want the nitrogen to be used up when fall approaches and the disease becomes active again.\nDo not use fertilizer containing ammonium nitrate, however. Ammonium nitrate is not the same thing as ammonium sulfate and will will not give you the desired results.\nSeveral fungicides are labeled for spring dead spot. However, university tests have shown that fungicides are not always successful in controlling this disease. Some products displayed no noticeable results at all. For other, results were inconsistent at best. If you do use a fungicide, it must be applied in September or when temperatures dip below 80 degrees. It must be applied as the disease activity begins.\nFollow label directions completely. If you are not having good results or having difficulty applying the product, remember that commercial applicators have access to fungicides and equipment that are not always available to homeowners.\nRed Thread and Pink Patch Diseases\nRed thread and pink patch are lawn diseases that often occur together. A variety of grass types are affected including Kentucky bluegrass, fine fescue, ryegrass and bentgrass. The fine fescues and ryegrass may be the most severely affected.\nThis lawn disease is one of the easiest to identify. The late stages of red thread lawn disease produces a network of bright pink to reddish color fungus with a thread-like appearance. On cool, damp mornings, the lawn fungus covers the grass with a pink, gelatin like mycelium. Pink patch develops a gelatinous, pink fungus on the grass.\nThe lawn disease attacks grass that is low in nitrogen. Their development favors cool, wet spring and fall weather. you will often see them during extended periods of damp, drizzly, overcast conditions. This disease has also been known to appear as snow is melting in winter. Mild winters will generally see more occurrences of the disease than harsh winters.\nThe disease over-winters in in thatch and organic lawn debris. The following spring as temperatures reach 65 degrees the disease becomes active. Moisture is important for the disease to spread. Prolonged dampness from rain, dew, or irrigating in the evening or at night accelerates the disease activity.\nOnce the disease starts, it can be easily spread by mowing. Collecting the grass clippings and disposing of them may slow the disease. Animals or people walking across the lawn can pick up and deposit the lawn fungus in other areas.\nCultural Practices that Discourage Disease Growth\nBe sure to maintain proper nitrogen levels in the turf. The disease doesn’t usually attack healthy grass. Lawns that are low in nitrogen will be the most severely affected.\nDon’t over-fertilize or you will predispose your grass to other lawn diseases, such as leaf spot.\nRed thread usually isn’t a serious lawn disease and fungicide use isn’t recommended. If you properly maintain your lawn with sufficient nitrogen you will have few problems.\nClick on the\nfor help in developing a fertility program.\nPowdery mildew isn’t usually a serious lawn disease. It looks a little worse than it actually is. The grass will look as if someone dusted it with a white powder. If you touch the blade, the powder will easily brush off.\nIt is primarily a lawn disease that grows in light to heavy shade. The most commonly affected is Kentucky Bluegrass, but fescue can also get the disease. The disease occurs when temperatures average 60 to 70 degrees during the cool, humid weather in spring or fall.\nPowdery mildew lawn fungus will not invade the crown or roots, but remains on the blade surface. However, the fungus produces structures that will pierce the grass’ outer leaf layer to draw nutrients. It does not attack as aggressively as other diseases. The biggest problem may be that the heavy coating of white powdery mycelium blocks the sunlight and prevents photosynthesis from taking place. If the powder remains, the leaves will turn yellow and could die back.\nConditions that Promote The Disease\nThis lawn disease grows in the shade during cool, humid spring weather. It doesn’t need heavy dew conditions to germinate like other lawn diseases. It is most severe under shade trees or on the shady side of homes. Trees with a dense canopy and low hanging branches are prime candidates for powdery mildew due to reduced air circulation. The low hanging branches trap air and humidity, thus providing the right environment for disease activity.\nWhile the lawn disease is active, fertilization and excessive water may help accelerate the disease. The spores are spread to uninfected grass while mowing or from the splashing of water from rain or sprinklers.\nCommon varieties of Kentucky bluegrass are not considered to be shade tolerant. As the leaves fill the trees in spring, the grass weakens. In this weakened condition, the grass offers little resistance to disease growth.\nPrune low hanging limbs as well as limbs in the canopy to allow in more light and better air circulation. On shady sides of homes, over-seed the area with shade tolerant and powdery mildew resistant varieties. Shade tolerant varieties of Kentucky bluegrass include America, Bensun, Exlipse, and Glade. With these grasses you get two things in one: shade tolerance and disease resistance.\nIf problems continue, it may be necessary to remove the grass and put down mulch. Depending on the amount of shade, you can always experiment with shade garden plants instead of grass.\nUse fungicides as a last alternative. Some fungicides can be expensive, so you will have to compare the cost with the unsightliness of the disease. Contact fungicides are protective (preventative) and need to be applied before the lawn disease begins for best results. Fungicides applied after the disease has begun may have little or no effect. Examples of fungicides for powdery mildew are Clearys 3336F or Fungo Flo 4.5F Carefully follow all directions on the label. Other fungicides are also available.\nHot Weather Lawn Diseases\nThe dog days of summer can also being some of the most damaging disease. Click here for common summer lawn disease profiles, including how they start, recognizing disease symptoms as well as treatment options.\nCultural Practices that Discourage Diseases\nAre your maintenance practices weakening your grass? Stressed and weakened grass is more susceptible to disease. Using proven methods to care for your lawn is far more beneficial than you think.\nUnderstanding Lawn Fungicides\nNever used a fungicide? While cultural practices are the best way to prevent diseases, you may someday find it necessary to use a fungicide. Knowing what they are and how they work is important for successful disease control.\nUsing Herbicides Safely\nYour safety, the safety of your family and the environment should be your greatest concerns when using lawn chemicals. This page is loaded with valuable information about personal protective equipment, mixing, using and storing lawn chemicals.\nCool Weather Diseases back to Grass Diseases Introduction\nCool Weather Diseases back to Lawn Care Academy Home']"	['<urn:uuid:2c5523f1-064b-4ee2-9ee0-74c176b3da04>', '<urn:uuid:a171d0ce-889b-4982-9678-c8017530b515>']	factoid	with-premise	verbose-and-natural	distant-from-document	multi-aspect	novice	2025-05-13T05:52:58.810667	27	90	3323
9	differences between african modernity colonial times now development changes	In colonial times, Africa's engagement with modernity was significantly constrained by colonial powers, who implemented systems that prevented full modernization while claiming to bring modernity to Africa. The colonial system created contradictions between stated modernizing goals and actual practices that limited African agency and development. In contemporary times, many African countries have achieved higher economic growth and greater integration into global financial networks, moving from a low-growth equilibrium to higher levels with increased access to imported products and more citizens with disposable incomes. However, current development still faces challenges - while there is unprecedented growth in many countries, there are concerns about the lack of structural transformation into globally competitive economies, limited industrialization in manufacturing and agriculture, insufficient employment growth, and continued reliance on raw material exports rather than value-added products.	['Taiwo, Olufemi. How colonialism preempted modernity in Africa. Bloomington: Indiana University Press, 2010. Open WorldCat. Web. 7 Oct. 2013.\nDon’t think sociocryonics is going to catch on–it’s a bit of an awkward neologism that relabels a concept well established in Mamdani and others.\nBut otherwise, the intro and first section are really gutsy: they come straight at the problem and Taiwo is not afraid to characterize the literature in broad but cutting terms right at the outset.\nThe definition of modernity in the book as a whole is interesting and fairly clear, focused more on political and legal structures and their accompanying Enlightenment conceptual apparatus than on capital or political economy. “Subjectivity, reason and progress”.\n“One possible answer is to say that Africa is hostile to modernity and its presuppositions…a related response is to say that Africans are congenitally incapable of working modernity. Neither explanation is plausible. They are racist to boot. But their implausibility does not stem from their racism. The problem is that such explanations tend to ignore history.” p5\nThis is ultimately a rather West African (and Western Cape) centered history of missionary modernity-it doesn’t work very well for East Africa or Central Africa or the rest of southern Africa except for Xhosa and Tswana experiences. There’s a counterfactual here that the creation of “self-supporting, self-propagating and self-governing” mission modernity would have spread continent-wide had it not been for colonialism, and I’m not sure that holds entirely true.\n“What is crucial is that when Africans were inserted or they inserted themselves into the discourse of modernity, they ran the entire gamut of possible reactions. But the most sophisticated among them wanted to marry the best of their indigenous inheritance with the best that the new forms of social living enjoined by modernity had to offer. This is what exercising agency is all about.” p. 13 [The problem here is perhaps that Taiwo is assuming that in general modernity was embraced, adopted or practiced agentively–but it’s possible to say that this was not only not true in Africa but not true anywhere, that no one ever chose it but always instead had it done to them.\nContrary to Mamdani, sees colonialism’s contradictions as “genuine” and a product of its philosophical underpinnings.\n“In spite of all the prattle about communalism, not even the scholars who was eloquent about their commitment to so-called African values and traditions build their houses or live in spaces that pay any serious attention to those values and traditions…contemporary Africans end up with spaces and landscapes that are superficially modern but lack the enlivening soul that makes their counterparts in other places such beauties to behold and celebrate.” p. 14\n“The underdevelopment of African agency has contributed to the persistence of sociocryonics at the present time. Evidence of the persistence abounds in many of the recent accounts of the relationship between Africa and modernity that focus on such ‘peculiarly African’ themes as ‘witchcraft’ and ‘village’…We have repeated affirmations of African difference and an almost uncritical embrace of ahistoricity in their understanding and explanation of African phenomena. Many feel that to embrace things Western is to abandon African authenticity. It is no less a sociocryonic momemnt for being popular with African scholars.”. p. 14-15\n“I assume that the modern way of life represents a leap forward in human history and that the gains it offers, had they been on the table in colonial Africa, would have made for a better life and a more salubrious history than that bequeathed by colonialism as it operated in Africa. This is an acknowledgement that Africans are almost forbidden to make.” p. 16\n“We shall see the inevitability paradigm that often characterizes the discourse of colonialism in Africa–things could not have turned out otherwise than they did–is inadequate, if not wrong. The key lies in showing the intimate even if conflicted connection between colonialism and the much larger complex from which it emanated: modernity.” p. 23.\n“The modern era is the era of subjectivity, of the sovereignty of the individual, of no taxation without representation, of knowledge, of progress, of science and technology, and, most of all of the equality of human beings and of their entitlement to respect for the dignity of their person and all that pertains to it.” p. 39\nSome clear connections here with Appiah’s approach to cosmopolitanism. Also a clear riposte to the “multiple modernities” literature: modernity is one thing, it’s an outgrowth of the Enlightenment project, and it is both material and intersubjective.\nLugard once again functions as the exemplar of ‘indirect rule’ (aka in Taiwo ‘sociocryonics’).\nNot necessarily much clearer than Mamdani about the motives or intent behind colonialism, but at any rate neither analysis really takes much interest in the classic view of colonialism as motivated by the self-interest of globalizing capitalism, etc. Does dovetail on Mudimbe a bit in asserting that Africa was in some absolute sense defined by difference not just from Europe but from all other colonies/non-Western persons. That inevitably is going to lead you back into an assertion of European difference–that Europeans had a particular prior way of imagining blackness and black subjects.\nIn some ways this is also a repudiation of the Non-Aligned Movement/Bandung/postcolonial theory/etc. assertion of an essential similarity between “the Rest” (vs. “the West”) in the expansion of Europe.\nDespite the limits of taking coastal W. Africa in the 19th Century as a proxy for the continent, the argument Taiwo makes about missionaries and modernity is really bold and exciting stuff. Even where it’s “wrong”, I can really see it pacing a serious revival of 18th/19th Century African history, which is often mired in the grinding aftermath of the numbing empiricism of the literature on the slave trade.\nThe arguments about law and constitutionalism in the later part of the book feel to me like something of a detour. I understand why he goes there (not the least because it’s part of his training and his past scholarly work) but it’s a plodding discussion by comparison with the exciting writing in the earlier part of the book. I also think in some ways the most subversive argument in the existing literature that he needs to deal with is not nationalism/Afrocentrism (which he is clearly poised to critique) but the growing tendency to break down or decompose the power of the colonial state and to question the degree to which “sociocryonics” was a totalizing system. (He may not agree with Mamdani on much but on this point they actually align.) The last chapter on globalization, on the other hand, is really subversive and interesting.', 'By Richard Joseph\nOn March 10, 2014, I gave a lecture on this topic to a large audience at the University of Ghana, Legon, sponsored by the Department of Political Science. It was followed by a seminar presentation at the Ghana Center for Democratic Development on March 13 on the related topic of “Development without Democracy in Africa: Confronting the Revisionist Paradigm”. The text of the lecture is provided here along with a video of the second talk. They should bring these debates to a wider audience and encourage examinations of the diverse outcomes of Africa’s political and economic abertura.\nThere has been good news in recent years about Africa that match reports of violent militias, ethnic and religious conflicts, complex humanitarian emergencies, and deaths by drowning of persons fleeing the continent. The new drumbeat about sub-Saharan Africa is the unprecedented growth that has now lasted over a decade in many countries. But there is a darkening cloud. Alarms have been sounded by economists who do not see a pattern of structural transformation into globally competitive economies, the increase in industrialization in manufacturing and agriculture and corresponding employment growth, and a shift in the composition of exports to more value-added products.\nStarting from a low-growth equilibrium that persisted for decades, many African countries have moved to a higher equilibrium with access to imported products for a larger percentage of the population, more citizens having disposable incomes and thus providing attractive markets for importers and providers of fast-food and cellphone services. As long as foreign aid inflows are maintained, revenues continue from the export of natural minerals and remittances from overseas Diasporas, a better life could be achieved by more people and affluence by an enlarged elite stratum.\nTwo lines of criticism have converged, however, regarding the political economy of contemporary Africa. The first is by senior economists, such as Joseph Stiglitz and Justin Yifu Lin, both former World Bank chief economists, and the second by Africa scholars and social scientists associated with the Overseas Development Institute (ODI) in London and other European research centers.1 Their core arguments can be summarized\n- The liberalizing and democratizing of much of sub-Saharan Africa since 1989 have resulted in political systems in which competition for political office and access to state resources take place via “competitive clientelism”. The “political settlements” of post-abertura Africa involve reconfigurations of power that have yielded a more stable geo-political environment with a handful of democratized polities and a preponderance of electoral or competitive authoritarian systems.\nImprovements in the macro-economic framework, and the inclusion of more capable technocrats in finance ministries, have yielded governments more adept at dealing with external aid officials and foreign investors. Africa is no longer marginalized from global financial networks as it was a quarter century ago.\nStill to be adequately explained is Africa’s growth spurt which is now of unprecedented duration including surmounting the global economic recession of 2008-2010. Much of this growth is attributable to the global commodity boom linked to the huge demand for raw materials of a rising China. Yet there is more to it than that.2 Despite the increase in per capita GDP, what the critics contend is that a different political and economic strategy is needed to achieve structural transformation of these economies that mirror the achievements of East Asian economies.\nThe key recommendation is the adoption of industrial policy strategies in which government plays a directive role in economies, implementing long-term approaches, controlling and managing the allocation of rents especially from foreign aid and mineral exports, and favoring firms that can increase domestic production and capture segments of external markets for new exports.\nDemocracy and good governance practices that include multiparty politics, constitutionalism, civil society advancement, human rights, and the array of enhanced freedoms of expression, assembly, and media, it is claimed, do not necessarily yield better governments and economies and may even detract from the pursuit of these objectives.\nOn the critical issue of the improved delivery of public services and goods, most African people are ill-served. Basic infrastructures of power, transport, and water are deficient. Health and education systems are often deplorable. The democratized countries have not produced a democratic dividend over their authoritarian counterparts in meeting these needs.\nBoth the development economists and the researchers of ODI’s Africa Power and Politics Programme (APPP) identify Rwanda and Ethiopia as alternative models of developmental governance.3 There is ideological reinforcement between the East Asian experience and the performance of these two African countries. China’s experiences hover over these debates. Its influence is seen in the model of authoritarian state capitalism, its extraordinary growth and development accomplishments, its non-judgmental attitude towards the internal politics of other countries, and its steady economic expansion in Africa.\nThe development economists show more flexibility, for the large part, regarding the desirable systems that can emerge in Africa. They are aware of the diversity of Asian experiences. The nature of the state is an unavoidable consideration. They hypothesize the emergence of developmentalist or facilitative states that may not replicate the developmental states of Singapore, South Korea, Taiwan, and China. Yet the economists do not grapple adequately with the deficiencies of African states. Some, such as Ha-noon Chang and Mushtaq Khan, argue that Asian economies were characterized by the same prebendalist and sub-optimal practices as contemporary African countries prior to their economic transformation. The APPP researchers are, however, too knowledgeable about government and politics in Africa to advance simplistic proposals regarding their likely transformation.4\nThe Case of Ghana\nWhere does Ghana fit into this scenario? On March 7, the Wall Street Journal published a front-page article on Ghana’s mounting economic dilemmas.5 It is insightful to note how Ghana’s economy is trending towards consumption rather than production. The boom in commercial and private construction is unmatched by advances in the power sector and the transport network. The article quotes President John Mahama concerning the over-reliance on imports.” “We’ve become,” he said, “a country that even imports toothpicks.”\nA power outage in the home of my son, Mark Joseph, who is a Visiting Scholar at the University of Ghana, Legon, prompted the use of matches to light candles. The box of matches showed that it was manufactured in Sweden. Why in 2014 does Ghana have to import matches from Sweden? Why, after almost six decades of independence, does Ghana have to import wooden matches from Scandinavia which has the most highly industrialized economies and standards of living in the world?\nThirty-six years ago, I published an article entitled “Affluence and Underdevelopment: The Nigerian Experience.”6 After 18 months as a lecturer in political science at the University of Ibadan, I did not see a salutary growth path. There was a great deal of consumption of imported products paid for by petroleum export revenues. However, I didn’t see those rents being invested in building a more productive economy. One of the achievements of the 1975-1979 reformist military regime was the passage of the Indigenization Degree which compelled foreign companies to transfer ownership shares to Nigerians. In retrospect, given the imperatives of a globalizing economy, of enhancing international trade and investments, it turned out to be a well-meaning but misguided policy. Not transferred along with the shares, captured by elites, was the capacity and norms to build growth-enhancing companies.\nWe know what a mess Nigeria has made of its petroleum wealth, the spendocracy that has emerged, the prebendalist practices that have spread throughout the government and society eroding institutions and behavioral norms.7 What model is Ghana following? The revisionists contend that while Ghana has achieved wider political and social freedoms, it is not laying the basis for the accelerated and inclusive growth that enabled South Korea to outstrip it over the past half-century. Instead of going from third world to first world, mirroring Korea and Singapore, Ghana seems to be settling into a 2.5 rut: a better performer than many of its African counterparts but not building a globally competitive economy despite its abundant advantages.\nTim Kelsall in his book, Business, Politics and the State in Africa, recognizes that Ghana cannot follow the developmental patrimonial models of Rwanda and Ethiopia.8 Yet he and his fellow revisionists do not take sufficiently into account the enormous political good of a constitutional democracy achieved by Ghana and other countries. Some of Kendall’s reform suggestions for Ghana are pertinent: reducing the swings of electoral politics on macro-economic strategies by giving more power and authority to independent regulatory agencies such as the Central Bank, and creating non-partisan instruments that sustain long-term policy commitments that transcend political party lines.\nThese solutions, I contend, are not radical enough. In my paper, “Industrial Policies and Contemporary Africa”, I cite the important work of Bo Rothstein and his colleagues of The Quality of Government Institute of the University of Gothenberg, Sweden. They draw on not only the 20th century experiences of the East Asian Tigers, but the late 19th century transformation of the Nordic countries from highly prebendalized systems to the productive, inclusive, and uncorrupt political economies of today.9\nTo break the bonds of what he called “supremely corrupt” and low-performing societies, Rothstein proposes a “big bang approach”. Francis Fukuyama also cites the transformation of the highly prebendalized system of pre-revolutionary France, and the transmission to much of Europe of law-based governance by Napoleon while lopping off the heads of the recalcitrant.”>10 I propose a less violent approach but one which must be revolutionary in its impact.”>11 I refer to it as a “macro-institutional rupture” using the nearby example of Lagos State of Nigeria in which successive governments led by Governors Bola Tinubu and Babatunde Fashola have succeeded in bringing about fundamental changes, within a democratic framework, that the late Meles Zenawi of Ethiopia, and Paul Kagame of Rwanda, have effected via highly autocratic means.\nI suggested that there were four components to this transformation: leadership, institutions, culture, and resources. Moreover, in the second paper in this series, “Inclusive Growth and Developmental Governance”, I advanced the idea of “African workshops of developmental governance”. The notion of “workshops” is adopted from Richard Sklar who applied it to democracy-building in Africa in a seminal 1983 article.”12 Ghana is today finely balanced between progress, regress, and stasis. It can be shifted onto a different growth path, one characterized by the sustainability, inclusiveness and transformation advocated by development economists.\nGhana has been a leader in Africa at several critical junctures. It was at the forefront of two prior liberations in Africa: from colonial rule in the 1950s, and from authoritarianism and flawed economic strategies a few decades ago. Over the next decade, Ghana can be the site of Africa’s Third Liberation, one that will not be based on armed struggle and minority ethnic bases as has been the case in Ethiopia and Rwanda. It will need leaders committed to this vision and equipped with the political and other skills to realize them. It must build appropriate institutions and institutional practices and sharply reduce current corrupt intra- and inter-institutional practices.\nOne of the great resources of Ghana is its political culture. It has enabled the country to undergo major transformations with relatively few physical casualties. At a time when a number of African countries, included neighboring ones, have been ripped apart by ethnic and religious conflict, Ghana has achieved an extraordinary degree of social accommodation. It has gone to the brink in the last two national elections as the voting gap between the two leading parties has narrowed, but its people have pulled back from violent conflict. Absent, however, is a culture of developmental capitalism. I addressed this topic in my Kronti ne Akwamu lecture of the Center for Democratic Development on the occasion of the Jubilee celebrations, drawing notably on the writings of Peter Ekeh and Bruce Berman.”>13\nHow will the enormous financial resources now available to Ghanaians and others in the continent be used, especially in light of the abundant oil, gas and coal reserves being discovered? Nigerians look back at a half-trillion U.S. dollars in national revenues from petroleum exports and wonder where it all went. Will Ghanaians ask the same question a decade or more from now?\nMy fourth category, resources, is, in the case of Ghana not a critical concern. Rather, the question is how will these resources be managed? How will the leaders and citizens of Ghana buy into a decade-long transformation agenda? To prepare for this visit and talks in Accra, I reread my January 2007 lecture. Much of what I planned to say now was said then, and without the benefit of the work of the revisionists. Today, I come with a different frame of mind, comparable to the attitudes of 1989-1992 when I participated in Ghana’s transition to a constitutional multi-party democracy on behalf of The Carter Center. My contention today is that Ghana 2025, a Ghana characterized by inclusive growth and developmental governance, is achievable, but not without a macro-institutional rupture. How that will be effected will depend on Ghanaians themselves.\nI hope to contribute to these endeavors via my writings, both retrospective and prospective. Also needed is a consortium of institutions which, through research, publications, teaching, and policy collaboration, can advance a decade-long transformative process. We do not have full answers to the challenges. Collectively, as in the promotion of the Africa abertura, they can be acquired through praxis: theorizing, practicing, and absorbing lessons from practical endeavors to formulate new theoretical approaches. In view of all its advantages, if Ghana cannot play this pioneering role, I do not know which country will lead the way in a democratic Africa.\n- See Akbar Noman et al., Good Growth and Governance in Africa: Rethinking Development Strategies (Oxford University Press, 2012); Joseph E. Stiglitz, Justin Yifu Lin, and Ebrahim Patel, The Industrial Policy Revolution II: Africa in the 21st Century (Palgrave Macmillan, 2013); David Booth and Diana Cammack, Governance for Development in Africa: Solving Collective Action Problems (Zed Press, 2013); and Tim Kelsall, Business, Politics, and the State in Africa: Challenging the Orthodoxies on Growth and Transformation (Zed Press, 2013). ↩\n- See Stephen Radelet, Emerging Africa: How 17 Countries are Leading the Way (Center for Global Development/Brookings Institution Press, 2010). ↩\n- See, for example, Nicholas Kulish, “Rwanda Reaches for New Economic Model,” The New York Times, 24 March 2014. ↩\n- I have advanced these arguments in two book chapters: “Industrial Policies and Contemporary Africa: The Transition from Prebendal to Developmental Governance”, in J. E. Stiglitz et al., The Industrial Policy Revolution II, and “Inclusive Growth and Developmental Governance: The Next African Frontiers,” in Justin Yifu Lin and Célestin Monga, Oxford Handbook of Africa and Economics (Oxford University Press, forthcoming). ↩\n- Drew Hinshaw, “Heavenly Forex Intervention Sought”, March 6 2014. ↩\n- Journal of Modern African Studies, vol. 16, no. 2 (June 1978). ↩\n- See Wale Adebanwi and Ebenezer Obadare, Democracy and Prebendalism in Nigeria: Critical Interpretations (Palgrave Macmillan, 2013). My book, Democracy and Prebendal Politics in Nigeria: The Rise and Fall of the Second Republic (1987) was reissued by Cambridge University Press in February 2014. ↩\n- Development Patrimonialism is a term coined by the APPP group. See David Booth and Frederick Golooba-Mutebi, “Developmental Patrimonialism? The Case of Rwanda”, African Affairs, vol. 111, no. 444 (May 2012). ↩\n- See Bo Rothstein, The Quality of Government: Corruption, Social Trust, and Inequality in International Perspective (University of Chicago Press, 2011), and papers published by The Quality of Government Institute, University of Gothenberg: http://www.qog.pol.gu.se/\xa0↩\n- The Origins of Political Order: From Prehuman Times to the French Revolution (Farrar, Strauss and Giroux, 2011). ↩\n- See “Industrial Policies and Contemporary Africa”. ↩\n- “Democracy in Africa,” African Studies Review, vol. 26, nos. 3/4 (1983). ↩\n- “Ghana and Democratic Development in Africa: Back to the Future”, Accra, 25 January 2007. Kronti ne Akwamu translates as Democracy and Governance. ↩']	['<urn:uuid:050fcd85-29f6-4a98-ad45-d519675d4498>', '<urn:uuid:ea6a8044-e314-4023-8a26-6ed571373d57>']	open-ended	with-premise	long-search-query	similar-to-document	comparison	novice	2025-05-13T05:52:58.810667	9	131	3733
10	is it ok to play bird calls on phone app to attract birds near me	No, it is not okay to play bird calls in the field using apps or other means. Birds need to spend their time feeding their young and defending their territory. When birders play calls, birds get distracted from these essential tasks of feeding youngsters and defending against predators and rivals. This interference can be harmful to their survival and well-being.	['A while back I had a well-intentioned person contact me regarding a newly discovered eagles nest. “Don, the eagles are so excited to see me they are showing off by flying around the nest and screeching,” they said. As I tried my best to keep from creating my own ear-piercing sounds of stress I managed to calm myself down for a few seconds and asked the caller to PLEASE get away from the nest area.\nI attempted to explain that he was stressing the birds out and could possibly cause them to abandon the nest. His answer was “No, they really like us.” Now, besides this person being in violation of the Bald Eagle protection act , the Migratory Bird Treaty Act and various other state and federal laws, a simple understanding of the birding ethics rules may have just stopped him from committing this infraction to begin with. So I thought it was a good time to remind all of us that the first rule of birding. much like the Hippocratic Oath, is to do no harm.\nAs we enter the most amazing time in birding, nesting and migration season, birds more than any other time of year need to be protected and kept safe from needless stress especially ones that are brought on by humans, well intentioned or otherwise. Migratory birds as well as our year-round residents have it very tough. Window strikes, habitat loss, stray cats, lack of food and water sources, climate change, the list goes on. The last thing we want to do is to interfere with the lifecycle of birds that have fought so hard, through so many obstacles, and traveled so many miles to be the reason that it does not survive the day.\nBut there are a few simple things we can remember to avoid to be sure we and the birds have a good day outdoors for all concerned.\n- “Keep a safe distance when observing or photographing birds, especially near nests” – Getting too close and spending too much time near nesting birds can cause them to abandon the nest or cause the young to come out of the nest too soon. It also could interrupt getting enough food to their nestlings. Birds do not want to approach the nest if you are watching them. This is a way they avoid showing predators where their nest is, so keep a safe distance, take a look and move on quickly.\n- Avoid posting and telling people about the location of endangered species and where the nest of any bird may be located.”\n- This is especially true when it comes to threatened and endangered species and all owls. Owls are birds that need to rest during the day and hunt at night. It would be like me keeping you up all night and then expecting you to work all day .. it usually does not go well.\n- Avoid playing calls in the field.\n- Birds spend all their time feeding their young and defending their territory. If birders are playing calls birds will be not doing their job of feeding the youngsters and defending against predators and rivals. And besides, I don’t want to hear a call that makes me run down the trail just to find its another birder playing an APP. It won’t go well – I promise.\n- There are other rules too, like staying on designated trails, keeping your feeders and birdbaths clean and respecting public property …topics for another day.\nSpring is a wonderful and incredible time to be outside for all nature lovers, especially birders, by respecting our passion for birds and keeping in mind that the birds themselves are more vital than us getting a closer look or a perfect photograph. This will teach the next generation the right way to enjoy birding and that we are doing no harm to the future of birding and especially to the birds we love so much.\nFor more information on the American Birding Association’s Principles of Birding Ethics, go to http://www.aba.org/about/ethics.html']	['<urn:uuid:e461f396-a840-4075-8148-2905312b8674>']	open-ended	with-premise	long-search-query	similar-to-document	single-doc	novice	2025-05-13T05:52:58.810667	15	60	676
11	What are the main research interests of Alex Dranovsky and Tomohisa when it comes to understanding how the brain maintains its function over time - do they study similar aspects of brain plasticity?	While both researchers study brain plasticity, they focus on different aspects. Alex Dranovsky's research centers on how stressful and enriching experiences affect adult hippocampal stem cells and their production of neurons, particularly examining how these changes impact stress adaptation. In contrast, Tomohisa focuses on the long-term maintenance of neural identity and plasticity through studying cell type-specific nuclear architecture, with particular attention to the effects of pathological aging. Both are interested in long-term brain maintenance, but approach it from different cellular mechanisms.	"['Alex Dranovsky, MD, PhD\n- Associate Professor of Psychiatry at CUMC\nCredentials & Experience\nEducation & Training\n- State University of New York\n- Residency: New York State Psychiatric Institute\n- Residency: NewYork-Presbyterian Hospital/Columbia University Medical Center\nVirtually all mental and some medical illnesses are exacerbated by stress and alleviated by enriching experiences. Such experiences are thought to be causal or protective in cases of schizophrenia, anxiety/affective disorders, and substance abuse. Yet, the mechanisms by which experiences can confer or neutralize genetic risks for mental illness remain elusive. In a longstanding collaboration with David Leonardo, our lab is focused on deciphering how stressful and enriching experiences produce lasting changes in the postnatal brain, and how such changes can predict adaptive and maladaptive behaviors.\nOne major area of focus is the adult hippocampal stem cells. These stem cells are greatly affected by enriching and stressful experiences, producing more or fewer functional neurons. Thus, they are an ideal model system for studying the molecular, cellular, and circuit substrates for stressful and enriching experiences. Moreover, the hippocampal stem cell system provides a naturalistic setting for unraveling the molecular logic of neural stem cell renewal and differentiation. Through the use of inducible genetic manipulations in mice, in vitro cellular assays, transplantation studies, opto and chemogenetics, awake behaving in vivo recordings, and behavioral experiments we are exploring the mechanisms by which stressful and enriching experiences instruct stem cells to produce more stem cells or neurons in the adult hippocampus. Given the important role of the hippocampus as a modulator of the HPA axis, we are also examining the contribution of hippocampal stem cells and their progeny to how the animal adapts to stress.\nOur second major focus is the mechanisms by which certain postnatal periods are particularly sensitive to the effects of stress and enrichment. Different experiences during such “critical” periods result in especially sustained behavioral phenotypes, but underlying changes in the brain are poorly understood. We are using computational approaches to analyze microscopic images and videos of mouse behavior to explore how the hippocampal stem cell system and other circuits across the whole brain can encode experiences during sensitive periods to establish sustained behavioral phenotypes.\n- Cognitive/Systems Neuroscience\n- Models of Psychiatric Disorders\n- Neurobiology of Disease\n- Stem Cell Biology\n- Synapses and Circuits\nDonato F, Alberini CM, Amso D, Dragoi G, Dranovsky A, Newcombe NS. (2021) The ontogeny of hippocampus-dependent memories. J Neurosci, 41(5):920-926;\nYoussef M, Atsak P, Cardenas J, Kosmidis S, Leonardo ED, Dranovsky A. (2019) Early life stress delays hippocampal development and diminishes the adult stem cell pool in mice. Sci Rep, 9(1):4120\nLeonardo E.D., Dranovsky A. (2017) An opening for humor in melancholy. Nature Neurosci 20(12) 1657-8\nKirshenbaum G.S., Lieberman S.R., Briner T.J., Leonardo E.D., Dranovsky A. (2014) Adolescent, but not adult-born neurons are critical for susceptibility to chronic social defeat. Front Behav Neurosci 8:289\nDranovsky A., Leonardo E.D. (2015) Neuroscience: The power of positivity. Nature 522(7556), 294-5\nSahay A., Scobie K., Hill A., O’Carroll C.M., Kheirbek M., Burghardt N., Fenton A., Dranovsky A., Hen R. (2011) Increasing adult hippocampal neurogenesis is sufficient to improve pattern separation. Nature 472, 466-470.\nDranovsky A., Picchini A.M., Moadel T., Sisti A, Yamada A., Kimura S., Leonardo E.D., Hen R. Experience dictates stem cell fate in the adult hippocampus. Neuron 70(5) 908-23', 'Tomohisa\'s scientific work in one sentence\nOur laboratory aims at elucidating biological links between the fundamental mechanism underlying the long-term maintenance of neural identity/plasticity and effects of pathological aging on it, especially focusing on the cell type-specific nuclear architecture.\nFor more information click here.\nPhD: Neuroscience, 2011, The University of Tokyo\nCurrent Position: Group Leader ""Nuclear architecture in neural plasticity and aging"", DZNE-Dresden\nWhat are - in your opinion - your best publications?\nToda T, Hsu JY, Linker SB, Hu L, Schafer ST, Mertens J, Jacinto FV, Hetzer MW & Gage FH. “Nup153 interacts with Sox2 to enable bimodal gene regulation and maintenance of neural progenitor cells.” Cell Stem Cell, 21, 5, 618-634 (2017)\nToda T, Shinmyo Y, Duong TAD, Masuda K & Kawasaki H. “An essential role of SVZ progenitors in cortical folding in gyrencephalic mammals.” Scientific Reports, 6:29578. (2016)\nToda T, Homma D, Tokuoka H, Hayakawa I, Sugimoto Y, Ichinose H & Kawasaki H. “Birth regulates the initiation of sensory map formation through serotonin signaling.” Developmental Cell, 27, 32-46. (2013)\nWhat are your most important prizes and memberships?\nERC starting grant (EAGER) DZNE, 2019\nThe Paul F. Glenn Center for Biology of Aging Research Postdoctoral Fellowship, 2018\nResearch Fellowship for Research Abroad from Japan Society for the Promotion of Science, 2015\nSociety for Neuroscience\nThe Japan Neuroscience Society\n5 questions about research - past, present, future\n1. What are your primary tasks and responsibilities in your actual position?\nI have started my own laboratory last year, and spent about one year to set up the lab. Thanks to the great support from many people, our lab is now up and running. My primary tasks are to support/advice my lab members, to take care of house-keeping works, and to get additional grants. In my spare time, I do pilot experiments by myself to find next seeds.\n2. What is it that gives you pleasure and/or satisfaction the most?\nObserving unexpected results and find novel possibilities/theories. I also do like to see that my lab members propose to try new experiments or take responsibilities by themselves and when it works. This is very different from the post-doc stage, which mainly focusing on our pure scientific interests.\n3. Which research question(s) affects you at the moment? What is its social significance?\nThe main questions in my mind have not been changed very much since my undergrad. Why does our brain develop in a specific temporal manner? After brain development, how do we maintain our brain function and plasticity over 80 years, without replacing neurons in most of brain regions? These primitive questions still attract me to work in science. I would like to understand how these robust temporal regulations are organized to achieve normal brain development and healthy brain aging at molecular/cellular levels. I strongly believe that understanding these fundamental mechanisms will provide significant insights to find novel therapeutic means to treat psychiatric diseases or age-related neurodegenerative disease. Also doing “interesting science” will inspire the next generation who will lead science in the upcoming decades, therefore I am hopeful that our science is interesting enough to attract those kids.\n4. Which publication influenced you the most?\nIt is not by single publications, but I like the series of discovery about ocular dominance plasticity and the effect of maternal cares on epigenetic regulations. Both of them provide novel insights about the interaction between environmental cues and genes, which are fundamental process in brain development and plasticity.\n5. What do you like most about AMPro? What are your particular plans within the collaboration?\nIts interdisciplinarity is excellent. My expertise lies within neuroscience, but today, we need interdisciplinary approaches to conduct medical research. AMPro makes it easy to talk with people from different fields, especially epigenetics and metabolics to start new collaborations. Our lab has just joined, so hope it goes longer!\n5 questions beyond research\n1. What are your experiences with reconciliation of family or private and working life?\nThis is the most challenging part for new group leaders. To be honest, I do not prioritize so much about life-work balance and I spent a lot of my time at work because I need to get so much things done before starting science. I do care about my family, which is the most important point I learned from my post-doc mentor. But, at the same time, I do care about my lab and lab members.\n2. What is the experience during your PhD you will remember all your life?\nWhen I found a new phenomenon, in which the birthing process triggers sensory circuit formation of pups to adapt environmental changes from the inside of mother to the external world. The birthing process is the most dramatic environmental change in mammalian life, but it was not clear if this environmental change regulates brain development. Since then, I explored underlying molecular mechanisms and found that serotonin signaling is a mediator. I really enjoyed the process, and but it was quite tough experience too. Looking back from now, If I failed to find the underlying mechanism, I may not be here, so it was a turning point in my short scientific carrier so far.\n3. Which book and/or movie has lately affected you the most?\nNot particularly these days. I am bit saturated to find something new. But,” Brave new world” by A. Huxley is still my favorite since my junior high school.\n4. What are your hobbies?\nWatch rugby games and play rugby with my son. Try new beers.\n5. What is your favorite color, season and/or football (or other sports) club?\nGreen & blue, Summer-Autumn, and Japan national rugby team.']"	['<urn:uuid:385dc3aa-bced-4606-aabf-e1a679a5e21b>', '<urn:uuid:95b95563-3bc4-4893-a859-4f61c03513ee>']	open-ended	direct	verbose-and-natural	similar-to-document	comparison	novice	2025-05-13T05:52:58.810667	33	81	1485
12	What are the main characteristics of sperm whale ivory, including its color and where it comes from in the whale's body?	Sperm whale ivory comes from the teeth found in the lower jaw of the sperm whale. The teeth are between three to ten inches in height, and the ivory is typically mellow yellow in color with a distinctive inner ring to its grain.	"['Sperm Whale Ivory\nWhale Ivory is derived from the teeth found in the lower jaw of the sperm whale. These teeth range from three to ten inches in height. It was with this type of ivory that American Whale men created the first pieces of Scrimshaw. Whale ivory is usually mellow yellow in color and has a distinctive inner ring to its grain.\nAncient Mammoth Ivory\nThe Wooly Mammoth was a large Prehistoric creature which roamed the earth over 10,000 years ago. Resembling our modern elephant they had long shaggy coats and large curved tusks often exceeding ten feet in length. Now extinct, their remains are occasionally unearthed in the northern hemisphere with their long ivory tusks intact. Over the centuries, the ivory has taken on a variety of colors including tans and greys which gives each piece a unique quality.\nAfrican Elephant Ivory\nElephant ivory is derived from the tusk of the African Elephant. From 1976-1989 ivory was obtained from the elephants in National Parks which died of natural causes or were culled from the herds. Due to corruption in a small percentage of these parks, the U.S. put a ban on the importation of Elephant ivory in 1989. Currently we are able to work with ivory that was legally imported into the U.S. prior to the ban.\nAntique Walrus Ivory\nAntique Walrus ivory is derived from the tusks and teeth of the walrus which lived years ago on the frozen tundra of Alaska. The ivory lay buried in a variety of mineral deposits which slowly changed its color to a myriad of mochas, tans, browns, and blacks. Today it is unearthed by\nAntique Piano Key Ivory\nPrior to modern synthetics, piano keys were covered with elephant ivory cut to 1mm in thickness. This ivory is still useable when removed from the wooden keys. Once cleaned and buffed, this recycled ivory will show off a classic yellow patina which has developed over many years. We use piano key ivory in designs ranging from inlays on boxes to bookmarks.\nVegetable Ivory or Tagua Nut\nTagua nut is an ivory-like nut of a palm tree in South America. When sectioned, sanded and polished, its dense texture and mellow color resemble the fine qualities of ivory. Residents of Ecuador gather Tagua in the rain forest and it is later used in the manufacturing of buttons,\nSperm Whale Ivory - The Law:\nThe Sperm Whale is an endangered species protected by the Marine Mammal Protection Act; importation of whale products for commercial purposes has been prohibited since 1973. Pre-act whale teeth can be sold intrastate as long as state law does not prohibit it. Scrimshaw artists and collectors acquire pre-act teeth from estate sales, auctions, and antique dealers.\nAncient Mammoth Ivory - The Law:\nCommerce in this 10,000- 40,000 year old ivory is completely unrestricted.\nAntique Walrus Ivory - The Law:\nRaw walrus ivory predating the 1972 Marine Mammal Protection Act, tusks bearing the Alaska state walrus ivory registration tags, and post law walrus ivory that has been carved or scrimshawed by an Eskimo are legal to buy, posses, and sell. Commerce in the ancient or unearthed walrus ivory is unrestricted.\nElephant Ivory - The Law:\nElephant ivory has be regulated since 1976 and was allowed into the U.S. only from game reserves that followed the guidelines set forth by The Convention on International Trade in Endangered Species or CITES. Importing, buying, and selling African elephant ivory has not been allowed internationally since 1989. It is legal to own, buy, sell or ship ""estate"" ivory which was present legally in the United States before 1989.']"	['<urn:uuid:6b90fc88-11b5-4044-9eeb-4ec0e651fd73>']	factoid	direct	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-13T05:52:58.810667	21	43	602
13	I'm worried about forest fires. Are there ways to prevent them?	Yes, one effective prevention method is controlled burning, which is a forest management technique. It involves creating artificial fires to reduce fuel build-up in the forest, which decreases the risk of more serious fires starting accidentally later. Controlled burning can actually help renew the forest by stimulating the germination of certain trees.	['Controlled burning in an Amazonian forest. Photo by Daro Montag/ Cape Farewell.\nFormer Foyle Young Poet Helen Mort sets out her third poetry writing challenge, asking you to respond to images from Cape Farewell’s archive of photos, videos and blog posts.\nCape Farewell leads expeditions of artists, musicians, writers and scientists to places like the Arctic and the Amazon so they can see the effects of climate change close up and respond to it in their work. Now you can add your voice by writing in response to the challenges – and Helen will be choosing poets to publish on Cape Farewell’s SWITCH website and win some particularly exciting prizes…\nSometimes, you have to destroy part of something to keep it. Look at Daro Montag’s image ‘Controlled burning in an Amazonian Forest’, above. Controlled burning is a technique than can be used in forest management to reduce the risk of fires in the longer term. It uses an artificially-induced fire (fire is often a natural part of forest ecology) to reduce fuel build-up in the forest so that there’s less chance of a serious, hotter fire starting by accident later. Controlled burning stimulates the germination of certain forest trees, therefore helping to renew the forest. This might seem like a slightly contradictory idea at first – how can partly destroying something help to save it in the long term? Sometimes, a part has to be sacrificed for the benefit of the whole.\nThis can be true of writing a poem too. Sometimes you have to ‘kill your darlings’ and take out a phrase or word that you’d really rather keep but need to edit out for the sake of the overall poem. Before you work on this challenge, read these handy tips from Young Poets Network about re-drafting your work.\nWriting your poem\nHave a look at this poem on the Poetry Society website, which I wrote a few years ago. In your piece of writing, you’re going to make the fire talk about itself too. You might start off by making a list of answers to some of the following things: What will fire have to say? Is this a small, domestic fire in a hearth or is it a large fire in the open? Has your fire been started deliberately like the controlled burning in Daro’s picture, or is it an accident? What might fire think about the things it burns? What does fire feel like? Does it want to be here or would it rather be somewhere else?\nLooking at Daro’s picture, we can almost smell the distinctive, acrid scent of burning. Try and weave this sense into your poem, considering how fire would talk about this aspect of itself.\nWhen you’ve drafted your poem, you might go back to it with some of the redrafting tips in mind and think about which words are essential and which words you might edit out.\nIf you have time, you could go on to look at this image of ice by Carol Cotterill:\nUntitled image by Carol Cotterill/ Cape Farewell\nWe’ve already heard what fire has to say, so how about ice? This time, make the ice talk about itself. Where is your ice? What shape does it have, or has it changed shape? Does it remember what it was like to be water? Carol’s photograph focuses on the idea of tasting ice, so try and weave that into your poem – how does ice taste, or what does it taste itself, as it freezes over other objects?\nYou might like to submit two separate poems, or you might like to incorporate both fire and ice into a single poem, as Robert Frost does:\n“Some say the world will end in fire,\nSome say in ice…”\nFrom ‘Fire and Ice’\nThe winners of the four Cape Farewell challenges will have their poems set to music by famous composer David Julyan, who has written the musical scores for the films Memento and The Prestige, among many others! Winners will be published on the Young Poets Network and SWITCH websites, and there will be other goodies too.\nIf you are a teacher reading this, we have good news! Helen has written a free downloadable Cape Farewell poetry lesson plan on the theme of ‘disappearance’, suitable for key stages 2, 3, 4 and 5. It’s part of our fantastic range of free downloadable Poetryclass resources and includes a class discussion, individual activities, tips for poem-building and a handout.\nSubmitting your poems\nThe challenge is now closed – but you can read the amazing winners and be inspired to write your own poem to submit to one of our Poetry Opportunities!\nThe 2013 winners discuss the Cape Farewell challenges\nSerena Cooke won Karen’s challenge to think about the causes and effects of climate change, expressed through a collage poem, with her wonderful piece ‘Green Tears’. Here Serena takes us through her response to the challenge.\nI really enjoyed the environmental themes of the Cape Farewell challenges because they allowed me to explore something very close to my heart in a poetic way. When writing my poem, I started off with a free write, thinking about the big tree in my front garden. I then looked at the pictures accompanying the challenge by Ana Cecilia Gonzales-Vigil and did another free write for those trees. My poem had to be a collage poem and so played around with the structure of my poem lots, starting off some stanzas with random words and sounds from my free write that I then pieced together. Because I love the environment and think very closely about my own carbon footprint, winning this event was very special to me as I had successfully connected my love of poetry with my love of the environment to write my poem. The Cape Farewell event in London was fantastic because it showcased the best young poetic talent and reunited us in writing about the dangers of climate change, a huge issue for our society that should be taken more seriously.\nHelen Mort was born in Sheffield in 1985. Her collection Division Street is published by Chatto & Windus and was shortlisted for the TS Eliot Prize. She has published two pamphlets with tall-lighthouse press, the shape of every box and a pint for the ghost, a Poetry Book Society Choice for Spring 2010. Five-times winner of the Foyle Young Poets award, she received an Eric Gregory Award from The Society of Authors in 2007 and won the Manchester Young Writer Prize in 2008. In 2010, she became the youngest ever poet-in-residence at The Wordsworth Trust, Grasmere. Helen is also the new Derbyshire Poet Laureate.']	['<urn:uuid:19d4b8bb-c3fe-4162-854f-8e6ca48cf17b>']	open-ended	with-premise	concise-and-natural	distant-from-document	single-doc	novice	2025-05-13T05:52:58.810667	11	52	1111
14	My friend suggested I might need medication for my anxiety, but I'm nervous about starting treatment and want to know how often I'd need to visit the doctor for checkups?	When starting a new medication, follow-up visits are typically recommended within 1 or 2 weeks. Based on your progress and medication tolerance, these visits may be extended to once a month or more, and eventually to every 3 months once symptoms are stabilized. Follow-up visits last between 15 and 20 minutes, during which the practitioner will listen to feedback about the treatment plan, review symptoms, evaluate progress, and make any necessary medication adjustments. According to current practice guidelines, follow-up visits must occur at minimum every 3 months, with the exact frequency determined at each visit based on the complexity of conditions being treated and the progress being made.	['Advanced Psychiatry provides treatment for clients between the ages of 16 and 65. Examples of psychiatric conditions treated include but are not limited to\n- Depression, including Postpartum Depression\n- Anxiety Disorders, including Panic, OCD and PTSD\n- Bipolar Disorder\n- Psychotic Disorders, including Schizophrenia\n- Impulse Control Disorders\n- Attention-Deficit Disorders and Hyperactivity (ADD/ADHD)\n- Addiction and Substance Abuse\n- Eating Disorders\nAs Psychiatric Nurse Practitioners, we focus on the biological and medical aspects of treatment. We do not provide counseling or psychotherapy in our practice and strongly encourage it as part of a well-rounded treatment plan. We are happy to make recommendations and referrals for therapists and counseling centers will best be able serve the patient’s therapy needs. When you’re ready, Advanced Psychiatry will be here for you. You can schedule a new patient evaluation or follow-up visit by calling us today.\nInitial Evaluation: What to Expect\nNew patient evaluations last between 45 and 60 minutes. During this initial visit, we review and explore various aspects such as medical history, family history, social and environmental factors, situational variables such as work and school, and how this affects the patient’s thinking and feelings.\nWe prefer to present our patients with the various options for their treatment. This is a collaboration between the patient and practitioner and no single treatment is dictated over another. The practitioner considers that patient’s concerns and the two together decide on the best treatment plan\nIf you are skeptical about psychiatric treatment, we challenge you to at least undergo a psychiatric evaluation with us. An evaluation is not a guarantee to initiate treatment, but rather to formulate a diagnosis and discuss treatment options. Ultimately the decision to start treatment is yours.\nFollow-up visits usually last between 15 and 20 minutes. This is the time where we listen to our patents’ feedback regarding the treatment plan and its effectiveness. We review the pertinent symptoms, evaluate their progress, and make any updates to their histories as needed.\nIf a patient is experiencing any adverse side effects or feeling like the dose of the medication is too high or too low, follow-up visits are the time to discuss and decide whether any medication changes or adjustments need to be made.\nWhen starting a new medication or after deciding on a new direction with treatment, it is usually recommended to follow-up within 1 or 2 weeks. Based on progress and medication tolerance, recommended follow-up visits may be extended out to a month or more and eventually to every 3 months once symptoms are stabilized. Follow-up visits are at a minimum of every 3 months as recommended by current practice guidelines. Ultimately, the frequency of follow-up visits is determined at each visit and is based on the complexity of the conditions being treated and the progress being made by the patient.\nThere is always a clinician on call to help in the event of an after-hours crisis. If you need immediate medical assistance, always call 911 first.\nMedication refills and other non-emergent concerns will be handled during normal business operating hours.\nA fee may be incurred if after-hour returned calls are not deemed to be urgent.\nAdvanced Psychiatry Cares\nWe know that it can be daunting to seek treatment for a psychiatric disorder. That’s why we try to make the process as smooth as possible so that you can get the help you need without delay. Call to schedule an appointment for a caring, collaborative solution.\nConditions We Treat\nOur clinicians are highly trained and experienced with several disorders including, but not limited to the ones below. You can learn more about each condition by clicking on its’ section.\nDepression can have many root causes, including hormonal imbalances that lead to Postpartum Depression. We order investigative blood tests and prescribe anti-depressants or other medications as needed to fight this debilitating disease.\nAnxiety can be acute and situational, or ongoing and general. There are many approaches for treating anxiety, Obsessive-Compulsive Disorder (OCD) and Panic Disorder. We will educate you on promising medications and supplementary treatments.\nWe treat all mood disorders, including Bipolar Disorder. After a complete evaluation, we will help you find the best mood stabilizers and anti-depressants to minimize mood swings and increase your quality of life.\nPsychotic disorders often require lifelong treatment. Our experts will help formulate a plan for long-term care. They will order medical tests to rule out other conditions that may be causing psychotic symptoms and refer the patient to inpatient treatment during times of crisis.\nImpulse Control Disorder (ICD) can manifest itself as a lack of self-control when confronted with tempting situations. It can lead to substance abuse, alcoholism, gambling or sexual addictions and other reckless behavior. We treat ICD with a combination of medication and referrals to psychotherapists.\nADD and ADHD\nAttention-Deficit Disorders are very treatable with the right medicines. Our clinicians prescribe ADD medication in accordance with state and federal law.\nTo cure insomnia, we must treat the cause as well as the symptom of sleeplessness. We sometimes order sleep studies to rule out physical complications. Your clinician will work with you to find a prescription sleep medication that helps you get the rest you need with minimal side effects.\nAsk a question or book an appointment below. For emergencies call 911 or visit your nearest hospital\nAdvanced Psychiatry, P.L.L.C\n1100 E. Southlake Blvd Ste 300, Southlake , TX 76092 US\nMonday-Thursday from 7am - 6pm and closed on Fridays.']	['<urn:uuid:11f6654b-99ea-4e56-b79b-3bb6d3155985>']	open-ended	with-premise	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-13T05:52:58.810667	30	108	907
15	Where is the watermill located in England?	The watermill is situated to the North of the Test Valley in Hampshire County in Southern England, on the banks of the River Test.	['Written by Guest Author, Gavin Sollars, Timber Frame Carpenter, UK\nThe village is the token and pride of England; there are usually found in it vestiges of earlier life – cottages, manor-houses, farm-houses, with buildings of more or less historic interest; and who should understand them, their origin, their peculiarity of structure, better than the local carpenter?Walter Rose, The Village Carpenter\nI became acquainted with Stan early in 2019 when I decided to look at buying an Ootsuki Nomi. During my search I became skeptical of many of the Japanese tools that are widely available to the European market and, after a lot of research, I came across Stan’s contact details and sent him an email. Stan took a great deal of time to discuss with me what really motivated my purchase, the kinds of things I should take into consideration when looking at Japanese tools and went into detail about the intricacies of Japanese craftsmanship. The information he freely provided was invaluable, and with his help I feel I made a very good choice, and now have a tool that will serve me for my entire career.\nI recently updated Stan with some pictures of buildings I had worked on and he asked if I would be willing to share them with the readers of his blog. The overall aim of these ramblings is to describe to you (who Stan calls his “Gentle Readers”) the general outlines of the reconstruction of an 18th century traditionally-jointed timber frame structure in a beautiful area of the English countryside in the summer of 2019. I hope that this article will give you an understanding of the work that was undertaken and also the enthusiasm I have for this archaic variety of building craft and carpentry as a whole.\nTimber framing in the UK has enjoyed a resurgence in popularity over the last 30 or so years, with quite a number of small to medium sized specialists in the craft building new ‘post and beam’ style buildings that emulate the traditional frames of the past. These companies are mixing time-honoured design details and timber framing techniques with more modern methods of production: chiefly circular saws and portable chain mortisers to rough out the work. This deep understanding and appreciation of historic building vernacular made my employer (The Green Oak Carpentry Co.) well placed to undertake the reconstruction of this Project.\nThe company was awarded the contract to reconstruct the building as close to the original as possible.\nThe Project is situated to the North of the Test Valley in Hampshire County in Southern England on the banks of the beautiful River Test, famous for trout fly fishing and “gin-clear waters.” The original waterwheel powered a grain mill. It was later converted to paper production, and even later housed a generator serving the nearby Manor House. Unfortunately, the original structure was completely destroyed by fire in early 2018.\nAt 21 metres (68.8’) long and 5.7 metres (18.7’) wide, the main structure is situated on a small island created by a man-made diversion in the River Test. The river flows from the north and is then diverted via a sluice gate to the right. The river then widens into a pool and bubbles quickly along the west side of the building. The diversion along the east flank drives the turbine, and passes underneath a wing that links the main structure back to the existing dwelling and also houses the turbine and mill workings.\nHistorical & Structural Considerations\nThe original building was “listed” with the Historic Buildings and Monuments Commission for England confirming the historical importance of the building on the one hand while placing restrictions on how any work to the building can be performed on the other. What remained of the original building after the fire was still subject to the Commission’s rules and regulations, of course. It once featured shorter posts sitting on top of a brick wall from approximately first floor height. In the wake of the fire the surviving outer brick walls were deemed too structurally unsound to bear a load – however, due to the walls being “protected” under UK law, they had to be preserved. To get around this issue we installed two outer plates running around the perimeter of the building with the lower of the two (D – below drawing) supported on metal brackets (C) connected to the back of the timber Jowl posts (B) by lag bolts. The full weight of these two plates, as well as the softwood stud wall with conventional insulation and weatherboarding is carried by these brackets transferring the load to the jowl posts (B).\nA detail drawing (drawn by myself) of the steel bracket, showing how load was removed from the fragile existing wall. The drawing also explains the interplay between our frame and the other elements in the building.\nDesign & Construction Details\nFraming work started in July 2019 with a team of eight carpenters framing the bulk of the structure over a period of five weeks in workshops off-site. A team of four transported the fabricated components of the timber frame to the jobsite, assembled and raised the frame, framed the hips and valleys, then fitted the common rafters and cut and assembled the jack rafters.\nConstructed entirely from European green oak, the structural frame is very utilitarian by design and lacks the aesthetic details like the curved braces typical in many historic timber structures in the UK. Nonetheless, it has some nice detailing that might not be obvious at first glance.\nThe main posts (wooden structural columns) are mostly jowl posts (aka “gunstock posts”) that flare at the top with tenons that fit into both the top plate (beam running along the top of and connecting the exterior posts) the column and tie beam. Historically, jowl posts were cut from the flaring grain of the base of a tree. These butts were often quartered and each post placed in the building adjacent to its sibling. I believe that this is a similarity historic English carpentry shares with its Japanese counterpart.\nHere you can see the cross frame construction\nThe dominant style of cross frame (or bent in North America) features a bridging beam (the large beam that spans the first floor and carries the common joists), a tie beam which spans the top plates. This beam stops the wall frames from spreading under the load from the roof. And then a simple truss design consisting of two vertical studs and an upper collar with short stub ties jointed horizontally between the principle rafters and studs. The purlins (the members that run the length of the roof) are ‘clasped’ between the stub tie and the principal rafter.\nThe main roof frame is comprised of bridled common rafter pairs, a pre-Georgian (prior to 1714) hip gable at one end and a standard gable at the other. A pre-Georgian hip is the English name for a hip rafter that is usually square in section and canted so that one edge is in the plane of either the gable or the main roof. Hip roofs were historically framed in this way until carpentry methods changed and more of a ‘hip board’ set plumb with jacks pitched onto the sides became the preferred method of hip framing.\nThe adjoining wing has a wider span and a higher apex to the main building, and the roof meets the main roof in a valley. These valleys are similarly canted into the plane of the roof like the hips. In the same way the hips produce two different jack rafter cuts so does the valley. You’ll notice that on the main building there is a square jack cut and on the linking building the jacks have a compound cut onto the valley rafter. After running into the valleys, two small hip rafters pick up the opposite slope of the main roof. All of these angles were found using the framing square.\nThe main building is split into two clear halves; one which is vaulted floor to ceiling, and the other which has two floors of joists.\nGreen Oak Timbers\nWhat sets this type of carpentry apart from other woodworking is its use of timbers that are rough-sawn and often of irregular dimensions, requiring an understanding of how to deal with imperfections. For example, timbers are often significantly out of square, and dimensions only approximate: according to the European standard allowable tolerances are +9mm ~ -3mm in section. 5mm of deflection per metre is also allowed. These significant irregularities complicate the carpenter’s job.\nMoisture contents can be in excess of 60% in fresher felled stock and during the summer months the warmer weather can cause problems with drying and shrinkage – we often keep our stacks covered with hessian cloth in an effort to shade the timbers and reduce warpage and cracking.\nTimber framing using this challenging material teaches a carpenter much about the nature of wood as a living thing, the characteristics of the timbers, how they are likely to behave and what can be asked of them.\nThe Layout Process\nCarpenters have developed various layout systems over many centuries to overcome the difficulties of working with irregular timbers. In my company we use lofting, for example. According to this method, we draw out entire layups on the floor and align the outside edges of each member to these lines with any sectional irregularities placed on the inside of the building, whilst any crowning (deflection or bowing) is oriented upwards and outwards.\nOnce the layout is drawn full-scale on the lofting floor, the timbers are placed on blocks in alignment with their corresponding grid lines on the floor. The various members are then laid one over the other so carpenters can accurately mark out lengths and scribe the shoulders of the joints using levels and plumb bobs.\nThe plumb bob is an ancient tool that you are doubtless familiar with – its importance in carpentry cannot be overstated. Plumb bob scribing, or ‘scribe rule’ layout, is a difficult thing to describe without actually seeing it done. What it boils down to is using a perfect reference in a less than perfect situation. By sighting down the plane of the timber by eye and comparing it at the same time with a plumb line a carpenter can gauge to what degree that face is out of plumb and then accurately replicate that plane on the shoulder of the intersecting timber. The shoulders of tenons and widths of mortices are carefully marked using this technique.\nOnce a frame is cut and fitted back together, a plumb bob can be used to accurately transfer and mark additional details up from the floor. In the case of this watermill I used a plumb bob to mark the theoretical positions of the purlin housings on each truss. The result was that, regardless of the amount of deflection or variation in thickness of each principal rafter, the purlin housing was maintained in a consistent level position down the entire length of the building.\nFrames are generally made up of wall frames (running the length of a building) and cross frames (spanning a building). Many of the timbers are therefore used repeatedly in multiple layups. In the case of main posts they are first framed into the exterior walls of a building. Once the walls are completed they are framed in the ‘cross frame layups’. To ensure that the posts return to the right height and rotation that they were in during their previous layups, we use scratched datums (often a set distance from the top of top plate) and rotation marks that allow us to wedge the timber to return it to plumb or level.\nEnsuring that a designated point on each timber is plumb and level is essential, particularly for those in multiple layups. It guarantees that a timber has been returned to the correct plane each time it is fitted up so that when it is stood up and connected to multiple beams, the rotation of each individual shoulder scribe is correct.\nOnce the bulk of the main structure is framed we laid-up floor joist and ‘cogged’ the tie beams into the top plates. Traditionally tie beams were dovetailed into the plates but because the shrinkage of dovetails (green oak, remember) tends to cause the building to spread, it is now more common to see a simple cog used. A cog also slightly outperforms a dovetail in green timber when under tension.\nAssembly and Erection at the Job Site\nThe building enclosed two concrete pads differing in elevation by about 200mm (8”). The base of each post therefore was designed to accommodate this change maintaining the design elevation of the building. This and other variables made laying-out of the building one of the most challenging I have ever been involved in.\nThis photo shows the “jowl posts” and the boom of the spider crane as assembly work is underway.\nThe only access to the site was a track through a field at the rear of the building and a small trackway and bridge over the river too narrow for a mobile crane to cross. The solution we employed was to bring in and set up a small spider crane in various places inside the building. The limitations of this machine required us to be very methodical about the assembly sequencing to ensure we didn’t obstruct subsequent lifts.\nSpace was at a premium. Without a large area to unload the piles of timber, we had to unload the timbers and other materials in the field behind the property and then use a remote-controlled tracked carrier to ferry timber across the narrow access bridge.\nAnd, to throw one more element into the mix, the river is an extremely well-protected ‘Site of Specific Scientific Interest’, meaning we had to be very careful when cutting roof members to prevent sawdust from drifting into the water course. The scaffolders installed netting around the entire perimeter to prevent anything from falling from the scaffold. We also did the majority of our cutting away from the edge of the scaffold on a plywood deck we laid on the joists.\nAs the building began to take shape its scale became more apparent. At nearly nine meters high, it’s an impressive structure.\nI took away a lot of lessons from this building project such as managing levels on-site, and the importance of every trade singing off the same song sheet, as it were.\nWe had issues with the initial layout of the structure as it became clear that the structural steel that effectively served as the starting point for everything above it had not been installed at the correct elevation. The work was delayed while we sorted out this problem.\nI also learned valuable lessons about effective joint placement. Because of the space constraints mentioned above, we were forced to erect the structure by lifting and placing each cross frame and then linking it back with its purlins. However, because the scarf joint landed on the wrong side of each truss, every time we craned a purlin into position, it was left temporarily unsupported at one end. These decisions were admittedly made early on before any proper site visits were made. A proper method statement was in place, of course, but the experience taught me that starting with the end in mind is important when planning.\nI hope that you, Gentle Reader, gained some insight into the work that I am involved with and found it an interesting read. If you would like further information about historic timber framing in the UK, I recommend a small book titled Discovering Timber Framed Buildings by Richard Harris.\n– Gavin Sollars\nThank you for your reading this article. It is rare to find a craftsman like Gavin with the skills and inclination to write about his work and a willingness to share it freely with others. Gavin did not write this to promote his company, but if you like this sort of thing as much as we do, please visit his company’s website and sign up for their newsletter.\nIn the next post in this series Gavin will outline the construction of the roof frame. Please stay tuned.\nIf you have questions or would like to learn more about our tools, please use the questions form located immediately below. Please share your insights and comments with everyone in the form located further below labeled “Leave a Reply.” We aren’t evil Google or incompetent facebook and so won’t sell, share, or profitably “misplace” your information. Stick a needle in my eye.']	['<urn:uuid:8f4520da-d5f7-4c31-b89a-f3d528b54179>']	factoid	direct	concise-and-natural	similar-to-document	single-doc	novice	2025-05-13T05:52:58.810667	7	24	2768
16	mri ct scan differences safety comparison	MRI has several advantages over CT scans. MRI provides more detailed images of soft tissues and is better at detecting small, deep lesions. Additionally, MRI does not use ionizing radiation, making it safer for patients, especially those requiring multiple scans. This safety aspect is particularly important as CT scans can expose patients to significant radiation, which may increase cancer risk. According to research, the cancer risk from CT scans, while very low, appears to be real, particularly when multiple scans are performed.	['There are many different technologies available for locating soft tissue injuries, but which one is best? It depends on the individual situation. Which Technology Would Be Best in Locating Soft Tissue Injuries? For example, if you are looking for a specific injury such as a torn ligament, MRI would be the best technology.\nHowever, if you are simply trying to locate any areas of soft tissue damage, ultrasound or x-ray might be better options. Ultimately, it is up to the medical professional to decide which technology would be best in each individual case.\nTable of Contents\nWhich Technology Would Be Best in Locating Soft Tissue Injuries?\nSeveral different types of technology can be used to locate soft tissue injuries. Some of these include 1. X-rays – These are commonly used to diagnose broken bones, but can also help locate soft tissue damage.\n2. MRI – This type of imaging can provide detailed images of the inside of the body and is often used to diagnose problems with the spine or brain. It can also help identify soft tissue damage. 3. CT scan – A CT scan uses x-rays to create a three-dimensional image of the inside of the body.\nThis can help diagnose problems with organs or blood vessels, as well as identifying soft tissue damage. 4. Ultrasound – This type of imaging uses sound waves to create an image of the inside of the body. It is often used to examine pregnant women and their unborn babies, but can also help locate soft tissue damage.\nWhich of These is an Advantage of an Mri Over an X-Ray\nIf you’re looking for a more detailed look at your insides, an MRI is the way to go. MRI machines use radio waves and magnetic fields to produce high-quality images of your organs, bones, and other tissues. That means that they can show things that X-rays can’t, like soft tissue damage and certain types of tumors.\nWhich of These is an Advantage of an MRI Over a Ct Scan\nThere are a few advantages that MRI has over CT scan. First, MRI does not use ionizing radiation, while CT scan does. This means that MRI is much safer for the patient, especially if the patient needs to have multiple scans.\nAdditionally, MRI can provide more detailed images of soft tissues than CT scan can. Finally, MRI is generally better at detecting lesions that are smaller and located deep within the body than CT scan is.\nMatch Each Technology With the Disease It Helps Detect Or Treat\nThere are a variety of different technologies that can be used to detect or treat diseases. Here is a look at some of the most common:\nX-rays: X-rays are commonly used to detect broken bones, but they can also be used to diagnose other conditions such as pneumonia and heart problems.\nCT scans: CT scans use x-rays to create detailed images of the inside of the body. They can be used to diagnose cancer, heart problems, and other conditions. MRI: MRI uses magnetic fields and radio waves to create detailed images of the inside of the body.\nIt can be used to diagnose brain tumors, multiple sclerosis, and other conditions. Ultrasound: Ultrasound uses sound waves to create images of the inside of the body. It can be used to examine pregnant women and their unborn babies, as well as diagnosing other conditions such as gallstones.\nWhich of These is a Disadvantage of Ct Scan Technology\nThere are a few disadvantages of CT scan technology to be aware of. First, the radiation exposure from a CT scan can be significant, especially for young children or pregnant women. Second, CT scans are very expensive, so they are not always an option for patients with limited resources.\nFinally, CT scans can sometimes produce false positive results, leading to unnecessary anxiety or even invasive procedures.\nMatch Each Device With Its Advantage\nWhen choosing what devices to use for your business, it’s important to first consider what advantages each one offers. Only then can you make an informed decision about which will be the best fit for your needs. One of the most popular devices used in business today is the smartphone.\nIts main advantage is its portability, as it can be easily carried around and used anywhere. Additionally, smartphones typically have a wide range of features and applications that can be very useful in a business setting, such as email, calendars, and GPS. Tablets are another popular choice for businesses, and their main advantage is their larger screen size compared to smartphones.\nThis makes them ideal for tasks that require more screen real estate, such as viewing documents or browsing the web. Additionally, tablets usually offer longer battery life than smartphones. Laptops are often seen as the go-to choice for businesses due to their versatility.\nThey offer a large screen size like tablets but are also powerful enough to handle more demanding tasks like video editing or graphic design. Plus, laptops come with a variety of ports and connections that allow you to connect external devices like printers or scanners. Finally, desktop computers are still widely used in businesses despite the rise of portable devices.\nThe main advantage of desktops is their raw power and performance; they’re simply unmatched when it comes to handling resource-intensive tasks. Additionally, they tend to be more affordable than laptop computers with comparable specs.\nWhich Technology Would Be Best in Locating?\nThere are many different types of technology that can be used for locating purposes. GPS is perhaps the most well-known and widely used type of technology for this purpose, but there are also other options available. Radio frequency identification (RFID) tags are one example of a type of technology that can be used for locating people or objects.\nNFC tags are another option that can be used for similar purposes.\nWhat is the Protocol to Treat a Soft Tissue Injury?\nThere is no one-size-fits-all answer to this question, as the protocol for treating a soft tissue injury will vary depending on the specific type and severity of the injury. However, there are some general principles that can be followed in most cases. The first step is always to seek medical attention, as even seemingly minor soft tissue injuries can become complicated if not properly treated.\nOnce you have been seen by a doctor or other medical professional, they will likely recommend some combination of rest, ice, compression, and elevation (RICE) for the first 24-48 hours after the injury. This will help to reduce swelling and pain. After the initial RICE period, you may be advised to start gently stretching and exercising the injured area.\nThis helps to prevent stiffness and aids in healing. As your injury heals, you can gradually increase the intensity of your activity level until you are back to your normal routine. If at any point during your recovery you experience increased pain or swelling, be sure to consult with your medical provider as this may indicate that you are doing too much too soon.\nFollowing these general guidelines should help you recover from a soft tissue injury without further complications.\nHow Do You Prevent Soft Tissue Damage?\nThere are many ways that you can prevent soft tissue damage. One of the most important things that you can do is to warm up before you exercise. Warming up helps to increase blood flow to the muscles and tendons, which can help to reduce the risk of injury.\nAnother way to prevent soft tissue damage is to avoid repetitive motions. If you do the same motion over and over again, it can cause strain on the tissues and lead to injuries. Instead, mix up your routine and give your body a variety of different movements to keep things fresh.\nFinally, be sure to stretch after your workout. This will help your muscles recover from any exertion and prevent them from becoming tight or injured.\nThe use of diagnostic ultrasound is an effective means of detecting soft tissue injuries. However, there are several different technologies that can be used to locate these injuries, and it can be difficult to determine which one would be best for a particular patient. A new study has evaluated the accuracy of three different techniques—magnetic resonance imaging (MRI), computed tomography (CT), and ultrasonography—in identifying soft tissue injuries.\nThe results showed that MRI was the most accurate, followed by CT and then ultrasonography. This study provides important information that can help clinicians choose the best technology for their patients.', 'Safety of CT scan\nIn light of a recent paper by Mark S Pearce et al. in The Lancet (Radiation exposure from CT scans in childhood and subsequent risk of leukaemia and brain tumours: a retrospective cohort study) early online publication, 7 June 2012, doi:10.1016/S0140-6736(12)60815-0, the following information is provided:\n- CT is one of the most valuable medical imaging techniques when used justifiably.\n- A number of professional organizations have provided appropriateness criteria or referral guidelines to achieve appropriate use. This website provides a link to some of these guidelines.\n- X rays used in CT, while having tremendous benefits, can have side effects such as a potentially increased risk of cancer in later years.\n- The risks of cancer from radiation dose imparted by a single CT scan is debated and international consensus is currently not available.\n- The risk figures for cancer available in literature are projected, that is, “estimated cancer risks” based on risk coefficients derived from data from survivors of Hiroshima and Nagasaki primarily, with some other study groups also supporting the data.\n- Despite a common view among international organizations that risk coefficients are also applicable at the level of radiation doses encountered in CT scanning, some groups have expressed the view that the risks are hypothetical as they are extrapolated from higher exposure down to lower exposures. Also, there have been objections that the risks from X rays may not be the same as with gamma radiation.\n- With current knowledge, there is no controversy on carcinogenic effects for organ doses in excess of 100 mGy, which can accrue in five to 15 CT scans (such a wide range is needed as it depends upon techniques utilized and organs scanned).\n- The controversy remains (despite common view among most international organizations) about cancer risk from a single or a few CT scans and this is where the new research published in the Lancet has importance.\n- The new research reinforces the belief of major international organizations about cancer risks from a few CT scans. The risk is very low but appears to be real, not hypothetical.\n- Image Gently, an alliance for radiation safety in paediatric imaging, has posted a message to parents on its website.\n- The IAEA recommends tracking of radiological examinations a patient undergoes, in particular a child, to enable easy reference to availability of desired information from previous scans. This also helps to compare radiation doses with previous examinations and help in the detection of a scope for optimization. Recently, a Joint Position Statement on the IAEA Patient Radiation Exposure Tracking has been issued jointly with ESR, FDA, IAEA, IOMP, ISRRT, WHO and also CRCPD.\n- There is information available on this website for patients and, in particular, for safety in computed tomography (CT).\nCT scans are an important diagnostic tool when used appropriately (American Association of Physicists in Medicine), direct link to AAPM web page\nPaediatric CT Scans Save Lives When Used Appropriately (American College of Radiology)\nImproving Radiation Protection of Children Worldwide (IAEA)\nTraining material for free download in different areas\nCopyright © 2013 International Atomic Energy Agency, Vienna International Centre, PO Box 100, 1400 Vienna, Austria']	['<urn:uuid:7e6991b9-2280-4161-afdd-0ead9c03d2d1>', '<urn:uuid:d69b9ded-e78b-4db4-9ed7-e2fe449f0545>']	open-ended	direct	short-search-query	similar-to-document	multi-aspect	novice	2025-05-13T05:52:58.810667	6	82	1950
17	How common is work-related asthma and who gets it most?	According to the AAAAI, about 15% of asthma cases in the U.S. may be job-related. High-risk occupations include agricultural workers, painters, plastics manufacturing, and cleaning work. People with existing asthma/allergies or family history are more susceptible.	"[""What is Obstructive Pulmonary Disease?\nThe most common chronic lung disease, includes diseased characterized by increased resistance to airflow as a result of airway obstruction or airway narrowing.\nWhat are the types of Obstructive Pulmonary Disease?\nAsthma, COPD, cystic fibrosis, and bronchiectasis.\nWhat is Asthma?\nIs a chronic inflammatory lung disease that results in variable episodes of airflow obstruction, but is usually reversible.\nWhat does chronic inflammation in Asthma lead too?\nRecurrent episodes of wheezing, breathlessness, chest tightness, cough, particularly at night or in the early morning.\nWhat are the risk factors of Asthma?\nRelated to the patient (e.g., genetic factors), or the environment. Obesity as well, and gender.\nWhat are the gender differences for males with Asthma?\nMale gender is a risk factor for asthma in children, but not adults for unclear reasons. Before puberty males are more affected.\nWhat are the gender differences for females with Asthma?\nAfter puberty and into adulthood, women are more affected then men. Women who are admitted to the ER are more likely to need hospitalization. Death rates in women are greater then men.\nWhat are the cultural and ethnic health disparities in regards to Asthma with African Americans?\nHigher prevelance rates over 38%, females have the highest mortality rate.\nWhat are the cultural and ethnic health disparities in regards to Obstructive Pulmonary Diseases with Whites?\nHighest incidence of COPD, highest incidence of Cystic Fibrosis.\nWhat are the cultural and ethnic health disparities in regards to Obstructive Pulmonary Diseases with Puerto Ricans?\nHigher asthma prevalence rates and age adjusted death rates than all other racial and ethnic subgroups.\nWhat is the Genetic Risk factor with Asthma?\nAsthma has a component that is inherited. Numerous genes are involved. Atopy the genetic predisposition to develop an allergic (IgE-mediated) response to common allergies, is a major risk factor.\nWhat is the Immune Response Risk factor with Asthma?\nHygiene response hypothesis is thought to play a role in Asthma.\nHow do Allergies effect Asthma?\nIndoor and outdoor allergens are well known to trigger asthma. House dust mites, cockroaches, furry animals, fungi and mold can trigger.\nHow does exercise effect Asthma?\nInduced or exacerbated asthma. Occurs after vigorous exercise. Symptoms are pronounced during activities where there is exposure to cool, dry air.\nHow do air pollutants effect Asthma?\nCigarette or wood smoke, vehicle exhaust, elevated ozone levels, sulfur dioxide, and nitrogen dioxide can trigger an attack.\nHow does cigarette smoking effect Asthma?\nAssociated with an accelerated decline of lung function. Increases the severity of the disease, may cause patients to be less responsive to treatment with corticosteroids (systemic or inhaled), and reduces the chance of asthma being controlled.\nWhat are occupational factors with Asthma?\nJob-related exposures. Irritants cause a change in the responsiveness of the airways. Agricultural workers, painters, plastics manufacturing, and cleaning work are high risk. Arrive at work feeling well but experience gradual development of symptoms towards the end of the day.\nHow do Respiratory Infections effect Asthma?\nMajor precipitating factors in acute asthma attacks. RSV and rhinovirus are two factors in developing and increasing severity of Asthma. Cause an increase in hyperresponsiveness of the bronchial system.\nHow do nose and sinus problems effect Asthma?\nAllergic rhinitis is a major predictor. Treatment of allergic rhinitis may reduce frequency of exacerbation. Chronic sinus problems can cause inflammation of the mucus membranes.\nWhat happens when some asthmatics take aspirin or NSAIDS?\nWheezing will develop within two hours. Usually rhinorrhea, congestion, and tearing occurs. Facial flushing, GI symptoms, and angioedema can occur.\nHow can B-Adrenergic Blockers PO or topical eyedrops effect Asthma?\nMay trigger asthma because of bronchospasms.\nHow can ACE inhibitors effect Asthma?\nMay produce cough in susceptible individuals, making symptoms worse.\nHow does tartrazine (yellow dye #5) and sulfating agents effect Asthma?\nUsed as preservatives and sanitizing agents. Commonly found in fruits, beer, and wine used extensively in salad to prevent oxidation. Can cause asthma exacerbation.\nHow does GERD effect Asthma?\nPostulated that reflux of stomach acid into the esophagus can be aspirated into the lungs, causing relfex vagal stimulation and bronchoconstriction.\nWhat are the Psychological Factors with Asthma?\nEmotional stress, extreme emotions such as crying, laughing, anger and fear can lead to hyperventilation and hypocapnia, which can cause airway narrowing.\nWhat is the Pathophysiology of Asthma?\nPersistent but variable inflammation of the airway. Airflow is limited because of inflammation results in bronchoconstriction, airway hyperresponsiveness, and edema of the airways.\nWhat are the inflammatory cells that are involved with Asthma?\nMast cells, macrophages, eosinophils, neutrophils, T and B lymphocytes, and epithelial cells of the airways.\nHow long does it take for someone to have an early phase response with Asthma?\n30 - 60 minutes after exposure to allergen or irritant.\nHow long does it take for someone to have an late phase response with Asthma?\n4 - 10 hours after initial attack because of eosinophil and lymphocyte activation and their release of more inflammatory mediators. Epithelial cells also produce cytokines and other inflammatory mediators.. Can persist for 24 hours or more.\nWhat is the allergic asthma response?\nTriggered when an allergen cross links IgE receptors on Mast cells, which are activated to release histamine and other inflammatory mediators (early-phase response). A late phase response may occur due to further inflammation.\nWhat are the clinical manifestations of Asthma?\nWheezing, cough, dyspnea, chest tightness after exposure to a precipitating factor or trigger. Expiration may be prolonged. Expiratory ration may be prolonged to 1:3, or 1:4. Bronchospasm, edema, and mucus in the brochioles, narrowing.\nWhat does examination of the person with Asthma reveal?\nHypoxemia, restlessness, increased anxiety, inappropriate behavior, increased pulse and blood pressure, and pulsus paradoxus (a drop in systolic during during the inspiratory cycle greater than 10 mm Hg). Difficulty speaking, increased RR (^30), use of accessory muscles. Hyperresonance on percussion, auscultating with wheezing. Silent chest indicates severe obstruction and impending respiratory failure.\nHow can Asthma be classified?\nIntermittent, mild persistent, moderate persistent, or severe persistent.\nWhat are the diagnostic studies for Asthma?\nH & P, pulmonary function studies including response to bronchodilator therapy, peak expiratory flow rate (PEFR), chest x-ray, measure of oximetry, allergy skin test if indicated, blood level of eosinophil and IgE.\nWhat is collaborative therapy for Asthma?\nID and avoidance/elimination triggers, patient and caregiver teaching, drug therapy, asthma action plan, desensitization, assess for control.\nWhat does a severe of life-threatening asthma exacerbation indicate?\nSaO2, ABGs, inhaled B2-adrenergic agonists, inhaled anticholinergic agents, )2 by mask or nasal prongs, IV or oral corticosteroids, IV fluids, IV magnesium or/and heliox, intubation or assisted ventilation.\nWhat do ABG's reveal with a person with Asthma?\nNormal between exacerbation, increase in pH in exacerbation, then decrease if prolonged or severe exacerbation, decrease in PaO2, decrease early in exacerbation of PaCO2 and increase if prolonged severe exacerbation.\nWhat do Pulmonary Function Tests reveal with Asthma?\nTotal lung capacity is increased, residual volume is increased, FEV1 decreased, FEV1/FVC normal to decreased.\nWhat are the goals in collaborative care with Asthma?\nTo achieve and maintain control of the disease.\nWhat anti-inflammatory drugs are used for Long term Control of Asthma?\nAnti-inflammatory drugs such as corticosteroids: inhaled (e.g., fluticasone [Floventil]), Oral (e.g., Prednisone). Leukotriene modifiers (e.g., montelukast [Singular]), Anti-IgE (omalizumab [Xolair]).\nWhat bronchodilators are used for Long Term Control of Asthma?\nLong acting inhaled b2-adrenergic agonists (e.g., salmeterol [Serevent]), Long acting oral b2-adrenergic agonists (e.g., albuteral [VoSpire ER]). Methylxanthines (e.g., theophyline [Uniphyl]), and Anticholinergics (inhaled) (e.g., tiotropium [Spirival]).\nWhat bronchodilators are used for Quick Relief of Asthma?\nShort-acting inhaled b2-adrenergic agonists (e.g., albuterol [Proventil HFA]), Anticholinergics (inhaled) (e.g., ipratropium [Atrovent]).\nWhat antiinflammatory drugs are used for Quick Relief of Asthma?\nCorticosteroids (systemic) (e.g., prednisone) - considered quick-relief when used in a short burst 3-10 days at the start of therapy or during a period of gradual deterioration.\nHow do Corticosteroids effect Asthma?\nAntiinflammatory medications that reduce bronchial hyperresponsiveness, block the late-phase reaction, and inhibit migration of inflammatory cells. More effective in improving asthma control then any other long term drug.\nHow do Leukotriene Modifiers effect Asthma?\nLeukotriene receptor blockers (antagonists) and leukotriene synthesis inhibitors interfere with the synthesis or block the action of leukotrienes - inflammatory mediators produced from arachidionic acid metabolism.\nHow do Anti-IgE medications effect Asthma?\nPrevents IgE from attaching to mast cells, thus preventing the release of the chemical mediators.\nWhat are the three classes of Bronchodilators?\nB2-adrenergic agonists, methylxanthines and derivatives, and anticholinergics.\nHow do B2-Adrenergic Agonists Drug effect Asthma?\nCan be short acting or long acting. Act by stimulating b-adrenergic receptors in the bronchioles, thus producing bronchodilation. They also increase mucociliary clearance.\nHow do Methylxanthines effect Asthma?\nBronchodilator with mild antiinflammatory effects, but the exact mechanism is unknown.\nWhat is the main problem with Methylxanthines Theophylline?\nRelatively high incidence of interaction with other drugs and the occurrence of side effects, which include nausea, headache, insomnia, GI distress, tachcardia, dysrhythmias, and seizures.\nHow do anticholinergic drugs effect Asthma?\nBlock the bronchoconstricting influence of the parasympathetic nervous system. Less effective than b2-adrenergic agonists.\nWhat is a Nursing Assessment with Asthma?\nIf the patient can speak and is not in acute distress, a detailed health history, including ID of any precipitating factors and what has helped alleviate attacks in the past can be taken. Subjective and objective data. Assess patients asthma control using one of the validated self-questionnaires.\nWhat objective data should you look at during a Nursing Assessment of a patient with Asthma in regards to the respiratory system?\nNasal discharge, polyps, swelling, wheezing crackles, diminished or absent breath sounds, rhonchi, hyperressonance, sputum, increase work of breathing, use of accessory muscles, intercostal and supraclavicular retractions, tachypnea with hyperventilation, prolonged expiration.\nWhat objective data should you look at during a Nursing Assessment of a patient with Asthma in regards to the Cardiovascular system?\nTachycardia, pulsus paradoxus, JVD, hypertension, or hypotension, premature ventricular contractions.\nWhat objective data should you look at during a Nursing Assessment of a patient with Asthma in regards to General data?\nRestlessness or exhaustion, confusion, upright or foward leaning body position.\nWhat objective data should you look at during a Nursing Assessment of a patient with Asthma in regards to the Integumentary System?\nDiaphoresis, cyanosis (circumoral, nail bed), eczema.\nWhat overall goals do you plan for the patient with Asthma?\n1. minimal symptoms during the day and night. 2. acceptable activity levels. 3. maintenance of greater than 80% of personal best PEFR or FEV. 4. few or no adverse effects of therapy. 5. no recurrent exacerbations of asthma, and 6. adequate knowledge to participate in and carry out management.\nWhat do you teach the patient about Asthma with Preventing Asthma Attacks or decreasing the severity?\nIdentify and avoid known personal triggers, and irritants. Use of special dust covers on mattresses and pillow. Washing bedclothes in hot water or cooler water with detergent and bleach. Avoidance of furred animals. Avoid cold air, dress properly with scares and use masks. Avoid NSAIDS and OTC drugs with asprin. Maintain fluid intake of 2 - 3 L q day, good nutrition and adequat rest.\nWhat is Status Asthmaticus?\nAn acute exacerbation of asthma that does not respond to standard treatments of bronchodilators and steroids.\nWhat are complications of Status Asthmaticus?\nPneumothorax, pneumomediastinum, cor pulmonale, respiratory arrest.\nWhat is Cor Pulmonale?\nPulmonary heart disease is enlargement of the right ventricle of the heart as a response to increased resistance or high blood pressure in the lungs.\nWhat should teaching of patient and caregiver of a patient with Asthma include?\nWhy use a peak flow meter, info on peak flow meter, what is asthma, what is good asthma control, hindrances to asthma treatment and control, environmental and triggers, medications, correct use of medications, breathing techniques, asthma action plan.\nWhat is Chronic Obstructive Pulmonary Disease?\nCOPD - a preventable and treatable disease state characterized by chronic airflow limitations that is not fully reversible.\nWhat is Chronic Bronchitis?\nPresence of chronic productive cough for 3 month in each of 2 consecutive years in a patient in whom other causes of chronic cough have been excluded.\nWhat is Emphysema?\nAn abnormal permanent enlargement of the air spaces distal to the terminal bronchioles, accompanied by destruction of their walls and without obvious fibrosis.\nWhat are the gender differences for Men with COPD?\nMore common in men than in women, but trend for men is not increasing. Fewer men are dying from COPD then women.\nWhat are the gender differences for Women with COPD?\nNumber of women with disease is increasing. Increase is probably due to increased number of women smoking cigarettes and increased susceptibility. Lower quality of life, more exacerbations, increased dyspnea, and better response to 02 therapy.\nWhat are the signs of Emphysema?\nLoss of lung elasticity, proteases break down elastin, hyperinflation o flungs, air trapped in lungs, poor gas exchange, loss of aveolar tissue.\nWhat is Chronic Respiratory Acidosis?\nA medical condition in which decreased respiration (hypoventilation) causes increased blood carbon dioxide and decreased pH (acidosis).\nHow does the inflammatory response to irritants affect Chronic Bronchitis?\nAffects small and large airways, hinders airflow and gas exchange.\nWhat is the etiology of COPD?\nSmoking, AAT deficiency, occupational chemicals and dust, air pollution, infection, genetics, aging.\nWhat are the complications of COPD?\nHypoxemia, acidosis, respiratory tract infections, cardiac problems - cardiac failure and dysrhythmias.\nWhat are the clinical manifestations of COPD?\nDyspnea with exertion, every day. Late stages dyspnea maybe at rest. Wheezing and chest tightness, vary by time of day. Weight loss and anorexia. Prolonged expiratory phase, decreased breath sounds. Hypoxemia, hypercapnia, polycythemia and cyanosis.\nWhat established the diagnosis of COPD?\nSpirometry whether or not the patient has chronic symptoms. The FEV1/FEV less than 70% establishes and the severity of obstruction.\nWhat are the diagnostic studies for COPD?\nH & P, pulmonary function tests, chest x-rays, serum a1-antitrypsin levels, ABGs, 6 minute walk test.\nWhat is collaborative therapy for COPD?\nCessation of smoking, treatment of exacerbations, bronchodilator therapy, corticosteroids, airway clearance techniques, breathing exercises and retraining, hydration of 3L qday, patient and caregiver teaching, influenza immunization yearly, pneumovax, longer term 02, progressive plan of exercise, pulmonary rehab program, nutritional supplement if low BMI, surgery.\nWhat does a nursing assessment for a patient with COPD involve?\nSubjective health information past health history and medications, functional health patterns, general objective data with integumentary, respiratory, cardiovascular, gastrointestinal, musculoskeletal and diagnostic findings.\nWhat should the health history contain of a patient with COPD during an assessment?\nLong term exposure to chemical pollution, respiratory irritants, occupation fumes, dust, recurrent respiratory infections, previous hospitalizations.\nWhat general objective data do you look at during a nursing assessment with COPD?\nDebilitation, restlessness, assumption of upright position.\nWhat integumentary objective data do you look at during a nursing assessment with COPD?\nCyanosis (bronchitis), pallor or ruddy color, poor skin turgur, thin skin, digital clubbing, easy bruising, peripheral edema.\nWhat respiratory objective data do you look at during a nursing assessment with COPD?\nRapid, shallow breathing, inability to speak, prolonged expiratory phase, pursed-lip breahting, wheezing, rhonchi, crackles, diminished or bronchial breath sounds, decreased chest excursion and diaphragm movement, use of accessory muscles, hyperresonant or dull chest sounds on percussion.\nWhat cardiovascular objective data do you look at during a nursing assessment with COPD?\nTachycardia, dysrhythmias, JVD, distant heart tones, right sided S2 (cor pulmonale), edema (esp in feet).\nWhat Gastrointestinal objective data do you look at during a nursing assessment with COPD?\nAscites, hepatomegaly (cor pulmonale).\nWhat Musculoskeletal objective data do you look at during a nursing assessment with COPD?\nMuscule atrophy, increased anterior-posterior diameter (barrel chest).\nWhat Possible Diagnostic findings do you look with a patient with COPD?\nAbnormal ABGs (compensated respiratory acidosis), decreased PaO2 and SaO2, increased PaCO2, polycythemia, pulmonary function tests showing expiratory airflow obstruction (low FEV1, low FEV1/FVC, large RV), chest x ray showing flattened diaphragm and hyperinflation or infiltrates.\nWhat are the main aspects of the psychosocial assessment with COPD?\nSmoking (pack years), anxiety, depression.\nWhat are nursing goals with planning of a patient with COPD?\n1. prevention of disease progression. 2. ability to perform ADLs and improved exercise tolerance. 3. relief of symptoms. 4. no complications related to COPD. 5. knowledge and ability to implement a long-term treatment regimen, and 6. overall improved quality of life.\nWhat are the teaching subjects for the patient and caregiver with COPD?\nOverall guide, what is COPD, breathing and airway clearance exercises, energy conservation techniques, medications, correct use of medications, psychosocial/emotional issues, management plan, health nutrition.\nWhat is LVRS?\nLung volume reduction surgery. Reduce the size of the lungs by removing the most disease lung tissue so the remaining healthy lung tissue can perform better.\nWhat is the benefits of a Lung Transplant?\nFor carefully selected patients with advanced COPD. Single-lung transplant is most commonly used technique because of shortage of donors, bilateral transplantation can be performed.\nWhat are the obstacles of lung transplant?\nOrgan rejection, effects of immunosuppressive therapy, and the high cost of surgery.\nWhat are the different breahting techniques for COPD?\nPursed lip breathing, positioning, energy conservation."", 'What is Occupational Asthma and whoís at Risk?\nDo you already have asthma and does it become worse when you go to work? Or have you developed a breathing problem you suspect is from your work? If yes, then you may have developed what is called Occupational Asthma (OA). Occupational asthma is asthma, with all the typical signs and symptoms, made worse or caused by your work place. According to the American Academy of Allergy, Asthma, and Immunology (AAAAI), about 15% of asthma cases in the U.S. may be due to a personís work.\nRisk factors for developing OA are the following: a person already has asthma and allergies, a family pre-disposition for asthma and allergies, or works around known asthma triggers. People who work with chemicals, animals and animal products, grains and other plant material, along with wood, cloth, and metals have an increased risk of developing OA. Itís also important to note that you can develop occupational asthma even working in an office.\nHow to tell if itís occupational asthma?\nIf you believe your breathing trouble could be related to work, itís helpful to keep a diary of your symptoms, with dates, and places symptoms develop. Be sure to also describe your symptoms and their severity. After a couple of weeks you should be able to see a pattern, with symptoms being worse while at work, and then either diminishing or going away completely over weekends and vacations away from your workplace, with symptoms returning once you are back at work. Once youíve seen a pattern, take your symptom diary to your doctor and discuss the proper course of action. Your doctor will determine what tests might be necessary to determine if you are having asthma, and the proper course of treatment to help improve your symptoms.\nItís very important to find the cause of your breathing troubles as soon as possible. Many times, workers are misdiagnosed as having bronchitis, and continue on with the work thatís making them sick. A misdiagnosis will lead to further sick days off from work, and an increased risk of needing emergency treatment for a full-blown asthma attack. Another problem with misdiagnosis of OA is continued exposure to the asthma triggers causing permanent changes and damage to your lungs. So be sure to get treatment as soon as you suspect your job is causing you to have asthma symptoms. A correct diagnosis can save your life and your job.\nAlso be aware of the laws in your country and/or state. In the U.S., OSHA (Occupational Safety & Health Administration) governs the safety of work places, and addresses the problem of OA and how employers should deal with it. All U.S. employers must follow OSHA standards in order to be in compliance with U.S. law. Know your rights under the laws of your own country/state. These laws exist to keep you and other employees safe and healthy.\nYouíve been diagnosed with occupational asthma, now what?\nOnce youíve been diagnosed with occupational asthma, itís important to work with your employer on how to avoid the irritants causing your asthma. Complete avoidance is the key, but if avoidance is not possible, wearing protective gear, the use of long-term asthma treatments, and even a change in your job might be necessary. You should discuss with your doctor how best to work with your employer on ensuring your long-term health and treatment for your OA.\nTake care of your lungs to breathe easier and be healthy!']"	['<urn:uuid:0c5e1c2e-f443-4119-af68-b9c50575ff02>', '<urn:uuid:34de3be9-5009-4ead-b6fc-e4dc59d27aeb>']	factoid	direct	concise-and-natural	distant-from-document	multi-aspect	novice	2025-05-13T05:52:58.810667	10	36	3403
18	theatre of dionysos seating capacity and front row	The Theatre of Dionysos could hold around 17,000 spectators. In the front row, there were great marble thrones, each inscribed with the name of an official of the festival or an important priest. The priest of Dionysos sat in the middle of the front row, with the representative of the Delphic Oracle seated to his right.	['Entrance to the South Slope site is either by a path tracking around the side of the Acropolis near the main ticket office, or from below, off pedestrianized Leofóros Dhionysíou Areopayítou close to Metro Akrópoli. A great deal of restoration and excavation work is ongoing here, including the opening up of a new area on the eastern edge of the rock, above Pláka where groups of statues have been gathered together.\nTheatre of Dionysos\nThe Theatre of Dionysos is one of the most evocative locations in the city. Here the masterpieces of Aeschylus, Sophocles, Euripides and Aristophanes were first performed; it was also the venue in Classical times for the annual festival of tragic drama, where each Greek citizen would take his turn as member of the chorus. Rebuilt in the fourth century BC, the theatre could hold some 17,000 spectators – considerably more than Herodes Atticus’s 5000–6000 seats. Twenty of the original 64 tiers of seats survive. Most notable are the great marble thrones in the front row, each inscribed with the name of an official of the festival or of an important priest; in the middle sat the priest of Dionysos and on his right the representative of the Delphic Oracle. At the rear of the stage are reliefs of episodes in the life of Dionysos flanked by two squatting Sileni, devotees of the satyrs. Sadly, this area is roped off to protect the stage-floor mosaic – a magnificent diamond of multicoloured marble best seen from above.\nHerodes Atticus Theatre\nThe dominant structure on the south side of the Acropolis – much more immediately obvious even than the Theatre of Dionysos – is the second-century Roman Herodes Atticus Theatre (Odeion of Herodes Atticus). This has been extensively restored for performances of music and Classical drama during the summer festival but is open only for shows; at other times you’ll have to be content with spying over the wall.\nStoa of Eumenes\nBetween the two theatres lie the foundations of the Stoa of Eumenes, originally a massive colonnade of stalls erected in the second century BC. Above the stoa, high up under the walls of the Acropolis, extend the ruins of the Asklepion, a sanctuary devoted to the healing god Asklepios and built around a sacred spring; restoration is ongoing, and there are extensive new signs in English.\nMonument of Thrasyllos\nAbove the Theatre of Dionysos, you can see the entry to a huge cave, originally sacred to Artemis. It later housed choregic awards (to celebrate victory in drama contests; see Monument of Lysikratos) won by the family of Thrasyllos, hence the name. The entrance was closed off around 320 BC with a marble facade – this is currently being restored. The cave was later converted to Christian use and became the chapel of Virgin Mary of the Rocks, but an ancient statue of Dionysos remained inside until it was removed by Lord Elgin (it’s now in the British Museum), while the Classical structure survived almost unchanged until 1827, when it was blown up in a Turkish siege.\nThe Peripatos was the ancient street that ran around the north side of the Acropolis. Access to this side has only recently been opened up so that you can now walk right around the rock within the fenced site, starting above the Theatre of Dionysos and emerging by the entry to the main Acropolis site; there’s also a new entrance from Pláka, by the Kannellopoulou museum.\nThere are no major monuments en route, but the numerous caves and springs help explain the strategic importance of the Acropolis. In one impressive cleft in the rock was a secret stairway leading up to the temples: this provided access to spring-water in times of war, and was also used in rituals, when blindfolded initiates would be led this way. Nearby are numerous other caves and rock arches that had cult status in ancient times.']	['<urn:uuid:5494f2ee-7261-411f-88ea-4a87db08798c>']	open-ended	with-premise	short-search-query	similar-to-document	single-doc	expert	2025-05-13T05:52:58.810667	8	56	650
19	tmj treatment initial goals relieve muscle spasm joint pain what methods	The initial treatment goals for TMJ disorders focus on relieving muscle spasm and joint pain. This is typically accomplished using pain relievers, anti-inflammatory medications, or muscle relaxants. Additionally, steroids can be placed directly into the joints to reduce pain and inflammation.	['TMJ Disorders (TMD)\nTMJ (temporomandibular joint) disorders, sometimes referred to as temporomandibular disorders (TMD), are a family of problems related to your complex jaw joint and muscles. If you have had symptoms such as pain or a “clicking” sound, you’ll be glad to know that these problems are more easily diagnosed and treated than they were in the past. These symptoms can occur when the joints of the jaw and the chewing muscles (muscles of mastication) do not work together correctly. TMJ stands for temporomandibular joint and is the name for each joint that connects your jaw to your skull. Since some types of TMJ problems can lead to more serious conditions, early detection and treatment are important.\nNo one treatment can resolve TMJ disorders completely and treatment often takes time to be effective.\nTrouble with Your Jaw?\nTMJ disorders develop for many reasons. You might clench or grind your teeth, which tightens your jaw muscles and stresses your TM joint. You may have a damaged jaw joint due to injury or disease. Injuries and arthritis can damage the joint directly or stretch or tear the muscle ligaments. As a result, the disk, which is made of cartilage and functions as the cushion of the jaw joint, can slip out of position. Whatever the cause, the results may include a misaligned bite, pain, clicking, a grating noise when you open your mouth, or trouble opening your mouth wide.\nDo You Have a TMJ Disorder (TMD)?\n- Are you aware of grinding or clenching your teeth?\n- Do you wake up with sore, stiff muscles around your jaws?\n- Do you have frequent headaches or neck aches?\n- Does the pain get worse when you clench your teeth?\n- Does stress make clenching and pain worse?\n- Does your jaw click, pop, grind, catch, or lock when you open your mouth?\n- Is it difficult or painful to open your mouth, eat, or yawn?\n- Have you ever injured your neck, head, or jaws?\n- Have you had problems (such as arthritis) with other joints?\n- Do you have teeth that no longer touch when you bite?\n- Do your teeth meet differently from time to time?\n- Is it hard to use your front teeth to bite or tear food?\n- Are your teeth sensitive, loose, broken or worn?\nThe more you answered “yes” to any combination of these questions, the more likely it is that you have a TMJ disorder. Understanding TMJ disorders will also help you to understand how they are treated.\nTMJ Surgery Overview\nFor a brief narrated overview of the TMJ surgery process, please click the image below. It will launch our flash educational MiniModule in a separate window that may answer some of your questions about TMJ surgery.\nTreatment of TMD\nThere are various treatment options that can improve the harmony and function of your jaw. Once an evaluation confirms a diagnosis of TMJ disorder, your doctor will determine the proper course of treatment. It is important to note that treatment always works best with a team approach of self-care combined with professional care.\nThe initial goals are to relieve muscle spasm and joint pain. This is usually accomplished with a pain reliever, anti-inflammatory, or muscle relaxant. Steroids can be placed directly into the joints to reduce pain and inflammation.\nSelf-care treatments can be effective as well and include:\n- Resting your jaw\n- Keeping your teeth apart when you are not swallowing or eating\n- Eating soft foods\n- Applying ice and heat\n- Exercising your jaw\n- Practicing good posture\nStress management techniques such as biofeedback or physical therapy may be recommended, as well as a temporary, clear plastic appliance known as a bite splint. A splint fits over your top or bottom teeth and helps keep your teeth apart, thereby relaxing the muscles and reducing pain. There are different types of appliances used for different purposes. A nightguard splint helps you stop clenching or grinding your teeth and reduces muscle tension at night and helps to protect the cartilage and joint surfaces. An anterior positioning splint moves your jaw forward, relieves pressure on parts of your jaw and aids in disk repositioning. It may be worn initially 24 hours/day to help your jaw heal. An orthotic stabilization appliance may be worn 24 hours/day or just at night to move your jaw into proper position. Appliances also help to protect from tooth wear.\nWhat about Bite Correction or Surgery?\nIf your TMJ disorder has caused problems with how your teeth fit together, you may need treatment such as bite adjustment (equilibration), orthodontic treatment, with or without jaw reconstruction, or restorative dental work. Surgical options such as arthroscopy and open joint surgery are sometimes needed, but are reserved for severe cases. TMJ surgery is not considered unless the jaw cannot open, is dislocated and nonreducible, has severe degeneration, or the patient has undergone more conservative treatment unsuccessfully.']	['<urn:uuid:b3ae6868-a0c8-4b2c-9fc7-bb9d5914d2a6>']	factoid	with-premise	long-search-query	similar-to-document	single-doc	expert	2025-05-13T05:52:58.810667	11	41	823
20	What role do family relationships play in African folktales, and how are efforts being made to preserve these narrative traditions for future generations?	Family relationships are central themes in African folktales, as shown in stories like 'A Girl Who Lived In A Cave' where a brother protects his sister from a cannibal, and 'The Girl Who Married A Lion' which explores family bonds through the relationship between a woman, her brother, and her sons. These stories reflect the importance of familial protection and trust in African cultural traditions. Regarding preservation efforts, organizations are working to protect these cultural narratives. For instance, in Malawi, a comprehensive project involving Sony Corporation and UNESCO is underway to collect, edit, and digitize folktales using high-definition recording equipment. The recorded materials will be used in early and primary education and added to the National Digital Repository Project at the National Library Service. The goal is to ensure these stories continue to be shared with future generations, with plans to publish them in children's books in various languages and present them on TV stations.	"[""- Shopping Bag ( 0 items )\nDennis DrabelleIn these folktales, Smith (who was born in Zimbabwe and now teaches law at Edinburgh University) acts as a veritable bridge between cultures.\n— The Washington Post\n|A letter from Mma Ramotswe|\n|Guinea fowl child||3|\n|A bad way to treat friends||8|\n|A girl who lived in a cave||13|\n|Hare fools the baboons||23|\n|Sister of bones||36|\n|Beware of friends you cannot trust||53|\n|Children of wax||57|\n|A tree to sing to||72|\n|A blind man catches a bird||78|\n|Hare fools lion - again||82|\n|Why elephant and hyena live far from people||99|\n|The wife who could not work||107|\n|The sad story of tortoise and snail||119|\n|An old man who saved some ungrateful people||125|\n|The girl who married a lion||141|\n|Two bad friends||146|\n|How a strange creature took the place of a girl, and then fell into a hole||152|\n|Greater than lion||160|\n|The grandmother who was kind to a smelly girl||169|\n|The baboons who went this way and that||173|\n|Two friends who met for dinner||177|\n|The Thathana Moratho tree||181|\n|Tremendously clever tricks are played, but to limited effect||185|\nPosted October 8, 2011\nMany of us have read Aesop's Fables, which teach us about man's foibles and morality, but I had never heard of many of these tales from Africa. These folk tales from Zimbabwe and Botswana are told by former law professor Alexander McCall Smith, a native of Zimbabwe, who now makes his home far to the north in Scotland. Africa maintains a rich tradition of oral literature and these stories are told with humor and spirit. Allow me to describe two of these tales to give the reader some idea of what I mean.\nIn A Girl Who Lived In A Cave, a cannibal confronts a girl returning to her family's home. When the family invites him to share a meal with them, he gobbles it up and abruptly leaves. The cannibal's appearance makes the family uneasy and they decide to depart. The young girl objects to leaving her beautiful home, but decides to live in a nearby cave while her family is gone. Soon, the girl's brother returns to check on his sister, singing her a special song to gain entrance to the cave. Unfortunately, the cannibal overhears the tune and later tricks the girl into allowing him to enter her sanctuary. The girl is captured and trussed up, while the cannibal lights a fire, preparing to eat her for his dinner. Like an avenging angel, the brother returns, pushes the cannibal into the flames instead and happily frees his sister.\nThe Girl Who Married A Lion is about Kumalo's daughter, who married a fine strong man. Soon, the woman's brother begins to worry that his sister has really married a lion in disguise. Several years go by and the woman bears two fine sons, but the brother worries that his brother-in-law still may have deceived his bride. Using a goat as bait, they trick the brother-in-law, finally driving him off. Now, the woman worries that her sons may somehow become lions, too. In a daring test, they cage the two sons in an area infested by lions, judging that if the boys are truly lions, the huge carnivores will not attack two of their own kind. The uncle is forced to defend his nephews to save the boys from the charging lions. Thus reassured, the woman once again welcomes her sons home.\nI thoroughly enjoyed reading this book! Children will really like this rare and wonderful departure from the more traditional folk tales. I embraced the difference and am the better for it."", ""Malawi is endowed with a diversity of folktales and culture of storytelling handed down orally from one generation to the next. But because these stories exist only in oral form, very few are preserved in print or audio format. And with the aging of live performers, the precious intangible heritage is on the verge of extinction. The Malawi Folktales project aims to safeguard the Malawian cultural heritage before it disappears.\nMalawi is a landlocked country in southern Africa, bordering Tanzania in the east, Mozambique in the south, and Zambia in the west. Of its population of approximately 15 million, more than 80% is rural and dependent on agriculture for subsistence, and some 82% between the ages of 15 and 24 are illiterate.\n(Source: UNDP International Human Development Indications)\nMalawi represents some 16 different languages spoken by a diversity of ethnic groups, each of which has stories handed down from generation to generation. Folktales and story-telling play an integral, indeed central, role in the live of Malawians. And yet because they are circulated within communities by word of mouth for the purpose of education, either in social morals or for children, they are seldom recorded in print or audio format.\nThis oral tradition is all but vanishing in recent years due to the aging of community figures who can deliver live performances as well as changes in lifestyle. And because Malawi has made little effort to preserve the tradition, the unique culture of its ethnic groups is on the verge of extinction.\n“The emphasis is on respect for tradition as well as nature in general. The respect for tradition goes along with the belief that everything, according to the elders’ vision of the world, trees, animals, rivers, stones, mountains, are endowed with life, hence the interaction of humans and non humans in the folktales. Mountains, trees or stones were believed to be the abode of the spirits. Because today respect for these has disappeared, we see the wanton cutting down of trees, the destruction of sacred places and the disinterest in oral traditions,” said Professor Boston Soko of Oral Literature, University if Mzuzu. He provides a pool of consultancy services as an expert of the field.\nSony Corporation, at the request of Malawi National Commission for UNESCO and the GFCT, provides audio-visual recording equipment and technical training for local engineers in this project that aims to collect, edit, and digitize (document) the valuable and rich traditional culture of Malawians and pass it down to children of the next generation.\n■Director, National Librarian, National Library Service\nFolktales are very important because they help to preserve part of our cultural Heritage. I am very excited with this project because the documented Malawian Folk tales will enrich our information Resources that will be shared with readers at the National Library Service. The final product will also be digitized and added to our National Digital Repository Project at the National Library Service. Some of the folktales will eventually be published in children books in various languages. I look forward to the day when these folktales will be presented on our TV Stations.\n■Head Development Information Centre, Malawi National Library Service\nFolktales and fables are one of the oldest educational tools through which cultures have passed values and lore from one generation to the next. Storytelling based on traditional folktales is a gentle way to guide young people toward constructive personal values by presenting imaginative situations in which the outcome of both wise and unwise actions can be seen.\n■NLS ICT Specialist for data entry & documents preparation\nWhen I was 6 years old, my family and I happily sat around the fire listening to folktales told by my Mother. This stopped when we got our first television at home. By integrating the modern technology and tradition, this project will reintroduce the tradition of folk-telling to another generation.\nTristam Johnson, Boston Machika, Mathews Katoleza, Chimwemwe Sumani, and Sherpherd Phiri\nThe full high definition recording equipment provided by Sony is the latest on the market and has enhanced the quality of the recording as well as knowledge of the technical team.\n■Malawi National Commission for UNESCO\nC J Magomelo\nA nation without culture is worthless and folktales carry the basic principles of this culture which we must preserve\n■Global Future Charitable Trust\nThe project team trained by Sony is on a two-year tour of Malawi, collecting and documenting folktales circulated by word of mouth. The audio-visual recordings will be used not only in early and primary education to teach life skills to Malawian children, but also as a tool to disseminate the wisdom and values embodied in the oral traditions of the African continent to people across the world. We hope to draw on our experiences in Malawi and spread the project to other regions of southern Africa.\n■Global Future Charitable Trust (GFCT):\nGFCT is registered as a charitable entity by New Zealand Charities Commission under the charities Act 2005. GFCT aims to attain social change through sustainable human development as a means of expanding people's life opportunities and their capacity to make their own decisions.\n■Malawi National Commission for UNESCO:\nMalawi National Commission for UNESCO is a government statutory body established to coordinate interaction between UNESCO and relevant Ministries, Departments, institutions of higher learning, civil society organizations and non-governmental organizations in UNESCO's fields of competence i.e. Education, Science, Social and Human Science, Culture and Communication.""]"	['<urn:uuid:dd68c2c9-8407-4c0c-b14c-580e31d7cf24>', '<urn:uuid:1b44ca3c-e26d-44a0-8d3a-50f9a40ac153>']	open-ended	direct	verbose-and-natural	similar-to-document	multi-aspect	expert	2025-05-13T05:52:58.810667	23	155	1498
21	what benefits regular weighing cattle provide for monitoring pasture problems	Regular weighing of cattle can reveal pasture deficiencies by showing differences in average daily weight gains depending on which paddock the cattle were grazing in. This allows for definitive identification of serious pasture problems in specific paddocks.	['At Jingeri we actively use cattle weights as an important and adaptive management tool. In early 2013 we urgently needed to upgrade our stock yards and cattle run. The existing run down infrastructure was not only difficult to use, but more critically was dangerous for our cattle and the team handling them.\nThe decision was made to include weigh bars with the new crush as it was a small cost in terms of the overall investment for the future. Plus we believe that we will see a rapid return on investment because it takes the guess work of general cattle management.\nRelating weights to profits:\nThe beauty of weighing your cattle each time you handle them, is that just like the ‘canary in the coal mine’, it will tell you very quickly when things are going wrong. Weight fluctuation and trends in your cattle can tell you a number of things.\nMaintaining body condition scores in breeders:\nAre your breeders with calves at foot getting enough protein in their diet? By calculating and recording average daily weight gains (ADG) over time, even small weight losses become obvious when you are recording weights at every muster. This allows for early intervention with things such as vitamin supplements, lick blocks, early weaning and supplementary feeding. At Jingeri we have avoided severe body condition loss in our cows by using these strategies earlier, rather than later, when body condition loss becomes visible. This has proven an enormously beneficial tool during the extreme dry conditions that we have been experiencing over the past couple of years.\nBy avoiding extreme body condition loss, we prevent problems in the future such as reduced fertility, low calf weights, calving difficulty and shortened breeding lifespan. This all amounts to reduced financial loss in the future and greater control of input costs in the short term.\nSomething that has become very obvious to us at Jingeri is that weighing your cattle can tell you an awful lot about the pastures the cattle have been grazing. I was astounded when we started to monitor cattle weights, the differences in ADG depending on the paddock the cattle were in. Whilst I recognise that most experienced cattle farmers are able to instinctively make these connections, having the weights recorded has allowed us to definitively identify serious pasture deficiencies in certain paddocks. We are now in the process of instigating a pasture improvement plan as part of an overall Grazing BMP. This involves using cattle to strategically graze specific areas, slashing and weed treatments, applications of trace minerals and chicken manure, adding more than 12 new pasture species (seed) and live soil microbes. All of these treatments are guided by a regime of soil testing, so that we are treating the specific deficiencies in our pastures. Ultimately we are very confident that by using these scientifically supported methods (Liddell Grazing Trial, 2014; More Beef from Pastures, 2013; Grazing BMP, 2013) we will see within five years:\n- Improved nitrogen availability and uptake within our pastures.\n- Better response to rain events.\n- Greater resilience during dry spells.\n- Improved nutrient cycling and humus production.\n- Improved soil biodiversity.\n- Return of native pasture species – especially nitrogen fixing legumes.\n- Low input costs producing significant financial benefits over time.\nTaking the guess work out of when to turn off:\nOne of the most obvious advantages to weighing our cattle at every muster was the increased accuracy in determining the weight gains in our fattening steers. Having made a significant investment in a mob of high quality Brangus yearling steers in July 2013, it was crucial that despite the drought, we would be able to fatten them quickly ready for market. Weighing them every six weeks or so provided several advantages:\n- Regular handling meant that they all met MSA criteria for temperament. This is critical for meat quality and fat cover as well as ossification levels in the growing steers. Mustering these boys was really a pleasure, they came when called and many could be hand fed. Ultimately this means reduced cortisol levels (a stress hormone) over time which is the enemy when trying to grow out MSA eligible beef.\n- We could see quickly when pasture health was declining as this was reflected in reduced ADG. Our decisions to move cattle to new grazing areas is based on this factor, rather than relying on how the pasture looks. This gave us the freedom to better spell less productive paddocks and ensure that the boys were always given access to the best available pasture at any time. As the dry weather continued and soils dried out, this became an invaluable method for maintaining positive weight gains in these fattening steers, whilst preventing pasture and soil degradation.\n- Recording the ADG over time allowed us to see exactly how we were doing in terms of reaching our weight gain targets. It also allowed us to accurately predict when they would be ready for market.\nThe result of all of this? Well it took us around 13 months to reach our target sale weights. These steers were wholly grass fed with only trace mineral supplementation and averaged a total gain of 200kgs per head. We sold them on to a Feedlot operation at an above market price (for that time), where they would go onto grain for 100 days and then be sold into the MSA/Jap market. Whilst this is not an extraordinary outcome generally, it occurred at a time when high quality grass fed cattle were in extremely short supply due to widespread long-term drought conditions. And yes we made a significant profit with a greater than 50% margin after costs!!!']	['<urn:uuid:f173e216-a562-4a5a-93e0-824b53f324b4>']	factoid	direct	long-search-query	similar-to-document	single-doc	novice	2025-05-13T05:52:58.810667	10	37	947
22	As a healthcare administrator looking to transition into military service, I'm curious about what educational background and training is required to become a Medical Service Corps officer in the Air Force. Could you explain the prerequisites and initial training?	To become a Medical Service Corps (MSC) officer in the Air Force, you need a bachelor's or master's degree in Healthcare, Management, Economics, Finance, Operations Research, Business Administration or a similar field. After commissioning, you must complete a specialized 5-week Health Service Administration Course at Fort Sam Houston, Texas. This course prepares new MSC officers to work as entry-level department managers in Air Force Medical Treatment Facilities and is accredited for 11 graduate credit hours by the American Council on Education. Additionally, MSC officers are expected to obtain Board certification from national healthcare administration organizations, typically while serving at the rank of captain or Major.	"[""The United States Air Force Medical Service (AFMS) consists of the five distinct medical corps of the Air Force and enlisted medical technicians. The AFMS was created in 1949 after the newly independent Air Force’s first Surgeon General, Maj. General Malcolm C. Grow (1887–1960), convinced the United States Army and President Harry S. Truman that the Air Force needed its own medical service.\nIn the summer of 1949, Air Force General Order No. 35 established a medical service with the following officer personnel components: Medical Corps, Dental Corps, Veterinary Corps, Medical Service Corps, Air Force Nurse Corps, and Women's Medical Specialist Corps.\nThe AFMS is led by The Surgeon General of the Air Force, who holds the rank of lieutenant general. The AFMS is found in all three components of the Air Force, including the Active Air Force, the U.S. Air Force Reserve, and the Air National Guard. Headquartered at The Air Staff, Bolling Air Force Base, Washington, D.C., AFMS senior leaders can be found in all of the Major Commands and in the Pentagon.\nBiomedical Sciences CorpsEdit\nEstablished in 1965 from the defunct Women’s Medical Specialist Corps and components of the Medical Service Corps, the Biomedical Sciences Corps (BSC) consists entirely of commissioned officers. This is the most diversified of the Medical Corps, consisting of members in Physical Therapy, Optometry, Podiatry, Physician Assistant, Audiology/Speech pathology, Psychology, Social Worker, Occupational Therapy, Aerospace physiology, Biomedical Scientists, Clinical Dietitian, Bioenvironmental Engineering, Public Health Officers, Entomology, Pharmacy, Medical lab Officers, and Health Physicists. The Chief of the Biomedical Sciences Corps is a brigadier general.\nThe Dental Corps consists of commissioned officers holding the Doctor of Dental Surgery degree or Doctor of Dental Medicine degree or a further, post-graduate degree. The chief of the Dental Corps is a major general.\nThe Medical Corps consists entirely of commissioned Air Force physicians, including holders of the Doctor of Medicine (MD) degree and the Doctor of Osteopathic Medicine (DO) degree. A member of the Medical Corps can also become a Flight Surgeon. The Chief of the Medical Corps is a brigadier general.\nPhysicians can enter service into the Air Force through several different paths. Cadets at the US Air Force Academy can compete for selection to medical school at the Uniformed Services University of the Health Sciences (USUHS) or at any CONUS medical school though HPSP. An academy graduate who attends USUHS will incur a twelve-year (seven for USUHS and five for the Academy) service commitment not counting any training such as residency and fellowship; an academy graduate who attends a civilian medical school will incur a nine-year service commitment not counting any training such as residency and fellowship. Civilian undergraduates can also apply to USUHS, they incur a seven-year service commitment. USUHS student are commissioned officers at the rank of Second Lieutenant (O-1) and are paid as full-time active duty members. All of their school and expenses are paid by the US Air Force. USUHS graduates must complete residency training in a military residency program. Civilian medical school students can apply for the Health Professions Scholarship Program (HPSP). HPSP medical students have their medical school tuition paid by the US Air Force and receive a monthly stipend for living expenses, but they are not on active duty. These graduates can usually attend a civilian or military residency training program and incur a three or four-year service commitment (one year commitment per year of scholarship assistance). Civilian resident physicians can enter Air Force service through the Financial Assistance Program (FAP). FAP physicians receive payment while in residency, but do not receive funds to pay for medical school. Unlike all other programs in the Air Force, they incur a service commitment of based on their length in the program, plus one year (e.g. two years in the program incurs a three-year service commitment). All graduates of residency training enter active duty at the rank of Captain (O-3). Most of the US Air Force Academy graduates pursue a career as an Air Force physician, while the vast majority of HPSP graduates leave the service as soon as their commitment is completed.\nThe Air Force also recruits fully trained and practicing physicians to enter active duty. Their rank at entry is based on their experience.\nMedical Service CorpsEdit\nThe Medical Service Corps (MSC) consists entirely of commissioned officers. Members are required to hold a bachelor's or master’s degree in Healthcare, Management, Economics, Finance, Operations Research, Business Administration or similar degree before receiving a commission, and must complete a specialized Air Force healthcare administration course. This course, conducted at Fort Sam Houston, Texas, provides new MSC officers with the knowledge needed to perform as an entry level department manager in an Air Force Medical Treatment Facility (MTF). The Health Service Administration (HSA) Course is a 5-week course designed to train newly commissioned Medical Service Corps officers for their first duty assignment. The course is accredited for 11 graduate credit hours by the American Council on Education (ACE). MSCs serve as hospital administrators, resource management officers, directors of information systems/technology, managed care and patient administrators, group practice managers, medical logisticians, and medical readiness officers. MSC officers are also expected to become Board certified by one of several national healthcare administration organizations. This is usually done while the officer is in the rank of captain or Major. The Chief of the Medical Service Corps is Brigadier General Charles Potter.\nThe Nurse Corps consists entirely of commissioned officers. New members of the Air Force Nurse Corps are required to hold at minimum a Bachelor of Science in Nursing degree prior to receiving a commission. Members of the Air Force Nurse Corps work in all aspects of Air Force Medicine and can serve as Flight Nurse in aeromedical evacuation missions, nurse practitioner, and nurse anesthetist.The first Chief of the Air Force Nurse Corps was Colonel Verena Marie Zeller (1949–1956). The first two-star general Chief of the Air Force Nurse Corps was Major General Barbara Brannon; she was replaced in 2005 by Maj Gen Melissa Rank. In 2008, it was announced that Colonel Kimberly Siniscalchi would be promoted to the rank of Major General and serve as the Chief of the AF Nurse Corps, thereby bypassing the rank of Brigadier General (1-star).\nAir Force Enlisted Medical personnel perform in over twenty different medical fields including medical administration, mental health, dental care, optometry, physical therapy, aeromedical evacuation, medical logistics, laboratory sciences, surgical care, emergency care, radiology, pharmacy, etc. Enlisted medics are led by a Chief Master Sergeant.\n|Biomedical Science Corps Badge|\n|Dental Corps Badge|\n|Medical Corps Badge|\n|Medical Service Corps Badge|\n|Nurse Corps Badge|\n|Enlisted Medical Badge|\n- 15th Medical Group:\n- 15th Aeromedical-Dental Squadron\n- 15th Medical Operations Squadron\n- 15th Medical Support Squadron\n- AFMS Home Page\n- AFMS online history\n- Virtual Naval Hospital - a digital library of military medicine and humanitarian medicine\n|This page uses Creative Commons Licensed content from Wikipedia (view authors).|""]"	['<urn:uuid:ab47f4cc-2bec-47f4-962f-0ca5e9f51074>']	open-ended	with-premise	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-13T05:52:58.810667	39	105	1151
23	skin boats fiberglass differences construction materials	Traditional skin boats like umiaks were made from local materials including driftwood, animal skins, sinews, tusks, bones and baleen, while fiberglass boats are constructed using glass fiber woven into fabric, with multiple layers of fiberglass cloth and resin applied over a gel coat in a mold.	['Inuit means of transportation\nInuit from the Thule culture used the umiak, kayak and dog sledge on their way to Greenland in the 1200s. These are highly specialized means of transport adapted to the difficult Arctic travelling conditions and the hunting of sea mammals. They are made of local materials in the form of driftwood and the skins of the hunted animals supplemented by sinews, tusks, bones and baleen.\nAn umiak is a 7-9 m long boat with a carrying capacity of 1.5-2 tons. The wooden skeleton is covered with sewn-together, waterproof skins. For whaling it was paddled by men, on journeys and transport it was rowed by women. It was also used for hunting trips for reindeer in inland West Greenland, when it was carried at crossing points from the upper reaches of the fjords to inland lakes. It could be furnished with a sail made of gut casings, or in later times of canvas.\nIn South Greenland it went out of use in the 1920s after the transition to commercial fisheries and the introduction of wooden boats. In other parts of the country its use continued for some years. Among the Inupiat in Alaska it is still used in connection with the traditional catching of the bowhead whale.\nThe kayak is a sophisticated vessel adapted to all kinds of weather. It consists of a light wooden skeleton covered with sewn-together, waterproof skins, and is closely adapted to the individual user’s anatomy. The kayak was mainly used for hunting.\nThe kayak and the related hunting equipment have constantly undergone changes and development, determined by among other things local natural conditions and hunting opportunities. The introduction of rifles in the mid-1800s led to the invention of a small keel fin, a camouflage sail and a gun case.\nIn South West Greenland the number of kayaks dropped after 1920, as a result of the occupational transition from hunting to fishing. In other areas of Greenland the transition to wooden boats was more gradual, and the use of the kayak continued in many places until the 1960s. In the Qaanaaq area and the northern Upernavik district the kayak is still used for hunting sea mammals.\nThe dog sledge\nThe dog sledge is tied together with skin straps which make the sledges flexible. Originally the runners had sledge shoes of bone or tusk; later iron was used, and later again plastic. The sledge is drawn by a team, typically of 7-10 dogs which are controlled by commands and dog whips.\nDog sledges are mainly used for transport to and from hunting and fishing places on sea ice and on land. The use of sledges is limited to areas with winter ice cover – that is, the West Coast north of Sisimiut, the Qaanaaq area and East Greenland. Among the Inughuit farthest to the north, where there are 9-10 months of ice cover, it was the most important means of transport.\nThere are three sledge types. The longest is the Thule sledge, which is adapted to the long journeys of the Inughuit on the sea ice, where they often have to cross cracks in the ice. The generally shorter West Greenland sledge is adapted to more varied terrain with more frequent travel on land. In Ammassalik before the colonial period people used a small dog sledge with upward-turning runners in front and wide uprights, drawn by just 3-4 dogs. This was superseded in the 1930s by a longer type with wide runners that is well suited to travel in an area with high annual snowfall.\nWooden boats and motor boats\nAfter the emergence of the large cod shoals off South West Greenland shortly before 1920, wooden boats began to replace skin boats for use in fishing and transport. In the first few decades most wooden boats were built locally. From the 1920s these were inspired by the flat-bottomed dories that western European fishing boats brought for the cod fishing in the North Atlantic and the waters west of Greenland. The dories were launched from mother ships and used for long-line fishing.\nThe first Greenlandic fitters were trained in engine factories in Denmark in the 1910s, and in the course of the 1920s the first Greenlanders became owners of motorboats for fishing.\nThe canvas boat was developed by Aron Nielsen and Apollo Tobiassen in Kangeq west of Nuuk around 1940. The type later became widespread along the whole of West Greenland. The canvas boat is inspired by features from the kayak, the umiak and the dory, and combines several of the advantages of these boats. It is cheap and quick to manufacture, and is suitable for both fishing and hunting. A short, particularly light version was made for use in reindeer hunting inland.\nThe boat was covered with canvas. Later other kinds of covering were also used, including oilcloth. In Kangeq the boats were sometimes fitted with a small sail. In the 1950s a version of the canvas boat was developed that could be fitted with an outboard motor.', 'Fiberglass is currently the most common material used to craft small recreational boats and other watercraft.\nChances are, if you have purchased a recreational boat, it is made of fiberglass, also known as Glass Reinforced Plastic or GRP.\nIn this article, we will look at how long fiberglass boats last and the factors that impact fiberglass boats’ durability.\nHow Long Do Fiberglass Boats Typically last?\nFiberglass boats can be sound and seaworthy for up to fifty years or more. Fiberglass is very durable, and with proper maintenance and care, fiberglass boats can last for many decades.\nFiberglass itself will not break down but instead will break down due to outside factors.\nSome factors that will affect break down are:\n- Exposure to UV rays\n- Fatigue from movement\n- Water saturation\n- Salt from seawater.\nToo much UV rays can cause the fiberglass to become more brittle. Because most boating happens during sunny weather conditions, this is a highly probable issue.\nWater saturation can cause a breakdown between the fiberglass and the resin. This is most often caused by acid formation with the water and products hidden in the fiberglass.\nSalt from saltwater can move between the fiberglass and become deposited in the fiberglass’s larger porous areas. This causes the salt to add to the pressure on the fiberglass.\nOne final issue could be poor production at the beginning of the boat’s life. This is hard to combat, and you will want to ensure you purchase a high-quality boat.\nOne of the biggest issues you will encounter with your fiberglass boat is the other components. Your fiberglass is much more likely to last than your other structural, engine, and electrical components.\n3 Factors That Impact The Durability Of Fiberglass Boats\nSo, what if you already have a fiberglass boat?\nYou’re probably thinking: what should I look out for?\nThe main things you want to look for in your fiberglass are:\n- Small cracks\n- Water damage\n1) Small Cracks\nTo find aging damage, you will want to look for microscopic cracks.\nAt first, they might seem minor, almost hairline. These cracks should not be ignored as they can get bigger with time—the bigger the cracks, the more pressure is applied to the fiberglass’s structure and integrity.\nThis break in the integrity of the fiberglass can further compromise the structure of your vessel. For this reason, fiberglass boat owners need to monitor their boats for cracks constantly.\nWhen cracks are found, they need to be dealt with and filled in.\nFiberglass can also experience fatigue.\nVibration and impact on the fiberglass can cause stress and fatigue. Repetitive waves, engine vibrations, and other activities can cause strain on the fiberglass.\nAfter a certain amount of time, fiberglass can also get worn down. Without proper care, the fiberglass can become weak and brittle.\n3) Water Damage\nYou need to ensure your fiberglass is not experiencing water damage.\nWhile the resin itself is waterproof, if water gets in, it can damage the fiberglass. Eventually, after enough water is absorbed, the damage will apply more and more pressure, which can cause wear, blistering, and cracking.\nThe part of the boat that is most susceptible to this damage is the part of the hull that is below the waterline.\nThe last thing to look out for is heat and sun damage.\nWith enough heat and UV rays, the fiberglass in the hull can become rigid and brittle. This can even cause warping.\nOne major issue with a fiberglass hull is that warping or major damage to the fiberglass itself can be challenging and expensive to repair.\nAs previously expressed, if you own an older boat, your main issue is most likely not in the fiberglass. That doesn’t mean that you should not need maintenance and monitor your fiberglass. Vigilance, maintenance, and preventative care are the best way to maintain your fiberglass’s structural integrity.\nHow To Prolong The Life Of Fiberglass Boats\nSome people will try to tell you that your fiberglass “does not need maintenance.”\nThis is not true.\nCompared to other types of boats, especially wooden boats, fiberglass is much less maintenance. This does not mean that there is no maintenance involved, and you must keep up with it.\nMost importantly, when maintaining your boat, you need to protect the bottom constantly exposed to water.\nIf your boat is left in the water for even a few days, you will want to attempt to protect it from algae and other growth. To prevent this, there are certain protectants and bottom paints you can apply.\nYou will want to ensure whatever growth repellent you purchase works for the area and body of water you plan on having your boat in. Before application, you will want to make sure to properly sand or otherwise prepare your fiberglass.\nThe area between the railing and the waterline needs to have regular maintenance done because this part of your boat takes on most of the waves, spray, and sun. Without proper care, this area will fade, oxidize, and get hazy. To combat this wear, you need to make sure you keep up the wax on your boat.\nIf waxing becomes a hassle, you can get a buffer. This will enhance the process and make it easier to complete.\nThe deck of a boat also sees a lot of wear. This comes from sun, dirt, grime, spills, and other general wear and tear. The main way to combat this is regular washings and a good stiff brush.\nBe sure never to wash a “non-slip” area with wax. This is highly important on the deck where people walk. Safety should always be your priority.\nBesides this maintenance, you will want to maintain cleanliness on all other aspects of your boat. This will help to keep the condition pristine and avoid aging and wear.\nFinally, no matter what type of boat you own, you will want to maintain the engine properly. You want to make sure you maintain your boat engine constantly.\nThis is true if you use your fiberglass boat every day or only occasionally. If you only use your boat occasionally, you will still want to maintain the engine as if you use it regularly.\nMaintaining your boat engine is like maintaining your vehicle engine. You will want to make sure it is properly oiled fueled, and the boat battery is charged.\nLike a car, keeping a boat’s radio or lights on for a long time can drain a battery and even kill it.\nHow To Spot Aging Signs On Used Fiberglass Boats\nWhen buying an old fiberglass boat, especially a “fixer-upper,” there are some things to keep in mind.\nUnlike wooden trim items, fiberglass boat structural issues are more difficult to repair or restore.\nRestoring a fiberglass hull can be almost impossible, depending on the wear accrued. Because these hulls are made all at once, patching them is your only option if the problem is that simple.\nWooden boats are more maintenance and more difficult to maintain, but they do allow for the replacement of parts by competent and qualified artisans.\nWhen purchasing a used fiberglass boat, you will want to look out for the signs listed above. You will need to know if you are looking at any structural issues.\nMake sure to check for cracks, fading, wear, growth, or damage. Look at the high-stress areas for cracks, wear down, or other signs of damage.\nThe pressure created in the fiberglass can cause issues for you later.\nAs well as fiberglass wear, you will want to make sure that your hull is not chipped, blistered, or starting to flex excessively.\nStress on a fiberglass hull can cause flexing as degradation occurs. This can cause major cracks and severe hull issues.\nIssues found with a boat can be fixed. Based on the extremity of the issue and your experience, you should look for a professional opinion on maintenance and damage restoration. This is important before you buy. Taking on too many issues may quickly make your new boat purchase a headache you never wanted and were not prepared for.\nIf everything is intact with the boat, and you do not see any cracks, warping, mechanical failure, or other issues, it would be safe to purchase the used fiberglass boat.\nIf you keep up with the proper maintenance, a used older fiberglass boat could last you many years to come.\nWhy Do Fiberglass Last So Long?\nFiberglass is a form of plastic that is reinforced using glass fiber. The glass fiber is usually woven into a fabric. This makes the fiberglass superior when it comes to durability.\nFiberglass material is relatively lightweight, extremely durable, and less brittle than standard glass or plastic.\nFiberglass can be easily molded and is often used to make more complex shapes. Standard uses for fiberglass are boats, aircraft, bathtubs, etc.\nFor a boat to be considered a fiberglass boat, the hull, deck, liner, and even large parts of the console are made from fiberglass.\nFiberglass boat construction in a mold first uses a gel coat; fiberglass cloth layers are applied, with resin applied on each layer.\nBefore fiberglass, boats were constructed from bark, wood, animal skin, iron, or steel. Today, larger ships are still constructed from aluminum or steel, while smaller recreational boats are made from fiberglass or GRP.\nFiberglass boat construction was experimented with as early as the late 1930s and is the main manufacturing method.']	['<urn:uuid:70b971ad-c5a5-444f-93ab-69bab2d49cbc>', '<urn:uuid:e2437e29-1570-448f-98ca-a5b77dbb93e5>']	factoid	direct	short-search-query	similar-to-document	multi-aspect	novice	2025-05-13T05:52:58.810667	6	46	2405
24	Can wildlife tunnels help animals cross highways while improving urban biodiversity?	According to studies, most wildlife do not want to use tunnels under roadways, with only select species willing to use them. However, urban conservation efforts like parks, green roofs, and corridors can help create connected habitats for wildlife in and around cities. A 2014 study found that rooftop gardens increased habitat connectivity for mobile species like bees and could improve ground-level habitat connections.	"['Finding California\'s Worst Highways For Wildlife | KCET\nFinding California\'s Worst Highways For Wildlife\nWhen a mountain lion in Los Angeles dies, it\'s most likely at the hands (or paws) of another mountain lion. When the otherwise solitary cats must contend with a cramped habitat hemmed in by freeways, aggressive, often deathly, interactions are a certainty. But the second most frequent cause of death for mountain lions in Los Angeles is cars. And that\'s not just true for mountain lions. Just about every species, both native and introduced, that calls California home turns up as roadkill from time to time.\nFor the last seven years, more than 1,000 volunteers have submitted more than 50,000 observations of roadkill to something called the California Roadkill Observation System, also appropriately known as CROS. The largest data collection effort in the world devoted to roadkill, CROS is run by the Road Ecology Center at UC Davis, which is itself managed by a biologist named Fraser Shilling. It might seem like a fairly macabre pastime, but Shilling points out that while the volunteers who contribute to the database come from a wide range of backgrounds, all have something in common. ""They think that collecting information about harm that people cause the environment can help reduce the harm.""\nWildlife collisions aren\'t just bad for the animals of course. When an animal – especially a large one – enters a road or highway, it poses a hazard to drivers, who might crash into the animal or who might swerve and get in an accident anyway. In addition to the property damage from these accidents, there\'s also the threat of injury or death.\nAccording to one of Shilling\'s recent analyses, there were nearly 6,000 car accidents that involved wildlife in California between February of 2015 and February of 2016. According to his calculations, they came at a cost of some $225 million dollars. More than nine of every ten incidents involved deer, with coyotes, black bears, mountain lions, and others filling in the rest.\nWhile just about every road, street, and highway winds up with the carcasses of dead bugs, birds, reptiles, amphibians, or mammals on them (though CROS only tracks vertebrates, not insects or other invertebrates), some spots are worse than others. Thanks to the massive amounts of data that Shilling and his colleagues have amassed, they can use powerful statistical modeling techniques to pinpoint roadkill hotspots. These are places that have a disproportionate number of dead animals compared to other stretches of highway.\nFor 2016, those hotspots included the area where Routes 1 and 101 meet north of the Golden Gate Bridge, for example, two stretches of Interstate 280 near San Mateo and Palo Alto, the coastline near Santa Rosa, and so on.\nMore on Wildlife Crossings\nThere are strategies for mitigating those hotspots. In some places, wildlife bridges like the one planned for Liberty Canyon in Agoura Hills are best. But these come with a hefty price tag, and aren\'t necessarily viable options everywhere or for every species. All told, the Liberty Canyon crossing could cost as much as $100 million dollars.\nThe most common strategy in California involves building tunnels or culverts underneath roadways. There\'s just one problem. ""We find that most wildlife do not want to go through tunnels,"" says Shilling. Only a select few species are willing to use them, he explains. So while there may indeed be deer or bears on both sides of a highway, they could remain genetically isolated from each other. ""Wildlife will approach roads and will die on the surface, which challenges the idea of building these wildlife tunnels,"" he adds.\nAnd then, of course, the animals have to actually find those crossings. Larger mammals like coyotes or bobcats have large enough ranges that they could find the over- and under-passes we\'ve built to provide them safe transit pathways. But smaller mammals, along with all the reptiles and amphibians, don\'t move around all that much. Finding a safe crossing is more a question of luck than intelligence.\nThere is another strategy though for minimizing the impact of roads on wildlife. When wild animals become roadkill, it\'s usually because of speed. A car barrels down a highway so fast that by the time an animal has registered the threat it\'s too late. Or a driver cruises along so rapidly that by the time he or she spots an animal, there isn\'t time to brake safely.\n""The bottom line is that one of the cheapest solutions for roadkill is having reasonable speed limits and enforcing them,"" says Shilling. ""In most places it\'s tried, people are responsive and there are way fewer collisions.""\nWhile Los Angeles sees plenty of roadkill, there are lots more data available in CROS for Northern California and the Central Valley, making identifying hotspots in the Southland more of a challenge. Indeed, CROS only covers some 5 to 10 percent of California\'s roadways.\nStill, the scant data that are available paint a bloody picture. Much of LA\'s share of the 405 is covered in roadkill data, as are State Routes 27 and 23 between the 101 and the ocean. That should serve as no surprise, since both roads cut straight through the Santa Monica Mountains NRA. Another local roadkill cluster occurs along the 2 and 210 just south of the Angeles National Forest. And in Orange County, the 74 and 241 are death traps for animals, likely because they\'re so close to a wide expanse of green space in the Santa Anas. Apparently, animals living along the edge of these protected areas occasionally venture too far into the developed landscape and quickly get ground into the pavement.\nTo enhance the database, Shilling is embarking on a grand mission to sample every road in the state, and he\'s planning and working with an army of volunteer cyclists to do it. ""Literally every mile of every road in California, four times a year,"" he says. In the meantime, we can all do our part. As with most other citizen science efforts, all you need is a GPS-enabled smartphone with a camera. You can easily enter your data on the CROS website.\nFor ongoing environmental coverage in March 2017 and afterward, please visit our show Earth Focus, or browse Redefine for historic material.\nKCET\'s award-winning environment news project Redefine ran from July 2012 through February 2017.\nEnter to win a pair of tickets to see the new Frogs: Dazzling and Disappearing exhibit at Aquarium of the Pacific.\nKCET flagship news series ""SoCal Connected"" earns 24 nominations, most of any nominated television series.\nToday, roughly 100,000 people in Central Valley cannot drink the water that flows from their taps, for it is contaminated with high levels of toxins.\nOrange County Supervisor Michelle Steel and Deputy Sheriff Ray Grangoff will be among more than a dozen Golden State officials meeting with President Donald Trump today to discuss their opposition to California\'s sanctuary-state law.\n- 1 of 51\n- next ›', 'According to a 2020 study in Scientific Reports, large preserved areas may not have the best outcomes for wildlife protection. The study found that in 80 percent of protected regions, the protection provided to endangered animals was equal to or worse than if the areas had been randomly located.\nMany people think of conservation as best embodied by large national parks like Yellowstone and Yosemite. Much of our conservation efforts at the federal level have focused on designating large areas as protected lands to provide both habitat for wildlife and to conserve natural resources. But for conservation to be effective, we will also have to find innovative ways to protect wildlife on non-federal lands, and to connect islands of protected areas so that wildlife can move between them.\nPolicy tools can help to connect our current protected areas and even make way for wildlife in developed areas. Two promising options for policymakers to consider are exploring conservation in urban spaces and establishing wildlife corridors. These approaches can help create a mosaic of conservation that connects wildlife to islands of protected habitats.\nUrban conservation provides habitat in developed areas\nEmma Marris discusses the key misconception about nature in her 2011 book, Rambunctious Garden. Nature is not found only in large, untouched areas but also in populated areas dotted with parks and other bright spots of biodiversity. Marris highlights the growing urban population, showing that cities only cover 3.5% of land in the U.S. but house 63% of the U.S. population. By changing the way we view urban spaces and utilizing the small pockets of nature found in cities, we can create a more connected habitat for wildlife that live in and around cities.\nUrban parks and green spaces in cities can be used to help achieve the goals of conservation. These natural spaces can be integrated into a city to create areas furthering conservation efforts. Cities without open space for parks can transform retired industrial facilities and empty lots into green spaces. Other examples of green spaces include green roofs (or rooftop gardens), community gardens, and unmanaged vacant lots.\nThe Duwamish River cleanup is a prime example of urban conservation and part of the EPA’s Urban Water Partnership program. The partnership has identified 20 rivers and watersheds across the United States in need of revitalization. Its goal is to revitalize the communities surrounding the area and improve the quality of the habitat provided by the rivers. Following the degradation of one of Boeing’s facilities and the subsequent release of harmful chemicals into the watershed, Boeing began to aid the clean-up project. The clean-up, primarily focused on the removal of polychlorinated biphenyls (PCBs), has the added benefit of restoring habitat for wildlife that relies on the health of the watershed. Projects like this one show how improving the habitat already located in our cities can create a more diverse and sustainable ecosystem.\nAnother example of an organization working to get good conservation outcomes from urban spaces is the Conservation Fund. The fund partners with cities to improve urban conservation efforts. They work to develop parks, improve water management, and develop green infrastructure. The group partnered with local organizations and state officials in Florida to ensure the continued health of the Loxahatchee River Watershed. The fund ensured that urban development around the area maintained the habitats of the local wildlife. By partnering with local governments, organizations like the Conservation Fund can increase the importance of conservation in the development of cities.\nThe pockets of nature found in urban areas provide habitat for a multitude of animals and insects and help to connect different habitats. A 2014 study in the Ecological Society of America found that rooftop gardens increased habitat connectivity of mobile species, like bees, and could lead to increased connectivity of habitats on the ground. A connected urban green landscape provides pathways that increase genetic diversity in wildlife and aid in foraging and migratory activities. As urban development continues, including green spaces in our urban planning will increase the biodiversity of our cities and provide better habitats for the species that share them with us.\nWildlife corridors help connect habitat\nValuable habitat for species is often fragmented, leaving wildlife with no way to travel between areas they depend on for their survival. This makes connecting existing habitats more important. Wildlife corridors are the paths wildlife use to cross between habitats. Protecting existing wildlife corridors and establishing new ones provides safe ways for animals to migrate between existing habitats. A connected landscape also makes biodiversity more resilient to the effects of climate change.\nWildlife corridors can take many forms. Some examples are local corridors, regional corridors, flyways, rivers, and urban greenways. Although these corridors may seem challenging to implement, land use practices can be adjusted to augment existing landscape elements that already contribute to wildlife corridors. For example, strips along roadways can be planted with specific species to help provide links between patches of useful habitat. Protected wetlands can provide important stopping points for migratory bird species. Buffers can also be created around areas with important habitat to help species reach them.\nIn Nevada, a man-made wildlife corridor provides safe crossings for many animals. Some of the animals utilizing the crossing include elk, bobcats, and mountain lions. Over four years, 35,000 mule deer successfully crossed the wildlife corridor. Wildlife corridors not only protect animals, but also humans. Vehicle collisions with wildlife cost an average of $4,135 per collision – a total of over $6 billion annually in the United States. The installation of wildlife fencing and crossing sites has led to a 97% decline in collisions between cars and large wildlife along parts of the Trans-Canada highway. In Oregon, the total number of vehicle collisions with wildlife in 2020 was 5,997. If even 60% of these collisions were prevented by the implementation of crossing sites and fencing, the total cost of wildlife collision accidents would decrease from about $25 million to $10 million.\nWildlife corridors can also be used in conjunction with wildlife refuges which help to provide animals with areas to migrate to and mate. For ducks and geese, wildlife refuges in the heartland of the United States “serve as stepping stones to help birds weather their journeys.” These refuges offer safe spaces for birds to find food and water before they continue their migratory journey.\nWildlife corridors can also improve urban conservation efforts. Urban greenways connect open areas across cities. They provide both recreation for humans and connected areas for wildlife to travel. In Raleigh, North Carolina, 3,700 acres are connected by the Capital Area Greenway. The greenway provides 117 miles of trails for both humans and wildlife. Of course, the benefits of such projects must be weighed against their cost to ensure we are making investments in habitat connectivity that will truly pay off.\nLarge protected areas are islands of conservation\nUrban conservation and wildlife corridors can help us to connect islands of important habitat across the country, including federal lands. Most federal conservation efforts, like the establishment and management of national parks, focus on large areas of protected lands. This approach creates large chunks of nature that may not provide wildlife with the habitat they need to thrive or the ability to travel between them. Parks also face the challenge of prioritizing not just conservation but also recreation.\nThe United States has 423 national parks that span 84 million acres. Despite their protected status, the primary purpose of national parks is not to conserve wildlife. The mission of the National Park Service emphasizes the preservation of unimpaired natural and cultural resources “for the enjoyment, education, and inspiration of this and future generations.” This mission describes the NPS’ dual focus on both preservation of natural resources and recreation in our national parks.\nTwo key challenges national parks face in the conservation of habitat are development of the surrounding areas and increasing numbers of visitors annually. The areas surrounding national parks are often developed for agriculture, mining, and housing. That development may trap the species within the parks by cutting them off from their habitat. Increasing numbers of visitors also make maintaining the habitats of the animals living in the parks more difficult. Park rangers are unable to minimize the impact visitors have on the degradation of habitat. As the number of visitors increases, habitat degradation also increases.\nConnecting conservation islands\nEstablishing urban green spaces and a nationwide wildlife corridor system would help make America’s conservation efforts more successful in protecting wildlife and conserving natural habitats. By integrating urban green spaces with new urban planning, we can help achieve better habitat connectivity.\nThese ideas are also gaining traction in policy discussions. The Build Back Better bill currently under review in the Senate designates $10 million to map wildlife corridors and provide monetary assistance for states working to implement and maintain corridors. The Wildlife Corridors Conservation Act would go even further by creating a National Wildlife Corridors System and stewardship fund for citizens to donate to its upkeep. The bill in its entirety has not yet been reviewed by the Senate. The Act would use federal lands and waters to create the system. Twelve states, including Utah, have already begun to implement their own policies to protect existing wildlife corridors.\nConnecting protected areas and creating safe ways for wildlife to migrate will be key in allowing humans to coexist with nature. Urban conservation and wildlife corridors can help us achieve better conservation outcomes. These tools improve existing conservation efforts and create new ways for us to interact with wildlife and nature in our daily lives.']"	['<urn:uuid:6179c510-506d-43a9-a64f-f3a8c357130a>', '<urn:uuid:4b9fa075-28ca-4e4a-8a8d-8e7c812214b7>']	factoid	with-premise	concise-and-natural	distant-from-document	multi-aspect	expert	2025-05-13T05:52:58.810667	11	63	2752
25	compare market volatility impact on trading opportunities versus flat market trading outcomes	Market volatility and flat market conditions have significantly different impacts on trading outcomes. In volatile markets, there are increased opportunities for traders due to larger price movements - for example, when the VIX jumps to 30, stocks may show twice the daily price range compared to normal conditions, creating more potential profit opportunities. In contrast, trading flat conditions offer minimal opportunities since securities neither increase nor decrease in price, resulting in trades without profits or losses. This difference occurs because volatile markets have more fluid price discovery and wider ranges of fair values, while flat markets maintain steady, unchanged prices with little indication of directional trends.	['We all worry about the financial markets going down and hold out hope they will go up, but there are times when the market remains pretty much the same. If you make a trade in a flat market, you do so without making a profit or taking a loss. When this happens, you’re trading flat.\nLearn how trading flat works, what it means for your portfolio, and what to do when it occurs.\nDefinition and Example of Trading Flat\nThe term trading flat can slightly vary in meaning, depending on which context it is used in. If someone is using the term in relation to a market or exchange, then trading flat refers to the fact that the exchange index has been unchanged for a certain amount of time.\nWhen it comes to stocks, trading flat means that the stock price has neither fallen nor risen during the period being reviewed. When it comes to bonds or other forms of fixed income, it simply indicates those investment products are trading without accruing any interest. If a bond trades flat, the buyer won’t be responsible for paying the seller any interest that has accumulated since the last coupon payment.\nAll that being said, the overarching meaning of this term is that the price of a security is neither increasing nor decreasing; it’s remaining relatively the same.\n- Alternate name: trade flat\nHow Does Trading Flat Work?\nA flat market leads to securities trading flat. When a market is flat, that means that there isn’t much price movement and that the market is trading within a tight range. There will be little indication of whether the market is trending up or down.\nA flat market can occur for a variety of reasons. In some cases, investors simply may be losing interest in the specific investment vehicle that is trading flat. Important financial events, or lack thereof, can also cause securities to trade flat.\nFor example, let’s say that on an upcoming Thursday, there is a planned economic indicator release that is expected to cause volatility. Some traders may be too hesitant to add exposure without knowing which way the market will turn and therefore may choose to pull back on trading activity for hours or even days leading up to the economic event. This is one potential reason behind a market trading flat.\nTo better understand what trading flat means, it helps to understand what market volatility is and what it reflects. The price of options is greatly affected by market volatility. Volatility measures how much the value of an asset or its price will change during a select time frame.\nIf a market experiences prices remaining stagnant for a long period of time, that’s a low-volatility market. If the price moves up and down frequently, especially in large volume, that market is a volatile one. When the market is highly volatile, you’ll typically see that an option’s value is higher. Markets with low volatility are often associated with lower option values. Low-volatility markets are more similar to flat markets.\nWhen a market is volatile, there’s a better chance it will experience multiple price levels during a particular time period. Flat markets, on the other hand, remain steady.\nLet’s take a closer look at what happens when a bond is trading flat. When someone purchases a bond at a discount because interest has accrued but has not been paid or has been defaulted upon, this process is referred to as trading a bond flat. It’s generally due to some type of financial distress. Because that unpaid or defaulted interest is not considered income, it is not eligible for taxation as interest later on, if paid.\nThis means that if the investor receives a payment of that interest, it’s a return of capital. Because it is considered a return of capital, the remaining cost basis of the bond is reduced. Any interest that accrues after the date of purchase is considered taxable income for the year the investor accrued it or received it.\n- Trades that happen without leading to a profit or a loss are referred to as trading flat.\n- Flat markets are more similar to low-volatility markets than they are to high-volatility markets.\n- When bonds trade flat, they do so without accruing any interest—this is usually caused by some form of financial distress.', 'The term volatility is used in a few different contexts by traders and the financial media. What exactly is market volatility and why do some traders love it?\nWhat exactly is market volatility and why do some traders love it?\nThe term volatility is used in a few different contexts by traders and the financial media. It seems the usage of the term increases when the broader market has been trending lower for a while and the financial media is flashing “Breaking News” alerts across your screen.\nMore precisely than the financial media’s definition, volatility can be defined as the standard deviation of returns. The returns used to calculate standard deviation are usually from an index like the S&P 500 or Dow Jones Industrial Average.\nAnother precise way to define volatility is with the CBOE Volatility Index, or VIX. The VIX is a measure of implied volatility, or expected future volatility, of the S&P 500 index. The VIX is a handy way to define and measure volatility because real-time VIX data is available in most trading platforms. And hey, it’s easier to check the chart of the VIX than calculate standard deviation. Plus, standard deviation relies on historical data, which means it’s based on history whereas the VIX is based on future expectations.\nWhen checking the chart of the VIX, traders are looking at the absolute value of the VIX in relation to its historical averages. This analysis can help traders define periods of relative calm in the markets or spot instances of market volatility.\nFor example, over the last three years, the VIX has seen extended periods when it traded in a range between about 12 and 15. These periods in the VIX coincided with a mostly steady and stable trend higher in the S&P 500. However, there have been many instances when the VIX “spiked” higher over the last three years, moving above 20 and, on a few occasions, trading above 30. There was one instance in August 2015 of the VIX reaching all the way above 50. All these higher spikes in the VIX are one way to precisely define periods of market volatility.\nBut why do traders love periods of market volatility?\nMarket volatility generally coincides with an increase in risk. The increase in risk might stem from economic indicators pointing to a recession, or a central bank surprising with a new policy announcement, or a high-profile company issuing an earnings warning.\nIncreases in risk make it more difficult for all stock market participants to find the fair value of stocks and the broader market. This is when the price discovery process becomes much more fluid and the range of fair values for stocks and the broader market increases. To put it simply, increase in risk causes stock prices and the broader market like the S&P 500 to experience big and frequent price changes.\nBut the risks causing these big and frequent price changes come with a silver lining. For traders, increased risk means increased potential opportunity. This opportunity comes from more range in price to potentially profit from. For instance, suppose XYZ averages a range of $0.50 from its daily low and high during periods when the VIX is between 12 and 15. But when the VIX jumps to 30, XYZ’s range from daily low to high increases to $1.00. That’s double the movement in price on a daily basis that a trader might seek to profit from. And that’s why traders love market volatility.\nfor thinkMoney ®\nFinancial Communications Society 2016\nfor Ticker Tape\nContent Marketing Awards 2016\nAll investing involves\nrisk, including loss of principal.\nMarket volatility, volume, and system availability may delay account access and trade executions.\nPast performance of a security or strategy does not guarantee future results or success.\nOptions are not suitable for all investors as the special risks inherent to options trading may expose investors to potentially rapid and substantial losses. Options trading subject to TD Ameritrade review and approval. Please read Characteristics and Risks of Standardized Options before investing in options.\nSupporting documentation for any claims, comparisons, statistics, or other technical data will be supplied upon request.\nThe information is not intended to be investment advice or construed as a recommendation or endorsement of any particular investment or investment strategy, and is for illustrative purposes only. Be sure to understand all risks involved with each strategy, including commission costs, before attempting to place any trade. Clients must consider all relevant risk factors, including their own personal financial situations, before trading.\nThis is not an offer or solicitation in any jurisdiction where we are not authorized to do business or where such offer or solicitation would be contrary to the local laws and regulations of that jurisdiction, including, but not limited to persons residing in Australia, Canada, Hong Kong, Japan, Saudi Arabia, Singapore, UK, and the countries of the European Union.\nTD Ameritrade, Inc., member FINRA/SIPC. TD Ameritrade is a trademark jointly owned by TD Ameritrade IP Company, Inc. and The Toronto-Dominion Bank. © 2019 TD Ameritrade.']	['<urn:uuid:65bcaebb-e641-4820-bd8a-b456c6e49b7b>', '<urn:uuid:8a8b1126-4796-47ca-86bb-4b4ca6dab32a>']	open-ended	direct	long-search-query	similar-to-document	comparison	expert	2025-05-13T05:52:58.810667	12	106	1563
26	reggae bands keyboard players collaboration history	Several prominent keyboard players collaborated across different reggae bands. Earl Lindo worked with The Wailers, Tommy McCook and the Supersonics, and the Impact All-Stars, while also recording at Studio One. Tyrone Downie, besides being a Wailers member, played with multiple artists including The Abyssinians, Black Uhuru, Burning Spear and Steel Pulse. Jackie Mittoo was part of various groups including The Skatalites, The Sheiks, The Soul Brothers, The Soul Vendors and Sound Dimension.	"['Roots Archives - Artist : Winston Wright. Keyboard instruments. The piano, a common keyboard instrument History Among the earliest keyboard instruments are the pipe organ, hurdy gurdy, clavichord and harpsichord.\nPiano. The pianoforte, commonly abbreviated to piano, is a musical instrument played using a keyboard. It is widely used in classical and jazz music for solo performances, ensemble use, chamber music and accompaniment and for composing and rehearsal. Although the piano is not portable and often expensive, its versatility and ubiquity have made it one of the world\'s most familiar musical instruments. The word piano is a shortened form of pianoforte (PF), the Italian word for the instrument (which in turn derives from the previous terms gravicembalo col piano e forte and fortepiano). Clavichord. History and use The clavichord was invented in the early fourteenth century. In 1504, the German poem ""Der Minne Regeln"" mentions the terms clavicimbalum (a term used mainly for the harpsichord) and clavichordium, designating them as the best instruments to accompany melodies.\nThe ""Lépante"" clavichord, Musée de la Musique, Paris One of the earliest references to the clavichord in England occurs in the privy-purse expenses of Elizabeth of York, queen of Henry VII, in an entry dated August 1502: Item. The same day, Hugh Denys for money by him delivered to a stranger that gave the queen a payre of clavycordes. Pablo Black. Organ. Non-piped organs include the reed organ or harmonium, which like the accordion and harmonica (or ""mouth organ"") use air to excite free reeds. Electronic organs or digital organs, notably the Hammond organ, generate electronically produced sound through one or more loudspeakers. Mechanical organs include the barrel organ, water organ, and Orchestrion. These are controlled by mechanical means such as pinned barrels or book music.\nLittle Barrel organs dispense with the hands of an organist and bigger organs are powered in most cases by an organ grinder or today by other means such as an electric motor. Booker T & The MG\'s - \'Time Is Tight\' (from the 1968 lp \'Uptight\') Mishka - Above the bones: 3rd Eye Vision. How do you play reggae keyboard. How to play reggae - 5 things You Should Know About The Reggae Keyboard. The reggae keyboard is probably the hardest instrument in reggae music to get information on. It is almost an enigma; search results in Google or any other place on reggae keyboard does not reveal much. Here are 5 five questions about this amazing instrument that I’ve answered for you. How Are Keyboards Used in Reggae? Autumn Sounds. Ansell Collins. Ansell Collins (sometimes spelled Ansil or Ansel) is a Jamaican keyboard player, producer, and occasional singer. Born 1949 in Kingston, Jamaica. Biography Roots reggae singer I Wayne was raised by his aunt and her husband Ansell Collins.\nRevolutionaries - Post Mortem (InstraDub) TEN TO ONE. Double Barrel (HQ) Monkey Spanner. Ain\'t That Lovin You. Power To The People. Ride Your Pony. In The Ghetto. Shocks of Mighty. Lonely Man Am I. Slavery Days. Interview Bob Marley and Tyrone Downie. A Quiet Place (ALA Johnny Dollar) Give Me Some Light. Burning Love. Secret Weapon. My Best Girl. Just My Imagination. What A Confusion (Live) Earl Lindo. Earl ""Wire"" Lindo (sometimes referred to as ""Wya"") is a Jamaican reggae musician, born 7 January 1953. He is a member of The Wailers and has collaborated with numerous reggae artists including Burning Spear. Biography Lindo can be heard on an album credited to the Impact All-Stars.\nReleased in 1975, the album is a collection of dub tracks recorded at Randy\'s Studio 17. Today Earl Lindo resides with his wife Cleopatra Rosemary, and two daughters Kyan and Kaleigh in London, England. References External links Earl \'Wire\' Lindo Discography at Discogs. Tommy McCook Jamaica Bolero. Tommy McCook Green Mango. Tommy McCook (Earl Lindo) - White Rum - Treasure Isle records. More Ball. Jackie Mittoo. Biography He was born Donat Roy Mittoo in Browns Town, Saint Ann Parish, Jamaica, and began learning to play the piano when he was four under the tutelage of his grandmother. In the 1960s he was a member of The Skatalites, The Sheiks, The Soul Brothers, The Soul Vendors and Sound Dimension. Jackie Mittoo Discography at Discogs. Jackie Mittoo playlist. Who Done It. Jackie Mittoo - Keep On Dancing at Discogs. Evening Time.\nChoice Of Music. Midnight Special. Full Charge. Best By Request. In London. Night Of Love. Napoleon Solo. Hot Shot. Rock Steady Wedding. Whiter Shade of Pale. Summertime. Kicksie. Mission Impossible. Winchester Cathedral. Hot Milk. Evening Time. One Step Beyond. Darker Shade Of Black. Jackie mittoo, drum song. Love Is Blue. Hip Hug. Ram Jam. Tyrone Downie. Tyrone Downie is a Jamaican keyboardist/pianist who is most known for his involvement as a member of Bob Marley and The Wailers. He studied at Kingston College and joined The Wailers in the mid-1970s, making his recording début with the band on Rastaman Vibration, having previously been a member of the Impact All Stars. He has also played with The Abyssinians, Beenie Man, Black Uhuru, Buju Banton, Peter Tosh, Junior Reid, Tom Tom Club, Ian Dury, Burning Spear, Steel Pulse, Alpha Blondy, Tiken Jah Fakoly and Sly & Robbie.\nRobert Lyn. REGGAE~ROBERT LYNN & SOUND DIMENSION - Zip Code. Third World. 96° In The Shade. One Cold Vibe. Dreamland. Jah Glory. Tribal War. Third World Man. 96 degrees in the shade. Feel A Little Better. Third World playlist. Journey To Addis. More Images Label: Island Records – 26 476 XOT Format: Country: Released: Genre: Style: Tracklist Notes Recorded & mixed at Compass Point Studios, Nassau. Barcode and Other Identifiers. Kumina. Rejoice. Human Market Place.\nSatta Massagana. Rhythm of life. African Woman. Cool Meditation. Now That We\'ve Found Love. Fret Not Thyself. Cold Sweat. Journey To Addis.', 'Robert Nesta “Bob” Marley, OM (6 February 1945 – 11 May 1981) was a Jamaican singer-songwriter, musician and guitarist who achieved international fame and acclaim, blending mostly reggae, ska and rocksteady in his compositions. Starting out in 1963 with the group The Wailers, he forged a distinctive songwriting and vocal style that would later resonate with audiences worldwide. The Wailers would go on to release some of the earliest reggae records with producer Lee “Scratch” Perry.\nAfter the Wailers disbanded in 1974, Marley pursued a solo career upon his relocation to England that culminated in the release of the album Exodus in 1977, which established his worldwide reputation and produced his status as one of the world’s best-selling artists of all time, with sales of more than 75 million records. Exodus stayed on the British album charts for fifty-six consecutive weeks. It included four UK hit singles: “Exodus”, “Waiting in Vain”, “Jamming”, and “One Love“. In 1978 he released the album Kaya, which included the hit singles “Is This Love” and “Satisfy My Soul”.\nDiagnosed with acral lentiginous melanoma in 1977, Marley died on 11 May 1981 in Miami at age 36. He was a committed Rastafari who infused his music with a sense of spirituality. He is considered one of the most influential musicians of all time and credited with popularising reggae music around the world, as well as serving as a symbol of Jamaican culture and identity. Marley has also evolved into a global symbol, which has been endlessly merchandised through a variety of mediums.\nNeville O’Riley Livingston O.J. (born 10 April 1947), better known as Bunny Wailer, and also as Bunny Livingston and affectionately as Jah B, is a Jamaican singer songwriter and percussionist and was an original member of reggae group The Wailers along with Bob Marley and Peter Tosh. A three-time Grammy award winner, he is considered one of the longtime standard-bearers of reggae music.\nPeter Tosh, OM (born Winston Hubert McIntosh; 19 October1944 – 11 September 1987) was a Jamaican reggae musician. Along with Bob Marley and Bunny Wailer, he was one of the core members of the band The Wailers (1963–1974), after which he established himself as a successful solo artist and a promoter of Rastafari. He was baptized by Ethiopian Orthodox Church. He was murdered in 1987 during a home invasion.\nCarlton “Carly” Barrett (17 December 1950 – 17 April 1987) was an influential reggae drummer and percussion player. His musical development in the early years was with his brother Aston “Family Man” Barrett as a member of Lee “Scratch” Perry‘s “house band” The Upsetters. The brothers joined Bob Marley and The Wailers around 1970. He wrote the well known Bob Marley song “War” and with his brother Aston co-wrote “Talkin’ Blues”. Carlton Barrett is featured on all the albums recorded by the Wailers. Barrett popularised the one drop rhythm, a percussive drumming style created by Winston Grennan. With Carly’s beats and his brother Aston’s bass, the Wailer rhythm section planted the seeds of today’s international reggae. Barrett was murdered outside his home in Jamaica on 17 April 1987.\nAlvin “Seeco” Patterson (born Francisco Willie, 30 December 1930, Havana, Cuba) is a percussionist. He was a member of The Wailers Band\nThe I Three, commonly called “I Threes“, previously known as the Soulletes, were a Jamaican Girl group/reggae singing group that was formed in 1974 to support Bob Marley & the Wailers, after Peter Tosh and Bunny Wailer — the original Wailer backing vocalists — left the band.\nThe three members were Marley’s wife Rita Marley, Judy Mowatt and Marcia Griffiths. Their name is intended as a spin on the Rastafarian “I and I” concept of the Godhead within each person.\nEarl Wilberforce “Wya” Lindo (7 January 1953 – 4 September 2017), sometimes referred to as Wya, was a Jamaican reggae musician. He was a member of Bob Marley and the Wailers and collaborated with numerous reggae artists including Burning Spear.\nWhile attending Excelsior High School in Jamaica, he played with Barry Biggs, Mikey “Boo” Richards, and Ernest Wilson in the Astronauts, and later played organ in the band Now Generation, and with Tommy McCook and the Supersonics, and the Meters. Aston “Familyman” Barrett heard Lindo and recommended him to play for a Saturday afternoon television program Where It’s At on JBC. Lindo also spent his early days working at Coxsone Dodd‘s Studio One, where he played on innumerable recordings.\nIn 1973, he was invited to join The Wailers on a US tour, going on to play on Burnin’. He left the Wailers in 1974 to join Taj Mahal‘s band.\nLindo can be heard on an album credited to the Impact All-Stars. Released in 1975, the album is a collection of dub tracks recorded at Randy’s Studio 17. On his return to Jamaica he played on recordings by Big Youth, Culture, I Roy, and Al Brown, and had some success with solo singles “No Soul Today” and “Who Done It”. In 1978 he rejoined the Wailers, playing on Babylon by Bus, Survival, and Uprising.\nAfter Marley’s death, Lindo was a member of The Wailers Band.\nLindo died in a London hospital on 4 September 2017, aged 64, shortly after being admitted with abdominal pain. Among the tributes paid, Olivia Grange, Minister of Culture, Gender, Entertainment and Sport, described him as “an exceptionally gifted musician who played a pivotal role alongside Bob Marley and the Wailers in the global success of Jamaica’s reggae music.”\nNathaniel Ian Wynter (born September 30, 1954), also known as Natty Wailer, is a Jamaican-born musician and Rastafarian, best known for his work with Bob Marley and the Wailers, Aston Barrett and King Tubby. He is credited on recordings as Natty Wailer, Ian Winter, Ian Wynter, or Brother Ian.\n©2021 The Wailers Tour LLC | Company Information | Web hosting by Kebecweb | Partners\n©2018 The Wailers Tour LLC']"	['<urn:uuid:352df487-b968-4aca-9a9c-c72b2a471927>', '<urn:uuid:95a76f8b-2903-4e13-b63f-9a9bbcf62e3b>']	open-ended	direct	short-search-query	distant-from-document	comparison	expert	2025-05-13T05:52:58.810667	6	72	1938
27	How do Islamic art and Moroccan zillij differ in their use of lines and shapes?	Islamic art from the Middle East generally features curved lines and arabesques that can spread endlessly, symbolizing the infinite nature of the divine. In contrast, Moroccan zillij is characterized by straight lines in its geometric patterns, an influence from pre-Islamic Berber architecture. Despite these differences, both art forms share common elements like the avoidance of representational art and the use of geometric patterns to reflect cosmic order and inspire meditation on the divine.	['In 2014, the DMA secured a 15-year loan for the Keir Collection. It’s one of the country’s largest collections of Islamic art, and this weekend, the museum will host an equally impressive festival in its honor.\nIt’s surprisingly full inside the Keir gallery for a Thursday morning. Elementary school kids are studying works of pottery, metal, and fabric. But what they see on display is only a fraction of a repository that boasts almost 2,000 pieces.\nSabiha Al Khemir, the DMA’s senior advisor of Islamic art, says the Keir collection covers a wide geographical area — from the 7th century to the 19th — and span of time — from Spain to Southeast Asia.\nStill, the works are unified by certain elements.\n“You find that the word — that is calligraphy — is everywhere in Islamic art, not just in the texts, not just in the books,” she says. “The word is written. It is embroidered. It is engraved. It is chiseled. It is carved. You name it.”\nDesigns like arabesques are fundamental, characterized by tendrils that unwind and spread seemingly without end.\n“The organic growth in a stylized way that can go on forever is a decoration that hints to the presence of the infinite, and the infinite is one of the major aspects of the creator, of the divine,” she says.\nAl Khemir says there are misconceptions about Islamic art. People think that the artists avoided figurative depictions, but that’s not true. And the art isn’t necessarily religious.\n“This is art that’s part of everyday life,” she says. “This is what people used, like works of paper. These are manuscripts that they’ve read. These are ceramics that they’ve used to eat from or to hang on the walls.”\nToday, ancient artifacts are being destroyed in conflicts across the Middle East. Al Khemir points to the Homberg ewer. It’s an ornate brass pitcher inlaid with silver, engraved with Christian and Muslim scenes.\n“It was made in Mosul in 1242, when Mosul was a center for amazing metalwork,” she says. “And we hear about Mosul in different ways now … being custodian of this art has a huge responsibility.”\nDon’t forget, in the midst of the bustle during this weekend’s festival, to pay a visit to the collection itself. To see these ancient works in near-perfect condition is nothing short of a miracle.\nWant more insight into Islamic art? Here’s an extended Q&A with Al Khemir.\nOn defining Islamic art\nWhen we say Islamic art, we expect it to be religious art …These are pieces that are part of secular space. They are not pieces used in a religious space. They don’t have a religious function. So, when you say Islamic art, it’s actually art that comes from Islamic culture, and Islamic culture is itself holding many, many cultures … We’re talking about a unity that holds diversity.\nI would say calligraphy is a connecting thread throughout. Also, when you say Islamic art, we have this image of geometry, of arabesque, of abstract motifs. Basically, decorative motifs that can be spread and extended forever. That gives a sense of the infinite, of the omnipresence of God, but they are not representing religion per se … We’re talking about a visual language that connects a huge geographical area and many centuries … We can still see the connections between all of these styles, something that we almost cannot really define that is very much connected to the spirit of the culture and to a way of thinking and a way of seeing the world.\nOn geometry in Islamic art\nImagine you’re an artist — a craftsman at the very beginning at the 7th century — and you’re asked to decorate the house of God, the mosque, and make it the most beautiful place. You’re told you’re not supposed to represent icons. You cannot represent God. You cannot represent all these divine aspects. It’s a challenge. You are going to create a space in which there is a sense of worship, of contemplation. A space which speaks for Islamic art, Islamic culture and Islamic religion. The development of geometry, and the arabesque — which is the organic growth in a stylized way that can go on forever — is a decoration that hints to the presence of the infinite, and the infinite is one of the major aspects of the creator, of the divine.\nOn the presence of human and animal figures in Islamic art\nTry to remove the lenses which are distorted by some preconceptions that we have. For example, one of the misconceptions is that there is no figural representations in Islamic art. You know how many times I’ve taken people around the gallery, and we stop and look at representations of human and animal figures in ceramic plate, on a page, in a textile, and at the end of the tour, they still ask the same question: why is there no figural representation in Islamic art … That preconceived idea is actually among people who come from Islamic culture, as well as people who come from outside Islamic culture.', 'Moroccan Mosaics: The Art of Zillij\nOnce you see a Moroccan zillij masterpiece, you can spot the style anywhere. It is an art form that has been practiced for a thousand years. It is a unique specialization of Morocco and continues to thrive in Moroccan society within a contemporary creative framework.\nThis website is full of research related to understanding zillij, such as my research on the meaning of the eight-point star. On this page, you will find the following:\nZillij is an Islamic art that is based on learning, discipline, and faith. The geometric patterns reflect the Islamic belief that life is ordered by cosmic intelligence, even if people cannot always understand it. The abstract patterns reflect the Islamic desire to understand God’s creation through study rather than copy creation through representational art, which is shunned as a pathway to idolatry. Zillij patterns are constructed from archetypal shapes that have been refined by centuries of scientific study, artistic tradition, and religious belief. “Truthfulness—sidq—is in everything I make” said a modern zillij artisan in a recent interview.\nFundamentally, the purpose of zillij is decoration used to inspire the viewer into meditative reflection of the underlying laws governing the universe. Since Islamic tradition frowns on representational art, Muslims celebrate beauty through decorative arts, such as arabesques, textiles, architecture, tile work, and pottery design. The Prophet Mohammad is quoted as saying “God is beautiful and loves beauty.” The Prophet’s love of learning, appreciation of beauty, and directive to avoid representational art provided an ideal set of constraints for the creation and support of zillij art work. It is hard to imagine this art form arising from any other tradition.\nIn Morocco zillij is used to decorate water fountains, home interiors, add architectural detail, and cover tombs. It is rarely, if unsuccessfully, liberally applied to the exterior of buildings. According to Zillij: The Art of Moroccan Ceramics, zillij is “the subtle application of man’s feelings through form and color, exactly as the house is designed to reflect his requirements. Zillij is an expression of man’s interior world.”\nZillij artisans today continue to be supported by commissions. Restoration work and new building projects keep them occupied as do commissions for zillij installations in private homes. If a family can at all afford it, they will likely add a zillij fountain, wall, or walkway to their residence.\nThe practice of zillij dates back to the eleventh century. The practice was likely inspired by Roman mosaics, remnants of which can be seen in the ruins at Volubilis. It is certainly influenced by Islamic belief and tradition, which warns against representational art for fear of idol worship. Whereas representational art may, according to the Islamic perspective, disfigure reality in the observers’ mind and lead to misplaced study and misguided worship, zillij, through a disciplined approach to space, line, and color, encourages the observer to reflect on the perfection of God’s creation.\nMoroccan mosaics are unique in the Muslim world. The lines in Moroccan geometry are straight as opposed to the curved lines used in Middle Eastern art traditions. This straight line is thought to be an influence of pre-Islamic architecture, constructed by the Berber (Amazigh) populations before Islamic culture arrived in North Africa. The Moroccan line can be seen in both the hard edges of zillij tiles and the rectangular, not round, minaret of mosques.\nI am facinated by zillij and have gathered a few resources that have assisted me in learning more about this incredible artform. I will continue to update this post with additional information and resources as I find them. If you have other zillij resources to share, please leave a comment so I can share the information.\n- Zelige Applet\nAn applet that let’s you construct your own zelige pattern.\n- Zillij in Fez\nArticle about the art and history of zillij in Fes.\n- Origin and Meanings of the Eight-Point Star\n- Advanced geometry of Islamic art\n- Islamic Patterns: An Analytical and Cosmological Approach\nThis book contains some heavy explanations about the origins and meaning of Islamic designs. I refer to it often for its many useful and accurate pattern templates.\n- Zillij: The Art of Morroccan Ceramics\nA book about how Morocco uses Islamic patterns in pottery and tile and other artisan crafts. Contains lots of color pictures. This is the only in-print English-language book I know of dedicated soley to Moroccan zillij. Includes a very useful glossary of zillij terms, including tile shapes and pattern names.\n- Arabic Geometrical Pattern and Design\nThis book contains 190 linear plates of geometrical Islamic patterns, including Middle-Eastern styles. The collection of plates was originally published in French in 1879. It was republished in 1973. There isn’t any text in the book except for brief a publishers note.']	['<urn:uuid:105643ca-48e2-43f3-8e67-3d47dc2900db>', '<urn:uuid:0cb34788-c7b9-4247-8b3b-232cbc591c35>']	open-ended	with-premise	concise-and-natural	similar-to-document	comparison	novice	2025-05-13T05:52:58.810667	15	73	1645
28	I've heard New Zealand has some special honey that's good for you - is there anywhere around Taupo where I can learn more about it and try some?	At the Huka Honey Hive, you can take a tour that teaches you about the benefits of manuka honey, royal jelly and bee pollen. New Zealand honey is renowned for its purity and healing properties. During your visit, you can enjoy honey ice cream and sample various honey-based products.	"[""With some of the North Island’s most impressive landscapes right on its doorstep, the Taupō region is perfect for outdoor adventures.\nHere are the top 10 things to do in the Taupō region.\n1. Encounter geothermal wonders\nThe valley of Orakei Korako Cave & Thermal Park is a real hidden gem. Accessible only by a short ferry trip across Lake Ohakuri, admire the power and energy of Mother Nature in the geysers, hot springs and bubbling mud pools.\n2. Sample delicious New Zealand honey\nNew Zealand honey is famous for its purity and healing properties. Visit the Huka Honey Hive and take a tour that teaches you about the benefits of manuka honey, royal jelly and bee pollen. Enjoy a honey ice cream before sampling a raft of honey-based products.\n3. Soak in geothermal waters\nWith a wealth of thermal attractions and cultural experiences, the Wairakei Terraces offers something for everyone. Soak in naturally heated geothermal pools below ancient silica terraces; enjoy a guided tour of the Wairakei steam field or relax during an evening of Māori cultural experiences.\n4. Hike the Tongariro Alpine Crossing\nArguably New Zealand's greatest day walk, the Tongariro Alpine Crossing, travels through volcanic alpine terrain, hikes around an active volcano and descend into the water-filled explosion craters known as the Emerald Lakes. Enjoy views of Mount Ngauruhoe - also known as 'Mount Doom' in the Lord of the Ringstrilogy.\n5. Visit the thundering Huka Falls\nGet up close to the mind-blowing roar and rumble of the Huka Falls where New Zealand’s longest river, the Waikato, is squeezed through a ravine of hard volcanic rock. Watch 220,000 litres of water blast by every second. View the falls from above via the footbridge, or get up close with a thrilling jet boat ride.\nWith over 60 Grade 3 roller-coaster rapids, a rafting trip on the Tongariro is a must. Wind through pristine forests & volcanic landscapes near Turangi. You may be lucky and catch a glimpse of the ‘whio’, New Zealand's rare native blue duck in its traditional home.\n8. Indulge in a volcanic wine and craft beer tour\nTaupō’s free-draining volcanic soil and pure alpine water means that the wines, craft beers and cider crafted in this region are both distinctive and delicious. Discover them for yourself with a volcanic wine and craft beer tour.\n9. Cruise on Lake Taupō\nCruise the largest lake in New Zealand with a scenic boat trip to Ngātoroirangi Mine Bay Māori Rock Carvings with Chris Jolly Outdoorsand catch your own lunch. Try your hand at living off the land, test your survival skills and learn to navigate the celestial way with a hands-on interactive survival walk.\n10. Explore the Prawn Park\nWith activities that will entertain the whole family for hours, Huka Prawn Park is a must-do. Take a guided tour. Race the Boat Lake on paddleboards, water trikes and pedal boats. Embark on the parks activity trail with interactive water features. Pack a picnic or dine at the Riverside restaurant soaking in the spectacular views of the Waikato River.""]"	['<urn:uuid:eebaddee-d0c3-48b8-a801-fa7f45e94b52>']	open-ended	with-premise	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-13T05:52:58.810667	28	49	510
29	speed of earth orbit around sun	The Earth's linear velocity in its orbit around the sun is about 19 miles per second.	"['Sectors, Areas, and Arcs: Worked Examples (page 2 of 2)\nThe ""angular velocity"" is the number of times the wheel revolves in some named time period. So this question is asking me to find the number of times the wheel twirls around in one minute. To do this, I\'ll need to find the distance covered (per minute) when moving at 45 kph. Then I\'ll need to find the circumference of the wheel, and divide the total per-minute distance by this ""once around"" distance. The number of circumferences which fit inside the total distance is the number of times the wheel revolves in that time period.\nFirst, I\'ll find the distance, using what I\'ve learned about converting units:\nSo the distance covered in one minute is 75,000 centimeters. The diameter of the wheel is 100 cm, so the radius is 50 cm, and the circumference is 100π cm. How many of these circumferences (wheel revolutions) fit inside the 75,000 cm?\nThe angular velocity is ω = 239 rpm\nThe abbreviation ""rpm"" for ""revolutions per minute"" is standard, so you can safely use this notation. The character ""ω"" is the Greek lower-case letter ""omega"", and is often the variable used for angular velocity.\nNote: This speed isn\'t as fast as it might appear: it\'s just under four revolutions per second. You can do that on your bike without breaking a sweat.\nThe linear velocity will be the distance, stretched out in the straight line, that a point on the wheel moves during a defined period of time. They\'ve given me the number of times the wheel revolves each minute. A fixed point on the tire (say, a pebble in the tire\'s tread) moves the length of the circumference for each revolution. Unrolling this distance onto the ground, the bike will move along the ground the same distance, one circumference, for each revolution.\nSo this question is asking me to find\nthe circumference length, and then use this to find the total distance\ncovered per minute. Since the diameter is 78\ncm, then the circumference is C\n= 78π cm. This means that the bike\ncm forward for each revolution of the tire. There are 120\nsuch revolutions per minute, so:\n(78pi cm/rev)×(120 rev/min) = 9,360pi cm/min\nNow I need to convert this from centimeters-per-minute to kilometers-per-hour:\nThe bike is moving at about 17.6 kph.\nThis is about eleven miles an hour.\nThe circumference of the circle with r = 93,000,000 mi will be the linear distance that the Earth covers in one year.\nC = 2π(93,000,000 mi)/year = 186,000,000π mi/yr\nThis is the distance covered, in miles, in one year. There are twenty-four hours in a day, sixty minutes in an hour, and sixty seconds in a minute, so the total number of seconds for that year is:\n(365.25 days/yr)(24 hr/day)(60 min/hr)(60 sec/min) = 31,557,600 sec/yr\nThen the linear velocity, being the total linear distance divided by the total time and expressed as a unit rate, is:\n(186,000,000π mi/yr)/(31,557,600 sec/yr) = 18.51649788... mi/sec\nThe linear velocity of the Earth is about 19 miles per second.\n""A curve of radius 3000 ft"" means that, if you tried to fit a circle snugly inside the curve, the best fit would be a circle with a radius of r = 3000 feet. In other words, I can use circle facts to answer this question.\nSince the radius of the curve is in feet and since I need to find the angle for one minute, I\'ll start by converting the miles-per-hour speed to feet-per-second:\n(10 mi/hr)(5280 ft/mi)(1 hr / 60 min) = 880 ft/min\nThe amount of the curved track that the train covers is also a portion of the circumference of the circle. So the 880 feet is the arc length, and now I need to find the subtended angle:\nBut this value is in radians, and I need my answer to be in degrees, so I need to convert:\n(0.293333... radians)(180°/π radians) = 16.80676199...°\nThe train turns through an angle of about 17°\nThey gave me the radius of a circle and a subtended angle, and want me to find the area. So I\'ll be needing to use the sector-area formula. However, since the wiper blade itself does not go all the way down to the pivot point for the swing arm, so I\'ll need to subtract out a portion of the sector to find the area that is actually covered by the blade.\nSince they gave me the angle in degrees, I\'ll need to be careful to adjust the formulas accordingly.\nThis is the total area swept by the swing arm. The wiper blade only covers the outer 60 cm of the length of the swing arm, so the inner 72 – 60 = 12 cm is not covered by the blade.\nI need to subtract this area:\nThe blade sweeps about 4618 cm2 of the windshield.\nOriginal URL: http://www.purplemath.com/modules/sectors2.htm Copyright 2009 Elizabeth Stapel; All Rights Reserved.\nCopyright 2009 Elizabeth Stapel; All Rights Reserved.']"	['<urn:uuid:692eb376-9ca1-4de6-a2f1-44a520f8672e>']	factoid	direct	short-search-query	distant-from-document	single-doc	novice	2025-05-13T05:52:58.810667	6	16	831
30	difference accuracy laser scanning vs industrial ct	Industrial CT scanning and laser scanning differ in their accuracy characteristics. CT scanning offers high precision with an accuracy of 9+L/50 microns using Calypso software. Laser scanning's accuracy depends on various factors including laser power, focusing optics, part surface roughness, surface reflectivity, and external factors like temperature fluctuations and vibration. For highly precise, geometrical machined surfaces, laser measurement is actually less accurate than traditional touch probe methods. Additionally, laser scanning can have accuracy issues with highly polished surfaces and cannot effectively measure transparent objects without surface modification. CT scanning's accuracy is not affected by plastic color or depth-of-feature, which can be problematic with laser scanning systems.	"['Industrial CT Scanning\nNel Pretech now offers A2LA-accredited CT scanning services.\nNel Pretech Corporation is pleased to announce that it now has a new computed tomography (CT) machine called the METROTOM 800, allowing it to offer industrial CT scanning services to its clients. This new acquisition makes the company the first A2LA-accredited lab to offer industrial CT services in the U.S.\nCreated by Carl Zeiss Corporation, a global leader and manufacturer of precision-measuring instruments, the METROTOM 800 is a new technology. It scans using x-rays to ultimately produce a 3-D digital rendering of the entire volume of a product, including external and internal geometry. Once a scan is complete, Nel Pretech can also provide post-scan engineering and measurement services as required.\nNel Pretech provides A2LA-accredited industrial CT scanning that saves customers time, effort, and money. While CT (computed tomography) scanning is a technology widely known for its medical use, it is also a powerful industrial tool used to examine internal components. Nel Pretech uses CT scanning technology to form 3D models that allow the user to examine the interior and exterior of the item being scanned — providing valuable insight for such industries as aerospace, automotive, electronics, and die-cast manufacturing. Nel Pretech provides expedient inspection reports compared with other industrial CT scanning companies, and focuses on methods that are non-intrusive, accurate and fast.\nWhat is the Concept Behind Industrial CT Scanning?\nIndustrial CT scanning gives you access to the inner details of items without requiring disassembly (Wikipedia). The process forces X-rays through objects in order to create 3D data sets. This allows for a thorough analysis of object dimensions, porosity, wall thickness, assembly defects, comprehensive comparisons, and reverse engineering. An important benefit of this process is that it is non-intrusive and does not damage the item being scanned. The information taken from the CT scan can then be compared to the CAD model, to other parts, or to other data sets. Nel Pretech gives you the option of user-definable color patterns so that you can then more easily analyze surface variations. Another useful feature is the ability to use cross sections for otherwise hidden features.\nNel Pretech’s CT scanning is an excellent tool for helping customers detect part flaws, determine the cause of a product failure, reassemble an item, or reverse-engineer a part.\n- Nel Pretech Corporation has been a leading metrology service provider since 1993 and has completed over 10,000 inspection and scanning projects on complex parts\n- CT Scanning technology is well suited to reduce part development time/cost\n- Maximum Part size: 300mm diameter x 350 mm tall\n- Scan time is typically less than one hour\n- Accuracy (using Calypso) 9+L/50 microns\n- Turnaround is typically 72 ARO\n- Free viewer provided with the scan results\n- Web conferencing used to share results\n- We’re fast. You receive your first article inspection report in days.\n- We help you save money. By giving you the ability to inspect without disassembling — and by expediting the design and development process — you save on operating costs.\n- Our process is non-destructive, giving you the ability to inspect internal and external geometry.\n- We don’t require fixturing or clamping forces, which can distort the part.\n- Our process helps you increase production ability with faster prototypes and replications without relying on CAD files.\n- Our X-ray based measurement system is non-contact (no force).\n- Parts do not require potting.\n- We’re accurate. In fact, plastic color and depth-of-feature will not affect accuracy or repeatability, which can be a problem with Part-CAD comparisons.\n- Our process lets you quickly determine whether a part has any critical defects.\n- We provide an option for extensive porosity (voids) and wall thickness reports.', 'QUALITY MEASUREMENT: Lasers Pinpoint Measurement\nHow does laser measurement pinpoint quality? The answer to this question is a broad one, even for such a precise and exacting measuring technique. Laser measurement uses the optical properties of focused light for noncontact dimensional scanning of a subject part, material or object yielding 1-D, 2-D or 3-D coordinate point surface positional information. Its use in\nmanufacturing-related activities consists of collecting many times more measured points in a given time compared with conventional techniques, allowing better definition of complex geometries.\nEngineers and designers confirm quality by using the data from laser measurement devices to reverse-\nengineer, improve or create new parts and products, or improve how parts are made. Quality control personnel use laser measurement to verify that parts have been made correctly, and if not, where they need to be corrected.\nLaser measurement ensures quality in manufacturing-related activities by creating absolute references for measurements, which do not change over distances the way mechanical or relative references do. Fast data acquisition is possible without the potential distortion that often occurs with conventional contact measurement. Because a laser does not touch the part it is measuring, the laser is not compromised when measuring soft materials, which might move or wear when touched.\nCompared to conventional contact measurement, laser measurement has fewer moving parts required to manipulate the part or the contact device. ""This will increase the durability and longevity of any manufacturing cell,"" says Stephen Sochowski, director of sales and marketing at Micro-Epsilon (Rolling Meadows, IL). ""Many contact devices can and will break, and must be replaced which increases downtime. Because tolerances are getting tighter, accurate measurement down to the microns is impossible with conventional contact technology. Even the smallest force applied by touching the specimen will affect the reading, or the target is too sensitive and does not allow any contact without compromising the quality.""\nLaser Types and Lights\nSelecting the correct laser system best ensures quality. Laser systems range from single-axis measurers to large 3-D point cloud devices. According to Glenn Valliant, managing partner of Optical Dimensions (Lake Forest, CA), at the low end, there are simple laser sighting and surveying measurements that take advantage of the ‘straightness\' of light. Other types of laser-beam configurations allow for the checking of surface flatness, porosity, diameters, gaps, positioning, velocity, eccentricity, surface inclination, thickness and height.\nSingle-point lasers with spot beams as small as 50 microns can be used on very small objects or features to confirm their presence. Single-point lasers project the laser beam onto a single point on the target and then return data. The laser sensor receiver can use the percentage of laser light reflected off the test object surface to determine the distance from the laser. The closer the laser is to the object, the higher percentage of light will be returned.\nThis method\'s accuracy is subject to variations in the reflective surface of the test object; however, it is the most cost-effective laser sensor. Applications for these types of lasers include measuring the thickness of a part, aluminum foil, plastic film and sheet metal.\nA laser tracker automatically tracks and follows the movement of the target by rotating the measurement head. Laser trackers measure the 3-D coordinates of a mirrored target by combining two measurement steps. The laser measures the distance between measurement device and a target. Then, incremental encoders measure the azimuth and elevation angle of the measurement head on which the laser is positioned. This results in the 3-D spherical coordinates of the target.\nThree-dimensional laser measurement scanners use projected light to determine a solid part\'s dimensions by generating a representative surface or solid model. Returned light and a photosensitive device, such as an array, generate point cloud data. ""The point cloud data is used to produce meshes, that are transformed into surfaces,"" says Christine Smith, laser metrology system project manager at Neptec International (Houston, TX). ""The surfaces can be stitched together to generate a solid model that is the same dimension as the part that has been scanned. This model can then be compared with the ‘as designed\' computer-generated model to determine if the part meets the as designed dimensional criteria.""\nJim Clark, vice president of marketing and business development at Metris North America (Rochester Hills, MI) says 3-D laser measurement scanners are best suited for:\n• Freeform surfaces, car exteriors, seating, car interiors, sculpture, archeology, heritage pieces and consumer products\n• Soft, deformable or fragile objects that cannot be touched during measurement\n• Surfaces with enormous detail, feature and webs\nThere are inexpensive, low-end and more complex high-end laser measurement devices. According to Cris Holmes, machine vision and sensor product manager at Axis Systems (Auburn Hills, MI), what makes a laser high end is primarily how the data is handled because inexpensive controllers can be configured to look for a set point match for a specific measurement.\nTo further ensure quality, most laser measurement devices have accessories performing calibration checks, alignment checks or part referencing of scan data. ""System and laser calibration accessories make automated calibration confirmation easy and fast to ensure the laser probe itself is operating within tolerance,"" says C. Martin Schuster, president of Laser Design Inc. (Minneapolis, MN). ""Alignment accessories allow for the scanning system to make sure it has aligned the laser scanner to the coordinate system orientation of the scanning system or part coordinate space."" Part referencing accessories allow object scanning from different orientations of the scanner to the part to be merged together into the same coordinate system easily, or in some cases automatically.\nLaser quality, or measurement precision, is a function of the laser power, focusing optics, part surface roughness, surface reflectivity and the amount of error introduced by external factors such as temperature fluctuations and vibration. High-quality scanners require precision optics and stable electronics and platforms.\nDifferent types of light and wavelengths are used in laser measurement devices. Halogen light is used in fringe-type scanners. Laser light of various wavelengths is used in stripe and area scanners. Laser light is not affected by gravity, only by atmospheric effects, which are infinitesimal at this level of application.\nLaser ApplicationsLaser measurement has several applications, most better than mechanical contact measurement. Laser measurement is favored when measured objects are fragile and can be damaged by contact with mechanical devices. When measured objects are very hard, laser measurement will not damage and degrade the performance of a mechanical measuring device.\nThe best laser measurement applications are those requiring accuracy and precision. According to Darin Sahler, product manager at Faro Technologies Inc. (Lake Mary, FL), these include reverse engineering, rapid prototyping, complex shape profile analysis, flimsy part measurement-such as plastic and sheet metal-and anywhere a high-density of points and detail is needed.\nHigh-volume manufacturing is aided by laser measurement because it is faster than mechanical measurement. Speed of laser measurements often can allow 100% inspection compared to statistical sampling often used with mechanical measurements. Laser measurements can sometimes even be employed in real time on-line.\nBecause of laser measurement\'s different applications and technologies, it is not possible to categorize laser measurements in general terms. ""Even within a single application this is not possible,"" Jos Jans, business development director at Metris (Leuven, Belgium) says. ""Take a handheld laser scanner as an example. Although it is less accurate than a coordinate measuring machine (CMM)-based laser scanner, it does not mean that handheld laser scanning is a lower-end application in the eyes of the user; the user trades accuracy in for more flexibility and a bigger working volume. Furthermore, the way a certain technology is implemented by the different vendors will give results with a different quality.""\nUnmeasurableDespite its many applications, there are situations where laser measurement should not be used. This includes any application that will have a change in temperature over the line of the laser. According to Dean Solberg, vice president at Exact Metrology Inc. (Algonquin, IL), laser is a light measurement tool and temperature changes the wavelength to give inaccurate results-a clean and controlled temperature environment is critical for a good measurement.\nHighly precise, geometrical machined surfaces and highly polished surfaces inhibit laser measurement\'s efficacy. ""In the first case, laser measurement is not as accurate as a touch probe and loses its advantage because few measured points are required,"" says Giles Gaskell, director of business development at NVision Inc. (Wixom, MI) says. ""In the second case, highly polished surfaces have a degraded level of accuracy compared to some other materials.""\nLasers can only measure locations where the beam can contact the part. It is difficult to measure the bottom of a hole from an angle, because the laser beam is occluded.\nIn general, most transparent objects cannot be measured with lasers. Anything that can interfere with the standard model of the laser\'s light reflection can affect performance. However, just because a surface or material is transparent does not mean it cannot be measured. According to Clark, painting the part or spraying a fine dust can permit measurability. Many new laser measurement scanners allow operators to either automatically or manually alter the scanner\'s laser power and camera sensitivity to overcome undesirable reflectivity effects.\nPurchasing and TrainingLaser measurement technologies have their advantages and disadvantages. Potential buyers need to educate themselves on available technologies and how well they are suited for their specific application.\nBefore purchasing a laser measurement system, Holmes recommends always getting an engineering study using actual parts to ensure that the application is a success. Most companies will do it for no charge or credit the cost back if a system is purchased. It is always good to ask for references on similar applications. Smith suggests buyers ask about accuracy, resolution, scan area and volume, number of points per second, NIST traceability and what file formats to interface to.\nLaser measurement devices often are more expensive than traditional measuring systems. Valliant advises using a lower-cost, mechanical device to meet specifications when volume does not justify the extra expense.\nAlso, there are few standards for laser measurement that make it possible to compare the solutions of different vendors on paper in an objective way. Because of this, Jans says a benchmark on the customers measurement object will always be needed to compare the quality of the different vendor solutions.\nAccording to Sahler, questions that must be asked prior to purchasing a laser measurement system include:\n• Is it safe?\n• What is the warm-up period?\n• What is the accuracy and how is it determined?\n• What is the operating distance range?\n• Can it do the job in time?\n• What about optical noise?\n• Can it be used in ambient light and any other disturbing factors?\n• What is the weight and size of the unit?\nTraining is different for every laser measurement system. ""The use of a laser-measuring system should be quite easy assuming the manufacturer provides the necessary software and adequate instruction for operating the system,"" says Melissa Young, marketing coordinator at Automated Precision Inc. (Rockville, MD). ""A good laser measuring system should be MS Windows-based to ensure ease of use. If a user has basic computer skills and knowledge, then training to use a laser system should not be difficult.""\nWhile the laser function is relatively easy to learn; handling and deciphering the data afterward can be a challenge. According to Martin Morris, president of Laser Measurement Services Inc. (Playa Del Rey, CA), while it is somewhat straight forward to train an operator to use currently available laser measurement systems to measure various aspects of machine tools and CMMs, it is more difficult and much more important to train the operator to analyze the measurements taken and apply corrections, mechanically or via software parameters, to correct the inaccuracies of a machine tools.\nTo ensure quality, laser measurement suppliers are simplifying procedures, and providing improved design, automation and fixturing. But laser measurement is different than mechanical measurement, and many international and commonly accepted training standards and procedures for measurements have evolved over decades based on mechanical devices.\nLaser measurement capabilities did not exist when many mechanical measurement standards and procedures were developed. These procedures and standards do not always apply to the laser measurement. Valliant advises that operators need to be open to new ideas and concepts. He says it is not always possible to directly relate mechanical procedures to laser procedures. Operators must be willing to accept the changes required to use the laser technology.\nLaser Measurement\'s FutureIn the future, as computers get faster, laser measurement will further ensure quality by producing more data per second from scanners. Increased competition should force prices to decrease. There will be a wider range of localizing devices, improved software and higher speeds of data acquisition. Devices should become lighter and smaller, have higher accuracies and distance capabilities, and enhanced automated feature recognition.\nAccording to Martin Dumberger, vice president of Micro-Epsilon (Raleigh, NC), semiconductor-based laser triangulation is currently about as fast and as accurate as it can get. ""More economical systems will be introduced that will have more features for the dollar,"" he says. ""Laser sensors with less than 0.03% linearity are at their limits of what is physically possible in spot penetration. So there will be even more sophisticated systems with even higher integration of intelligence to improve the performance.""\nUntil now the majority of laser scanners have been manually operated and flexible. Gaskell says this is ideal for design and development environments, but less so for in-line applications. He forecasts increasing numbers of in-line contact measurement solutions available in the future. Q\nFor more information on the companies mentioned in this article, visit their Web sites:\n• Automated Precision Inc., www.apisensor.com;\n• Axis Systems, www.axis-systems.com;\n• Exact Metrology Inc., www.exactmetrology.com;\n• Faro Technologies Inc., www.faro.com;\n• Laser Design Inc., www.laserdesign.com;\n• Laser Measurement Services Inc.,\n• Metris, www.metris.com;\n• Micro-Epsilon, www.me-us.com;\n• Neptec, www.neptec.com;\n• NVision Inc., www.nvision3d.com; and\n• Optical Dimensions, www.opticaldimensions.com.\n• Laser measurement ensures quality in manufacturing-related activities by creating absolute references for measurements.\n• To ensure quality, laser measurement suppliers are simplifying procedures, and providing improved design, automation and fixturing.\n• Laser systems range from single-axis measurers to large 3-D point cloud devices.']"	['<urn:uuid:89d67d9c-41f2-47af-9439-fd4b3c07b48f>', '<urn:uuid:98d8e88a-cee7-47ed-8ce0-d6a4532de99a>']	open-ended	with-premise	short-search-query	distant-from-document	comparison	novice	2025-05-13T05:52:58.810667	7	106	2976
31	Does water level affect beach activities at Greatstone like global tides?	Yes, tidal ranges significantly affect beach activities at Greatstone. For optimal sea swimming, visits are recommended between half tide to full high tide. The beach exhibits two distinct areas - firm sand near shore and soft mud approaching the sea, which affects activities like horse riding. These local patterns are part of the broader tidal phenomenon caused by sun and moon's gravitational forces, with tidal ranges typically becoming larger closer to coast and varying based on factors like water basin size and shape.	"[""The sandy beach at Greatstone is quite flat and stretches from north to south for over two miles, and is frequently 'washed' by the tide of the English Channel.\nMore than anything else, the beach has been the main reason that Greatstone village exists as ever since 'going to the seaside' has been popular people have visited Greatstone.\nGreatstone beach has drawn holiday makers from far and wide. It provides safe sea bathing in the haven of Romney Bay and miles of fine sand to build all the castles you want, play beach sports, have a swim in the sea or just laze around.\nThe fresh winds that often occur in Greatstone, together with the flat sandy beach devoid of groynes, makes the beach popular with a whole range of sports that use the wind.\nEnjoying a picnic\nGiven the flatness of the beach and a maximum tidal range of nearly 7 metres, the difference between high tide and low tide can be almost ½ mile.\nThis means that if you come to Greatstone to particularly have a swim in the sea, it is best to pay your visit from between about half tide to full high tide.\nPlease go to our Tide Times page to find out the tide times for today and the next 28 days.\nGreatstone Dunes separate the beach and sea from the land along almost the whole length of Greatstone. It is a Site of Special Scientific Interest with many rare species of plants.\nFor more information please see Greatstone Dunes.\nWalk through the dunes to the beach and sea\nAnimals on the Beach\nYou can walk your dog on the beach but certain areas are closed to dogs from 1 May to 30 September. For more information please see Dogs on Beaches.\nThe long stretches of flat firm sand can also suit horse riding and horse buggys.\nCaution There are two distinct areas of the beach:\n- the relatively firm sand nearest the shore and,\n- the soft mud with mudholes as you approach the sea.\nThe different physical appearance between the two is clear and horses should be kept to the sand area and the mud area should be avoided.\nIn July 2010 a horse got stuck in the soft mud and had to put down. More information\nYou will see a variety of birds on the beach, particularly when the tide is going out as this seems to be a popular time to feed.\nFor more information about birds please see our Birdwatching on Romney Marsh page.\nThe fresh winds that often occur in Greatstone, together with the flat sandy beach, makes the beach popular with a whole range of sports that use the wind.\nYou will find kite surfers on the sea and kite flying, kite boarding, kite buggys and land yachting on the beach. Indeed, Greatstone is deemed to be one of the finest land yachting sites in the UK. You can find out more about land yachting on Greatstone Beach on our Land Yachting page.\nOystercatchers feeding time\nThe Varne Boat & Social Club in Greatstone offers facilities for motor boats, sailing and jet ski. Access to the foreshore is via their own private slipway, which is constantly monitored and kept clear of shingle. The Varne has four launch vehicles, which move the boats from the compound down the slipway.\nFor more information please visit the Varne Boat & Social Club website.\nAround high tide, sea fishing from the beach is popular. Whiting, school bass, pouting, eels, flounder, sole and rockling all frequent the sea off Greatstone. The sea bed is rich in lugworms, which are regularly collected when the tide is out and used as bait.\nThe Varne club (above) has a fishing section for those who like to fish from a boat. You can find out more about fishing on our Fishing on Romney Marsh page.\nThere are two pay and display car parks in Greatstone, adjacent to the beach. One is in Coast Drive, opposite to Clark Road, and the other is in The Parade, opposite to Dunes Road.\nSee Greatstone Map\nThere are public toilets adjacent to the car park in the Parade. They are open 8am to 7pm from 1 May to 30 September, and 8am to 5pm from 1 October to 30 April. See Greatstone Map.\nBarbecues on the Beach\nThere is no by-law prohibiting people from having barbecues on the beach. However, please remove all evidence of the barbecue when done by disposing of all litter, including barbecue remains, in a responsible way.\nPlease take extra care with any remaining charcoal embers that may still be hot. There have been instances of the hot charcoal setting light to litters bins and, even worse, causing burn injuries to young children. Anyone leaving barbecue remains on the beach can be fined under the litter laws.\nHorse Trotting on Greatstone Beach"", ""What Is a Tidal Range?\nA tide refers to the rise and fall of sea levels due to the gravity from the sun and moon, as well as the rotation of the earth. A tidal range is the difference in the height of a high tide and its corresponding low tide. Tidal ranges are not fixed but vary depending on the location of the sun and the moon. Additionally, the greatest tidal ranges tend to occur during spring tides, when the gravitational forces of the sun and the moon are in alignment. Tidal ranges are also large during the first and last stages of a moon phase. During a new moon, the gravitational forces of the moon and the sun reinforce one another, while the two forces are opposed during a full moon. While coastal regions will receive higher than normal tidal ranges during these times, the highest tidal ranges are experienced when a spring tide coincides with the equinox.\nTidal Range Classifications\nThe average tidal range in an open ocean is approximately 0.6 m, with a global range between zero and 12 m. A tidal range typically becomes larger closer to a coast. Other factors that can determine a tidal range include the amount of water near the coast, as well the size and shape of the water basin. Tidal ranges are often greater in larger bodies of water, and the geography of a water basin can either funnel or disperse a tide, increasing and decreasing the tidal range, respectively.\nOne common misconception about the factors affecting tidal ranges is that they increase as one moves north from the equator. This erroneous theory stems from the fact that most areas with high tidal ranges are located in areas north of the equator.\nTidal ranges are typically grouped into three categories. Tidal ranges less than 2 m are classified as micromareal, those between 2 m and 4 m are classified as mesomareal, and tidal ranges greater than 4 m are classified as macromareal.\nThe World’s Largest Tidal Range\nThe world's largest tidal range is observed at Canada's Bay of Fundy, which can reach 16.3 m (53 feet). The Bay of Fundy is an example of how geography can increase a tidal range by funneling. The bay sits between the two Canadian provinces of New Brunswick and Nova Scotia, and the bay becomes narrower from the mouth of the bay to the inner shores. The tide at the Bay of Fundy is semidiurnal, meaning that there are two high tides and two low tides each day, spaced about 6 hours and 13 minutes apart. The difference between low tide and high tide can reach an astonishing 16.3 m with over 115 billion tonnes of water flowing in and out of the bay. The highest recorded tidal range was in 1869 where the water level rose 21.6 m (71 ft) during the Saxby Gale.\nLarge tidal ranges also occur in the United Kingdom, reaching up to 15 m at the Severn Estuary, which is between England and Wales. Parts of the United States that receive high tidal ranges of up to 12 m feet include Anchorage, Alaska.""]"	['<urn:uuid:4636695a-72ff-49e3-8657-c3562d6055d9>', '<urn:uuid:b9fb11ca-0c78-4518-9dd3-1ae3a13fb892>']	open-ended	direct	concise-and-natural	distant-from-document	comparison	expert	2025-05-13T05:52:58.810667	11	83	1341
32	I'm trying to understand the relationship between electrons' wave-like nature and their location - could you explain why it's impossible to determine both an electron's exact position and velocity at the same time?	This impossibility is described by the Heisenberg uncertainty principle: the more you know about an electron's velocity, the less you know about its position, and vice versa. This is because electrons behave more like waves than particles. Just like ocean waves, which can have either a clear direction of motion (like waves moving toward a beach) but no exact location, or a clear location (like ripples from a stone dropped in water) but no single direction of motion, electrons cannot have both properties defined simultaneously. This is a fundamental characteristic of electrons, not just a limitation of measurement.	"['General Chemistry/The Quantum Model\nIt turns out that photons are not the only thing that act like waves and particles. Electrons, too, have this dual characteristic. Electrons can be thought of as waves of a certain length, thus they would only be able to form a circle around the nucleus at certain distances. Of course, this brings up a problem: are electrons particles in a specific location, or waves in a general area? Werner Heisenberg tried using photons to locate electrons. Of course, when photons reach electrons, the electrons change velocity, and move to an excited state. As a result, it is impossible to know the velocity and location of an electron at the same time. This is known as the Heisenberg uncertainty principle. The Heisenberg uncertainty principle is a kind of scientific dilemma: the more you know about something\'s velocity, the less you know about its position; and the more you know about its position, the less you know about its velocity. The significance of this uncertainty is that you can never know exactly where an atom\'s electrons are.\nOn the tiny scale of an atom, the particle model of an electron does not accurately describe its properties. An electron tends to act more like a water wave than a billiard ball. At any one moment in time the ball is in some definite place; it is also moving in some definite direction at a definite speed. This is certainly not true for waves or electrons in general. The Heisenberg uncertainty principle states that the exact position and momentum of an electron cannot be simultaneously determined. This is because electrons simply don\'t have a definite position, and direction of motion, at the same time!\nOne way to try to understand this is to think of an electron not as a particle but as a wave. Think of dropping a stone into a pond. The ripples start to spread out from that point. We can answer the question ""Where is the wave?"" with ""It\'s where you plonked the stone in"". But we can\'t answer the question ""What direction is the wave moving?"" because it\'s moving in all directions. It\'s spreading out. Now think of a wave at the seaside. We know the direction of motion. It\'s straight in towards the beach. But where is the wave? We can\'t pinpoint an exact location. It\'s all along the water.\nThe Wave Function\nIf we can never know exactly where an electron is, then how do we keep track of them as they orbit atoms? Erwin Schrödinger made the concept of the Schrödinger Wave Function. It tells the probability of an electron being found at a given position. You don\'t know where the electron is, but you know where it is most likely and least likely to be found. The electron could be anywhere, but it is probably going to be a certain distance from the atom, staying within a certain shape.\nIn the following sections, we will learn about the shells, subshells, and orbitals that the electrons are in. Try not to get confused; it can be difficult. Understanding this information will help you to learn about bonding, which is very important.\nIn essence, each electron orbiting an atom has a set of four numbers that describe it. Those four numbers, called quantum numbers, tell us how far away the electron is, what shape of path it is likely to follow, and which direction its orbit goes. Each electron in an atom has a unique set of numbers, and the numbers can change if bonding occurs or an electron is energized into a higher-energy orbit. In the next chapter, we will learn the exact meaning of those four values and how they affect the path the electron follows.\n||Keep in mind that the pictures of the orbitals you will soon see show the area in which the electron is most likely to be, not its exact orbit. It\'s like a picture of a sprinkler watering a lawn, and the electrons are drops of water. You know the general area of the water, but not the exact location of each droplet. In the orbital pictures, you know the general area the electron could be in, but not its exact path. This is a result of the Uncertainty Principle.|']"	['<urn:uuid:8914d8c8-c613-4b12-b335-10092d5a271b>']	open-ended	with-premise	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-13T05:52:58.810667	33	98	715
33	how many pr professionals experience mental illness and what basic stress reactions happen in body	Approximately 34% of European PR professionals experience mental illness. When stress is experienced, the body responds through the sympathetic system by releasing stress hormones that cause physical reactions: the heart beats faster, blood vessels constrict except for those supplying arms, legs and heart, pupils dilate, mouth becomes dry, and the digestive system slows down, creating a butterflies sensation in the stomach.	"['Mental health is closely linked to occupation, with work at the core of most adults’ lives. For instance, the American Institute of Stress (AIS) recently indicated that approximately 66% of people’s stressors are related to their jobs.1 A particular problem is the lack of work-life balance, which can trigger certain mental illnesses like depression and anxiety.2\nDo Specific Jobs Pose a Mental Health Risk?\nNumerous studies have explored the occupational characteristics related to mental health, such as job demands, supervisor support, and work stress,3 with the key finding being that people in certain occupations are more prone to mental disorders. Stress, in particular, has been found to be positively correlated with mental health.4\nThe 10 most stressful jobs in America tend to revolve around emergency services, transport control, public relations, and executive roles. 5\nEmergency and Rescue Services\nFirefighters, soldiers, police officers, and disaster response personnel are at high risk for mental health issues as a result of being involved in emergency situations and being exposed to varying degrees of violence. This population has an increased risk of being exposed to traumatic events through their daily work, often leading to work-related post-traumatic stress disorder (PTSD).6,7\nFor instance, a study found high rates of PTSD and depression in firefighters.8 Likewise, approximately 100,000 active police officers in the United States suffer from PTSD, and many also live with the comorbidities of depression, anxiety, and suicidal ideation.9 Research from Johns Hopkins University Bloomberg School of Public Health in Baltimore, Maryland, confirmed that police and firefighters are at higher risk for mental illnesses compared with civilians, and that their exposure to trauma is related to the development of alcohol use and mood and anxiety disorders.9 In a study of military personnel, almost 25% of 5500 Army soldiers were diagnosed with a mental disorder such as depression or PTSD, with PTSD rates being approximately 15 times higher than the general public.10\nThe Germanwings Flight 9525 incident in 2015 brought airline personnel’s mental health status to the forefront. Indeed, the crash was reportedly caused by Andreas Lubitz, a pilot who had previously sought treatment for suicidal tendencies, depression, and psychosomatic illness. An international survey of 3485 pilots indicated that 12.6% of the sample population met depression thresholds and 4.1% were thinking about suicide.11 In addition to jet lag, the stressors experienced by pilots include long working hours, pressure from the responsibility of passenger safety, and cockpit conditions such as low oxygen levels and high noise levels. Some pilots may also be hesitant to seek treatment due to the impact this could have on career advancement.\nTaxi driving is another highly stressful occupation. One study of 508 taxi drivers found that 33% presented with at least 5 symptoms of depression, which was mainly attributed to lack of leisure activities.12 Another study found that, compared with the general population, public transportation drivers had higher rates of alcohol abuse, major depressive episodes, burnout syndrome, and anxiety.13 Drivers are often required to deal with long working hours and night shifts, which could explain some of these symptoms and unhealthy coping mechanisms. Traffic jams and air and noise pollution may also have a negative influence on their mental health.\nPublic Relations (PR)\nLike most people in PR jobs, newspaper reporters, broadcasters, and event coordinators face tight deadlines, managing unpredictable deals, covering violent social issues, and adapting to a hectic workplace environment. These factors may explain why approximately 34% of European PR professionals experience mental illness. Almost half of them reported that they perceive their colleagues as unaccepting of mental illness, and this lack of social support and taboo regarding mental illness is counterproductive to encouraging help-seeking behavior.14\nAn Australian study showed that 21% of 261 US-based senior executives are psychopaths.15 Furthermore, the antisocial characteristics often found in executives, such as deceitfulness and a lack of empathy, may further cause psychological turmoil for their subordinates. Indeed, middle managers, who often help senior executives, have higher stress levels than their bosses due to their job demands.16 Subsequently, managerial positions appear to be linked to high levels of depression and anxiety.17\nEvidence suggests that the key link between occupation and mental illness is high stress, which can increase the risk of PTSD, anxiety, depression, and mood and sleep disturbances. It is important for physicians to identify occupational stress as early as possible so that the appropriate interventions can be implemented before problems escalate. Tools such as the Job Stress Scale,18 Workplace Stressors Assessment Questionnaire,19 and Depression Anxiety and Stress Scales20 can assist with this.\nOnce occupational stress has been identified, stress management interventions can be put into place. The physician can assist with secondary interventions by attempting to reduce the stress severity before it leads to serious health problems.21Such interventions are aimed at the individual and involve techniques like relaxation, deep breathing, meditation, time management, exercise, and goal setting.22 These techniques help individuals by encouraging them to monitor their stress levels, identify the causes of stress, and develop the necessary skills to manage the stress effectively.\n- The American Institute of Stress. Workplace stress. www.stress.org/workplace-stress/. Updated 2017. Accessed April 17, 2017.\n- Wang J, Lesage A, Schmitz N, Drapeau A.The relationship between work stress and mental disorders in men and women: findings from a population-based study. J Epidemiol Community Health. 2008;62(1):42-47.\n- Thorsteinsson E, Brown R, Richards C. The relationship between work-stress, psychological stress and staff health and work outcomes in office workers. Psychology. 2014;5:1301-1311.\n- Jiang T, Ge H, Sun J, Li R, Han R, Liu J. Relationship between Occupational Stress, 5-HT2A Receptor Polymorphisms and Mental Health in Petroleum Workers in the Xinjiang Arid Desert: A Cross-Sectional Study. Int J Environ Res Public Health. 2017;14:402-413. doi:10.3390/ijerph14040402\n- Career Cast. The most stressful jobs of 2017. www.careercast.com/jobs-rated/most-stressful-jobs-2017. Updated 2017. Accessed April 17, 2017.\n- Skogstad M, Skorstad M, Lie A, Conradi HS, Heir T, Weisæth LWork-related post-traumatic stress disorder. Occup Med. 2017;63(3):175-182.\n- Harvey SB, Milligan-Saville JS, Paterson HM, et al. The mental health of fire-fighters: An examination of the impact of repeated trauma exposure [published online Nov 24, 2016]. Aust N Z J Psychiatry. doi:10.1177/0004867415615217\n- Alghamdi M, Hunt N, Thomas S. Prevalence rate of PTSD, Depression and Anxiety symptoms among Saudi Firefighters. J Trauma Stress Disord Treat. 2017;5(3):2.\n- Moreno, D. PTSD: The hidden toll of policing. The Epoch Times. 2017. www.theepochtimes.com/n3/2115193-ptsd-the-hidden-toll-of-policing/. Accessed April 17, 2017.\n- Willingham V. Study: Rates of many mental disorders much higher in soldiers than in civilians. CNN. http://edition.cnn.com/2014/03/03/health/jama-military-mental-health/. Accessed July 17, 2017.\n- Wu AC, Donnelly-McLay D, Weisskopf MG, McNeely E, Betancourt TS, Allen JG. Airplane pilot mental health and suicidal thoughts: a cross-sectional descriptive study via anonymous web-based survey. Environ Health. 2016;15(1):121.\n- Bawa MS, Srivastav M. Study the epidemiological profile of taxi drivers in the background of occupational environment, stress and personality characteristics. Indian J Occup Environ Med. 2013;17(3):108.\n- Ruiz-Grosso P, Ramos M, Samalvides F, Vega-Dienstmaier J,Kruger H. Common mental disorders in public transportation drivers in Lima, Peru. PloS one. 2014;9(6):e101066.\n- Griggs I. A third of PR people have experienced mental ill health so what is the industry going to do about it? PR Week. www.prweek.com/article/1335436/third-pr-people-experienced-mental-ill-health-so-industry-going-it. Accessed April 17, 2017.\n- Brooks N. The emergence of non-criminal psychopathy. Presented at: 2016 Australian Psychological Society Congress. September 13-16. Melbourne, Australia.\n- Prins SJ, Bates LM, Keyes KM, Muntaner C. Anxious? Depressed? You might be suffering from capitalism: contradictory class locations and the prevalence of depression and anxiety in the USA. Sociol Health Illn. 2015;37(8):1352-1372.\n- Edwards KL, Walker SL, Bodenham RF, Ritchie H, Shultz S. Associations between social behaviour and adrenal activity in female Barbary macaques: consequences of study design. Gen Comp Endocrinol. 2013;186:72-79.\n- Lambert EG, Hogan NL, Camp SD, Ventura LA. The impact of work–family conflict on correctional staff: A preliminary study. Criminol Crim Just. 2006;6(4):371-387.\n- Mahmood MH, Coons SJ, Guy MC, Pelletier KR. Development and Testing of the Workplace Stressors Assessment Questionnaire. J Occup Env Med. 2010:52(12):1192-1200.\n- Crawford JR, Henry JD. The Depression Anxiety Stress Scales (DASS): Normative data and latent structure in a large non‐clinical sample. Br J Clin Psychol. 2003;42(2):11-131.\n- Murphy LR, Sauter SL. The USA perspective: Current issues and trends in the management of work stress. Aust Psychol. 2003;38(2):151-157.\n- Giga SI, Cooper CL, Faragher B. The development of a framework for a comprehensive approach to stress management interventions at work. Int J Stress Manag. 2003;10(4):280.', 'Stress and its impact\nStress is one of those words that is used very casually. We talk about being stressed when faced with a choice of which dress to buy for an important event or when we canít find the charger for our mobile phone.\nReal stress, however, has a huge impact on our health. If you already have a long term health condition, it is even more important that you learn how to reduce your stress levels.\nSo, what exactly is stress?\nProfessor Stephen Palmer, an expert in stress and stress management, defines it thus: “stress occurs when perceived pressure exceeds your perceived ability to cope”\nWe all need a certain amount of pressure in our lives to make it enjoyable; that thrill when you go on a first date, the nerves as you walk into an exam room, the fun of trying something new. When you are choosing a dress or hunting for the charger, what you are feeling is pressure.\nHowever, if you feel that the pressure has become too much, perhaps your boss is giving you more work than you feel you can cope with or a relationship is going through a bad patch and you are worried your partner will leave you, then your stress responses kick in.\nThe stress response and mechanism behind it\nTo understand the stress response, we have to wander into the world of neuroscience to get a feel for how the brain works. At any given time, your brain is being bombarded with hundreds of pieces of information through your five senses. Your brain processes that information faster than any super computer and it does this by comparing the new information with things that have happened before.\nIf you pick up an apple, your brain will process the information that your eyes, nose and fingers send to it, compare it with what it has learnt before and come back with apple.\nThis happens so fast you are not even aware of it. If you pick up a strange fruit that you have never seen before, the brain takes longer to process it and you will find yourself turning it over in your hands, perhaps smelling it and looking for a sign to tell you what it is. This information processing starts from the moment you are born.\nWhat about if you see a tiger loose in the street? Our brains process this slightly differently. The human brain has been in development for thousands of years.\nFight or flight?\nThe first part to develop was the part at the back of your head just above your spine – called the amygdala. This is the most basic brain form and it’s here that the things you do to stay alive (such as breathing) are controlled. It’s also where the fight or flight response is triggered. This response prepares your body to either fight or flee from the potential danger and it was essential in the days when if you hesitated for a minute, you could end up being eaten!\nBack to the tiger. As soon as you see it, the brain starts running through its processes. A signal is sent along the neural pathways to the areas that control your sight, hearing etc. and to the part of your brain that makes decisions about risk.\nHowever, part of that signal is sent directly to the amygdala. As soon as the amygdala receives the signal, it sends out a flood of hormones into your system. Your heart starts beating faster, your blood vessels constrict except for those supplying your arms, legs and heart, your pupils dilate, your mouth becomes dry and you get that feeling of butterflies in your stomach as your digestive system slows right down.\nThis all happens incredibly quickly, before the rest of your brain has even had time to process that it’s a tiger on the loose. The technical term for the system that does all this is the sympathetic system and as well as the brain, the adrenal glands and pituitary glands are involved. Hormones such as noradrenaline, adrenaline and cortisol are released. Now that this is all in place, you can run away from the tiger as fast as you can - the flight response.\nThe fight response works in exactly the same way. To put it in the relevant context, imagine you are in a traffic jam. Then, someone cuts in front of you all those hormones start rushing around your body and your body gets itself ready for a fight.\nWhen the danger is past, your parasympathetic system then sends out a different hormone so that your heart rate returns to normal, your blood starts flowing again and your stomach gets back to the business of digesting your food. If you are sitting comfortably relaxed in a chair reading this, it’s your parasympathetic system that’s in charge.\nApplication to today’s world\nNow you are probably thinking this is all very interesting but the only tigers you have seen have been safely behind bars in a zoo. What does this have to do with you?\nIn this modern age, we are bombarded with more information than at any other time in human existence. Remember that this information is being gathered from the moment you are born. The human brain takes longer to develop to full maturity than any other animal.\nIn fact, all the connections aren’t complete until you are in your early twenties. The amygdala doesn’t know the difference between a tiger and a maths exam you haven’t studied for. It just processes that it’s scary, so let’s get those hormones flowing.\nIn some people, the flight or fight response is activated way more often than usual, especially if as a child they felt very insecure in their environment. This can mean that even simple things like loud noises or strong smells can be perceived as a threat, setting off the sympathetic system.\nWhy to manage stress\nEventually, your body becomes overloaded with cortisol and things start to go wrong. Some people have heart attacks or strokes; others may use alcohol or drugs to alleviate the stress. In some cases, mental health problems such as depression or anxiety may develop.\nWhen you have a long-term health condition, your body is already under stress from dealing with that. The difficulties you may be having around work, relationships etc. will be adding further to your stress levels.\nHow to manage stress\nSo you can see that learning to manage stress is very important. Each of us is different, so we all react differently in a given situation.\nTake some time out to think about your daily routine and look at the areas where you feel stressed. See if there are ways that you can change or adapt things to make your life easier.\nThere are lots of ways to destress...listening to music, relaxation techniques, going for a walk in nature, mindfulness, yoga, tai chi...The list goes on. Finding what works for you may take some trial and error but it will be worth it.\nSometimes, the biggest cause of stress is the thoughts that we have and how we react to them. If we think, ""I can\'t cope"", our stress levels soar. If we react badly to things other people say, if we keep wishing that our lives could go back to the way they were in the past or if we feel that we are being a burden to our loved ones, stress will be a constant companion.\nA life coach can help you deal with stress, working with you to change the way you think about things, helping you to find the best stress relief techniques and helping you to see the difference between pressure and stress.\nWhat are your best techniques for dealing with stress? Share them in the comments!\nSilimar articles you might find interesting:\n- What You Didn\'t Know About Maintaining a Positive Mental Attitude\n- Dealing with Anxiety: The Toll It Takes on Our Wellbeing\n- How to Notice Your Stress Triggers and De-stress?\n Palmer, S and Cooper, G: How to deal with Stress (2007) (Kogan Page)']"	['<urn:uuid:1e19590a-362f-40af-8fdb-ea2a0a4d8cd5>', '<urn:uuid:fc7e9758-9c41-4430-80a4-a4512f026fa5>']	factoid	direct	long-search-query	similar-to-document	multi-aspect	novice	2025-05-13T05:52:58.810667	15	61	2748
34	fabric scale prints moth infestation signs	When working with printed fabrics, scale is crucial - small prints appear as solids from a distance, while geometric designs add movement and interest to quilts. Various scales should be used together, including monochromatic prints and textured solids for a softer look. When examining fabrics for moth damage, there are specific signs to watch for: silken webs across fabric surfaces, webbing tubes, fecal pellets matching the color of the attacked material, and furrows or long holes in the fabric surface. These signs typically appear in dark, undisturbed areas where moths prefer to live, such as in closets or fabric folds.	"['Selecting fabric for a project is a personal thing. When looking through patterns and projects, it is clear to see that a quiltmaker will develop a unique style and taste.\nSome projects are made from soft flannels and brushed cottons to produce warm and comforting quilts, others are made from cottons, resulting in bright color arrangements suitable for display or for interior decorations. Your fabric choice will stamp your individuality on the project. It is never possible to re-create a quilt exactly, as fabric designs and color schemes are always changing.\nTo achieve interest in your quilt you need to use different tonal values, and if you are using print fabrics, the scale of the print is also an important factor. The tonal values of fabric in your quilt should include light, medium, and dark fabrics. These values are relative to each other, so one person’s medium may be another person’s light; the fabrics can even play different roles in the same quilt.\nIf you are unsure of the value of the fabrics, you can view them though a value finder, a red screen that eliminates the color and allows you to see the lightness and darkness, i.e., the value. A similar effect can be achieved by photocopying fabric and looking at the value of greyness. Another technique that you can employ is to stare at the fabric selection and gradually squint at it: the darker fabrics “disappear” first. This is a good technique when perhaps you are confused between brightness and lightness.\nThe scale of the design of a print fabric is very important. Your quilt needs to hold interest both close to and from a distance. Try to use a variety of scales — small prints when viewed from the distance will look like solids. Geometric designs add movement, encouraging the eye to move over the surface and allowing you to see the other fabrics. There are also fabrics on the market that are monochromatic prints or textured solids, which are good substitutes for a solid fabric, giving a softer overall finished look.\nYou can always experiment with coloring a quilt design on paper before making your fabric selection, but remember, no colored pencil or felt-tip pen can re-create a single fabric or its effect when placed next to another. If you are unsure of your fabric selection, purchase only a small amount and try a fabric mock-up. Quiltmakers are avid collectors of fabric, often buying without a project in mind. If you buy your fabrics separately, take the existing ones along with you to see them all together, as it is very difficult to carry an image of color in your head. Finally, always be prepared to change your mind.\nMost rotary cutting projects involve the cutting of strips first; these are best cut from across the width of the fabric. Therefore, take care if a design calls for a quarter: most quilting supply shops sell quarters either “fat” or “long.” A long quarter is cut 9 in./25 cm. deep by the width of the bolt. A fat quarter is cut 18 in./50 cm. deep by the width of the bolt, then split at the fold to give a piece 18 x 22 in./50 x 56 cm. Only buy a fat quarter if the design specifies such a size.', ""- The geographical origin of the webbing clothes moth is not yet known; some experts believe it came from South Africa, while others argue it has European origins.The clothes moth is now worldwide in distribution.\n- Contrary to common belief, it is not the adult moths that eat holes in fabrics and carpets - it is their larvae that feed on organic fibers in order to obtain the proteins they need for growth.\n- Clothes moths are rarely seen during the day. They prefer dark, undisturbed areas such as basements and closets, where they live in dark corners or the folds of fabrics.\n- Clothes moths will generally avoid synthetic and cotton fabrics, as they don’t contain keratin, and focus on clothes made of wool, angora, cashmere, and other animal fibers.\n- Moths don’t need liquid water; they obtain their needed moisture by feeding on garments that contain traces of human sweat, urine, and other liquids that have been spilled on them.\nThe adult stage of the webbing clothes moth has a uniform pale golden color and measures approximately ¼ inch with the wings folded back on the body and ½ inch with the wings spread. The eyes are black, and the top of the head is covered in a reddish golden tuft of hairs. The larvae’s head capsule is brown to black, and the body creamy white; eyes are absent in this stage. As it feeds on the surface of a fabric, the larva spins long threads and builds tunnels made of silk, excrements, and scraps of whatever fabric is available for feeding during this stage. Larvae are commonly found in the hidden parts of clothing, such as under cuffs and collars.\nDue to the similarity in size and appearance, webbing clothes moths are often confused with casemaking and grain-infesting moths. It is, however, possible for homeowners to differentiate between them by looking closely at their size at rest (clothes moths are approximately 1/2 inch while food-infesting moths are 1/3-1/2 inch in length) and color (the casemaking clothes moths are brown with colored spots and have lighter colored hairs on their heads than webbing clothes moths).Unlike the webbing clothes moth larvae, the larvae of casemaking clothes moths aren't exposed - they live inside a tube made of silk and wool, where they feed until they reach maturity.\nDiet, Behavior, and Habits\n(Image source: Flickr Commons\nTypically, if conditions such as room temperature, humidity, and the quality of food are favorable, the clothes moth goes from egg to adult in approximately 45 days. The eggs are glued on fabrics so that they will not be easily dislodged. Within 1-2 days of pupation, moths are ready to mate and lay an average of 40-50 pinhead-sized eggs, usually on the surface of or near fabrics and furnishings. Adult moths do not possess a mouthpart and cannot feed, and so they die within one month.\nThe webbing clothes moths' primary diet contains woolens, fur, leather, hair, mohair, and even dead insects and dried animal carcasses. Their typical dwelling places include clothing, carpets, blankets, stored wool garments, upholstery, piano felts, fish meal, mounted animals, and other dark and isolated places where they can feed and mate. Synthetic and cotton fabrics are usually avoided, unless they are mixed with organic fibers, in which case the larvae may feed on them and use the remaining ones to build their tunnels. Fabrics that are not of animal origin cannot be digested.\nThe home provides the ideal environment for clothes moths to grow and reproduce. They especially thrive on dirty and stained fabrics, from which they can obtain the vitamins, salts, and essential nutrients they need for survival. Clean wool, which lacks vitamin B and salts required by the larvae, will delay and even stop their development into adults. Clothes damaged by the webbing clothes moth display furrows on the surface of the fabric, a direct result of the grazing activity of the larvae. The presence of long, differently-shaped holes is usually the sign of a heavy infestation.\nSigns of Infestation\n(Image source: Flickr Commons\nWhere to look for moth larvae and damage ?\n- Cracks and crevices near or on food sources\n- Wool sweaters, fur, mohair, cashmere, and other organic fabrics; carpets and rugs; upholstered furniture; fabrics with food, beverage, and perspiration stains; synthetic and cotton blends\n- Bristle brushes made from animal fibers\nWhat are the signs of an infestation ?\n- Damaged fabrics\n- The presence of silken webs and scattered patches of silk across the surface of the attacked fabric\n- The presence of webbing tubes and fecal pellets, which are often of the same color as the attacked material\n- Threadbare sports in rugs and carpets\nManagement and Control\n. A moth infestation typically begins when infested garments are brought inside and stored with other clothes made from natural fibers. Therefore, in order to eliminate current infestations and prevent future ones, all clothes should be inspected prior to storage. Woolen fabrics should be dry cleaned and laundered at high temperatures in order to eliminate all moth life stages. Hanging clothes in direct sunlight and brushing them thoroughly will expose larvae and cause them to drop from the fabrics in order to seek protection. Using airtight containers to store items for longer periods is also useful in preventing and controlling infestations.\n.Exposing infested garments to lethal temperatures (lower than 0 degrees F) will almost always kill pests after a minimum of 72-hour exposure. A sudden change of temperature is most effective in repelling moths because it prevents the insects from acclimating to the room and developing resistance to freezing. High temperatures between 110 degrees F and 120 degrees F maintained for at least 30 minutes will also eliminate moths from woolen materials.\n.There are several chemical options available for the management and control of moth larvae, including:\n- Moth crystals containing naphthalene or paradiclorobenzene work to repel moths when placed in airtight containers with the infected clothes. However, the substances are toxic and may also leave an unpleasant odor on clothes and inside closets.\n- Pheromone traps work by luring adult male moths inside a sticky trap, where they get stuck and eventually die. They are relatively easy to use and quite effective at reducing both webbing and casemaking clothes moth infestations.\n- Insecticide sprays should typically be used as a last resort on infested garments that cannot be dry cleaned, laundered, frozen, or fumigated. Insecticides are commonly based on a substance called pyrethrin, which provides a fast knockdown effect. Heavy infestations requiring the use of large quantities of insecticide should be handled by specialized pest control companies.\nPreventing a clothes moth infestation is always easier than eliminating an existing one. In order to minimize the risk of infestation, homeowners must ensure:\n- Periodic dry cleaning and laundering of clothes at high temperatures\n- Proper storage of woolen and fur garments in special pest-proof containers with tight seals\n- Maintaining low humidity levels to delay moth development\n- Good housekeeping practices\n- Regularly monitoring of fabrics and closets for moth presence and signs of damage\n- Regularly vacuuming and inspection of tapestries and woolen carpets\n- Cleaning closets and dressers prior to storing clothes for the season\n- Careful inspection of the area underneath baseboards in closets""]"	['<urn:uuid:740a2890-a017-4dd8-b965-8f3063bfe110>', '<urn:uuid:b4455e3b-2058-4b94-b2d8-b163919c3967>']	open-ended	direct	short-search-query	similar-to-document	multi-aspect	expert	2025-05-13T05:52:58.810667	6	100	1766
35	How do wetlands naturally evolve, and what human activities disrupt them?	Natural wetland evolution can be observed in the Albufera lagoon's history, which maintained a brackish state for thousands of years with diverse microfossil communities and experienced natural fluctuations corresponding to climate events like Bond 5 and Minorca 7, which affected vegetation patterns. However, human activities severely disrupt these ecosystems through multiple mechanisms: hydrological control for agriculture can alter water salinity, while population impacts through agricultural runoff, wastewater effluent discharges, and industrial effluents can cause eutrophication. This accelerated accumulation of organic matter from overgrowth of aquatic plants, algae and bacteria impairs water quality, reduces light penetration, degrades aesthetic conditions, and can produce harmful algal blooms that may be toxic to wildlife.	['The Albufera de València coastal lagoon is one of the largest oligohaline lagoons in the Iberian Peninsula. Highly polluted and threatened by plans for urban development, it has been protected as a Natural Park since 1986 to preserve its environment and surroundings, mostly consisting of ricefields and a forested coastal sand bar. Restoration plans focus on recovering the water quality and submerged macrophyte cover that occupied most of the lagoon in the 1950’s. Until recent studies, little was known about the wetland’s palaeoenvironmental history. To improve this knowledge, we analysed the Holocene evolution of the lagoon based on sedimentology, geochemistry and microfossils (foraminifera, diatoms, ostracods and pollen remains) from four cores. Two were collected in the sand bar, and two from the central lagoon. In combination with previous work, our new data show that the lagoon remained brackish for most of its history since 8700 cal BP, with the frequent presence of accompanying freshwater taxa from 7000 to 3400 cal BP. Notwithstanding chronological uncertainties, some episodes of decline in the abundance of microfossils seem to match aridity events Bond 5 (8.2 ky BP) and Minorca 7 (7.5-7.2 ky BP), the latter marking the switch from a dominance of arboreal vegetation to grasses. The most important change in the water body consisted of a sharp change at the beginning of the 19th century from a brackish to an oligohaline lagoon, driven by anthropogenic hydrological control associated with the expansion of ricefields. Later on, by the 1960-1970’s, the growing population impacts of agricultural, wastewater and industrial effluents launched a major eutrophication process that would eventually sharply reduce the benthic vegetation and invertebrate communities and promote the phytoplankton dominance of the ecosystem in a turbid state. Although our multiproxy study has increased understanding of the lagoon’s history, somewhat supported by documentary evidence, further palaeoecological research in different parts of the wetland would help define the causes of heterogeneous timing of changes in this large, shallow, complex system. Notwithstanding the need for further research, there is a clear priority for managers and the society to work on restoration efforts to drive the Albufera wetland towards one of the previous, less impacted, states of this worn-out and neglected ecosystem.\nBibliographical noteFunding Information:\nThe former Spanish Ministry of Education and Technology funded this research through the project VARECOMED (REN2002-03272). JMB acknowledges the funding from a fellowship (BES-2003-2759) as part of the VARECOMED project. We thank also Blas Valero and Ana Moreno and the people from University of Minnesota, Limnological Research Centre and Lac Core who helped on the laboratory core descriptions. M.A. Rodrigo assisted in the interpretation of macrophyte changes. JMB wants to dedicate the paper to the memory of his grandparents, Carmen Polo and Jose Barba, for their support and advice, and who died during the development of this work. Patrícia Llàcer-Manri-que collaborated in the palynological analysis. We would like to thank two anonymous reviewers for their thoroughly effort in suggesting improvements to an early version of the manuscript. Finally, all living authors would like to acknowledge the great interest of the deceased senior author, Maria Rosa Miracle, for her perseverance in pursuing understanding of natural phenomena and for the conservation of nature.\n© Asociación Ibérica de Limnología, Madrid. Spain.\nCopyright 2019 Elsevier B.V., All rights reserved.\n- Climatic events\n- Coastal lagoon evolution\n- Iberian Peninsula\n- Pollen analysis\nContinental Scientific Drilling Facility tags', 'Eutrophication, or the accelerated accumulation of organic matter from overgrowth of aquatic plants, algae and bacteria, is an ecologically disruptive phenomenon that can impair water quality and, in some cases, harm animals and humans. One of the principal drivers of eutrophication is excess nutrient sources, which are introduced to water bodies by a diffuse array of human activities. Unlike other environmental factors that drive aquatic blooms, nutrients are within the direct purview of the water-quality management community to manage and control.\nSCCWRP is part of a community of researchers working to define how much nutrients in a given water body is too much, and how nutrients combine with other environmental factors to trigger eutrophication. SCCWRP recognizes that California water-quality managers need consistent, science-based approaches for reducing nutrient levels across freshwater and marine environments. Over the long term, SCCWRP’s goal is to develop comprehensive eutrophication management strategies, including the ability to pinpoint when and where eutrophication is likely to occur.\nManaging excess nutrient supplies\nIn population-dense California, nutrients – especially nitrogen and phosphorous – enter aquatic environments from a variety of sources, from urban and agricultural runoff to wastewater effluent discharges to atmospheric deposition. These excess nutrient levels can trigger sudden, rapid blooms of plants, bacteria and algae, including harmful algal blooms (HABs). The blooms, in turn, can lower dissolved oxygen levels, reduce light penetration, degrade aesthetic condition and produce nuisance odors. Some HABs and cyanobacterial HABs (cyanoHABs) also produce toxins that can be lethal to animals that are exposed to contaminated water, from birds to sea otters to domestic dogs.\nNutrient management is at the heart of SCCWRP’s multi-pronged research program to understand how to effectively combat eutrophication’s ecologically disruptive impacts. Although multiple environmental factors work synergistically to drive HABs and other eutrophic blooms, California’s water-quality management community is largely focused on nutrient management. In recent years, researchers have established a scientific foundation for developing management programs and policies focused around more prescriptive nutrient controls. SCCWRP science has helped inform:\n- The State Water Resources Control Board’s anticipated biointegrity and biostimulatory policy, which will govern the condition of wadeable streams statewide by restricting nutrient loading and protecting the health of in-stream biological communities; comparable regional policies in California also are in various stages of development.\n- A draft nutrient management framework for San Francisco Bay’s estuary environments, which is intended to guide managers in assessing risk of eutrophication and setting science-informed nutrient loading targets. Researchers’ long-term goal is to replicate this water body-specific framework elsewhere.\n- Restoration planning options for multiple Southern California estuaries, all of which have been based on nutrient load allocation modeling that quantifies the benefits of placing more stringent caps on nutrient levels.\n- California’s freshwater HABs management framework, which has provided a roadmap for water-quality managers to implement a coordinated, statewide HABs monitoring and mitigation strategy.\nUnderstanding other drivers of eutrophication\nWhile nutrient management is an essential strategy for combatting eutrophication, aquatic bloom events can be accelerated by a number of factors – both natural and human-induced – including habitat degradation, hydromodification and excessive sedimentation. Global climate change also is creating environmental conditions that are increasingly hospitable to disruptive aquatic blooms. SCCWRP is working to disentangle these factors, so that managers can design optimal, science-informed solutions for mitigating ecosystem damage and protecting human health.']	['<urn:uuid:2b77eda6-dbf5-4105-b6e7-dfc5a0d8a09a>', '<urn:uuid:1a0a77a8-5217-4036-8465-3ce607dbc670>']	open-ended	with-premise	concise-and-natural	distant-from-document	multi-aspect	expert	2025-05-13T05:52:58.810667	11	110	1109
36	world war 2 start end nagasaki peace	World War II began in September 1939 when Germany attacked Poland and ended on August 14, 1945, when Japan surrendered following the atomic bombings. After the war, Nagasaki transformed into a symbol of peace and culture under the 'Nagasaki International Culture City Construction Law' of 1949. This commitment to peace is exemplified by the Peace Park, which features the Peace Statue erected in 1955 and the Peace Fountain. The statue's elevated right hand points to the threat of nuclear weapons, while its left hand symbolizes tranquility and world peace, serving as both a memorial and a prayer that such tragedy would never be repeated.	['World War two Timeline\nBefore the official beginning of World War II, many countries acted in an aggressive and warlike manner. In Germany, Adolf Hitler opened the first concentration camps as early as 1933 and became the “Fuhrer” or sole dictator of Germany in 1934.\nIn 1935, Benito Mussolini rose to power and became dictator of Italy. Both rulers quickly started enlarging their territory by taking over smaller countries. Germany took over Austria and Czechoslovakia while Mussolini absorbed Ethiopia and Abyssinia. Meanwhile, In Asia, The Chinese and Japanese armies were at war. Japan signed a treaty with Germany, adding British and French to their list of enemies.\nThere were two sides in the war:\n- Allied Powers (including U.S., Britain, France, USSR, Australia, Belgium, Brazil, Canada, China, Denmark, Greece, Netherlands, New Zealand, Norway, Poland, South Africa, Yugoslavia), and\n- Axis Powers (including Germany, Italy, Japan, Hungary, Romania, Bulgaria).\nWorld war 2 started in September 1939 when Germany attacked Poland. But, the United States did not enter the war until after the Japanese bombed the American fleet in Pearl Harbor, Hawaii, on December 7, 1941.\nThe Bloodiest Battles of World War II:\n- Battle of Stalingrad – From 23 August 1942 until 2 February 1943\n- Battle of Berlin – Fron 16 April until 2 May 1945\nThe key timeline of World War Two are:\n- August 23, 1939: Adolf Hitler and Josef Stalin sign a nonaggression pact\nIn this agreement, the Soviet Union agrees to allow Germany to invade Poland as long as Germany ignores Russia’s invasion plans.\n- September 1, 1939: Germany invades Poland\n- September 3, 1939: Great Britain, France, Australia and New Zealand declare war on Germany\n- September 5, 1939: The United States under Franklin D. Roosevelt declares neutrality. Roosevelt promises American that they will not go to war\n- September 10, 1939: Canada declares war on Germany. This is the beginning of the war in the Atlantic Ocean\n- September 29, 1939: Hitler and Stalin divide Poland\n- November 30, 1939: The Soviets attack Finland\n- April 1940: Germany Invades Norway and Denmark\n- May 1940: Germany invades the Netherland, Belgium and Luxembourg\n- May 10, 1940: Winston Churchill becomes Prime Minister of Great Britain\n- June 1940: Germany invades and conquers France\n- July 1940: Germany begins to attack merchant ships in the Atlantic\nIn the Pacific, Japan begins to occupy French islands in the Pacific. The United States remains out of the war, but stops sending oil and other fuel to Japan\n- September 1940: Germany begins bombing London\nThey bomb London every night for 57 nights, killing more than 40,000 people. Germany, Italy and Japan sign a treaty promising to remain allies in the war against England and France\n- October 1940: Italy, with Germany’s help, invades Greece\n- March 1941: The United States begins lending England supplies, ammunition and other aid. President Roosevelt still refuses to send troops to aid in the war.\n- June 1941: Germany invades the Soviet Union. The United States freezes all German and Italian assets in United States banks.\n- September 1941: Germany begins the Siege of Leningrad. German troops cut off all supplies to the city for more than 2 years. During the siege, more than 500,000 people starve to death.\n- October 1941: Germany sinks a United States warship in the Northern Atlantic.\n- November 1941: The United States tells Japan to get out of China.\n- December 7, 1941: Japan attacks the United States when they bomb Pearl Harbor in Hawaii. Japan also attacked the United States territories of Guam and Wake Island.\n- December 8, 1941: The United States and Britain declare war on Japan.\n- December 11, 1941: Germany declares war on the United States.\n- January 1942: Germany begins patrolling the east coast of the United States with U-Boats. The first United States troops arrive in Britain. Japan takes the Philippines and Manila. In Germany, the government begins the “Final Solution” of the Jews.\n- April 1942: Japanese soldiers force 76,000 prisoners to march to distant camps on the Bataan peninsula. Many soldiers die on the “Bataan Death March.” On the west coast of the United States, the military forces Japanese-Americans into Internment camps.\n- May 1942: United States warships stop Japanese warships that are heading for New Guinea.\n- June 1942: United States forces stop the Japanese fleet during the Battle of Midway. This was the turning point of the war in the Pacific. In Germany, The government begins gassing Jews in the concentration camps.\n- July 1942: In Poland, German forces deport all Jews from Warsaw to concentration camps.\n- August 1942: United States forces defeat Japanese forces in Guadalcanal.\n- September 1942: Japanese plane bombs forests in Oregon. This is the first bombing in the continental United States.\n- October 1942: The British Eighth Army defeats Germany in North Africa.\n- January 1943: The Australian Navy beats back Japanese forces, protecting Australia from Japanese invasion. The United States begins bombing Germany.\n- February 1943: Germany troops surrender in Stalingrad.\n- April 1943: United States forces break Japanese codes and learn about the movement of Japanese generals and officials. This gives the United States an advantage.\n- June 1943: A Japanese ship rams a PT boat. The future president John F. Kennedy survives the attack. In Europe, United States and British pilots begin round-the-clock bombing in Germany.\n- July 1943: United States and British troops land in Italy.\n- September 1943: Italy surrenders to the Allies. Germany invades Italy and forces United States and British troops back, rescuing Mussolini.\n- October 1943: Allied troops invade Naples, re-taking Italy. Italy declares war on Germany.\n- January 1944: Leningrad saved from siege.\n- June 6, 1944: D-Day United States and British troops land on the beaches of Normandy. This begins the liberation of Europe.\n- September 1944: The Japanese shoot down the plane of future president George Bush over Okinawa. Bush parachutes to safety.\n- December 1944: German forces attack Allied forces in the forest of Ardennes. It is called The Battle of the Bulge because it forces the Allied Army to bulge in their weakest point.\n- January 1945: Allied forces defeat the Germans in the Battle of the Bulge.\n- April 1945: Italian freedom fighters capture and kill Mussolini. Soviet Troops enter Berlin. Hitler dies. United States troops free the prisoners of the Dachau concentration camp.\n- May 7, 1945: Germany surrenders.\n- August 6, 1945: The United States drops the first atomic bomb on Hiroshima, Japan.\n- August 9, 1945: The United States drops the second atomic bomb on Nagasaki, Japan.\n- August 14, 1945: Japan surrenders, ending World War II.', 'After experiencing “Hell”, we made our way to Nagasaki Atomic Bomb Museum and Nagasaki Peace Park. They are a short walk away from each other.\nNagasaki Atomic Bomb Museum\nThe Nagasaki Atomic Bomb Museum was opened in April 1996 as part of the 50th-anniversary projects for the Nagasaki atomic bombing. The Museum exhibits relics, as well as photographs, taken immediately after the bomb that depicts the devastation caused by the atomic bomb, leading up to the tragic day. The Museum also has Peace Study Rooms for listening to survivors’ talks and video rooms.\nIn 1949, the Japanese government enacted the “Nagasaki International Culture City Construction Law” to help the city recover from the atomic bombing. Nagasaki assumed a new role as a symbol of peace and culture – “Peace Begins in Nagasaki”.\nThe atomic bomb that exploded over Nagasaki at 11.02 a.m. on 9 August 1945 instantaneously reduced the city to ruins and took with it many precious lives. This wall clock (refer to below picture) was used in a house in Motofuna-machi about 2.8 kilometres south of the hypocentre. It was damaged by the blast and stopped at 11.02, the moment of the explosion. This clock is a donation by Ryoho Fumotoi.\nThe atomic bomb (refer to picture below – life-size model) dropped on Nagasaki was given the nickname “Fat Man” because of its shape. At a length of 3.25 metre, 1.52 metre in diameter and weighing 4.5 tons with an energy explosive force equivalent to 21 kilotons of TNT. The energy released from the explosion is presumed to have consisted of the blast (approximately 50% of the total energy), heat rays (approximately 35% of the total energy), and radiation (approximately 15% of the total energy).\nBefore the atomic explosion on 9 August 1945, the population of Nagasaki City was approximately 240,000. The atomic bomb caused 73,884 people to lose their lives and 74,909 people injured. Many atomic bomb survivors suffered from physical and psychological damage.\nAt the Museum, I had mixed emotions. I felt sad for the people at Nagasaki yet relieved that Japan decided to surrender after this incident.\nAtomic Bomb Hypocentre\nFrom the Atomic Bomb Museum, we made our way to the Atomic Bomb Hypocentre – ground zero – the place where an atomic bomb exploded approximately 500 metres above at 11.02 am on the 9th of August 1945. It was the second atomic bomb used in the history of mankind after the bombing of Hiroshima on 6th August 1945.\nThe Hypo Centre area is a place to pray for the repose of the atomic bomb victims, to inform the world about the horror of the atomic bombing and to appeal for the abolition of nuclear weapons and for the realisation of lasting world peace.\nFrom ground zero, we made our way to The Peace Park and reached the Peace Fountain, a place to pray for those victims who passed away whilst begging for water. The ever-changing shape of the water evokes the beating wings of the dove of peace and the crane. The crane is representative of Nagasaki Port, which is known as the ‘Crane Port’, because of its shape.\nThe Peace Statue\nWe continued our way to look for The Peace Statue created by Selbo Kitamura. The statue was erected by the citizens of Nagasaki in August 1955, on the 10th anniversary of the devastation of this city by the atomic bomb. The ten-metre bronze statue was dedicated as an appeal for lasting world peace and as a prayer that such a tragedy would never be repeated.\nThe elevated right-hand points to the threat of nuclear weapons, while the outstretched left hand symbolises tranquillity and world peace. Divine omnipotence and love are embodied in the sturdy physique and gentle countenance of the statue, and a prayer for the repose of the souls of all war victims is expressed in the closed eyes. The folded right leg symbolises quiet meditation, while the left leg is poised for action in assisting humanity.\nAtomic Bombing 50th Anniversary Commemorative Monument\nThis monument created by Nagasaki-born sculptor, Naoki Tominaga, expresses the horror of the atomic bombing, prays for the repose of the souls of the victims, through the form of a stricken child sleeping in her mother’s warm embrace. The child is like Japan on the day of the atomic bombing, while the mother represents the support provided by the countries of the world in Japan’s efforts to build the peace nation that it has become today.\nAfter walking around for a bit, we bought some snacks and drinks and ate at the Peace Park while we decide where to go next. We check out the Google map and found out that we are a short drive to Mount Inasa. Traffic was getting heavy as it was almost six in the evening.\nMount Inasa (Inasayama)\nMount Inasa is a 333-metre high mountain in close distance to Nagasaki’s city centre offering a great view over the city. The night view from Mount Inasa is ranked among Japan’s three best night views besides the views from Mount Hakodate and Mount Rokko. Mount Inasa is reachable by bus, car and ropeway. We drove up and parked our rental car at the open carpark located at midway, then took a free shuttle bus to the summit.\nThere is a daily light display from sunset until ten at the Mount Inasa Summit Radio Tower with music playing in the background. The changing colour of the light display went beautifully with the music in the background.\nFrom the summit of Mount Inasa, we looked down onto the Nagasaki Port, the Peace Park area to Megami Bridge.\nThe view was great and a nice way to end our evening and our visit to Nagasaki.\nStay tuned for my next update on our experience at Kagoshima.\nThis trip was made in October 2017.\nNagasaki Atomic Bomb Museum\nAddress: 7-8 Hirano-machi Nagasaki City 852-8117 Japan\nTelephone: 95 814 0055\nAdmission Fee: 200 Yen for Adults and 100 Yen for Students\nOpening Hours: 8:30 to 17:30 (last admission at 17:00) Closed from 29 to 31 December\nFor more information, go to nagasakipeace.jp.\nAddress: 407-6 Fuchimachi, Nagasaki, Nagasaki Prefecture 852-8012, Japan\nTelephone: 95 861 7742\nAdmission Fee: Free Admission\nOpening Hours: 9:00 to 22:00 Daily\nThank you for stopping by, Happy Living for Experiences!']	['<urn:uuid:4c1a39fe-9a73-4981-8986-c4b85b523b1d>', '<urn:uuid:c0403a69-639c-4797-933e-804cc988b7c9>']	open-ended	with-premise	short-search-query	similar-to-document	comparison	novice	2025-05-13T05:52:58.810667	7	104	2168
37	how many elderly people get fragile	Frailty, which is defined as a recognizable state of increased vulnerability resulting from a decline in function across multiple physiological systems, affects 10-15% of older adults.	['New Study Finds a Mediterranean-Style Diet May Reduce Likelihood of Frailty\nFrailty occurs in 10-15% of the population but a new study, published in The American Journal of Clinical Nutrition, found that consuming a Mediterranean-style diet may prevent frailty. Changing their diet can help people prevent frailty.\nBOSTON – A new study published in The American Journal of Clinical Nutrition found that consuming a Mediterranean-style diet may prevent frailty. Defined as a recognizable state of increased vulnerability resulting from a decline in function across multiple physiological systems, frailty affects 10-15% older adults, and leads to other health issues. Although the general benefits of a Mediterranean-style diet are well known, its role in the reduction of frailty in older Americans who do not normally consume such a diet was unclear.\nThe study titled, “Adherence to the Mediterranean-style diet and high intake of total carotenoids reduces the odds of frailty over 11 years in older adults: Results from the Framingham Offspring Study,” showed that consuming a Mediterranean-style diet, may prevent the development of frailty with aging. The study included 2,384 non-frail adults from the Framingham Offspring Study with Mediterranean-style dietary pattern score and antioxidant intakes [vitamin C, E, and total carotenoids] estimated from a food frequency questionnaire combined with frailty assessments that were conducted over ~11 years. Each unit higher score on the Mediterranean Style Dietary Pattern Score (i.e., higher adherence to a Mediterranean-style diet) reduced the odds of frailty by 3%.\nThe study also determined whether specific antioxidants (carotenoids, vitamins E, and C) found in a Mediterranean-style diet are related with frailty. Higher intake of carotenoids (an antioxidant commonly found in brightly colored fruits and vegetables) had the strongest association with reduced likelihood of frailty development in middle-aged and older men and women from the Framingham Heart Study, reporting that each 10-mg higher total carotenoid intake reduced the odds of frailty by 16%. Vitamin E and C were not meaningfully associated with frailty prevention.\nCourtney L. Millar, Ph.D., Post-Doctoral Fellow, Marcus Institute of Aging Research, Hebrew SeniorLife, and Harvard Medical School, is the lead author. “People may be able to prevent frailty by following the principles of the Mediterranean-style diet,” Dr. Millar said.\nThe Mediterranean-style diet encourages consumptions of fruits and vegetables.\n“Increasing the intake of brightly colored fruits and vegetables that are rich in carotenoids as well as other bioactive compounds may ultimately affect the health of older adults,” said Dr. Shivani Sahni, the senior author.\nThe Framingham Heart Study, Boston University, and Tufts University collaborated on this observational study. This study was funded by the National Institute on Aging’s support of the Boston Claude D. Pepper Center OAIC and the Peter and Barbara Sidel Fund.\nOther authors included Elise Costa, The University of North Carolina at Chapel Hill School of Medicine; Paul F Jacques, D.Sc., Senior Scientist, Nutritional Epidemiology Team and Professor, Gerald J. and Dorothy R. Friedman School of Nutrition Science and Policy at Tufts University; Alyssa B. Dufour, Ph.D., Assistant Scientist II at the Hinda and Arthur Marcus Institute for Aging Research, Harvard Medical School; Douglas P. Kiel, M.D., M.P.H., Director, Musculoskeletal Research Center and Senior Scientist, Hinda and Arthur Marcus Institute for Aging Research, Harvard Medical School; Marian T. Hannan, D.Sc., M.P.H., Co-Director, Musculoskeletal Research Center and Senior Scientist, Hinda and Arthur Marcus Institute for Aging Research, Harvard Medical School; and Shivani Sahni, Ph.D., Director, Nutrition Program and Associate Scientist, Hinda and Arthur Marcus Institute for Aging Research, Harvard Medical School.\nAbout Hebrew SeniorLife\nHebrew SeniorLife, an affiliate of Harvard Medical School, is a national senior services leader uniquely dedicated to rethinking, researching, and redefining the possibilities of aging. Hebrew SeniorLife cares for more than 3,000 seniors a day across six campuses throughout Greater Boston. Locations include: Hebrew Rehabilitation Center-Boston and Hebrew Rehabilitation Center-NewBridge in Dedham; NewBridge on the Charles, Dedham; Orchard Cove, Canton; Simon C. Fireman Community, Randolph; Center Communities of Brookline, Brookline; and Jack Satter House, Revere. Founded in 1903, Hebrew SeniorLife also conducts influential research into aging at the Hinda and Arthur Marcus Institute for Aging Research, which has a portfolio of more than $63 million, making it the largest gerontological research facility in the U.S. in a clinical setting. It also trains more than 1,000 geriatric care providers each year. For more information about Hebrew SeniorLife, visit our website or follow us on our blog, Facebook, Instagram, Twitter, and LinkedIn.\nAbout the Hinda and Arthur Marcus Institute for Aging Research\nScientists at the Marcus Institute seek to transform the human experience of aging by conducting research that will ensure a life of health, dignity, and productivity into advanced age. The Marcus Institute carries out rigorous studies that discover the mechanisms of age-related disease and disability; lead to the prevention, treatment, and cure of disease; advance the standard of care for older people; and inform public decision-making.']	['<urn:uuid:463b7370-5281-4970-ad4c-e67ab6bb764e>']	open-ended	direct	short-search-query	distant-from-document	single-doc	novice	2025-05-13T05:52:58.810667	6	26	804
38	equipment maintenance compliance requirements stability testing	Equipment maintenance and stability testing have specific compliance requirements. For maintenance, adequately qualified staff must regularly maintain equipment, document all checks, and perform calibration according to national/international standards. Maintenance checks must follow standard operating procedures or manufacturer instructions. For stability testing, organizations must implement proper testing programs, conduct tests at specific intervals (initial, 3,6,9,12,18,24,36 months), maintain appropriate storage conditions (24-25°C), and use stability-indicating methods. The testing must be done with the product in its final packaging, and any out-of-trend results must be investigated.	['In this article, we aim to provide an accessible summary of existing advice on equipment sourcing for clinical trials. We also offer some of MESM’s own expertise based on our years of experience supporting study managers and vendor managers on all aspects of managing equipment for clinical trials.\nThe International Council for Harmonisation of Technical Requirements for Pharmaceuticals for Human Use (ICH)\nThe ICH has published guidelines on designing, conducting and reporting clinical research trials involving people.\nThey recommend that the guidelines are followed when clinical trial data will be submitted for consideration by regulatory authorities. Clinical trial monitors must verify that the investigator has suitable qualifications and resources to run a trial. Any equipment and facilities must be adequate so that the trial can be properly and safely conducted, and they must remain adequate for the duration of the trial (2). Trial investigators must provide documents (e.g. certificates, accreditation documents) for medical, laboratory or technical procedures and tests so that the trial facility can show that it is competent to perform any necessary tests.\nMedical Research Council\nThe Medical Research Council has also published guidelines highlighting the importance of adequately maintaining equipment. They recommend that there should be procedures for ensuring there is training and support for staff who are using, servicing and calibrating the equipment (3). In cases such as this, working with an equipment partner can help to streamline processes. For example, among its other services, MESM can provide products pre-calibrated and will provide training for staff on using the equipment supplied.\nEuropean Medicines Agency\nThe European Medicines Agency have published guidelines for laboratories analysing samples for clinical trials. Any equipment that will be used to analyse samples obtained during clinical trials must be fit for this purpose. Adequately qualified staff should maintain the equipment regularly and any maintenance checks they perform must be documented. Any calibration, inspection or maintenance of equipment should be in line with the standard operating procedures or the manufacturer’s instructions and the results of these inspections or activities must be recorded. Calibration should be performed following national or international standards (4).\nIn addition to the previous points, ensure cold storage used to house biological samples must be fit for purpose. MESM regularly supports customers in ensuring cold storage meets the requirements of the trial protocol – this is particularly important in the case of very low temperature freezers, where it’s essential for the integrity of the trial that samples are constantly stored at the right temperature.\nWhen running phase 1 clinical trials, the type of equipment and facilities needed will depend on the type of trial the investigator is conducting for the sponsors. The Association of the British Pharmaceutical Industry (ABPI) guidelines for phase 1 trials state that it may only be necessary to have basic facilities for storing and dispensing an investigational medicinal product (IMP) providing that’s it’s already packaged and labelled. If the investigator is acting as the sponsor for the trial they will need to ensure they have any necessary equipment and facilities (5).\nWhen the trial is underway, each clinical area must have a resuscitation trolley containing equipment and medicines for use in a medical emergency. The trolleys must be checked at least once a week and every time they are used. All checks should be documented (5).\nThe type of equipment that’s needed for a clinical trial should be documented in the trial protocol. This is another area where a dedicated equipment partner can support – for example by consulting on which equipment and ancillaries to include in the protocol, to ensure the best possible results for the study. The Standard Protocol Items: Recommendations for Interventional Trials (SPIRIT) guidelines recommend that trial protocols should set out any sources of financial and non-financial support. The protocol should outline the specific types of support, which includes any equipment, and the length of time that the support will be given for (6).\nAdvances in technology often happen very quickly so it’s important to ensure that there will be enough budget to cover the cost of any upgrades in equipment that may be necessary during the trial. It’s important to review any equipment that will be needed to ensure that it complies with Portable Appliance Testing (PAT), so it will be necessary to allow enough time for testing to be performed at the coordinating centre or trial site (7).\nFrom an equipment procurement standpoint, MESM strongly recommends planning for equipment costs with a view over the full duration of a study; rather than choosing equipment suppliers based on per/unit costs alone. It’s important to take any additional equipment related costs into account – beyond individual unit price – such as maintenance, technical support and end of study services (e.g. equipment removal and disposal). Consider working with a supplier whose costs include those additional services, as this has the potential to deliver cost savings over the course of a trial, as well as driving efficiencies by reducing the potential for delays caused by faulty equipment or other equipment related issues.\nThe key factors to remember when sourcing equipment for a clinical trial are:\nEnsure you understand the guidance\nConsult all available guidance relating to the type of trial you are conducting, to minimise delays and ensure you are tracking all required equipment information that you may need to provide at the end of a study.\nMake sure the equipment is correct\nInterrogate the clinical trial protocol to ensure the equipment sourced is fit for purpose – this may require seeking further information from the protocol authors, but will save time and additional costs in the long run.\nPlan for your needs over the full duration of a study\nDon’t just look at individual unit costs for equipment, but consider the long-term value of the service you receive relating to equipment – including whether it provides for maintenance, technical support, calibration services, equipment removal, end of study reporting and so on.\n- Farrell B, Kenyon S, Shakur H. Managing clinical trials. Trials. 2010; 11:78. doi:10.1186/1745-6215-11-78.\n- International Council on Harmonisation of Technical Requirements for Registration of Pharmaceuticals for Human Use. ICH harmonised tripartite guideline. Guideline for good clinical practice. E6(R2). Current Step 4 version. November 2016. Available at: http://www.ich.org/fileadmin/Public_Web_Site/ICH_Products/Guidelines/Efficacy/E6/E6_R2__Step_4.pdf Date accessed: June 2017\n- Medical Research Council. MRC ethics series. Good research practice: principles and guidelines. https://www.mrc.ac.uk/publications/browse/good-research-practice-principles-and-guidelines/ Date accessed: July 2017.\n- European Medicines Agency. Reflection Paper for laboratories that perform the analysis or evaluation of clinical trial samples. 2012. Available at: http://www.ema.europa.eu/docs/en_GB/document_library/Regulatory_and_procedural_guideline/2012/05/WC500127124.pdf Date accessed July 2017\n- Association of the British Pharmaceutical Industry. Guidelines for phase 1 clinical trials. 2012 edition. Available at: http://www.abpi.org.uk/our-work/library/guidelines/Documents/guidelines_phase1_clinical_trials.pdf Date accessed: July 2017\n- Standard Protocol Items: Recommendations for Interventional Trials (SPIRIT). Funding http://www.spirit-statement.org/funding/ Date accessed: July 2017\n- UK Trial Manager’s Network. The Guide to efficient trial management. Effectively managing clinical trials. Fifth edition. 2016. Available at: http://c.ymcdn.com/sites/www.tmn.ac.uk/resource/resmgr/TMN_Guide/UKTMN_Guide_for_Web_V5_May_2.pdf Date accessed: July 2017', 'As device organizations continue to evolve in the integration of combination products CGMP’s into their business, a holistic approach can prevent many unnecessary delays. This article provides some insights to consider when integrating stability testing into your device Quality System Requirements (QSR) system. It will discuss a number of quality systems that Stability may significantly impact. Part of the holistic approach should be a discussion that looks out to five years from today and defines where does the organization wants to be with regards to the management, development, manufacturing and compliance of their combination products business. The following six combination product requirements should have good quantitative measures for this five-year plan.\n- Packaging/Labeling codes and the expected order fill rate. If you have five codes that are expected to be delivered to customers on a monthly basis, the delivery challenge will be different than coordinating the manufacture of a 100 codes that will be delivered weekly. The impact of drug release testing and approvals can significantly impact your delivery objectives. Drug testing failure investigations may take longer than expected.\n- Safety & Efficacy\n- The drug and combination product complaint and serious complaint (SAE/MDR) profile should be understood. This information should be incorporated into the risk management models.\n- This must be addressed for every lot. Make sure the drug definitions of lot and batch are well understood, this may affect the number of tests to be conducted and the infrastructure required.\n- How the device affects the strength of the drug may require special analytical methods. These analytical methods should meet ICH Q2 Analytical Methods.\n- Identifying all the impurities and degradants for both device and drug will be important. Also any process that can affect the impurities and/or degradants needs to be well understood and a control strategy implemented.\n- Once the drug and the device are combined the combination product quality characteristics must be defined. There can be effects due to storage, environment, contact time between the device and the drug and use.. A useful exercise is to match the critical-to-quality (CQA) characteristics with relevant product complaints. A control strategy that addresses the CQA’s of both product and process characteristics could be a good source of preventative measures.\nIt is important to identify key functions affected by these requirements (i.e. Stability) and assess the functions ability to meet them consistently. Part of the strategy should ensure that these functions have the ability to consistently meet the combination product requirements.\nFigure 1 is a framework that can be used to help organizations do the following:\n- Think about the affected functions, systems and infrastructures needed to manufacture the combination product\n- Develop a plan to prioritize what will be done and when\n- Include in the plan criteria for sustainable solutions to be implemented and monitored\nIntegrating a new set of CGMP’s (21CFR 820) into an organization that is already operating to a well-established set of QSR’s (21 CFR 820) can be disruptive. Often some basic planning and analysis can make a significant difference in the implementation effectiveness. Before beginning to evaluate the organization’s ability to integrate these new combination product 211 CGMPs into your quality system determine the foundation that would be necessary for each CGMP (21 CFR Part 4) you plan to implement. Once you decide what are the systems, personnel and infrastructure needed, then ensure your organizations relevant core competencies can address these needs. Also assess the maturity and consistency of their performance or at what stage of experience they are operating.\nExclusive VIDEO: How to Gather Clinical Evidence for Combination Products | WATCH NOWA good understanding of how the CGMP’s defined in 21 CFR Part 4 can impact the values of the organization can help you proactively address personnel concerns. Device manufacturers have a good understanding of the safety and efficacy of their products; however, these new CGMP’s may lead you to ask questions you did not previously consider (i.e., questions about the control of degradants, stability indicating methods, reserve samples, control of pyrogen). Employees may see these new requirements as a threat to the effective execution of their functional responsibilities. You may find that maintaining your compliance performance is impacted and some support is needed to get compliance to the level at which you are accustomed to operating.\nThe expectation is that these new CGMP’s will long term impact profits; temporarily there may be an impact. This should be defined and discussed early in the process.\nIn particular you may need to change or add facilities and/or new equipment. As you begin to pull together all of these CP CGMP insights that may impact your values, foundation and functions together, you must be specific what is expected of each function. An important aspect of your plan will be to make sure key stakeholders in impacted functions are on board with the approach. Make sure they agree with the need, the plan, what is acceptable and when this level of performance will be in place.\nMany device organizations have chosen the Streamline approach for their compliance with the combination products CGMPs. Specifically, the streamlined approach provides that a device organization manufacturing combination products may meet the requirements of both the drug CGMPs and device QS regulation by designing and implementing a CGMP operating system that is demonstrated to comply with the following:\n(i) 21 CFR 211.84. Testing and approval or rejection of components, drug product containers, and closures\n(ii) 21 CFR 211.103. Calculation of yield\n(iii) 21 CFR 211.132. Tamper-evident packaging requirements for over-the- counter (OTC) human drug products\n(iv) 21 CFR 211.137. Expiration dating\n(v) 21 CFR 211.165. Testing and release for distribution\n(vi) 21 CFR 211.166. Stability testing\n(vii) 21 CFR 211.167. Special testing requirements\n(viii) 21 CFR 211.170. Reserve samples\nA requirement for 211.137 Expiration dating is to have it determined by appropriate stability testing. For single-entity combination products, you will need to define the applicable standard of drug identity, strength, quality and purity. Most device organizations are well prepared for the quality and identity requirements; however, strength and purity can be difficult. How you measure the strength of the drug when it is physically or chemically combined with a device and how you define the specification can be challenging. Another area that has presented some degree of difficulty is purity, particularly understanding the degradant products of the drug and how the processing affects the degradants of the combination product.\nA helpful FDA technical guidance the device community should understand is “INSPECTIONAL TECHNICAL GUIDANCE; Expiration Dating and Stability Testing for Human Drug Products, 10/18/85 Number: 41. The agency provides guidance on key areas of Expiration Dating and Stability Testing. Some of the areas they cover are:\n- Absence of an Expiration Date will result in regulatory action\n- OTC Drug Exemptions\n- Products Intended for Reconstitution ED and Stability requirements.\n- Impact of no Written Stability Testing Program\n- Supportive Stability Data\n- Number and Size of Batches\n- Three Batch rule and changes\n- Number and Size of Batches\n- Accelerated Studies\n- Appropriate use of accelerated studies are discussed and certain uses of accelerated studies that are discouraged\n- Test Intervals\n- Normal interval – Initial, 3,6,9,12,18,24,36\n- Annual Testing\n- Storage Conditions\n- Room Temp defined as 24-250 C. Products liable to degradation by light or moisture, testing at these conditions needs to be evaluated and addressed.\n- Test Methods\n- Although 211,194 is not called out, review its applicability and confirm your record system meets this requirement, particularly Section 211.194 (a) (2) verification under actual conditions of use.. Also will need to have in place stability indicating methods. This will require a good understanding of the degradants in your combination product.\n- Container-Closure Systems\n- When changing the package or unit the drug is stored in, ways to do satisfactory comparison of container-closure systems\n- Container Sizes to be Tested\n- For more guidance also see ICH Q1D Bracketing and Matrixing Designs for Stability Testing of New Drug Substances and Products Preservatives\n- Guidance for products formulated to contain preservatives to inhibit microbial growth\n- Bulk Drug Substances (Bulk Pharmaceutical Chemicals)\n- Guidance for stability testing program for bulk drug substances\n- Sterility Testing\n- Guidance on container-closure system that has demonstrated ability to maintain sterility throughout the expiration dating period and revalidation when other ingredients are added\nTo help you design a stability program you should consult experts on how to incorporate the applicable sections of the ICH Quality guidances into your program:\n- Start with a commitment to gain a working knowledge of all applicable USP General Notices, Monographs & Chapters.\n- At a minimum, perform a thorough review of the following ICH guidances and identify what sections need to be addressed in your stability, expiry dating and reserve sample practices. Sections that do apply but have not been addressed should be discussed with experts in this area:\n- Q1A – Q1F Stability\n- Q2 Analytical Validation\n- Q3A – Q3D Impurities\n- Q4 – Q4B Pharmacopoeias\n- Q6A- Q6B Specifications\n- As you incorporate these guidances into your organization, an in-depth review of your laboratory practices and the labs’ ability to meet the requirements of 211.194 would also be helpful, particularly if your labs are testing drug products.\n- Review FDA’s “Investigating Out-of-Specification (OOS) Test Results for Pharmaceutical Production” Guidance and confirm your laboratory nonconformance practices would be able to meet the practices identified in this guidance.\n- Pay attention to how you manage stability trends, and evaluate historical data for the batch on stability as well as the overall product. When you find an out-of-trend indication, an investigation must take place.\n- If your combination product requires an NDA/ANDA, and you choose to keep your QSR system as the base Quality System, one of the many CGMP systems you will need to understand is the requirements of Annual Product Review.\n- Note for stability testing that the product must be in its final packaging. If this is not the case the FDA should be consulted. There are instances in which the agency has accepted other practices.\n- Have a good rationale for which product codes are included in the annual stability testing, which is particularly important when there are a large number of product codes.']	['<urn:uuid:42b9a16e-bdd5-49cb-b1fc-f7607cb45bf8>', '<urn:uuid:dd0bfe14-1b8c-45cd-942d-0304e5e0561f>']	open-ended	direct	short-search-query	similar-to-document	multi-aspect	novice	2025-05-13T05:52:58.810667	6	83	2858
39	glucose oxidase enzyme origin compare beta glucosidase source trichoderma	Glucose oxidase originates from the pharyngeal glands of bees, while beta-glucosidase is produced by the fungus Trichoderma harzianum found in the Amazon.	"['One of the main challenges of second-generation biofuel production is identifying enzymes produced by microorganisms for use in a ""cocktail"" of enzymes to catalyze biomass hydrolysis, in which the enzymes act together to break down the carbohydrates in sugarcane trash and bagasse, for example, and convert them into simple sugars for fermentation.\nA group of researchers at the University of Campinas (UNICAMP), working in partnership with colleagues at the Brazilian Biorenewables National Laboratory (LNBR) in Campinas, São Paulo State, Brazil, have discovered that Trichoderma harzianum, a fungus found in the Amazon, produces an enzyme with the potential to play a key role in enzyme cocktails.\nThe enzyme, which is called β-glucosidase and belongs to glycoside hydrolase family 1 (GH1), acts in the last stage of biomass degradation to produce free glucose for fermentation and conversion into ethanol. In the laboratory, however, the researchers observed that high levels of glucose inhibited the activity of β-glucosidase.\n""We also found that the enzyme\'s optimal catalytic activity occurred at 40 °C. This represented another obstacle to use of the enzyme because in an industrial setting, the enzymatic hydrolysis of biomass is performed at higher temperatures, typically around 50 °C,"" said Clelton Aparecido dos Santos, a postdoctoral researcher at UNICAMP\'s Center for Molecular Biology and Genetic Engineering (CBMEG) with a scholarship from FAPESP.\nBased on an analysis of the enzyme\'s structure combined with genomics and molecular biology techniques, the researchers were able to modify the structure to solve these problems and considerably enhance its biomass degradation efficiency.\n""The modified protein we developed proved far more efficient than the unmodified enzyme and can be used to supplement the enzyme cocktails sold today to break down biomass and produce second-generation biofuels,"" Santos told.\nTo arrive at the modified protein, the researchers initially compared the crystal structure of the original molecule with structures of other wild-type β-glucosidases in the GH1 and GH3 glycoside hydrolase families. The results of the analysis showed that glucose-tolerant GH1 glucosidases had a deeper and narrower substrate channel than other β-glucosidases and that this channel restricted glucose access to the enzyme\'s active site.\nLess glucose-tolerant β-glucosidases had a shallower but wider active site entrance channel, allowing more of the glucose produced by these enzymes to enter the last stage of biomass degradation. Retained glucose blocks the protein\'s channel and reduces its catalytic activity.\nBased on this observation, the researchers used a molecular biology technique known as site-directed mutagenesis to replace two amino acids that might be acting as ""gatekeepers"" at the entrance to the enzyme\'s active site, letting in glucose or blocking it. Analysis of their experiments showed that the modification narrowed the channel to the active site.\n""The mutant enzyme\'s active site shrank to a similar size to that of the glucose-tolerant GH1 β-glucosidases,"" Santos said.\nThe researchers conducted a number of experiments to measure the improved protein\'s performance in breaking down biomass, especially sugarcane bagasse, an agroindustrial waste with vast potential for profitable use in Brazil. During a research internship abroad with a scholarship from São Paulo Research Foundation - FAPESP, Santos worked with a research group led by Paul Dupree, a professor at the University of Cambridge in the UK, on an analysis of the tailored enzyme\'s glucose release efficiency when different sources of plant biomass were converted.\nThe analysis showed that the catalytic efficiency of the modified enzyme was 300% higher than that of the wild-type enzyme in terms of glucose release. Moreover, it was more glucose-tolerant, so more glucose was released from all the tested plant biomass feedstocks. The mutation also enhanced the enzyme\'s thermal stability during fermentation.\n""Mutation of the two amino acids at the active site made the enzyme superefficient. It\'s ready for industrial application,"" said Anete Pereira de Souza, a professor at UNICAMP and principal investigator for the project. ""One of the enzyme\'s advantages is that it\'s produced in vitro and not from a modified fungus or other organism, so it can be mass-produced at relatively low cost.""\nAbout São Paulo Research Foundation (FAPESP)\nThe São Paulo Research Foundation (FAPESP) is a public institution with the mission of supporting scientific research in all fields of knowledge by awarding scholarships, fellowships and grants to investigators linked with higher education and research institutions in the State of São Paulo, Brazil. FAPESP is aware that the very best research can only be done by working with the best researchers internationally. Therefore, it has established partnerships with funding agencies, higher education, private companies, and research organizations in other countries known for the quality of their research and has been encouraging scientists funded by its grants to further develop their international collaboration. You can learn more about FAPESP at http://www.', 'I am often asked whether my honey has been heated. The people who ask this want me to tell them that the honey is never heated. Often they ask the question because they are concerned about the enzymes and because they think that heat will destroy the enzymes in honey. They are partly right but enzymes and honey are more robust than people may realise.\nWhat is an enzyme?\nEnzymes are large, complex, biochemically active molecules of protein – they could be described as ‘smart’. The names of enzymes always end in an ‘ase’ while the front part of the name gives some indication of action they carry out. Invertase, for example, splits sucrose molecules then inverts the free D-fructose into L-fructose.\nWhat is the nature of enzyme activity\nEnzymes are very specific in their activities because they each have specially shaped ‘active sites’ which lock on to certain target molecules and manipulate them in a particular way, or ways, so as to pull them apart. All this takes place spontaneously and is brought about by the changing attractions between constituent molecules in the enzyme and in the target. The act of locking onto the target brings about changes in the enzyme which in turn break or alter the target in some way.\nWhat affects enzyme activity\nThe rate and/or efficacy of enzyme activity can be affected by chemicals or by temperature or pH or by concentrations of target and/or resultant molecules all of which may change the shape of the active site. Also enzymes each have an optimum temperature at which they perform most effectively and above, or below, which the activity is impaired or reduced.\nWhat happens when heat is applied?\nWhat happens when heat is applied, is the enzyme starts to unravel. If the temperature continues to rise, the shape of the active site is changed or ‘denatured’ and at this point the enzyme is deactivated. However, the deactivation of enzymes by heating is not necessarily permanent and once the temperature falls, the enzyme may return to its original shape and function as normal.\nOnly if the temperature substantially exceeds the denaturation point and is maintained for some time will the enzyme unravel to such an extent it cannot pull itself together again. At this point the enzyme can be said to be permanently denatured and it will cease to function as a biochemical entity. The temperature tolerance of enzymes is variable.\nHoney Enzymes and Temperature Tolerance\nEnzymes in honey are of both bee and plant origin and include:\n- Invertase which splits the sucrose found in nectars into D-glucose and D-fructose – also known as dextrose and levulose – sugars found in honey. Invertase is added to honey by the bees and its activity is thought to enhance the storage properties of honey by increasing the degree of possible sugar concentration. Invertase is relatively stable to 50 degrees C but the stability varies with the botanical origins of the honey.\n- Amylase (alpha and beta) – alpha amylase splits a starch chain randomly into sugars but beta amylase breaks maltose from the ends. Amylases are thought to originate from pollen – its purpose, if any in honey is unknown. Stable to 50 degrees C but degrades gradually over a period of days at this temperature.\n- Diastase is a name that is applied to both amylases when its presence in honey is to be assayed as a measure of the amount of heat a honey has been subjected to. It degrades naturally over time but degradation is accelerated at temperatures above 50 degrees C for 5 days. Diastase also deteriorates with storage;\n- Glucose oxidase originates in the pharyngeal glands of bees and oxidises glucose to gluconic acid, a by-product of this is hydrogen peroxide which has antibiotic properties. Before this discovery, the observed antibiotic effect was at one time attributed to the action of something named inhibine. Glucose oxidase is stable to 55 degrees C;\n- Catalase and phosphatase are also present in honey.\nIf you are going to eat the honey, the acids in your stomach will denature all the enzymes within seconds.\nCopyright © Beespoke.info, 2014. All Rights Reserved.\nBabacan, S. and Rand AG. Characterization of honey amylase. J Food Sci. 2007 Jan;72(1):C050-5.\nHooper,T. Guide to Bees and Honey. 1991 Blandford.\nKarabournioti,S.and Zervalaki,P. The Effect of Heating on Honey HMF and Invertase. Apiacta, 2001, 36 (4), 177 – 181\nKretavičius, J.; Kurtinaitienė, B.; Račys, J.; Čeksterytė, V. Inactivation of glucose oxidase during heat-treatment de-crystallization of honey. Žemdirbystė (Agriculture) 2010 Vol. 97 No. 4 pp. 115-122\nWhite.J.W. Composition of Honey. In Honey: A Comprehensive Survey. Ed. Eva Crane. Heinemann, London. 1975.']"	['<urn:uuid:1220036f-a123-4161-82e2-576c9c8e18b5>', '<urn:uuid:99075d13-6fe2-41e7-9ce6-b8fcdd2e0d75>']	factoid	direct	long-search-query	similar-to-document	comparison	expert	2025-05-13T05:52:58.810667	9	22	1556
40	user testing website accessibility wcag standards conformance levels requirements guidelines	Website accessibility testing combines both WCAG conformance and user testing with people with disabilities. For WCAG compliance, there are three levels: A (minimal) requiring basic features like text alternatives and keyboard navigation; AA (acceptable) requiring features like text resizing and consistent navigation; and AAA (optimal) requiring strict contrast ratios and timing controls. User testing should involve people with various disabilities (visual, hearing, cognitive, motor) using different assistive technologies, devices, and browsers to validate accessibility. Testing is recommended after remediating to WCAG 2.0/2.1 AA standards, with frequency depending on how often the website changes.	['User Testing Website Accessibility With People With Disabilities\nAn audit stating your website meets WCAG 2.1 AA standards is one thing.\nActual user testing and feedback from people with the disabilities WCAG attempts to account for is another.\nThe two compliment each other extremely well, especially when it comes to making a website accessible and reducing risk of an ADA website compliance (or state disability discrimination law) lawsuit.\nWith user testing, the objective is simple:\nGet valuable feedback from people with different disabilities so we can correct any issues and ensure as many people as possible have access to our website.\nIdeally, you’ll be able to get feedback from people who have different disabilities:\n- blind or visually impaired\n- deaf or hard of hearing\n- cognitive disabilities\n- reading disabilities\n- motor skills disabilities\nBut, even if you can’t get feedback from every group, feedback from people who are blind or visually impaired goes a long way in improving your website’s accessibility.\nPeople with vision impairments are the most impacted when it comes to website accessibility. This is evidenced by the guidelines within WCAG, the plaintiff’s listed disability in ADA Website Compliance lawsuits, and surveys taken by WebAIM, a leading provider in website accessibility.\nHow Testing is Conducted\nThere are many different approaches to how you test accessibility. Here are a few:\n- in person\n- form input\n- interview style\nRegardless of what approach you take, the primary objective is the same:\nObtain actionable data about the accessibility of your website and its primary visitor flows.\nActionable data constitutes detailed feedback pertaining to either or both the overall website and specific components.\nIf a website has undergone remediation prior to testing, there may not be changes to implement but positive feedback is still extremely useful in that:\n- You’ve demonstrated accessibility\n- You’ve shown genuine commitment and effort towards accessibility\n- You have independent documentation certifying 1 and 2\nTo extract the most value from user testing, you’ll want to get feedback from users across:\n- multiple assistive technologies (including the most popular screen readers — JAWS, NVDA, and VoiceOver)\n- different devices (desktop, tablet, phone)\n- different device manufactures (Apple, Android)\n- different browsers (Chrome, Firefox, Internet Explorer 11, Safari)\nUser testing doesn’t have to include every last screen reader, browser, and device but you will want to gather data from multiple angles as well as get documentation on exactly what has been used while testing your website.\nWhen and how often you test is up to you as the digital property owner.\nI recommend testing after remediating your website, app, etc. for WCAG 2.0 AA (or 2.1 AA) so that you’ve already addressed issues found in your initial audit.\nAnother benefit to this timing is it creates a second checkpoint rather than trying to account for all accessibility issues in a vacuum.\nAfter your website has been audited, remediated, and tested, the frequency at which you test is up to you.\nFor websites that are constantly changing and updating, you’ll want to test at higher intervals.\nFor large entities such as corporations, you’ll also want to test regularly (e.g., quarterly) as the concern and risk-reduction benefits will far outweigh the relatively low cost of user testing.\nFor other entities, a yearly review is a good default frequency. If your website is static, you can rely on your original testing so long as the going legal standard remains the same.\nRight now it’s best to conform with as much of WCAG 2.0 AA or 2.1 AA as possible. However, in 2021, the prevailing defacto standard will likely be WCAG 2.2 AA so at that point, you’d want to re-address accessibility.\nRobust user testing will include feedback from multiple vantage points.\nWe all experience and interact with the web differently so it’s best to have a team test your website vs. only one person.\nIf you attempt to procure user testing services ala carte in the market, the cost can be quite expensive (e.g. $500/hour and up). However, you can get a significant discount if you purchase a larger web accessibility package that includes user testing in the plan.\nMany reputable digital accessibility companies will include user testing as part of their service.', 'The Web Content Accessibility Guidelines (WCAG)\nWhat are the Web Content Accessibility Guidelines (WCAG)?\nThe guidelines offer technical recommendations on how to make website content accessible. The guidelines are also the standard reference for most website accessibility-related legislation like the Americans with Disability Act (ADA) in the US, and the European Web Accessibility Directive.\nWCAG Versions - 2.0, 2.1, 2.2 and 3.0\n- WCAG 2.0 - published 11 December 2008.\n- WCAG 2.1 - published on 5 June 2018 and is now the W3C recommended version\n- WCAG 2.2 - not yet in effect, scheduled to be published in 2021\n- WCAG 2.0 had 61 success criteria\n- WCAG 2.1 introduced 17 more success criteria to address mobile accessibility, people with low vision, and people with cognitive and learning disabilities.\n- WCAG 2.2 will be expanding on 2.1 with nine new success criteria, plus an update to one, with the goal of making content more accessible to a wider range of users.\nThe current standing WCAG versions 2.0 and 2.1 are categorized according to four principles, perceivable, operable, understandable, and robust (POUR).\nElements that convey information or components of a website’s user interface must be presented in a way that users are able to find, process, and understand.\nAll functionality and navigation on the website should be usable.\nInformation and the operation of the user interface must be clear and understandable to users of all abilities.\nThe website should be capable of adapting and developing itself to support a variety of current and potential future user agents, including assistive technologies.\nUnder each principle are testable success criteria that provide recommendations on how to make digital content more accessible. The success criteria are classified by three levels A, AA, and AAA, with A being the most basic level of WCAG compliance and AAA being the hardest.\nLearn more about the elements of WCAG and how to comply with its success criteria.\nOn the 21st of January, 2021, the WAI released the first working draft of the WCAG 3.0. WCAG 3.0 is planned to be a major revision with the intention to make the guidelines more user-friendly than the WCAG 2 iterations, and more flexible, covering even more content, apps, and tools, as well as organizations and disabilities. WCAG 3.0 is still in development and is not expected to be finalized for the next few years. Learn more about WCAG 3.0.\nThe different WCAG compliance levels\nThe WCAG categorizes its conformance based on three levels: A, AA, and AAA. To conform to the guidelines, it is a requirement that one of these levels should be fully met.\nMinimal WCAG compliance (level A)\nExamples of Level A success criteria:\n- All non-text content like images or videos must have a text alternative, like alt text or captions, that serves the equivalent purpose.\n- Users can navigate the website effectively using only a keyboard\n- Avoid using color as the only visual means of conveying information or prompting an action, like having green buttons with no text on them to suggest that it is meant to be selected as a ‘yes’ response.\n- If there is audio that auto-plays on your website for more than 3 seconds, ensure that that you provide means of adjusting the volume, stopping, or pausing it.\nAcceptable WCAG compliance (level AA)\nExamples of Level AA success criteria:\n- Ensuring that text on a webpage can be resized without assistive technology up to 200 % without loss of content or functionality.\n- Provide descriptive headings and labels in content\n- Navigational elements on the site, like menus, should be in a consistent, repeated position across the website.\n- When executing an action on the site, like filling in forms or clicking on buttons, errors can occur on the user’s part. If an error should occur, suggestions for correction should be provided.\nOptimal WCAG compliance (level AAA)\nExamples of Level AAA success criteria:\n- The visual presentation of text and images of text must have a contrast ratio of at least 7:1.\n- Removing timing limitations from all content, unless it is for non-interactive synchronized media and real-time events.\n- When a user has to submit information on a webpage, the submissions must be reversible, checked for input errors (and offer suggestions for correction if errors do occur), and there is a confirmation mechanism in place to allow the user to review the submission and edit if needed.\n- Images of text should be avoided or only used for decoration.\nWho should comply with the WCAG?\n- Web content developers (page authors, site designers, etc.)\n- Web authoring tool developers\n- Web accessibility evaluation tool developers\nHow to check your website’s WCAG compliance level\nHow Monsido can help your website meet WCAG standards\nEach audit scans your site for machine-testable issues, provides detailed reports so you can review any errors that may arise, gives you targeted recommendations on how to address these errors based on the guidelines, and shows you your compliance based on levels A, AA, and AAA. You can track and prove your accessibility compliance progress via reports in the History Center. We also offer accessibility training to customers and support, all-inclusive, to ensure that you are well-versed in both automated and manual remediation methods, and can efficiently and consistently improve your website’s accessibility.\nMonsido also offers free tools to complement your web accessibility efforts, including a color contrast checker for web teams to test out compliant color combinations for their web design, and an accessibility statement generator, which helps you generate a public statement declaring your commitment to web accessibility and helps make your web accessibility policy transparent to all your users.']	['<urn:uuid:6fe1f299-bbdf-4bcc-823b-2f1a553d3e97>', '<urn:uuid:a2ef5797-959c-4ba6-9b52-ee60633ac0ca>']	open-ended	with-premise	long-search-query	similar-to-document	multi-aspect	expert	2025-05-13T05:52:58.810667	10	93	1649
41	My yard has a wet spot that's always damp near one of the sprinkler heads at the bottom of my garden - what could be causing this constant moisture?	If you find a constant wet spot at the lowest sprinkler head on the line, it's most likely due to an automatic sprinkler valve not seating properly. This happens when grit or sediment on the membranes prevents the actuator from sealing properly, causing water to slowly leak down the lines and secrete from the lowest sprinkler head.	"['Troubleshooting a Sprinkler System\nTips for fixing residential sprinkler systems\nBy Scott Cohen, garden artisan and LandscapingNetwork.com columnist\nThe heads overspray and fog up. What is wrong? If water pressure is too high, the sprinkler system actually becomes a mist system and fogs the plantings. The slightest breeze will blow the water away from its intended area. All sprinkler heads are designed to work best when operating under an optimal water pressure. Check the sprinkler head instructions and install a ""pressure regulator"" (a plumbing device that reduces water pressure to a lower consistent pressure) if one is required to meet the optimal numbers.\nPlanter Coverage Tip:\nUse an alternated pattern for watering planter areas as growing plants often block sprinkler coverage. Called ""front to back coverage"" this triangular sprinkler pattern helps saturate the entire flower bed during irrigation sessions.\nIs the sprinkler system leaking or is the sprinkler valve not shutting off properly?When a sprinkler line is broken you can often see a ""blow hole"" like a whale\'s spout in the general area of the break. Inspecting the line will show a spot where soil is being blown out as water bubbles up from below.\nIf an automatic sprinkler valve is not seating properly, the actuator can\'t seal because of some grit or sediment on the membranes, then water can slowly leak down the lines. Typically this water will secrete from the lowest sprinkler head on the line. If you find a constant wet spot at the lowest head on the line it is most likely a valve that needs repair and not a broken sprinkler line.\nIrrigation controller location dilemma: Should I place my irrigation controller inside or out?Here\'s the scenario - You are a couple that travels a lot and you would like the maintenance gardener or a neighbor to be able to change the timer without access into the house, so the best place to put the timer is outdoors, right? Not so fast. If it\'s raining you need to go outside in the rainstorm to shut down the timer so you don\'t waste water. It sure would have been easier to turn off the timer if it had been installed in the garage.\nChoose timer location based on easiest access for the person that will need to set it most, and don\'t forget about rainy weather.\nDon\'t do this: To get adequate lawn coverage, this sprinkler pattern over-sprays adjacent cars and wastes water down the street.\nThe Green Scene in Northridge, CA\nAre you providing a free car wash when you water the parkway lawn? I hate it when I have just had my truck washed and I park next to parkway lawn strip and the sprinklers are installed wrong. The sprinkler installer placed one row of heads along the sidewalk side of the street using half pattern heads. In order to get adequate water on the lawn the heads all overspray the street. My timing is always perfect and when the lawn sprinklers turn on I get a free car wash I didn\'t want.\nThis is one the most common mistakes I see in residential sprinkler design. It\'s also a terrible waste of precious water and it is easy to avoid.\nPlace sprinkler heads in an alternated pattern for proper head-to-head coverage and reduced water waste. Best of all, no free car washes!\nScott Cohen is a nationally acclaimed garden artisan, author, speaker, and HGTV television personality.\nLearn how to save water and have a thriving lawn\nGet an overview of the sprinkler installation process\nGet seasonal sprinkler care tips from the pros\nReturn to Sprinkler Systems']"	['<urn:uuid:73bdd180-8147-4367-bcca-cfbccfce06ca>']	factoid	with-premise	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-13T05:52:58.810667	29	57	602
42	As a quality assurance manager, I'm looking to improve our customer service metrics - what's the recommended approach for measuring support quality using both internal and external indicators?	Support quality should be measured through two main approaches. First, use customer surveys like CSAT, NPS, or CES to understand what customers think about your product, support, and company overall. Second, conduct internal quality checks to measure agents' interactions and calculate the Internal Quality Score (IQS), which rates how well agents perform based on quality standards. Using both methods is important because customers might focus on product features rather than service quality in surveys, while analyzing support interactions alone without customer feedback could be misleading. The combination helps ensure you're tracking true support quality while staying focused on the end goal of customer satisfaction.	['If you’re not exactly sure how to improve customer service — and how to measure it in the first place — you’re about to find the answers below.\nHow to measure customer support quality\nMost companies keep an eye on certain customer service metrics to see how well they’re doing. But if you’re specifically checking how high your support quality is, you need to look at a couple of different things:\n- Customer surveys: Think CSAT, NPS, or CES. They tell you what customers think about your product, support, and company overall.\n- Internal quality checks: This is where you measure your agents’ interactions and calculate the Internal Quality Score. IQS rates how well your agents are doing based on your quality standards.\nWhy bother with both? Well, customers might not know all the things you’re looking for in good customer service. Sometimes, when filling out surveys, they talk about other stuff like the product itself or features it’s missing.\nOn the other hand, analyzing your support interactions without taking into account how your customers feel might mislead you. Customer surveys help you stay on track toward your end goal: keeping customers satisfied.\nKeep in mind that you can only improve what you measure. So, if you analyze your agents’ interactions and give feedback to them, your support team will become better at what they do and your support quality will improve.\nHow to improve customer service quality\nIf you’ve just measured your support quality and it leaves a lot to be desired, here’s more about improving customer service:\nDefine your customer service strategy and vision\nEvery company has its own idea of what’s most important for its business and customers. Some are all about giving personalized assistance to boost product engagement and upsell, while others prefer quick and to-the-point interactions.\nStart by figuring out what you want your customer service to be like before diving into analyzing your support interactions. Basically, nail down what “quality” means for your team first.\nAsk yourself these questions to figure out your support vision and goals:\n- What do we do? Decide how much support you want to provide — whether it’s minimal support (like what Facebook offers, for example) or going the extra mile to ensure your support team improves customer loyalty and revenue.\n- Whom do we serve? Determine if you’re helping all customers equally or focusing on paying or premium ones.\n- How do we serve them? Choose your approach, whether it’s a self-help focus or aiming to provide excellent customer service.\nOnce you know what you want, it becomes easier to set achievable goals. After setting your support goals, check again if they align with your vision.\nHere are some examples of customer service goals:\n- Improve customer service quality by getting both IQS and CSAT above 90% by year-end (check out how Pipedrive did it using Klaus).\n- Respond to all tickets and keep First Response Times under 2 hours every month.\n- Maintain consistent support levels via phone and live chat with IQS over 90% across channels.\n- Upsell products in every interaction possible, scoring at least 80% in the “Upselling products” category in quality assurance reviews.\nCustomer service teams that set goals improve faster than those that don’t. Customer service goals will elevate your customer service experience. Read more about setting the right goals for your customer support team →\nGive your customer service representatives the tools and training they need\nIf you want your customers to have great experiences, your agents need to be set up for success. This means:\n- When choosing customer service software, consider your budget and the features you need. But also, make sure your agents like using it because that affects how well they interact with customers.\n- Involve your support agents in decisions, not just about tools but everything. Don’t just give orders.\n- Keep in touch with your team regularly. Provide resources through customer service training, team meetings, and one-on-one sessions with your agents.\n- Keep an eye on motivation levels. Make sure your support team feels appreciated — use shout-out channels on Slack, have fun group activities, and give out swag packages or surprise gifts.\nIn simple terms, making things better for your agents and helping them continuously improve customer service skills, usually makes customers happier and boosts customer service overall.\nMake sure your customer service team has the answers ready\nFirst things first, good training is a must if you want your team to do well. If they don’t really know your products or services, they can’t help customers fast.\nBut training just covers the basics. Your support reps should be ready to handle all sorts of questions about features, functions, and situations on the spot. Even with proper training, it’s hard for all your customer service agents to have all this info at their fingertips.\nThat’s why a knowledge base is a must-have for any successful support team. Here’s what to think about when setting one up:\n- Central repository: Put all the info your team needs in one place. Agents don’t have time to search through different knowledge bases during a chat.\n- Information structure: Keep your data neat and easy to search. A clear structure saves time instead of trying to figure out how to navigate the knowledge base.\n- Search functionality: Searching by keyword might take a bit longer, but it’s a game-changer with a huge knowledge base. Add a keyword-based search function to help agents out when they’re feeling a bit lost.\n- Up-to-date information: Check and update the info regularly. Your agents are your best resource for keeping your internal documents in good shape. Let them point out old articles and suggest new ones.\nBonus tip: Mix real-life customer scenarios into your training and knowledge base. It helps agents use what they’ve learned in actual customer interactions.\nEncourage your agents to respond quickly to customer questions\nBeing speedy is crucial, and how fast your team responds really affects the quality of service. Your customers want quick, helpful answers with a personal touch. Anything less might show up as negative in customer surveys.\n- Break down the average response time for each customer service rep to spot those not hitting their targets. Figure out what’s slowing them down and suggest ways they can work more efficiently.\n- If a group of agents is having trouble, think about having a training session. It’ll get everyone on the same page about when and how to respond to customer submissions and emphasize that response time is a metric you want to improve.\n- To speed things up, consider adding faster customer service channels (like live chat) on your website to give customers more choices. Just be careful not to overextend by being on too many channels if your team can’t handle it.\n- If you’re getting a lot of cases submitted outside of regular hours and on weekends, think about adjusting shifts. This is especially useful if you’re dealing with customers in different time zones.\n- Encourage the use of canned responses, templates, and shortcuts. They help avoid coming up with custom responses to the same questions each time and also reduce the number of keystrokes needed to send a reply.\nHave a feeling that your team is not fast enough? Before jumping to conclusions, make sure your customer service team has enough people, everyone is trained, and they have the right tools to get the job done. Only after confirming this should you start looking at how each individual is performing based on key indicators.\nFind out who might be taking a bit more time to respond to customers and how well they handle support requests. The goal is to figure out what might be slowing them down and suggest ways to speed things up. However, if they’re not the fastest but provide great customer service, it could be that your team is dealing with a lot of support requests, or maybe your expectations for response speed are a bit too high.\nProactively tackle potential customer issues before they arise\nEven if your product and service are top-notch, customer dissatisfaction can still happen. But there are ways to deal with these problems and provide proactive customer service before you start seeing a drop in support quality:\n- Map out the customer journey: Identify all the possible challenges customers might face, and create a plan to improve customer satisfaction that prevents those hypothetical issues.\n- Build a customer community: Create a space for your customers to connect and share experiences. Use this community to gain insights into how customers use your product and what they think about upcoming features.\n- Review interactions with churned customers: Take a close look at the support interactions and notes from customers who have churned to prevent similar issues with other customers.\n- Keep tabs on reviews and social media: Stay updated on what customers are saying on review sites and social media. You can even go a step further and identify areas where your competitors are falling short, turning it into an opportunity for your business.\nPromote a culture of empathy in your organization\nEmpathy is probably the most important skill you should be looking for when hiring for customer service – and for good reason.\nWhen customers feel heard and understood, they’re more likely to trust you. This, in turn, leads to better ratings on the customer satisfaction (CSAT) surveys you send out.\nBut for empathy to really work, it has to be a part of your company’s culture. Here are some tips to help make that happen:\n- Hire people who love helping: Look for individuals who are passionate about helping and share the same mission and values as your company.\n- Include empathy in onboarding: Make sure your onboarding process for new agents covers how you expect them to communicate with customers, including voice and tone, language, structure, and formatting.\n- Focus on client conversations: Dedicate early conversations with new clients to understand their needs, workflows, and the customers they serve.\n- Measure empathy: Create a separate quality assurance scorecard category to measure the empathy displayed by your team. You can give it more weight or mark it as a critical category, meaning a negative rating in this area could lead to the entire conversation being considered unsuccessful.\nWe use KHC (Kind, Honest, Confident) as our categories in the QA program. IQS gives us the space to learn how to help customers feel the love. CSAT just tells us if it’s working — and it does! This paradigm has powered several customer support teams from the high 70s for CSAT into the upper 90s.\nBuild a feedback loop to show you care\nWe’ve emphasized how crucial it is to let your customers know they’re being heard.\nThis involves not just collecting customer feedback through various methods but also having an efficient way to communicate it internally and represent the customer’s voice.\nYou can also systematically review support interactions to create a positive feedback loop, for example:\n- Review a random sample of your support interactions (or let Klaus identify and score the most relevant conversations automatically).\n- Evaluate support conversations based on your internal quality standards — or check AutoQA scores if applicable.\n- Give data-driven feedback to help improve the customer support team’s performance during coaching sessions.\n- Repeat the process consistently.\nThere’s no better way to show your customers you’re listening than by integrating their requests into your product.\nNow, granted, this won’t always be feasible. But even in such instances, you can still demonstrate that you’re paying attention by having one of your Product Managers directly explain why a specific feature, for instance, isn’t being developed.\nTrack customer service quality continuously\nBy reviewing all your customer interactions, you can spot and proactively address support quality issues, including agent burnout. Remember — leaving a customer service agent alone with their negative emotions is one of the worst solutions in this situation. Even the most hardened people can sometimes feel down about awkward conversations with customers and need someone to help overcome these bad days.\nSo you should always review the troublesome conversations and provide proper feedback to the affected agents. Customers do not know your quality standards, and you should not let them be the sole judges of the quality of your service. If a case receives a negative rating, analyze it from your perspective to understand if it was handled correctly according to your quality standards.\nDon’t forget to balance those negative cases by looking at the conversations that received remarkably good scores from the customers. Find the interactions that everyone in your team could learn from and give the agents the praise they deserve.']	['<urn:uuid:f7033783-b9af-4d8b-8889-2a20e3dd3012>']	open-ended	with-premise	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-13T05:52:58.810667	28	104	2123
43	How is modern technology like virtual reality and artificial intelligence being used to improve construction projects and make them safer?	Modern technology is being used extensively to improve construction projects in several ways. Building Information Management (BIM) combined with virtual reality (VR) and artificial intelligence allows teams to digitally construct projects before building them, helping predict outcomes and select the best approaches. For example, virtual simulations can be used to test different emergency scenarios including evacuation procedures. AI and computer vision help with project monitoring, while IoT and blockchain facilitate project management. These technologies enable teams to visualize construction sequences in advance, coordinate supply chains effectively, and minimize both construction and commercial risks while maintaining high safety standards.	['Industry 4.0 Solutions for Building Design and Construction\nA Paradigm of New Opportunities\nThis book provides in-depth results and case studies in innovation from actual work undertaken in collaboration with industry partners in Architecture, Engineering, and Construction (AEC). Scientific advances and innovative technologies in the sector are key to shaping the changes emerging as a result of Industry 4.0. Mainstream Building Information Management (BIM) is seen as a vehicle for addressing issues such as industry fragmentation, value-driven solutions, decision-making, client engagement, and design/process flow; however, advanced simulation, computer vision, Internet of Things (IoT), blockchain, machine learning, deep learning, and linked data all provide immense opportunities for dealing with these challenges and can provide evidenced-based innovative solutions not seen before. These technologies are perceived as the “true” enablers of future practice, but only recently has the AEC sector recognised terms such as “golden key” and “golden thread” as part of BIM processes and workflows.\nThis book builds on the success of a number of initiatives and projects by the authors, which include seminal findings from the literature, research and development, and practice-based solutions produced for industry. It presents these findings through real projects and case studies developed by the authors and reports on how these technologies made a real-world impact.\nThe chapters and cases in the book are developed around these overarching themes:\n• BIM and AEC Design and Optimisation: Application of Artificial Intelligence in Design\n• BIM and XR as Advanced Visualisation and Simulation Tools\n• Design Informatics and Advancements in BIM Authoring\n• Green Building Assessment: Emerging Design Support Tools\n• Computer Vision and Image Processing for Expediting Project Management and Operations\n• Blockchain, Big Data, and IoT for Facilitated Project Management\n• BIM Strategies and Leveraged Solutions\nThis book is a timely and relevant synthesis of a number of cogent subjects underpinning the paradigm shift needed for the AEC industry and is essential reading for all involved in the sector. It is particularly suited for use in Masters-level programs in Architecture, Engineering, and Construction.\nTable of Contents\n1. Industry 4.0 Solutions for Building Design and Construction: A Paradigm of New Opportunities 2. AI-Based Architectural Design Generative BIM Workspace for Architectural Design Automation 3. Towards Intelligent Structural Design of Buildings: A BIM Solution 4. BIM and Design for Manufacturing and Assembly 5. Virtual Reality-Based Cloud BIM Platforms for Integrated AEC Projects 6. XR-openBIM Integration for Supporting Whole Life Management of Offsite Manufactured Houses 7. A Centralised Cost Management System: Exploiting Earned Value Management and Activity-Based Costing within Integrated Project Delivery 8. Success Factors Driving Cost Management Practices through Integrated Project Delivery 9. 4D BIM for Structural Design and Construction Integration 10. BIM Integrated Project Delivery: An Automated Earned Value Management-Based Approach 11. Revolutionising Cost Structure within Integrated Project Delivery: A BIM-Based Solution 12. Dynamic Sustainable Success Prediction Model for Infrastructure Projects: A Rough Set-Based Fuzzy Inference System 13. Multi-Objective Optimisation to Support Building Window Design 14. Artificial Intelligence Image Processing for On-Demand Monitoring of Construction Projects 15. Digitalisation of Architecture, Engineering, and Construction: Immersive Technologies and Unmanned Aerial Vehicles 16. Optical Code Division Multiple Access-Based Sensor Network for Monitoring Construction Sites Affected by Vibrations 17. Blockchain Integrated Project Delivery: An Automated Financial System\nFarzad Pour Rahimian is a Professor of Digital Engineering and Manufacturing at Teesside University, UK.\nJack Steven Goulding is Professor of Construction Project Management at the University of Wolverhampton, UK and Director of a specialist BIM consultancy service.\nSepehr Abrishami is a Senior Lecturer and BIM Programme Leader at the University of Portsmouth, UK.\nSaleh Seyedzadeh is a Data Scientist at Offshore Renewable Energy Catapult, Scotland, UK.\nFaris Elghaish is a Lecturer in Construction Project Management at Queen’s University Belfast, Northern Ireland, UK.', 'As part of Careys’ role as principal contractor for the initial phases of the ambitious North Yorkshire polyhalite project near Whitby, North Yorkshire, worth over £3.2bn, we have adopted a number of innovative techniques. These will help us to most effectively, efficiently and safely construct several of the mine’s most complex and vital components.\nIn two upcoming articles, we will delve more deeply into the details about these innovative systems and how we employed them. But, in this post, we will take a look at how our in-house Careys Design Team used cutting-edge building information modelling (BIM) technology, coupled with their considerable construction and digital engineering expertise, to ensure the successful and safe implementation of our construction plan at Woodsmith Mine.\nIdentifying the most efficient methods to help construct a trio of mine shafts\nSirius Minerals’ ambitious polyhalite project – which is set in the North York Moors National Park– aims to tap into a massive vein of polyhalite, a mineral in growing demand internationally as a fertiliser.\nAs part of our responsibilities on this ground-breaking venture – the first significant mining operation in the UK for decades – we have been tasked with constructing the initial 120m-deep sections of the mine’s three main shafts. Through these vertical shafts, miners will be able to extract the polyhalite, from a depth of over 1,500m and prepare it for the 37km underground conveyor journey to a processing plant and port on Teesside, in preparation for being shipped to destinations across the globe.\nIn keeping with Careys’ practice of finding and implementing the most efficient and innovative methodologies in order to complete our work to the highest of standards, we identified a number of innovative systems and solutions on the Woodsmith Mine project. These included employing a vertical sinking machine (VSM) – for the first time in the UK – and innovating a bespoke slip form system, used in tandem with the VSM, to continuously construct the initial 120mwalls of a 360m deep shaft.\nDigital models help ensure safe, effective deployment of innovative systems at Woodsmith Mine\nIn order to ensure that these innovative methodologies would actually function as they were designed to, once they were deployed at Woodsmith Mine, we called upon the extensive experience and skills of the team of digital and construction engineers at fellow Carey Group company, Careys Design Team (CDT).\nExperts in cutting-edge BIM and virtual reality (VR) technologies, CDT allows us to digitally construct projects, which gives us the capability to envision, in advance, how various building systems and equipment will perform in a real-world environment. By forecasting a range of possible outcomes for each aspect of the construction process, CDT’s BIM techniques and 3D and 4D models allow us to plan projects with a high degree of certainty, by predicting and selecting the best possible courses of action.\nWe are also able to use CDT’s digital models not only to explain projects to clients, providing them with greater understanding, reassurance and satisfaction, but also to give the site team a full understanding of the construction sequence prior to its arrival on site.\nAt Woodsmith Mine, CDT has generated a series of information and digital models, that have enabled us to:\n- Develop and carry out a customised construction programme that safely and efficiently capitalises on the capabilities of the new mine shaft construction technique we have created for the VSM\n- Facilitate optimal supply chain integration through\n- Ensuring full coordination of different cast-in items for machinery\n- Coordinating the control descending cable strand system\n- Installing monitoring sensor equipment within the shaft wall\n- Minimise risks, both those associated with construction, as well as those related to the commercial aspects of quantifying material and programme duration\n- Ensure a high level of health and safety on-site, through running virtual simulations of different potential emergency scenarios, including entry, exit and evacuation of injured staff\n- Protect the environment, by devising and implementing a set of responsible conservation practices, such as the reuse and effective disposal of all excavated materials throughout the construction process\nMore stories to come about how Careys is helping to facilitate the construction at Woodsmith Mine\nCheck back regularly over the weeks to come, as you’ll be able to discover more details about the landmark Woodsmith Mine project and our contributions to it. There will be upcoming articles covering topics, such as our:\n- Deployment of the state-of-the-art VSM, and implementation of a bespoke new slip form method, to construct the 120m-deep material transport system (MTS) shaft\n- Rapid, safe and high-quality construction of the service and production shafts\n- Well-planned and all-encompassing sustainability plan to safeguard the environment in the national park setting\n- Thorough health, safety and quality measures, focused on attaining a perfect safety record']	['<urn:uuid:b1fd34b9-7612-45c6-95de-70526c1d2206>', '<urn:uuid:61cf33a3-0ba0-4f6c-afc8-b057d3a36df5>']	open-ended	direct	verbose-and-natural	similar-to-document	three-doc	novice	2025-05-13T05:52:58.810667	20	98	1412
44	usa nuclear bomb power vietnam war	U.S. nuclear weapons considered for use in Vietnam were primarily gravity bombs that could be delivered from aircraft carriers offshore. The A4 Skyhawk aircraft could deliver various warheads including the B28 (20 kilotons), B43 (1 megaton), B57 (5-10 kiloton), or B61 (100-500 kiloton).	['The JASONs looked carefully at where Vietnamese insurgents might obtain tactical nuclear weapons (TNW) to respond to American nuclear first use, and how they might employ such weapons. 1n 1966, the Chinese had only recently tested and deployed their first nuclear weapons, so the JASONs considered the most likely source to be the former Soviet Union’s already well-stocked arsenal of tactical nuclear weapons.\nSupply of Soviet Tactical Nuclear Weapons\nThe JASONs state that Soviet tactical missile and fighter and medium bomber delivery systems relied on “fairly heavy warheads” that suggested “yields in the multi-kiloton range for all systems.” (p. 32).\n“The known Soviet TNW,” they state, “are all heavy and high-yield weapons designed for large-scale mechanized warfare. The smallest of them have warheads in the 1000 pound class, which would be extremely difficult for guerilla forces to handle.” (p.6). Thus, these standard Soviet TNW could only have been used in a direct riposte to US nuclear first use in Vietnam by the Soviets delivering them by aircraft, via missiles fired from offshore, or by sledding the weapons into a harbor base from offshore vessels.\nThey noted further that: “Very little seems to be known about the existence of TNW [tactical nuclear weapon] designed specifically for infantry” on the Soviet side (p. 31). They referred to a possible mortar or recoilless rifle-fired tactical nuclear weapons “weighing a few hundred pounds” as a “possible delivery system with a range of a few miles.”\nThe JASONS appear to have been uncertain as to whether the former Soviet Union had such weapons, assuming at one point that the USSR has manufactured a supply of TNW (p.31) “To give a feeling for what the Soviets might do along these lines,” they provided a Table that listed some relevant US systems, implying that physical design imperatives would lead the Soviets to make small tactical nuclear weapons along the same lines. These included nuclear warheads delivered by Little John missiles, Davy Crockett rocket fired from either a 120-mm or a 150-mm recoiless rifle, and Atomic Demolition Munitions. The latter came in three varieties, ADM50 and 50, and Special ADMs) (p.34). In reality, it appears that ADMs did not appear in the Soviet Arsenal until the 1970s. (Soviet Nuclear Weapons, p. 202). Indeed, the Soviet Union never developed or fielded a “recoiless rifle” similar to the Davy Crockett. As for the M-240 mm towed heavy mortar it was huge and heavy (3 tons) and not very portable. Ironically, it appears as though there weren’t really any Soviet “portable” weapons available in 1966 (Stan Norris, email, March 7, 2003). In a sense, the JASONs were shadow-boxing their own visualizations as to tactical nuclear weapons that might have been used by the Viet Cong, although at the time, there was no way to know what the Soviets or Chinese might have supplied.\nLittle John missiles used a W45 warhead with a yield of 1-10 kilotons. The Davy Crockett rocket used a W54-2 warhead with a yield of about 0.25 kiloton. Medium ADMs used W45-3 warheads with a 1-15 kiloton yield. Special ADMs used a W54 warhead with 0.1-1 kiloton yield. (U.S. Nuclear Forces and Capabilities, pp. 10, 33, 53, 60)\nThey noted that mortar tubes to fire nuclear weapons would weigh 500 to 1000 pounds, which would be “cumbersome for guerilla use.” (p. 33). “However,” they continued, “it is certainly within Soviet or Chinese technological capabilities to build sectioned mortar tubes, particularly since each tube need only be fired a few times, at most.” (ibid).\nMoreover, “If sectioned barrels and lightweight projectiles (250-pound) are used, the approach and emplacement problems would not differ significantly from logistic problems now solved successfully by the VC [Viet Cong].” All in all, they asserted, “While the possibility of a FROG [Free Rocket Over Ground ] attack cannot be neglected, a more probable mode of attack is one with nuclear weapons fired from mortars or recoilless rifles.” (p. 36)\nWith reference to ADMs, they state: “Relatively little seems to be known about the existence of Soviet atomic demolition munitions (ADM). Since such devices are small and light in weight and are emplaced by hand, this may merely indicate a gap in intelligence. There is no doubt that the USSR is capable of either designing ADM or adapting weapons from stockpile to ADM with little difficulty.”\nDelivery of Tactical Nuclear Weapons to Targets\nThe main emphasis in Soviet supply of TNW to Vietnamese insurgents, the JASONs suggested, would be on supplying the smaller weapons mentioned above into the battlefield. “In view of their small sizes and weights, introduction of these weapons into NVN [North Vietnam] and subsequent transportation along the Ho Chi Minh Trail into SVN [South Vietnam] offers only minimum difficulties, although it would probably take several months to deliver 50 to 100 weapons in this way.” (p. 38). Thus, a nuclear retaliation for US first use might take three-to-six months-a kind of slow motion nuclear war.\nTypes of Insurgent Counter-Attack\nThey examined three ways that insurgents might retaliate to US nuclear first use. The first was an intense barrage of 70-100 weapons of 10-20 kilotons in a coordinated attack on many US bases at once. “While such an attack cannot be ruled out,” they concluded, “it would require great coordination and run some risks of degradation by premature firing or partial discovery.” (p. 41).\nThey also reviewed a drawn-out, piecemeal attack by guerilla units over weeks or months. “Attacks of this kind are likely to include as much “mix” as the VC are capable of providing-mortar attack by infiltrating units and clandestine delivery by truck or boat.”\nThe JASONs considered a third type of “revenge” attack in which the Vietnamese were unable to launch a full-scale, tactical, nuclear counter-attack-particularly if they had to rely on presumably crude Chinese rather than Soviet nuclear weapons. In this attack scenario, they posited that the Vietnamese would use a few nuclear weapons of moderate yield to attack very important targets. They judged Saigon airport to be the most attractive single target in Vietnam: “The airport is on the outskirts of Saigon, in an area of sufficiently low population density to qualify as a military target, and the usual wind conditions would not carry fallout directly over Saigon. The present level of security would not keep out suitcase bombs.” (p. 41).\nFinally, they calculate that the 14 main US bases in Vietnam could be divided into subunits requiring one or two 10-kiloton airbursts for more or less complete destruction, presenting a total of about 70 targets and a requirement for about 150 10 kiloton weapons (allowing for duds, capture, redundant use etc). Although this number of weapons was well beyond Chinese stockpiles in 1966, this was not so with respect to the Soviet nuclear arsenal. “Thus,” they conclude, “there are no stockpile limitations and probably no weapon limitations on repeated attacks on U.S. forces with Soviet-supplied TNW.” (p. 45).\nUS Tactical Nuclear Weapons Considered by JASONS For Use in Vietnam\nIn considering American nuclear first use against the Vietnamese, the JASONs referred mostly to gravity bombs using either airburst or groundburst. (for example, p. 11). They did not seem to consider using other US tactical nuclear weapons such as ADMs, nuclear artillery shells, or other short and medium-range missile-delivered warheads. Gravity bombs would likely have been delivered from aircraft carriers operating offshore which would minimize the risk of loss-of-control of weapons on the ground. The carrier-launched A4 Skyhawk, for example, could deliver a single B28 (about a 20 kilotons), B43 (1 megaton), B57 (5-10 kiloton), or B61 (100-500 kiloton) warheads. (U.S. Nuclear Forces and Capabilities, pp. 44, 49, 63, 65).\nCiting 1966 studies by Sandia Corporation, the JASON’s refer to a “research earth borer” (REB) tactical nuclear weapon under development “which is an airdropped bomb that penetrates the ground to a desired depth. The bomb is optimized for a particular yield, and the crater diameter is about double that of a surface-burst of the same yield. Alternatively, the depth can be chosen so that the explosion is almost contained and fallout practically eliminated. [next sentence deleted by security exemption]” (p. 11).\n“REB,” the JASONs stated, “would be a useful weapon for dealing with the deep VC tunnel systems. The destructive range would not be much increased over that of a surfaceburst, so that a large number of weapons and accurate location of targets would still be needed. Elimination of long-range fallout, if REB actually performs up to specifications, would make a nuclear attack on tunnel HQ a relatively inconspicuous operation.”\nHowever, this weapon was not yet in service (indeed, it is still not in service although a variant of the B61 bomb has been created that placed a hardened steel casing around the warhead to enable it to penetrate about 20 feet into dry earth when dropped from 40,000 feet).\nPage references are to: F.J. Dyson, R. Gomer, S. Weinberg, S.C. Wright, Tactical Nuclear Weapons in Southeast Asia, Study S-266, JASON Division, Institute of Defense Analysis, contract DAHC15 67 C 0011, published March 1967; released to Nautilus Institute on December 4, 2003.\nOther technical specifications of US and Soviet tactical nuclear weapons are from:\nT. Cochran et al., US Nuclear Forces and Capabilities, Nuclear Weapons Databook, volume 1, Ballinger, Cambridge, Massachusetts, 1984.\nT. Cochran et al., Soviet Nuclear Weapons, Nuclear Weapons Databook, volume 4, Natural Resources Defense Council, Washington DC, 1989.']	['<urn:uuid:004d2696-faf2-4d9a-b0b3-a178f4205aaa>']	factoid	with-premise	short-search-query	distant-from-document	single-doc	novice	2025-05-13T05:52:58.810667	6	43	1562
45	how tell properly dried firewood ready use	Properly seasoned firewood can be identified by several signs: cracks in the ends of split wood, lighter weight, faded gray color, a ringing crack sound when pieces are knocked together (rather than a dull thud), and the ability to split easily into kindling. Well-seasoned wood should have below 20% moisture content.	['One of my earliest memories is of sitting on my grandfather’s lap as a toddler.\nWe were sitting next to the big old cookstove in grandma’s kitchen. I had an ear infection and was inconsolable. Grandpa snuggled me up next to the heat of the stove and blew puffs of smoke from his corncob pipe into my ear to soothe me.\nI ate many a meal and baked goods cooked with that cast iron beast. (The stove, not my grandfather.)\nMy grandmother was a pro at keeping the fire burning at just the right temperature. Between the woodstove in the cellar and the cookstove, their house was always cozy during colder months of the year.\nThere was a never-ending supply of well-seasoned wood coming into that house. And that’s what we’re going to talk about today – how to properly season firewood.\nIf you heat your home with wood, then having access to seasoned firewood is essential for a hot and clean-burning fire.\nIf you have a newer, high-efficiency wood burning stove, then burning well-cured wood is a must.\nUnseasoned, or ‘green’ wood has a higher water content, which leads to a smoky, weak burning fire. Trust me; you don’t want your house smelling like smoke and creosote.\nUnseasoned firewood doesn’t burn off the tar and pitch in the wood, which leads to creosote build-up. Creosote is responsible for that gross black film on the glass doors of your wood stove.\nIt will also build up in your chimney at the least, requiring more frequent chimney cleanings and at the worst, causing a fire.\nAside from having a good hot burn, seasoned firewood is just a safer fuel.\nBefore we go any further as someone who has spent many a year chucking and stacking firewood, (Ask my dad, kids are cheap labor.)\nI highly suggest investing in a sturdy pair of leather work gloves.\nWhether you are bucking a tree, splitting logs for stacking, or adding fuel to the fire, your hands will thank you for the added protection.\nI’ve always had a pair of Wells Lamont leather work gloves since I was a kid. They are nearly indestructible, and I swear by them. At 40 years of age, I’ve only had to replace them three times.\nObviously, the best way to have control over your source of fuel for your woodstove is if you are cutting the wood yourself.\nIn this way, you can be sure you’re cutting at the best time of year and control the entire seasoning process.\nWhen to fell trees\nYou should cut trees for firewood during the winter and early spring months. You want to fell your trees when the sap isn’t running, so before the maple syrup season.\nYou also want to cut a year ahead of when you need to burn your wood to give the wood optimal time to dry out.\nIf you’re planning on burning oak, an excellent burning hardwood, your curing time can be up to two years.\nDon’t use rotting or diseased trees for firewood, and you shouldn’t burn wood that’s been sprayed with insecticides or pesticides either. Damp wood is a breeding ground for mold, and you don’t want to bring mold into your home. Curing your wood as soon as it’s cut prevents mold growth.\nAirflow is key to drying out wood, so cut and split your wood as soon as your trees have been felled and bucked.\nRelated Reading: What’s The Best Wood To Burn In Your Wood Stove?\nBucking is cutting a fallen tree into logs.\nWhen you are bucking a tree, you want to keep your logs uniform in length. Ideally, your firewood should be around 3” shorter than the firebox of your stove.\n16”- 18” is a standard firewood length, and to make things even easier, 16” and 18” are common chainsaw bar lengths. In a pinch use your chainsaw bar to measure your next cut.\nGet the wood split as soon as possible. You want to expose as much of the wood to air as you can. If you don’t own or want to rent a log-splitter, you’ll need a splitting axe.\nI have always used and always will use a Fiskars Super Splitting Ax (36”). It’s the best splitting axe money can buy, and no I don’t want to argue about it. Trust me.\nIdeally, you don’t want pieces much bigger than 6” in diameter. At the very least, split even the small logs in half. Having a nice variety of sizes means good airflow while your wood is burning as well. And smaller pieces are always handy to have when lighting a fire.\nWind and sun are your friends when it comes to seasoning firewood, take a few minutes to find an area of your property that gets a good amount of both. This is where you’ll set up your stack.\nYou don’t want to stack wood directly up against buildings as this is just asking for a six-legged critter invasion.\nDon’t stack your wood directly on the ground; use some old 2×4’s or even straight tree branches laid down to stack it on.\nAirflow, airflow, airflow is the key to seasoned wood.\nYou want to stack facing the wind and in a single row for the best circulation. The sun will bake the moisture out and the wind will wick it away.\nFor safety reasons, don’t stack your pile higher than 4’ high. And for the last top layer, be sure to put your wood down bark-side up. This will add a layer of protection against moisture.\nIf you stack against a fence, be sure and leave a few-inch gap between the fence and your pile.\nTo cover or not to cover\nThere seems to be some debate when it comes to covering stacked wood. Some people insist that it traps moisture in, others say the wood will keep getting wet if you don’t cover it. In the end, I feel that this comes down to personal preference. Do what works best for you.\nIf you’re lucky enough to have your wood stove in a large cellar, you can finish seasoning wood indoors. I spent many a weekend in the basement stacking wood along the cellar wall as part of my chores at Dad’s house.\nIf you want to get fancy, have a go at building a Holz Hausen.\nMany people on the internet swear it’s the best way to season wood. Check out this YouTube video for details.\nIf you’re purchasing wood from someone else, you can’t always take their word that the wood has been properly seasoned. What they consider seasoned could mean it sat, unsplit in a pile in their backyard all summer.\nMy suggestion to you would be if in doubt – season the wood yourself after you purchase it.\nAnd always purchase your wood a year before you will need it. You can usually get a better price for buying green wood too. It will be fewer headaches in the long run.\nRelated Reading: 10 Smart Ways To Find Free Firewood\nHow do I know when my firewood is ready?\nCured wood will be below 20% moisture. While you can purchase a fancy moisture meter, there are a few easy ways to tell when your wood is seasoned.\n- Check the ends of your split wood for cracks.\n- As your wood loses moisture, it won’t be as heavy.\n- The color will have faded and become grayer.\n- Check the sound. Smack the ends of two split pieces together. You should hear a ringing crack rather than a dull thud.\n- Split a piece into kindling. It should split and splinter easily.\nNow that you are master at wood seasoning, you’ll be ready to face the harshest winter weather.\nStay warm and check out our article on what to do with all of the ashes left from those toasty fires.']	['<urn:uuid:a7acc417-1f82-4214-9820-0d2ae95e6595>']	factoid	with-premise	short-search-query	distant-from-document	single-doc	expert	2025-05-13T05:52:58.810667	7	51	1318
46	Being a mountain guide specialized in seasonal tourism planning, I'd like to know about the snow conditions and duration of winter in both the Albanian Alps and Svalbard regions, particularly regarding accessibility and tourism seasons.	In the Albanian Alps, particularly in the Valbona area, snowfall starts in early November and lasts almost until May, with an average yearly snowfall of 100 cm. The area is only accessible through high passes during summer months. In Svalbard, May is considered the optimal time for skiing as the snow conditions are perfect, coinciding with 24-hour daylight and the return of wildlife. This is actually when mainland Norway's ski season is ending, making Svalbard a unique late-season destination.	"['A Fairy Tale Journey\nThe flagship region for mountain tourism is the Albanian Alps, the National Parks of Thethi, Valbona and the Region of Kelmendi. The “Accursed Mountains” are both truly spectacular and virtually impenetrable except for a series of high passes that link the small number of farmsteads and homes in the valleys below to the outside world during the summer months.\nThe Valbona River Valley lies in the eastern part of the Albanian Alps.\nA national park of 8,000 hectares, it is one of the most beautiful natural areas in Albania. The park lies about 22 km from the alpine city of Bajram Curri. Before entering the valley you will find the spring (vrellen) of Shoshan, located only 3 km away from Bajram Curri.\nThis spring rushes through limestone fissures on its way to the Valbona River creating an attractive canyon, 2-3 m wide and 50 m deep. After entering the valley, you will pass several picturesque villages. The first, with alpine style houses, is called Dragobia, and it is where the valley narrows. Past Dragobia, at the foot of the mountain where the Cerremi stream joins the Valbona River, is the famous cave where the national hero Bajram Curri was besieged and killed. It was after this event that the city took his name.\nValbona is located 25km away from the city of Bajram Curri and is the most important inhabited center of the valley.It is full of traditional houses that create a picturesque view in symmetry with the natural wonders of the valley, which widens again at this point. In Valbona, there is a comfortable and traditional hotel, or you may have the opportunity to stay at a village home, as the inhabitants’ generosity and hospitality are well known.\nThe area is also known for its characteristic regional cooking, with specialties such as mazja, flija (a many layered pancake-like dish cooked outdoors over open coals and steamed, often served with local honey), and pitja. Beyond Selimaj, the road continues through the valley with breathtaking vistas with rich colors of both spring life and of the snow that covers the nearby craggy peaks.\nThe final village before you arrive at the source of the Valbona River is Rrogam.\nRrogam is a remote village surrounded by virgin natural landscapes. The entire valley is resplendent with rare colors and beauty. On one side, you see the crystal-clear waters of Valbona, and on the other sharp but verdant mountain face. Until May you can enjoy the contrast of the clean white snow on the treetops against the blue sky. The flora of the national park includes a variety of plants and trees, the most widespread of which are the Hormoq tree. The rest consists of beech woods, walnuts, chestnuts, and wild apple. There are also numerous berries, including wild blueberries and strawberries.\nThe animals in the park include bears, wolves, wild cats, and even herds of wild goats climbing on the cliffs. In the river one can find marble trout, a rare fish found in the crystal-clear waters of the Valbona which has a unique flavor. The valley, the park, and all surrounding area are known for heavy snowfall, which starts in early November and lasts almost until May. The average yearly snowfall in this region is 100 cm.\nThere are many outdoor activities in the national park, such as skiing, mountain climbing, fishing, excursions and trekking throughout the valley and streams (Cerremi, Kukaj), and canoeing along certain parts of the river. Valbona may also serve as a starting point if you wish to climb the Jezerca Mountain, the second highest mountain in Albania.\nAnother interesting spot of the Western Alps is Vermosh, located in the northern-most mountains of Albania, 95 km from Shkodra in the region of Kelmend (from the Roman word “Clemens,” meaning gentle, simple, and good). The first thing that catches your eye along the journey is Qafa e Rrapshit, where you can see the crystal-clear waters of the Cemi River creating a beautiful contrast with the surrounding landscape.\nDuring summer, the ponds of the river are perfect for sunbathing and many visitors stop to lounge in the sun and enjoy themselves. Vermosh stands in an alpine field 1,100 m above sea level surrounded by high slopes. You can entertain yourself by trekking, mountain climbing, skiing, or fishing for mountain trout. The locals pride themselves that their cuisine is only truly enjoyable for visitors when accompanied by their own dairy products, so be sure to indulge. A real journey among the people of this region will give you not only the chance to experience a world located between traditional village life and contemporary society, but will also let you enjoy the hospitality renowned by almost every visitor who has been fortunate enough to visit.\nAn alpine tour of Albania isn’t complete without a stop in the famed Western Albanian Alps, (Alpet Perëndimore). Here you will enjoy the unique opportunity to walk, breath, sleep, and eat amidst the legends dating from Homer and through modern tales of our majestic mystery and intrigue. This tour gives you the rare chance to enjoy the heart of the Albanian Alps, Gropa e Thethit. The journey begins from the cultural capital of Shkodra and wanders 41 km away to the village of Razma.\nSituated on a blackberry hill at the feet of the Veleçik Mountain, Razma stands amid lush forests of pine and birch trees. Meadows and amazing alpine pastures abound, drenching any visitor with a keen eye in the beauty of the Balkans. Even in the depths of winter when the snow drifts tout highest level of the season, adventure tourists visit Razma. Several hotels already exist and others are being completed. Common activities on the excursions are mountain climbing, skiing, and, weather permitting, camping. The road turns from Razma to the village of Dedaj and then onto Boga, a village surrounded by the Alps and described by Edith Durham in her book, “The Burden of the Balkans.”\nIt is here that the wealthy families of Shkodra built their houses and villas to rest and escape the city before the Second World War. Boga is the perfect place for mountain climbing, skiing, and cave spelunking. Among the most famous caves, visitors often delve into the Cave of Mulliri (Mill), Akullore (Ice Cream), and Njerëzve të lagun (Wet People).\nThe Cave of Puci is one of the most attractive, situated 1,087 m above sea level and 5 km deep. This cave is rich in stalactites, stalagmites, and wall veils, and branches into many different levels, five alone at the center. Passing through its curved galleries you can walk into the next cave, the Cave of Husi.\nAfter Boga, you can find one of the most popular tourist spot of the entire area, Thethi.\nLocated 70 km from Shkodra, you must pass Qafa e Tërthores at 2,000 m before descending to Gropa e Thethit by crossing a stream bearing the same name. It is a journey you’ll want to have your camera ready for, full of extended mountain views, with water cascading down craggy hillsides and trees reaching for sunlight on rocky slopes. The area is rich in sights such as the waterfall of Grunas, 30 m high, the amazing cold-water sources of Okol, and the caves of Birrat me Rrathë (Round Holes) and Mount Arapi.\nIn the park people often amuse themselves by hiking, mountain climbing, skiing (especially on the eastern slope), fishing, even mountain biking and spelunking. Almost 90% of the park area is covered by beech trees, providing shade for many different types of flowers such as the Wulfenia baldacci, discovered by the Italian botanist Baldacci. Fascinatingly, this flower is found only in Theth. The fauna is just as rich as the flora, distinguished by the famed golden eagle and rreqebull (lynx).\nIn the waters of Theth’s stream, marble trout make their home. While in Theth you can stay in local guesthouses designed to display traditional alpine architecture. The characteristic dish of the area is fërlik (rotisserie) or you can sample one of a large varieties of local trout. If time permits, many travelers enjoy a short excursion to the Shala Valley which brings them close to the heart of the Albanian Alps.\nFor more info please visit:', ""mai 24 - 29. mai 2022\nWelcome to one of our most exclusive trips so far. When the skiing season is about to end in mainland Norway, it’s at it’s best in the arctic archipelago of Svalbard! The sun is back and shining 24 hours a day, animals are back and thriving and the snow-conditions are perfect, so May’s a fantastic time in Svalbard.\nSvalbard can offer fjords, mountains and vast wilderness areas that are still untouched by human activity even now in our time. The traces we find in the nature here are not from people, but from the polar fox, seals, birds, reindeer or the queen of these lands, the polar bear! On this trip we’ll be accompanied by the wild animals and the elements; air, ocean and ice in every way - from sea ice, to glaciers and snow we can ski in all forms.\nWith 6 days at hand we have time to get to know the Isfjord. And if the weather forecast allows us we have the alternative of navigating out of the Isfjord basin and up along the north-west coast of the island Spitsbergen to the really majestic fjords. How far we sail each day to ski will of course be due to weather and snow-conditions along the way.\nWe will experience and explore raw nature, ski-tour and get tired and pumped, and eat and drink well. We use the dinghy to shore, put on our skis and skins at the beach, hike up and ski down a mountainside probably nobody have skied before us. Everything is set for an awesome trip!\nThe ski touring we do during this week will be planned with everyone the day before. After a day’s hike and ski we relax in the boat with warm and good food, before we sail to the next fjord, harbour or anchorage.\nWith us onboard on this trip we bring a certified ski-guide with several years of experience with this type of ski-touring in Svalbard.\nThis trip starts and ends in Longyearbyen, the main city of Svalbard. See the day-to-day program for more information.\nOn our trips we travel as sustainable as possible, we will use our sails as much as possible without using engine, and we try to not leave any lasting traces at sea or land. In SailNorway we are engaged in taking care of the environment as much as we can and we think that smaller sailing boats with fewer people and little pollution and waste, are way less harmful to the environment, the climate and local wildlife, compared to bigger vessels and cruise ships. We do also try to clean up plastic in the places we visit instead of leaving any trash. At Svalbard we follow AECOs regulations for encountering with wildlife, beach cleaning, cultural heritage sites and for visitors and tourist operators in the Arctic. You can read more about AECO’s guidelines here.\nEpic. Epic. Epic. As a skier and a outdoors-man it is impossible not to dream of Svalbard. There is also a very special light and skiing opportunities long into the summer.\nDay 1: Ship o’hoi - let’s meet and set sails!\nWelcome on board! We will meet in Longyearbyen harbour at 10:00, get settled in to the boat and get to know each other. Before we set sails, we’ll take you through safety routines on board, and familiarize you with the boat. We eat dinner on our way out of the fjord and we will try to get a ski hike during the day.\nDay 2: Skitouring in outer Isfjorden\nThe most famous and visited fjord in Svalbard is Isfjorden. In their respective side fjords in this fjord system, lies the cities of Longyearbyen, Barentsburg and Pyramiden as well as smaller abandoned places. The fjord is surrounded by great mountains for skiing, so before we sail north, we go for a hike or two around Isfjorden.\nDay 3 - 4: Isfjorden, Kongsfjorden (Kings Bay), Krossfjorden\nThese days we use in the Isfjord, and if the weather forecast allows us we will explore the magnificent fjords on the north-west coast of the Spitsbergen island. With ski touring and sailing, nice meals and spectacular wilderness!\nDay 5: Sailing back home towards Longyearbyen\nWe start thinking about the return, whether it'll be from the Isfjord or the southwards travel back home and stop for a skitour along the way if we see that there's time for it. We aim for a visit in Barentsburg and finish the day with dinner in Longyearbyen this last night!\nDay 6: Thanks for a great trip!\nAfter breakfast we clean ourselves out of the boat and we wish each other a good travel back home. Thanks for a great trip in these beautiful surroundings! If you have the time, we recommend spending an extra day or two in Longyearbyen to relax after the week’s impressions and get to know more of this little multicultural Arctic hub.\nThe program may change according to weather and conditions, but it gives an indication of how we spend the days. We start every day with a good breakfast and make a packed lunch before we go ashore. Some of the days we eat dinner right away after skiing, other days we just eat a little when we come back to the boat, and then sail on before we make a later dinner. Some days, we spend time fishing, and time to look around. If the weather should be really not in favour of skiing, then we spend the day sailing or do something else fun.\nTravel - in general\nSometimes we have to fly, but not always. If you have the luxury of time, we always encourage to travel as environmentally friendly as possible. Traveling slowly also gives another start to a holiday. Cycling, taking the train or driving a car together are good alternatives! Feel free to add some extra time before and after, since up in the north weather that can sometimes change your plans.\nVery few row to Svalbard, a few more sail, but most fly. Norwegian and SAS fly to Longyearbyen, check out www.norwegian.no or www.sas.no.\nWhat exactly is Ski & Sail?\nSki & Sail is a trip concept where we sail into the foothills of the mountains and start the ski trip by the edge of the water. By boat we can move from place to place, and choose mountain sides and areas based on weather and conditions. Ski & Sail is something Italian and French skiers have done in Norway since the 90s, and something Norwegians so far have only started to discovered the joys of. SailNorway has arranged Ski & Sail trips on Helgeland, in Steigen, in the Lofoten Islands, in Lyngen, Finnmark and on Svalbard for many years, and we dare say that we know many of the very best places along the coast. Skiing & Sailing is really cool!\nLevel of this trip - medium level\nOn this trip we require some experience with randonee/alpine touring/backcountry skiing. If you have a lot of experience it is great, and you will get to work on your skills and techniques. Those with a lot of experience often ski steeper slopes than the others, and may take on several runs during one day. But we try to keep the level as even as possible, so we can choose the destination from the participants' level. If you are in doubt as to whether this is the trip for you, please feel free to contact us, and we can look at the level of the other participants and find a trip that suits you perfectly - whether you are a beginner or experienced.\nSafety and risk - in general\nSailing wise, our trips are not difficult, and you are always welcome to join us! We have with us both people who have never sailed before and experienced sailors. However, you must be prepared for everything from no wind to sailing in harsh weather. If you are a beginner, we will try to make you a seaman/woman as soon as possible. If you are experienced you will be given responsibility and greater challenges. We take safety seriously and on our trips we train on handling different situations that can occur at sea. Man-over-board, fire, abandon vessel, dismasting and grounding are some of these. Building the participants' skills on how to handle critical situations are important elements for better safety on board. On board a boat and on trips, everyone must know what to do in potentially dangerous situations. For us it is important that you as a guest and participant is trained quickly enough to be a participant not a passenger. It contributes to learning, sense of achievement and increased safety for all. It's also why our trips are considered to be sailing courses, you are trained to be one of the crewmembers on board.\nWe have the same mindset when it comes to skiing and alpine/backcountry trips. The first day of skiing we train and repeat search and rescue techniques, and the use of avalanche equipment. Many elements determine the safety of an alpine/backcountry trip. Good planning, humbleness in relation to weather and avalanche risk, and a dynamic group are important.\nMountain hikes and alpine/backcountry trips involves a certain risk, as does sailing. However, we as an operator, and our skippers and ski guides, do everything we can to minimize the risk in a professional manner. Everyone gains on this and we have no one to lose. Feel free to contact us to discuss risk.\nIf we are in a place without snow, we sail to where the snow is! With the sailboat we are flexible with regards to finding the best snow, but that means we may go somewhere that is not mentioned in the program or a place that we have not tested in advance. Then it's extra exciting.\nOrdinary alpine/backcountry equipment is required for this trip, that means avalanche-/ski backpack with beacon, probe and shovel, and alpine/backcountry skis with skins and ski crampons. We have a few backpacks/sets that can be hired through us and ski equipment can be rented through our partners. In good time before departure we will send you a detailed recommended packing list for this trip.\nFood and cooking\nOn our trips everyone contributes to the operation of the boat, so as long as you have not booked one of our trips with a designated chef, all take their turns in the galley during the trip. Skippers and guides assist as much as they can along the way. In advance of the trip, we set up a menu and shop what is needed. We offer good menus with healthy and medium-advanced food. If you have allergies or preferences let us know in the registration form, and we take that into account.\nWhat we expect from you\nWe want you to take part in the routines onboard the sailboat, whether it is sailing, docking, navigating, looking for whales and icebergs, washing up, cooking, clean the boat or contribute in other ways when required. Our trips require a little work of the participants - and you must be open to contribute and open up a bit socially. We have many different people with us on our trips, and most people go very well together. Our experience is that doing things with others out in nature, and not least do things with new people with different personalities than one might be used to, is what creates the best, most interesting and memorable stories :)\nLife on board and accommodation\nLife on board a sailboat is social and pleasant, but for some it can be perceived as quite intimate and crowded, which is important to be prepared for. On our trips everyone participates in the operation of the sailboat and everyone is considered crew. We would like to get to know you well and hope that you will get to know everyone else on the sailboat as soon as possible. It requires some patience, generosity and an open mind to thrive, but the new acquaintances and completely raw nature experiences are quickly what will take your focus as soon as you become comfortable with life at sea.\nAccommodation on the boat is part of the fun. The accommodation is generally in shared cabins, some of which have a double bed and some have a bunk bed solution. The distribution is quite a puzzle, but we do believe we are quite good at it. Let us know if you have any special needs or reservations.Any accommodation before and after the trip must be arranged on its own. If you have any doubts about where to stay, we’re happy to give you some recommendations.\nOn the boat we have a lot of heat and a lot of good food, but not always abundance of fresh water.\nWhat kind of people join this trip?\nMany come alone, some travel as couples, some travel as a group of friends. The common denominator for everyone is that these are fun and committed people you become friends with almost no matter what. Sharing grand experiences creates strong ties! Many people wonder about the age composition of our trips, but that is not so important to us. It doesn't matter if you are young or old as long as you want to go on a trip and intend to do your part so that you and the rest of the crew will have a good trip together.\nEnvironment and sustainability\nBoth sailing and alpine/backcountry trips are environmentally friendly activities and we sail as much as we can and use the engine as little as possible. We encourage crew and participants to travel as environmentally-friendly as possible, and we use local ingredients and resources as far as possible. We also have our own trips where we collect litter and clean ocean trash from beaches.\nPhilosophically we often say that sailing is an exercise in sustainability; we move with the wind and we have limitations on things like water, diesel, electricity and food. In order to run sustainable - knowledge, patience, agility and hard work are required. The same can be said about many other things that one tries to do in a sustainable way.\nChanges to the program\nThe program should be seen as a starting point that we adapt to weather and conditions. We also reserve the right to constantly improve our itineraries. Onboard with us we always have a dinghy for beach landings and small expeditions, we have fishing gear for the cod, and gear to hike or make a bonfires on the beach - we are ready for adventure! Are you?""]"	['<urn:uuid:aab8b782-48e7-4fa0-b417-91fb47364f9b>', '<urn:uuid:758bd536-d5e6-41d6-8003-594b2db10260>']	factoid	with-premise	verbose-and-natural	distant-from-document	multi-aspect	expert	2025-05-13T05:52:58.810667	35	79	3826
47	coding security tools best practices adoption barriers	Software security faces significant barriers in adoption due to several factors. From a historical perspective, security has been an afterthought in software development, with poor implementation of basic concepts like input validation and access control. This is compounded by the fact that modern development environments have lowered entry barriers, leading to 6-10 million Java developers alone, many without security training. However, there are solutions through established security frameworks - multiple quality options like Microsoft SDL, SSF-BSI, and OpenSAMM provide structured approaches. These frameworks emphasize security throughout the development lifecycle and incorporate best practices such as least privilege, using proven secure components, economy of mechanism, and attack surface reduction. They require systematic security design documentation, defense in depth strategies, and regular security design reviews.	['What is it and why should I care?\nSoftware development has taken an interesting path over the short lifetime of the field. It began as a deeply technical field where only the best and brightest could participate, which is not unusual since it was born out of engineering, a very technical and structured field itself. However, as the field opened more widely to the general population due to the Internet as well as widespread access to computers and simpler programming paradigms, the barrier of entry was significantly lowered. There’s recently been some educated guesswork that places the number of java developers in the world at 6-10 million. That’s just one (albeit popular) language. In addition, the newer development platforms (web/mobile) and reduced time to market (days/weeks instead of months/years) have made the field even more popular and populous. Add to these points the fact that the web in particular was built to be open and that most developers haven’t had significant security training, often including even those building platforms and languages.\nFrom a software security perspective, that’s a challenging environment in which to function: simple and accessible languages/frameworks that are fairly insecure being used by novices, or even professionals, with little to no security training. Historically in software, security has been an afterthought – we’ve done a poor job overall with basic concepts such as validating input, encoding output, authentication, access control, etc. As for more esoteric issues, we have typically engineered solutions well after the attacks are discovered and known (this is partially acceptable since “you don’t know what you don’t know”). However, we also seem to have very bad memories, and tend to re-introduce the same weaknesses of design repeatedly (see web->mobile).\nBut there is hope! I have no doubt that the software security field is going to be active for a long time (lots of problems), but I am a firm believer that we can make significant improvement, especially within our sphere of influence. What it requires though is baking security into the way we build and deliver software, our software development life cycle (SDLC). Many of the posts in this series (and on this blog generally) are point solutions to specific problems. However, securing the SDLC is far more broad and reaching. The SDLC is just the way you build software, the set of steps you follow to get from thought or need to working software to retirement of the product. Examples you’ve heard of are agile, waterfall, spiral, etc. The point is that whether yours is heavily structured or very ad-hoc, you follow some process.\nThe simple idea of securing the SDLC is that you modify your current process (or adopt a new one) in a way that accounts for security. The truth is that if you want specific attributes out of something you build, you must plan for those attributes before you build it, or the re-engineering effort is not acceptable. If I want a chair that rocks, but I just start cutting pieces of wood in the shape of a chair that I’ve seen before (copy-paste code from stackoverflow or previous projects), I’m going to end up with something like a chair … but not one that rocks, and certainly not one that rocks smoothly.\nWhat should I do about it?\nWe want to build secure software, and we know we have to plan for it. Now, we need a process that allows that and helps us plan for that. Luckily there are several open source popular models that you can consider to help you get started. All of these should be customized and tailored for your environment, but they are very good at giving you ideas of areas of consideration. It’s a good idea to get familiar with several, so even if you use one as your basic model, you can borrow from others to create a plan that works in your organization. While there are many good resources (the US CERT catalogs several), a few of noted interest are the Microsoft Security Development Lifecycle (SDL), Software Security Framework – Building Security In (SSF) and the Software Assurance Maturity Model (OpenSAMM).\nAll of the models (including those I haven’t mentioned) have strong and weak areas, but I personally like these three a lot, and for different reasons (though they’re all reasonably similar, when push comes to shove). The Microsoft SDL has great documentation and lots of great tools and worksheets ready-built to help you get going. The SSF-BSI is grounded with real data (openly published, see BSIMM) and is extremely logical and simple and clean. The OpenSAMM is great because it shows very clearly how to extend and customize it for your environment. You get a great idea of the options available, and you can make an informed choice of what steps work for you.\nIt is actually pretty rare in our field that we have so many quality options that are open and available to solve a certain problem. In this case, we’re fortunate that we have options. Make sure that whatever route you choose, that you follow it, and certainly improve over time. If you find a hole in your methodology, fill it in with a practice so it’s no longer an issue.\nIn conclusion, software security is a long and arduous journey. Building secure software is no easy feat, but it helps tremendously to have a plan. Fortunately, there are several quality options for SDLC frameworks that account for security. Read about the different models to get ideas before you start – some cover certain areas better than others. Build a model that works in your environment, and by all means, use it!', 'NOTE: This article is not only for organizations that have already been hacked… The IEC 62443 is a generic standard recognized as applicable across critical sectors such as manufacturing, energy, transportation, healthcare, and many others.\nThis article is the second episode of a series of 8, covering the main practices to be implemented by any organization aiming to meet the State-of-the-Art in Cyber Security for industrial and automation control systems. Based on a pragmatic approach, this article guides you on how to handle the definition of requirements related to a secure development lifecycle (IEC 62443-4-1) within your current organization processes.\nIn order to systematically develop secure products, security must be emphasized throughout the whole software lifecycle, such that the results are secure by design. Thus, every phase of a common software lifecycle has to be enhanced with security practices. This leads to a secure development lifecycle as illustrated below. In this second episode, we will focus on good practices required to build a secure system right from the beginning, the Secure Design Process.\nThe term security by design describes practices used to ensure that a product is secure and followed defense in depth principles right from the beginning of the design phase. Processes required for secure design are required to be applied to all stages of product design, from conceptual design to detailed one, and to all levels of product design from the overall architecture to the design of individual components.\nFour main topics are addressed for secure design in standard part 62443-4-1. These points are described below.\nFirst, secure design documentation is required to ensure that security for access to assets is comprehensively addressed from the perspective of external and internal interfaces of the product through which attacks can be mounted. Having this process means that interfaces of the product are identified and characterized by the interactions that take place over them (for example, data and control flows), the security mechanisms designed to protect them and the assets that can be compromised if not adequately protected. Viewing interfaces within the setting provided by the product security context allows the secure design to focus on the specific environment in which the product is expected to operate, including both protections offered by the product security context and vulnerabilities resulting from it. An example is presented below. The same question should be answered for each interface in a systematic approach:\nSecond, Defense in depth design is required. This principle consists of providing multiple layers of security to thwart security threats. Each layer of a defense in depth strategy is designed to protect the assets from attack in the case that all other layers have been compromised. A process shall be employed to implement these multiple layers of defense using a risk based approach based on the threat model.\nFor exemple, the TCP/IP stack could check for invalid packets, an HTTP server could authenticate input, and then another layer could validate that the input and audit logs are produced for administrative changes. Each layer provides an additional defense mechanism, has a responsibility and provides attack surface reduction for the next layer. Each layer assumes that the layer in front of it can be compromised. The following figure presents this approach in a larger scale.\nThird, security design review are required to to ensure that the secure design addresses the requirements and threats defined for the product, and that design best practices have been followed (see last topic). All discovered security-related issues are to be documented and tracked. Having this process means that each version of the design is reviewed to determine:\n- whether any product security requirements have not been adequately addressed by the defense in depth strategy\n- whether there are threat vectors (paths for threats to follow) that bypass the defense in depth strategy or that are otherwise capable of breaching the defense in depth strategy.\nIn either case, the threat model is to be updated to reflect security-related issues discovered as a result of the review process.\nAs a fourth and last topic, secure design best practices are required to ensure that guidance is provided to developers to help them avoid common pitfalls during design that could lead to later security issues. Having this process means that the product supplier has a list of security best practices that is maintained and followed during the development of the secure design for the product. These best practices should be based on commonly accepted security best practices in industry for the type of product being developed. It is completely up to the supplier to determine which practices they consider to be most appropriate for their design practices. These practices are kept current as a result of both changes in the industry and the application of lessons learned by the product supplier.\nExamples of best practices below:\n- least privilege (granting only the privileges to users/software necessary to perform intended operations);\n- using proven secure components/designs where possible;\n- economy of mechanism (striving for simple designs);\n- using secure design patterns;\n- attack surface reduction;\n- documenting all trust boundaries as part of the design;\n- removing debug ports, headers and traces from circuit boards used during development from production hardware or documenting their presence and the need to protect them from unauthorized access.\nEven if 62443 compliance is not an ultimate target, secure design process should be considered as the baseline to be implemented and handled by organization developing secure product.\nIf you have any questions about secure design processes and/or certification criteria, please do not hesitate to contact our cyber security specialist: Kilian Marty']	['<urn:uuid:dc310801-d888-4eaf-96f0-3ded5900e38d>', '<urn:uuid:fff55beb-1d62-4978-887a-bf5653414d05>']	open-ended	direct	short-search-query	distant-from-document	multi-aspect	expert	2025-05-13T05:52:58.810667	7	123	1876
48	What was Ron Lutz known for in Missouri radio?	Ron Lutz was a radio legend from Fulton who was the voice of early-morning bluegrass music on KFAL from the 1950s until the first decade of the new century. He was known for his popular live Saturday program called The Rooster Creek Show.	['NOW YOU CAN HEAR MISSOURI RADIO’S HISTORY\n(Jefferson City)—They were the voices in the morning who told us the overnight news, the morning weather, and the sports scores. They entertained us and informed us throughout the day and into the night. They have been the unseen companions of Missourians for almost a century.\nThe State Historical Society of Missouri has catalogued and archived hundreds of recordings gathered by The Missouri Broadcasters Association under the auspices of the Library of Congress Radio Preservation Task Force. Some of the recordings from Missouri radio stations are more than fifty years old. The recordings include hundreds of hours of voices long-familiar to listeners in Missouri communities—news reports, music shows, homemaker and other call-in programs, and special events coverage. The MBA is working with its members to build the collection substantially larger.\n“Many of these recordings are not just broadcasting history, they are broader Missouri history,” says Terry Harper, Director of Member Services for the Missouri Broadcasters Association. “We’re hoping many current and former radio station staff members have recordings and other material in closets and attics that they will want to contribute.”\nThe MBA plans to ask its member stations to submit examples of their programming each year to reflect the ongoing role of radio in Missouri.\nThe project’s godfather is St. Louis media historian Frank Absher, whose St. Louis Media History Foundation has collected and archived examples of area radio and television broadcasts as well as advertising and print media for several years. The Library of Congress asked Absher to help establish a statewide audio archive of radio history as a prototype for a national radio archive.\n“This is exactly what we had in mind when the Library of Congress proposed the Radio Preservation Task Force,” says Dr. Josh Shepperd, the Director of the task force. “It wouldn’t be possible without the strong local commitment from the Missouri Broadcasters Association and the State Historical Society of Missouri. Their efforts will serve as a model for similar programs we are proposing in other states.”\nThe recordings are being preserved in a digital format and are archived by the State Historical Society at its Center for Missouri Studies in Columbia. Examples of programming from almost thirty radio stations already are in the collection and more will be added. The Broadcasters Association and the Historical Society are still accepting and cataloging contributions from individuals and from radio stations.\n“Missourians should be proud of what the State Historical Society and the Missouri Broadcasters Association have accomplished. Now anyone who is interested can listen to the state’s radio history the way it sounded when it was first broadcast. And as more people donate recordings of Missouri radio stations, the collection will gain national importance,” says Absher.\nThe first donation to the collection was made by the family of Fulton radio legend Ron Lutz, who was the voice of early-morning bluegrass music on KFAL from the 1950s until the first decade of the new century. The collection includes Ron’s popular live Saturday program, The Rooster Creek Show, from September, 1964.\nThe collection includes contributions from about thirty stations, including a 1954 recording of a half-hour program featuring the Ozark Playboys broadcast on KGBX, Springfield, and broadcasts by the Johnny Boys at the Cavalier Club in Kingdom City, aired on KWOS, Jefferson City that same year.\nMissouri’s oldest radio station, WEW in St. Louis, began broadcasting twice-daily weather reports for Missouri and Illinois on April 26, 1921. None of the material gathered so far goes that far back. While many national broadcasts exist because of transcriptions for later broadcasts, practical recording of local radio programming is rarely available earlier than the 1950s with the advent of affordable tape recording machines.\n“This growing collection adds to the State Historical Society’s massive collection of materials that will help generations yet unborn understand the personalities and events that have shaped and will continue to shape Missouri,” says Bob Priddy, retired broadcast news reporter and President of the Society. “We hope broadcasters, retired broadcasters, and the families of those whose voices are now silent forever will search through their closets and attics, contact the Missouri Broadcasters Association, and add to this important collection of the voices of Missouri.”\nHave some audio files to add to our collection? Contact Terry Harper, firstname.lastname@example.org to make your contribution.']	['<urn:uuid:4c3a0a5e-7094-482a-b6ce-f168c8704522>']	open-ended	direct	concise-and-natural	similar-to-document	single-doc	expert	2025-05-13T05:52:58.810667	9	43	721
49	I'm curious about how different art exhibitions handle international collaboration - what's the connection between Polish and French elements in Opałka's work compared to the international aspects of Skulptur Projekte Münster?	Roman Opałka had strong connections to both Poland and France - he was born in France to Polish parents, lived in both countries throughout his life, and became a French citizen in 1985 while maintaining his Polish artistic legacy. Similarly, Skulptur Projekte Münster demonstrated international collaboration by featuring artists from multiple countries, evolving from showing only male artists in its first edition to including a diverse international roster with almost half being women in recent editions.	['by Tobi MaierJune 12, 2017\nSkulptur Projekte Münster\nNow half a century old, the decennial public art exhibition Skulptur Projekte Münster has unquestionably grown up. The first exhibition featured only male artists while now almost half of the participants are women; a retrospective exhibition of Michael Asher’s photography at Skulptur Projekte Münster—the artist participated in every edition from its inauguration in 1977 to 2007—is taking place at the LWL-Museum für Kunst und Kultur; a series of newspapers (Out of Body, Out of Time, Out of Place) were published in the run-up to the opening; and a research publication on the history of the institution is scheduled for 2019.\nThe curators of this fifth edition—Britta Peters, Marianna Wagner, and co-founder Kasper König—have organized a non-thematic exhibition in 35 locations around Münster and the neighboring city of Marl. Add to that the 36 existing projects from previous editions—with works by Bruce Nauman, Claes Oldenburg, Donald Judd, and Rosemarie Trockel among them—and it is possible to trace a 50-year history of public sculpture, beginning with the placement of static monuments into the landscape and evolving to encompass digital media alongside participatory and performance art. While the monumental works mark the physical terrain, those of an ephemeral nature are lodged in the collective memory: this year’s press conference, for instance, took place at the Municipal Theater where, ten years ago, Elmgreen and Dragset staged their play Drama Queens about the history of modern sculpture.\nThe opening remarks at the press conference were followed by a short video introducing Michael Smith’s contribution, Not Quite Under_Ground (2017), a tattoo parlor for visitors aged 65 and over. With an aging population accounting for the majority of cultural tourism in the city, Smith invited friends and colleagues to design tattoos, thus expanding the number of artists participating in the show as well as the exhibition’s reach and legacy. This diffusion of images and messages via the bodies onto which they are indelibly inked might, indeed, mark the latest stage of Skulptur Projekte Münster’s expansion of the field of public sculpture.\nEi Arakawa’s Harsh Citation, Harsh Pastoral, Harsh Münster (2017), located in a field at the southern end of Lake Aa, consists of seven LED paintings based on works by Gustave Courbet, Nikolas Gambaroff, Jutta Koether, Joan Mitchell, Amy Sillman, Reena Spaulings, and Atsuko Tanaka. Reminiscent of billboards, the pixelated digital images are hung in Plexiglas frames the size of the original paintings. On their reverse, loudspeakers mounted on cardboard and dyed fabric play original compositions by Arakawa, Christian Naujoks, and Dan Poston. Rendered in a style akin to the lo-tech aesthetics of the electronic paintings, the lyrics of these songs (printed on labels beside the speakers) address the implications of the works’ dual existence as physical objects and digital images.\nA desire to disrupt the comfortable idyll of Münster can also be detected in the sculptural arrangement Sketch for a Fountain (2017) by Nicole Eisenman. Questioning normative concepts of body and sexuality, this queer Arcadia is situated on a park lawn and features five oversized bronze and plaster works grouped around a rectangular pool, alternately suggesting bohemian leisure and public disorder. Bárbara Wagner and Benjamin de Burca’s new film Bye Bye Deutschland (2017) is presented as a double-sided projection in the city’s iconic Elephant Lounge nightclub. The artists collaborated with local Schlager music singers Markus and Steffi, who perform songs by German folk musicians Helene Fischer and Udo Jürgens. While Markus is seen singing in the Preussenstadion, the camera follows Steffi into Rosemarie Trockel’s hedge sculpture on the shore of Lake Aa (Less Sauvage than Others, 2007), before she reappears to sing at the Botanical Gardens and finally in a duet with Markus in a local television studio. Weaving together oral history with documentary footage, the film benefits from its placement within an existing architecture of correspondingly kitsch aesthetics.\nAt the Public Library, behind the CD and gaming section, Gerard Byrne presents his new video installation In Our Time (2017). Set in the Reagan/Brezhnev era, it features a US radio anchorman delivering the weather forecast and introducing a music program. As the camera moves meticulously around his studio—capturing the details of his “Don’t Mess with Texas” mug and a band setting up for a live recording—the protagonist introduces his station: “CGBS, where you’re never more than one minute away from music—right here on the dial.” Exemplifying Byrne’s interest in music history, quotation, and interpretation, In Our Time is characterized by its unspecified duration. Different versions of the same studio program flow into one another, evoking viewers’ memories of radio listening.\nPierre Huyghe’s large-scale installation After ALife Ahead (2017) is situated in a former ice rink. By sawing open the concrete flooring, the artist has created a landscape of islands and valleys populated by peacocks and beehives, among other species. A culture of cancer cells is kept in a black box at one end of the hall, upon which the influence of the environment can be measured. An aquarium placed center stage contains an assemblage of concrete slabs resembling Caspar David Friedrich’s Das Eismeer (The Sea of Ice, 1823/1824), painted during a period of little success for the artist and alluding to failure. While the assemblage in the tank allegorizes political insecurity, ecological disaster, and apocalypse, perhaps it also creates the space for new beginnings.\nIn 1997 John Knight proposed modulating the streetlights in Münster’s city center to consider the relationship between institutional art and public life. His 2017 work, In Situ, consists of a spirit level attached to the façade of the recently renovated LWL-Museum für Kunst und Kultur. In the museum’s lobby, Nora Schultz has covered the marble floor with a pristine white carpet that will record the marks of its visitors. Also as part of Pointing their fingers at an unidentified event out of frame (2017) the artist has relocated Olle Baertling’s sculpture YZI (1969) from its iron plinth near Lake Marl and attached it to the museum’s staircase railings. Video projections at both ends of the foyer, meanwhile, show drone footage of the same space, its buzzing sounds echoing through the hall. In front of the museum, a collaboration between Cosima von Bonin and Tom Burr (Benz Bonin Burr, 2017) consists of a truck carrying a shipping crate parked beside a Henry Moore bronze, threatening its imminent removal. The scene is watched over by the Ludger Gerdes’s yellow neon Angst (1989), a timely analogy to Banu Cennetoğlu’s text piece Being Safe is Scary (2017), currently mounted above the entrance of the Friedericianum in Kassel as part of Documenta 14.\nMünster—a shopping paradise for a well-off white population, a clean, safe, green, and quiet Disneyland—is contrasted with the post-industrial decline of the nearby city of Marl. Founded in 1936, the city was made wealthy by coal in the mid-twentieth century and is now in decay, though its brutalist concrete architecture is preserved wherever possible. Having loaned works by Gerdes and Baertling from its museum collection to Münster, the city hosts pieces such as Richard Artschwager’s untitled bicycle stand monument, which was produced for the 1987 edition and is normally stationed in front of Münster Castle. Thomas Schütte has created a twin column for his famous, and recently relocated, Kirschensäule (Cherry Pillar, 1987). This watermelon in three slices is also sited—as the Münster original was—in a parking lot. Dominique Gonzalez-Foerster brings a selection of 11 miniature replicas of her Roman de Münster (2007) to the ground floor glass box at the Museum Marl, where they are installed in a formation corresponding to their original locations in Münster. Downstairs at the museum is an exhibition of models for realized and unrealized projects from the history of the Skulptur Projekte, combining works such as Mike Kelley’s Petting Zoo (2007) with lesser known proposals including a roomful of models for Friedrich Gräsel’s Gabelung von zwei Hauptrichtungen (Bifurcation of two main directions, 1969) and Modell einer Kreuzung (Model of a street crossing, 1969/1970).\nThe increased employment of video and performance at Skulptur Projekte Münster reflects a paradigm shift in the conceptualization of sculpture. Alexandra Pirici’s Leaking Territories (2017), displayed at the historic City Hall where the Treaty of Münster (1648) ending the Thirty Years War was signed, is a case in point. Its six performers situate the viewer in space and time by narrating the historical or geographical distance separating, for example, China’s expanding manmade island in the South Sea or the fall of the Warsaw Ghetto. The visitor is serenaded by their chants: Roam more, We’re on nowhere, emit time (in English), The perfect situation is one in which one transcends oneself (in Mandarin), and See the mystery of tomorrow (in Kurdish). Some of Pirici’s aphorisms inspire, while others fall flat.\nSkulptur Projekte Münster has over the course of its history reflected, and fostered, the transformation of sculpture as a medium. Its fifth edition is most effective where artists and organizers have installed works within context-specific architectures. This dialogue between work and site has resulted in an exhibition that continues to think about art historical developments while also opening up new possibilities of acting within the endangered public sphere.\n- 1Ei Arakawa, Harsh Citation, Harsh Pastoral, Harsh Münster, 2017, Meadow in front of Haus Kump. 7 LED strips on hand-dyed fabric, LED transmitter, power supply units, SD cards, transducers, cardboard, amplifiers, media player. LED paintings: 130 × 150 cm (Gustave Courbet), 193 × 128 cm (Nikolas Gambaroff), 190 × 250 cm (Jutta Koether), 188 × 280 cm (Joan Mitchell), 115 × 110 cm (Amy Sillman), 147 × 279 cm (Reena Spaulings), 194 × 131 cm (Atsuko Tanaka). © Skulptur Projekte 2017. Photo by Henning Rogge.\n- 2Nicole Eiseman, Sketch for a Fountain, 2017, Meadow alongside Promenade. Bronze, plaster, basin. Basin ca. 500 × 700 m, reclining bronze ca. 70 × 165 × 280 cm, standing bronze ca. 260 × 80 × 120 cm, seated plaster figure ca. 100 × 120 × 100 cm, reclining plaster figure ca. 50 × 120 × 320 cm, reclining plaster figure with water ca. 150 × 110 × 240 cm. © Skulptur Projekte 2017. Photo by Henning Rogge.\n- 3Bárbara Wagner and Benjamin de Burca, Bye Bye Deutschland! Eine Lebensmelodie [Bye Bye Germany! A Life Melody], 2017, Elephant Lounge. Video projection, 20:00 minutes. © Skulptur Projekte 2017. Photo by Henning Rogge.\n- 4Gerard Byrne, In Our Time, 2017, Public Library, Video, unspecified duration. © Skulptur Projekte 2017.\n- 5Pierre Huyghe, After ALife Ahead, 2017, former ice rink. Concrete floor of ice rink, logic game, ammoniac, sand, clay, phreatic water, bacteria, algae, bees, chimera peacocks, aquarium, black switchable glass, Conus textile, GloFish, incubator, human cancer cells, genetic algorithm, augmented reality, automated ceiling structure, rain. © Skulptur Projekte 2017. Photo by Ola Rindal.\n- 6John Knight, A Work In Situ, Façade of new building of LWL-Museum für Kunst und Culture. Carbon fiber, 365 × 13 × 33 cm. © Skulptur Projekte 2017. Photo by Henning Rogge.\n- 7Nora Schultz, Pointing their fingers at an unidentified event out of frame, 2017, foyer of the LWL-Museum für Kunst und Kultur. Plastic sheeting, carpet, 2 videos, sound, interference in the display panel. Integrated in the installation Olle Bærtling, YZI, 1969, on loan from the Skulpturenmuseum Glaskasten Marl. © Skulptur Projekte 2017, photo: Henning Rogge.\n- 8Cosima von Bonin + Tom Burr, Benz Bonin Burr, 2017, Forecourt LWL-Museum für Kunst und Kultur. Low-loader, wooden crate, safety ropes, variable dimensions. © Skulptur Projekte 2017, photo: Henning Rogge.\n- 9Thomas Schütte, Kirschensäule, 1987, © Skulptur Projekte 2017. Photo by Henning Rogge.\n- 10Thomas Schütte, Nuclear Temple, 2017, Former zoo grounds, behind music school. Mould, 8 mm steel sheeting, laser cut, welded, 250 x 300 cm. © Skulptur Projekte 2017. Photo by Henning Rogge.\n- 11Alexandra Pirici, Leaking Territories, 2017, Friedenssaal im Historischen Rathaus. Performers Beniamin Boar, Liliana Ferri De Guyenro, Montserrat Gardó Castillo, Susanne Grau, Susanne Griem, Jared Marks, Rolando Matsangos, Luísa Marinho Saraiva, Fang-Yu Shen, Tyshea Lashaune Suggs, Pia Alena Wagner, Andy Zondag. © Skulptur Projekte 2017. Photo by Henning Rogge.\n9TH BUSAN BIENNALE, Busan\nCONTEMPORARY ART GALLERY, Vancouver\nINGLEBY AND THE UNIVERSITY OF EDINBURGH, Edinburgh', 'Dire il tempo / Telling Time by Roman Opałka\n4 May 2019 – 20 July 2019\nRoman Opałka. Telling Time, a project curated by Chiara Bertola, is conceived and produced by BUILDING and Fondazione Querini Stampalia.\nAn exhibition in two parts: in Venice at the Fondazione Querini Stampalia museum and in Milan at BUILDING. Both exhibitions are centred on the OPAŁKA 1965 / 1-∞ programme, which the artist worked on for much of his life in an attempt to depict the passing of time and to circumscribe the infinite in visible and measurable forms. In Venice a nucleus of works by Mariateresa Sartori (Venice, 1961) – with whom the artist had formed an intense relationship in the city – will be presented. Interested in neuroscience, music and language, her works initiate a dialogue with Opałka’s, through their common research on the themes of time, duration and contingency, and the shared search for something visible capable of expressing the invisible. Dire il tempo / Telling Time springs from the desire to examine Roman Opałka’s work through a selection of works which are fundamental stages of his research, many of which have never been presented or exhibited in Italy before, coming from important private and public collections, including the Muzeum Sztuki in Łodź and above all the Fonds de Dotation Roman Opałka, with which a close relationship was formed during the ideation of the project.\nFrom 4 May until 20 July 2019, Roman Opałka, a Retrospective, the first chapter of this project, opens to the public in the Milanese spaces of BUILDING, which is setting aside all of its four exhibition floors to the exhibition. From 7 May until 24 November 2019, the second chapter, Roman Opałka. Mariateresa Sartori will run in the rooms of the Museum Home at the Fondazione Querini Stampalia in Venice, where the works of Roman Opałka and Mariateresa Sartori are placed in relation both to each other and to those of the institution’s historic collection. Both the Milanese and the Venetian chapters revolve around OPAŁKA 1965 / 1-∞, a project the artist dedicated much of his life to in the attempt to depict something immeasurable: the passing of time. Of particular importance for the critical awareness of the artist, the Venetian chapter reunites and presents for the first time two fundamental works for the entire OPAŁKA 1965 / 1-∞ programme: the first Détail, on loan from the Muzeum Sztuki, Łódź in Poland and exhibited for the first time in Italy, and the last, which remains unfinished, has never presented to the public and is on loan from a private collection. The Alpha and the Omega finally reunited. As the curator Chiara Bertola writes: “Seeing them together for the first time and being able to grasp the whole picture of what the artist had decided to trace one day is a strong and moving emotion. The project that is so explicitly shown also bears the tragedy of its very assumption: “He is no longer with us; there is the completed work”. Alongside these two important Détails is a series of photographic self-portraits and a sound recording of the artist’s voice, as well as two ‘exercises’, two ‘artist tests’ that Opałka made shortly before beginning his OPAŁKA 1965 / 1-∞ programme, which have also never been shown to the public before.\nOn 6 and 7 May 2019 Didier Morin’s film “Le dernier Detail peint de Roman Opałka” will be presented to the public for the first time. It depicts Opałka’s painting time, set to the rhythm of everyday life, in his atelier at Bois Mauclair, where everything turns sacred when the artist repeats out loud the numbers he is painting. The artist was filmed and recorded over approximately forty sessions while he was working on what would be his last Détail. “Le dernier Detail peint de Roman Opałka” duration: 225 minutes language: Polish, French, with English subtitles Screenings:\n- 6 May 11am first screening, 6pm second screening\n- 7 May 10am first screening, 2pm second screening\nIt is with these works that Mariateresa Sartori establishes a dialogue in the rooms of the Querini Stampalia Museum. As the curator highlights: “Her work provides the chance to create emptiness and new spaces of perception and understanding reality beyond pre-established meanings; it provides the entry key to new languages. Thanks to juxtapositions, deviations, superimpositions and intersections between different alphabets, Sartori’s work intercepts the subtle thread of relations which exist between nature and artifice, the epic and the everyday, visible and invisible, past and present, and objectivity and subjectivity, without ever being defined, always leaving the tension towards the infinite open… The purpose of all her research is about identifying the mechanism and the possible fragmentation in which the infinite seems to let itself to be harnessed. Above all, her work is about managing to represent the infinite in something finite, measurable and visible. Just as it was for Opałka…” In the site-specific installation Il tempo del suono. Onde / The Time of Sound: Waves on display here, the sheets of paper – individual particles of a wider totality – are recomposed on the wall in a single continuous series. The work, which translates the sound of the sea waves into a visual form, represents her attempt to listen to the passing of time and is the result of an immense musical score which codifies the sonorous and temporal flow.\nBefore reaching the room where the installation is housed, you walk down a long corridor where some self-portraits by Roman Opałka are placed in sequence. As you walk down the corridor you listen to the Polish sonority of the artist’s voice, which pronounces the numbers he is painting. These two different forms of representing infinite time resound contextually. Time is also etched in the two series of pinhole photos, Feuilles and Cronache. With a simple black cardboard box held together with sticking tape to make a pinhole camera, Mariateresa Sartori goes around gathering instances of the sensitive world, almost like evidence “that reality exists”. The results are the small images spread on the engraved table in the mythological room and those entirely covering the mirrors mounted in the stucco decoration of the museum boudoir. Cronache (Chronicles), the series of pinhole photos exhibited on the table in the museum’s mythological room, constitutes one of the site-specific works present in the exhibition. The subjects of the photos are isolated details taken from paintings found hanging in that room: the face of an elderly man with a beard, the head of a little dog, a child leave the narration of their own time and suddenly and dramatically become current to the eyes of the person observing them: facts of contemporary chronicle which each of us can find in our own personal memory. It is evidence of how the artist has managed to make the vision of paintings which risked no longer being seen and visible newly significant. This always happens with projects from the “Conserving the Future” programme: every time a contemporary artist relates to the past, the past demonstrates that it still has a lot to say.\nThanks to “Conserving the Future” another work present in the exhibition was made in 2008: Il suono della lingua, 11 audiobooks, which are now part of the museum’s permanent collection. The languages undergo an unusual process and are stripped of their meaning to assume another in terms of musicality, rhythm and melody. Once again the order that composes beauty is a question of rhythm, as is highlighted in another work in this exhibition in the Museum Portego: Tutti quelli che vanno / All Those Who Come. Two graphics but also two magnificent and enigmatic drawings which represent the flow of people walking around St Mark’s Square in Venice at a precise time. This cycle of drawings arises from an association with a research group from the University of Bologna which studies pedestrian flows from a physicalmathematical viewpoint. Finally, in the wardrobe room of the boudoir, the video Omaggio a Chopin / Homage to Chopin is screened, about which there was an important exchange between Mariateresa Sartori and Roman Opałka regarding a crucial point. The video is dedicated to Roman Opałka, who died before he could see it with the formal solution that he had suggested. “Both of these artists,” writes Chiara Bertola, “has created a system, invented a metaphor, a new code, a mechanism, a model, in order to get closer to and brush up against the infinite. The emotional dimension has always allowed them to translate arid scientific data into something universal and broader, reminding us that although we move around in our small everyday space we do so withinimmeasurable spatial and temporal coordinates.”\nBorn 27 August 1931 in Hocquincourt, France, to a family of Polish origin. The Opałkas returned to Poland in 1935, to then be deported to Germany in 1940, where they remained in a work camp until the end of the war. Once freed, they returned to France to then return finally to Warsaw, where Opałka attended the graphic design school Wałbrzych Nowa Ruda (1946-1948) and the art and design school in Łódź (1949). Between 1950 and 1956 he studied at the Warsaw Academy of Fine Arts and in 1957 he moved to Paris. In 1966 he held his first solo show at the Galeria Dom Artysty Plastyka in Warsaw. The following year he began the OPAŁKA 1965 / 1 – ∞ project, which he would dedicate the rest of his life to from 1970. Opałka would thus become inextricably linked to conceptual art. Between the 1960s and 1970s he won numerous prizes: the Grand Prize at the First British International Print Biennial, Bradford (1968), two awards at the seventh International Biennial Exhibition of Prints and the Art Museum Ohara, Tokyo (1970), and first prize from the Polish Ministry of Culture and Arts (1971). In 1972 he went to the USA for the first time. In 1979 he moved to Bazérac, in France, and won a prize at the fourteenth Biennale of San Paolo. In 1985 he became a French citizen. Between 1985 and 1990 he taught at the Summer Academy of Salzburg. In the following years Opałka would exhibit on numerous occasions and receive various prizes, such as the National Painting Prize, Paris (1991), and the Special Prize from the Polish Ministry of Foreign Affairs in Warsaw (1996). In 1992 he had an exhibition at the Musée d’Art Moderne de la Ville de Paris and in 1995 he represented Poland at the Venice Biennale. In 2002-2003 a large travelling anthology of his work would visit various European cities. In 2009 he was awarded the title of Chevalier des Arts et des Lettres in Paris, and the Gloria Artis Gold Medal in Warsaw. Opałka died in Chieti on 6 August 2011.\nBorn in Venice in 1961 where she lives and works. He research revolves around three thematic fulcrums: empirical scientific method; behavioural dynamics, often in relation to neuroscience; music and sound in relation to language.\nThe educational aspect is important to her artistic practice: she has taught drawing for over a decade, applying the Betty Edwards Drawing with the Right Side of the Brain method, which is based on the same neuroscientific presuppositions which inspire her own artistic research. The artist often works in association with experts in the fields she explores: geologists, theoretical physicists, musicologists, musicians, singers, actors, botanists, ornithologists. Concrete data is empirically revealed and then analysed from perspectives which vary from work to work and which have different outcomes, from video to drawing, from pinhole photography to sound work. Constants and not exceptions, the universal and not contingencies drive her research, which is aimed at a clearly unattainable objectivity. She has exhibited in numerous museums and galleries in Italy and abroad in personal and group shows: Cairn Centre d’art, Digne les-Bains, France; MMOMA, Moscow Museum of Modern Art; Palazzo Fortuny, Venice; Museum of the Russian Academy of Fine Arts, Saint Petersburg; Fondazione Bevilacqua La Masa, Venice; ICA,\nThe Showroom, London; NGBK Berlin; Hangar Bicocca, Milan; Macro, Rome; Neue Galerie, Graz; Palazzo delle esposizioni, Rome; Mucsarnok Hall of Art, Budapest; Careof, Milan; Folkwang Museum, Essen; Fondazione Querini Stampalia, Venice; Auditorium Parco della musica, Rome; Museo di Palazzo Poggi, Bologna; Serra dei giardini della Biennale, Venice; XLV Venice Biennale; Museo Mambo, Bologna; Kunsthaus Centre d’art Pasquart, Biel, Switzerland; the Hermitage Museum, Saint Petersburg; Les Ateliers d’artistes, Marseille.\n7 May 2019 – 24 November 2019\nFONDAZIONE QUERINI STAMPALIA, Castello 5252, Venice']	['<urn:uuid:36bfd8fc-adb8-4716-b026-ca0f401e640d>', '<urn:uuid:df7ce01e-bb5b-4f76-bdfe-ffd56f70224e>']	factoid	with-premise	verbose-and-natural	similar-to-document	comparison	novice	2025-05-13T05:52:58.810667	31	76	4091
50	what is sacha lodge amazon facilities and what threats face indigenous territories nearby	Sacha Lodge is a self-sufficient eco-lodge in a 5,000-acre preserve with 26 private rooms, featuring raised walkways, spacious rooms with hammocks, and facilities for wildlife viewing including a canopy walk and Kapok Tower. The lodge faces threats from oil companies that cut roads into the forest creating access for poachers. Similarly, indigenous territories in the Amazon face threats from commercial mining, with existing mining requests covering 176,000 km2 of indigenous lands, which could affect up to 15% of indigenous territories if new mining bills are approved.	['I leaned back on the comfy seat of a canoe shared with five other travelers in the magical maze of canals at Sacha Lodge in the Ecuadorian Amazon basin and watched a troop of squirrel monkeys overhead. With death-defying leaps they sprang from branch to branch forming a super highway through the tropical foliage. Bets were taken on who would become the first to have a monkey land on their head as the creatures peered at us with the comical faces of a curious child. After four days of total immersion in the rain forests surrounding the lodge, I felt I was a part of the scene.\nThis adventure begins in Coca, a gritty oil town where the Coca and Napo rivers collide and proceed to the mighty Amazon River. A motorized canoe awaited us on the banks of the Napo, the main artery in the region. On the way to the lodge about three hours downstream, we passed barges carrying heavy equipment to oil depots and locals in canoes fishing as they have done for thousands of years. Children waved to us as we passed remote villages tucked in the impenetrable sea of green foliage. We hiked on a boardwalk through a flooded forest to Pilchicocha Lake, aka the Black Lagoon, where canoes and guides were waiting. After a serene glide over the lake lined with rhododendron leaves as big as elephant ears and reeds where Caiman (a member of the alligator family) lurk, we arrived at the miracle of Sacha Lodge.\nNestled in a 5,000-acre preserve, this Robinson Crusoe fantasy made from local wood covered in a shaggy palm roof and staffed by 65 indigenous workers, is totally self-sufficient. The lounge upstairs overlooking the lagoon is cooled by most-welcome fans after a session of hiking in equatorial heat. Raised walkways lead to spacious rooms with open beam, wood floors, and inviting hammocks on the deck. There is nothing but a screen between you and the wild mish-mash of jungle trees and plants that are home to millions of thrumming insects, barking tree frogs, clicking cicadas, and the sharp whistles of birds that make up the chorus that intensifies as night draws nigh.\nAn early rise increases your chances of spotting some of the 600 species of birds counted at the lodge as well as other wildlife. Forest walks are the classroom for naturalist guides who point out medicinal properties in plants and how they were used by “the people.” They explain the symbiotic relationships between plants and insects that have evolved over the ages. Our guide carried an iPod downloaded with calls to attract the mot mots, toucans, and many more birds, while he talked to other creatures in their language trying to draw them near.\n“Friends, look at this mandible ant,” our guide Marco said as he pointed to a stream of insects on the jungle floor. “He can be used to suture wounds. Just let him clamp the wound with his mandible and then pinch off his head.”\n“Friends, you see the kapok tree? This one is centuries old. He is the tallest tree of the jungle. If he were to be cut down it would take hundred year for the forest floor to recover. His canopy provides shade for the plants below. Competition for light and nutrients is fierce in the rain forest.”\nLike Jack on the beanstalk, we climbed up a giant wooden stairwell wrapping the kapok tree. A drenching rain set in before we reached a viewing platform above the protective canopy. We stood atop what must be the 9th wonder of the world with our heads tucked into the hood of our ponchos waiting for the weather to change. Soon, blue skies opened over the platinum Napo River. Pink flamingo hues softened gray layers of clouds. Shafts of light streamed down upon the primal forest and mist began to rise from the verdant green canopy of the forest below. Orange, crimson, and yellow blooms that rest on the crown of trees brightened the scene. Birds begin to stir once again. A flock of toucans flew swiftly by and the droplet song of the industrious weaver bird was heard. The sun set with a tender sigh in soft pastels as we left our perch and canoed home through the tranquil channels to the lodge and another fabulous meal.\nHealthful salads of shredded cabbages, carrot, tree tomatoes, and avocado served with a tangy lime dressing were just a few of the choices. Entrees include tender beef in a peppercorn sauce, chicken, pork and tilapia fish prepared with a unique seasoning known only to our native chef. Wonderful desserts like strawberry mousse, caramel flan, exotic fruits, and walnut cakes were served buffet style in the lodge.\nOn our night canoe, the heavens opened wide with a neon crescent moon hanging in a crackling sky. Marco pointed out different constellations with his powerful green laser. The glide around the lake in splendid silence looking up to the southern sky listening to the serenade of the cicadas and frogs is a treasured memory.\nThankfully there are no radios or televisions, no boom boxes, no leaf blowers or car alarms at Sacha. The promise is that the lodge will build more exciting features like the longest (1,000 ft.) and highest (120 ft.) canopy walk unique to Ecuador, the Kapok Tower, and trails that enable people to experience the forests in an intimate way. They will not, however, add to the 26 private rooms ensconced in green. This spectacular eco-lodge exists because of the dream of Arnold Ammeter, more commonly known as Benny. He purchased the land surrounding the black water lagoon in 1991 and began construction of the now famous lodge. It will remain a very special place if it is protected from encroachment of oil companies that cut roads into the forest creating access for poachers and inevitable spills that threaten the entire Amazon basin. www.sachalodge.com\nIF YOU GO: Cafe Cultura, a boutique hotel in Quito situated walking distance to a farmers market and art in the park, is a perfect place to rest from a long flight. A charming restaurant with tasty selections, a welcoming study, and gracious hosts make this a comfortable safe haven. The staff arranged for an English-speaking guide who took me on a tour of Old Town, a UNESCO World Heritage site, which recently received a 250-million-dollar facelift. They also made arrangements for the driver waiting for me at the new Quito Airport.\n- Cambria: The Toast of the Central Coast - Jun 2018\n- Gateway to Adventure in the Chile Lake District - Apr 2018\n- Hot Spots on the Highway 1 Discovery Route on California’s Central Coast - Jun 2017\n- Into the Wilds of Africa - Sep 2016\n- Sublime St. Croix-the Gentle Virgin Island- Linda Ballou - Jan 2016\n- Pa’ia-Gateway to Adventures on Maui - Mar 2015\n- Nature’s Bounty in the Columbia River Gorge and the Mt. Hood River Valley-Oregon - Aug 2014\n- Saddle Up in Ecuador - Apr 2014\n- Sacha Lodge, Ecuador – It’s a Jungle Out There - Mar 2014\n- My Way On The Hana Highway - May 2013', '“The Brazilian Amazon has the highest concentration of indigenous peoples in the world. Recently, the Brazilian government sent a bill to Congress to regulate commercial mining in indigenous lands.”\n“This work analyzes the risks of the proposed mining bill to Amazonian indigenous peoples and their lands. To evaluate the possible impact of the new mining bill, we consider all mining license requests registered in Brazil’s National Mining Agency that overlap indigenous lands as potential mining areas in the future. The existing mining requests cover 176 000 km2 of indigenous lands, a factor 3000 more than the area of current illegal mining. Considering only these existing requests, about 15% of the total area of ILs in the region could be directly affected by mining if the bill is approved. Ethnic groups like Yudjá, Kayapó, Apalaí, Wayana, and Katuena may have between 47% and 87% of their lands impacted. Gold mining, which has previously shown to cause mercury contamination, death of indigenous people due to diseases, and biodiversity degradation, accounts for 64% of the requested areas. We conclude that the proposed bill is a significant threat to Amazonian indigenous peoples, further exposing indigenous peoples to rural violence, contamination by toxic pollutants, and contagious diseases. The obligation of the government is to enforce existing laws and regulations that put indigenous rights and livelihoods above economic consideration and not to reduce such protections.”\nThis abstract comes from a study out of the Environmental Research Letters Journal published on October 9th, 2020. We encourage you to read the full article by clicking below.\nFollow Director Todd Moen as he journeys into the Kayapo Territory to discover the Kayapo Project’s sustainable enterprise with Untamed Angling\nIs there a way for us to get a glimpse of paradise on Earth without drastically altering its nature, without destroying it forever? A small Kayapo community which lives along the banks of the Iriri river might have the answer. Deep in the heart of the Menkragnoti Indigenous Territory, in one of the most isolated settlements of the tropical world lies Kendjam. A small village established only in 1993 by chief Pukatire who brought his followers away from the destructive influences of alcohol and the extractive industry with the goal to create a deeply traditional community.\nPukatire was once quoted as saying, “we only need the white man for three things: eyeglasses, flip-flops and flashlights”. And while he feels as strongly about preserving his people’s traditional lifestyles as he did when he founded Kendjam, he is now embracing a new sustainable model that can benefit his people without compromising the natural world upon which they depend. Today, thanks to a partnership between Associacao Floresta Protegida (Kayapo NGO), Untamed Angling and several Kayapo communities, outsiders can visit the rainforest in a way which is respectful to the environment and equitable towards the indigenous hosts. Instead of jeopardizing the traditional way of life of the communities, the project aims at further bolstering the pride the Kayapo take in their way of life, in their ancestral wisdom and profound knowledge of the surrounding environment.\nYou don’t need to travel to the heart of the Amazon in order to get an idea of what it is to be in the heart of the Amazon rainforest. Whether you’re interested in fly-fishing or not, this brilliant short documentary produced by Todd Moen, a filmmaker affiliated from CatchMagazine, will take your spirit far from the confines of your modern life and will give you a glance of a world and a culture that have managed to survive despite all the mounting threats.\nI hope that watching this video gave you a better sense of how important it is for us to do whatever we can to protect this jewel of biodiversity and traditional culture. Without their rivers, but more importantly, healthy rivers, the Kayapo would not be able to have access to the healthy fish stocks and other resources that their protected lands offer them generation after generation.\n“We want to tell the kubẽ (white men) to listen, to respect our rivers, our forests, our land for where there is mining it gets worse for us because we can get sick. The relatives who live where there is gold mining are already sick. There is a lot of mercury contamination, even fish. That’s why I don’t want to mine in my village”. – Oro Muturua (Kayapó leader)\nIf you want to help the Kayapo in their fight for the protection of these pristine waters from the poisonous pollution of gold mining consider supporting their fundraiser. The funds will support the establishment of two guard posts in order to further the protection of Kayapo’s border entrances at the shores of the Iriri and Xingu rivers.\nThe Spirit of Survival – Written by: LINDSAY RENICK MAYER from Global Wildlife Conservation Original Blog\nKayapo Indigenous People Call on World to Help Protect Amazonia Against Extractive Industry, Brazilian Government\nThat was how the Kayapo Indigenous people approached the illegal goldmining camp that had, for months, been destroying part of the Amazon rainforest, home to countless animals and plants, and polluting the nearby river in the Kayapo’s ratified territory of Bau.\nAs 17 Kayapo came upon the camp in mid-October, after traveling for two days by boat and then by foot, any noise would have been drowned out anyhow by the goldminers’ hydraulic machines. Their actions resulted in the peaceful removal of the trespassers from the land, which was accessible to these outsiders only by plane, and the complete dismantling of the camp.\n“The area the goldminers destroyed is very large and the streams are badly damaged,” said Bepmoro-I, from the village of Bau located in Bau Indigenous Territory. “It’s awful there. But we blocked off the airstrip and so now the streams and forest will begin to recover. If goldminers come back, we will go and remove them again.”\nKayapo wait with goldminers from the illegal “Novo Horizonte” illegal gold mine in the Kayapo Bau territory. The air strip supplied their camp and here the goldminers wait to be picked up by their employer.\nThis is not the first time the Kayapo have had to remove invaders from 23 million acres of their rainforest and savanna territory in the southeastern region of the Brazilian Amazon, an area the size of the state of Virginia. For more than 40 years, the Kayapo have fought off many outsiders looking to exploit their natural resources. They have done so with the partnership of multiple NGOs, including Conservation International, Environmental Defense Fund, and GWC partner, the International Conservation Fund of Canada.\nThe removal of the goldmining camp came against the backdrop of a Brazilian Federal Government that has been considering a bill this year that would effectively legalize goldmining and other extractive industries in Indigenous territories across Brazil. This marks the latest in an onslaught of threats to Brazil’s Indigenous People’s cultures, lives and land, and to the wildlife and ecosystems that they protect.\nA Message to the World\nThe Kayapo are anything but silent against the congressional bill, Proposed Law 191/2020, that could significantly weaken protection of Amazonia, and they want the world to know what is going on.\nMore than 6,000 Kayapo from 56 communities of the Bau, Capoto/Jarina, Kayapo, Las Casas and Mekragnoti Indigenous Territory, the Indigenous organizations Associação Floresta Protegida, Instituto Kabu and Instituto Raoni recently published a declaration expressing their opposition to the bill.\n“How could we be in favor of such an activity that profoundly negatively impacts our environment, society and communities?” the letter asks. “How could we deprive our children and grandchildren of a vital territory that supports our livelihoods, autonomy, customs and traditions, as guaranteed by the federal constitution? We appeal to all Brazilians and international society to support our struggle to protect our forest and demand that the government respect the federal constitution and our right to use our territories according to our customs; as well as the right of all people to an ecologically balanced environment.” [READ THE FULL STATEMENT FROM THE KAYAPO]\nBrazilian President Jair Bolsonaro introduced the proposed law in February of 2020 to open up demarcated territories to the extractive industries of mining, oil and natural gas. Two other proposed laws would have similar devastating effects: one aimed at the establishment of a general environmental licensing law, which would essentially allow industry to easily obtain licenses for environmentally damaging extractive activities easily—even through self-declaration (PL3729/2004); and another that would grant amnesty to invaders and in essence encourage deforestation and land-grabbing (PL 2633/2020).\n“I have long admired the great courage of the Kayapo and their undying commitment to protecting their traditional lands, ever since I first visited them in 1991 with Barbara Zimmerman to help her establish her long-running program to work with these amazing people,” said Russ Mittermeier, GWC Chief Conservation Officer, who has visited the Kayapo lands and other parts of the Xingu region a number of times over the past three decades. “If the Brazilian government opens indigenous territories such as those of the Kayapo and their neighbors to legal goldmining and logging, this could signal a death knell for the magnificent forests of Amazonia and the great and wonderfully diverse Indigenous Peoples who call it home. The vast forests of Amazonia are critical to the health of our planet, and the Kayapo and their fellow indigenous peoples are its most important guardians.”\nWe Won’t Give Up’\nThe Kayapo protect more than 2,000 kilometers of heavily threatened borders around their territory. Kayapo land represents the last large block of forest in the southeastern Amazon and stores an estimated 1.3 billion metric tons of carbon. It is hard to understate the critical importance of the Amazon rainforest—one of the world’s five designated High Biodiversity Wilderness Areas and home to one-quarter of Earth’s terrestrial biodiversity—to the health of the planet, and the critical role that the Kayapo and other Indigenous communities play in protecting it. An estimated 20 million Indigenous people from more than 350 Indigenous groups call the forests of Amazonia home and depend on their natural habitats and resources for their livelihoods and culture.\n(Photo by Antonio Briceno)\nYet the forests of Amazonia continues to come under serious threats. Deforestation in 2019 and 2020 was the highest it has been since 2008 and represents a doubling in forest loss over 2012. Amazonia has experienced some of its worst fire seasons in the last two years, a result of previous deforestation, primarily for the expansion cattle ranching and cattle feed crops (soybeans), leaving a drier local microclimate. The fires themselves are often purposely started to clear land for agriculture, mostly cattle and cattle feed for export to the United States, EU, China and other countries.\n“The Kayapo face today face what Native America Tribes faced in the mid-1800s: an infinitely more numerous and better armed capitalist society building along their borders and slavering to devour their land no matter the law,” said Barbara Zimmerman, director of the Kayapo Project for the International Conservation Fund of Canada and the U.S.-based Environmental Defense Fund. “The difference is timing: in the 21st century there exist indigenous rights, international media, the internet and NGO Indigenous allies. We are about to see whether these factors help the Kayapo to save themselves and a vast tract of Amazonia forest upon which their culture and livelihoods are based. If the Kayapo can win, if they can hold out, then I think that anything can be achieved in the conservation of our planet.”\nFor the Kayapo, beating these bills, which the Brazilian Congress could vote on as early as February, and continuing to protect the forests of Amazonia is going to depend on the willingness of the rest of the world to help safeguard this irreplaceable place. But no matter what, the Kayapo say that they are not going to give up.\nPhoto by Cristina Mittermeier\n“We won’t stop doing this work. We won’t give up. We are going to keep fighting,” Bepmoro-I said. “We would like the entire world to see our effort, the work of the Kayapo people to protect our land and our culture—and help us with the resources we need to continue protecting our land and rivers.”\nYou can help. Make a donation to the Kayapo Fund today at Kayapo.org']	['<urn:uuid:1cd44e1a-2810-4a4c-a755-276cddf085c3>', '<urn:uuid:15310b56-8748-49a6-97fa-fe7fd816c150>']	factoid	direct	long-search-query	similar-to-document	multi-aspect	novice	2025-05-13T05:52:58.810667	13	86	3242
51	How can we practice forgiveness in daily life?	We can practice forgiveness by following the HEAL approach: identifying our Hopes that weren't met, Educating ourselves that hopes may have different opportunities, Affirming positive intentions to grow from negative experiences, and making a Long-term commitment to wellbeing. Additionally, as taught in the parable, we should remember how much we've been forgiven ourselves and extend that same mercy to others, focusing on love and care rather than dwelling on past hurts and mistakes.	['This lesson is the five in a nine part study for children on the parables of Jesus. For related ideas, search our website for “Parables of Jesus.”\nLesson Five: The Story of the Unforgiving Servant\nMain idea: As citizens of the Kingdom of Heaven, we forgive others their debt against us since Jesus forgave our debt against him.\n- Read Scripture references, James 2:13, Luke 17:3-4, Ephesians 4:32, Matthew 6:14-15\n- Gather: Bible; dry erase markers or chart paper and markers; various balls for the game; print this handout for each child; crayons, markers, and colored pencils; scissors\n- Take time to meditate on this week’s Scripture and think about your own life. Do you keep in mind the great debt you have been forgiven and allow that to encourage you to forgive others?\n- Optional Forgive our Sins coloring page\n- Matthew 18:21-35\n- 1 Corinthians 13:5\n- Mark 12:31\n- Colossians 2:13-14\nGame: How Many Times?\nAsk the children how many times they can do various tasks. “How many pushups can you do? How many times can you bounce a ping pong ball on a paddle? How many times can you bounce a hacky sack off your knee? How many free throws can you score in a row?” Have the children attempt these tasks. Ask if anyone can complete these tasks 490 times in a row without messing up. Let them try. The point of the game is to show that it is nearly impossible to do something 490 times. This idea ties in with today’s lesson. The exact activities you do don’t matter, as long as they get the wiggles out of the kids and show them how hard it is to do something 490 times.\nBible Lesson Message:\nOpen in prayer, then say, This is our fifth week learning all about the parables. As you remember, parables are stories Jesus told to teach us important lessons about the Kingdom of Heaven. From them, we learn what Heaven is like, what God is like, and what we should do as citizens of Heaven. We learned in the Story of the Soils that the message of the Kingdom of Heaven will be received differently by different people. In the story of the Wheat and Weeds and the story of the Fishing Net, we learned that when Jesus returns, he will separate those who believe in him from those who don’t, so it’s our job to tell everyone about his love. We learned that even the little things we do make a big difference in the Kingdom of Heaven in the Story of the Mustard Seed and the Story of the Yeast. In the Stories of the Hidden Treasure and the Pearl, we learned that the Kingdom of Heaven is worth more than anything in this world. The parables remind us that we represent the Kingdom of Heaven, we represent Jesus, everywhere we go in the world. In today’s parable, we will study one characteristic of citizens of the Kingdom of Heaven. We will learn one way that we are supposed to behave as Christians. Follow along with me as I read from Matthew 18:21-35.\n21 “Then Peter came to him and asked, “Lord, how often should I forgive someone who sins against me? Seven times?”\n22 “No, not seven times,” Jesus replied, “but seventy times seven!\n23 “Therefore, the Kingdom of Heaven can be compared to a king who decided to bring his accounts up to date with servants who had borrowed money from him. 24 In the process, one of his debtors was brought in who owed him millions of dollars. 25 He couldn’t pay, so his master ordered that he be sold—along with his wife, his children, and everything he owned—to pay the debt.\n26 “But the man fell down before his master and begged him, ‘Please, be patient with me, and I will pay it all.’ 27 Then his master was filled with pity for him, and he released him and forgave his debt.\n28 “But when the man left the king, he went to a fellow servant who owed him a few thousand dollars. He grabbed him by the throat and demanded instant payment.\n29 “His fellow servant fell down before him and begged for a little more time. ‘Be patient with me, and I will pay it,’ he pleaded. 30 But his creditor wouldn’t wait. He had the man arrested and put in prison until the debt could be paid in full.\n31 “When some of the other servants saw this, they were very upset. They went to the king and told him everything that had happened. 32 Then the king called in the man he had forgiven and said, ‘You evil servant! I forgave you that tremendous debt because you pleaded with me. 33 Shouldn’t you have mercy on your fellow servant, just as I had mercy on you?’ 34 Then the angry king sent the man to prison to be tortured until he had paid his entire debt.\n35 “That’s what my heavenly Father will do to you if you refuse to forgive your brothers and sisters from your heart.”\nLet’s start with the conversation that takes place just before this parable. Peter asks Jesus how many times he is supposed to forgive someone who sins against him, who does something wrong to him. Peter guesses that seven times should be enough. It seems like a strange number to pick out, doesn’t it? It also seems like a lot of times to forgive someone when they keep sinning against you. Imagine you are playing soccer with a group, and your best friend keeps stealing the ball from you. You hardly get to play because they are being such ball hogs! But every time your best friend steals the ball, he at least says he’s sorry. I don’t know about you, but by about the third or fourth time that happens, I don’t think I would want to play soccer anymore. What do you think? (Give students a moment to share. They will surely come up with their own experiences of slights and grudges that they should keep in mind for the rest of the lesson.\nRemind them not to share names or specifics, as that would be gossip and would hurt another’s feelings.) Peter probably thought he was being very generous by saying he could forgive someone seven times. A lot of Rabbis, who were the Jewish religious teachers at the time, said that it was plenty to forgive someone three times. Most people in Jesus’ time thought that if you forgave someone three times and they still wronged you, that you would not have to forgive them. So with that in mind, Peter’s guess that forgiving someone seven times seems awfully kind. But Jesus has a different idea of what forgiveness looks like. How does Jesus respond to Peter in verse 22 of Matthew 18? (Allow a student to respond.) Jesus says we must forgive them seventy times seven times! Let’s do a little math to figure out exactly how many times that is. (Work out this multiplication problem briefly on the board, or have the older students figure it out.)\nSeventy times seven is 490! Now that is a lot of times to forgive someone. Think of our story of playing soccer with our friend, or a time in your own life where someone kept sinning against you and hurting your feelings. Can you imagine forgiving them 490 times? In our game, it was nearly impossible to do any task 490 times in a row. It’s not likely we could forgive someone 490 times and still be kind to them and not be bitter or angry with them.\nBut do you think that is really what Jesus means? Do you think he really wants us to forgive people exactly 490 times, and then we stop forgiving them? I don’t think so.\nFor one thing, that would be really hard to keep track of. I would have to keep a little notebook with people’s names in it, and little tally marks for every time I forgive them. (Demonstrate tally marks on the board.) Jesus does NOT want us to do this. The Bible tells us in 1 Corinthians 13:5 that love keeps no record of wrongs. As Christians, we love everyone. Jesus told us in Mark 12:31 that we are to love our neighbor as ourselves. So if we love everyone, and keep no record of wrongs, then we shouldn’t be keeping tally marks of the number of times we forgive someone, should we? That is literally keeping a record of the wrong things they do against us.\nSo if Jesus does not want us to literally forgive 490 times, what do you think he means? (Allow a student to answer.) Jesus gives this really big number for two reasons. One is to tell us that we should forgive endlessly. We can’t keep record of wrongs, we can’t tally up the number of times we must forgive. We cannot keep track of the number of times we forgive. We must keep forgiving and forgiving and forgiving, no matter what, even if it means forgiving more than 490 times! The other reason he gives us such a big number is to tell us that we cannot forgive endlessly on our own. We need Jesus to help us forgive. So Jesus sets up this parable, the Parable of the Unforgiving Servant, by telling us that we must forgive endlessly.\nNow let’s look at the parable itself. There are three main characters. Who can tell me who they are? (Allow students to answer.) That’s right, we have the king, the servant who owed the king a big debt, and the servant who owed the first servant a small debt. (Write these characters on the board.) The king decided he wanted to settle his accounts. This means that he wanted everyone who owed him money to pay him back. So he calls in this one servant who owes him A LOT of money. the original language says this servant owed the king ten thousand talents. This was a type of currency used at the time. One talent was equal to about 6,000 denarii. A denarii is what a worker got paid for one day of work. So I did the math on this one and to pay off his debt to the king, this servant would have to work every day for 164, 383 years. So obviously, this man owes the king a debt that cannot be paid. Does that sound familiar? Let’s think of this parable in spiritual terms. Who does the king represent? (Allow a student to answer.) That’s right, the king is God. (On the board next to “king,” write “God.” And who is the servant who owes the king a big debt? (Allow a student to answer.) Yes, we are the servants who owe the king a big debt. (On the board, write “us” next to “servant who owes the king a big debt.”)\nNow of course we haven’t borrowed money from God. The debt we owe is not financial, it is not material. The debt we owe God is spiritual. Let’s have a sword drill to see what the Bible has to say about our debt to God. Take your fingers and bookmarks out of your Bibles and hold them over your head. When I say go, look up Colossians 2:13-14. Go! (Read, or have a student read Colossians 2:13-14.) “13 You were dead because of your sins and because your sinful nature was not yet cut away. Then God made you alive with Christ, for he forgave all our sins. 14 He canceled the record of the charges against us and took it away by nailing it to the cross.” These verses tell us that we have a record of charges, or a list of things we owe God. We owe him because we sinned against him. Our sin has separated us from God, and we need to be made right with him. The problem is, we can never pay back our debt to God. Romans 6:23 says, “For the wages of sin is death.” Thankfully, Jesus died in our place and paid our debt to God. So Romans 6:23 goes on to say, “but the free gift of God is eternal life through Christ Jesus our Lord.” Since Jesus has paid the debt that we owe God, we can have eternal life. We are free from the costs of sin, from the debt that we can’t ever pay! How should this make us feel? (Allow students to answer.)\nWe should be grateful, and very, very happy! How do you think the great debtor in our story should have felt? He should be grateful and very, very happy too! Is that what the story says, though? Nope.\nWhat does the debtor who owed the king more than he could ever pay do after being forgiven his huge debt? (Allow a student to answer.) Our parable says he went out to a fellow servant who owed him a much smaller amount and violently demanded that he pay the debt. This fellow servant owed 100 denarii, which is 100 day’s worth of work. When compared to the 164, 383 years worth of work the first servant owed the king, a few month’s worth is practically nothing. Who, spiritually speaking, is the servant who owed the small debt? (Allow a student to answer.) He’s anyone who owes us anything. (Next to “the servant who owed the small debt” on the board, write “others.”) Of course I don’t just mean people who owe us money. The fellow servant is the person who did something wrong or hurtful to us, and they owe us an apology.\nIs it easy to forgive people who do wrong to us? Of course it isn’t. That is why we need Jesus to help us forgive.\nThe end of this parable is a tough warning. What happened to the servant who owed the king an unpayable debt, after the king discovered he was unwilling to forgive his fellow servant? Matthew 18:34 tells us, “the angry king sent the man to prison to be tortured until he had paid his entire debt.” As we said, this man can never pay this debt. That means he will spend the rest of his life being tortured, all because he would not forgive as he had been forgiven. Jesus goes on to say in verse 35, “That’s what my heavenly Father will do to you if you refuse to forgive your brothers and sisters from your heart.” If we don’t forgive people, it means we deserve the punishment of hell. Now let’s be clear here. We are still sinners. Sometimes we will mess up and not forgive people. This DOES NOT mean we will go to hell. If we believe in Jesus and do our best to follow him, then we will go to Heaven. Forgiving others is not a way to earn a place in the Kingdom of Heaven, it is evidence that we have a place in the Kingdom of Heaven. As citizens of the Kingdom of Heaven, we forgive others their debt against us since Jesus forgave our debt against him.\nEnd in prayer.\nCraft: Mini Book (Download here)\nEvery week, students will make a mini book that retells the parable in very basic terms. This fifth mini book in their library reminds the kids how to forgive like citizens of the Kingdom of Heaven. To begin, demonstrate how to fold the book. Fold along the solid lines. Start by folding the long side to the long side. Crease well. Keep it folded, then fold in half, crease well, and fold in half again, creasing well. Now unfold it all the way and fold it in half short side to short side, so the dotted line in the center is folded in half. Cut along this dotted line. Do not overcut! Now unfold the paper and fold it in half again, this time long side to long side. Now for the tricky part. Pinch both short ends of the paper, with the crease facing up. Bring your hands together, causing the cut in the middle of the paper to open up. You should have a plus sign now. The last step is to press all the pages down so the cover is on top. Mush the pages down and crease all the folds. You may need to use a marker or pencil for these creases, as they are all now stacked up on each other. Now that you have a little book, have the kids write their name on the cover. Read each page and have the children illustrate it accordingly.', 'Written by: Frederic Luskin, Ph.D. and Daniel E. Martin, Ph.D.\nIn a competitive and often vindictive society, the opportunity for being hurt, mistreated and injured remain high. Holding on to real or perceived slights creates bitterness, resentment, and sadness which take their toll on physical and mental health. Research on forgiveness interventions has shown them to reduce blood pressure, the experience of pain, anger, depression and stress and lead to greater feelings of self-efficacy, optimism, hope, compassion and ease.\nWhat is Forgiveness?\nForgiveness is a rich word, with varied descriptions and definitions over time and culture. While many exist, for the purposes of the Stanford Forgiveness Project – SFP (Dr. Luskin is the founder and co-director), we define forgiveness as the experience of peace and understanding that can be felt in the present moment no matter what has happened in the past. In this context, we are the only ones who can remedy a situation in which life threw us a curve; which caused us to get upset because what happened was not what we wanted to happen. We got lied to when we wanted the truth. We got abandoned when we wanted care. Forgiveness reminds us we hold the keys to being assertive and creating peace in the present, no matter how recent or long ago a painful experience occurred.\nLife often unfolds in a chaotic way, and it’s our unmet expectations about the way it should play out that create much of our suffering. All of us have been in situations where our well-intentioned plans have gone array, be it as a student and not getting the grade, we believed we deserved, a job candidate believing we were the right person for the job and not getting it, an employee seeking a promotion and not getting it, or a life partner finding out it is over, or the patient, getting a terrible diagnosis. Life can be very challenging, and we are here to say it is our continued and often escalating objection to not getting what we want that causes emotional, social and physical pain.\nForgiveness is the resolution of this objection, it’s making peace when you didn’t get what you want and letting yourself move forward. Forgiveness doesn’t justify cruelty, nor is it to forget that something painful has happened, or even reconciliation with an offender. It is the choice to accept, the making of peace with our full lives that helps to take back power, lose the victim identity and control negative feelings.\nMaking Choices and Moving On:\nReflecting on life’s capriciousness the question becomes how strongly and for how long do we want to suffer and how much do we want to make choices that may lead to more peace and ease. For example, as a parent if someone hurts your child, you are going do everything and anything possible to minimize that harm. Afterwards as we process the threat and fear, we often end up with resentment towards the person who did the harm.\nThis blame and negativity is normal, and can be helpful. We must care for ourselves and those we love through chaotic and difficult life situations, and this requires analyzing what went wrong, who did the harm and how that can be stopped, Unfortunately, we often get stuck in blame and negativity, and go off into the maladaptive. We tell everyone we can about how unfair what happened to us (and the ones we love), then label that person as evil as they caused us to suffer. We ruminate about the experience, thinking about what should have been the outcome, building more and more resentment and creating in our minds our victimhood. This creates a negative feedback loop and can create patterns that can be hard to break. Forgiveness reminds us that after the initial helpful reaction of outrage, anger or pain, we have over time the increasing choice as to how long we suffer and whose responsibility our healing is.\nDr. Luskin’s work has led to many successful interventions in his book Forgive for Good, but one powerful approach from the Stanford Forgiveness Project is the mnemonic HEAL: This is practiced as guided imagery.\n- H for Hope – What did we hope for, as a positive outcome that didn’t occur (Example: I wanted a new job to better support my family).\n- E for Educate – Educate oneself that Hopes may not be achieved in a specific fashion, but also (growth mindset) that each Hope may have several opportunities. (Example: I understand that not all candidates get every job they want, but there are more opportunities out there to apply to).\n- A for Affirm positive intention. Holding on to grievances connect us with those who have hurt us in a powerless fashion. Affirming our intention to grow and prosper reminds us that we can grow and learn from negative experiences (Example: I will review my applications, resume, join and interact with relevant associations while asking for help in my pursuit of my goal).\n- L for Long term commitment to one’s own well-being. Understanding that we might slip back into rumination of our grievance, this commitment reminds us to revisit the previous steps and continue to pursue our goals (Example: Yes! I got a new job, and it is going well, but I am still looking for something more meaningful and lucrative to support my family. I will continue to try my best and have patience. It may take a bit of time, but I am working in my own behalf.\nVulnerability allows for love and loss:\nIf we were afraid all the time, protecting ourselves from hurt, there would be no safe space for love. The free will that allows us to make mistakes allows us to pursue life’s happiness. The basic choice of trusting enough to love even though we may get hurt is one of life’s most important decisions.\nWe often review the grievances we have built up over life, and dwell on others poor treatment of us, or our own mistakes. Dwelling on losses and mistakes is an option. So is to dwell on acts of goodness and love. Think of the people who have loved you, supported you, cared for you, educated you. When you do, you connect with an unbelievable source of care and love. Remembering that each time those folks chose to be kind, chose to do the right thing and chose to love they made a decision. If we dwell too much on the bad choices people made its hard to remember how often and deeply people chose to love and care for us. Ultimately, we all have a regular decision to make: to forgive the past, so we can focus on what is good in our present.\nThe Stanford Forgiveness Project and Brightsity are happy to announce the application of the SFP to the Brightsity platform.\nRecognizing and Managing Exceptional, Average and Underperforming Individuals\nHow to Follow Your Financial Playbook To Victory\n3 Ways to Build Mental Toughness\nThe Four Ingredients of Great Customer Experience\n5 Sales Tips to Break Through the Clutter\nThe Plight of the Long-Term Unemployed and How to Overcome It\nWhat High-Converting Landing Pages Have in Common\n4 Ways to Boost Your Motivation at Work\nEntering Into the Sales Evolution Showroom\nMillennials and Responsible Investing: Bridging the Generation Gap\nLearn9 hours ago\nMillennials and Responsible Investing: Bridging the Generation Gap\nSocial Selling9 hours ago\nIs Spending Piles of Money on Marketing Just a Waste?\nBuilding Smarter Portfolios9 hours ago\nUnderstanding Hedge Fund Replication\nInsights2 days ago\nLeaders: How Your Audacious Goal Can Actually Hurt People\nDevelopment2 days ago\nDiscouraged? Remember Why You Got in This Business\nFinancial Podcasts2 days ago\nWhat to Expect this Holiday Season According to the National Retail Federation\nDevelopment3 days ago\nA Better Way to Seek Referrals\nBehavioral Intelligence3 days ago\nHuman Behavior Is Predictable, Markets Are Not']	['<urn:uuid:3173f4aa-ec99-48c5-9b51-becae58605bd>', '<urn:uuid:3d42c2d0-ad70-4670-956c-df5866793e0a>']	open-ended	direct	concise-and-natural	similar-to-document	multi-aspect	novice	2025-05-13T05:52:58.810667	8	73	4119
52	Can you explain the recommended process for sending a cease and desist notice to stop collection agency harassment, including the specific delivery methods and essential content?	To send a cease and desist notice, it is advisable to send a notarized letter using a certified mail service. The letter should include basic details like your name and phone number. Once the collection agency receives this notice stating they shouldn't contact you, they can only communicate through legal proceedings. If the agency continues to harass you after receiving this notice, you have the right to file a lawsuit against them.	"[""A collection agency, also referred to as a debt collection agency, is a third party recovery unit, employed by financial institutions with the sole aim to recover their money from the debtors. A collection agency hires individuals, often referred to as debt collectors, to remind or persuade the debtors to fulfill their obligations.\nAt times, the methods used are outright annoying or even harassing. In such cases, most debtors suffer this unnecessary harassment. What we, as consumers, fail to understand is that we don't have to undergo this harassment, as the Fair Debt Collection Practices Act, a law constituted to ensure fair debt collection, has provisions to stop it.\nFair Debt Collection Practices Act (FDCPA)\nIt is the most formidable legal weapon you can use to stop collection agency harassment. The Act is intended to wipe out unethical or abusive practices of consumer debt collection and promote fair debt collection practices.\nIt covers important points which state that upon receiving a written notice from the consumer, stating that he/she will not pay the debt and at the same time, does not wish to communicate with the agency any more, the collection agency should cease trying to communicate with the said consumer by any means other than legal proceedings.\nThe Act also states that the collection agency shouldn't call the consumer frequently with the intention of annoying or harassing him, and should cease communicating with the consumer at his/her workplace after being advised that it is prohibited.\nWhat Amounts to Harassment?\nHarassment can be mental (calling during odd hours) or physical (using violence). Even threatening by offensive language, claiming to be law enforcement officers, confronting the consumer at odd hours, at odd place, causes harassment. Consumers should know legal issues and acts protecting their rights to stop being harassed by the collection agency.\nHow to Stop Such Harassment?\nThe foremost thing you will have to do is, send a cease and desist notice to the collection agency. According to the federal law, once the collection agency receives the notice on your behalf, clearly stating that they shouldn't contact you, they can't communicate with you by any other means except for legal proceedings.\nIt is advisable to send a notarized letter, using a certified mail service. Make sure that the basic details, like your name, phone number, etc., are properly covered in the letter. If the collection agency persists to harass you with unnecessary calls or confrontation, you can go ahead and file a lawsuit against them.\nWhat About Collection Agency Calls?\nIn this case, you can send them a cease and desist letter stating that they must stop calling you, and instead, can communicate through mails or legal proceedings. If you still continue to get calls after this, you are recommended to record your conversation with the collection agent.\nThis recorded conversation will act as an evidence of the collection agency violating the law. Politely request the collection agent to stop calling you. Mention about the cease and desist letter you sent to the agency. If required mention the relevant points from the Fair Debt Collection Practices Act.\nThis will send across a strong message about your seriousness in dealing with harassment that you are experiencing.\nYou need to understand that these are ways to deal with collection agencies, not to avoid the debt you owe to them. While they stop annoying you to repay the debt, you can try to come up with a debt settlement agreement with them. Being aware of the various legalities related to the issue can help you keep harassment at bay and stay out of trouble.""]"	['<urn:uuid:61929a33-ee2a-446a-80b1-b78aa23fd635>']	open-ended	direct	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-13T05:52:58.810667	26	72	601
53	nmma advocacy strategy invasive species prevention trade associations activities impact analysis	The boating industry's advocacy efforts combine multiple approaches to address issues like invasive species. NMMA has increased its federal advocacy resources and adopted a more aggressive approach, hiring additional staff in Washington D.C. and defining the industry's agenda proactively. Various marine trade associations focus on local issues, with organizations like the Michigan Boating Industries Association working specifically on stopping aquatic invasive species in the Great Lakes. Prevention and education are critical strategies, as demonstrated by programs like Wisconsin's Clean Boats, Clean Waters, which uses volunteers at boat launches to inspect equipment and prevent species transfer. The combined advocacy efforts have proven effective, with the industry's economic impact reaching $170 billion and becoming a recognized force in Washington.	['Advocacy across the boating industry is in a good place these days, with marine trades, corporate advocates and nonprofits all lobbying on issues that we either oppose or, more often recently, support.\nThe recent passage of the Modern Fish Act was a good example of combining old-school lobbying by a coalition of boating and sportfishing associations with mass action alerts that showed our congressional representatives the industry was paying close attention to the issue.\nModern Fish is the poster child of what the industry can accomplish when it works together. It also may be the signature legislative achievement of the last five years.\nAnd it’s just one of dozens of issues, big and small, that the industry is facing across the country.\nThe NMMA, which has become the industry’s de-facto lobbying arm on federal issues, has adopted a more aggressive approach to advocacy based on activism. It is now defining the industry’s agenda and actively pursuing it with legislators, rather than reacting to bills or regulatory challenges. More offense, less defense.\n“Our end goal is to at least be part of the conversation,” says Nicole Vasilaros, who heads up NMMA’s advocacy efforts. Or as NMMA president Thom Dammrich puts it: “If you’re not at the table, you’re on the menu.”\nThe trade association has increased resources for advocacy, hiring additional staff in Washington, D.C., for communications and state issues. Boating has become a recognized force in Washington, touting its bipartisan status as a “uniquely American industry,” as NMMA puts it, with an economic impact of $170 billion.\nBeyond federal issues, marine trades associations around the country are busy with local issues: Lake Erie Marine Trades Assocation is working on the potential hazards of wind turbines on Lake Erie; Rhode Island’s MTA has been busy with Clean Marina and zero-plastics programs. Northwest Marine Trade Association has its hands full with a NOAA guidance on the Endangered Species Act that could damage its $4 billion industry. The International Yacht Brokers Association helped draft a bill allowing sales of foreign-flagged vessels to U.S. buyers.\nIn Fort Lauderdale, the Marine Industries Association of South Florida tasked itself with improving visa access for non-U.S. yacht crews. The Texas Marine Industry Coalition wants a tax cap on boat sales so its marine businesses can compete with other states. Michigan Boating Industries Association is involved with stopping the spread of aquatic invasive species on the Great Lakes as well as educating new legislators on the industry’s importance to the state economy.\nThe list goes on and on.\nBeyond the marine trades, corporate advocates such as Veronica Floyd of Brunswick Corp., David Slikkers of S2 Yachts and Martin Peters of Yamaha spend much of their lives communicating with legislators on industry issues. Yamaha, in particular, has been integral to sportfishing legislation (for example, Modern Fish) that benefits the industry as a whole.\nGroups you probably don’t know anything about are also involved in old-school advocacy. The Lakes Environmental Association in Maine was launched in 1970 with a mission to restore the “traditional character of Maine’s lakes” by improving water quality. The nonprofit started out with a single lake, decimated by discharges, and within two years its research prompted legislators to do a statewide ban on phosphate detergents.\nNearly a half-century later, LEA provides comprehensive water testing for 40 Maine lakes. It also leads the fight against the spread of such invasive plants as milfoil and other aquatic invasive species. Beyond successfully lobbying for the strongest anti-milfoil laws in the country, LEA has established “wash stations” manned partially by volunteers.\n“The milfoil is moving around by boats,” says LEA executive director Colin Holme. “Volunteers serve as inspectors at boat ramps, but part of our mission is to get boaters to understand the problem, so they can inspect their own boats. They need to realize that non-natives like milfoil will ruin their lake experience.”\nDozens of other local groups lobby for every possible issue that impacts boaters.\nTechnology has also become an important tool for smaller associations like the Northwest Marine Trade Association. Peter Schrappen, vice president and director of government affairs, uses a program called VoterVoice to send alerts to members if he wants them to contact state legislators.\n“We’ve made it easy for them to engage because the process can be overwhelming,” he says. “If we want to reach one legislator on a committee, I can contact 10 of my most important members. If it’s a big issue, we can get all 735 members engaged.”The service is affordable, Schrappen says, especially considering its impact. He also has editorial control over the messages. “Some responses on issues like salmon runs, which has to do with tribal rights, can get racist, so I’m able to control what legislators read,” Schrappen says. “One bad message could impact a campaign. We’ve also found we don’t need a lot of people, but the right people.”\nOld school meets new school. It’s a good time to be an advocate — through a trade association or your own business — and have a measurable impact on industry issues. The tools have never been more accessible or easier to use.\nThis article originally appeared in the April 2019 issue.', 'Aquatic invasive species (AIS) are an economic and environmental danger that threaten all water bodies, and the St. Croix River is no exception.\nInvasives are defined by federal law as species that are non-native to an area that are likely to cause harm to the economy, environment, or human health. The St. Croix River already hosts populations of species such as Asian carp, banded mystery snails, and curlyleaf pondweed, each of which was likely introduced by humans.\nWhen introduced to a foreign ecosystem, invasive species tend to flourish due to a lack of natural predators or disease controls, and often crowd out native species as they take over food sources and space.\nVery often, once established, there is very little to be done to eradicate them.\n“The problem is that these invasive species are so good at adapting to these environments that…we often don’t have the people or resources to stop them,” said Trevor Cyphers, a fisheries biologist with the U.S. Army Corps of Engineers.\nEducation and prevention, therefore, are often just as important, if not more so, than restoration of already-infested ecosystems.\nOne particular invader that gets a lot of attention is the zebra mussel (Dreissena polymorpha). This small, freshwater mussel typically grows only two inches long at most, yet can become a massive problem in lakes and slow-moving rivers due to its ability to create a lot of offspring very quickly.\nByron Karns, Acting Chief of Resource Management for the St. Croix National Scenic Riverway, a unit of the National Park System, said that the ecological damage of a zebra mussel infestation fits many of the common patterns of an invasive species. Once in an area, their populations explode, and they quickly begin to overwhelm niches normally occupied by native species of mussel.\nThe zebra mussels will outcompete other mussels for food and space, and sometimes smother the natives by latching onto them and preventing them from moving, feeding or reproducing properly.\nZebra mussels can also cause economic damage.\nA good example is Bass Lake in St. Croix County, Wisconsin. Bill Holmberg is a resident living on the edge of the lake, which was diagnosed as infested with zebra mussels in 2010. Ever since the invasion, the local residents have had to deal with the economic consequences.\nBiofouling, or the accumulation of zebra mussels on surfaces put in the water, is a notable example.\n“The biggest issue for owners like myself is they cover everything you put in the water,” Holmberg said.\nBoats are less of a problem because they’re usually removed from the water before the microscopic mussel larvae, or veligers, have a chance to latch on. Docks, however, are oftentimes heavily coated since they remain in the water for the entire season, and any water that gets trapped within the motor of a boat when it’s tipped back might also contain larvae waiting to anchor themselves and clog up the system.\nOther, less obvious problems have arisen from the infestation at Bass Lake. Residents with sprinkler systems that draw from the lake have to invest in special filters to keep the mussels out. Such a filter might cost nearly $100, but to go without is to risk losing the entire sprinkler system and spending $5,000 on a new one.\nThe sharp, dead shells can also be a safety hazard to anyone walking barefoot on a beach, and the pump system normally used to keep the water level of the lake from overtaking nearby properties cannot be turned on for fear of spreading the mussels to other water systems.\nZebra mussels have already made their way into the St. Croix River, but so far they have not progressed north of Stillwater. Nor can they, without help from humans.\nKarns said that due to the method by which zebra mussels reproduce (spewing veligers into the water and allowing them to drift with the currents), they typically can’t move upstream on their own. To move up a river or from lake to lake, zebra mussels hitch rides with boaters or fishermen transporting water. Livewells, bait buckets and boats filled with water from an infested water body might contain microscopic veligers, which have the potential to become an entirely new infestation if released into an otherwise clean environment.\nPrevention, Karns said, is the most effective way to address this problem.\nA zebra mussel infestation, once it takes root, cannot be eradicated from an entire lake or river. Manual removal is impossible due to the veligers. Chemical treatments like copper sulfate and Zequanox can be effective in small, contained systems, but run into problems like cost and the risk of harming native wildlife when applied to an entire lake or section of river.\n“There’s no such thing as a whole lake treatment,” Karns said.\nMultiple natural resource organizations have mobilized efforts to prevent further spread of zebra mussels and other aquatic invasive species.\nWisconsin’s Clean Boats, Clean Waters program is one such effort operating within the St. Croix River watershed. The program organizes groups of volunteers and employees to serve as watercraft inspectors, and posts them at boat launches to remind people to inspect their equipment for plants and animals and to not transport water or live bait.\nControlling aquatic invasive species as a whole, Karns said, is going to require a combination of methods. Restoration of already-infested areas is an important aspect of the process, but oftentimes more important is education and prevention.\n“I think in some respects it’s something you have to have buy-in from the public,” he said. “Education is critical, in the beginning especially.”\nThe Bass Lake Rehabilitation District, in response to its infestation, has been implementing methods to educate people and prevent the further spread of zebra mussels. The 2016 Bass Lake Management Plan included a section on AIS, and a DNR grant has allowed them to purchase a camera for their boat landing that not only monitors for boats with AIS, but also serves as a reminder for people to inspect their equipment.\n“Be diligent in the prevention,” Holmberg said. “If there’s a public access…don’t just educate the users, try to educate the public in general.”']	['<urn:uuid:e6f5a957-9def-4e4e-afb4-bed49009f768>', '<urn:uuid:f30eb84a-f6b9-490e-8ded-93c658a09c4a>']	open-ended	with-premise	long-search-query	similar-to-document	three-doc	expert	2025-05-13T05:52:58.810667	11	117	1884
54	what equipment did surveyors use canada us border	The surveyors used 60-foot Gunter's chains, theodolite survey telescopes, air levels, sextants, compasses, and synchronized chronometers, which was top-of-the-line equipment for mid-Victorian field science.	['On a map, a border is a thin, black line—a scribble of ink delineating where the jurisdiction of one nation ends and another begins. It is a final thing: negotiated, tweaked, surveyed and marked. Blood was spilled along every international boundary in the world. When the fighting finished, more died trying to get to the other side.\nAcademics call either side of a new boundary a “borderland,” where the line is vague and populations on both sides are still interconnected. As the border becomes more defined and enforced, it evolves into “bordered lands”—where movement and commerce are restricted. What was once a singular region becomes two, and both sides develop individual identities, economies, and cultures.\nAmerica’s borders exist somewhere between these two. In the north and south, they are a place of commerce, a smuggler’s haven, a barrier that divides families and communities. U.S. borders become political pawns to politicians looking to control their constituency, bargaining chips in international trade deals, the object of threats to neighboring countries that do not bend to the desires of a leader.\nCollected here are seven books that discuss two things often left out of border discussions: land and people. The land could not care less what lines are drawn across it. It will always retain its own geological, climactic, and ecological borders (that outlast anything drawn by man). As for the people, many were living along the line before it was ever considered—some for thousands of years before newcomers arrived and divvied it up.\nThe books below tell these stories. They are real narratives about the way things really are along the boundary, not what they look like on a map.\nAll the Agents and Saints: Dispatches from the U.S. Borderlands by Stephanie Elizondo Griest\nTravel Writer Stephanie Elizondo, a native South Texan, researched Mexican revolutionaries, Spanish conquistadors, ranchers, Texas Rangers, and entrepreneurs in her portrait of the Rio Grande Valley. Then she compared it with another ethnic group displaced by a border: the Mohawks of the Awkwesasne Nation on the U.S.-Canada border. The story of the two vastly different regions and communities shows some striking similarities—like the way that ill-conceived treaties stole their land, how children were forced into English-only schools, and how entrepreneurs led the charge to take over their land. The result is a disturbing examination of how much of the U.S. came to be and how the original residents of this borderland continue to be oppressed.\nChamplain’s Dream by David Hackett Fischer\nTo see what life was like in North America before borders, read David Hackett Fischer’s masterpiece. Fischer travels in Champlain’s footsteps from Brittany to Nova Scotia, recounting the great, somewhat unknown explorer who inadvertently drew the first thousand miles of the U.S.-Canada Border. Champlain’s meticulous journal is the basis for much of the story and follows the Frenchman into battle against Mohawk armies, down death-defying whitewater on the Saint Lawrence River, and on foot farther inland than any white man had before. Champlain’s ease and lasting friendship with Native American chiefs throughout speaks to his humanist faith and fortitude. Following him into the wilds of interior America—all the way to the Great Lakes—the reader begins to understand America before it became America.\nThe Line Becomes a River: Dispatches from the Border by Francisco Cantú\nFrancisco Cantú once worked for the U.S. Border Patrol. His mother was a park ranger and also the daughter of a Mexican immigrant. While on duty, he was stationed in remote regions of the southwest border to watch for smugglers and illegal immigrants. Some died trying to cross; others were taken into custody. The job haunted Cantú and after an immigrant friend disappeared over the border—traveling to Mexico to visit his dying mother—and didn’t return, Cantú realized that he had to write about it. It is clear that the border is in his blood as he describes violence, injustice, and the brutal landscape of America’s southwest boundary. One of the more shocking revelations is how far that violence and injustice reaches into both nations, well beyond the line.\nWolf Willow by Wallace Stegner\nWallace Stegner’s memoir about growing up along the U.S.-Canada border in Montana is a portrait of the borderland, set sometime between when the line was drawn and when people started actually observing it. Stegner lived in an abandoned dining car near the Canadian Pacific Railroad as a child. In the summer, his family moved to a shack right on the boundary to farm wheat on what was then an honest-to-God no man’s land. “The first settlement in the Cypress Hills country was a village of métis winterers,” he writes. “The second was a short-lived Hudson’s Bay Company post on Chimney Coulee, the third was the Mounted Police headquarters at Fort Walsh, the fourth was a Mountie outpost erected on the site of the burned Hudson’s Bay Company buildings to keep an eye on Sitting Bull and other Indians who congregated in that country in alarming numbers after the big troubles of the 1870’s.”\nThe Crossing by Cormac McCarthy\nNo border reading list is complete without at least one volume from Cormac McCarthy’s trilogy. His raw and insanely detailed descriptions of the landscape and people on both sides of the border make you nostalgic for the age when the accuracy of your six-shooter determined how far north or south you could range. As the young Billy Parham trots south, with a wounded wolf in tow, McCarthy writes, “[they] crossed sometime near noon the international boundary line into Mexico, State of Sonora, undifferentiated in its terrain from the country they quit, and yet wholly alien and wholly strange.” A teacher I once had put his finger on McCarthy’s descriptions of the borderland: “He knows the names of things.”\nArc of the Medicine Line: Mapping the World’s Longest Undefended Border Across the Western Plains\nby Tony Rees\nYou rarely hear about how borders were drawn. Tony Rees’s meticulously researched Arc of the Medicine Line tracks the British and American surveyors, astronomers, axemen, soldiers, cooks and laborers as they haul sixty-foot Gunter’s chains, theodolite survey telescopes, air levels, sextants, compasses, and synchronized chronometers—top-of-the-line equipment for mid-Victorian field science—more than a thousand miles along the U.S.-Canada border. The Northern Boundary Commission of the mid-1800s, dressed Hudson’s Bay Company hooded greatcoats, moccasins, and sealskin pants, fought off mosquitoes, extreme heat, thunderstorms, and prairie fires while painstakingly making their way across the northern plains. Much of the border ran straight through Sioux territory, making British surveyors, who had never had any problems with the Sioux nation, terrified of being mistaken for American invaders. Sioux scouts were uninterested in the bearded and bespectacled foreigners and three years later the American commission’s 140 horses, 38 wagons, and 270 tons of supplies reached their destination: a limestone pyramid on Montana’s Mount Akamina that marked the end of the known border reaching east from the Pacific.\nBorder Contraband: A History of Smuggling Across the RioGrande by George T. Díaz\nStories about mobsters running booze over the border tend to focus on the forested northern fringe of the U.S. But there were bootleggers in the south during Prohibition as well. Tequileros delivered tequila from distilleries in Mexico to many southwestern towns and cities. Most of the runners were men, but there were a few women as well. The Texas Rangers infamously targeted (and murdered) hundreds of tequileros before they were taken into custody—a harbinger of the violence that would continue along the southern border. This book offers an interesting perspective into the first days of smuggling across the bushland of the U.S.-Mexico border, along some of the same back trails that smugglers use today.']	['<urn:uuid:d9471bdf-e93d-4a81-a620-36f57d0c41bf>']	factoid	with-premise	short-search-query	similar-to-document	single-doc	novice	2025-05-13T05:52:58.810667	8	24	1272
55	Who directed more French operas, Dave Brailsford or Gilbert Blin?	Gilbert Blin has directed several French operas, including Massenet's Werther for the Opéra de Nancy, Delibes's Lakmé, and various Baroque operas. Dave Brailsford is not mentioned as having directed any operas, as he was focused on cycling as British Cycling's performance director.	"['13 July 2007 Bourg-en-Bresse Tour de France Stage Six\nAfter an incredible solo breakaway, Bradley Wiggins emerges to claim his first podium on the Tour de France. Riding for Cofidis, Wiggins earns the prize for the day\'s most aggressive rider having spent virtually the whole stage out in front only to be reeled in at the end by the peloton. It proves his credentials on the Tour and Dave Brailsford [performance director of British Cycling] confirms his vision that a clean British rider could win the Tour within five years.\nAn hour later, with the dust settling on the stage and the finish area being noisily dismantled by members of the Tour\'s vast travelling army of workers, Brailsford sits in a bar and reviews the day. While his companions drink beer, he orders mineral water. ""I\'m in training,"" he explains. ""I\'m riding l\'Etape du Tour [a stage of the Tour, the popular mass-participation ride] with Shane [Sutton].""\nUntil now, Brailsford, though he has become a familiar figure at track cycling events, has not been a regular visitor to the Tour de France. But there\'s a good reason for that: it falls outside his remit. Three years earlier he had inherited [British Cycling\'s] track-focused programme known as the World Class Performance Plan, devised by his predecessor, Peter Keen. As Brailsford sits down in Bourg-en-Bresse he can reflect that Keen\'s World Class Performance Plan is exactly a decade old; what he cannot see, other than in his wildest dreams, is that in 13 months it will come to glorious fruition at the Beijing Olympics.\nSomething else is afoot here, however, and it has nothing to do with Beijing, and it has nothing to do with track cycling. Brailsford appears to be looking beyond all that, to some distant, imagined horizon. You can see it in his piercing blue eyes; they blaze with enthusiasm and sparkle with the excitement of a child catching a first, thrilling glimpse of … well, of the Tour de France.\nAs he outlines his dream, his enthusiasm intensifies; in fact, the plan seems to be progressing rapidly and taking shape in his imagination right here, under the large canopy of a tree, just outside a bar in Bourg-en-Bresse.\nThere have been several catalysts, says Brailsford, which all add up to ""a critical mass"", or a tipping point. ""That was a good effort from Brad today,"" he says. ""Good to see him having a go.""\nBut Wiggins\' big day out had been the icing on the cake – or the cherry on the icing on the cake. A few days earlier, Brailsford and a million or so others had been in London for the Tour\'s first Grand Départ on British soil. The Tour had got under way with a prologue time trial around the British capital, passing the Houses of Parliament, Buckingham Palace and Hyde Park, before, the next day, a road race stage took them to Canterbury along roads lined the entire way with spectators. It had been extraordinary – a weekend in which you\'d have been forgiven for thinking that London was cycling\'s spiritual home – and which prompted Christian Prudhomme, the Tour director, to eulogise London and Britain in a way that no Frenchman had done since Napoleon III. ""I do not know when we will come back,"" said Prudhomme. ""But one thing is certain: it is not possible for us not to return.""\nYet Brailsford feels that something even more significant than the London Grand Départ is brewing. Five British riders are riding – the biggest British participation since the last British team to ride the Tour, the ill-fated ANC-Halfords squad, took part in 1987. And among those five riders are two highly promising youngsters, Mark Cavendish and Geraint Thomas.\nThis has got Brailsford thinking. Twelve months after watching the then 19-year-old Cavendish win a gold medal at the World Track Championships in Los Angeles, Brailsford and Sutton [British Cycling\'s head coach] found themselves at the Commonwealth Games in Melbourne. It being the Commonwealth Games, at which riders compete for the home nations rather than for Great Britain, Brailsford and Sutton were not as occupied, or under as much pressure, as they\'d usually be during a major championship. They spent a fair amount of time sitting together in the stands, watching Cavendish win another gold medal on the track, this time for the Isle of Man, and they discussed the future. They cast their minds back to the Manchester Commonwealth Games in 2002, and forward to the Delhi Games in 2010. In between, of course, were the Olympics. But a sense of repetition, of being locked into a cycle of major games, was evident. Because that is the limitation of track cycling: it\'s all about the major games and world championships; there is no velodrome-staged equivalent of the Tour de France or Giro d\'Italia, or Tour of Flanders or Paris-Roubaix.\nThese road races are the monuments of the sport; where the history, the prestige and the money is. ""We were thinking,"" Sutton said later, ""that we can\'t keep doing this forever. We\'ve got to do something different.""\nThe conversation went no further. But 10 months later, back in Los Angeles for a track world cup meeting, Brailsford and Sutton once again found themselves with time to kill, and again they began to project beyond Beijing. Ironically, this owed to a stroke of misfortune for one of the latest of the talented young British riders to emerge, Ben Swift. Swift had been due to ride the madison with Rob Hayles, but he crashed and broke his collarbone. ""Shane and I had a lot of time on our own and a lot of time to chat,"" Brailsford said, ""and we inevitably got to talking about future plans.""\nAnd so to Bourg-en-Bresse, and the bar in which Brailsford is sipping water as the late afternoon turns to evening. What is always most striking about Brailsford is his enthusiasm; his shoulders hunch, and he cups his hands in front of his face, then he moulds those hands into constantly shifting shapes as he talks. ""I was inspired by London,"" says Brailsford, ""but this is something I\'ve been thinking about for a long time, and I feel that the time\'s coming for a British pro team.""\n""Here,"" he clarifies. ""In the Tour de France. From a personal point of view, if someone asked me what I wanted to do next, that would be it. We had a gut feel that Cav [Cavendish] and Geraint would come through at this level, but thinking it and seeing it are two different things. When I saw Geraint leave the start house for the prologue in London it was that moment of realising that it\'s not just something we\'re thinking about. I see Cav and Geraint now and think: it\'s on.""\nBrailsford outlines how such a team could work, in particular with regard to funding. Because what he\'s talking about would need serious backing, with a sponsor able and willing to pump millions into the project. ""The type of partner we\'d be looking for would be British. It would be a British initiative.\n""We\'d be all about innovation and about doing it clean. In the first instance it would be about being competitive: that\'d be our aim. But ultimately you\'d want to win. You wouldn\'t run a pro team if you didn\'t want to win. It wouldn\'t fit our mentality not to aim to win.\n""The money? It\'s difficult to be clinical about it, but there\'s a huge amount of money floating around the City, and a very small circle of people managing a huge amount of money. If you\'re in that circle … it\'s not finding money that\'s the obstacle. I don\'t think so. I mean, all the teams here are investing between £3m and £8m a year. It\'s a shed load of money, and they\'re all committed for four years, but if there weren\'t decent returns on that, they wouldn\'t be doing it, would they?""\nBut how would Brailsford do it? Would he combine running a Tour de France team with his current job, as British Cycling\'s performance director? ""It\'d have to be done as a private enter-prise – or as part of the governing body, which would be a first,"" he says. ""No other governing bodies run a pro team. But not many countries have the kind of funding structure for elite sport that Britain has.""\nOne of the reasons for Brailsford being here at the Tour, he explains – and apart from riding l\'Etape du Tour in a few days\' time – is to negotiate some of the British riders\' contracts. He is almost, it seems, acting as their agent, which is curious. But this too has highlighted a problem – or an opportunity. The problem is that the riders are contracted to, and under the control of, teams that operate independently of British Cycling, and with fundamentally different – even opposed – priorities.\nThey are not, for example, remotely interested in the Olympics.\nWhich is a problem for Brailsford, and a frustration. The riders in question, with Cavendish and Thomas to the fore, have been nurtured and developed by British Cycling.\nBrailsford wants to bring them back under an umbrella that he is holding. ""The lads here know I want to do this [set up a pro team] and they\'re all absolutely mad for the idea,"" says Brailsford. ""I\'m here negotiating their contracts for them; so I know what\'s in their contracts. And I know – or I\'m learning – how the teams are structured and how they operate.\n""We\'ve got a set philosophy about doing things at British Cycling,"" he continues, ""with the riders at the centre. But look at a lot of teams here at the Tour – that\'s not how they operate. Between races they don\'t even see their riders. They don\'t know where they are, never mind what they\'re doing. It\'s bonkers.""\nIt is also, thinks Brailsford, one reason why a doping culture is so prevalent in professional road cycling; the theory being that expectation/pressure coupled with absence of care/responsibility equals ideal conditions for such a culture to develop. He\'d do it differently, he says. ""If we did anything it\'d be 100% clean. We\'ve got this young generation coming through, riders who don\'t want to cheat. And there\'s wider enthusiasm; untapped potential. We saw it in London and on the road to Canterbury; the crowds, screaming by the roadside … despite all the doom and gloom and the negativity around the doping stories.""\nAnd what about the older guard – Wiggins and the reformed doper David Millar? Would they be involved? ""You\'d like to think it\'d be possible to do this before they\'ve retired,"" says Brailsford. ""I want to bring together lots of different elements in cycling in Britain. Instead of factions, let\'s get behind this thing and see what we can do.\n""It\'s dependent on these riders progressing and coming through,"" he adds. ""We\'re not going to do it until the riders are good enough to do it; until we have the critical mass of British talent we can\'t do it. It\'s unlikely you\'re going to get 25 British riders, but you need the critical mass; we wouldn\'t do it with an international team. But knowing what I do of the young lads coming through, there\'s plenty of talent. That\'s not the issue.\n""And with Cav, we\'ve got a winner. He\'s your goalscorer.""\nExtracted from Sky\'s the Limit by Richard Moore (HarperSport). Available now', ""Paul O’Dette (BEMF Co-Artistic Director, lute, theorbo, and Baroque guitar) has been called “the clearest case of genius ever to touch his instrument”, Toronto Globe and Mail. One of the most influential figures in his field, O'Dette has helped define the technical and stylistic standards to which twenty-first-century performers of early music aspire. In doing so, he helped infuse the performance practice movement with a perfect combination of historical awareness, idiomatic accuracy, and ambitious self-expression. His performances at the major international festivals in Boston, Los Angeles, Vancouver, Berkeley, London, Bath, Paris, Montpellier, Amsterdam, Utrecht, Bruges, Antwerp, Berlin, Munich, Bremen, Dresden, Vienna, Innsbruck, Prague, Milan, Florence, Geneva, Madrid, Barcelona, Tenerife, Copenhagen, Oslo, Cordoba, St. Petersburg, Moscow, Montevideo, Buenos Aires, Melbourne, Tokyo, etc. have often been singled out as the highlight of those events. Though best known for his recitals and recordings of virtuoso solo lute music, Paul O'Dette maintains an active international career as an ensemble musician as well, performing with many of the leading early music soloists and ensembles. He is a member of the acclaimed continuo ensemble Tragicomedia.\nPaul O'Dette has made more than 120 recordings, earning 5 Grammy nominations and numerous other awards. “The Complete Lute Music of John Dowland” (a 5-CD set for harmonia mundi usa), was awarded the prestigious Diapason D'or de l'année, while “The Royal Lewters” has received the Diapason D’or, a Choc du Monde de la Musique, a 5-star rating in BBC Music Magazine, 5-star rating in Goldberg and a perfect score of 10 from ClassicsToday.com. “The Bachelar’s Delight: Lute Music of Daniel Bacheler” was nominated for a Grammy in 2006 as “Best Solo Instrumental Recording.” Mr. O'Dette has performed in broadcasts for the ABC (Australia), Radio Argentina, BBC (UK), CBC (Canada), Radio France, RAI (Italy), Westdeutscher Rundfunk (Cologne), Bayerischer Rundfunk (Munich), SFB (Berlin), NOS (Holland), Austrian Radio, Spanish Radio and Television, TV Ankara, Hungarian Television, Norwegian Radio, Danish Radio and Television, Swedish Television, Swiss Radio and Television, National Public Radio (USA) and CBS Television (USA).\nRecently, Mr. O'Dette has been active conducting Baroque operas. In 1997 he led performances of Luigi Rossi's L'Orfeo at Tanglewood, the Boston Early Music Festival (BEMF) and the Drottningholm Court Theatre in Sweden with Stephen Stubbs. Since 1999 they have co-directed performances of Cavalli's Ercole Amante at the Boston Early Music Festival, Tanglewood, and the Utrecht Early Music Festival, Provenzale's La Stellidaura Vendicata at the Vadstena Academy in Sweden, Monteverdi's Orfeo and L'Incoronazione di Poppea for Festival Vancouver, Lully's Thésée and Psyché, Conradi’s Ariadne (Hamburg, 1691) and Mattheson’s Boris Goudenow for the Boston Early Music Festival. The recording of Ariadne was nominated for a Grammy as “Best Opera Recording of 2005,” while Thésée was nominated in the same category in 2007 and Psyché was nominated in 2008. Paul O'Dette has guest directed numerous Baroque orchestras on both sides of the Atlantic including the Portland Baroque Orchestra, Tafelmusik, Apollo’s Fire, Ensemble Arion, Chatham Baroque and Corona Artis.\nIn addition to his activities as a performer, Paul O'Dette is an avid researcher, having worked extensively on the performance and sources of seventeenth-century Italian and English solo song, continuo practices and lute technique, the latter resulting in a forthcoming book co-authored by Patrick O'Brien. He has published numerous articles on issues of historical performance practice and co-authored the Dowland entry in the New Grove Dictionary of Music and Musicians. Paul O'Dette is Professor of Lute and Director of Early Music at the Eastman School of Music.\nAfter a thirty year career in Europe, BEMF Co- Artistic Director and lutenist Stephen Stubbs recently returned to his native Seattle to establish Pacific Musicworks to introduce a wide range of musical productions to Seattle audiences with innovative multi-media collaborations.\nWith his direction of Stefano Landi's La Morte d'Orfeo at the 1987 Bruges festival, he began his career as opera director and simultaneously founded the ensemble Tragicomedia, which has since recorded numerous CDs and completed tours of Europe, North America and Japan. Stubbs has been invited to direct opera productions in Europe, the US, Canada and Scandinavia. Since 1997 he has co-directed the bi-annual Boston Early Music Festival opera. The Festival’s recording of Conradi’s Ariadne was nominated for a Grammy award in 2005, their recording of Lully’s Thesee was nominated in 2007 and their Psyché, also by Lully, was nominated in 2009.\nStephen Stubbs created the ensemble Teatro Lirico, who made their recording debut in 1996 with the CD Love and Death in Venice. A live recording of Antonio Sartorio's Orfeo of 1672 for Vanguard Classics was awarded the Cini Prize for best opera recording of 1999. Teatro Lirico now records for ECM records. Their debut CD on this label was a New York Times “pick of the year” for 2006.\nStubbs’ solo lute recordings include the music of J.S. Bach, S.L. Weiss, David Kellner and the Belgian lutenist Jaques St. Luc. With baroque harpist Maxine Eilander he has recorded Sonate al Pizzico, released on ATMA in 2004. Since the inception of the Dowland Project on ECM he has played on all the group’s recordings.\nTo cultivate the singers and players of the next generation he founded an early opera course called the Accademia d’Amore in 1997. Beyond this annual August workshop now located in Seattle, there is a series of weekend workshops during the year under the auspices of the Seattle Academy of Baroque Opera.\nGilbert Blin, BEMF Opera Director, Stage Director, Set Designer, Young Artists Training Program Director, studied Theater History and Stage Direction at the Sorbonne in Paris. Upon graduating in 1986, he concentrated on Rameau’s operas and their relation to the stage, an interest that has since broadened to encompass French opera and its relationship to Baroque theater, his fields of expertise as historian, stage director, and designer. His opera productions have been described by the American press as “revelatory,” “delightful,” “lavish,” “gorgeous,” “stunning,” and “extraordinarily moving.”\nFor his début in 1991, Gilbert Blin directed Massenet’s Werther for the Opéra de Nancy. For Opéra-Comique in Paris, he presented a new version of Werther in 1994 with Laurent Petitgirard conducting, and in 1995 directed Delibes’s Lakmé for the same house, a production frequently revived in France until 2000. In 1996, he was dramaturge for Bizet’s Carmen, directed by David Radok, at the Royal Opera of Copenhagen. In 1999, Mr. Blin was the first French stage director invited by the Prague State Opera: his popular production of Meyerbeer’s Robert le Diable, with musical direction by Vincent Monteil, has been performed for many seasons.\nGilbert Blin has worked extensively with the operas of Gluck. He was French adviser for Arnold Östman’s productions of Iphigénie en Tauride (Drottningholm, 1990) and Alceste (Concertgebouw, Amsterdam, 1993). As stage director for the Drottningholm Theatre, he presented Orfeo ed Euridice in 1992. This first modern production of the 1769 “Parma Version,” conducted by Arnold Östman, was filmed, recorded, and revived in 1998, as part of the Gluck Festival presented for Stockholm’s year as the EU’s “European City of Culture.” To study the period resources offered by Drottningholm Theatre, Gilbert Blin founded, in 1999, the Académie Desprez, Association Française pour le Rayonnement du Théâtre du Château de Drottningholm.\nHis staged realizations of operas of the 17th and 18th centuries include a newly designed and directed 2001 production of Vivaldi’s Orlando furioso for the State Opera of Prague, and a 2003 staged reconstruction of Vivaldi’s Rosmira fedele for the Opéra de Nice. Returning to the latter house in 2007, Gilbert Blin designed the staging, sets, costumes, and lights of his acclaimed production of Handel’s Teseo, and in 2012, he directed and designed a production of Alessandro Scarlatti’s Il Tigrane, conducted by Gilbert Bezzina. For the Ensemble Baroque de Nice, he also reconstructed a 17th-century Roman performance of Scarlatti’s oratorio La Giuditta in 2009. Since 2006, Mr. Blin has been working on reconstructing the original sets and costumes of Mozart operas: with Czech stage director Lubor Cukr, he presented Don Giovanni at the Prague Estates Theatre in 2006 and 2014, and Le nozze di Figaro at Opéra de Nice in 2008.\nGilbert Blin made his American début with the Boston Early Music Festival in 2001 by directing a fully staged production of Lully’s Thésée. Returning to BEMF in 2007, he directed Lully’s Psyché with musical directors Paul O’Dette and Stephen Stubbs at the Cutler Majestic Theatre in Boston. He became Boston Early Music Festival’s Stage Director in Residence in 2008, and directed and designed the sets for Steffani’s Niobe, Regina di Tebe, the 2011 Festival opera. For the 2013 Boston Early Music Festival, Mr. Blin presented Handel’s Almira to great acclaim.\nTo inaugurate the BEMF Chamber Opera Series in 2008, Gilbert Blin staged Blow’s Venus and Adonis and Charpentier’s Actéon. His production of Purcell’s Dido and Aeneas was created in 2010. For the same series, Handel’s Acis and Galatea was first presented in Boston in 2009, and toured the U.S. and Canada in 2011. This enthusiastically received production will be remounted in Boston in 2015. Last autumn, Gilbert Blin offered a pasticcio uniting Pergolesi’s two comic masterpieces, La serva padrona and Livietta e Tracollo.\nIn 2011 Gilbert Blin returned to the French repertoire and created a production pairing Charpentier’s La Couronne de Fleurs and La Descente d’Orphée aux Enfers. Consequently, he also served as drama coach for the GRAMMY-winning recording of these Charpentier’s masterpieces by Paul O’Dette and Stephen Stubbs. The staging was revived for the 2013 Boston Early Music Festival and toured North America in 2014.\nGilbert Blin became a Researcher at the University of Leiden in 2014; he is preparing a Ph.D. with the University’s Academy for Creative and Performing Arts under the supervision of Ton Koopman: “Operas of the 17th and 18th centuries and their historically informed and inspired staging.” Due to his extensive work in both the theory and practice of this field, Mr. Blin has been invited to give lectures at the Schola Cantorum in Basel, the Royal Conservatoire of The Hague, the Université de Paris-Sorbonne, and The Juilliard School.\nFollowing his acclaimed production of L’incoronazione di Poppea for the 2009 Festival, Mr. Blin staged Monteverdi’s Orfeo for the BEMF Chamber Opera Series in 2012. His new production of Il Ritorno d’Ulisse in Patria for the 2015 Festival completes the “Monteverdi Trilogy.”\nGilbert Blin is the Opera Director of the Boston Early Music Festival.\nRobert Mealy is one of America’s most prominent baroque violinists. The New York Times recently commented in a review of the BEMF Orchestra that “Mr. Mealy seems to foster excellence wherever he goes, whether he’s at Trinity Wall Street in New York, as concertmaster of the Trinity Baroque Orchestra; at Yale, as director of the Yale Baroque Ensemble; or at the Juilliard School, as director of the historical performance program.” He was recently appointed Orchestral Director for the Boston Early Music Festival, where he has led the orchestra in festival productions and Grammy-nominated recordings for nearly a decade.\nMr. Mealy began exploring early music in high school, first with the Collegium of UC Berkeley and then at the Royal College of Music in London, where he studied harpsichord and baroque violin. While still an undergraduate at Harvard College, he was asked to join the distinguished Canadian baroque orchestra Tafelmusik. Since then, he has recorded over 80 cds of early music on most major labels, ranging from Hildegard of Bingen with Sequentia, to Renaissance consorts with the Boston Camerata, to Rameau operas with Les Arts Florissants. He has led Baroque ensembles for the Mark Morris Dance Company, including a tour to Moscow, and accompanied Renée Fleming on the David Letterman Show. A devoted chamber musician, he co-directs Quicksilver, whose début recording was hailed as “breakthrough CD of the year” by the Huffington Post.\nA keen scholar as well as a performer, Mr. Mealy is Director of the distinguished Historical Performance Program at The Juilliard School and professor of early music at the Yale School of Music. He taught at Harvard for over a decade, where he founded the Harvard Baroque Chamber Orchestra. In 2004, he received Early Music America’s Binkley Award for outstanding teaching and scholarship.""]"	['<urn:uuid:f7721a9c-3f35-43ef-b8b0-0c79d38912a9>', '<urn:uuid:f9973bb0-bf1e-4fb6-a8ad-944c34f12d5b>']	factoid	direct	concise-and-natural	distant-from-document	comparison	expert	2025-05-13T05:52:58.810667	10	42	3932
56	What's similar between velvet cutting and crypto mining impacts?	Both velvet cutting and crypto mining operations have specific directional requirements and local environmental impacts. In velvet cutting, the direction of the nap affects the fabric's appearance and wear - cutting with the nap down makes the fabric look lighter and wear better, while cutting against it creates a darker appearance. Similarly, crypto mining operations have directional impacts on local communities, creating specific patterns of effects including noise pollution and local environmental disturbances. Both activities require careful consideration of their impact on the immediate environment - velvet cutting needs proper marking and workspace preparation to prevent damage and waste, while crypto mining requires monitoring and mitigation of local environmental effects, particularly regarding noise and pollution impacts on neighboring communities.	['How to Sew Velvet like a Pro\nIt’s that time of year when velvet starts making its triumphant comeback with holiday dresses for girls and ladies of all ages. Get tips from the pros who can sew it best.\nThis season designers looked to this winter staple to create looks that were anything but ordinary. Here are a few techniques that will help you get the look with none of the hassle. With new technical information and new sewing aids, velvet is no longer intimidating to sew. After you get a few skills under your belt, you’ll be able to include it in your day or night wardrobe with ease.\nWoven with an extra set of warp yarns that form a pile, velvets range in weight from chiffon to heavy upholstery fabrics. Originally made of silk, velvet is now available in cotton, rayon, acetate, polyester, and various blends. It’s usually woven as double cloth; two layers of fabric are woven simultaneously, one on top of the other. The pile, which joins the two layers, is then cut to create that signature, luxurious nap.\nSTYLES AND PATTERNS\nBecause of velvet’s nature, stitching lines tend to show. Try to minimize design details such as darts, seams, buttonholes, and topstitching. Choose simple semi-fitted to loose-fitting garment styles. Gathers, soft folds, and drapey styles work better than those that are fitted and contoured.\nAvoid ripping out stitches because that makes the fabric look damaged; refine the fit before you start your project. Or, make a garment from a pattern you have already perfected.\nVelvet has a definite nap (direction of the pile). When you run your hand over the fabric, you will be able to tell whether the nap feels smooth to the touch (the pile is going down) or pushing against the pile (the pile is going up). If the nap is up, the velvet looks darker. If the nap is brushed down, the fabric looks lighter.\nCUTTING AND MARKING\nThere are no hard and fast rules about which way to cut the fabric. Typically, velvet garments are cut with the nap going down, but if you prefer a richer, darker color, cut the garment with the nap going up. On the other hand, velvet will often wear better and mat less when cut with the pile down. It’s important to be consistent and cut all of the pieces with the nap running in the same direction. Use a chalk marker or a sliver of soap on the wrong side of the fabric to mark the nap direction.\nLay the fabric wrong-side up in a single layer on your cutting table, so the pattern pieces are on the fabric backing. When pattern tissue is placed on the pile side, it moves and shifts, making pinning difficult and cutting inaccurate.\nUse chalk or tailor’s pencils to mark dots and other necessary markings from the pattern on the fabric’s wrong side. The best way to mark velvet is with tailor’s tacks or with hand basting. Thread a very fine, sharp hand-sewing needle with silk thread to sew the marks. Silk thread is less damaging to the fabric than the pressure of chalk and can be removed easily. If you need to mark long edges such as a hem, use thread-tracing. Avoid using a tracing wheel and tracing paper. To mark notches, make a small snip into the seam allowance for a single notch or multiple snips for double and triple notches.\nLay out the pattern pieces on the fabric’s wrong side for easy cutting.\nAnother product that saves time and enormous frustration is temporary spray adhesive. Now, instead of painfully pinning, basting, and stabilizing, and hoping for the best, simply spray a light line of adhesive along the seamline on the fabric’s right side. Then place the right side of the corresponding piece along the seamline, and stitch the seam. You don’t even need pins! If you don’t get the pieces positioned perfectly the first time, pull the fabrics apart, and place them together again. There is no need to spray the adhesive again; the first spray will retain its sticking power.\nYou can also use this process when sewing a layer of velvet to other types of fabric such as lining or any other smooth, no-pile material. The most amazing thing is that the adhesive dissipates cleanly.\nThe adhesive dissipates from the fabric, but it won’t disappear from your table, the floor, or the surrounding surfaces, so always cover your work space to catch overspray. Adhesive manufacturers also make products to help remove the overspray from hard surfaces.\nTemporary basting spray holds layers of velvet together and prevents shifting while sewing. No pins necessary!\nStitching two pieces of velvet together can be tricky; traditional sewing methods simply don’t work. No amount of pinning and/or basting prevents the fabric from shifting and moving-in both directions-when you sew. Here are some classic tips for sewing seams in velvet:\n∙ Hand-baste with one or more of three basting methods-double, backstitch, or diagonal basting.\n∙ Loosen the machine tension.\n∙ Hold the fabric taut as you sew.\n∙ Use a walking foot, Teflon foot, or roller foot.\n∙ Use the stop and start sewing method.\n∙ Stitch with tissue paper or a stabilizer between the layers and/or between the fabric and the feed dogs\nWhen sewing velvet, use universal or sharp machine needles sizes 70/10H or 80/12H and 100-percent cotton or silk thread. Always stitch in the direction of the pile. To minimize bulk, trim and grade seam allowances, and slash darts along the fold. Press the darts open.\nFor easy stitching, try loading your machine with a walking presser foot. It has feed dogs on its sole to help feed the fabric evenly through the machine, and helps eliminate the fabric crawling.\nTest the foot on a swatch first to make sure it does not leave tracks in the fabric’s pile.\nIroning velvet is always delicate work. It is easy to mar the pile with an iron, so use only steam-never allow the iron to touch the fabric. There are several pressing-board surfaces you can use to safely position the velvet pile-side down while steaming from the wrong side.\nNeedle and Velva boards are both good surfaces, but they are rather small and need to be moved frequently while you work. It’s better to cover your entire pressing surface with a piece of stiff-pile fabric such as heavy velveteen, mohair upholstery, frieze, or even a thick terry towel; that way, you don’t have to shift the surface as you steam.\nIf your hands are sensitive to heat, use a press mitt or a finger mitt. Use a large scrap of velvet as a press cloth.\nSteam velvet face down over a needle board or towel to avoid crushing the pile.\nBefore hemming your garment, let it hang for at least 24 hours, giving it time to relax. Re-measure and re-cut the hem length if necessary.\nA hem may not need an edge finish. Simply turn it up, and stitch by hand, using a hand catchstitch, or by machine with a blindstitch. Either way, steam the hem; never let the iron touch the fabric. Finger-press the hem to leave a soft fold at the bottom.\nFor longer, lined garments such as coats and capes, use strips of bias-cut cotton flannel 1 inch wider than the hem allowance to support the hem. Position the strip parallel to the hem with the lower edge, crossing the hemline by 1/2 inch. The upper edge will extend above the hem allowance 1/2 inch. Catchstitch the top and bottom interfacing edges to the velvet’s wrong side. Fold the hem allowance up, and catchstitch the bottom edge to the flannel only. The flannel creates a soft, supportive fold in the hem.\nHandsew a bias-cut strip of flannel 1/2 inch into the hem allowance as shown at left. Sew along the strip’s top and bottom edges.\nFold up the garment’s hem and handsew the garment’s edge to the flannel only.\nThis was excerpted from the article “Velvet Indulgence” by Linda Lee from Threads issue #140.\nMax Azria at left and Prada at right use velvet in their Fall 2009 collections.\nGemma Maxi Dress by Named Clothing\nGet the latest including tips, techniques and special offers straight to your inbox.', 'FACT SHEET: Climate and Energy Implications of Crypto-Assets in the United States\nClimate change is one of the most pressing problems confronting our nation and our world, and President Biden has taken bold steps to address it with legislation and policy. Among the President’s commitments are: protecting communities from pollution, reducing greenhouse gas emissions by 50% by 2030, achieving a carbon pollution-free electricity grid by 2035, and reaching net-zero greenhouse gas emissions no later than 2050.\nTo achieve these ambitious goals, we must ensure that emerging technologies contribute to a net-zero, clean energy future. The use of digital assets based on distributed ledger technology (DLT) is expanding. Digital assets are a form of value, represented digitally. As an emerging technological innovation, digital assets have provided some benefits and value for some residents and businesses in the United States, and have the potential for future benefits with emerging uses.\nCrypto-assets are digital assets that are implemented using cryptographic techniques. Crypto-assets can require considerable amounts of electricity usage, which can result in greenhouse gas emissions, as well as additional pollution, noise, and other local impacts to communities living near mining facilities. Depending on the energy intensity of the technology and the sources of electricity used, the rapid growth of crypto-assets could potentially hinder broader efforts to achieve U.S. climate commitments to reach net-zero carbon pollution.\nIn March, in Executive Order 14067 on Ensuring the Responsible Development of Digital Assets, President Biden made clear that the responsible development of digital assets includes reducing negative climate impacts and environmental pollution. The Executive Order directed the White House Office of Science and Technology Policy (OSTP), in coordination with other federal agencies, to produce a report on the climate and energy implications of crypto-assets in the United States. OSTP assembled an interdisciplinary team of experts to assess and extend existing studies with new analysis, based on peer-reviewed studies and the best available data.\nToday, OSTP published its report, examining the challenges and opportunities of crypto-assets for the United States’ clean energy and climate change goals, and providing a set of recommendations to further study and track impacts of the sector, develop potential performance standards, and provide tools and resources to reduce negative impacts. This report’s assessment and recommendations align with federal actions that reduce greenhouse gas emissions to protect public health and welfare, grow a clean energy economy with good-paying jobs, and improve environmental justice.\nCrypto-Assets Can Be Energy-Intensive, and the United States Has a Major Crypto-Asset Sector\nFrom 2018 to 2022, annualized electricity usage from global crypto-assets grew rapidly, with estimates of electricity usage doubling to quadrupling. As of August 2022, published estimates of the total global electricity usage for crypto-assets are between 120 and 240 billion kilowatt-hours per year, a range that exceeds the total annual electricity usage of many individual countries, such as Argentina or Australia. This is equivalent to 0.4% to 0.9% of annual global electricity usage, and is comparable to the annual electricity usage of all conventional data centers in the world.\nNearly all crypto-asset electricity usage is driven by consensus mechanisms: the DLT used to mine and verify crypto-assets. The dominant consensus mechanism is called Proof of Work (PoW), which is used by the Bitcoin and Ethereum blockchains. Bitcoin and Ether combined represent more than 60% of total crypto-asset market capitalization. The PoW mechanism is designed to require more computing power as more entities attempt to validate transactions for coin rewards, and this feature helps disincentivize malicious actors from attacking the network. As of August 2022, Bitcoin is estimated to account for 60% to 77% of total global crypto-asset electricity usage, and Ethereum is estimated to account for 20% to 39%.\nThe energy efficiency of mining equipment has been increasing, but electricity usage continues to rise. Other less energy-intensive crypto-asset ledger technologies exist, with different attributes and uses. Switching to alternative crypto-asset technologies such as Proof of Stake could dramatically reduce overall power usage to less than 1% of today’s levels.\nThe United States is estimated to host about a third of global crypto-asset operations, which currently consume about 0.9% to 1.7% of total U.S. electricity usage. This range of electricity usage is similar to all home computers or residential lighting in the United States. Crypto-asset mining is also highly mobile. The United States currently hosts the world’s largest Bitcoin mining industry, totaling more than 38% of global Bitcoin activity, up from 3.5% in 2020. Despite the potential for rapid growth, future electricity demand from crypto-asset operations is uncertain, demonstrating the need for better data to understand and monitor electricity usage from crypto-assets.\nCrypto-Assets Can Have Significant Environmental Impacts\nGlobal electricity generation for the crypto-assets with the largest market capitalizations resulted in a combined 140 ± 30 million metric tons of carbon dioxide per year (Mt CO2/y), or about 0.3% of global annual greenhouse gas emissions. Crypto-asset activity in the United States is estimated to result in approximately 25 to 50 Mt CO2/y, which is 0.4% to 0.8% of total U.S. greenhouse gas emissions. This range of emissions is similar to emissions from diesel fuel used in railroads in the United States.\nBesides purchased grid electricity, crypto-asset mining operations can also cause local noise and water impacts, electronic waste, air and other pollution from any direct usage of fossil-fired electricity, and additional air, water, and waste impacts associated with all grid electricity usage. These local impacts can exacerbate environmental justice issues for neighboring communities, which are often already burdened with other pollutants, heat, traffic, or noise. The growth of energy-intensive crypto-asset technologies, when not directly using clean electricity, could hinder the ability of the United States to achieve its National Determined Contribution under the Paris Agreement, and to avoid the most severe impacts of climate change. Broader adoption of crypto-assets, and the potential introduction of new types of digital assets require action by the federal government to encourage and ensure responsible development. This includes minimizing negative impacts on local communities, significantly reducing energy intensity, and powering with clean electricity.\nDistributed Ledger Technologies May Help with Climate Monitoring or Mitigation\nDLT may have a role to play in enhancing market infrastructure for a range of environmental markets like carbon credit markets, though other solutions might work as well or better. The potential benefits of DLT would need to outweigh the additional emissions and other environmental externalities that result from operations to merit broader use, relative to the markets or mechanisms that DLT displaces. Use cases are still emerging, and like all emerging technologies, there are potential positive and negative use cases yet to be imagined. Responsible development of this technology would encourage innovation in DLT applications while reducing energy intensity and minimizing environmental damages.\nKey Recommendations of the Report\nTo help the United States meet its climate objectives, crypto-asset policy during the transition to clean energy should be focused on several objectives: reduce greenhouse gas emissions, avoid operations that will increase the cost of electricity to consumers, avoid operations that reduce the reliability of electric grids, and avoid negative impacts to equity, communities, and the local environment.\nTo ensure the responsible development of digital assets, recommendations include the following actions for consideration:\n- Minimize greenhouse gas emissions, environmental justice impacts, and other local impacts from crypto-assets: The Environmental Protection Agency (EPA), the Department of Energy (DOE), and other federal agencies should provide technical assistance and initiate a collaborative process with states, communities, the crypto-asset industry, and others to develop effective, evidence-based environmental performance standards for the responsible design, development, and use of environmentally responsible crypto-asset technologies. These should include standards for very low energy intensities, low water usage, low noise generation, clean energy usage by operators, and standards that strengthen over time for additional carbon-free generation to match or exceed the additional electricity load of these facilities. Should these measures prove ineffective at reducing impacts, the Administration should explore executive actions, and Congress might consider legislation, to limit or eliminate the use of high energy intensity consensus mechanisms for crypto-asset mining. DOE and EPA should provide technical assistance to state public utility commissions, environmental protection agencies, and the crypto-asset industry to build capacity to minimize emissions, noise, water impacts, and negative economic impacts of crypto-asset mining; and to mitigate environmental injustices to overburdened communities.\n- Ensure energy reliability: DOE, in coordination with the Federal Energy Regulatory Commission, the North American Electric Reliability Corporation and its regional entities, should conduct reliability assessments of current and projected crypto-asset mining operations on electricity system reliability and adequacy. If these reliability assessments find current or anticipated risks to the power system as a result crypto-asset mining, these entities should consider developing, updating, and enforcing reliability standards and emergency operations procedures to ensure system reliability and adequacy under the growth of crypto-asset mining.\n- Obtain data to understand, monitor, and mitigate impacts: The Energy Information Administration and other federal agencies should consider collecting and analyzing information from crypto-asset miners and electric utilities in a privacy-preserving manner to enable evidence-based decisions on the energy and climate implications of crypto-assets. Data should include mining energy usage and fuel mix, power purchase agreements, environmental justice implications, and demand response participation. OSTP could establish a National Science and Technology Council subcommittee to coordinate with other relevant agencies to assess the energy use of major crypto-assets.\n- Advance energy efficiency standards: The Administration should consider working with Congress to enable DOE and encourage other federal regulators to promulgate and regularly update energy conservation standards for crypto-asset mining equipment, blockchains, and other operations.\n- Encourage transparency and improvements in environmental performance: Crypto-asset industry associations, including mining firms and equipment manufacturers, should be encouraged to publicly report crypto-asset mining locations, annual electricity usage, greenhouse gas emissions using existing protocols, and electronic waste recycling performance.\n- Further research to improve understanding and innovation: For improved analytical capabilities that can enhance the accuracy of electricity usage estimates and sustainability, the National Science Foundation, DOE, EPA and other relevant agencies could promote and support research and development priorities that improve the environmental sustainability of digital assets, including crypto-asset impact modeling, assessment of environmental justice impacts, and understanding beneficial uses for grid management and environmental mitigation. Research and development priorities should emphasize innovations in next-generation digital asset technologies that advance U.S. goals in security, privacy, equity, and resilience, as well as U.S. climate goals.']	['<urn:uuid:f8e982ea-814b-4a98-b92b-4610033abc81>', '<urn:uuid:c2b3e9e1-0ef3-465d-9a23-92fdbe2309a6>']	open-ended	with-premise	concise-and-natural	distant-from-document	multi-aspect	novice	2025-05-13T05:52:58.810667	9	119	3101
57	What challenges do China and California face in energy storage deployment?	In China, the main challenge is addressing grid oversupply from must-run coal-fired plants that provide winter heating, leading to renewable energy curtailment. The solution involves new policies allowing energy storage to participate in ancillary services. In California, the challenges include needing massive deployment - over 10,000 MW in the next 10 years and 30,000 MW in 20-25 years. Both regions are working to create market opportunities, with China focusing on regulatory pathways for storage deployment and California remaining open to various storage types while establishing utility requirements through legislation.	['This month, Chinese policymakers passed the most substantial energy storage policy since power sector reforms began last year. The policy, “Announcement on Promoting Electrical Storage Participation in Ancillary Service in the ‘Three Norths’ Region” (the Announcement) opens up tangible regulatory pathways for energy storage deployments in China’s northeastern, north-central, and northwestern provinces, where high penetrations of wind power and must-run coal-fired power plants have created a need for better grid balancing.\nDuring periods of grid oversupply, generators in China’s northern grids earn money when grid operators call on them to steeply reduce output or shut down, an ancillary service called “peak regulation (调峰)”. The Announcement now allows energy storage to earn money by absorbing this oversupply – allowing coal-fired generators to improve efficiency and reducing curtailment for wind and solar.\nThis is particularly valuable in China’s north because of the large deployments of combined heat-and-power coal-fired plants that provide district heating during the frigid winter months. Because these power plants must operate regardless of demand – homes have to stay heated – renewables end up getting curtailed during periods of low demand. The Announcement opens a new value stream for energy storage to address oversupply conditions and store the wind and solar energy that would otherwise be curtailed.\nInterestingly, the policy allows both in-front and behind-the-meter energy storage to participate. Generator-side energy storage is required to be able to deliver 10 MW for four hours at a time. These installations will be compensated using existing payment schemes for coal-fired generators. The size requirements and compensation mechanisms for aggregated behind-the-meter installations have not yet been announced.\nA little back-of-a-napkin number crunching suggests that this policy will significantly reduce the payback period for energy storage projects co-located with wind farms – to as little as five years under certain circumstances.\nThe (Rough) Math\nSuppose that a 10 MW, four-hour energy storage system located at a wind farm fully charges twice during off-peak hours each day, and fully discharges twice each day during peak hours in the morning and evening.\nThis system can earn two value streams simultaneously: 1) “peak regulation” during charging, compensated at 300 CNY per MWh, and 2) electricity retail during discharge.\n1. Charging: Although the compensation for downward regulation varies by region, we’re looking at the northeast grid, where compensation is highest at 300 CNY per MWh of downward regulation. The energy storage system can absorb 40 MWh, twice per day, so:\nDaily regulation payment = 40 MWh x 300 CNY/MWh x 2 = 24,000 CNY\n2. Discharge: Because the energy storage unit is co-located with a wind farm, it sells electricity at the on-shore wind feed-in tariff of 0.5 CNY/kWh. For simplicity’s sake, let’s assume 100% round-trip efficiency and full discharge:\nDaily retail payment = 40 MWh x 1000 x 0.5 CNY/kWh x 2 = 40,000 CNY\nAssuming these (admittedly over-optimistic) circumstances persist throughout the year, an energy storage installation would earn about 23m CNY per year:\nAnnual earnings = (24,000 CNY + 40,000 CNY) x 365 = 23.36 million CNY/a\nAssuming this system costs 3000 CNY/kWh (~$460/kWh), a 40 MWh system would cost 120m CNY (not including construction costs, O&M, etc.), and have a payback period of about five years.\nGiven that the storage system only cycles twice per day, the number of cycles required to reach the payback date is only 3,744 cycles – a figure that lithium-ion, sodium-sulfur, and flow batteries can all achieve.\nA new value stream\nIn the days when energy storage couldn’t earn money from downward regulation, the payback period might be 8.3 years or longer. This new value stream opens up opportunities for energy storage providers, and helps China achieve its policy goals of reducing renewable energy curtailment.\nAdmittedly, these simple calculations are missing a lot, from round-trip efficiency losses, to discounting, to assuming full discharge twice every day year-round, so real-world payback periods are likely to be longer. But it is clear that with a new value stream available, energy storage is moving closer towards wide-scale commercial feasibility in China.', 'By: Corina Rivera-Linares JUL 28, 2020\nAlthough battery storage technology is gaining traction, the industry must face several challenges head on to take full advantage of it.\nFor electric utilities like Consolidated Edison Inc.’s subsidiary Orange and Rockland Utilities Inc., battery energy storage is a key component of providing reliable power, but challenges remain for storage technologies as they develop across the United States.\nIn March 2019, the utility announced it had selected Key Capture Energy LLC (KCE) to plan, design, install and operate a 3-MW battery storage project adjacent to its Ladentown substation in Pomona, New York, U.S., that would enable the utility to delay building costly new infrastructure to accommodate energy use at its peak, which occurs only a few times a year.\nMD Sakib, section manager for utility of the future with Orange & Rockland (O&R), said the battery storage project stemmed from the utility’s need for additional infrastructure to provide safe and reliable power alongside rapid load growth in the area. “Rather than building a brand-new substation, by leveraging these distributed energy resource technologies, what we’re doing is we’re deferring the build of brand-new substations for about 10 years or so,” he said.\nBattery storage technology like that in O&R’s Pomona project is gaining traction in the industry. Dramatic and recent decreases in pricing, advances in technology and more attention to improving resilience are all factors contributing to the exponential growth in energy storage markets. However, challenges remain for storage technology as it develops across the U.S., including not having enough in-field operational data, getting buy-in at the local level, a lack of sophisticated modeling tools, difficulty in determining the value of storage and the need for wholesale market rules to continue changing to account for the total value that energy storage provides to the grid.\nInterior view of Key Capture Energy’s KCE NY 1 battery storage project.\nThe Biggest Challenge\nAccording to the Energy Storage Association’s (ESA) website: “Energy storage is an enabling technology.”\nThe website explains that storage augments such resources as wind, solar, hydro, nuclear and fossil fuels as well as demand-side resources and system efficiency assets. It is flexible as it can act as a generation, transmission or distribution asset — or even combine all of these in a single asset.\nEnergy storage can improve reliability and resilience. For example, it can provide backup power during disruptions as well as smooth out the delivery of variable and intermittent resources such as wind and solar power — by storing excess energy when the wind is blowing and the sun is shining — and delivering it when the opposite is happening, per the ESA website.\nDespite these advantages, significant barriers exist that prevent utilities from accessing the full range of benefits, namely participation in energy markets. One reason for this is utilities do not have a firm knowledge yet of how batteries operate in the field, as a result of how relatively new many battery energy storage system (BESS) projects are.\nWhile the industry knows battery energy storage “is going to be a really big part of the clean energy future, there is not much operational data thus far across the United States, as there is less than 1 GW of battery storage installed,” says Jeff Bishop, CEO of KCE.\nHe added, “There are 50, 60, 70 GW of planned projects” in the interconnection queues, “so that disconnect between what batteries have been tested and proven to do vs. the theoretical and what they might be able to do is the biggest challenge” facing battery storage technology today.\nBishop said KCE approaches this issue by deploying 10- and 20-MW battery storage projects rapidly with laser focus on just a couple of markets so it can be part of the independent system operator’s (ISO’s) working group discussions, for example. The relatively low impact of these projects compared to other major infrastructure projects enables the company to highlight the more streamlined construction process for battery storage installation.\nInput at the Local Level\nNew technologies and new suppliers entering new markets always require a lot of stakeholder discussion and performance analysis to attain buy-in, particularly in the conservative environment in which utilities must operate. “Every technology has its own quirks and, as such, we really have to work in order to understand all the pluses and minuses, and work with our local communities in order to make sure that we mitigate everything we can,” Bishop explained.\nO&R’s Sakib echoed that challenges at the local level include informing the various authorities with jurisdiction over battery storage projects — such as local zoning boards — of the different safety mechanisms that the storage technology has and how we can work together to answer any and all questions that the first responders might have.\nAs of fall 2019, at least three major storage-related fires have occurred in the U.S., including a fire in 2012 that destroyed a 15-MW battery storage facility at a wind farm in Hawaii. For the Ponoma project, Sakib said O&R “brought in industry experts and conducted multiple on-site meetings with the local AHJs, fire department members, volunteers, and first responders to ensure that their outstanding questions were addressed.”\nKey Capture Energy employee, Jim Brown, inspecting the controls software inside of the KCE NY 1 battery storage project.\nGeoff Brown, president of Powin Energy, the BESS integrator for the Ponoma battery storage project, believes there is a need for dialogue among stakeholders. He said companies like his and others in the storage space need state regulators, for instance, to “be willing to reexamine regulations and rules [and] revenue generation opportunities, to allow for stationary storage assets to do everything that they can do. No state’s electrical generation rules were written with the concept of distributed stationary storage systems sitting at each substation. It’s a fundamentally different way of thinking [of] how do you manage grid-level problems — and we believe it’s, in many cases, going to provide a less expensive and a better service to the customer.”\nModeling Tools Needed\nJeremy Goertz, managing director of SunGrid Solutions — which was selected along with Black & McDonald to provide the engineering, procurement and construction (EPC) and balance of plant (BOP) services for the Ponoma battery project — said another challenge facing battery energy storage technology is the need for “sophisticated modeling and understanding” of the market-based approaches so utilities can maximize the benefits of batteries.\n“Batteries can do so many things and are not scripted to just one revenue stream,” Goertz said. “Many independent power producer investors are used to a more singular revenue-streamed-basis approach, such as solar-only projects, and are beginning to see the value through such projects as solar-plus-storage, as is the rest of the market, including utilities, transmission operators and independent system operators.”\nHe added, “They see the multitudes of opportunities that exist and” the evolution of those modeling tools is challenging.”\nFiguring out where the investment makes sense, such as through the distribution line or at the industrial user facility, is key, Goertz noted.\nThe acceptance of batteries in general — and Lithium-ion batteries, in particular — by financiers and developers as an accepted path has led to a heavy ramp-up of manufacturing, which has “brought down costs substantially, to the point where we’re seeing business cases that every day are making sense” to invest in, Goertz said.\nTotal Value of Storage\nSchuyler Matteson, senior project manager for the New York State Energy Research and Development Authority (NYSERDA), shared that NYSERDA has been focused on the wholesale market and “trying to make sure that the rules in the wholesale market represent the value that storage is actually providing to the market — so making sure that storage can provide capacity services to the New York ISO and be paid for it.”\nSimilarly, across the country in Oregon, Portland General Electric (PGE) is “exploring the opportunity to co-optimize all the potential value that the storage resource can deliver and gain some learnings from that to figure out what is the total value delivered back to the system over the life of the asset,” according to Darren Murtaugh, PGE’s senior manager for battery storage.\nIn 2015, legislation passed in Oregon (House Bill 2193) that directed utilities to invest in energy storage. As noted on the Oregon Public Utility Commission’s website, the legislation requires PGE and PacifiCorp to procure one or more energy storage systems by 2020.\nThrough subsequent negotiations with stakeholders and the commission, “We arrived at a place where we agreed on… five different project types that we’ll be doing — everything from an energy storage project colocated with a generation plant” to a couple of customer-sited projects, Murtaugh said.\nThe first project slated to be energized is in partnership with the city of Beaverton. The city was planning to build a public safety center and bring its own solar to the table with backup diesel generation, Murtaugh recalled. PGE offered to pair these with a utility-owned energy storage system, namely a 1-MWh battery and microgrid controller, to govern the dispatch of all resources, both grid tied and off grid. In the event of a utility outage, the microgrid controller will decide which resources to use and at what capacity to optimize the energy delivery.\nWith the microgrid controller, PGE hopes “to reduce or maybe even eliminate the need to run the diesel machines at all,” Murtaugh said.\nDiscussing challenges facing battery energy storage, Murtaugh, too, expressed a need for safety and “improving our own competency in co-optimizing the economics for energy storage, especially market participation.”\nHe added, “Here in the Northwest, we don’t have an ancillary services market, but we are recognizing value in flexible resources for our energy portfolio.”\nA neighbor of Oregon, California is one of the largest energy storage markets in the world, with about 316 MW of new storage deployed, 3,022 MW contracted or under development, and 3,080 MW of existing storage in the form of pumped hydro, according to California Energy Storage Alliance Executive Director Alex Morris. “[The] long-term trajectory of our market here is that we’ll need tons and tons of energy storage,” Morris said. “We’ll need over 10,000 MW in the next 10 years, which is a lot, and 30,000 MW in the next 20 to 25 years, roughly.”\nHe noted California is open to batteries of all types, including pumped hydro, compressed air, thermal storage, kinetic storage (like flywheels) and more. “[We] try to create market opportunities that help the grid and then let there be competition among the storage providers to see who’s the best fit,” Morris explained.\nTax Credit Changes\nCalifornia has long been aggressive with its environmental agenda, having established the first iteration of its renewable portfolio standard (RPS) back in 2002. The state then passed legislation (AB 2514) in 2010 that called for California utilities “to have energy storage as part of our tool kit,” said Morris.\nLike others, Morris said the main opportunities for batteries and other types of storage involve such policy enablers as a federal investment tax credit (ITC), which would help support storage deployments for rural areas or urban areas.\nESA CEO Kelly Speakes-Backman also noted a major priority of ESA and the storage industry is to create a level playing field for all clean technologies in the federal tax code. While energy storage currently is only eligible for the federal ITC when paired with solar, “storage can work alongside all types of power resources and often performs as a stand-alone asset to improve grid performance at the transmission or distribution level. The ITC should apply to all energy storage projects, opening up the same support provided to other energy technologies over the years.”\nAt the state level, utilities have proposed — and regulators have approved — more than 8000 MW of energy storage across the U.S., Speakes-Backman said, adding that wholesale market rules are changing to account for the multiple values energy storage provides to the grid.\nWhile dramatic and recent decreases in pricing, advances in technology and attention to improving resilience are all factors contributing to an exponential growth in energy storage markets over the next several years, she shared that COVID-19 has placed unprecedented stress on the physical and economic health of the energy storage industry.\nAmong other things, ESA is asking Congress to modify the current ITC to include stand-alone energy storage technologies and allow businesses to monetize them directly, according to Speakes-Backman. She also noted that regulators should establish clear rules for storage deployment, ownership and use; update forecast models in proceedings; streamline interconnection standards; and consider the effects rate design can have on deployment.\nO&R’s Sakib believes that as more outreach is done and more people get familiar with battery storage technology, “you’ll see a quick deployment, not just in the commercial space but also in a residential space.”\nHe added, “Storage is prime for takeoff.”\nThe industry continues to work through the challenges energy storage presents because, ultimately, it views storage as one of the tools in the tool kit that can help utilities to achieve their goals of delivering clean energy and improving reliability. “The ability to use storage to make sure that clean, zero-carbon resources can provide our [energy] need is really fundamental,” said Jason Doling, NYSERDA’s assistant director of distributed energy resources technology.\nHe pointed to the need in the downstate region of New York to bring 9 GW of offshore wind onshore and said, “The ability to use longer-duration energy storage…without needing to rely on traditional fossil generation is a huge opportunity that can only grow.”\nFor More Information:\nBlack & McDonald | www.blackandmcdonald.com\nKey Capture Energy | www.keycaptureenergy.com\nNYSERDA | www.nyserda.ny.gov\nO&R | https://oru.com\nPacifiCorp | www.pacificorp.com\nPGE | www.portlandgeneral.com\nPowin Energy | www.powinenergy.com\nSunGrid Solutions | www.sungridsolutions.com\nSource: T&D World']	['<urn:uuid:2b6debf4-4727-41f7-b2d2-1596638b4a0e>', '<urn:uuid:4b553f5c-d6de-4ed8-9a72-0da5c9bce839>']	open-ended	direct	concise-and-natural	similar-to-document	comparison	expert	2025-05-13T05:52:58.810667	11	89	2965
58	I'm passionate about food science and I'd like to understand what makes dark meat different from white meat in turkeys - what are the key differences in terms of nutritional content and culinary applications?	A turkey typically has about 70 percent white meat and 30 percent dark meat. White meat has fewer calories and less fat than dark meat. Dark meat, however, has more flavor and is particularly suitable for certain cooking methods - it adds richness to soups and stews, and holds up well when grilled or barbecued. While white meat is generally preferred in the United States, diners in other countries tend to choose the dark meat.	"['Thanksgiving dinner doesn\'t have to be difficult. We\'ve gathered a collection of tips and recipes to help guide you through through the meal.\nIt\'s a feast that Americans look forward to all year, and you\'re the cook.\nThanksgiving dinner doesn\'t have to be difficult. We\'ve gathered a collection of tips, shortcuts, timetables and recipes to help guide you through the meal preparation. The information comes from the U.S. Department of Agriculture\'s Food Safety and Inspection Service and the National Turkey Federation.\nBe sure to accept the compliments graciously.\nHow much turkey should I buy?\nFor turkeys under 16 pounds, estimate 1 pound per serving (this accounts for bone weight). For larger birds, a bit less is fine because they have a higher meat-to-bone ratio. But if your goal is to have ample leftovers, aim for 1 1/2 pounds per person, whatever the turkey\'s size.\nDo turkey prices go up during Thanksgiving?\nNo, not normally. In fact, turkey prices often go down during the holidays as many grocery stores use turkey as a ""loss leader."" This means that retailers run special, low prices on turkeys to entice customers into their store to buy other holiday foods for the traditional feast.\nFresh or frozen?\nThere is no quality difference between a fresh or frozen turkey. Frozen turkeys are flash frozen to 0 F or below immediately after packaging. Once defrosted, the meat is practically as fresh as the day it was processed. Fresh turkeys are deep-chilled after packaging and have shorter shelf lives. Because they are perishable and require special handling and merchandising, fresh turkeys are slightly more expensive than frozen turkeys.\nBy purchasing a frozen turkey, you can get the turkey in advance and take advantage of special sales and coupons. Fresh turkeys provide convenience because they do not require thawing.\nMore than two-thirds (69 percent) of those surveyed by the National Turkey Federation reported purchasing a frozen turkey for Thanksgiving dinner; 31 percent purchased a fresh turkey.\nWhat is a self-basted turkey?\nAs an option for consumers, some turkeys are sold as ""basted"" or ""self-basted,"" meaning they have been injected or marinated with a solution usually containing edible fat, natural broth, stock or water and seasonings. Self-basted turkeys are labeled with the percentage of the solution and its ingredients. Do not use self-basted turkeys when brining or deep-frying a turkey.\nHow do I thaw a turkey?\nTurkey can be thawed in the refrigerator, in cold water or in the microwave. Whole turkey takes about 24 hours per 4 pounds to thaw in the refrigerator. The refrigerator method is the safest and will result in the best finished product.\nIn cold water, changed every 30 minutes, turkey takes about 30 minutes per pound to thaw.\nWhen using a microwave to thaw a turkey, follow the manufacturer\'s instructions for the size turkey that will fit in your oven, the minutes per pound and the power level to use.\nNever defrost turkey on the counter. Once thawed, keep turkey refrigerated at 40 F or below until it is ready to be cooked. Turkey thawed in the microwave should be cooked immediately.\nWhat about the stuffing?\nStuffing or dressing should be prepared and stuffed into the turkey immediately before it\'s placed in the oven for cooking. If preparing the stuffing ahead of time, wet and dry ingredients should be refrigerated separately and combined right before stuffing the turkey.\nStuff the turkey loosely, about 3/4 cup stuffing per pound of turkey. Stuffing needs room to expand during cooking, so do not over-stuff the bird.\nIf the stuffing recipe yields more than the turkey can hold, bake the extra in a greased casserole dish.\nCooked inside or outside the bird, all stuffing and dressing recipes must be cooked to a minimum temperature of 165 F. Use a food thermometer to check.\nIt should be noted that the USDA does not recommend stuffing a turkey. For optimum safety and even cooking, it recommends cooking stuffing outside the bird in a casserole dish.\nOnce I have the bird, what do I do with it?\nRemove the neck and giblets from the neck and body cavities of the thawed turkey. Preheat the oven to 325 F for conventional ovens.\nPlace the turkey breast-side up on a rack in a shallow roasting pan. For a picture-perfect turkey, tuck wing tips ""akimbo"" under the shoulders.\nJuices from the turkey will baste the meat as it cooks. For added moisture, pour 1/2 cup water in the bottom of the pan and brush the turkey with oil or unsalted butter and seasonings or herbs.\nPlace an aluminum foil tent over the breast during the first 1 to 1 1/2 hours of cooking, then remove the foil to allow for browning.\nIf cooking stuffing inside the turkey, fill the body cavity with stuffing just before roasting. Insert a meat thermometer into the thickest part of the thigh, not touching bone. Roast the turkey, uncovered, until the meat thermometer registers at least 165 F.\nHow long do I roast a turkey?\nIn a 325 F conventional oven, use these guidelines.\n4 to 8 pounds (breast): 1 1/2 to 3 1/4 hours\n8 to 12 pounds: 2 3/4 to 3 hours\n12 to 14 pounds: 3 to 3 3/4 hours\n14 to 18 pounds: 3 3/4 to 4 1/4 hours\n18 to 20 pounds: 4 1/4 to 4 1/2 hours\n20 to 24 pounds: 4 1/2 to 5 hours\n6 to 8 pounds (breast): 2 1/2 to 3 1/2 hours\n8 to 12 pounds: 3 to 3 1/2 hours\n12 to 14 pounds: 3 1/2 to 4 hours\n14 to 18 pounds: 4 to 4 1/4 hours\n18 to 20 pounds: 4 1/4 to 4 3/4 hours\n20 to 24 pounds: 4 3/4 to 5 1/4 hours\nHow do I know when it\'s done?\nUse a two-step test for turkey doneness: First, insert a meat thermometer into the deepest portion of the thigh, not touching bone, and verify the temperature has reached 165 F. If the turkey has been stuffed, move the thermometer to the center of the stuffing and verify the stuffing has reached 165 F.\nIf the turkey is done and the stuffing is not yet 165 F, remove the stuffing from the turkey and place it in a casserole dish to be further cooked in the oven.\nLet the turkey sit about 20 minutes before carving, so juices can redistribute throughout the bird.\nWhite meat vs. dark meat\nA turkey typically has about 70 percent white meat and 30 percent dark meat. White meat is generally preferred in the United States, while diners in other countries choose the dark meat.\nWhite meat has fewer calories and less fat than dark meat. But dark meat has more flavor. It adds richness to soups and stews, and holds up well when grilled or barbecued.\nWhat are giblets?\nGiblets are the turkey\'s gizzard, heart and liver. The giblets and neck, when cooked until tender, are common additions to gravy and stuffing. If you choose to add the liver to the stockpot, do so during the last 15-20 minutes of simmering time. Overcooking the liver results in a bitter flavor.\nWhat does a Thanksgiving meal cost?\nThe American Farm Bureau Federation reported that in 2011, the average cost of the traditional Thanksgiving feast for 10 people was $49.20. The menu included turkey, stuffing, rolls and butter, cranberries, pumpkin pie with whipped cream and all the trimmings.\nSavory Herb Rub Roasted Turkey\n2 tablespoons rubbed sage or poultry seasoning\n1 tablespoon paprika\n1 tablespoon seasoned salt\n2 teaspoons garlic powder\n1 teaspoon black pepper\n3/4 teaspoon nutmeg\n1 whole turkey (12 to 14 pounds), fresh or frozen, thawed\n1 large onion, cut into wedges\n6 bay leaves\n1 tablespoon vegetable oil\nPlace oven rack in lowest position. Preheat oven to 325 F. Place roasting rack in shallow roasting pan. Mix sage, paprika, seasoned salt, garlic powder, pepper and nutmeg in small bowl.\nPlace turkey, breast-side up, in prepared pan. Sprinkle about 1/2 of the seasoning mixture inside turkey. Stuff with onion and bay leaves. Brush turkey breast with oil. Spread remaining seasoning mixture over entire surface and under skin of turkey. Add 1/2 cup water to pan. Cover turkey loosely with heavy-duty foil.\nRoast 1 hour. Remove foil. Roast 2 to 2 1/2 hours longer or until internal temperature reaches 165 F (175 F in thigh), basting occasionally with pan juices. Remove turkey from oven. Let stand 20 minutes. Transfer to platter or carving board to slice. Reserve pan juices to make gravy or to serve with turkey.\nMakes 12 servings.\nHome-style Cranberry Sauce\n1 cup sugar\n1 cup water\n1 package (12 ounces) fresh cranberries, rinsed and drained\n1/2 teaspoon cinnamon\n1/2 teaspoon grated orange peel (optional)\n1/2 teaspoon vanilla extract\nMix sugar and water in medium saucepan. Bring to boil on medium-high heat. Add cranberries, cinnamon and orange peel; return to boil. Reduce heat to medium-low; simmer 10 minutes or until cranberries burst and sauce begins to thicken, stirring occasionally.\nRemove from heat. Stir in vanilla. Cool to room temperature. Cover. Refrigerate until ready to serve.\nNote: Cranberry sauce can be prepared up to 1 week ahead. Store in refrigerator. Stir before serving.\nTo make Ginger Orange Cranberry Sauce: Prepare as directed, using 1/2 teaspoon ground ginger and orange extract in place of the cinnamon, grated orange peel and vanilla.\nMakes 2 cups or 8 (1/4-cup) servings.\n>From Spice Islands\n1 1/2 cups finely ground gingersnap cookies\n1/4 cup finely ground walnuts\n1/4 cup sugar\n5 tablespoons butter, melted\n3 packages (8 ounces each) cream cheese, softened\n1 3/4 cups sugar\n3 tablespoons all-purpose flour\n1 teaspoon vanilla extract\n1 1/2 teaspoons pumpkin pie spice\n1 can (15 ounces) pumpkin\nPreheat oven to 500 F.\nCombine gingersnaps, walnuts, sugar and butter in medium bowl. Press into the bottom and 1 inch up the sides of a 10-inch nonstick springform pan. Set aside.\nBeat cream cheese, sugar and flour with an electric mixer until smooth. Add 5 eggs, one at a time, then vanilla, beating on low speed. Transfer 2 1/2 cups to a separate bowl; set aside.\nBeat remaining egg, pumpkin pie spice and pumpkin into remaining filling until smooth. Pour half of pumpkin filling into crust, then half of the plain; repeat. Swirl gently with a spoon.\nBake at 500 F for 10 minutes; reduce temperature to 200 F and bake 30 more minutes. Tent with aluminum foil and continue baking 1 hour or until center appears nearly set. Run a knife around top of cake to loosen from pan. Turn off oven and open door to allow cake to cool gradually for 20 to 30 minutes. Remove from oven and finish cooling on a rack for 15 minutes, then chill in refrigerator at least 6 hours.\nTip: Place a pan of water in the oven with the cheesecake while baking. This will help prevent the cake from cracking.\nMakes 8 to 12 servings.']"	['<urn:uuid:a79dcbd9-7c1e-47f9-af50-cd64ea3d36ba>']	open-ended	with-premise	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-13T05:52:58.810667	34	75	1829
59	How does time work differently in physics and biology?	Time works in complex ways in both fields. In physics, through fractional calculus, the present state of a process depends on both past and future states, though this violates causality principles except for antiparticles that can move backwards in time. In biology, there's a 'self-constructing' time inversion symmetry restoration that creates a predetermined future for biological systems, enabling their self-maintenance and reproduction.	['Marina Sun / Shutterstock\nIn physics, according to the variation principle, the path taken by a particle between two points is an extremum of the action integral. This principle provides information about several symmetries of a system and their corresponding conserved quantities.\nIt is also possible to formulate all fundamental theories of physics (such as classical physics, quantum physics, general relativity and quantum field theories) with this principle. It is advantageous in many respects to describe the nature of the variation approach.\nVariation techniques cannot be applied directly to non-conservative systems. According to Bauer’s theorem, there is no single linear dissipative equation of motion with constant coefficients using variation principle techniques. However, in this theorem, the orders of derivatives are integers.\nNon-conservative systems can be described with the variation principle by using the fractional calculus. This was first proved by Riewe, and his study can be regarded as the beginning of the fractional calculus of variations. Many researchers have since developed different versions of this new technique and made significant contributions.\nFractional calculus is a branch of mathematics that generalizes the derivative (and integrals) of a function to a non-integer. Its origins go back more than 300 years. The history of fractional calculus is as old as calculus itself. In 1695 in a letter to L’ Hospital, Leibniz looked into the meaning of , if . “This is an apparent paradox from which one-day useful consequence will be drawn.” Leibniz replied, and fractional calculus was born.\nHowever, in fractional calculus, all derivatives are non-local operators. Therefore, fractional operators lead us to take non-local effects into account. In the time coordinate, non-local effects manifest as the memory effect, which states that the actual behavior of a given object is only influenced by events that happened in the past. For this reason, fractional mathematical physics approaches lead to a more effective way to investigate the problems in non-linear and complex systems.\nIn the last few decades, fractional calculus has appeared in different fields of science, including electrical circuits, quantum mechanics, statistical physics, and nuclear physics. Consequently, according to fractional calculus, physical processes evolve in fractal space-time. Hence, this behavior of space and time is not compatible with constraints of Euclidean geometry and context of Markovian approach. Therefore, using the fractional calculus instead of standard mathematics allows us to make a more realistic description of nature\nOn the other hand, some difficulties are encountered in this formalism. The most important difficulty is the simultaneous presence of left and right derivatives. From the viewpoint of physics, in the time domain, the left fractional derivative represents the past state of the dynamical process, whereas the right fractional derivative represents the future state of the dynamical process. In other words, the present state of any process depends on the past and future states of the process in the fractional approach.\nHowever, this means that the fractional version of Euler-Lagrange equation clearly violates the principle of causality for physics. In physics, the principle of causality states that the present behavior of a given object is only influenced by all its past states.\nNevertheless, in quantum mechanics, according to Feynman’s and Stückelberg’s views, antiparticles propagate backwards in time and hence fractional right derivative operator could be used to describe the velocity of an antiparticle. However, presence of right derivative seems to be a definitive failure for the non-conservative systems. In the literature, there are several techniques which are proposed to overcome this problem.\n- P. S. Bauer, Proceedings of the National Academy of Sciences of the United States of America, 17, 311 (1931)\n- F. Riewe, Physical Review E 53, 2, 1890 (1996)\n- F. Riewe, Physical Review E 55, 3, 3581 (1997)\n- R. P. Feynman, Physical Review 76, 6, 749 (1949)\n- E.C.G Stueckelberg, Helvetica Physica Acta 14, 322 (1941)\n- E.C.G Stueckelberg, Helvetica Physica Acta 15, 23 (1942)', 'On the Origin and Invariance of the Genetic Assignments as Elementary Semiotic Controls: A Basic Hypothesis\nEuropean Journal of Biophysics\nVolume 2, Issue 3, June 2014, Pages: 17-28\nReceived: Jul. 23, 2014;\nAccepted: Aug. 3, 2014;\nPublished: Aug. 10, 2014\nViews 2215 Downloads 85\nAndrás Balázs, Department of Biological Physics, ELTE TTK Budapest, H – 1117 Pázmány s. 1/A, HUNGARY\nIn this paper we hope to place the two basic facts of life, constant active self – maintenance and self – reproduction, into a fresh light. The basic idea is considering the genetic assignments as a „biological invariant of motion”, the latter forming a hierarchically produced, „self - constructing”, regressive time inversion symmetry restoration, a closed semantic real – time upbuilding loop. It is, actually, the predetermined future of the biological system. It is this, in fact, what gives birth to the above strange fact of determined self – maintenance and, as its derived consequence, „self” – reproduction, as the symmery attained. It is carried out in a mediated, „weak” self – reference loop, as a natural prerequisite for the invariance of the genetic code as a „biological invariant of motion”. Being an involved and dubious case, as it is usual, we mainly concentrate on its origin. We suppose a special type of quantum measurement as the original assignation mechanism, with a usual concomitant time inversion symmetry breaking. Symmetry restoring, in fact, is a semiotic control process of the genetic code, the process tentatively conceived to be the living (biological) state of matter.\nOn the Origin and Invariance of the Genetic Assignments as Elementary Semiotic Controls: A Basic Hypothesis, European Journal of Biophysics.\nVol. 2, No. 3,\n2014, pp. 17-28.\nBalázs A (2013) The biological “invariant of motion” vs. “struggle for life”? On the possible quantum mechanical origin and evolution of semiotic controls in biology. Information 4, 367 – 397.\nNeumann, J (1955) Mathematical Foundations of Quantum Mechanics (Princeton University Press, Princeton), Chapters V. – VI.\nWigner, E P (1961) Remarks on the mind-body question. The Scientist Speculates. ed. Good I.J., (Heinemann, London), pp. 284–302.\nBelinfante FJ (1975) Measurement and Time Reversal in Objective Quantum Theory. (Pergamon Press Ltd., Oxford)\nNicolis, G., Prigogine, I. (1977) Self-Organization in Non-Equilibrium Systems. (Wiley, New York)\nKauffman S (1993) The Origins of Order. (Oxford University Press, Oxford – New York)\nPatel A D (2008) Towards understanding the origin of genetic languages. Quantum Aspects of Life. eds. Abbot D, Davies P, Pati, A, (Imperial College Press, London), Ch. 10. arXiv: 0705.3895v2\nCrick F H C (1968) The origin of the genetic code. J. Mol. Biol. 38, 367–379.\nPattee, H H (1971) Can life explain quantum mechanics? Quantum Theory and Beyond ed. Bastin T, (Cambridge Univ. Press, Cambridge), pp. 307 – 319.\nPattee, H H (1974) The vital statistics of quantum dynamics. Irreversible Thermodynamics and the Origin of Life. eds. Oster, G.F., Silver, I.L., Tobias, C.A., (Gordon and Breach Science Publishers, New York), pp. 33 – 43.\nBashford, J D, Tsohantjis, I, Jarvis, P D (1997) Codon and nucleotide assignments in a supersymmetric model of the genetic code. Phys. Lett. A. 233, 481–488.\nBashford, J D, Tsohantjis, I, Jarvis, P D (1998) A supersymmetric model for the evolution of the genetic code. Proc. Nat. Acad. Sci. USA 95, 987–992.\nDarwin C R (1859) The Origin of Species. (Murray, London)\nElze, H-T, Gambarotta, G., Vallone, F. (2011). Path integral for classical dynamics, entanglement, and Jaynes-Cummings model at the quantum-classical divide. Int. J. Quantum Inf. 9, 203–224.\nDawkins R (1976) The Selfish Gene. (Freeman and Co., Oxford)\nDyson F (1999) Origins of Life. (Cambridge Univ. Press, Cambridge)\nMatsuno K (1989) Protobiology: Physical Basis of Biology. (CRC Press, Boca Raton)\nPatel A D (2001). Quantum algorithms and the genetic code. Pramana – The J. of Phys. 56 (2- 3), 367 – 381.\nPattee, H H (1973). Physical basis and origin of hierarchical control. Hierarchy Theory, ed. Pattee, H H, (Braziller, New York), Ch. 4.\nZurek W H (2008) Relative states and the environment: einselection, envariance, quantum Darwinism and the existential interpretation. arXiv: 0707.2832v [quant-ph]\nWigner E P (1961) On the probability of the existence of a self – reproducing unit. The Logic of Personal Knowledge: Essays Presented to Michael Polanyi (Routledge and Kegan Paul, London), pp. 231 – 238.\nStapp H P (1993) Mind, Matter and Quantum Mechanics (Springer, Berlin – New York)\nPopa R (2004) Between Necessity and Probability: Searching for the Definition and Origin of Life (Springer Verlag , Berlin – Heidelberg)\nBohr N (1934) Atomic Theory and the Description of Nature (Cambridge Univ. Press, London)\nWigner, E. P., 1959. Group Theory and its Application for the Theory of Atomic Spectra, (Academic Press, New York)\nConrad M. (1989) Physics and biology: Towards a unified model. Appl. Math. Comp. 32, 75 – 102.\nConrad M. (1993) The fluctuon model of force, life and computation. Appl. Math. and Comp.56, 208 – 259.']	['<urn:uuid:a68fba40-5662-4d38-8aba-ba74352de09c>', '<urn:uuid:1db43590-9fa9-4fa0-a9bd-c95b2260d63e>']	open-ended	direct	concise-and-natural	similar-to-document	three-doc	novice	2025-05-13T05:52:58.810667	9	62	1456
60	What role does feeding schedule play in pet health, and how can indoor pets stay fit?	The common practice of offering food at all times rather than at set mealtimes encourages overeating and makes housetraining puppies more difficult. This can lead to obesity, which is a significant health risk. For indoor pets, particularly cats, maintaining fitness requires active play sessions of 5-10 minutes, 2-3 times daily. Activities can include stalking, running, jumping, and using food puzzles or scattered feeding locations to mimic natural foraging behavior. These strategies encourage both physical and mental activity, helping prevent obesity and maintain good health.	"['Spring and summer are popular times for families to adopt a new puppy or kitten. Good nutrition is one of the key factors in ensuring that your new family member achieves their full potential. Research in the growing field of pet nutrition has resulted in better understanding of the needs of puppies and kittens, and has lead to new recommendations in feeding.\nWe know that young kittens and puppies have unique nutritional requirements that change as they grow. Very young animals have difficulty digesting complex carbohydrates due to a lack of digestive enzymes. Excessive carbohydrate intake can result in diarrhea in these youngsters. As their digestive systems develop, they begin producing the enzymes that are needed to digest carbohydrates, so older kittens and puppies are less susceptible to this problem. Young puppies and kittens are also more sensitive than adults to dietary imbalances, particularly protein deficiency or calcium excess. A deficiency in protein can slow growth and cause irreversible skeletal problems, while excess calcium can lead to bone and joint problems.\nLike human children, it has been shown that DHA (docosahexaenoic acid), an omega-3 fatty acid, supports optimal brain development and vision in puppies and kittens. The greatest period of brain development in puppies and kittens occurs before 12 weeks of age. Feeding a diet that is rich in DHA will permit puppies and kittens to reach their full potential and develop healthy brain and eye tissues.\nAs puppies and kittens approach puberty, their metabolism slows and their nutritional needs decrease. When they are surgically sterilized through castration or ovariohysterectomy, they will undergo additional metabolic changes that further decrease their energy requirements.\nVeterinarians and nutritionists agree that the most important two pieces of advice they can give owners of kittens and puppies are to feed a good quality growth diet and to avoid overfeeding. The common practice of offering food at all times rather than as set mealtimes encourages overeating, as well as making it more difficult to housetrain puppies. A fat puppy or kitten is more likely to be an obese adult, and obesity has become one of the more important health issues for adult dogs and cats. Obesity predisposes pets to other health problems, most notably diabetes and joint problems. Joint problems such as arthritis occur in about 20% of all dogs and cats, according to clinical research studies.\nAs pet owners, it is up to us to monitor our pet’s food consumption and body condition, and to provide the optimal amount and type of food to meet their nutritional needs and maintain a healthy weight. We, as your veterinary health care providers, can answer specific questions about feeding your puppy or kitten, and can give you professional advice about the general care of your new friend, thus optimizing their chance to lead a long and healthy life.\nCaution: These news items, written by Lifelearn Inc., are licensed to this practice for the personal use of our clients. Any copying, printing or further distribution is prohibited without the express written permission of Lifelearn Inc. Please note that the news information presented here is NOT a substitute for a proper consultation and/or clinical examination of your pet by our clinic veterinarian.', 'There are times I find it awkward discussing weight issues with clients. It is not easy telling a pet parent that their beloved furry friend is overweight and suffering from it. Many don’t want to hear it, some take offense, while others feel guilty and beat themselves up over it. No matter the situation, while it is not a favorite subject of mine, it is an important topic given the negative implications it has on health and well-being. Grab a cup of coffee and relax, while you read further about ways in which to pay attention to your cat’s weight and what to do if it is not ideal.\nMost of us consider ourselves good pet parents and our cats as family members. Like any family member, health is a priority. However, obesity in cats is rising and being overweight puts them at significant risk for many health issues and shorter lives. It can reduce their overall quality of life by interfering with the normal activities they used to enjoy when they were more physically fit. Just like us, carrying excess fat creates excess stress on joints, affects the heart, kidneys and other vital organs, and can lead to diabetes and a multitude of serious medical issues. Here are a few facts you should know.\n- According to the Association for Pet Obesity Prevention, 59% of American cats are estimated to be obese.\n- 15% of cat owners said their pet’s weight was normal when it was actually overweight or obese.\n- The five states that rank highest for obese cats are Minnesota, Nebraska, Iowa, Idaho, and Delaware\nIs My Cat Too Fat?\nDetermining if your cat is overweight isn’t as simple as stepping on a bathroom scale. Healthy cats come in all shapes and sizes, and there’s no single “right” weight. Depending on breed and body type, your cat could have an ideal weight range of anywhere from 7 to 25 pounds. The best way to discover if your cat is overweight is by calculating their body condition score. This is something your vet should do at every visit. A body condition score is a number assigned to a cat’s body type ranging from 1-9, with 1 being very underweight and 9 being very overweight. Ideally, your cat will have a body score around 5, indicating the most healthy cat weight.The way to evaluate your cat’s BCS is to view their body silhouette from above and from the side. The key structures to look at are the ribs, spine, hip bones, waist, abdomen and muscle mass. At a healthy weight, you should be able to see your kitty’s waistline (an hourglass figure) from above. From the side, your cat’s abdomen should appear tucked up behind the rib cage.\nIt is also important to use your hands to feel your cat’s body to evaluate his/her weight and you can do so by placing your thumbs on your cat’s spine and spreading both hands across the rib cage. Ideally, you should be able to feel each rib under a thin layer of fat.\nThis chart by the WSAVA will help you evaluate your fur baby’s BCS.\nAnother recommended resource to determine if your cat is overweight can be found on WikiHow\'s article, How to Determine if Your Cat is Overweight?\nWhy Are So Many Cats Overweight?\nIt is quite simple and these are four of the most common reasons that cats are packing on the pounds are:\n- They are on the wrong diet\n- They are being overfed\n- Too many treats\n- Too little exercise\n1) DIET - Because every cat is different, you should discuss a weight loss diet with your feline\'s veterinarian. Counting calories is important and your vet can give you the best guidance on how many calories your cat should be consuming daily based on breed, age, lifestyle, and body condition score. Canned food is lower in calories than dry, contains more protein and water which is why it is ideal for helping cats lose weight or stay trim.\nIt is very important that cats lose weight slowly over time and under the supervision of a veterinarian. That is because overweight cats are prone to hepatic lipidosis or fatty liver syndrome. This can happen when they mobilize accumulated stores of fat that overwhelm their liver and shut it down. Owners should work with their pet healthcare practitioner to determine the amount of weight that needs to be lost and the rate at which it should occur.\n2) EXERCISE - With pet obesity at an all-time high, active play and exercise are crucial and we cannot emphasize the importance of it enough. It is the key to prevention, weight loss, and maintenance. “The causes of obesity are varied and complex, but the lack of daily physical activity is an important factor. - Risa Lavizzo-Mourey\nPreventing the serious side effects of being obese is easy and fun. All it takes is getting your cat to run, chase, hunt, pounce and play for 5 - 10 minutes, 2 -3 times a day. That\'s it! Playing with your cat is amusing and entertaining and makes you both happy so why not do more of it together?\nToys that encourage stalking, running and jumping are good for maintaining muscle strength and burning calories. They help release endorphins and can provide an outlet for their instinctive prey-chasing behavior. Wands toys of all kinds are great for getting cats to run and chase. Ball toys like our Wiggly collection also encourage active play and exercise. Chasing laser lights, playing fetch, hide and seek, and other kitty games work well to keep most felines engaged. But remember, they can quickly tire of the same toys so it’s a good idea to have several different ones on hand that you can rotate out frequently. This way they will always have ""new"" toys to play with.\nIndoor cats are at greater risk for obesity due to their lifestyle and they depend on their owners to ensure they have plenty of opportunities to be active. Exercise prevents boredom and makes life more natural for our indoor cats. Check out New Ways to Eliminate Kitty Boredom for a more in-depth look at how boredom affects our indoor kitties.\n3) FOOD PUZZLES AND FORAGING - Outdoor cats burn calories while having to scavenger, hunt or beg for their food which helps keep them lean. Giving indoor cats the same opportunities is possible too. Playing with your cat before feeding him/her mimics the lifestyle of a cat that hunts in order to eat. If your cat is more of a scavenger, divide your cat’s food into multiple bowls and scatter them around the house. Cats benefit from the use of interactive toys that dispense food and toys they have to manipulate in order to receive their kibble. These strategies are effective at encouraging both physical and mental activity which is good for both body and mind. There are many creative ways in which to feed indoor cats today and combining many different strategies might be the best way to go.\nIs There Anything Else I Can Do?\nStay well informed. Because obesity can be defined as an excess of body fat that is enough to impair health, welfare, and quality of life, it is critical that pet parents help their cats maintain their ideal weight. While diet is an essential element, it is no more important than adequate exercise, play and the opportunity to be fit and active.\nOctober 11, 2017, is National Pet Obesity Awareness Day and the Pet Obesity Prevention Organization is conducting an online survey and looking for input from cat owners like you. Visit their website for the most current information on the pet obesity problem and you will also find lots of tools and articles to help you keep your cat fit and healthy.\nWe are curious what BCS you would rate your cat and what is the most important reason for it? If your cat is at its ideal weight what contributing factors do you think matter most and what advice would you give owners whose cats are overweight? We would like to hear from owners whose cats are obese to learn more about what challenges they face that make it difficult for them to keep their cats lean. Leave your comments below.']"	['<urn:uuid:5316fa4f-cc8b-4963-af8e-3e93bcba7657>', '<urn:uuid:18e2d9f0-6b0c-4f69-82cb-96b205f98a7f>']	open-ended	direct	concise-and-natural	distant-from-document	multi-aspect	expert	2025-05-13T05:52:58.810667	16	84	1922
61	modern rice farming challenges solutions developing countries production methods	Rice production faces multiple challenges including less available land, labor, and water due to urbanization and population growth, further complicated by climate change. Solutions include mixed farming systems that have proven more resilient and productive than traditional methods. In Indonesia, for example, a polyculture system combining rice with fish, ducks, and water ferns has shown groundbreaking results, offering higher yields without pesticides or artificial fertilizers. This is crucial as rice has twice the value of production in the developing world of any other food crop, exceeding $150 billion per year.	['Abstract: Rice is the most important food crop of the developing world and the staple food of more than half of the world’s population, many of whom are also extremely vulnerable to high rice prices. In developing countries alone, more than 3.3 billion people depend on rice for more than 20% of their calories. One fifth of the world’s population, more than 1 billion people, depends on rice cultivation for livelihoods. Harvested from 158 million hectares annually, rice has twice the value of production in the developing world of any other food crop: more than $150 billion per year. Nearly 560 million people living on less than US$1.25 (purchasing power parity [PPP]) per day are in rice-producing areas, far more than for any other crop. Rice remains productive in flooded environments where most other crops would fail. Production systems are unique and the longevity of rice farming speaks for itself. Irrigated lowland rice, which makes up three-quarters of the world rice supply, is the only crop that can be grown continuously without the need for rotation and can produce up to three harvests a year—literally for centuries, on the same plot of land. To maintain future global rice supplies many challenges must be addressed. There will be less land, labour and water available as economies grow, urbanization continues and populations increase. The effect of climate change will only exacerbate the challenges. The research pipeline must be fortified to insure a steady supply of new technologies suitable for adoption by small holder rice farmers. Increased investments are required by both the public and private sectors in the following thematic areas:\n- Harness genetic diversity to chart new productivity, quality, and health horizons\n- Accelerate the development, delivery, and adoption of improved rice germplasm\n- Increase the productivity, sustainability, and resilience of rice-based production systems.\n- Extract more value from rice harvests through improved processing and market systems and new products\n- Foster improved policies and technology targeting to enable improved rice production and marketing.\nSpeaker Profile: Robert ”Bob” Zeigler is an internationally respected plant pathologist with more than 30 years of experience in agricultural research in the developing world. He is currently the director general and chief executive officer of the International Rice Research Institute (IRRI). IRRI has around 1,300 scientists and support staff. Its headquarters are in the Philippines, with offices in 15 countries and activities in more than 25 others. IRRI focuses on sustaining, understanding, and using the genetic diversity of rice to improve rice productivity and the livelihood of rice farmers and consumers. There is also a major research emphasis on improving sustainable production practices and understanding the social and political context in which improved rice production systems operate. Dr. Zeigler’s research career has focused on the genetics of host plant resistance, the interaction of plants and their pathogens and pathogen population biology. Most of his work has been with rice and its pathogens. Dr. Zeigler is an elected fellow of the American Association for the Advancement of Science and of the American Phytopathological Society and is a member of the honor societies Sigma Xi (The Scientific Research Society) and Gamma Sigma Delta (agriculture). He is the recipient of several other prestigious awards throughout his career. He earned degrees at Cornell University (Ph.D), Oregon State University, and the University of Illinois (High Honors). Dr. Zeigler has authored and co-authored well over 100 refereed international journal articles, reports, and scientific papers and has delivered numerous invited lectures worldwide. He is married and has three grown children.', 'Mixed farming increases rice yield\nPublished on: December 12, 2018\nA standard Indonesian rice field may look pretty with a mountain backdrop. But these one crop agriculture systems are not future proof. The extreme weather we are facing due to global warming asks for more resilient systems that restore ecosystems rather than deplete them. Ph.D. candidate at Wageningen University & Research Uma Khumairoh shows that a polyculture with fish, ducks, water ferns and rice is a more resilient and, at the same time, more productive system.\nClimate change and food security\nIndonesia has already suffered from changing weather patterns. Although the country is the third largest rice producer worldwide, it had to increase their rice import with 44% in the last couple of years, due to the growing population and disappointing harvests. The weather changes could also cause more weeds, diseases, and pests in the Indonesian rice fields. Since it is expected that climate change creates variable weather conditions ranging from droughts to floods, food security is in danger. The need for a resilient and sustainable agriculture system rises.\nGroundbreaking results from mixed farming\nKhumairoh did her research on a polyculture with rice, fish, ducks and water fern in four different regions in Indonesia. She compared the polyculture with conventional rice fields and organic rice fields. Conventional agriculture had a higher yield in normal weather conditions. But the yield decreased dramatically in extreme conditions. The organic rice production had a smaller harvest but turned out to be more resilient in harsh conditions. The results of the mixed farming system, however, are groundbreaking.\nNot only was the system the most resilient in extreme weather, but it turned out to be the most productive compared to the conventional and organic agriculture. This robust form of agriculture with higher yields and without the use of pesticides or artificial fertilizers could be an example for all the rice-producing countries. The research was recently published in Nature Scientific Reports.\nHow does the polyculture function?\nCombining rice, fish, ducks and water ferns appears to be a better alternative than the monoculture of rice (organic or conventional). This polyculture does not need artificial fertilizers or pesticides. The ducks and fish eat Azolla and insect and crab pest. Duck feces and water ferns provide nutrients for the rice plants and the ducks and fish eliminate pesticides and herbicides, ensuring the natural enemies of rice pests can settle. The plant roots of the rice can soak up nitrogen better when the ducks and fish move around in the rice field to circulate oxygen. Khumairoh found a win-win combination.\nUma Khumairoh on experimental farming\nI spoke with Uma Khumairoh, who is currently in Indonesia, about sustainable agriculture and all its benefits. “I like to work on participatory, experimental farming together with farmers,” she says through Skype, “so that they can observe and give feedback as well as adopt research findings very quickly in their fields.” For Khumairoh, her fascination for rice farming started when she was working for an NGO on a project about the system of rice intensification (SRI). “We wanted to grow rice organically, but we couldn’t find organic fertilizers easily. Organic rice growing in Indonesia is still a monoculture. And the necessary animal manure is hard to come by, as Indonesia doesn’t have much livestock. When I did a Master’s at Wageningen University, I followed courses focusing on crop-livestock systems. Teachers gave assignments to design a system with animals and crops, and I chose rice, ducks, fish and water ferns as the basis to develop these complex rice systems.”\nCrop diversity gives farmers a more significant income.\n“The yield was very high in this first experiment, but we had to buy feed for the ducks, and we transported organic matter outside the farm to be composted. So, in my Ph.D. research, I added border plants to the system. The approximately 20-30 centimeters of dry land around the rice fields (called bunds) was used for growing duck feed, such as the nitrogen-fixing plant sunn-hemp and corn. We implemented this mixed system on the land of eight farmers in four regions. But after a while, some farmers started using their bunds to grow sweet potatoes, chili or eggplant. The farmers could get more income from selling these vegetables, and they chose to buy the duck feed instead of growing it themselves. It was crucial for the farmers to get this additional income from the vegetables while waiting for the rice harvest.”\nThe many advantages of mixed farming\nBesides the benefits of high yields, resilience in changing the weather and the reduction of the use of pesticides and herbicides, there’s another significant advantage for the farmers. “60% of the costs of growing rice consists of labor costs for weeding”, says Khumairoh. “All the weed removal has to be done by hand. We have many old farmers in Indonesia who can’t find people to do this for them. When the farmers can’t do this job on time, the weeds limit the growth of the rice. With this system, the ducks do all the weed removal, so competition of rice against weed is eliminated.”\nMixed farming works very well, is climate proof and gets high yields. But why are many farmers still hesitant to implement this sustainable rice system in their businesses? Khumairoh: “It is a huge investment for farmers. The rice bund is very small, so they have to invest in labor and materials to make the bund bigger to be able to grow vegetables on it. Then they need to buy ducks and fish and expensive nets to keep the ducks fenced in. Besides the high cost of investment, it is difficult to educate farmers about this production system. Khumairoh: “When I ask farmers why they keep using their conventional techniques for rice farming, they tell me that they get itchy skin from the manure of the ducks in the water. But the pesticides they spray are the root cause of their skin problems.\nDespite the trade-off on high costs, however, once you have this infrastructure, the only job you have is to maintain it. You don’t have to pay for herbicides, you don’t have to buy fertilizer, and you save much money and time on weeding.” Farmers need to know how to calculate short-term and long-term investments. Unfortunately, many rice farmers in Indonesia are illiterate. They don’t have good access to information. So, we have to find an appropriate method to transfer this knowledge.”\nKhumairoh also teaches Ecological Design and Permaculture at Wageningen University. Did she use permaculture as a design tool for her mixed system with rice, fish, and ducks? “It was not my intention to apply permaculture in my research, but it turned out to be permaculture after all. We take care of the land, the animals and the farmer. Just like the traditional system in a rural region in Java isn’t called permaculture, but it is indeed the same. For centuries, this pekarangan (a form of forest farming) in remote areas is very common and practiced in every household in this region. In pekarangan, you grow herbs and spices next to the kitchen, legumes, cassava, and other tubers, coconut, herbal, coffee, many types of fruit and vegetable trees, chickens and other poultry, a fish pond, et cetera. These families harvest all year round from their pekarangan and have been self-sufficient for ages.”\nWatch how the complex rice system of Uma Khumairoh works in the field of small-scale rice farmer Yopi Heriyanto in East-Java, Indonesia.']	['<urn:uuid:2d19a3c1-738a-4c0b-9ac3-c61bbd848e15>', '<urn:uuid:f1b1b8bf-918b-4f37-a9bf-3b019b4a4b9f>']	factoid	with-premise	long-search-query	distant-from-document	three-doc	novice	2025-05-13T05:52:58.810667	9	90	1835
62	explain main obstacles detecting financial mismanagement government institutions	Detecting fraud in government institutions faces several key challenges. First, there is often noisy data where identical records may have different problem identifications. Second, pattern recognition techniques can only find previously known patterns. Third, the small numbers of identified fraud cases make it difficult to build reliable models. Fourth, fraud detection requires high-skilled investigators to manually search through large amounts of computer data, while fraud continues to occur. These limitations hamper effective detection of improper payments, fraud, waste and abuse.	['Governments at all levels are faced with the challenge of setting agendas and creating the frameworks to improve the lives of citizens. As we all know, government touches each of us daily. Policies and initiatives come and go, each seemingly different from the last. Yet, they all have one thing in common: They all cost money, often a great deal of money. The undeniable truth of government is that it is an expensive business; typically, the more radical the agenda or the more holistic the policy, the more it will cost. Another sad truth is that where there is money, there is also fraud, abuse and error. Such misuse—intentional or not—costs the government and, ultimately, the taxpayers.\nConsider for a moment fraud in the government. If we accept that government exists to serve the people, to “improve our lives,” then fraud against the public purse removes some of the funding that could improve the lives of all of us, especially those most in need of government support. Not only is government fraud morally, ethically and legally wrong, it is the antithesis of everything good government stands for. Billions of revenue paid by hardworking citizens are lost each year due to improper payments, fraud, waste and abuse. Governments at all levels—federal, state and local—face the enormous challenge of rectifying this situation. What can agencies do to improve collection rates? How do they increase the productivity, effectiveness and efficiency of their auditors and investigators? By identifying a prioritized list of accounts that have a high likelihood of being fraudulent, agencies can optimize investigators’ time and increase the funds collected.\nImplementing a strategy and technology solution to find improper payments, fraud, waste and abuse helps governments ensure that vital services and programs that citizens desperately need are there for them. While fraud, waste and abuse have been identified as areas in which data mining is applicable, actually using data mining techniques for this application has historically relied on flagging cases where there are known problems, building models (or profiles) of these problems and “scoring” new data based on the profiles. Although this approach is useful, it is inappropriate to use only this technique because of the following limitations:\n1. A situation in which there are two identical records. Problem behavior is sometimes found in one record, while the other record is not even checked. This results in noisy data and problems with model building.\n2. The limitations of pattern recognition techniques. Pattern recognition techniques are only able to find patterns that have been found in the past. This means that the existing fraud, waste and abuse often remains undiscovered.\n3. Small numbers of identified cases of fraud, waste and abuse. When numbers are low, reliable models cannot be built.\n4. Offender behavior changes. Once offenders realize that a certain behavior triggers a problem, they no longer commit that behavior. Then models have to be built to capture the new offending behavior.\nFraud detection is generally hampered by the need for high-skilled investigators plowing their ways through backlogs of computer data, with successive findings triggering new questions involving new painstaking searches; in the meantime fraud, waste and abuse continue. This paper discusses systematic approaches to detecting fraud in three broad categories: vendor fraud, diversion of public funds, and service consumer fraud. Part 2 of fraud detection in government will provide an overview of public sector fraud schemes, then discuss traditional methods and data mining techniques for fraud detection, as well as the implementation of monitoring and reporting systems.']	['<urn:uuid:38e6c007-92c6-40a6-9ca3-6db3f1856db8>']	open-ended	with-premise	long-search-query	distant-from-document	single-doc	expert	2025-05-13T05:52:58.810667	8	80	584
63	geocentric model success failure history	The geocentric model, based on Aristotelian principles, dominated early astronomy with its view of a static Earth at the center of the universe surrounded by ten crystal spheres. Ptolemy perfected this model in the Almagest using complex epicycles, making it so successful that it remained the accepted text for over twelve hundred years. However, as astronomical instruments improved, more epicycles were needed to explain planetary motions, making the system increasingly complicated. This complexity, along with Copernicus's simpler heliocentric model that explained planetary motions more elegantly, eventually led to the geocentric model's decline.	"['Presentation on theme: ""Toward a New World-view""— Presentation transcript:\n1 Toward a New World-view Cover SlideChapter 18Toward a New World-view\n2 The Scientific Revolution / a new world View The scientific revolution of the seventeenth century was the major cause of the new viewScientific thought in the early 1500s was based on ancient and medieval ideas.European notions about the universe were based on Aristotelian principles. (Aristotelian View)A chief feature of this view was the belief in a motionless, static earth at the center of the universe.The four elements / fit with Christianity / science was a branch of theologyTen crystal spheres moved around the earth.\n3 The Scientific Revolution / a new world View Copernicus overturned the medieval view of the universe. (Copernican Hypothesis)He postulated that the earth revolved around the sun and that the sun was the center of the universe.This heliocentric view was a departure from the medieval view and created serious misgivings about traditional Christianity.\n4 Copernican SystemThis illustration of the Copernican System from the published text of Copernicus\'s treatise On the Revolutions of the Heavenly Spheres (1543) shows the earth and the planets revolving around the sun. Copernicus challenged traditional astronomy and its earth-centered universe. (Erich Lessing/Art Resource, NY)Copernican System\n5 The Scientific Revolution / a new world View Scholars from Brahe to Galileo contributed to the new world view.Tycho Brahe built an observatory and collected data.Johannes Kepler / the Three laws of planetary motionElliptical planet orbit / non-uniform speedOrbit time related to distance from the sunGalileo discovered the laws of motion usingthe experimental method.Law of inertia (at rest is not the natural state)Dialogue on two systems ….Poked fun at Aristotle / churchBankrolled by the Medici\n6 GalileoGalileoThis 1624 engraved portrait by Ottavio Mario Leoni ( ) of Galileo Galilei ( ) shows the Italian scientist in full vigor at age 60, before he was hounded by the Roman Inquisition.\n7 Galileo\'s moon paintings When Galileo Galilei ( ) published the results of his telescopic observations of the moon, he added these paintings to illustrate the marvels he\'d seen.\n8 The Scientific Revolution / a new world View With math Newton synthesized the integral parts into a whole.Principia (Newtonian Physics)Newton integrated the astronomy of Copernicus and Kepler with the physics of Galileo.He formulated a set of mathematical principles to explain motion.Law of universal Gravity\n9 Madame du ChateletGabrielle-Emilie Le Tonnelier de Breteuil, marquise du Chatelet ( ) was an intellectually gifted women from the high aristocracy with a passion for science. She was fascinated by the new world system of Isaac Newton. She helped to spread Newton\'s ideas in France by translating his Principia and by influencing Voltaire, her companion for fifteen years until her death. (Giraudon/Art Resource, NY)Madame du Chatelet\n10 The Scientific Revolution / a new world View Causes of the scientific revolution.Medieval universities had provided the framework for the new view.The Renaissance stimulated science by rediscovering ancient mathematics.Better ways of obtaining knowledge about the world improved the scientific method.Bacon advocated empirical, experimental research.Descartes emphasized deductive reasoning.\n11 Descartes in SwedenLouis Michel Dumesnil ( ) painted Queen Christina of Sweden surrounded by her court, listening to Descartes give a lecture on geometry. She encouraged art and science, and she invited many foreign artists and scholars to visit her court. The daughter of Protestant hero Gustavus Adolphus, Christina rejected marriage, abdicated in 1654, and converted to Catholicism. (Photographie Bulloz)Descartes in Sweden\n12 Enlightenment ideas expressed this new world-view The overriding idea was that natural science and reason could explain all aspects of life.The scientific method can explain the laws of mankind.Progress is possible if the laws are understood and followed.Gresham CollegePut science on par with religion studyForerunner of Royal Society of London\n13 Enlightenment ideas expressed this new world-view Many scholars made Enlightenment thought accessible to a wide range of people.Fontenelle stressed the idea of progress.Skeptics such as Bayle believed that nothing could be known beyond all doubt.Locke stressed that all ideas are derived from experience.\n14 Science from Fontenelle\'s work The most famous and influential popularizer of science was a versatile French man of letters, Bernard de Fontenelle ( ). The frontispiece illustration of his Conversations on the Plurality of Worlds invites the reader to share the pleasures of astronomy with an elegant lady and an entertaining teacher. The drawing shows the planets revolving around the sun.Science from Fontenelle\'s work\n15 Enlightenment ideas expressed this new world-view The philosophies = Elites committed to the fundamental reform of society.Montesquieu’s theory of the separation of powers was fundamental.Voltaire challenged traditional Catholic theology.The later Enlightenment writers created inflexible and dogmatic systems.\n16 Statue of VoltaireThe greatest portrait sculptor of his day, Jean-Antoine Houdon ( ) completed a statue of Voltaire in 1781, a statue commissioned by Catherine II of Russia. Voltaire posed for the sculpture as a frail old man, which is evident in the deep wrinkles of his face and the dry, papery skin of both his face and hands. Nonetheless, Houdon captures Voltaire\'s intellect and wit in his incisive gaze. (Scala/Art Resource, NY)Statue of Voltaire\n17 Producing the Encyclopedie Denis Diderot ( ) wanted to present all valid knowledge--that is, knowledge based on reason and the senses and not on tradition and authority. This plate, one of 3,000 detailed illustrations accompanying the 70,000 essays in Encyclopedia: The Rational Dictionary of the Sciences, the Arts, and the Craft, shows (from left to right) compositors setting type, arranging lines, and blocking down completed forms. Printed sheets dry above. (Division of Rare & Manuscript Collections, Cornell University Library)\n18 Urban Culture and Public Opinion Writing transformed urban cultureThe market for books grewSelling books /promoting ideas(like the internet issues today)Based on increased literacy rateNon-religious booksCensorship became an issueImmanuel Kant support Fredrick II because he did not censor books\n19 Urban Culture and Public Opinion The Salons and their influenceUsually run by womenSalons circumvented censorshipBrought together the best and brightestDiscussed the enlightenment and philosophyFunctioned as informal schools for womenIn France Books became the issueBooks were banned / based on topicOnly Agriculture and industry were safeThe Govern / church maintained control over thought\n20 Growth of the book trade Book ownership dramatically increased in the eighteenth century, and a wide range of secular works--from racy novelettes to philosophical tracts--were available in print. This painting of a bookshop, A L\'Egide de Minerve, shows shipments of books that have arrived from around Europe. Notice the artist\'s optimism in the great variety of persons, from the peasant with a scythe to a white-robed cleric, who are drawn to the shop by ""Minerva"" (the Roman goddess of wisdom). (Musee des Beaux-Arts, Dijon)\n21 The Enlightenment and Absolutism The philosophes believed that enlightened monarchs would create the necessary reforms.Not political at first / some believed that curbing the monarchy would increase libertyThey believed that a benevolent absolutism offered the best chance for progress.\n22 The Enlightenment and Absolutism Enlightened Absolutism allowed Kings to govern well. Monarchs were trained in this systemFrederick II (Great) of Prussia an enlightened monarch.Started the war of Austrian SuccessionInvaded Silesia / Broke the Pramatic SanctionMaria Theresa lostThe Seven Years War – almost lost but won over all other powers GB/Rus/Fr became the Great German PowerFrederick allowed religious freedom and promoted education and legal reform / used the legal system and bureaucracyDid not like Mendelssohn and did not believe that Jews should be given freedom and civil rights\n23 Moses MendelssohnEmbracing the Enlightenment and seeking a revitalization of Jewish religious thought, Moses Mendelssohn concluded that reason could complement and strengthen his religion. In his works he reflected the way the German Enlightenment differed from the French Enlightenment by generally supporting established religion. A Christian zealot named Lavater challenged Mendelssohn in a pamphlet to accept Christianity or to demonstrate how the Christian faith was not ""reasonable."" This painting by Moritz Oppenheim depicts an imaginary encounter between the two men.Moses Mendelssohn\n24 The Enlightenment and Absolutism Catherine imported western culture to Russia and supported the philosophes.German by birth / deposed her husband and took over and empress / Catherine westernized the thinking of the Russian nobilityDomestic reform / good intentions but failedReduced torture / religious toleration / tried to improve education and local governmentPugachev’s serf rebellion stopped the reformGave nobles complete control over serfs afterwardTerritorial expansion –subjugated the Tartars /Mongols Along with Prussia and Austria Russia partitioned Poland\n25 Catherine the Great, portrait Catherine was a German princess who had been brought to Russia to marry another German, Peter of Holstein-Gottorp, who was being groomed as heir to the Russian throne. Russia had crowned several monarchs of mixed Russian and German parentage since the time of Peter the Great\'s deliberate interest in and ties with other European states. (The Luton Hoo Foundation)Catherine the Great, portrait\n26 Map: The Partition of Poland and the Expansion of Russia The Partition of Poland / Expansion of RussiaCatherine the Great acquired present-day Lithuania, Belarus, and Ukraine, which had once constituted the duchy of Lithuania, part of the multi-ethnic Polish kingdom.Map: The Partition of Poland and the Expansion of Russia\n27 The Austrian Hapsburgs and impact of the Enlightenment Maria TheresaLost Silesia but started reforms to make the state strongerLimited papal influenceAdministrative reforms to strengthen the bureaucracy / reformed the tax systemImproved the agricultural people by reducing the power of the lords over the serfs and partial free peasantsJoseph II –the (revolutionary emperor) and son of Maria Theresa introduced reforms Promoted religious toleration of Jews and protestantsAbolished serfdom /required peasant payments in cash not work / nobles and peasants rebelled because of lack of moneyLeopold II (son) reinstated peasant forced labor and rolled back other reforms\n28 Absolutism in France Monarchy kept absolutism Philosophes were split over supporting the kingNobles challenged the system after Louis XVHigh courts system called parliaments were restored (ability to evaluate laws in writings prior to be put into placeAllowed them to circumvent taxes (nobility and clergy) by not paying / nobility won and taxes withdrew / will cause the French revolutionBeginning of common dislike of the king / propaganda / made king look human and lost the aura of leadershipLouis XVI will pay for the loss\n29 The impact of the Enlightenment By the mid eighteenth century, Enlightenment ideas foreshadowed momentous changes.In France, the rise of aristocratic opposition and liberalism signaled the death knell of absolutism.Created bureaucratic machine survives to todayIn Eastern Europe the results of the Enlightenment were modest.Reform to strengthen the state but not social reform for the people were paramountSuccessful in: religious toleration for minorities / simplifying legal codes / promoting practical educationExpanded the role of the state in society / made the people more dependent\n30 Vernet, Building Highway An expanding system of all-weather roads improved French communications, promoted trade, and facilitated relief in time of famine. This majestic painting by Claude-Joseph Vernet ( ) captures the spirit of the Enlightenment\'s cautious optimism and its faith in hard-won progress. (Giraudon/The Bridgeman Art Library International)', 'In the previous post, I left off the history of astronomy with Claudius Ptolemy, the last and greatest of the astronomers of ancient times. It was Ptolemy who brought the science of astronomy to its apex in classical times. In his treatise, the Almagest, as the Arabs came to call it, Ptolemy worked out the geocentric model with the complex system of epicycles that the ancients believed described the universe, along with a catalog of stars and constellations and tables of information on the motions of the planets and eclipses of the Sun and Moon. So well did Ptolemy do his work that the Almagest was the accepted text on astronomy for over twelve hundred years.\nThe science of astronomy did not stand still after the time of Ptolemy. The Western Europeans were a little distracted by the fall of the Roman Empire in the West and contributed little to the progress of learning for some centuries. Fortunately the ancient learning was preserved in the Greek East and when the Arabs conquered much of the Middle East in the century after the death of Mohammed, they were able to learn much from the peoples they ruled and soon began to make contributions of their own in science and philosophy. The Arabs translated many Greek texts into Arabic which Western scholars discovered and translated into Latin. The contributions made by the Arabs can be seen by the fact that Ptolemy’s standard text is known by its Arabic title and that many stars still retain names derived from Arabic\nThroughout the Early Middle Ages, the Muslims translated Greek texts into Arabic and so helped to preserve them until Western scholars could translate them into Latin once things had settled down in the West. The importance of the Arabic contribution can be seen by the fact that Ptolemy’s book is known by its Arabic title, not to mention that many stars are known by names derived from Arabic; Betelgeuse, Algol, Aldebaran, Deneb, Vega, and many others.\nOver time, the Arabs, and later the Europeans, developed better instruments for observing the positions of the stars and planets in the sky and to predict the motions of the planets. As their techniques improved, astronomers were able to revise and update the information on planetary motions collected by Ptolemy, and they also found that more epicycles were needed to explain and predict planetary motions. The Ptolemaic model began to seem increasingly over complicated. The last major revision of the tables of planetary motions was commissioned by King Alfonso X of Castile in the thirteenth century. Alfonso, called “the Wise” was known as a patron of many branches of learning and was himself conversant in the science of astronomy. He is supposed to have remarked that if God had consulted him during the creation, he might have suggested a simpler system than the complicated bicycles of Ptolemy. The king almost certainly did not say this, but the sentiment was shared by many who began to believe the universe shouldn’t be so complicated.\nAmong these was a Polish priest who lived some two hundred years after Alfonso. This priest was named Mikolaj Kopernik, better known by the Latinized version of his name, Nicolaus Copernicus. Copernicus was a true renaissance man who was learned in such diverse fields as mathematics, canon law, medicine, economics, classical languages, diplomacy, politics, and astronomy. It is in that last subject that he is remembered today. Copernicus came to realize that understanding the motions of the planets would be much easier if he simply assumed that the planets revolved around the Sun rather than the Earth.\nThe retrograde motions of the planets could simply be explained by their overtaking the Earth as they orbit the Sun. Copernicus seems to have developed his heliocentric theory by 1514 and spent much of the rest of his life working on his book “De revolutionibus orbium coelestium” or “On the Revolutions of the Heavenly Spheres”. Although Copernicus showed the manuscript to his friends and interested scholars, he was reluctant to actually publish his masterpiece for fear of the public ridicule such a radical theory might bring him. It was only after his friends assured him that the book would be favorably received and he was dying that Copernicus agreed to publish De revolutionibus in 1543.\nDe revolutionibus was favorably received by the few people who actually read it. The fact was that Copernicus’s book was so abstruse and technical that only astronomers and mathematicians could really appreciate and understand it.\nIt was in Latin and the script was hard to read too.\nCopernicus’s heliocentric model was not generally accepted for some time. The fact that the assumption that the Sun was at the center of the Solar System made calculating the motions of the planets less complicated did not necessarily made that assumption true and there was good reason not to believe the Earth moved. In fact, the Copernican model did not make the calculations that much less complicated. Like Aristotle and Ptolemy, Copernicus believed that the planets moved in perfect circles and his theory still required some epicycles to agree with observations. It was not until 1610 when Johannes Kepler proposed his first law of planetary motion, that the planets orbit the Sun not in circles that the need for epicycles was finally done away with. The heliocentric model then clearly provided a simpler means of understanding the motions of the planets and so was quickly adopted by most astronomers even though there was not yet clear proof that it was actually true.\nWhich brings us back to Galileo and the Church. In 1632, the year Galileo was tried by the Inquisition, the heliocentric model was rapidly gaining acceptance, yet from a strictly scientific viewpoint, the Church was quite correct in regarding the model with skepticism, even if it was not correct from any viewpoint to put Galileo on trial, although as I said Galileo himself was mostly to blame for his troubles. And, here I have to ask again, why was the heliocentric theory adopted a century before it could be proven beyond a reasonable doubt?\nScientists like to portray themselves cool, logical, unbiased observers interested only in the facts, that is the results of their observations and experiments. Any hypothesis, no matter how attractive, must be put aside if the observations do not agree with it. In fact, scientists are subject to the same sorts of biases as everyone else and a candid view of the history of science will show many instances when scientists have clung to a hypothesis even when the facts seem to show otherwise. This is not always a bad thing. I would even go further and state that this is often a good thing. Sometimes intuition serves as a better guide to discovering the truth than logic and sometimes finding the truth requires ignoring the facts that seem to point in a certain direction while pursuing an underlying truth.\nOne of the biases that has proven to be most useful in understanding the nature of the universe we live in is the idea that the universe is, as bottom, a simple place that we can understand. If things get to be overly complicated, it is usually taken as a sign we are moving in the wrong direction and should seek a simpler explanation. This is no scientific reason for believing this is the case, yet this bias has proven to be useful over and over again. Ptolemy’s epicycles became more and more complicated, so astronomers switched to the simpler heliocentric system, and were proven right. Physicists and chemists in the nineteenth century were dismayed to discover more and more chemical elements with no clear pattern, until they discovered that all these elements could be explained by the three particles, electrons, neutrons, and protons found in the atoms of every element. Physicist were then confused by the many sub atomic particles they kept discovered, until they learned that these particles were composed of a handful of still smaller particles called quarks. This is really the essence of science, to find simple patterns to explain complex phenomena and this process requires intuition and imagination as much as it requires logical thinking and careful observation. So, Galileo was right, even when he was wrong.']"	['<urn:uuid:22ae4193-79ba-45f3-946d-eb4995c5d67e>', '<urn:uuid:162ba786-40b8-4d6d-b818-24bb6662b24b>']	open-ended	with-premise	short-search-query	distant-from-document	multi-aspect	expert	2025-05-13T05:52:58.810667	5	92	3194
64	how do mathematical models analyze climate dynamics and what regional precipitation changes are predicted globally	Mathematical models analyze climate through nonlinear dynamics and complex network approaches, treating global weather as a dynamic system with fractal features and critical transitions. These models help detect patterns in atmospheric behavior and predict climate shifts. Regarding precipitation predictions, climate models show varied regional impacts - with a 4°C warming, North America and Europe would see 25% stronger extreme rainfall, Asian monsoon regions would experience even greater increases, while the Mediterranean, South Africa and Australia would see smaller increases. Some subtropical ocean areas are predicted to have decreased extreme rainfall due to atmospheric circulation changes.	"['VII. Pedia Sapiens: A Genesis Future on Earth and in the Heavens\n2. Global Climate Change as a Complex Dynamical System\nA new subsection added in 2011 to gather and report how the vast intricacy of world weather today, and in the paleological past, is coming to be appreciated, distinguished, and quantified by the same nonlinear critically self-organizing dynamics as everywhere else in cosmos, nature, and society. In regard ""warming"" could not be more of a misnomer, for by these measures abrupt, catastrophic change is more likely. As I again edit in September 2013, a 1000 year flood is presently washing away central Colorado. It would serve climate scientists, under siege by the deniers, to cite themselves say as “physicians of the planet” simply trying to check its relative health, temperature, pressures, electrolytes, and so on. See also Geosphere and Atmosphere for further entries.\nAmerican Physical Society Topical Group on the Physics of Climate. www.aps.org/units/gpc/index.cfm. As reported in the New York Times by Andrew Revkin on February 2, 2012, in “Two Nobelists Offer Views of Human-Driven Global Warming” about scientists now standing against deniers and smearers, this national organization has initiated this effort to apply physical and mathematical insights to our real planetary peril. The APS journal Physics Today, in its February 2012 issue, carries a similar report by Tom Feder “Climate Scientists not Cowed by Relentless Climate Change Deniers.”\nThe objective of the GPC shall be to promote the advancement and diffusion of knowledge concerning the physics, measurement, and modeling of climate processes, within the domain of natural science and outside the domains of societal impact and policy, legislation and broader societal issues. The objective includes the integration of scientific knowledge and analysis methods across disciplines to address the dynamical complexities and uncertainties of climate physics. Broad areas of initial scientific inquiry are described in the Areas of Interest below. These are expected to evolve with scientific progress, while remaining entirely within the domain of natural science.\nShaun Lovejoy Website. www.physics.mcgill.ca/~gang/Lovejoy.htm. The home site for the McGill University geophysicist at the forefront of understanding of earth’s atmosphere by way of nonlinear multifractal computations such as Mathematicia software and satellite imaging. The “gang” above is the “Group for the Analysis of Nonlinear variability in Geophysics,” whose interests run from soils and hydrology to cloud convections and aerosol emissions, each by way of multifractal dynamics. From this site many PDF papers can be accessed, with multiple authors, such as “Towards a New Synthesis for Atmospheric Dynamics” in press for the journal Atmospheric Research (96/01004, 2010). A New Scientist report “And Now the Forecast: Cloudy with a Chance of Fractals” extols these novel advances (November 7, 2009, search).\nMy research has been directly linked to a series of new geophysical paradigms. A particularly exciting one is the idea that atmospheric dynamics repeat scale after scale from large to small scales in a cascade-like way. The key is recognizing that as the scales get smaller, the horizontal gets “squashed” much more than the vertical so that the stratification which starts out being extreme (structures very flat at planetary scales) become rounder and rounder at small scales.\nBarnosky, Anthony, et al. Approaching a State Shift in Earth’s Biosphere. Nature. 486/52, 2012. Some 22 researchers from the University of California, Berkeley, Stanford University, Integrative Ecology Group, Estacion Biologica de Donana, Spain, University of New Mexico, University of Helsinki, Pontificia Universidad Catolica de Chile, Simon Fraser University, California Academy of Sciences, University of Wisconsin, and Missouri Botanical Garden, including Jordi Boscompte, James Brown, John Harte, Pablo Marquet, Geerat Vermeij, and Rosemary Gillespie, seriously worry by way of realistic nonlinear “planetary-scale critical transitions” about an increasingly imminent, forced, epochal climate change.\nLocalized ecological systems are known to shift abruptly and irreversibly from one state to another when they are forced across critical thresholds. Here we review evidence that the global ecosystem as a whole can react in the same way and is approaching a planetary-scale critical transition as a result of human influence. The plausibility of a planetary-scale ‘tipping point’ highlights the need to improve biological forecasting by detecting early warning signs of critical transitions on global as well as local scales, and by detecting feedbacks that promote such transitions. It is also necessary to address root causes of how humans are forcing biological changes. (Abstract)\nBathiany, Sebastion, et al. Abrupt Climate Change in an Oscillating World. Nature Scientific Reports. 8/5040, 2018. Wageningen University and University of Exeter researchers including Marten Scheffer and Tim Lenton push the concept of global weather as a dynamic complex nonlinear phenomenon to an inevitable consequence. As it becomes more energetically perturbed in small and large ways, a “tipping point” of maximum instability will be reached, untoward, whence the whole system will suddenly oscillate to a radical new set condition on its own.\nHere we show how abrupt and sometimes even irreversible change may be evoked by even small shifts in the amplitude or time scale of such environmental oscillations. By using model simulations and reconciling evidence from previous studies we illustrate how these phenomena can be relevant for ecosystems and elements of the climate system including terrestrial ecosystems, Arctic sea ice and monsoons. Although the systems we address are very different and span a broad range of time scales, the phenomena can be understood in a common framework that can help clarify and unify the interpretation of abrupt shifts in the Earth system. (Abstract excerpt)\nBerezin, Yehiel, et al. Stability of Climate Networks with Time. Nature Scientific Reports. 2/666, 2012. The online journal places this in a “Statistical Physics, Thermodynamics and Nonlinear Dynamics” section. With coauthors Avi Gozolchiani, Oded Guez, and Shlomo Havlin, Bar Ilan University physicists contribute to the imperative challenge of defining a “Systems Climatology,” whence nature’s universal intricacies can be equally availed in this ultra-complex local and global weather realm to better quantify, and surely mediate.\nThe pattern of local daily fluctuations of climate fields such as temperatures and geopotential heights is not stable and hard to predict. Surprisingly, we find that the observed relations between such fluctuations in different geographical regions yields a very robust network pattern that remains highly stable during time. Using a new systematic methodology we track the origins of the network stability. It is found that about half of this network stability is due to the spatial 2D embedding of the network, and half is due to physical coupling between climate in different locations. We also find that around the equator, the contribution of the physical coupling is significantly less pronounced compared to off–equatorial regimes. Finally, we show that there is a gradual monotonic modification of the network pattern as a function of altitude difference. (Abstract)\nBodai, Tamas and Tamas Tel. Annual Variability in a Conceptual Climate Model: Snapshot Attractors, Hysteresis in Extreme Events, and Climate Sensitivity. Chaos. 22/023110, 2012. Max Planck Institute, Physics of Complex Systems, researchers investigate such wild weather, which is seen to exhibit the classic features of dynamical phenomena.\nWe have investigated the effect of periodic driving on a conceptual climate model. In spite of the temporal simplicity of the driving, 2D snapshot attractors proved to be useful representations of the dynamics and show fractal features throughout the annual cycle, which owes to the fact that transient chaos and chaotic saddles are ubiquitous in the considered parameter regimes. (023110-9)\nBoers, Niklas, et al. Complex Networks Reveal Global Pattern of Extreme Rainfall Teleconnections. Nature Climate Change. January 30, 2019. Six atmosphere physicists including Jurgen Kurths with postings in the UK, Germany, and Russia quantify how even this liquid feature of regional and world weather can be found to exhibit nature’s intrinsic dynamics and topologies.\nClimatic observables can be correlated across long spatial distances, and extreme events, such as heat waves or floods, are often related to such teleconnection. Here we display the global coupling pattern of extreme rainfall events by detecting complex networks in satellite data. We find that the distance distribution of significant connections around the globe decays via a power law up to distances of about 2,500 kilometres. We show that extreme-rainfall events in the monsoon systems of south-central Asia, east Asia and Africa are significantly synchronized. Analysis of the atmospheric conditions that lead to these global teleconnections confirms Rossby waves as the physical mechanism underlying these patterns. (Abstract excerpt)\nBoers, Niklas, et al. Prediction of Extreme Floods in the Eastern Central Andes based on a Complex Networks Approach. Nature Communications. 5/5199, 2014. Humboldt University, UC Santa Barbara, and University of Sao Paulo researchers including Jurgen Kurths achieve a working mathematical representation of such weather phenomena by way of dynamic nonlinear theories. See also Complex Network Analysis Helps to Identify Impacts of the El Nino Southern Oscillation on Moisture Divergence in South America in Climate Dynamics (45/3-4, 2015) and Complex Networks for Climate Model Evaluation with Application to Statistical versus Dynamical Modeling of South American Climate (44/5-6, 2015), by this team, and the full journal, for further progress.\nChanging climatic conditions have led to a significant increase in the magnitude and frequency of extreme rainfall events in the Central Andes of South America. These events are spatially extensive and often result in substantial natural hazards for population, economy and ecology. Here we develop a general framework to predict extreme events by introducing the concept of network divergence on directed networks derived from a non-linear synchronization measure. We apply our method to real-time satellite-derived rainfall data and predict more than 60% (90% during El Niño conditions) of rainfall events above the 99th percentile in the Central Andes. In addition to the societal benefits of predicting natural hazards, our study reveals a linkage between polar and tropical regimes as the responsible mechanism: the interplay of northward migrating frontal systems and a low-level wind channel from the western Amazon to the subtropics. (Abstract)\nDijkstra, Henk. Nonlinear Climate Dynamics. Cambridge: Cambridge University Press, 2013. A Professor of Dynamical Oceanography at the Institute for Marine and Atmospheric Research, Utrecht University, offers an overdue re-assessment of our ultra-intricate and variable local and global weather in terms of mathematical systems science. Chapters range from Climate Variability, Stochastic Dynamical Systems, and Climate Modelling Hierarchy, to the North Atlantic Oscillation, El Nino, Pleistocene Ice Ages, and onto Predictability. While still weighted more toward physical mechanism than self-organizing networks, a turn in a better direction if we are ever to understand and resolve.\nThis book introduces stochastic dynamical systems theory in order to synthesize our current knowledge of climate variability. Nonlinear processes, such as advection, radiation and turbulent mixing, play a central role in climate variability. These processes can give rise to transition phenomena, associated with tipping or bifurcation points, once external conditions are changed. The theory of dynamical systems provides a systematic way to study these transition phenomena. Its stochastic extension also forms the basis of modern (nonlinear) data analysis techniques, predictability studies and data assimilation methods. Early chapters apply the stochastic dynamical systems framework to a hierarchy of climate models to synthesize current knowledge of climate variability. Later chapters analyse phenomena such as the North Atlantic Oscillation, El Niño/Southern Oscillation, Atlantic Multidecadal Variability, Dansgaard-Oeschger Events, Pleistocene Ice Ages, and climate predictability. This book will prove invaluable for graduate students and researchers in climate dynamics, physical oceanography, meteorology and paleoclimatology. (Publisher)\nDonges, Jonathan, et al. Earth system modeling with endogenous and dynamic human societies: the copan:CORE open World-Earth modeling framework. arXic:1909.13697. A dozen German and Swedish scientists with a main base at the Potsdam Institute for Climate Impact Research proceed with a comprehensive program going forward to gain ever better analyses, quantifications and hopefully sustainable remediations of our hyper-active global atmosphere and consumptive societal-industrial civilization. In regard we need to get a real sense of Earthkinder taking care of her/his self and do all we personally and collaboratively do to facilitate and survive.\nEarth system dynamics in the Anthropocene need to well take into account the increasing magnitude of processes operating in human societies, their cultures, economies and technosphere, along with their entanglement with physical, chemical and biological global systems. This paper (i) proposes design principles for constructing World-Earth Models (WEM) for Earth system analysis of the Anthropocene, i.e., models of social (World) - ecological co-evolution on up to planetary scales, and (ii) presents the copan:CORE open simulation modeling framework for developing, composing and analyzing such WEMs based on the proposed modular principles. Thereby, copan:CORE enables the epistemic flexibility needed for Earth system analysis of the Anthropocene given the diverse theories and methodologies used for describing socio-metabolic/economic and socio-cultural processes. (Abstract)\nDonges, Jonathan, et al. Identification of Dynamical Transitions in Marine Palaeoclimate Records by Recurrence Network Analysis. Nonlinear Processes in Geophysics. 18/5, 2011. A companion article in this effort by systems physicists and climatologists from the Universities of Potsdam, Humboldt, and Dresden to attain novel insights, as every other scientific field has done, to the hyper-complex in scale and intricacy of such ancient climes and biotas.\nAbstract. The analysis of palaeoclimate time series is usually affected by severe methodological problems, resulting primarily from non-equidistant sampling and uncertain age models. As an alternative to existing methods of time series analysis, in this paper we argue that the statistical properties of recurrence networks are promising candidates for characterising the system’s nonlinear dynamics and quantifying structural changes in its reconstructed phase space as time evolves. Specifically, we investigate the behaviour of recurrence network measures for both paradigmatic model systems with non-stationary parameters and four marine records of long-term palaeoclimate variations. We show that the obtained results are qualitatively robust under changes of the relevant parameters of our method, including detrending, size of the running window used for analysis, and embedding delay. We demonstrate that recurrence network analysis is able to detect relevant regime shifts in synthetic data as well as in problematic geoscientific time series. (545)\nDonges, Jonathan, et al. Investigating the Topology of Interacting Networks: Theory and Application to Coupled Climate Subnetworks. European Physical Journal B. 84/4, 2011. n a Focus Section on Frontiers in Network Science, Potsdam Institute for Climate Impact Research, Humboldt University, and Free University Berlin systems physicists provide further application of nature’s universal inherency to animate and abide via robust systems to global and local weather patterns and processes. Again, a novel, imperative phase of climate research is commencing, as most other fields of study have done, moving beyond masses of measurements to engage the equally present dynamical network interactions. An important feature, it is emphasized, is a “vertical” topological structure of atmospheric microclimes.\nNetwork theory provides various tools for investigating the structural or functional topology of many complex systems found in nature, technology and society. Nevertheless, it has recently been realised that a considerable number of systems of interest should be treated, more appropriately, as interacting networks or networks of networks. Here we introduce a novel graph-theoretical framework for studying the interaction structure between subnetworks embedded within a complex network of networks. This framework allows us to quantify the structural role of single vertices or whole subnetworks with respect to the interaction of a pair of subnetworks on local, mesoscopic and global topological scales. Climate networks have recently been shown to be a powerful tool for the analysis of climatological data. Applying the general framework for studying interacting networks, we introduce coupled climate subnetworks to represent and investigate the topology of statistical relationships between the fields of distinct climatological variables. Using coupled climate subnetworks to investigate the terrestrial atmosphere’s three-dimensional geopotential height field uncovers known as well as interesting novel features of the atmosphere’s vertical stratification and general circulation. The promising results obtained by following the coupled climate subnetwork approach present a first step towards an improved understanding of the Earth system and its complex interacting components from a network perspective. (635)', 'If global average temperatures rise by 4 degrees Celsius over the next hundred years, as many climate models predict given relatively high CO2 emissions, much of North America and Europe would experience increases in the intensity of extreme rainfall of roughly 25 percent. Some places such as parts of the Asian monsoon region would experience greater increases, while there will be smaller increases in the Mediterranean, South Africa and Australia.\nThere are a few regions that are projected to experience a decrease in extreme rainfall as the world warms, mostly located over subtropical oceans that lie just outside the tropical, equatorial belt.\nThe study, published today in Nature Climate Change, finds that the varied changes in extreme precipitation from region to region can be explained by different changes in the strength of local wind patterns: As a region warms due to human-induced emissions of carbon dioxide, winds loft that warm, moisture-laden air up through the atmosphere, where it condenses and rains back down to the surface. But changes in strength of the local winds also influence the intensity of a region’s most extreme rainstorms.\nPaul O’Gorman, a co-author on the paper and associate professor of atmospheric science in MIT’s Department of Earth, Atmospheric and Planetary Sciences, says being able to predict the severity of the strongest rain events, on a region-by-region basis, could help local planners prepare for potentially more devastating storms.\n“There is interest around the world in the question of whether to adjust codes to adapt to a changing climate and precipitation, particularly for flooding,” O’Gorman says. “We found there are regional variations in the projected precipitation response because of changes in winds, and of course if you’re interested in the impacts of precipitation extremes, you’d want to know what’s happening in your region.”\nA global grid view\nSince the 1990s, scientists have predicted based on climate models that the intensity of extreme rain events around the world should increase with rising global temperatures. Current observations have so far verified this trend on a broad, global scale. But knowing how extreme storms will change on a more specific, regional scale has been a trickier picture to resolve, as climate data is not equally available in all countries, or even continents, and the signal of climate change is masked by weather noise to a greater extent on the regional scale.\n“The observations are telling us there will be increases [in extreme rainfall] at almost all latitudes, but if you want to know what’s going to happen at the scale of a continent or smaller, it’s a much more difficult question,” O’Gorman says.\nHe and his colleagues began their study by taking a global perspective. They first looked through a massive archive of global simulation runs, known as the Coupled Model Intercomparison Project Phase 5 (CMIP5), which aggregates outputs, or predictions, made by different climate models, for everything from local air pressure to the thickness of sea ice in response to changing climate.\nFor this study, the researchers culled the CMIP5 archive for specific outputs, including daily accumulated surface precipitation and temperature, vertical wind velocity and pressure, and daily atmospheric humidity. These outputs were simulated by 22 climate models, for the years 1950 to 2100, under a scenario in which there are relatively high emissions of CO2.\nThe team looked at each of the 22 models’ outputs on a regional, grid-by-grid basis. Each model simulates climate conditions by dividing the globe up into a grid, with each grid cell’s side measuring 100 to 200 kilometers. For each cell in each model, the researchers identified the maximum daily rainfall per year and compared this to the average global temperature for that year.\nAll 22 models predicted that the highest increases in extreme rainfall will occur over parts of the Asian monsoon region such as India and over parts of the equatorial Pacific, with more moderate increases in North America, Central America, the Mediterranean, and Australia.\nO’Gorman says that while the spatial pattern of change was robust across the models, the magnitude of the change was much more uncertain in tropical regions, and higher-resolution modeling is needed to narrow down this uncertainty.\nTo see what was influencing the region-to-region variability in rainfall increases, the team plugged the outputs into a physics-based formula that relates the amount of surface precipitation to the vertical winds and the amount of water vapor in the atmosphere. They found that, overall, it was the changes in winds, and not water vapor, that determined the region-to-region variations in the change in extreme rain intensity.\nThe researchers also found decreases in extreme rainfall amounts over subtropical ocean regions, where the overlying atmosphere is generally dry, producing relatively weak storm systems.\n“It’s kind of striking,” O’Gorman says. “Almost everywhere, there’s an increase in precipitation extremes, except for these ocean regions.”\nHe suggests this may be partly due to the ongoing expansion of the tropics, and the associated changes to a atmospheric circulation system known as the Hadley cell, in which air rises near the equator and descends farther poleward. As the climate has warmed in past decades, researchers have noted that the climate at the equator has spread towards the poles, creating a much wider tropical belt. As the tropics and the Hadley cell continue to expand, this would affect the pattern of extreme precipitation, especially in the subtropics.\n“The subtropics are generally dry, and if you move the region of descending air poleward, you would get some regions with increases, and others with decreases [in extreme rainfall],” O’Gorman says. “However we found that this only explained half of the decreases from changes in winds, so it’s still something of a mystery as to why you get a decrease in precipitation extremes there.”\nO’Gorman is currently investigating whether the duration of extreme rainfall events changes with increasing temperatures, which could have practical implications for determining the resilience of buildings and infrastructure.\n“Given an extreme precipitation event, how long does it last, say in hours, and does that time change with climate warming?” O’Gorman says. “We think the intensity of an event changes, and if the duration also changes, that could be significant too.”\nThis research was supported, in part, by the National Science Foundation.\nImage courtesy of MIT News Office']"	['<urn:uuid:088455d4-fdf4-4bf1-b60e-4e10d22b9713>', '<urn:uuid:6e2002a6-9152-448a-905a-4e1492306675>']	open-ended	direct	long-search-query	similar-to-document	multi-aspect	novice	2025-05-13T05:52:58.810667	15	95	3658
65	how long antimicrobial shield lasts before reapplying	The antimicrobial shield should be reapplied every three months to maximize effectiveness, as the invisible coating eventually sheds through repeated touching.	['Frequently Asked Questions\nWhat is the difference between “cleaning,” “disinfecting” and “sanitizing”?\nCleaning, by definition, is simply removing germs, dirt, grease, and grime from a surface. Generally, this is done with simple soap and water and has no bearing on the killing of germs, bacteria, or viruses. It removes them and makes surfaces look good and “clean” to the naked eye. It is often the first step in the disinfection process.\nDisinfecting uses specialized chemicals registered with the Environmental Protection Agency (EPA) to kill germs, bacteria, or viruses on surfaces. Although disinfecting does not necessarily give the surface a “clean” look, it is highly effective in eradicating active germs to stop the spread of infection. Disinfectants are very carefully and deliberately created to treat certain bacteria and viruses, so they are rarely a one-size-fits-all solution. They have different kill spectrums, cure times, mixing instructions, and importantly, application directions, so be sure to read the label carefully when selecting and using a disinfectant. A disinfect is not effective if it is not used properly.\nSanitizing is simply lowering the number of germs on a surface to a safe level, as prescribed by public health authorities. It does not necessarily mean that the presence of germs is totally eradicated, but rather that they may not be numerous enough to cause immediate health concerns. Sanitization does not remove the threat posed by viruses and infectious diseases.\nHow long does a disinfectant kill microbes?\nDisinfectants that have been registered with the EPA can be expected to kill or inactivate microbes listed on the approved label (kill sheet), in the number of minutes indicated on the label (cure time), when applied according to label directions (application directions). As soon as the disinfectant evaporates, the killing and inactivation stops, or at the moment of application. The purpose of a disinfectant is to kill or inactivate microbes on the initial application. Because of this, regular scheduled cleaning and disinfection is recommended.\nIs there any way to protect a surface from accumulating microbes after disinfection?\nOne effective method is to apply a coating of a microbiostatic agent, or antimicrobial shield, that has been proven to prevent specific microbes from surviving on the coated surface for a period of time after its application. Like disinfectants, microbiostatic agents with any antimicrobial claims must be registered with the EPA. Aftermath Service’s Antimicrobial Shield is EPA registered for durable biostatic activity against a host of microbes, including bacteria, fungi and algae, when properly applied. Independent studies have also found that the ingredients in our antimicrobial shield are effective at inactivating enveloped viruses upon contact with the properly coated surface.\nHow does the Aftermath Antimicrobial Shield work?\nAntimicrobials are complex chemicals that have a chemistry that binds them to surfaces and chemistry that keeps microbes from growing and continuing to be viable. The effective action that destroys the microbe is physical, electrical, and chemical: it electrically attracts the microbe and it physically breaks the microbe open by piercing the lipid layer of the cell wall.\nHow is the Aftermath Antimicrobial Shield applied to a surface?\nFederal Law requires that the application of the Aftermath Antimicrobial Shield (registered with the EPA) must be applied according to label directions for the surface being treated. For non-porous surfaces, the application of the Shield requires that the surface first be cleaned to remove grease, grime and gross surface contamination followed by disinfection with an EPA registered disinfectant. This prepares the surface to receive the Shield solution. After a period of a few minutes, the coating is dry and ready to prevent microbes from thriving on the surface for an extended period of time.\nHow long will the Aftermath Antimicrobial Shield prevent microbes from growing or replicating on a surface?\nThe Aftermath Antimicrobial Shield’s EPA approved label indicates that it should be reapplied every three months to maximize effectiveness. The reason for reapplication is due to the fact that the invisible coating will eventually be shed through repeated touching.\nCan the Aftermath Antimicrobial Shield be used on fabric and porous surfaces?\nYes, Aftermath Antimicrobial Shield is suitable for application on the following:\n- Mattress cover pads\n- Filling and ticking\n- Pillow covers\n- Fiberfill for upholstery\n- Recreational gear\n- Quilts and pillows\n- Carpet and carpet underlay\n- Shower curtains\n- Toilet tank and seat covers\n- Wallcovering fabrics and wallpaper (including vinyl) for non-food contact surfaces\n- Fire hose fabric\n- Non-woven disposable diapers\n- Wiping cloths\n- Apparel including outerwear\n- Gloves and uniforms\n- Footwear (boots, shoes and components)\n- Sports equipment and athletic gear\n- Cloth for sails\n- Tents and other outdoor equipment\n- Book covers\nDoes the Aftermath Antimicrobial Shield damage the surface?\nAftermath Antimicrobial Shield dries clear and is safe for both porous and non-porous surfaces. The application is approximately 40 microns thick but dries to less than one micron in thickness. It is not labeled for use on food contact surfaces.']	['<urn:uuid:191723ac-6b83-4228-a0fd-7bced4e732e9>']	factoid	direct	short-search-query	similar-to-document	single-doc	expert	2025-05-13T05:52:58.810667	7	21	823
66	Which takes longer to recover from, a nose job or liposuction?	Both procedures have significant recovery periods. Liposculpture body contouring recovery is typically complete in 6-8 weeks, though final results may take 6 months to a year to be visible. For rhinoplasty, patients need to wear a splint for at least a week, avoid swimming for three weeks, and avoid strenuous activity and contact sports for at least a month. Both procedures require careful monitoring for complications, with liposuction patients watching for prolonged swelling, excessive bruising or bleeding, while rhinoplasty patients may experience bruising, swelling, and potential breathing problems.	['Liposuction is a popular cosmetic surgery that is performed to remove excess fatty deposits from various parts of the body. The Greek word Lipo means fat with suction implying the sucking out or removal of fat. Superficial liposuction or liposculpture body contouring, on the other hand, refers to the refining of the contours of the human body using the adjustment and removal of fatty deposits. Liposculpture body contouring gets its name because of the similarities between the way surgeons sculpt the body and artists sculpt pieces of art and is sometimes referred to as body contouring.\nLiposculpture Body Contouring Procedure\nLiposculpture body contouring is generally more aggressive than traditional liposuction and results in a greater volume of fat removal. Liposuction body contouring also takes a more artistic approach. During the procedure, the cosmetic surgeon is more concerned with aesthetics, including making sure the body is symmetrical and the skin is smooth and free from dents. The doctor will sculpt away fat to create a better physical form for the patient.\nThe most common areas of the body targeted by liposculpture include the stomach, hips, legs, arms, buttocks, chin, neck and face. As well as removing excess fat from the body, superficial liposuction can also include the addition of fat in areas that need additional padding, in an attempt to shape the body.\nUltrasound Assisted Liposculpture Body Contouring\nSuperficial liposuction relies in innovative technology and the newest techniques to insure the best results. Liposculpture body contouring typically is ultrasound assisted which means that ultrasonic waves are used to help liquefy the fat cells for easy extraction. The ultrasound can be applied above or below the skin. A motorized cannula may also be present. This type of cannula is up to forty percent faster than a manual version, and can save significant time when removing excess fat cells.\nTumescent Liposculpture Body Contouring\nThe tumescent technique is also popular in liposculpture body contouring. This procedure injects more fluid into the body before the surgery is performed than traditional methods. Typically, five times as much fluid injected with this technique. The larger amount is said to aid in the reduction of blood loss and other complications. It also assists in faster, less painful recuperation.\nBoth the use of ultrasound assisted liposuction and tumescent techniques contribute to more precise results and quicker healing times for patients.\nDoctors do warn however that no type of liposuction or body contouring should be used to replace healthy eating and regular exercise.\nGood Candidates for Superficial Liposuction\nPlastic surgeons stress the necessity of any patient having realistic expectations about the results of the surgery. While liposculpture body contouring is likely to enhance your appearance, it is limited by body type and technology.\nCandidates for body contouring should be in good mental and physical health. They should have no medical problems, or medical problems that can be treated with the use of medicine. Doctors advise that the best candidates for liposculpture body contouring are folks who are not extremely overweight. In addition, potential patients should also have firm, elastic skin for successful results.\nLiposculpture Recovery Time\nAs with many cosmetic surgery procedures the results of liposculpture body contouring may not be apparent immediately. This is because swelling and the use of compression garments may disguise the transformation. In addition, the injected fluids often take several days to completely drain from the body. Most recoveries are complete in six to eight weeks, but results may take six months to a year to be visible.\nAs with all surgeries, patients should report any complication to their doctor immediately. This includes swelling that lasts longer than two months, excessive bruising or bleeding, and skin denting or bulging.', 'What is Rhinoplasty (nose job)?\nRhinoplasty is the medical term for the procedure commonly known as a nose job, a surgical procedure where the shape of the nose is altered. Surgery to improve the nose has been in practice for thousands of years but this was typically done as a reconstructive procedure for broken or otherwise damaged noses. The first purely cosmetic rhinoplasty is attributed to a German plastic surgeon named Jacques Joseph who published a report on fixing a patient’s hump nose in 1904.\nRhinoplasty has remained a popular procedure since the mid-1900s and consistently places in the top 10 most performed aesthetic surgeries.\nHow does it work?\nWhether you want your nose reduced in size, increased or just reshaped, the surgeon first needs to cut through the skin of the nose in either an ‘open’ or ‘closed’ rhinoplasty. In closed rhinoplasties, the surgeon makes cuts inside the nostril which will hide any scars following the surgery. Depending on the scope of the corrections however, it might not be possible to do a closed rhinoplasty. In this case the surgeon will make a cut in the skin between your nostrils and pull the tip of your nose back, revealing the cartilage beneath. Open rhinoplasty has the benefit of a better view of the cartilage being worked on and can give better control of the cuts being made.\nOnce the opening cuts have been made, the following steps depend on what the patient wants done to their nose. If the patient wants reshaping and not a change in overall size, then cartilage can be moved around and the bone broken and re-set in a different shape to give the desired nose shape. Reduction in size can involve the cutting and removal of cartilage and/or the chiselling away of bone. Nose size can also be increased by grafting on extra cartilage from the ears and bone from the hips, although artificial grafts can also be used.\nOther corrections like narrowing the tip of the nose or changing the way the tip points can be done with stitches to the cartilage.\nWhat is it like?\nThe surgical procedure is typically done under general anaesthetic so the patient will be unconscious throughout. The surgery will last around 2 hours. Once the desired changes to bone and cartilage structure have been made, the cuts used to access them will be stitched up. For an open rhinoplasty this will leave a small scar between your nostrils but once healed they aren’t usually very noticeable.\nWhen the anaesthesia wears off you will have gauze packed into both nostrils and a splint on your nose. The gauze will prevent breathing through your nose but is removed when leaving the hospital. You can typically leave either the same day of the surgery or the day after. The splint will have to remain in place for at least a week.\nThere may be a follow up assessment session where the splint is removed and healing and shape are checked. A second, corrective rhinoplasty may be required if the first did not work as desired and this happens in as many as 15% of nose jobs.\nWhat is the recovery time?\nFor at least a week following the procedure you will be required to wear a splint over your nose. It is typically recommended to take this week off work as well.\nSwimming should be avoided for three weeks following the surgery, and strenuous activity and contact sports should be avoided for at least a month.\nYou may also be advised to avoid heavy sneezing and blowing your nose as well as wearing glasses.\nAll the recovery period times can vary and you should follow the advice of your doctor.\nWhat are the risks and side effects?\nAs a surgical procedure, rhinoplasty comes with some serious possible risks and side effects. There’s a small chance that following surgery you could develop permanent breathing problems, have and altered or lost sense of smell, develop an infection or blood clot or experience excessive bleeding during or after surgery.\nLess severe side effects include considerable bruising and swelling around the nose as well as black eyes, pain and tenderness around the nose and nosebleeds.\nSome people can also experience allergic reactions to anaesthesia.\nHow much does it cost?\nRhinoplasty can cost between £4,500 and £7,000.\nSo is it worth it?\nRhinoplasty is a serious, expensive and permanent procedure so it’s important to weigh up you options before undergoing surgery. Thousands of people in the UK each year undergo this procedure and a study found that overall satisfaction with the results was 83.6% of patients, though men alone had a much lower satisfaction of 56.1% .\nIn terms of alternatives, injected fillers are becoming a popular method of non-surgical nose reshaping. While these offer an attractive prospect of nose correction with a tenth of the cost and none of the surgery they aren’t appropriate in all cases as they can only add size to the nose. They’re also a temporary measure and will wear off in a year or so.\nUltimately, rhinoplasty is the only option for permanent corrections to nose shape. The cost may be high but it should be a one-time thing compared to yearly filler top ups. There are some severe risks involved and the recovery period can last months but if you’re truly unhappy with your nose then rhinoplasty may well be worth it.\n3.Khansa, I., L. Khansa, and G.D. Pearson, Patient Satisfaction After Rhinoplasty: A Social Media Analysis. Aesthet Surg J, 2016. 36(1): p. Np1-5.']	['<urn:uuid:4e7e6f0c-7493-40b0-8b0e-182c3e3ed7f4>', '<urn:uuid:9268f80e-69a7-4d22-8564-1038808184ed>']	open-ended	direct	concise-and-natural	distant-from-document	comparison	novice	2025-05-13T05:52:58.810667	11	88	1540
67	what is black box opera and how different small venue opera productions from traditional ones	Black box opera refers to small, chamber-sized works staged in very small venues, typically seating around 100 people. Unlike traditional opera houses like the Metropolitan Opera that seat 3800 people, black box venues put audiences right in front of the action, almost close enough to touch the performers. This creates a more intimate experience, similar to black-box theater and instrumental chamber music. However, this intimacy can present challenges for singers trained for traditional stages, as they sometimes project their voices too strongly for such small spaces. While these small-scale productions are exciting and allow for more experimental presentations, they raise concerns about financial sustainability and limited audience reach compared to large traditional venues.	"['Lean But Seen: The Joy Of Smaller Opera\nWhen a new festival for opera and musical theater called ""Prototype"" opened in New York last month, it wasn\'t inaugurated with a huge new piece. Instead, the festival was kicked off with the first staging of Mohammed Fairouz\' opera Sumeida\'s Song — a work for four singers and a handful of musicians that lasts just 60 minutes long, presented at Here, a theater in Manhattan\'s Tribeca that seats just 100 people.\n""Black box is the new red curtain!"" one of the presenters cheerfully crowed to the audience on opening night. It\'s easy to feel that way when one of these so-called ""black box operas"" — small, chamber-sized works staged in very small venues — is as successful as this one.\nCompleted in 2008, when the Arab-American composer was just 22 years old, Sumeida\'s Song is an operatic adaptation (with a libretto by Fairouz) of a play by the great Egyptian playwright Tawfiq al-Hakim, who was born in Alexandria in 1898. Al-Hakim\'s story is intense and visionary: A gentle, university-educated young man named Alwan returns from Cairo to his peasant village and his mother Asakir. It\'s not to be a happy reunion. Alwan learns over the course of the work that his mother\'s burning desire is for him to avenge his father\'s death nearly two decades earlier, when the boy was just a toddler. Soon, Asakir\'s sister Mabrouka and Mabrouka\'s son Sumeida are drawn into this new chapter of the family tragedy, which closes with a horrific end.\nIt\'s easy to see why al-Hakim\'s tale was so appealing to Fairouz in its complex web of clashes and loyalties. What he does with this material is noteworthy, too. Fairouz is a smart and sensitive composer, uneasy with neat (and ultimately faulty) categorizations of ""West"" and ""East."" You can hear all this in an excellent new recording of Sumeida\'s Song recently released on Bridge which includes the impressive mezzo Rachel Calloway as Asakir. In the Scene 1 aria for Asakir entitled ""Let Them Learn,"" both Fairouz\' lyricism and his pointed and even astringent shapes are strongly present:\nIn many ways, Fairouz\' opera is a perfect vehicle for ""black box"" exploration. It\'s an intense — almost claustrophobically close — household drama, albeit one with huge societal implications. And as an audience member, it\'s easy to love operas presented in small venues. Just as in black-box theater and in instrumental chamber music, you\'re right in front of the action — nearly close enough, from many seats, to touch the performers. (That was actually a bit of a challenge in the live performance for the two young female singers, mezzo Calloway and soprano Amelia Watkin as Mabrouka. Clearly mindful of their training for traditional stages, they were more often than not projecting their voices, and their emotional displays, with a far larger room in mind than the 100-seat theater they actually occupied.)\nBut there\'s also real economy of scale at work. Is the opera world splitting — out of both aesthetic choice and for more basic financial reasons — into two very different scenes? On the one hand, you have the model of the Metropolitan Opera, not necessarily just to fill the 3800 seats at each performance, but now, with the worldwide theater simulcasts, to which millions of people buy tickets each year. Everything is big. The screen, the reach, the budgets. (In 2010, the Met sold 2.6 million simulcast tickets.)\nThe Met\'s seed idea has spread fast. Tomorrow, opera buffs around the globe will be logging onto Medici.tv to watch a free stream of The Perfect Man, Philip Glass\' bio opera about Walt Disney, during its world premiere run at Madrid\'s Teatro Real. But there are only a handful of houses and other presenters around the globe who can continue to sustain those sorts of efforts, particularly when it comes to presenting ""risky"" new work, even from very well-established contemporary composers. On the other side lies the black box, whether the work being presented is brand-new like Fairouz\' or, for example, revivals of obscure Baroque and Classical-era works, such as what George Steel has been trying in recent seasons in venues scattered around the city with the struggling New York City Opera. Given today\'s economic woes, there\'s very little in between.\nThe rise of small-scale, more experimental presentations of opera is hugely exciting. But I can\'t help but wonder about the financial costs and the ""statement"" risks associated with such stagings. If a new opera only enjoys, at most, two or three or four stagings, in a venue that seats about as many people as a typical college survey course, at inexpensive ticket prices, how will those tickets begin to cover even some part of the costs of staging? And as these ""black box"" productions become part of the new norm, is there a tacit understanding that most new composers\' work can only reach tiny audiences?\nWhile the opera world continues to wrest over all this, it\'s great to see a work explicitly scaled to an intimate room find its natural home in a 100-seat theater. Here\'s hoping that Mohammed Fairouz finds the opportunity to paint on larger canvases as well.\nWhat small (and large) productions of new opera have you seen around the U.S. or in other countries lately? Did they work or not — and why? And which upcoming ones are you most excited about? Please tell us in the comments section.\nCopyright 2022 NPR. To see more, visit https://www.npr.org.']"	['<urn:uuid:1a98a1ce-c8b2-434e-98da-fdca522a172f>']	open-ended	direct	long-search-query	similar-to-document	single-doc	novice	2025-05-13T05:52:58.810667	15	113	915
68	I'm interested in oil spills in the US - how does the amount spilled in the 2013 Arkansas incident compare to the 2023 Michigan spills in terms of gallons?	The 2013 Mayflower, Arkansas spill released approximately 134,000 gallons (3,190 barrels) of crude oil when the Pegasus Pipeline ruptured. In comparison, the recent Michigan spill in the Flint River released about 5,300 gallons of machine-lubricating oil from the Algoma Steel Mill.	['Arctic, Arkansas, clean water, corruption, crude oil, DOJ, environment, Exxon, Exxon Mobil, ExxonMobil Pipeline company, Kara Sea, Lake Conway, Mayflower Arkansas, NORM, oil and gas, oil spill, pipeline rupture, radioactive waste, resource extraction, Rex Tillerson, risk management, TENORM, water\n“Oil flowed through the neighborhood, contaminating homes and yards, before entering a nearby creek, wetlands and a cove of Lake Conway. Some residents were ordered to evacuate their homes after the spill and remained displaced for an extended period of time. The spill volume has been estimated at approximately 3,190 barrels, or 134,000 gallons” (USDOJ)\nMayflower Arkansas (suburban Little Rock) Exxon Mobil Pipeline oil spill, USEPA\nUS Secretary of State nominee, Rex Tillerson, wants sanctions dropped against Russia to export equipment to drill the Arctic but is “not well-equipped to deal with” clean-up? “Rex Tillerson, CEO of Exxon Mobil, testified that “when these things [oil spills] happen, we are not well-equipped to deal with them.” Over the last 20 years nothing has changed. The industry and even the government has substantially invested in new technologies to drill in deeper water and deeper into the Earth, but little has been invested in safety or oil spill response and clean-up.(US Senator Menendez, June 22, 2010). https://www.menendez.senate.gov/news-and-events/press/menendez-finds-that-mmss-oil-spill-response-research-tank-is-inoperable Furthermore, the Kara Sea, where they want to drill, is full of radioactive waste, some barrels of it have been leaking since the 1990s, since no one has figured out how to clean-up that even more lethal problem. Given the low price of oil and the high price of radioactive waste disposal one can but wonder if it’s really oil drilling at stake or nuclear waste disposal, even if it is illegal. Or, perhaps they have found a loophole. Isn’t there one related to offshore rigs and TENORM (technologically enhanced naturally occurring radioactive materials)?\nRussian oil companies have already worked out how to make messes without Exxon’s help!\nMayflower oil spill, US EPA\nFrom the US DOJ:\n“FOR IMMEDIATE RELEASE\nWednesday, April 22, 2015\nExxonMobil to Pay $5 Million to Settle U.S. and Arkansas Claims for 2013 Mayflower Oil Spill\nExxonMobil Pipeline Company and Mobil Pipe Line Company (ExxonMobil) have agreed to pay civil penalties, fund an environmental project and implement corrective measures to resolve alleged violations of the Clean Water Act and state environmental laws stemming from a 2013 crude oil spill from the Pegasus Pipeline in Mayflower, Arkansas, the Department of Justice and the Environmental Protection Agency (EPA) announced today.\nUnder a consent decree lodged today in federal court, ExxonMobil will pay $3.19 million in federal civil penalties and take steps to address pipeline safety issues and oil spill response capability. In addition, ExxonMobil will pay $1 million in state civil penalties, $600,000 for a project to improve water quality at Lake Conway, and $280,000 to the Arkansas Attorney General’s Office for the state’s litigation costs.\nThe oil spill occurred on March 29, 2013, after the Pegasus Pipeline, carrying Canadian heavy crude oil from Illinois to Texas, ruptured in the Northwoods neighborhood of Mayflower, Arkansas.\nOil flowed through the neighborhood, contaminating homes and yards, before entering a nearby creek, wetlands and a cove of Lake Conway. Some residents were ordered to evacuate their homes after the spill and remained displaced for an extended period of time. The spill volume has been estimated at approximately 3,190 barrels, or 134,000 gallons.\n“This settlement holds ExxonMobil accountable for this very serious oil spill and its disastrous impact on the Mayflower community and environment,” said Assistant Attorney General John C. Cruden for the Justice Department’s Environment and Natural Resources Division. “This agreement is also an excellent example of federal and state cooperation that will benefit public health and the environment for years to come and most importantly prevent future disasters by requiring better pipeline safety and response measures.”\n“Oil spills like this one in Mayflower, Arkansas have real and lasting impacts on clean water for communities,” said Assistant Administrator Cynthia Giles for EPA’s Office of Enforcement and Compliance Assurance. “Companies need to take the necessary precautions to make sure oil is transported safely and responsibly. This settlement puts in place essential pipeline safety and response measures that are important to make this industry safer for communities.”\n“The U.S. and the state of Arkansas have worked together since the first barrel of oil was spilled in 2013 to provide relief and assistance to the residents of Mayflower and Faulkner County and to hold ExxonMobil accountable for this serious spill,” said U.S. Attorney Christopher R. Thyer for the Eastern District of Arkansas. “This settlement does both. In addition to paying significant civil penalties, ExxonMobil will provide money for safety and water-quality projects to help ensure that the residents of the affected area never have to go through an ordeal like this again. This resolution to a terrible disaster is a testament to the partnership between our federal and state governments to protect the citizens of Arkansas.”\n“Pipeline companies have the responsibility to protect both our water resources and people from oil spills,” said Regional Administrator Ron Curry for EPA. “Today’s settlement will help protect the environment by preventing the high economic and environmental costs of future oil spills.”\nThe penalties owed by ExxonMobil under the consent decree are in addition to the money that the company has already paid to reimburse federal and state response efforts and comply with orders and directives issued by the Pipeline and Hazardous Materials Safety Administration (PHMSA). The segment of the Pegasus Pipeline that includes the rupture site has not been used since the March 2013 spill, and under the terms of the settlement agreement, ExxonMobil must comply with all PHMSA corrective action requirements before returning the pipeline to operation. The consent decree also requires ExxonMobil to take other important pipeline safety corrective action to help prevent future ruptures and improve its spill response capabilities by providing additional training to its oil spill first responders. In addition, ExxonMobil is required to establish caches of spill response equipment and supplies at three strategically-chosen sites along the pipeline, including one location near Mayflower in Faulkner County, Arkansas.\nThe Clean Water Act makes it unlawful to discharge oil or hazardous substances into or upon the navigable waters of the U.S. or adjoining shorelines in quantities that may be harmful to the environment or public health. The penalty paid to the U.S. for this spill will be deposited in the federal Oil Spill Liability Trust Fund managed by the National Pollution Funds Center. Those funds will be available to pay for federal response activities and to compensate for damages when there is a discharge or substantial threat of discharge of oil or hazardous substances to waters of the U.S. or adjoining shorelines.\nThe joint federal and state complaint in the case, filed June 13, 2013, in the U.S. District Court for the Eastern District of Arkansas, alleges that ExxonMobil discharged crude oil in violation of the Clean Water Act. The complaint also asserts state claims for civil penalties for improper storage of hazardous waste generated during the cleanup and for water and air pollution violations pursuant to the Arkansas Water and Air Pollution Control Act and the Arkansas Hazardous Waste Management Act.\nThe proposed consent decree, lodged in the Eastern District of Arkansas, is subject to a 30-day public comment period and court review and approval. A copy of the consent decree is available on the Department of Justice website at http://www.justice.gov/enrd/Consent_Decrees.html.”\nOil spill location exported from Wikipedia. US EPA Photos public domain via Wikipedia https://en.wikipedia.org/wiki/2013_Mayflower_oil_spill', 'Equilibrium/Sustainability — Support for plant meats doesn’t translate to buying\nMore people support plant-based meats in theory than are willing to buy them in practice, a survey of Finnish shoppers has found.\nThe survey determined that while shoppers at Finland’s largest grocery chain tended to agree that they should eat less red and processed meat — and more legumes and fish — red meat still accounted for about 63 percent of their protein purchases, according to the study in PLoS Sustainability and Transformation.\nPlant-based proteins made up only 8 percent of weekly purchases, the study found.\n“Despite the media hype and accumulating evidence supporting sustainable protein sources” consumer purchases were dominated by “red meat preference and low regard for plant-based options,” the authors said in a statement.\nRed meat, particularly beef, generates the most greenhouse gas emissions of any food, according to Our World in Data.\nTwo wrinkles: The study looked only at people in Finland and included disproportionately more highly educated and high-income people — as well as more women — relative to the population at large.\nThe barrier is preference, not price: “Low income does not appear to be a barrier to buying more sustainable alternatives, as there is a wide price range within all protein sources,” researchers found.\nWelcome to Equilibrium, a newsletter that tracks the growing global battle over the future of sustainability. We’re Saul Elbein and Sharon Udasin. Send us tips and feedback. A friend forward this newsletter to you? Subscribe here.\nToday we’ll look at this week’s second oil spill in Michigan’s Flint River. Then we’ll take a look at how geothermal energy in Iceland has powered a circular economy of related businesses, from fish and algae farms to swimming pools and breweries.\nOil seeps into Flint River\nFor the second time in one week, thousands of gallons of a still-unidentified oil-based material spilled into Michigan’s Flint River on Wednesday, raising the concern of environmental activists in the region.\n- Officials from the Michigan Department of Environment, Great Lakes and Energy estimated that the spill amounted to several thousand gallons and that first responders were deploying a boom across the river to absorb the material, MLive reported.\n- The spill spanned about 5 miles long, according to the outlet.\nActivists fear for safety: “For the second time in one week, we have infrastructure that has been called safe and has failed, leaking oil into our waterways and we know it’s not going to be able to be fully cleaned up,” Sean McBrearty, coordinator of the Oil & Water Don’t Mix campaign, told MLive.\nA slippery history: “No oil spill has ever been fully cleaned up,” added McBrearty, whose campaign is fighting to shut down Enbridge Line 5, a pipeline that sends crude oil and natural gas from western to eastern Canada via the Great Lakes states.\nThe previous spill, which originated at the Algoma Steel Mill in Ontario, dumped about 5,300 gallons of machine-lubricating oil into the river about a week ago, MLive noted.\nDrinking water not in danger: Officials said that the region’s drinking water was not threatened as a result of the spill, The Associated Press reported.\nFlint last used the river as a drinking water supply in 2014-15, until contamination from lead prompted the city to return to a regional water supplier.\nTicking time bomb: Following Wednesday’s spill, the Michigan League of Conservation Voters described the consecutive events as “a wakeup call” that the government should shut down the pipeline.\nThe two spills “should be taken as a clear warning of the danger of oil pipelines in our waters,” Bentley Johnson, federal government affairs director for Michigan League of Conservation Voters, said in a statement.\n“Our water and our health are clearly threatened,” Johnson added, describing the system as a “ticking time bomb in our Great Lakes.”\nOIL SPILL IMPACT GREATER THAN THOUGHT\nHumans are responsible for more than 90 percent of the world’s oil slicks, a new study has found.\nThese findings represent a significant shift from previous investigations, which estimated that about half came from human sources and half from natural ones, according to the study, published on Thursday in Science.\n- Researchers from the U.S. and China said they teamed up to map oil pollution across the Earth’s oceans, using artificial intelligence to scrutinize more than 560,000 satellite images from 2014 to 2019.\n- Because oil slicks are made of microscopically thin layers on the surface of the ocean, short-lived patches are constantly moving around with the wind, currents and waves, according to the scientists. But artificial intelligence enabled the researchers to analyze the huge collection of radar images.\nOil spills big and small: “What’s compelling about these results is just how frequently we detected these floating oil slicks,” co-author Ian MacDonald, a professor at Florida State University, said in a statement.\nThe slicks came “from small releases, from ships, from pipelines, from natural sources such as seeps in the ocean floor and then also from areas where industry or populations are producing runoff that contains floating oil,” according to MacDonald.\n- The researchers found that most were near coastlines — about half were within 25 miles of the shore and 90 percent were within 100 miles, according to the study.\n- They observed fewer slicks in the Gulf of Mexico in comparison to the rest of the world, which they attributed to the effectiveness of government regulation and enforcement.\nImportance of our coasts: In the U.S., coastal waters support many key fish species and provide habitat for 85 percent of migratory bird species to breed, according to the Environmental Protection Agency.\nA potential global solution: “If we can take those lessons and apply them to places globally, where we have seen high concentrations of oil slicks, we could improve the situation,” MacDonald said.\nGeothermal energy powering the circular economy\nUsing the byproducts of one industry to help support the green development of others is a central component of the circular economy.\nThe Hill this week visited two Iceland “resource parks” built around geothermal energy to see this process in action.\n- What’s geothermal again?: This type of energy relies on tapping heat from deep within the Earth for power. (For more on geothermal energy and its central role in Iceland, check out our dispatch from Wednesday.)\n- Why it’s key: Optimizing geothermal resources and creating markets for material that would otherwise go to waste are essential in places like Iceland, which fulfills nearly all its electricity and heat demand from renewable energy.\nBy taking a circular approach to geothermal energy, Iceland’s power producers turn the resource’s waste products into ingredients — and revenue streams — for other industries.\nMultiple use: “You can imagine it as we use the same drop of water many times,” Árni Magnússon of GeoSurvey, which develops geothermal resources, told Equilibrium.\n- For example, the nearly 400-degree Fahrenheit steam that powers the HS Orka’s Svartsengi power station goes first to turn a turbine.\n- Then, once it has cooled to below the boiling point, the heat is drawn off through heat exchangers and used for applications like warming greenhouses and fishponds or processing cosmetics.\nHow do you draw off heat? The process is completed by using a heat exchanger, where a pipe containing cold water runs next to — and draws heat from — a closed loop of hot water.\nThe heat from the geothermal water warms up the cold water — which can then be used to move heat energy to houses, factories or businesses.\nPractical benefits: The exchange of heat without mixing water means that brewery Ölverk can use geothermal waste heat to boil water “without our beer smelling of farts,” CEO Laufey Sif Lárusdóttir told Equilibrium, referring to the characteristic hydrogen sulfide smell that can accompany geothermal steam.\nBaths and tomatoes: In many parts of Iceland, for example, the heat serves to warm swimming pools and the country’s famous thermal baths or power commercial greenhouses that grow peppers and tomatoes.\nSharing streams: The particular needs of geothermal energy provide many niches for other businesses to fill, creating new economies of scale.\n- For example, geothermal plants draw cold water out of the ground to cool their turbines — and inject the warmed-up water back into the ground where it can replenish the pressure in the steam chambers below.\n- This cycle yields additional products — from brine, cold water, steam and even carbon dioxide — that other businesses can use.\nPROFITING FROM A CIRCULAR ECONOMY\nBy placing many different industries near geothermal plants, plant operators are able to create “ecosystems” of green businesses that use each other’s byproducts or infrastructure to lower costs and raise profits.\n- For example, startup Vaxa grows algae to produce protein and Omega-3 fatty acids for use in supplements and by lab-grown meat products using water, electricity and waste heat from the Hellisheiði Power Station power plant in southwest Iceland.\n- Most indoor algae farms struggle with discharging excess heat from their LED grow lights — but Vaxa is able to dump its heat into cold water drawn by the plant, rather than having to pay for electricity to cool it.\nThe warmed-up water then rejoins, and is sent back underground along with, the wastewater stream from the power plant, where it helps maintain the pressure that drives the geothermal energy process.\n“The science we use would work anywhere, but the economics depend on geothermal,” Vaxa founder and CEO Kiddi Hafliðason told Equilibrium.\n- Amid the lichen-covered lava fields around the Svartsengi power station, about 30 miles from Reykjavik — which is owned by HS Orka, Iceland’s largest private geothermal company — several businesses turn the plant’s waste streams into profit.\n- Land-based aquaculture firms like nearby Samherji fish farm, for example, draw heat from the water leaving the plant — allowing the farm’s managers to run operations 30 to 40 percent cheaper than if they had to buy electricity to heat the water themselves.\nExpanding further: These economies of scale have helped HS Orka to host a mutually-reinforcing array of businesses at their Resource Park, manager Dagný Jónsdóttir told Equilibrium, noting that they are looking for additional businesses that can make use of the waste from existing businesses.\nThe Resource Park is in talks with fertilizer producers, who could buy the waste from fish farms, Jónsdóttir added — describing the fish feces from land-based arctic char and steelhead farms as an additional revenue stream.\nWhy bother capturing that waste? The answer may be obvious. “We make money off it,” Jónsdóttir said. “Every stream, we sell for money.”\nAmong the most problematic waste streams to come off a geothermal power plant — or any other thermal plant — is carbon dioxide, a primary culprit in global warming.\nOn Friday, Equilibrium will explore efforts to capture the gas and turn it into stone. This reporting is supported in part by Green by Iceland, a public-private partnership.\nHeat kills thousands of Kansas cattle, residents without tap water in West Texas and feral cats threaten the tiny marsupials of Kangaroo Island.\nExtreme heat kills Kansas cattle\n- Thousands of Kansas cattle have died in the past few days due to high heat and humidity, further straining an industry that is struggling amid extreme weather and escalating production costs, The Washington Post reported.\nWest Texas town waterless in a heat wave\n- Collapsing pressure from a broken water main left the 165,000 residents of the West Texas city of Odessa without water in the midst of nearly-100 degree temperatures, forcing the city to distribute bottled drinking water and deploy water trucks for filling buckets, The Associated Press reported.\nFeral cats threatening Australian marsupial: study\n- Predatory cats are threatening the survival of the critically endangered Kangaroo Island dunnart — a mouse-sized marsupial found only on Kangaroo Island, off the coast of South Australia, a new study in Scientific Reports has found.\nPlease visit The Hill’s Sustainability section online for the web version of this newsletter and more stories. We’ll see you tomorrow.\nThe Hill has removed its comment section, as there are many other forums for readers to participate in the conversation. We invite you to join the discussion on Facebook and Twitter.']	['<urn:uuid:1d2a3123-326b-4108-9859-ef53f56081f9>', '<urn:uuid:3e6566e6-23c4-4043-99e7-0dee4820900d>']	factoid	with-premise	verbose-and-natural	distant-from-document	comparison	novice	2025-05-13T05:52:58.810667	29	41	3279
69	how did pullman strike create labor day chicago history	The Pullman Strike of 1894, where 4,000 Chicago factory workers walked off their jobs due to pay reductions, was a key catalyst for establishing Labor Day as a national holiday. When the National Guard was called in during the strike, 12 people died, which led President Cleveland to create Labor Day as a response to the situation. The federal government established Labor Day as a national holiday in 1894, just months after the strike.	"['Unit #33 / 413 - Pullman National Monument\nSchool just started and you get no break till Thanksgiving.\nSummer\'s ending and there\'s no final bash at the beach.\nYour friend walks into the office wearing white and you have to exclaim, ""Deborah, don\'t you know you can\'t wear white after the first Monday in September?""\nThis is what life would be like sans Labor Day. Without that collective date when we say goodbye to summer with [insert your tradition here] and prepare for college football and pumpkin-spiced everything.\nIt\'d just be another manic Monday.\nBut thank your lucky underwear we do not live in a world without an official day to recognize our labors, and thank the workers honored by Pullman National Monument for making it happen.\nNow, if you\'re a millennial like me, you might assume that companies always consisted of campuses and open-floor workspaces, but if you were an immigrant of 19th century America, you\'d be more likely to complain of your child dying in an accident than the bean bags being taken.\nHowever, for those who made it to an oasis in the prairie south of Chicago, work conditions almost seemed pleasant (even for your 12-year-old little sister on the assembly line).\nYou\'d be given a job and a home to rent nearby, all within walking distance of your church, your children\'s school, a 1,000 seat theater, and one of America\'s first indoor shopping malls.\nAll of that is thanks to George Pullman and his creation of the first model industrial community in America.\nBegun in 1880, this town-built-around-a-factory eventually housed up to 12,000 people in homes that included indoor plumbing, a rarity for the era.\nIf the 1/2 million gallon water tower wasn\'t enough to impress you, you\'d soon be enthralled by the train cars which Mr. Pullman revolutionized.\nIt was on his journey from the East Coast to Chicago (to raise skyscapers so modern conveniences could be installed) that Mr. Pullman yearned for a more comfortable way to travel by train. So he began a business creating Pullman Sleeping Cars that not only made train travel more pleasant, but set the standard for size and style of train cars.\nThis successful enterprise allowed his living/working community to thrive.\nIf that wasn\'t enough to establish his place in history, his company was also the largest employer of African Americans at the time. This allowed for the creation of the first African American union: that for the workforce of former slaves Pullman specifically hired because they knew how to serve wealthy white people.\nThis Brotherhood of Sleeping Car Porters included in their ranks the Great Grandfather of future First Lady Michelle Obama, and is credited as having helped start the modern Civil Rights movement.\nThat union, and its leader A. Philip Randolph, are memorialized in a museum resting in the neighborhood that once made up this factory town (though sadly, African Americans were never allowed to live in Pullman\'s community).\nLarger than its Monument name would presume, this national park consists of homes and workspaces ranging from the original clock tower to executive managers houses and basic laborers less-grand houses.\nThough still in a rough neighborhood on the south side of Chicago, the area is being preserved more and more each day as this park site, established little over a year ago (in Feb. 2015), grows into its own.\nStill an infant compared to many of the National Park Service sites, within the next 5 to 10 years I expect both these buildings and the surrounding neighborhood to take on a Renaissance--hopefully returning this land to the splendor and beauty it had before its eventual demise in the 1890s.\nUltimately, that ruin was the result of what any investor would warn against: lack of diversification.\nWhen a national depression hit in 1893, it led to decreased profits for the entire town. With Pullman keeping rent at the same price--to recoup his investment by 5% per year--it led to a strike from workers feeling the strain. When the National Guard was called in to keep the peace, it led to the death of 12 people, causing President Cleveland to create Labor Day as a band-aid to the problem.\nSo as you sit on a boat, or stand over the grill this weekend, remember this place and the people who worked here. For without the history preserved by this national park, you\'d be fighting for that bean bag at work.\nVanny McVanface (above) just had his first bit of maintenance. To help him survive the coming 125,000+ miles, Donate Here\nPlanning your next vacation? Check out the pins on Mikah\'s map-blog for ideas!\nPullman Highlights (You Can Do)!\n1. Visitor Center\nThough still coming into its own as a park, the non-profit Historic Pullman Foundation has created a temporary Visitor Center while the Park Service renovates the iconic clock tower building to become the official NPS Visitor Center.\nOpen from 11 AM - 3 PM, Tuesdays - Sundays, it includes exhibits of historical artifacts and a comprehensive 20-minute film that sets up visitors well for a...\n2. Car or Foot Tour!\nAs mentioned above, the neighborhood is still rough compared to what most NPS visitors may be used to. Depending on your desire to walk/drive, and likely the weather, you can get a map from the Visitor Center and travel around the neighborhood to see the preserved buildings and homes.\n3. A. Philip Randolph Pullman Porter Museum\nCurrently open seasonally from April - Dec. 1, 11 AM - 3 PM on Thursday-Saturday, this museum ($5 entry fee) celebrates African Americans\' role in U.S. labor history.\n4. Explore Chicago\nYou\'d be crazy to come to this national park and not experience America\'s ""Second City.""\nWhile in the area I got to visit Rotary International\'s HQ in the suburb of Evanston, and be a guest on a number of radio shows. Check out my interview with WGN Radio, housed in the Tribune Tower, on the Brian Noonan Show (from 18:30 - 39:30).\nWe present United Airlines with a challenge, and I got to experience trying to focus while people walk by on Michigan Ave. waving through the glass windows!\nHelp Mikah keep inspiring people to follow their dreams: Donate Here\nWhy is seeing the national parks one of Mikah\'s dreams? Watch this short video to find out!\nUpcoming Units (COMMENT with recommendations. What should I do at each park? Local interesting detours? Food stops?)\nIndiana to Michigan to Ohio to New York to Vermont to New Hampshire to Maine\n-Indiana Dunes National Lakeshore\n-River Raisin National Battlefield Park\n-Perry\'s Victory & International Peace Memorial\n-James A. Garfield National Historic Site\n-Theodore Roosevelt Inaugural National Historic Site\n-Women\'s Rights National Historical Park\n-Fort Stanwix National Monument\n-Martin Van Buren National Historic Site\n-Marsh-Billings-Rockefeller National Historical Park\n-Saint-Gaudens National Historic Site\n-Appalachian National Scenic Trail\n-Katahdin Woods and Waters National Monument *New NPS site added 1 week ago*\n-Saint Croix Island International Historic Site\n-Acadia National Park\nThe journey thus far:', 'Labor Day: From focus on workers’ rights to end-of-summer fest\nBY MICHAEL LANSU Staff Reporter September 1, 2013 5:27PM\nThe Labor Day rally at Daley Plaza on Monday, Sept. 3, 2012, moved to City Hall. | Sun-Times file photo\nUpdated: October 3, 2013 6:21AM\nSmall airplanes race through the air at nearly 200 miles per hour as large groups gather in nearby picnic groves for an afternoon of revelry. It’s not the Chicago Air and Water Show, its Labor Day in Chicago, circa 1930.\nThroughout the first half of the 20th century, a majority of Chicagoans gathered the first Monday of September to celebrate labor at large picnics, elaborate parades or sporting events — including baseball games, boxing matches and airplane races, said Russell Lewis, Chief Historian at the Chicago History Museum.\nEarly Labor Day celebrations in Chicago, a city integral in the holiday’s creation, were “elaborate” events, Lewis said. Social changes meant Labor Day has evolved into a an unofficial celebration of the end of summer, but local union officials say the fight for workers rights is still as important as it was a century ago.\nStates began passing legislation recognizing a Labor Day in 1887, but the federal government did not establish a national Labor Day until 1894 — just months after the Pullman Strike, in which about 4,000 Chicago factory workers for the Pullman Company walked off the job because of pay reductions.\n“The Pullman Strike in 1894 was a big catalyst for the government to find a Labor Day celebration to recognize the labor class and get the focus away from violent confrontation,” Lewis said.\nEarly Labor Day celebrations in Chicago were large events organized by unions where members marched “in full regalia” in parades along Michigan Avenue or at Soldier Field, Lewis said. Other unions held large picnics or sponsored sporting events for its members.\n“People in labor unions were a big, large community,” Lewis said. “Your labor union was your social life and your work life.”\nChicago Federation of Labor President Jorge Ramirez noted, “a strong, healthy and vibrant community is the bedrock of the middle class.”\nBeginning in the 1950s, the “decline of the importance of unions in American life and Chicago” and the “loss of community” led to a transformation of Labor Day celebrations from a recognition of labor to a backyard barbecue-type celebration of the end of summer, Lewis said.\nHowever, not all of the traditional Labor Day celebrations are gone.\nMajor unions in Chicago still hold Labor Day events. The Illinois Labor History Society, Chicago Federation of Labor, Pullman State Historic Site and the National Parks Conservation Association will host a gathering at the Pullman Factory that led to the creation of the holiday nearly than 120 years ago. The gathering will feature music, tours, reenactments and presentations.\nOther union members will connect with community members of various religions at more than 100 services through the Labor in the Pulpits program, Ramirez said.\n“We want to draw a connection with the general respect for work and faith,” Ramirez said.\nAdditionally, some suburbs, including Harvey, Frankfort, Naperville and Schaumburg, still host annual Labor Day celebrations.\nWhile Labor Day celebrations have evolved, local union leaders maintain the importance of labor unions to workers rights. Ramirez noted 2013 is the 50th anniversary of the Equal Pay Act of 1963, created to eliminate wage disparity between sexes.\n“It’s not done. Just because a law is passed doesn’t mean the work is done,” Ramirez said.']"	['<urn:uuid:5fe556ed-8f2e-4130-891e-66e1131f9905>', '<urn:uuid:c67040bc-e124-491b-a6ac-b7c99d3589e2>']	factoid	with-premise	short-search-query	similar-to-document	multi-aspect	novice	2025-05-13T05:52:58.810667	9	74	1748
70	ways reduce sound air water pollution together	Multiple approaches can be taken to reduce pollution across different types. For noise pollution, creating green belts, using machines with silencers, and building high walls around factories help reduce sound transmission. For air pollution, using electrostatic precipitators in industries, avoiding high-sulfur fuels, implementing strip plantation, and maintaining strict vehicle exhaust checks are effective. Water pollution can be controlled by proper waste management, preventing the disposal of dead animals in water bodies, and controlling soil erosion. Legal enforcement and public awareness programs are crucial for all types of pollution control.	"['Noise pollution has become a major problem of modern times. Due to increasing urbanization, transportation (rail, air, and road) and mining, the problem of noise pollution is assuming serious dimensions. Virtually, noise has become an inevitable evil of growth and development.\nRoad congestion, the noise of vehicles, maddening sounds of horn all create such chaos that it seems that your ears will burst. Moreover, factory sirens, jarring sound of the running of machines and film songs ringing loud on loudspeakers too contribute in the increase in noise pollution. For the last some decades, the rise and pollution has drawn the attention of governments all over the world. Industrialization, modern means of transportation, population growth, urbanization and increasing human activities are taking their toll on the human and animal habitat.\nToday, man is living amongst deafening noises. The noise produced by motor vehicles, trains, jet aircraft, and sound amplifier devices installed at temple-mosque, synagogue and housing societies is having an adverse effects on human health. Hoarse voices emanate from factories; various businesses hit our ears and make our mind turbulent. Modern means of transport such as bus, car, truck, motorcycle, train, aircraft, etc fill the air with all kinds of sounds. Nowadays homes are very close to one another in cities, increasing the amount of domestic noise. The noise of radio, television and other sound-broadcasting devices is also growing day by day. Different kinds of sounds are occurring around us, giving rise to mental stress, deafness and health problems. This issue requires urgent attention now.\nFollowing are the major sources of noise pollution:\nAlmost all industrial areas are affected by noise pollution and a major reason for this is the sound generated by machines. Boilers and turbines installed in thermal power plants generate considerable noise in their surroundings. Most industries are established in urban areas, where there is higher intensity of noise pollution.\n- Means of transport\nVarious forms of transport are also a major cause of noise pollution. All these means produce sound in extremely high volumes. The pollution by these modes spreads across a large area. The total number of vehicles in India in 1950 was 30 million, whereas the total number of registered motor vehicles reached approx. 210 million in March 2015. In Lucknow alone, more than one lakh vehicles are registered and their number is increasing by 5 to 10 percent annually. Considering the above facts, one can only imagine the enormity of rising air pollution along with noise pollution.\nMan uses various means for his entertainment such as TV, radio, music systems, etc but these instruments cause unbridled noise. Loudspeakers and DJs used in wedding engagement programs, religious events, etc, greatly contribute towards noise pollution.\nUse of different machines and tools in various construction works leads to increased noise pollution with adverse effects on the health of construction workers as well as people living in the surroundings.\nThe firework at display on various occasions in our country is also a source of noise. Firework is a common item during various fairs, festivals, and cultural/marriage ceremonies. Crackers are burst to express the joy of India winning a cricket match. But apart from air pollution due to these fireworks, the intensity of their sound is so high that it gives rise to problems such as noise pollution.\nDuring Diwali, noise pollution levels due to fireworks increase many times in cities. As crackers are burst over fixed standard hearing limits, many people suffer damage in their ears and some also develop allergy. In cities, generally, bursting crackers of more than 125 decibels of sound is banned but despite various measures adopted by the Pollution Control Board, the level of noise is increased every time during festivals.\nExchange of words held among populations gathered at various social, religious functions, political rallies, and meetings of trade unions produce a deafening din. Similarly, intolerable noise is generated at market places, schools, colleges, bus stands, and railway stations due to the huge population present there. Similarly, several other smaller causes give rise to noise pollution. For instance, less wide roads, the lack of alternative arrangements for those who sell goods on the street, traffic in the peak hour traffic, etc.\nDue to growing population of cities and towns, lack of proper congregation sites as well great cost entailed in booking them on rent, people often occupy public road or pathway in front of the house and turn it in the venue of their event. This does not only block but even shuts the whole passage. Whereas under the Article 19 (1) (d) of the Constitution, citizens have the right to walk on uninterrupted barrier-free road. Obviously, organising such events also leads to noise pollution. As events take place late at night, the sleep of the residents of that area is bound to get disturbed. The situation becomes even more difficult for those who are mentally or physically unable to bear loud sounds. During night-long Jagrans, week-long religious programmes and all kinds of other entertainment events, standard sound limits are not followed. Students, in particular, suffer the consequences most as their studies are interrupted. Noise at the time of examination poses a serious threat to their future. Often such programs are patronized by local MLA/MP, so, the local authorities do not take any action despite complaints.\nNoise Pollution and Law\nAccording to rules, any kind of noise pollution is prohibited that emanates from scooter, car, bus horns, DJ, loudspeaker, marriage band, or musical instruments played during religious functions held in open space from ten at night until six in the morning. During this period, no one is allowed to produce any kind of noise that exceeds more than 75 decibels (up to one metre from the source of sound).\nBut law enforcement agencies have often been found to be grossly wanting in enforcing the law of the land. Parties and religious functions go at high pitch throughout the night, causing restlessness in the community. But if the people are determined they can force police action in such violations of the prescribed limits of sound and the time beyond which no noise is allowed to take place. In fact, the violators of these rules can be imposed a fine of Rs one lakh or five years’ jail, or both, may be sentenced together under the Environmental Protection Act, 1986 , besides Section 290 and 291 of the IPC. Thus, the problem of noise pollution needs to be dealt with in right earnest.', ""Pollution is the presence of a substance that tends to affect directly or indirectly the environment or changes, degrades or spoils the environment. Pollution can be categorized into following types:\n- Air Pollution\n- Water Pollution\n- Soil Pollution\n- Noise Pollution\nAn undesirable change in the physical, chemical or biological characteristics of air is called pollution. The substances which pollute the air called pollutants. Air pollution causes heart diseases, eye problem, cancer etc. Apart from it, air carries the bacteria and virus from one place to another place and transmits different diseases such as tuberculosis, polio, diphtheria and acute respiratory tract infections.\nCauses of air pollution\nThe following are the main causes of air pollution:\n- The dust particles and harmful materials blown out by the wind gets mixed in the air and pollutes it.\n- Natural gases that come from inside the earth's surface also pollutes the air.\n- Harmful gases released from different factories, industries and vehicles pollutes the air.\n- Gases that comes from burnt materials,rotten and decayed materials also pollutes the air.\n- Poisonous gases spreading out in the fields, rooms and houses are also the causes for air pollution.\nEffects of air pollution\nThe following are the effects of air pollution:\n- Air pollution causes respiratory tract infection (RTI) and asthma.\n- It deteriorates the cultural heritage and trees.\n- It brings various skin and eye allergy.\n- It is the main cause of global warming. that affects all the creatures of the world.\nPreventive measures of air pollution\nThe preventive measures of air pollution are as follows:\n- The air pollutants should be controlled as the point source by using electrostatic precipitator or filter in the industries.\n- The use of cheap fuel with higher sulphur content should be avoided. Use of disulphurized coal should be used.\n- Alternate sources of energy should be used in place of coal, wood, oil etc.\n- Population growth rate should be controlled.\n- Strip plantation should be done everywhere on the road side.\n- Strict check of car exhaust should be maintained.\n- Public awareness programme about the effects of pollution should be managed.\nDegradation in the quality of water is called water pollution. Water covers over the 3/4th part of the earth’s surface. It is a very important resource for people and the environment. Water pollution affects drinking water, rivers, lakes and oceans all over the world. In many developing countries, it is usually a leading cause of death, by people drinking from polluted water sources. Drainage and wastage from industries, laboratory, hospitals, and homes are the main factors that causes water pollution.\nCauses of water pollution\nThe following are the main causes of water pollution: -\n- Natural calamities like flood, landlides, soil erosion, heavy rain, etc. also pollute the water.\n- Leakage of agro-chemical from agricultural fields mixing with water resource can also cause water pollution.\n- Throwing of dead bodies of animals in water resources also pollutes water.\n- Some human activities like washing of clothes and utensils near wells, ponds, streams, lakes, etc. also pollutes the water sources.\nEffects of water pollution\nThe following are the main effects of water pollution: -\n- Water pollution causes water-borne disease like diarrhoea, dysentery and cholera.\n- It also brings various skin allergy if taken the bath with polluted water.\n- Acid rain deteriorates cultural heritages.\n- It has the negative impact on plants.\n- Aquatic animals cannot survive in polluted water.\nPreventive measures of water pollution\nThe following are the main preventive measures of water pollution: -\n- The dead bodies of animals and other wastes should not be thrown in water resources.\n- People should be made aware of the consequences of water pollution and they should be encouraged to participate in the pollution control programme.\n- Production of domestic waste should be reduced as far as possible and it should not be thrown in and around the water resources like ponds, rivers, lakes, streams etc.\\\n- Water pollution due to soil erosion, landslides, and floods should be controlled by minimizing the activities which cause these problems.\nLand pollution is the degradation of earth's surface. Land pollution makes the quality of soil low. It directly affects the plants and indirectly to human beings. Human actions have also caused many large areas of land to lose or reduce their capacity to support life forms and ecosystems. This is known as land degradation.\nCauses of land pollution\nThe following are the main causes of land pollution: -\n- The accumulation of huge amount of bio-degradable and non-biodegradable waste materials pollutes land.\n- Farmers use chemicals such as fertilizers and pesticides in their farms to increase production. However, it adversely can affect land and water resources in and around there.\n- Soil is polluted by storing of soluble and insolubledirt's on the earth.\n- Trekkers and mountaineers carry different types of packed food and other necessary things with them. After using them, they throw such materials like plastics, tins and other materials there. This pollutes some of the tourist areas of rural and city parts of Nepal.\n- The solid and liquid substance of the industries such as leather, shoe, battery distillery, paper and metal destroy the land conditions and it pollutes the soil.\nEffects of land pollution\nThe following are the main effects of land pollution:\n- Land pollution kills the useful organisms like an earthworm.\n- The soil becomes infertile and not suitable for cultivation.\n- Agriculture production will decrease.\n- Underground water becomes polluted.\n- Bad smell spreads from the polluted land and it causes pollution to the surrounding places.\n- It destroys beauty of the environment and the importance of cultural heritages as well.\nPreventive measures of land pollution\nThe following are the preventive measures of land pollution: -\n- Bio-degradable materials such as residue of plants, vegetables and other wastes of plants should be used to make compost.\n- Broken machines, vehicles and other materialsshould be re-used.\n- Legal provision should be made on the management of solid wastes.\n- The solid waste and harmful chemicals from industries, hospitals and laboratories should be processed and purified to some extent before discharging them to land and water resources.\n- The use of plastic bags and other materials made from plastic should be reducedand must be re-used in some extent.\nNoise is considered as environmental pollution, even though it is thought to have less damage to humans than water, air or land pollution. Noise pollution also disturbs the ecosystem. Noise pollution does not harm the environment as much as air pollution but if affects the health of the person negatively. If someone has to stay in a very noisy condition for long time, this will affect the hearing power (nervous system).\nCauses of noise pollution\nThe following are the main causes of noise pollution:\n- Noise is created during construction by machinery.\n- Market area, densely populated settlement, industrial area produces much sound that causes noise pollution.\n- Industries like cement factory, flour mill, metal industries, etc. produces loud noise.\n- Noise-pollution is caused by construction activities like road construction and building construction.\n- Crowd in urban areas and miking causes sound pollution.\n- Playing radio, television and various musical instruments in high volume causes sound pollution.\nEffects of noise pollution\nThe following are the main effects of noise pollution:\n- Sitting in a noisy place for long time damages our hearing capacity.\n- It causes imbalance in the production of hormones.\n- Frustration, depression, hypertension etc. may cause.\n- High-stress level and sleep disturbances may happen.\n- A loud noise may break the tympanic membrane of the ear and it leads to diseases.\nPreventive measures of noise pollution\nThe following are the preventive measures of noise pollution:\n- Green belts should be created where there is the high level of noises.\n- The people who work in noisy places should use earplugs.\n- Vehicles which produces loud noise should not be operated near the cities.\n- High walls can be built around the factory which helps to check the transmission of noise.\n- Machine with silencer should be used as far as possible. Regular servicing of machie is also helpful to check the sund pollution.""]"	['<urn:uuid:808e8f8b-3bb0-4047-9826-f32e2911b981>', '<urn:uuid:90fe0036-5348-4da8-9670-372db29d74db>']	open-ended	direct	short-search-query	distant-from-document	three-doc	novice	2025-05-13T05:52:58.810667	7	89	2451
71	radiological investigation bleeding intestine why	Mesenteric arteriography is performed when endoscopy cannot locate the source of bleeding in the gastrointestinal tract, or when other studies fail to provide enough information. It may be performed after nuclear medicine scans have identified active bleeding, allowing the radiologist to pinpoint and treat the source.	['Mesenteric arteriography is an x-ray exam of the blood vessels that supply the abdominal area, including the small and large intestines.\nAbdominal arteriogram; Arteriogram - abdomen\nWhy the Test is Performed\nThis test is done:\n- When endoscopy cannot locate the source of bleeding in the gastrointestinal tract\n- When other studies fail to provide enough information about abnormal growths along the intestinal tract\n- To possibly look at blood vessel damage after an abdominal injury\nA mesenteric arteriogram may be performed after more sensitive nuclear medicine scans have identified active bleeding. The radiologist can then pinpoint and treat the source. See: Endovascular embolization.\nHow the Test is Performed\nThis test uses x-rays and a special dye (contrast material) to make blood vessels show up on the images.\nThis test is done in a hospital. You will lie on an x-ray table. You may ask for a sedative if you are anxious about the test.\nThe health care provider will shave and clean the groin area. A numbing medicine (anesthetic) is applied, and a needle inserted into an artery. A thin flexible tube called a catheter is passed through the needle, into the artery, and up through the main vessels of the belly area and chest until it is properly placed into a mesenteric artery. The doctor can see live images of the area on a TV-like monitor, and uses them as a guide.\nContrast dye flows through the catheter into the blood vessels. X-ray images are taken. The catheter is occasionally flushed with saline solution containing a drug called heparin to help keep blood in the tube from clotting.\nPressure is immediately applied to the puncture site for 10-15 minutes to stop the bleeding. After that time the area is checked and a tight bandage is applied. The leg should be kept straight for an additional 4 hours after the procedure.\nHow to Prepare for the Test\nYou should not eat or drink anything for 8 hours before the test.\nYou will be asked to wear a hospital gown and sign a consent form for the procedure. Jewlery should be removed from the area being imaged.\nTell your health care provider:\n- If you are pregnant\n- If you have ever had any allergic reactions to x-ray contrast material or iodine substances\n- If you are allergic to any medications\n- Which medications you are taking (including any herbal preparations)\n- If you have ever had any bleeding problems\nHow the Test Will Feel\nThe x-ray table is hard and cold, but you may ask for a blanket or pillow. You may feel a brief sting when the numbing medication (anesthetic) is given. You will feel a brief sharp pain as the catheter is inserted into the artery, and some pressure as it is moved into place.\nAs the dye is injected, you will feel a warm, flushing sensation. You may have tenderness and bruising at the site of the injection after the test.\nThere is some risk of the catheter damaging the artery or knocking loose a piece of the artery wall, which can reduce or block blood flow and lead to tissue death. This is a rare complication.\nOther risks include:\n- Blood clot\n- Reaction to the contrast dye\nResults are considered normal if the arteries being examined are normal in appearance.\nWhat Abnormal Results Mean\nAbnormal results may be due to\nReviewed By: Benjamin Taragin M.D. Department of Radiology Montefiore Medical Center, Bronx, N.Y. Review provided by VeriMed Healthcare Network. Also reviewed by David Zieve, MD, MHA, Medical Director, A.D.A.M., Inc.']	['<urn:uuid:a27b8db1-aa38-4b87-8d4e-0de98c105eec>']	factoid	with-premise	short-search-query	distant-from-document	single-doc	expert	2025-05-13T05:52:58.810667	5	46	596
72	What are the main differences between vinyl and pressure treated wood when it comes to maintenance and durability for outdoor use?	Vinyl requires minimal maintenance, needing only occasional cleaning. It doesn't rot, splinter, or suffer from insect attacks, and is highly resistant to water and sunlight. Its main drawback is that it can become brittle and crack in cold weather. Pressure-treated wood, while more resistant to rot and insects than regular wood, still needs regular cleaning and finishing to maintain good condition, and can eventually crack, splinter and rot. However, wood has superior structural strength compared to vinyl, which often needs metal reinforcement for strength.	['The great debate\nWhether to pick vinyl or wood\nVinyl isn’t maintenance-free, of course, but it comes close to being that. Vinyl is currently used for a long list of building products, most of which require little care except occasional cleaning. The big virtue of vinyl is that the color goes all the way through — it has no surface finish such as paint or stain. It can be painted, but that is seldom necessary unless a color change is wanted. Unlike wood, it doesn’t rot or splinter and is resistant to insect attacks. It is also highly resistant to water and sunlight, both of which are anathema to wood.\nA disadvantage of vinyl, which I don’t consider a serious failing, is that it can become brittle in cold weather and a sharp impact while it is cold can cause it to crack. I have used many vinyl products and have never had this happen.\nPressure treating has made some wood a more durable outdoor material, giving resistance to rot and insects, but even treated wood can crack, splinter, and eventually rot. It also needs regular cleaning and finishing to help keep it in good condition. However, wood has superior structural strength. Where strength is important, vinyl is often reinforced with aluminum or other metals.\nPrice comparison is difficult because so many systems are available, but, in general, treated-wood railings are less expensive than vinyl railings.\nDear Gene: Can pressure-treated wood be stained? — E.T.\nTreated wood can and should be stained to help protect it against the effects of moisture and sun. Stains can be bought at any home center or paint store; Wolman, Cabot, and Olympic are just three of the many brands available.\nTwo basic types of stain are generally used: solid color (opaque), which is much like paint, and semitransparent, which is more lightly pigmented and allows some of the grain pattern to show through.\nAnyone planning to stain a deck or other outdoor structure should check an article titled “Deck Treatments” in the July 2006 issue of Consumer Reports magazine. The article rates a variety of stains on their performance in tests conducted by the magazine.\nIt is best to clean a deck before staining it. Use one of the special deck cleaners sold at home centers and paint stores.\nDear Gene: Last fall we had terrible rainstorms, and a lot of water came down our chimney and into the brick fireplace. Since then a powdery substance has formed on the surface of the fireplace bricks. We have brushed some of it off, but we don’t know how to get the rest off. What is this stuff, and what can we do about it? — L.G.W.\nThe white substance is called efflorescence; it consists of harmless minerals brought to the surface of he bricks by moisture. Efflorescence is also common in concrete.\nThe only real solution is to stop the water penetration. If you don’t have a chimney cap, you should install one.\nThere are chemical treatments to remove the powdery substance, but some are dangerous to apply and can do more harm than good. Some experts advise against using these treatments on bricks except in extreme cases. For more information, go to the Web site www.redlandbrick.com/techinfo.html.\nMy advice is to continue dry-brushing and vacuuming the bricks and let some time pass. It is possible that the bricks will eventually stop leaching minerals.']	['<urn:uuid:b574cda8-9079-4f47-b0ef-c1a01d9100b9>']	factoid	direct	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-13T05:52:58.810667	21	84	568
73	I'm getting a new puppy. What's the best age to bring it home?	The optimal age to bring a puppy home is 8 weeks of age.	['Updated November 29, 2020\nWelcome to the exciting path to getting a new dog. Please visit all three stages:\n- Deciding which dog breed to choose\n- Finding a good breeder or shelter\n- Choosing the best dog from the breeder or shelter (that’s this one!)\nYou thought you’d done the hard part: choosing your ideal breed, then finding the right breeder or shelter, and then you get that phone call. “Please come between 9 and 12 tomorrow to choose which puppy you want”.\nSuddenly, the pressure is on. How do you make a quick decision and not make a mistake in choosing a dog from a litter? We’ll get to that soon, but first a few special words about shelters.\nChoosing Dogs From Shelters\nWith rescue shelters, it’s often a case of choosing from what’s available. That doesn’t mean you’ll be worse off; you have their considerable expertise to help guide you.\nAny good large shelter will have clearly established procedures for matching dogs with owners. After all, they don’t want failures either. I can’t do better than to say:“go with their expert advice before mine”.\nSmaller shelters with only a few dogs may not have such clear guidelines, but they have a person who knows each dog very well. Once again, you can usually rely on their assessment.\nTo get around the inevitable risk, many places allow a limited trial period with a no-questions-asked return policy if things don’t work out. However, any good dog requires work, and no shelter dog is perfect out of the box so use this offer wisely and sparingly.\nNow let’s talk about choosing puppies in general. A lot of this applies to shelters as well.\nChoosing Which Puppy to Take\nYou may not get a choice in every litter. Some are earmarked for breeding, some may have been reserved for a long time. Sometimes there just aren’t that many pups to choose from. If this is your situation, don’t worry; differences within a litter aren’t usually huge, and even the difference between male and female dogs isn’t that big a deal. However, if you have a choice, here’s what to think about:\nGet there early\nIf you’re given a range of times, try to arrive at the start, not the finish. If you can’t be there, it’s probably better to communicate your wishes with the breeder than to send a friend. The breeder knows the pups far better than your friend, who really shouldn’t be put in that position anyway.\nBe practical, not emotional\nDon’t choose puppies just because you feel sorry for them. This especially applies to dodgy breeders and pet shops. If you buy that puppy, you support the breeding of more puppies in the same situation.\nWatch the litter together\nLook for puppies that are very boisterous and pushy over the others: these may always be the more confident and possibly headstrong dogs. Puppies who have separated themselves away need careful watching to make sure nothing’s wrong. Bear in mind puppies sleep a lot so sleeping means nothing.\nAssess each puppy individually\nFollow the breeder’s advice on what to do but I like to sit on the floor and have them passed to me. Each one should show interest in you and show minimal fear. None may be happy to separate from mum but ideally they will sniff and lick at you. If one seems especially timid, they will probably show up now.\nYou’re not a vet but there’s a lot you can see. Size isn’t important (read here why it’s a myth that runts are less healthy) but body condition matters a lot. All the puppies should have the same ‘covering’ of fat and muscle: beware the thin, bony puppy. Other things to look for include:\n- No discharge from the eye or nose\n- Clean ear canals\n- Coats in good condition\n- Good movement and sitting\n- Formed faeces (logs, not cowpats)\n- Minimal breathing noises in short-faced breeds like pugs\nMost breeders are great but don’t accept excuses like “their coats are dirty because it’s dusty” or “his poos are runny because we changed the food”.\nAsk the breeder’s opinion\nI’ve said it already: no-one knows these puppies like they do.\nIf you hear of other puppies from the litter that died, be careful. One pup death is normal, more than that isn’t.\nThink about gender differences\nMales can be more active and strong-willed, even when desexed, though the difference is not huge and can be a positive. Females are slightly more expensive to desex (neuter). In general, relationships are more harmonious if you choose the opposite sex to your existing dog (if you have one).\nAre two puppies better than one?\nUnless you are very confident, it’s better to only take one, get this pup well-trained, and 6 months later get a second. Having two puppies together is often just too much.\nWhat’s the best age?\nThe optimal age to bring a puppy home is 8 weeks of age. Read the evidence here.\nWhat about older dogs?\nSometimes the breeder will offer you a dog they have held back for breeding, rejected for showing or had returned. Issues can include:\n- Socialisation. If this dog may not have been adequately socialised before 16 weeks of age to the expected stimuli in your lifestyle. If so, you may see anxiety in novel situations such as going out for walks, travelling in cars or using vacuum cleaners.\n- Family-friendliness. Special mention is needed for socialisation to children. If this hasn’t happened adequately, your dog may always avoid kids, or worse.\n- Toilet training. Older dogs who have learnt to toilet on concrete have a hard time relearning not to go on floors.\nMany of these issues won’t apply if the dog lived in the house and was treated like a normal pet. They are more prevalent in busy breeding kennels.\nOn the plus side, older dogs that have been given a good start can be a lot easier for busy people.\nAbove all, don’t stress too much. Very few people make a bad choice. Even if you do, there’s still something we can do…\nMake sure you book your free vet check for shortly after you get your puppy. We can’t find everything, but most problems will be picked up straight away and treated. If it’s something serious like a bad heart, better to know straight away than later.\nBy Andrew Spanner BVSc(Hons) MVetStud, a vet in Adelaide, Australia. These blogs are from a series regularly posted on email and Twitter. Subscribe via email here to never miss a story!\nHave something to add? Comments are welcome below and will appear within 24 hours.']	['<urn:uuid:a9bacdfd-a1ba-41ee-8cda-dc1e5a31170f>']	factoid	with-premise	concise-and-natural	similar-to-document	single-doc	novice	2025-05-13T05:52:58.810667	13	13	1118
74	What are the mortality rates between polio and Chikungunya epidemics in different cases?	In the 1954 Jamaican polio epidemic, out of 759 infected people, 94 died. For Chikungunya, the average mortality rate is about 4 out of 100 people, with a slightly higher risk for infants. The mortality comparison shows that both diseases can be lethal, though their death rates manifest differently - polio had a specific outbreak with documented numbers, while Chikungunya has an ongoing statistical average.	"['Two spelling systems are used for the Jamaican language below. The first, which I call ‘chaka-chaka’, is based on English spelling. The second, ‘prapa-prapa’, is the specialist system designed by the Jamaican linguist Frederic Cassidy. It has been updated by the Jamaican Language Unit at the University of the West Indies, Mona. After the two Jamaican versions, there’s an English translation.\nMi nah put goat mout pon Malcolm Gladwell. Not at all. Mi hope mosquito never bite im an gi im chik-V wen im come ya fi talk last week up a UWI. Im come fi help raise money fi di Sir John Golding Rehabilitation Centre. Dat deh centre did set up inna 1954 fi look after di whole heap a people dem weh did ketch polio. Di sickness tek Jamaica inna di July an 759 smaddy did get lik down; an 94 a dem dead.\nPolio a one next virus laka chik-V. But a no mosquito spread it. Yu ketch it straight from one next smaddy. Mi know nuff a wi think seh a di said same ting wid chik-V. A no so-so mosquito. But di big-time scientist dem seh a no so. We done know bout science an science. But mek mi lef it.\nPolio mash up yu nerves an bend yu up same time. Di good ting bout polio, dem have injection weh can protect yu. No injection no deh fi chik-V. An wen it tek yu, it hold on pon yu. Long time. An if any odder sinting wrong wid yu, chik-V mek it worserer. Yu can dead sake-a chik-V. Mi tink more an 94 a wi a go dead by di time chik-V done wid wi.\nPITCH OVER YA SO\nMalcolm Gladwell write one book weh im call The Tipping Point. Inna fi wi language, pitch over ya so. See di rest a di title: How Little Things Can Make a Big Difference. A true. Look how one lickle mosquito mash up so much a wi! Mi seh wi ha fi tek bad tings mek joke. Like how di lickle yute, Wayne J, sing bout ‘One Panadol’.\nThe Tipping Point a di first book Gladwell write weh come out inna 2000. An it sell off! A fi him ‘tipping point’ dat. Di book pitch Gladwell over mek im a roll inna money. Nuff, nuff money. Mi glad fi him. Him a one a wi. Him mother born right ya so. An him father from England know good woman.\nHear how Gladwell explain himself: “The tipping point is that magic moment when an idea, trend, or social behaviour crosses a threshold, tips, and spreads like wildfire. Just as a single sick person can start an epidemic of the flu, so, too, can a small but precisely targeted push cause a fashion trend, the popularity of a new product, or a drop in the crime rate.”\nGladwell tek di science bout how sickness spread all bout an divel it up. Him show wi how sopn good can spread same way. Me tink seh right now, Jamaica ready fi pitch over. Chiv-V mek wi see seh wi ha fi clean up di country. An a no ongle dutty wata mi mean. By di way, di chik-V mosquito love clean wata.\nInna him lecture, Gladwell seh wi ha fi rispek one anodder an trust one anodder. Wi ha fi mek everybody inna Jamaica know seh di whole a wi a smaddy. An me seh if it tek chik-V fi force wi fi see seh wi can’t gwaan so careless bout evriting inna Jamaica, dat a fi wi ‘Tipping Point’ fi true.\nMi naa put guot mout pan Malcolm Gladwell. Nat at aal. Mi uop maskita neva bait im an gi im chik-V wen im kom ya fi taak laas wiik op a UWI. Im kom fi elp ries moni fi di Sir John Golding Rehabilitation Centre. Dat de centre did set op ina 1954 fi luk aafta di uol iip a piipl dem we did kech puolyo. Di siknis tek Jamieka iina di Juulai an sevn ondred an fifti nain smadi did get lik dong; an nainti fuor a dem ded.\nPuolyo a wan neks vairus laka chik-V. Bot a no maskita spred it. Yu kech it chriet fram wan neks smadi. Mi nuo nof a wi tingk se a di sed siem ting wid chik-V. A no suoso maskita. Bot di big-taim saiyantis dem se a no so. Wi don nuo bout saiyans an saiyans. Bot mek mi lef it.\nPuolyo mash op yu norz an ben yu op siem taim. Di gud ting bout puolyo, dem av injekshan we kyan protek yu. No injekshan no de fi chik-V. An wen it tek yu, it uol aan pan yu. Lang taim. An if eni ada sinting rang wid yu, chik-V mek it wosara. Yu kyan ded siek a chik-V. Mi tingk muor an nainti fuor a wi a go ded bai di taim chik-V don wid wi.\nPICH UOVA YA SO\nMalcolm Gladwell rait wan buk we im kaal The Tipping Point. Ina fi wi langgwij, pich uova ya so. Si di res a di taikl: How Little Things Can Make a Big Difference. A chruu. Luk ou wan likl maskita mash op so moch a wi! Mi se wi ha fi tek bad tingz mek juok. Laik ou di likl yuut, Wayne J, sing bout ‘Wan Panadal’.\nThe Tipping Point a di fos buk Gladwell rait we kom out ina 2000. An it sel aaf! A fi im ‘tipping point’ dat. Di buk pich Gladwell uova mek im a ruol ina moni. Nof, nof moni. Mi glad fi im. Im a wan a wi. Im mdaa baan rait ya so. An im faada fram Ingglan nuo gud uman.\nIer ou Gladwell eksplien imself: “The tipping point is that magic moment when an idea, trend, or social behaviour crosses a threshold, tips, and spreads like wildfire. Just as a single sick person can start an epidemic of the flu, so too can a small but precisely targeted push cause a fashion trend, the popularity of a new product, or a drop in the crime rate.”\nGladwell tek di saiyans bout ou siknis spred aal bout an divel it op. Im shuo wi ou sopn gud kyan spred siem wie. Mii tingk se rait nou, Jamieka redi fi pich uova. Chiv-V mek wi si se wi ha fi kliin op di konchri. An a no ongl doti wata mi miin. Bai di wie, di chik-V maskita lov kliin wata.\nIna im lekcha, Gladwell se wi ha fi rispek wanada an chros wanada. Wi ha fi mek evribadi ina Jamieka nuo se di uola a wi a smadi. An mii se if it tek chik-V fi fuors wi fi si se wi kyaahn gwaahn so kielis bout evriting ina Jamieka, dat a fi wi ‘Tipping Point’ fi chruu.\nI’m not putting a jinx on Malcolm Gladwell. Not at all. I hope he wasn’t bitten by a mosquito and didn’t get chik-V when he came here to give a talk last week at UWI. He came to help raise money for the Sir John Golding Rehabilitation Centre. That centre was set up in 1954 to care for the large number of people who caught polio. The epidemic broke out in Jamaica in July and 759 people were infected; and 94 of them died.\nPolio is another virus like chik-V. But it’s not spread by mosquitoes. You catch it directly from another person. I know a lot of us think that’s exactly how chik-V is passed on. Not only by mosquitoes. But the eminent scientists disagree. We know the difference between science and science. But don’t let me go there.\nPolio destroys your nerves and twists you up immediately. The good thing about the disease is that there’s a vaccine for it. There’s none for chik-V. And when it infects you, it lingers for quite a while. A ‘good’ while. And if have any chronic illnesses, chik-V makes them rather worse. You can die because of chik-V. I think that more than 94 of us are going to die by the time chik-V is finished with us.\nTHE TIPPING POINT\nMalcolm Gladwell wrote a book called The Tipping Point. In our language, pitch over ya so. Here’s the sub-title: How Little Things Can Make a Big Difference. It’s true. Just think about how one little mosquito has crippled so many of us! We really do have to laugh at our troubles. Like the boy, Wayne J, who sings about ‘One Panadol’.\nThe Tipping Point is Gladwell’s first book which was published in 2000. And it was a bestseller! That was his ‘tipping point’. The book catapulted him to fame and fortune. A huge fortune! I’m very happy for him. He’s one of us. His mother was born right here. And his father, who’s from England, chose his wife very well.\nHear’s how Gladwell explains the book’s title: “The tipping point is that magic moment when an idea, trend, or social behaviour crosses a threshold, tips, and spreads like wildfire. Just as a single sick person can start an epidemic of the flu, so, too, can a small but precisely targeted push cause a fashion trend, the popularity of a new product, or a drop in the crime rate.”\nGladwell applied to social issues the principle of how epidemics spread. He argued that good things can spread in exactly the same way. I think Jamaica is at at turning point right now. The Chiv-V epidemic has forced us to acknowledge the fact that we must clean up the country. And it’s not only dirty water I’m talking about. By the way, the chik-V mosquito loves clean water.\nIn his lecture, Gladwell said that we have to respect and trust each other. We have to make everybody in Jamaica know that that all of us count. And I say that if it takes chik-V to force us to see that we can’t continue to be so irresponsible about everything that matters in Jamaica, that truly is our ‘Tipping Point’.', '- Chikungunya: description\n- Chikungunya: symptoms\n- Chikungunya: causes and risk factors\n- Chikungunya: diagnosis and examination\n- Chikungunya: treatment\n- Chikungunya: disease course and prognosis\nChikungunya is a feverish viral disease. It occurs mainly in Africa and Southeast Asia and is transmitted by mosquitoes. In addition to high fever, severe muscle and joint pain are typical Chikungunya symptoms. The disease is usually benign. However, only the complaints can be treated, not the triggering virus. Read all important information about Chikungunya here.\nICD codes for this disease: ICD codes are internationally valid medical diagnosis codes. They are found e.g. in doctor\'s letters or on incapacity certificates. A92\nCauses and risk factors\nExaminations and diagnosis\nDisease course and prognosis\nChikungunya is a feverish infectious disease. It is triggered by the Chikungunya virus. This pathogen, also known as CHIK virus, is transmitted to humans by mosquitoes. The name comes from Tanzania. In the language of the Makonde, Chikungunya means ""warping"" or ""becoming crooked,"" indicating the typical Chikungunya symptoms of joint and muscle pain.\nChikungunya occurs in many Asian and African countries, including the tropical regions of the Indian subcontinent and the Pacific Islands. In 2013, Chikungunya met Caribbean islands and spread for the first time in the region of North, Central and South America. Previously, there had been only isolated cases with returnees.\nIn Europe so far only transfers from Italy (2007 scarcely 200 sick ones by a from south India returned tourists) and France were proven. Chikungunya is one of the ""travel diseases"" due to its distribution.\nIn 2014, the Chikungunya fever was observed in 162 vacationers, according to the Robert Koch Institute. The year before, it was only 16. As a reason for the increase, the spread of Chikungunya virus in the American countries is suspected. The number of Asian tiger mosquitoes - as a typical transmitter of the CHIK virus - is also increasing in Germany. But it has not yet come to disease transmissions.\nThe first symptoms of Chikungunya disease appear after about two to seven, sometimes even after twelve days (incubation period). Infected people suddenly get high fever (average 39 degrees Celsius) and headaches. In some cases, the increased body temperature drops abruptly after a few days, but then increases rapidly (about one to three days, sometimes only a week later). Physicians speak in this case of a biphasic fever course. Due to the rapid rise in temperature, infants and toddlers may experience febrile convulsions.\nTypical Chikungunya symptoms are also severe joint and muscle pain (arthralgia and myalgia) that occur from the beginning. These are sometimes so unbearable that those affected can hardly stand. In some cases, patients also complain of swollen joints and lymph nodes. Conjunctivitis, cervical and abdominal pain are among the rare but possible Chikungunya symptoms. The heavily perfused, hot skin (flush) can sometimes be followed by an itchy, nodular-mottled rash (maculopapular rash). Chikungunya\'s severe malady accompanied by fatigue and nausea will fade after about one to two weeks.\nThe Chikungunya symptoms are sometimes very strong. However, not all infected people develop signs of the disease. In some cases, Chikungunya is also symptomless. In about one quarter of those affected it comes to more severe disease processes with punctate skin bleeding (petechiae) and mucosal bleeding (eg nosebleeds). In this case, doctors speak of a hemorrhagic Chikungunya fever, which is why Chikungunya is also counted among the haemorrhagic fever diseases.\nChikungunya: causes and risk factors\nTwo points play a crucial role in the causes of Chikungunya disease. First, the Chikungunya virus itself as a pathogen, on the other hand its transmission to humans.\nThe CHIK virus belongs to the family of the so-called Togaviridae and the large genus of alphaviruses. Chikungunya is an RNA virus and was first described in 1952/53 during an outbreak in Tanzania. It\'s similar to the O\'nyong-nyong virus. Other typical togaviruses are, for example, the Ross River virus, the Eastern and Western Encephalitis virus or the rubella virus. The viruses spread through the lymph nodes and blood. However, how exactly the virus affects the human cells is still under investigation. Ingested there, the pathogen uses the cellular components to multiply. The Chikungunya virus is divided into three variants due to the smallest structural differences, one West African, one East Central South African and one Asian.It should therefore be able to adapt to new geographical circumstances.\nTransmission of the Chikungunya virus\nThe CHIK virus is transmitted almost exclusively by mosquitoes from person to person. Classic representatives are mosquitoes of the genus Aedes aegypti, Aedes albopictus, Aedes africanus, Aedes furcifer and Mansoniaspezies. But also mosquitoes of the Culex genus are possible transmitters. The virus spreads and multiplies after the sting in the human body. Repeated stings, the mosquito takes the Chikungunya virus again and transmits it to other people.\nThis cycle has also been observed in meerkats, baboons and rodents (jungle cycle). However, the animals are only intermediate carriers of the virus, which is also transmitted by mosquito bites ultimately from the animals to humans (bridge transfer). Special attention should be paid to the mosquito species Aedes albopictus. Known as the Asian tiger mosquito, it is currently spreading around the world and is responsible, among other things, for the transmissions in Italy. Also in Germany in 2007 their eggs, in 2011 finally living specimens were discovered.\nThis small (5mm), black-silver-white striped mosquito is very active. In addition, it transmits not only the Chikungunya, but also the West Nile, Yellow Fever and Dengue virus. Chikungunya was therefore observed simultaneously with dengue fever, especially in India and Southeast Asia. Other mosquito species can cause several diseases - for example Aedes aegypti yellow fever.\nPeople with high blood pressure, blood sugar disease or heart failure, older people over 65 years, and newborns have an increased risk that the Chikungunya virus causes a serious illness. Pregnancy is an equally dangerous risk factor because mothers can transmit the virus to their child.\nChikungunya: diagnosis and examination\nIf you suspect that you have Chikungunya, you should consult your family doctor or a specialist in tropical medicine. Since clear early symptoms are missing, the history of the medical history (anamnesis) is crucial. The doctor first asks for typical symptoms (and their course). In particular, information on recent trips is important. You may be asked the following questions:\n- Since when do the complaints exist?\n- When was the last time you were abroad?\n- Where did you go? How long was your stay in the travel destination?\n- Were you stung by mosquitoes?\n- Do you have fever? Or have you recently measured elevated body temperature?\n- Have your symptoms abated in the meantime and are now increasing again (as an indication of the possible biphasic Chikungunya course)?\n- Do you have (unbearable) joint pain or swelling?\nAfter the medical history, your doctor will examine you physically. Among other things, he can measure your body temperature and scan your lymph nodes. He will pay particular attention to the joints and assess any possible swelling or reddening of the skin.\nThere are several laboratory procedures to ensure the diagnosis Chikungunya. The doctor takes several blood samples. Nonspecific blood levels may be altered and generally indicate a physical illness. These include, for example, a reduction in white (lymphopenia) and red blood cells (anemia) and platelets (thrombocytopenia). In severe cases, for example, liver enzymes may also be elevated.\nFor safe detection, Chikungunya virus can either be isolated directly or its genetic material can be detected. In addition, infected blood is tested for specific antibodies against Chikungunya. The virus itself can be bred within the first three days in certain cultures. Specific proteins of the human immune system, so-called immunoglobulin (Ig) M antibodies, usually appear five to seven days after onset of disease and remain detectable for up to half a year. IgG antibodies can be determined approximately from the second week and months later. Through the so-called polymerase chain reaction (PCR) parts of the virus genome (viral RNA) can be duplicated and confirm the Chikungunya fever.\nDengue fever and other diseases\nIn the investigation on Chikungunya the doctor will exclude other diseases, especially other tropical diseases. These include leptospirosis, malaria, diseases caused by other alphaviruses (for example, O\'nyong-nyong, Ross river), rubella, enterovirus and parvovirus infections, as well as rheumatic diseases such as post-infectious arthritis. Due to similar symptoms, but a more severe disease, dengue fever should be considered. The following table compares chikungunya with dengue fever:\nduration of fever\nusually only a few days\nBleeding (hemorrhagic fever)\nalmost always and long lasting (sometimes months)\nrare and if, of significantly shorter duration\nIn addition, the laboratory values usually differ. While the white blood cells are usually reduced in Chikungunya, their number rarely changes in dengue. The reverse is true for the platelets. They are especially humiliated with dengue fever. If, during or after traveling, especially in high-risk areas, you have a medical condition, such as fever, headache, body aches, nausea and vomiting.\nThere is no treatment that directly combats and eliminates the Chikungunya virus. Therefore, only the symptoms of the disease can be treated and alleviated. It is crucial bed rest and adequate hydration, as the body loses much water, especially during the fever. Painkillers (analgesics) and fever (antipyretics) soften typical Chikungunya symptoms. For this purpose, especially non-steroidal anti-inflammatory drugs (anti-inflammatory drugs, NSAIDs) are suitable.\nIn case of persistent joint pain in addition to painkillers (locally applied) corticosteroids and physiotherapy can have a beneficial effect. In Dengue fever risk areas, acetaminophen (acetaminophen) is usually used to reduce the risk of bleeding. Acetylsalicylic acid (ASA), which disturbs the function of platelets, should therefore be avoided. In severe Chikungunya fever course, intensive care monitoring may be necessary. Even with other symptoms such as conjunctivitis, the treatment is expanded accordingly.\nA vaccine with inactivated chikungunya virus particles is currently being tested. A medical provision is not yet possible.\nChikungunya: disease course and prognosis\nThe Chikungunya virus can be different. In some cases, it does not trigger any symptoms. If it comes to Chikungunya fever, this usually heals without consequences within a few weeks. However, the joint complaints can sometimes last for months and occur at different joints. Especially in infants, the virus can also affect the liver or the nervous system. Although these severe illnesses are very rare, they represent a life-threatening situation. On average, about 4 out of 100 people die from chikungunya. In infants, the risk of dying from Chikungunya is slightly higher.\nThe Chikungunya virus can neither be treated nor vaccinated. Therefore, some measures should be followed to protect against mosquito bites that carry the virus. You should also avoid mosquitoes in the event of illness in the first week, as with renewed stitches, the virus is resumed and transmitted to your fellow human beings.\nUse insect repellent!\nParticularly effective are these so-called repellents with the active ingredients DEET, picaridine, IR3535 or plant-based lemon eucalyptus oil or products based on it, namely PMD / citriodiol.\nWear long pants and long-sleeved clothes!\nFor additional protection you can spray your clothes with permethrin.\nWatch out for mosquito nets, especially over the bed and windows!\nThis is especially true during sleep during the day, as the Chikungunya mosquitoes sting particularly aggressive at this time.\nAvoid and eliminate water points in your environment!\nHere mosquitoes multiply, which transmit Chikungunya. Empty buckets and buckets regularly or cover places where new mosquitoes can ripen. Avoid living in close proximity to ponds or similar waterholes. It may be necessary to use insecticides.\nDo not travel to risk areas if you have limited health or are pregnant!\nFor more information about high risk areas, visit the World Health Organization, the Federal Department of Foreign Affairs website and the European or American health authorities (ECDC, CDC).\nIn general, you should consult a doctor immediately if you have any general symptoms of illness (fever, nausea, vomiting, headache and body aches), especially during or after traveling to high-risk areas. Do not be afraid to visit the clinics of your travel destination if necessary (experienced by the regionally frequent occurrence of Chikungunya). In this way, a serious illness can be prevented in good time and a spread of Chikungunya be contained.']"	['<urn:uuid:533df545-1342-4e6a-9395-f80735591f61>', '<urn:uuid:b186da89-9834-492a-bf59-6c9b68eaab83>']	open-ended	with-premise	concise-and-natural	similar-to-document	comparison	expert	2025-05-13T05:52:58.810667	13	65	3710
75	Do both Hyde Park Circle and Piute Pass trails offer mountain views?	Yes, both trails offer mountain views. Hyde Park Circle Trail provides views of the Sangre de Cristo, Jemez, Sandia, San Pedro, and Ortiz mountains in most directions, while Piute Pass Trail offers views of Muriel Peak, Mount Emerson and Mount Humphreys in the Sierra Nevada Range.	"[""Piute Pass Trail is the most direct line to Humphreys Basin and surrounding peaks such as Muriel Peak, Mount Emerson and Mount Humphreys in the Sierra Nevada Range, California.\nNot quite as popular or scenic as the South Lake to Bishop Pass Trail, Piute Pass Trail to Humphreys Basin has its own fan base. The trail is generally low angle and easy to travel on. It passes by a number of lakes and meadows making it a desirable destination for anglers, pack horses and hikers. For those going deeper into the wilderness, this trail provides an easy access into the back country. During a summer weekend you have a great chance of running into dozens of groups traveling in both directions. These groups all pass over Paiute Pass and don't be surprised to see dozens of people on the pass resting and taking photographs.\nPiute Pass Trail generally hugs the southern flank of Mount Emerson and follows the northern banks of North Fork of Bishop Creek, Loch Leven and Piute Lake. The only peak making a prominent presence is an unnamed mountain to the southwest of Paiute Pass. This peak may not be very high, but its rugged and rocky eastern and northern slopes with a sharp summit make for a great view and ideal for photography. On a calm day with no waves, the reflection of this peak on the nearby lakes will be an awesome sight. During the late spring and early summer months, the wildflowers along this trail will overload your senses. Piute Pass Trail is about five miles long, one way, and gains only 2,150 feet. It's obvious that this trail is quite gentle and great for pack horses, a tradition to this trail for many decades.\nRoute map and description\nStart your hike at North Lake, elevation 9276. Head toward North Lake Campground on a dirt road. At the end of the dirt road there are bathroom facilities where the road turns into a trail. Shortly after the trailhead, the trail forks. The left one leads to Lamarck Lakes and Lamarck Col. The right fork goes straight and heads for Piute Pass. The trail crosses the creek on logs a few times, but it continues directly westward following the north fork of Bishop Creek. After nearly three miles you reach your first major landmark, Loch Leven, a lake at an elevation of 10,750 feet. This is a great place to photograph peak 12,707 and its reflection on the lake. Following the trail, you will pass by several green meadows and small lakes. These lakes are sections of the creek passing over low angle terrane. Looking up the valley, you get a distant view of Piute Pass.\nYour next objective is Piute Lake another mile up the trail. Piute Lake, at an elevation of nearly 11,000 feet, is scenic and a great place to rest. Climb up steps made of granite rocks with wildflowers on both sides.\nPiute Pass is clearly visible and less than a mile from here.\nNorth Lake to Piute Pass Trail\n|elevation||Distance from trailhead|\n|N 37.23050--------W 118.61890||9276||0|\n|N 37.23121-------- W 118.65311||10,750 ft||3 mile|\n|N 37.23504--------W118.67182||10,963 ft||4 miles|\n|N 37.23877--------W118.68433||11,460 ft||5 miles|\nHow to get there\nFrom the town of Bishop, along Highway 395 in California, take Highway 168 westbound toward the Sierras. After about 12 miles you will see a 3-way. The left fork takes you to South Lake. Go straight for another 7 miles to North Lake.\nNote: The road to North Lake turns to dirt just before reaching Lake Sabrina. This is a good dirt road, but be careful with the rocks and boulders that often fall from the steep hillsides.\nThere are bathroom facilities near the parking lot.\nNote: I have seen lots of bear activity in this area during the spring thaw. No bear boxes here.\nAdditions and Corrections[ Post an Addition or Correction ]"", ""Hyde Park Circle Trail\n|A trail with excellent views of the Sangre de Cristo, Jemez, Sandia, San Pedro, and Ortiz mountains (i.e., views in most all directions). This trail gains 855 ft (261 m) in the first 0.94 mi (1.5km). However, the climb is worth it for the views.|\n|Hike data||Waypoints||Maps||Getting to the trailhead||About the hike||Plants along the trail||Comments|\nWhen we hiked it:\n|Time it took us:||3:00.||3:00.|\n|Usage (people/hour):||2.67. Most of the people are on the trail behind the campground. I only saw two people on the ridge portion of the trail.||0.50. I saw nobody on the ridge. I could hear people in the park as well as the traffic on the road for much of the hike. The park gets heavy use due to its proximity to Santa Fe.|\n|HMPLP||Trailhead||Hyde Memorial State Park visitor center and trailhead for the loop trail|\n|HPLP2||Trail junction||Hyde Park Circle Trail crossing the campground road|\n|Map name||Cartographer||Year||Scale||Topo map?||Online access||Notes|\n|Guide to Indian Country of Arizona Colorado New Mexico Utah||Automobile Club of Southern California||1998||1:0||N||from Amazon (purchase)||Good overview road map for northwest NM. No scale is given on the map. The corner coordinates are approximate.|\n|McClure Reservoir||USGS||1976||1:24000||Y||from sar.lanl.gov (free)|\n|Pecos Wilderness, Santa Fe and Carson National Forests||US Forest Service||2004||1:54000||Y||from Amazon (purchase)|\n|Santa Fe||BLM||1996||1:100000||Y||from Amazon (purchase)|\n|Santa Fe||USGS||1954||1:250000||Y||from sar.lanl.gov (free)|\n|Santa Fe National Forest||US Forest Service||2004||1:126720||N||from Amazon (purchase)||East half|\n|Wildernesses of New Mexico||US Forest Service||1981||1:1000000||N||No online copies.||Base map with national forests, wilderness areas and highways.|\nSupport this site:By purchasing your hiking gear through these links, you will support this web site and it won't cost you anything more. Camping gear at Amazon Save 40% on Patagonia, The North Face, Mountain Hardwear, Marmot & More + Free Shipping over $75! Click to Save.\nGetting to the trailhead:\nFrom the Santa Fe plaza, head north on Washington Ave. Just past the pink Scottish Rite Temple (pictured here), turn right on Artist road; the sign says that Hyde State Park and the Santa Fe Ski Basin are this way.\nDrive seven miles to the Hyde Park Visitor's Center. Park in the visitor center parking lot and pay the park day use fee. The trailhead (shown here) is across the road from the visitor center.\nAbout the hike:\nYou start by crossing a bridge over the Little Tesuque Creek. You can barely see it in the trailhead photo above. While this trail's elevation is not large compared to many hikes we have done, the elevation gain happens in a much shorter distance. You get to start climbing as soon as you cross the creek, and you will be climbing almost non-stop for the first third of the hike. The initial part of the hike is in and out of shade, and as a result, the sun can be hot. Make sure that you take enough water on this hike. Here is an early view south, with some of the trail in it. As you are climbing, the trail at times has some level parts. Enjoy these---they are a welcome respite.\nAs you climb, you can see Black Canyon, where the campground is, however, you cannot see the campground itself. As you continue to climb, take regular stops to view the scenery; the views on this hike are great, and at one time or another, you get views off in all directions.\nThis view is to the SSE.\nWhen you have been hiking around 40 minutes or so, you reach a ridge line where you may get more breeze. I certainly appreciated the cooling air.\nThe trail is on granite and decomposed granite. Granite is made of feldspar, quartz, and mica. Sometimes you will see a bunch of only one of these minerals, or rocks which a preponderance of one. For example the rock in the picture has a lot of mica in it.\nAnother reason to look for the micaceous rocks is that they indicate that you are nearing the top.\nWhen we first hiked this trail, New Mexico had been in a serious drought for a while. As a result, there were few wildflowers. However, this Scarlet Gilia (also known as a Scarlet Skyrocket) was making a go at it.\nWhen you start getting views off to the southwest (Santa Fe, the San Pedro Mountains, the Sandia Mountains) and west (Jemez mountains), you can be happy for many reasons. One is for the views. Another is because you are nearly at the top of the hike.\nThis view is to the WNW, and you can see the Jemez in the distance.\nWhen you start to see trees down all around you from winter damage, you have reached the end of the big climb. Take a break, smell the forest, and drink some water.\nI shared the trail with this granite-colored horned lizard. He or she was gracious enough to allow me to take this photo.\nEnjoy the views of the Sangre de Cristo mountains.\nWhen the trail heads down, this is not really the beginning of the trek down.\nRight after a short climb, you reach a pair of picnic tables. These always strike me as odd, because normally I expect tables to be near a road. I wonder how they got up here. They make a nice rest before heading downhill.\nFrom the picnic tables, the trail used to have two branches. You could go past the picnic tables, or start down here. If you have older guidebooks, they will mention this. I took this older branch the first time.\nThe park has changed the trail; you should take the trail that goes down. They indicate it with tree trunks on either side of the trail.\nWhen I took this photo, I was standing near the second picnic table.\nThe forest is different on the way down. You are walking through more shade.\nThe second time we hiked this trail, the Oregon Grape were getting ripe. The turning leaves and ripening berries indicated that autumn was on its way.\nThe trail heads down, steeply at times (hiking poles may be useful). You also go around several switchbacks (such as this one). Please do not cut across the area between the switchbacks; doing so is even steeper, and it can cause erosion problems on the trail.\nWhen you get near the bottom of the hill, you will reach a junction. This is the Girl Scout Joe M. Clark memorial nature trail. The two paths will both take you to the trailhead for the nature trail. I took the lower branch. You will know you are on this trail when the trail is rock-edged.\nWhen you reach the trailhead for the nature trail, you have several options. You could walk along the highway back to the trailhead. However, a better choice is to cross the highway, and go uphill just past the ice skating pond. You will find this bridge. Cross it, and on the other side, go up and to the left.\nWhen the trail gets to the gravel road, you should see this trailhead across the road (GPS: HPLP2. This trail is one of several that runs behind the campgrounds. All should eventually take you to the visitor center.\nA ranger warned me that this trail goes through a couple of campsites. If you continue in the direction you were heading, you will find the trail picks up again. This was good advice, as I would have been quite confused had he not mentioned it. You go right through campsites 17 and 15. The trail takes up again on the other side of the road, on the right side of site 15.\nAlso, one time I obviously made a wrong turn and the trail I was on died out. I headed downhill and found the real trail again.\nPlants we saw along the trail:\nReader comments about this hike:\nAdd your comments about the Hyde Park Circle Trail hike.\nCopyright © 1997-2016 Kenneth Ingham Consulting, LLC.\nFor details about the copyright, see the full Copyright statement.\nUnhappy? Thinking of suing us? Read this disclaimer.\nYou can read our privacy statement.""]"	['<urn:uuid:7275611d-67f0-4540-8d10-4027800df1f8>', '<urn:uuid:01b1153b-67f9-4c40-91d5-b7a08c9f4fed>']	factoid	direct	concise-and-natural	distant-from-document	comparison	expert	2025-05-13T05:52:58.810667	12	46	1988
76	what is rna splicing exons introns function	RNA splicing is a process where introns (intervening sequences that don't code for proteins) are removed from pre-mRNA and exons (expressing sequences) are joined together. Exons can contain both coding sequences for amino acids and untranslated sequences, while introns are removed during RNA processing. This process is essential for gene expression and is carried out by a complex called the spliceosome. Through alternative splicing, different combinations of exons can be joined together, allowing multiple proteins to be produced from a single gene. The untranslated regions in exons are important for efficient translation and controlling the rate and half-life of the transcript.	"['From Wikipedia, the free encyclopedia - View original article\nAn exon is any nucleotide sequence encoded by a gene that remains present within the final mature RNA product of that gene after introns have been removed by RNA splicing. The term exon refers to both the DNA sequence within a gene and to the corresponding sequence in RNA transcripts. In RNA splicing, introns are removed and exons are covalently joined to one another as part of generating the mature messenger RNA.\nThe term exon derives from the expressed region and was coined by American biochemist Walter Gilbert in 1978: ""The notion of the cistron… must be replaced by that of a transcription unit containing regions which will be lost from the mature messenger – which I suggest we call introns (for intragenic regions) – alternating with regions which will be expressed – exons.""\nThis definition was originally made for protein-coding transcripts that are spliced before being translated. The term later came to include sequences removed from rRNA and tRNA, and it also was used later for RNA molecules originating from different parts of the genome that are then ligated by trans-splicing.\nIn many genes, each of the exons contain part of the open reading frame (ORF) that codes for a specific portion of the complete protein. However, the term exon is often misused to refer only to coding sequences for the final protein. This is incorrect, since many noncoding exons are known in human genes.\nTo the right is a diagram of a heterogeneous nuclear RNA (hnRNA), which is an unedited mRNA transcript, or pre-mRNAs. Exons can include both sequences that code for amino acids (red) and untranslated sequences (grey). Stretches of unused sequence called introns (blue) are removed, and the exons are joined together to form the final functional mRNA. The notation 5\' and 3\' refer to the direction of the DNA template in the chromosome and is used to distinguish between the two untranslated regions (grey).\nSome of the exons will be wholly or part of the 5\' untranslated region (5\' UTR) or the 3\' untranslated region (3\' UTR) of each transcript. The untranslated regions are important for efficient translation of the transcript and for controlling the rate of translation and half-life of the transcript. Furthermore, transcripts made from the same gene may not have the same exon structure, since parts of the mRNA could be removed by the process of alternative splicing. Some mRNA transcripts have exons with no ORFs and, thus, are sometimes referred to as non-coding RNA.\nPolycistronic messages have multiple ORFs in one transcript and also have small regions of untranslated sequence between each ORF.\nExon trapping or \'gene trapping\' is a molecular biology technique that exploits the existence of the intron-exon splicing to find new genes. The first exon of a \'trapped\' gene splices into the exon that is contained in the insertional DNA. This new exon contains the ORF for a reporter gene that can now be expressed using the enhancers that control the target gene. A scientist knows that a new gene has been trapped when the reporter gene is expressed.\nSplicing can be experimentally modified so that targeted exons are excluded from mature mRNA transcripts by blocking the access of splice-directing small nuclear ribonucleoprotein particles (snRNPs) to pre-mRNA using Morpholino antisense oligos. This has become a standard technique in developmental biology. Morpholino oligos can also be targeted to prevent molecules that regulate splicing (e.g. splice enhancers, splice suppressors) from binding to pre-mRNA, altering patterns of splicing.\n|Look up exon in Wiktionary, the free dictionary.|', '- Explain the role of RNA splicing in regulating gene expression\nRNA splicing, the first stage of post-transcriptional control\nGene expression is the process that transfers genetic information from a gene made of DNA to a functional gene product made of RNA or protein. Genetic Information flows from DNA to RNA by the process of transcription and then from RNA to protein by the process of translation. In order to ensure that the proper products are produced, gene expression is regulated at many different stages during and in between transcription and translation. In eukaryotes, the gene contains extra sequences that do not code for protein. In these organisms, transcription of DNA produces pre-mRNA. These pre-mRNA transcripts often contain regions, called introns, that are intervening sequences which must be removed prior to translation by the process of splicing. The regions of RNA that code for protein are called exons. Splicing can be regulated so that different mRNAs can contain or lack exons, in a process called alternative splicing. Alternative splicing allows more than one protein to be produced from a gene and is an important regulatory step in determining which functional proteins are produced from gene expression. Thus, splicing is the first stage of post-transcriptional control.\nAlternative splicing is a process that occurs during gene expression and allows for the production of multiple proteins (protein isoforms) from a single gene coding. Alternative splicing can occur due to the different ways in which an exon can be excluded from or included in the messenger RNA. It can also occur if portions on an exon are excluded/included or if there is an inclusion of introns. For example, if a pre-mRNA has four exons (A, B, C, and D), these can be spliced and translated in a number of different combinations. Exons A, B, and C can be translated together or Exons A, C, and D can be translated. This results in what is called alternative splicing. The pattern of splicing and production of alternatively-spliced messenger RNA is controlled by the binding of regulatory proteins (trans-acting proteins that contain the genes) to cis-acting sites that are found on the pre-RNA. Some of these regulatory proteins include splicing activators (proteins that promote certain splicing sites) and splicing repressors (proteins that reduce the use of certain sites). Some common splicing repressors include: heterogeneous nuclear ribonucleoprotein (hnRNP) and polypyrimidine tract binding protein (PTB). Proteins that are translated from alternatively-spliced messenger RNAs differ in the sequence of their amino acids which results in altered function of the protein. This is one reason why the human genome can encode a wide diversity of proteins. Alternative splicing is a common process that occurs in eukaryotes; most of the multi-exonic genes in humans are spliced alternatively. Unfortunately, abnormal variations in splicing are also the reason why there are many genetic diseases and disorders.\nThe splicing of messenger RNA is accomplished and catalyzed by a macro-molecule complex known as the spliceosome. The areas for ligation and cleavage are determined by the many sub-units of the spliceosome which include the branch site (A) and the 5′ and 3′ splice sites. Interactions between these sub-units and the small nuclear ribonucleoproteins (snRNP) found in the spliceosome create a spliceosome A complex which helps determine which introns to leave out and which exons to keep and bind together. Once the introns are cleaved and removed, the exons are joined together by a phosphodiester bond.\nAs noted above, splicing is regulated by repressor proteins and activator proteins, which are are also known as trans-acting proteins. Equally as important are the silencers and enhancers that are found on the messenger RNAs, also known as cis-acting sites. These regulatory functions work together in order to create splicing code that determines alternative splicing.\n- Introns are intervening sequences within a pre-mRNA molecule that do not code for proteins and are removed during RNA processing by a spliceosome.\n- Exons are expressing sequences within a pre-mRNA molecule that are spliced together once introns are removed to form mature mRNA molecules that are translated into proteins.\n- Alternative splicing allows for the production of various protein isoforms from one single gene coding.\n- A spliceosome is a complex comprised of both RNA molecules and proteins which determine which introns to leave out and which exons to keep and bind together.\n- intron: a portion of a split gene that is included in pre-RNA transcripts but is removed during RNA processing and rapidly degraded\n- exon: a region of a transcribed gene present in the final functional RNA molecule\n- spliceosome: a dynamic complex of RNA and protein subunits that removes introns from precursor mRNA']"	['<urn:uuid:54ff622d-dbe2-4424-bbd7-82381222ecfb>', '<urn:uuid:2a572f0a-41c8-4a1a-8585-e0d55dd5adff>']	open-ended	direct	short-search-query	similar-to-document	three-doc	novice	2025-05-13T05:52:58.810667	7	101	1366
77	how does dual factor protect against cyber attacks methods benefits	Two-factor authentication adds an extra security layer by requiring users to provide two different validation factors, making it harder for hackers to access accounts even if passwords are compromised through database theft or phishing. Using physical devices like key fobs or smart cards, or software applications that generate one-time PIN codes, 2FA ensures users can only access authorized resources. The system verifies both the user's credentials and links them with the organization's authentication data, while solutions like Fidelis Network provide real-time monitoring to detect suspicious activities and prevent data theft through deep content inspection.	['OneIdentity Syslog-Store Box – Centralized log collection and management solution\nThe syslog-ng Store Box™ (SSB) is a high-performance, high-reliability log management appliance that builds on the strengths of syslog-ng Premium Edition. With SSB, you can search logs, secure sensitive information with granular access policies, generate reports to demonstrate compliance and forward log data to third-party analysis tools. By leverage on syslog-ng log processing and filtering features you can improves the performance of your SIEM solution by reducing the amount and improving the quality of data feeding your SIEM.\nsyslog-ng Store Box™ (SSB) Key features:\n-Collect and index\n-Search and report\n-Store and forward\n-Secure log data\nFidelis Cybersecurity: Threat Detection & Response Solutions\nIdentifying threats and data leakage requires deep inspection and analysis of all forms of content, including unpacking and extracting deeply embedded files. Fidelis Network bi-directionally scans all network traffic, regardless of port or protocol, to reveal the network and application protocols, files, and content.\nBy conducting real-time network analysis and identifying behaviors that indicate compromises, Fidelis Network provides automated detection for the proactive discovery of attackers, suspicious hosts, and malware.\nIncluding multiple sensors that can be placed throughout your network to enforce prevention policies. These sensors can be placed inline or out-of-band based on your network configuration and prevention tolerance.\nFidelis Network detects and prevents data theft by utilizing our industry-best content decoding and inspection engine. Get ultimate visibility of exfiltration attempts and keep your sensitive data safe.\nFidelis Endpoint provides visibility into all endpoint activity including process actions, logged in users, registry writes, file system activity, and memory. Detect threats by applying Fidelis Insight threat intelligence, custom alert rules, YARA and OpenIOC formats to analyze, alert, and collect system events. Fidelis visibility is always on, whether the endpoint is on-network or off.\nAutomatically respond to any detection by executing tasks either shipped with the system or customized for your environment. Response tasks include endpoint isolation, creating and using restore points, process termination and file wiping. You can also jumpstart investigations including memory analysis, vulnerability scans, and system inventory. Integrate with Fidelis Elevate to execute response actions to threats detected in the network.\nFidelis Endpoint can be enhanced with Fidelis AV so you can see exactly where threats originate. Fidelis AV provides both traditional signature and heuristic-based detection and prevention of threats on the endpoint. Process scanning allows users to block execution of processes by hash or with easily created YARA rules.\nClassify all network assets, communication paths, and network activity to profile your users, services, and assets. The result is a network profile that includes all assets including servers, workstations, enterprise IoT devices, and shadow-IT. The profile is continuously adapted as changes occur within your environment.\nFrom automated discovery of an environment, accurate information is utilized to auto-generate decoys for deception layers. Decoys have profiles, services and activity matching the environment, plus recommended breadcrumbs for placement on nearby real assets to act as lures to decoys. Configuration options are available to customize the deception layer.\nLearn what attackers do once inside your network after compromising a foothold system often from phishing or social engineering attacks. Attractive breadcrumbs placed on real assets are quickly found by attackers to lure them to decoys, interactive services and fake data. Divert attacks from real resources and data to quickly detect and defend against post-breach attacks.\nDeception defenses provide a proactive opportunity to lure, detect and defend early within post-breach compromise incidents with no risk to resources or data, or impact to users and operations. Alerts come from deception layers unknown to users and partners resulting in high fidelity with no false positives. The result is a low friction, low risk accurate alarm system to detect post-breach attacks.\nPrivX – PAM with Zero-password security\nCertificate Base PrivX Privileged Access management\nSSH PrivX is a Browser-based PAM solution. No software on target servers. No agents. No software on desktops. No passwords. No rotation. No vaults.\nStatic credentials are no longer stored on machines, in a central vault, or anywhere. Credentials are now instantly provisioned on-demand, according to company policy, and only valid as long as needed.\nNo static credentials means no rotating, managing, or vaulting (PAM) of credentials is required. These credentials are important, but also the bottleneck to cloud efficiency and a persistent vulnerability.\nYubico: 2FA token that is more than just OTP\nThe YubiKey is a strong two-factor authentication for compliance with GDPR, PSD2, DFARS, and FIPS. Unphishable secure multi-factor authentication, protect your organization from costly security breaches with unphishable security that eliminates account takeovers. The YubiKey is the trusted secure authentication choice for the largest technology, finance, and retail companies in the world.\nRCDevs – Enterprise MFA Security Solution\nThe RCDevs main product Two-Factor: OpenOTP™ stands for a very powerful Multi-Factor authentication solution providing secure and reliable authentication of remote users to online services, Cloud, VPNs, Citrix, RDP, SSH, Intranet and much more.\nMain Feature to look at:\nAll-in-one security solution with Two-Factor, SSO, IAM, PKI\nNo SaaS / Cloud and no connection to any external services\nDevice independent with supports for open security standards\nIntegrations for VPNs, Microsoft, Linux, Web, Cloud\nIntegrates seamless with Enterprise directories and multiple LDAP\nAdvanced redundancy and HA with active-active clusters\nScalable from hundreds to millions of users\nAutomated user / device provisioning with self-services\nComplies with highest security standards (PCI-DSS, HIPAA)\nKnowBe4 – Security Awareness Training solution\nKnowBe4 is a security awareness training and phishing platform to enhance an organization’s cyber security by training your employees to be last line of defense. It is designed to mitigate the ongoing problem of social engineering threats by going through a cyclical process of training the users, phishing them and seeing the results. Users can be easily included by syncing with your current Active directory. With legitimate looking phishing email templates to phish your users available with logos, difficulty levels can be adjusted to suit your users’ knowledge on phishing. Educating your users using training modules are readily available, covering a wide range of topics. These can all be easily done with the simple and user friendly Graphical User Interface. Tracking of the organization’s and individual’s progress can be carried out with just a few clicks.\nWebArgus – Web defacement detection and recovery solution\nWebArgus is a web defacement detection and recovery system. Contrary to other similar web defacement products in the market, WebArgus provides 24/7 monitoring, instant recovery and is able to defend against zero day attacks targeting monitored files and directories.\nWebArgus is designed with low overhead in mind, and is coupled with a simple and easy to use user interface, which is easy to configure.\nWith WebArgus, engineers need not take down the website to remove the defaced materials, and can now focus on defensive measures against future attacks.', 'Are you curious about two-factor authentication and multi-factor authentication definition? So, What is two-factor authentication and for what reason is it utilised? The Two-factor authentication definition sometimes alluded to as two-step authentication or double factor validation, is a security interaction wherein clients give two unique validation factors to check themselves.\n2FA is carried out to more readily ensure both a client’s qualifications and the assets the client can get to. Two-factor authentication is much more secure than the traditional method of single-step verification, also known as SFA. The client provides just one factor, commonly, a password or password.\nTwo-factor validation adds an extra layer of safety to the confirmation interaction by making it harder for hackers to access an individual’s gadgets or online accounts. Regardless of the casualty’s password, it is hacked. Two-factor validation has been utilised to control admittance to delicate frameworks and information for some time. Online specialist co-ops are increasingly using 2FA to shield their clients’ certifications from being employed by programmers who took a password data set or utilised phishing efforts to obtain client passwords.\nEnabling two-factor authentication differs depending on the particular application or seller. Nonetheless, two-factor authentication processes involve a similar general, multistep process:\nThere are means by which two-way authentication can be implemented, such as tokens, RFID cards and even cell phone applications are also available. You can separate Two-factor confirmation items into two classifications:\nValidation tokens might be actual gadgets, like key coxcombs or smart cards, or they might exist in programming as portable or work area applications that produce PIN codes for confirmation.\nThese confirmation codes, otherwise called one-time passwords (OTPs), are usually produced by a server and can be perceived as valid by an authentication gadget or application. The authentication code is a short succession linked to a specific device, client or account and can be utilised just a single time as a feature of a confirmation cycle. Associations need to convey a framework to acknowledge, process and permit or deny admittance to clients authenticating with their tokens. This might be sent in server programming or a committed equipment server, just as assistance by an outsider seller.\nA significant part of 2FA is ensuring the validated client is given admittance to all assets the client is supported for and just those assets. Accordingly, one critical capacity of 2FA is linking the authentication framework with an association’s confirmation information. Microsoft gives a portion of the infrastructure necessary for associations to help 2FA in Windows 10 through Windows Hello, which can work with Microsoft accounts, validating clients through Microsoft Active Directory, Azure AD or Fast IDentity Online (FIDO).\nEquipment tokens for 2FA are accessible, supporting various ways to deal with validation. One well-known equipment token is the YubiKey, a little Universal Serial Bus (USB) gadget that upholds OTPs, public-key encryption and confirmation, and the Universal Second Factor convention created by the FIDO Alliance. YubiKey tokens are sold by Yubico Inc., situated in Palo Alto, Calif. At the point when clients with a YubiKey log in to online help that upholds OTPs, like Gmail, GitHub or WordPress, they insert their YubiKey into the USB port of their gadget, enter their password, click in the YubiKey field and contact the YubiKey button. The YubiKey produces an OTP and enters it into the area.\nThe OTP is a 44-character, single-use password; the initial 12 characters are a unique ID that addresses the security key enlisted with the account. The remaining 32 characters contain encoded information using a key known uniquely to the gadget and Yubico’s servers, set up during initial enrollment. The OTP is sent from the online help to Yubico for validation checking. When the OTP is approved, the Yubico authentication server sends back a message confirming this is the correct token for this client. 2FA is finished. The client has given two confirmation factors: The password is the information factor, and the YubiKey is the belonging factor.\nFortnite 2fa is significant, with the Fortnite two-factor authentication framework adding layers among you and programmers. It resembles a lock on the entryway where you keep all your in-game stuff, and assuming you’ve been playing some time – unlocking prizes and buying skins – you would instead not make it simple for criminals to take your account.\nThe entire two-factor confirmation bit in Fortnite 2fa means it adds two phases to you logging in. A password and code are utilised instead of a single password getting you straight into the game, which could be speculated, hacked, or turned up in an information break. When you initially sign in, the game sends you a code to enter too. Without the code, the password is futile, protecting your account from any danger as you pick where the code is sent, blocking out irregular logins.\nThis is all there is to know about two-factor authentication or 2fa. All the essential knowledge about 2-factor authentication has been provided above for your better understanding.']	['<urn:uuid:8abda88d-7208-4460-97ac-017825993a51>', '<urn:uuid:3b94e387-6353-45b3-8d50-2c50b4bf710d>']	factoid	direct	long-search-query	distant-from-document	multi-aspect	novice	2025-05-13T05:52:58.810667	10	94	1950
78	Working in land-use planning, I notice Minnesota and global approaches differ in addressing water resource management - how do Minnesota's One Watershed, One Plan program goals compare to the three main goals of international land-use planning?	Minnesota's One Watershed, One Plan (1W1P) program focuses on developing prioritized, targeted, and measurable implementation plans at the watershed scale, while international land-use planning is guided by three main goals: efficiency (matching land use with greatest benefit at least cost), equity (reducing inequalities in income, food security, and housing), and sustainability (meeting present needs while conserving resources for future generations). While both approaches aim for effective resource management, the international framework takes a broader socioeconomic perspective compared to Minnesota's more watershed-focused approach.	"['Land and water resources are essential for farming, grazing, forestry, wildlife, tourism, urban development, transport infrastructure, and other environmental functions. The increasing demand for land, coupled with a limitation in its supplies, is a major cause for more conflicts over land use throughout the world.\nThe Watershed Perspective\nEach type of land use has a varying effect on the hydrologic cycle , thereby affecting the people and the natural resources on a landscape. A watershed perspective can be used to scientifically study the effect of land uses on water and downstream ecosystems . A watershed is defined as a topographically delineated area drained by a stream system; that is, the total land area above some point on a stream or river that drains past that point.\nA watershed acts as a receiver, collector, and conveyer of precipitation on a landscape. Land uses affect these pathways by altering surface runoff and groundwater infiltration, thereby changing the quantity and quality of water resources.\nImpacts and Benefits of Land Uses\nNatural vegetation, such as forest cover, is usually the most benign of land uses, with higher infiltration and reduced runoff rates. The opposites of forest cover are urbanized areas, where large surface areas are impermeable, and pipes and sewer networks augment the natural channels. The impervious surfaces in urban areas reduce infiltration and can reduce the recharge of groundwater. In addition, urban runoff contributes to poor water quality.\nAgricultural activities are major forms of land use, including row crops, rangelands, animal farms, aquaculture , and other agribusiness activities. Cropping activities involve soil and water manipulation through tillage and irrigation , thereby affecting runoff water and groundwater resources. If improperly used, fertilizer and plant protection chemicals in agricultural operations can affect water resources and ecosystems.\nUrban and agricultural land uses contribute to what is termed nonpointsource pollution in watersheds. Nonpoint-source pollution is defined as diffuse (spread-out) sources of contamination from a wide area of a landscape, often difficult to be attributed to a single location. Transportation infrastructure (e.g., roads and airports) is another type of land use that affects water resources through road runoff and alterations to components of the hydrologic cycle.\nDespite land-use impacts, land is required to support human and ecosystem needs. Urban areas promote economic growth and satisfy housing, industrial, and commercial needs of growing human populations. Agricultural land is critical to provide food and fiber to growing populations, and is an important source of employment in many countries. Forest areas provide raw materials for housing and the lumber industry, and are important habitats for wildlife. Wetlands and waterbodies cover land and are important in sustaining aquatic habitat and water supplies. Coastal fisheries, which are influenced by land-based activities, provide commercial and recreational opportunities. Thus, the basic needs of food, water, fuel, clothing, and shelter are met from the land, which increasingly is becoming limited in supply.\nWhat Is Land-Use Planning?\nAs population and human aspirations increase, land becomes an increasingly scarce resource, calling for land-use planning. Land-use planning is important to mitigate the negative effects of land use and to enhance the efficient use of resources with minimal impact on future generations.\nLand-use planning is defined as a systematic assessment of land and water potential, alternatives for land use, and the economic and social conditions\nThe planning process is iterative (cyclically repetitive) and continuous, and three goals are used to develop a plan: efficiency, equity, and sustainability. Efficiency in land use is achieved by matching different land use with areas that will yield the greatest benefit at the least cost. Equity in land use focuses on reducing inequalities in income, food security, and housing. Sustainable land use meets the needs of the present while conserving resources for future generations.\nLand-use planning aims at achieving a balance among these goals through the use of information on trade-offs, appropriate technology, and consensus-based decision-making. Effective land-use planning often involves local communities, scientific information on land resources, appropriate technologies, and integrated evaluation of resource use.\nLevels and Process.\nPlanning can be at various levels: local, town, district, state, regional, national, and international. A two-way link between these levels is important for successful planning. A ""bottom-up"" type of planning starts at the local level and links to the next higher level with active local participation. Local acceptability of the plan is a critical element of a successful plan.\nA typical planning process involves the following steps:\n- Establishing goals and a baseline;\n- Inventorying and organizing resources;\n- Analyzing problems;\n- Establishing priorities and alternatives;\n- Checking for land suitability;\n- Evaluating alternatives and choosing the best option;\n- Developing a land-use plan;\n- Consulting and implementing the plan; and\n- Revising the plan.\nIt is important that local people and stakeholders be involved in all steps of the planning process to make it a successful plan. This will also ensure local acceptability and effective use of local information.\nThe Future of Land-Use Planning\nNew ways of effective land-use planning include information management through GIS (geographic information systems), computer simulation, and spatial-temporal data modeling on present land use, alternative scenarios, and assessment of consequences. While zoning and regulation are the primary methods adopted by land-use planners, public education often is a neglected area that is increasingly being recognized. Other methods that planners use include economic incentives, institutional reform, and investment through multiagency cooperative projects.\nLand-use planning is becoming complex and multidisciplinary as planners face multiple problems that need to be addressed within a single planning framework. Such problems include nonpoint-source pollution, water allocation, urbanization, ecosystem deterioration, global warming, poverty and unemployment, deforestation, desertification, farmland deterioration, and low economic growth. Watershed-scale planning is gaining popularity among communities and agencies so that biological, physical, and socioeconomic components of the landscape system can be integrated into the planning framework.\nSEE ALSO C HEMICALS FROM A GRICULTURE ; F LOODPLAIN M ANAGEMENT ; F OOD S ECURITY ; G EOSPATIAL T ECHNOLOGIES ; L AND U SE AND W ATER Q UALITY ; P LANNING AND M ANAGEMENT , W ATER R ESOURCES ; P OLLUTION S OURCES : P OINT AND N ONPOINT ; P UBLIC P ARTICIPATION ; W ASTEWATER T REATMENT AND M ANAGEMENT ; W ETLANDS .\nBrooks, Kenneth et al. Hydrology and Management of Watersheds. Ames: Iowa State University Press, 1997.\nFood and Agriculture Organization. Guidelines for Land-Use Planning. FAO Development Series 1. Rome, Italy: Food and Agriculture Organization, 1993.\nLoganathan, D., D. Kibler, and T. Grizzard. ""Urban Stormwater Management."" In Water Resources Handbook, ed. Larry W. Mays. New York: McGraw-Hill, 1996.\nMakepeace, D. K., D. W. Smith, and S. J. Stanley. ""Urban Stormwater Quality: Summary of Contaminant Data."" Critical Reviews in Environmental Science and Technology 25 (1995):93–129.\nGIS AND NATURAL RESOURCE MANAGEMENT\nGeographic information systems (GIS) technology is an information system designed to work with data referenced by spatial or geographic coordinates. GIS technology is capable of assembling, storing, manipulating, and displaying spatially and geographically referenced information (e.g., data identified according to its location). Users also regard the total GIS as including operating personnel and the data that go into the system, as well as a set of operations for analyzing such data.\nGIS is an important aspect for helping government and commercial organizations manage natural resources more efficiently. GIS helps the water resource professional evaluate arrays or ""layers"" of information, and hence provides a tool for conducting tasks ranging from watershed planning to assessments of global climate change.', ""Water planning within Minnesota and nationwide has been evolving to emphasize integrated water resources management at a watershed scale to solve soil and water resource issues. Issues related to water planning are wide-ranging and vary between watersheds, including urban stormwater management, agricultural water quality, subsurface sewage treatment, land use practices, plant community management, construction practices and climate change impacts.\nMany types of water planning have been conducted in Minnesota at different levels of government, including watershed district management plans and watershed management organization plans, counties, and other local and regional partners.\nPlanning Methods and Programs\nOne Watershed, One Plan\nOne Watershed, One Plan (1W1P) is a BWSR program that supports partnerships of local governments in developing prioritized, targeted, and measurable implementation plans. Key principles are planning at the major watershed scale and aligning local plans with state strategies. Plans created through the 1W1P program are called comprehensive watershed management plans and are described in §103B.801.\nCounty Comprehensive Local Water Management Planning:\nCounties with their planning and land-use authorities, are uniquely positioned to link many land-use decisions with local goals for surface and groundwater protection and management. Through the Comprehensive Local Water Management Act, counties are encouraged to make this link through the development and implementation of comprehensive local water management plans (county water plans). BWSR's role in local planning is to ensure that county water plans are prepared and coordinated with existing local, and state efforts; and that plans are implemented effectively. BWSR fulfills this role through Board review and approval of the plans while BWSR staff provide overall program guidance, process related grants, and provide plan review and comments. All parts of Minnesota have state-approved and locally-adopted county water plans in place. However, water management in Minnesota has been evolving towards watershed-based, rather than jurisdictionally-based water plans (i.e., One Watershed, One Plan (pdf)).\nThe Nonpoint Priority Funding Plan (NPFP):\nIn 2013, the Minnesota Legislature passed a law requiring the Board of Water and Soil Resources (BWSR) to prepare and post on its website a Nonpoint Priority Funding Plan (pdf) to prioritize potential nonpoint restoration and protection actions based on available Watershed Restoration and Protection Strategies (WRAPS), Total Maximum Daily Load (TMDL) plans and local water plans. The Nonpoint Priority Funding Plan is a criteria-based, systematic process to prioritize Clean Water Fund (CWF) nonpoint implementation investments.\nMinimal Impact Design Standards (MIDS):\nState agencies are focusing on using low impact design, and volume control best management practices (BMPs) to address issues related to large storm events. Impervious surfaces are increasing faster than population growth. This increase in impervious surface coupled with larger storm events will have a significant impact on receiving waters. Minimal Impact Design Standards (MIDS) are being used to increase infiltration and reduce runoff (including green infrastructure like rain gardens, urban forestry/trees, pervious pavement, swales, etc.). These practices are now focusing on volume control in addition to pollutant and rate control. Volume control, and working to mimic natural hydrology helps to result in less dramatic runoff events, which reduces stream erosion and scouring.\nMinnesota Hydrogeology Atlas:\nThe Minnesota Department of Natural Resources (MN DNR), Ecological and Water Resources Division’s Minnesota Hydrogeology Atlas (MHA) is a series of statewide, county, and regional maps and reports that can be used by government agencies in planning efforts to protect and preserve groundwater, to provide information for water appropriations permitting, for source water protection and well sealing programs, and for emergency response to contaminant releases. The MHA expands, compiles, and updates data developed by the County Geologic Atlas Program (CGA) providing more accessibility to information such as regional water pollution sensitivity to bedrock surface and near-surface materials, depth to water table, and water table elevation. The MHA includes a user’s guide, and lists training contacts and funding sources. Numerous links present users with a variety of state and national resources to assist in planning efforts including the DNR’s Watershed Health Assessment Framework, the USDA Web Soil Survey, and the Minnesota Geospatial Commons.\nMinnesota State Hazard Mitigation Plan:\nThe State Hazard Mitigation Plan, updated in 2019 by the Minnesota Division of Public Safety Department of Homeland Security and Emergency Management (HSEM), provides unified guidance to reduce and/or prevent injury and ensure coordination of recovery-related hazard mitigation efforts following major hazard events. The State’s 20 major hazards are identified, including flooding, drought, and ground and surface water supply contamination as they relate to geographic and demographic characteristics, development trends, and climate change. Local governments can use the county by county assessment of mitigation goals, strategies, actions, and initiatives to develop and update their plans. The plan provides information and resources on ranking and criteria for hazard identification, and determining steps to declare an emergency. Resources include a listing of agencies and organizations that may assist with mitigation efforts, and an inventory and brief descriptions of funding programs including the Hazard Mitigation Grant Program. Hazard mitigation success stories are also listed.\n1) Sustainable Regional and Urban Planning. Urban and regional planning that considers protection of natural areas, development of green infrastructure, and minimization of impervious areas during development and re-development can help to treat both water quality and quantity though a variety of practices.\n2) Protecting and Restoring Natural Areas. Protecting and restoring diverse natural habitats provides multiple benefits including water quality protection for groundwater and surface water, stable plant composition to resist invasive species, protect pollinator populations, preserved and improved wildlife habitat, and resiliency to weather extremes. For water planning it is recommended to identify high priority natural habitats including wildlife and water quality complexes and corridors, and promote a combination of agricultural BMPs, buffer programs, conservation plantings, wetland projects and riparian activities that will protect, restore and link water quality and habitat corridors. Minnesota’s Wildlife Action Plan and Prairie Conservation Plan are resources that can be used to aid planning efforts.\n3) Riparian Management. Protecting and restoring riparian areas, including adjacent floodplains brings multiple benefits by reducing soil erosion, increasing stream channel stability, decreasing phosphorus and nitrogen loading, flood attenuation, improving wildlife habitat and wetland functions. Water plans should identify high priority areas for riparian buffer easements, riparian erosion and sediment reduction, wetland restoration and other water storage and nutrient treatment opportunities, and target implementation efforts in those areas.\n4) Treating Water Close to Where it Falls. Higher amounts of rainfall from storm events in recent years increases the need to capture precipitation as close to where it falls as possible; prior to flowing into streams, lakes, and rivers and contributing to erosion and flooding. Stormwater runoff also transports high concentrations of pollutants into water bodies, causing impairment. To reduce these impacts, best management practice methods like cover crops, detention basins, vegetated swales, catch basins, infiltration basins, infiltration trenches, bioretention cells, grass swales, buffer strips, green roofs, etc. can improve water quality.\n5) Using Water Treatment Trains in Agricultural Landscapes. In agricultural landscapes it is beneficial to implement combinations of best management practices that promote soil health and the ability of soils to capture and store rainfall, and store carbon. Examples of key practices for agricultural areas include perennial crops, conservation tillage, conservation drainage, cover crops, buffer strips, and wetland restoration to manage water resources. These practices reduce runoff, recharge groundwater, maintain agricultural productivity, improve water quality, and 9educe flooding.\n6) Using Stormwater Treatment Trains in Urban Landscapes. In urban areas it is beneficial to implement combinations of practices to slow water volume and improve water quality. Practices in urban areas that are commonly combined include raingardens, infiltration trenches, treatment swales and detention basins.\n7) Strategic Site Selection. Water quality practices should be located where they will have the greatest landscape benefits to maximize the value of conservation funding. The Nonpoint Priority Funding Plan (pdf) (NPFP) helps to prioritize potential nonpoint restoration and protection actions based on available Watershed Restoration and Protection Strategies (WRAPS), Total Maximum Daily Load (TMDL) plans and local water plans.\n8) Nutrient Management. Detailed Nutrient Management Plans play a key role as an operational practice along with conservation practices in protecting water bodies from nutrients in agricultural areas.\n9) Wetland Protection and Restoration. Wetland protection and restoration provides benefits for water quality, peak flow reduction, habitat and wildlife. Water plans should support the continued implementation of the Wetland Conservation Act and look for opportunities to improve coordination across jurisdictional boundaries. The plan should also identify high priority areas for wetland restoration and strategically target restoration projects to those areas. The Restorable Wetlands Prioritization Tool is one resource that can be used to help identify areas for wetland restoration.\n10) Protecting Groundwater. It is important to identify priority areas for drinking water/groundwater planning, and management such as source water protection areas, groundwater management areas, and areas of groundwater/surface water interaction; or concerns about groundwater overuse or contamination that need to be addressed in plans. Ineffective septic systems and subsurface treatment practices are also important considerations.\n11) Sustainable Forest Management. Protecting the health of forests by sustainable forestry practices and control of invasive species can maintain the health of forest soils and plant communities that promote the infiltration and filtering of water before it reaches streams, rivers, lakes and wetlands. Long-range forest management plans are an important tool for maintaining healthy forests.\n12) Minimizing Landscape Stressors. Investigate opportunities to improve environmental conditions throughout watersheds to decrease environmental stressors such as flooding, water level fluctuations, sedimentation, environmental pollutants, decreasing water tables, or invasive species that can significantly detract from key ecological functions into the future.\n13) Increasing Perennial Vegetation. Areas of plant diversity supports wildlife species and increases resiliency by helping plant communities function as intact ecological systems during climate variation. Planting native species also prevents the establishment of invasive species. Diverse state seed mixes are available for a variety of project types and the Minnesota Wetland Restoration Guide summarizes restoration strategies for uplands and wetlands. The MPCA publication Plants for Stormwater Design summarizes environmental tolerances of native vegetation.\n14) Preserving and Restoring Soil Health. The use of cover crops and perennial vegetation is recommended to promote good soil structure, organic content and microorganism populations that promote healthy soils and sustain productive ecological and agricultural landscapes. Maintaining more vegetation more of the time increases evapotranspiration during the spring and fall seasons, reduces runoff and erosion and helps recycle nutrients. Root systems increase organic matter in the soil profile, which increases infiltration and water holding capacity for plant available water, and also reduces runoff, erosion and nutrient transport.\n15) Adapting to Climate Change. A major climate trend in Minnesota has been an increase in intense rainfall events that stress aquatic systems, cause erosion, and transport sediment and nutrients. Partners that are working on water plans should consider the potential for more extreme weather events and the implication for water and land resources. BWSR’s Climate Change Trends and Action Plan (pdf) provides details about climate change adaptation for conservation and protection of natural resources. All of the strategies summarized in this Toolbox play a role in climate adaptation efforts. In addition to the strategies already summarized related to water planning it is also important that NOAA Atlas 14 rainfall frequency data and good BMP/landscape planning and design practices are used to address larger storm events. It is also important to identify landscape and populations at risk from climate change trends.\n16) Public Engagement. Finding ways to engage landowners in projects within urban or rural communities can be an important way to promote conservation efforts. This can be accomplished though volunteer events, tours or promoting community gatherings where projects are featured. Having landowners speak about the benefits of projects on their property can be an effective method of convincing other landowners to sponsor projects.\n17) Practicing Adaptive Management. Adjust management practices based on monitoring efforts and experience with successes and failures to improve the long-term effectiveness of management practices and resiliency of plant communities. Practices such as prescribed burning, water level management and prescribed grazing and haying may replicate natural disturbances and promote diversity and resiliency. BWSR’s What’s Working webpages summarize strategies that have been successful for conservation professionals.\n18) Disaster Response. Flooding has caused significant damage to private lands and conservation practice infrastructure in Minnesota. Since 2000, BWSR has distributed $53 million in southeast, northeast and northwest Minnesota under the Disaster Recovery Assistance program to install, repair, or rehabilitate erosion and sediment control and water quality and watershed protection projects damaged by flooding. The Division of Homeland Security and Emergency Management (HSEM) also helps Minnesotans prevent, prepare for, respond to and recover from disasters among its other responsibilities. This includes efforts to reduce the risk to people and property from natural and human-caused hazards by developing and implementing long-term mitigation measures that will reduce or eliminate the severe effects of future disasters.""]"	['<urn:uuid:ea785bd4-665e-45d5-8507-60d8054e8818>', '<urn:uuid:c9f9f51c-177b-4378-b726-79f2fb338b80>']	factoid	with-premise	verbose-and-natural	similar-to-document	comparison	expert	2025-05-13T05:52:58.810667	36	82	3353
79	how many pounds nitrogen fixed by soybean at 60 bushels per acre yield	At a yield level of 60 bushels per acre, soybeans fix about 180 pounds of nitrogen out of the 270 pounds total nitrogen uptake needed, which represents approximately 65% to 70% of the total required nitrogen.	"['Soybean has high protein content, which is rich in N, so its needs for N are high.\nBecause soybean can fix its own N, farmers have traditionally taken a ""hands-off"" approach to N fertilization. The exception is in fields not recently planted to soybean, in which case a seed-applied ""inoculant"" of rhizobia bacteria has been used. This has been the extent to which most growers have worried about N fertilization for soybean, and it has largely been a successful approach for over half a century.\nToday, however, some soil fertility recommendations for soybean are including N fertilizer applications, often in the range of 20 to 40 lbs/acre but sometimes higher. At the same time, other recommendations are consistent with conventional wisdom - inoculating new soybean fields with rhizobia and nothing more. These varying recommendations may have growers wondering what has changed. The answer is that soybean fertility guidelines are evolving to account for increasing N demand from higher-yielding soybean. This article will discuss the N needs of today\'s higher-yielding soybean crops, sources of N supply to the crop, and whether N fertilizer applications may be needed for maximum soybean yields.\nAs Figure 1 indicates, average N fixed by soybean increases linearly with increasing yield, but only a portion of the total N requirement is met through N fixation (about 50% to 60% of total N requirements at yields of 50 bu/acre or less). Based on the average of the 100+ studies represented in Figure 1, at a yield level of 60 bu/acre, fixed N provides about 180 lb of the 270 lb N uptake in soybean, or 65% to 70% of the total required N. For yields up to 60 bu/acre, the difference between total N uptake (i.e., plant requirement) and fixed N is usually provided by soil sources.\nThe N budget in Figure 1 also illustrates that there may be a small N deficit for yields between 60 and 80 bu/acre, which means that yield could be restricted because of too little N. Realistically, conditions that are favorable for top soybean yields are usually conducive to high soil mineralization as well, so N would not always be limiting in the 60 to 80 bu/acre range. However, as soybean yields continue to increase and yields in this range and higher become more common, N fixation and soil N mineralization will reach capacity in many growing environments. Thus, an increasing number of N shortfalls are almost certain to occur based on the current understanding of this system, particularly at yields near 100 bu/acre. As the graph shows, soybean\'s upper limit for N fixation (considered to be about 300 lb/acre) combined with the upper limit of the soil supply (usually less than 100 lb/acre) are insufficient to meet the needs of a 100 bu/acre soybean crop (Salvagiotti et al., 2008).\nUnderstanding soybean N needs by comparing to corn\nAnother approach to understanding soybean N needs is to compare it to corn, a crop for which growers routinely estimate N needs. Consider a situation of growing corn without application of N fertilizer: if soils can provide 80 lb N by mineralization, resulting corn yields may approach 100 bu/acre, which contains 80 lb N in the grain. To achieve corn yields above 100 bu/acre would require supplemental N beyond what soils are able to apply, i.e., application of N fertilizer. This same 80 lb N supplied by the soil, when added to N fixed by the soybean crop, is sufficient to produce 50 to 60 bu/acre of soybean (Figure 1); achieving higher yields may require supplemental N.\nN Credit for corn following soybean?\nThe N budget also makes an important point about the prospect of an ""N credit"" from a soybean crop that may reduce the N fertilizer requirement for a subsequent corn crop. Because soybean does not fix enough N to satisfy its own needs, but rather, removes N from the soil at both low and high soybean yield levels, the concept of an N credit is not supported. Nevertheless, the practice of applying less N to a corn crop following soybean is still valid, but for a different reason.\nSoil microbes that digest crop residue use the carbon (C) remaining in plant materials as an energy source. As microbial populations increase in the presence of carbon-rich residues, they also require N for cellular growth and metabolism. Because most crop residues are high in C but not in N (C:N ratio is high), microbes use N that is available in the soil. This temporarily “ties up” the N, making it unavailable for other uses, including crop uptake. Eventually, however, N is released back to the soil as crop residues are decomposed and microbial populations decline. Soybean crop residue contains considerably more nitrogen than corn residue, which speeds up the process of residue decomposition and ties up less N in the subsequent corn crop. Thus, less N needs to be applied to corn following soybean.\nTo summarize, soybean requires a large amount of N. Because only a portion of this can be supplied by N fixation and soil mineralization, growing higher-yielding soybean will likely require another source of N.\nAt about 60 days after planting, or about the R4 growth stage, soybean begins to move N from the vegetative parts of the plant to the grain. This might suggest that the best time to apply additional N is prior to R4 (during the early reproductive growth stages) so that fertilizer N is readily available to the plant by R4. If this applied N could delay or minimize the shift of N from the vegetative parts to the seed, it may prolong the duration when the plant remains green and is moving carbohydrates to the seed, and therefore may increase overall grain yield.\nAlthough an N fertilizer application during early reproductive growth stages is during a period of great demand by soybean, it is not known if the N applied would be additive to the N fixed by the plant. Conversely, it could decrease N fixation by some amount, even up to the total quantity of N fertilizer applied, thus resulting in a zero net gain in available N to soybean. Unfortunately, as stated previously, there is not a straightforward answer at this time.\nSupporting research: A slow-release N study\nHow might N fertilizer be applied to soybean without adversely affecting N fixation? An approach taken in a Nebraska study was to apply 160 lb N/acre of slow-release N fertilizer (polymer coated) before planting and place it 8 inches below the soil surface midway between the rows (Salvagiotti et al., 2009). The placement at 8 inches depth was intended to avoid or minimize the reduction of N fixation, since this put the N fertilizer below the zone where most N fixation occurs. Using a slow-release form of N allowed the application to be made prior to planting but delivered the N fertilizer closer to the plant\'s peak demand (during reproductive growth stages). In this Nebraska study, the deep placement of slow-released N fertilizer was compared to broadcast applications of ammonium nitrate either split before planting and at the V6 growth stage or all applied at the R5 growth stage. The check treatment had no N fertilizer applied.\nField with soybean planted for the first time. Dark strips were inoculated with rhizobia bacteria; light strips were not.\nThe results showed that grain yields from all 3 N treatments were the same, achieving 81 bu/acre, which was 3.6 bu/acre greater than the untreated check. This relatively small yield response to N did not justify applying 160 lb N/acre. It is unknown whether less N fertilizer would have been sufficient to increase yield.\nResults also showed that the deep placement of slow-release N fertilizer was successful in not reducing the amount of N fixed by the soybean, as the 180 lb N/acre fixed by the plant for this treatment was the same as that fixed by the check treatment. This compared to 140 lb N/acre fixed for the broadcast ammonium nitrate treatments. However, the N fixed in this study was considerably less than average for 80 bu/acre soybean (220 lb N/acre) when compared to the many studies represented in Figure 1. Additionally, N uptake attributed to soil was between 160 and 200 lb N/acre - much more than typically attributed to soil mineralization (80 to 100 lb N/acre). For this Nebraska study, fixed N plus soil N totaled 340 to 380 lb N/acre, which is usually sufficient to produce 80 bu/acre soybean (Figure 1). Thus, the lack of response to the N fertilizer could have been a consequence of a soil that was already providing plenty of N by mineralization.\n* John P. Schmidt, Pioneer Research Scientist, Soybean Production, Champaign, Illinois.\nThe foregoing is provided for informational use only. Please contact your Pioneer sales professional for information and suggestions specific to your operation.']"	['<urn:uuid:19ab1f42-c2bf-4dd8-97ae-e1e78c381784>']	factoid	with-premise	long-search-query	similar-to-document	single-doc	novice	2025-05-13T05:52:58.810667	13	36	1475
80	benefit corporations social enterprises differences governance requirements how are they managed	Benefit corporations and social enterprises have distinct characteristics and management requirements. Benefit corporations are for-profit entities that must create positive social and environmental impact while pursuing profit, with specific targets in five areas: governance, workers, community, environment, and customers. They must report on their social and environmental impact alongside financial performance. Meanwhile, social enterprises, which may include NFPs, require different governance models focusing on policies, systems, and structures. These include clear roles and responsibilities, proper board composition, strategic planning, risk management, and maintaining organizational integrity. Both types of organizations need to balance social impact with sustainable operations, but benefit corporations have specific legal requirements, while social enterprises often follow governance frameworks like those outlined by organizations such as the Australian Institute of Company Directors.	"['Spend enough time in the social impact space, and you’re bound to hear the concept of “B-Corps” come up again and again. But what exactly is a Benefit Corporation, and why is the concept so important to the conversation around business as a force for good?\nBroadly speaking, businesses traditionally fell into one of two categories: they were either for-profit or nonprofit. For-profit companies were driven to maximize financial returns, while nonprofits relied on outside fundraising and donations to operate. With no social impact requirements for for-profits, and no ability for nonprofits to use the power of the market, the two camps remained firmly planted on opposite ends of the spectrum.\nMeanwhile, a historic global culture shift was already underway to harness the power of business to help address society’s greatest challenges. People were realizing that the business community could be part of the solution to global problems like wealth inequality, climate change, and social unrest.\nAgainst this backdrop, in 2006, three friends set out to explore a third option – almost a hybrid of the two, that would allow businesses to use the power of the market as a force for social and environmental good. They founded a nonprofit called B-Lab with the goal of accelerating that cultural shift to bring about an inclusive, equitable and regenerative economic system for all people and the planet.\nThe advocacy work done by B-Lab and its partners helped bring a new legal entity into existence: the Benefit Corporation.\nThe Benefit Corporation As a Concept\nIn the MovingWorlds Institute, we educate Fellows that a social enterprise is often a B Corp (not all social enterprises are B Corps, and in almost all cases, all B Corps are social enterprises). Specifically, B Corps have targets in five categories of responsible operating practices: Governance, workers, community, environment, and customers.\nIn setting targets and showing progress in these five areas, benefit corporations grow to create social good, manage their externalities, contribute to their communities, care for the planet, and ensure they are treating workers equitably.\nThe Benefit Corporation as a Legal Entity\nA benefit corporation, sometimes called a “B Corp,” is a for-profit corporation that commits to create a material positive impact on society and the environment from the business and operations of the corporation. As CooleyGo explains, “Like a traditional corporation, it pursues profit for the benefit of its shareholders, but a benefit corporation must also report on how it pursues a positive social environmental impact.” The table below outlines some of the other key differences between Benefit Corporations and traditional corporations:\nAnother advantage of the benefit corporation structure is that it gives entrepreneurs the freedom to define success beyond profit for their businesses, and protect their mission through changes in ownership and leadership by baking it right into their articles of incorporation.\nIs the option to incorporate as a Benefit Corporation available everywhere?\nThe short answer is: no. However, that is changing. In the United States, some version of the Benefit Corporation has been adopted in over 30 states plus the District of Columbia, but the actual name of these entities varies by state. In Washington State, for example, Benefit Corporations are called “Social Purpose Corporations.”\nSimilar legal structures are gaining momentum internationally as well. The United Kingdom offers an option called a “Community Interest Company,” with similar features to ensure it’s operating for the benefit of the community. Social Enterprise UK is an example of a Community Interest Company working to further the social enterprise movement.\nBringing this kind of legal structure or its equivalent to more parts of the world is a big part of B-Lab’s ongoing work. As its website explains, “B Lab works with our partners around the world to identify countries where corporate law impedes mission driven entrepreneurs. B Lab works with local experts to identify legal pathways for mission-aligned companies to consider impact over time. A key component of B Lab’s impact thesis is that accountability is fundamental to driving positive impact over the long-term. Companies can only consider impact over time if they are legally allowed (and even required) to do so. Building on the success of benefit corporation legislation in the U.S., B Lab is already working with governments in several countries to create and implement mission-aligned structures and working in all its regions to promote their use.”\nIn Latin America, for example, Sistema B promotes B Corps and other economic actors in Latin America in order to build a new economy, in which success and financial benefits include social and environmental well-being. Organizations with the same goal of furthering business as a force for good include Social Traders in Australia and Euclid in Europe.\nLegislation is already moving forward in Australia, Argentina, Chile, and Canada. For information on these legislative efforts, you can contact firstname.lastname@example.org.\nWhat’s the difference between a Benefit Corporation and a “Certified B-Corp”?\nThe B-Lab certification is similar to other certifications, like “Fair Trade” or “USDA Organic.” Most certified B-Corps will have this icon somewhere on their website:\nAny organization that is incorporated as a benefit corporation is a B-Corp. But for organizations in places where those legal structures aren’t available, or even organizations who are incorporated as a B-Corp but want an extra layer of accountability, Certification is a third-party service administered by the non-profit B Lab, based in part on a company’s verified performance on the B Impact Assessment.\nThe B Impact Assessment is a free, confidential tool that any business can use to start measuring and managing its social and environmental impact. Dimensions covered in the assessment include:\n- Mission & Engagement\n- Ethics & Transparency\n- Mission Locked Impact Business Model\n- Financial Security\n- Health, Wellness, & Safety\n- Career Development\n- Engagement & Satisfaction\n- Diversity, Equity, & Inclusion\n- Economic Impact\n- Civic Engagement & Giving\n- Environmental Management\n- Air & Climate\n- Land & Life\n- Environmental Education & Information Impact Business Model\n- Customer Stewardship\n- Education Impact Business Model\n- Economic Empowerment for the Underserved\n- Support for Underserved/Purpose-Driven Enterprises\n- Serving Underserved Populations (Indirect)\nStep 1 is taking the assessment. You have the option to answer fewer questions in about 30 minutes to get a quick snapshot, or to dedicate a few hours to answering all of the questions for a full impact report. Once you’ve completed the assessment, you can then compare your performance against thousands of other businesses to see how you measure up. Finally, you can create a customized improvement plan for your business and use B-Lab’s free best practice guides to help you implement.\nA benefit corporation is a legal structure, a certification, and a global movement. At its core, being a benefit corporation means that you exist for some public benefit – whether that’s social or environmental. As the B-Corp movement continues to gain momentum, new legal structures will continue to become available that balance profit with purpose. Want to learn more about the social enterprise movement and leverage your career for good? Apply to the MovingWorlds Institute.', ""Building a charity that thrives: key factors for successful governance and management of NFPs\nIs Not-For-Profit a sustainable objective? As the name suggests, Not-For-Profit organisations (NFPs) such as charities, foundations, institutions, and even political groups, are characterised by the objective of creating ‘social’ rather than ‘material’ value. This raises questions about their sustainability and ability to thrive. What are key drivers for successful governance and management of NFPs? This article examines the main challenges faced by the NFP sector and identifies the success factors of a well-managed charitable organisation.\nThe common thread in NFPs is that they all advocate a social objective which for example promotes religion, education, the alleviation of poverty and other laudable civic goals. Every country has its own statutes which govern NFPs and generally the financing of NFPs is done by donors, international agencies, government institutions, private individuals and the general public.\nNFPs have to operate with two contrasting disciplines: economics and sociology. These disciplines are at the root of the objective of any NFP and they represent the two longstanding dilemmas at the same time. On one hand, the standard economic model does not apply to a distinctive nonmarket situation which characterises NFPs while, on the other hand, the sociological perspectives offer interesting insight, but fail to develop plans of action for NFPs.\nLooking at the broader concept, it is worth making a distinction between ‘Non-Profit’ and ‘Not-For-Profit’ organisations which although used similarly do not mean the same thing. While both types of organisations may be advocating a social cause, the Non-Profit organisations would have different memberships, and their objectives may have settings which include scientific research, environmental challenges and the like. People will associate ‘Non-Profit’ status to Social Clubs such as the Rotary, Lions etc. NFPs are driven essentially by the sociological perspectives which make them sustainable in the longer term due to the ever-increasing need to integrate civil society to business, politics, the economy in general and social development. Individuals and groups often perceive the presence of NFPs as being attributed to market or government failure in specific services.\nHowever, the importance of human construction and social interaction in the emergence of shared realities make NFPs a sustainable objective.\nThe main challenges of NFPs\nResource dependency is one of the biggest challenges of NFPs. The sources of finance which rely on donations, fund-raising activities, direct support from business communities and Government grants in some cases become scarcer in the wake of increasing social needs.\nMismanagement is a particular problem with NFPs because the employees are not accountable to anybody who has a direct stake in the organisation. Projects may be started and they are never completed due to wrong forecast of costs and expenses. The recent Oxfam scandal in the UK tend to point out to the lack of ethics by people entrusted to run NFPs.\nLack of talent\nThere are reports of major talent shortages in the NFP sector today regarding newly graduated workers. NFPs inevitably face severe competition with private and public sectors in attracting and maintaining talented employees. Remuneration packages are very often not commensurate with the level of responsibilities and work stress employees have to undergo in NFPs.\nStrategic planning, accounting & auditing shortages\nAs far as NFPs strategic management is concerned, it comes as no surprise, that NFPs experience a significant lack of strategic planning. Accounting and auditing have been not very popular in NPO circles and these disciplines tend to be undermined in the management of NFPs.\nAlthough the techniques of financial management in NFPs do not fundamentally differ from those in profit-oriented enterprises, there are some peculiarities which underpin NFPs. They all pertain to the specific way NFPs are funded, and more specifically the diversity of sources of equity, which is clearly more important than for-profit oriented firms, and its consequences for the financial vulnerability of NPOs\nParticularly in the case of Foundations, the ‘Founder’s Syndrome’ is an issue organisations experience as they expand. Dynamic founders, who have a strong vision on how to operate the organisation, try to maintain control and this undermines new employees or volunteers who attempt to expand the scope of projects or to change policies.\nCompliance with legislations\nCharities have to abide by a lot of legislations to ensure that they are operating correctly and fairly. In the UK it is the Lobbying Act that is one of the biggest challenges facing the sector. In the US, the Trump Administration has brought the largest change in Tax Codes exercising much pressure on NFPs.\nEmbracing new technology\nAs in any sector, technology innovation has made a dramatic impact on the NFP sector. It has significantly changed how charities raise funds and how individuals donate and support charities they care about. Embracing new technology has create huge opportunities for those who managed successfully and left those who haven’t with a big challenge at hands.\nManaging NFPs successfully\nIn the wake of the various challenges NFPs must face, it is essential to identify the success factors and build up models that thrive\nA charity, for example, is accountable to its patrons and its beneficiaries and it is rightly being challenged more frequently and scrutinised closer than ever before. Transparency and accountability are very high on the agenda and charities need to enhance their channels for communicating their expenditure, strategies, impact and ethics to grow public understanding and instil confidence. They need to show that they are using funds in the best way to support the people on whose behalf they operate.\nAdopting a proper governance model is another challenge. Governance is an amalgamation of policies, systems, and structures, along with a strategic, operational framework that aligns organisational leadership to take action, so that they can make effective decisions with accountability. A model for governance refers to how those policies, systems, structures, and framework interface with each other and whether the responsibility for them lies with the board as a whole, or with the individual board members.\nThe Australian Institute of Company Directors has enumerated ten important requirements for an effective Governance Model for NFPs:\n- Roles and responsibilities\nThere should be clarity regarding individual director responsibilities, organisational expectations of directors and the role of the board.\n- Board composition\nA board needs to have the right group of people, having particular regard to each individual’s background, skills and experience, and how the addition of an individual builds the collective capability and effective functioning of the board.\n- Purpose and strategy\nThe board plays an important role in setting the vision, purpose and strategies of the organisation, helping the organisation understand these and adapting the direction or plans as appropriate.\n- Risk - recognition and management\nBy putting in place an appropriate system of risk oversight and internal controls, boards can help increase the likelihood that their organisation will deliver on its purpose.\n- Organisational performance\nThe degree to which an organisation is delivering on its purpose can be difficult to assess, but this can be aided by the board determining and assessing appropriate performance categories and indicators for the organisation.\n- Board effectiveness\nA board’s effectiveness may be greatly enhanced through: careful forward planning of board-related activities; board meetings being run in an efficient manner; regular assessments of board performance; having a board succession plan; and the effective use of sub-committees, where appropriate.\n- Integrity and accountability\nIt is important that the board have in place a system whereby: there is a flow of information to the board that aids decision-making; there is transparency and accountability to external stakeholders; and the integrity of financial statements and other key information is safeguarded.\n- Organisation building\nThe board has a role to play in enhancing the capacity and capabilities of the organisation they serve.\n- Culture and ethics\nThe board sets the tone for ethical and responsible decision-making throughout the organisation.\nThe Board should help an NFP to engage with its stakeholders. Some examples of key stakeholders are the people and/or groups served by the NFP, donors, creditors, directors, employees, volunteers, government (and its agencies), members, other related institutions, suppliers.\nPutting together the effective organisational attributes\nThe 6 core components of a successful NFP need to work together for effective organisational management.\nVision: Adoption of a clearly defined vision and mission statements for the organisation.\nStrategy: The systematic approach to charting an organisation's future business activity. This will include the development of formal strategic plans for fund raising and the engagement of holders.\nCulture: The shared assumptions, beliefs, values, expectations, rules, and predominant practices collectively held by members of an organisation\nBusiness Model: The economic logic of an organisation. There is a constant need for Board involvement in revenue development and implementation of plans for the diversity of revenue sources.\nOperations: Organisational apparatus engaged in administration and service delivery. Client-centricity of service delivery and quality control systems\nPeople: Policies and practices around the engagement of staff and volunteers. Clarity on performance accountability, job definition and staff support systems.\nIn summary, NFPs take their roots in well-defined social objectives which remain crucial for their existence. They form an integral part of our modern society and the way they are financed put them under constant pressure towards their different stakeholders and the civil society. They remain underpinned by the financial and economic impediment which imposes on NFPs the need to adopt sound business practices, good governance and organisational excellence.""]"	['<urn:uuid:4cd62967-7da9-4892-8a31-d8bde14f7bde>', '<urn:uuid:62091a26-e48c-4d66-b088-d49b074968f4>']	open-ended	with-premise	long-search-query	similar-to-document	multi-aspect	novice	2025-05-13T05:52:58.810667	11	124	2734
81	What kind of testing should be done to check if a medicine can handle the high temperatures used in steam cleaning during manufacturing?	Pilot plant or bench top laboratory studies are conducted where the formulated product in its intended container/closure system is exposed to maximum anticipated thermal and time conditions. After exposure to maximum sterilization cycle conditions, the drug product is tested to ensure it remains within specification limits. Additionally, thermally exposed products should undergo accelerated 40°C stability studies for at least three months.	['Book chapter – Steam Sterilization: A Practitioner’s Guide (Ch.11)\nactivities associated with conducting cycle development studies necessary for a regulatory filing. The activities associated with developing sterilization technology data for a new or modified drug product require the interaction of several disciplines.\n– How Does One Determine Whether the Product Withstands a Thermal Process That Is Encountered in Moist Heat Sterilization?\nGenerally, pilot plant or bench top laboratory studies are conducted, whereby the formulated product in the intended container/closure system is exposed to maximum anticipated thermal and time conditions. At this point, one would have to speculate on what the maximum conditions of the sterilization process would be. Following thermal exposure per the maximum sterilization cycle conditions, the drug product is tested to ensure that the product remains within the specification limits.\nMore than one set of cycle parameters may be evaluated, such as variable times and temperature conditions, to determine whether a heat sensitive product is compatible with a terminal sterilization process. These evaluations could be classified as initial R&D stability studies. Further, thermally exposed products should be placed on accelerated 40°C stability studies for at least three months. If the product stability data demonstrate that the initial product specification release limits cannot be maintained, a case exists for aseptically processing the product. These data would have to be included in the NDA or European regulatory submission.\nDuring the review process, questions may arise regarding whether extractables from the container/closure system influenced the drug or product data. Therefore, the developmental data must show whether the system will meet\nthe USP biological safety testing if the container/closure system is an elastomeric, plastic, or other polymeric material.\nTasks presented in the chapter :\n– Expectations of Regulatory Agencies Concerning Sterilization of the Solution and Cycle Selection on the Basis of Solution Selection—Development Studies That Need to Be Conducted\n– Defining requirements\n– Selection of a moist heat sterilization process\n– Container thermal mapping: determining the slowest-to-heat zone\n– How much lethality is enough?\n– What Is the Purpose of the D- and z-values?\n– Determining the Minimum Microbial Lethality\n– Determination of the Probability of Survival for Bioburden\n– Determination of the required sterilization process time (in minutes of F0) or cycle definition (load probe controlled cycles)\n-Required Sterilization Process Time\n– Cycle Definition (Product Penetration Controlled Cycles, i.e., controlled by Fo values in solution filled containers)\n– The container/closure system\n– True Fo cannot be calculated at closure sites\n– Regulatory expectations for container/Closure challenge data\n– The master solution – biological challenge\n– How does one select the Master Solution?\n– Special considerations related to the design of the subprocess solution challenge\n– Calculation of the required heat history for processes at temperatures other than 121°C\n– Fractional or half-cycle developement approaches\n– Container closure integrity testing\n– The master solution – heat penetration\n– The Master Equipment Challeng\n– What thermal distribution and penetration data are expected? –\n– Heat Penetration (Thermoprobed Product)\n– Temperature Distribution Studies\n– Time windows\n– Cycle Come-Up Time or Heat-Up Time*\n– Exposure Time\n– Calculation of Cooling Times\n– Loading patterns and configurations drying cycles\n– Sterilization and integrity of filters\n– Cooling water evaluations\nDevelopment of an appropriate sterilization cycle is difficult. The development of an efficacious and yet economic sterilization process is one of the most critical phases of a product development process. This chapter is intended to provide some guidance on the topic. However, each site needs to have an established cycle development program that takes into account the facilities and equipment actually used.[…]\nCourtesy of DHI Publications.']	['<urn:uuid:d9b3d726-1030-4432-b2a2-2d470e530b29>']	factoid	direct	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-13T05:52:58.810667	23	61	600
82	nail art products safety handling protocols	Nail art products require careful handling protocols. For decoration, various products are used including fimo (modeling clay), metallic foils, rhinestones, glitter powder, and chemicals like UV gel and nail polish. According to COSHH regulations, when working with these substances, proper safety measures must be implemented including: maintaining high personal hygiene, using appropriate protective equipment, proper storage of materials, and reporting any defects in control measures. Employers must ensure suitable training is provided and carry out risk assessments specifically focused on hazardous substances used in nail art procedures.	"['Contents: Nail art accessories\nProducts and their functions: nail art accessories\nThe variety of fingernail designs would be inconceivable without the extensive nail art accessories. Decorated fingernails with nail art are nowadays very important for many woman and a great eyecatcher. They can be designed in many different ways and every motif is an individual piece of art. Because of the high amount of different nail art accessories, there are no limits to your creativity in creating simple or extravagant and unique fingernails motifs. They give the fingernails a elegant and noble touch. Hereinafter you find a small listing of useful nail art accessories.\nNail art pen and nail art liner – to create detailed motifs\nThe nail art pen and nail art liner are indispensable products in creating different nail art motifs. They enable you to create detailed motifs on the small surface of your natural or artificial nails. The nail art pen as well as the nail art liner are indispensable as nail art accessories and belong to the assortment of all fingernail designers.\nContents: Nail art pen and nail art liner\nNail art pen – to draw fine dots or small leaves\nThe nail art pen is an indispensable nail polish bottle with a brush for painting and a small tube with a needle-sized opening under the lid to draw fine dots or small leaves at the nail art.\nNail art liner – to draw thin and fine lines\nThe nail art liner is filled with water-soluble acrylic paint. It has a very fine brush to draw thin, fine lines. The nail art liner is also available with glitter varnish to create beautiful effects on the motif.\nTools for decorating the fingernails\nWithout certain tools for decorating the fingernails, it is more difficult and tedious to use certain working techniques. Hereafter we would like to introduce you to the spot-swirl and the flat brush for the one stroke technique. As nail art accessories both tools are very important working tools for all fingernail designers.\nContents: Tools for decorating the fingernails\nSpot-Swirl – for individual nail art creations\nThe spot-swirl is ideal for the incorporation of rhinestones, bouillons, dried flowers, 3D figures etc. as well as for applying light-curing color gels. The spot-swirl is available with different ball heads and diameters for individual nail art creations. It is also very good for the marbling technique as well as for drawing an exact smile line with french gel.\nFlat brush for one stroke – ideal for acrylic paints\nThe flat brush is ideal for one stroke technique of painting. You can take with the flat brush several acrylic paints simultaneously to create floral motifs, leaves or other extravagant motifs on the fingernails. The flat brush or one stroke brush creates extraordinary and breathtaking artworks.\nNail art products for decorating the fingernails\nNowadays the industry offers nail art products for decorating the fingernails in many different variants. There are nail art accessories, fingernail stickers with various motifs, modeling materials called fimo, glitter powder and metallic foils as well as rhinestones in various colors, 3D ceramic flowers, half pearls as well as shell chippings and still much more to decorate the fingernails. We would like to introduce you to some of these nail art products and under “nail art instructions” you will also find many motifs that are illustrated and explained step by step. Just get ready! You will be amazed how quickly you learn the techniques and the handling of the nail art accessories from our instructions.\nContents: Nail art products for decorating the fingernails\n- Fimo (modeling clay) – Nail art fimos are available in different shapes and colors\n- Beaten gold – a touch of glamor and luxury\n- Metallic foil is available in different colors and as a hologram\n- Nail sticker are suitable for natural and artificial nails\n- 3D ceramic flowers are fixed on the fingernails\n- Dried Flowers – ideal for a summer effect\n- Half pearls give the fingernails a modern accent\n- Rhinestones in various colors and shapes\n- Nail art pearl necklace belong to the 3D elements\n- Glitter powder or glitter dust gives the fingernails a beautiful shine\n- Crushed shells have a light mother-of-pearl effect\n- Hologram motifs or nail art holograms shine and sparkle multicoloured in the light\n- Sequins or nail art sequins belong to the inlay motifs\n- Micro pearls or nail art bouillons for the caviar effect\nFimo (modeling clay) – Nail art fimos are available in different shapes and colors\nFimo is a modeling clay which is ideal for decorating. You can create very small motifs with this hardened mass, which you can use for nail art. You can attach it to the fingernails either with UV gel, tip glue or with clear lacquer. Nail art fimos are available in different shapes and colors. They are available as fimo flowers, leaves, stars, fruits or animals. You can buy them as a bar and then cut them into very thin slices with a special fimo blade, a carpet knife as well as a very sharp knife, or you can bought them already cutted, which is of course easier and the cuts are more precise. The fimo fruits give the fingernails a fruity sweet look especially in summer.\nBeaten gold – a touch of glamor and luxury\nThe beaten gold are thin gold leaflets for decorating the fingernails. You can pluck the gold leaflet apart with tweezers in small pieces and then place them on the wet nail polish or clear lacquer. The leaf gold is also offered already plucked in small bins. It gives your fingernails a touch of glamor and luxury especially at partys, weddings, on Christmas, New Year’s Eve or for a romantic date. This nail art design is extraordinary and a great eyecatcher.\nMetallic foil is available in different colors and as a hologram\nThe metallic foils are fixed with a foil adhesive on the fingernail. The metallic foil is available in different colors and as a hologram. First, the metallic foil is cut to the desired length. Then apply a very thin layer of the foil adhesive on the fingernail. Now wait until the milky foil adhesive has changed to a clear color. Firmly press the metallic foil onto the surface and rub the spot with the spot-swirl or draw lines with it. After a short moment, the metallic foil can be removed. You can create unique beautiful motifs with them on your fingernails.\nNail sticker are suitable for natural and artificial nails\nThe self-adhesive nail stickers are available in different colors and shapes, for example as holograms, flowers, borders, tribals, ornaments and many more. You can use them for natural nails and also artificial nails. To place them on the fingernail use a tweezers.\n3D ceramic flowers are fixed on the fingernails\nThe 3D flowers are made of ceramics. They are fixed with clear nail polish, nail glue or putted in the still wet UV gel.\nDried Flowers – ideal for a summer effect\nThe dried flowers are real flowers, that has been dried. You can dry them by gathering some small flowers from a meadow and putting them between two pages of paper. The dried flowers give the fingernails a fresh, light summery effect.\nHalf pearls give the fingernails a modern accent\nThe half pearls have a mother-of-pearl effect. They are available in different colors. They give the fingernails a beautiful and modern accent. Like for example 3D ceramic flowers, the half pearls are also fixed with clear nail polish or nail glue or inserted into the UV gel which has not yet hardened.\nRhinestones in various colors and shapes\nThe rhinestones are available in various colors and shapes like round, square, as drops, triangular, half-moon and in countless more shapes. They can be placed in the wet nail polish, clear nail polish or UV gel. With rhinestones the fingernails sparkle and shine in the light. The rhinestones are indispensable as nail art accessories.\nNail art pearl necklace belong to the 3D elements\nThe nail art pearl necklace is available in different colors. They belong to the 3D elements for the nail design and have a very noble and flashy effect on the motif. The pearl necklace can be shortened in the desired length. With the help of a tweezers it is placed on the wet nail polish, clear nail polish or in the uncured UV gel. The nail art pearl necklace sets beautiful accents on the fingernails.\nGlitter powder or glitter dust gives the fingernails a beautiful shine\nThe glitter powder or glitter dust is very fine. It is available in countless colors. The glitter powder can be spread into the still wet nail polish, clear nail polish or uncured UV gel. It gives the fingernails a beautiful shine. The glitter powder should have everyone as nail art accessories.\nCrushed shells have a light mother-of-pearl effect\nThe crushed shells are small chips from real or synthetic mussels. They are available in different colors and have a light mother-of-pearl effect. They are very thin and can be included very well in the wet nail polish, clear nail polish or in the uncured UV gel. With their shining shimmer they give the fingernails a maritime appearance.\nHologram motifs or nail art holograms shine and sparkle multicoloured in the light\nThe hologram motifs or nail art holograms are very thin iridescent inlay motifs. They shine and sparkle multicoloured in the light. You can take them with a tweezers and place them on the desired position. They are available in different colors and shapes for example as hearts, flowers, stars, half moons etc.\nSequins or nail art sequins belong to the inlay motifs\nThe sequins or nail art sequins belong to the inlay motifs. They are placed individually on the fingernails to set small accents. There are large and small sequins in different colors. The sequins give your nails the certain something and fit to every occasion.\nMicro pearls or nail art bouillons for the caviar effect\nYou can apply the micro pearls or nail art bouillons individually on the motif or cover the fingernail completely for the caviar effect. They are offered in different colors. The micro pearls or nail art bouillons are placed in the wet clear nail polish, nail polish or UV gel. They put nice highlights on the fingernails and are another great way to create unique nail art designs.\nNote: All information without guarantee for completeness and correctness. No liability can be assumed for any damage that may occur.', ""COSHH – A Guide to Employers’ and Employees’ Responsibilities\nEmployee Responsibilities under COSHH\nEmployee responsibilities within the COSHH (Control of Substances Hazardous to Health) Regulations of 2002 include:\n- Making use of control measures and facilities provided by the employer\n- Ensuring equipment is returned and stored properly\n- Reporting defects/insufficiencies in control measures\n- Wearing and storing personal protective equipment (PPE)\n- Removing PPE that could cause contamination before eating or drinking\n- Making proper use of washing, showering and bathing facilities when required\n- Maintaining a high level of personal hygiene\n- Complying with any information, instruction or training that is provided\nEmployer Responsibilities Under COSHH\nUnder COSHH regulations, employers’ responsibilities include:\n- Implementing control measures to protect workers from hazardous substances.\n- Preventing or adequately controlling exposure to hazardous substances.\n- Providing employees with suitable and sufficient information, instruction and training, and appropriate protective equipment where necessary.\n- Ensuring that control measures are maintained, kept in full working order, and in a clean condition where appropriate.\n- Drawing up plans and procedures to deal with accidents and emergencies involving hazardous substances.\n- Ensuring that any employees exposed to hazardous substances whilst at work are under suitable health surveillance.\n- Ensuring that substances do not exceed the Workplace Exposure Limit (WEL).\n- Carrying out a COSHH risk assessment.\nNaturally, workplaces with higher risks, such as catering or a hair salon, will require more action than, say, an office. But as an employer, you should be assessing what risks may be posed by hazardous substances, no matter where you work.\nThat way, you can identify if there are risks and if so take action to reduce them to a minimum.\nCOSHH Risk Assessment\nA COSHH risk assessment is essentially the same as a standard risk assessment in terms of the process, but your assessment of the workplace will focus solely on hazardous substances.\nIf you’re unfamiliar with risk assessments, here’s a breakdown of the main 5 steps:\n- Identify the hazards.\n- Decide who might be harmed and how.\n- Evaluate the risks and decide on precautions.\n- Record your findings and implement them.\n- Review your assessment and update if necessary.\nRisk assessments will also involve frequently monitoring the workplace’s processes and the level of exposure to substances.\nWorkplaces are active and constantly changing, so a one-off check won’t be sufficient in minimising the risks posed by hazardous substances. You have to remain constantly vigilant and alert to the dangers.\nRecap: What is COSHH?\nCOSHH stands for the Control of Substances Hazardous to Health Regulations (2002). It exists to ensure that both employers and employees do all they can in a workplace to minimise people’s exposure to hazardous substances and work in ways that are safe.\nThis means that all hazardous substances need to be identified and precautions need to be taken to ensure that workers know how to use and handle them safely.\nThe importance of controlling hazardous substances cannot be overstated. In 2012/13, around 35,000 workers reported that they had breathing or lung problems caused by work, and the most common type of reported skin disease was contact dermatitis.\nAnd it’s estimated that around 13,000 deaths occur each year due to occupational lung disease and cancer – fatal conditions that will have developed over a prolonged period of exposure to dusts and chemicals at work.\nAs an employee or employer, you can prevent statistics like this from increasing. If you fulfil your workplace duties, you can prevent dangerous levels of exposure and meet COSHH requirements.\nRecap: What is a Hazardous Substance?\nSimply put, a hazardous substance is any mixture or substance that is toxic, irritant, or corrosive – whether it’s a liquid, gas, vapour, fume, or dust.\nThey cause harm to the body via routes of entry:\n- By coming into contact with skin or eyes.\n- By being inhaled.\n- By being ingested through the mouth.\n- By entering the body through cuts or punctures in the skin.\nAlthough there are certain industries that will be at greater risk, hazardous substances could exist in any workplace. They are often used directly in work activities, produced by work activities, or already present in your workplace’s premises.\nExamples of hazardous substances include:\n- Chemicals, e.g. cleaning chemicals or bleach.\n- Fumes, e.g. from paint or vehicles that exhaust.\n- Gases, e.g. ammonia from refrigerators.\n- Dusts and powder, e.g. from flour.\nIt’s worth noting that even seemingly innocent substances can be harmful, and that includes natural materials like wood dust or flour.\nWhile many hazardous substances can cause immediate harm, such as a corrosive liquid being spilled onto someone’s skin, the main danger posed by hazardous substances is prolonged exposure. For example, if someone is in the presence of or uses a dangerous chemical for a long time, they could develop breathing difficulties or skin conditions.\nExamples of ill-health caused by hazardous substances includes:\n- Occupational asthma.\n- Occupational dermatitis.\n- Occupational cancers.\n- Skin irritation.\n- Infection from bacteria.\n- Injury or death as a result of exposure to toxic fumes.\nWhat to Read Next:\nSubscribe for the latest Hub updates! Tell us what you're interested in hearing about:""]"	['<urn:uuid:c4476d6b-6884-40f3-b428-407a66537432>', '<urn:uuid:e2c99559-4fd5-48cf-884f-dca2baae7e40>']	open-ended	direct	short-search-query	distant-from-document	multi-aspect	expert	2025-05-13T05:52:58.810667	6	87	2625
83	As an event insurance specialist, I often get asked about the differences between E&O and Event Cancellation coverage - which insurance type covers scenarios like trademark breaches versus weather-related cancellations?	E&O Insurance and Event Cancellation Insurance cover different risks. E&O Insurance specifically covers claims like breach of copyright, trademark, privacy, defamation and breach of contract that typically emerge after broadcast or exhibition. In contrast, Event Cancellation Insurance covers losses from unforeseen circumstances like adverse weather conditions, power failures, terrorism, and circumstances leading to cancellation, postponement or relocation of an event.	"['After it is confirmed by authorities that it is safe to go outdoors, you can begin to assess any potential damage. If you have property damage, you should report your claim as soon as possible. The Travelers Insurance company recommends, the more information you can provide when you report the loss, the better they can begin their response. However, if you have missing information but have sustained damage, please report your claim in any event.\nStay inside and make sure everyone is safe. Stay tuned to the radio or television until an official ""all clear"" is given (if you were evacuated, return home only after authorities advise it is safe to do so.\nAvoid downed power lines. Never touch anything in contact with power lines, including water or water puddles that may be near the downed power lines.\nProtect property from further damage. Board up broken windows at your production office, studio or filming location to protect against vandalism or additional weather damage. Arrange for reasonable temporary repairs\nKeep accurate expense records. Save bills and materials receipts from your temporary repairs. (Do not make permanent repairs until the insurance adjuster has reviewed the damage.) Also, keep accurate records of other expenses incurred.\nSeparate and inventory the damaged property. Write a list of any damaged contents. Include the item description, name of the manufacturer, the brand name, age, the place and date of purchase, if known. Use any photographs, videotapes or personal property inventories you may already have to help\nBy: Doran S. Chandler - Roberts & Stahl, Entertainment Lawyers\nE&O Insurance: The Value of a Lawyer\nEntertainment lawyers are often called upon to help clients obtain Errors & Omissions insurance for their productions. This job is easy if the needs of E&O insurers are considered before production begins. However, the process can be difficult and time-consuming if no thought is given to E&O coverage until after the final cut is locked.\nE&O Insurance covers claims against a production, including breach of copyright or trademark, breach of privacy, defamation and breach of contract. These claims do not usually surface until there has been a broadcast or exhibition of the production.\nE&O coverage is not included in the standard production insurance that is taken out for injuries, damage to property, etc. Only occasionally do you hear about the types of claims for which E&O insurance provides protection. For example, an action was brought several years ago against Dreamworks by an author who had written a book about the events depicted in the feature film Amistad. The author claimed that her copyright had been breached because the film told the story in ways which were similar to the book. More recently, one of the characters depicted in the recently released feature film Boys Don’t Cry has brought an action for breach of privacy because of the manner in which her life was depicted.\nBut most claims do not make headlines; usually they are threatened and then settled. Even if your insurer is ultimately successful in defeating a claim, it can still be costly because of the legal fees involved. And even if a claim is settled, the producer generally pays.\nThere are only a small number of insurers who provide E&O insurance to the entertainment industry. These policies are sold by specialized agents who are familiar with film and television production. If you have been involved in producing a documentary or television production, you have probably filled out the lengthy forms involved in making an E&O application. The application tells the agent how far along you are in the production and what the problem areas are likely to be, but it also serves as a handy checklist for you. Once the application is received, the agent will provide you with a quote and hand it over to lawyers who provide advice to the insurer about the risks involved with the production. The insurer will have its lawyer contact production counsel to review the potential problem areas and to discuss how these will be addressed.\nThe advantage of having your lawyer speak directly to the insurer’s lawyer is that often E&O insurance can be approved with a single phone call. The disadvantage from a lawyer’s perspective is that you sometimes end up doing the insurer’s dirty work by telling a client why certain material can’t be used. Because the insurer’s lawyer relies on production lawyers to decide whether to grant insurance, your lawyer is obliged to identify problem areas. If they do not, you (and the broadcaster) could end up being liable for the omission and your lawyer’s credibility can be affected.\nEvent Cancellation Insurance is purchased for one-off events as a protection against loss of revenue OR extra expenses that result from uncontrollable circumstances such as unforeseen weather conditions, power failure, terrorism, cancellation, abandonment, postponement, interruption or relocation of an event.\nThis type of insurance can also cover public liability, such as a serious injury to one of your patrons, if property is damaged, there is theft of expensive equipment or if you face a claim for actual or alleged bodily injury, and it is found to be your fault.\nWhy event CANCELLATION insurance is needed:\nEvent preparation can take years of planning, and with businesses incurring multiple expenses on the lead up to the event, most can not afford the costs associated with postponement, cancellation or relocation of an event. An organization’s physical assets impact the functionality of a business, therefore with risks to the bottom line being substantial, event cancellation insurance is needed to protect against the loss of costs, expenses or revenues associated with this exposure.\nObtain a no obligation Event Cancellation Insurance Quote Here:\nSome examples of situations that would have benefited from having event cancellation include the following:\nIn July of 2011 a stage collapsed at the Ottawa Bluesfest as the likely result of a strong downdraft of air from a thunderstorm. There were multiple injuries involved with including possible spinal injuries.\nDuring the Big Valley Jamboree in the summer of 2009, a powerful windstorm swept through the area causing the main stage to collapse. A total of 33 charges were laid against the three companies involved in this Alberta Stage Collapse. Each of the charges carries a maximum fine of $500,000 and possible jail time. There were more than a dozen injuries and one death.\nStage collapse at a Christian rock concert in April of 2008 where an auditorium floor collapsed at a church in Abbotsford, BC. Sound and Lighting scaffolds collapsed onto the front section of the stage and mosh pit with more than 40 injuries.\nWho needs event CANCELLATION insurance:\nEvent coordinators responsible for special events such as film shoots, concerts, trade shows & exhibitions, entertainment & sporting events, corporate events such as product launches, and conventions to name just a few. Circumstances such as extreme weather conditions, civil, social and political unrest, strikes by employees at the venues to non appearance of key personnel are all coverages that can be purchased.\nAn example of the importance for promoters in obtaining event cancellation insurance can be seen after Michael Jackson’s unexpected death and the outlays and expenses that resulted from his projected 50 concerts at London’s O2 Arena.\nThere are two types of coverages: the costs and expenses of putting on the event, such as rental promotion and fees charged by service providers, and secondly, the anticipated profits that the event is expected to generate.\nHow event CANCELLATION insurance is obtained:\nBy contacting your broker and/or completing an online application form and providing the relevant financial worksheets.\nHow long event CANCELLATION insurance takes to obtain:\nGenerally 48 hours is needed as a minimum in order to obtain coverage.\nCost of event CANCELLATION insurance:\nThe cost is generally calculated according to the gross revenue or costs/expenses, premiums therefore vary widely. Premiums are also dependent on such factors as whether the event is indoor/outdoor, and if outdoor, what type of protection is in place to negate the effects of the elements. Additional factors that affect the premium include whether an event is dependent on particular cast members or performers and if so, the age and health issues of the performer will need to be known. Premiums are generally higher for this type of coverage as usually a “one time” event that doesn’t occur is a total loss.\nClick here to obtain a quotation:\nOur service is friendly and knowledgeable: please contact us, we would love to hear from you!', ""Concerts. Festivals. Fairs. Sporting events. Live theater. Corporate events. Whether it is indoors or outdoors, we love to be entertained and inspired. We thrive on learning from experts and hearing from speakers we admire. And this is why the events industry is enormous. In the United States, business meetings, conferences, tradeshows and the like provided over 5.9 million jobs.\nEvents require detailed planning and organization to produce a quality experience for all those involved. To put on an event requires a financial investment in the venue, promotion, and people to make it a success. But what happens when things outside the event organizer’s control cause the event to be canceled or postponed? The financial impact can be disastrous for its organizers.\nEvent Cancellation Insurance coverage can help to limit the risk for those unforeseeable circumstances like illness or injury to a key person, adverse weather, loss of venue, and other situations that arise. This coverage is purchased in advance of the event to protect the event organizers, sponsors, and other rights-holders. Depending on the event type, policies can be purchased up to three years in advance. It is best to get a policy in place as soon as planning for the event begins.\nWHO CAN PURCHASE EVENT CANCELLATION COVERAGE?\nCarriers are looking for those who have an insurable financial involvement in an event. Concert promoters, event organizers, band managers, fairs or festivals, sporting events and venues, theater and media companies, sponsors, advertisers, tradeshows, conferences and exhibitions are all insurable. Also, personal or private affairs such parties have coverage options available.\nWHAT CAN EVENT CANCELLATION COVER?\nEvent cancellation policies can be purchased to cover two types of losses, though policies do not cover both on the same policy. The first option provides coverage for the Costs and Expenses (excluding profit) involved in putting on the event. At the least, the event organizer may want to cover their expenses. If an event is established to earn money for its backers, the other option is to cover Gross Revenues (including profit) earned from the event.\nNot all events are created to generate revenue. Corporate meetings and some conferences are examples of this. These types of events would typically look to purchase an event cancellation policy that would cover Costs and Expenses. But concerts, theaters, sporting events, tradeshows, and many other events expect to earn a profit from ticket sales, food and drink sales, and merchandise. These types of events may consider purchasing both types of policies, one to cover Costs and Expenses and also a policy to cover Gross Revenues.\nFor the majority of event creators, merchandise, food and drink sales, and sponsor revenue comprise less than 20%.1 For 48% of events, ticket sales compose 60% to 100% of revenue. The music industry is no exception. It is big business every day of the week. In 2017 concert tickets sold in North America accounted for over $8 billion in revenue while the average revenue per show generated nearly $1 million in gross sales.3,4 That’s a lot of music. And a lot of revenue on the line.2\nBroadway is also a big business. According to The Broadway League, touring Broadway shows grossed $1.63 billion in 2019-2020 and Broadway productions in New York City grossed a total of $1.83 billion.5,6 These are only two segments of the live theater industry. Whether it is the big leagues of Broadway or small regional theaters and production companies, what happens when a show is sold out but must close for a night or a week due to unforeseen circumstances?\nIf a loss does occurs, it will be necessary to provide copies of receipts, refunds, invoices, and contracts to show proof of the expenses and costs for the event. When the policy is insuring Gross Revenues, the insured must establish with reasonable certainty the amount of the loss. Discuss this in advance with the underwriter so you know what kind of documentation or other information they will expect in the event of a claim. If it is a first-time event, this may be more difficult than a recurring event with historical evidence of ticket sales, merchandise sales, and other revenue generators.\nUNFORESEEN, UNCONTROLLABLE, AND UNEXPECTED\nTicketholders shelled out big money to see their favorite pop star. Now the headliner has blown out her knee and cannot go on. A fire damaged the theater making it unavailable for the local movie festival. A huge storm blew in, and the location for the company conference has no electricity.\nWhat types of situations may trigger your coverage under an event cancellation policy? Depending on the coverage you requested to be underwritten for, the following circumstances may apply:\n- Non-Appearance of an Individual or Team (Also Extends to Non-Appearance Due to Illness or Death of a Family Member)\n- Adverse Weather\n- Accident or Illness\n- Failure of Utilities\n- Natural Perils i.e. Earthquake, Windstorm, etc.\n- Public Transport Failure\n- Third-Party Strike Action\n- Denial of Access\n- Damage to Venue\n- Death, Accident, Illness or Travel Delay of Key Speaker/Performer\n- Terrorism or Threat of Terrorism (May add via Endorsement)\n- Civil Commotion (May add via Endorsement)\n- National or State Mourning (May add via Endorsement)\n- Communicable Disease (May add via Endorsement)\nMost of these coverages are negotiable and may be added via a rider or endorsement to your policy. If you are concerned about a particular peril, be sure to discuss it with your underwriter.\nBEFORE PURCHASING COVERAGE\nWhen purchasing an event cancellation policy, be aware that once the policy period begins, it isn’t cancellable either by the insured or the carrier. Premiums are typically due prior to the policy being activated or the start of the event, and they are fully-earned, meaning there are no refunds.\nDiscuss with your underwriter exactly what and how you need the policy to be structured based on the unique aspects of your event. The policy can be constructed to cover at different points such as including set-up and teardown. For example, a golf tournament might be set up for coverage to begin when the first ball is played and end when the last ball is played or to cover weather for the whole weekend. These types of decisions will affect pricing for the policy.\nALL POLICIES ARE NOT THE SAME\nEvent cancellation coverage varies widely, even on policies offered by the same carrier. Terms and conditions are dependent upon so many factors such as event attendance, location, performances, number of days, and more. Certain perils must be added via a rider or endorsement. For instance, Communicable Disease is not typically included but can be added. When seeking out insurance, make it a priority to understand the details of the quotes you receive before purchasing the policy. Some carriers offer an ‘All Cause’ option. Depending on the size of the request, there may be sublimits or minimum losses before coverage begins. Since Event Cancellation policies are flexible, coverage can be crafted specifically for certain perils such as adverse weather, non-appearance, and terrorism.\nNon-Appearance. For many events, Non-Appearance coverage isn’t necessary. However, if your event relies on the appearance of an individual or group, make sure you consider this coverage. Wedding officiants, guest speakers, performers, players, and sports teams are examples of this. This also extends if your caterer, florist, or other major vendor fail to provide their promised services. When a major star has to cancel their event, the loss can be steep. Lady Gaga suffered a hip injury and had to cancel her tour in 2013 resulting in an estimated $30 million in losses.8 She was forced to cancel 22 tour dates after sustaining an injury to her right hip. More recently, Madonna suffered injuries during her live concerts and had to cancel shows.9\nWeather. As weather patterns continue to shift across the globe, the likelihood of weather impacting an event is increasing. Any event can be impacted if weather is significant enough. Hurricane Harvey and Hurricane Irma as well as other exposures led to $10-$15 million in losses when many college football and other sporting events had to be cancelled, postponed, relocated, or reschedule.10\nBroadcast Events. What happens if an event is being broadcast or televised in the media, and the broadcast transmission fails? This situation calls for a separate policy. It can be purchased to cover if there is an interruption to a live TV signal when a third-party is responsible for the broadcast.\nExclusions are a Part of Every Policy; event cancellation is no different. Typical exclusions depending upon the policy structure include financial failure, insolvency, or default; withdrawal of support by any party; lack of sales; and, radioactive contamination. That’s right, don’t expect there to be coverage if an event has to be cancelled or rescheduled due to the insured’s financial troubles or if ticket sales are too low; likewise if a sponsor for the event backs out. While these are difficult circumstances, they aren’t what this type of policy is designed for.\nAlthough it is unlikely that events cancelled due to the coronavirus will be covered under a typical Event Cancellation policy, insured should check their policy language for specific exclusionary language. If insureds have a current inforce policy with a Communicable Disease rider there may be coverage. If you are putting on an event big or small, the best thing you can do to protect your investment and your revenue is to have the right event cancellation policy in place. Working with a producer who specializes in Event Cancellation can ensure you are aware of all of the options available in the marketplace to ensure your event investment is protected.\nContact your CRC Group Producer for more information.\n- Chris Peterson is the President of Hanleigh, a CRC Group Company, located in the Windsor, CT office.\n- Scott Lalonde is the Chief Underwriting Officer of Hanleigh, a CRC Group Company, located in the Windsor, CT office.\nFor over 35 years, Hanleigh has designed and underwritten products for high limit disability, personal life & accident, special risk contingency, and other niche insurance needs, including event cancellation. Our clients include some of the most successful professionals, athletes, entertainers, and organizations in the world.\nHanleigh utilizes a balanced approach of discipline, creativity, and industry-leading sales support, allowing us to provide insurance solutions quickly, competitively, and accurately. As an organization, we are committed to superior service within all aspects of our business and pride ourselves on experience, market knowledge, and unique, consultative strategies.\n- Economic Significance of Meetings to the US Economy, Oxford Economics for the Events Industry Council, 2019. https:// insights.eventscouncil.org/Full-Article/ArtMID/398/ArticleID/69/Economic-Significance-of-Meetings-to-the-US-Economy\n- 2019 Event Statistics and What They Mean for Your Events, EventBrite.com, January 01, 2019. https://www. eventbrite.com/blog/event-statistics-ds00/\n- Concert ticket sales revenue in North America 1990-2017, Statista.com, August 26, 2019. https://www.statista.com/ statistics/306065/concert-ticket-sales-revenue-in-north-america/\n- 2019 Business Analysis: The State of the Concert Business is ‘F**kin’ Perfect’, Pollstar, December 16, 2019. https:// www.pollstar.com/article/2019-business-analysis-the-state-of-the-concert-business-is-fkin-perfect-143035\n- Broadway Season Statistics, Playbill, 2019. https://www.broadwayleague.com/research/statistics-broadway-nyc/\n- Statistics – Touring Broadway, Playbill, 2019. https://www.broadwayleague.com/research/statistics-touring-broadway/\n- Wedding Wire Newlywed Report 2020, WeddingWire.com, 2020. https://go.weddingwire.com/newlywed-report\n- Cost of Lady Gaga’s Tour Cancellation Could Exceed $30 Million, Rolling Stone, February 15, 2013. https://www. rollingstone.com/music/music-news/cost-of-lady-gagas-tour-cancellation-could-exceed-30-million-90849/\n- Madonna Cancels London Concert Due to Injuries, But Promises 'I Will Keep Going Until I Cannot', Billboard, January 25, 2020 https://www.billboard.com/articles/columns/pop/8549040/madonna-london-concert-canceled-injuries\n- Event Cancellation: What Is A Game Worth To Your Institution?, AthleticDirectorU. https://athleticdirectoru.com/articles/event-cancellation-what-is-one-game-worth-to-your-institution/""]"	['<urn:uuid:b020bb97-023e-4309-aa6b-f630336fdd70>', '<urn:uuid:9f4a5408-b30c-4ac4-85fb-65062d22694e>']	factoid	with-premise	verbose-and-natural	distant-from-document	comparison	expert	2025-05-13T05:52:58.810667	30	60	3302
84	I work in marketing and spend way too much time searching for files - how much time could I save with Digital Asset Management software?	Digital Asset Management (DAM) software saves around two hours per day in marketing administration time by providing a centralized online hub where you can quickly search and find creative files, instead of trawling through chaotic shared drives or Dropbox.	['Digital Asset Management (DAM) software is really a business process management solution which gives you with a centralized online hub to generate, manage, share, track and discover digital assets\nEach year, a lot more than 160 million Americans watch the Super Bowl on television. Given the huge viewership, 30-second commercials are highly coveted, despite a price of $5 million per spot (excluding the expense of production). In 2018 the set of big spending advertisers included; Budweiser, Coca-Cola, Hyundai, M&M’s, Pepsi, Stella Artois and many others.\nNow imagine if the Budweiser ad featured the incorrect logo or an uncomfortable typo pointing viewers to a competitor’s website. Fortunately, this didn’t happen, nonetheless it is every marketer’s nightmare.\nA Super Bowl commercial is really a digital asset, comprised of other digital assets, including; the logo, font, images, music, video, along with other elements. Everything should be carefully were able to help tell the brand story.\nEvery day, you can find a lot more digital assets being created. Attempting to keep an eye on versions, licensing and stakeholder access is harder than ever before – and the probability of (often costly) mistakes increase.\nDigital Asset Management (DAM) software is really a business process management solution which gives you with a centralized online hub to generate, manage, share, track and discover digital assets.\nAccording to leading business software site Capterra,\n“Digital asset management software (DAM) is made to keep your media files safe and sound. Be it photographs, videos, logos, and much more, these systems seek to help keep your company’s branding materials cohesive and protected.”\nA DAM streamlines management of most files including Microsoft Office documents, video, audio, design files, and presentations. Seamless integration of one’s DAM together with your other systems ensures your DAM isn’t an island – but instead, it’s the single way to obtain cohesion for the marketing stack.\nWith a constantly increasing amount of digital files being created and found in a multi-channel environment, with out a DAM it’s an easy task to feel perpetually disorganized and lose control of brand assets. Attempting to keep an eye on asset licensing, staying along with file versions and managing stakeholder usage of assets with out a robust system set up is both difficult and costly. Haphazard asset management can result in a slew of problems which stop your marketing team from providing inspiring, on-brand marketing.\nWith a DAM, your marketing team, designers, agency partners along with other business stakeholders have uninterrupted usage of your creative files. And at exactly the same time, you have clear processes for the creative content.\nThe core of any Digital Asset Management system is the opportunity to easily seek out your digital files in accordance with metadata you assign by tagging with keywords along with other descriptors. Financial firms just the beginning of what sort of DAM could make your daily life easy. Here are a few DAM use cases:\n- Online brandhub\n- Local area marketing\n- Creative approvals\n- Manage creative jobs online\n- Order branded materials\nWith custom brand guideline pages displayed inside your DAM, not merely will your users have the ability to access brand assets such as for example logos, fonts, and images, nevertheless, you may also put your brand guidelines online, rendering it accessible and update. It’s how to help keep everyone on brand.\nLocal area marketing\nWith web-to-print templates, adjusting creative content for local markets hasn’t been easier. With easily-accessible locked InDesign templates your retailers, franchises, dealers or local markets can fine-tune specific regions of creative like location and price. Templates link back again to your DAM library so users can select their logos or images to add, if permitted. Without more clip-art surprises, you should have creative consistency across diverse markets and can save well on agency fees for local customization.\nStreamline your creative projects with workflow approvals. This implies artwork is definitely approved by relevant stakeholders before it really is distributed, and files with talent usage rights associated require download requests so that you can capture how these file are employed. With audit trails and alerts, creative approvals keep everyone on a single page for brand compliance.\nManage creative jobs online\nWith custom forms and workflow, anyone can submit an online creative brief to your marketing or design team. Briefs could be approved and assigned so that you can track the status of projects, assign designers and monitor budgets. Run custom reports on design jobs and view all key dates in a calendar view. Bid farewell to complicated spreadsheets and hello to better-managed creative processes.\nOrder branded materials\nWith a database of promotional materials, your team or sales team can simply view pricing of every item, request customizations and order easily.\nIntelligenceBank CEO Tessa Court attributes the growth in DAM usage to the clear ROI benefits, “Digital Asset Management saves around two hours each day in marketing administration time and promotes creative quality”. Other benefits include that it; enables stakeholders to ‘self serve’, avoids duplication, ensures compliance, and promotes consistency.\nThe ROI of DAM\nTo put it simply, Digital Asset Management makes your daily life easier by helping you save around two hours each day in marketing administration time. With a DAM system, you have the next tangible returns on investment.\n- Save time looking for assets — rather than trawling by way of a chaotic shared drive or Dropbox, lightning-fast search means your stakeholders can instantly discover the creative files they need\n- Enable your stakeholders to ‘self serve’ therefore the marketing department isn’t repeatedly sending out exactly the same files\n- Template customization lets shops or dealers make limited adjustments to creative files, helping you save thousands on artwork localization costs\n- Reduce courier costs by emailing links to large files to both registered and non-registered users\n- Avoid duplication of creative that is costly and time-consuming\n- Ensure creative assets are compliant with talent usage rights and copyright, so penalty fees are avoided.\nWhile they are a few of the cost great things about a DAM, ensuring creative quality is another huge advantage.\nDownload the ‘What is Digital Asset Management?’ Whitepaper to understand concerning the many features and great things about a DAM.\nThanks to Rob Weisz for sharing his viewpoint in this article. Rob may be the VP of Marketing at IntelligenceBank. He can be an experienced marketing leader, having driven growth across a variety of industries for a lot more than twenty years in Australia, the united states and UK.']	['<urn:uuid:b1e1df89-184f-464b-89ae-497014f7b143>']	factoid	with-premise	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-13T05:52:58.810667	25	39	1077
85	insects food security sustainability worldwide	Insects contribute to food security and sustainability globally in multiple ways. For developing nations, they provide essential nutrients like protein, iron, and zinc, helping address malnutrition. In places like Papua New Guinea, palm weevil larvae supply essential amino acids missing in local staple foods. From a sustainability perspective, insects are considered unrivaled as they need little space, minimal food, and multiply rapidly. In Switzerland, they are now being recognized as an efficient, sustainable alternative to animal protein, with organic insect farming operations being established.	"['NUTRITION FACTS FOR SOME COMMON INSECTS\n89-160 calories (depending on country of origin)\nYellow mealworms (100g):\nhigh source of palmitoleic acid (omega-7 fatty acids)\nAnd now for something completely different. What if, instead of relying so much on traditional sources of animal protein, with their substantial impact on the environment, we switched our focus entirely and agreed to eat more bugs?\nYes, it’s true: There is a small, but growing movement to encourage Westerners to drop their fear of creepy-crawlies and embrace entomophagy — or eating of insects. And while cricket flour or locust meat aren’t necessarily high demand items (yet), that doesn’t mean we shouldn’t at least start to explore our relationship with bugs, which are commonly consumed as sources of energy and protein in many other parts of the world.\nEating cockroaches might not be your cup of tea, so to speak, but there is a good case to be made for them: Insects are natural sources of protein, and in particular contain a full complement of essential amino acids, the building blocks of protein, in many of the same ways that animal products do. At the same time, their environmental impact is far less substantial.\nTermites are particularly rich in oleic acid, the same type of fat found in olive oil\nAccording to a study, published in 2010 in the journal PLOS One, for every kilogram of mass (basically, weight) gained, insects typically produced about half as much carbon dioxide as cattle (an average of 2,835 g of CO2 produced per kilo of mass gained for beef, vs. a range of 337-1539 g of CO2 produced per kilo of mass gained by insects), as well as significantly smaller amounts of harmful ammonia and methane gas. At the same time, insects gained weight at a faster rate than the larger animals, which means that they could be brought to market faster, and yet with less damage to the environment.\nWhile their nutritional value can vary widely from species to species, and across their lifespans, in general, insects offer protein and fat, as well as energy (calories), and some key micronutrients, such as iron, magnesium and zinc. So how many calories does the average grasshopper contain? Estimates range from 89 calories per 100 grams of raw grasshoppers native to Thailand, to 160 calories per 100 grams of home-grown Canadian red-legged grasshopper — values that are comparable to many cuts of chicken, fish, or beef. If mealworms are more your style, however, you’ll want to account for the extra calories: 100 g of mature mealworms offer up 138 calories, but their larvae are relatively rich at 206 calories per 100 g.\nBeyond calories, the protein content of insect is also on-par with meat: Yellow mealworms, for example, provide between 14 g and 25 g protein per 100 g fresh weight, while termites, locusts, and grasshoppers provide 13 to 28 g. By comparison, beef, chicken, and fish typically provide 15-26 g protein per 100 g raw weight. Insects are also typically a source of fats, and often provide essential linoleic (omega-6) and alpha-linolenic (omega-3) fatty acids. Termites are particularly rich in oleic acid, the same type of fat found in olive oil, and numerous insects, including weevils and grasshoppers, boast up to one-third of their fat content as palmitoleic acid, a type of fat known as an omega-7 that has recently been reported to improve insulin sensitivity and have anti-inflammatory effects.\nBUGS FOR ALL?\nWhile eating bugs could provide environmental benefits for the Western world, it could also be of vital importance to developing nations, where malnutrition and deficiencies in protein, iron, and zinc can be major concerns. In some cases, the essential amino acids (the building blocks of protein) in insects are used to complement other foods, such as grains, which lack some of the eight essential amino acids. In Papua New Guinea, for example, palm weevil larvae provide lysine and leucine to those who practice entomopagy — two essential amino acids that are absent in tuberous (starchy) vegetables. Termites have also been suggested as a means of obtaining key amino acids in parts of Africa where maize, which is naturally low in tryptophan and lysine, is a staple food. The movement to promote the use of insects in our diets is significant enough that in 2011, the United Nations Food and Agriculture Organization (UNFAO) published a report, “Edible insects: Future prospects for food and feed security.”\nBefore we get too excited about having crickets for dinner, however, experts caution that we must be careful to develop sustainable cultivation and harvesting methods: there are examples of human overconsumption that has led to the collapse of some insect species. With careful cultivation and further research, however, there is good reason to believe that six-legged critters and their friends could have a valued place on our dinner plates at some point in the not-so-distant future — provided we can first overcome our fear of munching on food that creeps, crawls and flies.\n— Jennifer Sygo, MSc., RD, is a registered dietitian and sports nutritionist at Cleveland Clinic Canada. Visit her on the Web at jennifersygo.com and send your comments and nutrition-related questions to her at firstname.lastname@example.org.', ""ESG: three letters, three aspects of sustainability\nLearn how to align your personal investment goals with aspects of sustainability without losing sight of the details that matter.\nInsects as food: What was unthinkable in Switzerland until recently is a reality today. With his start-up “Ensectable”, veterinarian Dr. Benjamin Steiner is causing a stir in the meat market. For this organic pioneer, mealworms, crickets and co. are the most efficient, most sustainable alternative to animal protein. And he has the support of the Swiss Climate Foundation.\nDr. Benjamin Steiner at his organic insect breeding operation in Endingen (AG). In our video, find out how this trained veterinarian is laying the foundation for “Ensectable”, Switzerland’s first certified organic insect breeding operation. © Video: Vontobel.\nSince spring 2017, Switzerland has allowed the sale and consumption of insects. The Federal Food Safety and Veterinary Office gave this the green light. However, in order for “Swiss made” insect burgers or pralinés to find their way onto Swiss plates, it is necessary to tap the most important source of raw materials, and the right crickets, mealworms or grasshoppers are not indigenous in this country. Their production still takes place almost exclusively abroad. That's what Benjamin Steiner, co-founder of the start-up company Ensectable, wants to change in the future.\nInsects are small, they need little space, hardly any food – and they multiply rapidly. In addition, their food chain does not affect the diet of us humans, in contrast to conventional livestock. From a sustainability standpoint, this makes them unrivaled in many ways: economically, socially and ecologically.\nSo are insects the long-awaited opportunity for a society that has an appetite for both meat and sustainability? In principle yes, Steiner is convinced. But first a lot of pioneering work has to be done.\n“Insects don’t eat anything we want to.”\nIt will take time before feasting on insects is as commonplace as a meal of meat or sausage. Until that day, however, everyone faces challenges: the consumer, who has to overcome his culturally influenced squeamishness and comprehend that good food can also be good for the environment; the cook who needs to come up with creative ideas in order to give these new ingredients some zest; and the producer, who has to catch up on a lot of knowledge and experience until insect breeding in this country is at the same level as livestock farming, which is centuries old.\nBenjamin Steiner, together with economist Christian Bärtsch and animal keeper Mina Gloor, got the start-up going on his parents’ converted farm, where it goes without saying that “organic” is very much part of the program. People who work with insects fear nothing as much as the insecticide residues that can be found on conservatively produced foods. That is why the young entrepreneurs from Endingen (AG) feed their insects exclusively with organic vegetable leftovers and waste as well as by-products generated in the production of organic beer and grain.\nIn the summer of 2008, Vontobel and ten Swiss companies in the services industries founded the Swiss Climate Foundation. The deciding factor was the introduction of the federal CO2 steering tax. As a result, large energy-efficient service companies such as Vontobel received more money back than the amount of tax they were required to pay. Indeed, climate protection works all the better if everyone is involved. Through the Swiss Climate Foundation, we are now donating our reimbursements to SMEs so that they can implement their own climate protection ideas.\nBenjamin Steiner is the founder and CEO of the Swiss start-up “Ensectable”. He worked for several years as a veterinarian in the canton of Graubünden before he converted his parents’ farm into the first certified organic insect breeding operation.\nOn September 2018, the start-up “Ensectable” inaugurated its certified organic mealworm and cricket breeding operation. Among other supporters, this pioneering project was made possible by contributions from the Swiss Climate Foundation.""]"	['<urn:uuid:85edd96a-8b5a-46c3-97d6-eabdfa203c47>', '<urn:uuid:9b25faaf-360d-4f28-aa30-50385464e7af>']	open-ended	direct	short-search-query	similar-to-document	multi-aspect	novice	2025-05-13T05:52:58.810667	5	84	1512
86	What are the legal responsibilities for protecting worker safety in transport operations, and how should companies approach mental health support in their organizational strategy?	Under the Health & Safety at Work Act 1974, employers must take reasonably practicable steps to protect workers' health, safety, and welfare, both on-site and during client visits. This includes providing necessary training, instruction, and supervision. For mental health support, companies need to implement a strategic approach rather than short-term fixes, including regular wellbeing audits and allowing employees to participate in job-related decisions that affect their stress levels. Organizations should create workplace cultures where people feel safe to discuss mental health concerns without fear and implement reasonable adjustment policies where needed.	['Health and safety in logistics | 5 areas of focus for 2021\nThe logistics industry vitally ensures the storage and delivery of goods around the country. It involves not only haulage and distribution but warehousing as well. However, the hazardous nature of its operations means that the industry has a high accident rate. This is partly due to the size and weight of some of the loads involved and the vehicles and equipment required to transport them.\nIn 2019/20, the Health and Safety Executive (HSE) reported the following transportation and storage sector incident figures:\n- 52,000 workers suffering from work-related ill health: musculoskeletal disorders (43%), stress, depression or anxiety (31%) and other illness (26%).\n- 11 fatal injuries to workers – broadly similar to the five-year average of 14 fatalities per year – of which 35% were due to being struck by a moving vehicle, 22% resulted from a fall from height, and 13% involved being struck by a moving/falling object.\n- 28,000 non-fatal injuries: slip, trip or fall (32%), lifting/carrying (24%) and being struck by a moving/falling object (11%).\nThe national lockdowns have seen online retail shopping and delivery boom, which has boosted logistics and warehouse operations. However, with heightened demand comes heightened responsibility – employers have both a legal and moral duty to ensure the health and safety of their employees and others.\nHauliers, warehouses and storage facilities are under immense pressure to meet increased consumer demand while at the same time maintaining a safe working environment. Indeed, the HSE’s “spot check” inspection campaign is currently focused on logistics and transport businesses, checking whether goods are being safely stored and despatched.\nWith the HSE on the warpath, consider reviewing the following areas:\nYour safety management system\nGiven the potential for spot checks, now is the time to make sure you have a robust safety management system and can demonstrate compliance.\nDo your current arrangements comply with your legal obligations? Have you reviewed your policies and risk assessments recently? It’s essential that thorough, pro-active risk assessments are undertaken and regularly reviewed. Make sure all relevant risks are covered and that a suitable person is assigned to each issue.\nHSE inspectors will want to know how you allocate certain tasks and jobs to individuals and oversee that they are being met. Do people understand their responsibilities? Do you have visibility over the safety performance of different sites? Are vehicle checks and other statutory checks up to date? In essence, can you demonstrate compliance with the regulatory requirements and guidance if inspected?\nDemonstrating compliance will improve the defensibility of any claim. Last year, Amazon found itself accused of “failing to provide a safe working environment” after a series of serious incidents were reported to have taken place at its UK storage facilities.\nOne way to guarantee compliance is by conducting a health and safety audit. While an audit can be produced internally or externally, the auditor should be independent of the part of the organisation being audited. Whichever approach is taken, it must be led by a “competent person”.\nHow we can help\nIf you’re not fully confident that you have everything covered, our Health & Safety specialists can take a systematic look at your workplace and current arrangements, identify any areas where you fall short, and get you to where you need to be.\nAnd, if you’re looking for a simple way to stay on top of compliance on a daily basis, our market-leading software, MyH&S, allows you to see the risk status of multiple sites in real time, lets you assign responsibility for tasks, and provides paperless evidence of compliance.\nEmployers have a legal responsibility to provide staff with the necessary information, instruction, training and supervision relating to their role. When was the last time you revisited staff training needs? Is it time for a refresher? Has the increased consumer demand seen you take on more workers, and have they all had the requisite training to do their role safely?\nIt’s vital that all new staff receive training and existing staff are kept up to date with evolving safety culture and procedures. Increased warehouse health and safety knowledge will bring about greater observance of best safety practices.\nOne unprecedented challenge right now is COVID-19. Can your workplace operate within the social distancing two-metre plus rule? If not, it may be reduced to one, but you are obligated to provide training on the new procedures to operate within one metre.\nHow we can help\nIf you struggle to find time for training, our remote e-Learning courses are a convenient solution. With e-Learning, workers can complete courses in their own time, at their own pace, allowing you to continue to meet your responsibilities with minimal disruption during this hectic period.\nCourses include Accident Reporting (RIDDOR), Manual Handling, Safe Movement of Vehicles, Lift Truck Safety, COVID Response and more.\nVisiting client sites\nThe Health & Safety at Work etc Act 1974 says every employer must take “reasonably practicable” steps to protect the health, safety and welfare “at work” of all their employees. “At work” doesn’t just mean in the workplace – the required protective steps extend to occasions when your employees visit other locations and client sites.\nThe duty to protect workers both on and off site is more important than ever due to COVID-19. Have you got the right procedures in place and are they working as intended? For example, do your workers perform proper safety checks before and during client visits? If not, you will be falling short of requirements.\nDo you need support?\nSpeak to us for an honest, no obligation chat on:\n0345 226 8393 Lines are open 9am – 5pm\nSimilarly, are you protecting lone workers from health and safety risks? Supply chains have been strained by the changing economic lockdown circumstances and the surge in online retail business has increased the numbers employed in logistics and supply chain roles. However, many SME logistics firms will likely have employees, in a variety of roles, working frequently alone or remotely.\nWhat’s more, often awkward shift patterns necessitate workers operating out-of-sight of, or at different times, from colleagues.\nHave the risks associated with working unsupervised been carefully assessed? Have you implemented sensible precautions to reduce those risks? We discuss the steps you can take to manage lone working risks here.\nHow we can help\nWe can offer practical advice on precautionary measures, ensure you have an effective lone working policy in place, and provide e-Learning training for employees and managers to raise awareness of risks, controls and responsibilities.\n‘Basic’ everyday risks\nSlips trips and falls, manual handling, load security and safe vehicle movement are part and parcel of good health and safety management in logistics. While COVID-19 remains a clear focus, it’s important that COVID risk management doesn’t detract from all other ever-present and inherent risks present in your environment.\nBy its very nature, the logistics industry exposes workers to a wide variety of risks: not only accidents on the road and deaths and injuries resulting from unsafe forklift use but also the consequences of poor fire safety, long-term health risks due to poor manual handling techniques, and problems relating to mental health. Thousands of such incidents occur every year.\nAs an employer, you are legally required to protect the overall health, safety and wellbeing of employees and others, and COVID-19 hasn’t removed other statutory health and safety obligations that normally fall upon you. This means continuing to identify all hazards within your workplace and taking steps to control the risks arising from those hazards.\nFor example, forklifts are essential to logistics operation but pose a significant threat to workplace safety, accounting for 25% of UK workplace transport injuries. Where staff and machinery operate in close proximity, maintaining situational awareness is critical. Cost permitting, minimise the risk of collision through proximity warning and alert systems, 360° cameras, active RFID tags and other interactive equipment.\nNeed a helping hand?\nTime pressures, lack of resources and the temptation to cut corners, especially during busy operating periods, often leads to neglect of proper safety practices. However, breaches can mean a fine of up to £20,000, and for serious breaches that endanger life, fines are unlimited. In the transport and logistics sector, fines have reached £4 million, and in the most serious of cases, employers also face imprisonment. Of course, there’s also the added risk of civil claims and the reputational damage to your business.\nSupport from Ellis Whittam can help to dramatically reduce risk to your business and your people, give you the confidence in your compliance, and ultimately enhance productivity and efficiency by promoting a positive safety culture. If you would benefit from access to a named Health & Safety specialist, who will work with you to raise standards and keep you on the right track, call 0345 226 8393 or request your free consultation using the button below.\nSign up for the latest news & insights\nLatest News & Insights\nBLOG 2021 is being dubbed the year of ‘The Great Resignation’. Employees are burned out, fed up and craving change, and as a result are\nBLOG Written by Rachel Holding on 9 November 2021 When faced with employee issues, your employment contracts can either protect your interests or put you\nBLOG Written by Ed McFarlane on 2 November 2021 All employers must take care to avoid unlawful discrimination when dismissing employees. If you dismiss a disabled\nBLOG Written by Alexandra Farmer on 1 November 2021 With normality returning, many organisations have made the decision to roll out remote and hybrid working on a\nBLOG Written by Laura Cheng on 1 November 2021 Hormone surges caused by menopause can have a significant effect on women’s physical and mental health.\nBLOG When you think about workplace health and safety, your probably think about protecting your workers. However, under Section 3 of the Health and Safety at\nBLOG By now, the long-term effects of COVID on the modern workplace are clear. Most notably, a precedent has been set for remote and hybrid', 'Addressing mental health in the workplace\nThis article is available in Arabic.\nMental health is a topic that’s been increasingly on the rise, especially after the last two years where people had to undergo many changes caused by the Covid pandemic. The effects of uncertainty, lockdowns, confinements, isolation and stress came trickling down on people, creating an unprecedented wave of challenges, mainly on their health and wellbeing.\nAccording to Our World in Data, 792 million people – roughly 11 percent of the world population – suffer from mental illness. Depression and anxiety disorders are the most common. This percentage is much more prevalent in Arab countries, where it averages nearly 30 percent. As the youth population ages, they will have unprecedented mental health needs to cope with dementia, for example. The Arab Centre Washington DC states that dementia cases are estimated to increase by 400 percent in the Middle East and North Africa (MENA) region by 2050.\nThis is particularly alarming in a region where mental health is still highly stigmatised, especially in the workplace. Today, people with mental disorders still seek informal ways of inquiring about mental health for fear of being marginalised by their surroundings, or fired from their jobs. Moreover, studies reveal that low perceived need for treatment has been shown to be a greater barrier to seeking treatment than has stigma.\nThis status quo has started to slowly shift, mainly due to the global conversation happening around mental health. People, experts and companies are breaking the taboos and initiating actions aimed at shedding light on mental health and treating it like physical health. At the workplace, the conversation is driven by employees and candidates asking the questions and expecting answers. And while organisations in the Middle East have a long way to go on this journey, leadership is sitting up and listening.\nAccording to Professor Sir Cary Cooper, ALLIANCE Manchester Business School. and co-author of Managing Workplace Health and Wellbeing During a Crisis and Remote Workplace Culture, many companies are now seeing mental wellbeing of employees as a strategic issue. They do regular wellbeing audits and plan strategies to deal with it at the level of senior leadership teams.\n“You find companies like the global construction company MACE doing regular wellbeing surveys with all their employees, finding out what the problems are and intervening to sort them out. The Director of Health and Wellbeing explores with the SLT whether the interventions work and contribute to employee health and bottom line indicators. This strategic approach is increasing in many sectors from finance to manufacturing to the public sector,” he states.\nFor instance in the UAE the government is regularly undertaking new measures to address mental health issues and reduce the stigma associated with them.\nSo how can companies in the Middle East start embracing mental health in the workplace?\nThe US Centers for Disease Control and Prevention clarifies that the workplace is an optimal setting to create a culture of health because:\n- Communication structures are already in place.\n- Programmes and policies come from one central team.\n- Social support networks are available.\n- Employers can offer incentives to reinforce healthy behaviours.\n- Employers can use data to track progress and measure the effects.\nGoing for long-term fixes\nMany organisations are trying to go for short-term fixes. However, the shift needs to happen more strategically. More importantly, companies need to understand that the return on most initiatives will not happen overnight – and this is exactly why change needs to be embedded in a company’s strategic approach to employees’ health and wellbeing.\nIt starts by asking the basic questions of ‘why should work make people sick?’, ‘how do we create a workplace where people are purpose-driven?’ and ‘how do we embed health programmes that promote mental health and wellbeing?’\nDr Carolyn Lorian, Head of Clinical Transformation at SilverCloud Health, explains that this will help organisations understand how they will address the actual root causes associated with diminished employee mental health – whether that is the direct nature of the work (e.g. physical environment) or the indirect ways of working (e.g. resourcing challenges, lack of processes or change management).\nShe says that while many organisations are taking steps to improve employee mental health by putting in place a mental health strategy and increasing investment in various initiatives, fewer organisations have successfully translated this into a culture that positively impacts mental health. While a great first step is to build employees’ awareness around mental health, they also need to be considering a number of different top-down and bottom-up factors in order to enable a positive cultural shift.\nEven if companies haven’t started implementing effective strategies, taking small measures is a great leap forward. It will allow employees to take notice of the efforts that are being deployed. “It goes without saying that by offering mental health and wellbeing provisions as part of their organisation benefits, an employer shares a simple but important message that they care,” states Carolyn.\nCreating a suitable workplace culture\nAccording to the Mental Health Foundation: “When we create workplace cultures where people can be themselves, it is easier for people to speak about mental health concerns without fear, and easier for them to reach out for help when they need it. Even so, the decision to disclose distress at work is not one people take lightly. It is vital that workplaces become environments where people feel safe to be themselves.”\nThis implies that employees need to be open-minded and accept the experiences and feelings of colleagues. This also means that the workplace needs to similarly adapt, so that employees can enjoy some relaxation activities, or even some time off within their regular working hours.\nRe-centring job-related decisions\nOne very efficient measure a company can implement is to allow employees to participate in decisions pertaining to their jobs. Let them identify which tasks or issues are causing them stress, and what are the possible scenarios they could implement to be least impacted by that stress. Sometimes solutions are much simpler than they would appear at first. It could be to work in a team on a specific project or to get training in a field where they feel they lack some skills.\nDr Carolyn Lorian suggests that companies can indeed empower teams and groups to develop initiatives that are aligned to the overarching wellbeing strategy but are adapted to their unique needs.\nOnce employees are actively participating in shaping their jobs, they set better expectations for themselves and for their managers, and can better manage the stress that might arise from the work environment.\nApplying reasonable adjustment policies\nLast, but not least, workplaces need to have reasonable adjustment where needed. This is important in levelling the work conditions, so that people are not hindered by their mental health state to work on their tasks. Barriers that prevent them from performing their jobs need to be removed, for the ultimate goal of having an inclusive workplace where every person can easily thrive and achieve their full potential.']	['<urn:uuid:b496fbcd-d255-4615-a5a4-0d103cdbb2d8>', '<urn:uuid:530a1e28-5e11-426f-b071-f8de98acdbea>']	factoid	direct	verbose-and-natural	distant-from-document	multi-aspect	expert	2025-05-13T05:52:58.810667	24	91	2840
87	What happens in music studios, and how do artists improve tracks?	In professional music studios, artists work with high-quality equipment and mixers to enhance sound quality and make tracks sound more organic and wider. The improvement process involves careful filtering of unwanted frequencies, strategic use of effects and synthesizers, and mixing different sonic elements. Artists develop tracks by testing different arrangements, combining various parts over days or weeks, and working on multiple tracks simultaneously until achieving the desired sound quality.	['Music | Bittles’ Magazine: The music column from the end of the world\nIn the over-saturated world of electronic music it takes a lot to stand out from the crowd. Yet, this is something Berlin duo Soukie & Windish manage with ease, ably injecting a sense of melody, humour and personality into everything they do. So, if you ever start to feel as if you can’t take another rigid 4/4 beat, faceless techno loop, or by-the-numbers bassline, then the music of Fritz Windish and Nayan Soukie could well be the cure you seek. With releases on labels such as Liebe Detail, Audiomatique and Connaisseur to their name, their signature sound is rich, emotional, groovy and deep. By JOHN BITTLES\nThis May Soukie & Windish make a very welcome return with the loose textures, playful melodies, and spacious grooves of their sophomore album Loom. Tracks such as Jaglion, St. Tropitz, Heads Up My Dear and Dexter’s Vertigo seem to, almost, leap out of the speakers, daintily perching themselves on your knee, and singing the type of random nonsense you always wanted to hear. Deep, focused and melodic, the record finds the duo creating nine long, spacious tracks which don’t so much seduce the listener as make a true believer of them. Perfectly mixing the downbeat, the banging, the beautiful and the strange, Loom is one of those rare things, a house album you simply have to listen to from beginning to end.\nWith the record having been on repeat rotation on my headphones these last few weeks I was curious to know a bit more about the creators of these songs. In the following interview the duo discuss Loom, their record label URSL, how they met, touring and lots more. And, if you desire a funky-assed soundtrack for your reading needs then I can heartily recommend these snippets of Loom.\nBy way of introduction, can you tell us a bit about who you are and what you do?\nSoukie Windish – Berlin – ursl – techno\nYour new album Loom is out on the 13th of May. Why do we all need it in our lives?\nI think there is no music that everybody needs, it’s for people who like pads and great spaces. Our album has a really special mood, it’s mysterious, ghostly and warm music. LOOM is really a good soundtrack for a big city street, or Berlin’s‘ dirty subways. It contains deepness and melody without being cheesy at all.\nIf you had a stall in Camden Market to sell the album what would your pitch be?\nThe original painting of the artwork Another Fool On The Hill by Michael Conrads in the background, it’s massive and very impressive. Friendly selling people in elegant shabby clothes. Some stations with headphones. A lot of candles.\nWhat part of Loom are you most proud of, and why?\nWe love the part, when in St. Tropitz the bass starts, it’s perfectly introduced and when it comes it’s exactly how it has to be!\nFitzroy is a lush and evocative opener, its hushed bass pads and mournful strings conjuring vivid mental images. When you were working on it did you always know it was going to be the album’s opening track?\nNo, we discussed the track listing for a long time. It could have been also St. Tropitz, because it takes a long time to start. Or Dexter’s Vertigo. This tracklist was the first intuitive order and in the end we decided to take it, because it’s the best order for listening to all tracks together in one chain.\nOne of the early highlights for me is the slow-build synth drama of St. Tropitz. Can you tell us a bit about how this track came about?\nThat’s a hard question to answer. We always start with an idea, (which we) present to each other, if we both like it we develop it further. After a while we start an arrangement and figure out if the track works and how we have to combine the parts. We started to develop the ideas in Australia, so we had no analog synthesizers there; we tried out the Ableton push controller a lot. The staccato grove of the samplesynth is a typical sound of the controller combined with Ableton, simpler and lfo. The other hornsound is a cheap digital modular synth which is amazing for one typical monophonic sound.\nSo mostly we work like this: Nayan starts to program the arrangements, while Fritz jams with his stuff to the different parts; if something sounds great on special parts, we record it. If we like the work, we open the project again and again over days and weeks till we are finished. We produce always on different tracks at the same time and switch between them.\nSongs such as Jaglion, Cable Gardens and Head Up My Dear are gorgeously deep and will work wonders in any club. What’s the secret to creating depth in your tracks?\nThe secret is simply one’s taste, ears and experience in sound. We are working together for such a long time and know which atmosphere we want to create. To choose the right synths and samples are very important when you start a track or an idea!\nThe final mix-down for the album was done at Tobi Neumann’s Riverside Studios in Berlin. In what ways did working in this studio affect your sound?\nThe super good equipment and a good mixer makes everything sound better. And it helps you so much to decide which sound is really needed and which is not, when you really hear it. Its hard to explain but of course it sounds more organic and bigger, wider. That was our wish: to make the album sound great and not to sound pumpy.\nAre you planning on touring the album at all?\nYes, full on. Here are some dates… UK is still missing ;-)\n14.05. Sektor Evolution, Dresden\n20.05. Rote Sonne, München\n28.05. Kater Blau, Berlin\n04.06. KB18, Kopenhagen\n10.06. tba, Stockholm\n11.06. Open Air, Stockholm\n17.06. Zukunft, Zürich\n18.06. Sonar, Barcelona\n30.06. Fusion Festival, Lärz\n02.07. Midnight Sun Festival, Lofoten\n09.07. Rockefeller Music Hall, Oslo\n11.07. Jaeger Oslo?\n15.07. Dockland, Münster\n16.07. Greenwood Festival, Kiekebusch\n06.08. Garbicz Festival, Garbicz\n12.08. 3000 Grad Festival, Feldberg\n13.08. Wilde Möhre Festival, Spreewald\n19.08. Dockville Festival, Hamburg\n20.08. Bahnwärter Thiel, München\n03.09. Hangar 11, Winterthur\n17.09. Dr Vogel, Osnabrück\nDo you have anything special planned for this?\nFor this tour we are doing our DJ back 2 back set, with outboard effects and sounds. But we are currently working on our live set and do shows only on special request. No big stages, only venues where we feel very comfortable and where the sound and the crowd fit to us. We want to develop a real live set which we can play over years and develop it constantly. We want to put the best parts of our productions over the last years together and improvise with them, to avoid to get bored after one tour and it must work more like a flexible DJ set.\nThe album is released on your own label URSL Records. What made you set up your own record label?\nThe first impulse 5 years ago, was that the Bachstelzen from Fusion Festival wanted to start a label and Sebo & Madmotormiquel contacted Fritz, who had already some experience managing the labels from Stephan Bodzin and Oliver Huntemann back in the days. We wanted to give our Artist network a platform to release their music. URSL is constantly changing, we are not a concept label. We are releasing music that we like, it can be slo mo, pop, electronic, or banging techno. We go with the flow of our artists.\nWhat have been the key releases for the label so far?\nOf course our first album A Forest which was also the first LP on URSL, then we had last year the debut album from Nico Stojan, Twisted Manners. Our EP series are very diverse, but we are underground music and never had a real hit on our label so far. Everyone should check our back-stock and will find nice stuff from: Schlepp Geist, Krink, Lake People, NU, Mira, Chris Schwarzwälder…\nWhat can we expect from URSL Records in 2016?\nRight now we have the remix package from Nico Stojan’s album with remixes from, Thugfucker, Adana Twins, Guillaume & Coutu Dumonts for example. Krink is coming up with his new EP Transit. A solo release from Nayan Soukie and our compilation series URSL Superhits…with very special tracks.\nAlso check out our sub-label URS for some really experimental and more darker techno experience.\nYour first EP came out way back in 2008. How did you two first meet and what made you decide to work together to create music?\n2001 in a bar in Bremen, where we both studied.\n“Hey what is your name?”\n“What is this for a shitty name!”\n“So what is yours then?“\n“People who live in glass houses should not throw stones”\nShortly after, Nayan moved into Fritz‘ community student house, Nayan producing Hip Hop, Fritz singing Reggae…but in separate rooms :-). Fritz spent some time in Argentina and experienced his first raves, Nayan did the same in Bremen in illegal warehouse parties. Back together we started off location parties, we got into the music and then played the warm up sets. The next step was our own floor at Fusion Festival. The production started in between in bathrobes and Prosecco in our living room. Slowly and constantly, learning by doing.\nYou started out as DJs. What is the secret to rocking a club?\nGet there before, feel the dancefloor, have some shots…loads of water. Secret weapons, edits and own productions combined with live delays and reverbs!\nWhat five records are working for you right now?\n- Konrad Black – Scorched Earth (Barac Interpretation)\n- Orlando Voorn – Gain Upwards (Efdemin Remix)\n- Kotelett & Zadak – Nova Zembla (dub version)\n- Kontext – Gazotron (B Lous Remix)\n- Dj Aroma – Beautifooled (Soukie & Windish Remix)\nDo you have any final words for our readers?\nA party is just a party is just a party. Take good care of each other and love the music not the hype.\nLoom is available to buy now in all good download stores and record shops. Trust me, if you haven’t heard it yet, then you are missing a treat.\n| JOHN BITTLES\n| Photos: DAVID ULRICH', '- Band Management\n- Home Recording\n- Live Sound\n- Best Instruments\n- New Music & Video\nCut The Crap: What is a Filter & Why is it Your Most Important Mix Tool?\nWelcome to the wonderful world of music mixing! Your assignment today is to make everything sound great: huge drums, pounding bass, roaring guitars, thunderous synths, and captivating vocals. Sound easy? It’s not. You’ll know it’s not that easy when you push up all the faders and instead of sounding like a radio hit, what you’ve got sounds like a tiny little…demo.\nThere are many factors that go into taking the raw tracks and unifying them into something polished, moving, and engaging. Over the next few months we’ll talk about many of these elements. Today, we’re gonna talk about garbage: sonic garbage, not the band Garbage.\nAs I think about it, sonic garbage comes in two forms: The first kind is the low frequency rumble, noise, hum, whatever, that’s always present in recorded tracks. The source may be the room, or an amplifier, or the output of a synth. Yes, even samples may have junk down there! When you put up all the tracks, all the gunk adds up, and makes a cloudy, messy low-end. If your kick or bass sounds great in solo, but seems small or wimpy in the mix, likely it’s getting stuck in the muck.\nThe second sort of garbage comes from the normal sound of the instrument, but the parts that you don’t need. This is, of course, rather subjective, but if you are willing to cut away garbage sound, you will allow other elements to shine. For example, electric guitars, particularly the more they’re distorted, eat up the entire sonic spectrum. They can put out 100Hz to 8KHz, leaving no room for any of the other elements we listed above.\nI’m sure you’ve had the experience of getting the drums, bass, and vocals to sound perfect, and then you bring in the guitars, and suddenly everything goes to hell. This is where style, taste, and genre come into play. You have to decide which elements are key in which frequency ranges. Much of that furious guitar isn’t helping the song! Cut it away.\nFilters are the simplest element of an EQ. You’ve probably spent some time with EQs before, boosting or cutting frequencies to shape your sound. Likely, however, you’ve overlooked the filter section that is often built into the more complex EQ. Often labeled High Pass Filter (HPF), this simple band has a slope that more or less steeply approaches –inf (minus infinity, aka no sound passing). This is the simple tool for cutting away the gunk.\nGenerally, for simple filters I will use a plug-in, even though I typically do most of my processing in the analog domain. For filters and other surgical tools, I just find plug-ins to be more precise. In FIGURE 1 I’ve shown a basic filter in Avid’s EQ3 that I use often. Remember this isn’t intended to augment the sound, but rather to transparently remove elements that are getting in the way.\nNotice, first, that I’ve set the plugin to “HPF” using the button on the left shaped kinda like a square-root sign, but is actually a mini graph of the filter. Next, I typically turn the filter Q knob fully clockwise to 24dB/oct. This makes the slope of the filter as steep as it can go. Sometimes you’ll want a softer slope, but most of the time a steep filter is good. In the analog world steep filters can introduce phase shifts that can, themselves, muddy your work; properly designed plug-ins, however, avoid this issue.\nNow we begin to cut. If we’re looking to remove super low garbage from a kick or bass, aim really low, around 20-30 Hz. But wait, you say. No one can hear that low! A few of us can hear down there, but more importantly, the gear can hear down there – a speaker on which you or your audience listen will try to reproduce those frequencies causing distortion. It will react to signal even if we can’t hear it. For example, if you run that super low junk through a compressor later in the mix, you will find that the compressor reacts to that super low stuff, not to the audio you want to affect.\nWith instruments that live higher in the spectrum, you can start to cut higher. I often start around 100Hz. This works for guitars, vocals, snares, and synths. But here’s the key: you’ve gotta do this by ear, and with the whole mix going. If you do this in solo, you’ll fool yourself! So turn it all on, and then slowly raise the frequency of the HPF until you just start to hear the instrument changing. Stop and roll it back just a touch, and there you have it: bye bye garbage!\nNow that the low frequency garbage is gone, let’s think about the second type, the parts of the instrument that you don’t need. First, we rolled off the low frequency on the guitars only until they started to change tone; now, maybe we want to change their tone for the good of the song. At this point we have to consider what other instruments are sharing in the same sonic space and which are most important in each frequency range.\nFor example, maybe we rolled off the guitar to 200Hz but the guitar is still crushing the snare, or fighting with the bass. Try rolling off the guitar up to 400Hz. Did that kill the guitar or increase clarity? If it killed the guitar, you’ll need to roll back down to 200Hz, and consider another band of EQ to carve a smaller amount away from the guitar at 400Hz. These frequencies are just examples, you’ll have to do this by ear.\nOnce you understand that it’s the junk that leads to muddy mixes, you can see the solution. Grab your trusty filter, your most valuable tool, and carve your way to clarity.\nABOUT THE AUTHOR\nAward winning mix engineer and producer Jordan Tishler runs Digital Bear Entertainment in Boston. With a large Augsburger designed mix/overdub room with SSL console and racks upon racks of analogue outboard gear, tape machine, and gazillions of instruments, Tishler has credits including B Spears, JLo, Iggy A, MOTi, Justin Prime, SIA, and London Grammar. Contact me about producing your next record, or mixing the one you’re working on now! Fore more visit www.digitalbear.com.']	['<urn:uuid:0240d368-e7c4-4bfb-b868-9fd8ae341a9a>', '<urn:uuid:728b33bd-3bba-4358-bd7e-c0e2710d7405>']	open-ended	direct	concise-and-natural	similar-to-document	multi-aspect	novice	2025-05-13T05:52:58.810667	11	69	2834
88	What exactly was the Copper-Stone age and why was Tell Zeidan an important settlement during this time period?	The Copper-Stone age was a significant historical period when people first invented metallurgy. Tell Zeidan was a major settlement during this era, possibly one of the largest Ubaid temple towns in northern Mesopotamia. The site was strategically located at the crossroads of major trade routes along the Euphrates River valley. This period marked important developments including the first widespread irrigation agriculture, centralized temples, powerful political leaders, and the emergence of social inequality as communities became divided into wealthy elites and poorer commoners.	['By William Harms\n“ This is a remarkable opportunity to learn about a culture that really laid the groundwork for urban civilization”\ndirector, Oriental Institute\nArchaeologists longed to study the mounds in northeastern Syria, knowing they could hold clues to the origins of writing and specialized crafts. The opportunity was apparent to Gil Stein, Director of the Oriental Institute and an expert on early Mesopotamian cultures. In 2008 the Syrian Directorate of Antiquities approved the start of a joint Syrian-American excavation project at Tell Zeidan, led by Stein.\nThe complex project already is yielding discoveries, including stone seals that hint at a sophisticated system of trade and a hierarchy of social status.\n“This is a remarkable opportunity to learn about a culture that really laid the groundwork for urban civilization,” Stein says. “We hope our joint team will conduct long-term excavations and expose the full range of neighborhoods, activities, and public and private architecture on the site.”\nPotential to Revolutionize Understanding of Civilization\nThe site was at a critical junction of the Balikh and Euphrates rivers in ancient Mesopotamia, home to a people who began organizing communal life and inventing technology before full urban civilization emerged. Smaller sites exist from this culture, known as the Ubaid, but because the area was unoccupied starting about 4000 B.C., the prehistoric strata of Tell Zeidan are immediately accessible beneath the modern-day ground surface.\nAmong the first scholars to recognize the site’s potential importance was the famed British archaeologist Sir Max Mallowan, the husband of writer Agatha Christie. Now, researchers around the world are watching with keen interest as the international team begins to reveal millennia worth of mystery.\n“Because of its size and depositional history, Zeidan offers a historical opportunity to learn more about the Ubaid period than has been heretofore possible,” says Guillermo Algaze, Professor of Anthropology at the University of California, San Diego, and a specialist on the emergence of urban centers in the Middle East. “Accordingly, Stein’s work at this unique site has the potential to revolutionize current interpretations of how civilization in the Near East came about.”\nEngimatic Period Known As ‘Copper-Stone Age’\nThirty-one acres in extent, Tell Zeidan lay at the crossroads of major trade routes across ancient Mesopotamia that followed the course of the Euphrates River valley.\nStein says Tell Zeidan may have been one of the largest Ubaid temple towns in northern Mesopotamia, and that it was as large or larger than any previously known contemporary Ubaid towns in the southern alluvial lowlands of the Tigris and Euphrates rivers in present-day southern Iraq.\n“This enigmatic period saw the first development of widespread irrigation agriculture, of centralized temples, powerful political leaders, and the first emergence of social inequality as communities became divided into wealthy elites and poorer commoners,” says Stein.\nThe era when Tell Zeidan flourished is known as the “Copper-Stone age,” since it was when people first invented metallurgy. The copper artifacts being found at Tell Zeidan provide a window into how the people there obtained raw materials and used them in everyday life.\n“Understanding developments that took place in ancient Mesopotamia during the Ubaid period is absolutely essential if we are to gauge the magnitude and tempo of the social transformations that eventually culminated in the origins of cities and states in the ancient Near East in the fourth millennium B.C.,” says Algaze, who is an outside expert not involved in the project.\nExcavation Shows Evidence of Social Elite\nStein is the American co-director of the Joint Syrian-American Archaeological Research Project at Tell Zeidan, and Muhammad Sarhan from the Raqqa Museum in the nearby provincial capital of Raqqa is the Syrian co-director. Stein says the two-millennium-long occupation at Tell Zeidan spans four key periods: two phases of the late Copper Age on top, the Ubaid period in the middle, and the Halaf period at the bottom.\nThe new excavations reveal the emergence of an elite that possessed the political power necessary for communities to move from self-sufficient village life to societies dependent on trade and capable of acquiring luxury goods, Stein says. The wealth of the community came from irrigation-based agriculture, trade, and manufacturing.\n“One of our most remarkable finds was a stone stamp seal depicting a deer,” he adds. The seal was unusually large, about two inches by two-and-a-half inches and was carved from a red stone not native to the area, but was similar in design to a seal found 185 miles to the east near Mosul in northern Iraq. The seals were used as stamps to indicate possession of goods in the period before writing.\n“The existence of very elaborate seals with near-identical motifs at such widely distant sites suggests that in this period, high-ranking elites were assuming leadership positions across a very broad region, and those dispersed elites shared a common set of symbols and perhaps even a common ideology of superior social status,” Stein says.']	['<urn:uuid:2dbc2969-8d06-4936-a019-41963c20fd22>']	open-ended	direct	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-13T05:52:58.810667	18	82	815
89	I've heard different things about composting dairy and meat - some say never do it, others say it's fine. How do both home composters and professional facilities handle these items, and what's the real story about whether they work or not?	The truth is that dairy and meat can be effectively composted, despite common myths. For home composting, the conventional rules banning dairy and meat products are unnecessary limitations. As demonstrated by an example where powdered milk enriched soil and promoted grass growth, dairy products can actually benefit compost. For professional facilities and workplace composting programs, dairy, eggs, and meat (both raw and cooked) are regularly accepted and successfully processed. The difference lies in the setting - while city programs openly welcome these materials, home composting guides often discourage their use due to outdated beliefs rather than actual composting science. The prohibition of meat and dairy in home composting represents what's been called a 'triumph of theory over experience,' where rules are followed without practical justification.	"['The History of Composting in Americatags: composting\nComposting first appears in the historical record of what is now the United States in 1621, when Squanto showed the ""Pilgrims"" how to put a fish in each corn hill, so the maize and squash would thrive. Even that statement is contested, however. Some Wampanoags today say their ancestors never dedicated entire fish to the role of fertilizer; they only used the skin and guts. Some historians agree. I think the primary sources got this one right, however, partly because Pilgrim authors were hardly squeamish about discussing blood and guts, had that been what they had used for fertilizer. As well, when the little fish -- variously called ""alewives,"" ""herring,"" ""menhaden,"" ""pogies,"" and ""shad"" -- came upstream in the spring, they were so plentiful as to be catchable en masse. There was no need to save and savor their edible parts.\nMoreover, the languages themselves offer evidence. Narragansetts called the fish ""munnawhatteaûgs,"" which means ""fertilizer"" or ""that which enriches the land,"" a word the English corrupted into ""menhaden."" The Abenakis of Maine called them ""pauhagens,"" which also means ""fertilizer,"" a name the English shortened to ""pogies."" i\nLike dogwoods further south, ""shad blow"" trees flower before their leaves appear. Their blossoms signal that the shad (or menhaden or alewives...) are running in nearby creeks. They were incredibly numerous. Not only the Pilgrims (and of course Native Americans) used these fish as fertilizer. So did farmers on Long Island, for example, at least as late as the early nineteenth century. In the second half of that century, menhaden oil outstripped whale oil as an American and worldwide industry. Even today, American fishing boats catch more menhaden than any other species. ii\nSquanto was the first compost expert that European Americans consulted, but he was far from the last. In the twenty-first century, composting has become a pastime if not an art form. All kinds of people proclaim themselves experts at it and advisers on how to do it. Unfortunately, and unlike Squanto, many folks today don\'t know what they are talking about.\nOne such authority held forth on NPR not long ago. Asked if she was a purist who only made vegan compost, she replied, ""Oh, no."" She included ""crushed eggshells,"" she went on, although she always rinsed them out first. Presumably unrinsed eggshells might offend the maggots, bacteria, worms, and larvae that convert table scraps to compost.\nAt our house, we put everything in our compost. Well, almost everything. No bones, except fish bones -- they take too long to break down. No industrial ""food"" (like Coca-Cola).\nHouse guests are horrified. ""You put milk in your compost?"" one asks, as I rinse my cereal bowl and put the results in the compost can.\n""What do cows eat?"" I reply. ""Ashes to ashes and grass to grass.""\nThey remain unconvinced.\nOur current composting mythology is a triumph of theory over experience, or rather, of theory over lack-of-experience. Those who follow the vegan rules wind up with compost, to be sure -- a bit inferior to mine but perfectly useful. Thus they are confirmed that the vegan rules are right. Those who simply make compost out of everything don\'t often write about it.\nThe compost rules include:\n-- turn it (""ideally every day or two,"" according to ""Compost A to Z"");\n-- layer green and brown (""the brown and green components should be layered throughout the bin,"" according to ""Composting Rules"" at E-How.com);\n-- ""avoid fruit as it will tend to attract fruit flies"" (ibid.);\n-- ban cooked food (""can attract vermin and should not be home-composted,"" according to Garden Organic, ""the national charity for organic growing"" in the U.K.);\nand of course\n-- no ""oils, grease, lard, meat, bones, fish, dairy products..."" (typical municipal composting ordinance).\nAges hence, historians of family life will look back on all these rules with wonder. Staffs at historic houses of the late twentieth century will show open-mouthed visitors kitchen shredders with ""super-robust crank arms"" for ""pre-composting,"" special plastic bags that consumers bought because they would break down right along with the compost placed inside them; and ""Tumbling Composters"" to ensure that the top and bottom of the pile all compost evenly.\nThe butter churns and chestnut roasters that furnish historic nineteenth-century kitchens embody skills most of us have lost. These twenty-first-century items are just the opposite: they exemplify no skills, indeed, no understandable purpose. ""People bought rotators for their compost?"" visitors will ask, wide-eyed. ""They pre-shredded their garbage for the worms?"" The loss of common sense from one century to the next will be palpable.\nPossibly, like the future anthropologist who wrote ""Body Ritual among the Nacirema,"" iii historians of the future may conclude that the compost movement was a religion. They will discover uniform clothing worn to annual days of sacrifice like ""Earth Day"" -- such as T-shirts saying ""A rind is a terrible thing to waste"" and ""I heart composting."" They will note that after every meal we performed a thanksgiving ritual, giving a portion of our food to the compost god at its kitchen shrine. They will learn that we took the temperature of our compost pile as if it were alive and sought professional advice if it was ""too hot"" or ""too cold."" iv We gathered at community colleges and garden stores to listen to experts lecture on composting.\nTo thwart such misperceptions, historians need to get busy now, writing the history of compost for ages hence. ProQuest lists some 219 theses and dissertations with ""compost"" in their titles. Not one is in history, American studies, cultural studies, or any related field. Considering all the dissertations on food, cooking, and eating, it is surprising to find not one on our treatment of uneaten food.\nThe sheer volume of expertise on compost is enormous. 216 of ProQuest\'s 219 dissertations and theses turn out to be in biology, plant and soil science, and similar fields. v They bear titles like ""Suppression of Rhizoctonia solani and its interaction with Trichoderma hamatum in bark compost container media."" Then another massive industry popularizes these findings for the public. Rodale distributes one tome, Compost Gardening, that runs 350 pages long; each page is 8 1/2"" x 11"" and has two columns. Among its suggestions: sift your compost, so it looks better, and because ""sifting compost is fun."" vi\nSifting compost is not fun, however. Therefore, the main impact of these composting rules, gadgets, and books is to deter composting, except among those in desperate need of a time-consuming hobby. Even among the faithful who don\'t give up, the rules deter composting of about half of the stuff that could be composted. That\'s too bad, because composting is good for the planet. It\'s surprising, how much stuff can go into a compost heap and how compact the dirt is that comes out. No need to truck all that stuff away!\nAs well, the rules serve no purpose. I live in an urban neighborhood with a small back yard. I violate all the rules. I never turn it. I never water it. I never take its temperature. I just put stuff in on the top and take dirt out from the bottom. Yet my compost composts fine. (What else might it do? It has no other skills!)\nBanning fruit to avoid fruit flies is particularly wondrous. Fruit flies are exactly what you want! Fruit flies turn fruit into compost. It\'s their job, after all. The rule about cooked food is almost as silly. Cooked food is already partly-digested, for heaven\'s sake, ready to break down the rest of the way into compost. And dairy ... well, let me tell you how I learned that even bad dairy makes great compost.\nIt was 1964. I was a college student, working summers at Region Seven Explorer Canoe Base near Boulder Junction, Wisconsin. By now, my fourth year, I had worked my way up to ""Service Director,"" in charge of the operation of the base itself, including the kitchen and dining hall. Like many summer camps, Canoe Base got ""government surplus"" -- food commodities bought and processed by the United States Department of Agriculture. This program was supposed to maintain good prices for farmers\' products while helping nonprofit organizations.\nMost of these commodities we wanted. We got hundreds of pounds of cheese, sacks of flour, boxes of frozen ground beef.\nThen there was the milk. Powdered nonfat dry milk. Each box weighed four pounds and made five gallons of ""reconstituted milk."" ""Reconstituted"" it may have been, but milk it was not -- at least not milk that any self-respecting lad would ever drink. Reconstituting it hours ahead of time supposedly allowed its disgusting medicinal odor to dissipate. Not so. Pouring it from one container to another from a height of several feet supposedly aerated it, making it more palatable. We never found a palate for which that worked. Fifty years later, the government still distributes this stuff, and it suggests: ""Use nonfat dry milk as directed in recipes requiring dry or reconstituted milk or as a substitute in a cooked product when fresh milk is specified."" Perhaps it was a failure of our imagination, but we never came up with ""recipes requiring dry or reconstituted milk."" Our cook refused to risk her reputation substituting this powder for fresh milk in anything she cooked.\nWhat could we do?\nAccording to government regulations, we could not sell commodity foods. That would undercut local grocery stores. We could not give it away. We could not even store it over the winter -- we had tried that the previous year, and a USDA inspector had come by in February, found the milk, and fined us. All we could do was, turn it back to the government. But the rumor among food recipients was, if you do that, the government will not only cut your allotment of milk for the next year, they will cut all your government surplus proportionately. We could not risk that.\nI had a brainstorm. Why not line the volleyball court with it? The twine we tried to use to line the court broke. Marking just the corners led to arguments. So another staff member and I measured carefully and laid out two-inch lines of dried milk on each side of the net.\nThey worked perfectly, for two days. On the third day, it rained. The lines were still there, a bit yellowed perhaps, but functional. However, the entire court now smelled like spoiled milk. Not bad enough to deter play, but it does explain why Wimbledon prefers titanium dioxide.\nI had thought we would have to reline at regular intervals, but almost immediately it became clear that we would not. A streak of deep green grass, taller and thicker than the rest, soon grew along every white line we had put down. This richer grass continued to mark the court for the next two summers.\nThe volleyball court proved the value of milk as soil enricher. But it used less than two packages of our massive supply. We still faced the problem of what to do with the bulk of our milk. Arlo Guthrie had not yet composed ""Alice\'s Restaurant,"" but the crime scene in that song (and later, the movie) -- a roadside dump -- was hardly unique to western Massachusetts. I asked two staff members — ""Moose"" and ""Little John"" — to take all the rest to a dump in a ravine alongside a road about a mile from Canoe Base. There they were to dump it, but unlike Arlo, they were to leave no incriminating evidence. Instead, they were to bring back every carton, every box, even every plastic bag, for proper disposal. We wanted to bring off the perfect crime.\nMoose and John loaded up a vehicle which, like its contraband cargo, was itself government surplus. A carryall painted olive drab, the Army had condemned it years before and given it to the Boy Scouts. Its steering was so loose that in a wide area like a parking lot, the driver could hold the wheel steady and the truck would lurch from left to right as it ""caught"" first on one side, then the other. Driving in a straight line required a certain Zen-like concentration: one had to anticipate which way it would next lurch and move the wheel several inches to the opposite side until resistance was encountered, then apply a tiny nudge before returning the wheel to the center. I reminded Moose to drive carefully.\nMoose and John returned safely later that afternoon. I was told to come see them upon arrival, and the sight was unforgettable. At 6\'5"", Moose was our tallest staff member; at 5\'5"", John was our shortest. They stood before me, one Mutt, one Jeff, entirely white. It seems that merely slicing open each bag and emptying it into the ravine had grown boring, so they developed a more interesting routine: they whooshed each bag\'s contents at each other. They now gave new meaning to the term ""white folks."" Their lips were white. Their eyebrows were white. Their eyelids were white. Of course their shoes, socks, belts, and all items of clothing were white. Only when they spoke did glimpses of their tongues provide the only speck of color on their personages.\nFearing prosecution, I\'ve never told this story before. Canoe Base has closed, however, so it is safe. Surely the statute of limitations has expired, so I too can safely risk prosecution for violating USDA regulations. I fear, though, that I have veered off my main point. Like some ovo-lacto-vegetarians, I have let lacto dominate.\nI learned from the movie American History X that all good essays need to end with a quotation. So I spent almost an hour searching for a good joke, to leave you smiling. To my sorrow, I learned that all the compost jokes were rotten.\n* * * * *\ni.On pp. 15-17 of his engaging book, The Most Important Fish in the Sea (DC: Island Press, 2007), H. Bruce Franklin tells of the various names and species involved.\nii.Franklin, pp. 56-57.\niii.Actually by Horace Miner; see American Anthropologist 58:3, 7/1956.\niv.Admittedly, a compost pile is a system of living beings.\nv.The other three are in English. Two treat poetry.\nvi.Barbara Pleasant and Deborah L. Martin, Compost Gardening (no place indicated: Rodale, 2008), 220.\nCopyright James Loewen\ncomments powered by Disqus', 'What Can and Cannot Be Composted at Work? (+Other Tips)\nWondering what can and cannot be composted at the office? Today’s post takes a closer look at your workplace composting program to unearth what should and what shouldn’t be composted.\nComposting at work is becoming increasingly common, with green teams leading the way on what to do with food waste and other compostable products. Once your team has conducted a thorough waste audit, you’ll be better positioned to streamline your composting program.\nOffice composting can be complex without this initial audit. So, make sure that your team knows what kinds of compostable waste are being created onsite. According to The Environmental Protection Agency 24.9 million tons of food and yard waste was composted between 2015 and 2018.\nStudies have said that most people would compost if its easy to do – which means your workplace composting process needs to be simple for employees to adopt. Use this handy list to determine what can and cannot be composted at work.\nWhat Can You Compost at Work?\nWorkplace composting is similar to composting at home with one caveat – a large amount of people are expected to contribute to the program. For this to happen effectively, the right educational practices must be put in place alongside regular company reporting to gain employee buy-in.\nTo compost at work, processes must be put in place focusing on the kitchen or cafeteria area. Food scraps are going to be the essential composting items here. Remember that this post is aimed at curbside composting programs that are picking up your office compost on a regular basis.\n- Meat and Bone\nWhether raw or cooked, meat isn’t always meant for the compost heap. In this case, when your business is composting in conjunction with a municipal composting program, you might get away with it. Most city programs accept meats from cafeterias whether they are on or off the bone.\nDouble check whether or not your city accepts raw meat and carcasses though, in case they don’t want anything that doesn’t ‘grow’ in your green cart.\n- Dairy and Eggs\nAnother typical no-go for home composting environments, city programs are happy to accept all dairy and eggshell waste in your workplace compost.\n- Paper Eating Utensils\nCan you compost paper cups? What about plates, napkins, and towels? While soiled or food smeared paper utensils are a no for the recycling bin, they’re welcome in the office compost. The next time you have cake for Rita in accounting, remind your team to compost the remains.\n- Raw or Cooked Vegetables and Fruit\nWhether chopped, peeled, half-eaten or cooked into starchy grains – feel free to get your employees to compost all vegetable and fruit items.\n- Shredded Paper\nBeen wondering what to do with all that shredded paper you can’t recycle? Put it in your green compost bin. Add a special green waste bin to your printing room and add it to your composting bin at the end of every week.\n- Coffee Grounds, Coffee Filters, and Tea Bags\nAs long as your employees are removing the staples from your tea bags, they usually accept all forms of caffeinated breakroom refreshment. From filters and bags to leaves and coffee grounds – having a compost bin in the breakroom is a great way to promote your program.\nWhat Cannot be Composted at Work?\nThere are some surprising no-no’s when composting at work. Beginners may not know that these items shouldn’t go in your workplace compost bin, so get your green team to put up posters or send out mailers detailing where these banned items should go.\n- Pet Waste\nIf you have a dog or cat friendly office, make sure your employees aren’t trying to compost their pet waste. This includes all fecal matter, cat litter and soiled paper items used in the disposal of animal waste. Experts say the risk is too high, with parasites and harmful bacteria present.\n- Smoking Related Items\nSome of your employees will nip outside for a smoke break, but can that waste be composted? Typically, cigarette butts and ash can’t be composted. Neither can vape cartridges, mouthpieces, atomizers, or batteries! These don’t go in your normal recycling either, they should be placed in an e-waste recycling bin for disposal.\n- Most Corks\nDo you have Friday drinks at the office? Most corks these days aren’t natural corks, so they can’t be composted. If you do happen across some natural cork then it can go in the composting bin – just make sure all wire, foil and aluminum are removed from it first.\nAs always you can’t compost plastics, aluminum, or glass of any kind. The general rule is that only organic materials can be composted.\nMake sure that you check with your local municipality so that your workplace composting program is in line with your city rules. Follow their rules and you’ll know what can and can’t be composted at work.\nLearn something new? Tell us below!']"	['<urn:uuid:b1e769e7-cdfa-446b-a553-cdd0d4b7718d>', '<urn:uuid:b9fe0b24-b937-40fa-8a49-f9fced313a5c>']	open-ended	with-premise	verbose-and-natural	distant-from-document	multi-aspect	novice	2025-05-13T05:52:58.810667	41	125	3236
90	What are the seven main taxonomic ranks?	The seven main taxonomic ranks are: kingdom, phylum or division, class, order, family, genus, and species.	"['In biological classification, rank is the level (the relative position) in a taxonomic hierarchy. Examples of taxonomic ranks are species, genus, family, and class. Each rank subsumes under it a number of less general categories. The rank of species, and specification of the genus to which the species belongs is basic, which means that it may not be necessary to specify ranks other than these. The International Code of Zoological Nomenclature defines rank as:\nThe level, for nomenclatural purposes, of a taxon in a taxonomic hierarchy (e.g. all families are for nomenclatural purposes at the same rank, which lies between superfamily and subfamily)\n""2.1. Every individual plant is treated as belonging to an indefinite number of taxa of consecutively subordinate rank, among which the rank of species (species) is basic.""\nIn his landmark publications, such as the Systema Naturae, Carl Linnaeus used a ranking scale limited to: kingdom, class, order, genus, species, and one lower rank, below species. Today, nomenclature is regulated by the Nomenclature Codes, which allow names divided into an indefinite number of ranks. There are seven main taxonomic ranks: kingdom, phylum or division (see table), class, order, family, genus, species. In addition, the domain (proposed by Carl Woese) is now widely used as one of the fundamental ranks, although it is not mentioned in any of the Nomenclature Codes.\nNotes to table\nA taxon is usually assigned a taxonomic rank (in a hierarchy), usually when it is given its formal name. The basic rank is that of species. The next most important rank is that of genus: if an organism is given a species name it will at the same time be assigned to a genus, as the genus name is part of the species name. The third-most important rank, although it was not used by Linnaeus, is that of family.\nThe species name is sometimes called a binomial (a two-term name). For example, the zoological name for the human species is Homo sapiens: this is usually italicized in print (and underlined when italics are not available). In this case, Homo is the generic name and refers to the genus; it is capitalized; sapiens indicates the species: it is written in lower case.\nRanks in zoology\nThere are definitions of the following taxonomic ranks in the International Code of Zoological Nomenclature: superfamily, family, subfamily, tribe, subtribe, genus, subgenus, species, subspecies.\nThe International Code of Zoological Nomenclature divides names into ""family-group names"", ""genus-group names"" and ""species-group names"". The Code explicitly mentions:\nThe rules in the Code apply to the ranks of superfamily to subspecies, and only to some extent to those above the rank of superfamily. In the ""genus group"" and ""species group"" no further ranks are allowed. Among zoologists, additional terms such as species group, species subgroup, species complex and superspecies are sometimes used for convenience as extra, but unofficial, \'ranks\' between the subgenus and species levels in taxa with many species (e.g., the genus Drosophila).\nAt higher ranks (family and above) a lower level may be denoted by adding the prefix ""infra"", meaning lower, to the rank. For example infraorder (below suborder) or infrafamily (below subfamily).\nNames of zoological taxa\n* A taxon above the rank of species gets a scientific name in one part (a uninominal name)\nThere are definitions of the following taxonomic ranks in the International Code of Botanical Nomenclature: kingdom (regnum), subregnum, division or phylum (divisio, phylum), subdivisio or subphylum, class (classis), subclassis, order (ordo), subordo, family (familia), subfamilia, tribe (tribus), subtribus, genus (genus), subgenus, section (sectio), subsectio, series (series), subseries, species (species), subspecies, variety (varietas), subvarietas, form (forma), subforma.\nThere are definitions of following taxonomic ranks in International Code of Nomenclature for Cultivated Plants: cultivar group, cultivar.\nAccording to Art 3.1 of the ICBN the most important ranks of taxa are: kingdom, division or phylum, class, order, family, genus, and species. According to Art 4.1 the secondary ranks of taxa are tribe, section, series, variety and form. There is an indeterminate number of ranks. The ICBN explicitly mentions:\ndivision or phylum (divisio, phylum)\nThe rules in the ICBN apply primarily to the ranks of family and below, and only to some extent to those above the rank of family. Also see descriptive botanical names.\nNames of botanical taxa\nOf the botanical names used by Linnaeus only names of genera, species and varieties are still used.\nTaxa at the rank of genus and above get a botanical name in one part (unitary name); those at the rank of species and above (but below genus) get a botanical name in two parts (binary name); all taxa below the rank of species get a botanical name in three parts (ternary name).\nFor hybrids getting a hybrid name, the same ranks apply, preceded by ""notho"", with nothogenus as the highest permitted rank. (The hybrid\'s nothotaxon is an alias for a list of all of the taxa which are ancestral to the hybrid.)\nClassifications of five species follow: the fruit fly so familiar in genetics laboratories (Drosophila melanogaster), humans (Homo sapiens), the peas used by Gregor Mendel in his discovery of genetics (Pisum sativum), the ""fly agaric"" mushroom Amanita muscaria, and the bacterium Escherichia coli. The eight major ranks are given in bold; a selection of minor ranks are given as well.\n* The ranks of higher taxa, especially intermediate ranks, are prone to revision as new information about relationships is discovered. For example, the traditional classification of primates (class Mammalia — subclass Theria — infraclass Eutheria — order Primates) has been modified by new classifications such as McKenna and Bell (class Mammalia — subclass Theriformes — infraclass Holotheria) with Theria and Eutheria assigned lower ranks between infraclass and the order Primates. See mammal classification for a discussion. These differences arise because there are only a small number of ranks available and a large number of branching points in the fossil record.\nTaxa above the genus level are often given names based on the type genus, with a standard termination. The terminations used in forming these names depend on the kingdom, and sometimes the phylum and class, as set out in the table below. Pronunciations given are the most Anglicized; more Latinate pronunciations are also common, particularly /ɑː/ rather than /eɪ/ for stressed a.\n* In botany and mycology names at the rank of family and below are based on the name of a genus, sometimes called the type genus of that taxon, with a standard ending. For example, the rose family Rosaceae is named after the genus Rosa, with the standard ending ""-aceae"" for a family. Names above the rank of family are formed from a family name, or are descriptive (like Gymnospermae or Fungi).\nThe following is an artificial synthesis, solely for purposes of demonstration of relative rank (but see notes), from most general to most specific:\nOf these many ranks, the most basic is species. However, this is not to say that a taxon at any other rank may not be sharply defined, or that any species is guaranteed to be sharply defined. It varies from case to case. Ideally, nowadays, a taxon is intended to represent the phylogeny of the organisms under discussion, but in itself this is not a requirement.\n1. ^ International Code of Botanical Nomenclature Online, Vienna Code, 2005, articles 2 and 3\n* Benton, Michael J. 2005. Vertebrate Palaeontology, 3rd ed. Oxford: Blackwell Publishing. ISBN 0-632-05637-1. ISBN 978-0-632-05637-8\nRetrieved from ""http://en.wikipedia.org/""']"	['<urn:uuid:4f5f4df8-3f7f-4b2f-83a6-2ba116014a21>']	factoid	direct	concise-and-natural	similar-to-document	single-doc	expert	2025-05-13T05:52:58.810667	7	16	1233
91	moxifloxacin tuberculosis treatment effectiveness compared ethambutol sputum clearance rates 2 weeks	After two weeks of therapy with moxifloxacin, 21 percent of the sputum samples were negative and cleared of visible disease, while in the ethambutol study group, it was just 3 percent.	"[""Adding moxifloxacin to a standard combination of other antibiotics increased by 17 percent the number of patients who cleared active infections from their lungs (raising cure rates from 68 percent to 85 percent), after just two months of therapy, and when compared to patients taking the standard combination with another, older antibiotic, ethambutol.\n“This is the most compelling evidence in nearly 25 years that a novel antibiotic drug combination works better than the current gold standard at curing active TB infection,” says study senior author Richard E. Chaisson, M.D., a professor of medicine, epidemiology and international health at The Johns Hopkins University School of Medicine and founding director of its Center for Tuberculosis Research. Chaisson will present his team’s findings Sept. 18 in Chicago at the 47th Interscience Conference on Antimicrobial Agents and Chemotherapy (ICAAC).\n“Beyond the obvious value of healing patients more quickly, a shorter treatment time could also cut down on transmission of the disease to others and make it easier for health care workers worldwide, who are overwhelmed by large numbers of patients, to treat more people and to treat them faster,” says Chaisson, who started the study in 2003.\nHe notes that worldwide, each year, nearly 9 million new cases of TB are diagnosed, and more than one and a half million people die from the disease, caused by Mycobacterium tuberculosis.\nTB also remains the leading cause of death worldwide among those with HIV and AIDS and is epidemic in developing countries with the highest HIV-infection rates.\nThe new study of more than 170 men and women in Rio de Janeiro, Brazil – all with active TB – showed that combination drug therapy with moxifloxacin was more potent than combination therapy with an older, more traditional anti-TB drug, ethambutol. Symptoms of active TB include fever, cough, night sweats and weight loss.\nAfter two months of combination therapy, cultured sputum samples from patients taking moxifloxacin were significantly less likely to grow TB bacteria than samples from those on traditional ethambutol therapy. The time to clear the infectious organism from sputum was also significantly shorter in the moxifloxacin group.\nConventional TB therapy prescribes a mix of antibiotics, typically four, given in view of a caregiver and taken together for six months. Commonly known by its acronym DOTS, short for Directly Observed Therapy Short-Course, the treatment cures on average 95 percent of patients who finish taking their medications as originally prescribed.\nBut experts say the lengthy treatment period has proven a problem for patients, who sometimes miss taking their drugs on time, minimizing the therapy’s effectiveness and increasing the risk that drug-resistant strains will develop.\nHistory, says Chaisson, demonstrates that shorter regimens boost drug compliance and cure rates, often by as much as 50 percent. In the 1950s, TB treatment lasted from 18 to 24 months, and nearly a quarter of patients failed to complete therapy. It was not until new drugs appeared in the 1970s and 1980s, when treatment times were shortened to an average of six months, that cure rates shot up.\nIn the latest study, all participants were given a standard combination of three antibiotic pills – isoniazid, rifampin, and pyrazinaminde – and then randomly assigned to receive a fourth pill, either moxifloxacin or ethambutol. Moxifloxacin, approved for use in the United States since 1999 as a treatment for pneumonia, is not currently approved as a treatment for TB. However, ethambutol has been approved to treat TB since 1962.\nThe three combination drugs, which must be taken several times daily for six to eight months, have all been widely used to treat TB disease for decades: isoniazid (since 1952), rifampin (1968) and pyrazinamide (1954).\n“It was remarkable to see just how potent moxifloxacin was,” says Chaisson. After just two weeks of therapy with moxifloxacin, 21 percent of the sputum samples were negative and cleared of visible disease, while in the ethambutol study group, it was just 3 percent. After four weeks, the gap widened to 51 percent and 29 percent, respectively.\nChaisson says substituting moxifloxacin for one of the key ingredients in DOTS could also make treatment far less costly overall, allowing TB programs to expand their coverage. The medication currently costs $10 per day for short-term use, but the researcher says the drug’s manufacturer, Bayer Healthcare AG, has promised to make the drug available at affordable prices in poor countries should it gain approval for use in TB.\nChaisson and his team next plan to investigate a potentially even more potent drug combination that includes traditional DOTS drugs with yet another substitution, rifapentine in place of rifampin. Rifapentine became available in the United States in 1998 and scientists say it is more effective against drug-resistant strains of TB.\nChaisson and colleagues conducted their research with funding from the U.S. Food and Drug Administration’s Office of Orphan Product Development. The study was part of a series of studies on moxifloxacin that are being coordinated by the nonprofit Global Alliance for TB Drug Development (GATB) in collaboration with Bayer.\nThe GATB estimates that 1 billion people worldwide will be infected with tuberculosis by the year 2020, of whom 200 million will fall ill and 35 million will die.\nAs part of the research program, Bayer donated supplies of moxifloxacin.\nBiologists unravel another mystery of what makes DNA go 'loopy'\n16.03.2018 | Emory Health Sciences\nScientists map the portal to the cell's nucleus\n16.03.2018 | Rockefeller University\nAnimal photoreceptors capture light with photopigments. Researchers from the University of Göttingen have now discovered that these photopigments fulfill an...\nOn 15 March, the AWI research aeroplane Polar 5 will depart for Greenland. Concentrating on the furthest northeast region of the island, an international team...\nThe world’s second-largest ice shelf was the destination for a Polarstern expedition that ended in Punta Arenas, Chile on 14th March 2018. Oceanographers from...\nAt the 2018 ILA Berlin Air Show from April 25–29, the Fraunhofer Institute for Laser Technology ILT is showcasing extreme high-speed Laser Material Deposition (EHLA): A video documents how for metal components that are highly loaded, EHLA has already proved itself as an alternative to hard chrome plating, which is now allowed only under special conditions.\nWhen the EU restricted the use of hexavalent chromium compounds to special applications requiring authorization, the move prompted a rethink in the surface...\nAt the ILA Berlin, hall 4, booth 202, Fraunhofer FHR will present two radar sensors for navigation support of drones. The sensors are valuable components in the implementation of autonomous flying drones: they function as obstacle detectors to prevent collisions. Radar sensors also operate reliably in restricted visibility, e.g. in foggy or dusty conditions. Due to their ability to measure distances with high precision, the radar sensors can also be used as altimeters when other sources of information such as barometers or GPS are not available or cannot operate optimally.\nDrones play an increasingly important role in the area of logistics and services. Well-known logistic companies place great hope in these compact, aerial...\n16.03.2018 | Event News\n13.03.2018 | Event News\n08.03.2018 | Event News\n16.03.2018 | Earth Sciences\n16.03.2018 | Physics and Astronomy\n16.03.2018 | Life Sciences""]"	['<urn:uuid:a931d632-7aa0-40c6-a158-64d8005ddc2d>']	factoid	with-premise	long-search-query	similar-to-document	single-doc	expert	2025-05-13T05:52:58.810667	11	31	1185
92	What are the main differences between indemnity plans and managed care plans when it comes to healthcare providers and bill payments?	Indemnity plans offer a broader selection of healthcare providers and pay their share of the costs for covered services only after receiving the bill. In contrast, managed-care plans (which include HMO, PPO, and POS plans) utilize healthcare provider networks that perform services at pre-negotiated rates and submit the claim to the insurance company on behalf of the customer.	['Individual Health Insurance is one in which the individual is provided with a long-term benefits for their health and medical hazard costs. The individual makes an investment known as a premium for the variable costs incurred by him due to accidents, illness or sudden hospital checkups. It is a comprehensive medical coverage for the individual customer and / or his family.They are different from employer group or organizations health Insurance schemes. There is variety of medical insurance options available to the customers with customized services attached and at affordable rates.\nThere are mainly two kinds of Individual Health Insurance:\nIndemnity Plans Offer a broader selection of healthcare providers and pay their share of the costs for covered services only after the receipt of the bill.\nManaged-care Plans – Include HMO, PPO, and POS plans. The providers utilize the healthcare provider networks that perform the services for managed-care plan patients at pre-negotiated rates and submit the claim to the insurance company on behalf of the customer.\nThe Individual Health Insurance Options:\n1. Fee-for-Service Insurance\n2. Managed Care Plans\n3. Open Enrollment in Managed Care Plans\n4. Association-Based Health Insurance\n5. High-Risk Pools\nIndividual Health Insurance is a contract issued by an insurance company to an individual or group, in return of pay for health care reasonably required by the “insured” or “policy holder” to treat illness or injury. It is the type of health coverage that is available to individuals and families, rather than to employer groups or organizations. A particular plan can cover a list of illness and diagnoses types, like for example cancer, bypass surgery, heart attack, kidney failure, major organ transplant, stroke, paralysis, heart-valve replacement surgery, multiple sclerosis, etc. Individual and Family health insurance plans provide long-term protection and comprehensive medical coverage.\nThere are variety of options with affordable rates. Individual and family health insurance plans are either “indemnity” or “managed-care” plan types. The differences deal with: healthcare providers, out-of-pocket costs and how bills are paid.\nUnlike Managed-Care plans, Indemnity plans offer a broader selection of healthcare providers and pay the costs for covered services only after they receive a bill. There are several different types of managed-care health insurance plans, including HMO, PPO, and POS plans\nThere is no best plan designed for a particular family or individual. One needs to choose the plans judicially considering the following:\n1. Whether the need is for long-term coverage or for the short-term?\n2. Looking for a basic coverage or more comprehensive coverage?\n3. Prefer to pay for services before they are used or at the time of usage?\n4. How easy is the access of specialists (doctors) for the user?\n5. Any specific doctor or hospital preferred by the individual or family?\n6. The maximum sum of money that the user can afford to pay in case of a serious illness or injury.\nHealth Insurance Plan\nIn Blue Cross health insurance plan, the insurer pays to the insured, if the insured becomes ill or experiences any kind of accidents, due to covered causes.\nBlue Cross is a reputed insurance company, established in 1982, is based in Chicago. It offers various health benefits, through different individual health insurance policies to the inhabitant of California, to live a better life.\nIndividual and Family PPO Medical Plans\nIndividual and Family HMO Medical Plans\nIndividual Short Term Coverage\nIndividual Short term PPO Medical Plans\nPost-MRMIP Graduate Product\nIndividual Dental Plans']	['<urn:uuid:b6b4ed7c-7a48-41b4-a7e8-839149d46d11>']	open-ended	direct	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-13T05:52:58.810667	21	58	567
93	compare popularity history catan pokeno which game had more international success	Catan has had significantly more international success than Pokeno. Catan (originally Die Siedler von Catan) was notably the first German-style board game to achieve substantial popularity outside Europe, and has been translated into multiple languages including English, French, Italian, and Japanese. It also won several prestigious awards including Spiel des Jahres 1995, Deutscher SpielePreis 1st place 1995, and the Origins Award for 1996. In contrast, Pokeno is manufactured by the United States Playing Card Company and while it's available commercially (such as at Walmart), there's no mention of international success or awards for Pokeno in the documents.	"['How do you play the game Pokeno?\nPlayers lay a chip (wager) on any card, thereby marking two rows (one vertical and one horizontal). The dealer turns over cards one at a time, calling them out. Players only place a chip on their boards if the card called falls in one of the two rows marked by the wager chip.\nYou are watching: How to play pokeno with different pots\nWhat store sells Pokeno game?\nWhat is 4 of a kind in Pokeno?\n7 Chips = Four of a Kind – 4 cards of the same amount (e.g., 4 Kings). 6 Chips = Full House – 3 cards of one amount and two of another. 5 Chips = Flush – Any 5 cards of the same suit. 4 Chips = Straight – Any 5 cards in sequence (e.g., ace , 2, 3, 4, 5 of mixed suits).\nHow old is Pokeno?\nWork on the proposed Paeroa–Pokeno Line commenced in 1938 and whilst approximately 13 km of earthworks were completed at each end, the proposal was halted due to World War 2 and was not resumed following the war and was abandoned.\nWhat is Pokeno famous for?\nPokeno is also a popular resting point for motorists. Many of them visit Pokeno for its world-famous ice creams or flavoursome Pokeno bacon and sausages!\nIs Pokeno like bingo?\nPokeno is a game manufactured by United States Playing Card Company, the makers of Bicycle Playing Cards. This game is a combination of poker and keno (or lotto) and is similar to the game of bingo in several aspects.\nWhat are the pots for Pokeno?\nThere are several different labels that can be placed on each pot, but there are usually four standard pot labels that are typically used by players universally. The labels for the pots are Corners, Centers, Five in a Row, & Four of a Kind. Centers is for when a player covers the center space on their game board.\nDoes Walmart sell Pokeno?\nBicycle Original Pokeno Card Game – Walmart.com – Walmart.com.\nWhen was Pokeno invented?\nWhat are 4 Aces called?\n|Full house||Boat, full boat||Aces full; aces full of kings|\n|Four of a kind||Quads||Quad aces; four aces|\n|Straight flush||Ace-high straight flush (Also called a Royal Flush)|\nWhat is 3 of a kind worth in Cribbage?\nPair – Completing a pair (two of a kind) scores two points. Three of a kind is the same as three different pairs, or 6 points. Four of a kind is 6 different pairs, or 12 points.\nIs Catan more luck or skill?\nAt that point, covering over half of the possible rolls and 70% of rolls that gain resources, the game is clearly more luck than skill. That being said, the game does involve significantly more choices than most other luck based games.\nWho is the best cribbage player in the world?\nIs Catan a skill or luck?\nIn a 2020 survey conducted by YouGov, 82 percent of respondents in the United States stated that Settlers of Catan was a game of skill rather than luck.\nHow do you win at Catan every time?\nTop 6 Catan Strategies for Turning Your Losing Streak Around\nSettling Into Catan. Don’t Play Resources, Play the Odds. Balance Longest Road with Additional More Resources. Respect the Development Cards. Monopolize and Conquer. Trade Big or Trade with the Bank. Plan Ahead for Your Last Two to Three Points. Two Last Things to Remember.\nWhat age is Catan for?\nWhich version of Catan is the best?\nRanking The Best Versions Of The Catan Board Game\n1 Catan Traveler. Catan Traveler is a downright impressive game.2 Catan Geographies – Germany. 3 Catan Histories: Settlers of America. 4 Catan Histories: Merchants of Europe. 5 A Game of Thrones Catan. 6 Catan: Rise of the Incas. 7 Star Trek Catan. 8 Catan – 15th Anniversary Edition.\nIs Catan worth buying?\nWorth it. Catan is a classic. Social, simple, fun, and well known. Well known is important because 1) it’s available in many retail stores and 2) it has a high chance to be played by others so it becomes a “common lexicon” to speak about modern board games.\nWhich Catan game should I buy first?\nFor most players, the recommended first expansion is Seafarers of Catan. It comes in a light blue box that includes new sea tiles and boats so players can colonize islands. The new rules that the game adds are straightforward and intuitive, making Seafarers easy to integrate with the base game.\nWhat is the most fun Catan expansion?\nFor the chronic pain that this causes to our wallets, this rates as a dead last dishonorable mention on our list.\n#4 – Catan: Seafarers. Let’s get one thing out of the way: Seafarers is an excellent expansion. #3 – Catan: Traders and Barbarians. #2 – Catan: Explorers and Pirates. #1 – Catan: Cities and Knights.\nWhat is the best board game in the world 2020?\nTheir exclusion isn’t a sign that they’re not worth your time. Here they are: the 15 best board games of 2020….Here they are: the 15 best board games of 2020.\nThe Search for Planet X.Fort. Sonora. Tekhenu: Obelisk of the Sun. Pendulum. My City. The Shores of Tripoli. Nova Luna.\nCan you play Catan with 2 people?\nWant more two-player options? Struggle for CATAN is a card game that can be played with two to four players. CATAN Dice Game is a fast-playing roll-and-write game for any number of players. CATAN Traveler also includes this 2-player variant!\nCan 3 players play Catan?\nIn principle, the normal 3-4 player rules for The Settlers of Catan apply. The changes are described below. On your turn, you roll the dice twice in a row. Immediately after each of the two dice rolls, the two real players obtain resources and/or move the robber (a “7” result).\nCan you play Catan with 7 players?\nBut, I would never recommend playing Catan with 7 players. The 5-6 player expansion already makes the game way too long and slow. If you have that many players, I’d recommend playing two separate games (one with 3, one with 4).\nCan you play Catan with 4 players?\nCatan is a board game for two to four players in which you compete to gather resources and build the biggest settlements on the fictional island of Catan. It takes approximately one hour to play.', 'Redirected from The Settlers of Catan\nHistory Kosmos[?] published the game in Germany in 1995 under the name Die Siedler von Catan. It won the Spiel des Jahres 1995 and Deutscher SpielePreis[?] 1st place 1995 and the Origins Award[?] for 1996.\nSettlers is perhaps the first German-style board game to reach any degree of popularity outside of Europe. It has been marketed as ""The Settlers of Catan"" in the United States by Mayfair Games[?]. It has been said that the original Siedler actually consisted of the game we know as Siedler today and the first expansion set, Seefahrer. Whatever the case, both the original game and the expansion are available (at a bare minimum) in both Europe and the United States -- where Seefahrer is marketed as ""The Seafarers of Catan"". It has been translated into English, French, Italian, and Japanese from the original German.\nOverview Settlers is a 3-4 player game which takes about ninety minutes to two hours to play, unless one uses the 5-6 player expansion, in which case the game lasts correspondingly longer. The premise is that the players are colonists on the uninhabited Island of Catan. The colonists tap the abundant natural resources of the island to build settlements, roads, and cities, as well as to purchase development cards which represent further progress towards civilization. Because the production of resources is controlled by dice, there is a significant amount of luck involved, but expert players can still distinguish themselves by clever negotiation and trade. It is difficult for any one player to produce all the raw materials necessary for advancement, so the trading of commodities is critically important. The winner is the first to accumulate ten victory points, which are mostly awarded for building settlements and cities, but also for other achievements.\nThe Board The board consists of 37 terrain hexagons; nine water, nine ports, four plains, four pasture, four forest, three hills, three mountains, and one desert. The 19 land hexes are shuffled and arranged in a central hexagon. The nine ports are then shuffled and placed at every alternate space around the edge of the island, with empty water hexes filling in between.\nEach land hex, apart from the desert, produces a specific natural resource for players who build settlements or cities adjacent to it. After the board is assembled, a production token with a number from two to twelve, excluding seven, is placed on each hex. At the beginning of each turn, two dice are rolled, and all terrain hexes marked with that number produce their distinctive commodity. Because of the probabilies for two dice, hexes marked with six or eight are much more productive than those marked with two or twelve.\nRoads, Settlements, and Cities Roads are placed along the lines between two hexes, while settlements and cities are placed on the corner intersections between three hexes. At the beginning of the game each player places two settlements anywhere on the island and a road extending from each. Further roads can only be built as extensions of existing roads, and further settlements can only be placed on those roads. Cities can only replace existing settlements, like hotels replacing houses in Monopoly. Cities have double the production of settlements, and count for two victory points each as opposed to one each for settlements.\nTwo cities or settlements, whether friendly or otherwise, can\'t be built on adjacent intesections.\nThe Robber There is also a robber token which begins the game in the desert. Whenever a seven is rolled, the rolling player relocates the robber to any other hex, and steals a commodity from some player with an adjacent settlement or city. Furthermore, the hex on which the robber stands becomes unproductive for as long as the robber remains; even if the production number for that hex is rolled, adjacent players get nothing.\n|Road||1 Lumber||1 Clay|\n|Settlement||1 Lumber||1 Clay||1 Wool||1 Grain|\n|City||2 Grain||3 Ore|\n|Development Card||1 Wool||1 Grain||1 Ore|\nTrading Raw materials are represented by commodity cards, which the players can save, trade, or use to build roads, settlements, cities, and development cards. Only the player whose turn it is may trade or build.\nAlso there is maritime trade, or trading ""off the island"" so to speak. A player with four identical commodity cards may trade them in for one other commodity of any type. A player with a settlement or city adjacent to a port may trade in commodities at a more favorable ratio, but never one-for-one, so it is usually desirable to trade with other players if possible.\nDevelopment Cards and Victory Points Because settlements and cities can\'t be built adjacent to each other, the board often becomes crowded, and it is difficult to find room to expand. Furthermore, each player is limited to four cities and five settlements, so it is difficult to win without finding another source of victory points. Players therefore use their resources to buy development cards.\nDevelopment cards occasionally represent direct contributions to civilization, such as a library or church, and as such directly add one victory point to the total of the purchasing player. More often, however, they are soldier cards. A soldier card allows the purchasing player to relocate the robber and steal from another player. Also, whichever player has played the most soldier cards, with a minimum of three, is awarded two victory points for having the largest army.\nThere are also a few development cards which don\'t contribute directly to victory points, but are useful in other ways, such as Road Building (build two roads), Year of Plenty (get two resources of your choice), and Monopoly (steal all resource of one type from everyone).\nThe final source of victory points is building the longest road on the island, with a minimum of five segments.\nThe player with the longest road is awarded two victory points.\nHowever, the victory points for longest road and largest army are only temporary; another player who builds a longer road or larger army takes over those victory points as well.\nA more subtle contribution to Settlers popularity is that gamers (typically women) who have an inclination to cooperate more than to compete aren\'t shouldered aside as in more bloodthirsty board games. Hyper-competitive players may get caught in cycles of embargo and robbing revenge with each other, while a cooperative player angers no one, trades freely with everyone, and quietly wins.\nAt the same time, there is considerable depth to competitive strategy. In serious games everyone needs to pay attention during all players\' turns. The production and trading of commodities is public, but the commodity cards are held face down, which means that an alert player with a perfect memory can know everyone\'s exact holding, whereas the inattentive player will often be wondering (or asking out loud), ""Does anyone have grain?"". Commodities have an intrinsic value based on what they can be used to purchase, but their trading value changes from moment to moment based on shortages and surpluses. A sharp trader will know the distinct value of each commodity to each player at each turn, and use this information profitably.\nExpert games tend to come down to close finishes, because everyone is aware of who is leading, and the leader is most likely to be hurt with the robber. Furthermore, the rest of the players will usually absolutely refuse to trade with someone on the verge of victory, knowing that they could unwittingly provide the commodity necessary for the tenth victory point. Seldom does any one player produce all commodoties necessary to win, and being forced to use maritime trade can be a severe brake on one\'s progress.']"	['<urn:uuid:06a71b58-2423-438b-aaf6-26073ae0bdda>', '<urn:uuid:11ed75be-298f-4d4e-8920-4676a752945c>']	open-ended	with-premise	long-search-query	similar-to-document	comparison	expert	2025-05-13T05:52:58.810667	11	97	2336
94	monitor decode balloon data worldwide research	Weather balloon data can be decoded using software like SondeMonitor or RS command line program, which can interpret telemetry from various radiosonde models including Digital RS-41, RS92SGP, and others. The balloons are launched globally twice daily at around 0000 UTC and 1200 UTC, transmitting air temperature, humidity, pressure and location data. This worldwide data collection contributes to broader atmospheric research, with places like Antarctica's Davis station using the information for weather forecasting through the Bureau of Meteorology and for studying global-scale wave activity with research colleagues around the world.	"[""Around the world meteorological weather balloons are launched twice daily, and continuously transit weather telemetry to a ground station using something called a radiosonde. The RTL-SDR software defined radio combined with a decoding program can be used to intercept this telemetry, and display it on your own computer. You will be able to see real time graphs and data of air temperature, humidity, pressure as well as the location and height of the balloon as it makes it's ascent.\nNote that if you are in the USA, then this tutorial may not be applicable for you as different radiosondes are used. Instead have a look at this post which shows how to use the SkySonde software from NOAA. You can also try an alternative command line based decoder called RS available on GitHub.\nThis tutorial is also applicable to other software defined radios such as the Funcube dongle, Airspy, HackRF, BladeRF or even hardware radios with discriminator taps, but the RTL-SDR is the cheapest option that will work.\nIn this example YouTube user Superphish shows a radiosonde being received and decoded using a RTL-SDR, SDRSharp and SondeMonitor.\nHere YouTube user py22rn shows another radiosonde being received and decoded using a Funcube dongle, SDR-RADIO and SondeMonitor.\nIn order to receive and decode weather balloon radiosondes you will need four things.\n- An RTL-SDR dongle set up and working with SDRSharp, or any other software defined radio with similar performance.\n- An antenna capable of picking up signals near 403 to 406 MHz.\n- A decoding program called SondeMonitor which is able to decode radiosonde telemetry.\n- The knowledge of when and optionally where weather balloon radiosondes are launched in your area.\nWe will assume you have the RTL-SDR dongle set up and working already. If you have not bought a dongle yet, see the Buy RTL-SDR page for information on the best places to buy dongles and then check out the Quickstart Guide for an easy setup routine with SDRSharp. You will also need to have an audio piping method installed and set up. Audio piping will allow the audio from SDRSharp to be passed to a decoding program. You can use either windows stereo mix, VB-cable (free) or Virtual Audio Cable (paid with trial version).\nRadiosonde signals typically get good radio reception with any antenna tuned to 403 MHz as they transmit from high in the sky where there are no obstructions. Some antennas to try are 1/4 ground plane antennas, J-Pole antennas and collinear antennas. Discone antennas may also work well.\nQuarter Wave Ground Plane Antenna\nUsing this calculator, dimensions for a simple 1/4 wave ground plane antenna for 403 MHz can be calculated. The Stratodean amateur high altitude ballooning team used a very simple 1/4 ground plane made out of RG58 coaxial cable.\nTwin Lead J-Pole\nDecoding Radiosonde Telemetry\nWeather balloons most commonly transmit at around ~403 MHz and are launched around the world at the official observation time of around 0000 UTC and 1200 UTC. You will need to either Google or check with your local meteorological agency for a more exact time of when they are launched in your area.\nOne of the most commonly used radiosonde signals is the Vaisala RS92SGP digital signal. A waterfall example of this signal is shown on the below and a sound sample is provided further down. SondeMonitor is a Windows decoder which is able to decode Digital RS-41, RS92SGP, Analogue RS92AGP, Analogue RS80, Analogue 92KL, Graw DFM-06, MeteoModem M2K2/M10 and Meteolabor SRS-C34. If you discover a different signal to the RS92SGP example provided here, you will need to experiment in SondeMonitor to find the protocol which works.\nMore radiosonde signal and video examples can be found over on Sigidwiki.com.\nTo decode weather balloon radiosondes follow these steps:\n- Download and install SondeMonitor. SondeMonitor is paid software with a reasonable 25 euro price tag, but comes with a 21 day trial. Download SondeMonitor from this page.\n- When a weather balloon is due to be launched, open SDRSharp, set your audio piping method under the Audio Output drop down box and tune to a frequency between 403 and 406 MHz. Scan around and look for a radiosonde signal, tune to it and adjust the RF gain settings for best performance. Set the receive mode to NFM and filter audio to OFF. Adjust the filter bandwidth so that it just covers the signal.\n- Open SondeMonitor. (NOTE: In Windows 10 you must open SondeMonitor as Administrator - right click shortcut, choose run as administrator) Go to Options -> Audio -> Audio Source and choose the audio piping method you are using.\n- Select the radiosonde decoding protocol used in your area. These can be selected with the icons just to the right of the green circle start and square stop icons. Hovering over the icons will show what they are. If you are unsure, you might try experimenting with each one.\n- Now start the decoding by clicking the green circle. A telemetry data window will pop up. Next, click on the raw signal icon, which looks like a squiggle. Adjust the volume in SDRSharp or Windows volume settings so that the audio graph is loud enough to be visible, but not too loud as to cause clipping (square waveform).\n- At this point, if your signal reception is good, and you have selected the correct decoding method, the telemetry window will show data and have four green circles. Note, that SondeMonitor requires some initial time to calibrate. The completed amount of the calibration process can be seen in the red bar in the lower left corner, which will slowly turn all green as calibration completes. The calibration status can also be tracked in the telemetry window. If calibration does not complete, or takes a very long time, it means your signal strength is not good enough.\n- Click on the Graph 2 icon to see telemetry graphs. You can click the Autoscale icon which looks like a double ended vertical arrow to ensure that all the data is displayed on the screen.\nGPS Radiosonde Location Tracking\nFor most launches, the weather balloon's location and altitude can be tracked live in Google Earth. Some radiosondes such as the RS92SGP do not transmit latitude and longitude GPS data. Instead, they transmit raw GPS data, which must be converted into longitude and latitude on the receiving end (your computer). To do this, the radiosonde's starting coordinates, UTC launch date and UTC time, and an up to date GPS almanac are required. The almanac is a data file that stores information about the GPS satellite locations. The MeteoModem M2K2/M10, Graw DFM-06 and Meteolabor SRS-C34 are radiosondes which transmit already decoded location data. The following steps are for the other radiosondes which transmit raw GPS data, such as the RS92SGP.\n- Download an up to date Almanac from the US Coast Guard Nav Center. You will want to get the current SEM Almanac with the .al3 extension.\n- In SondeMonitor, go to Tools -> GPS Arm. Enter the Latitude and Longitude of the weather balloon's launch location. You will also need to enter the UTC date of the flight, and the approximate UTC time at mid flight. Make sure the date and time is in UTC time. Weather balloons last about 2-4 hours, so just estimate a mid flight time. Select Almanac as your Orbital data. The other options can be left as default.\n- Once you press OK, a file selection dialog box will pop up. Browse to the folder your current .al3 Almanac file is stored in, and open it. Now, if you have set the Almanac, start coordinates, and date and time up correctly, the GPS Residual in the SondeMonitor telemetry status window will be to within a couple of hundred meters. The smaller the residual, the more accurate the weather balloon location is. If you have gotten any parameters wrong, the residual will be very large.\n- To see the balloon in Google Earth, go to Options -> Google Earth and ensure that Live G-E Server has a check next to it by clicking it if it does not.\n- Now open your SondeMonitor folder in Windows Explorer. Find the file google_sonde.kml, and open this file with Google Earth. You should now be able to see the weather balloon's launch location and current live location in Google Earth.\nOther Radiosonde Decoding Software\nRS: This is a free command line based program which can decode multiple radiosonde protocols. Unlike Sondemonitor it however does not provide any graphs, just raw data.\nTracking your own High Altitude Balloons\nSome hobbyists enjoy launching their own balloons to take video and photography of the earth. It is legal to launch your own high altitude balloons with permission from your Civil Aviation Authority. Blogger nerdsville has been keeping tabs on the Stratodean team who have launched their own high altitude balloons and use the RTL-SDR to track them. A good video showing an overview of their SDR tracking system can be found here. More information about Amateur high altitude ballooning can be found here.\n- A good outside antenna is required to receive radiosonde signals. Ensure the antenna is placed as high as possible.\n- A low noise amplifier (LNA) such as this one or this one placed near the antenna may help with weak signals.\n- The signal frequency may bounce around a lot. This is because the radiosonde can pass through several atmospheric disturbances.\n- The YouTube video by Superphish shown at the beginning of this article can be used to test Sondemonitor by using Stereo Mix. Although, testing the GPS tracking will not be possible.\nIf you enjoyed this tutorial you may like our book available on Amazon. Available in eBook and paperback formats."", ""Dr Damian Murphy - atmospheric physicist\nScientists of the Antarctic: Dr Damian Murphy\nI research the movement of air in the upper parts of the atmosphere, above what we would typically call the weather.\nAtmospheric waves transfer momentum from the lower parts of the atmosphere into other parts of the atmosphere and, when they do that, they force large-scale circulations that can change the nature of the atmosphere.\nThese waves are made by airflow over mountains and landscape features, but they're also made by the air movements associated with cold fronts and changes in the jet-stream.\nSo the waves can be measured by making measurements of the wind using atmospheric balloons but also using atmospheric radars.\nWe operate three atmospheric radars at Davis station.\nThe three atmospheric radars look at different parts of the atmosphere. So one mostly looks at what we call the weather, so the troposphere and the lower stratosphere. It measures the wind speed in that part of the atmosphere every few minutes.\nAnother one looks quite high up in the atmosphere between about 70 and a hundred kilometres, in an area called the mesosphere and lower thermosphere. Once again, it does it every few minutes.\nAnd then finally we have one that detects meteors as they come into the atmosphere, and the trail of the meteor gets blown along by the wind and we are able to measure the wind speed by gathering a whole stack of those detections of meteors.\nInterestingly, that last radar can also be used to study the meteors themselves.A lot of the data taken is fed to the Bureau of Meteorology for them to use in their weather forecasting. The other radars are used by my colleagues all around the world for studying wave and other activity on a global scale around the Earth.\nDr Damian Murphy: BSc (Hons), MSc, PhD\nThe atmosphere moves in mysterious ways and my research has long been involved in trying to understand that movement, which is technically known as atmospheric dynamics. I came into this field through a remote sensing group at the University of Adelaide that used and developed atmospheric radars. These systems are now sophisticated enough to give us regular wind measurements at a range of heights through the lower and middle atmosphere. Investigations of atmospheric dynamics and its drivers were a natural progression of my PhD research, which focussed on the flow of momentum due to waves at heights above 80 km.\nA post-doctoral fellowship with the Mawson Institute of Antarctic Research took me to Mawson Station for the winter of 1991 and introduced me to the challenge of radar remote sensing in Antarctica. Our program has met this challenge well with three radars now operating at Davis, sensing different parts of the polar atmosphere in different ways. Along the way I have researched waves that span large horizontal scales (planetary waves), atmospheric tides, and the localized waves generated by fronts, storms and mountains (gravity waves).\nA recent focus on gravity waves has taken me into the world of atmospheric modelling. These waves are important for moving momentum around our atmosphere and, in the southern hemisphere, affect the background atmospheric structure in which the ozone hole forms. They are too small to appear naturally in climate models so they have to be introduced through a scheme called a parameterization. Recent observations of gravity waves have highlighted some of the shortcomings of existing parameterizations, something we need to fix if we are to be able to accurately model the ozone hole.\nThe ozone-hole induced changes in the dynamics of the stratosphere flow down to the earth’s surface to affect southern Australian weather in spring and summer. My work on parameterizations with colleagues in the USA, UK, Japan and Australia, which straddles the worlds of observation and modelling, will help us predict these and other changes to our weather and climate.\n- Member - Scientific Committee on Atmospheric Research (SCAR) Action Group - Antarctic Gravity Wave Instrument Network (ANGWIN)\n- National Center for Atmospheric Research, USA\n- Utah State University, USA\n- University of Tokyo, Japan\n- National Institute of Polar Research, Japan\n- Met Office, UK\n- Monash University, Australia\n- Bureau of Meteorology, Australia\nGarcía R.R., Smith A.K., Kinnison D.E., de la Cámara A. and Murphy D.J. (2017). Modification of the Gravity Wave Parameterization in the Whole Atmosphere Community Climate Model: Motivation and Results Journal of the Atmospheric Sciences 74(12) 275-291. doi: 10.1175/JAS-D-16-0104.1\nMurphy D.J., Alexander S.P., Klekociuk A.R., Love P.T. and Vincent R.A. (2014). Radiosonde observations of gravity waves in the lower stratosphere over Davis, Antarctica Journal of Geophysical Research: Atmospheres 119(21) 11973-11996. doi: 10.1002/2014JD022448\nMurphy D.J., Alexander S.P. and Vincent R.A. (2012). Interhemispheric dynamical coupling to the southern mesosphere and lower thermosphere. Journal of Geophysical Research 117 D08114, 14pp. doi: 10.1029/2011JD016865""]"	['<urn:uuid:b3feda7b-4a73-4067-8c98-863607d0ff52>', '<urn:uuid:7f4f9ed8-ae12-4df8-b567-ab39f2926d53>']	factoid	direct	short-search-query	distant-from-document	multi-aspect	expert	2025-05-13T05:52:58.810667	6	89	2431
95	What influenced the development of participatory art in Latin America, and how did different artists implement it?	Participatory art in Latin America emerged from multiple influences and took various forms. In Ecuador, Guayasamín built a museum and co-designed La Capilla del Hombre (The Chapel of Man), a space where people could engage with humanity's potential for both cruelty and greatness. In Brazil and Venezuela, geometric abstraction evolved into interactive experiences - Brazilian Neo-Concrete artists like Lygia Clark created manipulable sculptures like 'Bicho' for spectator participation, while Venezuelan artist Jesús Soto developed 'penetrables' - installations made of colored plastic tubes that participants could enter and interact with. These participatory works often received state support, particularly in Venezuela, where they were used to project an image of modernity and technological advancement.	"['Oswaldo Guayasamín Calero\nJuly 6, 1919\n|Died||March 10, 1999 (aged 79)|\n|Los niños muertos, Manos de protesta|\n|Awards||Premio Eugenio Espejo (1991)|\nGuayasamín was born in Quito, Ecuador, to a native father and a Mestiza mother, both of Kichwa descent... His family was poor and his father worked as a carpenter for most of his life. Oswaldo Guayasamín later worked as a taxi and truck driver. He was the eldest of ten children in his family. When he was young, he enjoyed drawing caricatures of his teachers and the children that he played with. He showed an early love for art. He created a Pan-American art of human and social inequalities which achieved international recognition.\nHe graduated from the School of Fine Arts in Quito as a painter and sculptor. He also studied architecture there. He held his first exhibition when he was 23, in 1942. While he was attending college, his best friend died during a demonstration in Quito. This incident would later inspire one of his paintings, Los Niños Muertos (The Dead Children). This event also helped him to form his vision about the people and the society that he lived in.\nGuayasamín started painting from the time he was six years old. He loved to draw from that age. Starting from watercolors and transforming all the way through to his signature humanity pieces, his art career had many highlights. Although tragedy molded Guayasamín\'s work, it was his friend\'s death that inspired him to paint powerful symbols of truth in society and injustices around him. While his interest was seldom with his school work, he began selling his art before the time that he could even read. After his attendance at the School of Fine Arts in Quito, his career took off.\nLa Galería Caspicara, an art gallery opened by Eduardo Kingman in 1940, was one of the first places that Guayasamín was featured. His themes of oppression in the lower social classes allowed him to stand out and gain more recognition. El Silencio in particular, was a painting from this showcase that stood out. It marks a shift in Guayasamín\'s work from storytelling to focusing on his subjects symbolizing all human suffering. (http://scholar.library.miami.edu/1492books/OswaldoGuayasamin.pdf)\nGuayasamín met José Clemente Orozco while traveling in the United States of America and Mexico from 1942 to 1943. They traveled together to many of the diverse countries in South America. They visited Peru, Brazil, Chile, Argentina, Uruguay, and other countries. Through these travels, he observed more of the indigenous lifestyle and poverty that appeared in his paintings.\nIn 1988 the Congress of Ecuador asked Guayasamín to paint a mural depicting the history of Ecuador. Due to its controversial nature, the United States Government criticized him because one of the figures in the painting shows a man in a Nazi helmet with the lettering ""CIA"" on it.\nOswaldo Guayasamín won first prize at the Ecuadorian Salón Nacional de Acuarelistas y Dibujantes in 1948. He also won the first prize at the Third Hispano-American Biennial of Art in Barcelona in 1955. In 1957, at the Fourth Biennial of São Paulo, he was named the best South American painter.\nThe artist\'s last exhibits were inaugurated by him personally in the Luxembourg Palace in Paris, and in the Palais de Glace in Buenos Aires in 1995. In Quito, Guayasamín built a museum that features his work. His images capture the political oppression, racism, poverty, Latin American lifestyle, and class division found in much of South America.\nGuayasamín dedicated his life to painting, sculpting and collecting; however, he was an ardent supporter of the communist Cuban Revolution in general and Fidel Castro in particular. He was given a prize for ""an entire life of work for peace"" by UNESCO. His death on March 10, 1999, was considered a great loss to Ecuador and occurred in the midst of a political and socioeconomic crisis, with the day marked by strikes by the indigenous people (whom he spent his life supporting) and other sectors of society. He is still lauded as a national treasure.\nIn 2002, three years after his death, a building co-designed by Guayasamín, La Capilla del Hombre (""The Chapel of Man""), was completed and opened to the public. The Chapel is meant to document not only man\'s cruelty to man but also the potential for greatness within humanity. It is co-located with Guayasamín\'s home in the hills overlooking Quito.\n- ""Life And The Human Condition Through The Eyes Of Oswaldo Guayasamín"".\n- Organization of American States, Pan American Union Published by Organization of American States (1982). Américas. p. 40.\n- Estrada, Daniela. Chile: Exhibit to Celebrate Indigenous Art. Inter Press Service. 2008. Retrieved 3 November 2009.\n- Los Angeles Times, December 9, 1989', 'During his decades spent living in Europe, Uruguayan artist and theorist Joaquín Torres-García experimented with several different artistic modes, including making representational paintings (depicting recognizable images) in a Neoclassical style or with bright colors and bold brushstrokes. While living in Paris, he would also come into contact with European geometric abstraction (abstract art based on geometric forms) and created a group with other artists he encountered there. He transitioned from making small toys and representational paintings to making geometric abstractions. He eventually returned to Uruguay and helped influence artists in Argentina, Brazil, and later, Venezuela to make art in this new modern style.\nGeometric Abstraction rose to prominence in South America between the 1930s and the 1970s. Prior to this period, traditional representational art styles rooted in the traditions of academic painting were officially sanctioned and considered respectable in the region. This radical departure toward geometric abstraction was embraced by artists and state powers across Latin America as a way of culturally distancing themselves from the colonial past (c. 16th to early 19th century), while signifying their alignment with a new modern, economically independent future.\nJoaquín Torres-García in Paris\nLike many Latin American artists of his generation, who lived, worked, and studied in Paris between World War I and II, Torres-García came to Paris because it was seen as the artistic capital of the West. While living there in the 1920s and early 1930s, he met Theo van Doesburg and Piet Mondrian, the Dutch founders of the art movement De Stijl (also known as Neoplasticism). Together, they formed the artistic group “Circle and Square,” which promoted geometric abstraction in opposition to Surrealism, an art movement based on dream-like imagery and the subconscious that was well known in France at the time. Torres-García was inspired by Mondrian, but was critical of De Stijl’s strict austerity. He wanted to propose a more “human” approach to geometric abstraction that would engage his interests in Latin American Pre-Columbian and European ancient and Classical art.\nTorres-García’s Color Structure, made in Paris in 1930, demonstrates his interest in many of the same principles as the Neoplasticists, including the grid, a reduced palette of primary colors, and the use of the Golden Ratio. These qualities are also evident in Mondrian’s Composition with Red, Blue, and Yellow (made the same year as Torres-Garcia’s Color Structure), a non-objective painting divided asymmetrically by thick black lines into squares of various sizes filled with flat planes of white and primary colors, the largest one, a bright red. Torres-García was inspired by De Stijl’s emphasis on the grid and Constructivism’s geometry, as well as what he believed to be the “universalism” of nonobjective art—in other words, he believed that geometric abstraction, which does not depict recognizable figurative imagery, could be visually understood across all cultures. In Torres-Garcia’s Color Structure, we also see a grid composed of different sized of rectangles in blue, yellow, white, and red, arranged vertically and horizontally.\nTorres-García also adopted van Doesburg’s and Mondrian’s use of the Golden Ratio, an important concept to him, which he felt would help his art become integrated with natural and cosmic forces. But, unlike Mondrian, Torres-García emphasizes Color Structure’s imperfections: the grid is drawn freehand with wavy lines and the colors are muddy and include tonal variation and rough brushwork.\nConstructive Universalism in Uruguay\nWhen Torres-García returned home to Uruguay in 1934 (for financial reasons and the encouragement of friends), after more than forty years living abroad, he sought to bring geometric abstraction to Latin America as a way to reconcile this style with the region’s own cultural histories and artistic traditions. Dissatisfied with what he saw as a lack of emotion or humanity in Constructivism and De Stijl, he developed his own style called Universalismo Constructivo (Constructive Universalism), which sought to combine the “reason” of Constructivism’s and De Stijl’s geometry with the sources of abstract art found in the arts and crafts of ancient civilizations from around the world. He incorporated pictographs (simplified images or symbols) related to the cultures of various ancient civilizations (including Pre-Columbian cultures), into his images. He felt these pictographs communicated common ideas to people everywhere, making them “universal.”\nAs a cultural nomad who lived abroad in the U.S. and Europe for 43 years before returning to Uruguay, Torres-García was interested in the concept of “universalism” because he wanted to find visual elements that were shared by all cultures, underpinning his belief in the metaphysical wholeness of the universe. He also wanted to show how the geometric principles of pre-Columbian, Indigenous artistic styles actually anticipated later European geometric abstraction. His ideas paralleled psychologist Carl Jung, who believed that archetypal images could connect individuals to collective cultures and universal experiences. Torres-García was not relating to Jung directly, and for him, the metaphysical was much more important than the psychological. His search for the universal was not based on the psyche of the individual, but rather the universal collective.\nWe find an expression of these impulses in his painting Universal Art, a composition in earthy browns depicting many interconnected rectangular compartments filled with pictographs, including shapes, symbols, and recognizable images such as the sun, the moon, scales, fish, a heart, a house, boats, and people, that appear as if they are carved into wood or stone. Like his earlier works that borrow from Mondrian, Torres-García creates an asymmetrical grid based on the Golden Ratio with a reduced color palette, but his earth tones convey more warmth, and his rough, painterly strokes and shading appear more “crafty” and reveal a human touch.\nLater, Torres-García founded an arts and crafts workshop called the Taller Torres-García to disseminate his artistic theories to a younger generation of Uruguayan artists, whose style came to be known as the School of the South. Following Torres-García’s innovations in the 1930s and 1940s, artists across Latin America—especially in Argentina, Brazil, and Venezuela—began working in geometric abstraction, which would dominate the painting and sculpture in those countries until the 1960s and 1970s.\nAACI and Madí in Argentina\nIn 1944, a group of Argentine and Uruguayan artists based in Buenos Aires published the first and only issue of a magazine about abstract art titled Arturo, with texts and reproductions of artworks by Torres-García, Mondrian, and the Russian abstract artist Wassily Kandinsky. The magazine was intended to promote Concrete Art (a term first used by Theo van Doesburg to describe nonobjective geometric abstraction) in Argentina.\nTwo Argentine Concrete Art groups emerged from the magazine: the Association of Concrete-Invention (AACI) and the Madí Group. These developments took place during the first term of the presidency of the Argentine populist Juan Domingo Perón, whose administration officially sanctioned naturalistic, figurative art styles, which these Concrete art movements fought against.\nThe AACI was founded in 1945 by Argentine artist Tomás Maldonado and poet Edgar Bayley. The catalogue for the group’s first exhibition included their manifesto—a written statement declaring the group’s intentions, motives, and views—titled the “Inventionist Manifesto.” It called for artists to “invent” their own images, rather than trying to copy what they see, and justified Concrete art through Marxist political theories. \nEmbracing Mondrian’s and van Doesburg’s strict Concrete aesthetics while rejecting Torres-García’s emphasis on symbolism and a hand-made aesthetic, the AACI emphasized a rigorous, mathematical, even mechanical-looking approach to geometric abstraction with flat, planar colors. These principles are on display in Maldonado’s Development of a Triangle a composition on a white ground of intersecting straight and angular lines and a series of triangles, one yellow and another violet. \nIn 1946 the Madí Group was formed by artists Rhod Rothfuss, Carmelo Arden Quin, and Gyula Kosice.  Like the AAIC, Madí endorsed making nonobjective artworks with flat planes of bright color. But, unlike the AAIC, Madí art was more playful and experimented with three-dimensions and unusual materials such as Plexiglas and neon.\nMadí artists often rejected the traditional rectangular picture frame in favor of an irregularly-shaped canvas, known as a marco recortado (cutout frame). The cutout frame was first conceived by Rothfuss in an essay he wrote for Arturo, in which he argued that irregularly-shaped canvases would allow artworks to function like other objects in the world, rather than as windows framing views of another world. One example of the cutout frame is Rothfuss’s Three Red Circles, a bright yellow geometrically-shaped composition with shapes delineated with thick black lines, a blue rectangle at the top and on the side, and three small red circles on the left.\nConcrete and Neo-Concrete Art in Brazil\nIn 1951, Swiss Concrete artist and former Bauhaus student Max Bill won the grand prize for sculpture at the First São Paulo Biennial (a large international exhibition occurring every two years) in Brazil, for his metallic sculpture of flowing, intertwining ribbon-like forms, called Tripartite Unity. This sculpture would influence a young generation of Concrete artists in the country, including the Grupo Ruptura in São Paulo and the Grupo Frente in Rio de Janeiro. Concrete art captured the values of science and mathematical precision heralded in Brazil in the 1950s, a period of rapid industrial growth, modernization, and the development of a new capital in Brasília defined by architect Oscar Niemeyer’s futuristic International Style architecture.\nThe Grupo Ruptura\nThe Grupo Ruptura was formed in 1952 with an exhibition at the Museum of Modern Art of São Paulo. The group’s name meant “rupture,” and it sought to break with traditional art styles, namely naturalistic painting, which was seen as elitist (though this break was not specifically tied to political radicalism). Their works were characterized by flat colors and a reduced palette, geometry, and industrialized media like enamels and mechanical techniques like spray painting that would not reveal the hand of the artist. Their works also incorporated Gestalt psychological theory (a perceptual theory about how the brain forms a whole image from many component parts) by training the viewer’s eye on outlines as contours of a solid shape, as in Judith Lauand’s Virtual Space, a painting of a pinwheel-like shape of white and purple lines in a field of black. Lauand was also the only woman in the Grupo Ruptura.\nThe Grupo Frente and Neo-Concrete art\nThe Grupo Frente was founded by artist and teacher Ivan Serpa in Rio de Janeiro in 1954. Many of the artists involved were his former students at the Museum of Modern Art of Rio de Janeiro. They rejected the Grupo Ruptura’s strict adherence to purity, science, and math and promoted instead more creative intuition in geometric abstraction. This shift in the Grupo Frente’s brand of Concrete art eventually led to a new style altogether, known as Neo-Concrete art, pioneered by artists Lygia Clark, Lygia Pape, and later, Hélio Oiticica.\nThe principles of Neo-Concrete art were theorized by poet Ferreira Gullar in his “Neo-Concrete Manifesto” (1959), which called for more sensuality, freedom, and feeling in Concrete art. Like Torres-García who sought to infuse geometric abstraction with more emotion, the manifesto sought to distance the new movement from the dogmatic rationalism of European Concrete art styles like Neo-plasticism and Constructivism.\nGullar also developed the theory of what he termed the “non-object,” by which he meant an art object that would function as a mediator between the spectator and the physical experience of the object. This is exemplified by Lygia Clark’s Bicho (Critter), a metal sculpture made of moveable flaps intended to be manipulated and rearranged by the spectator-participant (or someone who observes and participates). As Clark’s Bicho suggests, Neo-Concrete art adapted Concrete art’s geometric shapes and transformed them into organic three-dimensional objects to be handled by spectators, or environments to be physically entered, which helped to break down boundaries between art and life in Brazilian art of the 1960s.\nOptical and Kinetic Art in Venezuela\nTwo other forms of geometric abstraction, known as Optical (or Op, a style of abstract art based on patterns and optical illusions) and Kinetic art (objects that have moving parts), became popular in Venezuela in the 1950s and 1960s. These styles were dominated by three artists in the country: Carlos Cruz-Diez, Alejandro Otero, and Jesús Soto. Their works included small and large-scale abstract sculptures and public artworks made of bright colors and industrial materials that moved, or appeared to move.\nA famous example are Soto’s “penetrables,” tubes of colored plastic suspended from the ceiling in box-like shapes, into which participants could enter and play. While Brazilian Neo-Concretists sought to move away from the purely optical toward the experiential and sensual, the Venezuelans still embraced the visual, but also created participatory and sensually experiential environments and objects to be interacted with, like Soto’s penetrables.\nThe Op and Kinetic works by these artists received corporate and government support from the Venezuelan regime of Colonel Marcos Pérez Jiménez’s dictatorship of the 1950s, as well as later democratically elected administrations in the 1960s and 1970s, and resulted in the commissions of several large-scale public artworks. The state and corporate leaders believed such works helped position Venezuela on the world stage as a modern, forward thinking, and technologically advanced country. This was important to them as they were growing their oil industry for international export. These works were used by corporations and the state as propaganda promoting Venezuela as an international modern center of industry, revealing how state-patronage and nationalist interests intervened in the so-called “avant-garde” art in the country during the period.\nAnother important artist in the history of Venezuelan abstraction was Gego (Gertrud Goldschmidt), a German emigrant, who developed her own approach to geometric abstraction, creating delicate sculptures and environments (sculptures that occupy entire gallery spaces) made of wire. Gego’s large Reticulárea (Reticular), created at the Museo de Bellas Artes in Caracas in 1969, comprises a sprawling wire grid that filled the gallery’s floor, walls, and ceiling, into which spectators could enter and walk around.\nContributions and Legacy\nLatin American geometric abstraction united international principles of modernist abstraction with local cultural traditions, and led to more participatory forms of art. It also served as an ideological tool for both Latin American artists and nation-states to signal a break with traditional art styles—associated with their colonial past—and to assert a new, modern, and often utopian industrialized future. Latin American geometric abstraction is probably most notable for the large number of women artists who were leaders in these movements and who achieved successful artistic careers in their lifetimes, something that was much less common with mid-twentieth century art movements in the U.S. and Europe. \nNotes: Their formulation of “Concrete-Invention” was rooted in their commitment to Marxist materialism and anti-idealist revolutionary and collective art.  The term “Madí” has various purported origins: it may have represented the combination of the first syllables (in Spanish) of the term “dialectic materialism,” it may have been an abbreviation of “Madrid,” or it could have been an acronym for “Carmelo Arden Quin.”  In addition to the women artists mentioned in this article, Judith Lauand, Lygia Pape, Lygia Clark, and Gego, were many others, including Lydi Prati, Mira Schendel, Fanny Sanín, María Freire, Amalia Nieto, and Mercedes Pardo.\nGabriel Pérez-Barreiro, “Concrete Art in Latin America.” Grove Art Online, March 26, 2018.\nDavid Fernando Cortés Saavedra, “Geometric Abstraction and Concrete Art in South America.” Routledge Encyclopedia of Modernism, September 5, 2016.\nAlexander Alberro, Abstraction in Reverse: The Reconfigured Spectator in Mid-Twentieth-Century Latin American Art (Chicago: University of Chicago Press, 2017).\nMónica Amor, Theories of the Nonobject: Argentina, Brazil, Venezuela, 1944–1969 (Oakland, CA: University of California Press, 2016).\nYve-Alain Bois, et al. Geometric Abstraction: Latin American Art from the Patricia Phelps de Cisneros Collection (New Haven, CT: Yale University Press, 2001).\nDan Cameron, Kinethesia: Latin American Kinetic Art, 1954–1969 (Palm Springs, CA: Palm Springs Art Museum, 2017).\nMaría Amalia García, Abstract Crossings: Cultural Exchange between Argentina and Brazil (Oakland, CA: University of California Press, 2019).\nAleca Le Blanc and Pia Gottschaller. Making Art Concrete: Works from Argentina and Brazil in the Twentieth Century in the Colección Patricia Phelps de Cisneros (Los Angeles: Getty Publications, 2017).']"	['<urn:uuid:b366920f-d06a-4d59-b9f9-53f7c5f75b7f>', '<urn:uuid:86e2e91b-fbaf-45c1-9fb3-0d6526737c20>']	open-ended	with-premise	concise-and-natural	similar-to-document	multi-aspect	expert	2025-05-13T05:52:58.810667	17	112	3429
96	How did Ely Parker and James Longstreet differ in their post-Civil War political allegiances and reception among Southerners, considering both served in significant positions under President Grant?	Ely Parker and James Longstreet had notably different experiences in their post-Civil War political careers and reception. Parker served as Commissioner of Indian Affairs under Grant but faced controversy and resigned after being criticized for his handling of Indian purchases, though he was cleared of fraud charges. In contrast, Longstreet joined the Republican Party and openly supported civil rights for freed slaves, which made him deeply unpopular among Southerners. While both men received appointments from Grant, Longstreet's political choices made him a particular target of criticism in the South, especially from Lost Cause advocates like Jubal Early. Longstreet maintained his controversial political stance throughout his life, serving in various federal positions under multiple presidents, while Parker largely withdrew from government service after his resignation as Commissioner of Indian Affairs.	"['A Seneca Life\nBy: Patricia C. Galez\nOn April 9, 1865, a small group of men met in the sitting room of a home in the village of Appomattox Court House, Virginia. On that day and in that place, Lieutenant General Ulysses S. Grant, commander of the Union Armies, accepted the surrender of General Robert E. Lee, leader of the Confederate Army of Northern Virginia. Although other Confederate forces continued to exist and fought on until early June of 1865, the events of that April afternoon essentially brought to an end the bloodiest conflict ever to have taken place on American soil. The Civil War saw the death of more than 618,000 former fellow Americans: Northerners who fought to preserve the Union and Southerners who believed that the rights of the individual states superseded those of the government in Washington.\nAmong the small group of men who witnessed this momentous event were staff members of Lieutenant General Grant; Colonel Charles Marshall, military secretary to General Lee; and Ely S. Parker, adjutant to General Grant and member of the Seneca Nation of Indians. Ely Parker’s rise to national prominence speaks to the determination of one extraordinary man to succeed in a world other than his own.\nThe year 2015 marks the 150th anniversary of the war’s end. The sesquicentennial will be marked at cemeteries where the remains of Civil War dead are interred and at museums and battle sites in both the North and the South. Reenactments will bring to life numerous battles of the war, commemorating those epic events that ultimately decided the outcome of the conflict. As the entire nation – and, indeed, the world – looks back on the events of 1861 to 1865, it is fitting to turn one’s attention to a man whose name is unknown to many, but whose accomplishments before, during, and after the war were significant and unique.\nEly Samuel Parker was born in 1828 on the Tonawanda Reservation of the Seneca Nation of Indians near Indian Falls in Western New York State. The exact date of his birth is unknown. His name was Ha-sa-no-an-da, which means “Leading Name” in the Seneca language. The name Ely was conferred on him by the Reverend Ely Stone, a minister at the Baptist Mission School that Ely attended as a boy.\nEly’s father was William Parker, who had fought on the side of the United States in the War of 1812. The family acquired the surname Parker from a British officer who had been captured during the Revolutionary War and subsequently lived among the Seneca for a time. Before returning to Canada, the officer gave his name to the family with whom he had lived. The patriarch of that family was William Parker’s father.\nEly’s mother was Elizabeth Johnson, a member of the Wolf Clan. Elizabeth was from an illustrious lineage. Her father, James Johnson, was a Seneca Chief and successor to Handsome Lake, the Seneca leader credited with bringing back traditional religious beliefs to his people. Elizabeth’s uncle was Cornplanter, Seneca War Chief who fought on the side of the British during the American Revolution; her great-uncle was the legendary orator Red Jacket.\nThe story is told of a dream that Elizabeth had before the birth of her son. In her dream, the winter skies opened up to reveal a rainbow, which split in two. On one end of the rainbow were signs with letters resembling those on the signs of white business establishments. The dream was understood to be a prophecy about her soon-to-be-born son: “…he will become a white man as well as an Indian…His sun will rise on Indian land and set on white man’s land.” The dream was, indeed, prophetic.\nAt the age of ten Ely traveled to Canada, to the Six Nations of the Grand River near Brantford in southwestern Ontario. During this time, he reached a momentous decision. Ely was traveling with a group of military officers who passed the time with banter that they expected Ely would not understand. Ely was distressed by his lack of fluency in English, and the incident caused the young boy to resolve to become fluent in the English language. To accomplish his goal, Ely returned to Indian Falls and renewed his studies, first locally and then at the Cayuga Academy in New York State’s Finger Lakes Region.\nBy this time Ely Parker was coming of age, utilizing his talents for the good of his people. The Buffalo Creek Treaty of 1832 and the Compromise Treaty of 1842 provided for the sale of Seneca lands to the Ogden Land Company and removal of the Seneca people to the Territory of Kansas. Parker’s skills in both the English language and diplomacy put him at the forefront of efforts to help the people of the Seneca Nation escape the dire consequences that the treaties sought to bring about.\nAlthough there is no record of Parker attending college, he continued his education by studying with individuals who recognized his considerable intellectual abilities. In the late 1840s he studied law with an attorney in Ellicottville, New York. Unfortunately, his career as an attorney was brief: New York State law stipulated that only a citizen could be admitted to the bar, a status not accorded to members of Native Nations until 1924 with the passage of the Indian Citizenship Act.\nParker turned to engineering and proved to be an apt student, learning from the engineers with whom he worked on a project to extend the Genesee Valley Canal in Central New York State. In an effort to secure a position with the federal government, Parker applied to the U.S. Treasury Department, which appointed him construction superintendent for a project at Galena in northwestern Illinois.\nParker’s work for the Tonawanda Seneca continued even as he pursued his engineering career. In recognition of his tireless work for his people, he was proclaimed Grand Sachem of the Six Nations of Indians and given a new name: Do-ne-ho-ga-wa, which means “Open Door.” As a sachem, Parker was a member of the governing body of the Iroquois Confederacy, an affiliation of the six Native Nations of Western and Central New York State: Mohawk, Oneida, Onondaga, Cayuga, Seneca, and Tuscarora. Although all sachems were, in theory, equal in power and influence, Parker’s exceptional ability and accomplishments on behalf of his people caused him to emerge as the “first among equals,” the leading sachem of the Six Nations. He was twenty-three years of age.\nParker’s influence was most definitely felt in negotiations for the treaty ratified in 1858. This treaty provided for a maximum of $256,000 for the Tonawanda Seneca to purchase acreage from the Holland Land Company. Although they were only able to purchase 60% of the land they had lost, what they did purchase was theirs and would not be taken from them. For his efforts in securing the Tonawanda homeland, Ely Parker was given fifty acres of the newly acquired property.\nIn March of 1861 political considerations caused Parker to lose his job at Galena. Barely a month later, hostilities erupted when troops of the newly formed Confederate States fired on Union soldiers garrisoned at Fort Sumter, South Carolina. The Civil War had begun. Parker attempted to secure a military commission, but his efforts were in vain. He returned to his home and remained there, farming the land, for two years. When an acquaintance from Galena, now a brigadier general, recommended him for an appointment as assistant adjutant general of volunteers, with the rank of captain, Parker’s longtime quest to serve during the war was fulfilled; on June 4, 1863, Parker accepted his commission. On September 18th, he became a member of Ulysses S. Grant’s personal military staff and accompanied the General to Washington. When one of Grant’s military secretaries resigned for reasons of health, Parker was promoted to this position, in which he served for the remainder of the war.\nAs the war progressed into spring of 1865, the possibility of a Union victory became more and more likely. When General Lee agreed to meet with Grant to discuss terms of surrender, Ely Parker was introduced to Lee as a member of Lieutenant General Grant’s staff. After a brief moment of apparent consternation, Lee shook hands with Parker and said, “I am glad to see one real American here,” to which Parker responded, “We are all Americans.” When Grant’s other military secretary became too flustered to continue recording the articles of surrender, Parker was pressed into service and completed the task. Thus, Ely S. Parker, member of the Seneca Nation of Indians and Captain in the Union army, stepped firmly and for all time into the pages of American history.\nThe end of the war did not signal the end of Parker’s association with General Grant. He offered counsel to Grant on Indian affairs, not only concerning the Tonawanda Seneca but also Native Nations in other parts of the country. His military career continued on an upward path as well, and he received one commission after another, ultimately reaching the rank of Brevet Brigadier General. The term brevet refers to an honorary rank, often conferred for outstanding service.\nEly Parker’s life was a success by any standard. He had put his prodigious skills to work for the Tonawanda Seneca and for the\nUnited States and had risen to fame in both of these worlds. His personal life, however, had become one of loss. Parker’s mother, Elizabeth, died in February of 1862 and his father, William, in April of 1864. The passing of his parents, especially his father, left Parker bereft and without the strong ties to family and home that he had always had. All that was to change when, on Christmas Eve in 1867, Ely Parker married Minnie Orton Sackett. The groom was 39 years of age; the bride, from a prominent Washington family, was 18. Ulysses S. Grant continued to play a role in Parker’s life: because Minnie’s father had been killed during the war, the General had the honor of giving the bride away. The Parkers had one child, Maud Theresa, born August 14, 1878.\nParker’s history of public service continued, and on April 26, 1869 he was confirmed by Congress as Commissioner of Indian Affairs, the first Native American to hold this office. Unfortunately, his tenure as Commissioner was not without controversy: charges were brought against him for defrauding the United States Government while purchasing Indian supplies and, in early 1871, he was put on trial. Although he was not convicted of fraud, Commissioner Parker was criticized for failing to consult the Board of Indian Commissioners regarding Indian purchases. It is ironic that this Board had been created in 1869 at the suggestion of, among others, Ely Parker. When he learned that he would be compelled to submit all expenditures to the Board for review, Parker resigned as Commissioner after serving in this capacity for only two years.\nParker, embittered by the unfortunate outcome of his tenure with the Bureau of Indian Affairs, left government service and embarked upon a career as a businessman and investor. His success was not long-lived, however, and his financial losses became significant.\nHe soon found that he had been away too long from engineering and that resuming his career in this field was no longer an option. An old friend used his influence as President of the Board of Commissioners of the New York City Police Department to secure a position for Parker with the Committee on Repairs and Supplies of the Police Board of Commissioners. This was a job, not a profession, but it did provide Parker with gainful employment and at least somewhat of an outlet for his active mind. He also continued as an advocate for Native Americans, recognizing education as the key to a better future for members of Native Nations.\nThe death of his brother Levi in April of 1895 left Ely as the last remaining Parker sibling. The loss of his family, along with worries about his tenuous financial position and declining health, took their toll. On August 30, 1895, Ely Samuel Parker died. He was buried with full military honors in Fairfield, Connecticut, where he and Minnie had made their home for many years. On January 20, 1897, he was reinterred at Forest Lawn Cemetery in Buffalo, New York, under the statue of Red Jacket, renowned Seneca orator and ancestor of his mother, Elizabeth.\nThe name of Ely Parker is not widely known outside the Seneca Nation. Yet, for those who are aware of his life, his intelligence, his commitment to his people, and his military and civilian accomplishments in the world that he chose to make his own, he stands as an extraordinary figure. The title of William H. Armstrong’s biography of Parker, Warrior in Two Camps (which provided much of the information that comprises this article), is particularly apt. The notion of two camps is clear: the Seneca world and the larger white world that formed the earlier and later settings of Parker’s life. The idea of a warrior is equally as appropriate. As an army officer, Parker served the Union cause and was rewarded for his service with military honors. As a warrior for his people, he fought with words against a government that sought to deprive the Tonawanda Seneca of their ancestral home. It has been my privilege and my pleasure to retell, in some small way, the remarkable story of Ely S. Parker.', 'James Longstreet (1821-1904)\nJames Longstreet (January 8, 1821 - January 2, 1904) was one of the foremost generals of the American Civil War, and later enjoyed a successful post-war career working for the government of his former enemies, as a diplomat and administrator.\nLongstreet was born in Edgefield District, South Carolina, the son of a farmer, but grew up in Augusta, Georgia, until age 12 when his father died and the family moved to Somerville, Alabama. He was appointed to the U.S. Military Academy at West Point by the state of Alabama in 1838 and graduated in 1842. He served with distinction in the Mexican War, was wounded at Chapultepec, and received two brevets and the staff rank of major. He resigned from the U.S. Army on June 1, 1861 to cast his lot with the Confederacy in the Civil War.\nCareer as Confederate General\nLongstreet was already highly regarded as an officer, and he was almost immediately appointed as a brigadier general in the Confederate Army. His assignments included: brigadier general, CSA June 17, 1861); commanding brigade (in 1st Corps after July 20), Army of the Potomac July 2 - October 7, 186 1); major general, CSA (October 7, 1861); commanding division, Ist Corps, Army of the Potomac (October 14-22, 1861); commanding division (in Potomac District until March 1862), Department of Northern Virginia (October 22, 1861 - July 1862); commanding lst Corps, Army of Northern Virginia July 1862 - February 25, 1863; May - September 9, 1863; April 12 - May 6, 1864; and October 19, 1864-April 9, 1865); lieutenant general, CSA (October 9, 1862); commanding Department of Virginia and North Carolina (February 25-May 1863); commanding his corps, Army of Tennessee (September 19-November 5, 1863); and commanding Department of East Tennessee (November 5, 1863-April 12, 1864).\nCommanding a brigade, he fought well at the First Battle of Bull Run, and earned a promotion to major general.\nDuring the Peninsula Campaign in the spring and summer of 1862 he saw further action at Yorktown, Williamsburg, Seven Pines, and the Seven Days. In the final days of the latter he also directed A.P. Hill\'s men. Longstreet\'s career took off when Gen. Robert E. Lee took command of the Army of Northern Virginia. During the Seven Days Battles, Longstreet had operational command of nearly half the Lee\'s army.\nAs a general, Longstreet showed a talent for defensive fighting, preferring to position his troops in strong defensive positions and compel the enemy to attack him. Once the enemy had worn itself down, then and only then would Longstreet contemplate an attack of his own. In fact, troops under his command never lost a defensive position during the war. Lee referred to Longstreet affectionately as his Old War Horse. (Longstreet\'s friends generally called him Pete.) His record as an offensive tactician was mixed, however, and he often clashed with the highly aggressive Lee on the subject of the proper tactics to employ in battle.\nIronically, one of his finest hours came in August 1862, when he commanded what had become known as the First Corps at the Second Battle of Bull Run. Here, he and his counterpart in command of the Second Corps, Lieut. Gen. Thomas J. Jackson, switched their normal roles, with Jackson fighting defensively on the Confederate left, and Longstreet delivering a devastating flank attack on the right that crushed the slightly larger Union Army of Virginia.\nThe next month, at the Battle of Antietam, Longstreet held his part of the Confederate line against Union forces twice as numerous. On October 9, a few weeks after Antietam, Longstreet was promoted to lieutenant general, the senior Confederate officer of that rank.\nHe only enhanced his reputation that December, when his First Corps played the decisive role in the Battle of Fredericksburg. There, Longstreet positioned his men behind a stone wall and held off fourteen assaults by Union forces. About 10,000 Union soldiers fell; Longstreet\'s men lost but 500.\nIn the winter and early spring of 1863, Longstreet bottled up Union forces in the city of Suffolk, Virginia, a minor operation but one that was very important to Lee\'s army, still stationed in devastated central Virginia. By conducting a siege of Suffolk, Longstreet enabled Confederate authorities to collect huge amounts of foodfood that had been under Union controland send it to feed Lee\'s hungry soldiers. However, this operation caused Longstreet and 15,000 men of the First Corps to be absent from the Battle of Chancellorsville in May.\nLongstreet rejoined Lee\'s army after Chancellorsville and took part in Lee\'s Gettysburg campaign, where he clashed with Lee about the tactics Lee was using. Longstreet, who had come to believe in the strategic offense and the tactical defense, was proven right when the Confederate attacks on the second and third days were repulsed. This campaign marked a fundamental change in the way Longstreet was employed by Lee. In the past, Lee had preferred to use Longstreet in defensive roles, which were his strength, and use Jackson and the Second Corps to spearhead his attacks. But Jackson had been killed at Chancellorsville, and now Lee wanted Longstreethis best remaining lieutenantto fill that role.\nLongstreet was willing and capable of doing so, but he argued with Lee a number of times during the battle of Gettysburg, essentially telling Lee that his tactics were going to lead to defeat. Longstreet advocated disengagement from the enemy after the first day\'s battle, embarking on a strategic flanking movement to place themselves on the Union line of communication, and inviting a Union attack. He argued that Lee had agreed before the campaign that this ""strategic offensive, tactical defensive"" would be the proper course. But Lee had settled on the tactical offensive. On July 2, the second day of the battle, Longstreet\'s assault on the Union left nearly succeeded, but on July 3, when Lee ordered Longstreet, against his wishes, to attack the Union center in what became known as ""Pickett\'s Charge"", the Confederates lost 7,000 men in an hour. Longstreet was right, and Lee was wrong and immediately admitted as much, but to many of Lee\'s admirers, such as Jubal Early and the Lost Cause advocates after the war, the lost battle was Longstreet\'s fault.\nLee never blamed anyone but himself for the defeat, and in fact dispatched Longstreet to Georgia that fall in response to a desperate appeal for help from the Confederate Army of Tennessee. That resulted in Longstreet and 14,000 of his First Corps veterans taking part in the Battle of Chickamauga that September. Longstreet led an attack of his men and some of the Army of Tennessee men that routed the Union Army of the Cumberland and won the greatest Confederate victory ever in the western theatre.\nLongstreet soon clashed with the much maligned Army of Tennessee commander, Gen. Braxton Bragg, when Bragg failed to capitalize on the victory by finishing off the Union army and recapturing the city of Chattanooga, Tennessee. Longstreet became leader of a group of senior commanders of the army who conspired to have Bragg removed. The situation became so grave that Jefferson Davis, President of the Confederacy, was forced to intercede in person. What followed was one of the most bizarre scenes of the war, with Bragg sitting red faced as a procession of his commanders declared him incompetent. Amazingly, Davis sided with Bragg and did nothing to resolve the conflict. Bragg not only stayed in command, he sent Longstreet and his men on a disastrous campaign into east Tennessee, where in December, they were defeated in an attempt to recapture the city of Knoxville. After Bragg was driven back into Georgia, Longstreet and his men returned to Lee.\nLongstreet helped save the Confederate Army from defeat in his first battle back with Lee\'s army, the Battle of the Wilderness in May, 1864, where he launched a powerful flanking attack against the Union II Corps and nearly drove it from the field. But he was wounded in the processaccidentally shot by his own men not a mile away from the place where Jackson befell the same fate a year earlierand missed the rest of the 1864 spring campaign, where Lee sorely missed his skill in handling the army. He rejoined Lee from October, 1864, to March, 1865, during the Siege of Petersburg, commanding the defenses in front of the capital of Richmond. He surrendered with Lee at Appomattox Court House on April 9, 1865.\nAfter the War\nAfter the war, Longstreet renewed his friendship with his old friend and adversary, Lieut. Gen. and future President Ulysses S. Grant, and became the only major Confederate officer to join the postwar Republican party. For this, he lost favor with many Southerners, but nevertheless enjoyed a successful second career. He also converted to Catholicism when he married his second wife which also made him less popular in the more Protestant South. Moreover he advised the Southern state governments to extend civil and voting rights to freed slaves, much to the chagrin of his former Confederate comrades.\nLongstreet decided to make New Orleans his first post-War home. He found various business opportunities there, associating himself with a cotton brokerage and soon assumed the presidency of the Great Southern and Western Fire, Marine and Accident Insurance Company. He unsuccessfully sought the presidency of the Mobile and Ohio Railroad but was made president of the Southern Hospital Association.\nUlysses S. Grant appointed Longstreet to the position of surveyor of customs for the port of New Orleans after he was inaugurated President in 1869. In June 1873 he was named to the four-year position on the Levee Commission of Engineers. By 1878 Rutherford B. Hayes had appointed him deputy collector of internal revenue. He remained in the position for only a few months, before accepting the position of postmaster in Gainesville, Georgia.\nIn May 1880, President Rutherford B. Hayes appointed Longstreet as his ambassador to the Ottoman Empire. President Garfield, another former Union general, nominated him to a four-year term as U.S. Marshall for Georgia, a position he had long desired. He served in that capacity for slightly over three years, but his tenure was plagued by controversy and political intrigue.\nWith the election of President Grover Cleveland Longstreet had no prospects of receiving another position and he went into semi-retirement in Gainesville, Georgia. There he operated the Piedmont Hotel, and enjoyed raising turkeys, tending an orchard, and nurturing his vineyard. His wife, Louise died in December of 1889. He began to write his memoirs, but the task was to take five years.\nLongstreet married Helen Dortch in September of 1897. She was a native Georgian and assistant state librarian at the time of the marriage, and only 34 years old.\nLongstreet served from 1897 to 1904, under Presidents William McKinley and Theodore Roosevelt, as U.S. Commissioner of Railroads.\nLate in life, after bearing criticism of his war record from other Confederates for decades, he refuted most of their arguments in his memoirs entitled From Manassas to Appomattox. The memoir was published in 1896 and created a furor of controversy, which continues today in Civil War circles\nHe attended many military and Civil War related reunions, including the 100th Anniversary of the U.S. Military Academy in 1902 and the Memorial Day Parade of 1902, when he commented ""I hope to live long enough to see my surviving comrades march side by side with the Union veterans along Pennsylvania Avenue, and then I will die happy.""\nHe outlived most of his detractors and died of pneumonia on the morning of January 2, 1904, while visiting his daughter\'s home in Gainesville, Georgia, just six days short of his 83rd birthday. He is buried in Alta Vista Cemetery.\nBecause of criticism from authors in the Lost Cause movement (Jubal Early in particular), Longstreet\'s war career was disparaged for many years after his death. The publication of Michael Shaara\'s novel The Killer Angels in 1974, based in part on Longstreet\'s memoirs, has been credited with restoring his reputation as an outstanding general.\nIn 1990, one of the last monuments erected at Gettysburg National Military Park is a belated tribute to Longstreet. He is depicted on his horse at ground level in a grove of trees in Pitzer Woods, unlike most generals, who are elevated on tall bases overlooking the battlefield. This is indicative of the continuing controversies over the career of James Longstreet.']"	['<urn:uuid:9874e3fd-bac6-4851-864b-8538a4a11609>', '<urn:uuid:e7d1e680-caf0-4f0b-89f6-66ba3143ff55>']	open-ended	direct	verbose-and-natural	similar-to-document	comparison	expert	2025-05-13T05:52:58.810667	27	129	4302
97	what are differences cherry oak wood cabinets working with quality construction details	Cherry and oak have distinct characteristics in cabinet construction and workmanship. Cherry cuts, stains, and sands beautifully but tends to burn during routing and requires careful attention to feed direction when jointing and planing. Oak is commonly used in solid wood cabinets, with different varieties available - regular oak shows strong flower grain, while rift oak (a veneer) has the flower cut away leaving vertical grain. In higher-quality cabinets of either wood, solid wood may only be used for doors and frames, and the best-quality cabinets match the wood grains of their faces and boxes.	"['Oak is the most common wood used for solid wood cabinets. Because of the strong ""flower"" grain in the wood, oak looks best in country settings. You can stain it almost any color, and since the graining is so strong, the grain will always come through the stain. To offset the reddish coloring, use either white oak, which is lighter in its natural coloring, or, if you prefer red oak, go ""browner"" in the stain selection. A cherry stain enriches the color of red oak.\n- Cherry, used primarily in formal cabinets with raised panels, either French or English style, is an elegant wood with a natural reddish coloring that is much deeper than oak.\n- Rift oak is a veneer much sought after by architects and designers. The oak flower is cut away, leaving the vertical grain. White oak is used for rift selection, so that it becomes very light when stained. This type of oak would generally be used in flush overlay construction, in which no frames would be visible.\n- Hickory, another wood used in country settings, is a strong brown wood with natural markings.\n- Birch has a very white, natural coloring. It takes a stain well and is often used in contemporary cabinets as well as in raised and recessed panel doors.\n- Ash is the whitest wood and often employed in cabinet interiors. It has very little graining or flower and takes a stain well in addition to easily accepting enamel or lacquer paint.\n- Pine, which has a yellowish cast, takes distressing and antiquing beautifully, one reason it is so often used in English, French, and American country settings. Its drawback is that it is a soft wood and can be nicked easily.\n- Maple is a hard wood that some manufacturers use primarily as a base for enamel or stains. It has little graining and tends to appear yellow.\nMore exotic woods, such as wormy chestnut, which is highly distressed, and cypress, which has a yellow cast, are primarily available regionally and are not offered by most kitchen cabinet manufacturers. Those who know best about how to work with these woods are specialty wood workers. To find a cabinet shop in your area, visit NKBA.org/ProSearch.\nIn ordering wood kitchen cabinets, try to see a sample of currently produced work to check the colors. Samples can oxidize over time so you’ll want to see how the fresh stains appear.\nSolid Wood Inside and Out?\nNote that many stores will promote their kitchen cabinets as made of ""wood,"" yet a single cabinet box can be made up of a wide range of products and veneers. Even in higher-quality kitchen cabinets, solid wood may be used only for doors and frames.\nA kitchen cabinet made entirely of solid wood may not even be your best bet, particularly if you live in a high-humidity area. Wood reacts to humidity, or the lack of it, and to temperature changes in the environment. As a result, you can expect some shrinking or warping over time.\nOn the other hand, a solid wood kitchen cabinet looks, feels, and smells like ""quality"" and exudes a sense of warmth that can’t be matched by composite and synthetic materials. The best-quality cabinets match the wood grains of their faces and boxes.', 'American Black Cherry\nIn cabinetmaking, cherry is rated one of the favorites because of\nits beauty and versatility… it has warmth, personality and charm.\nAs a craftwood it cuts,stains and sands beautifully, which makes\nit a hobby wood of choice.\nAmerican black cherry is widely used for paneling and as a veneer,\nburial caskets and other specialty items such as gunstocks, tobacco\npipes, musical instruments, turnery, carvings, etc. It is only moderately\ndurable for outdoor projects. Cherry wood is my personal favorite,\nof all the domestic wood species.\nThe Tree: Prunus Serotina Family\nBlack cherry stands alone for its commercial value as a lumber wood.\nOther cherry trees most often function as decorative trees or fruit\nbearers. Black cherry is characterized by late maturing fruit and\nis distinct from the other cherries because it has dark bark with\nirregular scales that peel off easily and a light to dark reddish\nThe fruit of this tree is small and purple coloured with a bitter\ntaste and is used to flavour jelly and beverages. At one point it\nwas used to make a very potent liquor. American colonists used the\nbark as a drug to treat bronchitis and cherry stalks were used to\nmake tonics. Its grows predominately in east-central North America,\nwith smaller shorter trees more common in southern eastern Canada.\nCherry has a pale yellowish sapwood and a darker heartwood. The\nwood\'s colour deepens to its characteristic reddish brown, almost\nmahogany-like colour when exposed to the sun. The sapwood never\ndarkens to the same colour of the heartwood. Cherry often shows\na waving curly figure when finished. Heartwood can have dark spots\nor fine black lines that are actually gum pockets, that pose added\nchallenges in finishing.\nThe tangential shrinkage can be twice the radial shrinkage making\nwarping a problem if drying is hurried. Once cherry has been dried\nproperly, though, it is a relatively stable wood. It is as strong\nas maple but only about 2/3rds as hard. Often maple is stained to\nlook like cherry in furniture components that require a more dense\nWeight: 35 lbs. Per cubic foot.\nThe grain pattern welcomes a full range of medium to dark finishes\nand bleaching treatments. The best way to achieve a uniform deep\nred colour is to let mother nature do her work rather than attempt\nstaining. If you have to replace a board, remember in time, the\nsunlight will darken all cherry, even if it doesn\'t look like it\nmatches in the beginning. It has been suggested by some of my customers\nthat aniline dyes work particularly well on cherry, but I have no\nexperience in this area. Scratches show up easily on cherry so pay\nattention to your sanding preparation.\nWood is uniform in texture and machines well with normal wear on\nyour tools. Its tight fine grain routes well but does have a tendency\nto burn, so stick with carbide bits and don\'t stop the router on\nthe wood. Watch the feed direction when jointing, particularly on\nboards that show a nice curl. Likewise when thickness planing, keep\nyour passes to less that a 1/16"" and always pay attention to the\nfeed direction. If tear out occurs, you can always reverse the direction.\nObviously you don\'t want to be experimenting on the last pass. Cherry\nturns beautifully, but you must sand with the grain to eliminate\nthe cross grain marks.']"	['<urn:uuid:af094352-fe44-4713-8355-c400f247ca38>', '<urn:uuid:e37a92ff-937b-42d8-8d7d-5804ed1af7c2>']	factoid	with-premise	long-search-query	similar-to-document	three-doc	novice	2025-05-13T05:52:58.810667	12	95	1113
98	normal heart rate babies vs thyroid patients hyperthyroidism beats per minute compare	Normal heart rate for babies from birth to 3 months is 100-150 beats per minute. In comparison, hyperthyroid patients typically experience a fast heart rate of 100-120 beats per minute or higher as one of their symptoms.	['Thyroid Guide – Thyroid Disorders: The thyroid gland is a small butterfly-shaped gland that can be found just below the Adam’s apple. It produces thyroid hormones that are used for metabolism in the body. The growth and development of all the body tissues are dependent on the proper functioning of the thyroid gland. Problems arise if the thyroid gland is overactive or underactive. There are three common thyroid disorders. These are hypothyroidism, hyperthyroidism and the thyroid nodules.\nHypothyroidism happens when the thyroid gland fails to produce an adequate supply of thyroid hormones. Common symptoms of this thyroid disorder are hair loss, dry skin, sluggishness, constipation and weight gain.\nHyperthyroidism refers to an overactive thyroid gland. In this case, the thyroid gland produces more thyroid hormones than what the body needs. When this happens, an individual may feel exhausted most of the time, lose weight excessively, experience palpitations and irritability.\nCollect your sample, mail it back in the prepaid envelope, and receive results by email or phone.\nThyroid nodules are lumps that grow in the thyroid which are mostly common and harmless. Only a small percentage of thyroid nodules are cancerous. One must undergo a biopsy to be further evaluated if the lump or tumor is benign or cancerous.\nNot all people with thyroid disorders may notice and feel symptoms. Someone can even go on living without having any clue that they may be suffering from a thyroid disorder. It is best to consult a doctor should an individual feel any symptoms either related or not related to thyroid disorders. Thyroid disorders if left untreated may put one’s health and even life at risk.\nInteresting Questions about Thyroid:\nThe basic goal of treatment is to return thyroid hormone levels to normal.\nHyperthyroidism makes the body work too fast because there is too much thyroid hormone in the blood. Graves’ disease is the most common cause of hyperthyroidism. Graves’ disease occurs because of a problem in the body’s immune system: antibodies are produced that overstimulate the thyroid gland.\nPatients who are hyperthyroid from taking too much thyroid hormone need only to have their dosage properly adjusted.\nPatients whose hyperthyroidism is caused by transient thyroiditis usually do not require any of the treatments described below, since their condition gets better on its own.\nTreatment for hyperthyroidism from Graves’ disease, toxic autonomously functioning thyroid nodule, or toxic multi-nodular goiter may include one or more of the following:\nRadioactive iodine (I131)\nRadioactive iodine shrinks an enlarged thyroid or toxic nodule or nodules that are making too much thyroid hormone. This treatment is safe and is widely used in adults with hyperthyroidism.\n* Radioactive iodine (I131) is the treatment of choice for the majority of the endocrinologists in this country. It is an effective, simple, safe way to treat patients with Graves’ disease or other forms of hyperthyroidism. Patients often have fears and misconceptions about using radioactive iodine.\n* Studies have been done since the 1940’s on patients receiving this treatment. Treated patients, their children, and their grandchildren do not have an increased incidence of cancer, leukemia, etc.\n* There are no increased instances of birth defects in children born to mothers who have had this treatment and waited the recommended time before becoming pregnant. (Pregnancy should be avoided for at least six months after the treatment.) As a matter of fact, fertility is often restored to women whose infertility is due to hyperthyroidism. Treating the disease also lessens the chance of miscarriage.\n* Pregnant women should not be given radioactive iodine for any reason. If a patient has any doubt as to whether she is pregnant, treatment (and testing) with radioactive iodine should be delayed.\n* Hospitalization is not required in order to treat hyperthyroidism with radioactive iodine.\n* Radioactive iodine treatment ablates the thyroid gland (turns it into something like a dried-up raisin). Patients wishing to avoid destruction of the gland should know that the thyroid gland frequently “burns out” within 15 years even without treatment.\n* Radioactive iodine does not cause a person to gain weight. However, because Graves’ disease increases the metabolism, patients should keep in mind that they cannot continue to eat the way they did while hyperthyroid. Because of changes in the metabolism after hyperthyroidism is treated, many patients will gain weight . This weight can be lost through diet and exercise once the thyroid levels are normalized.\nAntithyroid drugs, such as propylthiouracil (PTU) and methimazole (Tapozole®), are used in patients with Graves’ disease and, less commonly, in other hyperthyroid patients\nIn some cases beta-blocking drugs are prescribed to treat the symptoms of hyperthyroidism while waiting for one of the above treatments to work.\nYour doctor will be able to discuss the benefits and risks of each treatment.\nMany patients treated for hyperthyroidism become hypothyroid. They will need to take thyroid hormone pills for the rest of their lives. In addition, they will need to see their doctor at least once a year.\n® Tapozole is a registered trademark of Jones Medical Industries.\nThe standard treatment for hypothyroidism is thyroid hormone pills. The pills provide the body with the right amount of thyroid hormone when the gland is not able to produce enough by itself. While the symptoms of hypothyroidism are usually corrected within a few months, most patients need to take the pills for the rest of their lives.\nThe preferred thyroid hormone for treatment is levothyroxine (T4). You should use only the brand-name that your doctor prescribes, since generic brands may not be as reliable. Name brand levothyroxine pills include Levothroid®, Synthroid®, Levoxyl®, and Eltroxin®.\nPatients sometimes take more pills than they should, trying to speed up the treatment or lose weight. However, this can lead to hyperthyroidism, a disease in which there is too much thyroid hormone in the blood, and to long-term complications, such as osteoporosis. You should take the pills as your doctor prescribes.\nAt different times in your life, you may need to take different amounts of thyroid hormones. Therefore, you should see your doctor once a year to make sure everything is all right.\n® Levothroid is a registered trademark of Forest Pharmaceuticals.\n® Synthroid is a registered trademark of Knoll Pharmaceuticals.\n® Levoxyl is a registered trademark of Jones Medical Industries.\n® Eltroxin is a registered trademark of Roberts Pharmaceuticals.\nSigns and symptoms of Hyperthyroidism may include:\n- fast heart rate (100-120 beats per minute or higher)\n- slightly elevated blood pressure\n- nervousness or irritability\n- increased perspiration\n- muscle weakness (especially in the shoulders, hips, and thighs)\n- trembling hands\n- weight loss, in spite of a good appetite\n- hair loss\n- fingernails partially separated from finger-tips (onycholysis)\n- swollen fingertips (achropachy or clubbing)\n- retracted (pulled back) upper eyelids\n- skin changes\n- increased frequency of bowel movements\n- goiter (an abnormal swelling in the neck caused by an enlarged thyroid gland)\n- in women, decreased menstrual flow and less frequent menstrual flow\n- in men, slight swelling of the breasts\n- in Graves’ disease: thick or swollen skin over the shin bones (pretibial myxedema); eyes that seem to be popping out of their socket (exophthalmos).\nMost of these conditions will return to normal after the hyperthyroidism is treated. Certain others may be treated separately.\nHave more questions? Need more answers? Check our Full Thyroid FAQ\nAutoimmune Thyroid Disorders\nAutoimmune thyroid disorders are common and occur when the thyroid gland is being attacked by the immune system. This results in an abnormal functioning of the thyroid gland. In cases like autoimmune thyroid disorders, the thyroid gland is either underactive or overactive. Examples of autoimmune thyroid disorders are Graves’ disease and Hashimoto’s thyroiditis.\nAutoimmune thyroid disorders are also more common in women than in men. Hashimoto’s thyroiditis occurs in women between the ages of 30 and 50. This disease may be inherited since it appears to have a genetic component. People over 50 years old who have hypertension are prone to develop an autoimmune thyroid disorder called Graves’ disease.\nThyroid Disorder Symptoms\nThyroid disorder symptoms often appear gradually, thus making it commonly misdiagnosed. Some people may not feel or notice any symptoms at all. Common thyroid disorders are hyperthyroidism, hypothyroidism and thyroid nodules. Common symptoms for hypothyroidism are weight gain, constipation, heavy or abnormal menstrual flows, dry skin and hair loss. As for hyperthyroidism, an individual may notice and experience hair loss, excessive weight loss, frequent bowel movement and irritability.\nThyroid nodules are often ignored because most of the time, the lumps or tumors are benign. But one must not ignore these lumps or tumors since these may also be cancerous. Should one feel any of these symptoms, it is best to consult a doctor and seek medical help. Tests will be done to check one’s thyroid function and determine if these symptoms are caused by any thyroid disorder.\nThyroid Guide & Links to Related Articles\n|There are four parathyroid glands that are normally having the size of a single rice grain. In some normal cases, they can be as big as the size of a pea.|\n|Also called underactive thyroid, hypothyroidism is a disorder that is characterized by abnormal level of thyroid hormones in the body, which is too low.|\n|The thyroid is a butterfly (pear)-shaped gland, it consists of 2 symmetrical lobes joined by a central isthmus that normally covers the 2nd & 3rd tracheal rings.|\n|Congenital hypothyroidism is a thyroid gland disorder that may lead to deafness or mental retardation if left undetected.|\n|Hypothyroidism can cause depression. Most people don?t realize that this feeling is depression caused by the thyroid gland not functioning as it should.|\n|Papillary thyroid cancer is one of the thyroid cancer types. This type of thyroid cancer arises from the follicles in the thyroid gland.|\n|The thyroid gland is located immediately below the larynx on each side of and anterior to the trachea. It is one of the largest of the endocrine glands|\n|These thyroid hormones are responsible in regulating the body?s metabolism, which is how much food will be broken down into useful energy for consumption.|\n|When the thyroid gland produces too much thyroid hormone, one may suffer from hyperthyroidism.|\n|The thyroid stimulating hormone is produced by the pituitary gland. The thyroid stimulating hormone promotes the growth of the thyroid gland.|\n|Thyroid hormones are chemical substances produced by the thyroid gland. The thyroid gland is located in the front of the neck.|\n|Natural thyroid supplements are helpful as a remedy to thyroid disorders. Its natural ingredients assure one of its safeties in taking it.|\n|The thyroid gland is an endocrine gland that is the primary responsible in regulating the body?s metabolism.|\n|Thyroid surgery is used to treat people with thyroid problems such as thyroid cancer, thyroid nodules and hyperthyroidism.|\n|Thyroid tests or thyroid function tests are done to check the thyroid function in one?s body. A doctor will be able to determine and diagnose the thyroid disorder.|\n|Treatment for thyroid disorders should be done to prevent unwanted results caused by the severity of the condition. Consult a physician for more of these treatments.|\n|Thyroidectomy is a surgical process wherein the whole or a part of the thyroid gland is removed. This surgical process is used to treat thyroid disorders.|\n|Having an underactive thyroid is a minor problem but it seeks proper attention to avoid further health problems. Consult a physician about any thyroid problem.|\n|Low thyroid, also known as hypothyroidism, is a condition where the thyroid gland is under active.|\n|Following a healthy meal plan, exercise and proper medication goes hand in hand to treat hypothyroidism. Consult a physician for a more individualized plan.|\n|Each thyroid cancer treatment depends on the type of thyroid cancer and the extent or stage of the thyroid cancer one is suffering from.|\n|Parathyroid hormones are considered to be the most important endocrine regulator. It basically regulates the calcium and phosphorus concentration in the body.|\n|Studies show that since 1925, the standard treatment for parathyroid disease is to surgically remove the parathyroid gland(s) which are overproducing parathyroid hormones.|\n|Parathyroid adenoma is a small tumor of the parathyroid gland and is known to be the most common disorder of the gland.|\n|Medullary thyroid cancer is one of the types of thyroid cancer. This type of thyroid cancer is more common in women than in men.|\n|Most people don?t feel any symptoms. Others can just lose weight and just feel depressed for no reason at all.|\n|Suppose you go in for a routine checkup and your doctor decides to test your thyroid function. You?ve experienced no thyroid disease symptoms|\n|Hypothyroidism develops for over a long period of time. It?s normally from several months to even several years.|\n|People who are suffering from hypothyroidism are advised to get plenty of exercise and have a balanced and healthy diet. The diet must be rich in protein and iodine.|\n|Self medicating one?s thyroid disorder with hypothyroidism diet pills without proper information of the diet pill does not address the problem.|\n|Hyperthyroidism is when the thyroid gland is overactive and produces too much thyroid hormones more than the body needs.|\n|Hypothyroidism is one of the chronic diseases in the world. Hypothyroidism is also known as underactive thyroid; hypo means under or below normal.|\n|Anaplastic thyroid cancer is a type of thyroid cancer that is rare and aggressive. It affects the thyroid gland and most especially its function.|\n|Problems arise if the thyroid gland is overactive or underactive. There are three common thyroid disorders. These are hypothyroidism, hyperthyroidism and the thyroid nodules.|\nThyroid Hair Loss\n|Hair loss may happen for so many reasons but it is commonly associated to thyroid problems such as hyperthyroidism and hypothyroidism.|\n|Thyroid Function Tests are the different tests conducted to assess and determine the cause of an individual?s thyroid problems.|', 'An arrhythmia is an abnormal heart rhythm usually caused by an electrical “short circuit” in the heart.\nThe heart normally beats in a consistent pattern, but an arrhythmia can make it beat too slowly, too quickly, or irregularly. This can cause the heart muscle’s pumping function to work erratically, which can lead to a variety of symptoms, including fatigue, dizziness, and chest pain.\nWhat Causes Arrhythmias?\nThe heart has its own conduction system, or electrical system, that sends electrical signals around the heart, telling it when to contract and pump blood throughout the body. The electrical signals originate from a group of cells in the right atrium, called the sinus node. The sinus node functions as the heart’s pacemaker and makes sure the heart is beating at a normal and consistent rate. The sinus node normally increases the heart rate in response to factors like exercise, emotions, and stress, and slows the heart rate during sleep.\nHowever, sometimes the electrical signals flowing through the heart don’t “communicate” properly with the heart muscle, and the heart can start beating in an abnormal pattern — an arrhythmia (also called dysrhythmia).\nArrhythmias can be temporary or permanent. They can be caused by several things, but also can occur for no apparent reason. Arrhythmias can be congenital (meaning kids are born with it), sometimes due to a birth defect of the heart but sometimes even when the heart has formed normally.\nOther causes of arrhythmias in kids include chemical imbalances in the blood, infections, or other diseases that cause irritation or inflammation of the heart, medications (prescription or over-the-counter), and injuries to the heart from chest trauma or heart surgery. Other factors (such as illegal drugs, alcohol, tobacco, caffeine, stress, and some herbal remedies) also can cause arrhythmias.\nSigns and Symptoms\nBecause arrhythmias can cause the heart to beat less effectively, blood flow to the brain and to the rest of the body can be interrupted. If the heart is beating too fast, its chambers can’t fill with the proper amount of blood. If it’s beating too slowly or irregularly, the proper amount of blood can’t be pumped out to the body.\nIf the body doesn’t get the supply of blood it needs to run smoothly, these symptoms can occur:\n- palpitations (a feeling of fluttering or pounding in the chest)\n- shortness of breath\n- chest pain\nArrhythmias can be constant, but usually come and go at random. Sometimes arrhythmias can cause no detectable symptoms at all. In these cases, the arrhythmia can only be discovered during a physical examination or a heart function test.\nWhat’s a Normal Heart Rate?\nHeart rate is measured by counting the number of beats per minute. Normal heart rate varies depending on factors like age and whether the person leads an active lifestyle or not. (For example, athletes often have a lower resting heart rate).\nThe resting heart rate decreases as kids get older. Typical normal resting heart rate ranges are:\n- babies (birth to 3 months of age): 100-150 beats per minute\n- kids 1-3 years old: 70-110 beats per minute\n- kids by age 12: 55-85 beats per minute\nYour doctor should help you determine whether or not your child’s heart rate is abnormally fast or slow, since the significance of an abnormal heart rate depends on the situation. For example, an older child or adult with a slow heart rate might begin to show symptoms when his or her heart rate drops below 50 beats per minute. However, trained athletes have a lower resting heart rate — so a slow heart rate in them isn’t considered abnormal if no symptoms are associated with it.\nTypes of Arrhythmias\nThere are several types of arrhythmias, including:\nPremature Atrial Contraction (PAC) and Premature Ventricular Contraction (PVC)\nPremature contractions are usually considered minor arrhythmias, in which the person may feel a fluttering or pounding in the chest caused by an early or extra beat. PACs and PVCs are very common, and are what happens when it feels like your heart “skips” a beat. It doesn’t skip a beat — an extra beat actually comes sooner than normal. Occasional premature beats are common and considered normal, but in some cases they can indicate an underlying medical problem or heart condition.\nTachycardias are arrhythmias that involve an abnormally rapid heartbeat. They fall into two major categories — supraventricular and ventricular:\n- Supraventricular tachycardia (SVT): is the most common significant arrhythmia, it’s characterized by bursts of fast heartbeats that originate in the upper chambers of the heart. The bursts can happen suddenly, and episodes can last anywhere from a few seconds to several days. Specific treatment is usually recommended if incidents of SVT are long-lasting or happen often.\n- Ventricular tachycardia: is a serious but relatively uncommon condition that originates in the lower chambers of the heart and can be dangerous.\nBradycardias — arrhythmias characterized by an abnormally slow heartbeat — include:\n- Sinus node dysfunction: is when the heart’s sinus node isn’t working correctly, most commonly following surgery to correct a congenital heart defect. An abnormally slow heartbeat is typically seen in this condition; however, episodes of rapid heartbeat due to SVT also can occur.\n- Heart block: is often caused by a congenital heart defect, but also can be the result of disease or injury. Heart block happens when electrical impulses can’t make their way from the upper to lower chambers of the heart. When this happens, another node in the lower chambers takes over and acts as the heart’s pacemaker. Although it sends out electrical impulses to keep the heart beating, the transmission of the signals is much slower, leading to a slower heart rate.\nDoctors use several tools to diagnose arrhythmias. It’s very important to know your child’s medical history and give this information to your doctor, who will use it, along with a physical examination, to begin the evaluation.\nIf an arrhythmia is suspected, the doctor will probably recommend an electrocardiogram (EKG) to measures the heart’s electrical activity. There is nothing painful about an EKG — a series of electrodes (small metal tabs) are fixed to the skin with sticky papers, then information about the electrical activity of the heart is transferred to a computer, where it’s interpreted and drawn as a graph.\nThe doctor might recommend the following types of EKG tests:\n- Resting EKG. This measures resting heart rate and rhythm, and lasts about a minute.\n- Exercise EKG (also called a stress test). This measures heart rate and rhythm while exercising, like riding a stationary bicycle or walking on a treadmill.\n- Signal-average EKG. This measures heart rate much like a resting EKG. The only difference is the signal-average EKG monitors the heartbeat over a longer time period (around 15-20 minutes).\n- Holter monitor. This is an EKG done over a long period of time, usually 24 hours or more. The electrodes are connected to the chest, and the wires are attached to a portable EKG recorder. The child is encouraged to continue normal daily activities, but must be careful to not get the electrodes wet (for example, no swimming, showering, or activities that cause a lot of sweating). The two kinds of Holter monitoring are: continuous recording, which means the EKG is on throughout the entire monitoring period; and event monitoring, which means data is recorded only when the child feels symptoms and then turns the Holter monitor on.\nMany arrhythmias don’t require treatment; however, some can pose a health problem and need to be evaluated and treated by a doctor.\nDepending on the type and severity of the arrhythmia, one of these options might be recommended:\n- Medications. Many types of prescription anti-arrhythmic medications are available to treat arrhythmias. The doctor will determine which is best by considering the type of arrhythmia, possible underlying medical causes, and any medications a child is taking. Sometimes, anti-arrhythmic medications can increase symptoms and cause unwanted side effects, so their use and effectiveness should be closely monitored by the doctor, you, and your child.\n- Pacemakers. A pacemaker is a small, battery-operated device implanted into the body (near the collarbone) through a surgical procedure. Connected to the heart by a wire, pacemakers can help treat bradycardia. Through a sensing device, a pacemaker can detect if the heart rate is too slow and sends electrical signals to the heart to speed up the heartbeat.\n- Defibrillators. Like a pacemaker, a defibrillator can deliver electrical impulses to the heart. A small battery-operated implantable cardioverter defibrillator (ICD) can be implanted near the left collarbone through a surgical procedure. Wires run from the defibrillator to the heart. It senses if the heart has developed a dangerously fast or irregular rhythm and delivers an electrical shock to restore a normal heartbeat.\n- Catheter ablation. “Ablation” literally means removal or elimination. In the case of catheter ablation, a catheter (a long, thin wire) is guided through a vein in the leg to the heart. Arrhythmias are often caused by microscopic defects in the heart muscle. Once the problem area of the heart is pinpointed, the catheter heats or freezes the muscle cells and destroys them.\n- Surgery. Surgery is usually recommended only if all other options have failed. In this case, the child is put under anesthesia, the chest is opened, and the heart is exposed. Then, the tissue causing the arrhythmia is removed.\nWhen to Call the Doctor\nAlthough many arrhythmias are minor and don’t represent a significant health threat, some can indicate a more serious problem. If your child has been having symptoms of an arrhythmia, call your doctor.\nReviewed by: Joel D. Temple, MD\nDate reviewed: August 2012']	['<urn:uuid:b47a39f2-f39f-4a0c-8e48-dbccb42f6627>', '<urn:uuid:044b303b-601a-4c37-9159-fe1b19064302>']	factoid	with-premise	long-search-query	distant-from-document	comparison	expert	2025-05-13T05:52:58.810667	12	37	3902
99	why old image files last long	Some old file formats remain in use either because they perform their function so well that no alternative is needed, or because of coincidental circumstances that keep them relevant. The GIF format is an example of this, surviving despite its original purpose being outdated, and finding new life as a medium for internet humor. Unlike other obsolete formats like .PCX files that have become digital fossils, GIFs have managed to persist and adapt to new uses.	['Computer file types come and go. It’s unlikely you’ve recently opened a .PCX for example, a type of image file now so redundant as to virtually be regarded as jurassic. That redundancy came less because it was a particularly specialized format, at least by the standards of today, but because it had it’s moment in the early stages of widespread computer use, served its purpose and was superseded by the advance of technology and newer file types which did a similar job better. There are dozens, perhaps hundreds of comparable examples of these digital fossils, but then there are also the freakish exceptions, the vestigial survivors which remain either because they simply do their job so well that there isn’t a need to come up with an alternative, or which end up remaining in use more out of fluke than anything else.\nOne example of the latter is the Graphic Interchangeable Files better known as the GIF. GIFs are a joke, or at least in many of the diverse cultures of the internet they are the universal shorthand for one. GIFs might have once enjoyed a useful role following their introduction in 1987 in the era before fast internet connections and streamable video, but today the format’s purpose is today largely consigned to that of conveying the Internet’s numerous memes in moving form. The web is awash with animated GIFs of funny things, from clips of cats going berserk at the sight of a surprise cucumber to Monty Pythonesque animations based on renaissance paintings. Entire online conversation are conducted through the exchange of humorous GIFs and sites like Giphy exist purely to fulfill the need for them in the context of these conversations. A famous and rather neo-Fordist sounding trademark of the Apple corporation was that whatever you need ‘there’s an app for that’. In humour terms one might say similar for GIFs. Whatever joke you want to make, whether tasteless or witty, rooted high culture or deep in the gutter, there’s probably a GIF for it, and if there isn’t? Make one. Predictably the GIF’s resurgent popularity has seen those outside the internet’s anarchic communities attempt to cash in on it. A range of companies have run GIF based marketing campaigns with varying success. In 2015 the British Channel 4 news program introduced Newswall, a slightly awkward website displaying the news of the moment in GIFS, a project which ran for about eight months before it was shut down. While often quite funny Newswall also made very clear the difficulty of using GIFs to discuss controversial or troubling issues without appearing to make light of them. In 2016 Coca Cola introduced a new slogan and promoted with a GIF maker which allowed internet users to add their own slogans to short video clips from Coca Cola adverts. Predictably it was quickly trolled by internet users and had to be taken down.\nThe GIF’s currency as digital shorthand for humour would seem to lie in a few of its unique characteristics. It has always been comparatively shareable, making low demands on bandwidth and storage compared to streaming video, although this is less an issue today. By popular demand social networks like Twitter and Facebook are gradually reintroducing support for them but in an example of how unnecessary the GIF’s low bandwith demands now are the GIFS displayed on Twitter are actually resampled and displayed as MP4 video files. A more important element which is perhaps often overlooked are the aesthetics of GIFs. In their humorously disjointed looping, their silence and their fractured visual quality they call to mind early cinema, particularly the jerky slapstick of Chaplin or Keaton, and certainly these early films feel in a strange way most at home in the format of a GIF. It felt particularly apt while researching this piece to stumble across the animation above, a homage to Edweard Muybridge, who in his experiments with high speed sequential photography laid the groundworks for the developments of later pioneers like the Lumière brothers. Perhaps the association also goes beyond the aesthetic. I sense that for a certain generation which grew up during the early stages of the internet, the GIF has a certain nostalgia value perhaps akin to the nostalgia that the aesthetic of the cinema or television screen was to previous generations generations. Rooted in our earliest memories and experiences of the interne,t we have a bond to them which the advance of technology has struggled to break.\nBeyond the history and mainstream use of GIFs I’ve recently been thinking about whether and how the format can be used for other purposes, like art, or journalism. GIF art is most definitely a practice (there’s even a GIF art collective) an activity with it’s roots in the early internet but which continues in diverse forms today, and which spans people experimenting with and highlighting the unique specificities of GIFs to others who view the format simply as a useful medium for other ideas they are keen to discuss. Much of this art references the popular use of GIFs as a medium of humour, escalating cheap cracks and meme’s into more sophisticated commentaries on art and culture. An example of this might be Zack Dougherty, who under the name of Hateplow creates GIFS that reference and rework classical sculpture and archaeology, combining the two to offer a commentary on the present. For another example more towards the photographic side of things, Swedish artist Martin Brink has experimented with a range of web based mediums in his work, including producing GIF based images which change with varying drama as the viewer watches them.\nI have also been sporadically experimenting with GIFs as a medium for work of a more documentary nature. Recently I became interested in the question of whether the refugee crisis that continues to unfold across Europe, the Middle East and North Africa, is leaving traces behind that are detectable from space. Using satellite imagery, I have been attempting to locate markers in the landscape left behind by various actors and agents in the crisis and to show the changes in these markers over time as the crisis also mutates and transforms, as new routes are opened and closed, and new sites appear and disappear. The expansion and contraction of the Calais refugee camp known as The Jungle is an obvious example, but others are more nebulous. The construction of the Hungarian border fence for example or the appearance and disappearance of seasonal camps used by refugees working as temporary farm workers in Turkey. Others, like the pathways beaten through the countryside by refugees seeking passage across borders might be barely detectable or may not even register at all on the intentionally degraded imagery available to public view. By imaging the same sites multiple times over several years and then compositing these images into animated GIFs I am trying to suggest the expansion and contraction of the crisis and it’s causes in different parts of the world at different times. In other instances, the locations imaged suggest not change, but inertia. The European parliament in Brussels for example appears in virtual stasis as the crisis unfolds over several years.\nAs I start to collect more of these I hope that these images will start to form a web of locations, which will in turn be mapped across the affected regions in order to give viewers a sense of how one flows into another. I have published some of these images on my website under the working title Borderlands and I am also releasing these and others as I create them on to GIF file sharing services. The hope being that when seen alongside jerky animations of a sneezing panda or a morose dog, a looping satellite image of a refugee camp blossoming out across the Jordanian desert might, in the jarring moment of an unexpected encounter, give someone pause for thought.']	['<urn:uuid:16fa294c-339c-47c5-8897-340e770f8ed5>']	open-ended	direct	short-search-query	distant-from-document	single-doc	novice	2025-05-13T05:52:58.810667	6	76	1316
100	How do depth limits compare between PADI Advanced and Junior Open Water certifications?	PADI Advanced Open Water certification allows diving up to 30 meters (90 feet), while Junior Open Water Divers aged 10-14 are limited to 40 feet maximum depth.	['Go beyond basic knowledge and become a PADI Advanced Open Water diver\nMay till December\n2 Days in Cabo:\n- 5 Open Water Dives\n- Physically Fit\n- Be at least 15 years old\n- Be PADI Open Water Certified\nWhy become Advanced:\n- Gain more experience\n- Go deeper 30m (100ft)\n- Make diving more interesting\n- 183 USD E-Learning Theory\n- 375 USD Practical Part in Cabo\nIncluded: Boat , PADI Instructor, All necessary Equipment, Water, Snacks.\nWhat to Bring: Sweater, Camera, Sunscreen, Hat, Towel\nBest time to go:\n- May 70% 70%\n- June 80% 80%\n- July 90% 90%\n- August 100% 100%\n- September 80% 80%\n- October 100% 100%\n- November 100% 100%\n- December 100% 100%\nPADI Advanced Open Water E-Learning\nThat’s what the PADI Advanced Open Water Diver course is all about. You don’t have to be “advanced” to take it – it’s designed to advanceyour diving, so you can start right after earning your PADI Open Water Diver certification. The course helps build confidence and expand your scuba skills through different Adventure Dives. You try out different specialties while gaining experience under the supervision of your PADI Instructor. You log dives and develop capabilities as you find new ways to have fun scuba diving.\nYou’ll plan your learning path with your instructor by choosing from a long list of Adventure Dives. There are two required dives – Deep and Underwater Navigation – and you choose the other three, for a total of five dives.\nDuring the Deep Adventure Dive, you learn how to plan dives to deal with the physiological effects and challenges of deeper scuba diving. The Underwater Navigation Adventure Dive refines your compass navigation skills and helps you better navigate using kick-cycles, visual landmarks and time.\nThe other knowledge and skills you get vary with your interest and the adventures you have – photography, buoyancy control, exploring wrecks and many more.\nGet started NOW:\nSign up for PADI eLearning: click here\nChose option: Continue Education –> Advanced Open Water\nCabo Trek PADI Store Number is: 25979\nContact us and let us know when you’ll be in Cabo and if you have any questions or doubts.\nReserve your spots now by clicking the “Book Now” button below.\nAs easy as that! You’re on the best trek to become a PADI Advanced Open Water Diver!\nWhat are the course prerequisites?\nTo be certified as a PADI Advanced Open Water Diver, you need to be at least 15 years old, medically fit and be PADI Open Water Certified. Also you will have access to a tablet.\nWhat’s so great about PADI Advanced Open Water Diver eLearning?\nAs you progress through the material, you’ll be presented with interactive presentations including videos, audio, graphics and text. Short quizzes gauge your progress, and review and correct anything you might miss. This allows you to progress efficiently and at your own pace. In order to complete the five required Knowledge Reviews, you must be connected to the internet and logged in. After completing each Knowledge Review, you’ll receive an email from PADI with the results, so please check your spam filter or junk mail folder in case you don’t see one.\nWhat else is required to complete the course?\nPrior to certification as a PADI Advanced Open Water Diver, you’ll visit your PADI Dive Center or Resort to complete your training. You’ll take a short Quick Review to confirm your understanding of safety-related material from the course, and you must successfully complete five open water training dives with your PADI Instructor. You learn and master each of the required skills and show your instructor that you can comfortably repeat those skills in open water. As a PADI Advanced Open Water Diver, you will be able to dive up to 30 meters (90 feet).\nWhat does PADI Advanced Open Water Diver eLearning cost and cover?\nThe cost of PADI Advanced Open Water Diver eLearning varies by region and is nonrefundable. The fee covers your knowledge development training and unlimited access to PADI Advanced Open Water Diver eLearning via the PADI Digital Library. Your PADI Dive Center or Resort will charge an additional fee for the in-water portion of your course.\nHow long do I have to complete the program? How long does it take?\nPADI Advanced Open Water Diver eLearning will be available for one year from the time of program registration. Though you must finish the online portion of the course within that time frame, you will have perpetual access to an online version of the PADI Advanced Open Water Diver Manual through the PADI Digital Library app. The PADI Advanced Open Water Diver eLearning should take approximately 12 to 15 hours to complete.\nHow do I document that I’ve completed the knowledge development portion of the program?\nOnce you finish PADI Advanced Open Water Diver eLearning, your dive center is notified that you have completed it and that you are ready for the practical portion of the course. At the end of the Advanced Open Water Diver eLearning program, you will need to print out your eRecord and bring a copy of it with you to your selected PADI Dive Center or Resort, or email it to them.\nIs PADI Advanced Open Water Diver eLearning available for Apple? Android? Windows?\nPADI Advanced Open Water Diver eLearning is currently available for Apple and Android operating systems only.\n- Day 1: Open Water Dive 1 & 2\n- Day 2: Open Water Dive 1, 2 & 3\nActivity is lead by highly qualified PADI professional Scuba Diving Instructors who will be next to you at all time during this experience.\nContact us if you need more information.\nTOLL FREE CALL NOW:\n1 844 373 3931', 'PADI Open Water Diver\nExperience another world\nThe PADI Open Water Dive Certification is the most recognized dive certification in the industry. Valid in over 200 countries, no other certification gives you the flexibility and freedom to dive safely with accredited shops worldwide.\nPADI Junior Open Water Diver Course\n- Minimum age 10 years old\n- Maximum depth for 10 to 14 year olds is 40 feet\n- All elements of the Open Water Diver course must be completed to certify\n10 & 11-year olds and parent or guardian must watch “Youth Diving: Responsibilities & Risks” before starting training\n- Children under 18 must have PADI release forms signed by a parent or guardian before starting training.\nCosta Rica Open Water Diver\nThe intensive and fun educational process and the skills you’ll learn will serve you for the rest of your life and is one of the most important steps towards greater freedom you can make in life, as we really only get to see a third of the world without being able to go beneath the waves. The PADI OWD Certification allows you to dive anywhere in the world to a depth of 60 feet or 18 meters, independent of professional supervision.\nThe PADI Open Water Diver Certification is composed of three distinct parts, each designed to build your knowledge and skill base until you are comfortable and confident diving on your own.\n- Knowledge Development – There are several ways to complete the Knowledge Development portion of the course work, which consists of 5 classroom sessions. Students may also opt to study online or independently on their tablet or laptop using PADI’s e-learning application. Learning the basics of scuba before you hit the water is essential and the subjects covered will enable you to build your confidence before you enter the water as well as dispel many common myths and preconceptions about scuba. Once you have finished your coursework, you will be tested on the principles of scuba. When you can demonstrate that you have retained enough to score a 75 percent or higher on an administered scuba test, you can move on to the second portion of the course.\n- Confined Water Dives – Now that you have a background in the basics of scuba and have demonstrated competency of what you have learned, the next step is to get in the water in a confined area such as a pool. The Confined Water portion of the course consists of 5 dives where the student is able to put into practice the skills and knowledge they gained during the study sessions. Under the supervision of your instructor, you will familiarize yourself with many common situations likely to encounter during your dives, such as resetting your mask or breathing off another diver’s tank. These common skills are essential to becoming a safe and confident scuba diver and will form the foundation of your skill base moving forward to the final portion of the course.\n- Open Water Dives – The final step in receiving your certification as a PADI Open Water Diver is to complete 4 Open Water dives in the majestic Pacific Ocean. Now that you have demonstrated your proficiency in the classroom and practiced and honed your skills in a limited environment, it’s time to put all that knowledge and skills to good use to explore the marine world that has been off limits previously. There is little that compares to the 360 degrees of freedom of movement that you have while scuba diving, and the marine wildlife that you will encounter will take your breath away. Once you have completed your open water dives and receive your certification, you will be free to dive anywhere in the world and experience the true variety and diversity of our amazing planet, both above and below the waves.']	['<urn:uuid:60a7f656-db7d-4a0f-8734-e7f78e5081e8>', '<urn:uuid:59c227bb-a0f7-42de-8c18-a4df55703b22>']	open-ended	with-premise	concise-and-natural	similar-to-document	comparison	expert	2025-05-13T05:52:58.810667	13	27	1598
