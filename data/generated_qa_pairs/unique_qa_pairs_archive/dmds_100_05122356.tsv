qid	question	answer	context	document_ids	question_factuality	question_premise	question_phrasing	question_linguistic_variation	question_multi-doc	user_expertise-categorization	generation_timestamp	question_length	answer_length	context_length
1	portuguese inheritance system terco civil code property distribution siblings	According to the Civil Code of 1867, Portugal follows a partible inheritance system. However, parents have the right to freely dispose of one-third share (terço) of their property. Women have equal rights to receive and bestow property. Among peasants in the north, parents often use the promise of the terço as a form of old age security by marrying a child into the family. This child becomes the owner of the house upon their death, while the remaining property is divided equally among all heirs.	['Even then, it is very onerous to fully erase your activity or data on any device. It could be safer to make use of a computer in a public library or at a trusted friend’s house. With a population already in the tons of of hundreds, and a equally burgeoning financial reference to the United States, the City of Sao Paulo couldn’t long be relegated to a secondary status by the Department of State. A Consulate was established on July 3, 1915, and Vice Consul Robert L. Keiser was appointed to head it.\nEventually, the Kandyan Kingdom was ceded to the British in 1815, and with that they gained control over the whole island. Resistance to British occupation cropped up virtually immediately. During the primary half-century of occupation, the British faced a quantity of uprisings, and had been pressured to take care of a large military in order to assure their control over the island.\nIn 1971, the Army discovered itself facing a full blown insurgency, when the JVP Insurrection broke out in April 1971. Having been caught unexpectedly, because of failure to grasp the magnitude of the insurgency from intelligence stories. Although completely ill-prepared to deal with an insurgency, lacking weapons, ammunition, tools and coaching; the army responded rapidly and successfully defeated the insurgency by the Janatha Vimukthi Peramuna by mid 1971. During the Second World War, Britain assumed direct management over the Armed Forces of Ceylon. During the First World War, many volunteers from the Defence Force travelled to Great Britain and joined the British Army, and plenty of of them were killed in motion.\nLike the Indian Army, the Sri Lanka Army has largely retained the British-style regimental system that it inherited upon independence. The particular person regiments operate independently and recruit their very own members. Officers tend to remain in a single battalion all through their careers. The infantry battalion, the fundamental unit of organization in area operations, consists of 5 corporations of four platoons each.\nThey can usually be discovered at rural markets promoting clothing and handicrafts. Portugal additionally has small Protestant and Jewish communities, largely composed of foreigners.\nU S. Embassy & Consulates In Brazil\nThese homes, that are constructed to maintain out the summer season heat, have huge chimneys and hearths. Since the Nineteen Seventies, new housing and large condo complexes have been built to accommodate the growing urban inhabitants. Successive invasions of Germanic tribes within the fifth and sixth centuries C.E. Added new parts to the inhabitants, significantly in the south. Portugal emerged as an impartial kingdom in 1140 with its capital within the northern metropolis of Guimarães.\nHealth care is better within the cities than within the countryside, though women in rural areas not give delivery at residence. Good health typically is associated with what’s natural, and modifications in food regimen are incessantly cited as the trigger of disease. The main causes of dying are malignant neoplasms, illnesses of the circulatory and respiratory systems, and death from accidents and poisons. Portugal has a low suicide fee however high motor accident fatalities. Curers use a mixture of prayer, spiritual paraphernalia, and traditional and trendy medicines. Church bells toll to ship the message that a neighbor has handed away. In some areas, the gates and doors of the dead individual’s home are opened to permit anybody to enter and relatives start to wail round a physique ready for viewing.\nU S. Consulate Basic Rio De Janeiro\nUnder every Branch, there are a number of Directorates, every headed by a Brigadier. The most well-known work of nationwide literature is Os Lusíadas , an epic poem concerning the voyage of Vasco da Gama by Luís de Camões (1525?–1579?). Of importance during the seventeenth century, when Portugal regained autonomy, were the Lettres Portugaises written by Sister Mariana Alcoforada. In the early 1970s, Alcoforada’s work stimulated the Novas Cartas Portuguesas , an announcement of feminism written by the so-called three Marias. The biggest women from portugal interval for literature was the nineteenth century, when Júlio Dinis, Camilo Castelo Branco, and José Maria Eça de Queirós used a social realist and generally satirical type to write down about class relations, family, inheritance, and faith. Realism was revived in the course of the twentieth century with the brief tales of rural life by Manuel Torga, the novels of Aquilino Ribeiro, and epic tales such as Ferreira de Castro’s Emigrantes . Perhaps the greatest Portuguese modernist is Fernando Pessoa.\n15 August, celebrating the Assumption of the Virgin, is observed. 5 October is Republic Day, commemorating the collapse of the monarchy in 1910. Since 1974 it has assumed extra significance as a nationwide vacation, whereas 28 May, a commemorative day full with navy parades that within the Salazar regime honored the 1926 army coup, is not a day of nationwide celebration. The Civil Code of 1867 referred to as for partible inheritance, however mother and father can dispose freely of a 3rd share ( terço ) of their property, and women have the proper to receive and bestow property.\nSri Lanka Military\nThe Romans referred to this area as the province of Lusitania, and the prefix Luso (meaning “Portuguese”) remains to be utilized in some contexts. In 1095, the king of Castile and Leon granted Portucale to a Burgundian count. Despite the variety of invading populations and distinct regional economies and methods of dwelling, Portugal is a homogeneous nation with a single nationwide cultural id and no ethnolinguistic groups. In latest years, Sri Lanka has turn out to be more and more reliant on China for weapons. This is as a outcome of of most European nations and the United States Governments passing rules concerning the selling of weaponry to nations which are suffering from internal conflict. However the United States has expressed its intent to hold up navy coaching assistance. Recently the Sri Lankan Army started to supply locally weapons similar to a model new multiple rocket launcher, with 10 barrels and a firing range of 20 km.\nPortugal is the Biggest Racist country that i’ve ever lived in. I feared for my life there and i contemplate myself fortunate that my household got out alive! I have never lived in such poverty 40% unemployment rate and 60% of the inhabitants earn lower than $932 USD per thirty days, and that’s considered Middle Class here! Within the European Union it’s the worst of the worst place to reside. Folk arts are well developed, and craftspeople are discovered all through the nation.\nIn January 2019, a Sri Lankan military officer and trooper on peace maintaining obligation in Mali had been killed and three extra wounded when their convoy got here beneath an IED assault. The incident prompted the military to speed up its Avalon program. The 1976 constitution defined Portugal as a republic engaged in the formation of a classless society. The center class has grown and the peasant inhabitants has declined, but the distance separating the social, economic, and political elites from the bulk of the inhabitants stays. Labor drive statistics incessantly underestimate the participation of women, significantly in the rural economic system of the north.\nAmong the peasants of the north, where inheritance is mostly postmortem, mother and father use the promise of the terço as a form of old age safety by marrying a baby into the household. At their dying, that youngster turns into the proprietor of the house ; the rest of the property is divided equally amongst all heirs. Partilhas can cause friction between siblings since land is variable in quality. Some peasants hold land under long-term lease agreements that historically was passed on in one piece to a minimum of one heir. The 1867 Civil Code eliminated the system of entailed estates ( vínculos ) that made it possible for wealthier courses to cross on property to a single heir, normally by male primogeniture. Wealthier landowners have been able to maintain property intact by having one inheritor purchase out the siblings. Portugal’s gypsy population, estimated at about one hundred,000, provides one other factor of ethnic variety.\nSocial Welfare And Change Applications\nThe Army Headquarters, housed in the Defence Headquarters Complex in Sri Jayawardenapura Kotte is the main administrative and the operational headquarters of the Sri Lanka Army. South Sudan – Sri Lanka Army’s entry into South Sudan in 2014 as the newest member in the UN peace keeping household, marks a milestone in the Army historical past. Sri Lanka turned the first country to deploy a surge contingent in South Sudan.Army maintains a SRIMED Level 2 Hospital, manned totally by Sri Lanka’s Sri Lanka Army Medical Corps personnel. Lebanon – a mechanized infantry firm with fight assist private within the United Nations Interim Force in Lebanon since November 2010. The struggle with the LTTE was halted several times for peace negotiations, the last of which following the signing of a ceasefire agreement in 2002 with the help of international mediation. However, renewed violence broke out in December 2005 and following the collapse of peace talks, the Army has been concerned within the heavy fighting that has resumed within the north and east of the country.\nToday workplace and positions of leadership are an achieved quite than an ascribed status, based on personal achievement somewhat than on whom one knows or the family of 1’s start. The peasants in the north cultivate corn , potatoes, wine grapes, and greens to sell at regional markets.']	['<urn:uuid:0e79bb15-8ec1-4a1b-ac18-8071bca44c60>']	open-ended	direct	long-search-query	similar-to-document	single-doc	expert	2025-05-12T23:56:45.148498	9	85	1569
2	How do home inspections affect coverage, and what contractor checks are needed?	Many home insurance quotes are contingent on home inspection results, and problems found during inspection could prevent you from getting the quoted policy. When it comes to contractors, it's essential to verify they have proper insurance coverage - specifically commercial liability coverage and workers compensation policy. You should get a copy of your contractor's insurance documentation before starting work, as hiring contractors without necessary protection could be risky.	"['Home insurance quotes are important when you\'re selecting coverage for your property. However, you need to be properly informed about home insurance quotes to make the right decision when you select a policy.\nThe following are six things you shouldn\'t assume when it comes to getting a home insurance quote.\nYou don\'t need to get quotes and should just buy a policy\nGetting policy quotes is an essential part of choosing a home insurance policy. You can\'t know what a reasonable premium rate is for your property and your area until you\'ve done your research and gotten quotes from a few different insurance providers so that you can compare them.\nAll insurance providers will definitely be able to provide you with a quote for a policy on your property\nDifferent insurance companies have different policies on the properties that they\'ll insure and the requirements you need to meet. Some insurance companies might consider that your property is high risk. In this case, you might be offered high premiums or you might not be offered a policy at all.\nIf a particular provider won\'t give you a policy quote, you can move on to a different insurance provider until you find a company that\'s willing to give you a quote. You might have to invest in some home upgrades before you can acquire insurance if you\'ve tried all your options and no insurance company has offered you a policy quote.\nYou\'ll get all the coverage you expect from a policy that you receive a quote for\nIt\'s always essential to read the fine print before you buy an insurance policy. Don\'t make any assumptions about the exact coverage details of a policy you\'ve gotten a quote on. Do your research so you know exactly what\'s covered by a policy before you buy it.\nIt hurts your credit to get a home insurance policy quote\nYou typically shouldn\'t have to worry about home insurance quotes damaging your credit. Home insurance companies typically do a ""soft pull"" when they check credit while preparing a home insurance quote. A soft pull shouldn\'t bring down your credit score or count as an inquiry on your credit report.\nYou don\'t have to get a home inspection done after you\'ve been provided with a home insurance quote\nA lot of home insurance quotes are contingent on the results of a home inspection. If you get a quote from a provider that hasn\'t yet inspected your home, it\'s important to realize that you might not be able to get the policy in question if a lot of problems come up in your home inspection.\nYou should choose the least expensive home insurance quote that you get\nSome consumers think that getting home insurance quotes is simply about finding the least expensive option. However, this is not true.\nYou should carefully evaluate the different quotes that you get and choose one that offers a combination of value and high-quality coverage. Simply choosing the least expensive policy could cause trouble for you down the road if the quality of the coverage you get is not very high.\nTo learn more about home insurance quotes, reach out to a local insurance company.\nOwning a home insurance policy is extremely wise. Updating this important policy when your circumstances change is also smart. For instance, people typically need to increase the amount of their home insurance policies when they build an addition onto their homes. If you’ve recently bought an expensive piece of jewelry or art, you might also wish to alter your home insurance coverage to reflect this purchase. If the location you live in has experienced multiple floods in the last few years, you might want to invest in flood insurance for your home. On this blog, I hope you will discover how to determine the amount and types of home insurance coverage you need to obtain in order to protect your house and belongings. Enjoy!', 'Home renovations can impact your rates, coverage limits, and may require additional coverage for your policy.\nIf your home is being remodeled, you’ll want to notify your insurance company\nAfter a major renovation, you may need to increase the amount of insurance in your policy\nIf the renovation involves new construction or a vacant premises, you may need additional coverage\nGet a copy of your contractor’s insurance to ensure they have general liability and workers comp coverage\nThere’s a lot more to remodeling your home than just picking out the right floor pattern and choosing a general contractor — you should also consider the impact that renovations can have on your homeowners insurance. If you plan on remodeling your home or you recently completed a project, inform your insurance company and make sure you have the right amount of coverage.\nIf you add an extension onto the property or replace your roof, the improvements will likely make your homes replacement cost go up, so you’ll want your dwelling coverage limit to reflect the higher rebuild value.\nDepending on the extent of the renovations and the home’s occupancy status, you should also look into additional coverage for your policy. Standard homeowners insurance usually won’t cover your home if it’s been vacant for more than 60 days or dwellings under construction due to the increased risk of theft, vandalism, and storm-related damage. If you’re planning on living elsewhere throughout the course of renovations or you’re adding a completely new section onto the property, look into supplemental coverage like vacant homeowners insurance, a dwelling under construction endorsement for your homeowners policy, or builder’s risk insurance.\nLastly, check to see if the contractor or builder is fully covered with commercial liability coverage and workers compensation policy. If your contractor doesn’t have the necessary protection, it may not be worth the risk of hiring them for the job.\nIn this article:\nA home remodel can mean anything from renovating the kitchen to adding an entirely new room or wing. Regardless of the project, if you’re making drastic updates or improvements to the home, it will likely increase the value of the structure. Before construction begins, notify your insurance company to increase your coverage limits to reflect the value of the rebuilt or renovated section of your home.\nIn other words, if your home is insured for $300,000 and your insurer determines that a new addition or remodel increases its rebuild value by $30,000, they may recalculate the dwelling coverage limit in your policy to $330,000. Many companies also offer replacement cost coverage enhancements that you can add to your policy, like extended replacement cost. Extended replacement cost coverage automatically increases your dwelling limit an additional 25 or 50% in the event the home is destroyed and your coverage limit isn’t high enough. If you’re remodeling your home and unsure if the suggested coverage limit adjustment is accurate, extended replacement cost may be an option worth considering.\nAny of the following scenarios may necessitate an update to your insurance policy:\nIf you’re building a new addition onto your home, you’re likely increasing its replacement value, or the cost to repair or replace the property. This amount is indicated in the dwelling coverage limit in your policy. If you’ve added onto your home, your dwelling limit will likely increase once your coverage is recalculated by your insurance company.\nWhile the increased coverage may increase your insurance premiums, it’s a bad idea not to inform your insurance company about updates to your home. Your insurance company requires that your home be insured for at least 80% of its replacement cost before they pay out losses, so if your home is renovated and your dwelling limit isn’t adjusted, your claim may be denied if you don’t meet the coverage limit threshold.\nBe sure to let your insurance company know about the addition prior to construction so that you can obtain the necessary coverage for the premises throughout the project.\nUpgrading your kitchen can significantly increase the rebuild value of your home. If you’re transitioning from veneer to marble countertops or installing new cabinetry, flooring, and so on, you’ll want the limits in your policy to be updated accordingly so you can be fully reimbursed in the event of a disaster.\nIf you plan on replacing the roof of your home, be sure to contact your insurance company and let them know. A new roof adds value to your home, so your coverage limits will likely be recalculated, but you also may qualify for a discount. Many insurance companies offer discounted rates if your roof is under a certain number of years old. You may qualify for further discounts if your roof is made with stronger material to withstand windstorms, hail, and leaks.\nPools can affect your homeowners insurance twofold: they can increase the rebuild value of your property and can also be a liability hazard. If someone is injured in a pool-related accident and decides to press charges, you’ll likely be responsible to pay out the damages. If you’re planning on adding an in-ground or above-ground pool, you’ll want to be sure it’s covered under the liability section of your policy. In most cases, pool accidents are covered, but your insurer may require a fence with a gate around the exterior of the pool as a condition for coverage.\nAdjusting your coverage limits isn’t the only reason to inform your insurance company of renovations prior to the start of the project — you should also make sure that the remodeling process itself is covered. There are multiple scenarios where your remodel may or may not be covered by your homeowners insurance policy.\nA standard homeowners insurance policy specifically excludes theft to a dwelling under construction along with materials and supplies used for the build. Your coverage typically won’t pick back up until the home is finished and occupied. This is where you’ll want clarification from your insurance company, as your definition of “construction” may be different from theirs.\nFor example, a simple interior update to a room in your home may necessitate alerting your insurer to update your coverage limits, but you likely won’t need to add any coverage to your policy to cover the materials and supplies involved in the renovation. Conversely, if you’re adding a new room onto your home or building an attached garage, your insurer may view your home as under construction and exclude theft loss from your policy until the project is complete. Why is that? Because it generally takes little to no effort to break into a construction site, making them hotbeds for theft, vandalism, and arson.\nBefore construction starts, check with your insurer to see if you need any special renovation coverage to ensure you’re fully covered. Many insurance companies offer dwelling under construction coverage that you can add onto your policy for an additional premium.\nYour homeowners insurance policy also won’t cover perils like vandalism if the dwelling has been vacant for more than 60 consecutive days prior to the loss. If your home renovations require you to live elsewhere for a few months, you may want to consider vacant or unoccupied homeowners insurance — many companies offer this type of policy in addition to the standard home insurance product. If you go this route, make sure you pause your homeowners insurance before the vacant home coverage kicks in. When you move back in, you’ll want to start your standard coverage back up.\nYour homeowners insurance policy specifically covers home structural collapse if it was caused by the use of defective material or methods in construction, remodeling, or renovation if the collapse occurred during the course of the work. That means if that half-finished second story bedroom addition falls through into your family room, the cleanup and repairs may be covered by your insurer.\nIf you plan on remodeling the home yourself or you anticipate that a friend or family member will be helping you out throughout the course of the project, you’ll want to check the personal liability and medical payments coverage in your policy. Do-it-yourself construction projects involving other people open you up to potential lawsuits if the person helping you is injured during the job.\nWhile it’s unlikely that a friend or family member would sue you over a remodeling accident, they may need help paying for medical bills as a result of their injuries — that’s where your no-fault medical payments protection comes in. With medical payments coverage, if a guest is injured in your home, they simply submit a claim through your insurance company and are reimbursed for medical payments like copays and deductibles. You can typically have up to $5,000 in medical payments coverage.\nPrior to renovations, ask your contractor or builder for a copy of their insurance for your records to ensure they have adequate protection and that all of your bases are covered financially. Your contractor should have commercial liability and workers compensation insurance to cover the wages of workers who are injured on the job.\nIf the contracting work involves new construction, check with your builder to see if storm damage and theft loss to the property itself or building materials are covered by their insurance. In many cases, this caveat will be spelled out in the builder’s contract. Typically, homes under construction or renovations involving extensive add-ons will require either a dwelling under construction provision to your homeowners insurance or a separate builder’s risk policy. If your contractor isn’t carrying a builder’s risk policy (also known as “course of construction” insurance), it may be your responsibility to obtain this coverage.\nAbout the author\nPat Howard is an Insurance Editor at Policygenius in New York City, specializing in homeowners insurance. He has been featured on Property Casualty 360, MSN, and more. Pat has a B.A. in journalism from Michigan State University.\nPolicygenius’ editorial content is not written by an insurance agent. It’s intended for informational purposes and should not be considered legal or financial advice. Consult a professional to learn what financial products are right for you.\nWas this article helpful?\nWe make it easy to compare and buy insurance.\nSecurity you can trust\nYes, we have to include some legalese down here. Policygenius Inc. (DBA Policygenius Insurance Services in California) (“Policygenius”), a Delaware corporation, is a licensed independent insurance broker. Policygenius does not underwrite any insurance policy described on this website. The information provided on this site has been developed by Policygenius for general informational and educational purposes. We do our best to ensure that this information is up-to-date and accurate. Any insurance policy premium quotes or ranges displayed are non-binding. The final insurance policy premium for any policy is determined by the underwriting insurance company following application.\nCopyright Policygenius © 2014-2020']"	['<urn:uuid:482a1df2-bea7-4c84-9050-d64b03f193ec>', '<urn:uuid:6f7b9d89-d2cf-40b5-9d17-30cd2a955c86>']	open-ended	direct	concise-and-natural	distant-from-document	multi-aspect	expert	2025-05-12T23:56:45.148498	12	68	2446
3	I've been studying Asian religious iconography and I'm particularly intrigued by Shiva's representations. Could you explain the significance of Shiva's various forms and roles in Hindu mythology, especially focusing on how these are depicted in traditional sculptures?	Shiva has multiple significant representations in Hindu mythology, particularly evident in sculptural forms. As Shiva Nataraja or 'Lord of the Dance,' he is depicted in a dynamic 10th century copper alloy statue celebrating both universal destruction and creation, dancing with four extended arms and half-closed eyes on a fiery wheel of creation. Shiva is also portrayed alongside his consort Parvati in sculptures that emphasize masculine and feminine attributes. In these depictions, Parvati appears as Uma or Devi, representing benign aspects like the goddess of light. Fundamentally, Shiva serves as both protector and destroyer, wielding powerful destructive energy. He is frequently worshipped and is considered a primary deity in Hinduism, forming part of the Trimurti (trinity) alongside Brahma and Vishnu. The Trimurti represents the three fundamental cosmic functions, with Shiva specifically associated with fire and destruction that precedes new opportunities.	"['""Images of the Divine: South and Southeast Asian Sculpture from the Mr. and Mrs. John D. Rockefeller 3rd Collection,"" July 1, 2005-Jan. 8, 2006, at Asia Society, 725 Park Avenue, New York, N.Y. 10021\nThey stand here as if forever. Fifty sculptures in stone, schist, copper, silver and gold, from South and Southeast Asia. Their features undergo change from region to region, from country to country, even from workshop to workshop, as craftsmen imprint Buddhist and Hindu gods and goddesses with the features of local inhabitants and the idiosyncrasies of local traditions.\nIn the early autumn sun their presence casts a solemn peace on the second floor of the Asia Society building at Park Avenue and 70th Street in New York City. ""Images of the Divine: South and Southeast Asian Sculpture from the Rockefeller Collection"" is a sublime selection from one of the most prestigious assemblages of Asian art ever created.\nHere are the divine images of the Buddha in his various guises, displaying his multiplicity of gestures. They are flanked by the ""bodhisattvas,"" individuals who have not yet attained the ultimate eighth circle of enlightenment and must earn their position by helping believers function in Buddha’s shadow. And there are the Hindu gods and goddesses from the great Valhalla of the Orient. All shine in this selection from the Rockefeller Collection, a gift to the Asia Society that has helped anchor the society’s holdings firmly in all the artistic disciplines of the East.\nThe myths of Asia are among the richest on earth. The story of Prince Gautama -- or ""Buddha"" as he came to be known -- is central to this presentation. The myth bears repeating. A young nobleman, though wealthy and with wife and child, finds great unhappiness through contemplating unresolved questions about the meaning of life and the constantly changing aspects of fortune. He leaves his home and wanders the vastness of India until he realizes that only by casting off all desires and all personal ambition can he attain the peace that comes through meditation and introspection. His philosophy, later termed Buddhism, though not a religion per se, if practiced wisely can lead a person to his own salvation and free him or her from the endless cycle of death and rebirth.\nRepresentations of the Buddha in the Rockefeller collection take several forms. First, there is the historical Buddha, often referred to as ""Shakyamuni."" There are seven representations of this Shakyamuni on display at Asia Society, originating from Kashmir, India, Cambodia, Burma and Tibet. In most of these sculptures, a middle-aged man wears a crown, his earlobes elongated because of the heavy earrings that were the standard for his time, his expression benign.\nThe most impressive of these crowned Buddhas is a copper alloy figure protected by the seven-headed serpent king, Muchilinda, whose imposing head shelters the Buddha, who sits erect on Muchilinda’s coils. The snake represents the waters of Cambodia’s mainland, source of irrigation and healing. The figure is probably of 12th century origin.\nThe Vajrasattva Buddha is easily identified by the thunderbolt or ""vajra"" he holds in his right hand, and the bell he holds in his left. An impression of wisdom and compassion is conveyed in his countenance. Vajrasattva Buddhas are found in the northern regions of Buddhism as well as Indonesia and Cambodia. Two of the sculptures on view are traceable to the 12th century, one is of copper alloy, the other of stone. The copper structure appears luxurious, yet immensely powerful.\nThrough the centuries of evolving Buddhism, the repose and wisdom reflected in the Buddha’s countenance remain a constant. We see this over and over in the life-sized Buddha heads on display. The heads may have been used for temple decoration, or perhaps they are simply missing parts of scattered statues. According to ancient texts, ""A Buddha’s face is to have eyes like lotus petals, eyebrows like an archer’s bow, a parrot beak nose and a chin like a mango stone."" Other characteristics include a marked depression in the middle of the forehead, or ""urna,"" and a slight bump on top of the head, or ""ushnisha.""\nThe Buddha is dressed modestly, in contrast to his disciples who are more likely to sport elaborate garments, crowns and footwear. Orientalists look for each figures’ gestures or ""mudras,"" which establish a Buddha’s attributes. These might be the absence of fear, the turning of the wheel of law, the teaching mudra and more. In fact, scholars have isolated as many as 22 such gestures found in various monuments. Of the Buddhas on exhibition, the earth-touching gesture is seen most frequently -- it indicates enlightened compassion.\nAmong Buddhist goddesses, the White Tara at Asia Society with her inlays of silver and gold stands out. She is the goddess of infinite compassion. Her eyes are placed in the center of her forehead indicating her concern for the welfare of mortals.\nLike Buddha, bodhisattvas are exempt from the rebirth cycle. Their primary task is to provide salvation and guidance to the average person. In contrast to representations of the Buddha, statues of bodhisattvas are often elaborately styled with crowns, armbands, necklaces and jewelry studded with semi-precious stones. Many do not have the Buddha’s characteristic urna or ushnisha, and their earlobes are seldom elongated. They are not usually represented as performing the Buddha’s mudras. When presented with the Buddha, bodhisattvas are shorter than the deity, although as individual statues bodhisattvas can equal the height of a Buddha.\nThe Rockefeller selection includes several statues of Avalokiteshvara, the bodhisattva of compassion. An exquisite example rendered in a gilt copper alloy is from the estate of Blanchette Hooker Rockefeller. He is standing in a relaxed pose with his right hand, appropriately, in a gift-giving gesture. Another exceptionally crafted example is traceable to the early Malla period in Nepal (13th century). Here Avalokiteshvara, richly encrusted with semi-precious stones, displays two gestures: that of reassurance with his right hand and that of teaching with his left.\nMaitreya, a bodhisattva of the future who must still be born in human shape, is presented in an astonishingly fine 8th century figure. Copper alloys with inlays of silver and black stone accentuate the youthful figure. The sculpture was unearthed in 1964 from the ruins of a temple in northeast Thailand.\nManjushri, the boddhisattva of wisdom, frequently accompanies the Buddha. The sacred texts speak of him as ""The light. . . shining on the torch of knowledge that is the lamp of the world, the great brilliance. . . the clear light."" The Rockefeller Collection has several examples of this important figure. A western Tibetan 13th century copper alloy rendering with turquoise inlays holds a book, but lacks the sword usually present. This symbol is meant to show an intolerance for ignorance -- a standard theme in most Manjushri depictions.\nThe dancing gods of the Hindu pantheon have their own pavilion at the Asia Society. Familiarity with Hinduism is not essential to appreciating this portion of the Asia Society exhibition, but a few facts are helpful. Hinduism evolved over more than 4,000 years, so it’s not surprising that innumerable sects have developed, all living side-by-side and practicing their own interpretive take on the Veda, the sacred scripture. However, central tenets of the Veda and beliefs common to all Hindu sects are that all living things have a soul; that there is an essential equality among all creatures; and that there is rebirth. One’s station in life and the nature of one’s rebirth, which is most likely to take place in an entirely different form, are determined by the experience of previous existences and merits earned in these former lives.\nIt may be difficult to separate the characteristics of Hindu art and religion from that of Buddhism. For one thing, the names of the god or goddess represented are not always clear. Hinduism had no human founder and the Hindu gods have no traditional image, leaving the craftsman or artist wider latitude in fashioning their appearance. The prime Hindu deities are Brahma the creator, Vishnu the preserver and Shiva the destroyer.\nThe Asia Society exhibit’s Brahma has four heads. These are variously said to represent the four cosmic cycles, the four great classes, or the four directions. His arms hold a lotus stem, a bundle of grass and a book, all said to represent knowledge and religious ritual. We assume that this particular presentation is part of a much larger monument, now lost.\nVishnu can be recognized by both a conch shell or ""shankha"" and by a discus or ""chakra"" held in his upper arms. These round objects act as reminders of the cyclical nature of Vishnu’s mission. A sacred thread, an element in all Hindu deity sculptures, runs across his chest. The Vishnus in the Rockefeller Collection are from India, Kashmir and Thailand.\nShiva Nataraja is ""Shiva as Lord of the Dance."" Here he celebrates on the one hand the destruction of our universe, and on the other hand, the creation of an entirely new cosmos as it passes through an eternal circle of flames. This statue is Indian from the 10th century, in copper alloy. With his eyes half-closed and his four arms extended, the god dances rhythmically on the fiery wheel of creation.\nSculptural representations of Shiva and his consort Parvati were made to invite worship. The two figures demonstrate the attributes of masculinity and femininity. Five examples are featured in the Rockefeller Collection. The manifestation of Parvati in these groupings is benign. She is here as Uma, daughter of the mountains, or Devi goddess of light. Parvati also has an alarming aspect, that of Durga, the slayer of the Buffalo-demon who held the world in thrall. This fearsome representation is personified in a sandstone sculpture from Cambodia, thought to be from the 7th century.\nWhat of Ganesha, the elephant-headed son of Shiva and Parvati? Legend has it that after Parvati was pregnant with their child against the will of Shiva, he decapitated the child in his rage. Inconsolable, Parvati railed against Shiva until he could no longer tolerate her anger and grief. In desperation he sent his minions to bring back the head of the first animal they encountered, which, as it happens, was an elephant. Ganesha is worshipped as the god of good fortune as well as the god of war. In representations, his tusk is broken, since myth has it that it was lost in battle. Ganesha is usually the lead god presented in any Hindu festival procession.\nFRED STERN writes on art and antiques.', 'Originated from India, Hinduism has been around for at least past 5,000 years. Although, current research has marked the existence of Hinduism from the various archaeological and literary sources, its beginning, evolution, and progression over such an extensive period of time, remains obscure. Whether Hinduism is classified as a religion is debatable as unlike many other world religions, Hinduism lacks a designated founder or prophet, and hence, most Hindus would consider it a way of life.\nHinduism, in its core philosophy, believes that God is absolute, formless, and only known as Brahman, the Supreme- Universal Soul. Brahman equates with the universe and everything in it, it has no form nor does it have any limits; it is Reality and the ultimate Truth.\nThere are three principal beliefs in Hinduism, which are afterlife and reincarnation, Karma (action), and Dharma (righteousness). Essentially, the primary goal of Hinduism is to attain ‘moksha’ from the cycle of rebirth.\nOn one hand Hinduism is a pantheistic religion: it identifies God with the universe and human beings are only manifestations. On the other hand, Hindu religion is also polytheistic as it is populated with myriad gods and goddesses. As a prominent Hindu saint Sri Ramakrishna once wrote, “There can be as many Hindu Gods as there are devotees to suit the moods, feelings, emotions and social backgrounds of the devotees.” The exceedingly wide variety of gods to choose from allows the aspirant to draw on and embody the symbolic power of a particular god when needed in specific life circumstances.\nBelow is a list of 8 Hindu gods and goddesses that you would commonly come across in the modern yoga world today:\nThe god of preserver, Vishnu is also known as the divine arbitrator. Symbolically, Lord Vishnu represents justice and moral order. Comes after creation, Vishnu sustains the universe and upholds its many laws. You might call on Vishnu if you’re seeking protection, patience, knowledge, or prosperity.\nThe god of both protector and destroyer, Lord Shiva is a powerful god and is widely worshipped for its potent destructive energy. Shiva is married to Parvarti, also known as Shakti, with whom he has two sons: Ganesha, the remover of all obstacles; and Skanda, god of war. Shiva is the ultimate representation of how great destruction precedes new opportunities. You might call on Shiva as a source of inspiration as you try to achieve a goal or when experiencing hardships in life.\nThere are many mantras reciting Lord Shiva, one of which is Om Namah Shivaya.\nThe god of creation, Brahma is the creator of the world and all creatures. Lord Brahma represents the source of the universal mind as well as intellect. Brahma is the least worshipped god in Hinduism today. Currently, there are only two temples in the whole of India devoted to him- one in Pushkar and the other in Kerala. One of the reasons why Brahma is rarely worshipped is that Brahma’s role as the creator is over. It is left to Vishnu to preserve the world and Shiva to continue its path of cosmic reincarnation.\nTrinity of Gods (Trimurti)\nTrimurti, the term denotes “having three forms,” refers to the three main Hindu gods mentioned above: Brahma, Vishnu, and Shiva. Initially, the Trimurti was worshipped as a single entity- the Supreme Being. Later, the three gods were separated and took on their own individualism. It is commonly believed that these three forms actually represent earth (Brahma), water (Vishnu), and fire (Shiva).\nPowerful yet widely misunderstood, Mother Kali is the goddess of death, time, and doomsday. Albeit her immense destructive power, she is a strong mother-figure and symbolic of compassionate-love. Kali is said to remove our attachment with the body reinforcing the awareness that the body is a temporary condition. In a sense, Kali grants liberation by demising the illusion of the ego.\nFor Hindus, the goddess Lakshmi is the symbol of prosperity, fertility, purity, generosity, and the embodiment of beauty and grace. Known as the daughter of mother goddess Durga and the wife of Vishnu, Lakshmi is an important domestic deity and her presence is found in almost every household. In statuary and artwork, Lakshmi is usually depicted as a beautiful woman with four hands, sitting on a full-bloomed lotus and holding a lotus bud. Her four hands symbolizes the four ends of human life: dharma or righteousness, kama or desires, artha or wealth, and moksha or liberation from the cycle of birth and death.\nSaraswati, the goddess of knowledge and arts, represents the free flowing of wisdom and consciousness. Saraswati is the daughter of Lord Shiva and Goddess Durga. She possesses four hands, which represent the four aspects of human personality in learning: mind, intellect, alertness, and ego. You would call upon Saraswati for the power of speech, wisdom, and learning.\nA very popular god in the modern yoga world, the elephant-headed god Ganesha is one of the most important deities in Hinduism. The son of Shiva and Parvati, Ganesha is the lord of success and the remove of all obstacles. He is commonly worshiped as the god of education, wisdom, and wealth. Ganesha’s head symbolizes the eternal soul (Atma), while his body signifies illusion in the material world (Maya). You would call upon Ganesha for protection and removal of any obstacles that may come your way.\nHanuman, the mighty monkey god, is the ultimate image of faith and devotion.\nHanuman’s tale in the epic Ramayana- in which he is given the mission of locating Rama’s wife Sita who was captured by the demon king of Lanka- Ravana, is known to inspire readers to face adversities and overcome obstructions in the way of the world. Hanuman’s strong character is used in the Hindu religion as a metaphor of the unlimited power that lies unused within each human individual. In times of doubt and great difficulties, you would call upon Hanuman for physical strength, perseverance, and devotion.']"	['<urn:uuid:6407d8f1-8ee5-4fcd-872a-6f4634053ff7>', '<urn:uuid:bdc7b1c9-4af6-4839-a81d-5c1fc30ddaaa>']	open-ended	with-premise	verbose-and-natural	distant-from-document	three-doc	expert	2025-05-12T23:56:45.148498	37	139	2736
4	What are some smart ways to make a website's bottom part help with getting more business or subscribers?	The footer can be a powerful conversion tool in several ways. Since visitors are already familiar with your content or services by the time they reach the footer, it's an ideal place for a final call-to-action (CTA) to encourage newsletter subscriptions or contact. You can also include social proof and trust elements like completed projects, awards, and certificates to build credibility. Additionally, the footer can assist with SEO for your deepest pages and increase SEO authority. Key business information, company values, and social media links should be highlighted to drive engagement.	['Website Footer Design: Best Practices, Tips and Many Examples\nThe footer is that one small section on the bottom of your website that contains all the useful information that isn’t included in the primary content. In most cases, visitors will scroll all the way down to find the links they can’t locate anywhere else. This includes helpful navigation, policies, contact information, social media links, job opportunities, and more. In short, your website footer has two main purposes: it marks the end of the page, giving the visitor a full and familiar experience; and it features the logical conclusion of your website: means for the visitors to contact you easily.\nOne of the main advantages of the website footer is that everyone knows where to look for it and they will. This is why it needs to provide consistent, familiar, and usable UX for the visitors, organize all the relevant information, and present it efficiently and in an aesthetically pleasing way.\nWithout further ado, let’s dive right into the topic and look through the best practices for designing a website footer., with many examples from live websites.\n9 Best Practices for Website Footer Design\nThe website footer is not a sitemap or a catch-all where the entire website content is squeezed into titles in columns. It’s in fact the last section where you can leverage a secondary call to action, convince your visitors of your expertise, drive engagement by linking to your social media, and much more. There are a few proven practices for website footers that can turn the small shy section on the bottom of the page into a powerful conversion tool.\n1. Pay Special Attention to your Links\nYour links should always be working, accurate, and updated. In addition, if you link to an internal page unrelated to the primary content or an external page, make sure the link opens it in a new tab.\n2. Optimize your Footer for Mobile\nIn some cases, you will need a big footer where you’ll organize a handful of necessary links. This is easy to do for desktop as you can group your links into categories, place them in colons, and make good use of so much space. For mobile, however, very wide footers with that much information translate into lots of scrolling and frustration for the users. This is why include only the most necessary links for the mobile version and make it compact.\n3. Use Short and Precise Titles\n4. Make it Consistent with the Page\nEven with a very complex dynamic and interactive website design, it’s best to keep your footer as simple and readable as possible. Here comes the fun part: you have the freedom of creativity to make the transition from a complex page to a simple footer through any means you seem fit. You can achieve it with colors, shapes, and other visual elements. In the following example, the designer solved that with animation: all shapes that you can find on the background while scrolling the page, unhooked themselves, and fell in the footer. Pretty effective, keeping the consistency of the design without breaking the footer’s minimalism. It makes the footer not only a part of the visual journey but also its logical conclusion.\n5. Highlight the Key Links\nYour key information about your business, company values, company address, social media links, key resource pages, help guides, tutorials, and everything that the visitors can’t find elsewhere, should be highlighted in the footer.\n6. Don’t Underestimate the SEO Possibilities\nGoogle will always prioritize your main content and the header, however, you can use your footer to assist your deepest pages and increase your SEO authority.\n7. Include One Last CTA\nBy the time your visitors reach your footer,m they are already familiar with your content or services. This one last CTA in your footer is a great conversion tool for them to subscribe to your services, newsletter, or contact you, so don’t deprive your design of that opportunity.\n8. Add Your Legal Info\n9. Don’t Shy Away from Including Social Proof and Trust Elements\nMake sure your visitors see the links for completed projects, awards, certificates, or any other kind of achievement. These are the elements that build trust and convince in your expertise.\n30 Real-Life Examples of Effective Website Footers\nThe best practices aside, nothing gives us more knowledge and insight than learning from other creators and taking inspiration from their work. Let’s look at these website footers and see what valuable design tips we can get.\n1. Wild Souls with Wild Statements\nThis website belongs to a small shop for wild and natural seeds and nuts products. Its entire aesthetics translates the shop’s philosophy for creating a new mentality: adoration for wild nature and everything that lives in it, rebellious attitude, and bold statements. Concluding in the footer, the design offers the key information, final CTA, and carousel animation of eye-catching rebellious brand visuals that keep the consistency of the overall design.\n2. Superfluid Brutalism\nIf the overall design style for the website is brutalist, make the best out of it in the footer. In this case, the beauty shop Superfluid embraces the brutalist trend to the fullest and makes the final touches with a giant brand logo that takes half of the footer. It features all essential links like shipping and payment info, legal, FAQ, and socials, and highlights the shipping information with a carousel to drive the attention towards the CTA.\n3. Plus with Bold Titles and Vibrant Colors\nThis website strikes with bold, colorful engaging design and doesn’t fail to deliver it till the very end. The giant red footer drives instant attention and is still well organized and highlights only the key information. The contact section in the middle takes a central position as a main converting element.\n4. Interactive Shapes and Minimalism\nA smaller footer in contrast to the previous brutalist examples. Here we have a very clean almost minimalistic website footer design with four main segments for the viewer to choose from. The segments are visualized as four interactive shapes with smooth hover animation.\n5. High Contrast on Friesday with Fun CTA Interaction\nThis footer is clean and minimalistic and completes the overall sticker design. In the center, the CTA right above the company’s address offers a fun hover interaction.\n6. High Contrast in Black and White\nAlthough this website alternates the colors of each section, it leaves the black and white for last that continues in the footer. It’s very well structured by categories, with big all-caps font and a nice animated carousel in the bottom. It has the magic to turn complexity into simplicity.\n7. Structure with Colors\nOverpass is a platform that helps hire sales experts and maintain customer relationships from anywhere in the world. Being that, the platform’s website is data-heavy with a huge amount of deep pages. In the website footer, the visitors can access each important page in a perfectly structured and easy-to-scan design, all in categories, separated by contrasting colors.\n8. Brutalist Boxes and Easy Access\nThis huge website footer uses text hierarchy well to highlight the most important pages inboxes. Their address takes the biggest part of the footer with lots of white space to lead the visitor’s attention to the interactive shape, while the categories for the company come next, and the legal and policies last.\n9. Fun CTA and lots of White Space\nThis interactive website with engaging transition and animations on scroll gives an entire screen for the footer to use the white space to its advantage. Here we have a huge section for contact, bold social media links, the company address, and a little surprise when you hover over the cat pun.\n10. Short and On Point\nWith this website, there’s only the most necessary info, taking little space at the bottom. The footer offers the socials, policies, and FAQ in two small columns with big readable fonts. Short, simple, and on point.\n11. One Highlighted Element\nAfter a very satisfying scroll through this creator’s portfolio, the website minimizes in a cool transition and reveals a simple black and white minimalistic footer that highlights the contact email. It is what the creator wants you to see and makes sure the other featured links don’t get in the way at all.\n12. Small Amount of Info in the Corner\nThis designer bets on huge images and fonts to give more scroll and interaction to their page. In this case, as the number of pages is small, they cleverly used the space for visuals, while the information is sent to the right corner, easy to see and access.\n13. Movie Poster Credits Style\nThis restaurant uses its modern city aesthetics to its advantage to make the footer an important part of its web design. All the information such as opening hours, takeaway option, address, contacts, and socials is there in separate movie poster credits style boxes with neon hover colors.\n14. Fighting Bad Boys with Good Website Footer Design\nAfter the cool retro image of the main character, the Bad Boys Movie official website ends with two main sections. The one on the left has the CTA that the visitor will easily see thanks to the attention-grabbing giant animated logo. On the right, it has satisfyingly arranged 9 pages into 3 columns with the same width and the proof of authenticity below.\n15. Not Entirely at the Bottom\nSimpson Motorcycle has a neat footer with one interesting element that differs it from other similar footer design pieces. It doesn’t stay at the bottom. Leaving enough white space gives more freedom for the visitor to scroll and the illusion that the experience isn’t over. In simpler terms, it looks cool.\n16. Stylish, Clean, and Perfectly Structured\nIn this case, we don’t have a fancy animation or interesting hovers. The Hotel Ballart website footer is clean and classy with its signature dark blue with great contrast over the light background color and uses its space to feature a logo, address, all-important links logically sorted into categories, and the two important for the hotel CTA options.\n17. Naming the Categories\nWe’ve chosen this example for its decision to name the links categories. It’s very useful and convenient for the visitors.\n18. Slick Corporate Design and the Essentials\nThe main focus of the three-part footer is the CTA section that starts with a question before the animation reveals the form and the button. Pretty nice way to emphasize the key goal of the page. The other essentials, such as contacts and socials go next and are very easy to access due to a lot of white space.\n19. Part of the Last Section With Clever Typography Design\nThis inspirational website footer takes consistency even further as it becomes part of the last section. The title cleverly mimics the circular shape of the images, highlighting the key categories, policies, and contacts.\n20. Little Text Taking the Entire Screen\nOne really can’t miss the key elements of the footer if they are very few and take the entire screen. Minimalism works great here as the main categories are giant, in the center, and instantly accessible. In terms of consistency, the footer uses the brand color scheme to its advantage to make a high contrast and add its accent blue as a hover color.\n21. The Footer is the Contact Section\nThe main purpose of a portfolio and the place where it should all lead is the contact option. Here every page ends up with a contact section instead of a footer.\n22. Highlighting the Footer with Hidden Interaction\nAt first glance, the footer is merged with the black background of the page. However, when you hover around, a gallery animation highlights the shape of the footer and makes it very effective. In terms of content, it offers the minimum and most essential: the four main pages, policies, blog, and email.\n23. Say Hi!\nThis two-part footer has a main contact section with CTA and awesome background animations and all socials centered below. The content hierarchy ends with agency information links at the bottom in a smaller font.\n24. Straight to the Point\nThis website footer includes just the address, socials, and careers, but makes sure to lead your attention straight to the point where you can’t miss the giant brutalist style CTA. A logical conclusion of scrolling each page.\n25. Eccentric Luxury for Design Consistency\nThe best way to make your website footer stand out is to make it different and break the standard. This luxurious website does just this with a very interesting decision to center the footer content in a small rectangle. And the best part- everything you might need is still there: FAQ, values, socials, blog, press, contacts, and policies. Less is more in action.\n26. Left Alignment and Lots of Space\nThis footer has 3 parts: CTA and links on the left, and a high-quality image on the right. The latter pushes the attention to the left where the visitor pays attention to the bigger size titles first. Its main purpose is to call for signing for updates.\n27. The Credits\nThis is one of the cases where it’s hard to reach the footer if you’re not willing to go through the entire page experience. With this in mind, there isn’t anything essential that a visitor could need instant access to when landing on the page. The footer takes an entire screen and plays the role of credits screen, giving sources for the images used in the presentation, social media links, and a nice interactive brush in the background.\n28. Text Hierarchy to the Extreme\nAjeeb’s website is a perfect example of a trendy website that has it all: brutalism, Riso print style, neon color effects, interactions, glitches, holographic images. And it still manages to keep it clean. The footer takes the entire screen with giant titles that highlight the main pages and contact info. Everything that isn’t as important goes at the bottom with significantly smaller text.\n29. Less is More but the Hover Animations are the Most\nThe hover animation of your pointer follows you through your entire experience while scrolling down the page. However, it keeps the best part for the footer where your pointer breaks the titles and might make you play around with the effects before you even start reading them. Modern interactive UX done right.\n30. Great Content Writing Game to the Very End\nThis website branded as Something Good is consistent in its message to the very end of its pages. What makes it so interesting as a good website footer example is that it doesn’t emphasize the contacts or links, but its message with a title animation, changing the adjectives to make its statements more powerful. In this case, the footer is a tool to strengthen the message.\nAnd last, let’s look at 5 more website footer examples for more inspiration and ideas.\nHere the footer isn’t the last section of the page, as it reveals an inspirational quote to strengthen the agency’s message.\nAnother example of design consistency with the overall design and great content structure. Since the website has sticky vertical navigation, it can afford to distribute more key information and categories between the navigation and the footer.\nThis website does a similar thing but without a dropdown menu in the navigation. Once a visitor reaches the footer, all information is available from both elements as one completed site map and makes it easy to scan.\nShort and sweet website footer with as least links as possible, highlighted by beautiful visuals.\nAnd last, an illustration footer. This website is dedicated to image compression and has all relevant actions and information on the page. Rather than using the footer for extra links, it adds the creator’s credits and a beautiful colorful illustration.\nThese were the 30 (+5 bonus) website footer examples for inspiration. After enjoying these effective designs, here are some tips and ideas we can gather from them.\n- Replicate your main navigation in the footer if you have long pages: It’s very useful for your visitors to find quick access to your pages after scrolling through a long page. This way they won’t need to scroll all the way to the top in order to find what they’re looking for.\n- Emphasize your main element boldly: You can use significantly bigger fonts to highlight your most important link, especially if your website sports brutalist design.\n- Use animations to gain attention: A simple non-interactive animation can lead the visitor’s attention to a certain part of the footer.\n- Hover Effects keep the footer design engaging: UX animations help your footer become a part of the whole experience and not just that boring section at the bottom.\n- Visual and Text Hierarchy: You can easily help your visitors figure out different categories by importance if you boldly use text and visual hierarchy.\n- Any section can become a footer: If you have anything displayed in the header you can use your footer to end each page with something else: contacts, credits, or inspirational quotes.\nAnd most importantly, think outside the box\nPlay with alignments, shapes, and colors. Your footer can merge with the design not even looking like a footer, or it can become an unfamiliar experience for the visitor to unveil.\nIn the meantime, why not have a look at some more inspirational and insightful articles on the topic of UI/UX design:']	['<urn:uuid:e7a3ba4c-6d40-4948-9d3f-85bbc75e2104>']	open-ended	direct	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-12T23:56:45.148498	18	91	2913
5	I'm curious about how different cultures approach writing from right to left - could you explain how Arabic writing works and what makes it unique compared to other writing systems?	Arabic writing has several unique characteristics. It is written from right to left, which means not just individual words but entire sentences and even mathematical equations follow this pattern. When reading an Arabic book, you start from what would be considered the 'back' in Western books, with the front cover opening on the right side. The Arabic script is cursive, meaning most letters must be connected in writing, with letters having different shapes depending on their position in the word (initial, medial, final, or isolated form). The system is classified as an abjad, which means it primarily writes consonants while largely excluding short vowels in regular texts. The script is also used beyond just the Arabic language - it's used to write Persian, Urdu, Pashtu, and Kurdish, serving over 560 million speakers worldwide. Additionally, the writing system is efficient in that it uses a limited number of basic shapes or 'skeletons' that are modified with dots in different positions to create different letters.	"[""Created | Updated Oct 19, 2007\nWriting appears to have been invented in about 4000 BC in Ancient Sumer (modern Iraq)1. Since then, humankind has used many different systems for writing down the languages we speak. This Entry looks at the main systems in use today, as well as offering a passing nod at some of the writing of the past.\nAlphabets, Abjads, Syllabaries and Ideograms\nThere are many different ways of writing down speech. The main ways are as follows:\nAn alphabet uses one symbol per sound. Alphabets are divided into two types:\nTrue alphabets have one symbol for each consonant and one symbol for each vowel. This is the system we are all familiar with.\nAbjads have one symbol for each consonant, but do not write down the vowels. The prime example of this is Arabic, where the vowels do not seem to be very important.\nA syllabary has one symbol for each syllable. This suits many eastern languages where most syllables consist of a consonant sound followed by a vowel sound.\nAn ideographic system uses many symbols which represent whole ideas. For example, in Chinese, a symbol may mean man or east or horse. All ideographic systems use a large number of symbols which represent sounds as well.\nWe'll look at each of these systems in turn and give the examples in use in the world today.\nA B C D E F G H I J K L M N O P Q R S T U V W X Y Z\nThe system that is used throughout the Western World is known as the Roman alphabet, or sometimes the Latin alphabet. It was spread through Europe by the Romans, and later throughout the world by the Europeans. It is a 'true alphabet' with symbols for both vowels and consonants. The alphabet that we know now with its 26 letters is not exactly as the Romans knew it - they had no U, J or W. These letters were added later. You can read all about the development of this alphabet at The Development of the Western Alphabet.\nNot all the 26 letters are used in all languages - Irish, for example, only uses 18 letters, having no J, K, Q, V, W, X, Y or Z. Some countries have added extra letters: Icelandic includes the letters Æ, Þ and Ð (pronounced igh as in 'high', th as in 'thorn' and th as in 'the' respectively). Many languages use accents on letters (both on vowels and on consonants) to represent extra sounds.\nThe Roman alphabet is used through Western Europe, the Americas and Australia, as well as in many other parts of the world.\nА Б В Г Д Е Ё Ж З И Й К Л М Н О П Р С Т У Ф Х Ц Ч Ш Щ Ъ Ы Ь Э Ю Я\nThe second main true alphabet is Cyrillic, or Russian. It is used for the Russian language itself and also for many eastern European languages, and the languages of countries which were once in the USSR. Cyrillic is said to have been invented by two Byzantine saints, Cyril and Methodius, who decided to convert the illiterate Russians and needed an alphabet to write down the holy scriptures. They devised the Cyrillic alphabet by adapting their own Greek alphabet, adding many letters to represent sounds found in Russian but not in Greek2.\nCyrillic has a very heavy look because the lower-case letters are in nearly all cases the same as the upper-case ones but just printed smaller. One distinctive feature of the alphabet is the 'backwards N'. In fact, this letter is nothing to do with an N but comes from the Greek letter H and represents the 'ee' sound.\nCyrillic is a useful alphabet because it contains many symbols and can easily write down many different sounds. For example there is a single symbol for the 'sh' sound which takes two symbols in Roman, and there is another symbol specifically for the 'ch' sound which is written variously as 'ch', 'tch', 'ci' or 'tsch' in Roman. Cyrillic became unpopular, however, due to its association with domination of small countries by Russia, and many such countries are in the process of changing to using the Roman alphabet.\nΑ Β Γ Δ Ε Ζ Η Θ Ι Κ Λ Μ Ν Ξ Ο Π Ρ Σ Τ Υ Φ Χ Ψ Ω\nThe Greek alphabet was the first true alphabet. In fact, the name 'alphabet' comes from the first two Greek letters, alpha and beta. The alphabet was created by the Greeks adopting the Phoenician consonantal alphabet and modifying five of the symbols to make them represent vowels. Two others were added to make the seven vowels needed in Ancient Greek. Greek is still used in Greece and Cyprus.\nNot only did Greek give rise to Cyrillic, as mentioned above, but it is also the ancestor of Roman, so many of the Greek letters are the same as the Roman ones, for example A, E, I, K, M etc.\nა ბ გ დ ე ვ ზ თ ი კ ლ მ ნ ო პ ჟ რ ს ტ უ ფ ქ ღ ყ შ ჩ ც ძ წ ჭ ხ ჯ ჰ\nGeorgian, or Mkhedruli, is a beautiful rounded alphabet which is used in and around the Caucasus Mountains between the Black Sea and the Caspian Sea. It is used to write the Georgian language and a few other languages in that area.\nAlthough it is not easy to see the relation between Georgian and Greek, the order of the letters is almost exactly the same, sounds not existing in Greek being added at the end of the alphabet. This makes it very likely that the alphabet was devised by somebody familiar with Greek. We don't know who did this, but the Georgians claim it was a Georgian, while the Armenians claim it was an Armenian.\nA little known alphabet is the Mongolian one. When Genghis Khan went from being a small-time tribal leader to the ruler of a vast empire, he realised that he would need writing to implement some sort of order. He himself was illiterate. He ordered a captured scholar to devise a suitable script for writing the Mongolian language. This man adapted his own Uighur writing to produce the Mongolian alphabet.\nThe alphabet is unusual in that it is written vertically rather than horizontally. It is a joined script, with each letter in a word being joined to the others, and with gaps between words. As a result, each letter may have three different forms depending on whether it is at the start, in the middle or at the end of a word.\nThe Mongolian alphabet is still written in the parts of China where the Mongolian language is spoken. It was officially replaced by Cyrillic in Mongolia itself, but is making a comeback now that the threat of Russian domination has been removed.\nThe main abjad in use in the world today is Arabic. This alphabet is used to write the Arabic language itself, but also many other languages of the Muslim world, such as Persian (Farsi) and Urdu. It is a joined writing, with each letter in a word running into the next, making a flowing script which lends itself well to calligraphy (the art of beautiful writing).\nArabic does not write down the vowels, although a couple of the consonants that are written down sound like vowels to western ears. In particular, the sound 'Ayn is the sound at the start of the name Ali, the sound before the 'l' sound. It is considered to be a consonant by Arabs, but is virtually indistinguishable from an ordinary vowel A to most non-Arabic speakers.\nArabic is written from right to left.\nAnother abjad closely related to Arabic is Hebrew, used in Israel to write the Hebrew language. Both the Hebrew alphabet and the Arabic one are descendants of Aramaic, an extinct alphabet which was common throughout the Middle East in the 1st Millennium BC.\nAlthough Hebrew does not normally write down the vowels, there are special accent marks which can be used to signify vowels when it is absolutely necessary, for example in a text explaining how something is pronounced.\nHebrew is written from right to left.\nIndia and South-East Asia have a huge number of different languages, and about 15 different writing systems are used to represent them. All of these use basically the same system:\nThere is a letter for each different consonant. This contains an implicit vowel, usually 'a'. So these letters represent the syllables 'ka', 'ba', 'da' etc. If a different vowel is required in the syllable, or if the consonant is to stand on its own, then a vowel symbol is added to the letter to make a single letter that represents the whole syllable. For example, the ka letter with a curl on top might represent 'ke'.\nThe main syllabary in use in Asia is Devanagari, which is used to write the Hindi language, the most common language in India. A distinctive feature of this script is that many of the letters have a strong horizontal line at the top. These almost join up to make it look as if all the letters are hanging from a single horizontal line.\nOther writing systems which work on the same principle are Gurmukhi, Gujarati, Oriya and Bengali, used in North India and Bangladesh; Tamil, Telugu, Kannada, Malayalam and Sinhalese, used in Southern India and Ceylon; and Burmese, Khmer, Thai and Lao, used in South-East Asia. Tibetan, which is related to these, was used in Tibet until recently.\nAll these systems are descended from a single system called Brahmi which dates back to about 300 BC. Brahmi is clearly descended from Phoenician: many of the letters are the same. It is not clear, however, by what route this happened. Brahmi may have come from Aramaic or by a different route.\nThe Korean writing system, Hangul, falls into the category of syllabary but appears to have been invented independently, so it deserves a special mention. Hangul constructs a symbol for each syllable from a consonant sign and a vowel sign. The traditional story is that Hangul was invented by King Sejong in the 15th Century; by all accounts he was a very well-educated man, but the writing is so well designed for the language that it seems more likely it was the result of a team of scholars.\nThe only ideographic system in use in the world today is Chinese. Many of the symbols, of which there are thousands, represent a complete word.\nThis has given rise to the myth that Chinese is a system which writes down ideas and not language - it is often said that speakers of the two main Chinese languages, Mandarin and Cantonese, can both read the same written texts even though they do not understand each other's languages. This is untrue. While many of the symbols represent words, about half of them provide phonetic information to allow the words to be interpreted. This would make the text readable only in a single language.\nThere have been a few attempts to write the Chinese language in the Roman alphabet. The first attempt was by the French in the 19th Century. Their way of transliterating the Chinese sounds does not correspond well with the sounds of English speakers. So T'ang, the name of a dynasty, should be pronounced Dang, and T'ao, the life force of the Taoist religion, should be pronounced Dao.\nMore recently, in the 20th Century, the 'pinyin' system was introduced. This is an accurate way of writing down the sounds of Chinese, and even includes four accents to represent the four tone-patterns of the language. For Westerners, pinyin can be confusing, because the letters don't bear the sounds used in the West. For example, 'b' is pronounced as 'p' and 'j' is pronounced as 'ch', so Beijing is pronounced 'pay-ching'.\nJapanese comes last in this list of current writing systems because Japan uses the most complex writing system of all - a mixture of Chinese ideograms, native syllabic symbols and even, in modern times, the Roman alphabet mixed in.\nAll writing symbols in Japanese are called 'kana'. Sentences are written using what are known as 'kanji'; these are Chinese ideograms, which each represent a word.\nBut Japanese is a highly grammatical language, so to indicate the grammatical endings on the words, a system of 80 or so syllabic symbols known as 'hiragana' are used. In Japanese, a syllable may be a pure vowel, a consonant followed by a vowel, or either of these with an 'n' sound at the end. This means that there are about 80 possible syllables ending in n and 80 without an n. The n is handled by a special n symbol, while each of the 80 syllables has a separate sign. Unlike Korean or the Indian writing systems, there is no system of using a particular sign for a particular vowel. Each syllable has a separate symbol and you just have to learn them all. In fact the hiragana system is such a good representation of Japanese that it could be used to write the complete language, but for some reason, probably cultural inertia, this is not done.\nA further complication is that foreign words are spelled out using a variant on the hiragana known as the katakana. Again there are about 80 of them and an n symbol. There is no attempt here to represent sounds that do not exist in Japanese. The foreign words must first be translated into Japanese-sounding syllables. Hotel becomes 'ho-te-ru'. Mahler becomes 'ma-ra'. The u ending is tacked on to any word which ends in a consonant other than 'n'. Extra u's are inserted to break up clusters of consonants, so that 'monster' would become 'mon-su-te-ru'. (The final 'u' sounds are usually not pronounced, however, in modern Japanese.) Finally the whole thing is spelled out in the katakana system. There's no reason why they couldn't use the hiragana system here, but they don't.\nSome Ancient Systems\nFinally, we'll take a quick run through some ancient systems which people may have heard of and point out their unusual features.\nPhoenician was probably the first alphabet in the world, and is, again probably, the ancestor of every writing system used in the world today other than Chinese, Korean and Japanese. Phoenician was used in Lebanon in the 2nd Millennium BC and spread from there throughout the Middle East. It used an alphabet of 22 letters which were more or less in the same order as the letters of our modern alphabet, but without any vowels. It was written from right to left.\nRunes were an alphabet developed in northern Europe in about the 2nd Century AD and used by Germanic peoples until about the 15th Century. They were designed for scratching on wood, so they used straight lines rather than curves, making them look very angular. In addition, they didn't use any horizontal lines, as such lines would get lost in the grain of the wood.\nThe origin of the Runic alphabet is not clear; it seems to have evolved from Greek rather than Roman, but with many other symbols which don't occur in either. It may have been invented by one person familiar with Greek.\nContrary to popular belief, runes were never used for divination. On the other hand, writing your name or the complete alphabet in runes on an object was thought to give it magical protection.\nPossibly the earliest form of writing, the cuneiform system was written with the sharpened end of a stick in smoothed clay or wax. The symbols were made from a load of narrow triangular notches which look like toothpicks, and are rather difficult to read for people used to modern alphabets based on lines. The cuneiform system was used throughout the Middle East, except in Egypt, for about 4,000 years.\nMost cuneiform systems were syllabaries with each symbol representing a syllable, but there was one system used in the town of Ugarit, Lebanon, which was an alphabet and was clearly based on the Phoenician alphabet.\nThe Egyptian hieroglyphic system is another contender for the oldest writing system in the world. It was used from before 3000 BC to about 300 AD. Most symbols represented either one consonant or two consonants. About one quarter of the symbols were 'determinatives' which classified words into categories (action, place, god etc) to remove ambiguity in the string of consonants.\nThe early Greek alphabet was similar to the present one but with one peculiarity. It alternated the direction of writing with each line. If the first line of text ran from left to right, then the next line would run from right to left, and all the letters would be written in mirror image form to match the direction. This form of writing is called 'boustrophedon' which means 'as the ox turns', because it resembled the way an ox would plough a field and turn at the end of each furrow.\nThe people of Easter Island in the Pacific Ocean developed a peculiar script which is known today as 'Rongo Rongo'. It was written on sheets of bark. Like the archaic Greek, it changed direction at the end of each line, but the symbols instead of being mirror image were turned upside down. This meant that to read the writing, you would turn the whole document upside down at the end of each line.\nThere are very few examples of Rongo Rongo in existence and it is as yet undeciphered."", 'The Arabic alphabet or abjad* of 28 letters, read from right to left. (See glossary for asterisked items.)\nAfter more than a decade of study, it’s safe to say that I’m a pretty experienced language learner. To me, languages are a medium for learning more about neighbors, those near and those far. If you say “direct and indirect object pronouns,” I know what you mean. “Accents and diacritical marks”? Got that, too. “Formal and informal registers?” Yes, I understand. But here’s a series of terms that are altogether new to me:\n- hamza and glottal stops\n- teeth and tails\n- vowelled and unvowelled texts*.\n(See the glossary at the end of the article for asterisked items.)\nThese are all characteristic of the Arabic language, and, before August 24, 2015, the first day of the Fall 2015 term, I had never heard of them.\nThanks to the Center for African Studies and the Foreign Language and Area Studies Fellowship (FLAS), I am on a journey that is not only introducing me to new vocabulary but is taking me on a metaphorical tour of lands I’ve never known. In this two-part blog series, I will review the first month of class meetings my Arabic 201 course has had and introduce you to some potentially new revelations.\nThe overarching goal of these pieces is to introduce you to print, digital, human and interdepartmental resources available to you in our library and all over campus should you be interested in Arabic, the Middle East, its diaspora, and/or Islam. In the first installment of “Arabic Adventures,” we will cover two topics, each with five themes: “Modern Day Use of the Language” and “Characteristics of the Language.” Be sure to check the Glocal Notes blog next week for “Ways to Cope with Difficulty” and “Miscellany,” in which we will explore more curiosities.\nMODERN DAY USE OF THE LANGUAGE\nThe Farsi (Persian) language written in Arabic script. It reads kaafee shaap, or “coffee shop.” Photo Credit: Rui Abreu\nThe Arabic script is used to write many different languages.\nJust as the Latin script—the one you are currently reading—is used to write many languages like English, Spanish, French, Portuguese and German, the Arabic script is used to write multiple languages as well. That is, the symbols used to write Arabic are the same symbols used to write Persian, Urdu, Pashtu and Kurdish. Combined, there are more than 560 million speakers of these four languages all over the world. Before the fall of the Ottoman Empire, Turkish was also written with the Arabic script (Csató 135).\nDemand for the language is growing (Conlin)!\nEvery seat in my classroom is full and has been for four weeks. This surprises me because the class meets five days a week and has handwritten homework due almost every day. Among the undergraduates and graduate students, we even have someone auditing the class. Students want to be there and are very motivated with the language. Moreover, the United States’ government has recognized the importance of developing a multilingual citizenry and has therefore established multiple lines of funding to support committed language learners in their efforts to master other tongues. Among the scholarships and fellowships available are the following:\nThere will be an information session regarding the Critical Language Scholarship Program on campus, October 8, 2015 from 3:30- 4:30 at 807 S. Wright St. Floor 5 (Illini Union Bookstore), Room 514. Students of Arabic and 13 other languages are eligible to apply.\nAn early edition of the textbook Alif Baa by Kristen Brustad used in beginning Arabic classes at the University of Illinois. Photo Credit: Meedan Photos\nVariants of the Arabic language are not 100% mutually intelligible.\nIn our classroom, we use a pair of textbooks titled Alif Baa and Al-Kitaab. (Alif is the first letter of the Arabic abjad* and baa is the second. Kitaab is the word for “book.”) With this text, we learn Modern Standard Arabic, which is also known as fusHa and is understood by most native speakers of Arabic. However, given the wide breadth of people and countries where Arabic is spoken—conservatively, from Morocco to Iran— the variations between and among regional dialects can make communication challenging. For example, as people in the West are infrequently exposed to the Englishes of India and Nigeria, one must accustom him or herself to varying accents and vocabulary in order understand and be understood. Therefore, learning Arabic in a classroom is a beginning on the road to competency and fluency, not an end.\nIt is a standard practice for Muslims to learn to read Arabic for the purpose of reciting verses from the Koran (Qur’an), the sacred Islamic text.\nHowever, many Muslims do not speak Arabic or use the language outside of religious contexts. For example, one graduate student I know at the U of I is from Bangladesh. She is a practicing Muslim and is able to read the Koran, but beyond the holy book and polite greetings, her knowledge of Arabic as a modern language is limited. Speaking of which, the Koran’s surahs (chapters) can be read and/or heard for free at quran.com and, as with the Bible, multiple sites allow you to order a free copy. The Google search “free qur’an” yields more than 33 million results.\nA young girl learns to read the Koran. Photo Credit: Plan Asia\nCHARACTERISTICS OF THE LANGUAGE\nRemnants, vestiges and “fossils” in the language reveal its history of contact with other cultures.\nDid you know that Arabs ruled what came to be known as Spain and the Iberian Peninsula for nearly eight centuries? The most commonly cited dates are 711- 1492 A.D. (Watt). Arabs also traded heavily with peoples in East Africa, particularly in places like the Swahili Coast and Dar es Salaam (Horton), which forms part of modern-day Tanzania. Wherever the Arabs went, they left a lasting vocabulary that provides evidence of their travels, influences, cultures and wares. While the words below are not all direct translations, they do reflect origins, roots and terms that have had centuries of comparable use in their respective tongues:\n||mafuta ya kupika\nA group of Muslim men bowing in prayer as a young boy poses playfully. Photo Credit: Daniel Bayona\nReligion is embedded in the language.\nIf you ask someone of the Arab world in Arabic how he or she is, an appropriate response is “al-Hamdu li-llah,” meaning, “Thank God.” This could mean “I’m great,” “I’m fine,” “I could be better,” “God is merciful” or simply be a verbal enunciation to accompany a shrug. Here is a list of five common, everyday expressions in Arabic that all contain a variant of “Allah,” the Arabic word for and name of God:\n- Allah!: Wow! What a surprise!\n- al-Hamdu li-llah: Thank God\n- Bismi-llaah: In the name of God (said before or upon beginning something)\n- Insha’aallah: God willing, hopefully\n- Maa shaa a-llah!: Wow, that’s wonderful/beautiful/adorable! (Brustad 166)\nWhen you think about it, this is not so different from:\n- God bless you (after a sneeze)\n- Jesus Christ! You scared me!\n- Lord, have mercy!\n- OMG/Oh my God!\n- TGIF/Thank God it’s Friday!\nYou have probably already heard that Arabic is written from right to left.\n.tfel ot thgir morf daer era secnetnes taht snaem osla sihT\nDid you catch that?\nThis also means that sentences are read from right to left.\nAnd organizational paradigms are constructed from right to left. For example, math equations were once carried out as follows:\n4 = 2 + 2\n7 = 3 – 10\n8 = 2\\16\nAlso, when you open a book, its front cover rests in your right hand. If you examine the comic below, note that the text begins in the upper right-hand corner of the right page and ends on the lower left-hand corner of the left page.\nA comic written in Arabic. Given the right-to-left reading pattern in Arabic, the panel in the lower left-hand corner of the entire image should be read last. Photo Credit: Maya\nSome sounds are entirely foreign, like the letters ع (ayn) and غ (ghayn).\nThere are no English equivalents for either of them and, therefore, they can represent real challenges in aural perception for native English speakers. In transliteration (Language Library), the ع character appears as a small, elevated “c,” as in the following word for “university”: jaami ͨ a.\nA screen shot of the word “university” in English, its Arabic script translation and the ع character circled in red, courtesy of Google Translate.\nب ت ث\nSee those three symbols above? Each of them shares the same skeleton. However, the dots, their placement and their numbers distinguish them from one another. On the right, the letter is baa; in the middle, the letter is taa; and on the left, the letter is thaa. Arabic can be resourceful in that it uses a limited amount of skeletons for different letters and makes minimal but perceptible changes to convey new meanings.\nWhere the English language uses one symbol for the letter “t,” Arabic uses multiple symbols to distinguish its varying sounds. Being mindful of your tongue, say the words “tab,” “thank,” “that” and “taught” aloud. If you pay close attention, you realize that the “t” sounds are different, particularly with the blends or combinations of two consonants. In Arabic, “tab” would be written with a ت,“thank” with a ث,“that” with a ذ and “taught” with a ط. The same is true with the letter “s”: “said” would begin with a س, “should” with a ش and “sought” with a ص.\nCursive is mandatory.\nLastly, for this week’s post, know that in Arabic, letters are generally connected in the written script. Just a handful of the 28 letters make up the exceptions, like ا (alif), ﯩ (daal), ذ (thaal), ر (raa), ز (zaay) and و (waaw). What makes the writing truly engaging is that the letters generally have an “independent/isolated” shape, an “initial” shape, a “medial” shape and a “final” shape. That is, depending upon where the letter appears in a word, it may take on a different appearance. Take nuun (ن), for example, the equivalent of “n” in the English alphabet. See the image below for its four different manifestations, all dependent upon position.\nA screenshot from ArabicPod101.com as seen on youtube.com depicting the four representations of the letter nuun.\nFor more on this topic, visit Glocal Notes next week and remember to like our Facebook page!\n*A mini glossary\nabjad: A system much like an alphabet that relies strictly on the writing of consonants to relay messages. In other words, short vowels are largely excluded from the script in writing.\nhamza and glottal stops: The word hamza describes a written symbol and a sound made with one’s throat. For example, upon saying “uh oh”, the “uh,” the sound produced is hamza. In linguistics, this vocal phenomenon is called a glottal stop. While most native speakers of English only make this sound to signify something haphazard, it is in fact an integral part of the Arabic language.\nteeth and tails: Just like tittles – the dots topping the letters i and j – in learning to write Arabic, it is important to pay attention to the letters’ dots, serifs, curvatures, strokes and lengths. The “teeth” refer to the beginning and connecting segments of letters and the “tails” refer to their ending segments.\nvowelled and unvowelled texts: In Arabic, words are typically written without short vowels. So, for example, the word “continent” would be written solely with its consonants, such as “cntnnt.” The language relies on the reader’s prior knowledge to supply the necessary vowels. For young and new learners and/or ambiguous messages, texts are generally “vowelled,” or, that is, they include the letters necessary to sound out the words’ pronunciations. These texts, however, are the exception, and not the rule. “Unvowelled texts” are far more common.\nBrustad, Kristen. Alif Baa: Introduction to Arabic Letters and Sounds. Washington, D.C.: Georgetown University Press, 1995. Print.\nConlin, Jennifer. “For American Students, Life Lessons in the Middle East.” The New York Times. 6 August 2010. Web. 26 September 2015. <http://www.nytimes.com/2010/08/08/fashion/08Abroad.html.>\nCsató, Éva Ágnes. The Turkic Languages. London: Routledge, 1998. Print.\nHorton, Mark. The Swahili: The Social Landscape of a Mercantile Society. Oxford: Blackwell publishers, 2000. Print.\n“Transliteration.” Language Library: A Dictionary of Linguistics and Phonetics. Hoboken: Wiley, 2008. Credo Reference. Web. 27 Sep 2015.\nWatt, W. Montogomery. A History of Islamic Spain. Edinburgh: Edinburgh University Press, 1965. Print.']"	['<urn:uuid:8fa0bfcc-b453-4fbc-b8a3-6b84d83a94c5>', '<urn:uuid:7d156873-3950-4f07-ac83-a92fef7083b7>']	open-ended	direct	verbose-and-natural	similar-to-document	three-doc	novice	2025-05-12T23:56:45.148498	30	163	5022
6	workers compensation coverage different between independent contractors relief vets and small business employees	Independent contractors (relief vets) and small business employees have different workers' compensation situations. For small business employees in New Jersey, employers are legally required to provide workers' comp coverage. In contrast, independent contractors/relief vets are not required to have their own workers' compensation insurance, though employers may require it. However, in most cases, independent contractors can still be covered under the employer's workers' comp policy even without having their own coverage.	['Seriously, What’s the Deal?\nThis is what my dog looks like when he sleeps. Mouth agape. Eyes half-open. Checked out. This is similar to how my face looks when I’m trying to understand my insurance policies and where I have coverage lapses.\nRelief vets who work as true independent contractors (in tax speak, a 1099 worker versus a W2 employee) often have a lot of questions and misunderstandings around workers’ compensation insurance. And with good reason! Insurance is one of those topics that float around in what I like to call “the cauldron of confusion”. (Along with business entities, tax issues, and DEA licensing requirements to name a few. But these are topics for another day.)\nRelief Rover has reached out to Rod Finnegan, the founder, and CEO of Vetinsure, to help us break down the bewildering insurance landscape as it relates to workers’ compensation and relief vets.\nQ: As an independent contractor with no employees, is it required that I have my own workers’ compensation insurance coverage?\nA: No, you do not have to carry workers’ compensation. Employers may require it though. In many cases, it may be less expensive and create more protection for you if you allow the employer to simply withhold a small percentage (+/- 2%) of your pay to offset their additional cost to have you on their workers’ comp.\nQ: How, as an independent contractor, could a practice require that I have my own workers’ compensation insurance? I thought workers’ comp was for entities that have employees. I don’t have any employees, I just work for myself.\nA: This is mixing two different things. First, any employer can require you to carry workers’ comp even if the state does not. Why? Because most 1099s can find a financial remedy for injuries sustained at the place of employment. So, your employer is audited every year by their workers’ compensation carrier and they must disclose all 1099 pay. If the 1099 does not show proof of their own workers’ comp, the employer will pay more premiums because the 1099 wages get included in their policy.\nQ: If I want to buy my own workers’ compensation insurance coverage, where do I buy it?\nA: Great question. Hartford is really one of the only carriers that would be willing to write an independent relief vet a workers’ comp policy (where they include themselves in coverage) and with no employees. Hartford is very limited in the industries they will offer this type of policy, but luckily veterinary is one of them. To include yourself but have no employees presents a moral hazard to the carrier which is why most would not do it. If Hartford will not offer you a policy for any reason, the state pool may also be an option but the premium for that policy starts at $1500 annually and that would be if you excluded yourself from coverage. Again, if you can get the employer to withhold a small percentage, you will likely be better off in the long run especially if you are injured.\nUnless you are in North Dakota, Ohio, Washington, Wyoming, Puerto Rico, or the U.S. Virgin Islands, you can purchase through an independent agent.\nQ: What is moral hazard?\nIn general, this is when individuals have an incentive to alter their behavior and suppress their morals to find benefits for themselves. As it relates to the insurance industry, it would be when a person with insurance coverage takes a benefit that is fraudulent. As an example, say an independent contractor has a workers’ compensation policy for themselves and they injure their back falling off a horse over the weekend. Then they tell the insurance company that they sustained the injury at work when lifting a dog in order to receive the benefit from their workers’ compensation policy.\nQ: As an independent contractor, am I covered under veterinary practice’s workers’ compensation insurance if I’m injured while on the job at their clinic?\nA: Yes, most of the time. Except if you reside in monopolistic states/territories such as North Dakota, Ohio, Washington, Wyoming, Puerto Rico or the U.S. Virgin Islands. Monopolistic states/territories provide workers’ compensation through the government.\nAlmost all 1099 sub-contractors that do not carry workers’ comp coverage can find remedy under their employer’s workers’ comp policy for injuries sustained on the job. In other words, if you work for a vet hospital, do not carry workers’ comp yourself, are 1099’d and get injured on the job, the hospital’s workers’ comp policy may pay 100% of your medical costs associated with the injury.\nQ: What percentage of the medical expenses are covered under workers’ compensation?\nQ: How do I make a claim if I’m injured at a practice while working as an independent contractor?\nA: If you do not carry workers’ compensation yourself, notify your employer immediately and seek professional treatment. Urgent Care facilities can take care of most non-emergency/life-threatening situations that may happen in a veterinary office.\nQ: Will I have to prove my independent contractor status to the insurance company?\nA: When they see you are a sole proprietor, show no staff payroll but chose to include yourself they understand what you are trying to accomplish.\nQ: Does my personal health insurance cover me if I’m injured at a practice while working as an independent contractor?\nA: Potentially but if you do not have workers’ comp, it would be best to allow the workers’ comp policy of the employer to respond because the coverage is broader than your health insurance.\nQ: Does my right to coverage by veterinary practice’s workers’ compensation insurance depend on the state where I’m working?\nA: Yes. For more information about workers’ comp, it is recommended to call your state insurance department or a local insurance agent. If you are in North Dakota, Ohio, Washington, Wyoming, Puerto Rico or the U.S. Virgin Islands, workers’ compensation coverage is through the state/territory and not a policy of the vet hospital where you work.\nQ: What if a practice requires me to have workers’ compensation coverage but I don’t have my own?\nA: You can either decline to work for that practice or you can offer to have the hospital you work for withhold 2% from your paycheck so that you can be covered under their policy at limited to no additional cost to the hospital. Alternatively, you can purchase your own workers’ compensation policy.\nQ: What if a veterinary practice asks me to sign a form staying that I won’t make a claim against their workers’ compensation insurance and I get injured on the job?\nA: This is legally meaningless and is only meant to deter you from making a claim. You will still be covered by the practice’s workers’ compensation policy if you are injured on the job.\nQ: What if I already have a workers’ compensation policy and I’m injured while working as an independent contractor?\nA: It depends on if you are included in coverage or excluded yourself. If you included yourself, simply file a claim for the injury. If you are excluded from the coverage you would need to file a claim with your health insurance or pay the bill yourself.\nQ: Does workers’ compensation insurance pay for lost income if I am severely injured while working as an independent contractor at a veterinary clinic?\nA: It can, but not 100% of your income. After 7 consecutive days out of work for an injury the carrier may begin to pay you lost wages, but at a rate no greater than two-thirds of your income. Typically, this income is tax-free.\nQ: Where do I go to get more information regarding my state laws about workers’ compensation coverage?\nA: For more information about workers’ compensation it is recommended to call your state insurance department or a local insurance agent.\nQ: Do practices have to literally add my name to their policy in order for me to be covered or is this just automatic?\nA: They never have to add your name. Workers’ compensation covers all W-2 and 1099 workers (who do not have their own workers’ comp) whether the employer calls the carrier or not. If an employer says “we are not going to add you”, that is likely because the employer either does not fully understand how workers’ comp actually works or they are hoping that you do not. Most 1099s are automatically covered by their employer’s workers’ comp unless the independent contractor has their own workers’ comp policy.\nHopefully, this sheds some light on the independent contractor/workers’ compensation insurance confusion. Insurance is tricky with all of the various states’ laws, so before you make any major decisions around insurance, be sure to consult with your state insurance agency or local insurance specialist. Check out part I of the workers’ compensation blog series for more information.\nFor more information on workers’ comp laws in different states, you can check out this link: National Federation of Independent Business.\nRelief Rover is working hard to provide you resources for your business and practice questions. We welcome your feedback, questions, and ideas.\nIf you are a relief vet, a practice looking to hire a relief vet, or want to learn more about relief life, come visit us at www.reliefrover.com!', 'Small business owners in New Jersey protect their establishments and employees with NJ business insurance, which can provide a financial safety net to cover unexpected expenses when things go wrong. These businesses are responsible for writing paychecks for more than 1.9 million employees, representing almost half of all workers in the Garden State.\nSmall business insurance provides financial protection against losses. The types of risks covered vary by policy and can include property damage, employee injuries and illnesses, liability and lawsuits, or acts such as cybercrime or employee theft. It can help keep your business on track after accidents and events such as:\n- Injuries to non-employees, including clients\n- Damage to someone else’s property\n- Claims of professional negligence\n- Employee injuries on the job\n- Auto accidents while driving for business\nMinimum business insurance requirements in New Jersey\nNew Jersey has multiple laws and regulations concerning business insurance requirements across a wide swath of industries operating within the state. The size of your business, industry, and number of employees will have the biggest role in determining insurance requirements for your business.\nWorkers compensation insurance and general liability insurance are the most common coverages in New Jersey. There are several factors that will mandate Workers’ Compensation Insurance in New Jersey. A licensed insurance advisor will be able to determine if your business falls within any of these requirements and if any exemptions are applicable.\nMost popular New Jersey business insurance policies\nWorkers’ Compensation Insurance\nNew Jersey state law requires most businesses with employees to carry workers’ compensation coverage. This kind of coverage provides protection when employees are hurt on the job, and can help cover medical bills and lost wages during their recovery.\nFor example, two employees at a construction company in Paterson suffer back injuries while moving a beam on the job, leaving them unable to work for a month. Workers’ comp could help pay for their medical expenses, and physical rehabilitation bills and cover lost wages while they get better.\nTypes of insurance under this include:\nYou and any other members of your business can acquire a life insurance policy. This is similar to key person insurance, providing a beneficiary with financial assistance in the event of your death. Having life insurance in place can give you peace of mind that your death will not burden your family or business partners financially.\nDisability income insurance\nDisability insurance is similar to workers’ comp in that it temporarily covers an employee’s lost wages if they are unable to work because of a disability. However, disability insurance will cover injuries or illnesses that occurred on or off the job, whereas workers’ comp only covers work-related issues.\nThis type of insurance is also sometimes required by law.\nKey person insurance\nWhen founders die, businesses often have a challenging time continuing operations. It is essential for entrepreneurs to create a business continuity plan so the company can still thrive if the worst happens.\nKey person insurance, also known as key man insurance or key woman insurance, helps replace lost revenue due to the death of a key executive of your business. Your business pays the premium while the key person is alive and then collects a death benefit after their passing.\nThese benefits can be essential to continuing the operation of your business or finding someone to fill their role.\nGeneral liability insurance\nGeneral liability coverage, also called commercial general liability insurance, is one of the most common and important forms of business insurance in New Jersey. If someone claims that your business caused injury or destroyed property, general liability insurance can help pay for damages and lawsuit costs if you’re sued.\nFor example, a homeowner accuses a Newark-based HVAC company of improper wiring that starts a fire and causes significant damage. General liability insurance could help cover the cost of repairs and pay attorney fees if the client takes the HVAC company to court.\nConstruction and cleaning companies in New Jersey might want to add tools and equipment coverage to their general liability policy. This optional coverage can help pay to repair or replace work gear that’s lost, stolen or damaged outside of normal wear and tear.\nProfessional liability insurance\nProfessional liability insurance, also known as errors and omissions (E&O) insurance, protects businesses that offer professional services in New Jersey. B2C businesses often use E&O coverage to protect against claims stating their services caused clients financial distress or bodily injury.\nDoctors’ malpractice insurance is a common type of professional liability insurance. This insurance type is also essential for professional service providers like consultants and financial advisors. Costs for professional liability insurance will vary depending on the industry and profession. For example, a doctor would likely pay more than a CPA.\nBusiness Owners Policy (BOP)\nIf you live in New Jersey and want general liability insurance and property coverage, you can package them together in a business owner’s insurance policy, also known as a BOP. A BOP provides liability coverage for customer injury, property damage, and product-related claims, in addition to commercial building and movable property coverage.\nMany BOPs also include business interruption coverage, which pays your lost revenues if you close for a covered claim. This coverage type is ideal for owners of small and midsize businesses like restaurants, retail stores, and wholesalers. Keep in mind that BOP insurance doesn’t cover your employees.\nCyber insurance protects businesses against losses and liabilities arising from cyber threats and data breaches. It provides coverage for expenses related to data breaches, including legal costs, customer notification, credit monitoring, and reputation management.\nBusinesses in New Jersey can use cyber insurance to manage the financial and legal risks associated with data breaches, cyber-attacks, and other cyber incidents.\nDirectors and officers (D&O) liability insurance\nIf your business has a corporate board of directors or advisory committee, you want D&O insurance. This insurance protects your directors’ and officers’ assets if they are personally sued for wrongful acts in company management (e.g., failure to comply with workplace laws, fraud, theft of intellectual property, misrepresentation of company assets, or misuse of company funds).\nCommercial auto insurance\nCommercial auto insurance provides coverage for vehicles used for business purposes in New Jersey. It includes liability coverage for third-party injuries or property damage, as well as coverage for damage to the insured vehicle.\nCommercial auto insurance is similar to personal automobile insurance; it protects your cars, trucks or vans in the event of damage, injury or liability claims. However, commercial auto insurance provides additional coverage, including property and liability trailer exposure, loading and unloading exposure, hired vehicle coverage, non-owned vehicle coverage, and higher coverage limits.\nCommercial auto insurance packages in New Jersey may include hired and non-owned auto coverage. This optional insurance upgrade can help pay for business accident damages for employees who occasionally drive their own cars for work or rent vehicles.\nCommercial property insurance\nCommercial property insurance in New Jersey can protect the things you need to run your business, such as equipment, inventory and even your business location if you own the property.\nIt’s important to read your policy documents carefully to make sure there aren’t exclusions for your business. Some locations prone to flooding or hurricane damage might have limited coverage.\nBest business insurance providers in New Jersey\nAllstate offers a line of insurance for small businesses. Its coverages include BOP, property coverage, business liability, business interruption, equipment breakdown, and commercial auto.\nAllstate’s overall ease of use seems to lag behind some other companies in our review. You can get a quote for a commercial auto policy online, but it’s not clear how easy it is to get a quote online for other business insurance products — it appears that an agent must complete quotes for some business types.\nAlso, according to its website, you can only file a claim through an 800 number.\nChubb is one of the largest insurers in the United States. Its business insurance offerings include workers’ compensation, BOP, cyber insurance, professional liability, general liability, and business umbrella.\nOn the Chubb website, you’ll find a lot of useful information to help small business owners understand their insurance needs, including articles and tools such as cost estimators. You can get a quote online or through an agent and report a claim online as well.\nNext Insurance is a relative newcomer to the small business insurance market. However, the company has received significant financial backing from Munich Re, one of the world’s largest multinational insurance companies.\nAs it is among a growing number of companies focused on insuretech, Next Insurance offers an easy-to-use web experience. You can get online quotes for general liability, workers’ compensation, BOP, commercial auto, and more. You’ll also find coverage packages tailored to the typical needs of certain types of businesses such as contractors, retailers, fitness providers, and even Amazon sellers.\nAlso, you can download a certificate of insurance through the website or the company’s app.\nBased in New Jersey, NJM sells business insurance to customers in several mid-Atlantic states. The company offers workers’ compensation, commercial auto, commercial excess and umbrella, EPLI, cyber insurance, BOP, and a commercial package policy.\nThe commercial package policy includes property coverage, liability coverage, business income insurance, inland marine, and crime coverage. It is similar to a BOP but caters to businesses with more extensive coverage needs. With NJM’s small business insurance policies, you can get a quote online or through an agent and file a claim online or by phone.\nWhile perhaps best known for its personal auto coverage, and ubiquitous advertising mascot, Progressive offers a broad slate of business insurance. Its offerings include BOP, professional liability, general liability, workers’ compensation, cyber insurance, commercial auto, and contractor liability.\nThe company claims to be the number one commercial auto insurer in the U.S. (based on premium), with more than 1.9 million insured vehicles.\nThe Progressive website promises quotes in just a few minutes and includes a variety of resources, such as articles and FAQs, to help you understand your coverage needs. The company is also supported by a countrywide network of independent agents. You can file a claim online or by phone.\nState Farm offers various types of protection, including BOP, commercial auto, liability, workers’ compensation, inland marine, E&O, EPLI, key person coverage, and more. The company website’s “Small Biz Quiz” is a helpful feature designed to assist you in determining coverage needs and you can also use State Farm for your retirement plan.\nPerhaps State Farm’s only drawback is its ease of use. Quotes and policy sales are through its local agents only, and the website does not appear to offer a claim reporting feature — you have to call the company instead.\nHow much does small business insurance cost in NJ?\nThe cost of business insurance in New Jersey can vary widely based on several factors. Business size, industry, and amount of coverage all affect monthly premiums in New Jersey.\nFor example, the cost of a Business Owners Policy for a manufacturing company operating in Newark will be very different from a Business Owners Policy for a hardware store in Paterson. Other considerations such as annual sales, payroll, company assets, and claims history also help determine the cost of business insurance in New Jersey.\nA licensed insurance advisor will be able to identify Business Insurance discounts in New Jersey that you may qualify for, along with discounts for bundling Business Insurance in New Jersey.\nThe average costs of business insurance in New Jersey are:\n- General liability: $40 per month\n- Workers’ comp: $44 per month\n- Professional liability/E&O: $64 per month\nBusiness insurance packages in New Jersey will be priced based on your company’s insurance requirements. Some of the factors that will affect your cost include:\nYour profession and risk profile\nIndustries that have a greater risk of injury and property damage can expect to pay more each month for coverage. For example, construction companies in New Jersey will likely have a larger business insurance bill than professional services firms.\nThe coverage options you select\nWhile you might be tempted to omit some types of recommended coverage when purchasing your insurance package, this may not be in your best interest. Although it could save a little money every month, this can put you at risk of paying out of pocket if you don’t have the right coverage when an accident happens.\nNumber of employees\nMost states determine workers’ compensation insurance costs based on the number of workers on your payroll. Providing up-to-date employee numbers for your insurance quote is the best way to get an accurate price.\nThe best way to explore coverage options and find out how much you’ll pay for a business insurance policy is to get a free instant quote.\nHow much business insurance coverage do I need in New Jersey?\nThe amount of coverage you need — and its cost — will vary greatly depending on the type of business you run, its size, number of employees and assets, and other factors.\nMost small businesses need general liability insurance, property insurance, and business interruption coverage. You can package these coverages into a BOP to make things easier and, in most cases, save some money. If you have employees, you’ll likely also need workers’ compensation. Meanwhile, you’ll need commercial auto insurance if your business owns, rents, or leases cars or trucks.\nMany insurance company websites have coverage selection tools to help you understand your business’s coverage needs. Some companies even sell packages of coverage tailored to the needs of specific types of businesses. You can also reach out to an insurance agent who sells business insurance.\nAn agent will take the time to understand your business and match you with a policy that meets your needs.\n- Business Insurance Quotes: Getting Insurance Quote Online\n- The Hartford Business Insurance Review 2023\n- 10 Best Commercial Insurance Companies 2023']	['<urn:uuid:10bbc8ca-337a-4162-9518-34726b6bfd67>', '<urn:uuid:7cb7ceff-1792-4cb8-ad59-08f2b8828c38>']	factoid	direct	long-search-query	similar-to-document	comparison	novice	2025-05-12T23:56:45.148498	13	71	3846
7	What happens when opening old Adobe files in new versions?	When loading older Adobe files in newer program versions, the software attempts to change them to the newer format, potentially damaging the contents and making them unreadable to the original program.	['My previous post on identifying file formats introduced my three approaches to uncovering evasive file definitions. Examine the context, search the internet and mine the header. In this post I’m returning again to those methods and the files from Prom Week’s Dropbox folder to highlight more file format related issues. This time I’ll focus on versioning issues and software obscurity.\nFirst, since I didn’t elaborate on this in the last post, the purpose for this type of investigation is to ascertain what a future researcher would need, in terms of executable resources (operating systems, programs, hardware configurations, etc.) to properly run and examine the work produced by a development team. In the case of just a subset of the shared cloud files for Prom Week the answer is surprisingly extensive and diverse. Looking through over 2000 files in the folder, I identified 60 different file types requiring the interpretation of at least 29 programs.\nPlopping the list here for effect, this is not a final assessment of the required programs, as I’ll explain in a sec. The file extensions are on the left, notes on the right.\n- .txt – text files\n- .docx – Microsoft Office Document 2007 or later, archive / ooxml filetype\n- .svg – Scalable Vector Graphics\n- .vue – Visual Understanding Environment (VUE) file (Tufts University)\n- .png – Portable Network Graphics\n- .zip – ZIP File Archive\n- .pptx – Microsoft Powerpoint Files 2007 or later\n- .ppt – Microsoft Powerpoint Files\n- .pdf – Portable Document Format\n- .xlsx – Microsoft Excel Files 2007 or later\n- .as3proj – FlashDevelop ActionScript 3.0 Project File\n- .xml – Extensible Markup Language\n- .bat – Windows Batch File\n- .swf – Shockwave / Flash Files\n- .old – “Old” backup file\n- .mxml – Flex meta XML file format\n- .as – Actionscript 3.0 file\n- .jpg – JPEG Joint Photographic Expert Group image file\n- .java – Java Source File\n- .fla – Adobe Flash File\n- .pbm – portable bitmap file (Netpbm)\n- .ai – Adobe Illustrator File\n- .html – Hypertext Markup Language\n- .css – Cascading Style Sheet\n- .doc – Microsoft Office Document\n- .psd – Adobe Photoshop File\n- .gif – Graphics Interchange Format image file\n- .avi – Audio Video Interleave\n- .camproj – Camtasia Studio project file (Camtasia Studio 7.0)\n- .rtf – Rich Text Format\n- .swc – Compiled Shockwave Flash File\n- .potx – Microsoft PowerPoint Template File (XML Format)\n- .xcf – GIMP (GNU Image Manipulation Program) file format\n- .vpk – VUE package file (for sharing VUE maps)\n- .camrec – Camtasia Studio recording file\n- .mp3 – MPEG-1 or MPEG-2 Audio Layer III digital audio file\n- .jpeg – Alternate extension for jpg file\n- .mov – Quicktime video file\n- .pages – Pages document file\n- directory file – Folder file\n- .dropbox – Dropbox configuration file\n- .wav – Waveform audio file format\n- .au – Audacity block file (NOT Sun .au audio file)\n- .aup – Audacity project file\n- .aup.bak – Audacity project file backup\n- .bak – Backup File\n- .lel – from “robert-portrait Logon.lel” filename clue, Windows 7 Logon editor file (http://www.tweakscene.com/viewtopic.php?f=149&t=4614)\n- .dll – Dynamic-link Library Microsoft Windows shared library\n- .pyd – same as a .dll though written in Python (http://docs.python.org/2/faq/windows.html#is-a-pyd-file-the-same-as-a-dll)\n- .sql – Structured Query Language File\n- .php – PHP language file\n- .odp – OpenDocument presentation file (OpenOffice Impress)\n- .mp4 – MPEG-4 Part 14 multimedia format\n- .7z – 7Zip Archive File\n- .odt – OpenDocument text document (OpenOffice Writer)\n- .fxp – Adobe Flash Builder Flex Project File\n- .csv – Comma-Separated Value file\n- .m4v – Apple video format\n- .xmpses – Adobe Premiere Elements DVD Marker file\nAside from being a rather imposing listing, at least to my archival mind, this crash of files highlights the difficultly in finding relevant programs to read and run individual entries.\nThe first problem is the need to find the correct version of a program for a specific file. For example, 7 and 8 on the list above are .pptx and .ppt files for Microsoft Powerpoint. The former is a XML based document scheme used for Microsoft Office documents created in 2007 or later. The latter is a pre-Office 2007 Powerpoint document, or a document saved as a .ppt in a post-Office 2007 Powerpoint. I don’t have a way to tell without doing some immediate digging.\nAnother version issue arises with Adobe Creative Suite programs. Adobe Illustrator (22) and Photoshop (27) files have maintained the same file extension for a large number of versions. Some features in older files are not reproducible in newer versions of the software and vice-versa. This creates an issue when you load an older file in a newer program; it attempts to change it to the newer format, thus making it unreadable to the program that created the file and potentially damaging the contents of the file itself. It’s effectively destroying the provenance of file, which is a huge no-no. In order to ensure that everything remained in the exact condition that the developers left it, an archivist or researcher would need to identify the file type and then find the contingent version of the software that created the file.\nA good example that I worked through was for the .camproject file type (30) above. This file is produced by Camtasia Studio, a screen capture program for Mac and Windows popular with screen casters, and also used here to record demo gameplay videos for Prom Week. After finding the file type after a simple search, I mined the header anyway just to see if there was anything interesting in there. Turns out it was a good example of a potential solution to the version issue, sometimes the information is just explicitly present in the file:\nThat seems pretty straight forward, but since that is just a project data version and not a program version, I ventured a little farther and found the path to the program’s executable.\nSo there, sometimes its not too difficult to find the version of a specific file. Since .camproject is also just a text file, it would be rather trivial to right a script or parser to analyze and provide the correct file version without snooping. However, the approach here would not generally scale, especially if the information in the file is in an arbitrary, non-textual form and could then only be identified through structural analysis. One would have to write a program to do statistically reasoning over a corpus of filetypes, and who would be that nuts?…Oh Harvard? Harvard and JSTOR…really…huh. So yeah, there is a program called JHOVE that does do that and I’ll be looking at it in a future post. By JHOVE!\nEven after you’ve found a file type or rather, think you’ve found a file type, there are still other potential barriers to getting it running. Two file types in the list, the .vue file (4) and the .lel file (48) illustrated the difficulties better than most. Starting with the .vue file, which is a Visual Understanding Environment file for a mind-mapping software made developed at Tufts University, I hit some identification road blocks when searching the internet. VUE files are commonly used three-dimensional geometry files (something that would conceivably be found in a game) and are also the file format for Microsoft FoxPro, a data schema development application (I hadn’t heard of it either.) Since both of these uses apparently aren’t uncommon, I figured one of them might be correct. Upon further analysis, however, it became obvious that there was no use for 3D geometry in a strictly 2D flash game, so that file type was out. Additionally, I couldn’t find any mention of FoxPro in the group email or discussion and it didn’t seem to make much sense, especially since the filenames for .vue files didn’t line up with data scheme type uses.\nEventually, after I had given up on the .vue file (since it’s header didn’t have anything helpful), I was examining another file, a .vpk (35) through a text editor and low and behold, there was some additional information:\nAfter seeing the Tufts reference in there, I went back to the Google and found the Visual Understanding Environment project page. This allowed me to identify the .vpk file and and the complementary .vue file! As should be evident, there will even be confusion when you think you’ve found a game related file type but it doesn’t fit the development context. Another issue is that the .vue and .vpk files are proprietary formats used for a little known application. In the future it will probably become even more difficult to locate a correct binary.\nEven more extreme is the .lel file (48). Searching the internet for a decent amount of time finally lead me to a forum posting mentioning the format. The post discusses a Windows 7 log on screen modification program, which I figured was correct since the file I was trying to identify was called “robert-portrait Logon.lel”. The link to the program from that post had expired, but given that I now knew it was associated with a specific program, I searched for and found a newer version. Sadly, both the application link there and its mirror are now both gone and I can’t find them elsewhere, meaning I have no way to open the .lel file nor verify it. The log on screen application is probably the most obscure program of the thirty or so I found. Its existence is was the most in danger, given that it’s a small, non-professional application made for a subset of the DeviantArt community.\nObscurity of software is a double-edge sword for preservation. If something is really obscure and made for a small user base it usually isn’t that large or complex (yes I know some people write their own flight simulators). So it’s generally easy to just save a copy with the data you want it to read. The log on editor program file is probably very small, and I could have just wrapped it up with all the other data in the project without much fuss. Therefore after sussing out file types, one should definitely see if any of their dependent programs are in immediate danger of disappearing or they might not be recoverable. The .lel file was created less than three years ago and is now unreadable, things go away fast on the Internet. A main point of this work is to highlight the transience and instability of data online, another site mentioning the .lel file literally told me to just Google it, assuming that it would just be available somewhere. Sigh.\nSo there, a bit more information on file types, I’ll return to them at some point in the future but I’m going to break up the posts a bit since there are so many things to talk about.']	['<urn:uuid:c0d1fcdb-d4a6-4d1b-a875-e2ef2de46680>']	factoid	direct	concise-and-natural	distant-from-document	single-doc	expert	2025-05-12T23:56:45.148498	10	31	1829
8	I notice that my teammates aren't really connecting or working well together lately. What's the science behind getting teams to stick together and work as one unit?	Research has shown that team cohesiveness - the tendency for a team to stay united in pursuing its goals - is key for team effectiveness. Team cohesion develops through several important factors: creating distinctiveness (like team names and routines), establishing clear individual positions and roles, developing shared group norms, encouraging individual sacrifices for the team, and fostering frequent interaction and communication between members. Additionally, psychological safety plays a crucial role - when team members feel safe to take risks and be vulnerable with each other, they're more likely to admit mistakes, ask questions, and work together effectively. Leaders can build this by framing work as a learning opportunity and encouraging open discussion.	"['What kind of teammate are you? What kind of team are you on? And what makes a good team tick?\nThose might seem like simple questions, but they’re harder to answer than you might think. And with businesses becoming more and more global and cross-functional, the issues they raise are increasingly important. Not only is the nature of teamwork changing, effective teams may be the most vital ingredient for successful transformation and innovation.\nPart of my job is to help clients and agencies think about the role teamwork plays and how to improve. Another part is to help teams inside Google work on their effectiveness, and it’s in that part, in trying to improve our effectiveness, that we uncovered a strange situation. Almost everyone agreed that team effectiveness was important, but no one had put together data to analyze what exactly makes a team effective.\nDefining the question, then finding answers\nAt Google, our researchers in People Operations quickly got to work on the question: What sets apart our most effective teams from the others?\nRight off the bat, the researchers needed to define what “effective” means in this context. The team began by asking three different groups of Googlers – executives, team leads and team members – for their definitions of the word. First up, the executives said effectiveness was all about results. Then the team leads defined effectiveness in relation to ownership, vision and goals. Finally, the team members told us that team culture was the defining attribute.\nThose three distinct, equally valid perspectives on effectiveness helped the researchers frame their method. Having prepared more than 250 inputs looking at team dynamics and composition, they used their preparatory research to define three outputs, then applied their survey at scale. The researchers interviewed more than 200 teams across all areas of the business, from Engineering to Product Management, Sales and everything in between. They drew on other data sources, too, in what became a major undertaking, involving more than 35 statistical models and the coding of over 170,000 words.\nThe five dynamics of effective teams\nWe had imagined that building an effective team would be like solving a puzzle – that the best teams would be those where outstanding individuals were put to work together. We even thought that there might be an opportunity to create a new algorithm that could predict how to assemble perfect teams.\nInstead, the researchers found something incredibly surprising. At Google, who is on a team matters much less than how team members interact, structure their work and view their contributions. And across all types of teams, from Sales to Engineering, from San Francisco to Singapore, five dynamics consistently differentiated top-performing teams from those at the bottom.\nThis was the single most important dynamic in an effective team. Psychological safety is about risk-taking and being comfortable with vulnerability. People who don’t feel psychologically safe worry that taking risks will mean they’re seen as ignorant, incompetent, negative or disruptive. Psychological safety means feeling confident about admitting mistakes, asking questions, or offering new ideas.\n- Dependability: On dependable teams, members reliably complete quality work on time. They don’t avoid their responsibilities and they take them seriously, helping to keep the team on track. As simple as it sounds, this turned out to be vital for effectiveness in teams.\n- Structure and Clarity: This means that a team has clear roles, goals and plans. Individuals understand what’s expected of them, what they and their team is aiming for and how they are all going to get there. Google often uses Objectives and Key Results (OKRs) to help set and communicate specific, challenging and attainable short- and long-term goals, at an individual and at a group level.\n- Meaning: For individuals on a team, finding a sense of purpose in their work or its output is vitally important for team effectiveness. That meaning is personal, so it varies from person to person, but might include financial security, their ability to support their family, their commitment to the success of the team, or their individual self-expression.\n- Impact: Do you fundamentally believe that the work you do makes a difference? This subjective judgment marks out the most effective teams and can be based on seeing how one’s work contributes to an organization’s goals and what it has helped to change.\nTake a moment to think about what could have been on the list, but didn’t make it. “Consensus-driven decision making” didn’t make the cut. Neither did “workload” or being co-located. Perhaps most remarkably, the number of top performers on a team and the general intelligence of a team emerged as a poor indicator of a team’s effectiveness. We found both attributes in some of the very best teams, but we also found them in the some of the weakest.\nPsychological safety: what matters most\nOf the five dynamics, one stands out ahead of the others. Our researchers found that the best teams created a climate of openness where team members admit to their errors and discuss them more often. In other words, they exhibited high levels of psychological safety, a concept originated by Harvard Business School professor Amy Edmondson.\nPsychologically safe teams accelerate learning and innovation by acknowledging mistakes and exploring new ideas. And not only are they more adaptable, they can also impact the bottom line. Our research revealed that sales teams with high ratings for psychological safety actually brought in more revenue, exceeding their sales targets by 17%. Teams with low psychological safety fell short by up to 19%.\nSo how can leaders create psychological safety in your teams and organizations? Edmondson gives us three recommendations:\n- Frame the work as a learning problem as opposed to an execution problem: Be clear that there are areas that still require explanation and that everybody\'s input matters. Admit that the future is not certain and you need to have everybody\'s brains and voices in the game.\n- Acknowledge your own fallibility: Tell team members that you need and respect their input. As a wider attitude, this can be expressed in many ways, but even simple statements can really encourage peers and subordinates to speak up, such as ""I may miss something — I need to hear from you.”\n- Model curiosity by asking a lot of questions: This creates a need for the team to develop a voice. It gives your team the responsibility to generate answers, which engaging in a discussion and taking ownership of the process.\nHow we interact with each other as a team is more important than the people on that team. But would you recognize whether your team had strong or weak psychological safety? How could you tell? Have a go at the short questionnaire below for an idea of how you measure up. And if you want to know more, pick up a copy of Teaching by Amy C. Edmondson or Humble Leadership by Edgar Schein for the expert take on psychological safety.\nQuiz: How psychologically safe is your team?\nAsk yourself the following questions to identify strengths and weaknesses in the way your team works together.\n- Do you struggle to have tough conversations?\n- Do you feel judged and that the team members lack respect for one another?\n- Do you fear asking for or delivering constructive feedback?\n- Are you or others hesitant about expressing divergent ideas or asking “silly” questions?\n- Do you feel that you can\'t make mistakes or take risks?\n- Are team discussions dominated by a few strong voices that marginalize other people’s perspectives?\n- Are the members of your team competitive with one another?', 'Leader & Team Dynamics\nMaterials presented here are based in part on information in Wann, D. L. (1997). Sport psychology. Upper Saddle River, NJ: Prentice-Hall.\nThe purpose of this Page is to develop an understanding of the intricate relationship between leader style and behavior and sport team performance.\nIntroductionMost successful organizations or teams are managed by effective leaders. A leader may be the expert, the one who\'s in-charge, the person most respected by her/his followers, the man that controls aversive power or the individual that has the capacity to dispense rewards. In fact, a leader may possess any one, or any combination of the above described sources of leadership powers (Wann, 1997).\nEarly systematic studies on leadership focused on psychological traits that are common among proven successful leaders. By the end of the 1970s it became quite clear that leaders, such as, Joseph Stalin and Martin Luther King, were successful despite possessing very different traits, leadership styles and goals. Thus, the focus of inquiry has shifted from trait to other possible explanations of successful leadership.\nThe study of personal leader characteristics did not produce dependable predictions of successful leadership. An alternative explanation to successful leader performance is based on the study of leader behaviors. The premise of this approach is that leaders engage in specific behaviors that contribute to their success. Thus leaders are better defined by what they do as apposed to who they are.\nA directive or possessive style coach takes full charge of her/his team and its business, and closely monitors athlete behavior and performance.\nA permissive or ""laissez-faire"" style coach delegates responsibility to her/his athletes and thus has more time to personally handle issues that he/she deems most critical.\nAn autocratic or command style coach maintains single-handed control over decisions and action regarding team business. As pointed out by Wann (1997), a directive autocratic style is effective with young, unexperienced athletes who have a lot to learn and little to offer.\nA democratic or interactional style coach involves assistant coaches, team captains and other player representatives in team business related decisions. To maintain credibility, interactional coaches must lead by persuasion, i.e., explain their choice for action rather than force it on their assistants and athletes.\nTask- or Person-Oriented\nA task- or production- oriented coach, according to Wann (1997), are mostly interested in the task at hand. Precise descriptions of team members\' roles and responsibilities are of primary concern to the production-oriented coach. Assistant coaches and athletes alike are expected to be familiar with practice and match protocols.\nPerson-oriented coaches, on the other hand, emphasize interpersonal ties on the team. Teams headed by a player-coaches, as Wann (1997) suggested, and less competitive teams that display strong social relationships are most likely to have and benefit from this leadership style.\nTheories of Leadership\nFiedler\'s (1978) Contingency Theory\nUtilizing laboratory controlled experiments, Fiedler (1967), tested his contingency theory of leadership. His model includes three situational factors (group atmosphere [good or poor], task structure [high or low], and leader position power [strong or weak]). His analysis predicted group performance based on a leadership style that corrsponds to situational factors and their direction or value. A re-examination of Fiedler\'s original data during the early 1980s using a different statistical analysis procedure yielded insignificant and unconclusive results. Fiedler\'s model like Kohlberg\'s, and the McClelland-Atkinson models is still relevant, not because it provids an accurate theoretical framework, but because it sparked a debate that paved the way to new, more robust theories of leadership (moral development, and motivation).\nThe Normative Theory of Leadership\nUtilizing Vroom and Jago\'s (1988) normative theory of leadership, Chelladurai (1993) proposed a normative model of decision styles (autocratic, participative, and delegative) in coaching (Wann, 1997). A casual observer of the dynamics on a typical competitive sport team would conclude that coaches make all decisions alone and take the blame for failure. Athletes on the other hand, like to concentrate on their responsibilities as players and prefer not to get involved in coaching. The available research clearly suppports the above observation.\nThe Attributional Theory of Leadership\nThe Normative Theory of Leadership\nThe Multidimensional Theory of Leadership\nDream Teams: From Collections of Individuals\nto Effective Sport Teams\nAnyone traveling around the world and observing different people can readily notice that human beings spend a great amount of time doing things together in groups. German sociologist, Kurt Lewin coined the term ""group dynamics"" and created fertile grounds for new ideas such as ""group culture"" and ""group mind.""\nYet, do terms like ""group mind,"" or ""team spirit"" make any sense when examined through a Newtonian perspective of reality? Can the extent of the team\'s spirit be somehow measured? Is a team\'s performance a reflection of the added individual talents of its individual members or is a team\'s performance a reflection of a sum that is greater, or smaller than, the tally of each of the individual performances?\nSir Isaac Newton\'s motto was to make no hypotheses. Newton\'s criterion for the validity of any observation was an experimental verification of that observation. Newton would put an observation in writing if he could produce the same result over and over again, and others using the same procedures could also get the same results. Given the fact that one has all the necessary information, according to Newtonian physics, it is possible, in principle, to predict exactly how a given event is going to unfold.\nQuantum mechanics (the study of motion of quantities) or the new physics is not an alternative for the old physics but is an extension of it. When the atomic and sub atomic levels are studied, the available data can only predict the probability of a certain event as opposed to the precise event as is the case in Newtonian physics. Subatomic particles cannot be pictured as an object, rather they can be viewed as ""tendencies to exist"" or ""tendencies to happen."" Experiments in the subatomic realm demonstrate that there is no way to predict individual events at that level. Therefore, quantum mechanics concerns itself only with group behavior (example of billiard balls vs. subatomic particles).\nPsychologists William McDougal and Floyd Allport led two opposing views regarding the ""group mind"" controversy (Gergen, 1982). F. H. Allport was a harsh critic of the anthropomorphic conception of human groups. In his view only individuals were real and groups or institutions were ""sets of ideals, thoughts, and habits repeated in each individual mind and existing only in those minds (Allport, 1924)."" Allport\'s view of interactions between members of a group is analogous to the relationships among billboard balls. They move and hit each other and affect each other in precisely predictable ways, and stay intact throughout the whole process. McDougal, on the other hand, held the position that groups, institutions, and culture formed new realities and forces that could not be explained by strictly adding the particular individual group members\' talents and contributions. McDougal\'s view is analogous to the relationships between subatomic particles which mix and merge with the neighboring particles and create new relationships.\nFloyd Allport\'s individualistic orientation was the dominating view in academia until Mayo (1933) and his associates reported their extensive research at the Hawthorn plant of the Western Electric Company. What started as a project to investigate the relation between conditions of work and the incidence of fatigue among workers ended up changing radically and irrevocably the thinking about industrial worker dynamics. ""The role of the leader began to shift from one who directed work to one who enlisted cooperation. The incentive to work was no longer seen as simple and unitary but rather infinitely varied, complex, and changing (Haire, 1954).""\nSports, as most sport scientists would agree, is a microcosm of society--it mirrors the values, structure, and dynamics of the society in which it exists (Coakly, 1994). It is no wonder, therefore, that the concept ""group mind"" was eventually investigated in the realm of sports and sports teams. Different groups, as well as sport teams, display a great variety of properties such as size, duration, objectives, internal structures, norms and many other aspects. The large variety of properties displayed was the main reason for the difficulty in the formulation of an all encompassing definition of the term ""group."" Such a definition would have to provide a clear distinction between those social entities to be called ""group"" and those to be given some other name.\nAccording to Homans (1950) ""A group is defined by the interaction of its members."" Lewin\'s (1948) point of view was that a group is best defined as ""...a dynamic whole based on interdependence rather than on similarity,"" and Bass (1960) defined \'group\' as ""...a collection of individuals whose existence as a collection is rewarding to the individuals."" It does not take a sport sociologist to see how each of the above mentioned definitions of \'group\' describe some aspects of a sport team.\nThis presentation focuses on the term first introduced by Kurt Lewin in 1935 ""cohesiveness"" (Cartwright & Zander, 1968) and the term ""group dynamics."" The relationship between social cohesion, group dynamics and sport team participation and performance will be examined. Athletes coaches and researchers alike often assumed that when players on a team display unity and ""stick together,"" they will have a greater chance of team success. Although some evidence supports this view (Arnold & Straub, 1972); Ball & Carron, 1976; Carron & Chelladurai, 1981; Gosset & Widmeyer, 1981; Widmeyer & Martens, 1978), there is also research which fails to provide support (Melnick & Chembers, 1974; Ruder & Gill, 1981), or research that support the opposite view; that is--there is a negative relationship between team cohesion and performance (Landers & Lueschen, 1974; Martens & Peterson, 1971).\nDeveloping the Sport Team Concept\nTeam Roles: Formal vs. Informal Roles\nrole clarity, role acceptance, and role performance\nEstablishment of Group Norms\nNorm for Productivity\nStabilizing Group Structure\nZander (1982, cited in Carron, 1986, p. 82) provides the following suggestions for the stabilization of group structure:\nShow individual team members how the group\'s standards can contribute to the achievement of desirable qualities for the team, more effective team performance, and a greater sense of team unity.\nPoint out to all team members how their contribution toward developing and maintaining the standards can contribute to the team\'s success.\nDevelop a method of assessing whether there is adherence to the group\'s standards, and then reward those team members who do adhere and sanction those who do not.\nProperties Associated with Cohesiveness\nTeam Cohesiveness Defined\nFestinger, Schachter, and Back (1950): ""...the sum of the forces that cause members to remain a part of the team.""\nGross and Martin (1951): ""...the resistance of the group to disruptive forces"".\nCarron (1982, p. 124): ""...dynamic process which is reflected in the tendency for a group to stick together and remain united in the pursuit of its goals and objectives."" Models of Team Cohesiveness\nCohesiveness: A Positive or a Negative Force?\nThe Circular Nature of Team Cohesiveness\nCorrelates of Team Cohesiveness\nSummary and Discussion\nYukelson\'s (1984) nine effective ways to enhance coach-athlete communications and team harmony:\nExamples of specific strategies that may be utilized to facilitate team cohesiveness: (Adapted from Carron & Spink, 1991)\nExample of Intervention Strategies Used\nDistinctiveness: Solicit suggestions for team name and vote on the submitted titles. Similarly, choose a team logo and uniform. Create chants, slogans, and team routines.\nIndividual Positions: Assign personal lockers and personal equipment. Let team members pick their own spot in the grid or on the field during warm-up, and encourage them to remain in it throughout year.\nGroup norms: Have members introduce each other to increase social aspects. Encourage members to become fitness friends. Establish a goal to improve certain aspects of a skill together. Promote a smart work ethic as a group characteristic.\nIndividual Sacrifices: Use the help of the more skilled team members to improve the performance of the less skilled ones. Ask individual members for their goal for the day and try to accommodate them, even though it may not be the wish of the entire team.\nInteraction and Communication: Create activities that require a partner. Make sure that team members practice, at least for part of the time on any given day, with a different partner. Create activities that engage small groups and rotate group members among the mini teams.\nDefinitions: (Based on lecture notes, and unpublished manuscript by Dr. Merril Melnick, SUNY Brockport, New York, Spring 1982)\n1. Clique: ""A relatively small, informal, voluntary group (two persons or more), without a formal structure, based on mutual interests and usually friendship. The relationship among members of the clique are usually intimate and cooperative ... The members of a clique share certain common interests that may be at variance with the structure or goals of the larger organization. The structure of social relationships within the clique is not part of and may to some extent run counter to the formal social structure of the group"" (Theodorson & Theodorson, 1969).\n2. Conformity: ""Behavior that is in accord with the expectations of a social group . . . the endeavor is to maintain the group\'s standards"" (Theodorson & Theodorson, 1969).\n3. Culture: ""The common meanings, the definitions of a situation\nCohesiveness Defined and Conceptualized\n1. Cohesiveness as attraction-to-group (a-t-g).\n"" Cohesiveness of a group is... the resultant of all the forces acting on the members to remain in the group... in other words, cohesiveness is the attraction of membership in a group for its members (Festinger, Schacter, and Beck, 1950).\n2. Cohesiveness as interpersonal attraction (IA)\n""... regardless of the unique properties in terms of which groups may be described, a group is inescapably made up of individuals. It is suggested, therefore, that when we speak of a group as being attractive, we are referring actually to the attractiveness of the members of the group"" (Lott, 1961)\n""... that group property which is inferred from the number and strength of mutual positive attitudes among the members of a group"" (Lott and Lott, 1965)\n""When the group dynamicist speaks of the \'attraction of the group for the individual\' does he not mean just attraction of the individuals for one another? If individuals are all drawn toward one another, are they not ipso facto drawn to the group?"" (Allport, 1962)\n""Cohesiveness and attractiveness are two similar ways of describing the same thing. It seems obvious that if a collection is more attractive to each of its members, each of its members must be more attracted to each other"" (Bass, 1960).\n3. Cohesiveness as intrinsic attraction (a-t-g) and instrumental attraction (social satisfaction).\n""Group cohesion refers to the relative attraction, both intrinsic and instrumental, of a small group for its individual members... Cohesion should be reviewed as a bidimentional property of small groups considering of intrinsic attraction or \'sociometric cohesion\' (a-t-g) and, instrumental attraction or \'social satisfaction\' (IA) (Enoch and McLemore, 1965)\n4. Cohesiveness as the unification of the group field.\n""Cohesiveness appears to be a group concept but has, in reality, been dealt with on an individual level...Attraction-to-group is on a lower level of abstraction than cohesiveness... It might be conceivable to develop a concept of \'cohesiveness\' which... refers to the group as a whole and not only to the individuals composing it. Such a concept, however, should not include a-t-g. To prevent contamination with individual motivation, the tipological approach seems to be more fruitful. The essence of cohesiveness should not be the staying in or leaving of the group but should be related to the degree of unification of the group field"" (Bergen and Kolkebakker, 1959)\n""...the ability of individual members to work together... The coach often refers to this ability as teamwork, togetherness, or morals, while the researcher refers to it as group interaction or group cohesiveness... The ability of individuals to effectively interact with teammates to obtain a group-desired goal has been recognized as contributing to team effectiveness"" (Martens and Peterson, 1971)\n5. Cohesiveness as uniformity/conformity.\n""Although there may be numerous definitions of team cohesion, each of which would be correct, for our purpose, we define it as a group of individuals thinking, feeling, and acting as a single unit"" (Tutko and Richards, 1971).\nCal State LA\nCoaching Philosophy ||\nPlayer Development || Fundamentals || Setting Goals || Practice Ideass\nLeadup Games || Getting Ready || Endurance || Flexibility || Nutrition\nPositive Discipline || Safety Tips || Related Links\nLast Modified: February 19, 2011']"	['<urn:uuid:b34279d7-2bba-4d33-b898-d667db86d53a>', '<urn:uuid:85dd213d-ffcc-480c-be7f-229f2c548938>']	factoid	with-premise	verbose-and-natural	distant-from-document	three-doc	novice	2025-05-12T23:56:45.148498	27	112	3997
9	pennsylvania industrial decorative arts legacy	Pennsylvania's industrial arts legacy spans from the Fred Sehring Brewery's decorative steins produced in Pittsburgh's Theumler factory (1900-1908), featuring elaborate transfer-printed designs and artistic motifs, to the Carrie Furnaces, which not only produced iron for America's iconic structures but now serves as a platform for contemporary artists, hosting sculpture conferences, iron casting events, and artistic residencies through the Rivers of Steel Heritage Corporation.	['Never before or since, to my knowledge, has a brewery over a span approaching a decade issued a series of dated steins and mugs. The Fred Sehring Brewery of Joliet, Illinois, from 1900 through 1908 annually commissioned Hugo Theumler of Pittsburgh to provide it with a new items for gifting to favored customers. By that time, brewery founder Frederick Sehring, an immigrant from Germany, shown here, had died. His son, Louis, took the reins of management and may be assumed to have given the orders for the ceramics, and likely approved the designs.\nThe first in the series, a stein, celebrated the Turn of the Century. Nationally the 20th Century had been ushered in with great fanfare and Louis had caught the spirit. “Prosit! - 1900,” it reads. This was a traditional German toast, indicating “to your good health” with a tankard raised high. The decor also has the trademark of the Sehring Brewery, a shield with a foaming stein marked with an “S” rampant. Stalks of wheat and sprigs of hops surround the shield.\nThe following year Sehring adopted a calendar motif. The elaborate label includes, as shown here, a woman whose twisted body indicates a flamboyant mood as she lifts high a foaming goblet while straddling a wooden keg. A monkish figure graced the other side of the 1901 calendar. He has his arm around a beer keg. The elaborate transfer-printed design is typical of the artistic and technical capacity of the Theumler factory.\nFor some reason I have been unable to locate a 1902 Sehring issue. In 1903 the company replaced the stein format with a beer mug. This one bears an illustration of the Joliet brewery, replete with dark smoke coming from a stack. While such a picture today might indicate air pollution, at that time such plumes indicated that the brewery was operating full out.\nFor the 1904 version, Sehring decided on a dark brown glaze surrounding the same brewery logo seen on the 1900 version. Although Theumler provided the design of the transfers on his ceramics, he did not make the actual vessels. Those were purchased as “blank” ceramics from a variety of potteries in and around Pittsburg, decorated and often stamped with his own mark. In 1904 Sehring also issued a mini-mug cum match striker, shown below It carried a design similar to the 1903 mug.\nIn 1905, the front of the stein was a repeat of the 1904 stein. The obverse, however, held portraits of lovely young women displaying considerable cleavage and a saucy manner. In a departure from the past these Sehring steins were trimmed in gold with gold handles. I am particularly fond of the woman at right who seems to have “bee-sting lips” and two purple camellias in her hair. Very fetching, indeed.\nThe 1906 mug had an unusual label. The lead word is “Gezundheit,” literally meaning “God bless you,” usually said when someone has sneezed. This raises the issue of whether Fred Sehring Brewing Co. thought their beer would make people sneeze. This mug carries the same glaze and logo that bedecks the offerings for 1904 and 1905.\nMy personal favorite among the Sehring offerings is the 1907 stein. It is decorated in a Chinese blue and white motif that features a number of idealized flowers of varying sizes. If it were not for the Fred Sehring logo and “Joliet” to guide us, we might thing ourselves back in the late Ming Dynasty. It is a truly elegant cup from which to drink beer.\nThe last stein in the series is celebrates the anniversary of the firm, founded by Frederick Sehring in 1868. It was issued by the brewery in two styles, one with the letters spelling “Sehring” in deep red, matching the familiar logo and a second in which the letters are hollow. Both stein wish “greetings” to the drinker, perhaps not as compelling as “prosit,” but better than “gezundheit.”\nIn contemplating this array of steins and jugs I am curious about the decisions that went into approving the designs for each, year by year. As to why the series stopped in 1908, we might look to the death of Hugo Theumler in September 1908 apparently of “acute indigestion.” With his passing production in Pittsburgh ceased and and all references to the firm disappeared. Nonetheless, the Sehring brewery has given us a unique series of stein and mugs. Happy the collector who can line them up, year by year, on a display shelf.', 'Almost 100 feet tall and constructed of 2.5-inch-thick plate steel lined with refractory brick, the iron cupolas at the Carrie Furnaces National Historic Landmark in Swissvale and Rankin, Pennsylvania, are extremely rare examples of pre-World War II iron-making technology. Since the collapse of the Pittsburgh region’s steel industry and the dismantling of most of the mills along the waterways of southwestern Pennsylvania, the Carrie Furnaces are the only non-operative blast furnaces in the area that remain standing. A visit to the Carrie Furnaces is like stepping into a cathedral of iron and steel. The architecture is both overwhelming and inspiring. This is a sculptor’s paradise, and it also happens to be one of the sites for the 26th International Sculpture Conference, “Sculpture in Context: Tradition and Innovation.”\nPlace matters, and tradition and innovation surround this National Historic Landmark. Built in the late 1880s, the Carrie Furnaces produced iron for the Homestead Works steel operation (after 1898), which was owned by Andrew Carnegie, and then US Steel (Henry Clay Frick). Iron flowed from its seven cupola furnaces for close to 100 years. Furnaces 6 and 7 are the only ones that still remain on the site. During the 1920s, ’30s, and ’40s, Carrie 6 and 7 consumed approximately four tons of raw iron ore, coke, and limestone for every ton of iron produced. The cooling system for the blast furnace required more than 5,000,000 gallons of water a day, all supplied by the Monongahela River. The furnaces reached their peak production in the 1950s and ’60s, when they were producing 1,000–1,250 tons of iron a day. It was here, just outside Pittsburgh, that steel became synonymous with American progress and industrial revolution. This is the birthplace of American big steel. From these furnaces flowed the molten alloy that was formed into many monumental icons of the American built environment, including the Empire State Building, the Golden Gate Bridge, and the Brooklyn Bridge.\nUS Steel ceased operations at the Carrie Furnaces in 1984. When the site was sold to the Park Corporation in 1988, the company started to dismantle and salvage the steel structures and machinery. During that time, many local artists would jump the fence and explore the derelict site, including the locally famous Industrial Arts Cooperative (IAC), a rogue group of guerrilla artists led by sculptor Tim Kaulen. The group created monumental site-specific installations from materials found there and spent several seasons of dedicated effort creating the massive Carrie Deer that is still on the site today. Many sculptors and graffiti artists created passionate works among the rusting giants of the Carrie Furnaces.\nThe Steel Industry Heritage Task Force was also founded in 1988, the same year that the Park Corporation bought the Carrie Furnaces. In 1991, the organization morphed into the Rivers of Steel Heritage Corporation (RSHC). A visionary nonprofit, the RSHC was formed through a collaborative effort between the National Parks Service and the Pennsylvania County and State Departments of Conservation and Recreation with the intention to secure the Carrie Furnaces site. The RSHC now owns and stewards many sites of cultural importance in the Pittsburgh region, repurposing and preserving them for future generations. Its mission includes historic preservation, cultural conservation, education, recreation, and resource development. Through the tireless efforts of the RSHC and its main historian and hyper-passionate site manager, Ron Baraff, the Carrie Furnaces now offers a dynamic platform for the arts. Baraff and the RSHC have approached the site in an extremely open manner. Realizing that the site had more potential than just a monument to the region’s past and that it could be accessed through multiple forms of interpretation, they welcomed art as a catalyst.\nAnyone who has a foundry practice or understands the steel and iron heritage of the area will marvel at the majestic array of buildings and cupolas that make up this unique campus. In the mid-2000s, local sculptor Ed Parrish Jr. started running iron pours at the Carrie Furnaces as part of his Hot Metal Happenings (funded by the Sprout Fund), whose purpose was to share with the regional community the fact that iron casting in Pittsburgh is still happening (at a smaller scale)—this time, for making contemporary art.\nIn 2013, two art professors from Indiana University of Pennsylvania (IUP)—Chris McGinnis, a curator, and fellow colleague/ sculptor Sean Derry—formed Alloy PGH. Artists accepted to this biennial residency, education, and exhibition program receive the opportunity to respond to the Carrie Furnaces site. Funded by local arts organizations such as the Sprout Fund, IUP’s Kipp Gallery, and Radiant Hall Studios, Alloy PGH has brought in artists, historians, ecologists, and curators to help the artists-in-residence learn more about what it means to work contextually. Luminaries such as Ann Hamilton and Mary Jane Jacob helped younger artists, including Ricardo Robinson, Oreen Cohen, Carl Bajandas, Ryan Keen, and Edith Abeyta, to create fantastic installations on site during the 2015 program. McGinnis and Derry had the vision and the drive to bring artists to this dynamic location to demonstrate how the visual and performing arts can transform neglected sites into gathering places. The 2013 and 2015 iterations of the program have been extremely successful, establishing the model as a regional gem of an art exhibition that challenges visitors to experience the Carrie Furnaces in a whole new way.\nAt the same time that iron casting events and Alloy PGH were beginning to take shape at Carrie, landscape ethicist and photographer Rick Darke had been documenting the site’s ecological fabric. Darke’s passion for place and the site led him, in consultation with the RSHC and Baraff, to invite the Penn State Master Gardener Program of Allegheny County to develop a comprehensive plant survey in and around Carrie.\nIn 2014, the Master Gardeners—led by Susan Marquesen, Joanne van Linden, Addy Smith-Reiman, and Anna Johnson—put together a team of artists, ecologists, historians, and students to develop a multi-disciplinary approach to interpreting the native and invasive plant species that are surviving, and even thriving, in the disturbed soils of the Carrie Furnaces site. As part of their research, they addressed best practices in environmental stewardship and responded to the site itself with the Iron Garden Walk, which is open to the public and features a series of 10 interpretive iron plaques. First, the Master Gardeners consolidated their research to develop the content, which includes botanical illustrations from the Hunt Institute of Botanical Documentation at Carnegie Mellon and descriptions of the various plants growing around the foundry, and Smith-Reiman created the layout of the plaque designs. The designs were translated and milled in high-density urethane (HDU) on the CNC in the Carnegie Mellon Sculpture Department by art student Lauren Valley. The patterns were molded by myself and Ed Parrish Jr. and cast on site with the Master Gardeners, CMU students, a large contingent of local artists, and Casey Westbrook of Carbon Arts. After the pour, the plaques were installed for future generations of visitors to discover through the seasons.\nThe Iron Garden Walk is a perfect example of collaboration between multiple organizations, using art and cast iron to bring people with related ideas together. The Master Gardeners, with the help of historians and artists, were able to realize their concept of how the site might be seen. By supporting projects like the Iron Garden Walk and Alloy PGH, the Rivers of Steel Heritage Corporation has been forward-thinking in its approach to how this site can benefit from its context, heritage, and public engagement.\nThe RSHC continues to diversify, bringing more artists to engage with the Carrie Furnaces. It recently unveiled a newly formed program, Rivers of Steel Arts (RoSA), headed by artist Chris McGinnis. Through RoSA’s multifaceted programing, the Carrie Furnaces is quickly becoming one of the region’s most exciting venues for the arts, education, and entertainment. RoSA has seen the benefits of multiple forms of community outreach and has teamed up with Parrish Jr. and Westbrook to develop Carbon Arts at Carrie, a metal arts program that will offer educational opportunities for mold-making, casting, and welding in the coming years. The groups are in the process of putting together infrastructure for a permanent foundry on the site, outfitted with a gantry, material storage, classrooms, and eventually multiple iron cupolas of various sizes. RoSA is dedicated to artistic programming that reimagines the future of familiar places, builds pride in community, and attracts renewed public interest in Pittsburgh’s Monongahela River Valley. It continues to evolve and hone its program offerings to attract new visitors from the local, regional, and global community to the site, while knowing the past and embracing the future. RoSA has already generated a substantial and eclectic program, including artist residencies, eco-arts, photo arts, urban arts (graffiti), film, dance, theater, festivals, and heritage arts consisting of a regional folklife center that represents eight counties in southwestern Pennsylvania.\nDuring the 26th annual International Sculpture Conference, conference-goers will have a chance to visit the Carrie Furnaces for panel discussions, cast iron workshops, tours of the Iron Garden Walk, and an exhibition of contemporary cast iron sculpture curated by Westbrook and Parrish Jr. For more on the arts at Carrie, visit http://rosarts.org.\nJoshua Reiman is an artist living in Portland, Maine, where he is also an assistant professor in the MFA in Studio Art + Sculpture programs at the Maine College of Art.\nWatch these videos on the Carrie Furnaces']	['<urn:uuid:6d9a76f3-2f22-47c0-aaa8-1bf244a04ac0>', '<urn:uuid:eef00725-c4d0-4ba0-8f28-fcef60e8f74c>']	factoid	direct	short-search-query	distant-from-document	multi-aspect	expert	2025-05-12T23:56:45.148498	5	63	2304
10	I'm researching digital cinema evolution - what's the key difference in resolution capabilities between the groundbreaking RED ONE camera from 2007 and Sony's new α1 for professional filmmaking?	The RED ONE was revolutionary as the first 4K-capable camera in 2007, while the Sony α1 can record at 8K (7680x4320) resolution, which is four times the resolution of 4K, representing a significant advancement in digital cinema technology over the past decades.	['Important Cameras of Cinematic History\nThese game-changing cameras changed the face of cinema, one frame at a time.\nAbove photo of cinematographer Robert Richardson from the set of ‘The Hateful Eight’\nAfter roughly a century of cinema, we’ve seen countless looks appear on screen as a result of countless camera variations, each with their own pros and cons. Among so many types of cameras throughout film history, few have stood out. With the transition from film to digital currently in its final stages, now is a good time to look back at some of the most iconic or game-changing cameras in movie history.\n1. Bell & Howell 2709 Standard 35MM\nIn the early 20th century, one of the biggest faults in camera technology was a lack of standardization. Manufacturers had yet to establish a universal film size that could be played back at any theater, but Bell & Howell changed this when they decided to only manufacture their various camera and projection technology according to a 35mm film width format. By standardizing their already popular equipment, they standardized the entire motion picture industry.\nImage via iCollector\nThe 2709 Standard 35mm was arguably their most historically significant model, as prior to its existence cameras were built with wood and leather. After filmmakers Martin and Osa Johnson lost their camera to termites and mildew in Africa, Bell & Howell released the first ever all metal movie camera, the 2709 Standard. By 1919, almost all Hollywood productions were using Bell & Howell equipment.\n2. Bolex H16\nWhile the Bolex H16 didn’t quite provide a level of image quality comparable to many on this list, it was nevertheless very important in film history. Bolex chose to take a step forward in the consumer industry by giving more people the opportunity to experiment with the medium.\nImage via LiveAuctioneers\nEventually one of the best-selling cameras of its time, this consumer-level 16mm camera was a choice tool for the young Steven Spielberg, and was a blessing for many other aspiring filmmakers that were looking for something reliable and versatile, yet still cinematic. Arguably the equivalent of the modern day DSLR, the H16 offered a stellar picture at a reasonable price.\n3. Super Panavision 70/Ultra Panavision 70 Systems\nThe Super Panavision 70 is among the more recognizable names on this list, having provided some of the definitive cinematic experiences in movie history. One of the quintessential 70mm systems, this spherical lens-based camera system brought you classics such as West Side Story, Lawrence of Arabia, and 2001: A Space Odyssey.\nImage via EOSHD\nBoasting a simply massive image size that still exceeds that of most digital movies today, the Super Panavision 70 brought forth a sense of true scope and wonder synonymous with films such as Kubrick’s 2001. This camera’s anamorphic counterpart, the Ultra Panavision 70, is similarly recognized, and actually saw a recent resurrection for Quentin Tarantino’s western, The Hateful Eight.\n4. Sony HDW-F900\nThe now industry-standard digital format is not as old as it may seem; at the turn of the century, the Sony HDW-F900 ushered in the digital era with the first (well known) all-digital production, Once Upon a Time in Mexico.\nImage via TheHDHouse\nGeorge Lucas worked with Sony to develop this camera for his upcoming Star Wars Episode II: Attack of the Clones, but first showed it to director Robert Rodriguez, who would become the first to utilize it. Offering a resolution of only 1920X1080 that had to be cropped down to 1920X817 for widescreen, this camera showed that digital had a long way to go before surpassing the quality that film offered. With that being said, it also showed that digital was at least potentially viable in the future.\n5. RED ONE\nIf the Sony HDW-F900 highlighted the weaknesses of digital filmmaking, the RED ONE highlighted its strengths. Oakley owner Jim Jannard founded RED Cinema in 2005, and completed the company’s first camera, the RED ONE, in 2007.\nImage via Vocas\nThe ONE was designed to revolutionize digital cinema, and did just that, as the first ever 4K-capable camera. Also offering high frame rates and surprisingly impressive low-light performance, the RED ONE made the digital platform seem a viable one for the first time. Since then, RED has excelled with many newer models that are constantly pushing the limits of what one can do on a budget.\nIMAX premiered to audiences is in the early 1970s, with a showing of Tiger Child in Osaka, Japan, and later, its first permanent installation in Toronto, Canada. Yielding an unforeseen film size three times larger than that of standard 70mm, IMAX is roughly the digital equivalent of a 12K image. Unfortunately, the size of the film stock limited the running time of an IMAX feature, and they are therefore mostly used to show documentaries in museums and the like.\nImage via MovieMail\nAs technology has progressed, a number of Hollywood productions have made it to IMAX screens, the first being Apollo 13. 6 years later, The Dark Knight was the first ever mainstream feature to actually shoot parts of the film with an IMAX camera. A handful of later films have used IMAX cameras, with The Dark Knight Rises holding a record of 72 minutes of IMAX footage. Star Wars: The Force Awakens is one of the more recent examples of brief IMAX use, featuring it during the Millennium Falcon chase scene on Jakku. The upcoming Avengers: Infinity War will be the first ever full-length feature shot entirely in IMAX.\n7. ARRI ALEXA\nThe ARRI ALEXA has become the final nail in the coffin for film. When ARRI, an established name and frontrunner of Hollywood film, made the transition to digital cinematography, it arguably marked the true start of the digital era. Up until 2010, digital movies were becoming increasingly prevalent, but still didn’t dominate all facets of the industry. Sony and RED were both excelling in digital cinema, but the ALEXA soon overcame them both to become by far the most common platform for digital shooting.\nImage via NoFilmSchool\nThe ALEXA took digital to the point of exceeding most of the capabilities of film, even convincing acclaimed cinematographer and film lover Roger Deakins to make the switch and declare digital the future. With the stunning possibilities that the new ALEXA 65 showcased in The Revenant, it’s now more clear than ever that times are changing.\nThe history of film has seen so many variations of camera technology that have almost all contributed something to the industry, but these cameras were able to stand out with true innovation that impacted cinema forever.\nWhat camera technology has furthered your own creativity? Let us know in the comments below.', 'α1 with superb resolution and speed\nThe α1 offers an extraordinary combination of high resolution and blazing speed. Ultra-fast readout from the 50.1 MP sensor allows continuous bursts at up to 30 fps with AF and AE tracking using the electronic shutter. Perfect for sports or any situation where the critical action is over in an instant.\nThe new 50.1 MP Exmor RS CMOS sensor delivers high resolution and sensitivity with low noise, plus up to 15 stops of dynamic range. A new image processing engine achieves even better colour accuracy than previous models.\nDespite the sensor’s high pixel count, a sensitive back-illuminated structure with gapless on-chip lenses and an AR coated seal glass allows a standard ISO range of ISO100~32000, expandable to ISO50~102400.\nUp to 16 images shot with precise in-body image stabilization control can be combined via computer software to create photos with up to 199 million pixels for extraordinary resolution, colour, and atmosphere.\n Normal Shooting  16-image Pixel Shift Multi Shooting\nHigh-level subject recognition technology now makes it possible for Sony’s Real-time Eye AF function to track and accurately focus on bird eyes, even if the bird suddenly takes flight or the framing changes. This innovative function easily meets the many challenges of bird photography.\nThe new image sensor and BIONZ XR engine in the α1 deliver 8K(7680×4320) 30p movie recording capability for extraordinary realism. Four times the resolution of 4K with full Real-time Tracking and Real-time Eye AF functionality. 8K footage is also ideally suited to flexible 4K editing.\nThe α1 supports high frame rate internal 4K movie recording at up to 120 fps, for smooth, expressive slow-motion playback at up to 5x. 10-bit 4:2:2 chroma subsampling can be used with Long-GOP or Intra (All-I) compression for outstanding image quality, while the new image sensor and BIONZ XR engine minimize image distortion.\nThe α1 includes the same S-Cinetone colour matrix that produces beautiful colour and skin tones in the FX9, FX6, and other Cinema Line cameras. S-Cinetone delivers natural mid-tones that are essential to healthy-looking skin colour, plus soft colours and gorgeous highlights, responding to a growing need for more expressive depth.\nThe 9.44 million-dot (approx.) OLED viewfinder in the α1 offers the highest resolution in the industry at this time. It features 0.90x magnification with a 41° FOV for a clear, wide view, and an updated structure that results in a 25mm high eyepoint. A 240fps refresh rate with UXGA FOV is another world first, for a clear view of fast action.\nBuilt-in wireless LAN allows communication on the 2.4 GHz and 5 GHz bands, the latter with 2x2 MIMO support (IEEE 802.11a/b/g/n/ac). Dual antennas ensure reliable communication.\nA USB Type-C® connector that supports fast USB 3.2 SuperSpeed USB 10Gbps data transfer makes fast PC Remote (tethered) data transfer available for smooth handling of large files.\nA built-in connector for wired 1000BASE-T connection enables fast, stable data transfers at gigabit speeds. FTPS is supported, allowing SSL or TLS encryption for greater security.\nElevate your photography with Imaging Edge desktop applications. Use “Remote” to control and monitor shooting live on your PC screen; “Viewer” to quickly preview, rate, and select photos from large image libraries; and “Edit” to develop RAW data into high-quality photos for delivery.\nThe Imaging Edge Webcam application makes it easy to use your Sony camera as a high-quality webcam, with wide compatibility, for impressive live streaming and conferencing.\nSpecifications & Features\n- Sensor Type\n- 35mm full frame (35.9 x 24.0mm), Exmor RS CMOS sensor\n- Number Of Pixels (Effective)\n- Approx. 50.1 megapixels\n- ISO Sensitivity (Recommended Exposure Index)\n- Still images: ISO 100-32000 (ISO numbers up from ISO 50 to ISO 102400 can be set as expanded ISO range.), AUTO (ISO 100-12800, selectable lower limit and upper limit), Movies: ISO 100-32000 equivalent, AUTO (ISO 100-12800, selectable lower limit and upper limit)\n- Battery Life (Still Images)\n- Approx. 430 shots (Viewfinder) / approx. 530 shots (LCD monitor) (CIPA standard)\n- Viewfinder Type\n- 1.6 cm (0.64 type) electronic viewfinder (color)\n- Monitor Type\n- 7.5cm (3.0-type) type TFT']	['<urn:uuid:e9c03e41-7926-4a1f-b133-4e912c4172f0>', '<urn:uuid:7d8b86c1-4d24-4905-8c49-a8e1792025df>']	factoid	with-premise	verbose-and-natural	similar-to-document	comparison	expert	2025-05-12T23:56:45.148498	28	42	1789
11	dangerous conditions monterey pebble beach diving	At Stillwater Cove in Pebble Beach, divers should be cautious of thick kelp and boat traffic. However, the site is one of the most protected in the Monterey/Carmel area, with predictably very calm conditions due to its location in the lee of Pescadero Point. When prevailing northwesterly winds blow, this is one of the calmest spots around, living up to its name with placid waters.	['All times are for SHOW times, to assess conditions – divers must be geared up for the mandatory briefing 30 minute later.\nPlease RSVP for dives to dive coordinator or on MBSO Facebook page!!\nSkill level: Beginner or better\nLocation: Along the 17-mile drive in Pebble Beach.\nAccess: By boat from Monterey or via the beach near the Pebble Beach Clubhouse.\nFacilities: Public parking toilets, boat and kayak launching at the clubhouse.\nEntry and Exit: Best to dive from a boat or kayak.\nDepth range: 10 to 50 feet\nConditions: Predictably very calm\nVisibility: 10 to 30 feet\nPhotography: Good macro photography for nudibranchs and other small invertebrates. Also good for fish portraits.\nHunting: Stillwater Cove is within the Carmel Bay State Marine Conservation Area where only finfish may be taken.\nCautions: Watch for thick kelp and boat traffic.\nOne of Monterey’s charter boat captains kept a record of his customers’ favorite dive sites. Each year the site that received the greatest number of votes was, not surprisingly, Stillwater Cove. This is one of the most protected sites in the Monterey/Carmel area and has a lot of marine life to please the most discriminating diver.\nStillwater Cove lies on the north side of Carmel Bay, and the cove is in the lee of Pescadero Point. When the prevailing northwesterly winds blow this is one of the calmest spots around, and the predictably placid waters rightfully give this site its name. Much of the cove bottom is sand, sprinkled with a rocky patch reef. In the center of the cove are the massive Pescadero Rocks. The best diving is on the south side of the rocks and on the massive wall just south of the rocks.\nAbout 100 feet from Pescadero rocks the bottom drops from 30 to 50 feet in a massive wall that runs nearly 100 yards; many call this Dali’s Wall. Much of the wall looks like it was once vertical and flat, and then someone with a massive ice cream scoop carved out short caves, undercuts, and shallow depressions. It’s more like diving underneath a wall than alongside one. The rock surfaces are adorned with encrusting sponges in hues of cobalt red and yellow. On the west side of the wall is a float that marks the location of an underwater statue.\nThe nooks and crannies of the wall harbor an assortment of photogenic invertebrates and fishes. It is a good idea to carry a flashlight so you can see what is hiding deep in the cracks. Look for small sculpins, gobies and rockfish underneath the ledges. This cove is heavily fished, so you won’t see many large game fish; but it is a great place to find and photograph juvenile rockfish, cabezon and lingcod. A large wolf eel is often found in one of the larger cracks. Just look for a pile of empty shells, and follow the trail up to find the wolf eel’s den.\nBlue-ring top snails and orange cup corals are easy to find due to their bright colors. However, you should take your time swimming along the wall as some of the more beautiful critters are well camouflaged and would prefer not to be seen. Look for decorator crabs, as well as mollusks whose shells are covered with bryozoans or anemones. Chestnut cowries are commonly found here, and have beautiful mantles.\nThe shallow area around Pescadero Rocks is covered with intensely colorful marine life – carpets of red, strawberry anemones, giant green and blood red fish-eating anemones, as well as yellow and cobalt sponges. Here live an abundance of hermit and decorator crabs and shrimp.\nThis area is also a great place to observe and photograph nudibranchs. The simple dorids such as the lemon and Monterey nudibranch are here in abundance. Photos of orange and white clown nudibranchs, gaudy red and white Hilton’s and ostentatious Dendronotids will wow your friends. These creatures are intrinsically photogenic, but it is a real treat to find them in colorful backgrounds, or doing nudibranch things — like feeding or mating. There are also “near nudibranchs,” like the berthella. These do not have exposed gills and are therefore not nudibranchs.\nMany dive Stillwater Cove from one of Monterey’s charter boats, and small inflatable boats and dive kayaks may be launched from the pier or beach. Diving from the beach is limited to 10 divers per day, and there is public parking along the hedges by 17th fairway. There are six parking spots for beach access that may be reserved up to 14 days in advance. There is a loading/unloading area, but incoming traffic may be limited 11 a.m. and 2 a.m. at the discretion of the harbormaster. A pier and boat hoist is available for recreational craft, from May 1 through September 30, with a limit of 10 boats per day. Diving, sunbathing, and picnicking are permitted during daylight hours only, and only on the beach east of the pier. Call (831) 625-8507 and ask for the Harbor Master for reservations and additional information. You will need to pay for access to the 17-Mile Drive.']	['<urn:uuid:bde23fce-7d87-43b3-bed3-e8b3ba2ddd2e>']	open-ended	with-premise	short-search-query	distant-from-document	single-doc	expert	2025-05-12T23:56:45.148498	6	65	848
12	best ways prevent bee swarm success rate	The most effective ways to prevent bee swarming include using first-year queens (especially spring-reared ones), breeding from non-swarming strains of bees, and providing adequate space through early super installation and brood box reversal. However, no method is 100% effective - even with good management, well-bred bees typically have a 10-15% swarming rate, though this can vary significantly depending on the season and bee strain.	['If you purchase an independently reviewed item through our site, we earn an affiliate commission. Read our affiliate disclosure.\nBeekeepers clip the wings of honeybee queens to prevent swarming. The effectiveness of this practice is in the balance. Research has found out that clipping may not increase queen supercedure. It also has very little impact on honey production. At the same time, clipping the queen bee’s wings has been observed to lead to supercedure. Some colonies see the queen with clipped wings as unhealthy and replace her. This article takes you through clipping honeybee wings and why it is done. It also looks at arguments both for and against the practice.\nHoneybees that have decided to swarm keep trying to do it. Beekeepers try to manage the situation by taking measures to prevent swarming. Finding honeybees clumped on the ground near a beehive alerts you to the swarming and you can take preventive measures.\n- A popular method of preventing swarming is the checkerboarding of drawn frames and empty frames. Honeybees swarm when they are many in the colony and have ample resources. Leaving too much honey in the beehive and having all frames drawn with comb are strong triggers for swarming. A honeybee colony that has empty places to fill with resources does not swarm easily.\n- Where the beekeeper wants, swarming can also be managed by splitting the hive. A new queen can be produced in a current hive. You can also bring in a queen from elsewhere and install her in a split hive. You may then keep the new colony or sell it off to a beekeeper starting a new beehive.\nSigns of Honeybees Swarming\nBefore honeybees split and for a swarm to start a new colony, they make some preparations. You might notice some of the preparations during a hive inspection. You may also be lucky to catch bees from your beehive swarming to a nearby location such as a tree’s branch. They can then be removed and put into a new hive or returned to the old one.\nPresence of honeybee queen cells in the brood area or under other frames is the surest sign a colony is preparing for swarming. The cells are easy to identify by their unusually large size. The appearance of these cells means a new queen bee is being reared. She may be to replace an old and failing honeybee queen or to form a swarm. When a new queen is raised for the beehive, the old queen dies soon after or is removed by balling.\nWhy Do We Clip the Queen’s Wings?\nClipping of honeybee wings is done only on queen bees. There is no need to clip the wings on any other types of bee in a hive. It is part of hive management done by the beekeeper.\n- Clipping honeybee wings of the queen honeybee is often aimed at preventing swarming. Without her wings, the queen bee cannot fly away from the beehive and take the colony with her.\n- The other reason you can clip a queen bee’s wings is for easy identification. With clipped wings, the queen bee is easy to identify from among other honeybees. The shorter wings make her stand out. A particular style of clipping can be applied to help differentiate queens. The clipping style is coded so the beekeeper can easily recall different queen bee details. Beekeepers may also choose to mark queen bees on the thorax using some dye in place of clipping her wings. A color code is used to denote the year the queen bee was introduced in the beehive.\nHow to Clip a Honeybee Queen Wings\nYou should be well prepared for clipping a queen bee’s wings. A pair of scissors to do the cutting should be brought to the beehive. A smoker for bee management should be with you during queen finding and clipping. You may use alternative honeybee calming techniques. A bee brush is also handy to help you remove bees from surfaces if necessary.\nTo clip the wings of the queen bee, you must find her from among the bees. This is easy if she is marked. If she is not, finding her can be difficult. Experienced beekeepers can find the queen by looking for her in places she is likely to be hiding. The queen does not like exposure to light and runs from it. She is also likely to be found in the brood area of the beehive. Beginner beekeepers can read on below to learn how to identify the honeybee queen.\nOnce identified, pick the queen bee by her wings to avoid hurting her. Cut some section of the wings off with the scissors. The cut should remove about 2/3 of her wings. Cutting more of the wings off is not advisable. It may make bees in the colony see the queen as unhealthy. They then swarm or raise a new queen.\nYour safety during clipping of the queen bee wings is important. Take safety measures and wear a beekeeping suit when working with bees. The queen bee should not be held with bare hands. She carries a barbless stinger that can be used repeatedly. When handling the queen bee, she may want to sting you.\nThere are various products manufactured for clipping the wings of a honeybee queen. They include arresting equipment to hold the queen bee in position for clipping. There are also cutting tools for clipping the wings with. Using such equipment makes the job easier and faster. It also minimizes contact with the queen bee. The beekeeper is less likely to be stung by the honeybee queen. This equipment gives great results since it is standardized. Both beginner beekeepers and experienced ones can use these equipment with ease.\nIs it Good to Clip the Wing of a Queen Bee?\nSwarming is a natural process for honeybees. It is how they start new colonies. However, this event is sometimes not a happy one for beekeepers, as the honeybee population in the beehive falls due to swarming. It can have an impact on yields of beehive products when the colony left behind is not strong enough. Some beekeepers allow swarming while others take steps to manage or prevent it. It is up to individual beekeepers to decide what to do when they notice signs of swarming.\nThere are beekeepers that do not clip the wings of queen bees. Various reasons are cited for this.\n- One popular reason is that the queen bee is seen as deformed and has a new queen raised. Other times, it leaves the queen bee unable to use her wings for balancing and breaking falls. This can be fatal for her. When it impedes her ability to accurately position eggs in cells, she it superseded.\n- Clipping the wings is also argued to be bad for genetic diversity among bees. Swarming bees start new colonies and contribute to the genetic pool of honeybees available in an area.\n- Clipping the queen bee’s wings may affect her health. Pressed abdomens, nicked feet and veins in the wings often lead to loss of vitality for queen bees. Bacteria may take hold in the haemolymph of the queen and lead to her death soon after being clipped.\nHow to Find the Honeybee Queen\nLooking for the honeybee queen for clipping her wings can be difficult. Here is how you can go about finding the queen with ease. The procedure and tips are helpful for when you are finding her for other hive management purposes as well. It is easy to find the queen bee from among a small colony of honeybees. With larger colonies, it takes a little more time. The queen bee often runs to hide on the floor of the beehive and sidewalls.\nAdopt a standard operating procedure for finding the queen. It can be included among other hive management activities. Make it a practice to try and spot the queen every time you are carrying out a beehive inspection. With regular practice, you can get very good at it.\nWhen looking for the queen for clipping of wings, be ready to catch the queen bee the first time you will spot her. For a search for the queen bee, frames of honeycomb and even undrawn frames are removed from beehive boxes. This is done procedurally so that all frames are inspected. During the inspection, look for eggs laid in brood frames. They can give you a rough idea of where the queen bee might be in the beehive. Freshly laid eggs means that you should look for the queen bee around that area.\nSome honey bee species have a frame of pollen at the edge of the brood area. On both sides of a brood box, you should not reach the last frames of pollen before finding the queen. Usually, she is to be found in the brood area. If you reach the frame of pollen on the last box, you should restart and intensify your search for the honeybee queen.\nGo looking for the queen bee when there are not many bees in the hive. Late mornings and late afternoons are great times. A lot of the foraging worker bees in the hive are out of the beehive at these times. You have fewer bees to manage. There are also not many bees to block the queen bee from view. Looking for the queen bee in a beehive full of bees can be frustrating when they are moving all about.\nBeehive frames on which honeycomb has not been fully drawn presents a challenge when finding the queen. The honeybee queen finds it easy to move from one face of the comb to the other. She passes through the gap presented by an area where there is no comb on the frame. Be on the lookout for this. You might even spot the queen running from one face to the next when your turn one face to the light.\nQueen bees can be differently colored from other bees. Regular spotting of the queen bee helps you memorize even small differences in color between the worker bees of the beehive and the queen bee. When you need to catch her for clipping, this knowledge is very useful. You will be able to quickly find the honeybee queen and carry out the activity you need to. Honeybees have different coloration based on the sub-species and breeding over time. Russian, European, Italian and African bees all have subtle differences in coloration. In a beehive, the queen bee is usually of a lighter hue than the worker bees.\nIn your search for the queen bee, look for her in concentric circles. Any other grid-based pattern of inspecting the beehive surfaces can also be applied. It is advised that you hold a frame under inspection over the brood area. If the queen falls off a frame, she falls into the brood nest of the beehive. For best results, the frame is held by its lugs and first scanned along its perimeter. The scan then moves inward in a spiral until it ends at the center of the frame. The frame is then turned and the process repeated.\nThis standard procedure of finding the queen bee works in nearly all scenarios. When followed well and diligently, the queen bee is fund by both experienced and beginner beekeepers. Hiding queen bees are usually found in various depressions and crevices on comb and in the beehive. If you cannot find the queen bee, just go over the beehive following the process once more.\nA Final Word\nBeekeepers want to prevent swarming because it reduces the working population of bees in a honeybee colony. A hive that swarms more than once can be left with few bees and impact production. Clipping the wings of the queen bee prevents the queen bee from being able to fly away with a swarm of bees. Once you have noted the colony wants to swarm, you can take measures to prevent swarming. These include and are not limited to checkerboarding and making voluntary splits of the honeybee colony.\nWhat are your thoughts on the practice of clipping the honeybee queen’s wings? Leave a comment below and let us know.', 'How to prevent swarming?\nI previously wrote about some potential factors involved in the swarming of honey bees and why swarm prevention and control are so important for the beekeeper. The idea that we can prevent swarms is probably misguided; it is after all what bees are programmed to do, it is how they reproduce, but we must nevertheless educate ourselves and do what little we can in this regard.\nThe people who are most qualified to advise on swarming, or any other honey bee management topic, are the commercial honey farmers who manage thousands of colonies and rely upon their efforts to earn their living from it. This is why I will be quoting from such people extensively here – they have lived and breathed a life with bees and I would rather take heed of their words than those of a keen hobbyist or a well read scholar.\n“If I were to meet a man perfect in the entire science and art of bee-keeping, and were allowed from him an answer to just one question, I would ask for the best and easiest way to prevent swarming.” C.C.Miller, 50 years among the bees\nI referred in my last post to a study in New Zealand by I.W. Forster which concluded:\n“Four methods of hive manipulation commonly used for swarm prevention failed to reduce its incidence. Colonies with first-year spring-reared queens made no attempt to swarm. The incidence of swarm preparation was less for colonies with first-year autumn-raised queens than for those with second-year queens.”\nI have read of beekeepers who have older queens and no swarming issues, but I think that is the exception rather than the rule. We know that there is a strong genetic factor associated with the propensity to swarm so these older “non-swarmy” queens are little treasures to breed from, I would suggest, assuming they have healthy and productive colonies.\nMy favourite beekeeping writer is R.O.B Manley, who was the first person in England to manage 1,000 colonies, and my favourite book of his is “Honey Farming” published in 1946. I know that things have changed since then, particularly the arrival of oilseed rape and varroa mites, but honey bees are still honey bees, and swarming still happens. Here is something to ponder from that wonderful book:\n“I have no doubt myself that the best hope of reducing the incidence of swarming lies in breeding from non-swarming strains, strains that is, that show much less addiction to swarming than is the case with the average colonies. I believe that if we systematically breed from queens and drones of strains that have swarmed little, and have produced much honey, and have not suffered from disease, we shall in that way lay the foundation of successful honey production.”\n“…after a time, unless we are careful how we breed our stock, strains are liable to arise that have the swarming tendency too highly developed, especially as we ourselves have a propensity to breed for profligacy, sometimes without paying enough regard to other traits, and that is why I, basing my opinion upon personal observation of many thousands of colonies, have come to the conclusion that the character of the bees themselves is the most important of all stimuli that set in motion the swarming instinct.”\nPerhaps, then, it is no coincidence that successful honey farmers tend to have their own successful queen rearing operations.\nMore sage words from Manley on the inevitability of swarming in some circumstances:\n“If you want to get your living from honey production you will be wise to ignore the theories of those who say bees ought not to swarm; that they will not swarm if properly managed etc. The reality, well known to every bee farmer in the world, is that they often will. We can never in any circumstances, under any management, in any climate, at any time during what we call the swarming season, rely upon absence of swarming in any strong healthy stock that has not already swarmed. With well bred bees we may expect that the incidence of swarming will not be much greater in most seasons than 10% – 15%, but in some years no method of management whatever will prevent swarming from being more prevalent than that, no matter what the strain of bees. On the other hand, in some seasons swarming will be almost absent, even if the bees are of a “swarmy” breed, and in spite of bad management.”\nI’ve got to admit, if swarming in my colonies was down around the 10% – 15% mark then I’d be very satisfied, and would surely have plenty of honey to show for it. I re-queened many of my colonies last August with stock bought from Ged Marshall and Peter Little so I am hoping that these undoubtedly superior genes will help me out in the season to come. For the hobby beekeeper there is certainly merit in breeding from your best queens, for it can only improve your stock, but somebody with hundreds or thousands of potential breeders to choose from will always be ahead, so my strategy is to buy in good queens then breed from the best of them, and perhaps buy in some more every few years just to keep the quality up. This all assumes that you can find a source of good quality queens. I hope to be able to get hold of some of Jolanta’s queens in future to see how Murray McGregor’s bees do in my rainy corner of England.\nGenetics and queen age aside, the other strategies used by commercial beekeepers to try to prevent swarming mainly involve providing enough space for the queen to lay eggs and for workers to store incoming nectar.\nWhen I asked Mike Palmer about what he does he said this:\n“…we put the supers on early to get the tree bloom and the dandelion bloom, and that acts like a reversing, so the bees can move up onto empty comb. If the queen feels she wants to move up and lay in the supers, so what? I don’t use excluders.\nI think queen excluders select for the least prolific queens because prolific queens will swarm with an excluder unless you do something to that colony like split it or take brood away. So they move up and by the end of the dandelion you have honey at the top in the supers, then the brood cluster and then empty space in the bottom box, so now it’s time to reverse the brood boxes to put the empty space above the brood. At that time, if they’ve been working well, we can put another one or two supers on. Once the bees are making honey and they have space to store it, it seems to take care of the swarming impulse, and they just get on with making honey.”\nMike has his bees coming out of Winter on double brood boxes and he puts supers on early to catch the Spring blossom flows and dandelion, then reverses the brood boxes after that and adds more supers as needed.\nHow can you tell when inspecting a hive that swarm preparations are underway? Back to Manley:\n“If you find your bees are building out foundation it is hardly necessary to trouble further, so far as possible queen cells are concerned. If the queen is spreading out onto new comb and covering it with eggs as fast as the workers build it out (laying out, we call it) there will rarely be queen cells. If the queen is very swollen and heavy with eggs, it is very unlikely that cells are present, at any rate cells with larvae in them, though there may be cells with eggs.\nIf foundation is not being drawn and the brood nest does not appear to be expanding, look carefully over most of the brood combs, for you are likely to find queen cells. The same if the queen is looking light and if she is slackening off in her laying.”\nI am flying off to New Zealand tomorrow, although I don’t actually land in Christchurch until Wednesday morning. It is Summer there and the swarm season may well be over, but I’ll certainly be asking commercial beekeepers about what they do. Springtime here in the UK seems a long way off but it is wise to use this downtime to reflect on seasons past and plan for the one ahead. Dealing with swarming must surely be one of the prime considerations of beekeepers, wherever they are on this beautiful planet of ours.']	['<urn:uuid:556da120-7472-4351-9106-d0108082a5c2>', '<urn:uuid:526515ec-8275-43f3-9e8c-91cbd5d2fdc6>']	factoid	direct	short-search-query	distant-from-document	three-doc	novice	2025-05-12T23:56:45.148498	7	64	3476
13	I'm interested in winemaking and I've heard about different ways to measure grape ripeness - could you explain what the Oechsle scale is and how it works?	The Oechsle scale is a hydrometer scale that measures the density of grape must to indicate grape ripeness and sugar content. One degree Oechsle (°Oe) equals one gram of difference between the mass of one liter of must at 20°C and 1 kg of water. For example, must with a specific mass of 1084 grams per liter has 84° Oe. The scale is widely used in German, Swiss, and Luxembourgish wine-making industries. In the vineyard, measurements are usually taken using a refractometer by crushing a few grapes and letting the must drip onto the glass prism, which measures the refractive index and translates it into Oechsle degrees.	"[""The Oechsle Scale is a hydrometer scale measuring the density of grape must, which is an indication of grape ripeness and sugar content used in wine-making. It is named for Ferdinand Oechsle (1774-1852) and it is widely used in the German, Swiss and Luxembourgish wine-making industries. On the Oechsle scale, one degree Oechsle (° Oe) corresponds to one gram of the difference between the mass of one litre of must at 20 °C and 1 kg (the mass of 1 litre of water). For example, must with a specific mass of 1084 grams per litre has 84° Oe.\nThe mass difference between equivalent volumes of must and water is almost entirely due to the dissolved sugar in the must. Since the alcohol in wine is produced by fermentation of the sugar, the Oechsle scale is used to predict the maximal possible alcohol content of the finished wine. This measure is commonly used to select when to harvest grapes. In the vineyard, the must density is usually measured by using a refractometer by crushing a few grapes between the fingers and letting the must drip onto the glass prism of the refractometer. In countries using the Oechsle scale, the refractometer will be calibrated in Oechsle degrees, but this is an indirect reading, as the refractometer actually measures the refractive index of the grape must, and translates it into Oechsle or different wine must scales, based on their correlation to refractive index.\nThe Oechsle scale forms the basis of most of the German wine classification. In the highest quality category, Prädikatswein (formerly known as Qualitätswein mit Prädikat, QmP), the wine is assigned a Prädikat based on the Oechsle reading of the must. The regulations set out minimum Oechsle readings for each Prädikat, which depend on wine-growing regions and grape variety:\n- Kabinett - 67-82 °Oe\n- Spätlese - 76-90 °Oe\n- Auslese - 83-100 °Oe\n- Beerenauslese and Eiswein - 110-128° Oe (Eiswein is made by late harvesting grapes after they have frozen on the vine and not necessarily affected by noble rot, botrytis, which is the case with Beerenauslese)\n- Trockenbeerenauslese - 150-154 °Oe (affected by botrytis)\nThe sugar content indicated by the Oechsle scale only refers to the unfermented grape must, never to the finished wine.\nIn Austria the Klosterneuburger Mostwaage (KMW) scale is used. The scale is divided into Klosterneuburger Zuckergrade (°KMW), and very similar to the Oechsle scale (1° KMW =~ 5° Oe). However, the KMW measures the exact sugar content of the must.\nThe Baumé scale is occasionally used in France and by U.S. brewers, and in the New World the Brix scale is used to describe the readings of a refractometer when measuring the sugar content of a given sample.\nSince a refractometer actually measures the refractive index of the grape must, it can be translated to many different scales (both related and unrelated to wine) based on their correlation to refractive index. Thus, all of these methods are similar and the differences are more cultural than significant, but all are equally valid ways to measure the density of grape must and other sugar-based liquids.\nThe Normalizovaný Moštomer (°NM) measures kg of sugar in 100 l of must and is used in Czech Republic and Slovakia.\n- By a slight abuse of physical terminology one says in German that the Mostgewicht (must weight) is measured rather than the must's density.\n- Deutsches Weininstitut: Must weights, accessed on March 26, 2009\n- Since the exclusion of degree Baumé from legal units in France by Decree No. 61-501 of 3 May 1961 relating to units of measurement and control of measuring instruments, the French regulation refers to sugars content expressed in grams per litre.""]"	['<urn:uuid:b24c83bf-ef47-44ec-87d1-b545f2d582df>']	open-ended	with-premise	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-12T23:56:45.148498	27	107	616
14	I'm trying to improve my hotel's pricing strategy and wonder what kind of information I really need to look at. What data should I focus on to make better decisions about room rates?	For revenue management, the most valuable data includes clean historical information about occupancy, rates and revenue figures, including booking dates, rate codes, arrival dates, departure dates and revenue by day. Web shopping data showing how many travelers look at and book rooms at different price points can provide insights into demand and price sensitivity. Additionally, market-level data, particularly competitor rate information from multiple channels, is considered essential as it helps avoid significantly underselling or overpricing room inventory.	['The processing power embedded in today’s smartphones and tablets makes it possible to perform analytic tasks in the palm of your hand that only a few years ago would have required a desktop computer and server. The fact that many of the most sophisticated and powerful enterprise applications are now available anytime, anywhere works to the great advantage of hotel operators who, given the nature of their jobs, are almost always on the go.\nNot surprisingly, the new breed of hotel business intelligence tools are cloud-based, mobile-enabled and specifically designed to meet the needs of on-the-go hotel operators. The tools deliver deep insights, faster and in far more accessible ways than most people only a few years ago could have even imagined possible.\nThe tools can pull data from the property management system, central reservation system, point of sale system, CRM system, channel management system, and any other existing system. The tools can also extract data on-the-fly from spreadsheets and any number of other sources, including guest satisfaction survey repositories, call centers, social networking apps, and website, mobile and in-room chatbox and text-based device logs.\nBI means using interactive visualization tools to bring data to life in a dazzling array of color-coded charts, funnels, pies, spider webs and various other configurations as well as drill-down and data filtering features to navigate, manipulate and analyze the data.\nStill, it is important to remember that, initially and also on an ongoing basis, BI also means leveraging the right data. The value of the interactive visualizations, dashboards and reports is entirely contingent on the quality of the data from which they are generated.\nThe diversity, velocity and sheer volume of data in the hotel industry has increased by orders of magnitude in recent years. Hotel operators today have an embarrassment of riches when it comes to data. There is practically no end to the number of internal and external data sources at their disposal.\nMeeting their business intelligence needs means, as a first step, connecting to data, whatever its source and wherever it may reside. But the key is to do so selectively, based on business objectives, whether those objectives relate to streamlining hotel operations, improving revenue management or identifying emerging trends in guest behaviors or market activity.\nThe question is: What data is relevant what data is not relevant and should not be included? This ranks as one of the top challenges with business intelligence, according to hotel operators, as indicated in the chart below.\nIn terms of data requirements for revenue management, most people would agree that the volume and depth of clean historical data related to occupancy, rate and revenue figures, including booking dates, rate codes, arrival dates, departure dates and revenue by day, provides the strongest basis for predictive modeling and forecasting accuracy.\nFor a large property, the totality of the data set may include dozens of guest segments, a dozen or more room types, several years of historical booking and reservations data, and upwards of a dozen length-of-stay buckets.\nMultiple other data sources may also provide significant value. For example, web shopping data (the number of travelers looking at and booking rooms and at what price, as well as the percentage of visitors abandoning the hotel website) can provide insights into current and future room demand as well as price sensitivity.\nBecause travelers shop beyond hotel websites, there are insights to be gleaned from the travel distribution network, as well — although, according to research conducted for a recent Starfleet Research study in partnership with The Rainmaker Group, less than one-third (29 percent) of hotel operators are capturing and integrating data related to guest website search and shopping behavior.\nWhile more hotel operators are integrating customer lifetime value data into pricing and availability, modeling consumer behavior from click-stream data, and integrating loyalty and total property spend data, only 62 percent of hotel operators indicate that they are currently using spend data to determine the value of guests by segment. That percentage is bound to increase over time.\nMarket-level data, including publicly available competitor rate information gleaned from multiple channels, may also rank as a must-have data source. Most hotel operators agree it is necessary to closely monitor competitive activity in order to avoid significantly underselling or overpricing guest room inventory.\nFor sales and marketing data requirements, length and purpose of stay data as well as the history of individual guests’ on-property behavior, such as their food, drink or spa treatment preferences, may be valuable in determining what offers should be sent to them and the messaging around those offers. How the recipient responded to previous marketing campaigns and discounts can also help determine what, if any, future messages they should receive, through what channel(s), and whether the messages are likely to elicit a favorable response.\nHotel operators get excited about the ever-growing number of data sources, but, in the end, it is better to think of data in terms of “quality over quantity” rather than “the more the merrier.” Capturing and analyzing every last bit of data can be a recipe for disaster. At a certain point, more data can simply mean more noise and the exercise becomes one of diminishing returns. It is imperative hotel operators select data sources that will help with fast, accurate decision-making and avoid the temptation to capture and integrate every last piece of data available to them from every possible data source.']	['<urn:uuid:c0acd14a-1013-4e1c-a7f4-1cad929b47b1>']	open-ended	with-premise	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-12T23:56:45.148498	33	77	900
15	I work in manufacturing and want to understand lead times better - how do MRP systems and make-to-order production differ in how they handle production lead times?	MRP systems use fixed 'planned lead times' stored in a database that don't reflect reality, since they include estimates of waiting times that actually depend on changing resource workloads. In contrast, make-to-order production actively manages lead times by predicting workflow and bottleneck formations through finite capacity scheduling. This allows for dynamic adjustment of resource capacities (like overtime or extra shifts) to control production lead times based on actual conditions, rather than relying on static pre-stored values that may be outdated.	"['MRP - A Planning System?\nThe MRP (Material Requirements Planning) concept exists since the 60s of the last century. It is the basis for most software systems supporting production planning and control in industrial practice. Most of these so-called MRP systems provide good assistance for order processing, data handling and inventory book-keeping, but they do not support planning.\nA typical MRP system follows a successive planning concept, as depicted in the following figure.\nMaster Production Scheduling.\nBased on existing customer orders and a medium-term aggregate production plan Master Production Scheduling (MPS) prepares a short-term production plan for end or rather main products. The planning result is the Master Production Schedule, which is commonly referred to as the MPS.\nMaterial Requirements Planning.\nThe next step, Material Requirements Planning (MRP), uses the MPS as a starting point and computes derived demands for all components required for the production of the end products. The planning data used are the bill-of-materials structure (BOM structure, Gozinto structure), the current inventory status (including planned receipts) and planned lead times. Within this planning step lot sizes are computed under the assumption that infinite capacity is available. Result of these computations are planned production quantities per item and period.\n» See also: Material Requirements Planning computations\nCapacity Requirements Planning.\nNext, for each operation required to make the products the planned starting time and ending time are computed with the help of standard project planning algorithms, such as the Critical Path Method (CPM). Again, capacities of the resources are neglected (infinite loading). Following this planning step, the capacity requirements resulting from infinite loading are tabulated and graphed. Usually the comparison with the available capacities shows that the production plan developped so far is infeasible.\nThis is the point in time when adjustment of the production plan by the human planner comes into play. Usually based on experience, the planner tries to shift operations on the time axis in order to generate a feasible production schedule. If this is not possible due to conflicts between the resource requirements of different operations, the capacity is extended by overtime, if possible. In general, a human does not have the capability to solve this complicated combinatorial optimization problem, which is a variant of the so-called Resource-Constrained Project Planning Problem (RCPSP).\nIn the last planning, for the upcoming short-term planning horizon production oders are released and assigned to the resources. For each resource orders are scheduled with the help of simple priority rules.\nCritique of the MRP concept\nBasically, the MRP concept is nothing else than the automation of order processing procedures that in earlier days have been done manually. Planning methods that support decision making in the sense that a feasible production plan is developped are not applied. The MRP concept has been criticized by many scientists as well as practitioners in a large number of publications. Its flaws are system-immanent and cannot be deleted by modern data base methods, user interfaces and faster computers. The major flaws to be criticized are:\n|1.||The medium-term aggregated production planning which aims at the coordination of sales and operations planning is not supported. Usually the production plan is equated to the sales plan. With scarce resources, however, these both plans must differ.|\n|2.||The production lot sizes are computed for each item in isolation without consideration of the interdependencies between predecessor and successor items in a multi-level BOM structure. The competition of items for resources is neglected, which leads to infeasible production plans. In addition, the cost-related interdependencies between a parent item and its components are not considered. Whitin the MRP planning phase a successive planning of the items is performed (first requirements computation, then lot sizing), based on an ordering of the items according to their low level codes.|\n|3.||In the MRP phase and in the Capacity Requirements Planning phase so-called ""planned lead times"" are used. These are stored as a resource-independent characteristic of an item in the production data base and are often not changed for years. The planned lead time includes estimates of transportation times and of waiting time due to scarcety of production resources. However, it is obvious that the waiting time for a resource depends on the workload of the resource. As the workload and, consequently, the bottleneck status of a resource changes over time, it does not make sense to store the waiting time (as part of the planned lead time) in a data base. The lead times are a result of the planning and not a given.|\n|4.||All planning phase suffer from the severe flaw, that the scarce capacities of the resources are completely neglected in the planning. Only immediately before the start of the production operation on the job shop level the infeasibility of a production schedule is recognized. But at this point in time, it is too late. Delivery delays and superfluous inventory are the consequence.|\nNote: The above criticism stands in sharp contrast to the majority of advertisements and whitepapers to be found in the internet.', 'Capacity Planning in High-Mix, Low-Volume, Make-To-Order Production\nCapacity planning is a planning exercise for correctly determining in advance the required resource hours for meeting fluctuating demand. According to Wikipedia, capacity planning is the process of determining the production capacity needed by an organization to meet changing demands for its products. This process is usually needed for any production system that has to handle spikes in demand using limited resources. Capacity planning is a challenging task in any order-driven, high-variety production.\nThe nature of make-to-order production\nA make-to-order (MTO) production unit makes a product only after it receives a customer order for the product. Such type of production is necessary when products are to be made to specifications given by customers. Custom manufacturing also involves MTO production. A high-mix, low-volume (HMLV) production unit has the capability to make a large variety of products for meeting diverse needs of customers. For most products in such high-variety systems, usually order quantities are small and the system makes a product only after receiving a customer order for the product. This is because maintenance of final goods inventory (FGI) for every product is prohibitive physically and economically. For this reason, most high-mix, low-volume production units usually operate like MTO units. Nevertheless, they maintain FGI for a few products which customers frequently need.\nThe complexity of make-to-order production\nMost MTO production units are job shops which are small in size and revenue. They keep receiving a stream of diverse orders to make a variety of products using very limited resources. But, they receive orders without any predictability. Process and resource requirements for fulfilling an order are also unknown until the manufacturer receives the order and therefore, advance preparation for the order is not possible. Customers want deliveries of their products within stipulated lead times. The production system is often more complex than a simple production line that makes products one after another. Many job shops simultaneously make several diverse products using common resources.\nImpact on production lead times, throughput and customer satisfaction\nIn MTO production units, product mix keeps changing rapidly and consequently, the workload levels for resources will keep changing and bottlenecks also keep shifting over time. If we cannot enhance resource capacities at right times even temporarily, the changing and heterogeneous workload in the system will have major impact on production lead times of orders and factory throughput. Also bottlenecks will increase those lead times and adversely affect customer satisfaction. Enhancement of resource capacities at right times will be helpful to control production lead times, increase customer satisfaction and increase throughput.\nOptimal determination of resource capacity enhancements\nIn HMLV and MTO production, capacity planning is the determination of resource capacity enhancements at right times for this purpose. The enhancements include overtime for workers, running machines for more hours, outsourcing bottleneck operations, etc. But, managers usually decide resource capacity enhancement in real time for quick inventory reduction at bottlenecks. This is a real-time, reactive approach to controlling inventory and job lead times. Some instantaneous decisions may quickly reduce inventories in real time but their impact on the overall on-time delivery performance may not be significant in MTO systems. There is relatively less flexibility with instantaneous decisions for enhancing resource capacities based on the existing situation in production. Such decisions may even amount to firefighting. Advance planning for resource capacity enhancements at right times as required will be very effective. This is known as proactive capacity planning.\nShort-term capacity planning involves running machines for a few extra hours, providing overtime for workers or running production for extra shifts on some days. Capacity planning may also involve outsourcing some operations or even entire production of some selected products. On the other hand, long-term capacity planning is done by hiring workers, training workers for additional skills, adding more machines or running extra shifts on long term basis.\nThe purpose of capacity planning\n- Expedite some jobs without any significant adverse impact on completion times of other jobs\n- Reduce the risk of delays for orders\n- Shorten production lead times for some orders\n- Overcome the adverse impact of major interruptions on job completion times\n- Mitigate the adverse effect of shifting bottlenecks\n- Accept more orders\n- Accept a new order with shorter lead time stipulated by customer\n- Accept and manage a rush order without adverse impact on other orders.\nProactive capaicty planning is very useful to:\nIn job shops engaged in MTO production, optimal proactive capacity planning is to plan in advance for minimal increase in resource capacities for meeting the above mentioned objectives. This is a real challenge regularly faced by many job shops engaged in MTO production. Those shops cannot easily do it for high-variety production without rigorous calculations.\nFinite Capacity Scheduling for Prediction of Work Flow and Bottleneck Formations\nIn make-to-order production, there is neither a simple formula nor an easy method for such capacity planning. Moreover, there is no unambiguous definition of capacity in such production. In many industries, capacity planning is done in Excel using experience, commonsense and crude calculations. However, the result is unsatisfactory in some cases, particularly in MTO environment. Rough-cut capacity planning which converts a master production schedule into requirements for key resources is not effective for MTO production with limited resources because it may not be possible to increase capacity of some resources temporarily as much as required.\nFor MTO production, capacity planning will be effective and dependable when it is based on (1) reliable prediction of work flow and bottleneck formations and (2) fast, accurate and extensive what-if analysis of production with the help of work flow prediction. But, the prediction and what-if analysis are quite difficult due to rapidly changing product mix and rapidly changing loads of limited resources. This is where production scheduling methodology can provide a lot of help in capacity planning. Even discrete event Monte Carlo simulation of production helps with capacity planning.\nThe effectiveness of capacity planning in high-variety production increases with the efficiency of production scheduling. Truly powerful scheduling software based on finite capacity scheduling (FCS) logic help predict (1) bottleneck formations in HMLV environment and (2) progress and completion time of each order.\nWhat-If Analysis for Proactive Capacity Planning\nWith their predictive capability, finite capacity scheduling software support fast, accurate and extensive what-if analysis for optimal, proactive capacity planning. FCS-based capacity planning is done by what-if analysis of finite capacity production schedules with respect to changes in resource capacities. What-if analysis is usually done by FCS for changes like:\n- Addition of a new machine with specific functionality\n- Hiring a new worker with certain skills\n- A worker acquiring an additional skill\n- Running an extra shift for some period\n- Overtime for some workers\n- Removal of a machine from production\n- A machine in non-operating condition while waiting for repair\n- A worker of certain skills leaving the system\n- A worker becoming absent for one or more days.\nIn summary, managers can easily perform proactive capacity planning in make-to-order production by performing what-if analysis of finite capacity schedules with the help of FCS. Powerful, low-cost FCS software are now easily available for this purpose.\nAdvantages of Capacity Planning:\n- Reduction in rejection of orders due to capacity concerns\n- Reduction of anxiety to meet due dates\n- Increased revenue due to acceptance of more demand and efficient management of demand spikes\n- Improved customer satisfaction with increase in on-time delivery and acceptance of rush orders without affecting other orders\n- Judicious and cost-effective investments on new resources for increasing production, revenue and profit.\nSoftware Tools for Capacity Planning in MTO Environment\nThere are some powerful, low-priced software tools for scheduling MTO production. These tools are also very useful for efficient capacity planning also. Unlike production scheduling, capacity planning does not demand job status updates from shop floor very regular because capacity planning is not required to be done as frequently as production scheduling. Some difficulties faced in using software for production scheduling disappear while doing the same for capacity planning. Production managers in some industries are using powerful scheduling tools exclusively for capacity planning and getting a lot of benefit from this exercise alone. Optisol software tools,Schedlyzer and Schedlyzer Lite are very appropriate for efficient, proactive capacity planning in a wide range of job shops engaged in MTO production. Both of them all support fast, accurate and extensive what-if analysis as part of proactive capacity planning in make-to-order production.']"	['<urn:uuid:cc741ea5-07ca-47bb-8c89-92ec761a99fe>', '<urn:uuid:e6fd63af-a300-4d10-a0b4-6c5f2e051b00>']	open-ended	with-premise	verbose-and-natural	similar-to-document	comparison	novice	2025-05-12T23:56:45.148498	27	80	2234
16	dividing fractions steps explain	To divide one fraction by another, you need to flip the second fraction (switch its numerator and denominator) and then multiply by the first fraction. For example, when dividing fractions, you first reciprocate (flip) the second fraction, then multiply the fractions together. This rule applies even with negative fractions, and the result isn't always a fraction.	['Fractions are difficult for many to understand, but any knowledge gaps here will create big problems down the road. A fraction represents a number of parts written as one number over another with a line in between. Fractions are the same as division, is equal to 3 divided by 4, which is also equal to three fourths of a whole. The top number in any fraction is called the numerator, while the bottom number is called the denominator. The numerator gives the parts out of the denominator of a whole that we have. has a numerator of 4 and a denominator of 5, it represents four fifths of a whole (or 80%).\nFractions can also be greater than 1 or negative.\nis equal to , or two and one third. When you break fractions out into whole number () and fractional parts () you get a mixed number (). While mixed numbers can be easier to interpret they make computations like multiplication more difficult so it is better to work with the pure fractions (like ) instead. Here are a few examples of conversions between mixed numbers and pure fractions:\nSome examples of negative fractions are:\nThe negative sign can come before the fraction, in the numerator, or in the denominator, but we’ll usually stick with the first two cases.\nThis is the easiest computation to do with fractions. To multiply two fractions you simply multiply the numerators to get a new numerator, then multiply the denominators to get a new denominator; combine these for your new fraction. Example:\nSometimes you’ll be able simplify the resulting fraction by dividing out numbers that factor into both the numerator and denominator. For example:\nThe last example was simplified by dividing three out of both the numerator and denominator. Here’s another example of multiplication and simplification:\nNegative and larger fractions follow the same rules.\nTo divide one fraction by another, follow this rule: flip the fraction you’re dividing by (switch the numerator and denominator) then multiply the flipped fraction by the other. Example:\nIf that didn’t demonstrate the technique well enough, here is another example:\nAgain, don’t let negative numbers throw you off:\nWhen multiplying or dividing two fractions, your answer isn’t always a fraction:\nCan you see all the cancellations that led to the previous answer?\nAdding and Subtracting Fractions\nTo add or subtract two fractions they must have matching denominators. If two fractions have common denominators, you can add or subtract them by simply adding of subtracting the numerators to create a new fraction. You won’t always begin with this luxury of equal denominators so you’ll often need to rescale one or both of your fractions. Observe that:\nWhenever you multiply (or divide) both the numerator and denominator of a fraction by the same number, you create an equal fraction written with different numbers. To better understand this, think of a pizza cut into 8 equal slices. If you eat 4 of the 8 slices you’ve eaten of the pizza, which is equal to of the pizza. Think of as a rescaled, but equivalent fraction to .\nYou will usually need to rescale both fractions to find common denominators before you can add or subtract them. Example:\nIn the above example we found the common denominator of 6 for our two fractions. We converted the first fraction by multiplying its numerator and denominator by 3. We converted the second fraction by multiplication both the top and bottom by 2. This gave us two rescaled fractions with equal denominators. At this point the addition becomes easy: add the numerators and leave the denominator alone.\nLike we did above, you can always find common denominators by multiplying the top and bottom of each fraction by the denominator of the opposing fraction. Example:\nHowever, this method will sometimes lead you to work with much bigger numbers than you need to:\nThe following could have been solved more easily if we found a smaller common denominator:\nIf you can see a simpler way to reach common denominators you can save time by avoiding the first approach, but when in doubt, just go that route.\nSolve and reduce to lowest terms.']	['<urn:uuid:dbd46798-e0e8-4dc9-bbc4-561cb00c1681>']	open-ended	direct	short-search-query	similar-to-document	single-doc	expert	2025-05-12T23:56:45.148498	4	56	695
17	buddhist temple art modern traditional elements	Buddhist temples in Thailand combine traditional and modern elements in unique ways. The White Temple in Chiang Rai features classical Northern Thai architectural elements like three-tiered roofs and stylized Nagas, while also incorporating contemporary pop culture references in its murals, including images of Michael Jackson, Harry Potter, and the Terminator. In contrast, Wat Suthat's traditional murals from the 1840s depict Buddhist and Hindu tales using natural pigments like laterite stone for red and gamboge for yellow. Both temples demonstrate how Buddhist art can preserve traditional symbolism while adapting to modern times.	"['Nothing Else Like It! Ancient Meets Modern in the White Temple of Thailand\nWhen the rebirth of an ancient building is assumed by a modern thinking artist, strange elements might appear. This is what has happened at the site of Wat Rong Khun, now the White Temple, Thailand. The Thai artist in question, Chalermchai Kositpipat, includes amongst the more traditional Buddhist symbolism, some images from the modern world, such as The Terminator, Michael Jackson and Harry Potter. The resulting work-in-progress is an absolutely fascinating creation.\nThe White Temple is a Buddhist temple complex located in Chiang Rai, a city in the northern part of Thailand. The construction of the current complex only began around the end of the 20 th century, after the original temple was completely demolished. Whilst the White Temple is not yet complete, it has already become a tourist destination, due to its uniqueness and difference from most of the other Buddhist temples in Thailand.\nThe Saviour of Wat Rong Khun\nThe original White Temple, also known as Wat Rong Khun, was in a decrepit state as the 20 th century neared its end. Whilst restoration works began in order to save the temple, they had to be stopped as a result of a shortage of funds. This temple was ‘rescued’ in a way, when Chalermchai Kositpipat, a local artist, decided to demolish the old structure, and to build a new one in its place, with funds for the project coming out of his own pocket. Kositpipat is perhaps best known for heading the team of Thai artists who painted the walls of the Wat Buddhapadipa, the first Thai Buddhist temple in the UK, which was constructed in Wimbledon in 1982. His murals in that temple are somewhat controversial, as they contain images of secular figures, including Muammar Gaddafi, Margaret Thatcher and Ronald Regan, in that sacred space.\nThai artist Chalermchai Kositpipat at Wat Rong Khun in Chiang Rai, Thailand. © BrokenSphere / Wikimedia Commons ( CC BY-SA 3.0 )\nAn Unorthodox Blend of Modern and Traditional Symbolism\nKositpipat’s unique style of blending the sacred and the profane is also seen in the White Temple, but a little bit more of that in a moment. Apart from its murals, the White Temple contains other elements which are rich in meaning and symbolism. First of all, the ubosot (or ordination hall), which is the most important building in the temple, is entirely white in colour, with fragments of reflective glass embedded in the plaster. The white colour of the ubosot is meant to represent the purity of the Buddha, whilst the glass is meant to symbolise his wisdom.\n- The magnificent ancient Buddhist Temple of Borobudur\n- The Powerful Past of the Former Siamese Capital Revealed in the Splendor of 400 Temples\n- Magnificent Tham Lod Cave Sheds Light on Earliest Humans in Thailand\nClassical, three-tiered roof of the all-white ubosot ( Public Domain )\nIn terms of architectural design, the ubosot contains some classical elements from Northern Thai temples, including its three-tiered roof, as well as the stylised Nagas on the barge boards. On the back wall of the ubosot, one will find a golden mural of the Buddha, and several more images of him in front of it. In addition, it is within this hall that Kositpipat’s distinct style can be seen. Apart from images of the Buddha, this hall also contains a mural depicting well-known figures, both real and fictional, including Michael Jackson, Harry Potter and the Terminator. Other elements in this mural include spaceships, an oil pump, and the September 11 attacks on the World Trade Center. The melange of images makes it difficult to provide a definitive interpretation of the mural, though in general, it is meant to symbolise the struggle between Good and Evil.\n- Wat Tilok Aram: The 500-Year-Old Underwater Temple of Thailand\n- Locals in Thailand Village Claim Black Magic Tattoos Helped Preserve the Skin of a Corpse\n- Ten Magnificent Ancient Structures of Asia\nThe Path to the Ubosot\nAnother feature of the temple complex worth mentioning is the bridge leading to the ubosot, which is known as the Bridge of the Cycle of Rebirth. In front of this bridge is a circular area containing many hands reaching out of the pit. These are meant to symbolise a person’s worldly desires, such as greed and lust, which one would need to overcome in order to achieve enlightenment. After this bridge is crossed, one reaches the Gate of Heaven, which is guarded by two figures representing Death and Rahu. After these are a few images of the Buddha in meditation, after which one would reach the ubosot.\nThe bridge of ""The Cycle of Rebirth"", White Temple, Thailand ( CC BY-SA 4.0 )\nTo date, the White Temple has still not been completed. If all goes according to plan, the temple complex will eventually contain nine different buildings, including the ubosot, a hall to house Buddhist relics, a meditation hall, and even an art gallery. For this project, Kositpipat is aided by over 60 volunteers. Nevertheless, it is estimated that it would take another 60 or 70 years before the temple complex is completed.\nTop image: A photo of the White Temple, Chang Rai, Thailand ( CC BY SA 3.0 ).\nBy: Wu Mingren\nAlex, 2013. Strange interior of the White temple in Chiang Rai. [Online]\nAvailable at: http://www.travelphotoreport.com/2013/01/11/strange-interior-white-temple-chiang-rai/\nCooper, A., 2015. Thailand\'s White Temple a sanctuary for Buddha — and Hello Kitty. [Online]\nAvailable at: http://www.latimes.com/travel/la-tr-d-thailand-temple-20150412-story.html\nHelen, 2017. Wat Rong Khun: The White Temple of Thailand. [Online]\nAvailable at: http://notwithoutmypassport.com/wat-rong-khun-white-temple/\nNėjė, J., 2015. Thailand’s White Temple Looks Like It Came Down From Heaven. [Online]\nAvailable at: http://www.boredpanda.com/white-temple-thailand/\nRenown Travel, 2017. Symbolism in the white temple. [Online]\nAvailable at: https://www.renown-travel.com/temples/symbolism.html\nRenown Travel, 2017. Wat Rong Khun. [Online]\nAvailable at: https://www.renown-travel.com/temples/wat-rong-khun.html\nRong Khun Temple, 2017. Wat Rong Khun. [Online]\nAvailable at: http://www.watrongkhun.org/', 'The restoration work at the royal temple, Wat Suthat Thepwararam, seeks to restore the murals lining the walls of the prayer hall to their original grandeur\nAlongkorn Thiamjun holds a small paintbrush in his right hand and rests it on a support stick. Fastidiously he dips colours onto a vast mural in the prayer hall of Wat Suthat Thepwararam, a royal temple near the iconic Giant Swing. Originally painted in the 1840s during the reign of King Rama III, the murals at Wat Suthat are the largest in the country, and they depict expansive and mystical legends with unrivalled exquisiteness.\nAn artist in the Office of Archaeology of the Fine Arts Department, Alongkorn is also in charge of the mural restoration project. This is the latest conservation effort of the two-century-old wall paintings after the last restoration had been done 36 years ago.\n""We found an advanced state of deterioration, especially from the lower part when we inspected the paintings in 2016,"" he said. Some pieces of those murals had already been lost while other parts were detached from the wall.\n""If nothing is done, there would be a high risk that this invaluable heritage would be gone forever,"" he said.\nWat Suthat was built in 1807 during the reign of King Rama I. The prayer hall was built to house the Phra Srisakayamuni Buddha image, a large bronze Buddha sculpture from the ancient Wat Maha That Temple in Sukhothai province. The king passed away two years after the construction had started, and the work was carried on by King Rama II.\nBut the temple was not completed until 1847 during the reign of King Rama III, who named it Wat Suthat Thepwararam. New buildings also were built during the period including the phra ubosot (ordination hall), sala kanparian (a sermon hall) and monks\' quarters. In 1950, King Rama VIII\'s relics were housed in the prayer hall under the Phra Srisakayamuni Buddha image. Today the temple is one of six most important royal temples in the country.\nWat Suthat underwent renovations from time to time. The grand restoration took place in 1982 as part of the celebration marking the 200th anniversary of the founding of Bangkok. The project was funded by the German government and was completed in 1985.\nIn 2016, the conservation team of the Office of Archaeology of Fine Arts Department found damage on the murals of the phra vihan (prayer hall). The department set aside a budget of 14 million baht for the three-year renovation project, started last year and is scheduled to finish in 2019.\nThe wall as canvas\nSome parts of the murals can\'t be repainted. pHOTO: Karnjana Karnjanatawe\nAccording to records of the department, the murals were painted during the reign of King Rama III. Covering the interior walls on all sides, they portray a series of Buddhist and Hindu tales that represent the foundation of the Siamese faith.\nIn uninterrupted swirls of colour, dimension and montage, the paintings recount the life of Lord Buddha in vibrant colours, as well as chapters from the Ramayana, which can be found around the four doors. Around the 26 windows, visitors can find 13 stories based on classic literature, while the pictures depicting dhamma teachings were painted on the eight pillars inside the hall.\nThe murals, which basically take up the entire hall, start from 1m off the ground and rise to the ceiling, which is at about 30m in height. When combined with murals on every side of the eight pillars, the total painted area is around 2,129m².\n""This is the largest mural area inside a prayer hall in the Kingdom,"" said Alongkorn.\nDevoted artists of yore had perfected the technique that ensures the lasting of the mural montage. The traditional process began with artists coating the walls with a mixture of quicklime. The wall must be free from the base in order for the colour to attain full vibrancy. The base was washed away by a cleansing with boiled water of cassod tree leaves, then a piece of turmeric was rubbed on the wall for it\'s a natural yellow hue -- and not the red-brick colour.\nThe last step was to apply a mixture of boiled white clay, or din so pong, and glue from tamarind seeds on the surface and scrub it until smooth. These steps made the walls like sturdy drawing paper ready to take ink.\nThose inks were made of a mixture of glue and watercolours. Natural ingredients give off natural colours, such as red from ground laterite stone or clay, yellow from gamboge and black from soot on the inner side of a clay pot.\nWhen it was time to paint, skilful artists of the 1800s did not draw outlines. They applied colours directly on the walls.\nMurals at Wat Suthat are regarded as masterpieces. Photos: Karnjana Karnjanatawe\nAs time passes the colours are blanched. The murals also are dirty, while some parts are peeling, have disappeared or have delaminated from the surface due to moisture, pollution and from being touched, said Fine Arts Department director-general Anandha Chuchoti.\n""Wear and tear is clearly shown on lower parts of the walls and the pillars although major parts of the murals are still in original condition. The restoration work is needed immediately,"" he said.\nStarting the restoration\nThe preservation began last year when a team of 10 artists documented the deterioration. The team took pictures of the areas that needed to be fixed. They drew the pictures on papers and marked the damage on the drawn images.\nThe team cleansed all dirt off the surface by covering sa paper on the wall and gently applying distilled water that was mixed with a little bit of either ammonium carbonate or ethyl alcohol. They then injected glue to consolidate the flakes.\nThis year, the team is working on repainting missing and faded colours. Based on the international charter on the Conservation and Restoration of Monuments and Sites, known as the Venice Charter of 1964, the team must use only watercolours produced by London-based Winsor and Newton paint company. ""The United Nations Educational, Scientific and Cultural Organization (Unesco) also identified 12 specific colours that we can use for repairing murals that can match natural colours used in old times,"" he said.\nThe team, half of whom were recruited from artists from the previous restoration project in 1982, plans to finish painting the lower part of the murals this year.\nThey plan to inspect the upper murals next year. They will repeat the same mural restoration process starting from removing dirt to repairing the colours.\n""After the project is completed, we will do a routine check. It is part of our conservation process that we have done not only for the royal temples like Wat Suthat, but also local temples and other historical sites throughout the nation,"" he said.\nAlongkorn Thiamjun is the head of the mural restoration project. Pawat Laopaisarntaksin\nGlue is injected to fix the flakes. Photo Courtesy of the Fine Arts Department']"	['<urn:uuid:a92a05f7-38ed-48a8-a85c-1ebd8e3e9870>', '<urn:uuid:c703c9fa-1e62-417a-9e64-27dfd45d416b>']	open-ended	with-premise	short-search-query	similar-to-document	three-doc	novice	2025-05-12T23:56:45.148498	6	91	2148
18	speech therapy tools and work locations needed	Speech therapists use various tools including assistive technology and devices, particularly for nonverbal children. Special apps like Speech Tutor provide animations of mouth and throat movements, while Apraxia Therapy uses video-assisted speech therapy for practice. These professionals work in diverse settings including hospitals, schools, community health centers, residential facilities, disability services, mental health facilities, juvenile justice centers, and private clinics.	"['Apraxia Therapy from Tactus Therapy is a comprehensive app designed to help people with apraxia, a speech disorder, overcome their ability to say what they want correctly and consistently. The app uses VSAT, or Video-Assisted Speech Therapy, to help users repeat what they hear and see by watching the model’s mouth movements on the video. Jun 18, · Speech Therapy TRICARE covers speech therapy to treat speech, language and voice dysfunctions resulting from birth defects, disease, injury, hearing loss and pervasive developmental disorders. A referral or prescription is needed before obtaining speech therapy services.\nMay 11, · Equipment Used in Speech Therapy. Speech therapists use a variety of different tools to help children with cerebral palsy improve or overcome their communication struggles. Assistive technology, or assistive devices, are also used as communication aids, especially for nonverbal children. Tools. Tools commonly used in speech therapy include. Aug 15, · Speech Tutor is one of the best speech therapy apps to give a clear overview of what happens inside the mouth and throat during speech. It offers animations depicting both a front view and a side view of the mouth so children have an accurate, visible example of how to create sounds.\nOnline Therapy for a Modern World Say goodbye to insurance headaches, high costs, and long commutes. Our certified speech-language pathologists offer high-quality care from the comfort of your home and at a time that works best for your family - all for a fraction of the cost of traditional, on-site therapy. Costs; What others say; Speech Therapy. School Speech Therapy; Assessment and advice; Meet the SLTs; Costs; What others say; Shop. Categories. Social Skills; Feelings; Speech & Language Therapy; Behaviour; Products by age group. Primary School () Secondary School () Special Schools () Adult (16+) Talkabout. Talkabout Books; Other.\nOver the duration of the Speech Therapy and Language undergraduate course, you will cover the foundations of speech and language therapy including both the social and clinical context of human communication. The four year course will provide you with clinical placements to develop your practical, clinical skills and knowledge of the field. Speech and language therapy for children offers support and care to kids who have trouble communicating or difficulty eating, drinking and swallowing. A speech-language pathologist (SLP) is a medical professional who evaluates and treats communication and swallowing disorders. They are sometimes called ""speech therapists."".\n""The facilities at Manchester Met for Speech and Language Therapy are very well developed. I was able to borrow items for placement from a wide selection of resources for both adults and children. They also have clinic rooms that are full of resources for a range of client groups where we were able to practise assessments, therapy or use for. Jan 27, · The Department of Speech and Hearing Sciences will educate you into a health profession in which you will use linguistic, social, behavioural, medical and other scientific knowledge to provide assessment and treatment for both children and adults who have developmental or acquired disorders of speech, language and swallowing.', 'Speech pathologists study, diagnose and treat communication disorders, including difficulties with speaking, listening, understanding language, reading, writing, social skills, stuttering and using voice. They work with people who have difficulty communicating because of developmental delays, stroke, brain injuries, learning disability, intellectual disability, cerebral palsy, dementia and hearing loss, as well as other problems that can affect speech and language. People who experience difficulties swallowing food and drink safely can also be helped by a speech pathologist.\nWhere do speech pathologists practice?\nSpeech pathologists work across a range of health settings including hospitals, schools, community health centres, residential and aged care facilities, disability services, mental health facilities, juvenile justice centres and private clinics.\nServices provided by government or not for profit organisations may be free of charge though there is often a waiting list for public services. Private services are provided by speech pathologists who may work in a sole practice or with other speech pathologists and in multidisciplinary practices.\nWhen should I see a speech pathologist?\nThere are many reasons why a person might benefit from seeing a speech pathologist. A formal referral is not generally required to see a speech pathologist. Some typical issues that may lead a person to see a speech pathologist include:\n- A child that has difficulty being understood by other children in the child care centre\n- A high school student who stutters and wishes to speak more fluently and with confidence.\n- A person experiencing difficulty speaking clearly after a brain injury\n- A person with dementia who needs assistance communicating with family and carers and making choices about their future\n- A person who is experiencing difficulties swallowing safely following a stroke.\nWhat services do speech pathologists provide?\nSpeech pathologists offer a broad range of services to support people in managing their communication skills and capacity to swallow safely. Examples of the type of work speech pathologists undertake with people are:\n- Providing communication strategies and augmentative or alternative communication devices for a person who cannot communicate verbally\n- Teaching a person who has had a stroke to swallow safely without choking and/or regain their communication skills\n- Helping children who have difficulty with their speech such aschildhood apraxia of speech\n- Helping pre-school and school aged children who have difficulty understanding others or difficulty sharing their thoughts, ideas and feelings\n- Helping children and adults who stutter to speak more fluently and with confidence\n- Providing advice to parents/carers who have babies or toddlers with feeding and swallowing difficulties.\n- Helping individuals with voice disorders including difficulties with voice quality, pitch or loudness.\nHow are speech pathologists qualified?\nIn order to practise as a Certified Practising Speech Pathologist (CPSP), speech pathologists must meet the following requirements:\n- Complete a recognised undergraduate or masters level qualification\n- Complete continuing professional development as set out by Speech Pathology Australia\n- Demonstrate that they have practised as a speech pathologist in the previous five years for a minimum of 1000 hours to meet Recency of Practice requirements.\nSpeech pathology is a self-regulated profession. Speech Pathology Australia is recognised by the Department of Education and Training as the assessing authority for speech pathologists in Australia.\nFor more detailed information about speech pathology, please visit the Speech Pathology Australia website.\nFind a speech pathologist\nSpeech Pathology Australia has a Find a Speech Pathologist service that can be accessed here.']"	['<urn:uuid:694835bc-b245-4093-b489-50badbe58f25>', '<urn:uuid:2c073f8e-3e84-4268-9372-11d28375cf84>']	factoid	with-premise	short-search-query	distant-from-document	multi-aspect	novice	2025-05-12T23:56:45.148498	7	60	1069
19	as tv content creator looking for funding red flags scam companies warning signs	There's a concerning trend where some companies are asking aspiring producers to personally fund pitch tapes with budgets of $30,000 or more. This is not a normal industry practice - legitimate production companies and established industry players would never ask someone to pay out-of-pocket cash for a show concept they want to pursue. While these companies may not necessarily have malicious intent, this is not how the business typically works in the unscripted TV industry.	"[""Today’s episode about pitch tape budgets may be the most serious we’ve ever recorded. It includes important tips for anyone who wants to pitch TV shows, but also a warning. We’ve received a cluster of emails in past weeks reporting something that concerns us. Some companies are asking aspiring producers to fork over thousands of dollars. Why? To create pitch tapes or sizzle reels for these producers’ original TV show ideas. Is this legit? Should you consider this? Would established production companies ask you for $30,000 or more to make a pitch tape for your concept? We have important answers for you. You’ll learn the real “why” behind pitch tape budgets. Plus, sizzle reel goals you need to set for yourself, no matter what.\nPitch Tape Budgets, Goals, and Realities\nWe’ve discussed pitch tapes (a.k.a. sizzle reels) before. Essentially, a pitch tape is like a “movie trailer” for your unscripted TV show concept — whether for a documentary series, reality TV show, or even feature length doc. (For instance, we made pitch tape for Dying to do Letterman originally framing it as a documentary series long before it made it to theaters and streaming as a feature film.)\nThe goal when making a pitch tape is to get a TV network or legit production company interested in your concept. This begins a journey that hopefully ends with your TV show concept on the air.\nThere’s no doubt that pitch tapes are an important part of our industry. Our own pitch tapes jump-started our careers and have sold numerous TV shows. That said, we’ve also preached about not going broke while putting together these kinds of presentation tapes.\nPlaying the Numbers Game (Without Going Broke)\nThe honest truth is that every individual TV show concept pitched (including those created by Mark Burnett, J.J. Abrams, the two of us, or anyone in Hollywood) is a long shot. You always pitch more shows than you actually sell. When you need to pitch so much, so often, it just doesn’t make sense to spend big, big money on any one pitch tape.\nIn fact, when we first started out, we never spent more than $500 out-of-pocket on our pitch tapes (and often far less than that. Granted, we were also shooting, editing, and making the graphics for our own productions, so that helped a lot.) To this day we warn people not to spend more than a few hundred dollars on their first-crack at a pitch tape.\nScary Emails from Some of You\nThat’s why we were so concerned when we received several emails — all within a relatively short time — from people asking if it was normal for production companies to ask them to personally fund pitch tapes. And these were enormous pitch tape budgets! Tens of thousands of dollars to make a sizzle reel for a concept these producers had pitched.\nMost frightening was that the producers who reached out to us were seriously considering paying up — all so their ideas could eventually get “pitched to TV networks.”\nNow, we’re not saying that, in all these cases, there was some kind of malicious intent behind these big asks. We don’t know these companies in question (nor did our agents.) That doesn’t necessarily mean that the people who run these places are trying to “rip producers off” or are “bad people.” We don’t know or understand their business models.\nHowever, our own production company would never ask someone to pony up out-of-pocket cash for a show concept we wanted to pursue. Neither would any of the companies we worked at when we were younger, or those companies we consider peers in the unscripted TV industry. In our experience, that’s never been how it works.\nThat’s why today we discuss:\n- Good reasons for big — and small — pitch tape budgets\n- Three considerations for every pitch tape you make\n- Developing your pitch tapes in stages\n- A simple sentence to remember when working with legit production companies\n- The one thing you should gladly give to any production company\n- How to get more lasting benefits out of your pitch tape budgets\n- Should you charge up your credit cards to make a pitch tape?\n- The rare circumstances under which your might consider spending big money on a pitch tape\nFor all this and more, hit that giant red button above!\nTranscript Coming Soon!\nHelpful and Related Links\n- What is a pitch tape? Should You Make One? Title says it all. More in-depth info on making sizzle reels and pitch tape budgets.\n- Sizzle Reels: Budgets, Investors, and More – more good info, especially if you’ve ever considered trying to get investors for your pitch tapes.\n- Sizzle Reel Secrets: How We Sell Shows – more specifics about making great pitch tapes.\n- In our free ebook How to Pitch a Reality Show, we have a whole section discussing reality TV pitch materials.\n- Thinking of (gasp!) shooting a whole TV pilot on your own? You need a great reason, and selling a TV show DOES NOT COUNT. Check out Should You Shoot Your Own TV Pilot?\n- Find us on Twitter and Facebook\nLet’s Make Some TV Together\nAre you trying to break into unscripted TV, reality television, or documentary series? Want to pitch to our company? Here’s what you need to know:\nSign up for our newsletter and you'll learn how to submit your unscripted concepts to us. You'll also learn how to develop, pitch, and sell reality TV shows and documentary series, and improve your filmmaking skills. From time to time we'll even tell you exactly what kind of shows we're looking for:""]"	['<urn:uuid:e5d906b6-a423-46a5-bc14-7f288d0ea3bf>']	open-ended	with-premise	long-search-query	distant-from-document	single-doc	expert	2025-05-12T23:56:45.148498	13	75	949
20	As someone studying animal nutrition, I'd like to know how daily protein requirements compare between dairy cows and adult human males, and what are the recommended amounts for each?	Dairy animals require 16 percent crude protein in their diet, with high quality pastures potentially offering up to 30 percent crude protein. In comparison, adult men ages 19 years and older need 56 grams of protein per day, which should constitute about 10 to 20 percent of their total daily calories.	"['by Sanne Kure-Jensen\nDr. Darrell Emmick shared his experience with animal foraging behavior and explained how to train livestock to eat weeds. This talk was part of a workshop called ‘From We-Feeders to Weed-Eaters: Controlling Weeds through Animal Grazing’ hosted by Watson Farm in Jamestown, RI. Dr. Emmick also spoke at two similar workshops in Litchfield, CT and South Deerfield, MA. Joining him were experts from each state speaking on weeds and forage.\nAnimal Foraging Behavior\nAccording to Dr. Emmick, animals learn what to eat through the interactions of two interrelated systems: affective and cognitive. The affective system operates without any conscious thought on the part of the animal, using feedback from osmotic, chemical, and mechanical receptors within the gut to evaluate the chemical and nutritional composition of foods eaten relative to the animal’s nutritional requirements. This is ‘Post ingestive feedback.’ If they feel good or energized after eating a certain food, they will eat it again. If they feel uncomfortable, bloated or sick afterwards, they are not likely to eat that food or plant again. The cognitive system uses information gained through the senses of sight, smell, touch, and taste, as well as social learning. Generally, babies eat what they see their moms eat. Animals also learn from other adventurous animals in their group.\nPlant Nutrition vs. Toxins\nA toxin is something that can make an animal sick. In small doses, toxins can act as a medicine. In large doses, toxins can kill. Dangerous or tolerated doses vary with animal age and health.\nHealthy young plants grown in ideal conditions typically contain lower concentrations of toxins — alkaloids, terpenes, phenolics and glycosides — relative to nutrients such as protein, carbohydrates, lipids, nucleic acids. This often changes for the same plants growing in less than ideal conditions. Cool-season plants grown on hot dry southern slopes are most nutritious and least toxic during spring and fall.\nPlant nutrients vary with time of day. Plants are typically less nutritious in the morning than at the end of the day.\nLegumes always have more nutrition than grass, even in the morning. Most animals start their day with legumes. Animals switch over to grass or other forage when their ‘conditioned taste aversion’ kicks in. After a certain amount of a particular food, our bodies tell us it is time to add something new or for a different food altogether. This ‘conditioned taste aversion’ prevents animals from eating the same food all day, every day which helps balance nutrition and toxin intake.\nAnimals use protein and energy to process, eliminate or neutralize toxins in their digestive systems. When processing large levels of toxins, they produce less milk or put on less growth than with a diversified diet.\nAlmost all forage plants contain some level of toxin along with their beneficial nutrition. Plants develop lower nutritional quality and higher or dangerous levels of toxins when subject to herbivory (pest or livestock browsing) or stressed plants growing in harsh climates, extreme summer heat, poor soils or excessive shade.\nSome toxins neutralize each other during digestion. The order plants or toxins are eaten matters to digestion, explained Dr. Emmick. Tall fescue contains alkaloids which upset rumen function and intake. Birdsfoot trefoil is high in tannins. If an animal eats tall fescue first, its intake will drop if later provided birdsfoot trefoil. If an animal eats birdsfoot trefoil first, intake will remain high when provided with tall fescue. The tannins in trefoil bind with the alkaloids and reduce their influence. There are many plant-herbivore interactions: nutrient-nutrient, nutrient-toxin and toxin-toxin interactions, which are just now being discovered.\nNutritional Needs of Cattle\nDairy animals need 16 percent crude protein. High quality pastures can offer 30 percent crude protein. Dr Emmick worked with Dr. Provenza in the Department of Wildland Resources at Utah State University studying animal grazing behavior and diet selection. In one study, they learned that dairy cows could self-select the foods with protein levels they need. If you feed them 11 percent crude protein in the barn, they will select high protein foods (clover) on pasture. If you feed then 21 percent crude protein inside, they will select low protein foods (grass) afterwards. Don Minto of Watson Farm confirmed that his cows know what they need. Minto described using a varied mineral free choice system allowing the animals to self-select their minerals rather than offering one single blend.\nWhile Dr. Emmick appreciated the need to analyze forage quality, the results will vary considerably by season, temperature, moisture levels, time of day and life stage of plant. He said, “The cows will figure out what they need.” Computer models recommending feed blends are humans’ attempt to understand the animals’ dietary requirements. While these models offer a reasonable place to start, they are not as accurate as we would hope.\nTraining Livestock to Eat New Plants\nFarmers can train their animals to eat new plants and weeds. Dr. Emmick recommends selecting one or more adventurous healthy animals. Harvest young, strong, healthy weeds. Mix a few into a bucket with favorite grains or in the barn with haylage. Dr. Emmick remembered being trained to eat mutton with mint jelly as a child. He recommended drizzling a little molasses over the top of unfamiliar weeds to make them appealing. Each day add a larger portion of the ‘weed’ to the mix. After a week to ten days, bring animas to a pasture with those same weeds. You can lightly spray the weeds with molasses for the first few days. The animals should be ‘trained’ to eat them.\nDr. Darrell Emmick is the former State Grazing Land Management Specialist with the USDA-Natural Resources Conservation Service in New York State. He can be reached via email at email@example.com or call 607-844-3211.\nby Sanne Kure-Jensen', 'How Much Protein Do You Need?\nProtein is having a moment. From Atkins to Paleo, it seems like everyone is eating a high protein diet. Even JetBlue is offering cricket-yes, cricket!-protein bars to airline passengers. Whether or not you eat a high-protein diet (or an insect snack mid-flight), chances are you\'re concerned about your intake of this important nutrient. Are you eating enough? Eating too much? Here\'s the skinny:\nAre You Getting Enough Protein?\n""In a generally healthy diet, about 10 to 20 percent of your total calories should be coming from protein,"" says Alison Massey, MS, RD, Director of Diabetes Education at The Center for Endocrinology at Mercy Medical Center in Baltimore.\nIndividuals with certain medical conditions or specific needs may need more or less protein, but, according to the Centers for Disease Control and Prevention, general recommendations for the average person in grams (g) per day are:\nMen ages 19 years and older: 56g\nWomen 19 years and older: 46g\nPregnant or nursing teenagers and women: 71g\nChildren ages 1-3 years: 13g\nChildren ages 4-7 years: 19g\nChildren ages 9-13 years: 34g\nBoys ages 14-18 years: 52g\nGirls ages 14-18 years: 46g\nWhile athletes may benefit from increased protein intake pre- and post-workout, the majority of us (even regular exercisers) are fine with the above guidelines.\nThe Problem With too Much Protein\nThe good news about protein intake is that most of us get enough-even those of us who follow a vegetarian or vegan diet. Plant-based proteins such as beans, nuts, and tofu help to create a balanced diet. The key word here being balanced, which brings us to the problem with high protein diets..\n""When you eat a high protein diet and exclude carbohydrates-which is your body\'s main source of fuel-your body begins to burn its own fat for energy,"" explains Heidi McIndoo, MS, RD, author of The Complete Idiot\'s Guide to 200-300-400 Calorie Meals. ""While that may sound good, it actually leads to a condition called ketosis. Ketosis may help reduce your appetite, but it also increases your fluid loss, making any initial weight loss often just a loss of fluids."" In addition, McIndoo cautions that when you lose large amounts of fluids, you may also lose the essential nutrients in the fluids.\nIf you are considering a high protein diet, McIndoo recommends you increase your protein intake slightly, while reducing-but not eliminating-your carbohydrate intake. Your carbohydrates (eaten at each meal and snack) should consist of whole grains, fruits, and vegetables, instead of highly processed carbs like sugar foods, cakes, pastries, candy, and sodas and other sugary drinks. And when it comes to choosing protein, opt for healthier, lower-fat sources, such as sirloin steak instead of a burger.\nThe Healthiest Sources of Protein\nThere are lots of options for incorporating healthy sources of protein into the diet. The healthiest sources are plant-based ones, followed by small amounts of seafood, poultry, and low fat dairy products.\nGood plant-based sources of protein include:\nLentils, with 18g in 1 cup.\nBeans, with 13g in 1 cup of canned baked beans.\nNuts, with 7g in 1 oz. of roasted peanuts\nSeeds, with 6g in ¼ cup.\nTofu, with 6g in 1 slice.\nNut butters, with 8g in 2 tablespoons.\nGood lean animal sources of protein include:\nFish, with 19g in 3 oz. of cooked salmon.\nLow fat Greek-style yogurt, with 8g in a 6 oz. container.\nLow fat cottage cheese, with 15g per ½ cup.\nSkinless white meat chicken and turkey, with 26.3g in 3 oz.\nBeef (lean meats such as eye round, top round, bottom round, top loin, sirloin), with 21g per 3 oz. serving.\n""Protein helps build and repair tissue in your body-bone, cartilage, muscle, skin, and more,"" says McIndoo. ""If you eat too little protein your body may not be able to heal itself as quickly from injury, or you may be more susceptible to illness. You may also have problems with other body functions for which protein is needed to manufacturer necessary enzymes and hormones."" Unless you have a medical condition that requires a lower protein intake, you should stick to the Centers for Disease Control and Prevention\'s recommendations.']"	['<urn:uuid:7bd73eef-89d5-4a11-84c6-b6621dfad145>', '<urn:uuid:c6cc7426-1a76-433e-9ef9-80efccb2a408>']	factoid	with-premise	verbose-and-natural	distant-from-document	comparison	expert	2025-05-12T23:56:45.148498	29	51	1652
21	What are the physical differences between male and female blue gouramis that help tell them apart?	Male and female blue gouramis can be differentiated by looking at their dorsal fin. Males have a long and pointed dorsal fin, while females have a short and rounded dorsal fin. Additionally, females tend to be larger in size than males.	['Taking care of your blue gouramis is more than just filling up a fish tank with some water and feeding them a couple of times a day with any random fish food that you cop from the supermarket.\nDespite being relatively easy to care for, you need to educate yourself on how blue gouramis behave, especially if you want them to stay healthy and live a happy, long life. You have to go beyond the basics and take care of the small details that make all the difference.\nIn this guide, we’ll walk you through everything you need to know about taking proper care of this interesting fish species, in addition to breeding, fish tank cycling, and preferred tank mates, so let’s cut to the chase!\nTable of Contents\nOverview, Origin, & Appearance\nBlue gourami (Trichopodus trichopterus) is also known as opaline gourami, gold gourami, and three-spot gourami. The “three-spot” naming comes from the two spots on the fish’s side that align with each of its eyes (the third spot).\nIts scientific name is trichopterus, which is derived from the Greek words ‘trichiasis’ and ‘pteron.’ The former means “hairy”, while the latter translates to “wing”.\nBlue gouramis primarily inhabit Southeast Asia. They prefer to live in vegetated waters, which is why they are usually found in canals, ponds, ditches, swamps, lakes, lowland marshes, peatlands, and rivers. They can also be found in flooded forests.\nSome of the areas that have the most significant blue gourami populations include the Mekong River basin in Vietnam, southern China, Laos, Thailand, Myanmar, Cambodia, Malaysia, Sumatra, Kalimantan, and Java.\nThe fish has limited commercial use as food, but it’s not uncommon to find them in home aquariums. It’s actually one of the most popular aquarium fish species because it’s easy to care for, making it especially suitable for beginners. It’s also super fun to watch!\n- Tank size: 20 gallons (minimum)\n- Temperature: 74°F – 82°F\n- pH: 6 – 8\n- kH: 6 – 8\n- Living zone: Top/middle\n- Temperament: May get aggressive with females after breeding. Will eat smaller fish that can fit in its mouth.\n- Diet: Omnivorous\n- Common Names: Blue gourami, opaline gourami, gold gourami, and three-spot gourami\n- Kingdom: Animalia\n- Phylum: Chordata\n- Class: Actinopterygii\n- Order: Anabantiformes\n- Family: Osphronemidae\n- Genus: Trichopodus\n- Species: T. trichopterus\nColors and Markings (Gender Differences)\nThree-spot gouramis are found in a variety of colors, including red, yellow, blue, and platinum.\nAnd speaking of colors, it’s worth noting that gouramis are known to change color when they feel stressed or aren’t kept under suitable conditions.\nKeep an eye on the color of the two brownish spots on its side, as these are usually the first parts that noticeably shift colors when something is wrong.\nAs for size, blue gouramis can have a length of up to 5 inches. They’re quite long, and their flattened bodies are characterized by unique-shaped rounded fins. Females, in particular, tend to be larger than males.\nAnd before we get into the ins and outs of breeding your blue gourami fish later in this article, you need to make sure that you can fully distinguish between male and female three-spot gouramis.\nOne easy way to differentiate between the two genders is by looking at the fish’s dorsal fin. In male blue gourami fish, the dorsal fin is long and pointed, while it’s short and rounded in female blue gouramis.\nBlue Gourami Care & Tank Set-Up\nTank Size (How Many Can Live Together?)\nThe minimum tank size for blue gouramis is 20 gallons. This number may increase as your blue gouramis get older or increase in number. A tank size of 35 gallons is pretty common among three-spot gourami owners.\nAlso, keep in mind that blue gouramis have a labyrinth organ that allows them to breathe air when needed. In other words, they can survive even if the tank isn’t filtered.\nHowever, this isn’t a good practice in the long term, which means that you need to keep the tank well-filtered. Another good idea is to add some air stones for extra oxygenation.\nThe number of gouramis that can live together is a function of the tank size. As a general rule of thumb, you can keep 2-3 gouramis in 10 gallons of water, and you’ll need an extra 5 gallons for every additional gourami.\nThe Nitrogen Cycle\nThe Nitrogen cycle is simply mother nature’s way of handling marine ecosystems. The nitrogen cycle ensures the aquarium’s ecosystem is safe for fish to live. It’s common for beginners to miss this (known as new tank syndrome) and can often end in disaster if skipped.\nWhen your blue gourami produces waste in the form of nitrites, they’re converted into nitrates once they reach a certain level. When the level of nitrites and ammonia in your fish tank is 0 ppm (parts per million), you can conclude that your tank is fully cycled.\nThe Nitrogen cycle is important because it purifies your fish tank from harmful chemicals and even converts these chemicals into useful food that your fish can consume.\nThe best way to kickstart a nitrogen cycle in your water-filled fish tank is to add ammonia by adding some fish food flakes until they decay. Then, you’ll have to test for ammonia, nitrites, and nitrates over the next few weeks until the levels of nitrite and ammonia diminish completely, and nitrates dominate.\nJust make sure that your nitrate level is lower than 40. In case it’s more than that, you’ll need to make some water changes to lower it a bit before adding your fish.\nWhenever water parameters are brought up, people think that they need to hit a perfect number when it comes to temperature, pH, and kH.\nHowever, the key here is to maintain stable conditions instead of chasing a magical number that will fully optimize your fish tank. Swinging water conditions is why large fish communities die. The reason for that is pretty simple; variable pH levels will show signs of distress on your fish, which will slowly kill them.\nThe best practice here is to maintain a stable pH level. If your gouramis show signs of distress, you can safely lower the pH levels a bit by using reverse osmosis, driftwood, catappa leaves, or peat moss.\nGenerally speaking, blue gouramis are pretty adaptable when it comes to water values, but they won’t really like it if the water is too acidic. Most tank fish adapt to whatever pH the water they were born in and have lived in captivity.\nPlants, Substrate, and Decorations\nAlmost all types of plants and decorations can be added to a fish tank that blue gouramis live in. Black substrates would be an excellent addition to your tank because they’ll create a nice contrast with the color of your blue gouramis.\nPro tip: Blue gouramis have a unique labyrinth organ that allows them to breathe fresh air from the surface, so don’t overcrowd your tank with floating plants.\nDiet and Feeding Blue Gourami\nEnsuring that your blue gourami fish get all of the essential nutrients they need to grow and flourish is essential for their development. Three-spot gouramis are omnivores and feed on meaty and algae-based foods.\nHowever, blue gouramis are known to be pretty flexible in their diet options. They’ll literally eat anything you give them, including flakes as well as live and freeze-dried foods.\nYour best bet is to get commercially prepared food that’s rich in protein sources like shrimp and salmon while also containing a significant amount of algae. Shrimp pellets, tropical flakes, color flakes, and tropical granules are all excellent choices for your blue gouramis.\nHowever, make sure that you check the food ingredients carefully because not all fish food delivers the same nutritional value. In fact, many brands add filler ingredients that will make your fish produce more waste and gain fewer nutrients.\nThis means that you’ll need to cycle your fish tank more often to make it habitable for your blue gouramis; not exactly something that you’d want, would you?\nTo further clarify, here’s a complete list of good ingredients that you need to look for:\n- Black worms\n- Whole fish\n- Spirulina (a blue-green alga)\n- Algae meal\n- Squid meal\n- Black soldier fly larvae\nOn the flip side, avoid buying fish food that contains any of these ingredients:\n- Low-quality fish meal\nOn a side note, take into consideration that blue gouramis are slow-growers, so don’t expect them to grow quickly even if you feed them pretty well.\nBlue Gourami In-Tank Behavior and Temperament\nBlue gouramis are usually peaceful, but the males tend to get a bit territorial after breeding (more on that later). This behavior isn’t limited to male-female three-spot gourami interactions, though.\nBlue gourami may exhibit a similar behavior towards fish of different species, especially if they’re males. They’re also fin-nippers, and they particularly hate species that have long fins, including goldfish, guppies, and bettas.\nIt’s a funny story, but male gouramis hate these particular species because they think that their elongated fins may impress female gouramis. That’s right; male gouramis can get jealous!\nTank Mates (And Who to Avoid)\nBlue gouramis may not like all of their neighbors from other fish species. Your best bet is to choose species that have similar sizes to your blue gouramis.\nSmaller species won’t really like living with blue gouramis because they’ll get territorial with them. Oh, and try to avoid larger species because blue gouramis may get skittish around them.\nGood Tank Mates For Blue Gourami\n- Large tetras\n- Peaceful catfish\n- Dwarf Crayfish\n- Cherry Barbs\n- Bristlenose Plecos\n- Kuhli Loach\n- Harlequin Rasbora\nBad Tank Mates For Blue Gourami\nBreeding Blue Gourami\nAs for the breeding itself, the process starts with the male blue gourami creating a bubble nest and enticing the female.\nThroughout the spawning period, the male gouramis wrap his body around its female partner, turning her on her back to facilitate the rise of the eggs to the surface. Another benefit of such contact is that it brings the reproductive elements closer together.\nA noticeable sign that spawning is coming to an end is when you see the male and female quivering. Once the female lays its eggs, which can be up to 800 eggs at times, you need to move it to a different aquarium since the male fish’s next instinct is to act aggressively towards the female.\nHowever, let the pair decide if they need to repeat the process and release more eggs, which usually happens over the course of a few hours. In that case, the number of eggs can reach up to 3000 eggs.\nThe male’s sperms can only survive in the water for a few minutes, which means that proper timing here is crucial here.\nThe male three-spot gourami then remains in the nest he created to protect the eggs. Note that you need to move the female to another aquarium because the male may attack her to protect the eggs from getting eaten.\nAfter the eggs hatch, which usually happens within 30 hours, you’ll need to change the water more frequently than usual to keep the fry healthy, especially in the third week when the labyrinth organ is developing. You should also feed the fry some nauplii and infusoria to keep it healthy.\nIs The Blue Gourami Right For Your Tank?\nTo sum it all up, taking care of blue gouramis may require a bit of a learning curve, but once you set up the water parameters, find out the right type of food that your blue gouramis enjoy, and figure out how to let them breed smoothly, things will be much easier down the line.\nAlso, don’t forget the nitrogen cycle. Adding your blue gouramis to a tank full of ammonia will only make them die within a few days, so make sure to cycle it first!']	['<urn:uuid:c4e27165-67ed-4125-abab-da7ba44717ca>']	factoid	direct	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-12T23:56:45.148498	16	41	1990
22	What similarities exist between South Africa's national identity building and an artist's process of creating a painting?	Both South Africa's nation-building and an artist's painting process involve careful layering and fundamental groundwork. South Africa has been building its 'Rainbow Nation' through sequential steps, including democratic elections, addressing racial divisions, and using sports as a unifying element. Similarly, the artistic process requires laying down proper foundations through techniques like applying a colored ground, understanding light and shadow, and building up layers of paint. Both processes require patience, careful planning, and addressing underlying structures - whether it's dealing with the legacies of apartheid in South Africa's case, or preparing a canvas with gesso and proper underpainting in artwork.	"['This module is comprised of four learning activities. The completion of all activities in this module may take three to four 50 minute class periods. Teachers may decide to teach the entire module or to select among the learning activities.\nThis module provides an introduction to the Republic of South Africa, an important country on the continent of Africa because of its political, social, and economic influence. Although the country still faces challenges such as continuing racism, the HIV/AIDS epidemic, and poverty, many countries in Africa (even throughout the world) look to South Africa for leadership and as an example of successful conflict resolution. South Africa experienced a remarkable, peaceful transfer of power in 1994 when all citizens could participate in fully democratic elections. This came after a long struggle against an oppressive white government. Since then, the government and the dominant political party have worked to build a “Rainbow Nation,” a nation where people divided in the past by their race can live and work together. These issues and the history of South Africa are explored in the module.\nActivity One introduces South Africa through an overview of its geography. Activity Two addresses South Africa’s history. This activity is designed to be a resource of basic knowledge of South Africa’s history as well as a lesson plan. Therefore, teachers are free to use the material as best suits their needs. A teacher may use the activity materials for one in-class presentation, a number of sessions focused on different periods of history, and/or assign the entire text as supplemental reading. Activity Three and Four focus in more detail on two aspects of building a “Rainbow Nation.” Activity Three looks at the renaming of places in South Africa, a logistical aspect of overcoming physical segregation with municipal restructuring, and a political issue regarding historical memory and the legacies of colonialism and apartheid. Activity Four looks at South African sport, an important part of South African culture that can help us understand both the country’s past and present.\nThe learning activities are designed to be used sequentially; however, each may also be engaged on its own. Each activity contains suggested classroom and individual learning exercises and may take three to four 50 minute class periods to present.\nAs emphasized in the introduction to module five Country Perspectives, there are a number of reasons for offering modules that focus on specific African countries such as South Africa, including:\n- Africa is not a country! Sampling of North American and European perspectives on Africa, whether in a K-12 classroom, college lecture hall, civic or church group, almost always reveals the notion that Africa is socially, culturally, politically, and economical homogenous—Africa is perceived as a country, and not as a richly diverse continent comprised of 54 countries and a myriad of social structures, cultural traditions, and economic practices. Unfortunately, most text-books used in middle and high school social studies classrooms reinforce the perspective of African homogeneity and uniformity. Textbooks usually treat Africa as entity or provide chapters on two or three regions of Sub-Saharan Africa. This is in striking contrast to the treatment of Europe and Asia in the same text-books where it is the norm to have separate chapters on selected countries (e.g. China, Japan, India, Britain, France, Germany, Italy, etc).\nExploring Africa provides an essential alternative to the perspective of African homogeneity by accentuating the reality of Africa’s political, social, cultural and economic diversity through the detailed study of South Africa and nine other important African countries.\n- Recognize and celebrate Africa’s rich diversity. An in-depth study of South Africa and country perspectives from all regions of Africa facilitates knowledge and understanding of the rich diversity of African political, economic, cultural and social realities, traditions and practices.\n- Countries are important: In spite of the growing political importance of globalization, the nation-state remains the primary and most important political entity in the early twenty-first century geo-political world. This is true in Africa as it is in Europe, Asia, and the Americas. Through the comparative study of South Africa and the nine other selected African countries students will gain an understanding and appreciation for the similarities and difference among African nation-states and between African states, their own country, and countries in other regions of the world.\nA Note on Photographs\nThroughout this module, numerous photographs will be used. It is important to remember that these photographs do not fully represent the “way things are” in South Africa. For example, photographs of different houses in South Africa represent actual houses, but cannot be seen as the only type of housing found across the entire country. Such photographs are just one among many possible representations. Photos are used in this module to help illustrate the geography and history of South Africa, and social, political and economic activities and practices of the country today. They do not represent a uniform way in which South Africans engage in these activities.\n- How has the physical geography of South Africa influenced the country’s settlement patterns, economic activities, and international relations?\n- What factors have determined the course of South African history?\n- What groups of people have settled in South Africa? How and why? What does that tell you about how South Africa has been linked to the rest of the world?\n- How is South Africa similar to and different from other countries in Africa that you have learned about? How is South Africa similar to and different from the United States?\n- What legacies of colonialism and apartheid does South Africa face today? How are they dealing with them?\n- What does it mean to be a “Rainbow Nation”? How is South Africa working towards that and what challenges do they face in creating such a nation?\n- What role has sport played in South African society and history?\nAfter completing this module students will have:\n- A clearer understanding of the geography, history, and cultures of South Africa.\n- A greater knowledge of the forces and actors that shaped South African history and still influence South Africa’s politics, economics, and internal and global relationships today.\n- An awareness of how and why places are named and renamed in South Africa.\n- A familiarity with South African sports and their role in society and history.\nBegin this module with Activity One or select from one of the other activities.', ""Free PDF Download - Beginner’s Guide to Acrylics\nAn overview about acrylic paint, colour palettes, tools & materials as well as how the different areas of the Will Kemp Art School fit together\nGetting Started: Choosing a Painting Surface for Acrylics\nUnderstanding paint film & diluting acrylics with water – the pros and cons\nGetting Started: How to Apply a Coloured Ground\nAn Old Master technique to rapidly improve your paintings\nA quick way to understand brushes + video\nOverview of acrylic brushes and the brush choices I make for a simple landscape\nA series of ‘how to’ articles and videos on some of the most common questions and simple video tutorials.\nHow to Choose a Beginner's Starter Set (Without making an Expensive Mistake)\nWhich colours should you buy when you first start painting?\nHow to Apply a Coloured Ground with Acrylic Paint (video)\nVideo demonstration on how to apply a coloured ground\nHow to Prime a Canvas using Gesso for Acrylic Painting\nDo you need to use Gesso? how can it help your paintings?\nHow to set up Art Studio Lighting (without being kept in the dark)\nDo you know your Kelvin from your CRI? how to set up consistent light in your art studio\nWhat is the best background colour for your studio walls & why does it matter?\nHow a change it studio wall colour can alter the perception of your paintings\nHow to Choose a Colour for a Tonal Ground (My Top 5 Choices )\nHow do you go about choosing a colour for your tonal ground? and what’s the best choice.\nPeonies in Water-Mixable Oils (How do they compare to Acrylics?)\nA still life set up of some fab oversized pink peonies beginning simply with acrylics then building up the piece using water-mixable oils.\nHow to shoot stunning still life set ups for your paintings - Part 1 of 3\nBasic camera instructions to use your DSLR in manual mode when photographing still life setups\nAre you 1cm away from the perfect composition? Part 2 of 3\nHow a slight change in your viewing position can drastically alter your painting success\nHow to Paint Glass & Reflections with Acrylics - Part 3 of 3\nLooking at tones and contrast in a step-by-step tutorial to create a realistic illusion of water in a glass\nA Beginners Guide to Light & Shadow\nThe key components of “Light Logic” to create the illusion of realism in your drawings\nHow to Shade a Drawing with Light & Shadow\nStep-by-step drawing demo, using a paper tortillion to create the illusion of form with graphite\nHow to Paint Light & Shadow in Acrylics\nThis two-part tutorial looks at applying the principles of light and shadow to your paintings to improve the illusion of form and realism\nPlein Air Acrylic Sketch of a Lemon Tree\nIn this on location video lesson, paint a lemon tree within a secluded grove as a plein air sketch with acrylics\nGlossary of Acrylic Painting Terms - The Ultimate Guide for Beginners.\nCommon terms used in Acrylic painting to get you started\nHow to Instantly add Depth to Your Mountains in Landscapes\nLearn how Da Vinci used science to create depth in his paintings\nHow to Paint a Simple Snowscene with Acrylics\nIn this two-part tutorial, learn how to paint a muted snow scene with a limited palette\nMonet Impressionistic Style Landscape - Part 1 of 4\nDiscover in this four-part tutorial series how to paint in a more Impressionistic style using Monet’s palette & techniques\nGreen Summer Trees with Acrylics\nIn this three-part tutorial, learn how to mix vibrant greens for a summer landscape painting\nHow to use Acrylics Gels & Mediums\nHow to change the consistency and handling properties of your acrylic paint using gels and mediums\nVarnishing & Isolation Coat\nHow do you varnish an acrylic painting? What is an isolation coat? And do you even need to varnish your oil painting at all?\n3 Reasons why artists varnish their work (and why some artists don’t)\nKey considerations when choosing to varnish your paintings\nColour Mixing & Understanding Pigments\nNEW Beginners Acrylic Colour Mixing Course\nA 5 1/2 hour downloadable colour mixing video course to help you understand the theory behind colour mixing, discover how to mix and match colours accurately and then put theory into practice, creating a series of 4 x still life acrylic paintings.\nThe 5 Key Differences between Acrylics vs Oil paints - a Beginners Guide\nAre acrylics or oils your natural medium?\nThe 8 key Differences Between Artist Quality vs Student Grade Acrylic Paints\nIs using cheaper paint holding you back as an artist?\nHow to Choose a Basic Colour Palette for Acrylic Painting\nWhat are the key 5 colours to mix 90% of your paintings?\nColour Mixing Basics with Acrylic Paint (video)\nThis video is a basic introduction to matching a colour using a step by step approach\nThe 3 Tricks of Complementary Colours you can Learn from Van Gogh\nLearn how Van Gogh combined colours to create a vibrancy in his works\nAcrylic Jug Painting - Part 1 of 3\nIn this simple tutorial series of three lessons, we use Burnt Sienna, Ultramarine Blue & Titanium White to understand the principles of warm & cool tones\nGolden Heavy Body vs Open Acrylics Paints Review, Which is Best?\nThe pros and cons of standard acrylics vs OPEN acrylics, which is best?\nHow to Paint Acrylic Portraits\nThis acrylic portrait course works on 3 different colour portraits, developing your portrait skills and learning how to achieve classical looking portraits with acrylics\nBeginners Landscape Painting - Part 1 of 4\nIn this four-part tutorial series, learn how to get started with a simple seascape lesson in acrylics\nAcrylic Cherry Painting - Part 1 of 4\nIf there is one lesson that will give a beginner amazing results, this is it. In this video tutorial series of 4 lessons, learn classical glazing techniques with acrylics\nFrench Cafe Scene with Acrylics - Part 1 of 5\nIn this five-part video tutorial series, paint on board rather than canvas. We work on drawing techniques and learn the importance of your paint consistency and underpainting in these lessons\nAcrylic Painting of a Cornish Harbour Scene\nThis harbour scene tutorial is a little bit more complicated, focusing on composition and drawing, so perfect if you want a challenge!\nHow to Paint a Copper Pot in Acrylics\nIn this three-part tutorial capture the brilliant qualities of reflections in copper, using acrylic paint\nAcrylic Glazing Tutorial\nCombine a monochrome underpainting with colour glazes in this lesson, to create a luminosity in your acrylic paintings\nThe Secret to Painting Realistic Shadows in Sunlight\nDiscovering the importance of Cast Shadows in sunlight and how to capture them in paint\nDistracted by Light (how a bowl of apricots sent my schedule out the window)\nOrange and blue still life painting of apricots looking at colour mixing theory and fundamentals\nHow to Paint a Terracotta Pot Still Life with Acrylics (Free 1 hr video tutorial)\nHow to paint a little collection of terracotta pots, balancing intense orange next to the muted purples of the brick, which is then broken up by the fresh greens on the leaves.\nSimple Acrylic Still Life Tutorial - Painting Morning Sunshine\nA simple still life step-by-step study looking at glowing backlight using acrylic paint for beginners\nInspiration, Travels, Exhibition Reviews & Art History\nExhibition reviews and painting travels looking at the exhibitions with an artist’s eye\nInside the Artist's Studio, Ruben's House & the Art of Antwerp\nAn art tour of Antwerp, Belgium to visit Ruben’s studio and house, experiencing the altarpieces of Baroque artist Sir Peter Paul Rubens (1577 -1640)\nDiscovering Velázquez, The Duke & Unexpected Treasures\nDiscovering Velázquez paintings hidden in plain sight in London\nCapturing Sunlight with Sorolla (inside the Artist's Studio)\nArtist studio tour of the Spanish painter Sorolla, who Monet called ‘the master of light’\nDiscovering Zorn, the Petit Palais & Patisseries in Paris\nA retrospective exhibition in Paris of the Swedish painter Anders Zorn\nInspiration, Impressionism and the Power of Environment\nHow a change in your environment can greatly influence the style and subject of your paintings, with a step-by-step watercolour marker garden sketch\nMonet & Architecture at the National Gallery (London)\nAn exhibition review of Impressionist Claude Monet, focusing on Monet’s relationship with architecture\nStudying Holbein's Portrait Drawings: A Brief Encounter\nExhibition review of a selection of Hans Holbein portraits\nHow to Paint, Sleep (and Nearly Die) like Cézanne\nHow a visit to Cézanne’s art studio in France highlighted the power of taking action on your dreams (even if you’re a late bloomer)\nLandscape Sketching in the Highlands\nTechniques for sketching landscapes on location with pen and wash\nOn Tate, Turner & Unlikely Partnerships\nA look at the history and development of Turner’s style and influences\nSketching the Light and Landscape in Venice\nAn inspirational sketching trip through the streets and canals of Venice\nThe 3 Steps to Becoming a Better Painter, by Painting Less\nHow too many choices can cause decision fatigue and stop you progressing in your practice\nOn painting, procrastination and what might have been\nKeeping yourself on the sideline as a viewer? It doesn’t have to be this way\nTurner Adventures in Colour Exhibition\nInstagram collection from a Turner watercolour exhibition and a trip to see the skies Turner was inspired by\nThe Immersive Power of Painting (a painting truth you can learn too late)\nWhat if the process of practicing a craft was as important as the final result?\nThe Importance of Contrast in Painting\nHow learning to view your paintings as drawings can improve realism in your work\nInside Rembrandt's Studio\nA close look at the oil painting techniques used by Rembrandt, and the lighting used in his studio in Amsterdam\nDiscovering Hepworth, Abstract Sculpture & St Ives (inside the Artist’s Studio)\nBarbara Hepworth artist studio tour in St Ives and her influence on the emergence of abstract sculpture in Britain""]"	['<urn:uuid:6f0ea915-2718-4abf-9974-5c822e49eda8>', '<urn:uuid:3b2c62f2-53fd-42d4-8615-01e458258bf7>']	open-ended	direct	verbose-and-natural	distant-from-document	comparison	novice	2025-05-12T23:56:45.148498	17	99	2730
23	What's the right amount of coffee and water to use when making coffee without using hot water?	You should use a ratio of one gallon of water for every pound of coffee. For brewing at home, a single pound of coffee should be sufficient.	['I am excited today to talk a little bit about our cold brew process and how you at home can do it as easily as we do it in our shops.\nSo, what is cold brew? How is it made? And what do you need to make it at home? Cold brew is basically no different than hot brewed coffee except, as the name implies, you brew it cold. By doing that you’re going to maybe make the flavor a little bit smoother, a little bit more chocolatey, and a little bit more caramel forward as opposed to bringing out the brighter flavors or acidity you might get in a hot brew.\nThe process for doing this is pretty simple: you’re going to take some coffee, grind it on the coarsest setting you have, and then steep it for anywhere from 12 to 24 hours. What you’ll need to do this is some coffee, some water, and a filter.\nWhen producing cold brew for the shops, we generally don’t like using a dark-roasted coffee. When you use a dark roasted coffee, it brings out too much bitter-sweet and charcoaley flavors with too much intensity. When the brew method is already giving you smooth chocolatey flavors, a medium roast really suits the process better.\nAs you measure out your coffee and your water, you will want to use a ratio of one gallon of water for every pound of coffee. When producing cold brew on a mass scale, we often will make batches containing up to 35 pounds of coffee (and 35 gallons of water). However, in the video below we are only using 3.5 pounds of coffee, and, for brewing at home, as single pound should suffice.\nWith regard to the filter, when making cold brew for the shops, we use a muslin filter rather than a paper or mesh or very fine mesh filter made of stainless steel. We do this because we find that the muslin filter will give you a full flavored cup with a chocolatey taste while getting all the sediment and preventing the murkiness and grittiness the sediment can produce.\nOnce you have your coffee and water measured out, and after you have chosen your filter, we can begin making our cold brew.\nSo, to start, we will pour our coffee into our grinder and grind right on into our container using the coarsest setting we have. Next we’re going to transfer our coarsely ground coffee to our filter. After the coffee has been transferred, we’re going to add a little bit of water first then we’re going to give it a stir just so we can kind of get the coffee saturated evenly, making sure there are no dry pockets before adding the rest of our water.\nOne thing that’s really important with cold brew is to giving it some good stirs during the first 10-15 minutes as the coffee starts absorbing the water. If you don’t do any stirring, the coffee’s going to float to the top and your extraction could get a little weak. So, during the first 10-15 minutes, give it a stir. Let it sit for a couple minutes. Come back. Give it one more stir. And eventually you will see the color on top change from a dark color to that of a hazelnut-looking foam.\nAt this point we will then let our coffee steep for 12-24 hours. When producing cold brew for the shops, we don’t necessarily brew it cold, but at room temperature. Therefore our extraction usually takes about 16 hours. But, if your wish to try putting it in the fridge, you may have to go closer to 24 hours to get the flavors you’re looking for.\nAs you become more experienced making your own cold brew, there are lots of ways you can alter this method, especially with regard to the coffee and the filter you use, as well as the temperature you steep it at, and the extraction time you aim for. But these instructions and the video tutorial below should definitely get you started.\nI hope you at home have fun giving this a try and I hope your cold brew turns out great. Thank you.']	['<urn:uuid:34ecf944-8b86-4c9f-b93e-9876f6b2a175>']	factoid	direct	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-12T23:56:45.148498	17	27	703
24	What's special about the sound sampling technology used in this digital piano model that makes it comparable to prestigious concert performances?	This digital piano includes samples from Yamaha's flagship CFX concert grand piano, which was the piano of choice by the winner of the 2010 International Chopin Competition. The CFX samples provide scintillating highs and a powerful bass, representing 19 years of research and development combining traditional craftsmanship with modern engineering.	"[""View Full Description\nMusic That You feel\nTravel from your bedroom to the concert hall. The YDP S54 now includes samples from Yamaha's flagship piano - the Yamaha CFX concert grand. The CFX grand piano represents 19 years of research and development to combine traditional craftsmanship with modern day engineering. This harmonious combination enabled the engineers at Yamaha to examine every element of the piano, discovering how every detail can impact the sound.\nIn 2010, the CFX was the piano of choice by the winner of the prestigious International Chopin Competition. Since then, the CFX has gained worth recognition as one of the greatest concert grands of all time. Now you can experience this, all in the comfort of your own home. Boasting scintillating highs and a powerful bass, these CFX samples will transform your practice into a recital.\nGraded Hammer 3 Piano Action\nAs well as the faithful samples, the YDP S54 features fully-weighted keys, reproducing the touch of an acoustic piano for natural playability. The Graded Hammer 3 (GH3) 88-key piano action recreates the natural feel when touching the keys, reacting accordingly to velocity changes and providing that 'heavy feel' in the lower register. The piano action also features a three-sensor configuration which analyses and interprets the behaviour of the keyboard, providing a natural response and feel. This lets you hear every nuance of the sound, providing authentic expressive control with the synthetic ebony and ivory key tops only adding to its natural feel.\nWho said pianos had to be traditional? The Smart Pianist app offers a range of features that places you in control. The app enables you to select instrument voices, adjust various settings, record your performance, and much more. You will find yourself making music faster with this app as it gives you the freedom to this on your personal smart device.\nWant to play along with your favourite songs? Well, now you can! Smart Pianist scans the audio songs loaded in your music library, analyses the chord progressions, and then displays them for you on the screen of your smart device. It's that simple. Play along as the chords scroll by, all the while hearing the song play back through the S54's speaker system. Loading MIDI songs into the app will also allow you to follow along with digital sheet music while you play.\nStereophonic Headphone Optimizer\nA great feature of digital pianos is the ability to practice in silence using headphones. The YDP S54 has catered to this feature with the Stereophonic Optimizer. The Stereophonic Optimizer works by adjusting the spacing of the sound and the separation from the instrument, resulting in a natural and spacious surround sound quality, immersing you within the pianos natural tones. This helps to perceive the sound of the piano as coming from the body of the instrument rather than the headphones, providing a more realistic and natural playing experience.\n3 Month Flowkey Premium Offer\nYamaha and the piano tutorial app Flowkey have collaborated for a limited time offer to give you 3 months of premium learning. Simply download the Flowkey app on to your smartphone or tablet, register your instrument, and begin your subscription. The user friendly interface allows you to learn each song in both a sheet music format as well as a play-along video. Thanks to the adjustable difficulty settings, Flowkey can be used by complete novices and developed musicians alike. Premium Flowkey members have access to over 500 songs covering major hits from pop, classical, rock and more. This intuitive app can even track your playing and offer instant feedback to help improve your skills. Any Yamaha digital piano purchased between 15th July 2016 and 31st March 2021 is now eligible for three months of premium Flowkey access.\nPlease visit Flowkey's website to find out more about this exciting offer.\n- Width: 1353 mm\n- Height: 792 mm\n- With key cover open: 976 mm\n- Depth: 309 mm\n- With key cover open: 317 mm\n- With anti-fall brackets attached: 404 mm\n- Weight: 40 kg\n- Keyboard: Graded hammer (GH3) keyboard with synthetic ebony and ivory keytops\n- Number of Keys: 88\n- Touch Sensitivity: Hard/Medium/Soft/Fixed\n- Pedals: Damper/Sostenuto/Soft\n- Key Cover: Folding key cover with music rest\n- Finish: White\nFunctions and Voices\n- Tone Generator: Yamaha CFX\n- Polyphony (Max): 192\n- Number of Voices: 10\n- Effects: Reverb (four types), Intelligent Acoustic Control (IAC), Stereophonic Optimizer, Damper Resonance\n- Preset Songs: 10 Demo Songs, 50 Piano Preset Songs\n- User Recording: 1 user song with 2 tracks\n- Data Capacity: 100 KB per song (approx. 11,000 notes)\n- Compatible Data Format (Playback): SMF (format 0, format 1)\n- Compatible Data Format (Recording): SMF (format 0)\n- Metronome: Yes\n- Tempo Range: 5 - 280 bpm\n- Transpose: -6 to 0, 0 to +6\n- Tuning: 414.8 - 440.0 - 446.8 Hz\n- Internal Memory: Total maximum size approx. 900 KB (User song: One song approx. 100 KB, Loading song data from a computer: Up to 10 Songs)\n- Connectivity: Stereo headphone jack x 2; USB-to-host\n- Amplifiers: 20 W x 2\n- Speakers: 12cm x 2\n- Acoustic Optimizer: Yes\n- Power Supply: PA-300 or an equivalent recommended by Yamaha\n- Auto Power Off: Yes\n- Power Consumption: 13 W (When using PA-300C AC adapter)\n- Included Accessories: PA-300C AC adapter; song book (50 Greats for Piano)""]"	['<urn:uuid:02a9422f-12b8-4ceb-881d-6539b909b959>']	factoid	direct	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-12T23:56:45.148498	21	50	898
25	gpr55 receptor relationship autoimmune conditions immune system molecular mechanism cbd	The GPR55 receptor is linked to autoimmune conditions through its role in inflammation control and immune system regulation. Found in the brain and gastrointestinal tract, GPR55 interacts with CBD and is involved in controlling inflammation. While autoimmune conditions involve T-cells inappropriately attacking the body's healthy tissues, CBD can help modulate the immune system through GPR55, slowing down T-cell production and suppressing immune system memory, potentially reducing future autoimmune attacks.	"['Story from: CannabisNow\nIs there a Third Cannabinoid Receptor?\nWe have long known about the two cannabinoid receptors: CB1 and CB2. Now there is growing awareness of a third such receptor that was identified in 2007.\nThis receptor, GPR55, may be key to understanding a wide spectrum of therapeutic applications for cannabinoids — and especially CBD.\nThe GPR55 gene is conserved in chimpanzee, Rhesus monkey, dog, cow, mouse, rat, chicken, zebrafish, and frog.\nThe Recent History of GPR55 Receptor Research\nIt was a 2007 study published by the National Center for Biotechnology Information (NCBI) that first identified what was until then known as the “orphan receptor” GPR55 — meaning its function had not yet been determined — as a “novel cannabinoid receptor.” In the years since then, evidence has been mounting that the GPR55 receptor could explain the actual biological mechanisms for many of the benefits reported by cannabis users.\nA 2009 study published by PNAS found a role for the GPR55 receptor in regulating osteoclast function — that is to say, bone formation and healing. A 2016 study published by the NCBI found a similar role in controlling inflammation.\nMost impressive was a 2015 overview published by Frontiers in Pharmacology, which found that two orphan receptors as well as the “deorphanized” GPR55 “may be promising therapeutic targets, with diverse physiological roles,” ranging from gastrointestinal to bone disorders.\nThe Science Behind the GPR55 Receptor\nThe GPR55 receptor — the 55th in the series of G-protein-coupled receptors that also include CB1 and CB2 — is found in the brain and gastrointestinal tract. The G stands for guanine, which is a nucleotide base, meaning it is one of the so-called “building blocks” of DNA. Guanine is associated with the G proteins because of how these receptors interact with cells. The receptor “receives the chemical and sends messages to cells such as neurons,” according to Robert Sindelar, chief science officer and head of product development at BAS Research — a Berkeley, California-based licensed manufacturer of “white-label” cannabis products.\n“The endocannabinoid system has been a black box for many years, partially due to federal restrictions on research,” Sindelar told Cannabis Now. “Basically, we’re starting to find out: How does this stuff do this? People with seizures are being affected by CBD. How does this actually happen? With the new work on GPR55, scientific research is catching up with what traditional knowledge and anecdotal evidence have documented for hundreds of years.”\nAs an example, Sindelar points to Dravet syndrome: “It’s a rare disease that was basically thought to be untreatable. Many sufferers have found their only relief in taking a steady regimen of CBD. Now they’ve found the mechanism or mode of action by which CBD sends a message to something in the brain that tells a child suffering from Dravet syndrome to either have a seizure or not.”\nBecause there is a growing body of evidence around the GPR55 receptor, including the 2017 study which discovered the GPR55 receptor’s role in treating Dravet syndrome, Sindelar says there is more pressure on the academic community to continue researching the GPR55 receptor as a potential target for epilepsy treatment, especially in terms of how it interacts with CBD.\nAnd Sindelar sees these studies as ultimately having political ripples. “Research is eliminating the scientific mystery about what people see in practice, or anecdotally,” he said. “This could provide the body of evidence we need to deschedule these chemicals. In many ways, I feel it’s inevitably leading to a change in the way cannabinoids are federally classified to allow further investigation into these things. That opens [research] up to federal funding.”\n“Because of its cannabinoid sensitivity and similar tissue localization, GPR55 can explain some of the effects observed that are not mediated by the canonical cannabinoid receptors Cb1 and Cb2. To date, LPI has been described as the endogenous GPR55 ligand, but endocannabinoids AEA, 2-AG, and the agonist O-1602 can also activate it. Therefore, GPR55 is likely the first LPI: receptor described. …….\n……Additional studies to elucidate the role of endocannabinoid GPR55 ligands in GPR55 physiology and pathophysiology are also warranted, as endocannabinoids have been shown to play a role in inflammation,68 cancer,69 liver disease,70 and inflammatory disorders of the intestinal tract,71 to name a few. In conclusion, GPR55 has emerged as a promising candidate for the development of novel anticancer therapeutic strategies.”', 'While advancements in science have enabled a greater understanding of our health, getting to the root cause of a chronic disease can be challenging. Autoimmune conditions are an area of medicine that remain largely misunderstood. Presently, there are more than 80 registered autoimmune disorders, affecting various parts of the body. More conditions may also turn out to be autoimmune related.\nAutoimmunity (AI) is an ""attack on self"", where the immune system gets triggered and thinks that the body\'s healthy tissues are invaders. Our immune system is mediated by beta cells which produce antibodies to foreign invaders. Beta cells produce antibodies to prevent infection or fend off bacterial and viral pathogens. T-cells are in charge of cell-mediated immunity are derived from the thymus and other immune tissues. They attack foreign invaders in the body. In an autoimmune response, T-cells take action as if the body\'s own cells were foreign in order to bring the body back into homeostasis. This self-attack is known as ""molecular mimicry"" and is the root of any autoimmune disease.\nThe location of the autoimmune attack will vary based on the condition. For example, if there is autoimmunity in the joints, rheumatoid arthritis may result. If molecular mimicry occurs in the thyroid, it may lead to Hashimoto\'s. For skin disorders like psoriasis, the dermal layer is the target. Autoimmune conditions may attack more than one part of the body at the same time. Lupus can manifest in the skin, digestive system, joints, and the brain.\nThe reason why the self-attack switch is turned on is relatively unknown. Common consensus is that those with autoimmunity have a genetic predisposition for these types of conditions. Then a particular event like an infection, parasite, leaky gut syndrome, or a traumatic experience sets off the autoimmune reaction.\nThe triangle of autoimmune triggers. Gut dysbiosis and genetic and environmental factors play mayor roles in the development of autoimmune diseases.\nAI can remain latent in the body, resulting in ailments that have not been properly pinpointed. Autoimmune related situations can linger in the body unexposed for many years, which can result in digestive complaints and various associated problems. Frequently, autoimmune diseases are misdiagnosed because their symptoms can mimic other ailments.\nThere has been a dramatic increase in the prevalence of autoimmune diseases since World War 2. Autoimmune conditions more commonly affect women than men. The National Institute of Health estimates that 23.5 million people in the USA have an autoimmune disease, while cancer affects 13 million in the country. The true number of those affected by autoimmunity is likely higher, due to misdiagnosis and general lack of understanding about the complexity of AI related conditions.\nConventional medicine ideology believes that the immune system cannot be controlled and once the autoimmunity switch has been triggered, it is impossible to revert back to the body\'s normal state. However, many alternative medical professionals feel that autoimmune conditions may be reversed or greatly resolved. In typical treatment protocols, patients are not given information about dietary changes and are generally told that pharmaceutical medications are required to get better.\nConventional treatments for autoimmune disorders\nCurrently, prescription medication for autoimmune diseases aim to ""turn off"" the immune system all together. Immunosuppressive drugs are synthetically created antibodies which attack the autoimmune antibodies. Immunosuppressive drugs can create many potential side effects. These medications may make someone more susceptible to infection, and may lead to the development of cancer. According to Dr. Bonni Goldstein, a cannabis friendly doctor in Southern California, many patients who try immunosuppressive medications end up discontinuing them due to unfavorable side effects. In her experience, patients seek holistic treatment options for autoimmune diseases.\nSteroids are a commonly prescribed medication for autoimmunity to lower inflammation and suppress the immune system. They are meant to be taken on the short term. Julie Holland, a pro-cannabis psychiatrist based in New York, says that the goal shouldn\'t be to be globally immunosuppressed, ""With steroids, you are sweeping the dirt under the carpet. You\'re not getting to the root cause at all. It\'s as if you\'re hitting mute on the alarm, but the alarm is going off for a reason."" Steroids may decrease blood supply to various parts of the body, and create fat deposits in the face or other areas. If someone has autoimmunity and chronic pain, steroids may not help address the root of the discomfort.\nIn general, immunosuppressive therapy is incredibly expensive and not always effective. The aim should be to modulate the immune system and bring it back into balance, not to turn it off completely.\nWhat options exist for someone with an autoimmune condition if they do not wish to use traditional medications? Holistic approaches for autoimmune conditions are to decrease inflammation, repair the digestive tract, and regulate the immune system. This includes getting rid of stressors and sensitivities on the broad spectrum, including environmental, food, chemical, and others. Managing autoimmune disease requires dietary and lifestyle changes, which have been reported to help reverse these conditions.\nSomeone with an autoimmune disease may consider cannabinoid therapies for their ability to decrease inflammation, modulate the immune system, and help to bring the system back into balance.\nImmune system modulation\nThe immune system is a delicate balancing act and deeper investigation is needed to better understand the mechanisms of how it works. Herbs and foods that work to modulate the immune system are ideal for someone dealing with an autoimmune condition. Cannabis therapy and dietary changes seem to be safer, cheaper, and possibly more effective for combating autoimmune conditions than pharmaceutical medications.\nCannabis and other adaptogenic herbs are known to be immune modulating. They act as a regulating tool: they can bring an over or under-reacting immune system back into balance. However, the difference between ""immune modulating"" and ""immune boosting"" can be tricky to decipher. It is generally felt that someone with autoimmunity would not want to take anything which boosts the immune system, but this is a point of contention among practitioners.\nAccording to Kevin Spelman, faculty member in Botanical Medicine at National University of Natural Medicine, the definition of immune modulatory is the biphasic effect of an herbal medicine. ""Immunomodulatory herbs offer a very beneficial strategy to treat autoimmune conditions. The category of immunomodulation rests on biphasic activity. If someone\'s immune response is overly vigilant, there would be a down regulation of immune response. If someone\'s immune response is \'deficient\' there would be an increase of immune activity."" Spelman explained that a patient\'s therapeutic response is dependent on how their individual molecular environment is behaving.\nCannabis is a unique biphasic botanical remedy that can bring the system back into balance in numerous regards. Based on current research, cannabis therapies may provide benefit for autoimmune disease in three basic ways: modulation of the immune system, decreasing general inflammation, and helping to assist the digestive system. Cannabis medicine may also treat symptoms of specific autoimmune diseases like ALS, rheumatoid arthritis, ulcerative colitis and Crohn\'s, fibromyalgia, Huntington disease, multiple sclerosis, and others. The plant may decrease chronic pain, inflammation, and spasms associated with some of these conditions. There have been few specific investigations on cannabinoid treatment for AI, due to federal prohibition on human clinical trials. However, extensive studies in test-tubes and in animals have reported the anti-inflammatory benefits of cannabinoids for specific AI conditions like multiple sclerosis and rheumatoid arthritis.\nInvestigation has demonstrated that CB2 receptors regulate many complex pathways of the immune system. Preclinical studies show that triggering CB2 receptors can suppress immune response, which can be beneficial for those suffering with AI. CB2 can also inhibit production of pro-inflammatory cytokines and enhance anti-inflammatory cytokines, which helps to restore a balanced state. However, there are conflicting reports as research has shown that CB2 activation, under certain conditions, may aggravate inflammation.\nThere has been some preclinical investigation focusing on the role of particular cannabinoids in AI disease models. CBD has been found to modulate the immune system instead of suppressing it. Cannabidiol also slows down T-cell production and suppresses immune system memory, meaning that CBD could cut down on the likelihood of future autoimmune attacks. CBD has also been found to increase the expression of genes that deal with oxidative stress, which may reduce cell damage from autoimmune attacks. As for THC, this cannabinoid is immunosuppressive only at very high doses. In low doses can be helpful as an analgesic and anti-inflammatory. Its ability to activate CB2 receptors may down regulate T cell function and decrease the harmful effects of immune cells.\nThe role of cannabis terpenes for autoimmunity deserve further investigation as well. The terpene beta-caryophyllene, found in certain strains of cannabis and black pepper, is known to decrease inflammation through its ability to stimulate the CB2 receptor. Myrcene, another terpene, also has antiinflammatory properties.\nBased on preclinical evidence, cannabinoids may help bring the system back into homeostasis, protect against damage from AI attacks within the body, slow down overactive T-cell production, and prevent the immune system from being triggered.\nInflammation is the root cause of many illnesses, and autoimmunity is no exception. Extensive research has been performed on the anti-inflammatory properties of THC, CBD, and other cannabis components. If inflammation response is regulated, there will be less likelihood of an autoimmune attack. More investigation is needed to examine the particular role of cannabinoids for autoimmune disorders.\nCannabinoid therapy has the potential to assist those with autoimmune conditions by decreasing systemic inflammation, with little to no side effects. Preclinical evidence has found that cannabinoids can attenuate autoimmune inflammatory response. In an animal model of multiple sclerosis, CBD decreased the gene transcription that promoted inflammation.\nDespite a scarcity of specific human based studies, patients with autoimmune disorders have been able to improve their situation by integrating cannabis medicine into their lifestyle. Dr. Bonni Goldstein has seen a number of patients with lupus and rheumatoid arthritis wean off pharmaceuticals and control their symptoms with cannabis, dietary changes, exercise, and stress reduction. Goldstein gave the example of a young patient with ankylosing spondylitis. Goldstein reported that after two months on cannabis the patient discontinued three of the pharmaceuticals, experienced a significant improvement in her pain symptoms, and was ""able to participate in her life again"". Dr. Goldstein encourages patients to try various CBD/THC ratios, and to experiment with raw cannabinoids such as THCA and CBDA. Trial and error is required to find what works best for an individual\'s unique situation.\nAdditional approaches one can take to lower inflammation:\n- A nutrient rich diet: a whole food diet, devoid of processed foods, will naturally decrease inflammation.\n- Exercise: active movement increases circulation of anti-inflammatory cytokines from the skeletal muscles.\n- Sufficient sleep: your body naturally lowers inflammation while you get shut eye.\n- Herbal medicine: turmeric, ginger, cinnamon, nettle, and various medicinal mushrooms can help decrease inflammation throughout the body.\n- Probiotics & Prebiotics: these supplements promote healthy bacteria in the gut, which lowers inflammation and promotes healthy immune response.\nWhile autoimmunity may be a complex and challenging situation in need of deeper investigation, there are holistic approaches one can take to manage their condition. Coping with an autoimmune disease may feel burdensome, but it can also be an opportunity to get back in touch with your body. Aim to treat it in the best way possible. Nature can be your guide.\nCampbell, Andrew W. ""Autoimmunity and the Gut"". Autoimmune Diseases. 2014\nGoldstein, Bonni. Entrevista personal. 24 de julio de 2017\nHolland, Julie. Entrevista personal. 6 de junio de 2017\nIgnatowska-Jankowska B, et all. ""Cannabidiol-induced lymphopenia does not involve NKT and NK cells"". J Physiol Pharmacol. 2009\nJacob, Aglaée. ""Gut Health and Autoimmune Disease — Research Suggests Digestive Abnormalities May Be the Underlying Cause"". Today\'s Dietitian. 2013\nKozela, E, et all. ""Pathways and gene networks mediating the regulatory effects of cannabidiol, a nonpsychoactive cannabinoid, in autoimmune T cells"" J Neuroinflammation. 2016\nMalfait, et al. ""The nonpsychoactive cannabis constituent cannabidiol is an oral anti-arthritic therapeutic in murine collagen-induced arthritis"". Proc Natl Acad Sci USA. 2000\nRothbard, Gary. ""Steroids: The Good, The Bad, The Worrisome For Autoimmune"". Autoimmune Mom. 2012\nSantamaria, Pere.""Cytokines and Chemokines in Autoimmune Disease: An Overview"". Madame Curie Bioscience Database\nYeshurun, M, et al. ""Cannabidiol for the Prevention of Graft-versus-Host-Disease after Allogeneic Hematopoietic Cell Transplantation: Results of a Phase II Study"" Biol Blood Marrow Transplant. 2015']"	['<urn:uuid:3d9b607a-12a7-4a41-9b6e-d040068ab752>', '<urn:uuid:76df9f75-5474-47b6-830b-067fb3279cc2>']	factoid	direct	long-search-query	similar-to-document	three-doc	expert	2025-05-12T23:56:45.148498	10	69	2767
26	san francisco earthquake 1906 jack london wife camera photos how many found recent	Twelve thousand photographs taken by Jack London and his wife were recently rediscovered in a vault. These included images from the 1906 San Francisco earthquake and other pictures taken during London's career overseas.	"['By Mary Lou Beatty\n""Photographs are, of course, artifacts,"" the social critic Susan Sontag once wrote. ""But their appeal is that they also seem, in a world littered with photographic relics, to have the status of found objects--unpremeditated slices of the world. Thus, they trade simultaneously on the prestige of art and the magic of the real . . . ""\nIn this issue of Humanities we look at the interaction of words and pictures. One instance involves the writer Jack London, who was jolted awake at his ranch on an April day one hundred years ago when an earthquake shook San Francisco. He and his wife Charmian grabbed their cameras and headed for the city to record the devastation.\n""Within an hour after the earthquake shock, the smoke of San Francisco\'s burning was a lurid tower visible a hundred miles away,"" London wrote in Collier\'s magazine. ""And for three days and nights this lurid tower swayed in the sky, reddening the sun, darkening the day, and filling the land with smoke."" Accompanying the piece were sixteen pages of photographs by London and his wife.\nSome of those San Francisco images and others pictures taken by the Londons were rediscovered recently--twelve thousand of them. ""They were in a vault,"" says professor Jeanne Campbell Reesman of the University of Texas, San Antonio, ""and people weren\'t allowed to access them because they\'re fragile."" She and a colleague, Sara S. Hodson, curator of literary manuscripts at the Huntington Library, are selecting 120 for a book that follows London\'s career overseas, from Britain\'s slums to the Russo-Japanese War.\nIn the 1920s, the world of the still picture expanded with the arrival on the scene of the newsreel. Rather than just seeing a static image, viewers could see figures in the news walking and talking as history was made.\n""Newsreels offered the American movie-going audience a glimpse of the important political, cultural, and natural events shaping the world around them,"" says Benjamin Singleton, news film coordinator at the University of South Carolina Newsfilm Library. Three quarters of the country\'s movie houses showed newsreels with each week\'s feature film. They captured historic moments: Lindbergh taking off for Paris, the Japanese attacking Pearl Harbor. They provided coverage of major events until the 1950s when television began to dominate the scene.\nThousands of images from the past have been preserved with NEH support. Benjamin Singleton\'s university maintains the Fox Movietone News Collection; the Denver Library cataloged 600,000 photographs on the opening of the West; the Oakland Museum of California documented the Depression-era pictures of Dorothea Lange; the New York Public Library preserved 175,000 vaudeville and theater images from the early 1900s.\nMany of the projects have put the images into databases that can be searched via the Internet. Making images more readily accessible is one of the benefits of the new technology. ""I get excited about these efforts to digitize information retrospectively,"" Vinton Cerf of Google tells NEH Chairman Bruce Cole. ""And we\'re not limited to textual material. We can be recording sound, we can be recording images and so on."" Where technology as a whole will take us is unpredictable, but Cerf takes an expansive view.\n""The edge of the Net is essentially open to anything you want to try. So for me it\'s not just the unleashing of the content, but it is the unleashing of human creativity to try things out.""']"	['<urn:uuid:a016afde-6be6-4db4-a920-231a5be4f1da>']	factoid	with-premise	long-search-query	similar-to-document	single-doc	novice	2025-05-12T23:56:45.148498	13	33	566
27	compare habitat depth atlantic sharpnose blacknose shark	The Atlantic Sharpnose Shark is commonly found off sandy beaches, in estuaries and enclosed bays and sounds, mostly over mud and sand bottoms, with a seasonal inshore-offshore migration pattern. The Blacknose shark inhabits depths of 0-64m, particularly in coral reefs and sand flats/scrub, though it is frequently encountered in shallow waters (surface to 10m) in the Bahamas.	"[""|Scientific Name:||Rhizoprionodon terraenovae|\nSqualus terraenovae Richardson, 1836\n|Red List Category & Criteria:||Least Concern ver 3.1|\n|Reviewer(s):||Musick, J.A. & Fowler, S.L. (Shark Red List Authority)|\nThis assessment is based on the information published in the 2005 shark status survey (Fowler et al. 2005).\nThe Atlantic Sharpnose Shark (Rhizoprionodon terraenovae) is a very abundant, small coastal shark found in warm temperate and tropical waters of the western North Atlantic. It is caught in both commercial and recreational fisheries, and in incidental fisheries, mainly as bycatch in gillnets and shrimp trawl fisheries. A fast maturing, relatively fecund species with moderate population growth rates and short generation times. The juvenile and adult stages seem to affect population growth rates almost equally. The species is assessed as Least Concern because of its abundance and life history characteristics, which make it less susceptible to removals than many other species of sharks.\n|Previously published Red List assessments:|\n|Range Description:||The Atlantic Sharpnose Shark occurs in the western North Atlantic, ranging as far north as New Brunswick, Canada, to the Yucatan Peninsula in the south, including the Gulf of Mexico.|\nNative:Canada; Mexico; United States (Alabama, Connecticut, Delaware, Florida, Georgia, Louisiana, Maine, Maryland, Massachusetts, Mississippi, New Hampshire, New Jersey, North Carolina, Rhode Island, South Carolina, Texas, Virginia)\n|FAO Marine Fishing Areas:|\nAtlantic – western central; Atlantic – northwest\n|Range Map:||Click here to open the map viewer and explore range.|\n|Population:||The Atlantic Sharpnose Shark is an abundant, small coastal shark of warm temperate and tropical waters (Compagno 1984b).|\n|Current Population Trend:||Unknown|\n|Habitat and Ecology:||This species is commonly found off sandy beaches and in estuaries and enclosed bays and sounds, mostly over mud and sand bottoms. There is a seasonal inshore-offshore migration, with individuals moving to deeper offshore waters in winter (Compagno 1984).|\nThe Atlantic Sharpnose Shark is a small, coastal carcharhinid that rarely exceeds 110 cm total length (TL). The life history of this species in the US Gulf of Mexico has been fairly well described. In this area, female seldom exceeds 107 cm TL and males rarely surpass 105 cm TL. Females generally mature between 85-90 cm TL (or 2.8-3.9 years of age) and males mature between 80-85 cm TL (or 2.4-3.5 years of age) (Parsons 1985, Branstetter 1987). Thus, both males and females reach maturity at about 80% of their maximum size. Maximum observed ages in two separate studies were 6+ years and 7+ years for both sexes combined, whereas theoretical longevities derived from von Bertalanffy growth curves predict that this species should reach at least 10 years (Cortés 2000a). Recent tag-recapture information has shown that this species can live to at least nine years (J. Carlson pers. comm.).\nThe Atlantic Sharpnose Shark is a placental viviparous species that reproduces annually. Gestation period has been reported to last from 10-12 months; litter size is generally 4-6, ranging from 1-7. Offspring are born at 30-35 cm TL or about 30% of maximum adult size. There is a positive correlation between maternal size and litter size and evidence of a trade-off between the number and size of offspring, i.e. there is a negative correlation between litter size and offspring size (Parsons 1983). Mating occurs between mid-May and mid-July and parturition generally takes place mostly in June. The sex ratio at birth is 1:1.\nThis species uses enclosed bays and sounds as nursery areas. Despite the abundance of this shark, its diet has not been very well described quantitatively. It is dominated by teleost fishes (66%) and crustaceans (32%), but also includes some molluscs (Branstetter 1981, Gelsleichter et al. 1999, Cortés unpubl. data).\nCortés (1995) extensively studied the demography of the Atlantic Sharpnose Shark in the Gulf of Mexico and found that the life history characteristics of this species did not allow it to withstand the levels of fishing mortality it was thought to be subjected to. Recent demographic studies of this species by Cortés (in press) that incorporate uncertainty in estimates of vital rates indicate that the Atlantic Sharpnose Shark has moderate population growth rates (λ) (mean=1.056 yr-1; 95% confidence interval = 0.970-1.195 yr-1) and short generation times (A) (mean=4.9 years, 95% CI = 4.0-5.4 years). Elasticity analysis (which examines the proportional sensitivity of λ to a proportional change in a vital rate) also showed that λ is more sensitive to juvenile survival and adult survival than to fertility (which includes survival to age-1). Annual survivorship values used in Cortés (2002) were estimated through five indirect life history methods and ranged from 55-79%.\nIn the United States, Atlantic Sharpnose Sharks are caught in commercial and recreational fisheries and also as bycatch. Recent commercial landings of this species indicate that it accounted for over one-third of all landings of small coastal sharks in the south-eastern United States during 1996-1999. In 1998 and 1999, over 90% of small coastal sharks were landed in Florida's east coast, the majority of which were caught with drift gillnet gear. Commercial landings of Atlantic Sharpnose Sharks averaged 61,000 individuals from 1995-1999 (Cortés 2000b).\nRecreational catch estimates from several surveys indicate that about 72,000 Atlantic Sharpnose Sharks were caught annually from 1981-1998, ranging from a minimum of about 18,000 sharks in 1985 to a peak of about 137,000 sharks caught in 1991 (Cortés 2000b). Additionally, bycatch estimates from the shrimp trawl fishery operating in the Gulf of Mexico indicate that about 1.75 million individuals were caught annually from 1972-1999 (Cortés unpubl.).\nThe Atlantic Sharpnose Shark is also heavily exploited in Mexico. A monitoring programme conducted in the Gulf of Mexico between November 1993 and December 1994 showed that it is the most important species in the artisanal fisheries, accounting for 46% of the landings numerically, especially in Campeche where 46% of the total is landed (Castillo et al. 1998). By month, the highest landings corresponded to May and October. This species is caught mostly with gillnets. Elsewhere this species has been documented as bycatch in Canada.\nNursery areas for this species are located inshore and adults frequent inshore waters, making this species vulnerable to exploitation and human-induced habitat degradation.\nIn the United States, the Atlantic Sharpnose Shark is classified as a small coastal species in the Federal Management Plan (FMP) for Sharks of the Atlantic Ocean, Gulf of Mexico and Caribbean, together with the Blacknose Shark (Carcarhinus acronotus), the Finetooth Shark (C. isodon), the Bonnethead Sharl (Sphyrna tiburo), the Smalltail Shark (C. porosus), the Atlantic Angel Shark (Squatina dumeril) and the Caribbean Sharpnose Shark (Rhizoprionodon porosus) (NMFS 1993). The small coastal shark complex is not currently considered to be overfished, but there are fishing regulations in effect, which include an annual commercial quota of 1,760 t dressed weight, and a recreational daily bag limit of two sharks per vessel per trip, with an additional allowance of two Atlantic Sharpnose Sharks per person per trip. A more recent FMP (NMFS 1999) called for more stringent measures, including a reduction of the annual commercial quota for small coastal sharks to 359 t and making the Atlantic angelshark, Caribbean sharpnose and smalltail sharks prohibited species.\nThis is a very abundant species, with early age at maturity, short lifespan and generation time, and moderately high litter size and population growth rates, capable of withstanding a higher level of removals than many other species of sharks. It is thus considered to be of low risk of extinction because of its life history and population characteristics.\nBranstetter, S. 1981. Biological notes on the sharks of the north-central Gulf of Mexico. Contributions in Marine Science 24: 13-34.\nBranstetter, S. 1987. Age and growth of newborn sharks held in laboratory aquaria, with comments on the life history of the Atlantic sharpnose shark, Rhizoprionodon terraenovae. Copeia 1987(2): 291–300.\nCastillo-Géniz, J.L., Márquez-Farias, J.F. Rodriguez de la Cruz, M.C. Cortés, E. and Cid del Prado, A. 1998. The Mexican artisanal shark fishery in the Gulf of Mexico: towards a regulated fishery. Marine and Freshwater Research 49: 611–620.\nCompagno, L.J.V. 1984. Sharks of the World. An annotated and illustrated catalogue of shark species to date. Part II (Carcharhiniformes). FAO Fisheries Synopsis, FAO, Rome.\nCortés, E. 1995. Demographic analysis of the Atlantic sharknose sharks Rhizopriondon terraenovae in the Gulf of Mexico. Fishery Bulletin 93(1): 57–66.\nCortés, E. 2000a. Shark Evaluation Annual Report. Sustainable Fisheries Division Contribution SFD-00.\nCortés, E. 2000b. Life history patterns and correlations in sharks. Reviews in Fisheries Science 8(4): 299–344.\nCortés, E. 2002. Incorporating uncertainty into demographic modelling: application to shark populations and their conservation. Conservation Biology 16: 1048–1062.\nFowler, S.L., Cavanagh, R.D., Camhi, M., Burgess, G.H., Cailliet, G.M., Fordham, S.V., Simpfendorfer, C.A. and Musick, J.A. (comps and eds). 2005. Sharks, Rays and Chimaeras: The Status of the Chondrichthyan Fishes. Status Survey. pp. x + 461. IUCN/SSC Shark Specialist Group, IUCN, Gland, Switzerland and Cambridge, UK.\nGelsleichter, J., Musick, J.A. and Nichols, S. 1999. Food habits of the smooth dogfish, Mustelus canis, dusky shark, Carcharinus obscurus, Atlantic sharpnose shark, Rhizoprionodon terraenovae, and the sand tiger, Carcharias taurus, from the northwest Atlantic Ocean. Environmental Biology of Fishes 54: 205–217.\nIUCN. 2009. IUCN Red List of Threatened Species (ver. 2009.2). Available at: www.iucnredlist.org. (Accessed: 3 November 2009).\nIUCN SSC Shark Specialist Group. Specialist Group website. Available at: http://www.iucnssg.org/.\nNMFS (National Marine Fisheries Service). 1993. Fishery Management Plan for sharks of the Atlantic Ocean. US Department of Commerce, NOAA/NMFS, Silver Spring, USA.\nNMFS (National Marine Fisheries Service). 1999. Fishery Management Plan for Atlantic tunas, swordfishes, and sharks. US Deptartment of Commerce, NOAA/NMFS, Silver Spring, USA.\nParsons, G.R. 1983. The reproductive biology of the Atlantic sharpnose shark, Rhizoprionodon terraenovae (Richardson). Fishery Bulletin 81: 61–74.\nParsons, G.R. 1985. Growth and age estimation of the Atlantic sharpnose shark, Rhizoprionodon terraenovae: a comparison of techniques. Copeia 1985: 80–85.\n|Citation:||Cortés, E. 2009. Rhizoprionodon terraenovae. The IUCN Red List of Threatened Species 2009: e.T39382A10225086.Downloaded on 24 October 2016.|\n|Feedback:||If you see any errors or have any questions or suggestions on what is shown on this page, please provide us with feedback so that we can correct or extend the information provided|"", 'Small but stocky. Black/dark spot on tip of snout; distinct in young animals but often an indistinct smudge or absent in large adults. Pectoral fins relatively small. First dorsal origin level with free rear tip of pectoral fin. Second dorsal origin level with anal fin origin. No interdorsal ridge. Dorsal coloration pale yellowish-grey or light olive-grey. Body looks more bronzy in bright sunlight. Second dorsal, anal fin, and lower caudal lobe often dusky. Ventral surface white or cream coloured.\nMaximum length 141cm (Jose Castro). Size at maturity approx 100cm. Size at birth 31-50cm.\nA warm water species inhabiting coral reefs and sand flats/scrub.\n0-64m. Often cited as occurring between 18-64m, but in the Bahamas I have consistently encountered blacknose sharks in shallow water (surface to 10m) where they are abundant.\nThe blacknose shark is a tropical coastal species from the western Atlantic, Gulf of Mexico, and Caribbean Sea. It has been recorded from Virginia to Southern Brazil but rarely strays north of Wreck Island in North Carolina.\nThe blacknose shark is fished in large numbers in parts of its range. It is caught in both the large and small coastal directed shark fisheries along the US Atlantic coast and is probably a target and bycatch in coastal fisheries throughout the rest of its range. It suffers considerable mortality as bycatch in US shrimp trawl fisheries causing the stock to be currently overfished. Shrimp trawl fisheries are intense in inshore waters throughout the Gulf of Mexico and on the Caribbean coast of South America. No information is available on catches or population trends for Blacknose Shark in this area, but it is possible that it is also declining there. However, analyses of data from northern and northeastern Brazil indicate that there is no evidence of population decline there, and large, mature adults are still present in catches. While the US population has declined, most of the decline has occurred since 2000 (less than one generation) and management actions will be required to rebuild the stock. This species is assessed as Near Threatened globally, reflecting continuing declines observed in the US Atlantic and apparently stable populations off northern Brazil. No species-specific data or information is currently available from the Caribbean Sea, and assessment of catches and population trends in this area is a priority. With further information from this region, the species may qualify for a threatened category (VU A2bd+A4bd). Population trends should continue to be monitored and efforts should be made to collect data throughout the rest of the species’ South American range.\nCitations and References\nMorgan, M., Carlson, J., Kyne, P.M. & Lessa, R. 2009. Carcharhinus acronotus. The IUCN Red List of Threatened Species 2009: e.T161378A5410167. https://dx.doi.org/10.2305/IUCN.UK.2009-2.RLTS.T161378A5410167.en. Downloaded on 22 September 2020.\nReproductive cycle of the blacknose shark Carcharhinus acronotus in the Gulf of Mexico\nJ. A. Sulikowski, W. B. Driggers III, T. S. Ford, R. K. Boonstra, J. K. Carlson\nFirst published: 02 February 2007\nA viviparous species with yolk-sac placenta. 1-8 pups per litter.\nIn South Carolina, mating takes place in early to mid June (Driggers 2002). Gestation in S. Carolina is 10-11 months. 9-10 months in the Gulf of Mexico (Sulikowski et al. 2007).\nDiet consists mainly of small bony fishes.\nBlacknose sharks undergo seasonal migrations related to water temperature. They are know to perform agonistic displays (fins down, back hunched) when threatened.\nReaction to divers\nShy around scuba divers but surprisingly bold in baited situations.\nNear South Bimini Island in The Bahamas, blacknose sharks are often encountered during Caribbean reef shark feeds at Triangle Rocks and Southern stingray feeds at Gun Cay. The depth at both sites is less than 6m. These dives are only offered by land-based operators because most liveaboards are too large to approach those dive sites.\nAndros Island is reputedly another good place in The Bahamas to find blacknose sharks; moving in and out of the mangroves with the tide. However, I did not encounter any when I was there.\nFurther south in the Caribbean in Sint Maarten, the reef shark feed organised by Dive Safaris (local operator) used to attract a handful of blacknose sharks but they became less frequent over time. It is unclear if they were fished out or if competition with the attending Caribbean Reef Sharks became too great.']"	['<urn:uuid:7722e458-86ed-44a9-87db-55f4f9500b1d>', '<urn:uuid:ea42e043-2c41-48f2-a691-28125965f1c7>']	open-ended	with-premise	short-search-query	distant-from-document	comparison	expert	2025-05-12T23:56:45.148498	7	57	2365
28	Why have fish populations in our oceans become depleted when people used to think they would never run out?	Living aquatic resources, once believed to be virtually inexhaustible, have become overexploited. This is due to complex interactions between biotic resources and their environments, ecosystem services, management interventions and their political determinants, and the socio-economic interplay of fishers, consumers, and market forces.	['Complexity Science and Evolution Unit (Ulf Dieckmann)\nSystems governing human wellbeing and ecosystem services are complex, involving nonlinear feedbacks, nonequilibrium dynamics, multiple scales, emergent phenomena, tipping points, and systemic risks. The structure and function of such complex systems are driven by self-organization and adaptation, with complexity science describing how self-organization shapes the interaction structure among system agents and evolutionary theory describing how adaptation shapes the adaptable characteristics of system agents. While social and biological forms of adaptation operate through fundamentally different mechanisms – social learning of memes and biological inheritance of genes –, their mathematical descriptions have in common essential features rooted in replicator dynamics. Taken together, complexity science and evolution provide the most powerful toolbox we have available for understanding and managing the challenges posed by complexity in social and biological systems.\nThe Complexity Science and Evolution Unit analyzes the dynamics of complex adaptive systems. Since this necessitates a pluralistic spectrum of approaches, methods are selected, combined, and developed as problems require, drawing on complexity science, evolution, socio-economics, ecology, game theory, theoretical physics, applied mathematics, and computer science. Key questions addressed include how to promote prosocial behavior, how to understand and manage biodiversity formation and loss, and how to utilize living resources sustainably. The unit’s specific research areas are outlined below.\nSocial dilemmas and governance of common goods. Social dilemmas are posing pervasive challenges to the functioning of societies, occurring whenever goods important for collective wellbeing are under the threat of selfish actors. Overcoming such dilemmas requires promoting cooperative action through governance solutions based on diverse mechanisms such as positive and negative incentives, appropriate rules and regulations, conditional cooperation and participation, as well as competition and movement among social groups. Building on and combining these mechanisms, we explore how to design governance solutions that are effective and efficient.\nBiodiversity dynamics and speciation. Even though biodiversity has become recognized as a key determinant of ecosystem services, biodiversity dynamics are only partially understood. In the ongoing quest to comprehend how species form, mounting attention is being devoted to parapatric speciation (advancing despite incipient species not being geographically isolated), ecological speciation (driven by selection pressures originating from biotic interactions), and adaptive speciation (occurring when evolving populations escape from being trapped at a fitness minimum). We investigate how ecological and evolutionary forces drive biodiversity formation and loss.\nSustainable fisheries management and fishing-induced evolution. Once believed to be virtually inexhaustible, living aquatic resources have become overexploited. Promoting sustainable fisheries from an ecological perspective requires understanding the complex adaptive systems involving biotic resources and their environments, ecosystem services, management interventions and their political determinants, and the socio-economic interplay of fishers, consumers, and market forces. Promoting sustainable fisheries from an evolutionary perspective requires recognizing how fishing imposes changes not only on the numbers of fish but also on their functional traits. We analyze fishing from both angles.\nSystemic risk and network dynamics. Systemic risk describes the likelihood of cascading failures in networks and occurs in a wide range of domains including disease dynamics, ecosystems, financial networks, supply chains, power grids, and transportation networks. A typical example is the spread of contagious diseases percolating across social contact networks: even when health systems are well geared to treating individual infections, they can be overwhelmed by infection cascades spiraling out of control. Across domains, we study how to assess, model, predict, and mitigate such dynamics.\nEvolutionary community ecology and eco-evolutionary vegetation dynamics. The structure and function of all ecosystems have been shaped by evolution. Evolutionary community models based on functional traits explain how ecological settings determine, in turn, biotic environments, selection pressures, coevolutionary dynamics, and thus, changes to the ecological settings. We apply this approach to diverse ecosystems including food webs and to vegetation dynamics in particular, where it enables us to predict from first principles how the compositions of plant biomes around the globe follow from regional environmental conditions.\nAdaptive dynamics theory and models. Adaptive dynamics theory describes the evolutionary and coevolutionary dynamics of phenotypic traits driven by natural selection in realistic social and ecological settings. Moving beyond classical evolutionary frameworks postulating fitness functions, adaptive dynamics theory stands out by deriving them from the underlying population dynamics. Having contributed to the foundations and applications of adaptive dynamics theory since its inception, we develop innovative theory and models on topics including species packing, function-valued evolution, evolutionary bifurcations, environmental-feedback dimension, and evolution of pattern formation.\nSimplifying spatial complexity. Spatial structures are ubiquitous in nature, and neither ecological nor evolutionary dynamics can be accurately understood without accounting for them. Nowadays, this is often accomplished by brute-force numerical simulations, while corresponding analytical methods have fallen behind needs. New avenues for overcoming this shortcoming and simplifying spatial complexity are opened up by realizing that classical models of well-mixed populations are special cases in a broader theoretical framework that uses as state variables the spatial densities of singlets, pairs, triplets, etc. of individuals. We research how truncating such moment hierarchies at the triplet level yields powerful approximations.\nDisease ecology and evolution. Humans, animals, and plants live under the constant threat of contracting contagious diseases. Pathogens frequently jump between species and incessantly adapt their functional traits, facilitating the transmission of variant pathogens. This is creating moving targets for individual and collective efforts at disease protection, as evidenced by the ongoing Covid-19 pandemic. The success of public health interventions thus crucially depends on accurately forecasting not only pathogen spread but also pathogen evolution. Strengthening the young field of evolutionary epidemiology, we devise new methods for predicting changes in the virulence of pathogens and the resistance of their hosts.']	['<urn:uuid:1a854c44-8cb4-41b6-85aa-4ea20543cd96>']	factoid	direct	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-12T23:56:45.148498	19	42	922
29	genetic predisposition disease prevention steps	When someone has a genetic predisposition to specific diseases, several preventative steps can be taken. First, researching family medical history can identify potential health issues like heart disease or high blood pressure that may develop with age. Working with a doctor to develop a specialized plan based on family medical history is crucial. Preventative care practices should be established as early as possible, and preemptive screening for genetic conditions like cancer can help diagnose diseases in early stages.	['There are a variety of ways to develop a healthy lifestyle and manage your medical issues.\nBy working with a trusted health care providers, you can create goals for your health over time whether you are trying to prevent the onset of an illness or trying to manage a current health issue.\nCombining preventative care and disease management practices is the most effective way to stay healthy.\nPreventative care is one important aspect of maintaining health, and includes understanding your genetic predisposition for certain conditions.\nThe symptoms of some diseases and conditions can also be reduced with proper care.\nDiabetes, high blood pressure, allergies and high cholesterol are common chronic conditions that you can manage, or even eliminate, over time, and making important lifestyle changes is a key factor in minimizing the symptoms of these medical issues.\nTo learn more about how you can manage common chronic health issues and how to prevent further issues from developing, continue reading below.\nSome people are prone to specific diseases and conditions due to their family medical history. For example, if certain medical conditions run in your family, you might be more likely to develop these ailments.\nLuckily, making lifestyle changes and implementing preventative care practices can reduce your risk of developing conditions affected by genetics.\nResearching your family medical history can shed light on what health issues could arise as you age, such as heart disease or high blood pressure.\nUsing this information, you can work with your doctor to develop a specialized plan based on your family medical history.\nIf you have a genetic predisposition for a certain condition, preventative care practices should be established as soon as possible.\nPreemptive screening for genetic conditions, such as cancer, also increase your chances of diagnosing a disease in the early stages.\nFor more information on how your family medical history can help you build a preventative care plan, you can read this article.\nDiabetes is a medical condition that affects your body’s ability to convert sugar to energy using insulin. This disease involves having an extreme decrease in bodily insulin production, which is why leaving this disease untreated can result in a wide variety of additional health problems.\nManaging diabetes helps promote longer life expectancy and prevent heart attacks, strokes and other serious conditions. To manage this disease properly, you and your health care provider can create a treatment plan that fits your specific needs.\nMaking lifestyle changes to your diet and exercise routine is one of the best ways to manage diabetes symptoms outside of taking medication. Eating healthier, more balanced meals can decrease the symptoms associated with the disease and help stabilize your insulin levels.\nAvoiding foods high in sugar is also an important aspect of combating diabetes through your diet. Additionally, regular exercise and making routine doctor visits can contribute to improvements in your health.\nImplementing a regular exercise routine can help decrease blood sugar levels and increase your overall energy. It is also crucial to keep track of your blood sugar over time and monitor your health by establishing periodic medical appointments.\nCombining proper medical care, a healthy diet and regular exercise can help reduce symptoms and reduce the amount of medication you need to take.\nHigh blood pressure, also called hypertension, is a common condition that occurs when the force of blood flowing through arteries is too high. Unmanaged hypertension can result in heart attacks, strokes and other serious medical issues.\nUnhealthy habits such as not exercising, eating fatty and sugary foods and smoking contribute to high blood pressure.\nWhile high blood pressure can be hereditary, daily habits are often the main reason for developing the disease. In both cases, lifestyle changes can prevent and even reverse symptoms.\nImplementing healthy eating habits and controlling your weight is an important aspect in managing hypertension. Certain types of foods and drinks contribute to increased blood pressure, so cutting unhealthy items out of your diet reduces your chances of developing this condition.\nRegular exercise will also lower your blood pressure and improve your overall health.\nManaging high blood pressure is possible with dedication and regular care, such as visiting your health care provider often to monitor the changes in your body over time.\nYou can also routinely check your blood pressure at home and personally track your progress.\nThe symptoms of allergic reactions can range from mild to life threatening. A large variety of allergens exist that may cause negative effects to your body, such as:\nWhether you have annoying seasonal allergies or an extreme allergic condition, you can take steps to combat this health issue and manage your allergies.\nBeing proactive in your allergy management may reduce the severity of symptoms. Although outside allergens are harder to combat than indoor or food allergens, understanding your condition and establishing a preventative routine can help manage allergic reactions.\nFor example, individuals who are affected by pollen can wear a protective mask or preemptively take medication.\nCommunicating with your health care provider is another way to learn about methods to prevent and reduce allergy symptoms.\nYour doctor can provide important medical information, prescribe medications for your specific symptoms and track allergy conditions over time, as some allergies develop later in life.\nCholesterol consists of two main components: LDL and HDL. LDL is the bad cholesterol, which can eventually create fat deposits in your arteries and can cause major health issues.\nHDL is deemed as the good cholesterol and helps lowers LDL levels. Monitoring cholesterol levels by visiting your health care provider and taking appropriate action can help you live a healthier and longer life.\nHigh cholesterol levels increase the potential of heart disease, which can lead to a heart attack or stroke. If high cholesterol is common in your family history, steps can be taken to minimize the presence of this condition through preventative care methods.\nHowever, the main causes of high cholesterol are lack of exercise and an unhealthy diet.\nManaging your diet is perhaps the most important aspect in lowering your cholesterol levels, as foods high in fat and sugar contribute to artery fat build-up, resulting in reduced blood flow throughout the body.\nDeveloping a healthy routine emphasizing portion control and more nutritional meal options can drastically reduce the risks of high cholesterol.']	['<urn:uuid:e6fd551f-f8f6-4ec7-b58b-d7ff62c5033b>']	open-ended	direct	short-search-query	similar-to-document	single-doc	expert	2025-05-12T23:56:45.148498	5	78	1042
30	whats difference julius caesar augustus power	Julius Caesar and Augustus had different paths to and forms of power. Julius Caesar declared himself Dictator in 48 BC but was assassinated. In contrast, Augustus, after becoming Caesar's heir and defeating his rivals in the Second Triumvirate, took a more subtle approach to power. While he restored the outward appearance of the Roman Republic with power vested in the Senate, he actually retained autocratic control as a military dictator. Unlike Caesar, Augustus rejected monarchical titles, calling himself Princeps Civitatis ('First Citizen of the State') and created a new constitutional framework called the Principate. The Senate granted him various powers for life, including supreme military command and the powers of tribune and censor, establishing a more stable and long-lasting form of rule than Caesar's dictatorship.	"['DIGGING DEEP – 8 by Abidan Paul Shah\n- Alexander the Great and the spread of Greek culture.\n- Koine Greek\nOne constant factor during the writing of the New Testament was Rome. Roman history can be divided into three parts:\n- ROMAN KINGDOM – early stages of Rome. (753 BC – 509 BC) Not very significant for our discussion\n- ROMAN REPUBLIC – still an early stage of our discussion (509 BC – 44 BC)\n- ROMAN EMPIRE – (44 BC – 6th century AD)\nRome had great admiration for Ancient Greece. Unlike Persia and Greek, Rome knew how to make people Romans. Persian Empire tried to absorb the conquered people but they still did not create unity. Greece tried but not everybody could be a citizen of Greece. But Rome knew how to truly absorb the surrounding cultures – both people and gods.\nSome key aspects of the Roman Empire:\n- The Emperor\n- In 48 BC Julius Caesar declared himself the Dictator. After he was assassinated, his adopted son, Octavius through a series of battles and events became the first emperor of the Roman Empire. Some of those battles might be familiar to you (Mark Anthony and Cleopatra).\n- In 27 BC the Senate gave him the title of Caesar Augustus and they became just an advisory council to the Emperor. His rule brought the PAX ROMANA. Rome’s first institutionalized police force and fire fighting force. He built roads throughout Italy.\n- The Imperial cult was typically instituted after the death of the emperor. Domitian (AD 81-96) was the first to institute it in his own lifetime. He demanded to be addressed as “dominus et deus” = “Lord and god. This was a major problem to the Christians. (See I Peter 3:12-17; and Revelation 2:13 – “Satan’s throne” in Pergamum)\n- Main administrative units; 2 kinds: Senatorial and imperial\n- Senatorial provinces were ruled by governors who were appointed by the Senate. They were no threat to peace. For e.g. Sicily, Spain, Pamphylia, Africa, Macedonia, Asia, Crete, Cyprus, etc.\n- Imperial provinces were also ruled by governors who were appointed by the emperor. They were on the borders of the empire and had a threat of revolt. For e.g. Syria, Gaul, Galatia, and Britain.\n- Client Kingdoms\n- Not directly administered by Rome but still under Roman rule.\n- They were independent rulers who could appoint their own officials and implement their own policies.\n- Palestine was ruled by Herod from 40BC – 4 BC (Judea, Samaria, Galilee, Peraea, and Idumea)\n- After his death, his territory was divided into 3 parts: Judea, Idumea, and Samaria to Archelaus; North of Galilee to Philip; and Galilee and Peraea to Antipas.\n- Archelaus was removed after 10 years and Idumea and Samaria went under Roman procurators (Pilate, Felix, and Festus).\n- Later Herod Agrippa (Herod’s grandson) was a client king over North of Galilee, Galilee, Perea, and Judea. (Acts 12) His son Herod II (acts 25-26).\n- Colonies and Free Cities\n- Self governing settlements of Roman Citizens\n- For e.g. Philippi and Corinth (locals who were granted Roman citizenship)\n- Roman Citizenship\n- People could have dual citizenship like Paul (Tarsus and Rome).\n- It ensured loyalty.\n- Roman Law\n- Basis of Roman Authority was Legal. It all depended on RIGHT and JURISDICTION. Magistrates had complete power. Measure of all things was the LAW. (Greek – man; East – king; Jewish people – God).\n- It was not perfect – THERE WAS CORRUPTION. The further from Rome, the more the corruption.\n- The power over life and death (ius gladii) was always retained by Governors.\n- Roman Taxation\n- Poll tax was on every adult, including women and slaves.\n- An amount was set but the local governors could set their amount.\n- Pax Romana\n- Common Currency – Greek coins (lepta, drachmai,) and Roman coins (assaria, quadrans, denarius). Also temple currency was in shekels\n- Matthew 10:18; 11:8; 17:25; 18:23; 22:2; 25:40\n- John 18:31\n- Acts 16:19-40\n- Galatians 3:28\n- Acts 24:5', 'Text #9686""Augustus"", in .\nAugustus (Latin: Imperātor Caesar Dīvī Fīlius Augustus; 23 September 63 BC – 19 August 14 AD) was the founder of the Roman Empire and its first Emperor, ruling from 27 BC until his death in AD 14.\nHe was born Gaius Octavius into an old and wealthy equestrian branch of the plebeian Octavii family. His maternal great-uncle Julius Caesar was assassinated in 44 BC, and Octavius was named in Caesar’s will as his adopted son and heir. He, Mark Antony, and Marcus Lepidus formed the Second Triumvirate to defeat the assassins of Caesar. Following their victory at Philippi, the Triumvirate divided the Roman Republic among themselves and ruled as military dictators.[note 4] The Triumvirate was eventually torn apart under the competing ambitions of its members. Lepidus was driven into exile and stripped of his position, and Antony committed suicide following his defeat at the Battle of Actium by Octavian in 31 BC.\nAfter the demise of the Second Triumvirate, Augustus restored the outward facade of the free Republic, with governmental power vested in the Roman Senate, the executive magistrates, and the legislative assemblies. In reality, however, he retained his autocratic power over the Republic as a military dictator. By law, Augustus held a collection of powers granted to him for life by the Senate, including supreme military command, and those of tribune and censor. It took several years for Augustus to develop the framework within which a formally republican state could be led under his sole rule. He rejected monarchical titles, and instead called himself Princeps Civitatis (“First Citizen of the State”). The resulting constitutional framework became known as the Principate, the first phase of the Roman Empire.\nThe reign of Augustus initiated an era of relative peace known as the Pax Romana (The Roman Peace). The Roman world was largely free from large-scale conflict for more than two centuries, despite continuous wars of imperial expansion on the Empire’s frontiers and one year-long civil war over the imperial succession. Augustus dramatically enlarged the Empire, annexing Egypt, Dalmatia, Pannonia, Noricum, and Raetia; expanding possessions in Africa; expanding into Germania; and completing the conquest of Hispania.\nBeyond the frontiers, he secured the Empire with a buffer region of client states and made peace with the Parthian Empire through diplomacy. He reformed the Roman system of taxation, developed networks of roads with an official courier system, established a standing army, established the Praetorian Guard, created official police and fire-fighting services for Rome, and rebuilt much of the city during his reign.\nAugustus died in AD 14 at the age of 75. He may have died from natural causes, although there were unconfirmed rumors that his wife Livia poisoned him. He was succeeded as Emperor by his adopted son (also stepson and former son-in-law) Tiberius.\nAugustus was known by many names throughout his life:\nAt birth, he was named Gaius Octavius after his biological father. Historians typically refer to him simply as Octavius (or Octavian) between his birth in 63 until his adoption by Julius Caesar in 44 BC (after Julius Caesar’s death).\nUpon his adoption, he took Caesar’s name and became Gaius Julius Caesar Octavianus in accordance with Roman adoption naming standards. He quickly dropped “Octavianus” from his name, and his contemporaries typically referred to him as “Caesar” during this period; historians, however, refer to him as Octavian between 44 BC and 27 BC.\nIn 42 BC, Octavian began the Temple of Divus Iulius or Temple of the Comet Star and added Divi Filius (Son of the Divine) to his name in order to strengthen his political ties to Caesar’s former soldiers by following the deification of Caesar, becoming Gaius Julius Caesar Divi Filius.\nIn 38 BC, Octavian replaced his praenomen “Gaius” and nomen “Julius” with Imperator, the title by which troops hailed their leader after military success, officially becoming Imperator Caesar Divi Filius.\nIn 27 BC, following his defeat of Mark Antony and Cleopatra, the Roman Senate voted new titles for him, officially becoming Imperator Caesar Divi Filius Augustus. It is the events of 27 BC from which he obtained his traditional name of Augustus, which historians use in reference to him from 27 BC until his death in AD 14.\nWhile his paternal family was from the town of Velletri, approximately 40 kilometres (25 mi) from Rome, Augustus was born in the city of Rome on 23 September 63 BC. He was born at Ox Head, a small property on the Palatine Hill, very close to the Roman Forum. He was given the name Gaius Octavius Thurinus, his cognomen possibly commemorating his father’s victory at Thurii over a rebellious band of slaves.\nDue to the crowded nature of Rome at the time, Octavius was taken to his father’s home village at Velletri to be raised. Octavius only mentions his father’s equestrian family briefly in his memoirs. His paternal great-grandfather Gaius Octavius was a military tribune in Sicily during the Second Punic War. His grandfather had served in several local political offices. His father, also named Gaius Octavius, had been governor of Macedonia. His mother, Atia, was the niece of Julius Caesar.\nIn 59 BC, when he was four years old, his father died. His mother married a former governor of Syria, Lucius Marcius Philippus. Philippus claimed descent from Alexander the Great, and was elected consul in 56 BC. Philippus never had much of an interest in young Octavius. Because of this, Octavius was raised by his grandmother (and Julius Caesar’s sister), Julia Caesaris.\nIn 52 or 51 BC, Julia Caesaris died. Octavius delivered the funeral oration for his grandmother. From this point, his mother and stepfather took a more active role in raising him. He donned the toga virilis four years later, and was elected to the College of Pontiffs in 47 BC. The following year he was put in charge of the Greek games that were staged in honor of the Temple of Venus Genetrix, built by Julius Caesar. According to Nicolaus of Damascus, Octavius wished to join Caesar’s staff for his campaign in Africa, but gave way when his mother protested. In 46 BC, she consented for him to join Caesar in Hispania, where he planned to fight the forces of Pompey, Caesar’s late enemy, but Octavius fell ill and was unable to travel.\nWhen he had recovered, he sailed to the front, but was shipwrecked; after coming ashore with a handful of companions, he crossed hostile territory to Caesar’s camp, which impressed his great-uncle considerably. Velleius Paterculus reports that after that time, Caesar allowed the young man to share his carriage. When back in Rome, Caesar deposited a new will with the Vestal Virgins, naming Octavius as the prime beneficiary.\nOctavius was studying and undergoing military training in Apollonia, Illyria, when Julius Caesar was killed on the Ides of March (15 March) 44 BC. He rejected the advice of some army officers to take refuge with the troops in Macedonia and sailed to Italy to ascertain whether he had any potential political fortunes or security. Caesar had no living legitimate children under Roman law, and so had adopted Octavius, his grand-nephew, making him his primary heir. Mark Antony later charged that Octavian had earned his adoption by Caesar through sexual favours, though Suetonius describes Antony’s accusation as political slander. After landing at Lupiae near Brundisium, Octavius learned the contents of Caesar’s will, and only then did he decide to become Caesar’s political heir as well as heir to two-thirds of his estate.\nUpon his adoption, Octavius assumed his great-uncle’s name Gaius Julius Caesar. Roman citizens adopted into a new family usually retained their old nomen in cognomen form (e.g., Octavianus for one who had been an Octavius, Aemilianus for one who had been an Aemilius, etc.). However, though some of his contemporaries did, there is no evidence that Octavius ever himself officially used the name Octavianus, as it would have made his modest origins too obvious. Historians usually refer to the new Caesar as Octavian during the time between his adoption and his assumption of the name Augustus in 27 BC in order to avoid confusing the dead dictator with his heir.\nCassius Dio’s Roman History: Books 45–56, English translation\nLife of Augustus by Nicolaus of Damascus, English translation\nSuetonius’ biography of Augustus, Latin text with English translation\nThe Res Gestae Divi Augusti (The Deeds of Augustus, his own account: complete Latin and Greek texts with facing English translation)\nAllen, William Sidney (1978) . Vox Latina—a Guide to the Pronunciation of Classical Latin (2nd ed.). Cambridge University Press. ISBN 0-521-37936-9.\nAndo, Clifford, Imperial ideology and provincial loyalty in the Roman Empire, University of California Press, 2000.\nBivar, A. D. H. (1983). “The Political History of Iran Under the Arsacids”, in The Cambridge History of Iran (Vol 3:1), 21–99. Edited by Ehsan Yarshater. London, New York, New Rochelle, Melbourne, and Sydney: Cambridge University Press. ISBN 978-0-521-20092-9.\nBlackburn, Bonnie and Holford-Strevens, Leofranc. (1999). The Oxford Companion to the Year. Oxford University Press. Reprinted with corrections 2003.\nBourne, Ella. “Augustus as a Letter-Writer”, Transactions and Proceedings of the American Philological Association (Volume 49, 1918): 53–66.\nBowersock, G. W. (1990). “The Pontificate of Augustus”. In Kurt A. Raaflaub and Mark Toher (eds.). Between Republic and Empire: Interpretations of Augustus and his Principate. Berkeley: University of California Press. pp. 380–394. ISBN 978-0-520-08447-6.\nBrosius, Maria. (2006). The Persians: An Introduction. London & New York: Routledge. ISBN 978-0-415-32089-4 (hbk).\nBunson, Matthew. (1994). Encyclopedia of the Roman Empire. New York: Facts on File Inc. ISBN 978-0-8160-3182-5\nChisholm, Kitty and John Ferguson. (1981). Rome: The Augustan Age; A Source Book. Oxford: Oxford University Press, in association with the Open University Press. ISBN 978-0-19-872108-6\nDio, Cassius. (1987) The Roman History: The Reign of Augustus. Translated by Ian Scott-Kilvert. London: Penguin Books. ISBN 978-0-14-044448-3.\nDavies, Mark; Swain, Hilary; Davies, Mark Everson, Aspects of Roman history, 82 BC-AD 14: a source-based approach, Taylor & Francis e-Library, 2010.\nEck, Werner; translated by Deborah Lucas Schneider; new material by Sarolta A. Takács. (2003) The Age of Augustus. Oxford: Blackwell Publishing (hardcover, ISBN 978-0-631-22957-5; paperback, ISBN 978-0-631-22958-2).\nEder, Walter. (2005). “Augustus and the Power of Tradition”, in The Cambridge Companion to the Age of Augustus (Cambridge Companions to the Ancient World), ed. Karl Galinsky, 13–32. Cambridge, MA; New York: Cambridge University Press (hardcover, ISBN 978-0-521-80796-8; paperback, ISBN 978-0-521-00393-3).\nEveritt, Anthony (2006) Augustus: The Life of Rome’s First Emperor. Random House Books. ISBN 1-4000-6128-8.\nGreen, Peter (1990). Alexander to Actium: The Historical Evolution of the Hellenistic Age. Hellenistic Culture and Society. Berkeley, CA; Los Angeles; London: University of California Press. ISBN 0-520-05611-6.\nGruen, Erich S. (2005). “Augustus and the Making of the Principate”, in The Cambridge Companion to the Age of Augustus (Cambridge Companions to the Ancient World), ed. Karl Galinsky, 33–51. Cambridge, MA; New York: Cambridge University Press (hardcover, ISBN 978-0-521-80796-8; paperback, ISBN 978-0-521-00393-3).\nHolland, Richard, Augustus, Godfather of Europe, Sutton Publishing, 2005.\nKelsall, Malcolm. “Augustus and Pope”, The Huntington Library Quarterly (Volume 39, Number 2, 1976): 117–131.\nMackay, Christopher S. (2004). Ancient Rome: A Military and Political History. Cambridge University Press. ISBN 978-0-521-80918-4.\nRaaflaub, Kurt A.; Toher, Mark, Between republic and empire: interpretations of Augustus and his principate, University of California Press, 1993.\nRowell, Henry Thompson. (1962). The Centers of Civilization Series: Volume 5; Rome in the Augustan Age. Norman: University of Oklahoma Press. ISBN 978-0-8061-0956-5\nScott, Kenneth. “The Political Propaganda of 44–30 B.C.” Memoirs of the American Academy in Rome, Vol. 11, (1933), pp. 7–49.\nScullard, H. H. (1982) . From the Gracchi to Nero: A History of Rome from 133 B.C. to A.D. 68 (5th ed.). London; New York: Routledge. ISBN 978-0-415-02527-0.\nSuetonius, Gaius Tranquillus (2013) . Thayer, Bill, ed. The Lives of the Twelve Caesars. J. C. Rolfe, trans. University of Chicago. Original publisher Loeb Classical Library.\nSuetonius, Gaius Tranquillus (1931). Lives of the Twelve Caesars. New York: Modern Library.\nShaw-Smith, R. “A Letter from Augustus to Tiberius”, Greece & Rome (Volume 18, Number 2, 1971): 213–214.\nShotter, D. C. A. “Tiberius and the Spirit of Augustus”, Greece & Rome (Volume 13, Number 2, 1966): 207–212.\nSmith, R. R. R., “The Public Image of Licinius I: Portrait Sculpture and Imperial Ideology in the Early Fourth Century”, The Journal of Roman Studies, Vol. 87, (1997), pp. 170–202, JSTOR\nSouthern, Pat. (1998). Augustus. London: Routledge. ISBN 978-0-415-16631-7.\nStarr, Chester G., Jr. “The Perfect Democracy of the Roman Empire”, The American Historical Review (Volume 58, Number 1, 1952): 1–16.\nSyme, Ronald (1939). The Roman Revolution. Oxford: Oxford University Press. ISBN 0-19-280320-4.\nWalker, Susan, and Burnett, Andrew, The Image of Augustus, 1981, British Museum Publications, ISBN 0-7141-1270-4\nWells, Colin Michael, The Roman Empire, Harvard University Press, 2004.']"	['<urn:uuid:ddaf22dc-adcd-40a7-97db-12a40a75b775>', '<urn:uuid:b0fa9fc8-6634-4ff0-9b7e-ec92cc460daf>']	open-ended	with-premise	short-search-query	distant-from-document	comparison	novice	2025-05-12T23:56:45.148498	6	125	2786
31	looking for modern artificial limb care options and payment systems worldwide explain	For care options, biodesigns has developed advanced non-surgical prosthetic technology called HiFi Interface, which is available globally through licensed Orthotic and Prosthetic facilities, including several NHS facilities in other countries. This technology focuses on improved comfort and connection between the device and user through specialized compression techniques. Regarding payment systems, in Australia, the NDIS provides comprehensive funding through three support budgets: Core Supports for everyday items, Capacity Building Supports for clinical services, and Capital Supports for the prosthetic devices themselves. The NDIS system allows participants to choose their preferred provider and manage their funds either through agency management, plan management, or self-management.	['WESTLAKE VILLAGE, Calif., Dec. 19th, 2020 – Southern California-based biodesigns, inc., the leader in non-surgical human interface development and technology, is pleased to announce another patent for their innovative High-Fidelity™ (HiFiTM) Interface technology. This latest patent, Method of Manufacturing Prosthetic Socket Interface (US10,878,137), complements their interface technology patent portfolio including Methods for Bone Stabilization, (US10,123,888, US10,702,404), Methods for Use of Compression Stabilized Prosthetic Socket Interface, (US8,323,353), Method, System, and Tools for Affixing Compression Stabilized Prosthetic Socket Interface, (US8,656,918), Adaptable Socket System, Method and Kit (US9,283,093, US10,369,027, EP2914221B1, CA2,889,918), System and Method for Engaging Target with Artificial Limb Equipment (CN106913407B), and Adjustable Pod System, Method and External Member (CN104884005B).\nRandall Alley, biodesigns’ CEO, Chief Prosthetist, and Head of User-Interface Technology, has discovered a revolutionary approach for attaching items, equipment, tools and technology non-surgically to the body. The core of the patented and patents-pending HiFi™ Osseostabilizing™ Human Device Interface (HDI) technology is its ability to improve worn device performance and control by syncing the interface more effectively and efficiently to skeletal motion. By surrounding the underlying bone with an alternating array of compression, users experience improved connectivity, a heightened sense of proprioception, and a higher level of device embodiment, whether wearing a prosthesis, exoskeleton, or other wearable technologies.\n“When I traveled the world for nearly 15 years fitting complex prosthetic systems, I continually witnessed poor outcomes and high rejection rates caused by the Standard of Care (SOC) sockets being provided. Patients’ biggest complaints were discomfort and feeling disconnected from their prosthesis. It was then I decided to dedicate my career to improving the human device interface by focusing more on interface biomechanics to achieve improved comfort, increased user feedback, enhanced performance, and ultimately greater device acceptance,” stated Alley. “Today, I am pleased to see the HiFi™ interface technology expand into other industries. Our goal is simple – device embodiment so we can be one step closer to seamless human-device integration.”\nTo make the technology more accessible to patients globally, biodesigns licenses the HiFi™ Prosthetic Interface technology to other Orthotic and Prosthetic (O&P) facilities in the U.S. and abroad, including several NHS (National Health Services) facilities who are interested in improving their outcomes for upper and lower limb prosthetic wearers. Additional programs include a license to their exoskeleton interface technology as well as a license to their recreational consumer interface products, including exolimb™ which is scheduled to launch in 2021.\nSouthern California-based biodesigns, inc. is a technology-driven facility specializing in the most advanced patient care, research and product development in non-surgical Human Device Interfaces. In prosthetics, it is reestablishing a connection that has been lost; with the military, it is enhancing mission-critical performance and reducing injury; and in consumer wearables it is improving the way individuals interact with tech, tools, and gear. biodesigns’ mission is to create the universal interface standard in Orthotics & Prosthetics (O&P), Exoskeletons, Orthopedics, and consumer wearables. biodesigns’ intellectual property portfolio is managed by Fish IP Law LLP, a premier intellectual property law firm.\nFor more information visit www.biodesigns.com', 'National Disability Insurance Scheme\nCongratulations on taking the first few steps in your NDIS journey! Like with everything new, understanding the NDIS can seem a little overwhelming at first, however we hope that with the following information you can feel better equipped with the knowledge you require to transfer your prosthetic service funding to the NDIS.\nIf you are a person with an amputation or limb loss, and you meet the NDIS’ access requirements, you can become a ‘Participant’ in the scheme.\nProMotion Prosthetics is a ‘Registered NDIS Provider’ and currently treats NDIS Participants for both upper and lower limb amputations or limb loss. If you’ve previously been treated under the Victorian (or other State’s) artificial limb program at a Public Department and are interested in transferring to the NDIS, then read on.\nThe NDIS is now fully rolled out in Victoria, including Metro Melbourne. So, if you are thinking about registering with the NDIS, or perhaps you already have and want to know what to do next, here are some resources for you to read, ahead of accessing your plan, funds and prosthetic treatment under the NDIS.\nThe main steps you will need to take are:\n- Register with NDIS\nIf you visit the Am I eligible page, you will find an NDIS checklist to see if you are eligible.\nIf you meet the criteria and you would like to become a participant, call the NDIA on 1800 800 110 or go in person to your Local NDIA office and ask to make an Access Request.\nYou will be required to provide evidence of your disability verified by a medical practitioner, for example your GP.\nIf you make your Access Request over the phone, you can email or post copies of your existing information, including letter or reports to one of the follow:\n- email: NAT@ndis.gov.au\n- Post to: GPO Box 700, Canberra ACT 2601, or\n- drop it in to your nearest NDIS office\nFor more information as a Participant under the NDIS you can visit the NDIS website.\n- Have your Planning Meeting (with a planner at the NDIS)\nPreparing for your planning meeting\nThe NDIS website has some important information to read in preparation for your planning meeting. You can access their website here.\nLimbs 4 Life has also produced the Amputee Guide to the NDIS, which is extremely useful in preparing for your Planning Meeting. Limbs 4 Life also has a checklist you can print off in preparation for your Planning Meeting.\nYou must also bring along any relevant reports or assessments to your Planning Meeting. It helps the NDIS planner to understand the types of supports you need.\nIt would be preferable to meet with you prior to you having your NDIS Planning Meeting so we can discuss your prosthetic needs. To make a ‘pre-Planning Meeting’ appointment, please contact the office on 03 9532 5098.\nAttending a Planning Meeting to create your plan\nAttending a Planning Meeting, either in person, or over the phone, is the best way for NDIS to gather all your information, to develop the best plan for you.\nDuring your Planning Meeting, make sure you discuss the goals/activities/tasks you want to achieve with your Local Area Coordinator (LAC) or NDIA planner.\nGoals/activities/tasks are a really important part of your NDIS plan and we will ask you what you would like to achieve. It could be a goal to use public transport independently; a goal to help build your life skills so you can become more independent, or a goal to assist with family or work duties.\nThe purpose of a Planning Meeting\nThe Planning Meeting would allow you to highlight any short-term goals or any unmet needs in your current life. If your goals/activities/tasks are medium to long-term, your planner can break them down into short-term goals and help you take ‘smaller steps’ towards achieving those bigger goals.\n- Plan approved\nReceiving your approved NDIS plan\nYour LAC or NDIA planner will talk to you about how long it will take to get your approved NDIS plan and the steps you need to take next.\nThe NDIA must approve your NDIS plan initially, then once it is approved, your LAC or NDIA planner will give it to you in person, post or via the MyPlace Portal.\nThere are three types of support budgets that may be funded in your NDIS plan.\n- Core Supports budget\nCore Supports help you with everyday activities, your current disability-related needs and to work towards your goals. Your Core Supports budget is the most flexible, and can be used for low cost (off-the-shelf) consumables such as stump socks, ointments, cosmetic stockings etc.\n- Capacity Building Supports budget\nCapacity Building Supports help build your independence and skills to help you reach your long-term goals. Funding can only be used to purchase approved individual supports that fall within that Capacity Building category.\nAs your prosthetic provider, we would access funds within your Capacity Building budget under the ‘Improved Daily Living’ category – which covers our clinical time for the “assessment, training or therapy to help increase your skills, independence and community participation”.\n- Capital Supports budget\nCapital Supports include higher-cost pieces of assistive technology, equipment and home or vehicle modifications, and funding for one-off purchases you may need.\nThe Capital Supports budget has two support categories: Assistive Technology and Home Modifications. Assistive Technology category is where we would access funds for your prosthetic devices – “This includes equipment items for mobility, personal care, communication and recreational inclusion such as wheelchairs or vehicle modifications”.\nUsing your plan\nWhen you have an approved NDIS plan, you need to understand the different support budgets (see above), who can help you start using your plan, and how your plan is managed.\nThere are 3 ways you can manage the funds in your plan, which should be explained to you during your Planning Meeting, so that you can elect for each Support Budget:\n- Agency Managed\nThe participant has nominated the NDIA to manage the funding for supports provided. After providing those supports, the provider will claim payment for those supports directly from the NDIA via the Provider portal.\n- Plan Managed\nThe funding for any of the supports provided is managed by a Plan Nominee. After providing those supports, the provider will send the participant’s Nominee an invoice for those supports for the participant’s Nominee to pay.\n- Self Managed\nThe participant has chosen to self-manage the funding for NDIS supports provided. After providing these supports, the provider will send the participant an invoice for the participant to pay. The participant manages the funds via the MyPlace portal.\nRemember to speak with your LAC or planner about how best to manage the funds in your plan.\n- AT quote to be submitted\nNDIS will always require a Quote to be submitted by us, for the AT (Prosthetic device) funds to be added to your Capital Supports budget.\nThe quote(s) will be generated following a full assessment; which will take about an hour to go over your goals, your current prostheses and highlight your prosthetic needs in the future. We may collect Outcome Measures at this appointment to help us generate a prescription that best suits your goals.\nAt the time of submitting your Prosthetic AT request paperwork, including your quotes to the NDIA we will request payment under your Capacity Building support budget for our clinical time (including assessment, prescription, AT request paperwork and quotes).\n- AT quotes approved\nOnce the AT quote(s) are approved, you will be notified by the NDIA. During the waiting period for funding to be added to your support budget, you may contact the NDIS or your LAC for updates on its progress.\nWe have found that the NDIS encourages self-advocacy and while we are happy to follow things up on your behalf, the NDIS responds best when contacted directly by the participant.\nRemember, you can also add ‘consent’ for ProMotion Prosthetics in your plan, so that we can contact the NDIA directly on your behalf. Speak to your LAC about this during your Planning Meeting.\n- Prosthetic treatment commences\nOnce the quote(s) have been approved and the funds added to your Capital (AT) support budget, we can commence the Prosthetic treatment.\nYour plan will have funds allocated for the remaining months of your (12 month) plan.\nOnce any work has been provided, we will submit a payment request for that work and provide an invoice to you, your plan manager or the agency (depending on how your plan is being managed).\nThings to know:\n- Your ‘plan’ being approved does not always mean you have funds allocated for your prosthetic service. This requires a quote from us to be submitted and be approved before those funds can be added to your plan\n- The AT quotes can take months to be approved (depending on the costs required)\n- It would be really useful to book in to see us for an appointment prior to having your Planning Meeting with NDIS, and you can contact our office on 03 9532 5098 to arrange an appointment\n- If you have already had your Planning Meeting and have your paperwork, that’s ok too. Call our office on 03 9532 5098 to arrange an appointment for us to talk through your prosthetic service needs\nThe Limbs 4 Life website has excellent information to help guide you through your NDIS journey; from registering all the way through to preparing for your Planning Meeting. You can access their website here.\nHere are some answers that may help guide you through the queries you may first have when you are considering registering with the NDIS:\nBut I already receive my prosthetic treatment at a Public Department, what does this mean for me?\nYou may currently be receiving your prosthetic treatment under a public department, funded by the Government’s artificial limb program, but once you become registered with NDIS you can choose to receive your prosthetic treatment with us at ProMotion Prosthetics.\nWe would be happy to help facilitate the transfer of your Prosthetic treatment, contact us on 03 9532 5098 to discuss your needs.\nHow will the NDIS work for me?\n- NDIS Providers (ProMotion Prosthetics) are registered with the NDIA to deliver a support or product to the participant of the NDIS (you).\n- You have choice and control over the providers you wish to engage with to deliver the supports in your plan.\n- After you are registered, you will be able to choose which Prosthetic provider suits your needs and goals best, and a plan meeting will be arranged between you and a representative from the agency.\n- It is ideal that you make contact with us prior to this meeting, so you are best prepared for the meeting that will be the point by which your plan will be developed and your prosthetic supports related to.\n- You will receive an individualised plan that identifies the outcomes you wish to achieve, the disability supports that will be funded by the NDIS, and other supports you require.\n- Your plan will last for 12 months, and can cover multiple prostheses for you to achieve all your life, family, work and hobby goals.\nWhat happens if you disagree with what’s in your plan?\nYou have the right to ask for an internal review of your plan by the NDIA.\nYour LAC or NDIA planner will explain how to do this and can put you in touch with advocates who can help you with this process.\nRequesting a review\nA request for internal review of a decision must be made within three months of receiving notice of the decision from the NDIA.\nIf you’re not happy with the internal review, you can apply for a review by the Administrative Appeals Tribunal (AAT), which exists outside the NDIA.\nIf you have any questions, have registered, or are thinking of registering with the NDIS, get in touch with us today on 03 9532 5098 to discuss your needs.\nProMotion Prosthetics Provider Registration #: 4050001505']	['<urn:uuid:a30200e9-7698-4510-895a-be038b65973a>', '<urn:uuid:aacc316c-faaa-478b-9f37-2bc070e1ffdc>']	open-ended	with-premise	long-search-query	distant-from-document	multi-aspect	novice	2025-05-12T23:56:45.148498	12	102	2511
32	Do magicians and philosophers think about illusions similarly?	Both fields approach illusions, but differently. Magicians use psychological techniques, misdirection, and cognitive biases to create illusions through careful manipulation and deception. Meanwhile, philosophers like Raymond Smullyan, who was both a logician and magician, explored illusions through logical puzzles and philosophical problems, particularly in works examining truth, deception, and paradoxes through scenarios involving knights who always tell truth and knaves who always lie.	"['||This article includes a list of references, but its sources remain unclear because it has insufficient inline citations. (February 2008)|\n|Raymond Merrill Smullyan|\nMay 25, 1919 |\nFar Rockaway, New York\n|Occupation||mathematician, logician, philosopher, pianist and magician|\nBorn in Far Rockaway, New York, his first career (like Persi Diaconis a generation later) was stage magic. He then earned a BSc from the University of Chicago in 1955 and his Ph.D. from Princeton University in 1959. He is one of many logicians to have studied under Alonzo Church.\nBorn in Far Rockaway, New York, he showed musical talent, winning a gold medal in a piano competition when he was aged 12. The following year, his family moved to Manhattan and he attended Theodore Roosevelt High School in The Bronx as this school offered courses suited to his musical talents, but he left to study on his own as the school did not offer similar courses in mathematics.\nHe attended several colleges, studying mathematics and music.\nWhile a Ph.D. student, Smullyan published a paper in the 1957 Journal of Symbolic Logic showing that Gödelian incompleteness held for formal systems considerably more elementary than that of Gödel\'s 1931 landmark paper. The contemporary understanding of Gödel\'s theorem dates from this paper. Smullyan later made a compelling case that much of the fascination with Gödel\'s theorem should be directed at Tarski\'s theorem, which is much easier to prove and equally disturbing philosophically. The culmination of Smullyan\'s lifelong reflection on the classic limitative theorems of mathematical logic is quite readable:\n- Smullyan, R M (2001) ""Gödel\'s Incompleteness Theorems"" in Goble, Lou, ed., The Blackwell Guide to Philosophical Logic. Blackwell (ISBN 0-631-20693-0).\nHe was a professor of philosophy at City College in New York and at the University of Indiana.\nHe is also an amateur astronomer, using a six inch reflecting telescope for which he ground the mirror.\nMany of his logic problems are extensions of classic puzzles. Knights and Knaves involves knights (who always tell the truth) and knaves (who always lie). This is based on a story of two doors and two guards, one who lies and one who doesn\'t. One door leads to heaven and one to hell, and the puzzle is to find out which door leads to heaven by asking one of the guards a question. One way to do this is to ask ""Which door would the other guard say leads to hell?"". This idea was famously used in the 1986 film Labyrinth.\nIn more complex puzzles, he introduces characters who may lie or tell the truth (referred to as ""normals""), and furthermore instead of answering ""yes"" or ""no"", use words which mean ""yes"" or ""no"", but the reader does not know which word means which. The puzzle known as ""the hardest logic puzzle ever"" is based on these characters and themes. In his Transylvania puzzles, half of the inhabitants are insane, and believe only false things, whereas the other half are sane and believe only true things. In addition, humans always tell the truth, and vampires always lie. For example, an insane vampire will believe a false thing (2 + 2 is not 4) but will then lie about it, and say that it is. A sane vampire knows 2 + 2 is 4, but will lie and say it isn\'t. And mutatis mutandis for humans. Thus everything said by a sane human or an insane vampire is true, while everything said by an insane human or a sane vampire is false.\nHis book Forever Undecided popularizes Gödel\'s incompleteness theorems by phrasing them in terms of reasoners and their beliefs, rather than formal systems and what can be proved in them. For example, if a native of a knight/knave island says to a sufficiently self-aware reasoner, ""You will never believe that I am a knight"", the reasoner cannot believe either that the native is a knight or that he is a knave without becoming inconsistent (i.e., holding two contradictory beliefs). The equivalent theorem is that for any formal system S, there exists a mathematical statement that can be interpreted as ""This statement is not provable in formal system S"". If the system S is consistent, neither the statement nor its opposite will be provable in it. See also Doxastic logic.\nInspector Craig is a frequent character in Smullyan\'s ""puzzle-novellas."" He is generally called into a scene of a crime that has a solution that is mathematical in nature. Then, through a series of increasingly harder challenges, he (and the reader) begin to understand the principles in question. Finally the novella culminates in Inspector Craig (and the reader) solving the crime, utilizing the mathematical and logical principles learned. Inspector Craig generally does not learn the formal theory in question, and Smullyan usually reserves a few chapters after the Inspector Craig adventure to illuminate the analogy for the reader. Inspector Craig gets his name from William Craig.\nApart from writing about and teaching logic, Smullyan has recently released a recording of his favorite classical piano pieces by composers such as Bach, Scarlatti, and Schubert. Some recordings are available on the Piano Society website, along with the video ""Rambles, Reflections, Music and Readings"". He has also written an autobiography titled Some Interesting Memories: A Paradoxical Life (ISBN 1-888710-10-1).\nIn 2001, documentary filmmaker Tao Ruspoli made a film about Smullyan called This Film Needs No Title: A Portrait of Raymond Smullyan.\n|This section requires expansion. (December 2009)|\nSmullyan has written several books about Taoist philosophy, which he believes neatly solves most or all traditional philosophical problems as well as integrating mathematics, logic, and philosophy into a cohesive whole.\n||This article may require cleanup to meet Wikipedia\'s quality standards. The specific problem is: misleading use of links. (October 2012)|\n- (1978) What Is the Name of This Book? The Riddle of Dracula and Other Logical Puzzles - knights, knaves, and other logic puzzles\n- (1979) The Chess Mysteries of Sherlock Holmes - introducing retrograde analysis in the game of chess.\n- (1981) The Chess Mysteries of the Arabian Knights - second book on retrograde analysis chess problems.\n- (1982) The Lady or the Tiger? - ladies, tigers, and more logic puzzles\n- (1982) Alice in Puzzle-Land\n- (1985) To Mock a Mockingbird - puzzles based on combinatory logic\n- (1986) This Book Needs No Title: A Budget of Living Paradoxes\n- (1987) Forever Undecided - puzzles based on undecidability in formal systems\n- (1992) Satan, Cantor and Infinity\n- (1997) The Riddle of Scheherazade\n- (2007) The Magic Garden of George B. And Other Logic Puzzles, Polimetrica (Monza/Italy)\n- (2009) Logical Labyrinths, A K Peters\n- (2010) King Arthur in Search of his Dog\n- (2013) The Godelian Puzzle Book: Puzzles, Paradoxes and Proofs\n- (1977) The Tao is Silent\n- (1980) This Book Needs No Title\n- (1983) 5000 B.C. and other philosophical fantasies\n- (2002) Some Interesting Memories: A Paradoxical Life\n- (2003) Who Knows?: A Study of Religious Consciousness\n- (2009) Rambles Through My Library, Praxis International\n- (1961) Theory of Formal Systems\n- (1968) First-Order Logic\n- (1992) Gödel\'s Incompleteness Theorems\n- (1993) Recursion Theory for Metamathematics\n- (1994) Diagonalization and Self-Reference\n- (1996) Set Theory and the Continuum Problem\n- Is God a Taoist? by Raymond Smullyan, 1977.\n- Planet Without Laughter by Raymond Smullyan, 1980.\n- An Epistemological Nightmare by Raymond Smullyan, 1982.\n|Wikiquote has a collection of quotations related to: Raymond Smullyan|\n- Raymond Smullyan\'s website at Indiana University.\n- Raymond Smullyan at the MacTutor History of Mathematics archive.\n- Raymond Smullyan at the Mathematics Genealogy Project.\n- Raymond Smullyan at Piano Society', 'In “Demystifying Magic Tricks: Behind the Curtain,” you will uncover the secrets behind the captivating world of magic. Through this article, you will gain insights into the techniques and tools used by magicians to create illusions that leave audiences spellbound. By exploring the inner workings of various magic tricks, you will learn about the artistry and precision required to execute these feats of wonder. Get ready to be amazed as we peel back the curtain and reveal the hidden secrets of the magic world.\nThe History of Magic Tricks\nMagic tricks have been captivating audiences for centuries, but have you ever wondered how they originated? The ancient origins of magic trace back to various cultures and civilizations. In ancient Egypt, magic was closely tied to religion, as priests and pharaohs would perform illusions to demonstrate their divine powers. In ancient Greece and Rome, magicians entertained audiences with tricks involving cups and balls, as well as various illusions. Magic also played a significant role in the court of emperors and kings, where skilled illusionists would perform for the royal courts.\nAncient Origins of Magic\nThe art of magic continued to evolve during the Middle Ages, as wandering performers traveled from town to town, enthralling audiences with their sleight of hand and mystical abilities. During this time, magic tricks were often associated with witchcraft and the supernatural, leading to a sense of mystery and intrigue surrounding the practice. Magicians would perform tricks using everyday objects such as coins, cards, and ropes, leaving audiences astounded and bewildered.\nThe Rise of Professional Magicians\nAs societies became more developed and urbanized, professional magicians emerged. These individuals dedicated themselves to mastering their craft and entertaining audiences on a larger scale. One of the most famous professional magicians of the 18th century was Jean Eugène Robert-Houdin, who is often referred to as the “father of modern magic.” Robert-Houdin’s performances incorporated storytelling, humor, and theatricality, setting the stage for future magicians to incorporate these elements into their acts.\nFamous Magicians Throughout History\nOver the years, numerous magicians have captivated audiences with their extraordinary skills and mesmerizing performances. Harry Houdini, renowned for his escapology acts, became a household name during the early 20th century. His daring escapes from handcuffs, straitjackets, and water-filled tanks left audiences in awe of his seemingly supernatural abilities. Other notable magicians include David Copperfield, who combined grand illusions with storytelling, and Penn and Teller, who added humor and skepticism to their unique brand of magic.\nPsychological Techniques in Magic\nMagic tricks not only require skillful execution but also rely heavily on psychological techniques to create illusions of the impossible. By understanding how the mind works and exploiting cognitive biases, magicians can deceive and amaze their audience.\nMisdirection and Distraction\nMisdirection is a crucial technique used by magicians to divert the audience’s attention away from the actual secret of the trick. By creating a momentary distraction or focusing the audience’s attention on something else, magicians can manipulate their perception and make the impossible seem possible.\nSleight of Hand\nSleight of hand refers to the dexterity and precision with which a magician manipulates objects. By performing quick and subtle hand movements, magicians can make objects vanish, appear, or transform right in front of the audience’s eyes. This skill takes years of practice and requires superior hand-eye coordination.\nThis image is property of images.pexels.com.\nMagicians often use psychological manipulation techniques to influence the audience’s perception and decision-making. They may use verbal suggestion, body language, or subtle cues to guide the audience’s thoughts and actions, leading them to perceive the trick as something beyond explanation.\nCognitive Biases Exploited in Magic\nMagic tricks exploit various cognitive biases that are inherent in human perception and thinking. For example, the confirmation bias leads people to search for information that confirms their preconceived notions, allowing magicians to control what the audience perceives. The anchoring bias causes people to rely heavily on the first piece of information they receive, enabling magicians to manipulate their understanding of a trick’s mechanics.\nProps and Equipment\nMagicians often rely on props and equipment to enhance their illusions and create a sense of awe and wonder.\nWands and Canes\nWands and canes are staples of magic performances. They are used to direct attention, create magical gestures, and even perform tricks themselves. With a wave of a wand or a tap of a cane, a magician can make objects disappear, change color, or transform into something entirely different.\nCards and Card Decks\nPlaying cards are perhaps the most iconic tools of magicians. From simple card tricks to elaborate routines, card decks offer endless possibilities for deception. Through skilled manipulation and sleight of hand, magicians can make cards disappear, reappear, or change into a card chosen by the audience.\nCoins and Money Tricks\nCoins and money tricks have long fascinated audiences, as they involve objects that people interact with regularly. Magicians can make coins vanish from their hands, teleport from one hand to another, or even pass through solid objects. Money tricks often involve visual deception, quick hand movements, and the use of hidden compartments within props.\nRopes, Scarves, and Handkerchiefs\nRopes, scarves, and handkerchiefs are versatile tools that magicians use for a wide range of tricks. These props can be stretched, cut, or tied in impossible ways, defying the laws of physics. Ropes can be cut and instantly restored, scarves can multiply or change colors, and handkerchiefs can disappear and reappear in unexpected places.\nThis image is property of images.pexels.com.\nBoxes, Hats, and Tables\nBoxes, hats, and tables serve as magical platforms for countless tricks. Magicians use boxes to make objects vanish or appear, hats to produce animals or objects, and tables to provide a solid surface for tricks involving levitation or disappearance.\nMirrors and Reflections\nMirrors and reflections play a crucial role in creating illusions and deceiving the audience. By strategically placing mirrors or using reflective surfaces, magicians can create the illusion of objects vanishing, appearing, or multiplying. Mirrors can also be used to distort perception and make objects appear different from their actual size or shape.\nOptical Illusions and Visual Tricks\nMagic often relies on optical illusions and visual tricks to deceive the audience’s perception of reality.\nForced perspective is a technique used in both magic and filmmaking to create an illusion of depth and distance. By manipulating the size and placement of objects, magicians can make them appear larger or smaller, distort their proportions, or create the illusion of objects floating in mid-air.\nPepper’s Ghost Technique\nThe Pepper’s Ghost technique is an optical illusion used to make objects or people appear and disappear. It involves reflecting an image onto a glass or transparent surface at an angle, creating the illusion of a ghostly apparition. Magicians use this technique to create mysterious and supernatural effects during their performances.\nMirrors are commonly used in magic to create illusions and misdirect the audience’s gaze. By strategically placing mirrors, magicians can hide objects, make them appear or disappear, or create the illusion of a person vanishing into thin air. Mirror magic adds an extra layer of mystery and wonder to the performance.\nVanishing and Appearing Acts\nVanishing and appearing acts are classic magic tricks that never fail to captivate audiences. Magicians can make objects, animals, or even themselves vanish from sight, only to reappear moments later in a different location. These tricks often involve cleverly constructed props, hidden compartments, and skillful misdirection to create the illusion of teleportation.\nThis image is property of images.pexels.com.\nBehind the scenes, magic tricks often rely on intricate mechanical secrets to create seemingly impossible illusions.\nTrap Doors and Hidden Compartments\nTrap doors and hidden compartments are commonly used in stage magic to make objects or people disappear or appear. By incorporating trap doors into the stage or using hidden compartments within props, magicians can create the illusion of teleportation or transformation. Careful planning, precise timing, and seamless coordination with stage technicians are essential to execute these mechanical secrets flawlessly.\nSecret Pockets and Sections\nMagicians frequently utilize secret pockets and sections in their clothing and props to conceal or produce objects. These hidden compartments allow magicians to seemingly pluck items out of thin air or make them vanish without a trace. The purposeful design and construction of garments and props play a vital role in ensuring the success of these magical effects.\nMechanical Devices and Gimmicks\nMechanical devices and gimmicks designed specifically for magic tricks are crucial to achieving certain illusions. From devices that make objects levitate to mechanisms that create the illusion of mind-reading, magicians rely on these tools to enhance their performances. These devices are carefully crafted, hidden from view, and operated with precision to create seamless magical experiences.\nMagnetic and Electric Tricks\nMagnetic and electric tricks involve the use of magnets or electrical currents to manipulate objects. Magicians can make objects move on their own, seemingly defy gravity, or even pass through solid materials. Hidden magnets or electrical systems are strategically placed in props or the stage to create these mind-boggling effects.\nScience and Physics in Magic\nMagic tricks often incorporate principles of science and physics, allowing magicians to create seemingly impossible illusions.\nNewton’s Laws of Motion\nNewton’s laws of motion are frequently employed in magic tricks that involve objects appearing to move or suspend in mid-air. By understanding the principles of inertia, gravity, and action-reaction, magicians can create the illusion of objects floating, levitating, or defying gravity.\nOptics and Light Manipulation\nOptical principles such as refraction, reflection, and diffraction play a significant role in magic tricks. Magicians utilize these principles to create illusions where objects appear or disappear, change shape and color, or even pass through solid materials. By manipulating light and the way it interacts with objects, magicians can deceive the audience’s visual perception.\nChemical Reactions and Fire Tricks\nChemical reactions and fire tricks add an element of danger and excitement to magic performances. Magicians use carefully controlled chemical reactions to create bursts of fire, smoke, or even small explosions, leaving audiences amazed and astonished. Understanding the properties and behavior of chemicals is crucial to ensure the safety and success of these tricks.\nMagnetism and Levitation\nMagnetism and levitation are often used to create stunning visual effects in magic tricks. By employing magnets, magicians can make objects seemingly float in mid-air, defy gravity, or move autonomously. The proper application of magnetic forces and understanding the principles of magnetism are crucial to achieving these astonishing illusions.\nMind Reading and Mentalism\nMind reading and mentalism tricks involve creating the illusion of supernatural or psychic abilities, leading the audience to believe the magician can read their minds.\nCold Reading Techniques\nCold reading is a technique commonly used by mentalists to gather information about individuals without their knowledge. Through careful observation, skilled questioning, and the ability to interpret nonverbal cues, magicians can create the appearance of mind reading or psychic abilities.\nPredictive programming is a technique used by mentalists to manipulate the audience’s perception of choice or control. By subtly influencing the thoughts and actions of individuals, magicians can create the illusion of predicting their decisions or knowing their innermost thoughts.\nNeurolinguistic Programming (NLP)\nNeurolinguistic programming (NLP) is a psychological technique often utilized by mentalists to influence and manipulate the thoughts and behaviors of others. By using language patterns, body language, and subtle cues, magicians can guide the audience’s thinking, leading them to believe in extraordinary abilities.\nSubliminal messaging involves presenting information or suggestions to the audience’s subconscious mind without their conscious awareness. Through carefully timed and hidden techniques, magicians can plant ideas or cues that influence the audience’s perception and decisions, further enhancing the illusion of mind reading or mentalism.\nEscape Artists and Illusionists\nEscape artists and illusionists have pushed the boundaries of magic to new heights, captivating audiences with daring feats of escape and seemingly impossible acts.\nHoudini’s Masterful Escapes\nHarry Houdini, one of the most famous escape artists in history, astounded audiences with his daring escapes from handcuffs, straitjackets, and even water-filled tanks. His ability to escape seemingly impossible situations made him a legend in the world of magic. Through meticulous preparation, physical dexterity, and an understanding of the limitations of locks and restraints, Houdini defied the odds and became synonymous with escape artistry.\nLocks and Handcuff Manipulation\nEscape artists employ lock and handcuff manipulation techniques to free themselves from seemingly secure restraints. By studying the mechanics of locks and restraints, escape artists can discover vulnerabilities and exploit them to their advantage. Practice, flexibility, and an intimate knowledge of their tools allow them to execute these daring acts of escape.\nWater Tank and Coffin Escapes\nWater tank and coffin escapes are among the most dramatic and dangerous acts performed by escape artists. These feats involve being confined in a submerged tank or buried alive in a sealed coffin, with the challenge of escaping before running out of air. Escape artists must possess exceptional breath control, physical endurance, and a deep understanding of water pressure and coffin mechanics to succeed in these adrenaline-fueled performances.\nDigital Magic in the Modern Age\nWith the advancement of technology, magicians have embraced digital platforms and augmented reality to create a new era of magic.\nAugmented Reality Tricks\nAugmented reality tricks make use of digital overlays and visual effects to create seemingly impossible illusions in real-time. Magicians can make objects appear to float, transform, or interact with the audience in ways that defy traditional physical limitations. By blending the digital and physical realms, magicians are able to create immersive and mind-bending experiences.\nMobile Apps and Virtual Platforms\nMagicians are utilizing mobile apps and virtual platforms to enhance their performances and connect with audiences in innovative ways. With the use of smartphones and tablets, magicians can perform mind-reading tricks, virtual levitation, or even teleportation. These digital tools add a new layer of interactivity and engagement between the magician and the audience.\nDigital Sleight of Hand\nDigital sleight of hand refers to the use of digital manipulation and editing techniques to create visual tricks. Magicians can make objects vanish, transform, or teleport in video performances by utilizing post-production effects and editing software. Digital sleight of hand has opened up new possibilities for magicians to create awe-inspiring illusions in the digital realm.\nUsing Technology for Illusions\nTechnology has become an integral part of modern magic, allowing magicians to push the boundaries of what is possible. From holographic projections and drone technologies to virtual reality and robotics, magicians are incorporating cutting-edge advancements to create magical experiences that were once unimaginable. The fusion of technology and magic opens up a world of endless possibilities, captivating audiences in ways never seen before.\nEthics and Secrets of Magic\nThe art of magic is built on a foundation of secrecy and respect for the craft. Magicians adhere to a code of ethics, balancing the entertainment value of their performances while safeguarding the secrets behind their tricks.\nThe Magician’s Code\nThe Magician’s Code is a set of guidelines that magicians adhere to, emphasizing the importance of respecting the art of illusion. This code outlines principles such as not revealing the secrets of tricks, maintaining the integrity of the performance, and upholding the mystique surrounding magic.\nRespecting the Art of Illusion\nMagicians strive to create a sense of wonder and suspension of disbelief in their audiences. To maintain the enchantment of magic, they must respect the art of illusion by not divulging the secrets of their tricks. By preserving the mystery behind their performances, magicians ensure that future generations can experience the same joy and astonishment that magic has brought for centuries.\nBalancing Entertainment and Exposing Tricks\nWhile maintaining secrecy is crucial to the allure of magic, some magicians choose to reveal certain tricks to educate and entertain audiences. Exposing tricks can provide insight into the skill, dedication, and creativity required to execute magical illusions. However, this delicate balance must be struck with care, as the exposure of too many secrets can diminish the overall impact and enjoyment of magic performances.\nDemystifying Magic Tricks: Behind the Curtain']"	['<urn:uuid:f76022d2-7743-40fe-8e3b-929c3668409a>', '<urn:uuid:643dd90b-dce8-4f94-8c4d-4ecc90824c6f>']	open-ended	direct	concise-and-natural	distant-from-document	comparison	novice	2025-05-12T23:56:45.148498	8	63	3923
33	I'm studying the career paths of Italian Renaissance figures - what important diplomatic position did Guicciardini hold early in his career?	After distinguishing himself in law practice, Guicciardini was appointed by the Florentine Signoria as ambassador to the court of Ferdinand the Catholic, King of Aragon.	['Francesco Guicciardini: The Historian as Aphorist. Francesco Guicciardini’s fame rests on two works of strikingly different character: the Ricordi and the Storia. Maxims and Reflections has 87 ratings and 9 reviews. James said: Sixteenth century Italy is remembered as the time of Machiavelli, but it also produced a. Maxims and reflections (Ricordi) / Francesco Guicciardini ; translated by Mario Domandi ; introduction by Nicolai Rubinstein Guicciardini, Francesco, .\n|Published (Last):||3 May 2016|\n|PDF File Size:||3.42 Mb|\n|ePub File Size:||20.81 Mb|\n|Price:||Free* [*Free Regsitration Required]|\nHaving distinguished himself in the practice of law, Guicciardini was entrusted by the Florentine Signoria with an embassy to the court of the King of AragonFerdinand the Ricordi guicciardiniin ricordi guicciardini Steven Teasdale rated it really liked it Nov 14, guicviardini Encyclopedia of the Renaissance New York: He ricordi guicciardini to lose great present profits and the chance of making one of his sons a great man rather than have it on his conscience that he had made one of his sons a priest gguicciardini of greed for wealth or great position.\nHis Maxims and Reflections were recorded over the better part of two decades and reflect his thoughts on various questions based on his personal experience.\nJournals with no new volumes being added to the archive. However, in AprilGuicciardini succeeded in averting an attack on Florence from a rebellious imperial army, which turned ricordi guicciardini Rome instead.\nThese high offices rendered Guicciardini the virtual master of the Papal States beyond ricorfi Apennine Mountains. Guicciardini is best known as the author of the Storia d’Italia History of Italywhich provides a detailed account of politics in the Italian Peninsula between ricordi guicciardini InGiovanni de’ Medici, the son of Lorenzo the Magnificentricordi guicciardini Pope Ricordi guicciardini X and brought Florence under papal control, which provided opportunities for Florentines to enter papal service, as did Francesco in Export a Text file For BibTex.\nAtkinson and Davis Sices, Trans.\nFrancesco Guicciardini: The Historian as Aphorist on JSTOR\nInfluential in Florentine politics, Guicciardini’s ancestors had held the highest posts of honor ricordi guicciardini the state for many generations, as may be seen in his own genealogical Ricordi autobiografici e di famiglia. Refresh and try again. Moreover, guicciardihi sets Guicciardini apart from other historians of his time is his understanding of historical ricordi guicciardini.\nSome of the topics covered include the role of boldness, luck, and deception in achieving ricordi guicciardini the value of reputation and ways to maintain it; how people are driven more by hope than by fear, and why ricordi guicciardini stingy with generosity helps to build hope in others; how negatives are exaggerated and positives underrated; eicordi.\nPreview — Maxims and Reflections by Francesco Guicciardini. Were these topics helpful? He died in without male heirs. Thanks for telling us about the problem.\nPay attention to names, capitalization, and dates. The death of an uncle, who had occupied ricordi guicciardini see of Cortonainduced the young Guicciardini to seek an ecclesiastical career.\nMaxims and Reflections of a Renaissance Statesman | work by Guicciardini |\nTo ask other ricordi guicciardini questions about Maxims guicciqrdini Reflectionsplease sign up. For the 19th century Italian cabinet member, see Francesco Guicciardini politician. One of the wisest books I’ve ever read.\nEero rated it really liked it May 29, From Wikipedia, the free encyclopedia. ricordi guicciardini\nMaxims and Reflections of a Renaissance Statesman\nNot any individual, be it noted, but those in positions of command: Hi Sixteenth century Italy is remembered as the time of Machiavelli, but it also ricordi guicciardini another noteworthy author of maxims ricordi guicciardini other works giicciardini Francesco Guicciardini March 6, – May 22, ricordi guicciardini Guicciardini served three popes over a period of twenty years, and perhaps because of his experiences, he was highly critical of the papacy: In his masterpiece, The History of Italy, Guicciardini paved the way for a new style in historiography with his use of government sources gjicciardini support arguments and the realistic analysis of the people and events of his time.\nLike his ricordi guicciardini, Francesco received a fine humanist education and studied the classics, learning both Latin and a little Greek. And wishing there ricordi guicciardini more starts to be given! Khalil rated it really liked it Nov 20, Quotes from Maxims and Reflec Ricordi by Francesco Guicciardini.\nThe “Ricordi” are an excellent window on the world of Renaissance Italy, and on the foibles of humans in power.']	['<urn:uuid:3ba92edc-54f8-4d69-a0a1-efd26947fb65>']	factoid	with-premise	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-12T23:56:45.148498	21	25	733
34	What measures have been developed to help organizations contribute to addressing the global water scarcity crisis through financial mechanisms?	Gold Standard has developed requirements to certify the positive socio-economic impacts of water projects through Water Benefit Certificates (WBCs). Each WBC represents a volume of water that has been sustainably supplied, purified or conserved. Projects must deliver impact toward at least three SDGs and demonstrate a clear financial need for additional finance from selling Water Benefit Certificates.	['Environmental integrity + sustainable development\nHigh-impact Gold Standard assets -- from carbon credits to renewable energy certificates -- allow the power of markets to drive change, accelerating progress toward the Paris Agreement and the Sustainable Development Goals.\nGold Standard was founded to ensure carbon markets feature the highest levels of environmental integrity and contribute towards sustainable development. We continue to strengthen and scale efforts across a range of environmental markets, focused on making it simpler for high-impact climate protection projects to achieve certification and access markets in the context of the new Paris Agreement Framework.\nVoluntary + Compliance Carbon Markets\nThe latest IPCC report highlights the urgency to fully decarbonize our global economy. Carbon markets help accelerate and finance the transition to net-zero emissions by enabling businesses and individuals to take accountability for their unavoidable emissions through the purchase of carbon credits.\nThis helps close the emissions gap left by countries commitments under the Paris Agreement, the finance gap where urgently needed climate action is not yet funded, and the time gap that favours action today over waiting for sufficient policy measures from governments.\nDRIVING FINANCE TO HIGH IMPACT CLIMATE PROTECTION ACTIVITIES\nHowever much we try to reduce our footprint, in our current world some emissions are still unavoidable. Financing emission reductions by purchasing high impact carbon credits is a way to take responsibility for your climate impact and to take-action beyond your own footprint.\nCarbon credits represent the reduction or removal of one tonne of CO2 equivalent (tCO2e). Gold Standard carbon credits also include gender-sensitive and inclusive stakeholder design, environmental and social safeguards, and a contribution towards at least three Sustainable Development Goals (SDGs) - ensuring the greatest impact delivered for every dollar channeled to projects.\nGold Standard Verified Emission Reductions (VERs) for voluntary climate action\nFor more information\nRENEWABLE ENERGY MARKETS\nRenewable energy markets\nAt least 42% of electricity must be supplied by renewable sources by 2030 to reach net zero emissions by midcentury -- the ambition of the Paris Agreement -- which requires doubling renewable power capacity. The private sector is key to this transition, yet some companies are limited in their ability to source renewable energy directly. Renewable energy markets allow these companies to purchase clean energy from their grid.\nBy purchasing clean energy -- whether directly or through renewable energy markets -- companies demonstrate a commitment to being more environmentally friendly, something clients, consumers + civil society are increasingly demanding.\nACCELERATING THE CLEAN ENERGY TRANSITION\nMore and more businesses are setting ambitious renewable energy targets in an effort to spur the global transitions to renewables and purchasing renewable electricity through energy attribute certificates is a convenient, affordable and accessible option.\nGold Standard labelled Renewable Energy Attribute Certificates represent a megawatt-hour (MWh) of electricity generated and delivered to the grid from a renewable source. They are issued on top of I-RECs, internationally recognised and reliable electricity attribute tracking certificates (RECs). And most importantly, they follow Gold Standard principles to ensure that a buyer’s purchase results in real-world emissions reductions and the addition of new renewable energy capacity to the grid, helping to drive the clean energy transition.\nFor more information\nWater Benefit Certificates\nThe World Economic Forum names water crises as the #1 greatest risk facing the world.\nFreshwater sustains life – neither people nor nature can exist without it. But many of the world’s water systems are dangerously stressed and experts predict that ‘business as usual’ water use will expose 4.8 billion people to severe water scarcity by 2050.\nINCREASING ACCESS TO SAFE WATER FOR ALL\nWater is the most fundamental human need and many organisations are committed to water stewardship, working collaboratively to ensure that social, environmental and economic benefits are achieved.\nGold Standard has developed requirements to certify the positive socio-economic impacts of water projects, enabling companies to support high-impact water projects through the purchase of Water Benefit Certificates (WBCs).\nA Water Benefit Certificate represents a volume of water that has been sustainably supplied, purified or conserved. There are different volumes for different project types, depending on size and impacts provided. Each Gold Standard certified water project must deliver impact toward at least three SDGs and demonstrate a clear financial need for additional finance from selling Water Benefit Certificates – delivering development impacts that would not have otherwise happened.']	['<urn:uuid:64e7b0b6-1149-4982-bade-00bdbfc0dbe5>']	factoid	direct	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-12T23:56:45.148498	19	57	716
35	I've heard many different versions of Celtic folk songs - what are some well-known artists and groups who have performed traditional Celtic music pieces?	Several notable performers and groups have performed traditional Celtic music, including the Chieftains who performed Carrickfergus, Alasdair Fraser who performed The Mermaid and The Lassie with Golden Hair, Dougie MacLean who sang Bonnie Bessie Logan, the Tannahill Weavers who performed Wild Mountain Thyme, and The High Kings who performed Rocky Road to Dublin.	"[""Celtic Airs (2010)\nAlbum Liner Notes\n1. Carrickfergus (trad. Ireland) An 18th-Century Ulstermen’s melody. This oldest town in Antrim is on the Belfast Loch, not far from C.S. Lewis’s childhood home. From the playing of the Chieftains. Bass: Henry Smith.\n2. Auld Lang Syne (trad. Scotland) Popular tune for the poem by Robert Burns./This Shall Be the Year (Timothy Seaman, 2005 Pine Wind Music, Inc.) Looking ahead to new times with great aspirations! Keyboard: Henry Smith.\n3. Bonnie Dundee (trad. Scotland) Harp: Ardie Boggs; Bowed dulcimer: Ann Robinson. A tune in honor of John Graham, a leader of the first Jacobite Rising, who died victorious at Killiekrankie in 1688./Believe Me if All Those Endearing Young Charms (trad. Ireland) Highland pipes: Peter Budnikas; Harp: Ann Robinson. Tune for a poem by Thomas Moore, 1846.\n4. Guide Me, O Thou Great Jehovah (Cwm Rhondda) (Wales: John Hughes, 1907) Piano: Robin Jester. Tune for the hymn by William Williams, 1745.\n5. She Moved Through the Fair (trad. Ireland) Harp, bowed dulcimer: Ann Robinson. Donegal tune collected by Padraic Colum and published in 1909. /The Mermaid (An mhaighdean mhara) (trad. Scotland) From the playing of Alasdair Fraser. Fiddle, guitar, high-strung guitar: Bill Gurley.\n6. Bonnie Bessie Logan (trad. Scotland) From the singing of Dougie MacLean./Loch Lomond (By Yon Bonnie Banks) (trad. Scotland, published 1841).\n7. Archibald MacDonald of Keppoch (trad. Scotland) Harp: Ardie Boggs. A tune in honor of a hero of the Jacobite Rising of 1715./Ye Banks & Braes (Bonnie Doon) (trad. Scotland) The tune for a Robert Burns poem set beside his local river.\n8. Be Thou My Vision (Banks of the Bann) (trad. Ireland) Title from an 8th-Century Irish hymn translated by Mary Byrne, 1905 and versified by Eleanor Hull, 1912./O the Deep, Deep Love of Jesus (Ebenezer, Ton-Y-Botel) (Wales: Thomas Williams, 1890) Title from the 19th-Century hymn by Samuel Trevor Francis. Keyboard, bass, electric violin: Henry Smith.\n9. Jesus, Lover of My Soul (Aberystwyth) (Wales: Joseph Parry, 1879) Piano: Robin Jester. Tune for the hymn by Charles Wesley, 1740.\n10. Blind Mary (Ireland: Turlough O’Carolan, 18th Century)/The Southwind (Ireland: Freckled Donal Macnamara, 18th Century) Harp: Ann Robinson.\n11. I'll Bid My Heart Be Still (trad. Scotland)/My Sweet Rowena in the Glen (Timothy Seaman, 2008 Pine Wind Music, Inc.) Accordion: Howard Nilsen.\n12. Pulling Bracken (Alle Bain) (trad. Scotland) Harp: Ardie Boggs, Ann Robinson./Comin' Thro’ the Rye (trad. Scotland)\n13. Wild Mountain Thyme (trad. Scotland) From the playing of the Tannahill Weavers./The Lassie with Golden Hair (trad. Scotland) From the playing of Alasdair Fraser. Harp: Ann Robinson.\n14. The Rowan Tree (trad. Scotland, early 19th Century) Tune for Lady Nairn’s nostalgic poem “o’ hame and infancy.”\n15. Our Hero (Mo Ghile Mear) (trad. Ireland, 17th Century) Eire’s lament for the exile of their cousin Bonnie Prince Charlie. From the playing of Phil Cunningham and Micheal O’Domhnaill of Relativity./The Broom o' the Cowdenknowes (trad. Scotland, published 1651) A shepherdess’s love ballad later adapted into a poem by Sir Walter Scott. From the version by Andrew Stewart and Phil Cunningham of Silly Wizard. I’m reminded of the great Irishman C.S. Lewis’ concept of “inconsolable longing” which he first experienced in viewing the Castlereagh Hills from his nursery window. This yearning, built into the human soul, for Joy, beckons us to regard Heaven and God as our true and needed home."", 'What is the meaning of The Rocky Road to Dublin?\n“Rocky Road to Dublin” is a 19th-century Irish song written by Irish poet D. K. Gavan about a man’s experiences as he travels to Liverpool, England from his home in Tuam, Ireland. Originally popularized by Harry Clifton, it has since been performed extensively and become a standard of Irish folk music.\nIs Rocky Road to Dublin a slip jig?\nROCKY ROAD TO DUBLIN  (“An botar sgreagmar go Baile-Ata-Cliat” or “An bothar carrach go Baile Atha Cliath”). AKA and see – Rocky Road (2) (The). Irish, Slip Jig or Air (9/8). A Dorian (most versions): A Mixolydian (O’Neill/1915 & 1001).\nWho sang the Rocky Road to Dublin?\nThe High Kings\nThe Rocky Road To Dublin/Artists\nWhat genre is Rocky Road to Dublin?\nThe Rocky Road To Dublin/Genres\nWhat time signature is Rocky Road to Dublin?\nSheet Music: Rocky Road to Dublin\n|Title||Rocky Road to Dublin|\nWhat is slip jig music?\nSlip jig (Irish: port luascach, port luascadh) refers to both a style within Irish music, and the Irish dance to music in slip-jig time. The slip jig is in 9. 8. time, traditionally with accents on 5 of the 9 beats — two pairs of crotchet/quaver (quarter note/eighth note) followed by a dotted crotchet note.\nWhat does whack fol de dah mean?\n“Whack fol the dah” does not have a meaning. It’s similar to “la la la” or “shooby-dooby-doo-bop”. It’s called “lilting”, similar to Jazz scatting.\nWho are the members of the High Kings?\nBrian DunphyVocalsMartin FureyGuitarFinbarr ClancyGuitar\nThe High Kings/Members\nThe High Kings are Finbarr Clancy, Darren Holden, Brian Dunphy and newest member Paul O’ Brien.\nWhat is the difference between a jig and a slip jig?\nA slip jig is similar to a single or double jig (and can incorporate either, or both, note patterns), but is played in 9/8 time. This gives it a slightly more lilting, more leisurely, less driving, feel than the single and double jigs.\nWhat are the features of traditional Irish music?\nMost tunes are in AABA, ABBA and AABB forms. Irish music is melodic instead of harmonic. Ornamentation and melodic variation is preferred over chords and harmony. However, trad instruments like the hard and accordion can be used for chordal accompaniment, and pipes have drones and regulators.\nWhat happens on the Rocky Road to Dublin?\nHunt the hare and turn her down the rocky road And all the way to Dublin, whack-fol-la-de-da. In the merry month of June, when first from home I started, And left the girls alone, sad and broken-hearted. Shook hands with father dear, kissed my darling mother, Drank a pint of beer, my tears and grief to smother;\nWho was the original singer of Rocky Road to Dublin?\nOriginally popularized by Harry Clifton, it has since been performed extensively and become a standard of Irish folk music. The song is also often performed instrumentally. The words were written by D. K. Gavan, “The Galway Poet”, for the English music hall performer Harry Clifton (1824–1872), who popularized the song.\nWhen did Manus O’Connor write Rocky Road to Dublin?\nRather than with 6 strong musical beats (9/8 + 9/8): And frighten all the dogs on the rocky road to Dublin. Version reported by Manus O’Connor in 1901. And left the girls alone, sad and broken-hearted. Then off to reap the corn, and leave where I was born. Sure I frightened all the dogs on the rocky road to Dublin.\nWhat did the Dubliners sing all the way to Dublin?\nAll the way to Dublin, Whack follol de rah! With a load “hurray !” joined in the affray All the way to Dublin, Whack follol de rah! This song, like many recorded by The Dubliners, is a traditional Irish song recorded by many artists.']"	['<urn:uuid:72776971-dfe9-4cca-b03d-ca1c8951ac37>', '<urn:uuid:337b69a1-096d-4a23-9f34-accf27779277>']	factoid	with-premise	verbose-and-natural	distant-from-document	three-doc	novice	2025-05-12T23:56:45.148498	24	53	1189
36	What should I do first if my luggage gets damaged during a trip?	If your luggage is damaged, you should report the incident to the airline or travel provider immediately. Take photographs of the damage and keep all documentation you receive from them, as well as any receipts for repairs.	['Traveling can be an exhilarating experience, allowing you to explore new destinations and experience different cultures. However, with the thrill of traveling come plenty of risks, including lost or damaged luggage. This can be a daunting experience, and with the cost of replacing lost or stolen items, it can create a significant financial strain. This is where travel luggage insurance comes in – providing you with peace of mind knowing that your possessions are protected. In this article, we will delve into the benefits of travel luggage insurance and why it’s worth considering on your next trip.\n– The Importance of Travel Luggage Insurance: Providing Peace of Mind\nBenefits of Travel Luggage Insurance\nWhen you’re traveling, you’re often carrying your entire life with you. From clothing to electronics, your luggage is an extension of you, and losing it can be devastating. Travel luggage insurance provides peace of mind in case your luggage gets lost, damaged, or stolen. It can be a lifesaver when you’re far away from home.\nProtect Your Belongings\nTravel luggage insurance provides comprehensive protection for your belongings. If your luggage is lost or stolen, you can receive reimbursement for the value of your lost items. Additionally, if your luggage is damaged, you can receive reimbursement for the cost of repairs. Having travel luggage insurance means you won’t be left scrambling to replace your lost or damaged items on your own.\nMany travel luggage insurance policies also come with assistance services. These services can provide you with assistance in the event your luggage is lost or stolen. For example, they may be able to help you locate your luggage or provide you with a loan for necessary expenses if you’re without your luggage for an extended time.\nPeace of Mind\nPerhaps, the most important benefit of travel luggage insurance is the peace of mind it provides. Knowing that your belongings are protected can help you enjoy your trip worry-free. You won’t have to spend your entire vacation fretting about the possibility of losing your luggage. Instead, you can focus on creating lasting memories.\n– Understanding the Risk: Common Causes of Luggage Loss or Damage\nFactors that can lead to luggage loss or damage are many and often unpredictable. One of the leading causes is the mishandling of luggage during transit, either due to manual handling errors or mechanical irregularities. In most cases, luggage is mishandled when airport staff fail to follow safety protocols or when automated processes malfunction. Baggage mishandling is a common occurrence during peak travel periods, such as holidays or during weather disruptions.\nAnother common reason for luggage loss or damage is theft, which can happen in several ways. For instance, a traveler may fall prey to theft if they leave their luggage unattended or if they use insecure locks. Further, baggage theft can occur during transit, especially if the luggage is not labeled correctly or if it is left in an open area. Generally, thieves target bags containing valuable items such as electronics and jewelry, and they often work in groups or as individual opportunists.\nIn addition to mishandling and theft, luggage loss or damage can also arise from airline errors, such as misplacing luggage, or from passengers exceeding airline baggage limits or bringing prohibited items. A traveler may also lose their baggage when they miss a connecting flight or when there are last-minute ticket changes.\nMoreover, luggage loss or damage can occur due to environmental factors, such as exposure to extreme temperatures or humidity. Travelers should also note that, although unlikely, luggage can get damaged when it becomes caught in the airport’s conveyor systems.\nIn summary, there are several factors that may cause luggage loss or damage, including mishandling during transit, theft, airline errors, missed flights, prohibited items, exposure to environmental factors, and mechanical issues. As such, it is vital for travelers to be vigilant when traveling and to take necessary precautions such as ensuring their luggage is securely locked and labeled. Also, travelers should consider purchasing baggage insurance to protect their belongings against loss or damages.\n– Don’t Let Mishaps Ruin Your Vacation: Types of Luggage Insurance Coverage\nCommon Types of Luggage Insurance Coverage\nWhen traveling, your luggage can be susceptible to unexpected mishaps such as theft, loss or damage. In such cases, luggage insurance can be a lifesaver for your vacation. Luggage insurance provides various types of coverage for different kinds of mishaps, including:\n1. Loss or Theft Coverage: This type of insurance typically covers the cost of lost or stolen luggage, including the contents within it. Some policies even extend to cover identity theft that occurs due to lost or stolen bags.\n2. Damage Coverage: If your luggage is damaged due to handling or other reasons, this type of insurance provides you with protection against the cost of repair or replacement. They may even cover cosmetic damages such as scuffs and scratches.\n3. Delayed or Misdirected Coverage: This type of coverage pays for associated expenses such as buying necessities and clothing if your luggage is delayed or misdirected by the airline or other modes of transportation.\n4. Worldwide Coverage: Insurance coverage for luggage is worldwide and designed for all categories of travel, including domestic, international, and cruise travel.\n5. Premium Coverage: A premium policy offers additional benefits such as the reimbursement of unused portions of the trip if you cancel due to a covered reason, baggage delay, baggage loss, emergency medical expenses, and emergency medical evacuation.\nIn conclusion, luggage insurance is a vital investment if you’re a frequent traveler or planning a long trip. Make sure you’re purchasing the right coverage for your needs, and you can look forward to a stress-free and enjoyable vacation.\n– Taking the Next Step: How to Purchase Luggage Insurance for Your Travels\nTypes of Luggage Insurance Coverage\nWhen purchasing luggage insurance, there are several types of coverage to choose from, including lost baggage, delayed baggage, damaged baggage, and theft. Lost baggage coverage will provide compensation for lost items while delayed baggage coverage comes into play if your luggage is not delivered within a certain time frame. Damaged baggage coverage will pay for any damages incurred during transit, and theft coverage will provide financial compensation if your luggage is stolen.\nChoosing a Luggage Insurance Provider\nChoosing the right luggage insurance provider is essential to ensure peace of mind while traveling. When selecting a provider, consider their reputation, customer service, coverage options, and pricing. Read customer reviews and compare prices to ensure that you are getting the best deal.\nSteps to Purchasing Luggage Insurance\nPurchasing luggage insurance is a simple process that can be done online or in person. Start by researching reputable luggage insurance providers and compare pricing and coverage options. Once you have a shortlist of providers, obtain a quote from each and compare the coverage and pricing.\nBefore making a final decision, read the terms and conditions of each policy to ensure that the coverage meets your needs. Once you have chosen a provider and reviewed the policy, pay for the insurance. Your policy will then be sent to you via email or mail, and you can enjoy travel with peace of mind.\n– What to Do When the Unexpected Happens: Making a Claim on Your Luggage Insurance\nUnderstanding your luggage insurance policy is essential for making a claim in the event that something unexpected happens. The first step is to review your policy paperwork carefully to understand exactly what is covered and what is not. Make a note of the coverage limits, whether there is a deductible, and what documentation you will need to support your claim.\nIf your luggage is lost or delayed, report it immediately to the airline or travel provider. Make sure to keep all documentation, including the claim form, receipts for your luggage, and any other supporting paperwork that might be needed. You will want to file your claim promptly after the incident, as many travel insurance policies have strict deadlines for filing a claim.\nIf your luggage is damaged, you should also report the incident to the airline or travel provider as soon as possible. Take photographs of the damage and keep all the documentation you receive from the airline or travel provider, as well as any receipts for repairs you may have had to make. Again, make sure to file your claim with your luggage insurance company according to the policy terms and deadlines.\nWhen making a claim on your luggage insurance policy, it is essential to be honest and accurate with all the information you provide. Remember to include all relevant documentation and to keep a record of all communication with the insurance company, such as phone calls or emails. Being organized and thorough can help make the claims process smoother and increase your chances of a successful outcome.\nIn conclusion, making a claim on your luggage insurance may seem daunting, but with careful preparation and attention to detail, it can be a straightforward process. Know your policy, report any incidents promptly, keep all paperwork, and be honest and accurate with your information. Following these steps should help to ensure that your luggage insurance claim is processed quickly and fairly.\n– Other Benefits of Travel Luggage Insurance: Beyond Protection of Physical Possessions\nFinancial Benefits of Travel Luggage Insurance\nTravel luggage insurance provides financial security to travelers in case of flight cancellations, trip interruption, or delays. Most insurance policies have provisions for covering expenses incurred during delays, missed flights, and baggage loss. It is essential to check the coverage details before purchasing the policy to know the specific expenses included in the package.\nApart from covering loss or damage to luggage, travel luggage insurance also provides medical coverage to travelers in case of accidents, illnesses, or injuries. Such insurance policies have provisions for emergency medical treatment or evacuation, which can save travelers thousands of dollars in medical bills.\nPeace of Mind\nTraveling requires a lot of preparation, and the last thing anyone wants is to worry about unexpected expenses, lost luggage, or an emergency medical situation. Travel luggage insurance provides peace of mind, allowing travelers to enjoy their trip without any worries. Knowing that they are covered for any mishaps, travelers can focus on discovering new destinations and experiencing new cultures.\nTravel luggage insurance provides a myriad of benefits, most of which are beyond protecting physical possessions. With financial benefits, medical coverage, and peace of mind, it is worth the extra cost to ensure a safe and hassle-free trip. Before purchasing the policy, travelers must carefully review the coverage details and compare multiple insurance providers to choose the best option that meets their needs and budget.\n– Going the Extra Mile: Finding the Right Fit and Coverage for Your Luggage Insurance\nUnderstanding Your Luggage Insurance Needs\nIt’s essential to identify your insurance goals before purchasing any policy. From basic coverage to comprehensive plans, there are numerous options to consider. Therefore, one must outline their collateral for risks to ensure that the policy provides adequate cover. Thinking through the potential risks will lead you to a suitable plan.\nIdentifying Your Luggage Type\nLuggage insurance policies come in various types. It’s essential to ensure that you obtain a policy that provides sufficient cover to your luggage type. For example, if you’re carrying expensive or delicate items, you should consider getting a specialized policy.\nChoosing Your Luggage Insurance Provider\nIdentifying the right luggage insurance provider is fundamental. It’s essential to research prospective providers before accepting any policy to avoid any unpleasant surprises. Ensure that the provider has a good reputation for delivering on its promises and addressing claims efficiently. Additionally, check the customer service level provided, including their communication channels and service hours.\nUnderstanding the Policy Exclusions\nBefore buying any policy, it’s vital to review the policy’s exclusion section with a keen eye. The exclusion section outlines the types of risks that do not cover the policy. It’s essential to note any conflict areas before accepting any proposal to avoid any issues during filing claims.\nPeace of Mind for a Worry-Free Trip\nA comprehensive luggage insurance policy provides peace of mind since it covers a wide range of risks that may arise during your travels. You can be sure that your luggage is protected against loss, damage, theft, and other unforeseen contingencies. Above all, it enables you to travel with confidence while protecting your belongings.\nQuestions People Also Ask:\n1. What is travel insurance for luggage?\nTravel insurance for luggage offers financial protection against loss, damage, and theft of your baggage during your travels. This can include various forms of baggage, such as checked luggage, carry-on luggage, and personal items.\n2. What does travel insurance for luggage cover?\nDepending on the policy, travel insurance for luggage can cover loss, damage, and theft of your baggage, including the contents inside. It can also cover additional expenses, such as the cost of replacing lost or stolen items, or the cost of purchasing necessary items if your luggage is delayed or lost.\n3. What is not covered under travel insurance for luggage?\nTravel insurance for luggage may not cover certain items that are particularly valuable, such as jewelry or expensive electronics, unless specifically stated in the policy. Additionally, items that are lost or damaged due to negligence or recklessness on your part may not be covered.\n4. Do I need travel insurance for luggage?\nWhether or not you need travel insurance for luggage depends on your individual travel needs and preferences. If you are traveling with valuable items or are concerned about the potential loss or theft of your baggage, purchasing travel insurance for luggage may provide peace of mind.\n5. When should I purchase travel insurance for luggage?\nIt is recommended to purchase travel insurance for luggage at the time of booking your travel. This ensures that you are covered for any potential losses or damages from the start of your trip.\n6. How do I file a claim for lost or damaged luggage?\nIf your luggage is lost, damaged, or stolen during your travels, you should contact your travel insurance provider as soon as possible. They will provide you with the necessary forms and instructions to file a claim. It is important to keep track of any documentation related to your luggage (such as baggage claim tags) to provide to the insurer.\n7. How much does travel insurance for luggage typically cost?\nThe cost of travel insurance for luggage can vary depending on various factors, such as the amount of coverage you require and the length of your trip. On average, it can cost around 5-10% of the total cost of your trip.\n- Luggage insurance provides coverage for lost, stolen, or damaged luggage during travel.\n- Travelers should review their existing insurance policies to determine if they already have luggage coverage.\n- When choosing a luggage insurance provider, consider the coverage limits, exclusions, and deductibles.\n- Ensure that the coverage provided meets the specific needs of your trip, including the type of luggage and destination.\n- Consider the additional services offered by the provider, such as emergency assistance and lost item return.\n- Read the terms and conditions carefully to understand the coverage and its limitations.\n- Compare prices and coverage options from multiple providers to find the best fit for your needs.\n- Be prepared to provide documentation, such as receipts and police reports, in the event of a claim.\n- Don’t assume that all luggage insurance policies are the same and choose the one that provides the best coverage for your individual needs.\n- About the Author\n- Latest Posts\nI’m Kara Lester, a writer for Digital Maryland News. I love telling stories about Maryland, especially those that involve the water. I’m an avid sailor and love spending time on the Chesapeake Bay. In my free time, I enjoy fishing, swimming, and kayaking. I’m grateful for the opportunity to use my writing to share the beauty of Maryland with the world.']	['<urn:uuid:f8778978-16e0-47e3-b2e2-e7ef251e9829>']	factoid	with-premise	concise-and-natural	similar-to-document	single-doc	novice	2025-05-12T23:56:45.148498	13	37	2653
37	deep cave risks broken bones	Deep cave exploration in places like Bat'n Sabsab involves risks when penetrating narrow tunnels up to 70 meters deep, with hazards from partially collapsed ceilings and break-down chunks. If bone injuries occur, they should be treated as follows: the injured area should not be moved or realigned, soft padding should be applied for support, ice should be used to reduce swelling, and emergency medical assistance should be sought immediately while monitoring blood circulation in the injured area.	"[""Chris Killey, Greg Gregory, Katherine Hurley, Roy Mueller, Dan Leonik, Odette Harmsen, Larry Norton, Paul and Lou-Anne Nicholson, Philippe Montaggioni, Kamal Babour, Fabrice Uran, Karl Leyrer, Kevin Devlin,Linda Holloway\nFifteen Dhahran Geoscience Society (DGS) members recently got the chance to study reservoir-prone carbonate rocks from a unique perspective: in tube-like crawlways within the rocks themselves some 18 meters (60 ft.) underground in a dahl, or cave, called Bat’n Sabsab.\nMuch of eastern Saudi Arabia is characterized by thick sections of carbonate strata, some lying just beneath the desert surface. In some areas, particularly near Riyadh and ArAr to the north, extensive cave networks in carbonates have been discovered and mapped.\nBat’n Sabsab is one of the few known major caves located relatively close to the Gulf.. It lies about 250 kilometers (155 miles) to the west of Dhahran and 30 kilometers (18 miles) from the nearest paved road..\nAlthough devoid of the decorative and delicate stalactites, stalagmites and helictites which highlight many of the Kingdom’s caves, it is nonetheless a geologically significant feature in Tertiary limestone.\nIt has numerous passages at several levels that were formed in association with north-south trending fractures, and can be accessed from three fracture-related entrances.\nGetting ready to rappel into Bat'n Sabsab: Greg andFabrice; Dan, and Kamal\nThe DGS members arrived at the cave entrances in the middle of a large basinal drainage area, surrounded by outcropping marly hills, after an hour-long, off-road journey through a wide spectrum of terrain.\nPanoramic view of Sabsab setting; Vehicles on-site\nThey gathered their gear, including lights, hardhat, knee pads and water, and split into four groups. Three groups entered the gently sloping south entrance, and one rigged ropes for the 6-meter (20 ft.) vertical drop into the cave from the north entrance.\nThat fourth group subsequently rigged three additional steep drops in the middle of the cave, gaining access to its deepest portions -- which feature narrow, sinuous, tunnel-like passages, many of which are partially filled with cool, crystal-clear water.\nIt’s quite likely this was the first time that the lower passages have ever been so deeply penetrated by cavers. And, there appears to be no end in sight to the longest tunnels, which lie well below sea level.\nDGS cavers penetrated at least 70 meters (230 ft.) into a deep, contorted bifurcating “pipeline,” which was choked in places with sand and “break-down” chunks from the partially collapsed cave ceiling. In a unique bonus, participants experienced moments of complete darkness and silence by turning off their lights and lying quietly within the farthest-reached depths of the cave.\nGreg returning from the far distant part of the tight tunnels\nThe experience provided “delicious minutes of meditative repose,” said Chris Killey of Dhahran.\n“In the inky blackness ... the silence was deafening. It was magical sensory deprivation [where] a pin drop might sound like a cannon.” (See more of Chris's insightful comments below - Editor)\nTheir distant explorations completed, the cavers gradually worked their way back up through the cave’s shallower portions. Overcoming some navigational uncertainties and challenges, they eventually made a joyous return to the sunlit surface, having spent some four hours exploring within the Earth.\nDead dhubb at the bottom of a long dark drop, way beyond the surface. How did it get so far inside the cave ??\nMost of the cavers spent the night near a small canyon north of Bat’n Sabsab, where comfortable temperatures, and clear, star-filled skies contributed to a congenial camping atmosphere.\nKarl entering the narrow walk down into the south entrance\nAfter breakfast the next morning, the cavers’ convoy took a scenic northeasterly route, bouncing past large groups of camels and a deep, expansive wadi to reach the main Hanid road and head for home.\nAll fifteen members of the expedition gained valuable experience and insight with their cave explorations. They are eagerly looking forward to new opportunities to explore the voids beneath the desert.\nKids at camel camp, seen on the way back to Hanid\n“It was a battle of bones, muscles, willpower, ego, dust and mud,” Killey said of her experience. “I can't wait for the next one!”\n-- Greg Gregory\nFew people can wax poetical while sliding through the mud, in total darkness, down ever-narrowing tunnels. Chris Kiley is one of those few! Her report follows. Editor\nIt's two days after the fact and every muscle in my body aches. It’s a caving legacy they say…\nImagine crawling along on your belly in a tiny rocky limestone tunnel, hard hat hitting the roof every few seconds, knee guards jamming in the spaces between the rocks, elbows bashing into the walls on either side. Somehow we inch along on forearms and elbows, twisting and turning hips and thighs inch by inch. Legs doing over-time and screaming at you to stop. Toes dig in to propel you forward, to yet another twist in the tunnel. Your caving buddies just ahead, the soles of their shoes lit up by your headlight. If they can do it, then so can you! They’re an inspiration… Somebody else scraping along behind you, huffing and puffing….\nThirty minutes pass by and we come to a six-foot-long puddle of water stretching across the tunnel floor. No way around but through. Only a few inches between you and the roof. Sink your chest and belly into the cool liquid and slime into it, twisting through it to the next little cave. This must be the closest thing to mud wrestling. The biscuit in my shirt pocket turns to mush. My water rations dwindling. Don’t forget to twist the bum bag around to the back – it could be the lifesaver – contains spare flashlights, batteries, water bottle and a little map of the known tunnels in this long cave. Don’t get it soaked.\nFabrice in the tight tunnels, over a silted-up crystal-clear puddle\nEach little event takes on mountainous proportions. Ever rope-climbed rock walls before? Its easy when there’s no other way to go! Talk about breaking through personal boundaries! And then there’s the ego to contend with as well – of course you can do it!\nAnother 20 minutes of crawling goes by and we come to a real big space, about 10sq.ft with ceiling five feet up. Break time and we stop to gather our wits and rest for a bit while the hardened cavers explore new ground further along. They return after twenty minutes with tales of more narrow access ways & water pools.\nKamal, Chris, Odette and Larry, going deeper down the sloping, connecting shaft\nWe really take a break now; turn off our lights and lay quiet and still in the inky blackness. The silence is deafening. Its magical, sensory deprivation. A pin drop might sound like a cannon. I hope the others can’t hear my mind chattering on.\nAfter endless delicious minutes of meditative repose, our fearless leader breaks the silence and forces us to come to life. We heave our limbs into movement again. Backtracking, we now know what’s in front of us, exactly where we’re going, and how long it will take to get back to the beginning point.\nChris climbing up the shaft above the tight wet tubes\nOn and on down the endless tunnel, it seems to take forever. Fifteen minutes later, someone up front says they can’t get through a narrow bit. Doubt starts to creep in and I realize that I don’t recognize any of these walls, twists and tunnel turns. Somebody else up front says they don’t think this is the right way. In my bones I feel I already know this, but hey - I’m a virgin caver; this is my first time. I can’t be sure about anything yet. Its finally a group decision – we’ve come the wrong way! - down a narrowing tunnel which will eventually lead to a dead-end… Somebody yells “Don’t anybody panic” and I immediately wonder why I’m not panicking. I’m confused about what to panic about (yet another new experience).\nChris, Odette, Larry, and Dan, elated to be in a large breezy chamber, after backing out of the southernmost tight, warm, and fetid dead-end passage.\nWe all slowly inch uncomfortably backwards, on and on; and finally come back to the drop which is marked with a rope and find the real entrance to the exit. It leads us to the big finish-line cave and the blinding sunlight. Euphoria overtakes me. After 4 hours underground, I make it back to the real world. It was a battle of bones, muscles, willpower & ego, dust and mud. No wonder people go back for more and more. Caving exploration must be one of the last great frontiers…\nI can’t wait for the next one!\nAND THAT'S NOT ALL, FOLKS!\nWant to know more about Sabsab? Check out the following trip reports:\nDahl SabSab, April 19-20,\n2001 by Greg\nBat’n SabSab Trip Report, March 29-30, 2001 by Marek Wiechula"", 'Fractures occur when the bones break. Open fractures are when the bone has broken through the skin or when a wound is present. A fracture is closed when there is no disruption of the skin. On the other hand, dislocations occur when there is an abnormal separation in the joints, where the bones meet.\nIn all cases of fractures and dislocations, the person should not be moved unless danger is present in the environment. Basic first aid requires that the injured bone, even the limbs, should not be realigned or pushed back. Moreover, it should not be allowed to move at all. Provide soft paddings and slings to support the position chosen by the person. Apply ice to the fractured or dislocated limb. These should reduce swelling and pain. The rescuer should check and monitor for circulation, ensuring that the injured area has continuous blood flow or nerve sensations. Emergency medical assistance should be called immediately. Fracture injuries in the limbs vary in first aid treatment. This is because of the different types and shapes of the bones in the body,\nWhen the arm is fractured, the weight of the elbow and the lower arm is supported by the person to minimize pain. Fracture of the upper arm may be grave due to the pressure on the major nerves and blood vessels, especially the ones adjacent to the shoulder and elbow joints. Help the person into the most comfortable position, usually sitting on a chair or half sitting with assistance. Place the injured arm of the person on a pillow or folded clothing. While waiting for emergency help, apply an elevation sling to minimize the injured arm’s movements.\nIf the lower arm or wrist is fractured, the injured arm of the person may be supported with the other arm. Help the person into the most comfortable position, usually sitting down with the weight of the injured wrist against the body. To give support, a pillow or clothing may be placed on the lap to give a soft support for the patient to use so he/ she can rest the burden of the arm. While waiting for emergency help, utilize a firmly folded newspaper folded into a gutter shape and use as a splint under the fractured wrist. Use a narrow-fold bandage above and below the injured limb to keep the splint in position. Arm slings may be applied for supplementary support and stability.\nThe same treatment can be given to a fractured hand and fractured or dislocated finger. Do not attempt to move replace the dislocated finger, only a medical professional may do so. To relieve of pain, soft padding may be applied around the injured hand and/ or fingers. Apply an elevation sling, taking extra precaution to prevent hitting the injured area when tying the knot.\nOftentimes, it is hard to determine whether a person has suffered a fracture of sprain in the ankle. However, when there is doubt, treat the injury as a fracture. The same treatment may be given to fractured or dislocated foot or toe/s. Help the person to lie down\nand elevate the injured ankle/ or foot on soft padding. This will remove the weight from the injured food and minimize swelling and pain. Do not remove the shoes to prevent any further injury unless there is a suspected open wound. A soft pillow or rolled blanket may be utilized to immobilize the injured area. To keep the padding in place, make use of a two narrow-fold bandage.\nAlthough these injuries are fairly common only in sports, medical assistance is required for any type of bone injury. The sooner first aid is performed on victims, the greater chances of minimizing damages. Through first aid training and various other workplace approved programs, the lay community can provide to victims to minimalize pain in emergency situations such as these.']"	['<urn:uuid:66504f51-16b2-4d16-9885-f84223231b4d>', '<urn:uuid:89202a48-993f-4f4c-a2df-5582df7e6dab>']	factoid	direct	short-search-query	distant-from-document	multi-aspect	novice	2025-05-12T23:56:45.148498	5	77	2130
38	How do airports track and monitor passenger data to improve security, and what are the specific measures being implemented at US airports to identify people who overstay their visas?	Airports use data collection and analytics across various applications to improve security. They implement machine learning and analytics to establish baselines of normal behavior and detect anomalies, such as suspicious account access or unusual baggage handling patterns. Additionally, they use data encryption and tokenization technologies to protect critical customer information like credit cards and identification numbers. In US airports, Customs and Border Protection is implementing biometric exit systems that use facial recognition technology to scan passengers at departure gates. This system matches photographs taken at the gate against facial scans that foreign visitors submitted when entering the country or from their visa applications. The system also checks passenger identification against law enforcement and intelligence databases. This effort aims to better track the approximately 629,000 visitors who overstayed their visas last year, as visa overstays represent the largest group of people in the United States illegally.	['Customer experience is paramount in an industry as competitive and prone to issues as air travel. To deliver a great experience, airports are innovating, from mobile apps to mood lighting and entertainment systems. An area that’s less visible to passengers is the activity monitoring and data collection airports conduct across a wide range of applications. This information is used to improve operations that impact every stage of the traveller experience. Even before passengers arrive at the airport, there are many ways applications are helping to make the experience more efficient, and as a result, more data than ever is being used to protect passenger privacy and keep departures on time. But, as well as the opportunities this creates, it’s also important to be aware of the cybersecurity risks.\nTicketing, frequent flyer miles, and personal data: access points for identity theft and fraud\nLooking at the recent experiences of some of the best-known airlines offers some valuable lessons. In 2018, British Airways announced that its systems had been hacked and the credit card information of roughly 380,000 passengers had been stolen. According to GDPR guidelines, the maximum penalty for a company hit with a data breach is a fine of either £17 million or four per cent of global turnover, whichever is greater. In this case, authorities intend to order British Airways to pay a fine of nearly $230 million for the breach.\nTwo months later, Cathay Pacific reported that the personal information of some 9.4 million passengers had been compromised — a collection of sensitive data that included passport and other identification numbers.\nAttacks like these have ripple effects beyond fines and public scrutiny: they impact customer confidence and brand reputation. That’s why data encryption and tokenisation technologies to protect critical customer information —such as credits cards, identification numbers and bank accounts — are now so important to keeping every aspect of the travel process more secure.\nBeyond credit card data, a growing black market for frequent flyer data is flourishing. Visitors to the ‘dark web’ can find hundreds of thousands of airline miles available at a fraction of the cost they would pay to airlines or credit card companies. Those ill-gotten miles can then be used to redeem gift cards or other points-based rewards – a simple form of illicit arbitrage. These miles can also be resold and put toward first-class upgrades and other bonus offers, according to Comparitech’s study into the black market for frequent flyer miles conducted last year.\nThat resale market has created a demand for bad actors to crack frequent flyer accounts. It’s also created a need for analytics to eliminate an unrelenting risk. For any application of this nature, software can be implemented that can spot behaviour-based anomalies — such as repeated password reset requests on the same account or login attempts from an odd location — to identify possibly illicit account access. Customers can then be alerted before the problem develops further.\nThat process starts with collecting data and tracking every incident, whether benign or threatening, and defining what constitutes normal account use. By leveraging machine learning and analytics, it’s possible to create a baseline of standard behaviour for the individual. This makes it easier to spot behaviours that fall outside that norm. Appropriate action can then be taken to stop the activity and build processes to address them.\nBaggage and luggage: Turning to analytics\nSeveral airlines have discovered baggage handlers that have checked an extra bag filled with rare and high-tariff goods into the system for an accomplice to collect at the destination. In such cases, neither the passenger, airport nor the airline are aware of the illegal use of identity and systems.\nNow that all appears to be on the brink of change: as of June 2018, the International Air Transport Association issued Resolution 753 requires that airlines track baggage at four key points: passenger handover to airline, loading to the aircraft, delivery to the transfer area and return to passenger.\nAirports and airlines are turning to data collection and analytics to solve this problem. Beyond tracking the location of a piece of luggage at a given time, analytics can spot unusual patterns, such as bags unexpectedly entering the system on loading or baggage handlers that stand out for baggage that is persistently misrouted — a sign that they may be using passenger bags to route illicit goods to an accomplice.\nIn the end, that means nothing gets on the plane that shouldn’t, which plays a significant role in keeping planes and passengers secure.\nRunways and perimeter breaches: Securing access to the plane\nBetween 2004 and 2015, there were 268 perimeter breaches at airports that handle three-quarters of U.S. commercial passenger traffic.\nFor example, there was the mentally ill man in L.A. who hopped the fence eight times in less than a year and twice reached stairs that led to jets. There was the man who threw his bike over a fence in Chicago, riding the bike across a runway and knocking on a terminal door. Then there was the man who drove an SUV through a security gate in Philadelphia and played chicken with a plane trying to land. In the UK, consumer drones entering the airspace of London Heathrow forced the entire airport to shut down.\nMuch of the protection required to prevent those breaches is physical, with additional barricades and security personnel on the ground. But there’s also the need to protect what’s on board because, in the modern airline industry, threats don’t always take a physical form.\nEvery month, there are 1,000 cyberattacks across the air transport industry. At the same time, just 35 per cent of airlines and 30 per cent of airports believe they are prepared to deal with cyber-threats today.\nBut, the same technology that is creating these new vulnerabilities is also being used to stay ahead of them. Machine learning, big data and analytics are all being used to gather data and set a baseline of normal behaviour, which makes threats and anomalous behaviour easier and faster to identify. Systems that can detect and escalate unusual patterns and help pinpoint event timelines provide deep insight on security events that may be the source of the anomalies. Gaining access to that insight before something happens is critical because it allows officials to stop problems before they start.\nIf something does come to pass, advanced tracking and analysis also facilitates a faster investigation — and ultimately find a faster way to resolution. The right tools can transform a process that typically takes weeks of searching through multiple months-worth of raw incident logs into one that takes only seconds — and presents a timeline for each security incident. And the faster you can find your way to the root cause of a problem, the quicker you can implement policies and procedures to prevent the same thing from happening again.\nPlanes, ageing fleets and controls: Securing the plane\nAnalytical insights are used every day to secure the plane from emerging and potential threats. In the past several years, a few examples of cybersecurity attacks on planes have surfaced.\nIn 2015, a cybersecurity consultant told the FBI he was able to successfully hack into an airplane’s computer system and force it to climb. Then, a year later, a Department of Homeland Security official remotely hacked the systems of an airplane parked at an airport in Atlantic City, N.J.\nWith a significant portion of every airline’s fleet made up of older airplanes, how do aircraft mechanics and maintenance teams track when those older systems are about to break or need to be tuned? At the same time, airplanes are coming onto the market with new bells and whistles, greater energy efficiency and their own unique vulnerabilities.\nSo how do we ensure both old and new airplanes are safe and secure? And how do we prevent cybersecurity attacks?\nThe answer, once again, lies in software.\nNewer planes can harness the power of data to spot red flags and identify possible security breaches as they’re happening. As standard procedure for newer planes, all flight data from a single flight is automatically downloaded when the aircraft is parked. This data will be used to gauge what’s happening in flight and pinpoint any anomalies in the plane’s functions. Airlines then run applications that log the files and use machine learning to analyse them for irregularities onboard and during the flight. Data collection and analysis ensure that problems don’t repeat themselves over time.\nFlying remains one of the most convenient and safest ways to travel. As the travel industry continues to provide better and more personalised experiences, analytics software will continue to drive innovation through the entire journey for passengers.\nOrion Cassetto, director product marketing, Exabeam', 'WASHINGTON — On a recent morning, passengers boarding Emirates flight 232 from Washington Dulles airport to Dubai confronted an unfamiliar sight: a uniformed Customs and Border Protection officer at the gate.\nBefore passengers approached the airline gate agent, the customs officer, Sung Hyun Ha, scanned their travel documents at a kiosk, which was also equipped with a camera. The photograph taken was matched against a facial scan that foreign visitors submitted to Customs and Border Protection when they entered the country or from their visa application, while the passenger’s identification also was checked against law enforcement and intelligence databases.\nThe pilot effort is part of a decades-long push to more accurately identify people who overstay their visas and remain in the United States, a group that represents the largest number of people in the United States illegally.\nThe department believes that if officials can better track who has left the country, they will be able to better assess who has stayed here beyond the legal limit of their visa.\nAccording to the Department of Homeland Security, last year an estimated 629,000 visitors to the United States — just over 1 percent of all travelers — remained in the country after overstaying their visas as students, workers or tourists, and they represent a growing share of the nation’s unauthorized immigrant population.\nJohn Roth, the inspector general at the Department of Homeland Security, said the number of overstays posed a greater security risk than might be apparent from the relatively small numbers, noting that two of the Sept. 11 hijackers had overstayed their visas.\nAn executive order signed in January by President Trump would require all travelers to the United States to provide biometric data on entry and exit from the country. Currently, visitors provide biometric data only when they enter the country.\nBoth Democratic and Republican administrations have long viewed a biometric exit system as preferable to paper documents to ensure border security, but for years the technology to collect that information was slow to take hold. Now devices that gather biometric information, from smartphones to security systems, are in widespread use.\n“The technology has finally caught up to the legislative intent,” said Christian J. Beckner, a former staff member on the Homeland Security Committee who is now deputy director of the Center for Cyber and Homeland Security at George Washington University.\nBut the biometric exit system has come under criticism from privacy rights groups, who say the facial recognition scans, while ostensibly set up to make sure foreign visitors leave the country, are an invasive form of surveillance of American citizens. Harrison Rudolph, a fellow at the Center on Privacy & Technology at Georgetown University Law School, raised issues about the accuracy of facial recognition scans and said the agency had not laid out clear guidelines on how the system was to be used.\n“Their own data show about 4 percent of people are rejected in facial recognition,” he said. “And what happens if you are rejected? Are you selected for some type of further screening? Customs and Border Protection is subjecting U.S. citizens who want to fly abroad to unreasonable searches.”\nKim Mills, director of the Entry-Exit Transformation Office at Customs and Border Protection, said that while the system did take facial scans of American citizens, the information was used in a very limited way.\n“For American citizens, the photo scan is only used to confirm that they are indeed citizens,” she said. “We’re not collecting any new information.”\nNearly 20 years ago, Congress passed a law requiring the federal government to develop a system to track people who overstayed their visas. After the Sept. 11 attacks, an entry- and exit-tracking system was seen as a vital national security and counterterrorism tool, and the 9/11 Commission recommended that the Department of Homeland Security complete a system “as soon as possible.”\nNearly three dozen countries, including many in Europe, Asia, and Africa, collect biometric information — fingerprints, iris scans and photographs that can be used for facial recognition — of people leaving their countries. But the United States has trailed other nations in adopting the technology, despite the congressional mandate.\nOne reason has been the design of airports in the United States. In most countries, international passengers depart from a separate terminal where customs officials collect biometric information of those exiting the country. But in the United States, passengers for domestic and international flights are often in the same terminals, making it difficult for officials to collect information on people who leave the country — a flight to Jackson, Miss., can be located next to one going to Japan.\nCustoms and Border Protection has been testing a number of biometric programs in partnership with several airlines in Atlanta, Boston, New York and Washington, funded by up to $1 billion collected from certain visa fee surcharges over the next 10 years.\nJohn Wagner, deputy executive assistant commissioner at the Customs and Border Protection’s Office of Field Operations, said the program would look different at different airports. In some cases the airlines themselves would run the program, incorporating the biometric system into their boarding process. At some airports, Mr. Wagner said, the exit system would be staffed by Customs and Border Protection officers, similar to the situation passengers faced at the Emirates airline boarding gate at Dulles airport.\n“We’re trying to figure out the most effective way to do biometric exit,” he said.\nFor example, in New York and Atlanta, the agency has partnered with Delta Air Lines to test a facial recognition system at the boarding gate for international flights.\nThe Delta system checks whether a passenger is supposed to be on the plane by comparing the individual’s face with a gallery of photos that the airline has of people on its travel manifest. It also checks the passengers’ citizenship or immigration status against various Homeland Security and intelligence databases. For American citizens, the facial scans are checked against photos from State Department databases.\nIn Boston, Customs and Border Protection, in cooperation with JetBlue airlines, is testing a facial recognition system for travelers flying to Aruba.\nMr. Wagner said the agency hoped to begin using the biometric exit system at all airports with international flights in 2018.\nHomeland Security officials say they believe the entry and exit biometric system can also be used to crack down on illegal immigration.\nA report by the Department of Homeland Security inspector general’s office found that Immigration and Customs Enforcement, the agency responsible for investigating in-country visa overstays, had to piece together information from dozens of systems and databases, some of which were not integrated and did not electronically share information.\nIn the absence of a biometric entry and exit system, the agency depends on incomplete data from airline passenger manifests to track people who leave the country.\nICE agents and officers are currently unable to say how often targets of investigations are incorrectly recorded as having left the country, the department’s Office of Inspector General said.\nThe inspector general said there was a backlog of 1.2 million visa overstay cases, and ICE has arrested under 1 percent of the individuals who potentially overstayed their visas.']	['<urn:uuid:1c7739f1-e27f-4946-8c11-65ee2ad6cba2>', '<urn:uuid:672efb7e-6819-42ac-bc0e-1117ecc2210a>']	open-ended	direct	verbose-and-natural	similar-to-document	multi-aspect	novice	2025-05-12T23:56:45.148498	29	145	2643
39	atmospheric band color meanings jupiter	On Jupiter, the banded pattern of colors is related to cloud height and temperature. Lighter colored clouds are higher and cooler, while darker clouds are lower and warmer. The planet is covered with storms that appear as red, white and brown spots, often on a white background.	['After a summer “out of orbit” for re-painting, the Planet Jupiter will return to its spot in the Maine Solar System Model on Friday morning, Oct. 6. Located 5.2 miles from the Sun, which is housed at the University of Maine at Presque Isle, the planet is one of the most easily-spotted features of the Maine Solar System Model, which stretches from UMPI to Topsfield, Maine.\n“We originally planned to have this down for only a few weeks,” Kevin McCartney, coordinator for the model, said. “However, 15 northern Maine winters had caused considerable deterioration of the northern hemisphere fiberglass surface and more maintenance was needed than originally anticipated.”\nWork on the planet took most of the summer, delays mainly due to the busy schedules of local companies that donated labor to complete the project. The entire solar system model, which remains the largest in the Americas, was built by the community of Northern Maine, with participation from many local individuals and companies. Maintenance of the model components will occur through the same process, with a zero budget.\nMcCartney said the model serves as a well-appreciated testament to the Northern Maine community. Everything associated with the solar system model is a community project of many people. The Jupiter site is no exception, with the students of four Aroostook County schools involved in the original construction. The work to take the planet down for maintenance and put it back in “orbit” was done by Langille Construction in Washburn, with transportation to and from Beaulieu’s Garage and Auto Shop in Caribou provided by Dan Robertson. Paint and materials for the recent work on Jupiter was provided by Advance Auto Parts. Mowing the ground around Jupiter and some other planets is done by Larry and Nancy Fletcher of Mars Hill.\nThe entire surface of the planet was recovered in fiberglass and sanded: “We have learned a few things about the effects of weathering here, and I hope that the new cover and paint can last another 25 years,” Jeff Robertson, manager at Beaulieu’s, said.\nRepair to the globe and initial primer was done by Colin Patterson and Rick Canterbury. Since the house paint that covered the planet for 15 years, as it sat in its spot along Route 1, had not held up very well, the decision was made to use fiberglass, which should last much longer.\nOrganization of the repainting of Jupiter was done by Richard and Deborah Jones, members of the Aroostook County Astronomy Club. Additional painting work was done by Christine Akridge, who paints for Shutterbug Studios, and McCartney.\n“We tried to draw in some of the complicated atmospheric turbidity that characterizes the surface of Jupiter,” Jones said.\nSpecial attention was given to the Great Red Spot, which has been known for more than 350 years and takes six days to rotate around the planet. The final clear coats that cover the paint were done by Sam Robertson.\nPainting Jupiter presents a special challenge, as this planet has perhaps the greatest variation of color, at least seen from a distance: “This banded pattern seems to be connected to the height and temperature of the clouds,” Jim Stepp, local astronomy enthusiast, said.\nLighter colored clouds are higher and cooler, with darker clouds being lower and warmer. The planet is covered with storms that show up as red, white and brown spots, often on a white background. Those who painted the planet tried to reproduce that effect.\nThe Maine Solar System Model was built over a period of four years, from 1999 to 2003, with dwarf planets added in 2008. Established by the University of Maine at Presque Isle, the Northern Maine Museum of Science, and the northern Maine community, it is the largest solar system model in the Western Hemisphere, with both the planet diameters and distances from the Sun set to a scale of one mile equal to an astronomical unit (AU, the distance from the Sun to Earth). The model consists of a 50-foot diameter Sun and extends 95 miles to the dwarf planet Eris, which is about one inch in diameter, in Topsfield.\n“Tourists are often very curious and want to learn more about the model,” Theresa Fowler, Executive Director of the Central Aroostook Chamber of Commerce, said.\n“At the Houlton Visitor’s Center, we see a number of tourists who have traveled to the region just to see the Solar System Model,” Kathy Hogan, manager of the center, added.\nMaintenance to Saturn and Neptune will likely be needed over the next several years, and construction of posts and bases are needed for two more recently recognized dwarf planets, to be located north of Caribou.\nFor more information, about the Maine Solar System Model, contact UMPI’s Community and Media Relations Office at 768-9452 or email@example.com.']	['<urn:uuid:4263e980-7534-4d82-a4f9-dc7dd0642b26>']	factoid	with-premise	short-search-query	distant-from-document	single-doc	expert	2025-05-12T23:56:45.148498	5	47	795
40	As a wildlife biologist studying bear populations, I'm concerned about how trophy hunting impacts Kodiak bears in Alaska - what effects have researchers observed on their size and behavior?	Researchers have found that repeated hunting over many years has gradually diminished the size of Kodiak bears in Alaska. Additionally, hunting has altered their behavior - the bears have become so frightened of humans that they often avoid their normal salmon runs, which undermines their nutrition and health.	"['For supporters of animal rights, hunting for trophies is one of the worst kinds of violations. The animal rights viewpoint starts with the premise that animals deserve to live out their natural lifespan just like humans. From that standpoint, killing any animal for sport is morally offensive: It deprives animals of their right to life, and their deaths serve no justifiable purpose. The offense is compounded when some of the animals killed by trophy hunters are from rare or endangered species.\nSome methods of obtaining exotic or outsized trophies are far from sportsmanlike. Proponents of ethical hunting and animal welfare both condemn the practice of canned hunting -- breeding animals in captivity to be killed by hunters in enclosed spaces. South Africa is one of several countries that have banned the practice, but it still continues [source: Environmental News Service]. Practices like canned hunting are considered by some as abuse of wildlife.\nSome scientists say that systematically hunting the most mature members of an animal population can adversely affect its gene pool. This will reduce the average size of future generations and threaten the ability of the species to thrive in its habitat. Researchers claim repeated hunting over many years has gradually diminished the size of the Kodiak bears of Alaska. Furthermore, hunting has altered the bears\' behavior in a cause-and-effect manner. Because the bears have grown so frightened of humans, they are more likely to forego their normal salmon runs, thus undermining their own nutrition and health. Killing off the adult males of any species may decrease the survival odds of the surviving young. It may also destabilize the population by creating a shortage of males. If females are also targeted, hunting can mean the loss of the survival knowledge that mother bears pass on to their offspring [source: Nilsson].\nDespite the arguments, trophy hunting is sure to continue around the world. How do you feel about it? Is trophy hunting good, bad or somewhere in the middle? Now that you have the facts, you can join in on the debate that is sure to continue for generations to come.\nRelated HowStuffWorks Articles\nMore Great Links\n- African Sky. "" Hunting the Big Five, Hunt with African Sky."" (Accessed 11/24/08)http://www.africanskyhunting.co.za/hunting-big-five.html\n- African Trophy. ""Hunting Safaris."" (Accessed 11/24/08)http://www.africantrophy.com/safari.html\n- African Trophy. ""Trophies, Horns & Hides."" (Accessed 11/24/08)http://www.africantrophy.com/trophies.html\n- Albrecht, Carl W. ""Arsenic and Old Collections."" Ohio Historical Society Local History Notebook. March/April 1993. (Accessed 11/24/08)http://www.ohiohistory.org/resource/oahsm/notebook/marapr1993.html\n- Boone and Crockett Club. ""26th Big Game Awards Results."" (Accessed 11/24/08)http://www.boone-crockett.org/bgRecords/records_26thap_results.asp?area=bgRecords\n- Boone and Crocket Club. ""Join B&C."" (Accessed 11/24/08)http://www.boone-crockett.org/join/associates_overview.asp?area=join\n- CITES. ""Ivory sales get the go-ahead."" Press Releases. 06/02/07. (Accessed 11/24/08)http://www.cites.org/eng/news/press/2007/070602_ivory.shtml\n- CITES. ""What is CITES?"" Discover CITES. (Accessed 11/24/08)http://www.cites.org/eng/disc/what.shtml\n- Dorrington, Stewart. ""Hunting in South Africa: The New Regulations."" CIC. (Accessed 11/24/08)http://www.cic-wildlife.org/index.php?id=263\n- Dorrington, Stewart and Butland, Peter. ""Trophy Hunting: The Professional Hunter\'s Dilemma."" African Indaba eNewsletter. Vol. 5. No. 3 Special Issue. (Accessed 11/24/08)http://www.africanindaba.co.za/Archive07/AfricanIndabaVol5-3.pdf\n- Environmental News Service. ""South Africa Curbs Canned Lion Hunting."" 02/20/07. (Accessed 11/24/08)http://www.ens-newswire.com/ens/feb2007/2007-02-20-02.asp\n- Gunn, Alastair S. ""Environmental Ethics and Trophy Hunting."" Ethics & the Environment\n- Vol. 6 No.1. Indiana University Press. 2001. (Accessed 11/24/08)http://muse.jhu.edu/journals/ethics_and_the_environment/v006/6.1gunn.html\n- Lee, Raymond. ""Hunting for Trophies."" African Indaba eNewsletter. Vol. 5. No. 3 Special Issue. (Accessed 11/24/08)http://www.africanindaba.co.za/Archive07/AfricanIndabaVol5-3.pdf\n- Meredith, Don H. ""Trophy Hunting."" Don H. Meredith Professional Writing Services. 1999. (Accessed 11/24/08)http://www.donmeredith.ca/outdoorsmen/TrophyHunt.html\n- Microsoft Encarta Encyclopedia Online. ""Taxidermy."" (Accessed 11/24/08)http://encarta.msn.com/encyclopedia_761556049/taxidermy.html\n- Missoula Valley School of Taxidermy. ""Taxidermy School Course Description & Curriculum. (Accessed 11/24/08)http://www.taxidermyschools.com/\n- Nelson, Dan. ""The Vanishing Hunter, Part 1: Hunting Participation Continues Long-Term Retreat."" Delta Waterfowl Magazine. Spring 2008. (Accessed 11/24/08)http://www.deltawaterfowl.org/magazine/2008_01/vanishinghunter.php\n- Nilsson, Greta. ""Endangered Species Handbook: Persecution and Hunting: Effects of Trophy Hunting on Animals."" Animal Welfare Institute. 1983, 2005. (Accessed 11/24/08)http://www.endangeredspecieshandbook.org/persecution_effects.php\n- Parker, Ian. ""Hunters Shoot Themselves in the Foot."" African Indaba eNewsletter. Vol. 5. No. 3 Special Issue. (Accessed 11/24/08)http://www.africanindaba.co.za/Archive07/AfricanIndabaVol5-3.pdf\n- Roosevelt, Theodore. ""Outdoor Pastimes of an American Hunter."" Charles Scribner\'s Sons. 1908.\n- Schramm, Dieter. ""Trophy Hunting: How I See It!"" African Indaba eNewsletter. Vol. 5. No. 3 Special Issue. (Accessed 11/24/08)http://www.africanindaba.co.za/Archive07/AfricanIndabaVol5-3.pdf\n- The Humane Society of the United States. ""Trophy Hunting."" (Accessed 11/24/08)http://www.hsus.org/wildlife/hunting_old/trophy_hunting/\n- Turkey Ridge Hunting and Fishing Sports Club. ""Home."" (Accessed 11/24/08)http://www.turkeyridgehuntclub.com/index.php\n- U.S. Fish & Wildlife Service. ""Frequently Asked Questions."" Polar Bear Information. (Accessed 11/14/08)http://www.fws.gov/home/feature/2008/polarbear012308/pdf/037257PolarBearQAFINAL.pdf']"	['<urn:uuid:cea48297-46f0-4718-b9bb-fb50ef1fdc12>']	factoid	with-premise	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-12T23:56:45.148498	29	48	705
41	scientific explanation why proteins living things use left handed amino acids only	Life exclusively uses left-handed amino acids because proteins cannot function with a mix of left- and right-handed amino acids. This preference may have originated from asteroids, where a small initial left-hand excess (possibly caused by polarized ultraviolet light from stars) could have been amplified through crystallization processes in the presence of liquid water, and then delivered to Earth through meteorite impacts.	"['July 26, 2012\nTagish Lake Meteorites Reveals Secrets Of The Early Solar System\nLee Rannals for redOrbit.com - Your Universe Online\nNew clues have been unveiled that shed light on why living things use only molecules with specific orientations.Research analyzing meteorite fragments that fell on a frozen lake in Canada is providing strong evidence that liquid water inside an asteroid leads to a preference of left-handed over right-handed forms of common protein amino acids in meteorites.\n""Our analysis of the amino acids in meteorite fragments from Tagish Lake gave us one possible explanation for why all known life uses only left-handed versions of amino acids to build proteins,"" Dr. Daniel Glavin of NASA\'s Goddard Space Flight Center and lead author of a paper being published in the journal Meteoritics and Planetary Science, said in a press release.\nA meteorite landed on Earth back in January 2000, and because many people witnessed the event, pieces were able to be collected and preserved in their frozen state for research.\n""The Tagish Lake meteorite continues to reveal more secrets about the early Solar System the more we investigate it,"" Dr. Christopher Herd, a co-author on the paper, said. ""This latest study gives us a glimpse into the role that water percolating through asteroids must have played in making the left-handed amino acids that are so characteristic of all life on Earth.""\nProteins are used in everything from structures like hair to enzymes, and are the catalysts that speed up or regulate chemical reactions. Life uses just 20 different amino acids in a variety of arrangements to build millions of different proteins.\nAmino acid molecules can be built in two ways that are mirror images of each other, and although life based on right-handed amino acids would presumably work fine, they cannot be mixed.\n""Synthetic proteins created using a mix of left- and right-handed amino acids just don\'t work,"" Dr. Jason Dworkin of NASA Goddard, co-author of the study, said.\nBecause life is unable to function with a mix of left- and right-handed amino acids, scientists are trying to know how life got set up with the left-handed ones.\n""The handedness observed in biological molecules — left-handed amino acids and right-handed sugars — is a property important for molecular recognition processes and is thought to be a prerequisite for life,"" Dworkin said.\nThe team used the meteorite samples and mixed them into a hot-water solution, then separated and identified the molecules in them using a liquid chromatograph mass spectrometer.\n""We discovered that the samples had about four times as many left-handed versions of aspartic acid as the opposite hand,"" says Glavin.\nAspartic acid is an amino acid that is used in every enzyme in the human body, and is also used to make sugar substitute Aspartame.\n""Interestingly, the same meteorite sample showed only a slight left-hand excess (no more than eight percent) for alanine, another amino acid used by life,"" he added.\nHe said that at first, the findings did not make sense because if both amino acids come from contamination by terrestrial life, both should have large left-handed excesses.\n""However, a large left-hand excess in one and not the other tells us that they were not created by life but instead were made inside the Tagish Lake asteroid,"" Glavin said.\nThe team was able to confirm that amino acids were most likely created in space using isotope analysis.\nIsotopes are elements with different masses, and since the chemistry of life prefers lighter isotopes, amino acids that have a heavier isotope like carbon 13 were likely created in space.\n""We found that the aspartic acid and alanine in our Tagish Lake samples were highly enriched in carbon 13, indicating they were probably created by non-biological processes in the parent asteroid,"" Dr. Jamie Elsila of NASA Goddard, a co-author on the paper who performed the isotopic analysis, said.\nThe research marks the first time carbon isotope measurements have been reported for these amino acids in Tagish Lake. The carbon 13 enrichment, combined with the left-hand excess in aspartic acid, provides strong evidence that some left-handed proteinogenic amino acids can be produced in excess in asteroids.\nSome say that large left-handed amino acid access in meteorites formed by exposure to polarized radiation in the solar nebula, however these are so large they cannot be explained by this alone. The team believes that another process would be required.\nThe large left-hand excess found in aspartic acid and not alanine gave the team a critical clue as to how these amino acids could have been made inside the asteroid.\n""One thing that jumped out at me was that alanine and aspartic acid can crystallize differently when you have mixtures of both left-handed and right-handed molecules,"" Dr. Aaron Burton, a NASA Postdoctoral Program Fellow at NASA Goddard and a co-author on the study, said. ""This led us to find several studies where researchers have exploited the crystallization behavior of molecules like aspartic acid to get left-handed or right-handed excesses.""\nHe said that because alanine forms different types of crystals, these processes would produce equal amounts of left- and right-handed alanine.\n""We need to do some more experiments, but this explanation has the potential to explain what we see in the Tagish Lake meteorite and other meteorites,"" Burton added.\nThe team believes a small left-hand excess could get amplified by crystallization and dissolution from a saturated solution with liquid water. Some amino acids have a shape that allows them to come together in a pure crystal form. These amino acids have a small initial left- and right-hand excess that could become greatly amplified at the expense of the opposite-handed crystals.\nOther amino acids have a shape that prefers to join together with their mirror image to make a crystal, which are comprised of equal numbers of left- and right-handed molecules. As these crystals grow, any small initial excess would be washed out for these amino acids.\nBoth of these processes can convert to left-handed to right-handed molecules, and vice-versa while they dissolve in the solution.\nThe process only amplifies a small excess that already exists. The team said that polarized ultraviolet light or other types of radiation from nearby stars may fair the creation of left-handed amino acids or the destruction of right-handed ones. This left-hand excess could then get amplified in asteroids by processes like crystallization.\nImpacts by asteroids and meteorites could help deliver this material to Earth, and left-handed amino acids may have been incorporated in emerging life due to their greater abundance. Similar enrichments of left-handed amino acids by crystallizations could have taken place on Earth in ancient sediments that had water flowing through them, the team said.\n""Since it appears a non-biological process can create a left-hand excess in some kinds of amino acids, we can\'t use such an excess alone as proof of biological activity,"" Glavin said.']"	['<urn:uuid:d1959928-05a6-48ce-bafe-c7e7108e26f6>']	factoid	with-premise	long-search-query	distant-from-document	single-doc	expert	2025-05-12T23:56:45.148498	12	61	1142
42	What prompted NATO to establish a group of experts to evaluate its future direction in 2020?	The panel was created after French President Emmanuel Macron declared NATO was experiencing 'brain death', which caused disputes within the alliance. This declaration, along with disagreements between Macron and US President Donald Trump, exposed major rifts in the alliance.	['NATO Secretary-General Jens Stoltenberg announced on Tuesday (31 March) the creation of a panel of 10 experts to determine NATO’s future after French President Emmanuel Macron declared last autumn that the alliance was experiencing “brain death”.\nThe strategic shift comes after a dispute between Macron and US President Donald Trump exposed major rifts in the Cold War-era military alliance.\nThe French resident’s sobering comments in an Economist interview took many NATO members by surprise and sent shock waves through the Alliance, which had already been plagued for months by squabbles over burden-sharing and strategic choices.\nThey caused usually diplomatic German Chancellor Angela Merkel to mildly rebuke Macron in public, while in private, according to a New York Times report, she told him she had suffered enough from his disruptive “truth telling”.\n“Over and over again I have to glue together the cups you broke just so we can sit together again and have a cup of tea,” the report quoted her as saying.\nMacron’s remarks also came amid a standoff between the US and Turkey, who late last year took unilateral military action in northern Syria and blackmailed the military alliance over the alleged lack of support in its actions in the region.\nAlthough Ankara backed off from a threat to block NATO’s Eastern European defence plans unless allies declared Kurdish fighters in Syria terrorists, the dispute exposed cracks in the 70- year-old military alliance.\nA Franco-German proposal for a strategic review of NATO’s strategic mission in the form of a “wise persons” group won broad support during the 2019 NATO Leaders Summit in December.\nNATO leaders then agreed Stoltenberg would initiate a “reflection process” on NATO’s future strategy, which, according to draft plans, could involve a stronger focus on the Middle East and Africa.\nNATO said the expert panel is meant to “offer recommendations to reinforce alliance unity, increase political consultation and coordination between allies, and strengthen NATO’s political role.”\nThis effectively means the panel is to determine how NATO can play a stronger political role and avoid public displays of dissent as seen around last year’s NATO summit in London.\nThe composition of the expert group takes into account the gender balance, the relevant experience and the geographical distribution of the allies.\nComprised of five men and five women, the panel will include, amongst others, former French foreign minister Hubert Vedrine, his former Polish counterpart and current MEP Anna Fotyga (PiS/ECR), former Italian deputy foreign minister Marta Dassu, and former Assistant NATO Secretary-General Tacan Ildem from Turkey, whose choice is an indication of the wish to mend relations with Ankara.\nOther appointed members are ex-Canadian national security advisor Greta Bossenmaier, cybersecurity expert and advisor to the Dutch government Herna Verhagen, Danish terrorist and security policy expert Anja Dalgaard-Nielsen, and British historian and advisor to UK Prime Minister Boris Johnson, John Bew.\nThe group will be co-chaired by Thomas de Maizière – a former member of the German Bundestag and German defence minister who is a longtime ally of Chancellor Angela Merkel – and A. Wess Mitchell, a former assistant secretary of state for European affairs in US President Donald Trump’s administration.\nHowever, security officials rated the choice of Mitchell, known as a hawk on Russia, and some of the other core conservative personalities, as a rebuff to Macron’s calls for warmer ties with Moscow.\nStoltenberg told reporters on Wednesday (1 April) he will present the outcomes and recommendation to NATO leaders during their next summit in 2021.\n“This is a good opportunity for NATO to look into how we can strengthen the alliance and strengthen its political dimension,” Stoltenberg said, adding that it is “natural that there are differences” among its members, who now comprise 30 countries after North Macedonia formally joined on 27 March\nNATO foreign ministers are set to meet for their first ever virtual teleconference on Thursday (2 April) to coordinate their response to the COVID-19 pandemic.\n[Edited by Zoran Radosavljevic]']	['<urn:uuid:e871d3d4-7c52-48fc-bfa7-f3e4f2306885>']	factoid	direct	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-12T23:56:45.148498	16	39	656
43	How do different halls balance size constraints with sound quality?	Concert halls employ various strategies to manage size and acoustics. The Ryman Auditorium, with 2,362 seats, deals with numerous reflective surfaces and uses strategic volume control and careful sound management through BSS Audio Soundweb London Architect matrix and Lake systems. Meanwhile, Yamaha Hall, despite its smaller 333-seat capacity, overcomes space limitations by emphasizing height over depth and employing specially designed side walls with three types of angled tiles to control reflection patterns. Both venues demonstrate how different architectural approaches can achieve excellent acoustics despite varying size constraints.	"['Mumford & Sons, Old Crow Medicine Show and Jerry Douglas doing “Wagon Wheel” during Mumford’s recent sold-out, three-night run at the Ryman.\nPhoto: Erika Goldring\nA few months ago, Nashville’s storied Ryman Auditorium went dark for three weeks while the stage was replaced. The old stage, in place since 1951, was showing wear, and the Ryman staff took advantage of the opportunity to add further structural support to increase the stage’s weight capacity. The new Brazilian teak stage is beautiful and stronger than ever, but now there’s a question on a lot of Nashvillians’ minds: What are they going to do with the old wood?\n“I never got so many emails from people,” says the Ryman’s chief engineer, Les Banks. “Everyone requesting pieces of wood, pieces of history.”\nFor now, the boards walked by legends from Hank to Elvis, from Patsy to Emmylou, are being stored at an undisclosed location. Banks says the wood was removed under strict security, and he speculates that pieces may be sold at some point, “like the seats from Yankee Stadium.” But meanwhile, he says, “I was just told no one’s allowed to remove any wood from the Ryman.”\nThis sort of thing comes with the territory of working in a place where so much musical history has taken place. Banks has become something of a historian and caretaker, as well as occasional front-of-house mixer, and—for 80 percent of the acts that come in—a technical expert and guide for visiting engineers.\n“We’re a museum open to the public,” Banks says of the venue many call the Mother Church of Country Music. “People come by and ask what we do here, and I say, ‘We do rock ’n’ roll, country, weddings and sometimes funerals.’ We’ve had open-casket funerals here for Chet Atkins, Bill Monroe and Eddie Arnold, and we had amazing memorial tributes to Johnny Cash and Tammy Wynette.”\nBanks, a 30-year concert sound man, has been the Ryman’s full-time audio engineer since he came off the road in 2000, but he can tell tales about the Ryman’s Opry days as though he’d been there. He will talk about how before the proscenium was added in ‘94, the balcony seats and pews ran all the way to the upstage wall, so in the days before the Opry moved to Gaylord Opryland, “You could hand your autograph book down to Hank Williams before he went onstage, and he’d sign it and hand it right back up to you.” Or he’ll tell a joke—doing a pretty good Little Jimmy Dickens impression—that he says is one of the same jokes the 91-year-old Opry veteran has been telling for decades.\n“I absolutely love this place, and I’m proud of it,” Banks says. “We have respect for history; we are history.”\nOne of the most gratifying aspects of Banks’ job is to help touring engineers manage the challenging acoustics of the 2,362-seat auditorium. “The seating is all original hardwood pews [dating back to the 1890s],” he points out. “There are so many reflective surfaces, and the biggest challenge is the absolutely phenomenal difference between the empty Ryman at soundcheck and a full house that night. It’s night-and-day different; to this day I get freaked out by how loud everything is when it’s empty.”\nChief engineer Les Banks mixes from the balcony of the Ryman.\nPhoto: Steve Lowry/Ryman Archives\nLesson One in coaxing a nice mix from the Ryman, Banks says, is to turn down the volume: “People will ask me, ‘What’s your dB limit?’ And I answer, ‘Common sense.’ Just take a deep breath and be sensitive to the room. And while they’re upstairs [at the mix position], I’ll take the wireless [Dolby] Lake tablet and walk downstairs. I’m their assistant for the day, so they don’t have to run around.”\nMost productions that visit the Ryman bring in their own gear and simply tie into house stacks and racks. The venue is equipped with a Yamaha PM5D board at front-of-house and a JBL VerTec P.A. system. The visitor’s console and house console are routed to a BSS Audio Soundweb London Architect matrix, which distributes signal to all zones; speakers are managed by the Lake system. Stage monitors are recently acquired L-Acoustics 115XTIQ wedges. The venue also keeps a large supply of mics from Shure and others.\nThough much of the Ryman’s gear doesn’t see action daily, it’s all very much needed during the holidays, when a popular Christmas program is put on at the Grand Ole Opry, displacing regular live shows/broadcasts. For those three months every year, the Opry comes back to the Ryman, as it did, unscheduled, when the Cumberland River overflowed its banks in May 2010.\n“The river got as far as 3rd Avenue, and we’re between 4th and 5th,” says Banks. “So we got very lucky. But water in the Opry House got to be four feet high, and they were underwater for two weeks.” Audio equipment, archived performance tapes and loads of other memorabilia were damaged.\n“But as long as you can breathe, life goes on, and the show went on,” says Banks. “I’ve got to give credit to my Opry colleagues, the audio and technical folks over there. The Opry radio show started in 1925 and in 85 or 86 years, they have never missed a live radio broadcast. The flood was on a Sunday, and the next Opry was on a Tuesday. In 48 hours, the Opry had become a road show, playing at different venues around town. We hosted 48 shows for them during the reconstruction, and so many people came to our assistance. SIR provided all the backline we needed. Shure microphones replaced all the mics needed by the show.”\nOther venues that hosted flood-displaced Opry shows included David Lipscomb University, Two Rivers Baptist Church, Nashville’s Municipal Auditorium, and the War Memorial Auditorium, which was actually home to the Opry from ’39 to ’43, before the program moved to the Ryman. But the Ryman was the logical choice for most performances—not just because of its historical relationship to the program, but because the venue has an in-house recording/broadcast studio that’s Opry-ready.\n“We have ISDN and T1 lines directly to the radio station,” Banks points out. “It’s a fully functional studio with a Harrison Trion console, 120 tracks of Nuendo, Phantom Focus monitors, and we do live recording projects. We recorded Alan Jackson’s gospel record [Precious Memories] here.”\nEven when the Opry is operating at full power, the Ryman hosts 200-plus shows a year. Recent visitors include Mumford & Sons (three sold-out shows), Snow Patrol, Merle Haggard, and the Tedeschi Trucks Band.\n“The Ryman’s not an easy room to mix,” Banks says, “but even the most hardcore road crews come in and get mellowed out because they’re honored to be here. It makes people happy, and when you look around and see 2,000-plus people smiling, you know everyone feels it. Some of our ushers are 80 years old, and even if we have a loud rock band in here, they’ll say, ‘Oh, Les, that was a good show!’ When that happens, you know that everyone felt it. Everyone went along on the same ride, and that’s why we do it.”', ""Yamaha Hall, Part 2: Aiming for Ultimate Acoustics\nNew, Long-Lasting Acoustical Design\nThe next challenge the project teams faced was to build the hall so that it would remain state-of-the-art for decades to come. Most contemporary concert halls in Japan are either long-and-narrow shape, “shoebox”, type or else “arena” shape type, with the audience seats surrounding the stage. While the project team could have followed either of these approaches, they wanted to build a hall that would provide a unique and utterly distinctive acoustic experience. For this reason, they set their sights on an entirely new hall design—a design that features height over depth and that focuses on acoustics. The hall shape is ideal for acoustic instruments, and offered the possibility of achieving superlative acoustics unmatched by other halls.\nModel Testing and Numerical Acoustic Simulations\nYamaha Hall, located on floors 7 to 9, is a small concert hall with a seating capacity of 333. Because it is small, the walls are fairly close together, creating two big acoustic design challenges: how to get rich reverberation in such limited space, and how to avoid the problem of excessive side wall reflection. The main solution the team arrived at was to increase the height to produce more space above the audience while the shape of the side wall was designed as diffusive. But there are no precedents for this type of design within Japan, and so it became necessary to adopt a trial-and-error approach.\nFirst, the designers used model testing and ran numerical acoustic simulations to investigate side-wall patterns. The simulation approach seemed an ideal way to meet the challenge of coming up with a new hall design, as designers can use computers to test the acoustics of a wide variety of shapes. So the design team embarked on two months of daily trial-and-error testing.\nWave acoustics simulation is a method for predicting wave acoustics phenomena for changing sounds. As the video above shows, the designer can watch the computer screen to see how the waves generated from a sound source change and propagate.\nRich Reverberaion and Clear Sound in a Small Hall…\nThe design team's goal was to achieve a clarity of sound that is usually not attempted with small halls owing to the proximity of the side walls. Close walls tend to produce loud and rapid lateral reflection of the instrument sounds, resulting in a loss of note contour and clarity. The problem seemed difficult to resolve, since size constraints meant that the walls could not be further separated.\nBut then the design team investigated the flow of the reflections and set about designing side walls that could control this flow. After many cycles of trial-and-error, they came upon a diagonal-lattice wood-tile design that returned quite gentle reflection.\nDesign of Side-Wall Wood Tiles, and Acoustic Simulations\nThe team set up a variety of angled wall tiles. Angles were careful adjusted in accordance with 1/5 scale model experiments, and designed so that most of the sound waves hitting the walls would reflect toward the ceiling, with multiple reflections before returning to audience seats. This design caused reflected sounds to go the “long way around,” holding down the reflection energy levels. The team ultimately designed three tile types; “forward down” tiles, “back up” tiles, and a “peaked” combination of the two (shown in corresponding order below).\nThe team then had to decide how to best arrange the tiles on the walls. They used acoustic simulation to predict the sound characteristics of the hall under different tile arrangements, and then used an auralization system to hear how actual acoustics would sound in each case. They ran comparison tests of the various arrangements while listening to the sound, until constructing what they felt was the optimal pattern. So while the wood wall tiles are an essential aspect of the appearance and ambiance of the building, they also play an essential role in its acoustics.\nThe final design preserves the clarity of each instrument sound while providing a rich and balanced reverberation. The figure below shows the actual arrangement of the tiling. The three different tile types have been carefully arranged to produce ideal acoustics.\nRich Reverberation From Above\nThe ceiling of Yamaha Hall was placed as high as possible, and the side walls themselves are angled slightly upward. The design is such that waves reflect upward not only from the individual tiles but also from the walls themselves, howeer through the overhead space, and reflect down from the ceiling toward the seats in a very balanced manner, achieving the rich reverberation reminiscent of a church.\nApplication of A.R.E. (Acoustic Resonance Enhancement) Wood-Aging Technology\nAfter designing the side walls, the last step was to design the floor for the stage. Stage design is extremely important, and the flooring material has a large effect on the sound of the performance. A wooden floor, in particular, can be thought of as an extension of the instruments being played.\nDesigners considered the idea of applying A.R.E. technology to wooden flooring. A.R.E. (Acoustic Resonance Enhancement), a Yamaha technology that artificially ages wood in a short period of time, was developed to treat wood for high-end guitars, violins, and other string instruments. The technique places wood under high-pressure steam, causing rapid aging—so that characteristic changes occur in days rather than years. While it is common knowledge that string instruments produce better sound as they age, Yamaha's A.R.E. technology has made it possible to get a mature sound even from young instruments. A.R.E. brings numerous benefits, including higher output volume, better clarity, and better listening for the performers themselves.\nBut while A.R.E. had achieved successful results with instruments, the design team did not yet know whether it would deliver the same benefits when used for stage flooring. So the team spread some concrete on our factory floor and built some small stages using different types of processing. They then asked musicians and others to come in and run comparative tests, evaluating the stages built with processed wood against those using traditional flooring (see photo below). Results revealed that the processed wood was surprisingly effective in improving the sound. A.R.E. not only resulted in clearer sounds but also delighted musicians who could now better hear their own output.\nIt has often been observed that the concert hall itself performs as an instrument. The use of flooring that draws on A.R.E. technology enhances the character of Yamaha Hall and contributes substantially to its sound.\nAnd Finally, Hands-On Adjustment\nWith the design and construction completed, it is up to the technicians to make the final fine adjustments to the environment. They decide the height of the acoustic reflectors (“clouds” ), the position of the piano, the reverberation adjustment, and more. The people who have built our Yamaha Hall acoustics continue to diligently adjust the many parameters until their own ears are satisfied.\nThe Power of Yamaha Technology\nYamaha made unsparing efforts in designing the Yamaha Ginza Building, mobilizing our long and deep history of acoustic design together with the latest acoustic technologies and a team of dedicated professionals. Yamaha Hall, in particular, has been gaining attention for delivering a fabulous acoustic experience available nowhere else in Japan.\nWe overcame many difficulties in designing the hall, and we hope you will come to experience its superlative acoustics.""]"	['<urn:uuid:ebdcddde-fa93-492b-af49-eb1c53112c5c>', '<urn:uuid:e32d2249-80ce-4715-bad4-2895bfdbc8ce>']	open-ended	direct	concise-and-natural	distant-from-document	multi-aspect	expert	2025-05-12T23:56:45.148498	10	87	2409
44	jurassic period plant fossil preservation modern ginkgo medicinal safety concerns	Jurassic period plants were preserved as fossils through various conditions including lack of oxygen, submergence under ice or water, extreme temperatures, extreme drought, and extreme pH. These fossilized remains provide information about growth patterns, population density, reproductive patterns, and environmental conditions. Today, the surviving Jurassic plant ginkgo biloba is used medicinally but requires careful consideration. Safety concerns include potential adverse effects when used by people with heart problems or those on blood-thinning medications, which can result in nausea, dizziness, and in severe cases, internal bleeding. Additionally, pregnant and lactating women should avoid using ginkgo or only use it under professional guidance.	"['Jurassic Period Plants Were Responsible For Supporting Life\nWhen it comes to the Jurassic period most often people are concerned with the giant dinosaurs that roamed the Earth. If it weren’t for the Jurassic period plants however, the now extinct dinosaurs would never have survived as long as they did. In this article we will cover a number of well known Jurassic period plants including: conifers, ginkgophytes and cycads and cycadeoids.\nThe Importance of the Jurassic Period Plants\nWhen it comes to the Jurassic period many people tend to focus on the larger carnivorous dinosaurs of this era. What many people don’t understand however is that without the Jurassic period plants these creatures would never have survived. Understanding why Jurassic period plants play a role in the life of carnivorous dinosaurs isn’t too complex; these creatures depended upon many of the herbivorous dinosaur species to feed. Without plant life to sustain herbivores the carnivorous dinosaurs would have been unable to survive. So while the mighty carnivores did not feed directly upon vegetation they depended greatly upon the creatures that did.\nA Timeline of Jurassic Plant Life\nWhat is interesting about Jurassic period plant life is that no new major groups of plant life evolved during this period. At the beginning of the Jurassic period the Earth saw the disappearance of seed-fern floras but the gymnosperms and true ferns were thriving. Of the plant life that really thrived during this period it was the gymnosperms or the naked seed plants that really dominated the land. The gymnosperms were first seen in the Paleozoic era and were divided in to cycads and cycadeoids, conifers and ginkgos.\nCycads and Cycadeoids\nCycads are seeded plants that are physically recognized by the presence of a thick and wooded trunk and a crown of stiff evergreen leaves. Of these plants individuals of the species are all male or all female and both are known to have exceptionally long life spans. Cycad plants are found throughout the world even today but prefer to thrive in areas that have tropical or subtropical climates. Cycads are particularly hardy trees and can thrive in a number of different types of habitat including deserts, swampy bogs, shaded areas, sunny areas, salt rich areas and even on rocky surfaces. The diversity of these plants and their ability to grow in any number of habitats is believed to be what allowed them to thrive for such a considerable amount of time. These plants first made an appearance in the early Permian era and are still thriving today! A significant number of herbivorous dinosaurs fed on cycads because of their hardy nature, their bountiful presence and the fact that they grow both close to the ground and high from the ground.\nCycadeoids are a group of plants otherwise known as bennettitales. This order of plants became apparent in the Triassic era and is believed to have become extinct in the Cretaceous period. The Cycadeoids were seed plants that generally look much like Cycads in terms of physical appearance. The Cycadeoids are separated in to two groups, Cycadeoidaceae and Williamsoniaceae. Each of these groups contains a number of individual plant species. The Cycadeoidaceae include: Cycadeoidea, Cycadekka and Monanthesia. These plants are all characterized by thick trunks and the presence of cones. The Williamsoniaceae include: Williamsonia, Wielandella, Williamsoniella and Ischnophyton. These species of plant had much more slender trunks that branch and cones that are used for reproduction.\nConifers are known by any number of names including: Pinophyta, Coniderophyta or Coniferae made their first appearance in the late Carboniferous period and remain a thriving plant family today. Like cycads and cycadeoids conifers are cone bearing. Only a few of the conifers known today are recognized as plants, most of this species are woody trees such as Douglas-firs, cypresses, junipers and firs. There are currently 68 genera and 630 living species of conifer; however, this variety of plant was certainly not as bountiful back in the Jurassic period. One thing that makes this plant variety particularly interesting is the fact that it seemed to thrive as a result of the Permian-Triassic extinction event that had such a devastating effect on many other living things.\nGinkgophytes or simply ginkgo is known as a genus of plant that does not flower and is currently known only by a single living species: ginkgo biloba. Ginkgo biloba is seen by many as a living fossil and is taken in the modern day as a supplement. Is it believed that the ginkgo plant dates back as far as 199.6 million years ago to the beginning of the Jurassic era and it currently still thrives. The Jurassic period was a particularly beneficial era for the ginkgo plant not only because it saw its beginning but also because it was able to diversify. Throughout the middle of the Jurassic period the ginkgo plant diversified and came to spread throughout Laurasia and this diversification carried on through the beginning of the Cretaceous period. By the middle of the Cretaceous period however, this plant began to decline in diversity. Today there is only one single specimen of this plant life left living, this species of ginkgo was able to thrive in China where all other gingko plants died out in the rest of the world. All of today’s ginkgo supply was ago to survive as a result of the single remaining gingko species. Species of ginkgo that were once living include: ginkgo adiantoides, ginkgo apodes, ginkgo digtata, gingko dissecta, ginkgo gardneri, ginkgo ginkgoidea, ginkgo huttonii and ginkgo yimaensis.\nThe Difference in Jurassic Period Plant Life\nThere are a number of differences between the plant life found in the Jurassic period and the variety of plant life found today. Land plants were indeed plentiful during this historic era however, they were not the plants that you and I commonly recognize today, they were mostly non-flowering plants. If one word were to be used to describe the plants of the Jurassic era it would most commonly be the word “ferns” since many of the plants from this time were similar in appearance to the ferns of today. One of the reasons that plant life in the Jurassic era was all adapted to a particular type of environment is due to the overall higher latitudes and the humid and warm climates that they created. The tropical environment created during the Jurassic period was particularly conducive to this type of non-flowering plant. So hardy were a number of the plants that began life in the Jurassic period that they managed to thrive for millions of years and can still be found today.\nThe Progression of Plant Life in the Jurassic Period\nDuring the Jurassic period the supercontinent known as Pangaea broke in to Laurasia and Gondwana. This breaking up of the mega continent of Pangea allowed for more diversification of plant species and as the continents continued to break apart plant life became even more diversified. The diversification that occurred among plant life is also evident among the superorder Dinosauria. As the continents shifted and moved from one area of the ocean to another the climates began to change drastically which allowed for plant and dinosaur species both to begin adapting to suit their new ecosystems.\nDiscovering the Plants of the Jurassic Age\nMany people wonder just how it is that we can know anything about plant species that lived so very long ago particularly since plant life does not have any skeletal remains. Plants are not all that unlike the dinosaurs and other small mammals of history however in that they did get preserved. Fossils are any evidence of past life, this evidence does not have to contain skeletal remains and as such plants can be fossilized as well. While a number of plants and animals did not undergo the preservation that fossilized elements did, some were exposed to just the right conditions which enabled them to be preserved in some type of element. Fossils are commonly preserved in amber, animal or dinosaur feces and soil or sediment. In order to result in a fossil an item can be exposed to a number of different conditions such as:\n- A lack of oxygen\n- Submergence under ice or water or permafrost\n- Extreme temperatures\n- Extreme drought for an extended period of time\n- Extreme pH\nThese elements can result in plant material being fossilized so that paleontologists and other researchers can discover a wealth of information about Jurassic period and other prehistoric plants! Some of the information that these researchers can find out about plant life from these fossilized remains are growth patterns, population density of specific plant species, reproductive patterns of particular plant species, the age of plant life and levels of moisture in the air at the time of the plant’s death. These fossils can also tell much about the environments in which the specific plant species grew and even what types of elements were rich in the soil and ecosystem where the plant grew. Fossils of Jurassic period plants can tell us so much about the planet in a snap shot of time.', ""Please share this page:\nNames of Gingko Biloba, past and present\nChinese: yin xing / yinguo / bai guo\nJapanese: icho / ginnan / ginkyo\nVietnamese: bach qua\nEnglish: gingko / maidenhair tree\nLatin (scientific nomenclature): Gingko biloba\nGingko Biloba - Background and History\nThe gingko tree is a relatively ancient and extremely long-lived plant that is said to be a native to the Asiatic part of the world, more specifically in China, where it has been growing since prehistoric times.\nUses of Gingko Biloba - image to share / repin\nbackground Gingko photo - © emer - Fotolia.com\nTermed a living fossil, the gingko plant is now the only one of its kind in the world, with no (as of yet) known living relations and is, in effect, a genus unto itself. Initially a landscape tree much-loved for its wide range and shade-providing capacities as well as its unique aesthetic appeal, gingkos are now chiefly cultivated in both the East and West for its long-standing medicinal properties which can be found chiefly in its leaves.\nCharacterised by its large size and somewhat uneven yet looming growth pattern, gingkos are veritable landscape trees, as they are highly resistant to wind and snow damage. Thriving in areas that are well-drained and which receive adequate amounts of rainfall, gingkos are best planted in wide, open spaces such as on promenades, sidewalks, and spacious parks. It is highly discernable for its uniquely shaped leaves, which resemble an open fan – something which makes it quite unique among tree species in much the same way that the maple is unique unto itself.\nGingkos were initially cultivated in China for landscaping purposes, although in earlier periods, the plants were chiefly wildcrafted and employed medicinally. Nowadays, gingkos are cultivated for a variety of different reasons, although two of the primary driving forces for its propagation is in its use as a landscaping tree, and in its use as an alternative medicinal supplement.\nGingko Biloba - General herbal Uses\nThe earliest use of gingko did not always veer towards the medicinal, as these large, long-lived trees were prime candidates for landscaping and other horticultural pursuits, so much so that it was cultivated both in the (literal) large-scale and small-scale either as shade trees or as potted bonsai.\nGingko trees are also known for their pest-resistent wood, making them prime carpentry material for the creation of various articles of light furniture. In feudal Japan and Imperial China, gingko wood was employed for carpentry and general construction, although it itself is not a prime wood (in terms of the 'Western' sense of aesthetics) for such a purpose. \nVeering towards the culinary, the seeds of the gingko tree, or, more specifically, the inner gametophytes encased within the seeds are used as a type of foodstuff in several Asiatic countries, more commonly in China, Japan, and Korea. Despite its technically 'edible' nature, this inner 'flesh' can cause allergic reactions in certain individuals which results in seizures or convulsions, especially when consumed in excess. Eaten moderately however, it is traditionally ascribed medicinal and aphrodisiac qualities, and is commonly prepared (in both China and Japan) during the holidays as an accompaniment to sweetmeats or staple dishes. \nPerhaps the most popular use of gingko biloba in these modern times is in the employment of its leaves as prime sources for gingko biloba extract, which is typically marketed as a food supplement said to provide the consumer with a number of health benefits. Gingko extracts are derived from a concentrated and standardised dosage of the gingko tree's active compounds which are chiefly derived from its leaves. In earlier times, gingko was often employed medicinally simply by wildcrafting its leaves, and subsequently drying them and creating decoctions or infusions of the leaves either by itself, or in combination with other (often complimentary) herbs.\nIn Traditional Chinese Medicine, gingko leaf tea is typically prescribed for individuals who are suffering from a coldness of the extremities, as well as for persons suffering from lethargy, headaches, insomnia, and general restlessness. Gingko leaves are often brewed into a tisane and drunk as a general enervating tonic. It is traditionally prescribed as a 'scholar's herb', and is taken (usually in combination with ginseng root and oolong tea) as an energising herb that is said to stimulate focus, concentration, and memory retention (a ascription which remains to this day as among the primary uses for gingko biloba extract. \nModern applications have standardised the use of gingko, and now employ extracts instead of whole plant matter. Whole leaves, however, are still widely available in traditional Chinese apothecaries, although the bulk of gingko's medicinal usage these days is derived from standardised extracts derived from its leaves. These extracts, which are available in a select range of concentrations, are usually encapsulated or otherwise made into solid tablets and are sold in health food stores as a food supplement. Among its medicinal uses are as follows: food supplements for improving memory, preventing the onset of dementia or Alzheimer's, treating Raynaud's disease, improving blood flow to the extremities, aiding in the proper management of stress, and revitalising the body. Some evidence may also point to gingko's usefulness in treating glaucoma and helping to reverse and / or allay the progression of macular degeneration. \nDue to its vast range of applications, gingko biloba extract can be found in varying concentrations as an accompaniment to other food supplements such as those touted to be 'anti-aging' or 'memory enhancing' supplements. The efficiency of these extracts is still widely debated by several medical fields, although proper usage does seem to provide significant improvements in the fields where it claims some therapeutic benefits.\nGinkgo biloba Scientific Studies and Research\nGinkgo biloba, especially its leaves, is extensively studied to date for its being widely used as an herbal medication. A number of controlled clinical studies had furnished clear-cut evidence regarding the effectiveness of Ginkgo biloba as a treatment for some neurologic sequelae associated with Alzheimer's disease, traumatic brain injury, stroke, normal aging, tinnitus, and macular degeneration. These sequelae include impairments in memory, cognitive speed, and activities of daily living; edema; inflammation; and free radical toxicity. Ginkgo biloba is able to influence the electrochemical, physiologic, neurologic, and vascular systems of the body, acting as an agent with antioxidant, neurotransmitter/receptor modulatory, and antiplatelet-activating factor properties. \nGinkgo biloba appears to protect neurons from the injury or degeneration associated with hypoxia, ischemia, seizure activity, and peripheral nerve damage. Researchers from the Golestan University of Medical Sciences, Gorgan, Iran, had determined that pretreatment and treatment injection of G. biloba extract can have a protective effect for astrocytes in all areas of hippocampal formation.  Astrocytes are specialized glial cells in the brain and spinal cord that perform several vital functions in the central nervous system; they play an essential role in synaptic transmission and information processing by neural circuit functions. \nOne of the most well-studied properties of Ginkgo biloba is its putative ability to improve cognition and memory among patients suffering from dementia, especially from Alzheimer's disease. A German multicenter trial involving 410 outpatients with mild to moderate dementia (Alzheimer's disease, vascular dementia, or mixed form) revealed that the administration of Ginkgo biloba extract EGb 761 at a dose of 240 mg per day is significantly superior to placebo with respect to treatment of patients suffering from dementia and its neuropsychiatric symptoms.  This finding is in keeping with the findings of a 24-week randomized, placebo-controlled, double-blind study involving 50-80-year-old patients with Alzheimer-type dementia (mild to moderate). This trial directly compared the efficacy of Ginkgo biloba special extract as a means to slow down the progression of dementia and that of placebo and donepezil, the long-time drug of choice when it comes to treating mild to moderate symptoms of dementia associated with Alzheimer's disease. The results from this study indicated that both Ginkgo biloba and donepezil have the same clinical efficacy as regards treating the symptoms of dementia of the Alzheimer's disease type. \nAs mentioned with a point earlier, Ginkgo biloba seems to possess cerebral-enhancing properties, and because of such ability, Ginkgo biloba extract could be a promising treatment of sexual dysfunction disorders. An open trial from the University of California had deemed the extract obtained from the leaves of Chinese ginkgo tree effective in treating antidepressant-induced sexual dysfunction. At a dosage of 60 mg daily to 120 mg twice daily (or 209 mg/day), Ginkgo biloba extract favorably influenced the desire, excitement (erection and lubrication), orgasm, and resolution (afterglow) - the four phases of the sexual response cycle - of the study participants, with women being more responsive than men. \nMolecular Components and Chemistry\nMyricetin and quercetin are among the flavonoid constituents of Ginkgo biloba, two compounds with antioxidant property that might be partially responsible for the beneficial effects of Ginkgo biloba extract on brain neurons.  Ginkgo biloba also contains ginkgolide B, a potent plateletactivating factor (PAF) antagonist,  as well as other terpene trilactones.\nGingko Biloba - Esoteric Uses\nIn Asiatic folklore, the gingko tree is considered sacred to Buddhists, which often propagate and cultivate trees in their temples. While very little mythology has been transferred to the Western world with regards to the esoteric function of the gingko tree, its long-lived nature usually features in Japanese folklore. It is believed in earlier times that extremely old gingkos housed kami, the animistic spirits that are inherent in all things in Japanese belief. Some folkloric stories even suggest that very large gingkos are prime 'vessels' for imprisoning wily youkai - demonic entities that take are able to shapeshift between human and animal form. This 'imprisonment' or 'sealing' is typically performed by a Shinto or Buddhist priest, or by a sorcerer or omyouji, via the use of various chants and incantations, accompanied by the application of spells and / or mantras written on pieces of paper and pasted upon the tree at the end of the 'sealing' ritual. Gingko trees are not the only candidates for such ceremonies however, as large rocks, other trees, and even household objects may be used to imprison youkai and their ilk.\nGingko Biloba - Safety Notes\nThe consumption of gingko biloba in standardised or traditional form is relatively safe although some contraindications do exist. Care should be taken when consuming gingko extracts or tea if one is suffering from heart problems, or if one is under blood-thinning medications since it may result in adverse side-effects such as nausea, dizziness, and, in worst-case scenarios, internal bleeding or uncontrollable bleeding from severe wounds. Pregnant and lactating women should likewise refrain from the use of gingko, or continue to use it under the strict guidance of a healthcare professional or an expert herbalist.\nGingko Biloba - References:\n Diamond B. J. et al. (2000). Ginkgo biloba extract: mechanisms and clinical indications. Archives of Physical Medicine and Rehabilitation, 81(5): 668-678. Retrieved 30 May 2013 from http://www.ncbi.nlm.nih.gov/pubmed/10807109\n Jahanshahi M., Nikmahzar E., Yadollahi N., & Ramazani K. (2012). Protective effects of Ginkgo biloba extract (EGB 761) on astrocytes of rat hippocampus after exposure with scopolamine. Anatomy and Cell Biology, 45(2): 92-96. doi: 10.5115/acb.2012.45.2.92. Retrieved 30 May 2013 from http://www.ncbi.nlm.nih.gov/pubmed/22822463\n Sofroniew M. V. & Vinters H. V. (2010). Astrocytes: biology and pathology. Acta Neuropathologica, 119(1): 7-35. Retrieved 30 May 2013 from http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2799634/?report=classic\n Ihl R. et al. (2011). Efficacy and safety of a once-daily formulation of Ginkgo biloba extract EGb 761 in dementia with neuropsychiatric features: a randomized controlled trial. International Journal of Geriatric Psychiatry, 26(11): 1186-1194. doi: 10.1002/gps.2662. Retrieved 30 May 2013 from http://www.ncbi.nlm.nih.gov/pubmed/21140383\n Mazza M., Capuano A., Bria P., & Mazza S. (2006). Ginkgo biloba and donepezil: a comparison in the treatment of Alzheimer's dementia in a randomized placebo-controlled double-blind study. European Journal of Neurology, 13(9): 981-985. Retrieved 30 May 2013 from http://www.ncbi.nlm.nih.gov/pubmed/16930364\n Cohen A. J. & Bartlik B. (1998). Ginkgo biloba for antidepressant-induced sexual dysfunction. Journal of Sex & Marital Therapy, 24(2): 139-143. Retrieved 30 May 2013 from http://www.ncbi.nlm.nih.gov/pubmed/9611693\n Oyama Y., Fuchs P., Katayama N., & Noda K. (1994). Myricetin and quercetin, the flavonoid constituents of Ginkgo biloba extract, greatly reduce oxidative metabolism in both resting and Ca2+-loaded brain neurons. Brain Research, 635 (1-2): 125-129. Retrieved 30 May 2013 from http://www.sciencedirect.com/science/article/pii/0006899394914311\n Smith P. F., Maclennan K., & Darlington C. L. (1996). The neuroprotective properties of the Ginkgo biloba leaf: a review of the possible relationship to platelet-activating factor (PAF). Journal of Ethnopharmacology, 50(3): 131-139. Retrieved 30 May 2013 from http://www.ncbi.nlm.nih.gov/pubmed/8691847\nMain article researched and created by Alexander Leonhardt, scientific studies by Dan Ablir. © herbs-info.com 2013""]"	['<urn:uuid:20cbed97-d1ba-4ed1-951b-afb37c277977>', '<urn:uuid:fc124fc8-64d6-4d2e-bfd0-119d269f9132>']	open-ended	direct	long-search-query	similar-to-document	multi-aspect	expert	2025-05-12T23:56:45.148498	10	101	3592
45	how far moon earth distance january 20	The Moon is 378,655 km (235,285 mi) away from Earth on this date.	"['Gibbous ♊ Gemini\nPrevious main lunar phase is the First Quarter before 2 days on 18 January 2024 at 03:53.\nMoon rises in the afternoon and sets after midnight to early morning. It is visible to the southeast in early evening and it is up for most of the night.\nLunar disc appears visually 3% narrower than solar disc. Moon and Sun apparent angular diameters are ∠1893"" and ∠1950"".\nNext Full Moon is the Wolf Moon of January 2024 after 5 days on 25 January 2024 at 17:54.\nThere is medium ocean tide on this date. Sun and Moon gravitational forces are not aligned, but meet at very acute angle, so their combined tidal force is moderate.\nThe Moon is 10 days young. Earth\'s natural satellite is moving from the first to the middle part of current synodic month. This is lunation 297 of Meeus index or 1250 from Brown series.\nLength of current 297 lunation is 29 days, 11 hours and 2 minutes. It is 1 hour and 1 minute longer than next lunation 298 length.\nLength of current synodic month is 1 hour and 42 minutes shorter than the mean length of synodic month, but it is still 4 hours and 27 minutes longer, compared to 21st century shortest.\nThis lunation true anomaly is ∠328°. At the beginning of next synodic month true anomaly will be ∠345.9°. The length of upcoming synodic months will keep decreasing since the true anomaly gets closer to the value of New Moon at point of perigee (∠0° or ∠360°).\n7 days after point of perigee on 13 January 2024 at 10:35 in ♒ Aquarius. The lunar orbit is getting wider, while the Moon is moving outward the Earth. It will keep this direction for the next 8 days, until it get to the point of next apogee on 29 January 2024 at 08:14 in ♍ Virgo.\nMoon is 378 655 km (235 285 mi) away from Earth on this date. Moon moves farther next 8 days until apogee, when Earth-Moon distance will reach 405 781 km (252 141 mi).\n2 days after its ascending node on 17 January 2024 at 14:05 in ♈ Aries, the Moon is following the northern part of its orbit for the next 11 days, until it will cross the ecliptic from North to South in descending node on 31 January 2024 at 20:17 in ♎ Libra.\n2 days after beginning of current draconic month in ♈ Aries, the Moon is moving from the beginning to the first part of it.\n10 days after previous South standstill on 10 January 2024 at 07:04 in ♑ Capricorn, when Moon has reached southern declination of ∠-28.164°. Next 2 days the lunar orbit moves northward to face North declination of ∠28.203° in the next northern standstill on 23 January 2024 at 03:44 in ♋ Cancer.\nAfter 5 days on 25 January 2024 at 17:54 in ♋ Cancer, the Moon will be in Full Moon geocentric opposition with the Sun and this alignment forms next Sun-Earth-Moon syzygy.']"	['<urn:uuid:bc8122d2-b119-4008-b2de-8dfca73700af>']	factoid	with-premise	short-search-query	distant-from-document	single-doc	novice	2025-05-12T23:56:45.148498	7	13	505
46	How should I maintain the cleanliness of waterjet components, and what role does the jewel orifice play in the cutting system?	Cleanliness is crucial for waterjet maintenance - components should be rebuilt in the cleanest possible conditions, away from dust and abrasive particles. High-pressure components should be stored in clean areas, and parts should be rinsed before disassembly. An ultrasonic cleaner is recommended for nozzle components. The jewel orifice, typically made of diamond, ruby, or sapphire, is a critical component that focuses the water stream, with openings ranging from 0.005 to 0.016 inch diameter. Diamond orifices are becoming the industry standard as they last longer and produce more consistent streams, preventing the need to stop cuts prematurely for replacement.	['- How the equipment is run\nThe harder the equipment is run, the more frequently things break. Running at higher pressures will also require more frequent maintenance.\n- How much care is taken during maintenance\nIf you rebuild in a clean-room, your equipment will last much longer than if you rebuild in a dirty environment. There are a lot of high precision components in a waterjet that microscopic bits of grit can easily damage. A tiny speck of dust underneath the jewel in the nozzle will cause the jet to shoot to the side, and cause accelerated wear of the mixing tube. Take the parts to a clean area of your shop, preferably with a sink where you can wash the parts before reassembly.\nYour waterjet benefits from a clean maintenance area\nWhen you first get your machine, you will probably be overwhelmed during the few days of training that you get. Once training is complete, you will feel pretty confident that you know how to operate the machine, and you may have a general idea of how to maintain it. It will, however, be a few weeks before you perform your first maintenance, and even longer before it’s time to rebuild the pump. Once these items do come up, you probably will have forgotten everything you have been taught. Therefore, consider having someone from the factory or a distributor use your first pump rebuild as an opportunity to provide you with advanced training on the machine operation, and refresher training on how to do maintenance.\nFrequency of maintenance\nWaterjets certainly require maintenance. Expect to change nozzle parts frequently (daily). Expect to change pump parts less frequently, but regularly enough that you wish you didn’t have to. You should also keep some critical spares at hand, so that you don’t have to stop machining while waiting for a spare part to be shipped.\nGenerally speaking, the higher the pressure at which you run, and the more on and off cycles the equipment sees, the more frequently it will need maintaining.\nAlso, if you have dirty or hard water, you will either need to maintain everything more often, or purchase a good water softener and filtration system.\nEase of maintenance\nFor the most part, anyone who can change brake pads on a car can keep an abrasive jet going with a day’s training and a good manual, and the occasional phone call to tech support. Mixing tubes wear out and are easy to replace (often similar to replacing a drill bit). Pumps will need periodic seal changes. Depending on pump design, seals can be anywhere form relatively easy and quick to quite awkward and time consuming to replace.\nHowever easy it is to maintain your waterjet, it’s even better to reduce the need for maintenance.\nStart with clean water\nIf your water has particles in it, or dissolved minerals, these will bang into or accumulate on high pressure components and accelerate wear. Dissolved minerals can accumulate as a deposit on the top of the jewel, and cause the jet to cut less efficiently, and worse yet, deflect it sideways so it’s cutting the side of your mixing tube. Tiny invisible-to-the-naked-eye sized particles underneath the jewel can cause it to miss align, and eat your mixing tube quickly. Dirt in the high pressure plumbing can become bullets that crack the jewel.\nWater quality has a large impact on frequency of maintenance. Better water means less frequent maintenance and more time cutting and making money with your waterjet.\nTiny bits of dirt can have devastating effects on component life, especially the nozzle components. Waterjets typically operate in a harsh environment, one that’s filled with abrasives and often other machining tools. You need to be extra vigilant to keep everything as clean as possible to avoid unnecessary maintenance.\n- Always rebuild high pressure or nozzle components in the cleanest possible conditions.\n- Do not store high pressure or nozzle components where dust (or worse yet microscopic abrasive particles) can settle on them.\n- Rinse all dirt from components prior to disassembly, and go to another room to do maintenance.\n- Get an ultrasonic cleaner for cleaning nozzle components\n- When rebuilding something up-stream of the nozzle, remove the nozzle, and flush the lines with low pressure prior to putting the nozzle back on. This prevents dirt in the lines from damaging the nozzle.\n- Remember, anything you do upstream has only one way to exit: through the nozzle.\n- Plungers and seals inside of the pump are also sensitive to particles.\nAvoid pressure cycles on high pressure components\nEach time high pressure is applied to the plumbing, the metal expands. When the pressure is removed, it contracts. This causes fatigue that can cause the components to eventually crack. Operating at lower pressures is one way to solve this. Pressure fluctuations typically either come from the pump itself, or from turning the nozzle on and off. There are also methods employed in most equipment for maintaining relatively consistent pressure in the high pressure tubing even though the nozzle is being turned on and off. Understand, though, that all of the high pressure plumbing is considered “wear parts” and does need to be periodically replaced.\nRotate your mixing tube every morning\nIn the event that the jewel is slightly misaligned, it will hit one side of the mixing tube harder than another side. This causes uneven wear. By rotating the mixing tube once in a while, this is minimized.\nUnderstand the basic principals of how ultra-high pressure tube fittings work\nUltra-high pressure tubing is different than standard household plumbing. For example, in high-pressure tubing the thread is not what makes the seal. Instead the screw threads force the parts together to make a metal-to-metal seal. The threads are only used to hold the pieces in place. Once in place, the cone of the tubing fits inside a negative cone in the mating piece.\n- There is no need to over-tighten the components. You do have to make it tight enough to allow it to have a basic metal to metal seal, but you don’t have to use a lot of force to do it.\n- A small piece of dirt between the cones can scratch it, or otherwise prevent the seal from occurring. Again, cleanliness reduces maintenance.\n- If you find that you do need to put a lot of torque on the fittings to make a seal, then something is wrong, such as a scratch, bend, or piece of dirt interfering with the seal. Another possibility is that the cones are not properly touching due to improper assembly of the high pressure seal.\n- If you have a leak, fix it soon. Otherwise, the leak will erode the components that make the seal, and you will have to replace it.', 'Published in: Canadian Industrial Machinery MagazineOctober 2013\nMany factors influence the precision and efficiency of a waterjet cutting system. The type of CNC machine used, the materials being cut, and the speed and pressure of the abrasive water all play a role in the cleanliness of the cut. However, the waterjet cutting head is perhaps the single most important component in a waterjet cutting system, and so understanding the different components and their roles in the cut will help you ensure you are getting the most out of any CNC waterjet machine. It is important to note that each component of the waterjet cutting head must be accurately machined and assembled to ensure a consistent water stream and wear. Using quality components and replacing parts in a timely manner will enable your CNC waterjet cutting system to provide you with quality cuts for years. The following components affect cut quality:\nHigh-pressure Water. Normal tap water is enhanced to pressures reaching 50,000 to 90,000 PSI through the use of a specially designed intensifier. A properly sized intensifier, in conjunction with a jewel orifice, ensures that the pressure is maintained at the cutting head during the cutting operation. Jewel Orifice. The jewel orifice, a critical component in the cutting head, focuses the water stream. Typically, this orifice is made of diamond, ruby, or sapphire with an opening ranging in size from about 0.005 to 0.016 inch diameter. Diamond is more than four times harder than ruby or sapphire, and it is fast becoming the industry standard for jewel orifices. Some parts require long, timeintensive cuts, and replacing a jewel orifice midway can ruin the cut. Switching to a longer-lasting diamond orifice helps to prevent the need to stop the cut prematurely for orifice replacement. A diamond orifice also produces a consistent stream, resulting in more even wear inside the cutting head.\nAbrasive. Most applications require an abrasive to be added to the water stream to increase the cutting power, rather than pure water alone. Two factors affect the cut in regards to abrasives: the type of abrasive used and the speed at which the abrasive is added to the water stream. The most popular type of abrasive is made from garnet, a hard, brittle gemstone. A coarser abrasive will provide a faster cutting speed, but will wear out the mixing tube faster. A softer abrasive will cut slower, but will wear out the cutting head components slower as well. Ultimately, the ideal abrasive to use will depend on the materials you wish to cut. The abrasive is metered from a minihopper through a plastic tube down to the cutting head and is sucked into the waterjet stream in the mixing chamber. As more abrasive is added, cutting speed will increase until a saturation point is reached. However, if too much abrasive is added, the mixing tube will clog. A CNC abrasive metering system precisely controls the amount of abrasive that is allowed to flow to the cutting head. Because abrasive usage can represent as much as 67 percent of a waterjet’s operating costs, monitoring the flow of abrasive not only ensures longer life for consumables, it also reduces the amount of abrasive unnecessarily wasted.\nMixing/Focusing Tube. The mixing tube, as the name suggests, is the area where the abrasive mixes with the higher-pressure water before striking the material. The mixing tube also is the component that most frequently needs to be replaced in a waterjet cutting head. The opening (orifice) of a mixing tube typically increases in diameter by about 0.001 in. per day of cutting as the abrasive erodes the nozzle. If the wear is even, a nozzle can be used up to 120 hours. However, if the wear of the nozzle is not symmetrical, the waterjet stream will not be round, and the nozzle may need to be replaced sooner. The length of the tube itself also plays a role in cut quality. A longer abrasive mixing tube produces a more coherent waterjet stream. A mixing tube length of between 3 and 4 in. is optimum.\nMixing Tube Orifice. Although the tube orifice is part of the mixing tube, its opening diameter requires separate consideration. The smaller the opening, the more coherent the stream, but the trade-off is a slower cut than with a larger opening. Smaller orifices also wear faster and can clog more easily if the wrong amount or type of abrasive is used. However, larger orifices do not result in the same amount of precision as a smaller orifice; the desired outcome of the cut must be taken into consideration. When choosing a mixing tube and orifice, it is helpful to use a feed rate calculator. By changing the parameters, you can calculate cost per inch. Keep in mind, however, that these estimates are on straight lines only, and the shape of your cut will play a role as well.\nGuard. A splash guard can be added to a cutting head to reduce the amount of water that is deflected during a cut. Although not an essential component of the cutting head, it can also protect the nozzle from accidental bumps, decreasing the frequency of nozzle replacement.\nFinally, the distance between the cutting head and the material also will affect your cut. Typically, the optimum height for abrasive waterjet cuttingis between 0.040 and 0.060 in. Distances greater than that will result in a rounding of the cut. A higher nozzle also will result in a wider kerf (width of the cut) angle. Automatic height control is the most reliable and accurate way to maintain proper nozzle distance. Many CNC waterjet cutting machines include a system that calculates optimum nozzle height and cutting speed to obtain cut consistency.\nTo see the complete online version of CIM Magazine’s October issue click here.']	['<urn:uuid:41657dce-47c3-45bd-95ee-5f332d9e515d>', '<urn:uuid:6e2edab2-fed3-4130-b6fe-4ee4e75c6d73>']	open-ended	direct	verbose-and-natural	similar-to-document	multi-aspect	novice	2025-05-12T23:56:45.148498	21	98	2098
47	best flowers for pressing beginners	Hydrangeas, impatiens, irises, lilies, and ferns are all great flowers to start with for pressing. It's important to select fresh and undamaged plant specimens. If a flower is torn or has brown spots, it will not press well. It's best to collect plant material on sunny days and avoid picking specimens after heavy rain to minimize moisture.	['Southern Bloom Press makes modern pressed flower art\nLauren Whiteside Mann’s next flower-pressing class is on May 31 at West Elm; find details at southernbloompress.com.\nLauren Whiteside Mann may have been the youngest person to tote a flower press and tweezers to the World Wide Pressed Flower Guild conference in Pennsylvania last March, but at home in Charleston, the owner of Southern Bloom Press is drawing quite the young, hip crowd to classes and pop-up shops at the likes of Cannonborough Collective, The Skinny Dip, and West Elm. “From interior design to fashion, there’s an obsession with botanicals right now,” notes Mann, and the trend has brought flower pressing back into vogue.\nMann’s own childhood interest in the art was reawakened in 2016 when she wanted to preserve her bridal bouquet. After translating the arrangement into a piece of wall art, she began using wildflowers from the wedding to make gifts for family and friends. She was hooked—so much so that she launched Southern Bloom despite a day job at College of Charleston.\n“Pressing flowers really isn’t complicated,” she encourages. Presses are inexpensive to buy or make, and plant materials are probably right outside your door. “Hydrangeas, impatiens, irises, lilies, and ferns all are great to start with,” says Mann. Cut flowers and leaves away from stems and place them individually into a press; after three or four weeks, reveal the results and start designing.\nHow to Make Pressed Flower Art\nFollow Southern Bloom Press’s steps for pressing and designing\nAcid-free craft glue\nBlotter paper or watercolor paper\nPhone book, other heavy type of book (without glossy pages) or wooden flower press\nPlant Material: Look for flowers and plants that are fresh and in bloom. In May, you might find hydrangeas, impatiens, irises, lilies, and ferns.\nFlower Press Method:\n1. Prepare your workstation and place flower press on a flat and solid service, such as a desk or kitchen counter.\n2. Start with one layer of cardboard in the bottom of the press.\n3. Place a piece of blotter or watercolor paper on the top of the cardboard.\n4. Select fresh and undamaged plant material.\n5. Cut the individual blooms and leaves with scissors. Cut stems off flowers and press the stems separately.\n6. Place the blooms and leaves on the paper face-down. Make sure to leave enough space (half an inch to an inch) around each bloom or leaf so that they do not touch.\n7. Place another piece of paper on top of the plant specimens.\n8. Cover the paper with a second piece of cardboard.\n9. Repeat steps 5 to 8 until your flower press is filled.\n10. Place the top of the wooden press. Fasten the press with nuts, bolts, and washers or straps—whatever your wooden flower press may use.\n11. Store the press in a cool and dry spot, such as a bookshelf or desk. Avoid placing it in sunlight.\n12. Wait approximately 4 weeks, then open the press.\n13. Remove dried plant materials and store them in acid-free, airtight containers.\nTelephone Book Method:\n1. Please note the telephone book or hardback book method is typically only used for very thin plant specimens. You can press thicker plant material, but the quality of pressed material will vary.\n2. Begin about 30 pages back from the telephone book or a quarter of the way back in a hardback book.\n3. Select fresh and undamaged plant material.\n4. Cut the individual blooms and leaves with scissors. Cut stems off flowers and press the stems separately.\n5. Cover first section of plant specimens with approximately 30 pages of the book, and continue layering until you have filled the book or you have run out of plant material. If you prefer, you can add blotter paper or copy paper inside the book’s pages to keep the ink from discoloring the blooms and to avoid damaging the pages.\n6. Stack several other books (at least 15 to 20 pounds of weight) on top of the pressed flower book.\n7. Wait approximately 4 weeks, then open the press.\n8. Remove dried plant materials and store them in acid-free, airtight containers.\n1. Start by choosing which plant specimens you’d like to use in your design.\n2. Cut a sheet of watercolor paper or acid-free paper to fit the size of the picture frame.\n3. Draft your design by arranging blooms and leaves on the sheet of paper.\n4. Once you have an idea of the design, begin to glue plant material to paper. Place tip of toothpick in glue and dot the plant material with glue.\n5. Repeat until you have all plant material glued to paper.\n6. Let design dry completely before placing the design in the frame.\n1. Select the freshest undamaged plant specimens. If the flower is torn or has brown spots, it will not press well.\n2. Sunny days are the best for collecting plant material from your garden. Avoid picking plant specimens after a heavy rain. Avoid unnecessary moisture.\n3. Try picking a variety of different plant specimens at different stages.\n4. For thicker flowers with lots of blooms, disassemble the flower by pressing each individual flower petal.\n5. When using a book, use one that you do not mind damaging the pages.\n6. Do not have a fan running, as light blooms and leaves can fly off the press.\n7. Wait at least 4 weeks to open your press or book. Avoid peeking, even though it is hard to wait!\n8. Keep stored plant material in acid-free containers or folders and avoid sunlight.\n9. Use a label maker or sticky note to record the date and type of pressed plant specimen.\nPhotographs by (Southern Bloom Press-3) Upper King Photography']	['<urn:uuid:545da003-c29f-41f9-ab43-d0cc6f7e34b4>']	open-ended	direct	short-search-query	similar-to-document	single-doc	novice	2025-05-12T23:56:45.148498	5	57	953
48	early stage mesothelioma surgery options and treatment advances	In early stages (I-II), curative surgery like extrapleural pneumonectomy is the first line treatment. Recent advances have improved outcomes, particularly when combining treatments. For example, using intensity-modulated radiotherapy (IMRT) before surgery has extended median survival to 36 months. Additionally, for peritoneal mesothelioma, combining cytoreductive surgery with HIPEC has achieved median survival of 97.8 months in early-stage patients.	"[""There are four primary stages of mesothelioma that doctors use to identify the seriousness of a mesothelioma diagnosis, labeled stage I, II, III or IV. The staging systems used to identify what stage of mesothelioma a patient has are the Brigham, TNM or Butchart systems. The lower stage number you’re given, the more treatment options you have, and the better your chances are for long-term survival.\nStaging is an accepted way for cancer doctors to describe to patients – and to one another – how advanced the disease is, how prevalent tumors are and how far the cancer has spread. Given the aggressive nature of the cancer, mesothelioma staging is a key part of proper diagnosis and treatment.\nWhy is mesothelioma staging important? Because knowing where a cancer is in its development sets the table for treatment, which treatment options are available and which are not. For example, doctors use cancer stage as a guideline when deciding whether a patient is likely to benefit from surgery.\nIf a patient is healthy enough for aggressive treatment and doctors believe that all visible signs of cancer can be completely removed, they say the cancer is resectable and will likely recommend a treatment plan involving surgery. If the spread of cancer is too advanced, however, and can’t be removed completely, the cancer is unresectable. In this situation, doctors will recommend other treatment options, including chemotherapy and experimental treatments.\nStage I pleural mesotheliomas are generally resectable, as well as some diagnosed at stage II and III. But by stage IV, the cancer can't be removed completely with surgery. The cancer's subtype can also affect treatment options because most doctors agree surgery doesn't help with sarcomatoid mesotheliomas.\nWhen peritoneal mesotheliomas have spread beyond the abdomen, surgery likely is not helpful. Doctors consider peritoneal mesothelioma unresectable when it has invaded certain areas within the abdomen, including:\nIf the cancer has spread to these locations, doctors typically deliver chemotherapy to the entire body or directly to the abdomen.\nFree information, books, wristbands and more for patients and caregivers.Get Your Free Guide Get Your Free Mesothelioma Guide\nThe stage of cancer is vital information for oncologists (cancer doctors) who treat mesothelioma, but all experts agree universally on one principle: It's preferable to catch cancer, specifically mesothelioma, in the earliest stage possible.\nMany specialists who treat these cancers — even some of the most respected ones in the field — don't agree on one staging system. Although many doctors agree that staging is a strong predictor of lifespan, not all do.Learn More About Staging Methods\nIf you are diagnosed with mesothelioma, you should seek a second opinion. Oncologists treat a variety of cancers, but they may not have experience with staging asbestos-related cancers. Always find a doctor who does.Get Help Finding A Specialist\nUsing one of three systems, doctors will assign your cancer a stage of I through IV. The stage varies depending on several factors, including the size and location of your tumor and whether it has spread to lymph nodes or distant organs.\nDoctors use three primary systems for mesothelioma staging: Brigham, TNM, and Butchart. These systems are used primarily for pleural mesothelioma staging because there are currently no formal staging systems for the other types. TNM and Brigham are the most-used by mesothelioma specialists, although some doctors believe that none are accurate enough.\nStage I typically offers the best chance for survival because of the potentially curative surgical treatments available for patients. Most stage I patients qualify for extrapleural pneumonectomy, an aggressive surgery that attempts to remove as much of the tumor growth as possible. Surgeons take out an entire diseased lung and other tissues, including the diaphragm, nearby lymph nodes and the linings of the chest and heart.\nAt this stage of progression, most doctors only recommend palliative treatments because the cancer has spread to many parts of the body. Trying to remove all the tumors is too difficult, and many patients are too weak to withstand aggressive treatments. Palliative treatments, which focus on symptoms rather than curing the disease, can ease pain and suffering and improve quality of life.\nBecause of the nature of mesothelioma and the way the cancer grows and spreads, most people are not diagnosed until stage III or IV. Doctors usually treat asbestos-related cancers with a combination of chemotherapy, radiotherapy and surgery. Depending on the progression and location of cancer cells, they may recommend different options.\nWe'll help you or a loved one find the most qualified mesothelioma specialists and treatment facilities in your area.\nAt this point of early development, tumors are close to the original tumor, having only grown in one layer of the lining of the lungs (pleura). The cancer may also have grown into the covering of the heart and the diaphragm on the same side as it first formed.\nThe life expectancy for someone with stage I mesothelioma is significantly better that those with later stages, and these patients may live three years or longer. However, it is difficult to catch the cancer this early because people with this stage do not usually have symptoms.\nCurative surgery to remove the tumor is considered the first line of treatment, and doctors usually recommend aggressive treatment that includes chemotherapy and radiotherapy.\nMedian life expectancy at stage I is 21 months.\nStage II symptoms are vague and mild. Patients — and even doctors — sometimes mistake them for signs of other illnesses like the flu. Patients with peritoneal mesothelioma may lose weight and yet feel bloated.\nSeveral treatment options are available, and doctors can usually offer curative surgery to remove tumors. In studies, some patients diagnosed at this point survive for years.\nMedian life expectancy at stage II is 19 months.\nOnce the cancer progresses to stage III, it may have spread to several locations on the same side of the body as it formed. These areas may include the lymph nodes, esophagus, muscles, ribs, heart and the chest wall.\nPleural mesothelioma patients may suffer from more difficulty breathing and intense chest pain even when resting. Peritoneal mesothelioma usually involves some type of bowel obstruction and pain. Because the tumors have now spread to multiple areas of the body, discomfort may be felt in other parts of the body as well.\nTumors typically do not respond to potentially curative treatment, and some stage III cancer patients will find themselves ineligible for surgery. At that point, doctors offer palliative options.\nMedian life expectancy at stage III is 16 months.\nAbout 30 percent of mesothelioma patients are not diagnosed until this stage. By stage IV, tumors have metastasized (spread) throughout the body via the bloodstream and could be present on the liver, in the brain, bones or elsewhere.\nPatients experience extreme difficulty breathing and suffer from severe chest pain. Tumors can spread to the esophagus or stomach, causing digestive problems and difficulty swallowing or eating.\nDoctor's don't recommend aggressive surgeries. Instead, they fall back on palliative treatments designed to ease pain and control symptoms.\nMedian life expectancy at stage IV is 12 months or less.\n|Parietal pleura:||The lining of the chest cavity|\n|Visceral pleura:||The lining of the lungs|\n|Lung parenchyma:||Any form of lung tissue, including the bronchioles, bronchi, alveoli, interstitium and blood vessels|\n|Mediastinal:||Affecting the mediastinum, the area between the lungs containing the heart, aorta, trachea esophagus and thymus|\n|Diaphragmatic pleura:||The lining of the diaphragm, a primary breathing muscle|\n|Peritoneum:||The lining of the abdominal cavity|\n|Endothoracic fascia:||A layer of connective tissue that separates the ribs from the pleura|\n|Pericardium:||The lining of the heart|\n|Myocardium:||The muscle tissue of the heart|\n|Diffuse:||Spread across a wide area|\n|Multifocal:||Occurring in more than one location|\n|Unresectable:||Not capable of being removed with surgery|\n|Nontransmural:||Occurring not completely, but partially across the wall of an organ|\n|Ipsilateral:||On the same side of the chest as where the cancer formed|\n|Contralateral:||On the opposite side of the chest as where the cancer formed|\nThe Brigham staging system was created by Dr. David Sugarbaker at the Brigham and Women’s Hospital in Boston. With this system, doctors examine organs, tissues and other structures to learn how far the cancer has advanced.\nTumors are confined to the lining of the lungs and cancer has not spread to the lymph nodes.\nTumors are confined to the lining of the lungs. Either the intraparenchymal or mediastinal lymph nodes are cancerous.\nAggressive and unresectable tumors in the lining of the lungs have spread into the mediastinum or invaded the chest wall, diaphragm or contralateral lymph nodes.\nCancer has spread to other parts of the body and is unresectable.\nFind out if you or a loved one qualifies for free mesothelioma medical care.\nDoctors use the TNM system to stage many different types of cancer. In 1995, the International Mesothelioma Interest Group (IMIG) modified this system specifically for asbestos-related cancers because of the lack of a universally accepted staging system.\nAlso called the IMIG Staging System, this is the most widely used system for someone with pleural cancer. Doctors sometimes use it for other types as well. Earlier staging systems like the Butchart system and Brigham system were based largely on studies of patients who underwent extrapleural pneumonectomy.\nThe abbreviation TNM signifies three different parts of a diagnosis:\n(T) describes tumor size and location.\n(N) describes whether lymph nodes are affected.\n(M) describes whether the tumors metastasized, or spread, to other parts of the body.\nDoctors add a number after each letter to describe how far the cancer has advanced. As tumor size increases and the cancer invades more structures, the number increases.\nT describes the size and location of the tumor:\nThe primary tumor cannot be assessed.\nThere is no evidence of a primary tumor.\nThe tumor is limited to the ipsilateral parietal pleura as well as the mediastinal and diaphragmatic pleura. There is no involvement of the visceral pleura.\nThe tumor has spread to the ipsilateral parietal and visceral pleura, along with the mediastinal and diaphragmatic pleura.\nThe ipsilateral pleural surfaces, which include the parietal, mediastinal, diaphragmatic and visceral pleura, have been invaded by tumors. At least one of the following features is also included in this stage:\nThe tumor has expanded locally, but can potentially be removed with surgery. It has invaded all of the ipsilateral pleural surfaces, which include the parietal, mediastinal, diaphragmatic and visceral pleura. One or more of the following features will be displayed:\nThe tumor is locally advanced and is unresectable. It has spread to all of the ipsilateral pleural surfaces including the parietal, mediastinal, diaphragmatic and visceral pleura. These tumors will also display at least one of the following features:\nN describes whether the cancer has spread to glands of the immune system called lymph nodes:\n|NX||The regional lymph nodes cannot be assessed.|\n|N0||Cancer has not spread to the regional lymph nodes.|\n|N1||Cancer has spread to the ipsilateral bronchopulmonary or hilar lymph nodes.|\n|N2||Cancer has spread to the subcarinal or the ipsilateral mediastinal lymph nodes, which include the ipsilateral internal mammary nodes.|\n|N3||Cancer has spread to the contralateral mediastinal, contralateral internal mammary, ipsilateral or contralateral supraclavicular lymph nodes.|\nM indicates whether cancer has spread to other parts of the body. If the cancer has metastasized, that means it has spread, causing secondary tumors to grow in distant parts of the body away from where the first tumor formed.\n|MX||The presence of metastasis cannot be assessed.|\n|M0||The tumor has not metastasized to other parts of the body.|\n|M1||Metastasis to other parts of the body has occurred.|\nTNM stage grouping combines the tumor, node and metastasis values to reveal the cancer's stage.\n|Stage||Primary Tumor (T)||Regional Lymph Nodes (N)||Metastasis (M)|\n|Any T||Any N||M1|\nHear how survivors learned about their diagnosis and what steps they took to cope. Learn More\nA former shipyard worker visits his doctor and complains of relatively mild symptoms including difficulty breathing and a feeling of heaviness in the chest. Because the patient presents with a history of exposure to asbestos on the job, the doctor suspects mesothelioma.\nAfter conducting a series of tests, the doctor finds a tumor that involves the supporting tissues of the lung and the diaphragm (T2), but finds no evidence that the tumor has spread to the lymph nodes (N0) or other areas of the body (M0). The doctor would likely diagnose the patient with stage II mesothelioma.\nThe Butchart system is the oldest method of staging pleural mesothelioma. Eric Butchart proposed this system in 1976 in an article for Thorax medical journal.\nThe Butchart system classifies tumors as stage I through IV using the same basic parameters as the TNM and Brigham systems.\nButchart intended his system to help identify which patients are good candidates for radical treatment. Again, only patients with stage I or II cancer are candidates for curative treatment, and palliative treatment is offered to patients in the two late stages.\nThis system also may help doctors determine prognosis. In four multivariate studies, early stage is listed as a sign of good prognosis. Two of the studies cited stage I disease as a highly favorable factor for survival.\nThe cancer affects the pleura on only one side of the chest, and may have spread to the pericardium and diaphragm. Curative surgery is considered a first-line treatment.\nCancer has spread to the chest wall and may affect both sides of the pleura. It may have spread to the esophagus, heart or lymph nodes of the chest. Butchart primarily recommends high-dose radiation therapy to most patients with stage II mesothelioma.\nCancer has spread to the diaphragm or peritoneum. Mesothelioma cells have also traveled through the lymphatic system to lymph nodes outside the chest. These tumors are generally unresponsive to curative therapies, so patients are introduced to their palliative options. Butchart suggests tube drainage for pleural effusions and delivery of chemotherapy drugs directly to the chest.\nThe cancer has spread through the bloodstream to distant parts of the body. Tumors may now be present on the liver, brain or bones, among other organs. Patients with stage IV mesothelioma are considered terminal and Butchart recommends solely palliative treatments.\nThrough a process known as tumor grading, doctors classify cancerous cells based on how they appear under a microscope. Researchers confirmed that cellular features of tumors can offer signs to help doctors better predict survival among mesothelioma patients.\nOne of several approaches to tumor grading is nuclear grading. The process classifies the size and shape of the nuclei in tumor cells while examining other factors, including nucleolus size, chromatin patterns and the rate of cell division. These variables play central roles in cancer cell genetics, and ongoing studies are exploring their clinical value as indicators of prognosis.\nThe nuclear grading system developed at Cleveland Clinic inspired other studies that investigated the connection between tumor grade and mesothelioma survival. In what turned out to be the strongest evidence supporting this relationship to date, researchers at Memorial Sloan-Kettering Cancer Center analyzed 232 cases of epithelioid diffuse malignant pleural mesothelioma for the following features:\nThe analysis proved that nuclear atypia (variations in cell nucleus appearance) and mitotic count (the number of cells actively dividing) were directly related to a patient's prognosis.\nSevere nuclear atypia was found to drastically reduce overall survival, and a low mitotic count, which means that few cells are dividing and spreading, indicated the highest overall survival. Using this information, the researchers developed a three-tier nuclear grade score that divides patients into the following prognostic groups:\n|Grade||Median Overall Survival|\n|Grade 1||28 months|\n|Grade 2||14 months|\n|Grade 3||5 months|\nThe results of this study also showed tumor cell's chromatin, which is a combination of nuclear DNA and protein, was also linked to survival.\nNot only was nuclear grade found to be a simple, cost-effective prognostic tool for determining overall survival, but it also helped predict the time to mesothelioma recurrence among patients treated with surgery. Patients with a low mitotic count averaged 67 months before their cancer returned, and those with a high mitotic count averaged 14 months.\nView our resources for patients and familiesGet Help Today"", '01. Treatment Advancements\nAdvancements in Treatment Modalities\nAs mesothelioma awareness increases, more research dollars and time are being spent on testing and improving standard therapies, and studying impacts of combining these therapies with newer modalities, such as immunotherapy.\nUpdates to Traditional Treatments\nStandard mesothelioma treatments include surgery, chemotherapy and radiation. Researchers continue to study different applications and combinations of these treatments for the best patient outcomes.\nFor peritoneal mesothelioma patients, cytoreductive surgery (CRS) combined with hyperthermic intraperitoneal chemotherapy (HIPEC) has been shown to improve survival for patients whose disease is diagnosed in the early stages. In one study, more than 50 patients treated with a CRS and HIPEC combination achieved median overall survival of 97.8 months. However, further studies are needed to test the efficacy of the treatment for peritoneal mesothelioma patients diagnosed in the later stages of disease, which currently occur more often than early diagnoses.\nThe most encouraging development in chemotherapy treatment in recent years has been the success found with bevacizumab, sold as Avastin. When the drug was added to treatment with standard chemotherapy drugs (pemetrexed and cisplatin), pleural mesothelioma patients experienced improved survival rates. One study found patients treated with bevacizumab in addition to pemetrexed plus cisplatin achieved median survival of 18.8 months. Comparatively, patients in the same study treated with just pemetrexed and cisplatin had a median overall survival of 16.1 months.\nOne of the most promising additions to mesothelioma radiation treatment is intensity-modulated radiotherapy (IMRT). The therapy is among the most common types of radiation therapy now used for most mesothelioma patients. One study found using IMRT prior to surgical treatment with extrapleural pneumonectomy extended median patient survival to 36 months. The average malignant pleural mesothelioma life expectancy is six months to one year.\nEmerging Cancer Treatments\nIn addition to analyzing necessary adjustments and improvements to the standard treatments, researchers are testing emerging cancer treatments as potential adjuvant, neoadjuvant and first- and second-line therapies. Promising new treatments include gene therapy and immunotherapy, specifically cancer vaccines and Keytruda®.\nGene therapy treats mesothelioma cancer by introducing new genes to the patient’s body. These genes, often given through virus vectors, invade the mesothelioma tumors, making it easier for the body’s own immune system to attack and kill the cancer cells. A 2016 study found pleural mesothelioma patients previously treated with chemotherapy who underwent gene therapy followed by a second round of chemotherapy achieved a median overall survival of 21.5 months, with a 2-year survival rate of 32%. The patients were treated using the human interferon-alpha2b gene (Ad.IFN).\nA second group in the study received gene therapy and then their first round of chemotherapy. This group had a median overall survival of 12.5 months. These findings suggest that gene therapy given between two rounds of chemotherapy creates the most favorable outcomes for pleural mesothelioma patients. However, both groups in the study achieved median overall survival times longer than the average survival time for pleural mesothelioma patients, which is about one year. Further study is required to determine the best therapies to combine with gene therapy, though the results of this study along with the tolerability of the treatment gives hope.\nImmunotherapy uses a patient’s own immune system to fight their cancer. Immunotherapy drugs help differentiate cancer cells from normal healthy cells, enabling the body to better detect and target cancerous tumors. The ability to attack the cancerous tumors and not blindly kill all cells creates less harmful side effects for the mesothelioma patients. Two of the most promising immunotherapy treatments for mesothelioma patients are cancer vaccines and Keytruda®.\nA cancer vaccine uses cancer cells and the body’s immune system to treat a patient’s mesothelioma cancer. The vaccines use immune system memory to treat the cancer, with the hope that the treatment will persist long after the vaccination. There is currently no cancer vaccine approved by the U.S. Food and Drug Administration (FDA) for the treatment of mesothelioma, but there has been success using the therapy for the cancer in clinical trials.\nOne trial using a dendritic cell cancer vaccine found promising results. Seven out of the 10 pleural mesothelioma patients treated with the vaccine achieved survival of at least 24 months. Greater still, two patients were alive 50 and 66 months after treatment. While the clinical trial was small, the favorable patient outcomes confirm the need for further studies into mesothelioma cancer vaccines.\nKeytruda®, generic name pembrolizumab, is an immune checkpoint inhibitor that blocks the PD-1/PD-L1 gene pathway. Blocking the pathway enables the immune system to identify and kill cancer cells. The drug is currently approved by the FDA for use in non-small cell lung cancer (NSCLC), hodgkin’s lymphoma and melanoma. While not specifically approved for the treatment of mesothelioma cancer, the drug has been successful in clinical trials.\nOne trial, KEYNOTE-028, found that of the 25 pleural mesothelioma patients they treated with the drug, 52% had stable disease following treatment. Additionally, the trial reported a patient median overall survival of 18 months. More than 62% of patients in the trial achieved 12-month survival, which is currently the average survival time for pleural mesothelioma patients. The trial shows that Keytruda® is a promising mesothelioma treatment option, and also proved that the drug is safe for long-term use by patients as there were minimal side effects reported.\nResources for Mesothelioma Patients\n02. Research Limitations\nAreas that Require More Research\nAdvancements in mesothelioma cancer research are being made every single day. Cancer treatments are being improved, scientists are creating more effective new drugs and mesothelioma survivors are living longer than ever. However, in order to find a cure, there are obstacles that need to be addressed. Symptom latency and the variety of genomic alterations within the cancer are two of the roadblocks that healthcare professionals need to overcome in their search for a mesothelioma cure. Thankfully, progress is being made.\nEarly Detection to Combat the Latency of Symptoms\nA major hurdle in the fight for a mesothelioma cure is late diagnosis of patients. When diagnosed in the later mesothelioma stages (stage 3 or 4), patients may be ineligible for aggressive treatment modalities, such as certain surgical treatments, due to the metastasis of tumors.\nUnfortunately, early detection is rare. Patients are often not diagnosed until the later stages because the cancer does not manifest until decades after initial asbestos exposure. Once symptomatic, patients may not receive an accurate diagnosis due to the common, nonspecific nature of mesothelioma symptoms. For instance, pleural mesothelioma may be misdiagnosed as the common cold or influenza.\nHowever, researchers have begun to make progress toward being able to diagnose mesothelioma in the earlier stages. Biomarkers and blood tests are being used to combat the difficulty associated with the latent symptoms. Researchers in a 2016 study were able to accurately identify malignant mesothelioma in 17 patients between 4 – 10 years prior to symptom manifestation. The researchers tested serum samples from the asbestos-exposed individuals for the presence of ENOX2, which is a known cancer marker. Their findings require further research to identify if this particular biomarker may be viable on a larger scale.\nBiomarkers that are already widely used for mesothelioma include MESOMARK, HMGB1 and N-ERC/Mesothelin test. While these tests are not enough to diagnose mesothelioma patients, they can be used to identify if further more invasive procedures, like a biopsy, are needed for diagnosis.\nOnce diagnosed, proper initial staging of the cancer is the first step to best treating a patient’s specific mesothelioma case, and leads to the most favorable outcomes. Researchers have found that a PET-CT works best to determine cancer stage and predict patient outcomes. Once staged appropriately, the most aggressive viable treatment option can be administered. Accessing treatment early is proven to increase mesothelioma survival rates. A group of pleural mesothelioma patients in France achieved a 46% 5-year survival rate when diagnosed at the early stages of disease and treated with a multimodality approach. On average, studies have found the 5-year survival rate for pleural mesothelioma is 12%.\nVariety of Genomic Alterations\nOnce diagnosed, the variety of genomic alterations within mesothelioma on a per patient basis further complicates the treatment of the cancer. Patients may have between 1 – 5 genomic alterations, which makes it critical to know the treatment that is most effective for each genomic defect. Studies have found that each patient’s molecular portfolio is different, suggesting that personalized medicine may be necessary for treatment of mesothelioma patients, specifically patients presenting with pleural mesothelioma. The most common alterations for mesothelioma patients occur in the BAP1, NF2, CDKN2A/B and P53 genes. Ongoing clinical trials are focusing on treating these specific genomic alterations to find a cure for mesothelioma cancer.\nGet a Free 2022 Mesothelioma Guide\n- Top doctors and clinics\n- Latest treatments\n- Caregiver information\n03. Moving Forward\nWhile there is still no cure for mesothelioma, the improvements made within mesothelioma treatments and diagnostic tests give hope for the future. Patients are able to fight their cancer with new tools that have enabled some patients to survive for years beyond their initial prognosis. Those diagnosed with mesothelioma should discuss all potential treatment options with their medical team to decide which options may provide the most favorable outcome.']"	['<urn:uuid:809a81ab-16f7-42ec-a82f-56e3e97ecfb7>', '<urn:uuid:65291f2b-7dc3-4410-91a3-a8db84dd7e61>']	factoid	with-premise	short-search-query	similar-to-document	multi-aspect	expert	2025-05-12T23:56:45.148498	8	57	4184
49	My well water has a terrible rotten egg smell and I'm worried about bacteria - what's the recommended treatment approach for this specific situation?	For water with hydrogen sulfide 'rotten-egg' odor and iron bacteria, a good practice is to chlorinate the water prior to using a greensand filter. The injection of chlorine substantially increases the effectiveness of the greensand media and allows it to work without potassium permanganate while removing higher levels of iron and manganese. For such cases with high hydrogen sulfide gas or coliform bacteria, a contact tank is recommended.	['Iron is one of the Earth’s most plentiful resources, making up at least 5% of its crust. In well water, iron is usually found as ferrous iron, which is in a dissolved state, potentially causing water to appear clear when first drawn from the tap.\nThe maximum level of iron recommended in water is 0.3 mg/L, or 0.3 ppm. When the level of iron in water exceeds this limit, water may have a red, brown or yellow color, and can stain laundry and fixtures. The water also may have a metallic taste and an offensive odor. Water system piping and fixtures can become restricted or clogged, and appliances such as water heaters, dishwashers and washing machines can become plugged with rust and sediment.\nIn some applications, ion exchange resin can be used to remove ferrous iron, but the most common method is to oxidize it to a ferric state, and then filter out the precipitated particles. One way to accomplish this is to use one of many types of oxidizing manganese-based filter media.\nUnder the proper conditions, when water flows through a tank with this type of media, the dissolved iron oxidizes and becomes trapped. Periodic backwashing and rinsing clean the iron filter media of the trapped substances.\nThis oxidation and filtration process, called regeneration, can occur continuously or intermittently, and there are advantages and considerations for each type of process.\nVarious types of iron filter media are available, including Birm, manganese greensand, Pro-OX, Filox and Pyrolox. Birm and greensand are two types of coated iron filter media, whereas Filox and Pro-OX are solid manganese dioxide media.\nOxidizing iron filters use either oxygen injection (with air or pure oxygen), potassium permanganate, chlorine or ozone to aid the filter media in oxidizing the iron.\nManganese Oxide-Coated Media\nBirm and greensand are two widely used types of iron filter media. Birm is a trademark of Clack Corp., and is manufactured from a type of natural pumice coated with manganese dioxide. It is lighter in weight than solid manganese dioxide filter media, and therefore often requires less backwash water. It does not remove manganese unless the pH is more than 8.2, however, and is not recommended for use when hydrogen sulfide gas is present. It cannot be used if the water is chlorinated.\nIn most cases, Birm requires an air induction system to work effectively. It will not work well if the pH is less than 6.9. It may last for many years under some conditions, but the coating can wear off. The media may need to be replaced every three to five years.\nSimilar to Birm, greensand filter media have a special coating of manganese dioxide, which oxidizes iron, manganese and iron in water upon contact.\nUnlike Birm, chlorination aids in the filtration process and does not harm the filter media. Greensand works under more acidic conditions, down to a pH of 6.2. Filters using this media remove manganese and hydrogen sulfide.\nTo provide the oxidizing power to precipitate iron and manganese, greensand iron filters are commonly automatically cleaned and restored with potassium permanganate during each backwash cycle. This is known as intermittent regeneration.\nAs an alternative to potassium permanganate powder, a chlorine injector pump can be used ahead of the greensand filter to regenerate the filter media continuously, a process known as continuous regeneration. Greensand media generally need to be replaced every four to six years, although under the right conditions and proper maintenance, it has been known to last for 10 years or more.\nFor some applications in which the water has hydrogen sulfide “rotten-egg” odor and/or iron bacteria, a good practice is to chlorinate the water prior to the greensand filter. The injection of chlorine (or hydrogen peroxide or ozone) substantially increases the effectiveness of the greensand media, and allows it to work without the use of potassium permanganate and remove higher levels of iron and manganese.\nManganese Dioxide Solid-Core Media\nUnlike Birm and greensand, which are coated with manganese oxide, manganese dioxide solid-core iron filters use natural mined solid manganese oxide ore in a relatively pure form. Most mined manganese ore is found in concentrations of less than 50% manganese, and is widely used in the manufacture of batteries and other industrial applications. In some areas of the world, there are mines that contain manganese with a high concentration of manganese oxide. This mineral is selected and carefully graded especially for water treatment.\nManganese dioxide iron filter media utilize an oxidation-reduction reaction and filtration process similar to greensand, but at a higher level of performance. The Pro-OX, Filox and MangOX brands, for example, contain more than 85% manganese dioxide, whereas greensand contains around 1%.\nThis type of solid manganese dioxide media is heavy and requires a strong backwash flow rate to lift and clean the oxidized particles from the filter bed. Because of the higher performance, faster throughput can be realized, and higher flow rates with smaller filter vessels can be used, which compensates somewhat for the higher backwash flow required. This type of solid manganese dioxide is long lasting, usually requiring replacement after 10 to 15 years.\nThese filters can use either intermittent or continuous regeneration. With intermittent regeneration, a solution of chlorine bleach or potassium permanganate automatically cleans and restores the media. The filter media is first backwashed to clean out any trapped oxidized particles. A concentrated solution of chlorine or potassium permanganate is then automatically fed into the filter system to clean and regenerate the media. In continuous regeneration, compressed air, or, more commonly, chlorine, is fed into the water continuously ahead of the filter.\nFor many applications in which the oxidation-reduction potential (ORP) can be raised to more than 200 mV with aeration alone, no chemical regeneration is required. A typical treatment plant will include air injection under pressure, where the water flows through the tank containing dissolved air. This increases the dissolved oxygen in the water and raises the ORP so the manganese dioxide media can be regenerated with simple backwashing and rinsing.\nHydrogen peroxide is not recommended with manganese dioxide filter systems due to the interaction between peroxide and manganese, which can cause manganese to leach into the water.\nA chlorine feed ahead of the iron filter super-charges the media and allows it to remove high levels of iron, manganese and hydrogen sulfide. Coliform and iron bacteria are killed, and tannins are oxidized.\nA chlorinator metering pump automatically injects a small amount of chlorine ahead of the iron filter. The chlorine pump is installed so that when the well pump turns on, the chlorine pump also turns on and injects a small amount of chlorine bleach.\nFor water high in iron, hydrogen sulfide gas or coliform bacteria, a contact tank is recommended.\nOxidizing filters combat problematic iron contamination']	['<urn:uuid:b45e5baf-3f6d-46c7-91dd-54623871c4c4>']	factoid	with-premise	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-12T23:56:45.148498	24	68	1126
50	I remember Dusty Rhodes and the Road Warriors being a dominant team in JCP - when did they first win the six-man tag team titles and who did they defeat to get them?	Dusty Rhodes and the Road Warriors won the six-man tag team titles on May 17th 1986 in Baltimore, defeating the Russian team with Baron Von Raschke.	['Recently, AEW introduced a new championship into what most would call an already over-saturated market when it comes to championships. The Trio’s tournament concluded with a great match at ALL OUT on September 4th 2022. Unfortunately, the activities that took place at what is now known as “Brawl Out” have over-shadowed this match and the championship it was meant to introduce. Since then, new champions have been crowned in the formitable trio known as Death Triangle.\nBut one may ask, why pick this championship over all the others and what may have been better options for a new championship. Let’s take a look at two of the most famous versions of this historic championship.\nSix-man championships have been around since the mid-1950s. The first recorded use of this title came from the National Wrestling Alliance (NWA) territory in Chicago. The belts were called the NWA World Three-Man Tag Team Championship and would hold this name until 1974. Roy McClarity, Pat O’Connor, and Yukon Eric are the first and only recorded champions to hold this version of the belts. The championship seemed to go dormant until 1974, when NWA Mid-America (later to be known as the Memphis territory) would revive the belts under a new and more familiar name. The NWA Six-Man Championship would be a mainstay for the territory with future legends and Hall of Famers getting a chance to hold this title. Names like Bobby Eaton, Dennis Condrey, Tommy Rich, and Paul Orndorff would add their names to the list of title holders. The championship would once again go dormant until 1984, when a blossoming Mid Atlantic Territory would once again revive the title.\nWhile the NWA was busy deactivating and reactivating one form of the Six-Man title, there was a family down in Texas that would breathe new life into the championship. World Class Championship Wrestling (WCCW) was an NWA territory during the 1980s. They promoted all around the state of Texas and while a part of the NWA still seemed to be doing their own thing regarding championships. On December 25th 1982 at WCCW Star Wars, the team of Michael Hayes, Terry Gordy and David Von Erich defeated Iron Mike Sharpe, Ben Sharpe and Tom Steele to become the first recognized champions. Von Erich would later give his part of the championship to Buddy Roberts, who was unable to be a part of the match. This would play into developing the storyline between the Von Erichs and Freebirds.\nThe NWA World Six-Man Tag Team Championship (Texas version) as they sometimes referred to it, was around until 1988. The Freebird combination of Hayes, Roberts and Gordy held the championship five times, the most of any trio. Kevin Von Erich held the championship 11 times with various partners, including his father Fritz Von Erich, brothers Kerry, David and Mike Von Erich, as well as Michael Hayes, Brian Adias, Chris Adams, Steve Simpson and Lance Von Erich. The longest individual reign lasted 282 days, as Kevin, Mike, and Lance held the title from July 4, 1986 to April 12, 1987. The Freebirds’ five reigns combined to at least 581 days, the longest combined of any team. Fritz, Kevin and Mike Von Erich held the championship just a few hours, as Fritz gave his third of the championship to Kerry Von Erich at the end of the show where they won it.\nWhile the Von Erichs and Freebirds were feuding down in Texas, Jim Crockett Promotions (JCP) was using the original version to help bolster their ever-growing roster. NWA Mid-America would go out of business in 1981, and the titles hadn’t been active since. The newest form of this title would reemerge on July 18th, 1984. Ivan and Nikita Koloff, along with Don Kernodle, would beat Rufus R. Jones, Angelo Mosca Jr and Tom Shaft to be crowned the first champions for JCP. The belts (a trophy at the time) would then change hands just a few times over the next few years, with the Russian team being the most consistent champions.\nThe most famous team to hold these titles would have to be Dusty Rhodes and the Road Warriors. They would defeat the Russians with Baron Von Raschke on May 17th 1986 in Baltimore. They would hold the titles until February 1988 when Ivan Koloff and The Powers of Pain would win them; This would be short-lived as the Powers of Pain would shortly depart for the World Wrestling Federation (WWF). Dusty and the Warriors would regain their belts after defeating Ric Flair, Tully Blanchard, and Arn Anderson in the summer of 1988. The final set of champions would be once again the Warriors, but this time they would call on a new partner in the form of Genichiro Tenryu. The championship vacated in February 1989 because of Tenryu choosing to focus on All Japan’s Triple Crown Championship.\nWorld Championship Wrestling (WCW) would pick up the titles again in 1991. Only 4 teams would hold this title version before deactivating it in December 1991. The last time the titles were mentioned was before Beach Blast 1992, when the match between Bobby Eaton, Arn Anderson, and Steve Austin against Barry Windham, Dustin Rhodes, and Nikita Koloff was originally to bring back the titles, as the match ended up a standard six-man tag match.']	['<urn:uuid:e67f3775-77fe-4a4f-97e2-bae407004809>']	factoid	with-premise	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-12T23:56:45.148498	33	26	882
51	What is the relationship between IgG1 antibodies and bacterial load in leprosy?	Mycobacterium leprae-specific IgG1 antibodies display a direct relationship with bacterial load in individuals with leprosy, suggesting these antibodies could serve as surrogate markers of disease development.	['Mycobacterium leprae-specific immunoglobulin G1 (IgG1) antibodies in individuals with leprosy display a direct relationship with bacterial fill (=0748; < 0002) recommending that IgG1 B-cell reactions could be surrogate markers of disease development. not linked to contaminants with endotoxin. Epitope mapping using 15-mer overlapping peptides spanning the ML 10 000 MW exposed an immunodominant IgG1 binding peptide (aa41C55) in individuals aswell as healthy controls. This peptide is a shared epitope with 10 K suggesting that postswitched IgG1 B cells recognizing this epitope rather than naive B cells are being expanded. INTRODUCTION Dysregulation of both B- and T-cell responses is observed in leprosy with antibody responses being augmented towards the lepromatous or disseminated form of the disease and depression of T-cell responses.1C3 The role of antibody Rabbit polyclonal to ACYP1. is not clear in either protection or disease pathogenesis in leprosy. In the murine model augmented antibody responses are associated with activation of T helper 2 (Th2) subset and progressive disease in several intracellular infections.4,5 Cytokine secreted by the Th2 subset (interleukin-4; IL-4) selectively augment immunoglobulin E (IgE) antibody responses in the murine model6 and IgG4 and IgE in parasitic infections in humans.7 Dissection of antibody responses at the isotype and BMS-790052 2HCl IgG subclass level to whole sonicate in leprosy has not indicated selective activation of either of the antibody isotypes BMS-790052 2HCl (IgG4 and IgE);8 rather we have observed a selective augmentation of (ML)-specific IgG1 and IgG3 antibodies towards the lepromatous pole of the disease.8 Lepromatous individuals also demonstrated polyclonal activation of B-cell reactions for many IgG and isotypes subclasses.8 The existing research addresses the problem of whether IgG1 upregulation in individuals using the lepromatous type of the condition is an over-all feature of B-cell reactions to all or any ML antigens, which might indicate a polyclonal activation-related event, or when there is selective reputation of ML epitopes and antigens by IgG1 antibodies. Among the ML protein, heat shock protein (HSP) have already been BMS-790052 2HCl been shown to be dominating targets of immune system reactions in both experimental versions (evaluated by Coates9) and in individuals with leprosy.10 We’ve therefore completed complete analysis of IgG subclass antibody responses to the combined band of antigens. MATERIALS AND Strategies Individuals and controlsNewly diagnosed leprosy individuals presenting in the Marie Adelaide Leprosy Center (MALC) had been recruited to your studies and also have been referred to at length elsewhere.11 BMS-790052 2HCl Individuals are diagnosed clinically aswell as histologically on a 4-mm punch biopsy taken from the edge of an active lesion. Sixty-five patients from across the leprosy spectrum (lepromatous form, LL/BL = 26; tuberculoid form, BT/TT = 39) who had not been treated for leprosy previously were included in the study. Healthy controls included household contacts of leprosy patients with active disease (HC = 14) and endemic controls (EC = 19) who were employees of the Aga Khan University (AKU) and had no previous history of exposure to leprosy. Ethical approval was obtained from both the AKU ethical committee and MALC Human Rights Protection Committee. Written/oral consent as appropriate was obtained from both patients and control groups. Antigens10 000 MW (ML 10 K; batch ML 10-2) and 10 000 MW (MT BMS-790052 2HCl 10 K; batch MT10-2) 18 000 MW (ML 18 K Lot #36-38) and 65 000 MW (65 K Lot #65-5C) antigens were obtained from the World Health Organization (WHO) reference reagent bank through the courtesy of Dr Jan van Embden. The 10 000 MW (ML 10 K) contains 603 units/mg of endotoxin and 10 000 MW (MT 10 K) contains 698 units/mg of endotoxin. sonicate (ML) Lot CD197 was obtained through the courtesy of Dr J. Colston, Mill Hill, UK. Endotoxin (LPS Lot#103H4009)) was obtained from Sigma Chemicals, St Louis MO. AntiseraFive millilitres of blood collected from leprosy patients was allowed to separate overnight at 4. Serum was removed and centrifuged at 400 for 15 min; the very clear supernate was distributed in little aliquots and iced at ?70 before use. Reagents, monoclonal antibodies and conjugatesMonoclonal antibodies particular for individual IgG subclasses: Horsepower 6001(anti-IgG1), Horsepower 6002 (anti-IgG2), Horsepower 6047 (anti-IgG3), Horsepower 6023 (anti-IgG4) ready at the guts for Disease Control, Atlanta, GA had been something special from Dr Reimer. The specificity, evaluation and efficiency features of the antibodies elsewhere are described at length.12,13 Goat antihuman IgG (Fc particular) and goat antimouse IgG (H+L string particular), conjugated to alkaline phosphatase had been.']	['<urn:uuid:9f03cf3a-9ff0-4178-8a6d-23c031f24b09>']	open-ended	direct	concise-and-natural	similar-to-document	single-doc	expert	2025-05-12T23:56:45.148498	12	26	731
52	What role does dissociation play in both artistic video creation and social media use?	In artistic video creation, dissociation is used creatively to transform reality into abstract digital spaces, as seen in works that convert landscapes and architecture into fluid digital forms. In social media, dissociation manifests as a problematic state where users become disconnected from their actions, losing track of time and self-reflection while scrolling through content.	"[""Interview with Sabrina Ratté\nImage: Sabrina Ratté. Courtesy of the artist.\nSabrina Ratté is a Montreal-based media artist and the visual part of Le Révélateur, a collaboration with the electronic music composer Roger Tellier-Craig. In 2010, I saw one of the earliest screenings of Ratté’s work in the show, Sleep… in the gallery, curated by the sound artist crys cole at Winnipeg’s Ace Art Inc. Ratté has since been named “One of the most promising names in Canadian experimental film today” by the blog, The Sound of Eye and it can be argued that her work represents the future of retro. Ratté also contributes to one of the nerdiest sites on the Internet, Computers Club Drawing Society, a collective of artists who draw using basic online tools.\nI contacted Ratté in the winter of 2012 to discuss her work and her artistic process. The interview took place over the span of a few e-mails.\n* * *\nClint Enns: Was Sleep… in the gallery your first screening?\nSabrina Ratté: It was among the first screenings I participated in as a video artist. L’entre-Deux (2010) and Le Labyrinthe (2010) marked the beginning of my exploration of video as a medium.\nCE: L'entre-Deux is a sophisticated meditation on light and shadow. What role did the camera play in making the piece? Did you exploit the auto-exposure mechanism?\nSR: L’entre-Deux was made while I was on holidays with my family. I only had a small, ten-year-old digital camera with me. It was very basic; there were not a lot of options for manual settings. That day, the sun was really strong and the clouds were regularly passing in front of it. On the white terrace next to the restaurant, the shadows of the palm trees were appearing and disappearing in a very rhythmic way. The ghostly movements of the shadows were so beautiful that I stood there shooting for almost an hour. To emphasize the natural contrast of the image and to add more texture I re-shot the footage off of my computer screen many times. It was the first time I abstracted images through this type of re-photography. Now I do it almost all the time.\nCE: What type of art did you make before these first videos?\nSR: I did my BA and my MFA in the Film Production program at Concordia University in Montreal. I had the opportunity to direct short fiction films and to experiment with 16mm film and Super 8. I was also taking a lot of photos, which remains an important part of my practice. It took me a while to realize that I wasn’t interested in working with film as a material and that I'm not into conventional storytelling. My interest has always been more oriented towards the aesthetic side of cinema – engaging with the image rather than with narrative. On the other hand, as a spectator, I love narrative cinema and it is often an inspiration for my work. Also, video seemed more natural to me. Once I made that realization, everything took on an extra dimension and my relationship with the medium developed quickly.\nCE: Can you describe your collaborative process with musicians? How do you choose the musicians you work with, and how did you begin collaborating with Roger Tellier-Craig? What comes first, the images or the music?\nImage: Mirages (Le Révélateur [Sabrina Ratté and Roger Tellier-Craig], 2010). Courtesy of the artist.\nSR: I started collaborating with Tellier-Craig when I became more dedicated to video. My personal research is very much intertwined with our collaboration Le Révélateur, – which involves live projections as well as press photos, album covers, and videos. Even though this project is collaborative it is as personal as my solo work. It has also been very important to my development, both in terms of techniques and idea. With time, my solo practice and my collaboration with Le Révélateur evolved in different directions.\nWith my own videos, I tend to seek out music that is more neutral. The music is usually abstract and parallels the visual language, adding interpretations without overpowering the images. The music always comes after the image. With Le Révélateur the music comes first. The melodies and the atmosphere inspire me. With each release, we often discuss our influences and the kind of world we want to create.\nCE: Does the video ever generate the music or vice versa?\nSR: No. I have experimented a little bit with plugging Roger’s synth into my video synthesizer, however, I am not yet convinced that this is the direction I would like to take. I like accidents and coincidences, and the way we work right now provides a lot of them.\nImage: Bleu Nuit (Le Révélateur [Sabrina Ratté and Roger Tellier-Craig], 2011). Courtesy of the artist.\nCE: You have also made music videos for Innergaze, Steve Hauschildt, Jefre Cantu-Ledesma, Femminielli, Boxcutter, and Raglani.\nSR: I make music videos occasionally with musicians that I like. It is important that the music inspires me, and that I have freedom to do what I want. This way it feels collaborative and it helps me to develop new artistic approaches. Each of these videos represents a step further in my experimentation. Each video I make takes a lot of time and that is part of the process. This is why I have to be selective. Sometimes I do make videos strictly for money, but at this point I am hesitant. Every artist struggles with making a decent living and making time to develop personal work.\nCE: Can you talk about your involvement with Plink-Flojd?\nSR: David Quiles Guilló emailed me, asking if I wanted to participate in this project. It consists of making a video in collaboration with a musician who remixes a Pink Floyd song. In this instance I used video feedback and an Azden analog mixer. David, Yoshi Sodoeka and Eric Mast, the founders of the project, did a fantastic job curating it. I’m curious to see where it will go in the future.\nCE: Are you interested in visual music? Who are some of your influences?\nSR: Visual music has been a huge influence on my work. It’s hard to say which artist influenced me the most, or if they all fit the “proper definition” of visual music. Among others, I would name Lillian Schwartz, Erkki Kurenniemi, Toshio Matsumoto, Ed Tannenbaum, Steina and Woody Vasulka, and Vibeke Sorensen. Recently I have discovered the work of Michael Scroggins. Totally mind blowing! I often post about artists I am interested in on my blog, Diamond Variations.\nCE: Auroratone films are also examples of visual music. How did you become involved with the recent Auroratone project  for Pop Montreal? Did Kier-La Janisse see your work in Winnipeg at the sleepscreening?\nSR: I don’t know how Kier-La found out about my work, but when she invited me to participate to this project I was really excited about it. The concept of the project was so original and interesting, I had never heard of that film genre before. It gave a whole other dimension to visual music and this was really motivating for me.\nImage: AURORATONE (Sabrina Ratté, 2012). Courtesy of the artist.\nCE: Your Auroratone video was extremely well edited. How do you balance working between analogue video synthesizers and digital editing software?\nSR: For the Auroratone project I used a similar technique to the Activated Memory series (2011); it is based on animated photographs. I then re-photograph the animation and add some video feedback. For the Auroratone, I also added visual textures made with a video synth. The editing was very simple; I didn’t cut anything until the very last sequence when everything gets blue. The animation and the video feedback did all the work. Once I have the perfect rhythm and type of images, the editing seems to take care of itself! This has been true for many projects I have done, but sometimes I do work very thoroughly with precise and multiple cuts, like my last video for Raglani, for instance.\nCE: How did you get involved with Computers Club Drawing Society, and do you approach the process of making images (i.e. drawings) differently than making videos? Are the images tests for your videos?\nSR: I was invited to join the Drawing Society in 2011 by Krist Wood, the initiator of the project and an artist that I admire. It was a real honor. At first, I was frightened... I hadn’t practiced drawing since I was a child; however, it was also a great opportunity to think about images differently and to explore new tools. It turned out to be something that I really enjoy doing. It certainly influenced my video work. I began to think about the videos as drawings or paintings, and I wanted to see how far I could push that idea. In Data Daze (2012), a video made for Le Révélateur, I literally draw in the video image.\nCE: It seems that you are interested in the early CGI aesthetics from the late-80s and early-90s.\nSR: Yes, it is something that fascinates me. The idea of creating a very realistic world and yet so obviously artificial creates this tension that I am trying to convey in some of my videos. I guess I have a particular taste for what was made during those decades.\nImage:Station Balnéaire / Variation 1(Sabrina Ratté, 2011). Courtesy of the artist.\nCE: That seems reflected in your choice of video equipment. What analogue and digital tools are you using? Do you prefer one type over the other?\nSR: Definitively both! I use a Sony HDV camera, a Mac, Modul8, and Final Cut Pro. On the analog side of things, I found an Azden mixer that allows me to experiment with video feedback and to manipulate video images in a variety of ways. I also bought a LZX video synthesizer, which I am slowly but surely integrating into my work. This is a huge step in my process, and I have been overwhelmed by the potential of that new tool over the last few months. The video I made for Raglani, that I mentioned earlier, is the first time I used images produced by my LZX.\nCE: Some of your work reminds me of Jane Wright’s Electronic Sunsets from the 1970s. The series consists of over 40 video landscapes made using an early video synthesizer. The images are very spiritual, meditative, and soothing. Are you familiar with them?\nSR: I wasn't until recently! I think you mentioned this connection somewhere before, however, I can’t remember where. I’ve only watched an excerpt on YouTube, so if you happen to know where or when I can see more of her work I would be enchanted! It is absolutely inspiring, and the treatment of sound, too.\nCE: I helped transfer some of her videos from 1-inch videotapes at Vtape. In the future, I hope someone will screen your work together. I’m intrigued by your landscape imagery. It seems different from Wright's, less representational.\nImage: Transit (Sabrina Ratté, 2011). Courtesy of the artist.\nSR: All my personal videos, so far, are based on images taken from “reality.” Even Transit (2011), the most abstract one, was based on images that I shot in Paris when I was sitting in a café in the evening, mesmerized by the shadows of people passing by an illuminated map. I like that passage from “reality” into a digital one. Another example is Station Balnéaire (2011), which was shot in Italy, on the Amalfi Coast. It is more figurative, which I like; however, it has been completely transformed by video feedback. That process, of transforming landscapes or architecture into something more abstract, atmospheric, where pixels and electronic signals are suddenly prominent, inspires me.\nCE: This can also be seen in the videos Activated Memory I and Activated Memory II, where you transform buildings and landscapes into fluid digital spaces. You’ve also used found footage. How do you choose what images to work with?\nSR: I did work with found footage in the past, but mostly for short experiments. Found Video #1 (2011) is done with found footage as main material, and for Retour des Étoiles (2010) I used some found footage of the galaxy. There is a short clip in Mirages (2010) as well. But eventually, I started using only images that I shot myself. I’m not sure how this happened. I am constantly taking pictures, often of architecture, night shots with artificial lights, landscapes, etc, that I assume I will eventually use in a video. The atmosphere of spaces, and the way I project myself in those spaces, attracts me. I have a blog where I started to collect my favorite series of photos, which eventually might end up in a video.\nImage: Activated Memory I (Sabrina Ratté, 2011). Courtesy of the artist.\n1. Le Révélateur has a limited edition DVD-R, Root Strada release #76.\n2. The Auroratone Project was a commission of original short films by experimental Canadian filmmakers set to the music of POP Montreal’s 2012 participants. “Auroratones” were abstract musical films used in mental institutions and army hospitals after World War II as a means of soothing post-traumatic stress disorder and general mental disturbance. The technology was invented by the film enthusiast Cecil Stokes, who was continuing on nearly two centuries of previous pseudo-scientific attempts to correlate color with musical tones.\n3. See: http://cinepoeme.blogspot.ca/2012/01/melting-signals.html\nVarious experiments can be found at:\nPublished February 26, 2013\nABOUT THE AUTHOR\nClint Enns is a video artist and filmmaker from Winnipeg, Manitoba. His work, which utilizes broken and/or outdated technologies, has shown nationally and internationally at festivals, alternative spaces and mircocinemas. He recently completed a Master's degree in mathematics at the University of Manitoba and is continuing his studies in cinema and media studies at York University in Toronto."", 'Disrupted sleep, decrease life satisfaction and poor vanity are just some of the adverse psychological well being penalties that researchers have linked to social media. In some way the identical platforms that may assist folks really feel extra linked and educated additionally contribute to loneliness and disinformation. What succeeds and fails, scientists say, is a perform of how these platforms are designed. Amanda Baughan, a graduate pupil specializing in human-computer interplay on the College of Washington, research how social media triggers what psychologists name dissociation, or a state of diminished self-reflection and narrowed consideration. She offered outcomes on the 2022 Affiliation for Computing Equipment Laptop-Human Interplay Convention on Human Elements in Computing Techniques. Baughan spoke with Thoughts Issues editor Daisy Yuhas to elucidate how and why apps want to alter to present the individuals who use them better energy.\n[An edited transcript of the interview follows.]\nYou’ve proven how altering social media cues and shows may enhance well-being, even when folks strongly disagree on points. Are you able to give an instance?\nThe design of social media can have quite a lot of energy in how folks work together with each other and the way they really feel about their on-line experiences. For instance, we’ve discovered that social media design can truly assist folks really feel extra supportive and type in moments of on-line battle, offered there’s a bit little bit of a nudge to behave that method. In a single examine, we designed an intervention that inspired individuals who begin speaking about one thing contentious in a remark thread to change to direct messaging. Folks actually preferred it. It helped to resolve their battle and replicated an answer we use in-person: folks having a public argument transfer to a personal area to work issues out.\nYou’ve additionally tackled a unique downside popping out of social media utilization known as the 30-Minute Ick Issue. What’s that?\nWe in a short time lose ourselves on social media. When folks encounter a platform the place they will infinitely scroll for extra data, it may set off an identical neurocognitive reward system as in anticipating a profitable lottery ticket or getting meals. It’s a robust method that these apps are designed to maintain us checking and scrolling.\nThe 30-Minute Ick Issue is when folks imply to examine their social media briefly however then discover that half-hour have handed, and once they notice how a lot time they’ve spent, they’ve this sense of disgust and disappointment in themselves. Analysis has proven that individuals are dissatisfied with this ordinary social media use. Lots of people body it as meaningless, unproductive or addictive.\nYou’ve argued this expertise is much less a matter of dependancy and extra a problem of dissociation. Why?\nDissociation is a psychological course of that is available in many varieties. In the most typical, on a regular basis dissociation, your thoughts is so absorbed that you’re disconnected out of your actions. You could possibly be doing the dishes, begin daydreaming and never take note of how you might be doing the dishes. Otherwise you would possibly search immersive experiences—watching a film, studying a e-book or taking part in a recreation—that move the time and trigger you to overlook the place you might be.\nThroughout these actions, your sense of reflective self-consciousness and the passage of time is diminished. Folks solely notice that they dissociated in hindsight. Consideration is restored with the sense of “What simply occurred?” or “My leg fell asleep whereas we had been watching that film!”\nDissociation generally is a constructive factor, particularly if it’s an absorbing expertise, significant exercise or a wanted break. But it surely can be dangerous in sure instances, as in playing, or are available in battle with folks’s time-management targets, as with social media scrolling.\nHow do you measure folks’s dissociation on social media?\nWe labored with 43 contributors who used a customized cell app that we created known as Chirp to entry their Twitter accounts. The app let folks work together with Twitter content material whereas permitting us to ask them questions and take a look at interventions. So when folks had been utilizing Chirp, after a given variety of minutes, we’d ship them a questionnaire primarily based on a psychological scale for measuring dissociation. We requested how a lot they agreed with the assertion “I’m presently utilizing Chirp with out actually listening to what I’m doing” on a scale of 1 to five. We additionally did interviews with 11 folks to be taught extra. The outcomes confirmed dissociation occurred in 42 p.c of our contributors, they usually usually reported shedding observe of time or feeling “all-consumed.”\nYou designed 4 interventions that changed folks’s Twitter expertise on Chirp to scale back dissociation. What labored?\nProbably the most profitable had been customized lists and studying historical past labels. In customized lists, we pressured customers to categorize the content material they adopted, comparable to “sports activities” or “information” or “buddies.” Then, as an alternative of interacting with Twitter’s major feed, they engaged solely with content material on these lists. This method was coupled with a studying historical past intervention through which folks acquired a message once they had been caught up on the most recent tweets. Moderately than persevering with to scroll, they had been alerted to what that they had already seen, and they also targeted on simply the most recent content material. These interventions diminished dissociation, and once we did interviews, folks stated they felt safer checking their social media accounts when these modifications had been current.\nIn one other design, folks acquired timed messages letting them know the way lengthy that they had been on Chirp and suggesting they go away. In addition they had the choice of viewing a utilization web page that confirmed them statistics comparable to how a lot time they’d spent on Chirp prior to now seven days. These two options had been efficient if folks opted to make use of them. Many individuals ignored them, nevertheless. Additionally, they thought the timed messages had been annoying. These findings are fascinating as a result of quite a lot of the favored time-management instruments obtainable to folks appear like these time-out and utilization notifications.\nSo what may social media firms be doing in a different way? And is there any incentive for them to alter?\nProper now there’s a lot working towards individuals who use social media. It’s unimaginable to ever totally compensate for a social media feed, particularly when you think about the algorithmically inserted content material comparable to Twitter’s trending tweets or TikTok’s “For You” web page. However I feel that there’s hope that comparatively easy tweaks to social media design, comparable to customized lists, could make a distinction. It’s essential to notice that the customized lists considerably diminished dissociation for folks—however they did not considerably have an effect on time spent utilizing the app. To me, that factors out that lowering folks’s dissociation will not be as antithetical to social media firms’ income targets as we’d intuitively suppose.\nWhat’s most essential for folks utilizing social media now to know?\nFirst, don’t pile a bunch of disgrace onto your social media habits. Hundreds of individuals are employed to make you swipe your thumb up on that display screen and maintain you doing what you’re doing. Let’s shift the duty of designing protected and fulfilling experiences from customers to the businesses.\nSecond, get conversant in the well-being instruments which are already supplied. TikTok has a function that, each hour, will inform you that you simply’ve been scrolling for some time and may contemplate a break. On Twitter, customized lists are a function that already exists; it’s simply not the default choice. If extra folks begin utilizing these instruments, it may persuade these firms to refine them.\nMost essential, vote for people who find themselves occupied with regulating expertise as a result of I feel that’s the place we’re going to see the largest adjustments made.']"	['<urn:uuid:b808191e-c284-4235-812f-0a9e9454dc55>', '<urn:uuid:28ea44cd-4054-4290-8fcb-a13be7579900>']	factoid	with-premise	concise-and-natural	similar-to-document	multi-aspect	expert	2025-05-12T23:56:45.148498	14	54	3629
53	What kind of flies are used in these genetic studies and why?	Various species of Drosophila flies are used because they are tractable in both genetic and ecological studies.	"['Research Interests: Evolutionary genetics in Drosophila\nWhat shapes genetic and phenotypic diversity in natural populations? We are broadly interested in the interaction between evolution, genetics, and ecology. The first main topic of research in the lab is how organisms adapt to their environment. We are interested in the genetic basis of ecologically important traits and how evolutionary forces such as selection and gene flow interact in the processes of adaptation and speciation. The second main topic of research is how the genetic environment affects gene evolution. For example, factors such as the pattern of inheritance, the level of recombination, and the presence of selection at nearby genes can have significant consequences for how a gene responds to selection. To address these questions we take an integrative approach, and combine molecular techniques and classical Drosophila genetics with theoretical modeling, behavioral observations, and field studies. We use various species of Drosophila because they are tractable in both genetic and ecological studies.\n- Council Member, Society for the Study of Evolution, 2014-2017\n- Council Member, European Society for Evolutionary Biology, 2013-2017\n- CAREER Award, National Science Foundation, 2012\n- Council Member, American Genetics Association, 2011-2013\n- Associate Editor, Evolution, 2010-2012\n- Lilly Teaching Fellow, 2009-2011\n- New Scholar in Aging, Ellison Medical Foundation, 2009\n- Reviewing Editor, Journal of Evolutionary Biology, 2009-2012\nCurrent Grant Support:\n- ""CAREER: Evolutionary genetics of mate discrimination in the fly Drosophila subquinaria,"" (NSF)\n- ""The impacts of the distribution of phenotypic effects and the distribution of pleiotropic costs on the genetics of natural adaptations"" (NSF, with C. Jones and P. Volkan)\nRundle, H. D. and K. A. Dyer. 2015. Reproductive character displacement of female mate preferences for male cuticular hydrocarbons in Drosophila subquinaria. Evolution, online early. doi: 10.1111/evo.12761\nConn, C. E., R. Bythell-Douglas, D. Neumann, S. Yoshida, B. Whittington, J. H. Westwood, K. Shirasu, C. S. Bond, K. A. Dyer, and D. C. Nelson. 2015. Convergent evolution enabled host detection in parasitic plants. Science 349: 540-543.\nArthur, N. J., and K. A. Dyer. 2015. Asymmetrical sexual isolation but no postmating isolation between the closely related species Drosophila suboccidentalis and D. occidentalis. BMC Evolutionary Biology 15:38.\nBewick, E. R., and K. A. Dyer. 2014. Reinforcement shapes clines in mate discrimination in Drosophila subquinaria. Evolution 68: 3082-3094.\nDyer, K. A., B. E. White, J. Sztepanacz, E. R. Bewick, and H. D. Rundle. 2014. Reproductive character displacement of epicuticular compounds and their contribution to mate choice in Drosophila subquinaria and D. recens. Evolution 68: 1163-1175.\nBray, M. J., T. Werner, and K. A. Dyer. 2014. Two genomic regions together cause dark abdominal pigmentation in Drosophila tenebrosa. Heredity 112: 454-462.\nPinzone, C. P., and K. A. Dyer. 2013. Higher polyandry is associated with lower prevalence of sex-ratio drive in natural populations of Drosophila neotestacea. Proceedings of the Royal Society, Series B 280: 20131397.\nDebban, C. L., and K. A. Dyer. 2013. No evidence for behavioral adaptations to nematode parasitism by the fly Drosophila putrida. Journal of Evolutionary Biology 8: 1646-1654.\n- Curtis, S., J. Sztepanacz, B. E. White, K. A. Dyer, H. Rundle, and P. Mayer. 2013. Epicuticular compounds of Drosophila subquinaria and D. recens: Identification, quantification, and their role in female mate choice. Journal of Chemical Ecology 39: 579-590.\n- Giglio, E.M. and K.A. Dyer. 2013. Divergence of premating behaviors in the sister species Drosophila subquinaria and D. recens. Ecology and Evolution 3: 365-374.\n- Dyer, K.A., M.J. Bray, and S.J. Lopez. 2012. Genomic conflict drives patterns of X-linked population structure in Drosophila neotestacea. Molecular Ecology 22: 157-169.\n- Dyer, K.A. 2012. Local selection underlies the geographic distribution of sex-ratio drive in Drosophila neotestacea. Evolution 66: 973-984.\n- Dyer, K.A., C. Burke, and J. Jaenike. 2011. Wolbachia-mediated persistence of mtDNA from a potentially extinct species. Molecular Ecology 20: 2805-2817.\n- Dyer, K.A., B.E. White, M.J. Bray, D.G. Piqué, and A.J. Betancourt. 2011. Molecular evolution of a Y chromosome to autosome gene duplication in Drosophila. Molecular Biology and Evolution 28: 1293-1306.\n- Jaenike, J. and K.A. Dyer. 2008. No resistance to male-killing Wolbachia after thousands of years of infection. Journal of Evolutionary Biology 21: 1570-1577.\n- Dyer, K.A., B. Charlesworth and J. Jaenike. 2007. Chromosome-wide linkage disequilibrium as a consequence of meiotic drive. Proc. Natl. Acad. Sci. USA 104: 1587-1592.\n- Jaenike, J., K.A. Dyer, C. Cornish and M.S. Minhas. 2006. Asymmetrical reinforcement and Wolbachia infection in Drosophila. PLoS Biology 4: 1852-1862.\n- Dyer, K.A. and J. Jaenike. 2005. Evolutionary dynamics of a spatially structured host-parasite association: Drosophila innubila and male-killing Wolbachia. Evolution 59: 1518-1528.\n- Dyer, K.A., M.S. Minhas and J. Jaenike. 2005. Expression and modulation of embryonic male-killing in Drosophila innubila: Opportunities for multi-level selection. Evolution 59: 838-848.\n- Shoemaker, D.D., K.A. Dyer, M. Ahrens, K. McAbee and J. Jaenike. 2004. Decreased diversity but increased substitution rate in host mtDNA as a consequence of Wolbachia endosymbiont infection. Genetics 168: 2049-2058.\n- Dyer, K.A. and J. Jaenike. 2004. Evolutionary stable infection by a male-killing endosymbiont in Drosophila innubila: Molecular evidence from the host and parasite genomes. Genetics 168: 1443-1455.\n- Guindon, S., A.G. Rodrigo, K.A. Dyer and J.P. Huelsenbeck. 2004. Modeling the site-specific variation of selection patterns along lineages. Proc. Natl. Acad. Sci. USA 101: 12957-12962.\n- Huelsenbeck, J.P. and K.A. Dyer. 2004. Bayesian estimation of positively selected sites. Journal of Molecular Evolution 58: 661-672.\n- Jaenike, J., K.A. Dyer and L.K. Reed. 2003. Within-population structure of competition and the dynamics of male-killing Wolbachia. Evolutionary Ecology Research 5: 1023-1036.\n- Ross, C.L., K.A. Dyer, T. Erez, S.J. Miller, J. Jaenike and T.A. Markow. 2003. Rapid divergence of microsatellite abundance among species of Drosophila. Molecular Biology and Evolution 20: 1143-1157.\n- Price, C.S.C., K.A. Dyer and J.A. Coyne. 1999. Sperm competition in Drosophila males involves both displacement and incapacitation. Nature 400: 449-452.\nPopulation genetics and molecular evolution; genetic basis of adaptation and speciation; intragenomic conflict and selfish genetic elements; host-parasite interactions; insect ecology and evolution']"	['<urn:uuid:a2533dc6-1922-462a-abec-af641a44a1ae>']	factoid	with-premise	concise-and-natural	similar-to-document	single-doc	novice	2025-05-12T23:56:45.148498	12	17	983
54	what documents needed prove wrongful dismissal tribunal case and how much compensation available insolvency situation	For wrongful dismissal tribunal cases, employers need extensive documentation including: employment contract, staff handbook, misconduct documentation, copies of letters to employee, warning copies, evidence notes, witness statements, and appeal documents. The tribunal will examine if proper procedures were followed, including fair investigation, hearing opportunity, and consideration of mitigating factors. In insolvency situations, compensation is available through the government's Redundancy Payments Office, with payments capped at £508 per week. This includes redundancy pay (based on age and service), up to 6 weeks holiday pay, 8 weeks of unpaid wages, and statutory notice period pay. However, these payments are only accessible when the employer enters formal insolvency proceedings.	"[""What is gross misconduct?\nGross misconduct covers a long list of offences that staff members could commit at work. This behaviour is unprofessional and unethical, falling short of regular standards in the typical workplace.\nConduct this severe destroys the relationship between employer and employee and warrants instant dismissal (also known as ‘summary dismissal’)—without notice and without pay in lieu of notice (PILON).\nWhat constitutes gross misconduct in the workplace?\nIt is hard to define gross misconduct because there are so many examples of it. However, a few gross misconduct examples are:\n- Theft or fraud.\n- Physical violence or bullying.\n- Damage to property.\n- Serious misuse of an organisation's name or property.\n- Deliberately accessing internet sites that contain pornographic or other offensive material.\n- Setup of a competing business.\n- Misuse of confidential information.\n- Serious insubordination.\n- Discrimination or harassment.\n- Bringing the organisation into serious disrepute.\n- Offering or accepting bribes.\n- A serious breach of health & safety regulations.\n- A serious breach of confidence.\n- Causing loss, damage, or injury through serious negligence.\n- Serious incapability at work due to alcohol or illegal drug use.\nThis list is not exhaustive.\nYou should make sure that your business identifies what you deem to be gross misconduct in advance of any hearings. Great places to do this are the contract of employment and the staff handbook.\nIf you want to be on top of the game, also list the offences that the business would sanction with summary dismissal. You could also make clear that the list, like ours, is not exhaustive.\nMake sure that you also have a written procedure, which all staff can access, for handling allegations.\nThe difference between misconduct and gross misconduct\nMinor misconduct examples include frequent lateness, failure to finish work tasks on time, failure to follow instructions, and poor execution of tasks. This list is also not exhaustive.\nAs you can see, the difference between the two types of misconduct is substantial. Furthermore, if the employee’s behaviour was deliberate or amounted to gross negligence, it should be considered gross misconduct.\nIf a hearing finds the staff member guilty, you can dismiss them with immediate effect.\nHow should I manage an allegation of gross misconduct at work?\nAfter an allegation, the first thing you should do is choose whether to suspend the employee (on full pay). Good reasons to do so are if they could pose a risk to your business, if they could be a risk to themselves or others (for example, if they are very drunk and their job requires them to operate machinery), or if the person could influence any witnesses by staying in work.\nIf you choose to let them stay at work, go through a risk assessment with them.\nYou should make it clear to all that a suspension is not a sanction.\nYour next step should be to find facts. Collect and store evidence (this can be done via our HR software) and ask witnesses for details of what happened.\nIf you find something that supports the allegation, it is time to invite the employee to a disciplinary hearing. Do this in writing. In the letter, you must give details of the offending behaviour. You should mention that they have the right to a colleague or trade union representative accompanying them.\nAll hearings should include a chairperson and a person to take notes—both of whom should be impartial. By having somebody to take notes, you will be adding to your records of the process.\nAt the hearing, you must give access to the evidence you are relying on in the interest of being transparent.\nAfter the hearing, what should I do next?\nAdjourn the hearing before you decide on the outcome. It is important that you think about the mitigating factors. For example, if the employee is a long-serving member of staff whose record has been clean up to this point.\nYou must then inform your employee, in writing, of the hearing’s outcome. You should set out:\n- The nature of the gross misconduct.\n- Any given time for them to improve and what improvement you expect.\n- The disciplinary penalty and, if needed, the length of the penalty.\n- The consequences of further misconduct or poor performance.\n- The timescale for them to lodge an appeal and how they should make it.\n- Your reasons for the action taken.\n- The decision was one that a reasonable employer would make.\n- It was a fair and reasonable decision given the circumstances of the matter.\n- The offence warranted immediate dismissal.\nHow an employment tribunal will treat an unfair dismissal claim after gross misconduct\nIf the employee makes a claim against you following an upheld appeal, an employment tribunal will investigate the conduct of your company to determine whether your decision was reasonable and fair based on your findings.\nWith the abolition of tribunal fees, it is now easier than it has been in years for people to take their employer to a tribunal if they think they have a claim.\nEven if you have acted in a fair and reasonable manner in investigating the allegations of gross misconduct, you might find that the person you dismissed makes an ‘unfair dismissal’ claim against you.\nThere are many factors that a tribunal would consider when deciding whether the penalty of dismissal was fair. These include:\n- Did you have a true belief in their guilt?\n- Was it reasonable to hold this belief after this investigation?\n- Did you give them a chance to state their case?\n- Did you give them all information that you had gathered?\n- Did you warn them that they were to attend a disciplinary hearing?\n- Did you give them time to prepare for it?\n- Did an impartial individual chair the hearing?\n- Was the offence gross misconduct as set out in your policies, staff handbook, and contract of employment and did the employee have access to these documents?\n- Did you consider other options than dismissal?\n- Did you consider mitigating factors, such as ignorance, health problems, provocation, etc?\n- Have you been consistent in invoking this penalty in similar cases?\n- Did you inform the employee of their right to appeal and their deadline to do so?\n- Did you follow the policy set out in your staff handbook?\nThe tribunal will look at whether you missed any steps in your process that you should have taken.\nKeep records of everything to be prepared for a tribunal if one occurs. Evidence includes:\n- Contract of employment and any variations.\n- Staff handbook.\n- Documents and recordings relating to the misconduct.\n- Copies of letters to the employee.\n- Copies of warnings.\n- Notes on any evidence.\n- Witness statements from the investigation.\n- Any appeal documents.\nPeople who saw what happened, the investigator, the person who chaired the disciplinary hearing, and the person who chaired the appeal hearing, should be your witnesses in the event of a tribunal.\nThe Acas code for reasonable behaviour\nAcas has a Code of Practice that offers guidance for you and your staff. The code sets out the basic requirements of fairness and gives a minimum standard of reasonable behaviour. You can incorporate this code into your company’s policies. The code also applies to issues of grievance."", 'What rights do workers have once they have been made redundant by an employer that has gone into administration or liquidation? Coodes Solicitors Employment Lawyer Philip Sayers comments, in light of the latest news from troubled café chain Patisserie Valerie.\nIn the latest in a stream of headlines about Patisserie Valerie, it has now been revealed that the company has failed to pay hundreds of its redundant workers.\nIf a company becomes insolvent, some or all of its employees may be made redundant. This is what has happened in the case of Patisserie Valerie. When an employee is made redundant, he or she will retain certain rights and entitlements, even if the employer is unable to pay them.\nEmployees who have been made redundant due to insolvency have the right to know how their job is affected and what they should do next. An insolvency practitioner will step in to handle a number of employment procedures. Their role includes providing each employee with a RP1 form and a case reference number to use when applying for any money owed. Depending on the situation, an employee can apply to the government’s Redundancy Payments Office for a number of outstanding monetary arrears due from their employer.\nWithin six months of being made redundant, an employee can apply to the government for the following:\nEmployees should have been continuously employed by the insolvent business for a minimum of two years to claim redundancy payment, which is capped at £508 a week. An employee under the age of 22 can be eligible for half a week’s pay for each year they completed at that age. This rises to one week’s pay for each year for employees aged between 22 and 40 and one and half week’s pay for each year if the employee is 41 or older, to a maximum of 20 years.\nAfter being made redundant, an employee can get paid for holiday owed. This includes any holiday days which they were not paid for in the 12 months before the insolvency for up to six weeks of holiday days. This is capped at £508 a week.\nAn employee who has been made redundant may also be able to claim for outstanding payments, such as unpaid wages, overtime and commission. This is also capped at £508 a week and an employee can receive up to eight weeks’ worth of outstanding payments.\nAn employee is entitled to a paid statutory notice period, capped at £508 a week, even if it is not in their contract. An employee will be paid one week’s notice for every year they were employed, up to a maximum of 12 weeks.\nMore information, and details on how to apply, can be found on the government’s website.\nThese rights and compensation are only available when the employer enters into a formal insolvency event, which can include administration, liquidation or Company Voluntary Arrangements (CVA).\nOne problem I have encountered when advising clients is when an employer runs out of money and ceases trading but fails to enter into a formal insolvency event. In that situation for all sums except a redundancy payment, an employee will have to bring about a tribunal claim and get a judgment against the employer before the Redundancy Payments Office will pay out.']"	['<urn:uuid:06b714d2-d6d0-410a-977f-9f4d0845830a>', '<urn:uuid:c624ca46-ce89-4a2b-89a2-db16c4ac312c>']	open-ended	with-premise	long-search-query	similar-to-document	multi-aspect	novice	2025-05-12T23:56:45.148498	15	106	1770
55	I'm doing research on historical food packaging - I heard Venice was innovative in this area, but what exactly did they do with spices that was so special?	Venice invented an early form of packaging called 'Venetian bags' - these were pre-packaged mixed spices that were ready for use. This was truly innovative for its time, as they were the first to offer spices in such a convenient, pre-packaged form.	['Built on land, isolated from the waters of the lagoon, without being able to cultivate wheat and wheat, nor “anything at all to the human lives”, Venice has nevertheless held a primary position in the art of gastronomy for centuries.\nBy virtue of necessity, the Venetians quickly become skilled merchants, to obtain those primary goods that were not there in the Lagoon, but what was originally meant to be a simple source of subsistence soon turns into a source of income, as they begin to import from distant markets not only wheat and wheat but also spices, sugar and other culinary goods unknown in Europe.\nIn advance of several centuries Venice soon senses the potentiality of these goods and literally invents marketing, realizing that in order to be able to sell a product well, it is necessary to create demand and not to wait for it to form itself. This is why Venice itself “invents” the luxury of spices. But not only that, always ahead of the times, he also invented the packaging, putting on the market the famous “Venetian bags”, that is mixed spices already packaged and ready for use!\nA direct heir to the Byzantine and Roman tradition, lagoon gastronomy is one of the first to confront other cuisines in the world: from Muslim to Austro-Hungarian cuisine, passing through Spanish and French cuisine. These are encounters that arise from the coexistence with the Islamic populations on the markets of the Levant and from the confrontation with the foreign minorities present in the city since the earliest times.\nBetween the fourteenth and sixteenth century new and significant new products add to this basic richness: from the icy waters of the northern seas comes the codfish, alias stockfish, an authentic culinary revolution, in an era when there is no refrigerator.\nIn an already privileged situation, the Renaissance invests Venice with all its innovative energy, and how could it be different in a city that can use all the weapons of seduction, including that of food, refined and luxurious, sending messages of political power to foreign guests gifts by tramortandoli with rivers of spices, sugar and gold leaves on oysters?\nBut the real greatness of Venice was to know how to get out of the kitchens and to get to the libraries, which then means going out of the ephemeral dimensions to stay in the centuries. A unique case in the whole peninsula, here is developed a great gastronomic publishing with the publication of recipes, translations of dietary books from Arabic and Greek, agricultural treatises and travel reports that inform about the discovery of new products.\nThe end of the sixteenth century brought to a close the age of dishes buried by a mountain of spices, and the wind of new modern tastes brought by the French came to Venice. The consumption of luxury takes other roads, and for Venetian merchants it no longer makes sense to fill the holds of ships with those spices that have made their fortune. But the patricians certainly do not lose heart and recycle themselves by taking the mainland road, with major land reclamation, agricultural investments, and the cultivation of those first fruits that revolutionize the Veneto region in the form we still see today.\nBetween inns and finger food, enlightened chocolates and French chefs, we reach the eighteenth century. The Republic is extinguished but not the gastronomy, which is tempered by the Central European tastes imported from Austrians. The first bourgeois recipes of the 19th century are printed and the cuisine is internationalised.\nIn the twentieth century, linked with a concrete and iron bridge to the mainland, Venice lost its insularity. The tourist replaces the traveller, the bacari are transformed into bars all the same, the cicchetto all too often leaves room for pizzas and frozen sandwiches.\nThe invasion of globalized taste does not however cancel the good Venetian cuisine, which remains perched in a few rooms and in the intimate dimension of the house.']	['<urn:uuid:6da0eca0-f5c8-4da2-a01d-2a5826349331>']	factoid	with-premise	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-12T23:56:45.148498	28	42	661
56	What are the audio reminder message capabilities built into the PERS-3600B system for helping subscribers with their daily activities?	The PERS-3600B Console can record and play up to approximately eight 15-second audio reminder messages. These messages can be programmed to play daily, every other day, weekly, or monthly using the RA-2400 software. When played, the messages repeat in three-minute intervals for either 15 or 30 minutes until canceled. Messages can also be programmed for single-play. These reminders can help subscribers remember to take medications, call someone, or get ready for appointments.	"['PERS-3600B: Personal Emergency Reporting System\nThe Model PERS-3600B Personal Emergency Reporting System is a supervised wireless emergency reporting product designed for medical alert applications. The table-top Console provides pushbutton emergency assistance to anyone who desires additional security and peace of mind. For the visually impaired, each button on the Console is molded with braille characters to identify the button\'s function.\nThe Console can receive signals from up to 16 Linear wireless transmitters. Activating a transmitter causes the Console\'s digital communicator to send the appropriate alarm report to the central monitoring station via the standard telephone network. In addition to the central station report, audible and visual indications occur and the alarm relay energizes during an emergency activation.\nThe emergency alarm can be triggered by the large HELP button on the top of the Console or with a wireless transmitter. The fire alarm can be triggered by wireless Model DXS-73 smoke alarms. The carbon monoxide alarm can be triggered by wireless Model DXS-80 carbon monoxide detectors.\nThe optional activity timer can be set for 8, 12 or 24 hour operation or disabled. The emergency alarm will trigger automatically if the time set elapses before an activity transmitter is triggered or the Console\'s HOME button is pressed.\nTo simplify operation, the Console can ""speak"" to the subscriber with its built-in digitally synthesized voice. The Console will say ""emergency"", ""fire"", ""timer done soon"", and other system operation, setup, and supervisory prompts from a 49 word vocabulary. If necessary, the voice option can be disabled.\nThe Console can perform 2-way voice activated (duplex), 2-way manual, and 1-way listen-only audio communications through the Console\'s built-in high-sensitivity microphone and speaker. Communications with central station monitoring personnel starts after an alarm. Two-way communications can also be started without any subscriber action. An authorized individual may call the Console twice from any touchtone telephone and activate two-way voice communications by keying in a four-digit password after placing the second call.\nAs a special feature, the PERS-3600B Console can record and play up to approximately eight 15-second audio reminder messages. The reminder messages can be used to help the subscriber remember to take medications, call someone, get ready for an appointment, etc. Each message is controlled by a real time clock and can be programmed via the RA-2400 software to play daily, every other day, weekly, or monthly. Reminder messages are played and repeated in three-minute intervals for either 15 or 30 minutes (programmable) until canceled. Messages can also be programmed for single-play.\nThe Console can be programmed to act as a remote controlled ""speakerphone"". With the speakerphone mode enabled, the Console will monitor the telephone line for an incoming call. Activating any emergency transmitter (or the Console\'s HELP button) while the telephone is ringing will cause the Console to seize the line and begin speakerphone communications. Activating any emergency transmitter (or HELP button) during the call will disconnect the line. The Console will auto-disconnect after 15, 30, or 60 minutes (programmable).\nSupervised transmitters regularly send status reports to the Console and low battery reports when their batteries are low. When the Console receives a low battery report, the STATUS indicator blinks. If the Console fails to receive a status report from a transmitter for a period of 24-hours, the STATUS indicator will light. All supervisory conditions can sound a local annunciation and be reported to the central station (optional through programming).\nThe Console\'s digital communicator can route calls to three telephone numbers: primary, secondary, and supervisory. General reporting codes and individual sensor reporting codes are programmable for the 4x2 format. Alternately, Ademco Contact ID format can be selected. The telephone line is constantly monitored, line failure and restoral will be locally announced by the Console (optional through programming).\nPowered by a low voltage plug-in transformer, the Console has provisions for a rechargeable backup battery for operation during AC power outages. A power switch allows for out-of-service storage of the Console without discharge of the battery. The battery is recharged by the Console, even if the POWER switch is off (as long as the transformer is plugged in). If the backup battery becomes low, the POWER light will flash and the condition can be reported to the central station.\nInstallation and programming are made easy by Linear\'s RA-2400 remote access software.\n- Two-way voice capability\n- Suitable for temporary or permanent installations\n- Braille characters for help, home, and cancel buttons\n- Unique call-in communications feature\n- Speakerphone capability\n- Reminder message capability\n- Delayed, silent alarm feature\n- Selectable inactivity reporting: 8, 12, or 24 hours\n- Selectable two-way voice activation\n- Single telephone seizure and true phone line seizure capability\n- Distinct alarm tones provided for emergency and fire alarm conditions\n- Power on/off switch\n- Capacity for up to 16 DX/DXS transmitters\n- Point ID communicator reporting\n- Programmable with Windows-based RA-2400 Software\n- Installs in minutes\n- UL listed per standard 1637\n- DX and DXS format\n- Operating Frequency: 315 MHz\n- Backup battery size: 12 volts, 1.2 Amp/hour (30 hour backup)\n- 9"" W x 5"" H x 5-1/2"" D\n|What\'s in the box||(1) Linear Personal Emergency Reporting System|']"	['<urn:uuid:c3b48a1e-0e34-4e5f-add0-feaeda423eff>']	factoid	direct	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-12T23:56:45.148498	19	72	856
57	I'm working with thick epoxy layers for a countertop project, and I'm concerned about potential issues. What problems could arise if I pour the epoxy too thick in one go?	Pouring epoxy too thick can lead to several problems: it's likely to crack, bubbles become more difficult to remove, the curing time becomes longer, and the epoxy tends to yellow over time due to UV light reflection and absorption.	['Epoxy is a resin that can be used to coat and seal any surface. It’s ideal for repairing or creating a new floor, but it also has many other uses around the home.\nLet’s say you have a concrete garage floor that needs some work. You could pour more concrete over the old one and use epoxy to make sure it stays level, or you could pour liquid roofing cement (also known as “liquid rubber”) on top of your existing garage floor and then apply an epoxy coating afterward.\nEither way, adding another layer of material between your garage floor and the ground below will help keep moisture out, preventing mold from growing inside your home or vehicle\nCan you put a second coat of epoxy?\nYou can apply a second coat of epoxy at any time after the first has dried. For example, if you applied your first coat today and it’s now tomorrow, then you can apply your second coat to the same surface tomorrow.\nIf you applied your first coat on Monday and it’s now Tuesday, then you should wait until Wednesday before adding more epoxy. If you want to do this sooner than that, just make sure that both coats are completely dry (i.e., not sticky) before putting them together.\nIf at any point in this process something goes wrong — for example, if one of the coats dries too quickly or if it gets dirty from dust particles — there’s no need to despair: simply clean off whatever didn’t get covered properly with solvent (or runny water) and try again!\nCan you pour epoxy resin over?\nIt is possible to pour epoxy over epoxy, but it’s not the easiest thing in the world. You may need to sand or scuff the first layer of epoxy before you pour your second layer. You may also need an extra layer of adhesion promoter between your two layers of epoxy resin.\nIf you’re going to be pouring one layer over another, make sure that both layers are completely cured before you start working with them again.\nIf either one is still tacky when you try to lay down another coat, this can cause problems with adhesion and penetration into both layers at once.\nWhen can I apply second coat of epoxy?\nThe answer to this question depends on several factors. First, you need to make sure that the first coat has cured completely, or else the resin won’t adhere to it. Generally speaking, epoxy takes about 24 hours for full curing and adhesion; however, materials or conditions like high humidity can slow down the process.\nYou also have to consider what type of epoxy you’re using—some types are more flexible than others and thus may be more prone to peeling off later if not applied at just the right time. For instance:\n- A polyester-based resin will cure faster than a polyester-resin blend because polyester is a more reactive material; therefore, they require less time between coats (generally 12 hours).\n- Epoxy resins that use polyester as their main ingredient tend to be harder than those made from vinyl ester or urethane resins because they form crosslinks between molecules instead of being held together by chains alone (polymers).\nWhy is my epoxy bumpy?\nWhen you’re working with epoxy resin, it’s important to make sure that the ingredients are mixed thoroughly and in the right proportions.\nIf your epoxy is lumpy or bumpy, it may be because the mixture was not thoroughly blended before pouring it into the mold.\nThe correct ratio of hardener to resin is 3:1 (3 parts hardener for every 1 part resin) by volume. This ensures that both materials have time to react before being applied over your surface.\nTo avoid getting lumps or bubbles in your finished product, use a drill mixer on low speed until all ingredients have fully blended together into an even color throughout—this should take about 10 minutes of mixing at slow speeds (or until a couple of drops of mixed material floats freely).\nWhen finished mixing, pour directly from your container onto the surface you wish to coat (ensure good ventilation if this is indoors), making sure not to disturb any unmixed areas near where you’re pouring—this will lead to unevenness in color when cured!\nHow long should you wait between resin layers?\nYou should wait for the epoxy to cure before pouring another layer. Let the first layer set up completely, and then let the second layer do its thing while you’re sleeping or in class.\nIf you want to be extra cautious, I recommend using a timer so that you don’t accidentally pour too soon. This way, if your epoxy has not reached full cure by the time your timer goes off, then it’s still safe to pour over top of it (but not yet dry).\nThe general rule for curing epoxies is about 12 hours per inch of thickness—so for example, two inches of cured epoxy will take 24 hours before it’s ready for another layer.\nHowever! There are many variables here including temperature, humidity, and thicknesses; these all influence how long an epoxy takes to reach full cure and therefore whether or not it can safely be poured over the top of itself at some point within that timeframe.\nWhat happens if you pour epoxy too thick?\nIf you pour epoxy too thick, it’s likely to crack. This can happen if the epoxy is too viscous (thick). The increased viscosity causes bubbles to be more difficult to remove, which causes the curing time to be lengthened.\nThick epoxy also increases the likelihood that air bubbles will be trapped when pouring. And last but not least—thicker epoxy tends to yellow over time because UV light is reflected by its surface and absorbed into its bulk.\nCan you sand epoxy and recoat?\nYou can sand and recoat epoxy only if the previous layer is cured. If it is not, you will have to sand off the entire surface and start over.\nIt’s best to do this process in a well-ventilated area with gloves on your hands so that you don’t get your skin irritated from all of the dust particles flying around from sanding away at everything.\nYou can use a random orbit sander or electric hand sander, but I prefer using my hand because it doesn’t cause as much vibration in my wrist as using an electric tool does (and I also find it easier).\nJust make sure that you’re wearing long sleeves so that none of those fine particles get in your eyes! Sandpaper for different purposes varies depending on how dull or shiny you want them—you might even want two different kinds so that one can be used for heavy-duty cleaning while another could be used lightly just for small details like corners or sides where there isn’t much pressure needed).\nHow do you stop air bubbles in epoxy?\nThere are a few ways to keep air bubbles out of the epoxy resin. The first is to pour it slowly, thus limiting the amount of air that’s mixed in with your mixture.\nThe second is to use heat when you pour the resin into its mold so that any remaining air bubbles rise up and get trapped beneath your surface layer of hardened epoxy. This may not work if there are too many small bubbles present, but it can be helpful if there are only a few larger ones present.\nThe third option is using a vacuum chamber for the removal of all bubbles during curing time (this requires specialized equipment).\nThe fourth option is using a spray bottle filled with soapy water and spraying this onto surfaces as they begin curing—this helps dissolve some trapped pockets within the epoxy matrix before they have time to harden completely and become difficult or impossible for later removal.\nYou can pour epoxy over epoxy if the first coat of epoxy has cured properly. If you’re working with a DIY epoxy product, make sure to follow the manufacturer’s instructions carefully and wait until your first coat has fully hardened before applying additional coats.\nIf you’re working with an industrial-grade product, such as one from Structural Innovations or Superior Coating Technologies, then make sure to contact them for advice regarding how best to proceed.\nYou should allow your second coat of epoxy at least 24 hours before proceeding with any further work (such as sanding).\nThis will give it ample time to cure and ensure that there won’t be any problems down the road when you apply another coat or begin construction on top of this area.']	['<urn:uuid:7d35a3e9-ecc1-438b-8f53-15a308ab6e78>']	factoid	with-premise	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-12T23:56:45.148498	30	39	1439
58	Which requires a more stable environment during storage: aging wine bottles or ski equipment, especially regarding temperature fluctuations?	Wine bottles require a more stable environment during storage. While ski equipment needs to be stored in a warm, dry area (above 10 degrees Celsius for boots), the specific stability of temperature is not critical. In contrast, for wine storage, temperature stability is crucial - it's better to have a constant 65°F than fluctuating temperatures between 40° and 80°, as temperature changes can damage the wine.	['As the days get warmer and the snow sadly starts to melt, it’s time to think about storing your ski equipment. Unless you’re going to New Zealand or another summertime ski destination, you probably won’t use your gear for at least six months. If you don’t want your ski edges to rust or your ski coat to smell, you’ll need to store them properly. Our guide will walk you through the basic storage techniques for each key item of equipment.\nWashing a Ski Jacket & Trousers\n- Program your washing machine to a synthetic 30 degrees cycle and add detergent\n- Add two white tennis balls to stop your down jacket from clumping\n- Complete a second rinse cycle to make sure there isn’t any remaining washing detergent\nHow to Dry a Ski Jacket & Trousers\nDrying your ski suit properly prevents it from smelling when stored over summer. The easiest way to make sure your coat and trousers are dry is by using a tumble dryer. However, you can still get a dry coat by hanging or laying your coat out -- it’ll just take much longer.\nDrying a Ski Jacket with a Tumble Dryer\n- Program your dryer to a soft or delicate cycle\n- Add two tennis balls to air a down feather jacket\n- Run several cycles to make sure your coat is thoroughly dry\n- Between cycles, fluff the jacket to prevent lumps\nDrying a Ski Jacket without a Tumble Dryer\n- Lay your ski coat and trousers flat down in a dry place\n- Wait for one to two weeks\n- As you wait, occasionally fluff the jacket to avoid lumps (you should do this at least four to five times)\n- Do NOT store till the coat is 100% dry\nHow to Wax Skis for Storage\nAt the end of the season, after you’ve finished your final run, you’ll need to bring your skis into the shop so they can be waxed and restored. If you know how to wax skis, you can also do this at home. Unlike regular waxing, we recommend leaving a layer of wax on the bottom of your skis to protect and nourish the bases during the summer months. Ski maintenance is an important part of ski ownership.\nHome Ski Storage\nOnce your skis are waxed and restored, the best place to store them is in a warm, dry and dark indoor area to prevent rust. Leaving them in direct sunlight, like on your balcony or patio, can dry out the wax on the bottom of your skis and cause your equipment to crack.\nIt’s also a good idea to hang your skis side-by-side vertically with the bottoms facing each other and in a protective cover. Try to avoid the temptation to hook them together, but rather leave a small space, so the bases aren’t directly touching.\nPreparing Ski Bindings for Summer Storage\nAt the end of the season, you should pull up and loosen your ski bindings as this will help to preserve their spring. To relax the spring, you’ll need to use a flat-head screwdriver to unscrew the screw at the front and back of the bindings. This will take the pressure off the spring. However, make sure to note down your adjustment so you can reset the binding once the summer is over.\nYou can also bring your skis to your closest ski shop and they can adjust your bindings to prepare them for summer storage and keep you safe on the slopes.\nSki Boot Storage Systems\nStoring your ski boots properly guarantees that they’re still comfortable next season and don’t smell bad.\nBefore putting them away for the summer, make sure you follow these steps:\n- Thoroughly air your boots by removing the liner from the plastic outer shell\n- Examine the heel and toe units. If you notice any damage (like a split) or if they appear worn, you may need to have them replaced\n- Buckle the buckles on the first notch to help them keep their shape\n- Store your boots in a boot bag in an indoor dry and warm area. Ideal storage temperature is above 10 degrees Celsius as this will keep the plastic from cracking.\nNow that you’re equipment is safely put away, sit back and count down the days till the mountain opens again!', 'Many people think that if they’re going to store wine at home then they need a cellar. But the word “cellar” conjures up images of dark, cavernous chambers cut out of bedrock, or slick, temperature and humidity-controlled rooms lined with mahogany wine racks. All very nice, but not at all necessary. We recommend you interpret “cellar” somewhat loosely.\nThere are four main things to consider when storing wine: temperature, light, vibration and keeping the cork wet.\nTemperature: Both red and white wine likes to be kept cool. 55°F is ideal, but more important than this magic number is that the temperature doesn’t fluctuate. Better a constant 65°F than 40° one day and 80° the next.\nLight: Bright light and sunlight can damage wine as it ages in bottle, so the darker the room, the better. Total darkness is easily achieved by simply closing the lid of the case or the closet door.\nVibration: Areas subject to heavy foot traffic (or vacuum cleaners) should be avoided as wine, unlike martinis, should be neither shaken nor stirred.\nKeep the cork wet: Laying your bottles down on their sides keeps the wine in contact with the cork, which in turn prevents the cork from drying out. Dry corks contract, allowing air to pass into the wine and wine to leak out. If air gets in, it renders the wine dull and lifeless and it will taste more like old sherry than wine.\nIf you keep these basic requirements in mind, you’ll find it remarkably easy to find a place to store your wine, and you won’t need a cellar at all. A corner of the basement, a closet in a spare bedroom, your shipping box or the cupboard under the stairs will all do nicely. And remember, the longer you plan to store your wine, the more important these factors become. If a newly-purchased wine is to be drunk in a day or two, it really doesn’t matter too much where you keep it, but if the wine is to be kept for weeks or months then find it a nice cool, dark spot.\nNow, some wines require not months but many years, even decades, of bottle aging before they’re ready to drink. This is a small percentage of all the wines made, but nonetheless, it is an important one. Where you store these high quality (and often expensive) wines designed for long aging takes on a special importance if your investment is to be protected. In this case you may want to consider one of the commercially available wine storage units, which come in a variety of sizes and finishes. Another alternative is off-site storage, where you rent a locker in a temperature and humidity-controlled wine storage facility. This option is great for wines that you don’t plan to drink for some years and has the added advantage of being out of reach; a real bonus during those weak moments.\nAs your collection of wine grows you’ll need to keep track of it. An old-fashioned cellar book where you record each new wine that goes into your cellar and cross them off as you take them out, works just fine. These days, however, there are also numerous cellar software programs that make it easy and fun to manage your wine collection.']	['<urn:uuid:438c2cfa-6242-4676-a60d-0d0cf6e634cb>', '<urn:uuid:894311c3-40f9-481e-9b9e-3a9ed34c8672>']	factoid	direct	verbose-and-natural	distant-from-document	comparison	expert	2025-05-12T23:56:45.148498	18	66	1276
59	mmorpg social benefits risks addiction	MMORPGs have both positive and negative social effects. On the positive side, collective gameplay in MMORPGs can enhance online social capital, broaden social networks in the virtual world, and encourage offline civic engagement through improved civic skills and self-efficacy. However, these games also pose addiction risks, with some players developing Internet Addiction Disorder symptoms including mood swings, social isolation, neglect of work/relationships, and the need for increasing playtime to achieve satisfaction. The variable reinforcement effects of MMORPGs make them particularly addictive since they never end and provide unpredictable rewards.	['CityU Institutional Repository >\n3_CityU Electronic Theses and Dissertations >\nETD - Dept. of Media and Communication >\nCOM – Doctor of Philosophy >\nPlease use this identifier to cite or link to this item:\n|Title: ||The effects of MMORPG play on online and offline social capital|\n|Other Titles: ||Duo ren xian shang jiao se ban yan you xi dui xu ni he zhen shi she hui zi ben de ying xiang|\n|Authors: ||Zhong, Zhijin (鐘智錦)|\n|Department: ||Department of Media and Communication|\n|Degree: ||Doctor of Philosophy|\n|Issue Date: ||2009|\n|Publisher: ||City University of Hong Kong|\n|Subjects: ||Social capital (Sociology)|\nOnline social networks.\nInternet games -- Social aspects.\nRole playing -- Social aspects.\n|Notes: ||CityU Call Number: HM708 .Z45 2009|\nix, 166 leaves 30 cm.\nThesis (Ph.D.)--City University of Hong Kong, 2009.\nIncludes bibliographical references (leaves 110-125)\n|Abstract: ||This dissertation examines the impact of massively multiplayer online role-playing\ngame (MMORPG) play on social capital in both the virtual world and the real world.\nMMORPG play is conceptualized as a combination of general-play (represented by the\ntime and frequency of game play) and collective-play (represented by the frequency of\njoint gaming actions and gamers’ assessment of the experiences in guilds and groups).\nSocial capital is conceptualized to exist at both individual level and collective level.\nIndividual-level social capital refers to the resource and support provided by bonding\nand bridging social networks; collective-level social capital refers to people’s civic\nengagement. Since online social capital is based on computer-mediated communication,\noffline social capital is based on face-to-face communication; this study examines the\neffects of MMORPG play on online social capital and offline social capital respectively,\nand explores the relationship between online social capital and offline social capital.\nA two-wave online survey was conducted to collect data from 232 MMORPG\nplayers. Structural equation modeling was employed to test the hypothesized effects of\ncollective MMORPG play on gamers’ online/offline social capital and the effects of\nonline social capital on offline social capital.\nThe results show that collective-play positively affects gamers’ online bonding\nsocial capital, online bridging social capital and online civic engagement, which\nsuggests that group-play and guild-play in MMORPGs can broaden gamers’ social\nnetworks in the virtual world and enhance gamers to engage in online civic activities.\nThe effect of collective-play on offline bonding and bridging social capital is not\nsignificant; the effect of online bonding/bridging social capital on offline\nbonding/bridging social capital is not significant either. These non-significant results imply that whether people extend their online relationships into real lives depends on\nmany social conditions as well as on the social skills of the individuals. The study finds\na significantly positive impact of collective-play on offline civic engagement, which\nmay attribute to the reason that collaboration and community participation in\nMMORPGs can improve gamers’ civic skills, build their self-efficacy in public affairs\nand therefore encourage them to engage in offline civic activities. The effect of online\ncivic engagement on offline civic engagement is found to be non-significant, inferring\nthat due to the convenience and low cost of online civic participation, those who are\nactive in online communities do not necessarily perform actively in offline\nIn comparison with collective-play, general-play is found to negatively affect\nindividual-level social capital and collective-level social capital in both the virtual world\nand the real world. This finding justifies the importance to differentiate collective-play\nfrom general-play because it is collective-play that contributes to gamers’ social capital.|\n|Online Catalog Link: ||http://lib.cityu.edu.hk/record=b2375082|\n|Appears in Collections:||COM – Doctor of Philosophy |\nItems in CityU IR are protected by copyright, with all rights reserved, unless otherwise indicated.', 'What Is Internet Addiction?\nDo you play video games on the Internet in excess? Are you compulsively shopping online? Can’t physically stop checking Facebook? Is your excessive computer use interfering with your daily life – relationships, work, school? If you answered yes to any of these questions, you may be suffering from Internet Addition Disorder, also commonly referred to as Compulsive Internet Use (CIU), Problematic Internet Use (PIU), or iDisorder. Originally debated as a “real thing,” it was satirically theorized as a disorder in 1995 by Dr. Ivan Goldberg, M.D. who compared its original model to pathological gambling. Since this hoax of sorts, the disorder has rapidly gained ground and has been given serious attention from many researchers, mental health counselors, and doctors as a truly debilitating disorder. Though not officially recognized as a disorder in the Diagnostic and Statistical Manual of Mental Disorders (DSM-IV), its prevalence in American and European cultures is staggering – affecting up to 8.2% of the general population. However, some reports suggest it affects up to 38% of the general population. The widely variable difference in prevalence rates might be contributed to the fact that no true and standardized criteria has been selected for Internet Addiction Disorder. It is researched differently among scientists and mental health professionals. And, it is researched differently across ethnic cultures.\nThe advancement in study of Internet Addiction Disorder has been negatively impacted by the lack of standardization in this area. It has been generally accepted among researchers, however, that Internet Addiction is only a subset of technology addiction in general. As the name states, its concentration is on compulsion with the Internet – as other areas of media addiction can be seen in television addiction, radio addiction, and other types of media addiction. Due to the explosion of the digital age, Internet Addiction Disorder has taken the reigns as the top culprit is technology addiction as of late. The troubling thing about this disorder is that if you are suffering from it, you are endlessly surrounded by technology. In the digital age, the Internet has taken over. Most of what we do, as a general population, can be done on the Internet. Can’t find that shirt you want in the store? No worries – the Internet has it! Need to place an order for pizza? Why call? Complete an online order! Can’t call over a friend to play a video game at 3am when you’re suffering from insomnia and can’t go back to sleep? I bet there’s someone across the globe that is awake and ready to play! That’s, in essence, why this disorder can be so troubling – even treatment-wise. It’s hard to live these days by getting rid of the Internet. We’re always surrounded by it – and for most of us, we use it daily.\nJust because you use the Internet a lot – watch a lot of YouTube videos, shop online frequently, or like to check social media does not mean you suffer from Internet Addiction Disorder. The trouble comes when these activities start to interfere with your daily life. In general, Internet Addiction Disorder is subdivided into varying categories. The most commonly identified categories of Internet Addiction include gaming, social networking, email, blogging, online shopping, and inappropriate Internet pornography use. Other researchers suggest that it is not the amount of time spent on the Internet that is particularly troublesome – rather, it is how the Internet is being used. That is, the riskiness of Internet use can be just as important as the amount of time spent. Do you have a teenager using teen dating sites that could have child molesters lurking on the site? This is risky – and one of the multidimensional aspects of Internet Addiction Disorder. Other identified multi-dimensional risk factors of Internet Addiction Disorder include physical impairments, social and functional impairments, emotional impairments, impulsive Internet use, and dependence on the Internet.\nWhat Causes It?\nLike most disorders, it’s not likely to pinpoint an exact cause of Internet Addiction Disorder. This disorder is characteristic of having multiple contributing factors. Some evidence suggests that if you are suffering from Internet Addiction Disorder, your brain makeup is similar to those that suffer from a chemical dependency, such as drugs or alcohol. Interestingly, some studies link Internet Addiction Disorder to physically changing the brain structure – specifically affecting the amount of gray and white matter in regions of the prefrontal brain. This area of the brain is associated with remembering details, attention, planning, and prioritizing tasks. It is suggested one of the causes of Internet Addiction Disorder is structural changes to the prefrontal region of the brain are detrimental to your capability to prioritize tasks in your life, rendering you unable to prioritize your life, i.e., the Internet takes precedence to necessary life tasks.\nInternet Addiction Disorder, in addition to other dependency disorders, seem to affect the pleasure center of the brain. The addictive behavior triggers a release of dopamine to promote the pleasurable experience activating the release of this chemical. Over time, more and more of the activity is needed to induce the same pleasurable response, creating a dependency. That is, if you find online gaming or online shopping a pleasurable activity and you suffer from an addiction to the Internet, you will need to engage in more and more of the behavior to institute the same pleasurable feeling prior to your dependency.\nThe variable reinforcement effects of Internet addiction is another cause of this behavior. According to the Variable Ratio Reinforcement Schedule (VRRS) theory, the reason why you might be so addicted to Internet activity (e.g., gaming, gambling, shopping, pornography, etc.), is because it provides multiple layers of rewards. That is, your constant surfing of the Internet leads to multiple rewards that are unpredictable. Perhaps your addiction to Facebook provides a multiple and unpredictable layer of rewards in the sense that every time you sign on to read your updates, you get repeated and unexpected good news. Maybe you found out one of your great friends just got engaged. The next time you sign on, you learn another friend just had a baby! Or, perhaps the man you are really interested in just posted an update that he and his longtime girlfriend just broke up. Each sign on gives you unpredictable results that keep you entertained and coming back for more. Certain games, such as MMROPGs (massively multiplayer online roleplaying games) – including World of Warcraft and Everquest may lead to Internet addiction because, in effect, they never end.\nBiological predispositions to Internet Addiction Disorder may also be a contributing factor to the disorder. If you suffer from this disorder, your levels of dopamine and serotonin may be deficient compared to the general population. This chemical deficiency may require you to engage in more behaviors to receive the same pleasurable response compared to individuals not suffering from addictive Internet behaviors. To achieve this pleasure, individuals may engage in more behavior to the general public, increasing their chances for addiction.\nPredispositions of Internet addiction are also related to anxiety and depression. Oftentimes, if you are already suffering from anxiety or depression, you may turn to the Internet to relieve your suffering from these conditions. Similarly, shy individuals and those with social awkwardness might also be at a higher risk of suffering from Internet addiction. If you suffer from anxiety and depression, you might turn to the Internet to fill a void. If you are shy or socially awkward, you may turn to the Internet because it does not require interpersonal interaction and it is emotionally rewarding.\nWhat are the Symptoms?\nSigns and symptoms of Internet Addiction Disorder may present themselves in both physical and emotional manifestations. Some of the emotional symptoms of Internet Addiction Disorder may include:\n- Feelings of guilt\n- Feelings of Euphoria when using the Computer\n- Inability to Prioritize or Keep Schedules\n- No Sense of Time\n- Avoidance of Work\n- Mood Swings\n- Boredom with Routine Tasks\nPhysical Symptoms of Internet Addiction Disorder may include:\n- Carpal Tunnel Syndrome\n- Poor Nutrition (failing to eat or eating in excessively to avoid being away from the computer)\n- Poor Personal Hygiene (e.g., not bathing to stay online)\n- Neck Pain\n- Dry Eyes and other Vision Problems\n- Weight Gain or Loss\nWhat are the effects of Internet Addiction Disorder? If you are suffering from this disorder, it might be affecting your personal relationships, work life, finances, or school life. Individuals suffering from this condition may be isolating themselves from others, spending a long time in social isolation and negatively impacting their personal relationships. Distrust and dishonesty issues may also arise due to Internet addicts trying to hide or deny the amount of time they spend online. In addition, these individuals may create alternate personas online in an attempt to mask their online behaviors. Serious financial troubles may also result from avoidance of work, bankruptcy due to continued online shopping, online gaming, or online gambling. Internet addicts may also have trouble developing new relationships and socially withdraw – as they feel more at ease in an online environment than a physical one.\nHow is it Diagnosed?\nThough it is gaining traction in the mental health field – and recently added to the Diagnostic and Statistical Manual of Mental Disorders as a disorder that needs more research, a standardized diagnosis of Internet Addiction Disorder has not been discovered. This is also a significant contributing factor to the overall variability in the disorder as a whole and wide range of prevalence in the population from 0.3% to a whopping 38%.\nOne of the more accepted diagnostic assessments of Internet Addiction Disorder has been proposed by KW Beard’s 2005 article in CyberPsychology and Behavior. Beard proposes five diagnostic criteria in the identification of Internet Addiction Disorder in the general population:\n- Is preoccupied with the Internet (constantly thinks about past use or future use)\n- Needs to use the Internet with increased amounts of time to gain satisfaction\n- Has made unsuccessful efforts to control, cut back, or stop use of the Internet\n- Is restless, moody, depressed, or irritable when attempting to control Internet use\n- Has stayed online longer than originally intended\nIn addition, Beard (2005) suggests at least one of the following must also be present in a diagnosis of Internet Addiction Disorder:\n- Has jeopardized or risked the loss of a significant relationship, job, educational, or career opportunity because of the Internet\n- Has lied to family members, therapists, or others to conceal their involvement with the Internet\n- Uses the Internet as a way of escaping from problems or to relieve a dysphoric mood (e.g., guilt, anxiety, depression, helplessness)\nIf you have sought help with an Internet Addiction Disorder, you have likely been given a mental test or questionnaire of some sort to assess your dependency on the Internet. The most common assessment tools used to help make a diagnosis of Internet Addiction Disorder include:\n- Young’s Internet Addiction Test\n- the Problematic Internet Use Questionnaire (PIUQ)\n- the Compulsive Internet Use Scale (CIUS)\nWhat are the Treatment Options?\nThe first step in treatment is the recognition that a problem exists. If you do not believe you have a problem, you are not likely to seek treatment. One of the overarching problems with the Internet is that there is often no accountability and no limits. You are hidden behind a screen – and some things that you may say or do online are things you would never do in person.\nThere is debate in the literature whether treatment is necessary in the first place. Some believe Internet Addiction Disorder to be a “fad illness” and suggest that it usually resolves itself on its own. Studies have show that self-corrective behavior can be achieved and successful. Corrective behaviors include software that controls the Internet use and types of sites that can be visited – with the majority of professionals in agreement that total abstinence from the computer is not an effective method of correction.\nSome professionals argue that medications are effective in the treatment of Internet Addiction Disorder – because if you are suffering from this condition, it is likely that you are also suffering from an underlying condition of anxiety and depression. It is generally thought that if you treat the anxiety or depression, the Internet Addiction may resolve in step with this treatment approach. Studies have shown that anti-anxiety and anti-depressant medications have had a profound affect on the amount of time spent on the Internet – in some cases decreasing rates from 35+ hours a week to 16 hours a week. Physical activity has also been indicative of effective in increasing serotonin levels and decreasing dependency on the Internet.\nSome of the more common psychological treatments of Internet Addiction Disorder include:\n- Individual, group, or family therapy\n- Behavior modification\n- Dialectical Behavioral Therapy (DBT)\n- Cognitive Behavioral Therapy (CBT)\n- Equine Therapy\n- Art Therapy\n- Recreation Therapy\n- Reality Therapy\nBecause of the prevalence of the disorder in the general population, treatment centers and programs have started to pop up in the US and across the globe. In some cases, electro-shock therapy was used to wean individuals off the Internet – this method has since been banned. The ReSTART residential treatment facility was started in 2009 in Seattle, WA for pathological computer use. In 2013, a USB-connected keyboard device was created to provide a very low voltage shock to users who visited particular websites. In other places nationwide and internationally, de-addiction centers have been started to aid individuals suffering from Internet Addiction Disorder.\nIn many instances, multimodal treatments have been employed to treat Internet Addiction Disorder. In this method of treatment, if you are suffering from this condition, you might be prescribed both medications and psychotherapy to treat your addiction to the Internet.\nContinued or Questionable Existence?\nThough originally diagnosed as a “hoax” disorder – the increased digital age has propelled us into the Internet age and Internet addiction has become a truly real “thing.” However, many researchers are uncertain of whether Internet Addiction Disorder is a disorder in its own existence or rather a symptom of other underlying conditions.\nCreating an even more problematic interaction is the fact that everything is online nowadays. It’s hard to make a distinction between online and offline worlds. Everything is Internet-based. From ordering food, interacting with friends, playing games, and even watching tv. Adding an additional layer of confusion and distinction is that other digital technology is taking over the world as well – make access to computers even easier. Now, we don’t have to be physically sitting in front of the computer – we can do anything from anywhere with just our phones, tablets, or other electronic devices.\nStill, other researchers question whether excessive Internet use is an addiction or an obsessive-compulsive or impulse-control disorder. Indeed, the Diagnostic and Statistical Manual of Mental Disorders is correct in its acknowledgement that much more research is needed to study this disorder.']	['<urn:uuid:346db7c2-b248-44e7-93ce-3aba0092b609>', '<urn:uuid:4521d3a8-4d42-4c7e-ac3b-e2011c4a66cd>']	open-ended	direct	short-search-query	similar-to-document	multi-aspect	expert	2025-05-12T23:56:45.148498	5	89	3097
60	user testing vs expert review which better finding problems	Both methods have different strengths in finding usability problems. Traditional usability testing with 5 users can detect 85% of problems that affect 31% or more of users. In comparison, expert reviews (like heuristic evaluations) identify around 30% of the problems found in usability tests on the same interface. Expert reviews are particularly useful for interfaces that are difficult to test with real users due to cost or recruitment challenges, especially in B2B contexts where interfaces have been found to contain almost twice as many problems compared to consumer software.	['The five user number comes from the number of users you would need to detect approximately 85% of the problems in an interface, given that the probability a user would encounter a problem is about 31%. Most people either leave off the last part or are not sure what it means. This does not apply to all testing situations such as comparing two products or when trying to get a precise measure of task times or completion rates but to discovering problems with an interface. Where does 31% come from? It was found as an average problem frequency from several studies (more on this below).\nFor example, the calendar on Hertz.com has a problem with the dates. Let’s imagine that this will adversely affect 31% of reservations—which is quite a lot. So the question becomes, if a problem occurs this frequently (affects this many users) how many users do you need to observe to have an 85% chance of seeing it during a usability test? You might be tempted to think you only need 3 to see it once, but chance fluctuations don’t quite work that way at small sample sizes. You actually would need 5, and this comes from the binomial probability.\nThe formulas actually work quite well, but math tends to bring back bad memories for many people so I’ve provided some simulations below to show you how it works.\nWe all know that there is a 50% chance of getting a tails and 50% chance of getting heads when flipping a coin. If you wanted to know how many times you should plan on flipping a coin to see tails at least once, using the binomial formula the answer is 3. You can see this for yourself; click the flip 1 coin until you see tails. 85% of the time you’ll need to click it no more than three times. You can repeat this exercise and see the number of sample sizes which take more than 3. Over time, a bit more than 85% of all your samples will be 3 or less.\nQ: How many times do you need to toss a coin to be 85% sure you’ll see tails at least once?\nA: 3 or fewer\nSample Sizes :\nThere is a 1/6 chance of getting any number from a 6-sided die. So on any toss there is a 16.667% chance of getting a 1. The binomial formula predicts that you’d need to toss a die on average 10 times to be 85% sure you’ll see a 1.\nQ: How many times do you need to toss a die to be 85% sure you’ll see a one at least once?\nA: 10 or fewer\nSample Sizes :\nNow I have three UI problems which occur 31%, 10% and 1% of the time. Every time you click “Test 1 User” it’s like testing a user (but without the expenses!).\nQ:How many users do you have to test to be 85% sure you’ll see a problem that affects 31% of users at least once?\nA: 5 or fewer\nQ: How many users do you have to test to be 85% sure you’ll see a problem that affects 10% of users at least once?\nA: 18 or fewer\nQ: How many users do you have to test to be 85% sure you’ll see a problem that affects 1% of users at least once?\nA: 189 or fewer\nSample Sizes :\nOf course not all problems affect 31% of users. In fact, in released software or websites, the likelihood of encountering a problem might be closer to 10% or 5%. When problems are much less likely to be “detected” by users interacting with the software, you need more users to test to have a decent chance of observing them in a usability test. For example, given a problem only affecting 10% of users, you need to plan on testing 18 to have an 85% chance of seeing it once. I’ve graphed the differences in the figure below. The blue line shows problems affecting 10% of users and the red affects 31% of users.\nThere’s no concern about the binomial formula (or Poisson equivalent), the controversy is around how frequently UI problems really occur. In reality they aren’t a fixed percent like 31% or 10%, instead these represent an average of problem frequency.\nProblems in fact do not uniformly affect users, or affect users in an easily predictable way. While it is difficult to know how frequently problems occur, as a general rule, for early designs it will be higher (31% or more) and for applications that are in use with many users it will likely be below 10%. Of course you don’t know what the probability a user will encounter a problem. In fact, you often don’t even know if there is a problem—if you did you’d fix it!\nAs a strategy, pick some percentage of problem occurrence, say 20%, and likelihood of discovery, say 85%, which would mean you’d need to plan on testing 9 users. After testing 9 users, you’d know you’ve seen most of the problems that affect 20% or more of the users. If you need to be surer of the findings, then increase the likelihood of discovery, for example, to 95%. Doing so would increase your required sample size to 13.\nThe best strategy is to bring in some set of users, find the problems they have, fix those problems, then bring in another set of users as part of an iterative design and test strategy. In the end, although you’re never testing more than 5 users at a time, in total you might test 15 or 20 users. In fact, this is what Nielsen recommends in his article, not just testing 5 users in total.\nSo if you plan on testing with five users, know that you’re not likely to see most problems, you are just likely to see most problems that affect 31%-100% of users for this population and set of tasks. You will also pick up some of the problems that affect less than 31% of users– just not 85% of them. For example, a sample size of 5 should pick up about 50% of the problems with likelihoods of occurrence of 15%, 75% of the problems with likelihoods of 25%, and so on. Change the tasks or type of users and you’ll need a new sample of users.', 'There’s a continued need to measure and improve the user experience.\nIn principle, it’s easy to see the benefits of having qualified participants use an interface and measuring the experience to produce reliable metrics that can be benchmarked against.\nBut in practice, a number of obstacles make it difficult: time, cost, finding qualified participants, and even obtaining a stable product to test.\nThese challenges seem even more daunting in the B2B space where it’s hard to recruit specialized participants and to get access to enterprise environments. Yet we’ve found that these B2B interfaces are actually less usable and most in need of usability testing. For example, the average number of problems in B2B interfaces was almost twice as high compared to consumer software and a magnitude higher than websites.\nWhile there are ways of mitigating each of these challenges, in our experience, many interfaces simply go without any testing at all, only perpetuating the problem. To provide practitioners with another option, I worked with Christian Rohrer at Capital One who created a method that provides a type of score to estimate the amount of “friction” a typical participant is likely to encounter while using an interface. The method is called PURE, or Practical Usability Rating by Experts, and is based on experts familiar with UX principles and heuristics, who rate a user experience based on a pre-defined rubric.\nThe PURE Method\nWhile most UX methods—such as usability testing, card sorting, and surveys —are empirical, the PURE method is analytic. It’s not based on directly observing users, but instead relies on experts making judgments on the difficulty of steps users would take to complete tasks. It’s based on principles derived from user behavior. It’s the same idea behind expert reviews, guideline reviews, and Keystroke Level Modeling (KLM). An expert review (often loosely referred to as heuristic evaluations) is a popular usability method that involves multiple evaluators examining an interface against a set of rules (called heuristics). The result is a list of problems, or potential problems, users will likely encounter. Expert reviews tend to identify around 30% of the problems found from usability tests on the same interface.\nKeystroke Level Modeling involves deconstructing tasks into smaller steps and then using pre-calibrated times to estimate how long it would take an expert user to complete the task error free. Applying the PURE method involves a hybrid of expert reviews and KLM.\nTo apply the PURE method, have two or more evaluators complete the following steps:\n- Identify the target user or persona (very similar to an initial step in a usability test).\n- Determine the critical or top tasks for this persona.\n- Decompose each task into logical steps and the path(s) this typical user would take to complete the task. As with KLM, specify what steps your target user will take through the interface. There will likely be disagreement on what path users actually take; use data when available and document judgments.\n- Independently score the difficulty/mental effort of each task step using a 3-point scale, referred to as the scoring rubric (shown in Figure 1).\n|The step can be accomplished easily by the target user, due to low cognitive load or because it’s a known pattern, such as the acceptance of Terms of Service agreement.|\n|The step requires some degree of cognitive load by the target user, but can generally be accomplished with some effort.|\n|The step is difficult for the target user, due to significant cognitive load or confusion; some target users would likely fail the task at this point.|\nFigure 1: Scoring rubric for PURE.\n- A PURE score for a given task is the sum of the scores of all steps in that task. Reconcile differences in ratings between evaluators to agree on one rating (note the reasons for disagreement). The overall color for the task and the product is determined by the worst score of a given step within that task and product. For example, a single red step (rated 3) in a task causes that entire task and product to be colored red. The rationale for this is that no mature consumer product should have a step in which the target user is likely to fail a fundamental task. An example of a PURE scorecard for one task is shown in Figure 2.\nFigure 2: Total PURE score for a product (38) and task-based scores (starting from “Download” to Resolve Issue found”).\nReliability & Validity\nWe conducted a traditional benchmarking study on three consumer software products (15 moderated participants) and eight websites (202 unmoderated participants). Our primary metrics were the SUPR-Q, SUS, NPS at the study level and completion rate, task ease using the SEQ, and time on the task level.\nSeparately we had four evaluators go through an hour of training on the PURE method and then independently evaluate the software and websites (following steps 1 through 5) to create PURE scores.\nTo assess the reliability, we found the average correlation between evaluators (called inter-rater reliability) was r=0.5, suggesting reasonable agreement given the modest amount of training. More experienced teams conducting the method had higher agreement, with inter-rater reliability ranging between r=0.6 and 0.9.\nThe method also showed reasonable concurrent validity for some of the key benchmark metrics by exhibiting medium and statistically significant correlations. The correlation between task ease on the SEQ across products and websites was a r=0.5. The correlation with the SUS was r=0.5 and SUPR-Q was r =0.6. The correlations with task time and completion rates were not statistically different than 0. In short, the PURE metrics can explain (predict) around 25%-36% of the variation in the perception of task difficulty, overall usability, and the quality of the website user experience on some consumer software and websites. This is comparable to the 30% overlap in problems identified in expert reviews to usability tests.\nLike other analytic techniques in the UX methodology toolbox, the PURE method shows promise as a quick and reliable method for estimating some key benchmark metrics. Here are a few things to consider.\nNot a substitute for usability testing: The PURE method is not a replacement for usability testing. In our experience, it’s ideally used for identifying low-hanging problems in an interface that’s unlikely to be tested with users (because of cost, priority, or difficulty testing it) and when a metric about the experience is needed for management.\nScale refinement: The 3-point scale used in the scoring rubric may need more points of discrimination as it’s often hard to pick between say a 2 and 3. Using the average of multiple evaluators as the PURE score does provide more points of discrimination, but may present too much variation for executives. We’ll continue to evaluate the rubric and scale.\nDouble experts help: As with heuristic evaluations, having judges who are versed in both interface design, and know the user and domain are likely to generate more reliable results.\nRepeat for tasks and personas: For tasks with multiple paths and multiple personas, you may want to conduct multiple PURE evaluations and then compare or average the ratings.\nWe’ll continue to assess PURE’s validity and reliability between evaluators. If you’d like to give the PURE method a try or have questions, see our CHI paper for more background and contact us as we’re happy to share our experience and conduct a PURE evaluation for your product.']	['<urn:uuid:bf42c353-790b-49ec-b886-bffdf5e134e5>', '<urn:uuid:2d7f7fa8-9a7c-4af3-b418-c0c606c198ec>']	open-ended	with-premise	short-search-query	distant-from-document	comparison	novice	2025-05-12T23:56:45.148498	9	89	2294
61	tax evasion biblical reference legal consequences	The biblical reference comes from the famous quote 'Give back to Caesar what is Caesar's,' which addresses paying taxes as a duty. In modern legal terms, tax evasion is a serious crime with specific consequences - it can result in up to 5 years in prison and fines up to $250,000 at the federal level. The IRS estimates that about 17% of taxpayers commit tax violations annually, though only 0.0022% face criminal prosecution. There is an important legal distinction between tax evasion (illegal) and tax avoidance (legal) - evasion involves willful fraudulent action while avoidance involves legally permissible conduct to reduce tax liability.	"[""|OLD TESTAMENT||NEW TESTAMENT|\n|Old Testament |\n|Epistles of |\n|1 Thess. |\n|1 Καὶ ἤρξατο αὐτοῖς ἐν παραβολαῖς λαλεῖν. ἀμπελῶνα ἄνθρωπος ἐφύτευσεν, καὶ περιέθηκεν φραγμὸν καὶ ὤρυξεν ὑπολήνιον καὶ ᾠκοδόμησεν πύργον, καὶ ἐξέδετο αὐτὸν γεωργοῖς, καὶ ἀπεδήμησεν. 2 καὶ ἀπέστειλεν πρὸς τοὺς γεωργοὺς τῷ καιρῷ δοῦλον, ἵνα παρὰ τῶν γεωργῶν λάβῃ ἀπὸ τῶν καρπῶν τοῦ ἀμπελῶνος: 3 καὶ λαβόντες αὐτὸν ἔδειραν καὶ ἀπέστειλαν κενόν. 4 καὶ πάλιν ἀπέστειλεν πρὸς αὐτοὺς ἄλλον δοῦλον: κἀκεῖνον ἐκεφαλίωσαν καὶ ἠτίμασαν. 5 καὶ ἄλλον ἀπέστειλεν: κἀκεῖνον ἀπέκτειναν, καὶ πολλοὺς ἄλλους, οὓς μὲν δέροντες, οὓς δὲ ἀποκτέννοντες. 6 ἔτι ἕνα εἶχεν, υἱὸν ἀγαπητόν: ἀπέστειλεν αὐτὸν ἔσχατον πρὸς αὐτοὺς λέγων ὅτι ἐντραπήσονται τὸν υἱόν μου. 7 ἐκεῖνοι δὲ οἱ γεωργοὶ πρὸς ἑαυτοὺς εἶπαν ὅτι οὗτός ἐστιν ὁ κληρονόμος: δεῦτε ἀποκτείνωμεν αὐτόν, καὶ ἡμῶν ἔσται ἡ κληρονομία. 8 καὶ λαβόντες ἀπέκτειναν αὐτόν, καὶ ἐξέβαλον αὐτὸν ἔξω τοῦ ἀμπελῶνος. 9 τί οὖν ποιήσει ὁ κύριος τοῦ ἀμπελῶνος; ἐλεύσεται καὶ ἀπολέσει τοὺς γεωργούς, καὶ δώσει τὸν ἀμπελῶνα ἄλλοις. 10 οὐδὲ τὴν γραφὴν ταύτην ἀνέγνωτε: λίθον ὃν ἀπεδοκίμασαν οἱ οἰκοδομοῦντες, οὗτος ἐγενήθη εἰς κεφαλὴν γωνίας: 11 παρὰ κυρίου ἐγένετο αὕτη καὶ ἔστιν θαυμαστὴ ἐν ὀφθαλμοῖς ἡμῶν;||1 Then he began to speak to them in parables; There was a man who planted a vineyard, and put a wall round it, and dug a wine-press and built a tower in it, and then let it out to some vine-dressers, while he went on his travels. 2 And when the season came, he sent one of his servants on an errand to the vine-dressers, to claim from the vine-dressers the revenue of his vineyard. 3 Whereupon they took him and beat him, and sent him away empty-handed. 4 Then he sent another servant on a second errand to them, and him too they beat over the head and used him outrageously. 5 He sent another, whom they killed; and many others, whom they beat or killed at their pleasure. 6 He had still one messenger left, his own well-beloved son; him he sent to them last of all; They will have reverence, he said, for my son. 7 But the vine-dressers said among themselves, This is the heir, come, let us kill him, and then his inheritance will be ours. 8 So they took him and killed him, and cast him out of the vineyard. 9 And now, what will the owner of the vineyard do? He will come, and make an end of those vine-dressers, and give his vineyard to others. 10 Why, have you not read this passage in the scriptures, The very stone which the builders rejected has become the chief stone at the corner; 11 this is the Lord’s doing, and it is marvellous in our eyes?||1 Et cœpit illis in parabolis loqui: Vineam pastinavit homo, et circumdedit sepem, et fodit lacum, et ædificavit turrim, et locavit eam agricolis, et peregre profectus est. 2 Et misit ad agricolas in tempore servum ut ab agricolis acciperet de fructu vineæ. 3 Qui apprehensum eum ceciderunt, et dimiserunt vacuum. 4 Et iterum misit ad illos alium servum: et illum in capite vulneraverunt, et contumeliis affecerunt. 5 Et rursum alium misit, et illum occiderunt: et plures alios: quosdam cædentes, alios vero occidentes. 6 Adhuc ergo unum habens filium carissimum, et illum misit ad eos novissimum, dicens: Quia reverebuntur filium meum. 7 Coloni autem dixerunt ad invicem: Hic est hæres: venite, occidamus eum: et nostra erit hæreditas. 8 Et apprehendentes eum, occiderunt: et ejecerunt extra vineam. 9 Quid ergo faciet dominus vineæ? Veniet, et perdet colonos, et dabit vineam aliis. 10 Nec scripturam hanc legistis: Lapidem quem reprobaverunt ædificantes, hic factus est in caput anguli: 11 a Domino factum est istud, et est mirabile in oculis nostris?|\n|12 καὶ ἐζήτουν αὐτὸν κρατῆσαι, καὶ ἐφοβήθησαν τὸν ὄχλον: ἔγνωσαν γὰρ ὅτι πρὸς αὐτοὺς τὴν παραβολὴν εἶπεν. καὶ ἀφέντες αὐτὸν ἀπῆλθον. 13 Καὶ ἀποστέλλουσιν πρὸς αὐτόν τινας τῶν Φαρισαίων καὶ τῶν Ἡρῳδιανῶν ἵνα αὐτὸν ἀγρεύσωσιν λόγῳ. 14 καὶ ἐλθόντες λέγουσιν αὐτῷ: διδάσκαλε, οἴδαμεν ὅτι ἀληθὴς εἶ καὶ οὐ μέλει σοι περὶ οὐδενός: οὐ γὰρ βλέπεις εἰς πρόσωπον ἀνθρώπων, ἀλλ' ἐπ' ἀληθείας τὴν ὁδὸν τοῦ θεοῦ διδάσκεις: ἔξεστιν δοῦναι κῆνσον Καίσαρι ἢ οὔ; δῶμεν ἢ μὴ δῶμεν; 15 ὁ δὲ εἰδὼς αὐτῶν τὴν ὑπόκρισιν εἶπεν αὐτοῖς: τί με πειράζετε; φέρετέ μοι δηνάριον ἵνα ἴδω. 16 οἱ δὲ ἤνεγκαν. καὶ λέγει αὐτοῖς: τίνος ἡ εἰκὼν αὕτη καὶ ἡ ἐπιγραφή; οἱ δὲ εἶπαν αὐτῷ: Καίσαρος. 17 ὁ δὲ Ἰησοῦς εἶπεν αὐτοῖς: τὰ Καίσαρος ἀπόδοτε Καίσαρι καὶ τὰ τοῦ θεοῦ τῷ θεῷ. καὶ ἐξεθαύμαζον ἐπ' αὐτῷ.||12 This parable, they saw, was aimed at themselves, and they would gladly have laid hands on him, but they were afraid of the multitude; so they went away and left him alone. 13 Then they sent some of the Pharisees to him, with those who were of Herod’s party, to make him betray himself in his talk. 14 These came and said to him, Master, we know that thou art sincere; that thou holdest no one in awe, making no distinction between man and man, but teachest in all sincerity the way of God. Is it right that tribute should be paid to Caesar? Or should we refuse to pay it? 15 But he saw their treachery, and said to them, Why do you thus put me to the test? Bring me a silver piece, and let me look at it. 16 When they brought it, he asked them, Whose is this likeness? Whose name is inscribed on it? Caesar’s, they said. 17 Whereupon Jesus answered them, Give back to Caesar what is Caesar’s, and to God what is God’s. And they were lost in admiration of him.||12 Et quærebant eum tenere: et timuerunt turbam: cognoverunt enim quoniam ad eos parabolam hanc dixerit. Et relicto eo abierunt. 13 Et mittunt ad eum quosdam ex pharisæis, et herodianis, ut eum caperent in verbo. 14 Qui venientes dicunt ei: Magister, scimus quia verax es, et non curas quemquam: nec enim vides in faciem hominum, sed in veritate viam Dei doces. Licet dari tributum Cæsari, an non dabimus? 15 Qui sciens versutiam illorum, ait illos: Quid me tentatis? afferte mihi denarium ut videam. 16 At illi attulerunt ei. Et ait illis: Cujus est imago hæc, et inscriptio? Dicunt ei: Cæsaris. 17 Respondens autem Jesus dixit illis: Reddite igitur quæ sunt Cæsaris, Cæsari: et quæ sunt Dei, Deo. Et mirabantur super eo.|\n|18 Καὶ ἔρχονται Σαδδουκαῖοι πρὸς αὐτόν, οἵτινες λέγουσιν ἀνάστασιν μὴ εἶναι, καὶ ἐπηρώτων αὐτὸν λέγοντες: 19 διδάσκαλε, Μωϋσῆς ἔγραψεν ἡμῖν ὅτι ἐάν τινος ἀδελφὸς ἀποθάνῃ καὶ καταλίπῃ γυναῖκα καὶ μὴ ἀφῇ τέκνον, ἵνα λάβῃ ὁ ἀδελφὸς αὐτοῦ τὴν γυναῖκα καὶ ἐξαναστήσῃ σπέρμα τῷ ἀδελφῷ αὐτοῦ. 20 ἑπτὰ ἀδελφοὶ ἦσαν: καὶ ὁ πρῶτος ἔλαβεν γυναῖκα, καὶ ἀποθνῄσκων οὐκ ἀφῆκεν σπέρμα. 21 καὶ ὁ δεύτερος ἔλαβεν αὐτήν, καὶ ἀπέθανεν μὴ καταλιπὼν σπέρμα: καὶ ὁ τρίτος ὡσαύτως: 22 καὶ οἱ ἑπτὰ οὐκ ἀφῆκαν σπέρμα. ἔσχατον πάντων καὶ ἡ γυνὴ ἀπέθανεν. 23 ἐν τῇ ἀναστάσει, ὅταν ἀναστῶσιν, τίνος αὐτῶν ἔσται γυνή; οἱ γὰρ ἑπτὰ ἔσχον αὐτὴν γυναῖκα. 24 ἔφη αὐτοῖς ὁ Ἰησοῦς: οὐ διὰ τοῦτο πλανᾶσθε μὴ εἰδότες τὰς γραφὰς μηδὲ τὴν δύναμιν τοῦ θεοῦ; 25 ὅταν γὰρ ἐκ νεκρῶν ἀναστῶσιν, οὔτε γαμοῦσιν οὔτε γαμίζονται, ἀλλ' εἰσὶν ὡς ἄγγελοι ἐν τοῖς οὐρανοῖς. 26 περὶ δὲ τῶν νεκρῶν, ὅτι ἐγείρονται οὐκ ἀνέγνωτε ἐν τῇ βίβλῳ Μωϋσέως ἐπὶ τοῦ βάτου πῶς εἶπεν αὐτῷ ὁ θεὸς λέγων: ἐγὼ ὁ θεὸς Ἀβραὰμ καὶ ὁ θεὸς Ἰσαὰκ καὶ ὁ θεὸς Ἰακώβ; 27 οὐκ ἔστιν θεὸς νεκρῶν ἀλλὰ ζώντων. πολὺ πλανᾶσθε.||18 Then he was approached with a question by the Sadducees, men who say that there is no resurrection: 19 Master, they said, Moses prescribed for us that if a man’s brother dies, leaving a widow behind him but no children, he, the brother, should marry the widow, and beget children in the dead brother’s name. 20 There were seven brethren; the first married a wife, and died childless; 21 the second married her, and he too left no children, and so with the third; 22 all seven married her, without having children, and the woman died last of all. 23 And now, when the dead rise again, which of these will be her husband, since she was wife to all seven? 24 Jesus answered them, Is not this where you are wrong, that you do not understand the scriptures, or what is the power of God? 25 When the dead rise, there is no marrying or giving in marriage, they are as the angels in heaven are. 26 But as for the dead rising again, have you never read in the book of Moses how God spoke to him at the burning bush, and said, I am the God of Abraham, and the God of Isaac, and the God of Jacob? 27 Yet it is of living men, not of dead men, that he is the God; you are wrong, then, altogether.||18 Et venerunt ad eum sadducæi, qui dicunt resurrectionem non esse: et interrogabant eum, dicentes: 19 Magister, Moyses nobis scripsit, ut si cujus frater mortuus fuerit, et dimiserit uxorem, et filios non reliquerit, accipiat frater ejus uxorem ipsius, et resuscitet semen fratri suo. 20 Septem ergo fratres erant: et primus accepit uxorem, et mortuus est non relicto semine. 21 Et secundus accepit eam, et mortuus est: et nec iste reliquit semen. Et tertius similiter. 22 Et acceperunt eam similiter septem: et non reliquerunt semen. Novissima omnium defuncta est et mulier. 23 In resurrectione ergo cum resurrexerint, cujus de his erit uxor? septem enim habuerunt eam uxorem. 24 Et respondens Jesus, ait illis: Nonne ideo erratis, non scientes Scripturas, neque virtutem Dei? 25 Cum enim a mortuis resurrexerint, neque nubent, neque nubentur, sed sunt sicut angeli in cælis. 26 De mortuis autem quod resurgant, non legistis in libro Moysi, super rubum, quomodo dixerit illi Deus, inquiens: Ego sum Deus Abraham, et Deus Isaac, et Deus Jacob? 27 Non est Deus mortuorum, sed vivorum. Vos ergo multum erratis.|\n|28 Καὶ προσελθὼν εἷς τῶν γραμματέων, ἀκούσας αὐτῶν συζητούντων, ἰδὼν ὅτι καλῶς ἀπεκρίθη αὐτοῖς, ἐπηρώτησεν αὐτόν: ποία ἐστὶν ἐντολὴ πρώτη πάντων; 29 ἀπεκρίθη ὁ Ἰησοῦς ὅτι πρώτη ἐστίν: ἄκουε Ἰσραήλ, κύριος ὁ θεὸς ἡμῶν κύριος εἷς ἐστιν, 30 καὶ ἀγαπήσεις κύριον τὸν θεόν σου ἐξ ὅλης τῆς καρδίας σου καὶ ἐξ ὅλης τῆς ψυχῆς σου καὶ ἐξ ὅλης τῆς διανοίας σου καὶ ἐξ ὅλης τῆς ἰσχύος σου. 31 δευτέρα αὕτη: ἀγαπήσεις τὸν πλησίον σου ὡς σεαυτόν. μείζων τούτων ἄλλη ἐντολὴ οὐκ ἔστιν. 32 καὶ εἶπεν αὐτῷ ὁ γραμματεύς: καλῶς, διδάσκαλε, ἐπ' ἀληθείας εἶπες ὅτι εἷς ἐστιν καὶ οὐκ ἔστιν ἄλλος πλὴν αὐτοῦ: 33 καὶ τὸ ἀγαπᾶν αὐτὸν ἐξ ὅλης τῆς καρδίας καὶ ἐξ ὅλης τῆς συνέσεως καὶ ἐξ ὅλης τῆς ἰσχύος καὶ τὸ ἀγαπᾶν τὸν πλησίον ὡς ἑαυτὸν περισσότερόν ἐστιν πάντων τῶν ὁλοκαυτωμάτων καὶ θυσιῶν. 34 καὶ ὁ Ἰησοῦς ἰδὼν αὐτὸν ὅτι νουνεχῶς ἀπεκρίθη, εἶπεν αὐτῷ: οὐ μακρὰν εἶ ἀπὸ τῆς βασιλείας τοῦ θεοῦ. καὶ οὐδεὶς οὐκέτι ἐτόλμα αὐτὸν ἐπερωτῆσαι.||28 One of the scribes heard their dispute, and, finding that he answered to the purpose, came up and asked him, Which is the first commandment of all? 29 Jesus answered him, The first commandment of all is, Listen, Israel; there is no God but the Lord thy God; 30 and thou shalt love the Lord thy God with the love of thy whole heart, and thy whole soul, and thy whole mind, and thy whole strength. This is the first commandment, 31 and the second, its like, is this, Thou shalt love thy neighbour as thyself. There is no other commandment greater than these. 32 And the scribe said to him, Truly, Master, thou hast answered well; there is but one God, and no other beside him; 33 and if a man loves God with all his heart and all his soul and all his understanding and all his strength, and his neighbour as himself, that is a greater thing than all burnt-offerings and sacrifices. 34 Then Jesus, seeing how wisely he had answered, said to him, Thou art not far from the kingdom of God. And after this, no one dared to try him with further questions.||28 Et accessit unus de scribis, qui audierat illos conquirentes, et videns quoniam bene illis responderit, interrogavit eum quod esset primum omnium mandatum. 29 Jesus autem respondit ei: Quia primum omnium mandatum est: Audi Israël, Dominus Deus tuus, Deus unus est: 30 et diliges Dominum Deum tuum ex tota corde tuo, et ex tota anima tua, et ex tota mente tua, et ex tota virtute tua. Hoc est primum mandatum. 31 Secundum autem simile est illi: Diliges proximum tuum tamquam teipsum. Majus horum aliud mandatum non est. 32 Et ait illi scriba: Bene, Magister, in veritate dixisti, quia unus est Deus, et non est alius præter eum. 33 Et ut diligatur ex toto corde, et ex toto intellectu, et ex tota anima, et ex tota fortitudine, et diligere proximum tamquam seipsum, majus est omnibus holocautomatibus, et sacrificiis. 34 Jesus autem videns quod sapienter respondisset, dixit illi: Non es longe a regno Dei. Et nemo jam audebat eum interrogare.|\n|35 Καὶ ἀποκριθεὶς ὁ Ἰησοῦς ἔλεγεν διδάσκων ἐν τῷ ἱερῷ: πῶς λέγουσιν οἱ γραμματεῖς ὅτι ὁ Χριστὸς υἱὸς Δαυίδ ἐστιν; 36 αὐτὸς Δαυὶδ εἶπεν ἐν τῷ πνεύματι τῷ ἁγίῳ: εἶπεν κύριος τῷ κυρίῳ μου: κάθου ἐκ δεξιῶν μου ἕως ἂν θῶ τοὺς ἐχθρούς σου ὑποκάτω τῶν ποδῶν σου. 37 αὐτὸς Δαυὶδ λέγει αὐτὸν κύριον, καὶ πόθεν αὐτοῦ ἐστιν υἱός; καὶ ὁ πολὺς ὄχλος ἤκουεν αὐτοῦ ἡδέως. 38 Καὶ ἐν τῇ διδαχῇ αὐτοῦ ἔλεγεν: βλέπετε ἀπὸ τῶν γραμματέων τῶν θελόντων ἐν στολαῖς περιπατεῖν καὶ ἀσπασμοὺς ἐν ταῖς ἀγοραῖς 39 καὶ πρωτοκαθεδρίας ἐν ταῖς συναγωγαῖς καὶ πρωτοκλισίας ἐν τοῖς δείπνοις: 40 οἱ κατεσθίοντες τὰς οἰκίας τῶν χηρῶν καὶ προφάσει μακρὰ προσευχόμενοι, οὗτοι λήμψονται περισσότερον κρίμα.||35 Then Jesus said openly, still teaching in the temple, What do the scribes mean by saying that Christ is to be the son of David? 36 David himself was moved by the Holy Spirit to say, The Lord said to my Master, Sit on my right hand while I make thy enemies a footstool under thy feet. 37 Thus David himself calls Christ his Master; how can he be also his son? And the multitude at large listened to him readily. 38 This was part of the teaching he gave them, Beware of the scribes, who enjoy walking in long robes, and having their hands kissed in the market-place, 39 and the first seats in the synagogues, and the chief places at feasts; 40 who swallow up the property of widows, under cover of their long prayers; their sentence will be all the heavier for that.||35 Et respondens Jesus dicebat, docens in templo: Quomodo dicunt scribæ Christum filium esse David? 36 Ipse enim David dicit in Spiritu Sancto: Dixit Dominus Domino meo: Sede a dextris meis, donec ponam inimicos tuos scabellum pedum tuorum. 37 Ipse ergo David dicit eum Dominum, et unde est filius ejus? Et multa turba eum libenter audivit. 38 Et dicebat eis in doctrina sua: Cavete a scribis, qui volunt in stolis ambulare, et salutari in foro, 39 et in primis cathedris sedere in synagogis, et primos discubitus in cœnis: 40 qui devorant domos viduarum sub obtentu prolixæ orationis: hi accipient prolixius judicium.|\n|41 Καὶ καθίσας κατέναντι τοῦ γαζοφυλακίου ἐθεώρει πῶς ὁ ὄχλος βάλλει χαλκὸν εἰς τὸ γαζοφυλάκιον: καὶ πολλοὶ πλούσιοι ἔβαλλον πολλά, 42 καὶ ἐλθοῦσα μία χήρα πτωχὴ ἔβαλεν λεπτὰ δύο, ὅ ἐστιν κοδράντης. 43 καὶ προσκαλεσάμενος τοὺς μαθητὰς αὐτοῦ εἶπεν αὐτοῖς: ἀμὴν λέγω ὑμῖν ὅτι ἡ χήρα αὕτη ἡ πτωχὴ πλεῖον πάντων ἔβαλεν τῶν βαλλόντων εἰς τὸ γαζοφυλάκιον: 44 πάντες γὰρ ἐκ τοῦ περισσεύοντος αὐτοῖς ἔβαλον, αὕτη δὲ ἐκ τῆς ὑστερήσεως αὐτῆς πάντα ὅσα εἶχεν ἔβαλεν, ὅλον τὸν βίον αὐτῆς.||41 As he was sitting opposite the treasury of the temple, Jesus watched the multitude throwing coins into the treasury, the many rich with their many offerings; 42 and there was one poor widow, who came and put in two mites, which make a farthing. 43 Thereupon he called his disciples to him, and said to them, Believe me, this poor widow has put in more than all those others who have put offerings into the treasury. 44 The others all gave out of what they had to spare; she, with so little to give, put in all that she had, her whole livelihood.||41 Et sedens Jesus contra gazophylacium, aspiciebat quomodo turba jactaret æs in gazophylacium, et multi divites jactabant multa. 42 Cum venisset autem vidua una pauper, misit duo minuta, quod est quadrans, 43 et convocans discipulos suos, ait illis: Amen dico vobis, quoniam vidua hæc pauper plus omnibus misit, qui miserunt in gazophylacium. 44 Omnes enim ex eo, quod abundabat illis, miserunt: hæc vero de penuria sua omnia quæ habuit misit totum victum suum.|\n Ps. 117.22; cf. Rom. 9.33; I Pet. 2.7.\n vv. 1-12: Mt. 21.33; Luke 20.9; cf. Is. 5.1.\n Ex. 3.6.\n Deut. 6.4.\n Lev. 19.18\n Ps. 109.1.\n vv. 13-37: Mt. 22.15; Lk. 20.19.\n vv. 38-44: Lk. 20.45; 21.1.\nKnox Translation Copyright © 2013 Westminster Diocese\nNihil Obstat. Father Anton Cowan, Censor.\nImprimatur. +Most Rev. Vincent Nichols, Archbishop of Westminster. 8th January 2012.\nRe-typeset and published in 2012 by Baronius Press Ltd"", 'Give back to Caesar what is Caesar’s, Jesus instructed. Taxes must be paid by everyone, except those who have the means and resources to find what is commonly referred to as a “loophole.” While the concept of taxes should apply to everyone, not everyone feels obliged to return to Caesar what is owed to Caesar. The basic inequity of taxes is that loopholes are legal; evasion and fraud are not.\nFederal Tax Crimes\nFederal tax fraud and tax evasion are cousins in crime. Tax evasion is the crime most often charged by Federal prosecutors. The offense is generally tied to the taxpayer’s deliberate misrepresentation of taxable income. For the individual, the crime is punishable up to five years in prison, a fine of up to $250,000 (or both), and an assessment for the cost of the prosecution. These crimes are most often prosecuted under Section 7201 of Title 26, the Internal Revenue Code.\nTax fraud, on the other hand, general involves a host of crimes: filing false tax returns, failure to pay taxes, filing false documents, failure to collect employment taxes, and failure to file a tax return. Tax fraud can trigger a host of criminal laws violations found in both Title 26 and Title 18 of the United States Code.\nTax fraud can be punished both as a criminal and civil offense. Civil offenses are usually prosecuted under Title 26 while criminal offenses are prosecuted under Title 18. If two or more people are involved in any tax fraud scheme, the Government will generally indict under the conspiracy statute in Title 18 (Section 371).\nTax fraud-related crimes are some of the most difficult to prove. The Government is required to prove beyond a reasonable doubt that the defendant intentionally defrauded the IRS out of taxable revenue. Because the Internal Revenue Code is so complicated, and because most people from whom a jury pool is chosen have a strong distaste for the complex nature of the code, the Government will often choose to civilly prosecute the offense because the standard of proof is significantly lower.\nThat’s what only .0022 percent of the taxpayers ever face criminal prosecutions, according to the IRS. Yet the IRS estimates that as many as 17 percent of taxpayers commit a tax law violation in some way each year. While the figure is subject to considerable debate, the IRS reports that 75 percent of the income tax fraud in this country is committed by individual taxpayers rather than corporations. The agency attributes this figure to services workers—such as restaurant workers, mechanics, and handymen—who commonly underreport their cash income.\n“Tax avoidance” can, and sometimes is, used as a defense in tax evasion offenses. The IRS, and the courts who decide tax-related cases, have carved out distinctions between tax avoidance and tax evasion. The latter involves (as does most tax fraud) a willful and knowing fraudulent action to reduce tax liability while the former involves legally permissible conduct to reduce tax liability. In 1934, the famed jurist Learned Hand once offered this classic definition of tax avoidance in United States v. Gregory:\n“Anyone may arrange his affairs that his taxes shall be as low as possible. He is not bound to choose the pattern of which best pays the Treasury, there is not even a patriotic duty to increase one’s taxes. Over and over again courts have said that there is nothing sinister in so arranging affairs has to keep taxes as low as possible. Everyone does it, rich and poor alike, and all do right, for nobody owes a public duty to pay more than the law demands.”\nThe IRS Manual (IRM 9781, § 412, Jan. 18, 1980) itself notes the “fine distinction” between tax avoidance and evasion: “One who avoids tax does not conceal or misrepresent. He shapes events to reduce or eliminate tax liability and, upon the happening of events, makes a complete disclosure. Evasion on the other hand involves deceit, subterfuge, camouflage, concealment, some attempt to color or obscure events, or to make things seem other than they are. For example, the creation of a bona fide partnership to reduce the tax liability of a business by dividing the income among several individual partners is tax avoidance. However, the facts of a particular case may show an alleged partnership was not in fact established and that one or more of alleged partners secretly returned his/her share of profits to the real owner of the business, who in turn did not report this income. That would be an instance of attempted evasion.”\nThe IRS also recognizes “negligence” as a defense when no signs of fraud exist. In these instances, tax auditors will consider mistakes in tax returns as careless errors.\nBoth tax evasion and tax fraud are considered a white-collar crime both at the federal and state level.\nTax Evasion in Texas\nTexas doesn’t have a personal income tax. So Texas’ main source of state revenue comes from its sales tax. Which means that, in Texas, tax evasion and fraud laws are usually applied to businesses or corporations.\nIf you have been arrested and charged with tax evasion in Texas, you will first want to contact an experienced tax evasion attorney who is qualified to defend your white-collar crime. Then, you will want to understand the meaning of your tax evasion charges and the penalties those charges hold.\nIf you don’t pay your taxes or commit a fraudulent act involving record-keeping or falsifying electronic sales records, you could face some pretty hefty fines and prison time.\nUnder the Texas Tax Code section 151.7032, knowingly or intentionally failing to pay the comptroller the required tax is considered tax evasion. Depending on the amount of the tax collected and not paid, there are different levels of charges that you could possibly face, such as:\nIf the amount of tax collected and not paid is under $10,000, you will face a Class C misdemeanor, which is punishable by a fine up to $500 and no jail time.\nIf the amount of tax collected and not paid is over $10,000 but under $20,000, you will face a state jail felony, which is punishable by a fine up to $10,000 and 180 days to 2 years in a state jail.\nIf the amount of tax collected and not paid is over $20,000 but under $100,000, you will face a third degree felony, which is punishable by a fine up to $10,000 and 2 to 10 years in a state prison.\nIf the amount of tax collected and not paid is over $100,000, you will face a second degree felony, which is punishable by a fine up to $10,000 and 2 to 20 years in a state prison.\nTax evasion and tax fraud are serious charges, but with an experienced Texas white-collar lawyer at your side, you will have the best chance at beating them, clearing your good name, and getting back to your business.']"	['<urn:uuid:53382c8b-9ccd-4585-9ff3-c2fb1a3588b2>', '<urn:uuid:de17e3ed-70d2-44ca-8f12-35e884949a2b>']	open-ended	with-premise	short-search-query	similar-to-document	multi-aspect	expert	2025-05-12T23:56:45.148498	6	103	3991
62	How do different types of blood abnormalities affect oxygen delivery to tissues, and what wound care approaches are recommended for patients with circulatory problems?	Blood abnormalities affecting oxygen delivery include anemia (decreased hemoglobin but normal PO2 and oxygen saturation), carbon monoxide poisoning (decreased oxygen saturation due to CO displacing O2 on heme), and methemoglobinemia (Fe3+ instead of Fe2+ preventing oxygen binding). For wounds associated with circulatory problems, the Wound Care Center provides comprehensive treatment plans including evaluation of underlying causes, blood work, and specialized treatments. These may include hyperbaric oxygen therapy, specialty wound dressings, and surgical interventions like bypass surgery to improve blood flow in leg arteries. Treatment plans are individualized and may involve coordination with primary care physicians.	"[""Flashcards in 1. Cell Injury Deck (35):\nWhat do we use to measure oxygen in the body?\nHemoglobin, oxygen saturation (on the heme), partial pressure of arterial oxygen\nWhat does it mean for oxygen saturation to be 100%?\nAll 4 spots on heme bound to oxygen\nWhat is partial pressure of arterial oxygen?\nOxygen dissolved in PLASMA\nWhat is the relationship between oxygen saturation and partial pressure of arterial oxygen?\nMove in the SAME direction because oxygen saturation gets its oxygen from the oxygen dissolved in plasma\nWhat is the most common cause of ischemia?\nThrombus in muscular artery\nWhat is hypoxemia?\nDecreased partial pressure of arterial oxygen\nWhenever you have respiratory acidosis, what happens to partial pressure of O2?\nGoes down - hypoxemia; there is always an inverse relationship between PCO2 and PO2\nPatient with hypoxemia given 100% O2 and O2 doesn't increase - what's happening?\nShunt - perfusion but no ventilation (kids - hyaline membrane disease, adults - adult respiratory syndrome)\nWhat happens when you give 100% O2 to someone with a perfusion defect?\nO2 will increase because not every single alveoli is not perfused\nDoes anemia give you hypoxemia?\nNO - it gives you decreased Hgb but PO2 and oxygen saturation are normal\nYou will have hypoxia (tissue lacks oxygen) but not hypoxemia (PO2 in the blood is normal)\nHeater in the winter time, automobile exhaust, house fire - what should you think of?\nWhat else should you think of with house fire aside from CO poisoning?\nCyanide poisoning because of upholstery on furniture\nWhat is the only lab value affected in CO poisoning?\nOxygen saturation is decreased because CO displaces O2 on the heme\nHow do we treat CO poisoning?\nWhat does cyanosis mean?\nDecreased oxygen saturation\nWhat is the first symptom of CO poisoning?\nWhy do we not see signs of cyanosis with CO poisoning?\nIt produces a cherry red pigment that can mask the blue\nWhat is methemoglobin?\nHemoglobin with FE3+ instead of 2+ which makes it so that oxygen can't bind - decreased oxygen saturation\nDude coming out of the Rocky Mountains, cyanotic, give him 100% O2 and he's still cyanotic - diagnosis?\nMethemoglobinemia because of drinking water with nitrites/nitrates which are oxidative agents\nWhat is the main treatment for methemoglobinemia?\nWhat are 2 things that sulfa and nitro drugs (oxidizing agents) do?\n1. Produce methemoglobin\n2. Produce hemolytic anemia in G6PD deficiency\nWhy do we see methemoglobinemia in HIV patients?\nThey are usually on TMP-SMX for treatment of PCP\nWhat shifts hemoglobin curve to the right?\nCADET: CO2, acidosis, 23BPG, Elevation (causes increase in synthesis of 23BPG), Temperature\nWhat shifts hemoglobin curve to the left?\nCO, HbF, alkalosis\nWhat inhibits cytochrome oxidase?\nCO and cyanide (think 3 C's)\nWhat does CO do?\n1. decreases O2 sat\n2. shifts hemoglobin curve to the left\n3. inhibits cytochrome oxidase\nthis is why CO is so bad\nWhat is one of the complications of salicylate poisoning?\nHyperthermia because salicylates are uncoupling agents\nAcute respiratory acidosis - what happens to Hgb, oxygen sat, PO2?\nHgb - nothing, Oxygen sat and PO2 - both decreased\nWhat can you give in addition to methylene blue for methemoglobinemia?\nWhat are the biggest problems in tissue hypoxia?\n1. Decrease in ATP leading to anaerobic glycolysis and lactic acid build up\n2. ATPase pumps broken\nWhat does the build up of lactic acid do in a cell?\nDenature proteins and enzymes --> coagulation necrosis (grossly: infarction)\nWhy are cells swollen in tissue hypoxia?\nDecreased ATP --> Na-K pump stops working --> Na stuck in cell --> cell swells\nWhat happens to calcium in tissue hypoxia?\nEnters cell because Ca-ATPase pump stops working - once it's in the cell calcium activates all kinds of enzymes (membrane damage, nuclear pyknosis)\nWhen you have free radical damage what kind of pigment do you see in cells?\nLipofuchsin - can't break down lipids all the way"", 'Wound Care & Hyperbaric Medicine Center\nHeal Better, Faster.\nIf you have a wound that does not heal, even after weeks or months of care,\nthe specialized services of the Wound Care & Hyperbaric Medicine Center\nmay be able to help. Whether your wound is the result of circulatory problems,\ndiabetes or some other medical condition, our highly skilled team of physicians\non the medical staff and nurses will work to develop a treatment plan\ntailored to your unique needs. Our team approach is designed to:\n- Correct the underlying causes of the wound\n- Control infection\n- Improve overall health and nutrition\nOur trained specialists follow a multidisciplinary approach to wound healing.\nAfter an initial evaluation, each patient receives a comprehensive, individualized\nplan designed to help heal these complicated wounds. We work to address\nthe underlying cause of the problem, control infection and improve the\noverall health of our patients. We are committed to providing care with\ndignity and respect, and we focus on the whole person by considering your\nphysical and emotional needs, because we know these are integral parts\nof the healing process. Our staff will coordinate your care with your\nprimary care physician to ensure your overall well-being.\nFor more information about wound therapy, please call 702-657-1506.\nEvaluating Your Wound\nThe first time you visit the Wound Care & Hyperbaric Medicine Center,\nyou will be given a comprehensive evaluation that includes your medical\nhistory, a physician exam, photographs of your wound, blood work and non-invasive\ntests needed to help develop your treatment plan. Please bring:\n- All medications you currently take, including over-the-counter medicine\n- A list of any allergies\n- Your insurance information\n- X-rays, if available\nDuring your evaluation, you should discuss any questions or concerns with\nyour wound care team to be sure you understand your treatment plan. Your\ncommitment and active participation in your care are\nessential to success.\nDepending on your overall health and medical condition, there are many\ntypes of wounds that resist traditional treatment methods, including:\n- Slow or non-healing surgical wounds\n- Failing skin/muscle grafts or flaps\n- Brown recluse spider bites\n- Skin tears or lacerations\nWhatever the cause, any wound that is present for 30 days or more is cause\nfor concern and should be evaluated by specialists in wound healing.\nHyperbaric Oxygen Therapy\nAt North Vista Hospital, we offer state-of-the-art hyperbaric oxygen therapy\n(HBOT) to help heal wounds. Over the course of several treatments, many\npatients achieve wound healing that is not otherwise possible using other methods.\nHBOT allows you to breathe 100% oxygen at an increased pressure in a special\nchamber. This increases the level of oxygen in your tissues to promote\nhealing and fight infection.\nOther Treatment Options\nSpecialty Wound Dressings- Medicines and dressings can sometimes encourage wounds to close and heal.\nDebridement- The removal of dead tissue around the wound, or debridement, is often\nneeded to clean the wound and promote healing.\nAntibiotics- Antibiotics are often used, even if an infection is not clearly present.\nThis is done to prevent an infection. Usually antibiotics are administered\nfor 4-6 weeks.\nAlleviation of Weight-bearing Wounds- Keeping pressure off of foot ulcers promotes healing. Sometimes special\ncasts or boots are placed on the foot to ""off-load"" pressure from the ulcer.\nBlood Sugar Control- Infected ulcers are likely to cause high blood sugar levels. High blood\nsugar levels lower immune response and prevent wound healing. Adjustments\nin diet or medications can aid in fighting infections and healing wounds.\nSometimes insulin shots are needed in the short term to achieve optimal\nblood sugar control.\nSkin Grafts- A bio-engineered skin graft or human skin graft can be used to treat\ndiabetic foot ulcers which fail to heal with conventional treatments.\nSkin grafts have been shown to speed up the healing process.\nSurgery- Bypass surgery to improve blood flow within the arteries of the legs\nmay help with wound healing and spare amputations. As a last resort, amputation\nsurgery may be needed to stop the spread of infection to the rest of the body\nAddress and Directions\nWound Care Center\n1815 E. Lake Mead Blvd., Suite 100\nN. Las Vegas, NV 89030']"	['<urn:uuid:122dfc00-80b0-4a9e-88d6-8cb73a7986f3>', '<urn:uuid:4a0a35b1-4783-443e-ba01-bcdbdd148d99>']	open-ended	direct	verbose-and-natural	distant-from-document	multi-aspect	expert	2025-05-12T23:56:45.148498	24	95	1344
63	cheese company food safety practices experience dangerous additives	Henning's Cheese focuses on quality and safety in their cheese-making process, using proper ingredients and aging methods. This contrasts with historical dangerous practices in food production, where toxic additives like borax, formaldehyde, and lead salts were commonly used in foods including cheese before FDA regulation. The Pure Food and Drug Act of 1906 and subsequent laws banned these harmful substances to protect consumers.	"['At Henning’s Cheese, cheese lovers, and those yet-to-become cheese lovers can find a wide array of cheese flavors, thanks to the the cheesemaker’s attitude about adding the “spice of life” to the cheese making process.\nMaster Cheesemaker Kerry Henning and his crews have shown their penchant for trying new cheese flavors. Their journey has taken them beyond the mundane to cheeses that\n“All of the cheese made here is good cheese. We want to open peoples senses up to appreciate the varying flavors that add to the taste experience,” Kert Henning said.\nFinding that right flavor takes a lot of tweaking and experimentation. While all the flavored cheeses work off the same quality Henning’s Cheese base, the process involves several factors—coming up with the right ingredients and learning the right aging window for each variety.\n“Sometimes it takes six months to a year for a new flavor that Kerry is working on to be ready for the market,” Kert said.\nSmall batches are hand worked when a new flavor is tried. Then, the cheesemaker has to let the aging process take over. “Some cheeses taste different at three months than they do at six months. What might not peak at three months opens up to a whole new set of flavors when you try it again at six months,” he added.\nPeppers top the list\nIn the process of working out new flavors, Henning’s Cheese has developed several successful flavors using peppers.\nRight now, hot peppers seem to be the rage in the industry.\n“For some people you can’t get it hot enough,” Kert said.\nWhether its jalapeño, habañero or hatch pepper, Henning’s tries to find the right blend to fit the tastes of the marketplace.\nStill, there are always those markets who favor things even hotter than can be made in the Midwest. At the request of one customer, Henning’s made a batch of cheese using scorpion pepper—one that grades out above ghost pepper on the Scoville scale for “heat.”\nThe pepper is so volatile that it vaporizes when placed on cheese in a vat. To create the cheese, the vat crews had to wear gas masks, rubber gloves and aprons. The scorpion pepper was so volatile that any expose skin would literally be burned by the heat.\nThat’s when the master cheesemaker said, “No more scorpion pepper.”\nHenning’s Cheese still serves the needs of those clients that like it hot, but they work with safer ingredients to generate the heat.\nFlavors that don’t bite back\nIn addition to its peppered cheeses, Henning’s Cheese also produces flavors that don’t bite back.\nItalian and Mediterranean spicings are popular. A tomato basil flavored cheese is fun on its own, but also makes for great pizza and Italian food recipies.\nCheese flavored with onion, chives or dill can be used on any kind of sandwiches, but they sure give new zip to the average cheeseburger.\nFor the consumer, it’s all about experimenting with different flavors. That means being able to think creatively in the kitchen. Cheeses with flavors can be used as substitutes for traditional ingredients in many recipes.\n“Sometimes people are too worried about following a recipe to the letter. A flavored cheese allows them to proceed in the spirit of the recipe, making it possible to develop a more intriguing taste to their foods,” Henning said.\nSome cheeses tickle the palate with sweetness. Such is the Henning’s blueberry cobbler cheese, which stands on its own as close to dessert as cheese can get.\nThrow it in pancakes or a grilled cheese sandwich and you have just upgraded your breakfast and lunch.\nAt holiday time, Henning’s cant keep its cranberry orange cheese on the shelves. New this year, the cheese was a big hit. “It had a phenomenal flavor,” Kert said.\nCheese fans can also make their recipes work better with quality cheese. A quarter cup of traditional sharp cheddar will go a lot father to enhance a recipe than the low fat cheese called for in a recipe that calls for a lot more cheese.\n“It’s a way to get more from less, and the palate changing experience is amazing,” Kert said.\nMeanwhile back in the cheese room, one never knows what the mind of the master cheesemaker will conjure up next.\nBeyond its traditional cheddar and low fat cheeses, Henning’s Cheese still gets a lot of inquiries for a cheese variety that dates back more than 60 years, to Otto Henning’s era.\nThe Colby longhorn, “the way grandpa used to make it,” is one of those treats common to cheese lovers who frequent Henning’s Cheese.\nMade in individual forms, the longhorns are formed with cheese cloth around the outsides then hand-dipped in was.\n“The flavor profile of this horn is so different from regular Colby. It still has holes all over it, which makes it more interesting. There is just no comparison in the taste,” he said.\nAged cheeses gain popularity\nIn addition to throwbacks like the longhorns, Henning’s Cheese has seen a growing interest in aged cheeses. The warehouse stock of older cheeses, four years and up has grown exponentially in recent years.\nThe aged cheeses, longhorns and flavored cheeses might not all be found on the shelves of the local grocery store, but they aren’t far from home either.\nOut on Point Creek Road, near Wilke Lake, Henning’s Cheese operates its cheese store and museum as a source for people who want to savor the flavor on all levels.\nThe store is open Monday through Friday from 7 a. m. to 4 p. m. and on Saturdays from 8 a. m. to 2 p. m.\nThe Henning’s Cheese store is a great place to find all of the Henning’s flavors, and all of the aged varieties of cheese. But, it’s a whole lot more, as Henning’s also brings in some specialty cheeses from other cheesemakers to round out the selections. Most are made right here in Wisconsin, and might include varieties like aged brick cheese, bleu cheeses, various Sartori cheese selections, cooked cheese. One of the most unusual selections is a German hand cheese, an import which is gauranteed to “change the aroma of your refrigerator” when you bring it out of frozen storage to thaw it out.\nHenning’s Cheese also offers some variations of cheese that the company purchases and repackages.\nWhile shopping for your favorite cheese at the Henning’s Cheese store, customers can also browse through the selection of wines, cheese souvenirs and trinkets, specialty meats and snacks, including ice cream and speciality popcorn products.\nAlways popular, Henning’s cheese curds are available every day, depending on the cheese making schedule. Call ahead to 894-3032 to find out when the fresh curds hit the counter.\nPerhaps the best opportunity of all awaits the visitor who wants the “full cheese” experience can be found in the cheese making museum which adjoins the store.\nCheese making and other dairy manufacturing equipment from days of old is on display in the spacious museum room. As an added attraction, the room contains two large window bays that allow visitors to watch the cheesemakers as they go about the business of producing some of Wisconsin’s finest cheese.\nHenning’s Cheese is located at 20201 Point Creek Road, northeast of Kiel.\nYou can find them on the web at henningscheese.com.', 'Artificial Chemicals and Additives in Food\nA dizzying array of chemical compounds is used in modern food. Artificially manufactured dyes, preservatives, flavors, texture-enhancers, and fats are used to alter the way food looks, tastes, and feels. Considerable debate has raged over the long-term safety of chemical food additives, which are regulated by the Food and Drug Administration (FDA) in the United States. The FDA allows the addition of non-nutritive substances to food so long as the added chemicals are “generally recognized as safe (GRAS).” Certain additives have been banned over time as their toxic natures have become more evident.\nRegulation of Food Additives: A Brief History\nPrior to the formation of the FDA, artificial additives to food were not regulated. Borax was used in many foods as a preservative, and lead salts were used to give cheese a bright orange color. Sulfuric acid was dumped into beer to decrease the brewing time. Since refrigeration was difficult to obtain in the early 20th century, formaldehyde (embalming fluid) was added to milk to prevent curdling.\nButchers sold rotten meat, disguising it by using a mixture of boric acid, salt, and a red dye from the cochineal beetle so the putrid meat would appear fresh enough for purchase by an unwitting consumer. It isn’t surprising that more than a few food scandals erupted. Russel Alger (the Secretary of War under William McKinley) was forced to resign after formaldehyde-laden beef was fed to U.S. troops during the Spanish-American War. The troops became so ill that they could not fight.\nThe Poison Squad: Testing Chemicals in Food\nCongress finally granted $5,000 to study the effects of various food additives on people. Dr. Harvey Wiley, the head of the Bureau of Chemistry (part of the USDA, which later became the FDA) spearheaded the study using a group of twelve brave volunteers known as the “Poison Squad.” These men were fed some of the common food additives of the day (borax, salicylic acid, sulfuric acid, sodium benzoate, and formaldehyde) in controlled doses mixed into their food. The volunteers consumed the additives in gelatin capsules (not knowing which capsules contained additives and which were placebos) and were subjected to medical examinations each week. The men consumed the additives for a period of five years and agreed not to sue the researchers for any ill effects obtained during the study.\nThe publicity garnered by Wiley’s experiments (and the resultant health problems in the volunteers) helped to launch the Pure Food and Drug Act of 1906: borax, copper sulfate, formaldehyde, and salicylic acid (aspirin) were banned as food additives due to their toxic nature. The law was expanded in 1938 to become the Federal Food, Drug, and Cosmetic Act. Additives could not be added to food unless they were found to be safe, and chemicals could not be added to food to mask ingredients that were unfit for human consumption.\nLaws regulating food purity and safety are not always followed. In 1992, the grocery chain Food Lion was infiltrated by ABC news. In an undercover exposé, Food Lion employees were shown to re-wrap and re-label meat which had passed the expiry date. Rotten meat was also rinsed in bleach to remove the putrid stench prior to sale. In response, Food Lion sued ABC for fraud, claiming they had misrepresented themselves as employees. The lawsuit also alleged trespassing, since the news reporters came into the Food Lion plant without permission. The grocery chain was awarded $5 million in damages, though a later appeal to the U.S. Court of Appeals (Fourth Circuit in Richmond, Virginia) overturned the verdict.\nWhy Sodium Bisulfite Was Banned on Fresh Produce\nSodium Bisulfite is an anti-oxidant, and is banned by the Food and Drug Administration for use on fresh produce. Sodium Bisulfite causes a high number of allergic reactions, which range from hives to respiratory complications. The most severe form of an allergic reaction is known as ""anaphylactic shock,"" which can lead to death. Up to 8% of all asthmatics are sensitive to sulfites - over 500 serious allergic reactions were reported to the FDA, instigating a medical investigation into the additive ""generally regarded as safe."" The review found that 13 deaths were attributed to the use of sodium bisulfite.\nWhile only 40% of the complaints were associated with fresh produce (the remaining complaints were from reactions to beer and wine, which also contain sulfites), the FDA focused on the largest single instigator of sulfite-induced allergy attacks: fresh produce. Sodium bisulfite is now regarded as hazardous and is banned from use on raw fruits and vegetables.\nBHA: Butylated Hydroxyanisole (BHA) is a white or yellow waxy solid, and is added to food as an anti-oxidant. BHA is fat-soluble, and reacts with oxygen in a preferential manner over the food it is added to, preventing spoilage in fatty foods.\nBHT: Butylated Hydroxytoluene (BHT) is similar to BHA: it is an anti-oxidant and is added to food to prevent spoilage. BHT is a white powder and will preserve the flavor and color characteristics of fatty foods.\nCalcium Propionate: This preservative acts as an anti-microbial agent and a fungicide, and is commonly added to bread products. It is also added to meat and dairy products to prevent spoilage. This chemical works by preventing microbes from using energy: it is considered “slightly toxic” and may also be used as a pesticide. It must be noted, however, that Vitamin C (ascorbic acid) is also considered “slightly toxic,” so this rating is often applied to food additives.\nSodium Nitrate: Sodium nitrate has many uses: it is used in enamels for ceramics, in propellant for rockets, and is also used in the “smoke bombs” sold at fireworks stands. It is a common preservative used in cured meats: the chemical breaks down into nitrosamines – a human carcinogen. Alzheimers, Parkinson’s Disease, and gastric cancer are correlated with the consumption of Sodium Nitrate and Sodium Nitrite (below). Hot dogs, along with many lunch meat products, contain this chemical. Sodium Nitrate was originally mined in Chile, where it is bound with mineral deposits (the mineral-Sodium Nitrate complex is called caliche). It is now synthetically manufactured in laboratories by adding washing soda (sodium carbonate) to nitric acid.\nSodium Nitrite: Sodium Nitrate is used as an anti-microbial agent. It is recognized as toxic, and is dyed bright pink when used as a food additive, so that it cannot be confused with regular table salt or sugar. The chemical can be deadly: if a 150 pound person ate 4.85g of the chemical, the result would be lethal (LDlo 71mg/Kg). Sodium nitrite works by reacting with DNA, which causes either cancer or cell death. The artificial ingredient is added to meat and fish – giving the meat a pinker color (due to the dye used in the Sodium Nitrite raw material) and preventing the formation of botulism. On an interesting note, Sodium Nitrate has found a medical use as an antidote to cyanide poisoning. It is also used as a poison to cull wild boars in Australia.\nSulfur Dioxide: Found in nature, sulfur dioxide is often released in volcanic eruptions. Sulfur is also commonly found in petroleum products, and sulfur dioxide can be obtained by combustion. It is used primarily in dried fruit, and prevents discoloration and rot. The chemical is also added to wine (in small amounts) to prevent oxidation: oxidized wine turns into a rather unpalatable vinegar. To determine if a bottle of wine contains sulfur dioxide, look for the term “contains sulfites” on the label. Sulfur dioxide is correlated with premature births and with respiratory problems.\nSodium Bisulfite: This chemical is often added to canned fruit to prevent discoloration. Under the trade name LeafGreen, it is also added to lettuce in restaurant salad bars, to keep the produce looking bright and green. The use of sodium bisulfite on raw produce is banned in the United States, because it can be lethal in high doses.\nPotassium Hydrogen Sulfite: Like the other sulfuric compounds, Potassium Hydrogen Sulfite is used as an anti-microbial (anti-oxidant) and is used in the production of alcoholic products.\nDisodium EDTA: Disodium EDTA is known as a chelating agent, because it can bind heavy metal ions. It is used in a medical setting to counteract lead or mercury poisoning. Since Disodium EDTA is an anti-oxidant, it is often used in food products to prevent discoloration and spoilage.\nPropyl Gallate: Another anti-oxidant, propyl gallate is added to fats to prevent spoilage. It is a white powder, and can be found in a diverse range of products. Microwaveable popcorn, bubble gum, frozen “TV” dinners, and mayonnaise are all items preserved with propyl gallate.\nDanger for Manufacturers of Microwave Popcorn\nThe Occupational Safety and Health Administration (OSHA) has issued a Hazard Communication Guidance for workers who manufacture products containing diacetyl, the artificial butter flavor in microwaveable popcorn. Employees exposed to high doses of diacetyl have demonstrated a respiratory disease known as bronchiolitis obliterans, which causes permanent lung damage. Some workers have been placed on lung transplant waiting lists: OSHA now requires respiratory protection for workers in microwave popcorn packaging plants. There is no established permissible exposure limit (PEL) for diacetyl.\nThe Flavor Industry\nSitting amongst the heart of industrial New Jersey, the world\'s largest flavor company (International Flavors and Fragrances) produces a wide variety of artificial flavors in food. The company has multiple labs: from ""snack-and-savory,"" where artificial flavors for chips and breads are manufactured, to ""confectionery,"" which manufactures flavors for everything from toothpaste to ice cream.\nLab technicians in white coats mix vials of chemicals in specific (and highly secretive) formulations to achieve unique flavors. The majority of artificial flavors are created from compounds which generate esters. Esters are highly aromatic chemicals that carry the generic chemical formula of R-COO-R\'. For example, an artificial raspberry flavor can be created by mixing Isobutanol with Formic Acid: these two chemicals will give rise to the ester Isobutyl Formate, which has a strong raspberry flavor and scent.\nCommon Artificial Flavors\nGummy candy, drinks\nImitation almond extract\nChewing gum, candy\nPear tea, pear cider\nEnglish toffee, candy\nImitation vanilla extract\nChewing gum, candy\nBanana cakes, candy\nCandy, grape drinks\nChewing gum, mints\nList of Artificial Colors Used in Foods\n- FD&C Blue No. 1, Brilliant Blue, FCF, E133\n- FD&C Blue No. 2, Indigotine, E132\n- FD&C Green No. 3, Fast Green, FCF, E143\n- FD&C Red No. 40, Allura Red AC, E129\n- FD&C Red No. 3, Erythrosine, E127\n- FD&C Yellow No. 5, Tartrazine, E102\n- FD&C Yellow No. 6, Sunset Yellow FCF, E110\n- Orange B: Used only in hot dog and sausage casings\n- Citrus Red 2: Only for coloring orange peels\nDifferences in Food: Pop Tarts in Europe vs. the U.S.A.\nCommon Food Dyes\nOf all the artificial food additives, artificial color serves the least amount of purpose. It does not preserve food or enhance flavor in any way. Artificial color in food simply makes food more enticing to eat - without artificial color, hot dogs would be gray. Farmed salmon has a pink dye added to make the filets red. Everything from children\'s vitamins to candy (""Taste the Rainbow!"") have artificial color.\nMany artificial food dyes are manufactured from coal tar or petroleum products. Blue No. 1, for example, is manufactured from coal tar and can be found in some dairy products and in sweets. This dye has been banned in the European Union, but is acceptable in the United States. Red No. 3 is another dye manufactured from coal tar, and is often used in cherries.\nYellow No. 5 (tartrazine) has been subjected to many studies which link artificial coloring agents to Attention Deficit Hyperactivity Disorder. A 1996 study in the Journal of Nutritional & Environmental Medicine (Journal of Nutritional & Environmental Medicine (1997) 7, 333±342) demonstrated increased activity levels and aggression in children with ADHD who consumed beverages laced with tartrazine and sunset yellow (Yellow No. 6). Beverages laced with amaranth (a red dye, currently delisted by the FDA because of suspected carcinogenic properties) did not show an increase in hyperactivity.\nSeveral food dyes have been delisted, including Orange No. 2 (previously used to color Florida oranges) and FD&C Violet No. 1. Orange No. 2 was delisted after animal toxicity studies showed the dye was, indeed, toxic. Violet No. 1 was delisted in 1973 after it was found to produce cancer in rats.\nDelisted Dyes: A Brief Synopsis\n- FD&C Red No. 1 was delisted in 1960 because it caused liver damage in dogs, rats, and mice.\n- FD&C Red No. 4 was delisted in 1965 after laboratory studies demonstrated damage to the adrenal cortex and urinary bladder in dogs. The chemical was still allowed for use in maraschino cherries until 1976.\n- FD&C Green No. 1 and FD&C Green No. 2 were delisted in 1966: the dyes were not necessarily harmful to health, but were simply unnecessary (green dye can be made by mixing tartrazine with a blue dye).\n- FD&C Violet No. 1 was delisted in 1973 due to suspected carcinogenic properties (studies showed the dye produced cancer in lab rats).\n- Carbon Black was delisted in 1975 because of carcinogens released during the manufacturing process. The artificial colorant is still allowed in Canada.\n- FD&C Red No. 2 was delisted in 1976 after studies showed it was a carcinogen in rats. Studies performed in Russia also demonstrated the dye was an embryotoxin.\n- Graphite was delisted in 1977. Graphite contains aromatic hydrocarbons, which are known carcinogens.\nPotassium Bromate is added to flour to create a high-rising bread dough with a springy texture. When added in extremely small amounts (15-30 parts per million), the bromate is “used up” in the baking process, leaving no residual chemical in the bread. If it is used in higher quantities, or if the bread is not cooked at the right temperature, potassium bromate will remain in the finished product. Potassium bromate has been shown to induce tumor formation in rats. The FDA has not banned the additive, but has suggested that bakers stop using the chemical on a voluntary basis.\nPotassium bromate has been banned in the United Kingdom and Canada. Since the state of California lists bromate as a carcinogen, bread products must be labeled with a cancer warning if they contain potassium bromate. For this reason, nearly all bread products sold in California are bromate-free.\nCommon Fat Substitutes\nOlestra was developed by Proctor and Gamble, and approved by the FDA in 1996. The chemical had the same general properties of natural fats: it provided a rich taste and mouthfeel, but passed through the digestive system without being absorbed. Olestra is a synthetic chemical manufactured from sucrose (table sugar), and is able to bond to a number of fatty acids. The resultant molecule is extremely large, and cannot be absorbed in the intestines – because of this property, it adds no calories or nutrition to food.\nUnfortunately, the side effects of Olestra caused many people to stop purchasing the product. The chemical additive caused intestinal cramping and diarrhea, and would also bind any natural Vitamin E, Vitamin D, and Vitamin K consumed during the meal. The chemical is banned in the United Kingdom and Canada.\nDue to a large drop-off in sales, Proctor and Gamble is now marketing Olestra as a lubricant for industrial use and as an additive for paint. The chemical has been renamed “Sefose” for this purpose.\nCommon Artificial Sweeteners\nA number of artificial sweeteners are used in place of natural sugar in processed foods. Here are some of the more common examples you are likely to run into.\nAspartame has come under a great deal of scrutiny, as a widely circulating “chain mail’’ style of email claimed the artificial sweetener caused diseases ranging from Multiple Sclerosis to Alzheimer’s Disease. The original email is ascribed to a “Nancy Markle,” though the name is likely fictitious. A very similar health scare rumor letter was penned in 1995 under a different screen name. While chemical additives to food are controversial, there has been no evidence that aspartame has caused the great diversity of medical problems stated in the email chain letter.\nAspartame is dangerous to those suffering from phenylketonuria (PKU), and anyone who has this genetic disease should avoid the consumption of Aspartame.\nAspartame is a non-saccharide sweetener, made from aspartic acid/phenylalanine dipeptide. The sweetener was subjected to a medical review in 2007, and found to be safe. Of all the artificial sweeteners on the market, aspartame is the most studied and tested on the market. While some critics maintain the FDA is biased in its studies, the entirely independent Government Accountability Office (GAO) found the FDA’s rulings to be accurate and the study methods to be properly conducted.\nDiscovered in 1967, most people are unaware that this artificial sweetener exists. With a chemical structure similar to saccharin, the acesulfame-K (K is the chemical symbol for potassium) is stable through heating processes and is calorie-free. The product is added to chewing gum, sugar-free Jell-O, and some “Lite” chocolate syrups. Approved by the FDA in 1988, the sweetener has been studied many times and has not shown any carcinogenic effect. Acesulfame-K is allowed in the United States and in the European Union.\nThe only sweetener to have carried an active warning label, saccharin demonstrated an increase in bladder cancer rates among male laboratory rats. The artificial sweetener was added to the U.S. National Toxicology Program’s “Report on Carcinogens” in 1981. The increase in bladder cancer could never be demonstrated in a human population, and further studies determined the increase in bladder cancer rates were due to a unique mechanism found in male rats. While saccharin is a carcinogen for rats, it will not increase bladder cancer rates in humans. The chemical was delisted from the “Report on Carcinogens” on December 21, 2000. The warning labels were taken off the product, as the danger did not apply to human consumers.']"	['<urn:uuid:378c759b-edbe-4ac6-a4ca-ef12505225ba>', '<urn:uuid:ae5e06f4-9e98-41c2-bf27-1751c752dd09>']	factoid	direct	long-search-query	distant-from-document	multi-aspect	novice	2025-05-12T23:56:45.148498	8	63	4200
64	Which pollutes more: a plane tire or a car tire?	Car tires are significantly worse polluters than plane tires when it comes to microplastic pollution. While planes contribute only 2% of global tire microplastic pollution, cars create the majority. These tire particles are primarily made from synthetic plastics and are generated through friction between roads and tires. They can be transported by winds across the globe, with about 52,000 tonnes settling in the ocean annually. The particles vary in size between 5 millimeters and 1 micrometer, and their production depends on factors like tire type, road surface, vehicle characteristics, and driving conditions.	['Both cars and planes are awful polluters. But if you’re planning a trip and the less polluting alternatives — train or bus — aren’t options, which should you choose: driving or flying?\nThere are many considerations when traveling, including time, money, the number of people, and whether or not kids are involved. But if you’re deciding between traveling by car or by plane, based solely on environmental impact, which one is least harmful? We looked at two criteria for determining the better option: emissions and microplastic pollution from tire wear.\nEnvironmentalists have been worried about carbon emissions for years now — it’s why electric vehicles are so popular and why Google allows you to search for flights based on carbon emissions. But there’s more to emissions than just carbon, so here’s a quick refresher of the terms relevant to cars and planes.\n- Greenhouse gas (GHG) refers to atmosphere-warming gases. NASA lists five as influential on anthropogenic (human-caused) global warming.\n- Carbon dioxide (CO2) is the most well-known greenhouse gas and the primary GHG emitted by human activities. It can last for centuries in the atmosphere.\n- Methane (CH4): While its warming effects in the atmosphere last only about 20 years, this GHG is up to 80 times more powerful at trapping heat than CO2.\n- Carbon dioxide equivalent (CO2-eq or CO2e): This refers to the number of metric tons of carbon dioxide equal to 1 metric ton of another greenhouse gas in warming capability. This calculation is what we use to compare primarily CO2-emitting cars (99% CO2) to multiple GHG-emitting planes (CO2, CH4, and more).\nThe travel method that produces the least emissions in this race will be determined by CO2/CO2-eq per passenger.\nDriving vs Flying Emissions\nOur data will focus on averages, but the equations and sources below will show you how to figure out calculations for your own trip.\nFor car emissions, we’ll use the US fuel economy calculator, which you can use for your planning. For plane emissions, we’ll use Google’s flight emissions calculator as listed on its booking search. However, a plane’s carbon emissions account for only about one-third of its total emissions, and Google recently neutered its flight calculator to calculate only CO2 and ignore other GHG. Because of the recent change, the UK government recommends multiplying Google’s flight emissions data by 1.9 to determine the total emissions of a flight — this is a long-agreed-to multiplier to assess total emissions. Most travel sites also list Google’s emissions data.\nFactors that we consider in this comparison include the number of people traveling, type of vehicle, and distance of travel (short trips vs long trips). Google also accounts for the size and type of aircraft in its data. Lastly, regular unleaded fuel is used in this comparison.\nCar and Trip Comparisons\nWe’ve picked two cars and two trips to compare driving vs. flying. Gas guzzler and fuel-efficient, long and short distances. The cars and their emissions are:\n- 2021 Honda Insight Hybrid. It gets 52 miles per gallon city and highway combined and emits 170 grams of CO2 per mile.\n- 2020 GMC Yukon 4WD. It gets 17 miles per gallon city and highway combined and emits 525 grams of CO2 per mile.\nThe two trips are:\n- Los Angeles to New York City: Google Maps says it is 2,789.3 miles on a preferred route through the upper Midwest and takes 42 hours of continuous driving, so not exactly realistic, but a good benchmark.\n- Minneapolis to Milwaukee: It is 336.5 miles and takes a little over five hours to drive.\nEmissions Results of Flying vs Driving\nFor our flying trips, we picked nonstop direct and the lowest emissions option. This is the minimum, best-case scenario for flying.\nWe’ll also multiply Google’s stated emissions by 1.9 to get the flight’s CO2e. The data listed are per passenger, which decreases as the number of car passengers increases.\nFor flights, the number of passengers doesn’t change the results because the data are already listed per passenger. However, while flight emissions per passenger stay the same, the total amount of emissions increases for every person added.\nLA to NYC\nFor this trip, we’re using a nonstop Spirit Airlines flight that takes a little over five hours.\nInsight (kg of CO2)\nYukon (kg of CO2)\nPlane (kg of CO2e)\n|2 Passengers||237.09||732.19||752.4 (376.2 x 2)|\n|4 Passengers||118.54||366.09||1,504.8 (376.2 x 4)|\n|8 Passengers||NA||183.04||3,009.6 (376.2 x 8)|\nMinneapolis to Milwaukee\nFor this trip, we’re using a nonstop Delta flight that takes 1 hour and 27 minutes.\nInsight (kg of CO2)\nYukon (kg of CO2)\nPlane (kg of CO2e)\n|2 Passengers||28.6||88.33||250.8 (125.4 x 2)|\n|4 Passengers||14.3||44.16||501.6 (125.4 x 4)|\n|8 Passengers||NA||22.08||1,003.2 (125.4 x 8)|\nAs you can see, from an emissions perspective, flying is almost always the more environmentally damaging option.\nWildcard: Tire Pollution\nTires are one of the main sources of microplastics found in the ocean, and it would be irresponsible to compare the environmental effects of driving and flying while focusing only on GHG emissions. Microplastics are now found on newly formed volcanic beaches, at the top of mountains, and in human breast milk. While we are not fully aware of all the damage microplastics do, we know that they lead to both ocean acidification and biodiversity loss through toxin leaching.\nThese days, tires are made primarily from synthetic plastics rather than rubber, and microplastics are created from friction between roads and tires. Planes contribute only 2% of global tire microplastic pollution, with cars creating the majority. Microplastics range in size between 5 millimeters and 1 micrometer, and they move with the winds and the oceans.\nWe are comparing toxic gases and toxic solid objects here, which is a little like comparing poisonous apples with poisonous oranges. It doesn’t work. But at the same time, this discussion would be lacking if microplastics weren’t mentioned. Our planet is interconnected, and climate change is not a problem alone on an island. Biodiversity loss, ocean acidification — these things all go together.\nSo, Which Should You Use, a Plane or a Car?\nAs you can see, both are damaging in their own ways. For short-haul trips covered in a day or less, cars are preferable. But for the long haul as a solo traveler, planes are more efficient.\nAnd regarding the microplastic problem, companies are working on plastic-free and low-plastic alternatives. There are almost plastic-free tires and plastic-free rubber options. But to butcher a Mark Twain quote, the difference between plastic-free and almost plastic-free is the difference between lightning and the lightning bug.\nThe best thing you can do though is talk about this during your planning, and use some of the tools mentioned in this article. When you talk and share your thoughts about these things, the effects can be exponential. Because our planet will be here for a long time — whether or not it’s livable for us, that’s another question.', 'Each day, millions of vehicles release microscopic particles of polymers generated by the friction between tires and the road. Some of these particles are so small and light, they’re easily carried by atmospheric winds across the globe. According to a new study, as much as 52,000 tonnes of road-traffic-sourced microplastics carried by winds settle in the ocean every year, with dire consequences for marine life.\n“The reason why we wanted to do research to answer this scientific problem was that, although transport of microplastics (MPs) via runoff and wash-out processes to the marine and/or freshwater ecosystem has been studied extensively, very little is known about how these particles are dispersed in the atmosphere and where they are deposited. This is important due to their health impact in animals and humans, but also due to their affinity to absorb organic compounds and heavy metals increasing their toxicity,” Nikolaos Evangeliou of the Norwegian Institute for Air Research (NILU), lead author of the new study, told ZME Science.\nMuch talk about the environmental impact of tires is focused on their manufacturing. Typically, tires are derived from ethylene and propylene, for which production generates significant greenhouse gas emissions. At the end of their lifecycle, tires often end up in landfills polluting the environment.\nHowever, tires also produce important pollutants during their operation. Due to their constant wear and tear, tiny particles of rubber, fibers, and other organic and inorganic materials are generated and transported via atmospheric currents far away from their source.\nSuch particles have been previously detected in highly remote areas of the globe — even as far away as the Arctic, where their deposition can decrease the surface albedo effect and accelerate the melting of ice.\nIn their new study, Evangeliou and colleagues wanted to quantify just how much of these microplastics circulate through the world’s atmosphere on a yearly basis.\n“The biggest surprise when conducting this study, which is actually the biggest challenge for the future, is that lack of atmospheric measurements of MPs. Although there are some, they only present number concentrations and only for particles larger than 20 micrometers, which are less labile and less vulnerable to long-range transport, and hence, they cannot travel to long distances from the main source regions. For the record, here we study particles with a size smaller than 10 micrometers. However, many groups are currently working to solve the problem of proper sampling and analysis of MPs and many methodologies are being tested,” Evangeliou told ZME Science.\nThe particles targeted in the new study are known as non-exhaust traffic-related particles (NETP). They are released due to mechanical abrasion and corrosion, as well as the resuspension of already deposited particles due to turbulence from traffic (Evangeliou calls this “the grasshopper effect”).\nNETPs are not only generated by the wear on tires, but also by wear on the clutch and engine, abrasion of bearings, and corrosion of various vehicle components.\n“For the tire wear particles (TWPs), the wearing process depends on the type of tire (i.e. size, tread depth, chemical composition, accumulated mileage, set-up), road surface (i.e. material, porosity, condition, maintenance) and vehicle characteristics (i.e. weight, location of driving wheels, engine power), as well as on vehicle’s state of operation (i.e. speed, acceleration, frequency and extent of braking and cornering),” Evangeliou explained.\n“Brake wear particle (BWP) emissions depend on the bulk friction material, on the frequency and severity of braking (driving conditions), while speed, condition and maintenance of the automobile can also be important. Another key factor that affects BWP emissions severely\ndeals with the environmental conditions during the braking (temperature and environmental compounds present in the road).”\nTogether, TWPs and BWPs constitute around 1.8% of the total plastic production, according to a 2017 study.\nThat might not seem like a lot, however, tire wear microplastic emissions alone account for roughly 30% of all microplastic pollution in freshwater and oceanic ecosystems. Most of it is sourced in the eastern US, Northern Europe, and the heavily urbanized areas of Southeast Asia.\nAs much as 52,000 tonnes of these microscopic particles smaller than 2.5 microns end up in waterways and the world’s oceans every year, according to the new study published in Nature Communications. An additional 20,000 tonnes of microplastics associated with road and vehicle wear are deposited in remote ice-covered regions of the world, where they drive more melting.\nAlthough PM10 (microplastic particles 10 micrometers in size or smaller) are less susceptible to long-range airborne transport than PM2.5, traffic-related emission generates roughly 10 times more such emissions. PM10 particles tend to stay closer to their source — in most situations, that’s urban environments where they can contribute to adverse health effects, particularly those affecting the lungs like asthma.\nThe exact impact that traffic-related particle emissions have on the climate is currently unknown, but this is something that may be addressed by research in the future.\nIn the meantime, this study is a perfect illustration of how very small things can add up to produce a significant impact on the planetary level.']	['<urn:uuid:88498831-afa2-4c72-b73b-0450406a8bff>', '<urn:uuid:69088220-6d4d-40d8-8eda-5bd054e2c727>']	open-ended	with-premise	concise-and-natural	similar-to-document	comparison	novice	2025-05-12T23:56:45.148498	10	92	1984
65	want photograph people without posing what style is this photography called	This style is called candid photography, where the subject is not in a controlled position or is unaware of the camera, resulting in more natural and spontaneous-looking pictures.	['There is a term in photography, candid shots, where the subject of the photograph is not in a controlled position or unaware of the camera (photo coverage). The resulting picture looks more natural, spontaneous, and less contrived. The following are tips for successful candid photography:\n1. Bring your camera everywhere. Be ready to shoot at any time because an interesting moment may be just around the corner.\n2. Pay close attention to your surroundings. The simplest things may become interesting objects to shoot. These may be a daydreaming store owner, people waiting for their train, the elderly, someone sitting next to you, a couple of lovebirds. The possibilities are endless. Read the rest of this entry » .\nRelated Photography Ideas for street shots at OneSlidePhotography.com\nThis video will help you set up and understand the different settings in your Nikon D7000. I walk you through each step of the way while interjecting how I would set up the menu if I owned the camera. If you have a Nikon D90 this video will also help you set up your camera […]\nFor those of you new to photography, shopping for a new camera can get quite confusing. Oftentimes beginners or amateurs of photography spend countless hours in the store and still end up buying the wrong product (not what’s right for their needs) because lack of knowledge and information. In order to obtain the right digital […]\nNowadays, a camera phone is something of a daily staple in our lives. The quality of images these camera phones can also be compared to dedicated compact pocket cameras. But not many knows of the history of how the camera phone came to be. Officially, the first camera phone recorded was a prototype developed in […]\nIt can be said that sensor is the heart or the center of your camera. Image sensor plays a fundamental role in digital photography, so knowing and fully understanding the key character of sensor will be very helpful for you in photography when you deal with digital camera. What should we know about an image […]\nEven though I almost always shoot in RAW files, especially in client photo shoots, there are times when it’s better to record using the JPEG format. (Read RAW vs JPEG). The advantage of the JPEG format, besides its smaller file size,, are also that they are quite suitable for those new to photography. Why?\nAs a photographer, whether it be as an amateur or a professional, you’ve probably experienced difficulties and failures in your work. With preparation and experience, it may well be avoided. What are these worst case scenarios that photographers need to prepare for? The following are several examples of cases and how to avoid these worst […]\nWho doesn’t know instagram these days? This photo-processing app is installed in almost every smart phone all over the world. The way it works is simple. This app adds various filters (most of which are vintage-inspired) on photos taken with the phone’s camera, then it uploads it onto its built-in social website. It’s for certain […]']	['<urn:uuid:13d9c3f1-9f9f-46db-a954-6e7c412021bb>']	factoid	with-premise	long-search-query	distant-from-document	single-doc	novice	2025-05-12T23:56:45.148498	11	28	516
66	traceability systems seafood supply chain requirements	Traceability systems must allow fish to be tracked from net to plate, accompanied by evidence showing it was caught legally and ethically. These systems should be backed up by third party audits, which focus on the areas of the supply chain with the highest risks.	['We’re on a roll: EJF’s Charter for Transparency gains momentum as M&S and Waitrose sign up\nEJF’s Charter for Transparency is gaining real traction as Marks & Spencer and Waitrose & Partners become the latest major retailers to sign. They join the Co-op, Sainsbury’s and Tesco in making a commitment to ensure their seafood supply chains are free from illegal fishing and human rights abuse. Together these five companies represent a significant majority of grocery sales in the UK and their actions will lead to meaningful change.\nSupermarkets are a vital part of ensuring that the seafood we eat was caught legally, ethically and sustainably. And thanks to EJF’s supporters signing our letter urging retailers to take up the transparency cause, many big hitters have answered the call.\nThe lack of transparency in the global seafood industry means that illegal fishing is rife, costing the global economy an estimated US$10 - 23.5 billion every year and threatening food security in some of the world’s poorest nations.\nAs fish stocks fall, so does income from the vessels. To scrape a profit, some companies exploit workers, engaging in violent human rights abuses and employing forced, bonded and slave labour. EJF has documented shocking abuse aboard fishing vessels across the world – from slavery to murder – all facilitated by the lack of transparency.\nThe charter includes detailed recommendations retailers can use with suppliers to make sure no boat associated with illegal or unethical practices taints their supply chain.\nCentral to this is the use of traceability systems that allow fish to be tracked from net to plate, accompanied by necessary evidence showing it was caught legally and ethically. These should be backed up by third party audits, focused on those areas of the supply chain with the highest risks.\nIn addition, supermarkets have a powerful voice that they can use to call on governments to make critical reforms. The charter calls on them to support the adoption of EJF’s ten principles for global transparency in the fishing industry.\nHaving major retailers sign the Charter for Transparency is a vital opportunity for real change all along supply chains. It gives supermarkets the tools to develop effective risk mitigation policies and processes in place, backed by truly independent verification.\n“We have been working on responsible seafood sourcing for over 20 years, only sourcing fish from fisheries and farmed aquaculture operations that are responsibly managed and fully traceable,” said Sam Ludlow Taylor, Waitrose & Partners’ Ethical Trade Manager. “Our leading approach to responsible fishing extends to the welfare conditions of all workers in our supply chain as their well-being is equally important to us. By signing this charter, further safeguarding measures will be implemented to ensure all workers are operating within a safe and ethical environment, as well as practising the high standards both we and our customers expect.”\nMike Mitchell, Fisheries Specialist at M&S, added: “At M&S, we’re committed to sourcing all our fish responsibly and we’re proud to lead the sector on transparency with our interactive supplier map, which shows where every type of fish or seafood we sell is caught or farmed. We believe collaborating with EJF and the wider industry to prevent illegal fishing will enable us to create meaningful and lasting change in seafood.”']	['<urn:uuid:e6db8c4a-7e6e-4052-8fd4-b228b1fc76d9>']	open-ended	with-premise	short-search-query	similar-to-document	single-doc	expert	2025-05-12T23:56:45.148498	6	45	544
67	correlation between student teacher relationship quality academic performance and school engagement	Strong and supportive student-teacher relationships are key to students' academic success and school engagement. Students with poor student-teacher relationships have poorer grades in school. Specifically, conflicting student-teacher relationships in kindergarten negatively correlate with students' math and language achievement from Grades 1 through 9. Additionally, positive student-teacher relationships are associated with increased motivation, school engagement, improved attendance, and reduction of problem behaviors.	['Over the past two decades, there have been significant search pointing on requirement for relationship between college students and instructors, exhibiting that these dating “enjoy a popular character regarding the growth of students’ instructional, societal, and you can psychological competencies regarding preschool, primary, and you will center-school years” (Pianta, 2001, p.1). The latest literary works provides evidence you to definitely good and you may supportive pupil-teacher relationship are key on compliment development of every pupils in universities (elizabeth.g., Hamre Pianta, 2001; Myers Pianta, 2008; Pianta, 1999), in order to kid’s instructional achievements and socioemotional advancement (Pianta, Hamre, Stuhlman, 2003; Pianta, Los angeles Paro, Payne, Cox, Bradley, 2002; Pianta, Nimetz, Bennett, 1997; Pianta Stuhlman, 2004), also to upcoming instructional experiences. Having said that, students that have worst student-teacher matchmaking features poorer grades at school (DiLalla, ). Conflicting student-professor dating inside kindergarten has actually a terrible correlation with students’ mathematics and you will language end into the Grades 1 using nine (Hamre Pianta, 2001).\nStudent-professor matchmaking also are in the https://datingranking.net/tr/cupid-inceleme/ numerous key factors in order to academic success, particularly determination and school engagement (Baker, Grant, Morlock, 2008; Pianta, 1999), school improvement (Lee, 2007; Pianta Steinberg, 1992), attendance and you will reduction of situation choices (Rosenfeld, Richman, Bowen, 2000), development of positive peer dating (Hamre Pianta, 2006; Pianta Stuhlman, 2004), socio-psychological competence (e.g. Birch Ladd, 1998; Howes, 2000; Pianta Steinberg, 1992; Silver, Measelle, Armstrong, Essex, 2005), and you can thinking on the university (e.g. Birch Ladd, 1997). Conversely, dispute (we.age. negative, discordant, volatile, and offensive scholar-teacher interactions) and you will reliance (i.age. overreliance and you may possessiveness of boy in the relationship) inside beginner-teacher relationship is one another regarding more negative thinking with the school, significantly more university protection, faster care about-directedness and less collaborative participation throughout the class (Birch Ladd, 1997). Reliance relationship also are relevant to hostile violence and you will personal withdrawal (Birch Ladd, 1997; Howes, Hamilton, Matheson, 1994). Look including reveals brand new determine away from college student-professor relationship for the variables instance college or university dropout. Even though the school dropout is extremely determined by social and you can common variables, the latest college student-teacher dating try determinant to the student decision of quitting or residing in school (Fortin, Royer, Potvin, ).\nTeachers’ sex and you can feel including seem to be highly relevant to this new student-teacher relationship, while this is shorter investigated in accordance with inconsistent overall performance\nConcurrently, confident beginner-professor relationship are very important not only for the development of children, but also for the newest health regarding coaches. With respect to the comment by Spilt, Koomen, and Thijs (2011), teacher reports regarding disagreement (we.elizabeth. negative, discordant, volatile, and you can unpleasant beginner-professor interactions) and you may closeness (i.e. love, desire, and you will discover communication) was regarding teachers’ effectiveness values. High professor-beginner argument decrease teachers’ effectiveness thinking, if you are highest professor-scholar intimacy is also improve teachers’ efficacy beliefs. Ergo educators benefit from personal relationships with youngsters and you may experience negative apply to from conflicting relationships which have pupils (Spilt et al., 2011).\nAs a result, they differ according with students’ and you will teachers’ properties. Facts shows that coaches generally have a whole lot more contradictory relationship that have men than that have ladies, and a lot more intimacy into the relationship that have females than just having boys (e.g., Kesner, 2000; Spilt, Koomen, Jak, 2012). Instructors have a tendency to create closer relationships for the youngest people, with college students inside the prior to levels (e.grams., Barbosa, Campos, Valentim, 2011; Garcia ).\nLookup as well as reveals that scholar-teacher dating utilize market, emotional and developmental attributes of some one and their logo of the relationships (Hamre Pianta, 2006)\nParticular education signify older male teachers declaration quicker disagreement, and that educators with an increase of sense statement quicker conflict and a lot more closeness (age.g., Quaglia, Gastaldi, Prino, Spaghetti, Longobardi, 2013). Alternatively, almost every other performance indicate that basic-degree teachers with a lot fewer years of sense be more tuned in to the children than just teachers with an increase of feel (elizabeth.grams., Connor, Guy, Hindman, Morrison, 2005), one lady educators declaration better relationship making use of their college students than simply men teachers, and that there are more dispute relationships anywhere between male coaches and you will men (e.grams., Spilt ainsi que al., 2012).']	['<urn:uuid:eeadb59e-bb45-498b-a477-c5a29c0b7a91>']	open-ended	direct	long-search-query	similar-to-document	single-doc	expert	2025-05-12T23:56:45.148498	11	61	724
68	why cetus dwarf spheroidal galaxy important for understanding local group galaxy evolution environmental effects	Cetus is one of the few dwarf spheroidal galaxies in the Local Group found in isolation, away from larger galaxies. This makes it particularly valuable for understanding internal evolution mechanisms of dwarf galaxies, as its properties are minimally affected by environmental effects. It is especially interesting because it does not follow the Local Group morphology-density relation, which is typical for most early-type dwarf galaxies that are usually found near larger galaxies.	['Volume 618, October 2018\n|Number of page(s)||22|\n|Published online||25 October 2018|\nInstituto de Astrofísica de Canarias, C/ Vía Láctea s/n, 38205 La Laguna, Tenerife, Spain\n2 Departamento de Astrofísica, Universidad de La Laguna, 38205 La Laguna, Tenerife, Spain\n3 Max Planck Institute for Astronomy, Königstuhl 17, 69117 Heidelberg, Germany\n4 European Southern Observatory, Karl-Schwarzschild Strasse 2, 85748 Garching, Germany\n5 Excellence Cluster Origin and Structure of the Universe, Boltzmannstr. 2, 85748 Garching bei München, Germany\n6 Institute of Astronomy, University of Cambridge, Madingley Road, CB3 0HA Cambridge, UK\n7 Instituto de Astrofísica, Pontificia Universidad Católica de Chile, Av. Vicuña Mackenna 4860, 782-0436 Macul, Santiago, Chile\n8 Millennium Institute of Astrophysics, Av. Vicuña Mackenna 4860, 782-0436 Macul, Santiago, Chile\n9 Kapteyn Astronomical Institute, University of Groningen, 9700 AV Groningen, The Netherlands\n10 Institute of Physics, Laboratory of Astrophysics, École Polytechnique Fédérale de Lausanne (EPFL), 1290 Sauverny, Switzerland\n11 GEPI, CNRS UMR 8111, Observatoire de Paris, PSL Research University, 92125 Meudon Cedex, France\nAccepted: 3 July 2018\nContext. The great majority of early-type dwarf galaxies, in the Local Group as well as in other galaxy groups, are found in the vicinity of much larger galaxies, making it hard to disentangle the role of internal versus external effects in driving their evolution.\nAims. In order to minimize environmental effects and gain an insight into the internal mechanisms that shape the properties of these systems, we study one of the few dwarf spheroidal galaxies of the Local Group found in isolation: Cetus. This system is of particular interest since it does not follow the Local Group morphology-density relation.\nMethods. We obtained Very Large Telescope (VLT) FORS2 spectra (R ∼ 2600) in the region of the nIR CaII triplet lines for 80 candidate red giant branch (RGB) stars. The analysis yielded line-of-sight velocities and metallicities ([Fe/H]) for 54 bona fide member stars.\nResults. The kinematic analysis shows that Cetus is a mainly pressure-supported (σv = 110−1.3+1.6 km s−1), dark-matter-dominated system (M1/2/LV = 23.9−8.9+9.7 M⊙/L⊙) with no significant signs of internal rotation. We find Cetus to be a metal-poor system with a significant metallicity spread (median [Fe/H]= − 1.71 dex, median-absolute-deviation = 0.49 dex), as expected for its stellar mass. We report the presence of a mild metallicity gradient compatible with those found in other dwarf spheroidals of the same luminosity; we trace the presence of a stellar population gradient also in the spatial distribution of stars in different evolutionary phases in ancillary SuprimeCam photometric data. There are tentative indications of two chemo-kinematically distinct sub-populations, with the more metal-poor stars showing a hotter kinematics than the metal-richer ones. Furthermore, the photometric dataset reveals the presence of a foreground population that most likely belongs to the Sagittarius stream.\nConclusions. This study represents an important step forward in assessing the internal kinematics of the Cetus dwarf spheroidal galaxy as well as the first wide-area spectroscopic determination of its metallicity properties. With our analysis, Cetus adds to the growing scatter in stellar-dark matter halo properties in low-mass galactic systems. The presence of a metallicity gradient akin to those found in similarly luminous and pressure-supported systems inhabiting very different environments may hint at metallicity gradients in Local Group early-type dwarfs being driven by internal mechanisms.\nKey words: galaxies: dwarf / Local Group / galaxies: kinematics and dynamics / galaxies: abundances / galaxies: structure / techniques: spectroscopic\nBased on observations made with ESO telescopes at the La Silla Paranal Observatory as part of the program 090.B-0284(B)\nThe averaged spectra (FITS files) are only available at the CDS via anonymous ftp to cdsarc.u-strasbg.fr (18.104.22.168) or via http://cdsarc.u-strasbg.fr/viz-bin/qcat?J/A+A/618/A122\n© ESO 2018\nCurrent usage metrics show cumulative count of Article Views (full-text article views including HTML views, PDF and ePub downloads, according to the available data) and Abstracts Views on Vision4Press platform.\nData correspond to usage on the plateform after 2015. The current usage metrics is available 48-96 hours after online publication and is updated daily on week days.\nInitial download of the metrics may take a while.']	['<urn:uuid:44e3d519-e3cf-4517-b896-c3eea1175afb>']	open-ended	with-premise	long-search-query	similar-to-document	single-doc	expert	2025-05-12T23:56:45.148498	14	71	664
69	looking info when historic clock tower leicester city center first built who made it	The Clocktower in Leicester was built in 1868 and was designed by Joseph Goddard, who often worked in a Gothic style during this period.	"[""Photo: reliefs depicting the life and adventures of Thomas Cooke on the side of the Thomas Cooke building in Leicester city centre.\nIf you have lived in Leicester for any amount of time you may not know about the Goddard architectural dynasty, but you will certainly have seen their buildings.\nFrom the Clocktower through churches, houses and schools, generations of the Goddard practice have helped to shape the face of Leicester. The story of the Goddards is told very well in 'Men of Property - The Goddards and Six Generations of Architecture' by Geoff Brandwood and Martin Cherry, and anyone wanting to know more about the practice and the buildings it designed should read this book.\nJoseph Goddard (b.1751) came to Leicester from Kirby Muxloe and settled around Belgrave Gate. Henry Goddard was born in 1792, an era before the idea of an architect, as we know it, existed. Like Joseph, he would have to have been a jack of all trades - carpentry, surveying, etc. - and in 1807 he was articled to father.\nPhoto: The Fish and Quart Pub.\nHenry's first known work was in 1817 when he designed some tenements in Belgrave Gate for his father. Various other houses and farm buildings followed including the Fish and Quart pub in 1832.\nIn 1840 Henry's son Joseph was born and 16 years later he was articled to his father (this story is complicated slightly by the main characters all having the first names Henry or Joseph – so pay attention!).\nThe 1860s saw an upturn in the fortunes of the practice and in 1862 Joseph became a partner in the firm, but a few years later in 1868 Henry died and Joseph was in business by himself.\nPhoto: Tur Langton Church\nBuildings of this period include Tur Langton church 1865-6 and the Clocktower 1868, and Joseph often worked in a Gothic style, as in the schools of the 1860s and '70s. Up to this point a lot of the practice's work was church restoration, but things became more varied into the 1870s.\nPhoto: Tintern House\nJoseph became a Fellow of the Royal Institute of British Architects in 1871, the same year as he designed Tintern House. The Leicestershire Banking Co HQ followed in 1872-4 and marked the high point and end of his use of Gothic for secular work.\nIn 1874 AH Paget became a partner in the practice, which became known as Goddard & Paget. Joseph became President of the Leicester & Leicestershire Society of Architects in 1879-81 and buildings of this period including Brookfield 1876-7, the first use of half-timbering in Leicester and a pointer to the Domestic Revival of the future.\nAround this time there was a definite movement among younger architects away from the Victorian Gothic towards an eclectic pick and mix of styles influenced by the Renaissance and traditional English housing.\nPhoto: Knighton Spinneys\nThere was a need for change and from 1875 'Queen Anne' elements were introduced into some of Goddard and Paget's buildings, and the Domestic Revival was exemplified by Goddard's own house, Knighton Spinneys 1886.\nThe commercial buildings of the practice were also being influenced by the arrival in 1888 of Joseph's son, Henry, in the practice, which became known as Goddard, Paget & Goddard.\nPhoto: Thomas Cook building\nHenry had toured Europe and now brought a Renaissance enthusiasm to bear, resulting in buildings such as the Thomas Cook offices 1894, the General News Room 1898, and several Jacobean-style houses in both city and county. This influence was also present in Henry's St James the Greater , Leicester 1914 (although designs go back as far as 1895).\nThe versatility of the practice in this period is demonstrated by churches such as Melbourne Hall 1880-81 and St John the Baptist 1884-5.\nPaget retired around 1897 and WA Catlow became a partner - the practice became Goddard & Co. Catlow designed the Tudor Hotel in 1900-01. Joseph Goddard died in 1900 and after this the practice came to specialise in country house work, such as the houses built in Horninghold 1905-1913.\nIn 1914 Henry went to fight in France and the practice did little during the war. However, his son Henry continued the family business, as does Anthony Goddard to this day.\nA Guide to Architectural Styles in Leciester\nThroughout this trail references are made to styles of architecture such as 'Gothic', 'Baroque' etc. Many buildings combine elements from different styles and below is a very brief, and very simple, guide to what these expressions mean. For a more detailed look at buildings, architects and the history of architecture try this architecture site\nArts and Crafts - influenced by Willam Morris this movement reacted against cheap mass-produced buildings and decorating materials by advocating a return to high quality materials and hand-made excellence in all fields of art and decoration - furniture, textiles, wallpaper etc.\nPhoto: Gimson's White House\nAn example of the simplicity admired by this school is Gimson's White House in Leicester, 1898. Buildings often mixed Arts and Crafts with elements from the English Vernacular, Old English, or Queen Anne styles.\nBaroque - the origin of the term 'baroque' is uncertain but buildings in this style may display exuberant decoration, expansive curved shapes, rich colours, large-scale, sweeping vistas, and spatially complex compositions.\nPhoto: the General News Room.\nThe English didn't really take this style to heart and here it was often tempered with classical elements. Think of Blenheim Palace nationally or, on a much smaller scale, Leicester's General News Room , 1898, which combines baroque and classical elements.\nClassical - the principles of Greek or, more often, Roman art and architecture. Georgian classicism was most heavily influenced by Palladianism - understated decorative elements and use of classical 'orders' such as Ionic, Doric, and Corinthian.\nPhoto: New Walk\nThis began in the 1750s as a reaction against the excesses of late baroque. New Walk has several buildings in a variety of Classical styles, while there is a simple classical building, c.1750, in Friars Lane.\nDomestic Revival - the English vernacular revival applied to houses. Medieval or Tudor styles - half-timbering, overhanging gables.\nGoddard's Knighton Spinneys , 1885, is an example of this, and the council houses at 317-355 Narborough Rd, 1928, also show this influence.\nGothic - known in the Middle Ages as the 'French Style', medieval architecture was critically attacked in the 16th century and compared to the barbarism of the Goths who had attacked Rome - hence 'Gothic'.\nThink of buildings with strong vertical lines, high vaulted ceilings, pointed window and door openings, and buttressed walls. From 1066 architectural style in England moved from Anglo-Saxon to Norman (also called Romanesque). Gothic elements were added to Romanesque buildings in a Transitional stage, occasionally called Norman Gothic, and from around 1200 the history of the style in England is usually divided into three phases - Early English Gothic, Decorated Gothic, PerpendicularGothic - each of which shows an evolution in style.\nThe Victorian Gothic revival began in earnest around 1840, a good example being the Palace of Westminster, London. High Victorian Gothic, such as the Albert Memorial in London or Leicester's Clocktower ,1868, became very popular in the mid to late 1800s.\nQueen Anne - buildings shaped by English mid-17th century brick houses under Dutch influence. This style became popular at the beginning of the 1870s and Leicester was, for a change, being quite modern when it commissioned the Town Hall in the Queen Anne style in 1876.\nPhoto: Leicester Town Hall\nHowever, architects often combined Queen Anne elements with other styles and two buildings as seemingly different as the Aylestone Nursing Home 1878, and The Tudor 1900-01, may be said to be Queen Anne influenced and yet share only a few features with the Town Hall.\nPhoto: Aylestone Nursing Home.\nFeatures of the style include tall sash windows, ornate chimneys, decoration with tiles or ornamental carvings,and asymmetric gables. It was a style often used for the Board schools of the late 1800s.\nThis trail is part of a larger trail that explores the architecture of the Goddard family in Leicester, it can be found on the East Midland Oral History Archive. www.le.ac.uk/emoha/leicester/goddardindex.html\nTo find out more about architecture of Leicester visit the Sound and Vision website, an off-shoot of the East Midland Oral History Archive.""]"	['<urn:uuid:a8636719-8236-420f-bd26-313fb0c112a5>']	factoid	with-premise	long-search-query	distant-from-document	single-doc	novice	2025-05-12T23:56:45.148498	14	24	1383
70	I'm interested in taking HDR photos but don't really know what they are - what exactly does High Dynamic Range photography do to improve a picture?	High Dynamic Range photography increases the dynamic range of an image by recovering lost details in both the highlights and shadows. The result can either be subtle, making the image match what the human eye sees, or it can create hyper-realistic images.	['High Dynamic Range photography increases the dynamic range of an image by recovering lost details in the highlights and the shadows. Typically, a photographer uses 3 to 7 separate exposures then combines the exposures using HDR software. The result can be subtle and can make an image more closely match what the human eye can see. It can also be used to create hyper-realistic images that some associate with HDR.\nHDR from a Single Image\nI am often asked if a HDR image can be created from a single image. The reason people ask is because they have an image, with good composition, they took before they started using HDR techniques. The good news is if your photo was taken as a RAW file, you can do a decent job to create an HDR-like image in Photoshop. There are several ways to do this and I will outline one of the more popular ways below.\nFirst, find your RAW file; ideally, it should be well exposed with no clipping of the white or black values. Check the histogram to make sure it is within the exposure limits. We are going to make use of more of the information contained within a RAW file to simulate 3 different exposures.\nOpen your image in Photoshop Camera RAW, the right hand dialog box should be set to basic so that you can see the exposure slider. This slider increases or decreases the exposure, to the left, decreases the exposure and sliding it to the right increases the exposure.\nFor the first exposure move the slider to the right to +2. This will over expose your image. If your original is properly exposed +2 should work fine but keep an eye on your highlights if +2 blows them out and a lot of clipping occurs move the slider back slowly until the clipping is minimized and the shadows have been lifted.\nWe need to create the other 2 exposures. I like to save a separate “0” exposure so I don’t accidentally save over the original RAW file.\nThe next step is to save the original exposure, move the slider back to zero, save this image, again use a unique name, and save as a TIFF.\nLastly we need to create the underexposed image. Move the slider to the left to -2, save this image, again use a unique name, and save as a TIFF.\nMerge to HDR Pro\nClick Done on the Camera RAW dialog to close the window you are now ready to create the HDR Image. On the main Photoshop menu, select File – Automate – Merge to HDR Pro. Click browse to add your saved TIFF files. If you are using the most recent version of Photoshop, the program will do its thing and a Merge to HDR Pro window will pop up with your 3 images already merged.\nIf you are using an older version of Photoshop, you might get a warning advising you to use original RAW files. You can go ahead and close this window. You might also get a second window asking you to set the exposures you can go ahead and adjust the shutter speed by +/- 2 or increase or decrease it by the same amount that you adjusted in Camera Raw.\nWhen you get to the Merge to HDR Pro window you can start use the adjustment sliders to archive the look you want. There are 16 pre-sets in the top drop down menu that you can select to get various different looks such as photorealistic, saturated, and Scott5. (Scott Kelby of KelbyOne developed this one) Below the drop down menu are sliders for Edge Glow, Tone and Detail, Curves and an Advanced tab that includes sliders for shadows, highlights, vibrance and saturation.\nA single exposure HDR will not be as effective as a multi exposure HDR image however as you can use this technique to improve the look of some images.']	['<urn:uuid:1242d355-409c-486f-b8cb-12844daf91d8>']	factoid	with-premise	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-12T23:56:45.148498	26	42	658
71	What are the artistic approaches to river representation in Meanders versus South Park Discount Foods?	The Meanders installation uses white cloth streamers to physically recreate the river's original 1907 contours, while the South Park Discount Foods mural takes a more comprehensive approach, depicting the current river alongside the bridge, shipping industry, and local residents.	"['Explore South Park’s art scene\nArt is a big part of South Park and our community of local artists is growing. Our public artworks are being added to as well. Come see what South Park has to offer. Drive around, find some great stuff and grab a bite to eat afterwards.\nSouth Park Arts is an organization dedicated to supporting, representing, and promoting art and artists in Seattle’s South Park neighborhood. You don’t have to be an artist to join this group. No matter your skills, you can be involved in this fun and lively organization.\nFind out what they are currently up to: South Park Arts website\nBelow is a list of public art spots to discover\nArtwork at South Transfer Station\nCarol de Pelecyn salvaged items brought to the transfer station as material for her sculptures.\nSouth Park Community Center Public Art\nWatch Seattle Artist Ginny Ruffner making the whimsical archway for the South Park Community Center.\nCesar Chavez Park’s Singing Stones\nJesus Bautista Moroles, a nationally recognized stone sculptor, donated a sculpture titled “Musical Steles,” comprised of three musical basalt columns fabricated in the South Park neighborhood. Stop by and tap a rock on the sculptures to compose your own tune.\nStudents at nearby Concord school have participated in workshops learning about modern art and Cesar Chavez, and created a painting that is posted at the park.\nCesar Chavez Park: S Cloverdale St & 7th Ave S, 98108\nA documentary titled “Seasonal Soil…Singing Stones,” made in 2003 by Jennifer Maas, tells the story of Cesar Chavez Park and South Park. The documentary has aired on the Seattle Channel and is shown as part of a permanent exhibit of Jesus Moroles’ work at the Houston Museum of Art.\nRiver City Skate Murals\n736 S. Cloverdale\nMurals commissioned by South Park Arts and painted by Angelina Villalobos in 2012, adorn the entrances to the skate park.\nThe Good City Mural 1997\nCloverdale/599 Underpass Murals\nBy Dana Schuerholz and Karen Euler and numerous community members\n‘From the Roots’ Public Art Brigade\nThis mural titled “Living with the River,” under the 509 overpass features a river of fish swimming above houses and hands reaching up to the sky. The south wall is called “Home” and illustrates a large flock of geese flying toward the heart of our neighborhood.\nGateway Park South Artwork\n8th Avenue S and S Portland St\nThis park includes tiles made and painted by the community (coordinated by Gregory Fields) of South Park as well as large red gears (from the old Fremont Bridge) symbolizing South Park’s ties to local industry.\nMike’s La Cantina Mural\n8601 8th Avenue S\nThe outside wall of this building sports a colorful mural embodying the unique qualities of life in South Park. It pictures kayaks, fish, birds, tugboats, and industry cohabitating with beautiful mountains visible in the distance. The building was built in 1908, this structure marked the terminus of the trolley line that crossed the Duwamish River at 8th Avenue S between 1900 and 1910.\nS Henderson Street/Hwy 599 overpass bridge\nPainting done in 2010, led by community artists Amaranta Ibarra-Sandys and Concord Elementary Students.\nOld South Park Bridge Murals\nMural panels were painted by several local artists the day of the South Park Bridge Wake. Once the new bridge is completed, the old approach will be dismantled and a park will appear where these murals once were, and they will become a part of our art history. Now fenced off, the murals are still somewhat visible.\nSouth Park Vortex at Marra Farm\nArtist Horatio Hung-Yan Law created the public art sculpture “South Park Vortex”. It consists of over 450 laminated glass snowflakes swirling in a vortex-shape framework.\nSouth Park Vortex symbolizes the coming together of the South Park community to effect change. The sculpture reflects the independent spirit of South Park: dynamic, creative, proud and inclusive. South Park residents designed and cut individual snowflakes through a series of workshops sponsored by the South Park Library. Together, they represent the unique contributions of individual members in this multi-ethnic and multi-generational community.\nHuge Veggies at Marra Farm\nSeattle Artist Matt Kelly (once a South Park resident) created these metal vegetable signs in conjunction with an educational sign project designed by Noise w/o Sound. The metal art holds 5 removable educational boards that are stored when students are not at the farm learning.\nSouth Park Identifiers\nAlong 14th Ave. S\nGregory Fields (once a South Park resident) created several ceramic pillars that mark the northern and southern ends of the business district on 14th Ave S. Look for sidewalk tiles too.\nPack of Doom Mural\nAlley behind the South Park Library\nAlong the S Donovan Street Alley residents commissioned a mural to be painted on their garage by artist CT as a way to support local art.\nSouth Park Library Lights\n8604 8th Ave. S at So Cloverdale St\nIn 2006, Artist Franklin Joyce created theatrical lighting fixtures to project images onto the exterior wall of the library. The imagery changes seasonally, creating opportunities for the artwork to remain relevant to community interests and activities. The artist created eight gobos (thin plates of metal with the artist’s design cut out of the surface) that provide displays for a one two-year exhibition cycle.\nAccording to the artist, South Park is one of Seattle’s most spirited and dynamic communities and needed an inclusive artwork that would allow the community to represent itself and be consistent with the vision of the new library.\nSince the original installation art students and artists from South Park Arts have created more gobos featured on the library wall.\nThe artistry of Tim McNeil\n8106 & 8112 Dallas Ave S\n1046 & 1056 S Southern St\nTim McNeil was a true visionary. He had ambitions to single handedly turn South Park into a hip neighborhood full of yard art that celebrated our close ties to local industry. Visit the following homes to see his masterful use of recycled and repurposed materials to build fences and structures for the several properties that he owned with his wife Debbie.\nThe fence at 1049 Elmgrove was inspired by Tim and built by Dave Means. Be sure to check out the salty sea captain wearing a yellow slicker, overlooking the river in a nearby yard.\nDistinctive banners along South Park’s main thoroughfare, feature images created by artists John Hicks of the birds, fish, boats, airplanes, and houses that make up our community.\nGraffiti Art Murals, 2011\nOld South Park Hall building on 14th Ave S\nBy various artists\nConsejo Youth and Family Center Mural\n8615 14th Ave S\nThis mural celebrates our youth with a vibrant display of musicians surrounded by imagery that evokes ancient Aztec culture.\nSouth Park Discount Foods Wall Art\n8507 14th Ave S\nSporting images of our commercial district, bridge, river, shipping industry, and local residents, this is the image that welcomes people when crossing the bridge into South Park. It speaks to our diversity, pride, history, livelihood, home and community.\nGear Works Fountain\n700 block of 5th Ave S\nStop by and relax by the soothing sounds of the 13 foot tall rock fountain in the Gear Works lot.\n8107 8th Ave S\nSeattle artist John Hoge specializes in the design, fabrication and installation of stone sculpture, using primarily granite and basalt\nThe Sparks Building\n8601 8th Ave S\nThis century old building has seen an array of businesses come and go throughout it’s lifetime, and hasn’t had much use until the current owners began renovations a few years ago. Now, the second floor of this historic building has nine updated studio units perfect for artists or a small office space. The first floor is still undergoing renovations but is available for private functions and perfect for an art show you just can’t seem to find the space for.\nFor more information about The Sparks Building please contact the building manager by phone at 206-734-2008 or you can email them at email@example.com\nDuwamish Revealed Bring Great Art to our Area\nThe art featured in Duwamish Revealed is all site specific, developed for this place and time. The selected artists are creating work that deeply considers and reacts to the river and the communities along it. They bring a diverse set of backgrounds, approaches and levels of experience; some of them are from the neighborhood and some are from halfway around the world. Some of them knew a lot about the river when they applied, some knew very little. Together they make an incredible exhibition of beautiful, thoughtful and challenging work.\nCheck out the website to learn more.', ""An eclectic series of public-art installations and performances along Seattle’s Duwamish River this summer is meant to draw attention to clean up efforts and the value of the city’s waterway.\nDustin Slimp, equipment manager at Pacific Pile & Marine in South Park, usually operates the company’s barge-mounted cranes for marine work.\nBut come Saturday, Aug. 8, he’ll move the crane downriver for a different task: suspending an aerial performer above the Duwamish River in an illuminated moon, while members of a chorus contribute their voices to the show.\n“It’s not something we get to do all the time,” said Slimp. “[We’re] piling, dredging buckets, stuff like that, so to get the opportunity to have somebody do a performance from the crane, it’s pretty special.”\nFor aerialist Tanya Brno, the performance is an opportunity to draw attention to the river.\nIF YOU GO\nThe series of art installations, public performances, field trips and more continues on and around the river in Seattle through Sept. 30. Full schedule: duwamishrevealed.com.\n“Most people don’t even hang out down here … ” she said. “So maybe it will encourage people to take better care of it, and hang out in the places that we pay for.”\nMost Read Stories\n- Seattle hits record high for income inequality, now rivals San Francisco\n- Anthony Bourdain brought 'Parts Unknown' to Seattle — here's where he ate\n- Seattle’s crazy restaurant boom | PNW Magazine VIEW\n- Seattle-Dublin nonstop flights to begin in May 2018\n- Cleveland Browns waive Kasen Williams, could a return to Seahawks be in the offing?\nBrno’s performance is one of many spectacles Seattleites may see on and around the river this summer as part of “Duwamish Revealed,” a series of art installations and performances that’s as varied as the history of the river itself. Straightened from its original windy course in the early 20th century for the purposes of industrial shipping, the river was declared one of the most toxic waste areas in the nation in 2001.\nSince then, the Environmental Protection Agency has addressed all of the most concerning waste areas in early action plans, which cover half of the contamination. The art series comes at a time when the community is still planning the next stage of cleanup, which will take 20 years. Funded by an ArtPlaceAmerica grant given to the Environmental Coalition of South Seattle (ECOSS), its primary goal is to use the arts to inspire people to care about the river, as well as address safety concerns for those who fish there.\nIt’s a project that’s bringing industry — Boeing and Pacific Pile & Marine are two examples — to work together with environmental groups and artists in producing a variety of river-themed works.\nFor “Duwamish Revealed’s” artistic directors, urban planner Sarah Kavage and landscape architect Nicole Kistler, the river cleanup depends on getting these groups to work together. They see an art series as a way to promote these conversations.\n“We feel like if you really want to create lasting change then you need to have dialogues that include everybody,” said Kistler.\nDespite the diversity of approaches, everyone in the project — from artists who hardly knew anything about the river to companies that have worked on it for generations — seems to have some kind of stake in the river.\nIt catches the corner of your eye as you drive down Corson Avenue past South Seattle College in Georgetown: streamers of long white cloth dipping and swelling in the breeze. It may compel you to look over your shoulder as you head toward the stoplight, and even to take two right turns to go back and inspect it.\nShould you do so, you can walk through an original meander of the Duwamish River.\nOr rather, artist Frances Nelson’s representation of it: a piece called “Meanders.”\n“If someone doesn’t tell you or if you don’t sort of experience a piece or work, how do you know that something is there?” said Nelson of the work, whose streamers run from lengths of 4 to 16 feet and represent the exact contour of a part of the river that, in 1907, ran through what is now Georgetown.\nYou can walk in between the streamers, catching ever-shifting shade, or watch them ripple in the breeze. With help from civil engineer Zac Corum and environmental anthropologist and ecology researcher Amir Sheikh, Nelson hoped to create an experience that would replicate the feeling of walking near the river — and make people aware of the unknown story behind why the streets are so angular in Georgetown.\nA quick drive across the South Park Bridge and down meandering streets to 12th Avenue and Elmgrove brings you to the artwork of Ben Zamora, titled: “Alone. Standing. In the Middle of Darkness. Invisible.”\nDespite the dark title, Zamora described the piece as “playful.” Designed around a two-way mirror, the work is a fragmented combination of several external mirrors in tall, rectangular blocks that contain a lighted hexagonal mirror.\nThe external world fades away from view as the sun goes down and gives way to the internal mirror’s light. If you stare at it at this time of day, you’ll fade out of sight along with the external mirrors.\n“I love the fact that it is a beautiful lighthearted piece about dissolving into nothing,” said Zamora. “That there’s nothing wrong with that … it’s an acknowledgment that death is part of life and that’s OK.”\nFor Zamora, it certainly draws attention to the river by reflecting the interaction between people and their landscape. But he also hopes that this idea gets people to think about universal themes, like that of ephemeral existence.\nOne purpose, many groups\nAlmost everyone involved in the project expressed concern about people not knowing that there is, in fact, a river in Seattle.\nMany, like Stephen Reilly, fund development manager for ECOSS, hope that the project can spread the word about the quality of the water for fishing — many local fishermen are recent immigrants who don’t know which fish are safe to eat. Currently, there’s an advisory against eating crab, shellfish or resident fish from the river.\nFor the Duwamish Tribe, it’s a matter of heritage. James Rasmussen, the coordinator for the Duwamish River Cleanup Coalition and a Duwamish tribal member, considers the river a home.\n“My family came from the Black River Village, and I know, I can feel the spirits of my ancestors are still here,” he said, referring to a village that stood for 1,400 years on the bank of the Black River, a former tributary to the Duwamish that was drained in 1916.\n“That’s the type of thing that I look at, the way I was taught: the salmon, he’s your relative, the cedar tree, he’s your relative … they’re all part of my family,” he added.\nBusinesses like Pacific Pile & Marine are concerned about the public’s perception of companies that work along the river.\n“You get a bad name being on the river as an industrial purpose,” said Slimp. “You get frowned upon by certain people, so we just want everybody to know we’re here to help.”\nRasmussen hopes that the art series will bring people to the river who haven’t been there before, and may not realize that their tax dollars are being spent on the $342 million cleanup.\n“We are one of the biggest contributors to that pollution,” he said. “And the only way to really deal with it is to make sure that your government does the best job they can do here … And if we do that means that those communities down there can thrive, an answer for fish and wildlife, an industrial area that actually could expand.”""]"	['<urn:uuid:0042ed02-41ed-498d-bfc5-c1390dcd26b5>', '<urn:uuid:9708b9bb-3a92-4ec0-adad-26d069fe6d6c>']	factoid	direct	concise-and-natural	similar-to-document	comparison	expert	2025-05-12T23:56:45.148498	15	39	2724
72	I'm into ancient architecture - how do Petra and Machu Picchu differ in building materials?	Machu Picchu was built using quarried granite stone in a dry-stone wall technique called ashlar, where stone blocks were cut precisely to fit without mortar. Each stone weighed over 22 kilograms. In contrast, Petra's monuments were carved directly from existing sedimentary rocks, specifically sandstone formations from the Ordovician Disi and Cambrian Umm Ishrin formations. The sandstone in Petra has a distinctive rosy color, leading to it being called 'a rose-red city'.	['Machu Picchu was build at the height of the Inca Empire around 1450 but abandoned just over a century later in 1572 after the Spanish arrival in Peru.\nMachu Picchu is located 2430 meters (7970 feet) above sea level on a ridge between the Huayna Picchu and Machu Picchu mountains in Peru.\nIn the Quechua Indian language, “Machu Picchu” means “Old Peak” or “Old Mountain.”\nMachu Picchu is also known as the Lost City of the Incas.\nMachu Picchu was built in a typical Inca style, with beautiful, polished dry-stone walls of quarried granite stone.\nMachu Picchu is made up of more than 150 buildings ranging from baths and houses to temples and sanctuaries.\nThe primary archaeological treasures of Machu Picchu are: The Main Temple of the Machu Picchu located at the highest position of the city.In the temple are seven trapeze-shaped niches on the central wall and five on each side wall.\nThe Temple of the Sun, also known as the Torreon may have served as a primitive solar observatory.A semi-circle shaped temple that at once time was thought to have gold and precious jewels inlaid in the door.It was dedicated to their greatest deity, the Sun.\nThe Intihuatana, it’s a stone located on the top of a hill. Access is via 78 steps which lead to a platform. It’s believed that this stone was used as calendar or an astronomic clock.\nAnd Temple of the Three Windows is one of the foundations with the longest history in the sacred lost city of Machu Picchu.\nThe Incas were experts at using a building technique called ashlar in which blocks of stone\nare cut so precisely as to fit together tightly without mortar.\nAlthough many of the stones that were used to build the city were more than 22 kilograms (50 pounds), it is believed that no wheels were used to transport these rocks up the mountain. Rather, it is thought that hundreds of men pushed the heavy rocks up the steep mountain side.\nMachu Picchu was only known locally until Yale Professor Hiram Bingham re-discovered the site in 1911. His book, The Lost City of the Incas, was based on his findings.\nBingham’s team excavated an estimated 40,000 artifacts to Yale University for further study including mummies, ceramics, silver statues, jewelry and bones. Peru has long wanted these artifacts back and an agreement was recently agreed for the majority of these items to be returned.\nSince re-discovery over 30% of Machu Picchu has been reconstructed to give a better idea of how the original structures looked, restoration continues today.\nIt was named a Peruvian Historical Sanctuary in 1981, and two years later, in 1983 UNESCO classified it as a World Heritage Site.\nThanks to an internet and cell phone messages in 2007, it was voted as one of the New Seven Wonders of the World.\nYou might know that you can trek up Machu Picchu for free. However, the trail upwards is steep and strenuous, taking approximately 90-minutes in total, but at the top, the views is amazing!\nEvery year marathoners race along the 42 kilometers (26 mile) long Inca Trail. The fastest time is 3-hours and 26-minutes.', 'Petra is famous for its rock-cut monuments like sanctuaries, tombs, and temples. These monuments are located in the Shera alps of Jordan, situated east of the Wadi Araba Valley.\nApproximately 2200 years ago, Nabateans (ancient Arab people who inhabited northern Arabia) had carved more than 900 monuments using sedimentary rocks as they were well-aware of the aesthetical features of sedimentary rock.\nIn 1986, the United Nations of Education, Science, and Cultural Organization (UNESCO) emblazoned Petra on the directory of the world heritage site as a work of genius, bearing inimitable testimony to the advancement of civilization that has vanished. Rock-cut monuments of Petra are the epitome of exceptional architecture and represent an important phase of human history.\nIn 2007, the rock-cut monuments of Petra were selected as one of the seven wonders of the world. Petra region is also considered as a famous historical site in Jordan because it has impacted the tourism economy of the country. More than 700,000 tourists visit the rock-cut monuments of Petra in a year.\nThe sedimentary rocks of the Petra region are of lower paleozoic age. Mostly, the sandstone formations of the sedimentary rock are the pertinent stratigraphical units used for carving the monuments. These sandstone formations are the part of the Ordovician disi formation and the Cambrian umm ishrin formation.\nMost of the rock-cut monuments of Petra are undergoing weathering due to external agents such as water, humidity, and salt that have contributed to the damage. Also, anthropogenic activities, natural hazards like floods, and earthquakes have worsened the situation.\nThus, by looking at the development of damage, the world monuments fund added the rock-cut monuments of Petra to the list of top 100 endangered monuments of the world in 1998, 2000, and 2002. Therefore, the rock-cut monuments of Petra have become a global concern for preservation.\nIn this article, we will discuss the rock types, weathering agents, which are contributing to the degradation process, and preventive measures to reduce the degradation of the rock-cut monuments.\n1. Geology of the Petra Site\nThe ruined city of Petra includes many monuments, tombs, quarries, stairways, and theaters all constructed directly from sandstone rock, especially Cambrian and Ordovician sandstones. More details about the sandstone rock, which is mostly affected by the weathering, are described below:\n- Most of the sandstone rocks are underlain by igneous rocks, such as granite, gneisses, and schists.\n- Plinth level of igneous rock displays a well-defined characterized contact plane whereupon the sandstone strata is situated.\n- The shade of Petra sandstone is rosy, that is why the city is called “a rose-red city”.\n- Umm Ishrin Sandstone stratum is of middle to upper Cambrian age, and the thickness of the strata is around 300 m.\n- The upper-level blanketing formation is comprised of Disi sandstone, and the thickness of this formation is 100 m. This stratum displays a whitish-beige color and is seen throughout the valley.\n- Sandstones of the Disi formation are critically influenced by the weathering agents. Such strata erode into characteristic domed features that can be recognized from miles away.\n- Umm Ishrin sandstone formation shows extensive moment jointing and faulting. In contrast, Disi formation sandstone shows less frequent jointing.\n- Weathering induced sandstone surface recession ranges from 12-50 mm on a horizontal surface and 6-20 mm on vertical surfaces.\n2. Climatic Conditions at Petra Site\nThe climatic conditions at the Petra region are generally arid with moderate to mild blustery winters and sweltering, dry summers. Regional rainfall occurs due to change in barometric pressure conditions as the peripheral precipitation passes through northern Israel and Jordan. However, when low-pressure fronts get across northern Africa or up through the red sea, heavy rainfall occurs in the Petra region. Such conditions occasionally bring flooding in the region due to a combination of orographic lifting and cyclonic flow.\nMostly, the precipitation occurs between November and March, and the mean yearly precipitation at the Petra region is around 110-130 mm. Hints of snowfall are also reflected. However, a large portion of the precipitation is observed as rainfall.\nThe temperature in the Petra region may dip below 0 degrees during January. However, freezing temperature conditions are not common, and the temperature rises rapidly during the daytime. The maximum and minimum temperature is observed in the months of August and January and the range of temperature is around 18-390C and 6-120C, respectively.\n3. Weathering Factors and Degradation of the Monuments\nHigh-temperature loads are induced on many rock-monuments in Petra. Mostly, the monuments located in the south and west are exposed directly to the sun, for example, the Silk Tomb. Variation due to direct isolation and high-temperature loading affects the monuments and promotes the attack of weathering agents.\nResearchers have hypothesized temperature as a mild to moderate weathering agent for degrading the quality of Petra’s rock-cut monuments. As indicated by the outcomes gathered from various investigations, the correlation of high-temperature loading and weathering damage is not very severe. However, mild to moderate damages occur on the monuments exposed to temperature loading compared to the monuments insignificantly affected by temperature loading. Thus, high-temperature loading has turned out not to be the principal reason for the degradation of the monuments due to weathering.\nOn the other side, a strong correlation exists between water impact and weathering damage. During rainy reason, runoff water flows over the facades of the rock-cut monuments, and flooding conditions were also observed occasionally. Thus, the potential of damage to the monuments due to water impact is high. For example, the effect of water on the Unaishu Tomb during heavy rainfall is illustrated in Figure-2. The portion of monuments protected from the rainfall appears in a lighter color, whereas, the portion of monuments exposed to rain appears in a darker color in the photographs.\nResearchers have observed the changes in exposure characteristics of the monument during periods of rainfall. Such observations helped in mapping the exposed part of the monument, which is vulnerable to damage due to water impact. An example is presented in Figure-3. It was discovered that the south to west exposed monuments are more influenced by water impact due to precipitation compared to the north to east exposed monuments.\nThe architectural elements, such as moldings and pediments, provide protection from rain for some of the locally exposed monuments from south to west. Overflowing water affects sites, especially when water channels above the site are filled or eroded with debris. Water flowing from architectural elements is an attribute of many Petra monuments because precipitation often exceeds the water absorption capacity of the rock sediments. The lower sections of many monuments are also influenced by increased humidity.\nThe predominant weathering factors causing the degradation of the rock-cut monuments are water, salt, and humidity. Water runoff and floods affecting the monuments are characterized by high mechanical water impact potential. Several types and extents of humidity and the impact of salt relate to the weathering patterns formed on the monuments. Mostly, the monuments are categorized into damage index of two degrees. The low damage index represents the monuments sheltered from the rainfall. Thus salt penetration is negligible. The high damage index represents the monuments directly exposed to the rainfall, therefore higher salt penetration is possible.\nSalt weathering has been found to be the main and most detrimental water or moisture-induced weathering activity. The results of mineralization and geotechnical studies have exhibited that all major types of rock separation, such as contour deposits, flaking and granular decomposition, are associated with the presence of salts.\nMostly, halite (NaCl) was found to be the primary salt mineral deposited on the external walls of the monuments. Also, the presence of niter (KNO₃), Gypsum (CaSO₄.2H₂O), and sylvite (KCl) were observed. The type, amount, spatial distribution, and crystallization cycle of salt control the type and strength of stone exfoliation. Chemical analysis of rainwater shows that a significant proportion of the salt component comes from rain, especially with respect to the formation of halite. Nitrate load on the walls of the monument (especially at the bottom) is probably due to the effects of livestock over the decades.\nThe wind is observed to be another weathering agent influencing the degradation of the rock-cut monuments. However, the wind is not causing the collapse of stones. Still, it contributes considerably to the erosion of loose stones, and the evaporation of salt fluids and their movement through rocks.\n4. Preventive Measures\nThe following types of preventive measures should be taken into consideration to protect the rock-cut monuments of the Petra region:\n- Stone blocks should be prevented from breaking out. Preservatives should be used to reduce salt weathering.\n- Loose stone materials should be reinforced again to preserve the originality of the monuments.\n- For highly damaged monuments, structural stabilization or reinforcement should be provided to keep them structurally sound.\n- Repair should be done for the damaged stone parts and missing parts should be replaced.\n- Joints and fissures should be sealed properly to avoid the percolation of water and thus to prevent the disintegration of stone material.\n- A system should be provided to construct and maintain the control of runoff water. Thus, the capillary rise can be prevented and further the disintegration of stones can be reduced.\n- The rise in humidity should be controlled by planting more trees at the affected locations.\n- Desalination of runoff water must be provided because salt weathering is mostly affecting the rock-cut monuments.\n- The regular cleaning process must be carried out to reduce the deposition of harmful agents on the surface of stones.\n- External stone wall surfaces, which are exposed to weathering agents, should be protected. Protection can be provided by applying preservative solutions on external surfaces.\nPetra is a world heritage site and recognized by UNESCO as a work of genius, bearing inimitable testimony to the advancement of civilization that has vanished. Rock-cut monuments of Petra are the epitome of exceptional architecture and represent an important phase of human history.\nRock-cut monuments of Petra are located in the Shera alps of Jordan, situated in east of the Wadi Araba Valley.\nMost of the rock-cut monuments of Petra are suffering from weathering. The weathering agents such as water, humidity and salt have contributed to the development of damage. Also, the anthropogenic activities, natural hazards like floods and earthquake have worsened the situation. Thus, by looking at the damage, the world monuments fund added rock-cut monuments of Petra to the list of top 100 endangered monuments of the world in 1998, 2000, and 2002. Therefore, the rock-cut monuments of Petra have become a global concern for their preservation.\nThe Petra region is made up of sedimentary rocks. Mostly, the sandstone formations of the sedimentary rock are the pertinent stratigraphical units used for carving the monuments. These sandstone formations are the part of the Ordovician Disi formation and the Cambrian Umm Ishrin formation.']	['<urn:uuid:4497a745-acb5-417e-9eb2-f9dda10bf13f>', '<urn:uuid:3dedb8cc-4c74-4135-bc30-415b7c523f06>']	open-ended	with-premise	concise-and-natural	distant-from-document	comparison	novice	2025-05-12T23:56:45.148498	15	71	2335
73	aquatic ecosystem expert here what triggers of blanket weed growth nutrients phosphates eutrophication process dead zones	Blanket weed growth is triggered by excess nutrients, particularly phosphates, in water bodies. This is part of the eutrophication process where high nutrient levels fuel algae growth, leading to algae blooms. In severe cases, this can create dead zones as decomposing algae consumes oxygen, causing fish and other organisms to suffocate. This process occurs both in ponds and larger water bodies, with nutrients often entering through fertilizer runoff, sewage, and decomposing vegetation.	['Blanket weed is a major problem in ponds, not only does it look unappealing but it can also overwhelm plants and pond life you may have in your garden. Not only this but it can also be a sign of imbalance in your pond, so eliminating it before it takes hold is essential.\nAny keen aquatic enthusiast knows how detrimental blanket weed can be to a pond, however if you’re unfamiliar with this major pond problem then keep reading to find out more.\nWhat is blanket weed and where does it come from?\nThere are around 20,000 different forms of algae with over 500 species under the umbrella of blanket weed or string algae as it is also known. Blanket weed is a hair like algae that consists of long green fibres which grow rapidly and if left untreated will quickly spread throughout a pond. This form of algae can either free float on the ponds surface or cling to the pond walls, rocks and plants.\nJust like all forms of algae, blanket weed reproduces through spores. These spores are present in the air and can also be carried from pond to pond on birds, amphibians and plants.\nHow do I remove blanket weed from my pond?\nIf you find that your pond is affected by blanket weed then it is a sign that your pond is not balanced. The most cost effective way to control blanket weed is to help everything in the pond reach the right balance. It is important to remember that a pond is a mini eco-system, each element within the pond combines to balance it as a whole.\nWe would advise ensuring your pond has enough plants within it, as these will use the excess nutrients that can lead to blanket weed building up in your garden pond. It is important to have the right balance of plants in your pond, so aim to mix up oxygenators, marginal and deep water plants. The use of phosphate removers/absorbers provide an alternative method of removing these excess nutrients in ponds where plants are not an option.\nIf you find that blanket weed is an extreme problem in your pond, why not try one of our blanket weed removal products? This selection of handy treatments provide a temporary solution to the problem, so it is vital you look to balancing the problem from the root. Once the pond has been treated you can then look to balancing your pond correctly to ensure the problem does not return.\nWhy does blanket weed keep coming back to my pond?\nIf you’ve used a treatment to remove blanket weed from your pond, then it is vital you create the right balance in your pond after this. If you fail to do this, you can guarantee the problem will reoccur.\n- Keep the amount of fish in your pond to a minimum as waste from pond life can increase the nutrient level in the water causing algae to build up.\n- Remove any rotten vegetation, including dead leaves, although these seem like small issues they can unbalance the levels in the water again boosting the nutrient levels.\n- Regularly maintain pond filters to remove uneaten fish food, fish waste and other debris which all contribute to excess nutrient levels.\n- Ensure all plants in your pond are healthy and thriving. Again this may seem like a simple step but it can really make the difference between a healthy and unhealthy pond.\n- In ponds where plants are not an option use phosphate removers to artificially reduce the excess nutrients to cut off the blanket weeds source of food.\nAre plants good at controlling blanket weed? And if so which plants?\nPlants are an excellent way to balance your pond, they can thrive on high levels of nutrients and can be key indicator as to whether your pond is healthy or not.\nRorippa Nasturtium Aquaticum or Water Cress as it is commonly known is an excellent choice if you have issues with blanket weed. This plant will only grow where there is a high level of nutrients in the water. Meaning when the balance is corrected the plant will gradually shrink, helping you know you’ve achieved a good balance.\nPond Lilies are also a great idea as blanket weed thrives on sunlight. By adding pond lilies to your pond these will reduce sunlight levels as well as absorbing nutrients which otherwise the blanket weed would use to thrive. They also provide shade and shelter for you fish.', 'What Is Nutrient Pollution of Water?\nA common way that humans pollute water is through the addition of nutrients (fertilizers and sewage) to water as nonpoint source pollution. These added materials are full of nitrogen and phosphorus, two nutrients that encourage the growth of aquatic producers, such as algae. The excessive growth of algae dramatically disrupts the entire ecosystem. Because this type of pollution results from excess nutrients, it’s called nutrient pollution.\nBodies of water naturally exist with different nutrient levels:\nWaters that have low levels of nutrients and, therefore, low numbers of producers and low biological productivity are called oligotrophic. Oligotrophic waters are clear without many microscopic algae plants.\nWaters that have high levels of nutrients and, therefore, high biological productivity with large algae populations are called eutrophic.\nThe transition from oligotrophic to eutrophic — called eutrophication —occurs naturally over time as a type of community succession in lakes and ponds. Additional sediment and nutrients enter the ecosystem via streams, rainwater runoff, and other sources. Eventually, the biological activity and plant growth in the lake or pond increase to a degree that it may no longer be a lake or pond, becoming instead a wetland.\nWhen humans pollute water with nutrients, this normally long, slow process of eutrophication occurs very rapidly and is called cultural eutrophication. The rate of cultural eutrophication is much faster than natural rates of eutrophication; as a result, the organisms in the ecosystem don’t have time to adapt to the changes and die. Here’s what the cultural eutrophication process looks like:\nPollution enters the water, adding sediment, nitrogen, and phosphorus (the nutrients).\nThe added nutrients fuel algae growth; algae begin to reproduce in huge numbers, creating what’s often called an algae bloom.\nThe algae population continues to grow until it runs out of either nutrients or space — covering the surface of the water completely.\nExtensive algae across the surface of the water blocks sunlight from reaching organisms below the surface of the water, such as aquatic plants.\nUnderwater plants begin to die from lack of sunlight, while the large algae population, having reached its limit, also begins to die, sinking into the water where bacteria decompose it.\nDecomposition of dead plants and algae by bacteria consumes the dissolved oxygen in the water, creating oxygen sag conditions.\nFish and other oxygen-breathing organisms suffocate from lack of oxygen, and the entire aquatic ecosystem collapses, creating one big dead zone.\nCultural eutrophication doesn’t occur only in lakes. Coastal waters also experience the effects of nutrient pollution and cultural eutrophication. As a result, highly polluted areas of water become dead zones that don’t have enough oxygen to support a healthy aquatic ecosystem.\nOne of the most studied dead zones from nutrient pollution occurs in the Gulf of Mexico. The Mississippi River flows into the gulf and brings with it nutrient runoff from agricultural fields in the Midwestern United States. For a long time, scientists didn’t understand what was causing huge numbers of fish to die off and whole regions of the Gulf of Mexico to display low levels of dissolved oxygen.\nAfter observing the ecosystem for a number of years, scientists realized that the worst dead zones occur after spring rains along the Mississippi River. These rains wash fertilizers and manure from agricultural fields into the river, which then carries these nutrients into the gulf. When these nutrients reach the gulf, the cycle of cultural eutrophication begins with an algae bloom and subsequent ecosystem disruption.\nThis pollution scenario isn’t unique to the Gulf of Mexico. It’s also common in other regions, such as the Mediterranean Sea and the Black Sea. In most cases, the dead zones are a recurring event; after the ecosystem recovers, a fresh flow of nutrients occurs and the cycle repeats itself.\nMany cities have begun to monitor and limit the amount of nitrogen and other nutrients that enter nearby aquatic ecosystems in an effort to control nutrient pollution, oxygen sag, and cultural eutrophication. Another way to solve this type of water pollution problem is by finding ways to clean sewage and wastewater before it enters and damages an ecosystem.']	['<urn:uuid:53e37574-2956-4c3b-a39c-a58e8300c486>', '<urn:uuid:59cb45f9-b7bc-4997-9944-bc70e867aaf1>']	factoid	with-premise	long-search-query	similar-to-document	three-doc	expert	2025-05-12T23:56:45.148498	16	72	1439
74	I'm on chlorpromazine - can I drink and go outside?	You should avoid alcoholic drinks while taking chlorpromazine as alcohol can increase dizziness and drowsiness. Regarding sun exposure, chlorpromazine makes you more sensitive to the sun, so you should avoid sunlight or tanning beds. If you must be outdoors, wear protective clothing and use sunscreen with SPF 30 or higher.	"[""Chlorpromazine Hydrochloride tablet\nWhat is this medicine?\nCHLORPROMAZINE has many different uses. It is used to treat certain mental and behavioral disorders. This medicine is also used to control nausea and vomiting, nervousness before surgery, and hiccups that will not go away. It is also used to treat episodes of porphyria and in combination with other medicines to treat tetanus.\nWhat should I tell my health care provider before I take this medicine?\nThey need to know if you have any of these conditions:\n- blood disorders or disease\n- frequently drink alcoholic beverages\n- liver disease\n- Parkinson's disease\n- Reye's syndrome\n- uncontrollable movement disorder\n- an unusual or allergic reaction to chlorpromazine, sulfa drugs, other medicines, foods, dyes, or preservatives\n- pregnant or trying to get pregnant\nHow should I use this medicine?\nTake this medicine by mouth with a glass of water. Take your doses at regular intervals. Do not take your medicine more often than directed. Do not stop taking this medicine suddenly. This can cause nausea, vomiting, and dizziness. Ask your doctor or health care professional for advice if you are to stop taking this medicine.\nTalk to your pediatrician regarding the use of this medicine in children. Special care may be needed. While this medicine may be prescribed for children as young as 6 months for selected conditions, precautions do apply.\nOverdosage: If you think you have taken too much of this medicine contact a poison control center or emergency room at once.\nNOTE: This medicine is only for you. Do not share this medicine with others.\nWhat if I miss a dose?\nIf you miss a dose, take it as soon as you can. If it is almost time for your next dose, take only that dose. Do not take double or extra doses.\nWhat may interact with this medicine?\nDo not take this medicine with any of the following medications:\n- arsenic trioxide\n- certain antibiotics like gatifloxacin, grepafloxacin, sparfloxacin\n- medicines for mental depression\n- medicines to control irregular heart rhythms\nThis medicine may also interact with the following medications:\n- barbiturate medicines for inducing sleep or treating seizures, like phenobarbital\n- local and general anesthetics\n- prescription pain medicines\nThis list may not describe all possible interactions. Give your health care provider a list of all the medicines, herbs, non-prescription drugs, or dietary supplements you use. Also tell them if you smoke, drink alcohol, or use illegal drugs. Some items may interact with your medicine.\nWhat should I watch for while using this medicine?\nVisit your doctor or health care professional for regular checks on your progress.\nYou may get drowsy, dizzy, or have blurred vision. Do not drive, use machinery, or do anything that needs mental alertness until you know how this medicine affects you. Do not stand or sit up quickly, especially if you are an older patient. This reduces the risk of dizzy or fainting spells. Alcohol can increase possible dizziness or drowsiness. Avoid alcoholic drinks.\nThis medicine can reduce the response of your body to heat or cold. Try not to get overheated. Avoid temperature extremes, such as saunas, hot tubs, or very hot or cold baths or showers. Dress warmly in cold weather.\nThis medicine can make you more sensitive to the sun. Keep out of the sun. If you cannot avoid being in the sun, wear protective clothing and use sunscreen. Do not use sun lamps or tanning beds/booths.\nYour mouth may get dry. Chewing sugarless gum or sucking hard candy, and drinking plenty of water may help. Contact your doctor if the problem does not go away or is severe.\nWhat side effects may I notice from this medicine?\nSide effects that you should report to your doctor or health care professional as soon as possible:\n- allergic reactions like skin rash, itching or hives, swelling of the face, lips, or tongue\n- breast enlargement in men or women\n- breast milk in women who are not breast-feeding\n- breathing problems\n- changes in vision\n- chest pain\n- confusion, drooling, restlessness\n- dark urine\n- fast, irregular heartbeat\n- feeling faint or lightheaded, falls\n- fever, chills, sore throat\n- stomach area pain\n- uncontrollable movements of the eyes, mouth, head, arms, legs\n- unusual bleeding, bruising\n- unusually weak ot tired\n- yellowing of skin or eyes\nSide effects that usually do not require medical attention (report to your doctor or health care professional if they continue or are bothersome):\n- change in sex drive or performance\n- trouble passing urine\n- trouble sleeping\nThis list may not describe all possible side effects.\nWhere should I keep my medicine?\nKeep out of the reach of children.\nStore at room temperature between 15 and 30 degrees C (59 and 86 degrees F). Throw away any unused medicine after the expiration date."", ""Generic name: chlorpromazine (oral/injection) (klor PROE ma zeen)\nBrand name: Ormazine, Thorazine, Thorazine Spansule\nDosage forms: injectable solution (25 mg/mL); oral tablet (10 mg; 100 mg; 200 mg; 25 mg; 50 mg)\nDrug class: Phenothiazine antiemetics, Phenothiazine antipsychotics\nWhat is chlorpromazine?\nIn children ages 1 through 12 years, chlorpromazine is used to treat severe behavioral problems (such as combative or explosive behavior) or hyperactivity with excessive motor activity.\nChlorpromazine may also be used for purposes not listed in this medication guide.\nCall your doctor at once if you have uncontrollable movements of your eyes, lips, tongue, face, arms, or legs. These could be early signs of dangerous side effects.\nChlorpromazine is not approved for use in older adults with dementia-related psychosis.\nBefore taking this medicine\nDo not use chlorpromazine if you have recently used large amounts of alcohol or medicine that makes you sleepy.\nChlorpromazine may increase the risk of death in older adults with dementia-related psychosis and is not approved for this use.\nTell your doctor if you have ever had:\na sulfite allergy;\nbone marrow suppression;\nliver or kidney disease;\na blockage in your intestines;\na brain tumor; or\npheochromocytoma (tumor of the adrenal gland).\nTell your doctor if you will be exposed to extreme heat, or to insecticide poisons while you are using chlorpromazine.\nDo not give this medicine to a child without medical advice. Talk with your doctor before giving chlorpromazine to a child who has been ill with a fever or flu symptoms.\nUsing antipsychotic medicine in the last 3 months of pregnancy may cause medical problems, breathing problems, feeding problems, or withdrawal symptoms in the newborn. However, you may have withdrawal symptoms or other problems if you stop using your medicine during pregnancy. If you get pregnant, tell your doctor right away. Do not stop using chlorpromazine without your doctor's advice.\nYou should not breast-feed while using this medicine.\nHow should I use chlorpromazine?\nFollow all directions on your prescription label and read all medication guides or instruction sheets. Use the medicine exactly as directed.\nChlorpromazine oral is taken by mouth.\nChlorpromazine injection is injected into a muscle, or given as an infusion into a vein. A healthcare provider will give you this injection.\nYou may be asked to lie down for a short time after you receive a chlorpromazine injection. This medicine can lower your blood pressure and you may feel light-headed after an injection.\nYour doctor will need to check your progress on a regular basis. Your vision may also need to be checked.\nThis medicine can affect the results of certain medical tests. Tell any doctor who treats you that you are using chlorpromazine.\nIf you need to have a spinal tap (lumbar puncture) or any type of x-ray scan or MRI of your spinal cord, tell the doctor ahead of time that you are using chlorpromazine.\nDo not stop using chlorpromazine suddenly, or you could have unpleasant withdrawal symptoms. Ask your doctor how to safely stop using this medicine.\nStore at room temperature away from moisture, heat, and light.\nWhat happens if I miss a dose?\nUse the medicine as soon as you can, but skip the missed dose if it is almost time for your next dose. Do not use two doses at one time.\nWhat happens if I overdose?\nSeek emergency medical attention or call the Poison Help line at 1-800-222-1222.\nOverdose symptoms may include dry mouth, bloating or stomach cramps, feeling restless, fever, muscle stiffness, jerky muscle movements, changes in heart rate, fainting, or seizure (convulsions).\nWhat should I avoid while using chlorpromazine?\nAvoid driving or hazardous activity until you know how chlorpromazine will affect you. Dizziness or drowsiness can cause falls, accidents, or severe injuries.\nAvoid getting up too fast from a sitting or lying position, or you may feel dizzy.\nDrinking alcohol with this medicine can cause side effects.\nAvoid exposure to sunlight or tanning beds. Chlorpromazine can make you sunburn more easily. Wear protective clothing and use sunscreen (SPF 30 or higher) when you are outdoors.\nChlorpromazine side effects\nGet emergency medical help if you have any of these signs of an allergic reaction: hives; difficult breathing; swelling of your face, lips, tongue, or throat.\nLong-term use of chlorpromazine can cause a serious movement disorder that may not be reversible. The longer you use chlorpromazine, the more likely you are to develop this disorder, especially if you are a an older adult.\nCall your doctor at once if you have:\nuncontrolled muscle movements in your face (chewing, lip smacking, frowning, tongue movement, blinking or eye movement);\nstiffness in your neck, tightness in your throat, trouble breathing or swallowing;\na light-headed feeling, like you might pass out;\nconfusion, agitation, feeling jittery, trouble sleeping;\nbreast swelling or discharge;\njaundice (yellowing of the skin or eyes);\nlow white blood cell counts--fever, chills, mouth sores, skin sores, sore throat, cough, trouble breathing, feeling light-headed; or\nsevere nervous system reaction--very stiff (rigid) muscles, high fever, sweating, confusion, fast or uneven heartbeats, tremors, feeling like you might pass out.\nSome side effects may be more likely in older adults.\nCommon side effects may include:\ndry mouth or stuffy nose;\nimpotence, trouble having an orgasm.\nThis is not a complete list of side effects and others may occur. Call your doctor for medical advice about side effects. You may report side effects to FDA at 1-800-FDA-1088.\nWhat other drugs will affect chlorpromazine?\nUsing chlorpromazine with other drugs that make you drowsy can worsen this effect. Ask your doctor before using opioid medication, a sleeping pill, a muscle relaxer, or medicine for anxiety or seizures.\nOther drugs may affect chlorpromazine, including prescription and over-the-counter medicines, vitamins, and herbal products. Tell your doctor about all your current medicines and any medicine you start or stop using.\nMore about chlorpromazine\n- Side Effects\n- During Pregnancy or Breastfeeding\n- Dosage Information\n- Drug Images\n- Drug Interactions\n- Compare Alternatives\n- Pricing & Coupons\n- En Español\n- 58 Reviews\n- Drug class: phenothiazine antiemetics\n- Other brands\nRelated treatment guides\nRemember, keep this and all other medicines out of the reach of children, never share your medicines with others, and use this medication only for the indication prescribed.\nAlways consult your healthcare provider to ensure the information displayed on this page applies to your personal circumstances.\nCopyright 1996-2021 Cerner Multum, Inc. Version: 14.02.""]"	['<urn:uuid:f23e2be6-64d1-409e-a675-b6c7ee97a33c>', '<urn:uuid:f7edde0b-5451-4345-88ae-388d8a8d572e>']	factoid	with-premise	concise-and-natural	distant-from-document	multi-aspect	novice	2025-05-12T23:56:45.148498	10	50	1870
75	I'm analyzing time series data. What was the measured lag-1 autocorrelation value?	The lag 1 autocorrelation value was 0.97	"[""Exploratory Data Analysis\n1.4. EDA Case Studies\n1.4.2. Case Studies\n188.8.131.52. Standard Resistor\nAs a first step in the analysis, common summary statistics are\ncomputed from the data.\nSample size = 1000 Mean = 28.01634 Median = 28.02910 Minimum = 27.82800 Maximum = 28.11850 Range = 0.29050 Stan. Dev. = 0.06349\nOne way to quantify a change in location over time is to\nfit a straight line\nto the data using an index variable as the independent\nvariable in the regression. For our data, we assume\nthat data are in sequential run order and that the\ndata were collected at equally spaced time intervals. In our regression,\nwe use the index variable X = 1, 2, ..., N, where N is the number\nof observations. If there is no significant drift in the location\nover time, the slope parameter should be zero.\nCoefficient Estimate Stan. Error t-Value B0 27.9114 0.1209E-02 0.2309E+05 B1 0.20967E-03 0.2092E-05 100.2 Residual Standard Deviation = 0.1909796E-01 Residual Degrees of Freedom = 998The slope parameter, B1, has a t value of 100.2 which is statistically significant. The value of the slope parameter estimate is 0.00021. Although this number is nearly zero, we need to take into account that the original scale of the data is from about 27.8 to 28.2. In this case, we conclude that there is a drift in location.\nOne simple way to detect a change in variation is with a\nBartlett test after dividing the\ndata set into several equal-sized intervals. However, the Bartlett\ntest is not robust for non-normality. Since the normality assumption\nis questionable for these data,\nwe use the alternative Levene\ntest. In particular, we use the Levene test based on the median\nrather the mean. The choice of the number of intervals is somewhat\narbitrary, although values of four or eight are reasonable.\nWe will divide our data into four intervals.\nH0: σ12 = σ22 = σ32 = σ42 Ha: At least one σi2 is not equal to the others. Test statistic: W = 140.85 Degrees of freedom: k - 1 = 3 Significance level: α = 0.05 Critical value: Fα,k-1,N-k = 2.614 Critical region: Reject H0 if W > 2.614In this case, since the Levene test statistic value of 140.85 is greater than the 5 % significance level critical value of 2.614, we conclude that there is significant evidence of nonconstant variation.\nThere are many ways in which data can be non-random. However,\nmost common forms of non-randomness can be detected with a\nfew simple tests. The lag plot in the 4-plot in the previous\nsection is a simple graphical technique.\nOne check is an autocorrelation plot that shows the autocorrelations for various lags. Confidence bands can be plotted at the 95 % and 99 % confidence levels. Points outside this band indicate statistically significant values (lag 0 is always 1).\nThe lag 1 autocorrelation, which is generally the one of greatest interest, is 0.97. The critical values at the 5 % significance level are -0.062 and 0.062. This indicates that the lag 1 autocorrelation is statistically significant, so there is strong evidence of non-randomness.\nA common test for randomness is the runs test.\nH0: the sequence was produced in a random manner Ha: the sequence was not produced in a random manner Test statistic: Z = -30.5629 Significance level: α = 0.05 Critical value: Z1-α/2 = 1.96 Critical region: Reject H0 if |Z| > 1.96Because the test statistic is outside of the critical region, we reject the null hypothesis and conclude that the data are not random.\n|Distributional Analysis||Since we rejected the randomness assumption, the distributional tests are not meaningful. Therefore, these quantitative tests are omitted. Since the Grubbs' test for outliers also assumes the approximate normality of the data, we omit Grubbs' test as well.|\nIt is sometimes useful and convenient to summarize the above\nresults in a report.\nAnalysis for resistor case study 1: Sample Size = 1000 2: Location Mean = 28.01635 Standard Deviation of Mean = 0.002008 95% Confidence Interval for Mean = (28.0124,28.02029) Drift with respect to location? = NO 3: Variation Standard Deviation = 0.063495 95% Confidence Interval for SD = (0.060829,0.066407) Change in variation? (based on Levene's test on quarters of the data) = YES 4: Randomness Autocorrelation = 0.972158 Data Are Random? (as measured by autocorrelation) = NO 5: Distribution Distributional test omitted due to non-randomness of the data 6: Statistical Control (i.e., no drift in location or scale, data are random, distribution is fixed) Data Set is in Statistical Control? = NO 7: Outliers? (Grubbs' test omitted due to non-randomness of the data)""]"	['<urn:uuid:f010deea-76f5-4516-a838-a7e85784e908>']	factoid	with-premise	concise-and-natural	distant-from-document	single-doc	expert	2025-05-12T23:56:45.148498	12	7	765
76	I'm hoping to enter my first book into a major literary competition. Can you explain what the monetary prizes are for the National Book Awards and what other benefits winners receive?	The National Book Awards offer significant monetary prizes. Each finalist receives $1,000, a medal, and a citation from the panel at a private Medal Ceremony. The Winners in each of the four categories (Fiction, Nonfiction, Poetry, and Young People's Literature) receive $10,000 and a bronze sculpture. Beyond the monetary rewards, winners and finalists become permanent members of the National Book Foundation family. The Foundation continues to support them by promoting their new books and upcoming readings, and inviting them to future National Book Award-related events.	['How the National Book Awards Work\nWhat Is the National Book Award?\nEstablished in 1950, the National Book Award is an American literary prize administered by the National Book Foundation, a nonprofit organization. A pantheon of such writers as William Faulkner, Marianne Moore, Ralph Ellison, John Cheever, Bernard Malamud, Philip Roth, Robert Lowell, Walker Percy, John Updike, Katherine Anne Porter, Norman Mailer, Lillian Hellman, Elizabeth Bishop, Saul Bellow, Donald Barthelme, Flannery O’Connor, Adrienne Rich, Thomas Pynchon, Isaac Bashevis Singer, Alice Walker, Charles Johnson, E. Annie Proulx, and Colum McCann have all won the Award.\nWho Are the Judges?\nEach year, the Foundation selects a total of twenty Judges, including five in each of the four Award categories: Fiction, Nonfiction, Poetry, and Young People’s Literature. Historically, Judges are published writers who are known to be doing great work in their genre or field, and in some cases, are past NBA Finalists or Winners. As of 2013, judging panels will no longer be limited to writers, but now may also include other experts in the field such as literary critics, librarians, and booksellers. One of the five Judges on each panel is selected as the panel chair. This person acts as the voice of the panel and the liaison to the Foundation. The Foundation staff takes no part in the Judges’ deliberations, except to verify a submission’s eligibility.\nWho Can Submit Books?\nEach April, the Foundation sends the official National Book Awards guidelines and entry forms to the publishers in its master database. Those publishers who do not receive the materials automatically can call or email the Foundation to request a copy. Authors cannot submit their books themselves; they must have their publishers contact us directly. However, the guidelines are always available for informational purposes here: www.nationalbook.org/nbaentry.html.\nIn order to be eligible for the Award, a book must be written by an American citizen and published by an American publisher between December 1 of the previous year and November 30 of the current year. Self-published books are only eligible if the author/publisher publishes the work of other authors in addition to his own. Books published through services such as iUniverse are not eligible for the Award.\nEach publisher must submit a completed entry form to the Foundation by May 15. They must then mail one copy of each entered book to the Foundation, as well as one copy to each of the five Judges in the appropriate category, by July 1. The entry fee is $135 per book.\nHow Are the Finalists Chosen?\nEach panel reads all of the books submitted in their category over the course of the summer. This number typically ranges from 150 titles (Poetry) to upwards of 500 titles (Nonfiction). As of 2013, each panel will now compile a “longlist” of ten titles, to be announced in mid-September. They will then narrow down that list to five Finalists, to be announced in mid-October. They may arrive at these choices using whatever criteria they deem appropriate, as long as they do not conflict with the official Award guidelines.\nThe Finalists Announcement has taken place at various literary sites around the country, from William Faulkner’s front yard in Oxford, Mississippi (2005) to the Flannery O’Connor Childhood Home in Savannah, Georgia (2010). In 2011, the Finalists Announcement was made on Oregon Public Broadcasting’s morning radio program “Think Out Loud,” and in 2012, the announcement was made on TV for the first time, on MSNBC’s “Morning Joe.”\nHow Are the Winners Chosen?\nNo one, not even the Foundation staff, learns who the Winners are until the day of the National Book Awards Ceremony and Benefit Dinner, which takes place in mid-November in New York City. That afternoon, over lunch, each panel collectively decides who the Winner in their category will be. Often, this decision has been made ahead of time, but occasionally the panel works to come to a consensus until the very last minute. The panel chair announces the Winner at the Ceremony that evening.\nWhat Does the Award Entail?\nThe night before the Awards, each Finalist receives a prize of $1,000, a medal, and a citation from the panel at a private Medal Ceremony. Immediately following the Medal Ceremony, all twenty Finalists read from their nominated books at the Finalists Reading. The four Winners in Fiction, Nonfiction, Poetry, and Young People’s Literature are announced the following evening at the National Book Awards Ceremony and Benefit Dinner, where each Winner receives $10,000 and a bronze sculpture.\nOnce an author has been a National Book Award Finalist or Winner, he or she becomes a permanent member of the National Book Foundation family. We do our best to keep in touch with both the authors and publishers, promote the authors’ new books and upcoming readings, and invite them to future National Book Award-related events. Check us out on Facebook, Twitter, and Tumblr to see how we continue to support past Winners and Finalists all year round.']	['<urn:uuid:a101fd47-c708-44c0-ae6d-fdc058da56ac>']	open-ended	with-premise	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-12T23:56:45.148498	31	85	823
77	traditional masonry repair skills course duration compare digital design sessions	The traditional masonry repair course is a one-day workshop, while the digital design training consists of 6 sessions of approximately 2.5-3 hours each.	"['- Skills Training\n- Repairing Traditional Masonry Structures\nThis one day workshop covers the construction and appropriate repair of traditional masonry structures such as culverts, tunnels, light houses, viaducts, canals, harbours, retaining walls, piers and masonry arch bridges\nTaught by a blend of theory and practical ‘hands-on’ sessions, this course covers the construction and appropriate repair of traditional masonry structures such as culverts, tunnels, light houses, viaducts, canals, harbours, retaining walls, piers and masonry arch bridges using natural stone and the range of lime and early patented cements that have been used in the past as bedding and pointing mortars.\nThese structures contribute so much to the richness of our built heritage and many are still in use after 200+ years. But in many cases, we are asking these structures to outperform any of the expectations that their original designers intended, which can leave us with various ‘headaches’ to deal with, without spoiling their beautiful aesthetics.\nThere are now a wide range of lime and natural cement binders along with additives that can be used to emulate both the technical and aesthetic performance of original mortars in repair schemes from re-pointing to stitching cracks and grouting structures to secure them.\nDownload full course description here (PDF)\nThis workshop is suitable for Structural and Civil Engineers and their technicians including those that look after our roads and railway network, contractors working on unprotected masonry structures and for custodians of our industrial heritage.\n- Recognising different types of failures in masonry construction;\n- Ability to recognise different types of mortar, which are original and which are later interventions;\n- Understanding masonry unit construction in solid walls and masonry arches and the role of mortars;\n- Identifying voids in structures;\n- Understanding the principles of grouting;\n- Identifying the mortar performance requirements of replacement mortars on different elements of a structure, including above and below high and low water marks, cut waters, piers, abutments, bridge spandrel walls subject to heavy road traffic, parapets, retaining walls, embankments, undersides of arches, tunnel walls and the like;\n- Use of additives to augment the working and final performance characteristics of replacement mortars and grouts;\n- Making and using mortars with accuracy and consistency;\n- Correct application and curing of mortars for repointing, grouting and rebuilding works;\n- Identifying dormant cracks in masonry structures;\n- Crack stitching with mortar and stone and concealed embedded stainless steel reinforcement.\n- Health and safety issues\n- Historic use of lime and early patented cements used in traditional mortars\n- Common types of failures and remedies appropriate to masonry structures including masonry arches\n- British and European Standards for building limes and natural cements\n- Choosing appropriate sands and aggregates for mortars and grouts\n- Additives for use in replacement mortars\n- Best practice for proportioning materials for accurate and consistent mortar mixing\n- Building a masonry arch in natural stone dry\n- Repointing masonry\n- Designing and executing grouts to consolidate voided structures\n- Stitching dormant cracks in masonry with stone and mortar and with concealed stainless steel reinforcement\n£200.00 + VAT\n(£240.00 incl VAT)\nContact me when a new date is scheduled\n15th August 2023 - 10th November 2023\n08th August 2023 - 26th January 2023\n11th April 2023 - 28th June 2023\n03rd September 2021 - 9th February 2022', ""Time17:30 — 20:30\nAbout this Workshop\nFormat: 6 pre-recorded sessions, which you can access anytime via the links below\nVenue: Online, pre-recorded course\nSkill Level: For beginners or intermediates\nWatch our 6-session course and bring your ideas to life! During this 6-session training, you will learn how to digitally design forms and realistic designs in 2D and 3D using free open-source software such as Autodesk Fusion 360.You will explore the various software functions, and have the opportunity to design small objects throughout the course. After each training session, you will be given a design exercise to design small objects from the comfort of your home.\nThe CAD (Computer Aided Design) and CAM (Computer Aided Manufacturing) skills you will gain from this training can be applied to almost any project or industry.\nThrough our 'Design Almost Anything' training, you will:\n- Learn how to design objects, products and artworks in 2D and 3D using Autodesk Fusion 360 and other software such as Inkscape, Slicer and Meshmixer\n- Learn how to use the various functions of Autodesk Fusion 360, such as Extrude, Revolve, Loft and Sweep, but also Sculpt and rendering to make your design look realistic and professional\n- Learn how to prepare your designs for digital fabrication machines such as 3D printers, laser cutter and CNC milling machines, and understand the many possibilities of 3D and 2D digital fabrication\n- Have the opportunity to design small objects\n- Understand budgeting and costs of making your designs in the Fab Lab\n- Learn how to find open source (accessible to everyone) designs online\nEquipment & Software Requirements\nEnsuring that you have the equipment, software and basic skills needed prior to beginning the training is very important so that you can follow and learn CAD and CAM skills during this course. Please carefully read our Info Pack, which provides links and details to all equipment and software that you will need.\nThis training was originally held over 6 weekly online sessions that have been recorded and added to the Smart Citizens video channel, with each video being roughly 2.5-3 hours long. You can access these videos at any time and at your own pace through the following links:\nSession 1 - In Week 1, tutor Owen explored 3D digital design using Autodesk Fusion 360.\nSession 2 - In Week 2, tutor Ian explored Cura, 3D printing and Slicer.\nSession 3 - In Week 3, tutor Ian explored 2D digital design and fabrication using Fusion 360 and Inkscape.\nSession 4 - In Week 4, tutor Owen explored lines, duplication and browser organisation in Fusion 360, PreForm, as well as SLS and SLA 3D printing demonstrations.\nSession 5 - In Week 5, tutor Ian explored 3D scanning and Meshmixer to create 3D models.\nSession 6 - In Week 6, tutor Owen explored the process of designing for CNC subtractive machining.\nWho is this workshop for?\nThis free 6-session training is open to everyone, 16 years or over. It is suitable for beginner and intermediate levels - perfect for those wanting to gain new skills, or develop existing skills in 2D and 3D digital design. No previous experience of computer aided design (CAD) is required.\nThis event is part of the iMayflower project and has been supported by The Department for Digital, Culture, Media and Sport, who fund the Cultural Development Fund, which is administered by Arts Council England.""]"	['<urn:uuid:753189d5-b463-4963-ae12-3681431e26ca>', '<urn:uuid:dbf3ae86-59ce-4ecf-99ce-1d4662fd1dd4>']	factoid	direct	short-search-query	similar-to-document	comparison	expert	2025-05-12T23:56:45.148498	10	23	1115
78	I'm wondering when would be the best time to prune my blueberry bushes that I grow in containers, and what exactly should I be cutting back?	Blueberries should be pruned in late winter just before growth begins. For container-grown blueberries, the goal is to open the center of upright bushes and remove low, shaded branches on spreading bushes. You should focus on removing wood that is over 4 years old since it has lost its vigor. It's also important to prune out old canes and encourage new growth coming from the roots. If any shoots appear in late summer, these should be pruned off.	"['Pruning Container Grown Blueberries Getting Rid of Tomato Blight Better to Till Soil In The Fall or Spring Keep Apple Tree In A Container When To Dig Geraniums Up For Overwintering Lemon Tree Turning Yellow Are Jacaranda Flowers Safe To Cook With Pruning Virginia Creeper Vine\nPlease scroll down to read the answers.\nQuestion #1: Pruning Container Blueberries\nI have three blueberry bushes in containers. These bushes are especially grown for containers.I am not sure how and when to prune them. Can you please advise? Thanks.\nPeter Tilburn, Pickering, North Yorkshire, England\nANSWER: Hi Peter! Blueberries (Vaccinium spp.) are wonderful to grow, and with all the new varieties out these days, they can be grown just about anywhere.\nSounds like you have midhigh blueberry varieties - these are a hybrid cross between highbush and lowbush varieties and are bred for growing in containers. These types of blueberries have similar pruning requirements to other varieties, but here is what I would do with yours:\n1. New plants should be pruned back at planting time. They should be cut back by one-fourth and any low, bushy growth near the base of the plant pruned away.\n2. After 2 or 3 years of growth, regular pruning can start. On upright bushes, the goal is to open the center of the bush. On spreading bushes, the goal is to remove any low, shaded branches.\n3. Prune plants in late winter just before growth begins.\n4. Because blueberries bear fruit on the previous year\'s wood, and they bear best on young branches which are sending out vigorous new growth each season, the main goal of pruning is to keep the bush well supplied with young, fruitful branches.\n5. After wood becomes 4 years old, it has lost its vigor and won\'t produce as well.\n6. Prune out old canes and encourage new growth coming from the roots. For thinning, take twiggy branches off newer canes. If any shoots appear in late summer, prune them off.\nFor more detailed information about growing blueberries and several bush and bramble berries please read:\nThis year in central Pennsylvania we were hit with tomato blight.I know it is an air-borne fungus. My question to you is do I treat the soil this fall for next spring or do I just let it go? Thank You.\nJames L Hawkins, Glen Hope, PA, USA\nANSWER: Hi James! This is a very good question. First let\'s take a look at blight because there are two forms of it: Early blight and late blight. Each is equally destructive.\nThis is caused by a fungus that survives during the winter on old vines, it overwinters in plant residue, and is soil-borne. It can also come in on transplants.\nEarly Blight Control\nTo fix, remove and destroy all diseased foliage. In the future, avoid overcrowding by planting farther apart, and prune for good air circulation. You\'ll also need to rotate tomatoes with unrelated crops, such as corn, beans or lettuce because the fungus can get into the soil and will simply reinfect your tomatoes the following year.\nWet weather and stressed plants increase likelihood of attack so don\'t get the foliage wet when you water, and keep your tomatoes as healthy as possible. Thickly mulching helps limit splashback reinfection from your soil. Fungal disease however, is also airborne, so you can also use a good fungicide like Soap-Shield Liquid Copper Fungicide This fungicide will prevent further development of the fungus.\nThis is caused by a fungus that is favored by wet weather. The spores travel great distances and can infect large areas.\nLate Blight Control\nAgain, avoid overcrowding, and if the infection is severe and widespread, remove and destroy all affected plants. Late blight fungus can overwinter in frost free areas, and since it spreads to potatoes, it also overwinters in potato debris and seed, even in colder areas. Remove all debris. Rotate tomatoes with unrelated crops, use a good fungicide like Soap-Shield Liquid Copper Fungicide This fungicide will prevent further development of the fungus.\nUse Raised Beds\nLastly, if your soil and area are too infected, try setting up a new area using raised beds and fresh soil. Make sure to rotate your crops in a raised bed as with a regular garden plot, so no fungus will build up for future problems.\nI hope this helps and you can have healthier tomatoes in the future.\nQuestion #3: Better to Till Soil In The Fall or Spring?\nIs it best to till up the soil for the garden next year or best to wait until spring? We want to add topsoil and wondered when is the best time of year to add the soil?\nMary Altmeyer, Newburgh, IN, USA\nANSWER: Hi Mary! Actually I just blogged about this very topic about two weeks ago, so yours is a timely question!\nI personally think that any time you want to add compost or topsoil to your garden is a good time, but that said, there are a couple of considerations.\n1. Soil preparation in the fall can be super beneficial because it can help control insects and overwintering bugs, and by adding organic matter in the fall, your soil will be in better condition by springtime and will be easier to dig and plant.\n2. If you add a large amount of organic matter such as guano, compost, bark, and manures in the fall, it will start decomposing because the microbes are active currently and ready to start breaking everything down.\n1. Tilling in the fall can cause some soil erosion if your area gets huge rain or winds during the fall and winter months. If that is the case, think about the tradeoffs of losing good topsoil to waiting and doing your tilling in the spring.\n2. Be careful not to ruin your soil structure. Never work wet soil, especially clay. You may ruin the soil structure for years to come. Here\'s how to best determine How To Care For Your Soil Structure with this step-by-step article: Care For Your Soil Structure\nI personally add organic matter both in the fall and in the spring. I live in an area where soil erosion is not a problem and I have great soil. If you have the same conditions, add compost, organic matter, or top soil in the fall, and you won\'t have any problems.\nQuestion #4: Keep Apple Tree In A Container\nI have just bought a Malus \'Gorgeous\'. Could I keep it in a large container as I have not got much room, or up against a wall? How can I keep it small please?\nMarie Twomey, Cork, Ireland\nANSWER: Hi Marie! Well Malus \'Gorgeous\' also known as a White Crab Apple gets about 6 meters (18 feet) tall, but they are considered a good choice for small landscapes where space is restricted because they tend to turn into a really large shrub rather than a tree.\nThey are a very ornamental small tree that has wonderful spring flowers and crimson-red fruit that hang like small cherries so I can see why you chose this particular apple tree, they are beautiful.\nIf you have a very large container, like 1.5 m x 1.5 m (4 feet x 4 feet) you could plant it that way.\nI think your best bet is to plant it by your wall as long it gets full sun. To keep it small just prune it back when it goes dormant in the winter, and prune to shape and size.\nSince this isn\'t a very large tree to begin with, or an aggressive grower, you won\'t have any problems keeping it at the height or width that you want and have room for.\nDuring the summer if you need to prune back a branch or two to keep it to size, or to remove a dead branch, that\'s fine too, you won\'t hurt anything.\nEnjoy your tree!\nQuestion #5: When To Dig Geraniums Up For Overwintering\nThe Overwintering Geraniums article your did is of great help. I do have one question, though. I live in zone 5 and my Geraniums are still in bloom. When is the correct time to dig the Geraniums up?\nTo answer your question, the best time to dig your geraniums up is before they get damaged by a heavy frost. That means they may still have leaves and flowers on them. If they do, remove the flowers and don\'t worry about the leaves because they will drop off by themselves during the overwintering process.\nThanks for the question, it\'s always good to clarify these things!\nQuestion #6: Lemon Tree Turning Yellow\nMy Lemon tree leaves keep turning yellow, I have tried trace elements, magnesium, iron chelates, it has blooms and had lemons from it. Do I just leave it alone or does it need more trace elements?\nAileen Young, Cronulla. NSW, Australia\nANSWER: Hi Aileen! Well, it could be a couple of things. You don\'t mention how the leaves are yellow, such as they are entirely yellow, or have green veins but yellow in between, etc. That\'s Ok, but let\'s take a look at some nutrient deficiencies and see if anything matches up for you to help diagnose what the problem is.\n1. Check to see how much you are watering. Lemons don\'t like wet feet and if the soil is too wet, then their leaves will turn yellow.\n2. I noticed you didn\'t mention giving your lemon a good balance fertilizer (like a 10-10-10) three or four times a year. Are you doing that? Lemons need a good source of nitrogen, so check your feeding schedule. If you\'re not giving it proper nutrition it can turn yellow, especially in sandy soil where the nutrients leach out very quickly.\n3. You might want to get your soil tested to see if there is another underlying problem.\nIron Chlorosis Deficiency: Leaves turn yellow from edges inward, veins remain dark green. The same symptoms can be caused by overwatering - so check your watering amounts.\nManganese Deficiency: Fine mottling on young leaves, and pale or yellowish areas between dark green veins.\nZinc Deficiency: Yellowish blotching or mottling between leaf veins. Can happen at the same time as a manganese deficiency. Can be hard to tell one from the other.\nNitrogen Deficiency: Yellow across entire leaf surface and smaller than normal leaves. On some plants the leaves can turn red or purple.\nPotassium Deficiency: Tips and edges become yellow with brownish-purple spotting.\nCheck to see if any of the above match up to what you are doing and let me know if you can. Good luck!\nQuestion #7: Are Jacaranda Flowers Safe To Cook With\nHi WG, I saw your piece above about Jacaranda tree. I live in Pretoria and we have many many flowering trees at the moment. They are beautiful! Just wanted to know if I can use the blossems in cakes or salads? Thank you in advance!\nCarmen, Pretoria, Gauteng, South Africa\nANSWER: Hi Carmen! I agree with you that Jacaranda (Jacaranda mimosifolia) flowers are stunning, but they are very poisonous and so under no circumstances should you eat them or cook with them.\nIn fact, the seeds are poisonous if ingested, and just about all parts of plant are poisonous if ingested.\nFor some people handling the plant may cause skin irritation, and some people have an allergic reaction to the flower pollen.\nI\'m glad you asked this question!\nQuestion #8: Pruning Virginia Creeper Vine\nWe planted a Virginia Creeper in our front garden this spring and want to know if we should prune it down now that the leaves have fallen off. It is nothing more than a bunch of twigs now on the wall?\nBonnie Lindsay, Alliston, Ontario Canada\nANSWER: Hi Bonnie! Virginia Creeper (Parthenocissus quinquefolia) is a deciduous vine and what you are describing is how they grow. Those twigs on the wall may not look so good now, but they will start growing again in the spring.\nTypically when the vines reach the desired size, prune them back each winter, while they are dormant, to restrain spread and to keep away from doors, windows, or house eaves.\nSimply cut out any branches to trim it back and remove any branches that have pulled away from their support, since they won\'t reattach.\nYou will be able to see the branching structure best during the winter, so prune back as far as you like, it will grow back.\nDuring the growing season, same thing, simply trim back to keep it to the height, size, and width you prefer.\nBasically, Virgina Creeper is most often pruned to prevent it from getting out of control!\nAsk Your Gardening Questions Here:\nIf you have a question, fill out the form and hit the ""Submit Question"" button. Check next month\'s issue for an answer.']"	['<urn:uuid:8ff89308-b76b-4df4-a205-f9ea3595aaba>']	factoid	direct	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-12T23:56:45.148498	26	78	2139
79	chimpanzee trust school outreach program areas	The Chimpanzee Trust conducts its school outreach program in three operational areas: schools neighboring Ngamba Island Chimpanzee Sanctuary, schools in the Northern Albertine rift landscape, and schools around Entebbe. The program aims to pass conservation knowledge to future generations through conservation education activities at local, national and international levels.	['Chimpanzee Trust’s school outreach program is aimed at passing conservation knowledge to the future generation. This has been done through enhancing schools’ participation in conservation education activities at the local, national and international level. The school outreach program is done in three (3) operational areas these are schools neighboring Ngamba Island Chimpanzee Sanctuary, schools in the Northern Albertine rift landscape and schools around Entebbe.\nMusic Dance Drama\nDespite little success to pass on its conservation messages through music dance and drama at National level, the Chimpanzee Trust works closely with Wildlife Clubs of Uganda (WCU) to organise music dance and drama competitions during key conservation events.\nThe Chimpanzee Trust also organises an annual event to create awareness on conservation education among schools on Koome Islands, 13 primary schools are actively involved in this program. Music Dance and Drama contributes to talent deelopment and it improves the learning experience of children hence reducing pupils’ dropout rate among the island community schools.\nDebates and Quiz Competitions\nTeachers from schools working closely with Chimpanzee Trust meet to come up with a theme for the year in line with nature conseration, set up or modify the existing guiding rules, and decide on the hosting community or school.\nThis annual event brings together 13 island schools that debate and participate in a quiz competition to create awareness on nature conservation. Parents are always amused by what their children can do. The activity over the years has improved the children’s communication skills, public speaking and grades in school. We appreciate the support of Born Free Foundation who has sponsored this program over the past years. To support this activity click here\nSchool-Based Enterprises (SBE)\nYouth unemployment remains a serious policy challenge in many sub-Saharan African countries, including Uganda. Rapid population growth and high unemployment of youth (national definition, 18-30 years) in Uganda was at 64%. (UBOS, 2013)\nThe Chimpanzee Trust promotes School-Based Enterprises as a means to bridge the gap between school and the employment world. We promote School Based Enterprises with a bias to education for sustainability (EFS). ,” School-Based Enterprises are school entrepreneur activities that produce goods and services, to meet the needs of the schools’ market and provide learning experiences for students.”\nThe Chimpanzee Trust is currently working on three school-based enterprises including; Beekeeping at Myende Community school (Link picture), Mushroom growing at Munteme Junior school (Link picture), fruit tree growing at Buyana RC primary school (Link picture).\nThe Chimpanzee Trust notes the numerous benefits that School Based Enterprises provide, however the most important is that they provide realistic and practical learning experiences that reinforce classroom instruction and prepare learners for the future employment world. The School Based Enterprises allow students to apply their knowledge and skills in a “live” business setting where challenges arise daily and people interactions are always varied.\nSchool-Based Enterprises, share several traits with Education For Sustainability, including, flexibility, multidisciplinary, promotion of participation, cultural diversity, gender equity, promotion of the culture of peace and non-violence, global citizenship, skills development, human rights, environment and social-economic sustainability. With this in mind, School-Based Enterprise provides a platform that can easily nurture Education For Sustainability in the school and therefore; Foster personal and social development for worthwhile lives, and acquire, develop, transmit, conserve, and discover a worthwhile culture. (Plant, 2005, p. 24)']	['<urn:uuid:c3fa3b12-ba94-4f6c-97db-6f9a509f3a8a>']	open-ended	direct	short-search-query	similar-to-document	single-doc	expert	2025-05-12T23:56:45.148498	6	49	549
80	What happens when you try to use regular printer ink with sublimation sheets, and why doesn't it work even if you try multiple times?	Regular ink will not work on sublimation sheets because sublimation sheets are designed to work with a specific kind of ink that turns into gas. The sheets need to secure this vapor onto the paper. When standard ink is used, it will simply fall right off the page.	['Printing is a necessity for many people. As we often need multiple copies of documents, reports, and records, there’s no sign of printing becoming obsolete yet. Despite this, printing is a process that can cost a lot.\nInk and specialty papers are usually highly-priced, which is why it can be tempting to save money by using alternative papers in the machine.\nMany people continue to do this with sublimation paper, a particular type of transfer paper.\nSo, is sublimation paper suitable for all kinds of printers? The short answer is no.\nUsing sublimation paper in your standard printer is a bad idea and you won’t receive the intended outcome.\nOnly printers that are designed to handle sublimation ink can be used with transfer paper, provided the ink and paper are compatible. Regular printers just aren’t compatible in this way.\nWe’ll cover more about why sublimation paper isn’t suitable for regular printers, including whether you can convert your home printer to handle sublimation paper.\nWhat Is Sublimation Paper?\nSublimation paper is a special kind of heat-sensitive paper. This is the main reason why sublimation paper is so different from regular paper.\nInstead of being used to print books and reports, sublimation sheets are specially treated to print images onto fabric and clothing.\nOnce the paper is exposed to heat, the ink transfers from the paper onto fabric.\nThis allows you to create custom designs or images without having to use embroidery or expensive equipment.\nThe main benefit of sublimation paper is that it doesn’t require any specialized equipment.\nIt works well with printers that are designed to handle sublimation printing. However, not every printer has these features.\nWhy Can’t All Printers Handle Sublimation Paper?\nDifferent kinds of papers are designed to do specific functions. This is why printers often state which types of paper are compatible with their model.\nSome printers won’t be able to handle sublimation paper due to the way sublimation sheets are made.\nIn the case of standard printer paper, ink handles the job of printing things onto the page.\nSublimation paper is different, as the paper does the job of printing on each sheet.\nAs sublimation ink is heated, it transforms into a gas. This vapor is compressed onto paper to leave a fixed, detailed pattern.\nMost printers aren’t equipped with printer heads or ink canisters that are compatible with the sublimation method, which is why these printers won’t be able to use sublimation paper.\nWhat Kinds Of Printers Can Use Sublimation Paper?\nNow you know why most printers aren’t able to handle sublimation paper, you should assess whether your current printer can handle the sublimation process.\nThese are some general observations for printers that can handle sublimation paper.\nPrinters Designed For The Sublimation Printing Process\nThese printer models tend to be advertised as sublimation printers. This allows people to buy them if they specifically need to carry out sublimation printing.\nIf a printer states that it is a sublimation printer, it can always handle sublimation paper.\nInkjet Printers Compatible With Sublimation Paper\nThe majority of lower-priced inkjet printers won’t be able to do so, but higher-quality ones may be able to handle sublimation printing.\nSome workforce printers may be compatible too, but do your research and look at different models to find out.\nPrinters that can handle sublimation paper will state that they are compatible with its description or specifications.\nIf you’re unsure, you can look up the model of your printer online and check its details.\nPrinters That Aren’t Compatible With Sublimation Paper\nIn most cases, printers that aren’t advertised as sublimation-compatible will not be able to handle sublimation paper. The following guidelines can help you avoid these printers.\n- Printers that are affordable and lower in quality aren’t likely to have sublimation-friendly printer heads.\n- The majority of HP printers aren’t sublimation compatible, but you may be able to convert them by purchasing a CISS kit.\n- Any printers that specifically state they aren’t compatible with Sublimation CISS Ink won’t work with sublimation paper.\nCan Regular Printers Convert Into Sublimation Compatible Models?\nIn theory, you may be able to convert a printer into a sublimation compatible machine.\nIf your printer states they can handle CISS Ink, you may be able to swap the printer heads so the machine works with sublimation sheets.\nHowever, this converting option is currently only possible with particular Epson printers.\nSome of the easiest printers to convert into sublimation compatible machines are models from the Epson EcoTank Series.\nIf you want to convert your printer into a sublimation compatible one, you will need to purchase a CISS Ink system.\nCISS systems can vary depending on the brand you go for, so ensure that you choose a system that can work with your current printer model.\nWhat Will Happen If Sublimation Paper Is Used In A Regular Printer?\nIf you use sublimation paper in a printer, you’ll just be wasting your money.\nSublimation sheets won’t damage your printer straight away, but any images or words you print won’t bond with the paper. You’ll be wasting time, effort, and money.\nHow To Prepare A Printer For Sublimation Paper\nIf you want to print on sublimation paper, you need to have a sublimation compatible printer and sublimation ink on hand. Follow these steps to prepare your printer for the process.\nIf your printer needs to be converted, make sure you do so beforehand. Install your CISS Ink system following the instructions that came with the product, or by the following advice online.\nNext, swap your standard ink canister for sublimation ink ones. These cartridges should make an audible click once they are securely in place.\nNow switch your standard paper for sublimation sheets.\nIf your printer needs any software, load this up, then start printing. Some kinds of printers will need specific software so they can handle sublimation sheets properly.\nYou should be able to find this software and any necessary information regarding it online.\nCan Standard Ink Be Used On Sublimation Sheets?\nAs hard as you try, regular ink will not work on sublimation sheets, no matter what you decide to print. Sublimation sheets of paper are designed to work with a specific kind of ink.\nThis ink will turn into gas, so the sheets need to have the ability to secure the vapor down onto the paper.\nStandard ink isn’t compatible with sublimation sheets, which is why this ink will fall right off the page if they are used to print with.\nSublimation paper is designed specifically for printing on clothing. The ink which sticks to paper won’t produce a bold result on the fabric.\nCan Standard Paper Handle Sublimation Ink?\nYou print on regular paper using sublimation ink, but the result won’t be up to standard.\nAs the printing session continues, traditional sheets of paper aren’t designed to carry the ink well.\nIf sublimation ink is used in this way, around half of a cartridge can be wasted in the process.\nThe result is a smudged design that will continue to fall off of the page. You won’t be able to transfer this design onto fabric at all, so don’t waste your time trying.\nStandard paper won’t be able to handle transferring designs as sublimation sheets can.\nAlternatives To Sublimation Printers\nHere are some alternative solutions to sublimation printers.\nPaying For Professional Printing\nThis will cost you money, but paying for this service will ensure your desired pattern is printed on your fabric properly, without issue.\nHeat Transfer Sheets\nSublimation sheets are usually the most common method of transferring patterns onto fabric, but heat transfer paper is another option.\nMost printers can handle heat transfer paper, but always remember to check beforehand.\nTry Screen Printing\nScreen printing is another way of transferring your designs onto clothing or fabric, but it does take a lot of time to learn.\nSublimation printing is an amazing way of creating unique clothes and fabrics.\nHowever, if you’re not using a special kind of printer, you won’t be able to get the best results from the process.\nSo if you want to create stunning pieces of art, you’ll need to invest in a sublimation compatible device.\nThis means converting your current printer or swapping out your existing one for a sublimation compatible version. Once you’ve done this, you’ll be ready to start sublimation printing!\n- The 10 Best Sublimation Blank Wholesale Suppliers - July 12, 2022\n- The Best Wholesale Sublimation T-Shirt Blanks Suppliers - July 12, 2022\n- Eight Common Reasons Why Your Heat Vinyl Transfer Won’t Adhere To Garments - July 12, 2022']	['<urn:uuid:64126290-9e27-460c-acd9-46c7be82e820>']	factoid	direct	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-12T23:56:45.148498	24	48	1430
81	When setting up a new router at home, what steps do I need to take to make it work well for online games, and what should I do to keep hackers out of my network?	For gaming optimization, you should: update your router's firmware, enable MU-MIMO for multiple data streams, select less congested wireless channels, and enable Quality-of-Service to prioritize gaming traffic. For security, you must: set up WPA2 or WPA3 encryption, change the default username and password, enable the firewall, set up a separate guest network, and configure a VPN. The router should be placed close to your gaming setup for the best connection, and you should ensure your modem can handle your internet speeds.	"['Router settings for gaming are all about ensuring the connection is as good as possible. You want the computer running a game to have a prioritized connection in some cases or to be on a different channel if there’s interference. Anything you can do to improve your speed and reduce latency will help you have a better gaming experience.\nOf course, not all options will be available on all routers. If you want to optimize your gaming router setup, choose a router designed for that purpose.\nWhy Setup My Router for Gaming?\nSetting up your router for gaming can give you a better overall experience. When your connection is stable and smooth, games just run better. A shaky connection could introduce lag or even crashes to a game at the worst possible moments.\nOn the other hand, choosing the proper settings for your router can enhance everything about your gaming experience. Load times, lag, and other problems that might keep you from accomplishing your goals will improve – as long as your basic connection is good enough. Specific settings benefit you more than others.\n- Switch Wi-Fi Band: If you can’t use a wired connection to your modem or router, you can change the wireless network settings on your router to give yourself access to a better Wi-Fi band. It can help improve your connection because the lower bands are compatible with more devices and are generally more congested.\n- Switch Channel: Changing the wireless channel, you’re operating on can also improve your gaming experience by reducing interference. Some channels are used more than others and swapping to one with fewer devices can improve your connection.\n- QoS Adjustment: Many routers offer a Quality-of-Service option that adjusts how the data packets moving through your network are handled. If you need better performance on your gaming PC than your television, microwave, cellphone, and other wireless devices, you can prioritize it with a tweak on QoS.\nThese are only some changes to your router settings that will help optimize your gaming connection and make you more familiar with adjusting your router settings. Get acquainted with the adjustments, and you’ll be able to easily redo them whenever you swap routers or add a new device to your gaming array.\nBest Router Settings for Gaming\nThe best router settings for gaming are the ones that work best for you. Try changing them one at a time and then playing your favorite fast-paced game to see how it performs with different settings selected.\nChange Your Router’s Settings\nIt might initially seem a little complicated if you haven’t adjusted your wireless network before. However, it’s pretty easy once you get used to it. Here’s how you gain access to start making changes.\n- Look for a label on your router that lists device information, including the default name and password. If you don’t see it there, check the manual for the router. You can also use a search engine to find your router model’s standard user ID and password. They’re all the same until you change it – which you should do once you gain access to the router’s settings for security purposes.\n- Use a web browser to navigate to your router’s default gateway. If you aren’t sure what it is, check the router manual or type\nipconfiginto a Command Prompt window. The address you’re looking for will be listed as the default gateway.\n- Enter the basic user ID and password to log in. Again, change these once you’re in and use ones you’ll remember that will be difficult for others to guess.\n- Update your router’s firmware if an update is available. It might offer more options to improve your gaming experience versus the old firmware, fix problems, and optimize what’s already there.\n- Look around at the available settings to get comfortable navigating the router options. You don’t have to change anything. Just click through the different categories, check out the advanced options, and see what kinds of things are available. As you try to make specific adjustments, seeing it and knowing where it is can help.\nEvery router is different, and the ways to find settings on mine might not be exactly what’s right for you. However, a little preparation and familiarizing yourself with what settings are available and where they are will make optimizing your connection a lot easier.\nChoosing a Wireless Network\nMany modern routers offer more than one wireless network that can be broadcast from the router. You have to enable the networks, set up their options, and then connect to the right one with your gaming PC.\nThe most important part of this is choosing the correct wireless network. Routers almost all offer 2.4 and 5 GHz options for Wi-Fi networks. Some routers may have a higher 6 GHz band as well. You want to connect to the highest and least-used band that your computer’s networking card can handle.\n- Sign into your router and look for an option for Wi-Fi networks. It might be in Advanced Settings or have its own category. For example, my router requires me to choose Wireless Signal.\n- Turn on the higher-band network if it isn’t already enabled. You want to run multiple wireless networks if your router allows it so that other devices can connect on the lower band network.\nOn mine, I click Enable the Wireless Band to make the network active, and then I click Apply. However, it’s already active by default on most routers, including mine.\n- Give the network a different name from the others so you can recognize it easily. The name doesn’t have any bearing on its performance, so it’s based on pure preference.\n- Set a password that you’ll remember, but that’s difficult for others to guess.\n- Save the changes.\n- Swap devices that aren’t your gaming computer to the lower band networks you don’t intend to game on. Check your phones, smart devices, and other computers.\n- Connect to the high-band network from your gaming PC with the username and password you set.\nThis works because the 2.4 GHz network is overwhelmed by users a lot of the time. Almost every device will connect to this wireless network – and more devices than ever have network connections these days. Your other home appliances could all be using the 2.4 GHz network and reducing the amount of bandwidth available to your gaming PC.\nThe 5 and 6 GHz networks are less likely to be compatible with smart devices and older legacy devices. That’s a significant reason why they’re less congested.\nSet Your Wireless Channels\nWireless channels are like lanes where information can flow from one place to another. If too many devices try to use the same lane, the traffic gets crowded, and things slow down. Choosing a wireless channel with less usage for your gaming computer can help improve the connection and reduce lag.\nOne of the challenges with finding the proper channels is that they aren’t necessarily standard. It would be best to find out which ones near you have less congestion and use those with a wireless analyzer. Luckily, you can use a free one from an app if needed.\n- Download a wireless channel analyzer app. There are plenty available for free that will work for a basic scan. Once it’s on your phone, run it to see what channels more congestion might have based on where you live. If you live near many other people and many other routers, you might see a considerable overlap.\n- Log into your router and go to your Wi-Fi Settings. On mine, I have to choose Wireless and then set my Region.\n- Navigate to the wireless band you want to adjust. For most gamers, you’ll be looking for a 5 GHz network. On my router, there are two 5 GHz and a 2.4 GHz, so I would select the 5 GHz network I am using on my gaming computer rather than the other.\n- Select a channel. Choose any number that might work based on your channel analysis. You can always swap it out later if you don’t see a performance improvement.\n- Save your settings and exit the router menu.\nMost routers are configured to select the best possible channel, but that doesn’t always work. You can run a speed test or check your ping and frames in your game with each swap to see how it’s affecting your gaming connection. If a channel offers significant improvement, stay on that one instead of using the default suggested by the router.\nThe Quality-of-Service feature in routers is fantastic because it means all traffic isn’t treated the same. It shouldn’t be. Different programs have different network delivery needs that affect how well they perform.\nFor example, a program just passively downloading a file doesn’t need fast and frequent network traffic. If it’s a little delayed, it won’t affect the final file and will only take a bit more time to finish. If you’re in a first-person shooter or endgame MMO raid and the network starts prioritizing a download instead of your game, it could make a profound negative impact.\nYou may also want to try a Dynamic Quality-of-Service option. This can change priority based on current network activity. Netgear recommends using it on connections slower than 300 Gbps.\n- Log into your router and look for a Quality-of-Service function. It might be abbreviated as QoS.\n- Choose to enable Quality-of-Service, especially dynamic, if you have slower internet speeds. You may need to tell the router your bandwidth or enable automatic detection. The automatic option is the better choice for most people. My router requires a speed test, and Netgear recommends having no other devices connected to the network during it.\n- Adjust any settings your router requests. You may have to specify which computer or applications you want to prioritize.\n- Save your settings.\nIf you don’t see this option on your router, you may have to upgrade to a newer one. However, if you have a fast connection, you may not need it.\nMultiple User-Multiple Input Multiple Output is a newer protocol that lets routers transfer information more effectively than the old single output style. Instead of only sending information to one connected client at a time, MU-MIMO enables multiple streams, so information comes through more quickly. This is very useful for gaming, especially if you have multiple connections on your Wi-Fi network.\n- Connect to your router. Navigate to the same place you set up your wireless networks. It could be in Advanced Settings, Networking, or elsewhere. It all depends on what router you’re using.\n- Search for an option to enable MU-MIMO. You will probably have to select a box or toggle a button to turn it on if it isn’t on by default.\n- Save your settings.\nMU-MIMO offers many benefits but can also lead to less stable connections on some older devices. If you notice a performance drop after enabling it, go back in and turn it off.\nWhat Else Can I Do to Improve My Gaming Connection?\nYou can do a few other things to boost your connection once your router settings are perfected. It all depends on how much money and time you want to put into your network connection.\n- Look for a newer router or upgrade your wireless card. While this can cost money and take time to set up, using old equipment can seriously hamper your performance. Older routers may have only some of these settings available, and you might not be able to create as stable a connection without them.\n- Check your modem and what speeds it’s capable of handling. If your modem can only handle 300 Mbps and you have a Gigabit connection, you’re losing out on a lot of speed. It will affect every part of your network. If you aren’t sure what routers and modems are compatible with your connection, speak to your ISP to get a list.\n- Move the router closer to where you game. Distance definitely doesn’t help you get a stronger connection. Physical barriers like walls or heavy furniture can also reduce the actual speed you get.', ""Cybersecurity is a necessity for any modern home network. In order to achieve this effectively, you will need to make sure that you are using the most secure router possible, locking down your network to the best of your ability.\nYou will still want a router that performs well and is capable of everything you need, but you will also want to have the best security features like encryption, firewalls, and even parental controls.\nMalware and cybercrimes are on the rise, especially as more people are spending their days online. Here are the best routers for security on the market right now.\nFeatures That The Most Secure WiFi Router Should Have\nIn order to keep cybercriminals out of your network, you need to consider the WPA encryption you are getting from your router. The WPA2 is the most widely-used form of encryption on the market, but the newest form is the WPA3.\nRegardless, you never should opt for a router that has neither of these options. Encryption makes it hard for anyone to simply walk into your network and begin poking around, so look at WPA first.\nGuest Network Access\nEveryone needs WiFi, regardless of where they are at, including your friends or family that is over. The best thing that you can do for a visitor is to have a guest network setup on your router.\nThis way, an outsider cannot access your shared files or even the devices within your network, ensuring that they do not accidentally breach your security settings and allow in malware to your network.\nHaving a VPN or Virtual Privacy Network is also a great way to ensure your security online. A VPN works by hiding your IP address from websites that you might be visiting, so nothing can make its way back into your network.\nEven the web traffic is encrypted, so anything interfering it would not be able to work out what your actual destination was. Routers should come with a VPN and you need to make sure it is enabled.\nParental Controls & Time Access Restrictions\nFinally, when securing your router, make sure that the router has parental controls, which might include time restrictions. As children are needed to be more and more online, the need for this is continually greater.\nIt can prevent children from accessing dangerous content while also keeping cybercriminals away from them. Time limiting is another great feature, where the router can disable their device after a set amount of time.\n7 Most Secure Routers (2022)\n1. Netgear R7000\n2. Synology RT2600\n3. Turris Omnia\n4. Linksys EA7500\n5. Asus RT-AX88U\n6. Gryphon AC3000\n7. Linksys WRT 3200\n1. Netgear Nighthawk R7000 WiFi Router\nMost Secure Router (Editor's Choice)\nOur choice for the most secure router is the Netgear Nighthawk R7000. The R7000 has good speeds, reliable performance, and all of the security features you need.\nThe R7000 is a horizontal router made with three high-gain antennas that can be positioned in the direction that you need most. The design is large, so it will take up a lot of room on your shelf.\nThe router also uses Amazon Alexa voice controls of you have any Amazon devices in your home. Beyond the USB 3.0 port, you will get 4 x 1 Gigabit Ethernet ports.\nThe R7000’s security includes supporting WPA2 wireless security protocols, guest WiFi access, a firewall, a VPN, and DoS.\nThe Netgear Armor will protect your network from malware and viruses under a paid subscription. The router also connects to the OpenVPN Connect App, which allows you to have remote access to the network. It also has smart parental controls for more safety.\nThe performance for the R7000 is great. You can have up to 1800 square feet with dual-band up to 600 + 1300 Mbps. You can have up to 30 devices connected at one time with the R7000, which should work for most homes.\nThat means your TVs and gamin consoles as well as mobile devices. The router also features the ReadySHARE Vault that provides an automatic backup to your USB 3.0 port.\nThe R7000 has a 1 GHz dual-core processor as in addition to a Beamforming+ feature that adds more power to your antennas while extending the reach of your network. Another feature with this router is the dynamic QoS, so you can prioritize which devices should get the best speeds.\n2. Synology RT2600ac Secure Router\nThe runner up is the Synology RT2600ac router. The Synology RT2600ac is a great choice with excellent parental controls.\nThe Synology router has a typical standard router design, since it is black, sits horizontally, and has four antennas. It comes with five Ethernet ports, so you will be able to directly wire-in whatever devices that you need to.\nThe Synology router is built with a 1.7 GHz dual-core processor so it is ready to take on whatever job that you want to through at it. It also has Dual-WAN capabilities, which allow for load balancing and failover support.\nThe router also can act like a private cloud server with its advanced file management capabilities. It operates between 40 degrees Fahrenheit and 104 Fahrenheit; it will not overheat in summer or stop working if it gets too cold in winter.\nThe best performance features that the Synology router has is the parental control features. It will let you to block thousands of potentially harmful websites. You can also setup customizable profiles for different family members, allowing for a variety of protections.\nIn the days where internet access is more available to children of all ages, being able to lock down your internet has never been more important. The data transfer rate on this router is 2.53 Gbps, which is outstanding as well.\nThe comprehensive VPN server can also keep you safe without losing any speed in the process. The router itself is regularly updated, keeping you safe from the latest threats. The router offers bandwidth prioritization to prevent lags as well, so your gaming or streaming will not lag.\n3. Turris Omnia Most Secure Router\nThe best high performance secure router is the Turris Omnia. If you are not familiar with this brand, do not think that this should be ignored. In fact, this router is impressive.\nThe design of the Turris Omnia is boxy and bulky. It has three antennas that can be moved in whatever direction that you need them to go as well. It comes with six Ethernet ports, so you will be able to wire-in whatever devices that you really want to. It also has a USB 3.0 port.\nThe security configuration with this router is easy to set up and it also has automatic updates, keeping your system as current as possible with any new malware floating around. It also comes with a SIM card slot. The security features can be configured to lock it down as much as you need to.\nThe Turris Omnia supports speeds up to 800 Mbps, which is faster than most ISPs will allow. It has a high-powered dual-core ARM CPU at 1.6 GHz with PC-like performance, which is unusual from a router. It also offers 2 GB RAM, so it really will be able to handle whatever you throw at it. It is a dual-band router with 3 x 3 MIMO to keep everything running smoothly.\nWhat makes this router especially different is that it has open hardware and runs open source. It has an open source operating system, giving you an infinite amount of options and variations to choose from. It will not work if you are not computer-savvy, because the system needs to be configured correctly.\n4. Linksys Max-Stream EA7500\nFor a router that is easier on the wallet, take a look at the Linksys Max-Stream EA7500. This router can still give good performance at a more affordable price and still has the kind of security features that you would really want to get.\nStarting with its design, the EA7500is black, rests horizontally, and it has three external high-gain antennas. They can also be pointed in the direction that needs a stronger and more reliable signal. It also has a USB 3.0 and Gigabit Ethernet ports, allowing you to hook up whatever devices or connections that you need.\nThe settings for the EA7500 are simple and easy. There’s even a quick start guide to help you through everything that you will need to know in order to complete the set up online. It comes with a great firewall that is simple to set up, allowing you to lock down your network without a headache.\nYou will not be disappointed with the performance of the Linksys Max-Stream EA7500. It has 4K HD streaming capabilities, which is great for networks that stream a lot from multiple devices.\nThis is beneficial regardless of whether you are an online gamer or an avid streamer. With the MU-MIMO technology on board, you should not experience any kind of lag with others online.\nFinally, the EA7500 also supports more than 15 connected devices at a time. This makes it easy to stream videos and games without any trouble from more than one device. The range is also excellent, since it reaches up to 1,500 square feet in coverage, more than most of the other budget-friendly routers on the market.\n5. ASUS RT-AX88U AX6000 Router\nGamers sometimes need even more security than the average user. If you or anyone in your network is serious about gaming, we suggest the Asus RT-AX88U AX6000.\nThe AX6000 has a horizontal design with four high-gain antennas that can be moved to point in whatever direction that you like. The design is a little bit bulky and will take up a lot of space wherever it is placed, but it is worth it. It comes with 8 LAN ports as well to support even more devices.\nWhen it comes to security, the AX6000 uses Ai-Protection to keep malware and other viruses out of your system. You can’t get more secure than a router that is able to intelligently determine whether something is a threat before it has had any opportunity to cause havoc in your network. The security is really commercial-grade.\nThe Asus AX6000 is a dual-band 8-stream router that is built to perform. It is compatible with the Asus Ai-Mesh WiFi system for seamless whole home coverage support as well, giving you more control over what happens in your network. It is backward compatible with 802.11a/b/g/n/ac as well, even though it is an 802.11ax router.\nThe speeds of the router can reach 6000 Mbps, handling even the busiest networks out there without breaking a sweat. It can reach speeds up to 1148 Mbps on the 2.4 GHz band and 4804 Mbps on the 5 GHz band. The adaptive QoS prioritizes game packets, giving you a lag-free, uninterrupted game play. Since this router is made for gamers, it will not disappoint any gamer out there.\n6. Gryphon AC3000 Mesh WiFi Router\nThis router is a little bit different than most of the routers that we have looked at here, in both design and abilities, making it a unique and impressive choice.\nThe Gryphon has a unique design since it is white and stands vertically, keeping the router cool, increasing its overall longevity. Since the antennas on this high performance router are all internal, there are no unsightly pieces sticking out of it, making it easier to blend in with your décor\nThe set up for this router is simple and straight forward, including when you want add on new Gryphon routers to further extend the coverage. It does come with security features as well, including ESET malware detection, AI-Intrusion Detection, and content filtering. It also works with an app to help manage your settings.\nThe Gryphon is a powerful router that covers up to 3,000 square feet, but it also can easily act as a mesh system, where you can infinitely expand the network by simply adding on another Gryphon router. It does not need more than one Gryphon to reach 3,000 square feet in coverage, however, which should work with the average larger home network all by itself.\nThis is a tri-band router with a 2.4 GHz band and 2 5 GHz bands, which will keep traffic flowing steadily on your network, without interruptions. It also has 4x4 MU-MIMO technology, making it easier for more than one user to stream at the same time without interruption. Generally, it is a powerful, secure router with a long range and lots of capabilities.\n7. Linksys WRT A3200 WiFi Router\nBest secure router that is also open source is the Linksys WRT AC3200. This is a little different than some of the other routers, but still offers a lot of security features that will not disappoint you.\nThe Linksys WRT A3200 sits horizontally, but it also has legs that keep it elevated from the surface. This provides better ventilation, keeping the device cooler while increasing its longevity. It is also the Linksys blue and black color combination, which might be nice if you are tired of the regular black router casings.\nBecause this is an open source router, it provides advanced customization options in just about every way, from security features to customization. The level of security that you want from this router is really up to you. It does require more configuration, but if you take the time, it will be worth the effort.\nThe performance of the Linksys WRT A3200 is excellent. It is a tri-stream router with 160 technology, doubling the bandwidth from 80 MHz to 160 MHz. It allows 4K streaming, which is ideal for gaming or heavy video streaming, all without buffering or any other lags that run the potential of ruining your games. It also has MU-MIMO technology on board, so you will be able to have multiple devices streaming at the same time.\nThe router offers great speeds. It is dual-band with speeds up to 2.6 Gbps, with an operating temperature from 32 to 104 F (0 to 40 C), meaning the machine will not overheat easily and should be able to handle anything.\nWhen it comes to looking for the most secure router on the market, you will need to think about encryption, firewalls, parental controls, and even VPNs.\nThe best all-around router to meet this need is the Netgear Nighthawk R7000. This router has the security that you want with all of the performance needs the average home network has.\nEven if you want a higher performance router, like the Turris Omnia, you will still need to make sure that it has all of the security features that will keep your network safe and locked down. Whether basic or open source, your security should be your first consideration.""]"	['<urn:uuid:0191dca5-e489-489f-bd9b-9a3f76c83fc2>', '<urn:uuid:662a6d89-b4d9-4ca9-8a11-0000cd07c343>']	factoid	direct	verbose-and-natural	distant-from-document	multi-aspect	novice	2025-05-12T23:56:45.148498	35	81	4495
82	where did cave art first appear europe or indonesia research findings	Research shows that cave art did not arise solely in Europe as long believed. Instead, two early cave art provinces arose at a similar time in remote corners of Palaeolithic Eurasia - one in Europe and one in Indonesia. The findings in Borneo and Sulawesi, both dated to around 40,000 years ago, demonstrate that Southeast Asian artists played a key role in the development of cave art, challenging the traditional view of Europe as the sole center for cave art development.	['Griffith University researchers have dated cave paintings in Borneo to as early as 40,000 years ago, showing that these enigmatic artworks are among the world’s oldest examples of figurative depiction.\nThis finding adds to the mounting view that cave art – one of the most important innovations in human cultural history – did not arise in Europe as long believed, and that ‘ice age’ artists in Southeast Asia played a key role in its development.\nSince the 1990s, caves in remote and rugged mountains of East Kalimantan, an Indonesian province of Borneo, have been known to contain prehistoric paintings, drawings, and other imagery, including thousands of depictions of human hands (“stencils”), animals, abstract signs and symbols, and related motifs.\nThese near-inaccessible artworks are now known to be far older than previously thought, according to a study led by Griffith’s Associate Professor Maxime Aubert, along with Indonesia’s National Research Centre for Archaeology (ARKENAS), and the Bandung Institute of Technology (ITB), published in Nature.\nAssociate Professor Aubert’s team reports Uranium-series dates obtained from calcium carbonate samples collected from the Kalimantan cave art, providing the first reliable estimates for the approximate time of rock art production.\n“The oldest cave art image we dated is a large painting of an unidentified animal, probably a species of wild cattle still found in the jungles of Borneo – this has a minimum age of around 40,000 years and is now the earliest known figurative artwork,” Associate Professor Aubert said.\nThe Kalimantan stencil art was shown to be similar in age, suggesting that a Palaeolithic rock art tradition first appeared on Borneo between about 52,000 and 40,000 years ago.\nDating also indicated that a major change occurred within this culture around 20,000 years ago, giving rise to a new rock art style (including rare portrayals of humans) at a time when the global ice age climate was at its most extreme.\n“Who the ice age artists of Borneo were and what happened to them is a mystery,” said team co-leader Dr Pindi Setiawan, an Indonesian archaeologist and lecturer at ITB. Setiawan has studied the art since its discovery, and, along with ARKENAS rock art expert Adhi Agus Oktaviana, leads expeditions to the Kalimantan caves.\n“The new findings illustrate that the story of how cave art emerged is complex,” Oktaviana said.\nEurope has long been seen as the centre for cave art development. But although Borneo is the Earth’s third largest island, throughout most of the ice age it actually formed the easternmost tip of the vast continental region of Eurasia – at the western extremity of this 13,000 km-wide landmass was Europe.\n“It now seems that two early cave art provinces arose at a similar time in remote corners of Palaeolithic Eurasia: one in Europe, and one in Indonesia at the opposite end of this ice age world,” said Associate Professor Adam Brumm, a Griffith archaeologist also involved in the study.\nA 2014 Nature paper published by Associate Professors Aubert and Brumm (with ARKENAS) revealed that similar cave art appeared in the island of Sulawesi about 40,000 years ago.\nSulawesi lies off the edge of Eurasia and is a vital stepping-stone between Asia and Australia.\n“Our research suggests that rock art spread from Borneo into Sulawesi and other new worlds beyond Eurasia, perhaps arriving with the first people to colonise Australia,” Associate Professor Aubert said.\nRead The Conversation article']	['<urn:uuid:871a6bfd-561c-4d95-a428-862241ee00c7>']	open-ended	with-premise	long-search-query	similar-to-document	single-doc	novice	2025-05-12T23:56:45.148498	11	81	562
83	How do marine protected areas impact coral reefs conservation and bottom trawling control?	Marine protected areas serve dual purposes in ocean conservation. They help protect coral reefs by reducing stresses and enabling study of both healthy reefs and those affected by global warming without other man-made factors present, as demonstrated in the Phoenix Islands protected area. Additionally, these areas help protect subtidal benthic invertebrates by prohibiting damaging bottom trawling activities, allowing impacted populations to potentially recover over time, though they may still be subject to other fishing activities like commercial potting or recreational fishing.	"[""An Aquarium conservation expert\nholds juvenile fishes raised in a sustainable\nThe Aquarium’ mission is to serve as an ocean steward. We promote conservation efforts and undertake applied research that helps us understand the potential impacts of climate change on ocean animals. We look for ways to mitigate or reduce these impacts by supporting right whale research and lobster research. Aquarium educators are also collaborating with other institutions nationwide to teach the public about global climate change, working with seafood wholesalers to encourage them to buy sustainable seafood or by creating marine protected sanctuaries to reduce stresses on coral reefs affected by climate change.\nHow are Aquarium educators collaborating with other institutions to teach people about global climate change?\nThe Aquarium, collaborating with other aquariums across the country, is leading a national effort to enable aquariums to effectively communicate the impacts of climate change and ocean acidification on marine animals. Read more.\nAn Aquarium researcher dives with a\nmanta ray in the Phoenix Islands.\nSee more images.\nHow does the Aquarium support one of the world’s biggest marine reserves?\nNearly a decade ago, a dive boat captain based in Fiji invited Greg Stone, a marine biologist and at the Aquarium's vice president of global marine programs, to visit the Phoenix Islands. This remote coral reef archipelago, located between Hawaii and Fiji, was swarming with reef fish and giant clams, including many species that were rare or unheard of elsewhere. According to Stone it was “the first time I had seen what the ocean may have been like thousands of years ago.”\nIn 2000 and 2002, Stone and other marine biologists cataloged coral and the fish species that lived on the reef. In 2001, Stone and the Aquarium proposed that the area be set aside as a reserve. He also called on Conservation International, a U.S.-based environmental group that raised money to offset the income that would come to the islanders from commercial fishing that would now be curtailed. Anote Tong, the President of Kiribati— the island nation that includes the Phoenix Islands protected area (PIPA)— and a graduate of the London School of Economics, was supportive of the project, seeing it as a way to both protect his island nation and support eco-tourism. For his work, Greg Stone was recognized by The Boston Globe as a “savior of the seas.”\nToday, scientists use the marine reserve to study the life of coral reefs, both healthy reefs and those that have been affected by over-fishing and the potential impacts of global warming on coral reefs “with no other man-made factors present.”\nAccording to the article “Our Imperiled Oceans: Victory at Sea,” which appeared in Smithsonian, the reserve is one of the planet’s ecological bright spots, the boldest, most dramatic effort to save the ocean’s coral reefs, the richest habitat in the seas.\nHow does the Aquarium support right whale research?\nHow does the Aquarium support research on our local lobsters?\nHow is the Aquarium educating local fish distributors about the benefits of sustainable seafood?\nToday, many species have been fished to near extinction and some seafood is caught or produced in ways that harm the environment. Through the Sustainable Seafood Programs in our conservation department, the Aquarium is working to help maintain healthy fish populations while supporting the fishing industry.\nThe Aquarium works directly with seafood buyers and sellers, such as Ahold USA, Stop & Shop's parent company, and Gorton’s, to help these companies make environmentally responsible seafood choices for their stores. We also educate consumers on which fish provide the best seafood choices and sponsor events, such as the Celebrate Seafood Dinner Series, to highlight sustainable seafood."", 'Designate a Marine Protected Area and prohibit bottom trawling\nOverall effectiveness category Unknown effectiveness (limited evidence)\nNumber of studies: 3\nBackground information and definitions\nFishing can impact subtidal benthic invertebrates through species removal or habitat damage from fishing gear entering in contact with the seabed (Collie et al. 2000). Mobile fishing gear such as bottom trawls are known to be particularly damaging as they are dragged along/above the seabed, but can be prohibited within an area. Specific areas can be designated as protected, and specific management measures taken to control for impactful activities, such as bottom trawling (Huvenne et al. 2016). Inside protected areas where bottom trawling is prohibited, the threat from bottom trawling to subtidal benthic invertebrates is removed, and previously impacted populations are, in theory, able to recover over time (Hiddink et al. 2017). However, species and populations are still subjected to the effects of other fishing activities allowed (for instance commercial potting or recreational fishing).\nWhen this intervention occurred outside of a marine protected area, evidence has been summarised under “Threat: Biological resource use – Cease or prohibit bottom trawling”. Evidence for other related interventions is summarised under “Threat: Biological resource use”.\nCollie J.S., Hall S.J., Kaiser M.J. & Poiner I.R. (2000) A quantitative analysis of fishing impacts on shelf‐sea benthos. Journal of Animal Ecology, 69, 785–798.\nHiddink J.G., Jennings S., Sciberras M., Szostek C.L., Hughes K.M., Ellis N., Rijnsdorp A.D., McConnaughey R.A., Mazor T., Hilborn R. & Collie J.S. (2017) Global analysis of depletion and recovery of seabed biota after bottom trawling disturbance. Proceedings of the National Academy of Sciences, 114, 8301–8306.\nHuvenne V.A.I., Bett B.J., Masson D.G., Le Bas P. & Wheeler A.J. (2016) Effectiveness of a deep-sea cold-water coral Marine Protected Area, following eight years of fisheries closure. Biological Conservation, 200, 60–69.\nSupporting evidence from individual studies\nA replicated, site comparison study in 1997 of 14 seamounts south of Tasmania, South Pacific Ocean, Australia (Koslow et al. 2001) found that seamounts within a protected area closed to trawling tended to have different invertebrate community composition, more species and higher biomass of invertebrates, compared to shallow unprotected seamounts, but not compared to deep unprotected seamounts, after two years. Results were not tested for statistical significance. Invertebrate community composition appeared typically similar at protected seamounts and deep unprotected seamounts, but different to that of shallow unprotected seamounts (data presented as graphical analyses). Protected seamounts tended to have more invertebrate species (22 species/sample) and biomass (6 kg/sample) compared to shallow unprotected seamounts (9 species/sample; 1 kg/sample) and similar to deep unprotected seamounts (20 species/samples; 7 kg/sample). The low diversity and biomass at shallow unprotected were associated with the loss of coral substrate from intense trawling. In 1995, a protected area was established and closed to trawling. In 1997, invertebrates (including corals) (>25 mm) living on the seamounts inside (6 seamounts; 12 samples) and outside (8 seamounts; 22 samples) the protected area (peaks at approximately 660–1,700 m depths) were sampled using a dredge. Invertebrates were sorted into groups and weighed by groups. Shallow unprotected seamounts were heavily fished, but deep seamounts were only lightly fished.Study and other actions tested\nA randomized, replicated, site comparison study in 1992–1993 in four areas of mixed seabed inside the Great Barrier Reef Marine Park off northern Queensland, Coral Sea, Australia (Burridge et al. 2006) found no difference in the biomass of non-commercial unwanted catch (invertebrates and fish discard) or in the number of ‘common’ and ‘rare’ discard species between areas closed to trawling and adjacent fished areas, seven to eight years after the closure. Data were reported as statistical model results. A 10,000 km2 area of the Great Barrier Reef Marine Park was closed to trawling in 1985. Two surveys were carried out, one in 1992 and one in 1993. During each survey, 25 randomly selected sites were sampled at each of four areas within the marine park, two closed areas, and two fished areas located 10 nm away, using both a benthic dredge and a prawn trawl. A total of 156 dredges (86 in closed areas, 70 in fished areas) and 122 trawls (68 in closed areas, 54 in fished areas) were towed. For each tow, discard species were collected, identified, counted, and weighed from subsamples (amount not specified). Total weight of discard was estimated from the subsamples. Species were either recorded as ‘common’ (found in at least 11 of the 25 sites) or ‘rare’ (found in 10 or fewer sites).Study and other actions tested\nA replicated, site comparison study in 2006 of 25 deep-sea seamounts located south of Tasmania, South Pacific Ocean, Australia (Althaus et al. 2009) found that, four to nine years after prohibiting bottom trawling in marine protected areas, invertebrate community composition was different and abundance lower at protected seamounts compared to trawled and natural (never trawled) seamounts, and diversity and species richness was similar to trawled but lower than at natural seamounts. Community data were reported as graphical analyses and diversity data as diversity indices. Species richness was similar at protected (46 species/1,270 m2) and trawled seamounts (46), but lower than natural seamounts (52). Abundance was lowest at protected (1–3 individuals/m2), compared to trawled seamounts (3–5), and natural seamounts where abundance was the highest (5–18). Species richness, diversity, and abundance were positively related to the cover of habitat-forming corals, which was higher on protected seamounts (3%) than trawled seamounts (0.1%), but lower than on natural seamounts (52%). Invertebrates (including corals) were identified and counted at 25 seamounts from videos transects (up to 4.7 km long, from 1,100 to 1,400 m depth; 38 transects in total). Ten seamounts were located either in continuously trawled areas or in areas where trawling had stopped following establishment of reserves (at some point between 1997 and 2003), and 15 were in never-trawled natural areas. Fishing history of individual seamounts was verified using logbook data from the Australian Fisheries Management Authority.Study and other actions tested']"	['<urn:uuid:3fe1f29c-dcbe-4399-ba14-4beb3146b275>', '<urn:uuid:fb742932-b61c-4a73-ba27-cc8bb2940b09>']	open-ended	with-premise	concise-and-natural	similar-to-document	multi-aspect	expert	2025-05-12T23:56:45.148498	13	81	1589
84	what ways exist to track if employees are doing dangerous things in cloud apps	Managing privileged accounts allows security teams to monitor user interactions with the system and evaluate if individual user behaviors pose security or compliance risks. The system should detect concurrent log-ins, suspicious activity and repeated failed log-in attempts, such as logging in at unusual hours or downloading suspicious items and data.	['A Cloud Computing Service System (PaaS) makes it possible for clients to construct, safeguard, run, and handle internet applications. It allows groups to create and deploy apps without acquiring or managing the IT facilities that support them.\nOn the whole, the platform supports the complete software application advancement and use life cycle while simultaneously providing developers and individuals with Net gain access to. PaaS benefits include simplicity of use, expense savings, flexibility, and also scalability.\nHow to Safeguard System as a Service (PaaS) Settings\nA PaaS is regularly not protected the same way an on-premises data facility is.\nProtection is included in PaaS environments. PaaS clients protect their system accounts, applications, and also information. In an excellent globe, premise safety and security transfers to identity boundary safety.\nSo the PaaS customer must focus on identification as the primary safety and security boundary. Verification, operations, tracking, and logging will undoubtedly be necessary to safeguarding code, data, and configurations.\nDefend applications against unidentified as well as frequent hazards\nUndoubtedly, the most effective strategy is to utilize a real-time computerized safety system to find and stop an attack immediately. Furthermore, PaaS individuals may use the system’s protection functions or third-party remedies.\nUnauthorized gain access to attacks or breaches should be detected and protected against right away.\nGood Read: Learn more about hygine and mental health.\nYou ought to be able to detect aggressive customers, weird log-ins, destructive robots, as well as take-overs, to name a few anomalies. Together with technology, the application should have safety.\nSafeguard customer and application resources\nEveryone gets in touch with is a feasible attack surface. The best method to prevent strikes is to restrict or restrict untrustworthy individuals’ access to susceptibilities and sources. To minimize vulnerabilities, protection systems should be automatically patched and also updated.\nEven if the service provider safeguards the platform, the customer is ultimately responsible for safety and security. Integrated system safety and security features, attachments, third-party services, and safety and security approach significantly enhance account, application, and information protection. It likewise assures that just licensed individuals or employees might access the system.\nAnother approach is to restrict administrative accessibility while creating an audit system to spot possibly dangerous interior groups and exterior customer actions.\nAdministrators should additionally limit customers’ authorizations as high as possible. To guarantee that programs or other actions are effectively carried out, customers need to have as marginal approvals as possible. The strike surface area is reducing, and also blessed sources are being exposed.\nApp to look for safety vulnerabilities\nEvaluate safety and security threats and also susceptibilities in applications as well as their libraries. Make use of the results to enhance total part security. For example, daily scanning would be scheduled immediately in a suitable scenario based on the app’s sensitivity and possible safety risks. Include an option that can incorporate right into other devices, such as interactive software applications, or inform the appropriate people when a protection risk or attack is recognized.\nAnalyze and deal with addiction-related safety and security problems\nApplications usually count on both direct and indirect open resource requirements. If these weak points are not dealt with, the application may come to be insecure.\nExamining APIs and validating third-party networks needs assessing the program’s interior as well as external elements. Patching, upgrading, or changing a secure variation of the dependence are all practical mitigating approaches.\nPentesting and also hazard modelling\nPenetration testing helps identify and solve safety and security troubles before aggressors discover as well as manipulate them. Nevertheless, penetration testing is aggressive and also might seem like DDoS assaults. To stop false alarms, safety workers must interact.\nDanger modelling entails simulating attacks from reliable borders. These assists identify weak design points that aggressors may exploit. Consequently, IT groups may enhance protection and produce treatments for any recognized weak points or threats.\nTrack customer as well as file gain access to\nManaging fortunate accounts enables protection groups to see just how users engage with the system. On top of that, it allows security teams to assess if they choose individual actions to pose a risk to security or compliance.\nDisplay and document customer approvals and data activities. This checks for unapproved access, changes, downloads, and uploads. Data activity checking systems must, in addition, record all individuals that have viewed a file.\nAn appropriate service needs to discover completing the log-ins, suspicious activity and duplicated not successful log-in attempts. For example, visiting at uncomfortable hrs, downloading dubious products and also information, etc.\nLimited information access\nEncrypting information during transport as well as storage is the best technique. On top of that, human assaults are protected by safeguarding Internet interaction links.\nIf not, establish HTTPS to use the TLS certification to encrypt and shield the channel and, therefore, the information.\nGood Read: Tips to receive best Search Engine Optimization Mississauga\nValidate the information regularly.\nThis guarantees the input information is risk-free and also in the correct style.\nWhether it originates from interior users or external protection groups, all data should be considered risky. If done correctly, client-side recognition and safety mechanisms must stop compromised or virus-infected files from being submitted.\nAnalyze the susceptibility code during development. Till the protected code is verified, programmers should not release the program right into manufacturing.\nMulti-factor verification guarantees only accredited individuals may access apps, data, and systems. As an example, a password, OTP, TEXT, or mobile application may be utilized.\nApply password security\nMost people select weak passwords that are conveniently recalled as well as never updating them. Therefore, administrators may minimize this safety threat by utilizing robust password plans.\nThis demands the use of solid passwords that end. Preferably, encrypted verification tokens, credentials, and passwords are conserved and transferred as opposed to plain text qualifications.\nAuthentication and also permission\nVerification, as well as permission approaches and protocols like OAuth2 and Kerberos, are suitable. Nonetheless, while unique authentication codes are unlikely to reveal systems to assailants, they are not error-free.\nGood Read: Learn more about kid-safe moving methods.\nAvoid using foreseeable cryptographic keys. Instead, use safe and secure necessary distribution techniques, revolve secrets regularly, restore keys on time, and stay clear of hardcoding keys into applications.']	['<urn:uuid:bcf7cb76-0caa-481e-88bc-1264524ed7ca>']	factoid	direct	long-search-query	distant-from-document	single-doc	novice	2025-05-12T23:56:45.148498	14	50	1024
85	mobile mapping robots construction benefits challenges	Mobile mapping offers significant benefits for construction, including rapid scanning of hard-to-reach spaces like ceiling voids and creation of detailed digital twins that help spot problems early. Using tools like the ZEB-REVO, scans that traditionally took 8 hours can be completed in just 10 minutes with accuracy within 2 centimeters. However, completely automating construction faces challenges - while robots could reduce material usage by up to 70% and improve efficiency like in automotive manufacturing, buildings are unique rather than standardized. Simply applying existing robotics or 3D printing technologies doesn't work well, as 3D printers would need to be larger than the buildings themselves.	['We are designing digitally, but still constructing manually, says Stuart Maggs, CEO of Scaled Robotics.\nMost people in the construction industry have a story to tell, often humorous: a column in the wrong place, a door that opens into a wall or a stairway to nowhere. But what this all alludes to is that the construction industry today is not working well.\nCompared to other manufacturing industries it is wasteful and inefficient, still using the same technology as 100 years ago. So it’s no surprise that with such little technological advancement, 63% of the UK’s construction industry is operating on a 5% profit margin, 17% is losing money and only 20% operates above the 5% threshold.\nHowever, it is unfair to say there has been no technological advancement. In the design and planning stages, software has taken great strides, going from 2D to 3D and now 3D to 4D. There is no denying construction is a digital industry – every architectural studio from the smallest to the largest relies on digital tools. A new generation of powerful software is capable of generating more efficient structural designs, just not possible in traditional ways.\nA great example of this is the design of a 3D printed structural node point by Arup. The geometry of the node is optimised to reduce the amount of material required by 75%, whilst still performing the same structural function as the traditionally designed element. The complex shape of the node means that it can only be produced by a 3D printer.\nSo, it is not that we cannot design better structures or buildings, we just do not have the right construction tools to produce them. While buildings are becoming more complex, resources more expensive and margins get tighter, the tools to produce them have not improved.\nThis brings us to the root of the problem, we are designing digitally but still constructing manually. It is this disconnect between the digital model and the physical world that leads to many of the inefficiencies that plague the industry.\nNevertheless, these are not new problems. Other industries, such as automotive, have introduced robots to the production line 50 years ago automating the manufacturing process. This means they manufacture products of a higher quality more efficiently. Yet cars are standardised while buildings are unique, which poses another set of challenges.\nOther manufacturing industries are using 3D printing as a way of creating complex and unique shapes not possible by other methods. Again the structural node point by Arup illustrates this, its manufacture only possible using a 3D printer.\nHowever, the solution for construction is not just as simple as introducing robots or 3D printing. Applying existing technologies designed for other industries to construction does not work. For example, a 3D printer must be larger than the object it produces. Therefore, to 3D print a building, the machine must be larger than the building itself, which is simply not scalable.\nAt Scaled Robotics our goal is to digitise construction. We replace these large machines with “teams” of small mobile robots, thereby bridging the gap between digital and physical and working directly from the BIM model.\nWe are moving towards a future where construction is fully automated and we believe that 3D printing is one technology that will play an important role in the future of construction. This presents the possibility of building structures that consume up to 70% less material, without using costly moulds and scaffolding, creating shapes that were either not possible or not financially viable due to the limitations of traditional methods.\nUltimately, though, such advances are only possible step by step. The logical progression is to start by using robots to perform tasks that drastically improve current workflows, then move on to more complex tasks such as 3D printing. It’s a case of learning to walk before you can run.\nSo how does Scaled Robotics fit into this process? We are currently developing robots that directly link the physical world to the BIM model, with the capability to find construction errors in real time by comparing the BIM model to the environment and locating errors in construction before they become costly. This puts valuable information into the hands of the people that need it the most.\nComparing the digital model to the site is not new, but right now it is painfully slow. It takes hours or days, even with the availability of a total station or 3D scanner. A complicated process that leaves room for interpretation and error.\nSo if BIM has played a vital role in the digitisation of construction, now it is time to match the capabilities of digital design to real-world digital construction tools, and at Scaled Robotics we believe the introduction of robots to the job site is the crucial next step towards the digitisation of construction.', 'Scanning hard-to-reach, overhead or “limited access” spaces has historically posed many challenges for those working in the construction sector. Stuart Cadge, from leading indoor mobile mapping specialist, GeoSLAM, explains how innovations in mobile mapping technology are paving the way for a new dawn in surveying.\nArchitects, project managers and surveyors are constantly under pressure to finish projects on time and within budget. Not surprising, considering that most contractors anticipate that up to 30% of their projects will be subject to costly delays. This issue is not limited to large-scale construction schemes, as similar constraints affect smaller building renovation projects too.\nBut creating a dynamic “digital twin” of a building’s features throughout a project’s lifecycle can help stakeholders remain up to date with a scheme’s progress, enable problems to be spotted early on, and speed up the decision-making process should alterations be required.\nOnce a 3D scan of an asset – whether complete or part-finished – has been conducted with a handheld, lightweight mobile mapping tool, project teams can generate highly detailed 3D models and 2D plans. These digital representations of a project can then be updated, re-scanned and interpreted at any stage in an asset’s lifecycle.\nNow, 3D mobile mapping technology has gone one step further. New mobile mapping tools use Simultaneous Localisation and Mapping (SLAM) technology, providing the ability to rapidly scan even difficult-to-reach places such as multi-level spaces, large multi-room hotels or enclosed basements.\nThe speed and non-evasive nature of mobile scanning also allows for the surveying of occupied premises, such as live construction sites, or in-use buildings surveyed for renovation or redevelopment.\nThe high ceilings in Turner Construction’s offices were problematic for traditional scanners\nThe model of the suspended ceiling voids\nConstruction projects routinely require a series of surveys and the subsequent creation of a model. One such recent example involves Turner Construction, the US-based global multinational construction services company which employs more than 5,200 people and completes 1,500 projects every year worth in the region of $10 bn.\nThe firm embarked on an extension project of its Atlanta, Georgia, office, and the latest mobile mapping tools offered a welcome alternative to traditional yet more cumbersome survey methods.\nBefore works were able to begin on site, the Turner Construction team needed to conduct a survey of the suspended ceiling voids. However, no previous 3D model of the space existed, and as a result, Turner was tasked with surveying the notoriously difficult space from scratch.\nDue to the building’s high ceilings and the limited space available in the void to manoeuvre equipment, traditional scanners would have struggled. However, thanks to the incorporation of SLAM technology, the Turner Construction team were able to put a GeoSLAM ZEB-REVO to use and complete a scan in just 10 minutes. Weighing just 1kg, the ZEB-REVO was deployed on an extendable pole into the ceiling void to capture scan data easily while overcoming the location’s relative inaccessibility.\nThe ZEB-REVO scanner completed the scan in a fraction of the time\nUnlike conventional methods of surveying, which can often take a great deal of time, the ZEB-REVO can be quickly and effortlessly moved without the need for time-consuming set-ups. It is also able to mitigate occlusions (object shadows), saving time on the overall modelling as the team already had a complete picture to work from – rather than having to interpolate between shadows that are usually seen in terrestrial scanning.\nIf traditional techniques had been used, it would have taken more than eight hours to complete the scan – 48 times longer than by using a ZEB-REVO. Added to that, surfaces had an average measurement accuracy to within two centimetres – more than sufficient for modelling the data in a BIM model.\nThe accuracy of the mobile data collected allowed for a full MEP layout to be built in just one working day, showing features all the way down to under four centimetres.\nTime and budget constraints will always pose challenges for those working on construction projects, regardless of their role or level of seniority. But, if the past few years have proven anything, it is those who choose to harness the latest digital technologies who will be rewarded with significant cost and time savings across the board.']	['<urn:uuid:8cf7e26d-91ed-44b9-a799-9848dbf36fe5>', '<urn:uuid:eb50ae4b-1494-4ac3-b8d5-94b1f1074356>']	open-ended	with-premise	short-search-query	similar-to-document	multi-aspect	expert	2025-05-12T23:56:45.148498	6	103	1506
86	residential wiring dangers safety professional services	DIY electrical wiring can lead to severe hazards including electrical shocks, fires, and system damage due to common mistakes like overloading circuits and poor quality connections. Professional electrical services are essential because they ensure compliance with electrical codes, proper permits, and necessary inspections. Key requirements often overlooked in residential projects include smoke detectors, AFCI protection for bedrooms, GFCI protected circuits for bathrooms and kitchens, and dedicated circuits to avoid overload conditions. Licensed electrical contractors have the required knowledge, tools and training to handle these tasks safely while adhering to local and national codes.	['Are You Doing Your Electrical Wiring Project Right?\nI am Installing Some Electrical Wiring Myself, Am I Doing it Right? Installing Home Electrical Circuit Wiring, Planning Electrical Wiring for a Home Project, Electrical Codes and Circuit Requirements.\nInstall Home Electrical Circuits and Wiring\nElectrical Question: I am Installing Some Electrical Wiring Myself, Am I Doing it Right?\nHere is my project:\nI am finishing my basement project. I am doing the electrical wiring myself, but I will have an electrician hook up the circuit breaker box.\n- I have installed 30 can lights and 32 outlets.\n- I have 6 empty slots which will have 20amp breakers.\n- I did use 12 AWG wire.\nI was going to split the breakers as follows:\n- Half of great room with 4 can lights and 6 plugs.\n- Half of great room with 6 can lights and 5 plugs.\n- Bedroom with 5 can lights and 6 plugs.\n- Bathroom with 5 can lights, 4 plugs, and a vent fan.\n- Laundry room and storage room with 4 can lights (2 in each room) and 5 plugs. *the washer and dryer will use their existing breakers from upstairs.\n- Office with 6 can lights and 6 plugs.\nWill the 6 (20 amp) breakers suffice for these rooms?\nThanks in advance,\nThis electrical wiring question came from: Wayne, a Homeowner from Shepherdsville, Kentucky.\nThanks for your electrical wiring question Wayne.\nElectrical Wiring for a Home Project\nApplication: Installing Home Electrical Wiring\nSkill Level: Intermediate to Advanced – Best performed by a Licensed Electrical Contractor.\nTools Required: Electricians Pouch of Hand Tools for Rough-In Wiring, Electric Drill and Auger Bits and Extension Cord.\nEstimated Time: Depends on the extent of the basement wiring project, the type of construction and available access to the basement project area.\nPrecaution: Any existing wiring in the immediate area that may interfere with the installation should be identified and turned OFF and Tagged.\nNotice: Installing additional electrical wiring should be done according to local and national electrical codes with a permit and be inspected.\nPlanning Electrical Wiring for a Home Project and Doing It Right\n- Wayne, this is a very loaded question, so I will summarize with this, and please understand my position here. I admire the fact that you want to do this project yourself, however every electrical project should be done right, beginning with a plan, after obtaining a permit and then fully inspected. With the information that you have provided there are some serious issues with your basement wiring project.\n- I might add here that with a project like this you may have a problem hiring a licensed electrical contractor who will come in and make the connections, because he will be assuming responsibility for your electrical wiring project, unless he requires you to sign a waiver that will release him of any liability.\n- I will say as nicely as I can that just because any individual installs electrical wiring does not mean that it is done correctly, even if it appears to work. This is why we have electrical codes and we must install our projects with a permit and have all the necessary inspections.\nOverlooked items that are not mentioned in this Basement Wiring Project include:\n- Smoke Detectors where required in inhabited areas.\n- AFCI protection for bedrooms and other outlets as required.\n- GFCI protected circuits for bathrooms, kitchens, and other locations as required.\n- Dedicated Circuits as required to specific areas to avoid overloaded conditions.\n- An explanation of all of these items can be found in my book, and are too extensive to list here, you may want to consider my Home Electrical Wiring eBook.\nFailure to Plan is the Biggest Mistake\nThe biggest problem with this and so many other projects like this is the person starts asking questions after the work has been done. Each and every successful electrical wiring project should begin with a plan and an understanding of the full scope of every component of the project and the all the building codes and local ordinances that apply.\nMore about Basement Electrical Wiring\nBasement Electrical Wiring\nFully Explained Photos and Wiring Diagrams for Basement Electrical Wiring with Code Requirements for most new or remodel projects.\nElectrical Codes and Circuit Requirements\nElectrical Code Directory covering circuits and wiring methods.\nWiring Electrical Outlets for the Home\nHome electrical wiring includes 110 volt outlets and 220 volt outlets and receptacles which are common place in every home. See how wiring electrical outlets for the home are done.\nElectrical Circuit Wiring\nThis article looks at common 120 volt and 240 volt house wiring circuits and the circuit breakers that are installed identifying the types and amperage sizes used in most homes.\nHome Electrical Circuit Breakers\nA guide to home electrical circuit breakers and how they work to protect your electrical wiring. When properly installed, your home electrical wiring is protected by a circuit protection device.\nElectrical Wire for the Home\nComplete listing of electrical wire types and parts used for home projects with electrical code information serves as selection guidelines.\nElectrical Junction Boxes for Home Wiring\nUnderstanding electrical junction boxes and what they are used for. Home electrical wiring is the process of installing electrical wire to a location that will serve electrical devices or an appliance. One very important component is the box where the wire will be installed. The type and size of the home wiring electrical boxes will depend upon the circuit size, application and its location.\nBathroom Electrical Wiring\nFully Explained Photos and Wiring Diagrams for Bathroom Electrical Wiring with Code Requirements for most new or remodel projects.\nLaundry Room Electrical Wiring\nFully Explained Photos and Wiring Diagrams for Laundry Room Electrical Wiring with Code Requirements for most new or remodel projects.\nBedroom Electrical Wiring Requirements\nFully Explained Photos and Wiring Diagrams for Bedroom Electrical Wiring with Code Requirements for most new or remodel projects.\nFor more information about Electrical Wiring\nHome electrical wiring projects with pictures and wiring diagrams.\nBe Careful and Be Safe - Never Work on Energized Circuits!\nConsult your Local Building Department about Permits and Inspections for all Electric Wiring Projects.\nThe Safest Way to Test Electrical Devices and Identify Electric Wires!The Non-Contact Electrical Tester\nThis is a testing tool that I have had in my personal electrical tool pouch for years, and is the first test tool I grab to help identify electrical wiring. It is a Non-contact tester that I use to easily Detect Voltage in Cables, Cords, Circuit Breakers, Lighting Fixtures, Switches, Outlets and Wires. Simply insert the end of the tester into an outlet, lamp socket, or hold the end of the tester against the wire you wish to test. Very handy and easy to use.\nThe Quickest Way to Check for Faulty Electrical Wiring!The Plug-In Outlet Tester\nThis is the first tool I grab to troubleshoot a problem with outlet circuit wiring. This popular tester is also used by most inspectors to test for power and check the polarity of circuit wiring.\nIt detects probable improper wiring conditions in standard 110-125 VAC outlets Provides 6 probable wiring conditions that are quick and easy to read for ultimate efficiency Lights indicate if wiring is correct and indicator light chart is included Tests standard 3-wire outlets UL Listed Light indicates if wiring is incorrect Very handy and easy to use.\nStrip Off Wire Insulation without Nicking and Damaging the Electric Wire!The Wire Stripper and Wire Cutter\nMy absolute favorite wire stripping tool that I have had in my personal electrical tool pouch for years, and this is the tool I use to safely strip electrical wires.\nThis handy tool has multiple uses:\nThe wire gauges are shown on the side of the tool so you know which slot to use for stripping insulation.\nThe end of the tool can be used to grip and bend wire which is handy for attaching wire onto the screw terminals of switches and outlets..\nThe wire stripper will work on both solid and stranded wire. This tool is Very Handy and Easy to Use.\n|« Understanding Electrical Circuit Wiring||How Much Will an Electrician Charge to Install a New Circuit »|', 'The Need for Electrical Contractor Services\nIn today’s modern world, electricity is an integral part of our daily lives. It powers our homes, offices, and industries, making it essential to have reliable and safe electrical systems. This is where electrical contractor services come in.\nThe Importance of Reliable Electrical Work\nProper and reliable electrical work plays a crucial role in ensuring safety and functionality in any space. Whether it’s a residential home, a commercial building, or an industrial facility, well-maintained electrical systems are vital. They power appliances, provide lighting, and support various technologies that we depend on daily.\nReliable electrical work also ensures that all electrical systems are up to code, reducing the risk of electrical fires, shocks, and other potential hazards. This is why it’s essential to choose a reliable electrical service provider who can offer comprehensive services, from electrical installation services to electrical repair services.\nDangers of DIY Electrical Work\nWhile DIY projects can be satisfying and cost-effective for certain tasks, electrical work is not one of them. Attempting to handle electrical issues without professional training and experience can lead to severe hazards, including electrical shocks, fires, and potential damage to your electrical system.\nOne common mistake is overloading circuits, which can lead to overheating and potentially cause a fire. Another risk is poor quality work, which can result in unstable connections and unsafe wiring setups. These can lead to frequent electrical issues or even accidents.\nProfessional electrical contractor services are equipped with the necessary knowledge, skills, and tools to handle electrical tasks safely and efficiently. They understand the complexities and risks involved in electrical work and are trained to address these problems while adhering to local and national electrical codes.\nWhether you need residential electrician services or commercial electrician services, it’s always safer and more efficient to hire a professional. In the event of an electrical emergency, many providers also offer emergency electrician services to address critical issues promptly.\nIn conclusion, the need for electrical contractor services cannot be overstated. They ensure reliable and safe electrical work, which is essential in maintaining a safe and functional living or working environment. Always remember, when it comes to electrical work, it’s always best to leave it to the professionals.\nOverview of Electrical Contractor Services\nElectrical contractor services encompass a wide range of solutions, each tailored to meet the specific needs of different settings – residential, commercial, and industrial. Understanding these services can help individuals and businesses make informed decisions when seeking professional electrical assistance.\nResidential Electrical Contractor Services\nResidential electrical services cater to the needs of homeowners and residential properties. Some of the key services in this category include electrical installations, repairs, upgrades, and maintenance. For instance, these services might involve the installation or repair of lighting systems, electrical panels, wiring, or outlets.\nSafety inspections are also crucial in the residential setting, ensuring that all electrical components meet the required safety standards. Emergency electrical services, available 24/7, provide homeowners with peace of mind, knowing that professional help is just a call away in case of any unexpected electrical issues. Want to know more? Our article on residential electrical services provides a comprehensive overview.\nCommercial Electrical Contractor Services\nCommercial electrical services, on the other hand, are tailored to meet the unique requirements of businesses, offices, and commercial buildings. These services often involve larger-scale projects such as electrical wiring for entire buildings, installation of commercial lighting systems, and electrical maintenance of commercial spaces.\nCommercial electrical contractors also provide safety inspections and adhere to commercial electrical standards, ensuring businesses remain compliant with all relevant regulations. Routine maintenance and emergency services are critical to prevent business disruptions due to electrical issues. For a more detailed look at these services, visit our page on commercial electrical services.\nIndustrial Electrical Contractor Services\nIndustrial electrical services cater to industrial facilities like factories, power plants, and manufacturing units. These services involve complex, large-scale electrical systems and require specialized knowledge and skills. The scope of services can range from the installation of industrial machinery, maintenance of power distribution systems, to the troubleshooting of electrical problems in an industrial setting.\nSafety inspections in an industrial environment are vital, not only to ensure compliance with regulations but also to maintain a safe working environment. Preventative maintenance is also a key service, helping to reduce costly downtime due to electrical failures. Read more about these services in our article on industrial electrician services.\nIn sum, electrical contractor services vary based on the environment they cater to. Whether it’s for a residential, commercial, or industrial setting, it’s important to opt for professional, experienced, and licensed electrical contractors to ensure safe and reliable electrical work.\nKey Aspects of High-Quality Electrical Contractor Services\nWhen it comes to electrical contractor services, there are key aspects to look for to ensure you’re getting the highest quality of service. These key aspects are a reflection of the professionalism, capability, and reliability of the service provider.\nLicensed and Insured Professionals\nFirst and foremost, a reliable electrical contractor employs professionals who are licensed and insured. This is an assurance that the electricians have undergone the necessary training and have the skills to perform electrical works safely and correctly. A licensed professional is knowledgeable about the local codes and regulations, ensuring that the work done complies with these standards. Insurance, on the other hand, provides protection for both the contractor and the client in case of accidents or damage.\nRange of Services Offered\nThe range of services offered is another important aspect to consider. A top-notch electrical contractor should be able to provide a wide array of services to cater to diverse electrical needs. This includes, but is not limited to, electrical installation services, electrical repair services, and electrical maintenance services. Offering a comprehensive range of services eliminates the need for clients to seek different contractors for varying electrical needs.\nTimeliness and Efficiency\nTimeliness and efficiency are crucial when dealing with electrical issues. A reputable electrical contractor understands this and is committed to providing prompt and efficient service. Whether it’s emergency electrical services or routine maintenance, the contractor should be able to deliver quality service in a timely manner. This reflects their commitment to customer satisfaction and their capability to handle jobs of varying complexity.\nQuality of Workmanship\nLastly, the quality of workmanship is an integral aspect of high-quality electrical contractor services. This pertains to the level of skill and precision employed in carrying out electrical tasks. Superior workmanship not only ensures the functionality and safety of the electrical system but also extends its lifespan. It’s always recommended to look for contractors who guarantee their work, as this is a testament to their confidence in the quality of their service.\nWhen hiring an electrical contractor, these key aspects should serve as your guide in choosing a service provider. Remember, your choice of contractor can significantly impact the safety and efficiency of your electrical system. Therefore, it’s crucial to carefully evaluate your options and make an informed decision. For more insights on electrical services, check out our extensive range of articles on topics such as electrical safety tips and electrical troubleshooting tips.\nWhen to Call an Electrical Contractor\nRecognizing the right time to call an electrical contractor can help you avoid potential hazards and costly repairs. Whether you are experiencing signs of electrical problems, need preventive maintenance and inspections, or are planning home renovations and upgrades, professional electrical contractor services are essential.\nSigns of Electrical Problems\nCertain signs indicate the need for professional electrical services. These include frequent tripping of circuit breakers, flickering lights, unusually high electricity bills, warm or sparking outlets, and burning smells or visible signs of electrical fires. It’s critical not to ignore these signs as they can indicate serious electrical issues that require immediate attention.\n|Frequent circuit breaker tripping\n||Overloaded circuits or faulty breakers\n|Flickering or dimming lights\n||Loose or defective bulbs, voltage fluctuations\n|High electricity bills\n||Electrical leak, inefficient appliances\n|Warm or sparking outlets\n||Loose or damaged wiring\n|Burning smells or signs of electrical fires\n||Short circuit, overload, faulty devices\nIf you notice any of these signs, it’s time to seek help from an electrical service provider to prevent potential hazards and ensure the safety of your home.\nPreventative Maintenance and Inspections\nRegular preventative maintenance and inspections are a crucial part of maintaining the safety and efficiency of your electrical system. Regular inspections can help identify potential electrical problems before they manifest into significant issues.\nThese services typically include inspecting the electrical panel, checking for visible signs of wear and tear, testing the operation of circuit breakers, and ensuring that all electrical connections are safe and secure. For more information on these services, visit our page on electrical maintenance services.\nHome Renovations and Upgrades\nIf you are planning to renovate or upgrade your home, you may need an electrical contractor’s services. Whether you are adding new rooms, upgrading your electrical panel, rewiring the house, or installing new fixtures, it’s essential to ensure that all electrical work is done safely and efficiently.\nProfessional electrical contractors can ensure that all new installations meet local building codes and regulations. They can also advise on the best solutions for your specific needs and ensure that all work is done to the highest standards. For more information on these services, check out our page on electrical renovation services.\nRemember, whether you’re dealing with signs of electrical problems, need regular maintenance and inspections, or are planning home renovations and upgrades, professional electrical contractor services are invaluable. By recognizing the right time to call in the professionals, you can ensure the safety and efficiency of your electrical system while avoiding potential problems down the line.\nTips for Choosing the Right Electrical Contractor\nWhen you require electrical contractor services, it’s crucial to choose a professional who can deliver high-quality work. The right electrical contractor will not only meet your electrical needs but also ensure the safety and efficiency of your electrical systems. Below are some important considerations when making your selection.\nCredentials and Reviews\nThe first step in choosing an electrical contractor is verifying their credentials. This includes checking for proper licensing and insurance. Licensing assures that the contractor has met certain industry standards and follows safety regulations. Insurance, on the other hand, protects you from liability in case of accidents or damages during the service.\nIn addition to credentials, it’s also essential to consider reviews and references. These can provide insight into the contractor’s workmanship, reliability, and customer satisfaction.\nConsider the following factors when reviewing credentials and reviews:\n||Verify the contractor’s licensing with your state’s regulatory board.\n||Ensure the contractor has liability insurance and workers’ compensation coverage.\n||Look for reviews on trusted platforms to gain insights into the contractor’s performance and customer service.\n||Ask the contractor for references you can contact directly.\nEstimate and Pricing\nBefore hiring an electrical contractor, ask for a detailed estimate. This should include the cost of materials, labor, and any additional fees. A transparent pricing structure can help avoid hidden charges and provide a clear understanding of what you’re paying for.\nComparing estimates from multiple contractors can help you gauge the average cost of the services you need. However, remember that the cheapest option isn’t always the best. Quality workmanship and safety should never be compromised for a lower price.\nConsider the following factors when reviewing estimates and pricing:\n||The estimate should itemize the cost of materials, labor, and any additional fees.\n||The contractor should be clear about all costs, with no hidden charges.\n||Compare estimates from multiple contractors to understand the average cost.\n||Consider the quality of workmanship and safety measures in addition to cost.\nCustomer Service and Communication\nLastly, pay attention to the contractor’s customer service and communication skills. They should be responsive, willing to answer questions, and capable of explaining complex electrical issues in understandable terms. Good communication can ensure that your needs and expectations are clearly understood.\nConsider the following factors when assessing customer service and communication:\n||The contractor should be quick to respond to your inquiries.\n||They should explain technical electrical issues in a way you can understand.\n||The contractor should treat you with respect and exhibit professional behavior.\n||They should thoroughly understand your needs and expectations.\nBy carefully considering these factors, you can find an electrical contractor who will provide the top-notch service you require. For more guidance on electrical services, check out our articles on electrical service standards and electrical service cost.']	['<urn:uuid:41e3580d-8d30-4947-b045-e4ca1ec8ac98>', '<urn:uuid:2e256927-e5c7-4f78-89d6-264629a3c1b3>']	open-ended	direct	short-search-query	distant-from-document	multi-aspect	expert	2025-05-12T23:56:45.148498	6	93	3431
87	How do public versus private ash tree management strategies compare?	Public ash trees are managed through city-led initiatives, including systematic inventory, health assessment, and coordinated removal/treatment programs, with dedicated municipal funding. For private ash trees, property owners are encouraged to work independently with certified arborists for inspections and treatments, though some cities like Wayzata offer bulk discount programs through contracted services for private tree treatment. Both public and private management emphasize the importance of tree diversity and replacement planning.	"['EAB management for cities and towns\nEAB has taken its toll on this Kansas City streetscape. (Photo by Kevin Lapointe, City of Kansas City.)\nAsh trees are common in both rural and urban areas throughout the state, but EAB will strike cities and towns especially hard. It is estimated that about 14 percent of trees lining streets in urban settings are ash. In some neighborhoods and parks the figure reaches as high as 30 to 40 percent.\nMissouri communities will benefit in many ways from preparing a plan of action to deal with the invasive EAB beetle before it arrives and starts killing ash trees. Take these steps now to stay ahead of the beetle.\nGather the team\nIdentify an EAB readiness team for your community. The team should include representatives from the following areas:\n- Office of the mayor or town council president\n- City forestry department (if your community has one)\n- Streets department\n- Parks department\n- County council\n- Chamber of commerce\n- Appropriate utility companies\n- Public relations department\n- Soil and water conservation district\n- Local MU Extension center\n- Local businesses, such as nurseries, tree care businesses, etc., that will be affected\nAssign one person on the team to act as the EAB urban forestry manager, point person or liaison. This team member should ideally have urban forestry training or a background in environmental studies. He or she will work closely with the public relations coordinator, if applicable.\nThe team should also become familiar with state quarantine procedures, compliance agreements and whom to contact for any questions that might arise from either the team or community.\nInform the community\nIt is imperative to generate public awareness about EAB before the insect is found. An informed public is much more cooperative than one that has not been adequately prepared.\n- Encourage local media to feature articles and interviews about EAB and how other communities are dealing with related issues.\n- Let the community know your EAB readiness team is in place and working on a specific action plan. Keep the residents informed of progress and the needs of the municipality to address this issue.\n- Invite experts to speak on EAB at appropriate community events, such as Arbor Day programs or meetings of master gardeners or other gardening groups.\n- Obtain EAB flyers, leaflets and education handouts from the Missouri Department of Conservation’s community forestry office. Place EAB information in libraries, park centers, community centers, government centers and other public gathering places.\n- Link this EAB website to your city’s Web pages.\nDetermine funding for EAB related programs\nDetermine corporate and private partners who are willing to fund removal and replacement of infested ash trees on private property. A town riddled with dead or dying trees does not look economically promising to potential new businesses and residents, so depressed landscapes can hinder existing business opportunities. Determine what community funds are available for removal and replanting on public property.\nInventory equipment and consider labor force\nTo be able to effectively handle tree removal, you must first know what type of equipment and labor is available.\n- Determine which department(s) in the community is responsible for felling and removing trees. Identify employees who have had training on the use of chain saws and tree felling.\n- Develop a list of equipment and vehicles that will be available for tree removal and clean-up, including wood chippers, bucket trucks, refuse packers, loaders, supervisory vehicles, chain saws, barricades, handsaws and pole pruners.\n- Identify and contact operators and owners of portable saw mills in the area. After bark is removed from ash, the slabbed logs can be used for lumber. This lumber could be used for park projects, community kiosks, benches, playground equipment, etc. Private property owners could join together and hire a portable sawmill operator to slab logs on site. They might use the resulting lumber for home projects or donate it to woodcrafters in the county.\n- Identify tree care companies and landscape businesses capable of tree removal and chipping services. For the ash wood chips to become exempt from quarantine, they must be processed to smaller than 1-by-1 inch in two dimensions. EAB larvae cannot survive in small wood chips as they quickly desiccate.\nIdentify disposal and mulch sites\nDesignate a disposal site or sites within the community or county for ash wood debris before EAB arrives. This could be a landfill, solid waste area or industrial site where the debris can be buried or chipped. If burning is an option in your area, a burn permit must be obtained in advance.\nDetermine a mulch/compost site for the ash wood chips that will be processed to smaller than 1-by-1 inch in two dimensions. Offer the mulch to residents and parks in the area.\nWork with local utility company\nContact the appropriate utility provider regarding potential problems with proximity of ash trees to utility lines in the area. You may also want to work with them on a procedure for ash tree removal and replacement in these areas.\n- Locate your ash trees\n- Trees cannot be effectively managed in a community setting until their location and general condition are known. The period before EAB arrives is an excellent time for your community to conduct a thorough inventory of all of its trees.\nInventory and evaluate ash trees\n- First, check to see if there is a current inventory on file. If not, conduct and inventory all true ash trees, including those in all public, park, cemetery and private lands. Communities interested in performing complete inventories might be eligible for grant funds from the community forestry program. If you do not have the time or finances to do a complete inventory, at least document where your ash trees are and record their general condition.\n- Assess the health and condition of all ash trees on public property during the inventory. Be on the alert for signs and symptoms of EAB as you conduct the inventory.\n- Inform the mayor and other elected officials of the potential effects that the loss of the community’s ash trees will have on the area and how the loss might affect the environmental health and public safety of the community.\n- Preemptively remove any ash trees that are in severe decline from any cause. Replace dying ash trees with other species that are appropriate sizes and have appropriate growth habits.\nReplace ash trees\nThe Missouri Department of Conservation does not recommend planting ash tree species in Missouri at this time. Select replacements from a diversity of tree species and cultivars. Be sure to consider types that are not over-planted in the community.\nFor trees suitable to Missouri, see these MU Extension publications:\nArborday.org offers detailed information — height and spread, soil and sun requirements, leaves and fruit, history, wildlife habitat and more — on dozens of commonly planted landscape trees that grow throughout the U.S.\nAdditionally, encourage property owners whose ash trees are currently healthy to begin mixing in other types of trees on their property. This will ensure that there will be established, larger trees in place if their ash trees are killed by EAB and have to be removed. This is vital because it is the maturing size of large trees that offers the community the greatest environmental benefit.\nAfter EAB is officially identified\nOnce EAB has been confirmed in your city or town, then an official announcement from the Missouri Department of Agriculture (MDA) will be made. Once done, you might release information to your community through your community EAB liaison. Other communication and outreach activities to consider:\n- A statement from the mayor to local media explaining what tools and resources the community has in place to help its residents, what the plan of action is, where the public can take ash debris, quarantine rules and recommendations for businesses and private property owners.\n- An EAB informational meeting, in conjunction with the MDC Community Forestry Program, for the public to discuss EAB, ash tree identification and replacement plantings.\n- Activate previously designated ash wood debris marshalling yards.\n- Inform citizens of services available to help with tree removals, woody debris management and tree replacement through local news media outlets and community Web sites.\n- Encourage ash wood utilization using portable sawmills. When milling ash wood, sawyers need to be reminded to dispose of the bark debris as determined in their compliance agreement with the MDA and/or the USDA. Typically, ash logs from quarantined areas need to be edged 1/2 inch deeper than normal. The squared-off log needs to be bark free with no insect pockets.\n- Contact the MDA for a list of vendors who have compliance agreements with the state for handling ash debris.', 'Emerald Ash Borer\nWhat is EAB?\nThe emerald ash borer (EAB) is a small invasive green beetle that infests and kills all species of ash (Fraxinus) trees. EAB are native to eastern Asia but were discovered in Michigan and Ontario in 2002. The larvae (shown on the right) of these shiny green beetles tunnel beneath the bark of ash trees and gnaws away at the living tissue of ash trees until the tree eventually dies, usually 2 to 4 years after being infected.\nNot every green bug is an Emerald Ash Borer.\nAt this time, the city encourages residents to learn more about EAB, its symptoms and its common insect ""lookalikes"" by visiting the Minnesota Department of Agriculture website and the University of Minnesota Forest Resources Extension website. Below is a side-by-side comparison of an Emerald Ash Borer and the Six-Spotted Tiger Beetle (native insect).\nHas the Emerald Ash Borer Arrived in Wayzata?\nThe Emerald Ash Borer (EAB) has not been discovered in Wayzata yet, but it is likely only a matter of time until this unwelcome guest shows up at our doorstep. However, EAB infestations have been confirmed less than one mile away from Wayzata in Orono.\nTo see where Emerald Ash Borers have been found in Minnesota, check out the Minnesota Department of Agriculture\'s EAB Status Map.\nHennepin County under EAB Quarantine\nThe US and Minnesota Department of Agriculture (MDA) are the lead agencies handling EAB. Per the state EAB Response plan, the city of Wayzata will be notified directly once quarantines are established. Because the insect is so difficult to detect, once EAB is detected in an ash tree, it has likely been in an area for 3 to 5 years.\nLeft to their own devices, EAB spread at a rate of ½ to 2 miles per year. However, the human spread of firewood and goods has accelerated the rate at which it is establishing in new areas. The mature beetles can fly 2 to 6 miles in its short 3-week life span.\nBecause of the EAB discovery, Hennepin County has been added to the MDA\'s list of quarantined counties. The quarantine restricts the movement ash trees, ash limbs and branches, ash stumps and roots, ash logs, ash lumber, ash wood, or ash bark chips from a quarantined county into a non-quarantined county.\nIn addition, hardwood firewood of any kind (ash, oak, etc.) may not be moved from a quarantined county into a non-quarantine county. More details about the quarantine can be found on the Emerald Ash Borer - Minnesota Quarantine website.\nDamage to Ash Population\nAccording to the Minnesota Department of Agriculture (MDA) no evidence to date of resistance against EAB has been found in any native North American ash populations. In areas where EAB has become established in North America, ash tree mortality rates approach 100%. Insecticide treatments are available that can in some situations protect individual trees from EAB attack. The damaging agent is the immature stage, the larvae, of the insect.\nSymptoms & Treatment\nThe larvae kill ash trees as they feed on the living tissue under the bark. Sometimes the symptoms can be very subtle. Contact a local consulting certified arborist for an inspection and treatment options. Timing is crucial to any treatments and trees that are already infested may not survive.\nDoes the City of Wayzata have a plan to deal with EAB?\nThe City of Wayzata approved a plan in April 2014 to protect a portion of the City\'s trees from the invasive Emerald Ash Borer. The City of Wayzata\'s Emerald ash borer (EAB) management plan dedicates funding to treat ""legacy"" public ash trees in parks and boulevards, remove others that are in poor condition or become infested, and plant new trees. In 2016, the City removed public ash trees on public right of way in the spring and in the fall will plant with bare root trees.\nRead the synopsis of the management plan: City of Wayzata Emerald Ash Borer Management Plan.\nAsh Injection Program and Treatment of Private Ash Trees\nIn preparation of the inevitable arrival of EAB, the City of Wayzata has contracted with Rainbow Treecare to treat public ash trees growing along streets and in parks. A city-wide bulk discount is being offered to Wayzata homeowners for trees on private property that are at least 10"" in diameter and in good physical condition.\nResidents can take advantage of the City\'s contract prices to treat ash trees on their private property. Residents will be responsible for the full cost of these private treatments. Residents interested in scheduling a treatment for private ash trees should contact Rainbow Treecare at 952-767-6920 for pricing and scheduling.\nContacting an Arborist\nResidents may also contact a certified arborist working for a private company. Most reputable companies employing certified arborists will be familiar with the 2 insecticides available. One is applied as a soil drench, the other is an injection. It is not necessary to remove healthy ash trees at this time. Homeowners may also contact the MDA\'s ""Arrest the Pest"" hotline at 651-201-6684 after learning more about the pest.\nAsh Tree Removal Guidelines\nIt is not necessary to remove healthy ash trees at this time, though you should start diversifying the tree species in your yard if you have mostly ash trees now.']"	['<urn:uuid:4bfa719c-2988-4860-8e81-948747138f33>', '<urn:uuid:abe44dfe-1450-4dda-92b5-7eb5fe2dc950>']	open-ended	direct	concise-and-natural	similar-to-document	comparison	expert	2025-05-12T23:56:45.148498	10	69	2338
88	mens womens lacrosse game start beginning different ways face off draw	Men's lacrosse begins with a face-off where two squatting players place their sticks on the ground back-to-back at the center of the field, and the official places the ball between them. In women's lacrosse, the game begins with a 'draw' where two centers press their sticks together back-to-back with the ball between them, and they push the ball up and out when the umpire calls 'draw'.	"['Your Guide to the Fastest Game on Two Feet\n- ATTACK: The attackman\'s responsibility is to score goals. He generally restricts his play to the offensive end.\n- MIDFIELD: The midfielder\'s responsibility is to cover the entire field playing both offense and defense.\n- DEFENSE: The defenseman\'s responsibility is to defend the goal. He generally restricts his play to the defensive end of the field.\n- GOAL: The goalie\'s responsibility is to protect the goal and stop the opposing team from scoring.\nMen\'s lacrosse is a contact game played by ten players: a goalkeeper, three defensemen, three midfielders and three attackmen. The object of the game is to shoot the ball into the opponent\'s goal. The team scoring the most goals wins.\n- Each team must keep at least four players, including the goalie, in its defensive half of the field and three in its offensive half Three players (midfielders) may roam the entire field.\n- Generally, high school games are 48 minutes long, with 12 minute quarters. Each team is given a two minute break between the first and second quarters, and the third and fourth quarters. Halftime is ten minutes long.\n- Teams change sides between periods. Each team is permitted two timeouts each half. The team winning the coin toss chooses the end of the field it wants to defend first.\n- Men\'s lacrosse begins with a face-off. The ball is placed between the sticks of two squatting players at the center of the field. The official blows the whistle to begin play. Each face-off player tries to control the ball. The players in the wing areas can release; the other players must wait until one player has gained possession of the ball or the ball has crossed the goal line.\n- Center face-offs are also used after a goal and at the start of each quarter.\n- Players may run with the ball in the crosse, pass and catch the ball. Only the goalkeeper may touch the ball with his hands.\n- A player may gain possession of the ball by dislodging it from an opponent\'s crosse with a stick check, which includes the controlled poking and slapping of the stick and gloved hands of the player in possession of the ball.\n- Body checking is permitted if the opponent has the ball. However, all contact must occur from the front or side, above the waist and below the shoulders. An opponent\'s crosse may also be stick checked if it is within five yards of a loose ball or ball in the air.\n- If the ball or a player in possession of the ball goes out of bounds, the other team is awarded possession of the ball. If the ball goes out of bounds after an unsuccessful shot on goal, the player nearest to the ball when and where it goes out of bounds is awarded possession.\n- An attacking player cannot enter the crease around the goal, but may reach in with his stick to scoop a loose ball\nThe penalty for a personal foul is a one to three minute suspension from play and possession to the team that was fouled. Players with five personal fouls are ejected from the game.\nSLASHING: Occurs when a player\'s stick contacts an opponent in any area other than the stick or gloved hand on the stick.\nTRlPPlNG: Occurs when a player obstructs his opponent at or below the waist with the crosse. hands. arms. feet or legs.\nCROSS CHECKING: Occurs when a player uses the handle of his crosse to make contact with an opponent.\nUNSPORTSMANLIKE CONDUCT: Occurs when any player or coach commits an act which is considered unsportsmanlike by an official, including taunting. obscene language or gestures. and arguing.\nUNNECESSARY ROUGHNESS: Occurs when a player strikes an opponent with his stick or body using excessive or violent force.\nILLEGAL CROSSE: Occurs when a player uses a crosse that does not conform to required specifications. A crosse may be found illegal if the pocket is too deep or if the crosse was altered to gain an advantage.\nILLEGAL BODY CHECKING: Occurs when any of the following actions take place: (a) body checking of an opponent who is not in possession of the ball or within five yards of a loose ball: (b) avoidable body check of an opponent alter he has passed or shot the ball; (c) body checking of an opponent from the rear or at or below the waist; (d) body checking of an opponent by a player in which contact is made above the shoulders of the opponent. A body check must be below the neck, and both hands of the player applying the body check must remain in contact with his crosse.\nILLEGAL GLOVES: Occurs when a player uses gloves that do not conform to required specifications. A glove will be found illegal if the fingers and palms are cut out of the gloves, or if the glove has been altered in a way that compromises its protective features\nThe penalty for a technical foul is a thirty second suspension if a team is in possession of the ball when the foul is committed. or possession of the ball to the team that was fouled if there was no possession when the foul was committed.\nHOLDING: Occurs when a player impedes the movement of an opponent or an opponent\'s crosse.\nINTERFERENCE: Occurs when a player interferes in any manner with the free movement of an opponent, except when that opponent has possession of the ball, the ball is in flight and within five yards of the players, or both players are within five yards of a loose ball.\nOFF SIDES: Occurs when a team does not have at least four players on its defensive side of the midfield line or at least three players on its offensive side of the midfield line.\nPUSHING: Occurs when a player thrusts or shoves a player from behind.\nSCREENING: Occurs illegally when an offensive player moves into and makes contact with a defensive player with the purpose of blocking him from the man he is defending.\nSTALLING: Occurs when a team intentionally holds the ball. without conducting normal offensive play, with the intent of running times off the clock.\nWARDING OFF: Occurs when a player in possession of the ball uses his free hand or arm to hold, push or control the direction of an opponent\'s stick check.\nWhat is the object of lacrosse?\nThe object is to put the ball into your opponent\'s goal.\nHow does the game begin?\nA lacrosse game begins with a face off at the mid-field line at the X spot in the center of the field.\nWhat is a face off?\nA face off consists of the two center players at the mid-field line crouching down and placing their sticks on the ground so that the heads of the sticks have their backs to each other. The official then places the ball on the ground between the heads of the sticks, steps back and blows a whistle which signals to the players they can fight for possession of the ball.\nWhen are face offs used?\nAt the beginning of a game, at the beginning of each quarter and after each goal is scored.\nHow many men are there on a lacrosse team?\nSquads range from 25 to 30 men normally.\nHow many men are there on the field for one team?\nThere are ten men consisting of one goaltender, three defense men, three mid-fielders, and three attack men.\nWhat are the goaltender\'s special privileges?\nHe uses the largest stick on the field with a maximum width of 12 inches. He is the only one allowed to use a stick this large. He cannot be checked if he has gained possession of the ball within the crease are nor is an opponent allowed in the crease area.\nWhat is defined as ""in the crease area""?\nA goaltender is considered in the crease as long as he has one foot on or within the 18-foot diameter circle. If he lifts his foot up and puts t back down while in the possession of the ball, it is called ""out and in"" and he loses possession of the ball.\nHow long can a goaltender stay in the crease with the ball?\nA goaltender has four seconds to step out of the crease or throw the ball to a teammate. If he does not do this, he loses possession of the ball.\nTHE LACROSSE FIELD\nWhat is the mid-field line?\nThis line divides the field exactly in half. At the beginning of a game, at the beginning of each quarter and after each goal is scored, the ball is faced off at the mid-field line at the X spot.\nWhat are the wing areas?\nThese two lines indicate where the two outside mid-fielders must stay until the official blows his whistle to start a face off.\nWhat is the crease area?\nA goal crease is a circle 18 feet in diameter that marks an area where an offensive player can never enter under any circumstances except one.\nWhat is the one exception that allows an offensive player to enter the crease area?\nIf an offensive ball player should fall into the crease such that he lands with his feet outside the crease and both hands on his stick within the crease in a push up position he may then get up and out of the crease with no stoppage of play.\nWhat are the restraining areas?\nThese areas mark where all the players other than the three players who are the mid-field line must stay in during a face off until either team has gained possession of the ball. In the defense restraining area there are three defense men plus the goaltender. In the offensive area there are three attack men. Leaving the restraining areas before the referee signals possession will result in loss of the ball.\nHow big is a lacrosse goal?\nThe front of a lacrosse goal is a perfect square, six feet by six feet.\nHow To Play Women\'s Lacrosse\n- A game begins when the two centers from each team ""draw"" at the center of the field: a ball is placed between their two sticks pressed together back-to-back. When the umpire calls ""draw,"" the centers attempt to control the ball when they push the ball up and out of the circle -- the area around the face-off. (Think of the tip-off in basketball.)\n- Then, the players around the circle -- usually the attack wings, defense wings, 3rd Homes and 3rd Men from both teams -- sprint for the descending ball. Once control is attained by a team, it works pretty much like some other sports: players run and pass the ball to push it down field toward the goal.\n- Cradling is the method by which a player holds the ball in the stick\'s pocket. Unlike men\'s lacrosse, women\'s sticks may not have a deep pocket in which to hold the ball securely; a player ""cradles"" the ball to keep it in the pocket. Cradling uses centripetal force -- the force generated by moving something in a circle -- to press the ball into the back of the pocket. (You can feel centripetal force at the amusement park when a ride spins and pushes you out from the axis around which you\'re turning.)\n- To learn to cradle, hold a pen or pencil with your right fist around the top, and the left hand around the bottom (for lefties, reverse it -- left hand on top.) Now bring both fists and the pen to your right shoulder, keeping the pen vertical. Then bring it to your left shoulder, keeping the pen vertical. Although you won\'t be able to see the centripetal force at work using this example, very basically, this is cradling.\n- When a player has an opening to the goal, she shoots the ball by pushing the head of the stick forward, and pulling the the shaft back. The shots can be extremely accurate and fast.\n- Passing is the fastest way to get the ball down field, but it can also be one of the hardest things to do. Releasing the ball with speed and accuracy can take LOTS of practice to make it effective.\n- Passing is done in the same manner as shooting, but catching the pass is often the hardest part. Not only does the ball have to land in your stick, but you must also learn to put the catch immediately into a cradle to gain control of the ball and prevent yourself from being checked.\n- Checking is the technique in which a series of short, sharp, controlled strikes to an opponent\'s stick is used to force a player carrying the ball to drop it.\n- A player can check the head or shaft of the stick, or body check.\n- Body checking sounds like a player would strike an opponent\'s body, but it\'s actually accomplished when a defender sticks close to her opponent in an effort to intimidate the player into dropping the ball, or changing the opponent\'s path towards the goal.\n- There are 12 players on each team, including the goalie.\n- Attack positions are: Center, Right Attack Wing, Left Attack Wing, 3rd Home, 2nd Home, 1st Home\n- Defense positions are: Right Defense Wing, Left Defense Wing, 3rd Man, Cover Point, Point, Goalie\n- Player Equipment: Stick, Cleats, Mouthguard, Numbered shirt and kilt or shorts, and Padded Gloves (optional)\n- Goalie Equipment: Helmet with face-mask and throat protector, Padded Gloves, Arm Pads, Chest Pad, Leg Pads, and goalie stick\n- The Field: There are four types of demarcation lines around the goal: the circle, the arc, the fan, and hash marks. The circle envelopes the goal cage and no one but the goalie is allowed in the circle. The goal is guarded by a single goalie and measures about 6 feet by 6 feet. The field has no boundaries, but is usually enclosed by existing borders, such a trees, a track or fences.\n- Before the game begins, the umpire checks every stick (except the goalie\'s) for legality. The most common illegality in a stick is that its pocket is too deep. The strings at the bottom of the stick\'s head can be pulled to tighten the pocket.\n- If a player commits a foul, the umpire blows the whistle and play stops. The player fouled wins or retains the ball, while the player who fouled her is moved several yards behind or to the side of the player she fouled.\n- If a major foul is committed in the arc by the defense, the umpire blows the whistle, and a ""free shot"" on goal is taken by the player fouled. All of the defense players are required to clear the arc to the border closest to which they were standing when the whistle blew.\n- The attack player who was fouled takes her place at the hash mark closest to which she was standing when she was fouled. The defense must move away at least four meters from the fouled player. When the umpire blows the whistle again, the player can take a shot on goal or pass while the defense moves in.\n- There are no boundaries to the field, but if a ball enters an area that is dangerous, unplayable or not clearly visible to the umpire, the player who retains it or is closest to it (if the ball has been grounded), at the umpire\'s whistle wins it. The player then waits for the second whistle to begin play again, either by running with or passing the ball.\n- When the umpire blows the whistle because a foul has occurred, or the ball has gone ""out of bounds"" all players must stop and check all forward movement. Play resumes and the players can move when the umpire blows the whistle again.\n- Checking -- the method by which a player knocks the ball from another\'s stick -- is prohibited when it is: directed toward the face', ""Girl's lacrosse is a non-contact game played by 12 players: six attackers, five defenders and a goalkeeper. (First through fourth graders play with 8 players on a shortened field.) The object of the game is to shoot the ball into the opponent's goal. The team scoring the most goals wins.\nBelow are the modified names and positions for players on a full field. As the game evolves, so do these names. Every coach has a different style and may call these positions different names.\nRight and left attack players are considered playmakers and also have the responsibility of transitioning the ball from the defense to the attack. They should be good feeders and able to shoot well from every angle and distance from the goal.\nGoal circle attack player is responsible for scoring. She plays closest to the goal and must continually cut toward the goal for a shot or away from the goal to make room for another player. She should have excellent stickwork and must play well while closely guarded.\nRight and left attack wings are responsible for transitioning the ball from defense to attack. Wings should have speed and endurance and should be ready to receive the ball from the defense to run or pass the ball.\nCenter is responsible for controlling the draw and playing both defense and attack. She should have speed and endurance.\nRight and left defense are responsible for guarding the area closest to the goal. They should be able to stick check and look to intercept passes. They should be excellent at getting into good defensive position.\nDeep defense is responsible for defending players coming over the restraining line towards the goal. She should be able to intercept passes, clear the ball, run fast, and have good footwork.\nRight and left defense wings are responsible for marking the attack wings and bringing the ball into the attack area. Wings should have speed and endurance.\nGoalkeeper is responsible for protecting the goal. She should have good stickwork, courage, and confidence.\nThe following is a list of terms you may frequently hear while watching a lacrosse game. Some, you may be familiar with, others, may sound a little odd at first. But all are part of knowing the game of lacrosse.\n· Cradle: The act of moving the stick from side to side causing the ball to remain in the upper part of the pocket webbing.\n· Checking: The act of using a controlled tap with a crosse on an opponent's crosse in an attempt to dislodge the ball.\n· Catching: The act of receiving a passed ball with the crosse.\n· Cutting: A movement by a player without the ball in anticipation of a pass.\n· Dodging: The act of suddenly shifting direction in order to avoid an opponent.\n· Passing: The act of throwing the ball to a teammate with the crosse.\n· Pick-Ups: The act of scooping a loose ball with a crosse.\n· Shooting: The act of throwing the ball at the goal with the crosse in an attempt to score.\n· Clear: Any action taken by a player within the goal circle to pass or carry the ball out of the goal circle.\n· Critical Scoring Area: An area 15 meters in front of and to each side of the goal and nine meters behind the goal. An eight-meter arc and 12 meter fan are marked in the area.\n· Crosse (Stick): The equipment used to throw, catch, check and carry the ball.\n· Checking: Stick to stick contact consisting of a series of controlled taps in an attempt to dislodge the ball from the crosse.\n· Deputy: A player who enters the goal circle when the goalie is out of the goal circle and her team is in possession of the ball.\n· Draw: A technique to start or resume play by which a ball is placed in between the sticks of two standing players and drawn up and away.\n· Eight-Meter Arc: A semi-circular area in front of the goal used for the administration of major fouls. A defender may not remain in this area for more than three seconds unless she is within a stick's length of her opponent.\n· Free Position: An opportunity awarded to the offense when a major or minor foul is committed by the defense. All players must move four meters away from the player with the ball. When the whistle sounds to resume play, the player may run, pass or shoot the ball.\n· Free Space To Goal: A cone-shaped path extending from each side of the goal circle to the attack player with the ball. A defense player may not, for safety reasons, stand alone in this area without closely marking an opponent.\n· Goal Circle: The circle around the goal with a radius of 2.6 meters (8.5 feet). No player's stick or body may “break” the cylinder of the goal circle.\n· Grounded: Refers to any part of the goalkeeper's or deputy's body touching the ground for support outside of the goal circle when she attempts to play the ball from inside the goal circle.\n· Indirect Free Position: An opportunity awarded to the offense when a minor foul is committed by the defense inside the 12 meter fan. When the whistle sounds to resume play, the player may run or pass, but may not shoot until a defender or one of her teammates has played the ball.\n· Marking: Being within a stick's length of an opponent.\n· Penalty Lane: The path to the goal that is cleared when a free position is awarded to the attacking team.\n· Scoring Play: A continuous effort by the attacking team to move the ball toward the goal and to complete a shot on goal.\n· Stand: All players, except the goalkeeper in her goal circle, must remain stationary following the sound of any whistle.\n· Sphere: An imaginary area, approximately 18 cm (seven inches) which surrounds a player's head. No stick checks toward the head are allowed to break the sphere.\n· 12 Meter Fan: A semi-circle in front of the goal used for the administration of minor fouls.\n· Warning Cards: A yellow card presented by an umpire to a player is a warning which requires that she sit out of the game for three minutes without a substitute. A second warning card to the same player automatically becomes a red card and she is prohibited from playing the remainder of the game. If an umpire issues a red card to a player, the player is suspended from further participation in the current and next game. A green card is presented by an umpire to the team captain indicating a team caution for delay of game. See www.uslacrosse.org for other details pertaining to cards.""]"	['<urn:uuid:d616729f-4e04-4618-be38-5a779c1f2e59>', '<urn:uuid:92738060-ade5-4da4-9d28-30debadbf307>']	factoid	with-premise	long-search-query	similar-to-document	comparison	novice	2025-05-12T23:56:45.148498	11	66	3829
89	As an environmental specialist focusing on regional challenges, can you explain why water scarcity is particularly significant in the Mediterranean region and what implications it has?	The Mediterranean is the world's most water scarce region and is particularly vulnerable to climate change and extreme weather events. These environmental challenges are contributing to regional instability and migration. However, the region has significant potential for climate change mitigation and adaptation, which could create opportunities for job creation and entrepreneurship, especially among Mediterranean youth. This approach could help address regional instability issues that stem from unemployment, disenfranchisement, and migration.	['Latest on Partnerships\n- Knowledge Library\n- Contact Us\nCenter for Mediterranean Integration\nThe Mediterranean region is the most water scarce region in the world and one of the most vulnerable to climate change and extreme weather events, which are fuelling regional instability and migration. However, the region also has considerable potential for climate change mitigation and adaptation, which are a common concern for its future.\nCombating water scarcity and supporting climate change adaptation and mitigation in the Mediterranean region could be conducive to job creation and entrepreneurship, particularly among Mediterranean youth, with clear knock-on effects on regional instability deriving from unemployment, disenfranchisement and migration.\nTargeting youth through capacity-building and green entrepreneurship opportunities revolving around water is therefore a key means to leverage untapped youth potential in the region with positive socio-economic and environmental outcomes.\nCreation and Maintenance of the CMI-managed MedYWat Network\nThe Center for Mediterranean Integration (CMI) launched the Mediterranean Youth for Water (MedYWat) network in April 2017 through the annual CMI World Water day workshop series. MedYWat targets young Mediterranean water professionals (aged 18-35) who are determined to tackle water-related issues in the region by amplifying the voice of youth in the regional water agenda.\nToday, MedYWat’s is the only Mediterranean Youth water network involving young water researchers, entrepreneurs and activists from both rims of the Mediterranean to network, share knowledge, collaborate, engage in capacity-building and influence water policies in their countries of origin and the region.\nWith CMI’s support, the network generates and shares knowledge leading to the preparation of each World Water day (Water and Migration 2019; Water and Nature-Based Solutions 2018; Treated Wastewater Reuse and the Circular Economy 2017) in collaboration with leading international senior water experts. The MedYWat network counts over 150 members, representing 15 nationalities from across the Mediterranean and composed of 75% female members.\nRegular Water Hub meetings are being held with the CMI Water Program partners since 2016 to set up a multi-partner regional agenda and ensure ongoing exchanges and joint programming between Water Hub partners (AFD, CIHEAM, GIZ, EIB, Plan Bleu and World Bank) and observers (Switch-Med, GWP-Med, World Water Council UfM, IOM, FAO, CEWAS Middle East and others).\nThe hub thereby contributes to increased collaboration and integration on water issues in the water-scarce Mediterranean region, while taking into account best practices and experiences from around the world.\n“How do we see our Water Future?” – Strategic planning in Tunisia\nThe national workshop held in Tunis, Tunisia in December 2015 took place in an evolving governance context, with the finalization of the new Water Code and the reform of water users’ associations. Some of the country’s successful experiences in groundwater management showed a potential for replication in other regions of Tunisia. Furthermore, many of the situations and solutions discussed at the workshop are of interest for the whole MENA area and will be shared region-wide.\n“Water Demand Management for beginners” and advanced decision makers\nFollowing two synthesis papers in early 2015, a research paper and a technical report with case studies were released by AFD on the management of groundwater resources as common goods. The research paper will be an input to the forthcoming WDR 2017 “Governance and the Law”.\n“Dealing with Water Scarcity through Desalination, Non-Revenue Water Reduction and Public Private Partnerships” with the World Bank Water Global Practice and CMI Partners, 12-14 December 2016, Villa Valmer, Marseille\nThis workshop gathered water desalination experts, government representatives, development agencies, international financial institutions and private actors to take stock of the potential of desalination for increasing water security in the Mediterranean, as well as the ways in which it can be coupled to renewable energy sources to increase its sustainability. Furthermore, the financial sustainability of desalination projects was discussed through presentations on several desalination and renewable energy Public Private Partnerships in the Mediterranean and other best practices from around the world.\nCMI launched the “Mediterranean Water Heroes” contest (in collaboration with the World Bank and Wamda), which offered young water researchers, entrepreneurs and activists from around the Mediterranean the opportunity to showcase their innovative work on wastewater and the circular economy during the “Youth Innovating with Wastewater for a Sustainable Mediterranean” workshop in March 2017.\nWinners of the contest were invited to present their work at the World Water Day event and received sponsored registration to Stockholm World Water Week (August 2017) to represent the Med Water Youth Network.\nThis youth-focused workshop gathered Mediterranean youth and technical experts working in the wastewater field to discuss the opportunities and challenges facing treated wastewater reuse in the region.\nIt stimulated inter-generational and regional knowledge exchange on treated wastewater reuse through plenary presentations, team activities and collective brainstorming sessions ranging from the technical to the economic opportunities and social impacts of wastewater reuse, and resulted in the launch of the MedYWat (Mediterranean Youth for Water) Network.\nWater and Sanitation services are essential humanitarian needs during both peace and instability situations. Utilities and service providers should therefore be well prepared for crisis situations with improved institutional capacity, training and systems. This workshop exchanged knowledge and experiences to improve their readiness to meet crisis challenges and maintain service provision to their populations.\nIts objective was to understand utilities’ needs during crises, share lessons, drive innovation, and influence policy to better meet the needs of refugees, internally displaced persons (IDPs), and host community needs.']	['<urn:uuid:7170306c-f7b8-41b4-bde0-a0dc7689eae4>']	open-ended	with-premise	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-12T23:56:45.148498	26	70	888
90	ways reduce expenses feeding cows winter months grazing strategies costs	Several strategies can reduce winter feeding expenses: 1) Stockpiled forage grazing costs $0.55/day and requires 1.1 acres per cow for 112 days, significantly cheaper than hay at $1.05-1.40/day. 2) Limit-feeding corn at 12-16 lbs/day costs about $1.03/day. 3) Strategic grazing of winter pastures can be optimized by allowing 25% utilization in May, but avoiding June grazing to maintain sufficient winter stockpile. When using hay, it costs about $350 annually to maintain a cow, with feed representing about two-thirds ($230) of this cost. Environmental conditions must be considered, as cold temperatures increase energy requirements - each degree below 32°F increases energy needs by 1%.	"['– Dr. Steven C. Loerch, OSU Animal Sciences Department, OARDC\nMeeting the nutritional needs of beef cows during the winter is a costly proposition. On average, it costs about $350 a year to maintain a cow. Of these annual costs, approximately two-thirds ($230) is cost of feed. If you feed hay valued at $60/ton for five months during the winter, this cost is approximately $160 (or $1.05/cow/day). Reducing winter feed costs provides the greatest opportunity to improve profits for beef producers. This paper will outline factors affecting cow nutrient requirements and winter feeding systems for beef cows that reduce annual feed costs for the cow herd.\nCow nutrient requirements must be met for optimum production and reproductive performance. These requirements are dependent on the size (body weight) of the cow, her milk production potential, her stage of production, and the environment (temperature, wind and wet hair coat). In Ohio and surrounding regions, meeting requirements for calories (energy) is the most costly and important nutrient. Every 100 lb increase in average cow body wt increases net energy requirements by about 6%. Milk production potential plays a bigger role in energy requirements, but this only is of major importance during the first three months of lactation. Cows with superior milking ability require 25% more energy than those with average milking ability. Stage of production plays a major role in energy requirements. For example, we will consider a 1200 lb beef cow with average milking ability (16 lb/d). This cow requires 16.3 mega calories of net energy per day for the first three months post calving, 12.5 mega calories per day from three months post-calving to weaning, 8.8 mega calories per day from weaning until 60 days before calving, and 11 mega calories per day during the last 60 days of pregnancy. If these requirements are not met, calf survival, weaning weights and the cows’ ability to rebreed are compromised. Based on these numbers, it is obvious that there is up to a 2-fold change in energy requirements dependent on stage of production. This is the main rationale for calving cows in the spring. Spring calving matches the highest nutrient requirements of the cow with cheap, plentiful, high quality, cow-harvested forage. Having a short, defined calving season is also important because cows are then all in the same stage of production, allowing their nutrient requirements to be met. Over feeding cows wastes money on feed and under feeding cows reduces production and reproductive performance. Both should be avoided. Spring calving also means that costly winter feeds are being used when nutrient requirements are the lowest. Environmental effects are most significant in the winter. For a cow with little wind and a dry hair coat, energy requirements go up by 1% for every 1 degree drop in temperature below 32 degrees. This means if it is 0 degrees, a cow requires 32% more energy than if it were 32 degrees.\nWinter Feeding Strategies – I will focus this discussion on meeting energy requirements of non-lactating, pregnant cows. Adequate mineral supplementation is important every day of the year and requirements can be met by providing a quality mineral mix free choice. Non-lactating, pregnant cows only require about 8% protein and meeting this protein requirement is rarely a problem when cool-season forages are fed.\n1. Forage testing. To me, there are two main reasons for forage testing. First, it allows you to predict deficiencies in energy and protein for a particular stage of cow production. Cows can’t eat as much poor quality forage and it is lower in net energy for maintenance (NEm). This is a double whammy. Hay that is more than 70% NDF will not meet energy needs the last eight weeks of gestation or during early lactation. This causes all kinds of production problems (loss of Body Condition Score, more dystocia, lower milk production, and delayed return to estrous and difficulty rebreeding). All of these are magnified in 1st and 2nd calf heifers. Protein is probably not as big an issue for our forages, although some supplementation may be necessary during early lactation if you have good milking cows and hay is less than 10% protein.\nThis brings me to the second reason for forage testing: to help in the decision of what hay to feed when. Perhaps this is the simplest and most effective step a producer can take. Great efficiency can be achieved just by matching forage quality with nutritional needs of the cow. For March/April calving cows, the poorest quality hay should be fed first during the winter. After weaning, the cow’s requirements are the lowest. When grazing can no longer be accomplished in the fall, then feed your poorest quality hay. During late January, February and March (before calving) energy requirements are on the rise. This is also when cold weather taxes the cow’s energy status. Hay quality factors and the cow’s energy requirements should dictate what hay gets fed when. The best hay should be saved for late gestation and early lactation (before spring pasture turn-out). Sorting cows into groups based on their nutritional needs is another good way to save supplemental feed costs. If half of my cows are in good condition, there is no point in wasting supplement on them just to meet energy needs of my thin cows. You can save supplement costs by pulling out thin cows and feeding them with your replacement heifers. Cows will usually start showing the effects of poor quality forage in late January and February. Keep a sharp eye on body condition score during these last eight weeks before calving season. Management intervention to maintain cow body condition during this time is more effective and profitable than letting cows get thin and then trying to recover later.\n2. Hay feeding. Feeding hay in the winter is an expensive habit. A cow will generally use 35 to 40 lbs of hay per day. They won’t eat quite this much, but when you consider storage and feeding losses, this is a reasonable estimate (maybe even an underestimate). Hay at $40/ton results in feed cost per cow of $.70/day. If hay is $60/ton this is $1.05/day; $80/ton is $1.40/day. Typical cost estimates for grazing (cow harvested forage) are $.25 – .30/day. Feeding hay instead of using grazing alternatives may be a dollar per cow per day right out of your pocket.\n3. Extended pasture grazing. We have completed three years of research on extended grazing at the Coshocton Branch of OARDC. There were 31 cows per year grazing the stockpiled pasture. We used 34 acres of stockpiled fescue. There were six fenced paddocks in the pastures ranging in size from 5 to 8 acres. Pastures were fertilized on August 1 with ammonium nitrate to provide 80 lbs of N per acre. This fertilizer cost was about $20/acre. Pastures were set aside and not grazed from August 1 until the trial began in late October. Cows spent about 18 days in each paddock before being rotated to the next paddock. Forage was depleted by mid February. Emergency feed during snow cover was limit-fed whole shelled corn (11 lb/day), supplement (1.7 lb/day), and hay (3 lb/day). After February 16, when pasture was depleted, cows were limit-fed a corn-based diet until spring pasture turnout in April. Cows gained 100 lbs during the 112 day trial and held their body condition score (Table 1). Part of this weight gain would have come from fetal development because end weight was made three weeks before the calving season began. This pasture system supported a cow on 1.1 acres for 112 days (Table 2). There was an average of 20 days/year when supplemental feed was needed due to snow and ice cover. Based on pasture rental, fertilizer and harvested feed costs, this system fed a cow for $.55/day. The breakeven value for feeding hay all winter (instead of stockpiling forage) was $31/ton. This means if hay costs more than $31/ton, you could feed cows cheaper with stockpiled forage. If hay is $80/ton, stockpiled forage saves you $1/cow/day. It is important to point out that deferring 1.1 acres/cow for winter grazing means this land can not be used for grazing in late summer and the fall. Adequate pasture land is necessary to carry your herd through the summer grazing season and allow 1.1 acres/cow to be deferred for winter grazing. Fiber content (NDF) of stockpiled forage increased during the winter from 60% to over 70% due to leaf shatter and leaching of soluble sugars. Protein content averaged about 11% and did not change significantly during the winter.\n4. Limit-feeding corn (or byproducts like soyhulls). Corn grain is the least expensive harvested feed per unit of digestible energy available to producers in Ohio. The most common feed used for wintering cows is hay. This is despite the fact that hay costs 50 to 100% more than corn, per unit of energy. Corn priced at $3.00/bu is worth $107/ton. Because hay has only about half the energy value as corn grain, the break-even price for hay on an energy basis would be approximately $54/ton. In many situations it is economically advantageous to use corn rather than hay to meet the energy requirements of cows.\nCows, and all other animals, require a certain amount of energy (calories) per day. If a low energy feed like hay is fed, cows can be full-fed. If corn is used to provide most of the energy, then intake has to be restricted so the animals don’t get fat. We have developed a limit-fed, corn-based nutrition program which has been tested with sheep and cattle. The procedures we used to meet the nutrient needs of gestating and lactating cows is outlined below. Some forage has to be fed to maintain a healthy rumen.\n* Feed 4 lbs first cutting hay, supplement, and 12 lbs whole shelled corn (per cow basis). The rule of thumb here is to feed corn at 1% of cow body weight in mid-gestation. The protein and mineral supplement should be similar to that used for feedlot cattle fed a high-grain diet. Follow feeding instructions on the bag.\n* Feed corn whole. Ohio State research shows that whole corn works better than ground corn when daily hay intake is limited to less than five pounds.\n* Adjust corn intake to achieve desired weight and/or body condition score. You may need to increase corn in January and February due to increased energy requirements associated with cold temperatures and late gestation. We generally feed 12 lbs/cow/day until late December, and 14 to 16 lbs/day until spring turnout on pasture.\n* When starting the program, take 7-10 days adjusting up the corn and decreasing hay to the 4 lb level. Make sure bunk space is adequate so all cows get their share and that cows are in a securely fenced area.\nWe have used this system on part of our cow herd at the Coshocton Branch for over 20 years with good success. Beef producers should not be afraid to feed shelled corn to cows. Corn makes a good energy supplement to improve (or maintain) cow body condition. It can also be used as the basis for the whole winter feeding program. In our work, limit-feeding corn throughout the winter resulted in the same cow performance as feeding hay (Table 1). If hay = $80/ton, corn = $3.00/bu, and supplement = $150/ton, it costs about $1.03/day to feed a cow with this system (Table 2). With these assumptions for feed costs, the breakeven value for hay would be $48/ton.\nThere are other feedstuffs available that may also be cheaper than hay on an energy basis. See this Fact Sheet in our OSU Beef Team Library web page: http://ohioline.osu.edu/as-fact/0001.html\nThis article by Steve Boyles and Cliff Little does a good job pricing alternative energy sources if supplementation is needed. Here are some additional thoughts in this regard. Dried distillers grains (DDGS) provide the same energy as corn and have 3 times the protein. A pound of DDGS will replace 2 pounds of hay. Procedures for feeding DDGS are the same as feeding corn, except no supplemental protein is needed. Soybean hulls are a great forage supplement, and are more economical than purchasing hay this year and most years. One pound of soyhulls is equal to about 1.5 pounds of hay.\nGood quality hay is a great supplement to feed with average quality hay during peak cow energy needs, but purchasing good quality hay may be cost prohibitive. Five to eight lbs of corn/day is a cost effective energy supplement during late gestation and early lactation (corn will likely be a much cheaper source of calories than purchasing good quality hay). One effective option producers rarely consider is hay chopping. Chopping hay allows the cows to eat 25-30% more energy. Costs of chopping hay (equipment, labor, etc.) should be compared to costs of purchasing supplemental energy. For some producers, this may be a cost effective option. I came to realize the potential of hay chopping from an observation I made two years ago at the OARDC Beef Center in Wooster. Steers fed a chopped hay based diet gained 2.5 lbs/day while those fed round baled hay (same hay source) in a rack gained less than 1.5 lbs/day.\nAs outlined in the Boyles/Little article, there are several options for producers who need to increase energy intake because hay quality is insufficient. Be creative and sharpen your pencils!\n5. Grazing Corn or Stalks. Grazing crop residues (such as corn stalks) is a simple and effective method for extending the grazing season. One acre of stalks will support a cow for up to 60 days. Our research indicates if we strip graze (moving fence twice per week) an acre will support two cows for 60 days. Only mineral and water is needed if this occurs in November and December.\nWe have also investigated strip grazing standing corn that has not been harvested. In this system, an acre will support two cows for about 110 days. We moved cows twice per week and gave them access to round baled hay for four hours before each move. Cows were hungry before each move because we wanted them to eat as much stalks as possible. Hay was provided so cows didn’t over consume corn immediately after fences were moved. Estimated feed costs for this system was $.60/cow/day.\nTable 1. Effect of feeding stockpiled forage, limited corn, or hay to gestating cows (3 year average)\n|No. of cows||31||24||17|\n|Days on test||112||112||112|\n|Initial wt, lb||1457||1457||1460|\n|Final wt, lb||1557||1566||1563|\n|Wt change, lb||100||109||103|\n|Initial body condition score||6.5||6.5||6.5|\n|Final body condition score||6.2||6.6||6.0|\n|Body condition score\n|Calf birth wt, lb||109||109||103|\n|Cow wt, 7/12||1502||1526||1478|\n|Cow body condition score,\n|Calf wt, 7/12||400||415||408|\n|Conception rate, %||91||86||96|\nTable 2. Effects of three cow wintering systems on feed use (3 year average)\n|No. of cows||31||24||17|\n|Total harvested feed/cow|\n|Total days of harvested feed||20.3||112||112|\n|Harvested feed cost/cow/d\n|Total harvested feed\n|Pasture rental, $/cow/d||$0.43|\n|Total cost, $/cow/d||$0.58||$1.03||$1.61|\na) Prices used: Corn = $3.00/bu, Hay = $80/ton, Supplement = $150/ton.', 'By: Robin Salverson, Cow/Calf Field Specialist, SDSU Extension\nHow can ranchers improve profitability when feed typically represents well over half of cow-calf production costs? Grazing dormant winter range is a common practice to reduce costs. Grazing winter range when plants are completely dormant minimizes negative impacts on the function of the plant during the growing season. Separate pastures are typically designated for winter use only, often based on availability of winter shelter, water and access to stored feeds.\nIn practice, winter pastures are often deferred from grazing during the growing season to allow for grass to stockpile for winter grazing. Is deferred grazing the best option for maximum production? Initial response would be yes. However, research has shown that carefully planned defoliation or grazing during the growing season may stimulate plant production. Therefore, designing a system that allows for some grazing when plants are growing (i.e. spring) could possibly increase the use of winter pastures without sacrificing the amount of stockpiled forage.\nIn western South Dakota vegetation is dominated by cool-season grasses, so that a majority of plant growth occurs in April, May and June which corresponds with peak moisture months. Expectations would be that plants reach maximum height and yield about by July 15. Based on this knowledge, we would anticipate plants grazed after July 15 would not have sufficient regrowth potential to accumulate for winter grazing.\nThis brings us to the question when is the right time to graze? Research was conducted at SDSU Cottonwood and Antelope Research Stations in western South Dakota for three seasons to test the hypothesis that clipping early in the growing season at a low intensity would allow adequate regrowth, compared to winter clipping only. Treatments included either a 25 or 50% relative utilization of the current stand of western wheatgrass. Clipping dates were May 15, June 15, July 15 and August 15. An additional treatment was no clipping during the spring or summer. Using previously established height/weight relationships, production was estimated by measuring the plant height of western wheatgrass. Quantities of short and mid grasses were determined at the conclusion of the study to see if there was any shift in plant community composition.\nResults of the study suggest that grazing winter pastures in May, targeting 25% relative utilization, allows sufficient regrowth to occur during the remainder of the growing season to maintain sufficient stockpiled forages for winter use. Human nature is to push the limit by either increasing utilization or extending the grazing period. Based on the results, we need to be cautious not to graze at a higher utilization rate in May (50%) or extend the grazing period into June even at a lower utilization rate (25%). Standing forage available for winter use could be reduced. There was also a negative shift from mid to short grasses when plots were clipped in June. Results are consistent with other research demonstrating that grasses are most vulnerable during the rapid elongation phase of growth. Timing of this event may vary considerably from one year to the next. Excellent grazing management requires adapting grazing schedules in response to growing conditions and plant development.\nImplementing this strategy will include intense management. Conceptually, cattle should graze only the upper portion of plants. This will require cattle to be restricted to pastures for a short period (< 2 days) at a high stocking density and then moved through several pastures, promoting even distribution of grazing throughout the pasture. Heavy use of one species can result in decreased production for future use. This concept is called ""flash grazing."" A common response is ""we can’t do that."" However, ranchers in the western region are successfully using this flash grazing approach.\nIt has been proven in clipping studies that dual use of ""winter range"" in the spring and during the winter can be accomplished without a negative effect on quantity of stockpiled forage. Looking at both the production and economics it works, however, management is the key.']"	['<urn:uuid:b4ad7e5a-3ba0-411c-a275-5cab063bbd40>', '<urn:uuid:fe9e9298-be3f-452e-8337-f4b431185e55>']	open-ended	direct	long-search-query	distant-from-document	three-doc	novice	2025-05-12T23:56:45.148498	10	103	3158
91	colorado agriculture water rights vs environment	In Colorado, agriculture controls the oldest water rights and uses 86% of the water, while environmental and recreation interests have junior (newer) water rights dating only to the 1970s. Under Colorado's prior appropriation law, these older agricultural rights get priority during drought, limiting the effectiveness of environmental protections.	['Colorado’s stream management planning watered down by agriculture\nFlow targets for the environment, recreation lacking\nAmong the goals of Colorado’s 2015 Water Plan was to focus more attention on “non-consumptive” water uses — environmental and recreation water needs — through stream management planning.\nThe basic idea of a stream management plan, or SMP, according to the Colorado Water Conservation Board, is when stakeholders convene to evaluate the ecological conditions of their local river to identify flow needs to support environmental and recreational water uses.\nThe goal was to turn some attention on non-consumptive water needs and try to address the gap between how much water is in the stream and how much is needed for a healthy environment and a good recreational experience.\n“The environment and recreation are too critical to Colorado’s brand not to have robust objectives; a strong Colorado environment is critical to the economy and way of life,” reads the Water Plan, referring to the need for SMPs. The Water Plan’s objective was to cover 80% of locally prioritized rivers with an SMP by 2030.\nBut according to a recent River Network report on the 26 SMPs completed or in progress statewide as of September 2021, in some cases the process seems to have been taken over by agricultural interests, watering down what was supposed to have been a tool specifically for the benefit of non-consumptive water uses.\n“A pillar of CWCB’s grant guidance for stream management planning is to ‘identify flows needed to support environmental and recreational water uses,’” the report reads. “This pursuit — as a primary SMP focus — has not been consistent and has proven problematic and even unpopular among participating stakeholders.”\nMost SMPs evaluate flow regimes, but don’t make recommendations for a specific target flow. Of all the 269 project recommendations, just 6% focused on environmental flow targets and only 1% focused on recreation flow targets. In contrast, 14% of recommendations involved agriculture diversion reconstructions, the largest percentage of recommendations.\nAnd although there are many recommendations for projects like stream restoration (11%) and recreation enhancements (7%), putting a number on how much water a stream needs for environmental or recreation purposes is rare. Projects tend to focus on physical modifications to the stream channel and not necessarily how to get more water into that stream channel.\n“This was something I was afraid was going to happen,” said Ken Neubecker, retired Colorado projects director for American Rivers and former Colorado Basin Roundtable member. “I am a little disappointed. Yes, you’ve got to have the other stakeholders engaged, but the original intent with stream management planning was that it should primarily be addressing the environment and recreation needs of a certain stream reach.”\nBringing ag to the table\nNicole Seltzer is the Colorado River basin program director with River Network, the organization that produced the report and which works to protect and restore rivers. She said there are multiple factors as to why more environmental flow recommendations haven’t yet come out of the SMP process, including a lack of stream gauge data on some tributaries. But a main reason is because it’s a sensitive topic that has to be navigated carefully.\n“Sometimes you have to let go of the conversations that are super divisive in order to keep your group together and keep making progress on other things,” Seltzer said. “I think that we’ve seen that the conversation around environmental flow goals and how you meet those goals is sensitive and it has the ability sometimes to derail the entire process.”\nThat divisiveness reveals the tension between traditional water users like agricultural producers, who take water out of the rivers, and recreational and environmental water advocates, whose goal is to keep water in the river. Environmental and recreation groups have historically not played as big a role in water planning as agricultural and municipal water managers. The SMP process was supposed to be a way to legitimize and enhance their role.\nBut because agriculture controls the oldest water rights and makes up the largest slice of water use in Colorado — 86% according to numbers provided by the state — some SMP stakeholder groups realized they couldn’t make progress without including agriculture representatives.\n“Our organization very quickly realized if you’re going to get anywhere environmentally, you don’t just want to operate in a vacuum,” said Richard Van Gytenbeek, Colorado River basin outreach coordinator for environmental group Trout Unlimited, and a Colorado Basin Roundtable member. “You’ve got to bring your municipal and agriculture folks to the table.”\nIn some cases, what started out as an SMP morphed into an IWMP — Integrated Water Management Plans — so named because they integrate the “non-consumptive” environmental and recreation water uses and the “consumptive” agricultural uses.\nThe Colorado Basin Roundtable adopted the term IWMP in place of SMP in 2016 and defined the primary goal of an IWMP as “identifying opportunities to meet environmental flow needs along with needs of agriculture, municipal, industrial and residential water users.” The roundtable’s choice to use the term IWMP was in response to concerns that stream management planning could emphasize environmental and recreational water needs in a way that might negatively impact agricultural water users and other interests.\nThe IWMP undertaken by the Middle Colorado Watershed Council was one of these that started out as an SMP and then expanded the scope to incorporate agricultural interests. The Book Cliff, South Side and Mount Sopris conservation districts tackled the agriculture portion, which included an agricultural water use analysis and inventories of 59 ditches. The individual results of the ditch inventories were not made publicly available, despite being publicly funded.\nThe final action plan outlines 55 recommendations, including six which it says address protection of flows. These include doing a survey of boaters and anglers to see what their flow preferences are, installing more stream gauges on local tributaries of the Colorado River and supporting the Colorado River District as they work to keep water on the Western Slope.\nThe idea was that a watershed council, environmental group or other organization would come up with a way to prioritize local streams and get to work creating SMPs for 80% of the ones they deem to be high priority. But since there was no standardized way to do this across the state, streams in areas with environmentally focused watershed organizations tend to have SMPs, while those without them don’t.\nMany of the projects recommended in the SMPs are “multi-beneficial,” meaning they benefit multiple water user groups: agriculture, environment, recreation, municipal, industrial. Checking more category boxes for a project can sometimes aid in getting grant funding.\nOften, the thinking around a diversion reconstruction or other improvements to irrigation infrastructure is that it can help irrigators more effectively get water out of the river. At the same time, a project could also create a safer passage for boaters or better fish habitat. But these multi-beneficial projects can also have a downside.\n“There is an argument that focusing on multibenefit projects that primarily benefit water users dilutes environmental and recreational flow objectives,” the River Network report reads.\nAnd the tools for boosting river flows are few. While some SMPs are motivated by needing to meet federal requirements, for example keeping enough water in the chronically dry 15-mile reach of the Colorado River in the Grand Valley for the benefit of endangered fish, this is not common, according to the report.\n“In most communities, the only options for pursuing flow-driven outcomes are expensive infrastructure (e.g. ditch piping) or tools for leaving excess water in the river (e.g. water leasing),” the report reads.\nThe idea is that when irrigators have more efficient diversions, they don’t need to take as much water from the river, leaving more for the benefit of the environment and recreation. But whether that actually happens or not is unclear.\nCWCB Watershed Protection Director Chris Sturm said that addressing flow needs is not the only metric of success for an SMP or a project. If a project results in any kind of physical benefit to the stream, it can be considered a win. He said by and large the SMPs are accomplishing what they set out to do.\n“Stream management planning is not all about identifying what the flow needs are,” Sturm said. “I think what our stakeholders are doing is they are finding a path towards trusting each other enough to get to those discussions about flow needs. And it’s being done in a way where they are partnering on projects like diversion reconstructions, which is why you see so many of them.”\nAlthough low flow is not the only issue for the environment and recreation communities, it is often the biggest; other problems like high water temperatures are partly a result of there not being enough water in the river.\n“I would say recreation in Colorado is more threatened by diminishing streamflow,” said Hattie Johnson, southern Rockies stewardship director with American Whitewater. “You can fix the navigation hazard, but if there’s no water in the river to float down it, it doesn’t matter. I think the flow aspect of it is much more dire.”\nAgriculture has the bulk of the water\nRaymond Langstaff is the president of the Bookcliff Conservation District, which extends roughly between Glenwood Springs and Parachute, mostly on the north side of Interstate 70. His organization, along with the Mount Sopris and South Side conservation districts, led the agriculture portion of the IWMP process for the Middle Colorado region.\n“One of the reasons we got involved is because we have a target on our back for water,” Langstaff said. “The bottom line is ag has the bulk of the water. When people need water, where are they going to go? They are going to go to ag to get the water.”\nAnd agricultural water users are feeling the squeeze from drought and climate change too. Langstaff, a retired engineer with the U.S. Forest Service, has a place on Dry Rifle Creek that has been in his family since 1951. He irrigates about 22 acres of grass and alfalfa with water from the Grass Valley Canal and sells the bales of hay to horse owners.\nThis year, the number of days he is allowed to use water from the local irrigation water project dropped from 50 to 35 this year. If the water gets cut more, he may do one fewer cutting of hay. And irrigators on the south side of the Colorado River have it even worse.\n“If you live on Divide Creek, chances are you will be out of water somewhere around the Fourth of July,” he said.\nOne of the ideas behind the ditch inventory, in which irrigators got an analysis of their system and potential areas of improvement, was that they would result in efficiency projects that would benefit the irrigator and could also leave more water in streams for the benefit of the environment.\nBut Langstaff is skeptical that agriculture projects will automatically lead to more water in streams. If agricultural producers can more easily get access to their full water right by making efficiency improvements, they will probably take advantage of that by using all of their water, he said.\n“It’s a false hope they might be able to free up a little more water to leave in the river,” Langstaff said. “If you get more efficient, you get to water more times. And it’s their water and they have the right to use it.”\nThe results of a 2019 survey about SMPs by the Colorado Cattlemen’s Ag Water Network seems to confirm that sentiment. More than half of respondents said the amount of water available to them was a challenge. Survey responses also indicated that more acres would be irrigated and more acres would be more fully irrigated if more water was available for diversion.\nIf environmental and recreation groups want more water to stay in the river, it will require paying agricultural water users, Langstaff said.\n“If you want ag to let water stay in the stream, you’re going to have to compensate somehow,” he said. “If you’re in the ag business exclusively, you need every nickel and dime.”\nA way forward\nThe actions of diverters often have the biggest influence on the health of rivers and the quantity of water in them. And as the flows of the Colorado River and its tributaries continue to decline due to climate change, there will be even less water to go around.\nIn the hierarchy of water uses in Colorado, environmental and recreation interests have taken a back seat to traditional water uses like agriculture. Under the bedrock principle of Colorado water law, prior appropriation, the oldest water rights — typically agricultural water rights — get first use of the river.\nThe only way to secure a water right specifically for the environment is through an instream flow right, which is held exclusively by the CWCB to “preserve the natural environment to a reasonable degree.” Although the state has ISF rights on nearly 1,700 stream segments around Colorado, they date to the 1970s and later, making them very junior to most agricultural and municipal water rights, and thus limiting their ability to keep water in the stream.\nAs for recreation, a handful of communities around the state hold what’s known as a recreational in-channel diversion, or RICD, around which they have built a whitewater park or play waves primarily for kayakers. But in a nod to traditional water users, these rights often end up making concessions to future water development. Two bills floated by recreation proponents that aimed to secure water for recreation purposes have stalled in 2021 and 2022.\nBut most environmental and recreation groups still say that cooperation among all water users within the existing constraints is the best way forward and insist they are making inroads.\n“If you’re an environmental advocate you do the best operating in the system that exists, and the system that exists is Colorado water law,” Van Gytenbeek said. “You have to work with water rights holders to see if there’s flexibility in their operations. It’s not a perfect world and it can be very frustrating if you are a kayaker or a fisherman. But we are making progress by collaborating.”\nAspen Journalism covers rivers and water in collaboration with The Aspen Times. For more go to http://www.aspenjournalism.org.\nSupport Local Journalism\nSupport Local Journalism\nReaders around Glenwood Springs and Garfield County make the Post Independent’s work possible. Your financial contribution supports our efforts to deliver quality, locally relevant journalism.\nNow more than ever, your support is critical to help us keep our community informed about the evolving coronavirus pandemic and the impact it is having locally. Every contribution, however large or small, will make a difference.\nEach donation will be used exclusively for the development and creation of increased news coverage.', 'By Jerd Smith\nIn 1973, Colorado broke new legal ground by establishing water rights solely for the protection of streams, fish and wildlife. Prior to that, water could be diverted only for things like farming, manufacturing and residential water use.\nWhen the state moved to establish these environmental water rights, it was one of the first states in the American West to do so.\nThis year it will dramatically expand that ground-breaking effort as three new laws, passed in 2020, take effect. One involves the use of temporary water loans, a second adds protection for ranchers who divert water for cattle in stream segments where special environmental flows have been designated, removing an important obstacle to establishing new environmental flows, and a third creates a new tool for environmental flows once only available to cities and farmers.\nZane Kessler, director of public affairs for the Glenwood Springs-based Colorado River Water Conservation District, said the changes represent an important evolution in protecting environmental flows while balancing the needs of Colorado’s ranchers and cities with those of the environment.\n“Good policy helps us evolve to meet changing needs and priorities over time,” Kessler said.\nHow the new laws work\nThe expanded temporary loan program authorizes emergency loans and allows loans of water for five years in three separate 10-year periods. Previously those same loans could be used only for three years in a single 10-year period.\nThis provides relief for several regions, including the Yampa River Basin, where an instream flow loan had been used to its fullest extent under the old law, even though drought has continued to harm the Yampa River. The new longer-running loan program will provide critical flows to the river.\nThe stock water law, though it doesn’t directly add water to streams, writes specific rancher protections into law, paving the way for more stream segments to be considered for the program.\nAnd the third law, which advocates believe may have the most significant impact of the three, allows something known as an augmentation plan to incorporate environmental flows to help protect streams.\nAdvocates, such as the Colorado Water Trust, a nonprofit that spearheaded the new approach, say the tools can be used as templates across other river basins, where older water rights are already spoken for.\n“In the long run, this could be more impactful,” said Kate Ryan, an attorney for the Colorado Water Trust.\nAcross Colorado nearly 40,000 miles of streams flow year-round and, as a result, have the potential to receive protection under the state’s Instream Flow Program. To date, the state has been able to establish environmental flows on nearly one-quarter of these, according to the Colorado Water Conservation Board, which manages the program. The CWCB is the only entity legally allowed to hold these environmental water rights in Colorado.\nWho gets to choose\nAnyone can go to the CWCB and ask that it protect a certain stream segment, but whether it’s a member of the public, the U.S. Forest Service, or The Nature Conservancy, the entity must be able to show that there is enough water in the stream to support a new water right. They must also show that, by decreeing an instream flow on that segment, the stream’s existing conditions will be preserved or, where possible, improved.\nTo accomplish this, extensive engineering and measurements must be conducted. Once an instream flow case has been researched and documented, the state must go to a special water court to have the right legally established. The court must also hear any challenges that other water rights holders on the stream segment may raise if they fear their own water rights could be harmed. The process often takes several years to complete.\nLinda Bassi oversees the Instream Flow Program for the CWCB.\n“It’s difficult because there are a lot of competing interests for water,” Bassi said. “On some streams, if the state wants to obtain a water right to protect flows there are a lot of other entities with water rights that may feel threatened. Or there are other entities that might have plans to develop a water right on that same segment who are made uneasy by the fact that we are coming in to establish one [an instream flow water right].”\nIn Colorado, water rights follow what’s known as the Prior Appropriation Doctrine, or “first in time, first in right.”\nThat means that a water right claimed in, say, 1894 will get its water before one claimed in 1905 during periods of drought, when there isn’t enough water for everyone who has a right to water in a given stream.\nA late start\nBecause the state environmental program was established 100 years after water users had claimed much of the water in the states’ rivers, the water rights the state has managed to claim are very young, or junior to other more senior rights. That means that in drought years, when they are needed the most, these rights frequently go unfulfilled.\nAs a result, the state has changed its laws to allow older, senior water rights to be loaned or donated to the state. When it has enough money, the state can actually purchase older water rights that are more likely to receive water during dry years.\nWhen proponents of the 2020 expansion went to lawmakers in 2019 to seek support for the new laws, they faced significant opposition from agricultural interests and cities. It took months of negotiations to craft the bills that finally won near unanimous bipartisan support at the Colorado State Capitol in 2020.\nGetting to “yes”\nThe Colorado River District represents 15 Western Slope counties, many of which are heavily dependent on ranching. Historically any efforts to add new water rights for protecting streams have been viewed with deep skepticism.\nThis time was no different, Kessler said, but rural lawmakers were able to add enough protections into the new laws that the district’s board ultimately came out in support of the expansions.\nOne important measure gives the state engineer, Colorado’s top water regulator, the authority to oversee ranchers’ rights to their so-called stock water.\n“During the winter months, ranchers with an irrigation water right [tied to] the summer season will often pull small amounts of water from the stream to keep their animals alive,” Kessler said. “With that [protection] in hand, we became a lot more malleable about how we approached the Instream Flow Program.”\nA third part of the expansion, allowing the use of augmentation plans to restore environmental flows, could be among the most important part of the expansion effort, according to Ryan.\nFarmers and cities have long used augmentation plans to repay the river when they divert out of turn. Now under the new law, this same tool can be used to help streams.\nOn the Front Range, for instance, the first environmental augmentation plan is getting ready to launch, with the cities of Fort Collins, Thornton and Greeley offering up water they own and already store under an existing augmentation plan. These “seed” flows will be added above various stretches on the Poudre River that dry up every year. As the new water flows downstream, it will restore habitat for fish and wildlife, and eventually travel down to a segment of the river that these cities are presently legally required to restore.\nAnd though most environmental water deals require individual trips to water court, an expensive, time-consuming process, the new law allows existing augmentation plans to be used, which means proper quantities, times of diversion, and water right dates are already in place.\n“There are those who believe that prior appropriation as it is practiced in Colorado is too rigid,” said Sean Chambers, Greeley’s water resources manager. “But I think this is an example of how we can use existing statues, tools and programs to meet the needs of municipalities, irrigators, agricultural interests, and the ecological and recreational needs of the river. And it’s a template that can be used in other [river] basins.”\nHow many more miles of streams could still be protected under the Instream Flow Program isn’t clear, according to Bassi, because the state’s priorities and its ability to buy water rights change.\nBut every year there are victories.\nFor decades, fish experts believed that a certain line of endangered cutthroat trout known as the San Juan lineage cutthroat had been extinct. But then they discovered them in a remote part of the San Juan River Basin and, last year, the CWCB was able to establish an instream flow on a critical stream segment there, helping ensure the endangered fish will survive.\n“Priorities change, whether it’s [water for] a gold medal fishery, which helps the recreation industry, or to protect a declining species. We don’t have a set quota. We’re just trying to help these organizations achieve their goals through our program,” Bassi said.\nJerd Smith is editor of Fresh Water News. She can be reached at 720-398-6474, via email at firstname.lastname@example.org or @jerd_smith.\nFresh Water News is an independent, nonpartisan news initiative of Water Education Colorado. WEco is funded by multiple donors. Our editorial policy and donor list can be viewed at wateredco.org\nThe Water Desk’s mission is to increase the volume, depth and power of journalism connected to Western water issues. We’re an initiative of the Center for Environmental Journalism at the University of Colorado Boulder. The Water Desk launched in April 2019 with support from the Walton Family Foundation. We maintain a strict editorial firewall between our funders and our journalism.']	['<urn:uuid:7f2eac4d-fdd4-491d-b269-e05431f54ecd>', '<urn:uuid:303c6359-1170-4603-a28f-8f04c1d81ca0>']	factoid	with-premise	short-search-query	similar-to-document	three-doc	novice	2025-05-12T23:56:45.148498	6	48	4053
92	bone formation in medical implants how it happens naturally and what safety checks needed	Bone formation in medical implants occurs naturally through a process where capillaries invade the implant area and osteoblasts form new bone in direct contact with materials like hydroxyapatite, particularly within concavities of the implant. As for safety, medical device manufacturers must evaluate biocompatibility through multiple tests including cytotoxicity, sensitization, and implantation tests, while also considering the duration of contact (limited, prolonged, or permanent) and conducting risk assessments based on ISO standards.	"['such as ""Introduction"", ""Conclusion""..etc\nFig. 1 Tissue induction and morphogenesis by bone morphogenetic/osteogenic proteins (BMPs/OPs). (A) Islands of chondrogenesis with vascular invasion and osteoblastic differentiation and matrix synthesis as a recapitulation of embryonic development, 8 days after heterotopic implantation in a Long-Evans rat of 2.5µg of recombinant hOP-1 in conjunction with 25 mg of bovine insoluble collagenous bone matrix as carrier (original magnification x45). (B) Bone induction by naturally-derived BMPs/OPs purified from baboon bone matrix and implanted orthotopically in a calvarial defect of an adult baboon Papio ursinus: 30 days after implantation of 280µg of baboon osteogenic fractions after gel filtration chromatography there is induction of large osteoid seams in orange-red surfacing newly developed mineralized bone matrix in blue (undecalcified section, original magnification x25). (C) Low-power view of a corticalized ossicle induced after the implantation of 125µg of recombinant hTGF-β in the rectus abdominis muscle of an adult primate Papio ursinus showing vigorous osteogenesis with osteoid synthesis 30 days after heterotopic implantation (undecalcified section, original magnification x4.5).\nFig. 2 Morphology of calvarial regeneration by recombinant hTGF-β2 in conjunction with collagenous matrix as carrier. Low-power photomicrographs of calvarial defects treated by 100µg hTGF-β2 delivered by insoluble collagenous bone matrix and harvested on day 30 (A) and 90 (B) after implantation in non-healing calvarial defects of the primate Papio ursinus. Minimal bone formation at the edges of the defect on day 30 (A) and osteogenesis albeit limited is found in a specimen harvested 90 days after implantation with bone formation only pericranially. Note the trabeculae of newly formed bone facing scattered remnants of collagenous matrix particles, embedded in a loose but highly vascular connective tissue matrix (undecalcified sections, original magnification x3).\nFig. 3 Northern analyses of type IV collagen and Smad6 (A) and OP-1, BMP-3, TGF-β1 and type II and IV collagens mRNA expression (B) in tissues generated by rhTGF-β alone (A) and in ossicles generated by doses of porcine platelet-derived TGF-β1 alone and in combination with 25ìg hOP-1 implanted heterotopically with insoluble collagenous bone matrix as carrier in the rectus abdominis muscle of adult primates Papio ursinus and harvested on day 30. Minimal mRNA expression of Smad6 in ossicles generated by rhTGF-β when implanted heterotopically (A). (B) Upon implantation of 5 µg doses of recombinant hTGF-β1 there is expression of osteogenic markers of the TGF-β superfamily, namely OP-1 and BMP-3 gene products. Note the two to three fold increase of expression of collagen type IV mRNA, a marker of angiogenesis, in ossicles generated by TGF-β1 alone and in synergistic binary application with hOP-1 (B).\nFig. 4 Effect of the geometry of the substratum of biomimetic matrices on tissue morphogenesis and bone induction on day 30. (A) Capillary sprouting, invasion and elongation of the capillaries within a concavity of a biomimetic matrix of highly crystalline hidroxyapatite implanted heterotopically in the rectus abdominis muscle of Papio ursinus and harvested 30 days after implantation. Top right note the newly formed bone in direct contact with the hydroxyapatite substratum (decalcified section, original magnification x45). (B) Spontaneous initiation of bone formation within a concavity of the biomimetic matrix without the addition of exogenously applied BMPs/OPs. The newly formed bone in light blue in direct contact with the hydroxyapatite substratum is surfaced by contiguous osteoblasts (decalcified section, original magnification x60). (C) Detail of another specimen showing the spontaneous initiation of bone formation in direct contact to the crystalline hydroxyapatite together with capillary invasion within the fibrovascular tissue invading the concavity (decalcified section, original magnification x60).\nFig. 5 Tissue morphogenesis in concavities of the substratum 90 days after heterotopic implantation in the rectus abdominis muscle of the primate Papio ursinus. Low power view of a histological section of a monolithic disc of highly crystalline hydroxyapatite: bone has formed only within the concavities prepared on both planar outer surfaces (decalcified section, original magnification x12).\nSource: J. Cell. Mol. Med. Vol 8, No 2, 2004 pp. 169-180\nEnter the code exactly as it appears. All letters are case insensitive, there is no zero.', 'How To Meet Biocompatibility Needs Of Polymeric Medical Components\nBy Dr Vinny Sastri\nThis article was originally published in Medical Plastics Data Service, Sep—Oct, 2016.\nMedical device manufacturers need to ensure that their products are safe and effective. Safety considerations should include usability, energy, operation, informational, and chemical and biological hazards. Biological hazards can be extensive and complex. When materials come in contact with human skin or tissue, their biocompatibility should be evaluated. The importance of patient safety with respect to biocompatibility continues to be an important area that regulatory bodies continue to focus on.\nThe international standard ISO 10993-1Biological evaluation of medical devices — Part 1: Evaluation and testing within a risk management process, updated in 2009, added the risk management process based on ISO 14971 in the selection and evaluation of biocompatible materials. In 2016, the United States FDA published its final guidance titled Use of International Standard ISO 10993-1, Biological evaluation of medical devices — Part 1: Evaluation and testing within a risk management process. This guidance document covers the use of the standard including specific requirements that the agency expects in selection, testing, evaluation and documentation. In June 2016, the European Parliament and the Council of the European Union published its draft proposal on its new Medical Device Regulation. Section 7 of Annex 1 details the requirements for a medical device and material chemical, physical and biological properties.\nIn September 2016, the Center for Devices and Radiological Health (CDRH) in the USA published the CDRH Regulatory Science Priorities (FY2017). One of the top 10 priorities for 2017 is to “Modernize biocompatibility and biological risk evaluation of device materials”. The report states that “it is critical to perform biocompatibility evaluation to assess the risk of adverse events” “to determine the safety profile of implantable or patientcontacting medical devices” The report emphasizes that “less burdensome approaches that are more patient-centric and predictive of realworld device performance are needed to modernize and transform biocompatibility evaluation of medical devices and their materials.”\nThe medical device manufacturer is ultimately responsible for the safety and effectiveness of the final device. The device, its components and raw materials that come into contact with human tissue must all be evaluated for biocompatibility. As a result, suppliers of parts, components and resin that are used to build the device should also do their part in ensuring that the products or processing conditions do not adversely affect the biocompatibility of those products. Figure 1 illustrates the raw material to finished device value chain with respect to plastic materials and components. There may be instances where the resin manufacturer directly supplies the raw material to the medical device manufacturer who does their own processing and converting.\nThe steps involved the selection of materials and their evaluation and testing is as follows:\n1. Risk Assessment\nThe intended use and application of the final device is first identified. The initial design concepts can be used to conduct an initial risk assessment of the device design, the material and component characteristics, the manufacturing processes including sterilization, the clinical use of the device, and the nature and duration of contact with human tissue.\nThe nature of contact falls into three categories per the standard.\n- Surface contacting devices — Those devices contacting skin, mucosal membranes or breached and compromised surfaces (broken skin)\n- External contacting devices — Those devices that contact blood paths indirectly, tissue/bone/dentin and circulating devices\n- Implantable devices — Those devices that come into long term contact with tissue and bone, and blood\nThe durations of contact are:\n- Limited exposure — Contact up to 24 hours\n- Prolonged exposure — Contact between 24 hours and < 29 days\n- Permanent contact — Contact > 30 days\nThis information should be used to identify potential risks with respect to biocompatibility and the types of biocompatibility tests that need to be conducted. The standard and the guidance document allow for the use of historical data and information to make informed decisions before committing to extensive biocompatibility testing.\n2. Identification of Potential Risks and Exposure Assessment\nThe physical and chemical characteristic of the materials under evaluation should be listed. Before conducting any biocompatibility tests the potential risks can be evaluated using methods like literature and historical data.Sources of information on potential biocompatibility risks can include previous experience with the same material(s) that have been used in the same or similar devices in the same anatomical location. In addition post market data for similar devices and applications can also provide a rich source of data as an initial risk assessment for biocompatibility.\n3. Material selection\nWhen selecting materials to be used in a specific device design, manufacture and use, consideration should be given to the fitness for the device’s intended use with respect to chemical, toxicological, physical, electrical, morphological and mechanical properties. With respect to the biological evaluation of the device, the following should be considered:\ni. The properties of the base resin\nThe choice of the base resin can be constrained by the application and process needs of the device. For example, hydrolytically unstable resins cannot be used in implants. Highly porous materials may not be suitable under ethylene oxide sterilization because unremoved residuals from ethylene oxide could impact patient safety. Thermally unstable grades cannot be used in applications where high temperature autoclave sterilization is required. In addition to physical and mechanical instability, degradation products could affect the material’s biocompatibility.\nii. The material formulation\nAdditives, catalysts, colorants, fillers, nanoparticles, plasticizers and other materials either alone or by interactions with each other can significantly affect biocompatibility. If each individual component of the formulation is claimed to be biocompatible, it does not automatically mean that the complete, formulated material is biocompatible. Compounders should evaluate the breadth of additives and a range of levels in their formulations to gain maximum flexibility of biocompatible materials in their portfolio.\niii. Manufacturing Processes — Degradation and Residues\nExcessive heat and shear during the manufacturing of plastic parts can change the levels of extractables and leachables in the final part and thus significantly affect biocompatibility. Joining and cleaning of parts and residues from materials used in facilitating production (e.g. mold release) can also change a product’s biological properties. Processors should define the process ranges that will not affect biocompatibility.\niv. Master Files\nIn the case where formulations are proprietary, Device Master Files (MAF) of the product can be used. Material suppliers can submit a Device Master File that is privy only to the FDA for review and evaluation of final device submissions. Device Master Files typically contain the name of the product, its formulation (ingredients and levels), manufacturing conditions, sterilization compatibility, physical and mechanical properties, known impurities and chemical characterization. Included are also biocompatibility screening studies.\n4. Biological Evaluation\nIn order to reduce unnecessary testing, including animal testing, manufacturers should first consider all available relevant information from literature and test data. For example, in some circumstances, a chemical analysis can demonstrate that the extractables and leachables using a specific solvent have not changed compared to a baseline material, eliminating the need for additional biocompatibility testing using that type of solvent. In addition, chemical analyses can be used to assess the toxicological risk of the chemicals that elute from devices. For example, chemical analysis using exhaustive extraction techniques can also be helpful to evaluate long-term toxicity endpoints such as potential carcinogens.\nIt is critical that test articles are prepared using the proper methods and solvents and also using representative configurations of the end product. Both polar and non-polar solvents should be used. Extraction conditions based on the device application and use should also be employed. Justification of the selected extraction conditions should be provided.\nDeveloping “finger prints” of the extractables and leachables can help in decisions for additional biocompatibility testing if there are changes to materials and manufacturing conditions. If the “finger prints” match the rationale not to conduct additional biological tests can be made.\nWhen biocompatibility tests are required, the decision on the applicable tests can be identified using the Table A.1 in Annex A of the standard. The evaluation tests described should be considered and carried out where necessary tocomplete the data sets needed for the biological evaluation of the particular medical device or its materials and components.\nConsiderations should be made for testing like cytotoxicity, sensitization, hemocompatibility, pyrogenicity, implantation, genotoxicity, carcinogenicity, reproductive and developmental toxicity and degradationassessments.\n5. Biocompatibility Documentation\nDue to the diversity of medical devices, not all biocompatibility tests identified in a category will be necessary or practical. Documentation of biocompatibility evaluation and testing should include:\n- The strategy, plan and content for the biological evaluation of the medical device, part or material\n- The criteria for determining the acceptability of the material for the intended purpose using risk-based methodology\n- The adequacy of the material characterization\n- The rationale for selection of methods used\n- The interpretation of existing data and results of testing\n- The need for any additional data to complete the biological evaluation\n- The overall biological safety conclusions for the material component and the medical device\n6. Changes to Product or Process\nWhen there are changes to an existing, approved and tested material, component or device, biocompatibility should be reevaluated if there is:\n- Any change in the source or in the specification of the materials used in the manufacture of the product\n- Any change in the formulation, processing, primary packaging or sterilization of the material or product\n- Any change in the manufacturer’s instructions or expectations concerning storage, e.g. changes in shelf life and/or transport\n- Any change in the intended use of the product\n- Any evidence that the material or product may produce adverse effects when used in humans\nIn order for plastics processors and resin manufacturers to understand the critical characteristics and application of the final device their products go into, the lines of communication between medical device manufacturer and their suppliers should be seamless and effective. Processors of the components and parts should control their production processes so as not to affect or change the biocompatibility of the material provided by the resin supplier. Resin suppliers (virgin or compounded) should provide the basic biocompatibility characteristic to both the processor and the finished medical device manufacturer. Any changes to material or process should be communicated to the medical device manufacturer, as the medical device manufacturer is ultimately responsible to ensure safety, effectiveness and biocompatibility of their finished device.']"	['<urn:uuid:abb7759f-f779-48a5-b373-913c1f4f4407>', '<urn:uuid:768c9c7d-51ff-4196-aba6-5687877217b0>']	factoid	with-premise	long-search-query	similar-to-document	multi-aspect	novice	2025-05-12T23:56:45.148498	14	71	2398
93	mediation process main purpose when parties still stable relationship	Mediation's primary purpose is to further enlighten each party of perceived injustices, allow a third party (the mediator) to give their opinion, help find common ground between both parties, and attempt to broker a deal that can be willingly carried out. It is typically performed between parties that are still on stable terms with one another.	"[""Arbitration vs. Mediation -- What's the Difference?\nThe legal definition of mediation does not differ far from the common colloquial understanding of the term.\nMediation, in many cases, is performed between two parties that are still on stable terms with one another. Mediation's primary purpose is to further enlighten each party of perceived injustices, and also allow a third party (the mediator) to gives it opinion on those injustices. The mediator then helps find common ground between both parties, and attempts to broker a deal between both parties that can then be willingly, and hopefully amicably, carried out. After mediation, both parties must agree to the results of the mediation and can only willingly fulfill the terms of the mediated agreement.\nArbitration is a process of conflict dispute that focuses again around a neutral third party, this time known as an arbitrator. Arbitration looks not to find a comfortable middle ground between the conflicted parties, but instead looks to lay find its own decision - known as a judgement - that will end the dispute between both parties. Arbitrators are often used in situations where the relationship between both parties is tenuous, and an amicable agreement seems out of reach.\nThey key portion of arbitration is that the arbitrator, the neutral third party that will make the judgement in a dispute, will give a decision that is considered legally binding. The arbitrator is more of a judge than a facilitator, utilizing their knowledge and position to effectively act as a judge. The major difference between court and arbitration is that the arbitrator is agreed upon by both parties, and in most cases, the process of arbitration is significantly less costly and time consuming than a court process.\nWhich to use?\nBoth systems of resolution have their merits, but are better suited to separate situations. Mediators are often called upon to find mutually beneficial and agreeable results, ending with a favorable decision for both parties that can preserve or even strengthen the relationship between the two parties being mediated. A business and a client who are having a disagreement, but would like to continue to work in the future, can utilize a mediator to try to find an acceptable solution - a solution that they can then reject if they find unfair.\nArbitration, on the other hand, has the same finality of court proceedings and can render decisions that feature the same animosity and disdain as losing a court case. The arbitrator lays down a decision that they think is fair, not that is necessarily mutually beneficial or believed fair by either party. If a business does not mind burning a bridge, has a strong case, and does not care about the negative effects of being known for ‘beating' clients, arbitration may be a viable option. However, businesses that are looking not just for future relationships with a disputed party but also for being known for reaching magnanimous and acceptable agreements with their clients - mediation may be the high road that ends with satisfaction (and future business) for all parties involved.\nBy Travis Lindsay""]"	['<urn:uuid:59aaea00-aebe-4ceb-9efc-e51957a550f9>']	factoid	with-premise	long-search-query	similar-to-document	single-doc	expert	2025-05-12T23:56:45.148498	9	56	514
94	What are the main types of aircraft fuel and their climate impact?	The main types of aircraft fuel are kerosene-based fuels (Jet A, Jet A1, and Jet B), various military fuels (JP series), and AvGas for small piston-powered aircraft. Regarding climate impact, aviation contributed 4.9% to global warming in 2005 despite being only 2.2% of CO2 emissions, and by 2018, aviation caused approximately 2.6% of manmade CO2 emissions.	['Of all the questions asked by airplane enthusiasts, one of the most basic and most interesting questions is, what type of fuel does an airplane use? After all, it can’t run on regular gasoline like cars do – or can it? If you’ve ever been curious about the type of fuel that is needed to operate an airplane, wonder no more, because following is a description of all of these types to answer this question.\nTable of Contents\nWhat Affects the Type of Fuel Used in an Airplane?\nIf you’re curious about what determines the type of fuel used by an airplane, the answer is simple: the fuel type is a direct result of the type of engine used in that plane. Simply put, commercial and fighter planes tend to use kerosene-based fuel, but certain products are usually added to the fuel. This includes antifreeze, hydrocarbons, metal deactivators, and antioxidants, all of which prevent corrosion and freezing at higher altitudes, to name a few.\nAlthough there are blends and mixtures of airplane fuel, it all begins with three basic types, and they are described below.\nKerosene-Based Aircraft Fuels\nKerosene-based fuel for airplanes is usually broken down into various types, according to physical qualities and certain specifications. These types include:\n- Jet A:\nOnly available in the United States, Jet A fuel was developed to be heavy, with a higher flash point and higher freezing point than standard kerosene. This fuel has low vapor pressure and a flash point that is roughly 110ᵒ Fahrenheit.\n- Jet A1:\nMost turbine-engine aircraft use this type of fuel. It has a flash point of 100ᵒ Fahrenheit and a maximum freeze point of -52ᵒ Fahrenheit. It is an easy fuel to find if you’re located outside of the United States.\n- Jet B:\nAlso called wide-cut fuel because it is a combination of kerosene and gasoline, it is used mostly in areas that experience very cold weather, in part because its freezing point is around -76ᵒ Fahrenheit. Its vapor pressure is somewhere between that of gasoline and kerosene.\nThere are eight different types of military-based airplane fuel, as described below.\nThis fuel is pure kerosene and has a freezing point of -76ᵒ Fahrenheit. Even though it was efficient fuel, it was soon replaced by other types of wide-cut jet fuel, including fuels made from kerosene-naphtha and a kerosene-gasoline mixture.\n- JP-2 and JP-3:\nJP-2 was originally developed to replace JP-1 fuel and was rarely used. JP-2 fuel had a high freezing point, but was eventually replaced by JP-3, which was more volatile and was supposed to improve the former. However, because both of these fuels had high vapor loss and were unstable, neither are being used today.\nThis type of fuel is flammable and transparent, with a clear or straw color and a smell similar to kerosene. In addition, the JP-4 fuel floated on water and easily evaporated. It had such a low flash point (0ᵒ Fahrenheit) that a match dropped in it would not ignite, and its maximum water temperature was 6,670ᵒ Fahrenheit.\nThe JP-5 fuel is yellow in color and contains ingredients such as hydrocarbons, naphthenes, alkenes, and aromatic hydrocarbons. It has a high flash point of 140ᵒ Fahrenheit and a freeze point of -51ᵒ Fahrenheit, and it contains no antistatic agents.\nThis fuel was developed specifically for the General Electric YJ 93 Jet Engine associated with the XB-70 Valkyrie Supersonic Aircraft, a high-altitude bomber plane. It was similar to the JP-5 fuel except its freeze point was -65ᵒ Fahrenheit. It also had better thermal oxidative stability than the JP-5.\nThis fuel copes well with the heat and stress associated with high-speed supersonic flights, in part because of its high flash point. It was specifically developed for the twin Pratt & Whitney J58 Turbojet/Ramjet engines of the SR-71 Blackbird.\nThe JP-8 fuel is similar to the A1 fuel utilized by many commercial airlines, and it has been widely used by the U.S. military. Ingredients were added to it for corrosion barrier and anti-icing purposes, and it has a freezing point of -52ᵒ Fahrenheit, as well as a flash point of 100ᵒ Fahrenheit.\nThis is a very popular type of airplane fuel that is often used by small piston-powered aircraft. It is specifically used for tasks such as crop-dusting and for private flying, flying clubs, and even flight training.\nAvGas fuel works on these planes because their pistons work much like those in car engines, and the fuel itself works much like gasoline does on these systems, although the two fuels themselves are different.\nAvGas fuel is a safe, stable, and predictable fuel that promises great performance regardless of the conditions, and its formulation is a bit different than the regular gasoline that is used in most cars.\nIt comes in many different grades and normally has octane ratings that are much higher than those of regular gasoline.\nWhen Producing Aviation Fuel\nWhen aviation fuel is developed, it normally falls into one of two categories – fuel suitable for turbine engines and fuel suitable for internal combustion engines. For each of these types, there are international specifications required.\nFor instance, in both turboprop and jet aircraft, jet fuel is used because it has low viscosity at low temperatures and burns clean, is limited in density and calorific value, and remains stable even when heated to high temperatures.\nAll of these characteristics are crucial when it comes to the right aviation fuel.\nAvGas, which stands for aviation gasoline, is made from a very refined type of regular gasoline. It is pure, has anti-knock properties, and minimizes fouling of the spark plugs.\nIn addition, this type of gas has both the right mixture condition for takeoff power settings and the leaner mixture condition needed for the cruise phase when reduced fuel consumption is important.\nAs a general rule, much less AvGas is sold than jet fuel, although a lot of independent aircraft carriers use it.\nConversely, large aircraft companies, including commercial airlines and the military, tend to use jet fuel instead of AvGas.\nThe Wave of the Future\nIn addition to these types of airplane fuel, research is promising to produce newer and even better types of fuel in the future. This is partly because most fuels are fossil-based and, therefore, not sustainable or clean.\nIn fact, a more sustainable type of fuel for both airplanes and vehicles is the goal of many of these research companies, and below are a few of the more promising developments.\nThese include fuels made from the biomass-to-liquid method and encompass certain sustainable aviation fuel (SAF) and even vegetable oil.\nSome advantages associated with SAF include the fact that when used, there is little to no changes required to the aircraft itself.\nSome SAFs include small amounts of fossil fuels mixed into them, and they offer lower GHG and particle emission levels.\nHowever, most biofuels are higher in price than other types of aviation fuel, and they face enormous economic and political complications that hinder their use.\n- Compressed Natural Gas/Liquefied Natural Gas:\nBoth compressed natural gas (CNG) and liquefied natural gas (LNG) have low specific energy, making them a disadvantage for flight applications.\nStill, some aircraft – including one used by NASA’s N+4 Advanced Concept Development Program – were made specifically to use one or more of these types of natural gas.', 'Project Drawdown defines the efficient aviation solution as the increased use of technologies to reduce aircraft fuel burn. This solution replaces conventional aircraft with existing global fleet-wide fuel efficiency.\nIn 2005, all of aviation’s share of global warming was 4.9 percent despite being only 2.2 percent of carbon dioxide emissions in that year. This is due to aviation’s generation of other climate pollutants besides carbon dioxide that also cause warming. Considering aviation fuel consumed in 2016, and all global carbon dioxide emissions in 2016, all aviation is estimated to have caused approximately 2.6 percent of manmade carbon dioxide emissions in 2018. Growth in aviation’s share is causing increasing alarm. Airplane fuel efficiency efforts aim to reduce fuel use per passenger-kilometer of air travel. Though freight-only aircraft fuel efficiency is not analyzed here, part of the impact on air freight fuel use is accounted for in the large fraction of total air freight that is carried in the belly of passenger aircraft.\nThere are numerous technologies and operational approaches for reducing airplane fuel use; only the most impactful technologies in use today to improve fuel efficiency were included in this study. Therefore, well-publicized but noncommercial technologies such as aviation biofuels were excluded.\nThis analysis includes the newest, most fuel-efficient aircraft (called “intermediate generation”), as well as the use of fuel efficiency retrofits to existing aircraft. Intermediate generation aircraft are expected to be 15–20 percent more fuel-efficient than earlier models, in part as a result of more fuel-efficient engines, new wingtip devices, and light weighting approaches. Research suggests that the combination of these three technologies in a retrofit would amount to efficiency improvements comparable with a newer aircraft model. In this study, new and retrofitted aircraft are compared to conventional aircraft with the existing global fleetwide fuel efficiency.\nTotal Addressable Market\nThe total addressable market for efficient aviation is measured in terms of total interurban passenger travel by air, projected for every year of analysis (2020–2050), in billion passenger-kilometers. Current adoption was taken as the total passenger-kilometers provided by existing intermediate generation aircraft, in the single-aisle and twin-aisle categories.\nProjected adoption of fuel-efficient aircraft was based on the expected production of intermediate generation aircraft, according to published delivery rates of major suppliers. Delivery rates were assumed fixed for each aircraft type.\nImpacts of increased adoption of efficient aviation from 2020 to 2050 were generated based on two growth scenarios, which were assessed in comparison to a Reference Scenario where the existing fraction of higher-efficiency aircraft remains constant.\n- Scenario 1: Fuel burn is improved by 13 percent, Boeing and Airbus supply aircraft at their published rates, and an additional supplier starts adding comparably efficient aircraft to market. One hundred aircraft are retrofitted annually.\n- Scenario 2: Fuel burn is improved by 18 percent. Aircraft delivery rates, retrofitting, and retirement are similar to the Scenario 1. Global load factors increase to 83 percent (U.S. average).\nEmissions for each scenario were estimated using the fuel emissions factor taken from the Intergovernmental Panel on Climate Change (IPCC) guidelines, and applied to fuel consumption data from the International Council on Clean Transport (ICCT).\nCosts of adopting the intermediate generation aircraft are reported as the additional cost compared to adopting aircraft with average fleet efficiency. For each intermediate generation aircraft, an equivalent conventional aircraft was priced and the price difference was derived. The average difference for single-aisle aircraft was around US$11 million, and that of twin-aisle was US$40 million. Operating costs, which included fuel costs, were derived using historical data from the International Energy Agency (IEA). The solution’s operating costs were reduced by the efficiency improvements noted above.\nTo prevent double-counting, steps were taken to ensure that the total travel demand of all non-urban passenger Transport Sector solutions remained below the projected total non-urban travel demand.\nIn Scenario 1, a potential reduction of 6.3 gigatons of carbon dioxide-equivalent greenhouse gas was found from 2020 to 2050, which corresponds to an 80 percent adoption rate by 2050. Net costs over that time would be US$863 billion above the conventional approach. Efficiency improvements are estimated to bring lifetime operating savings of US$2.5 trillion, however. For the Scenario 2, the emissions avoided amounted to 9.2 gigatons with 85 percent adoption.\nThe use of more efficient aircraft is desirable for airlines in times of higher fuel prices. It would have direct bottom-line impacts, as fuel often represents a third of operating costs. Since 2015, however, fuel prices have been relatively low, and there is no assurance that prices will return to their previous levels of almost three times higher. At these lower fuel prices, the financial attractiveness of these aircraft efficiency improvements is not great, and in some cases result in negative net present values for airlines according to our calculations. However some of this may change with the coming implementation of the Carbon Offsetting and Reduction Scheme for International Aviation (CORSIA) program. To some extent, inclusion of fuel switching approaches such as aviation biofuels can help reduce the need for aircraft technology improvements.\nThere are limitations to this approach. For example, the potential of other technologies being implemented was excluded in this study. Also, the Reference Scenario conservatively assumes fixed fleet efficiency. These limiting assumptions were made to show the impact of existing technologies on the airline industry. The results indicate that airlines have a role to play in the planet reaching the point of drawdown.\n Lee, D. S., Fahey, D. W., Forster, P. M., Newton, P. J., Wit, R. C., Lim, L. L., ... & Sausen, R. (2009). Aviation and global climate change in the 21st century. Atmospheric Environment, 43(22-23), 3520-3537.\n From OECD/IEA (2018) World Energy Balances 2016, OECD/IEA, Paris\n According to Airbus, belly freight is about 52 percent of all air freight.\n Including the 787, 777X, and 737MAX family of Boeing, and the A320neo family, A330neo family, and A350XWB of Airbus.\n Also called “winglets” or “sharklets”, these devices cannot be installed on all older aircraft due to lack of sufficient wing strength and other limitations.\n For more on the Total Addressable Market for the Transport Sector, click the Sector Summary: Transport link below.\n Current adoption is defined as the amount of functional demand supplied by the solution in 2018. This study uses 2014 as the base year due to the availability of global adoption data for all Project Drawdown solutions evaluated.\n Delivery of a single-aisle aircraft is assumed to provide 247 million passenger-kilometers, and a twin-aisle aircraft 840 million passenger-kilometers, of adoption.\n This additional manufacturer can represent any or all of numerous nascent options, such as COMAC of China or the UAC of Russia. It produces around 5 percent of all efficient aircraft annually.\n For instance, the Airbus A320neo was considered a more efficient replacement for the A320, and the Boeing 777X-9 was considered a replacement for the 777-300ER. These relationships were determined through web searches for each efficient model.\n All monetary values are presented in 2014 US$.\n It is assumed that this differential represents the retrofit costs for each aircraft type, and acknowledged that airlines often pay different prices than the list prices due to negotiations that occur with the manufacturers.\n The fuel prices (2007–2018) were averaged, and this fixed average was used for the future projections.\n The net operating savings for the full lifetime of all units installed during 2020–2050.\n The potential for open rotor engines could be large, but estimates seem to indicate availability in the 2030s onward.']	['<urn:uuid:4fbd1956-5127-4603-bc13-a38be06184f4>', '<urn:uuid:034d41d9-10c6-4686-b3da-477b79d07814>']	factoid	direct	concise-and-natural	distant-from-document	multi-aspect	expert	2025-05-12T23:56:45.148498	12	56	2456
95	How long does Tet last in Vietnam?	Lunar New Year (Tết) in Vietnam is a nine-day celebration, although not everyone celebrates for nine days, they will do it for at least three. It begins on the first day of the Lunisolar calendar, usually at the end of January or the start of February.	['Vietnam is steeped in spirituality, superstitions, and old-age traditions. Throughout Vietnam’s rich and long history, a fascinating cultural heritage has been passed down through generations. The Vietnamese take their traditions seriously, which has contributed to their strong national identity – a blend of traditional and contemporary values. They strongly value family, respect for the community, respect for their ancestors, working hard, and living in harmony with nature. If you’re interested in some of the most unique traditions in Vietnam, this is for you!\n7 of the Most Unique Traditions in Vietnam\n1. Ancestor worship\nIn almost every house in Vietnam, You’ll find a small altar dedicated to the ancestors. That’s because Vietnamese ancestors are highly revered and respected. They’re also believed to continue living in another realm and the living is to provide them with they what they need. Offerings consist of food, wine, votive paper, candles, burning incense, and of course, prayer. In return, the ancestors bring good fortune to their loved ones.\n2. God of Wealth\nThần Tài, or the God of Wealth, is believed to bring good fortune to businesses. You’ll see the God of Wealth in many shops, restaurants, hotels, and other commercial businesses. Vietnam also celebrates God of Wealth Day, which is the tenth day of the lunar year. Buying gold to celebrate this day is said to bring good fortune and financial success.\n3. Visiting pagodas\nMany Vietnamese families will flock to pagodas to pray during the first three days of Lunar New Year celebrations. It’s become a valued custom for Vietnamese people. They visit pagodas to pray for the health, fortune, and luck of themselves, family, and loved ones. And in Vietnamese culture, delivering offerings is a way to increase the chances of their wishes coming true. Typical offerings include flowers, incense, and fruit. Not only do they wish for a successful year ahead, but they also reflect upon the year behind them while enjoying the calm and serene setting.\n4. Lunar New Year\nLunar New Year, or Tết as it’s known in Vietnam, is a nine-day celebration. Although not everyone celebrates for nine days, they will do it for at least three. It begins on the first day of the Lunisolar calendar, usually at the end of January or the start of February. There are several ancient traditions within Tết itself. New Year’s Day is a big affair, and one of the most important is whoever walks through the door first on the day. The first person to enter the house sets the benchmark for the year to come. If someone with a negative character or an unlucky astrological sign walks through first, it sets a precedent of misfortune for the whole year.\n5. Celebrating a baby’s first month\nNgay Day Thang is the day for celebrating a baby’s one-month birthday. The purpose of the celebration is to prepare a feast for twelve ‘fairies’. And according to Vietnamese mythology and folk religion, these fairies teach the baby various skills. Also, during the first month, or even 100 days, the mother is expected to rest indoors. So, it’s also a day to celebrate the baby and the mother. At the Ngay Day Thang, family and friends eat together and offer the mother and the baby money to bring good luck.\n6. Cooking a whole boiled chicken\nLike many cultures, Vietnamese celebrations strongly revolve around food. Boiling is a whole chicken, including the head and feet, is just one of them. The Vietnamese consider this to be good fortune, especially on Tết. Many people place the boiled chicken at the altar of their ancestors to bring good luck, worship their ancestors, and have a propitious start to the new year.\n7. Lucky numbers\nThis one’s more of a contemporary superstition, but many people in Vietnam customise their phone numbers based on lucky numbers. It’s actually advertised in almost any SIM card shop. While in western culture the number seven is considered lucky, in Vietnam it’s a deeply unlucky number. Therefore, many people choose to remove or exclude the number seven from their phone number. Instead, they add lucky numbers like nines and consecutive eights.']	['<urn:uuid:a1c7b4ca-589a-4a3d-8687-2a231c837130>']	factoid	direct	concise-and-natural	distant-from-document	single-doc	novice	2025-05-12T23:56:45.148498	7	46	690
96	As an astronomy researcher studying impact events, I'm curious how the energy release from the 2008 Sudan asteroid compares to the 2013 Chelyabinsk meteor in terms of their atmospheric effects and detection capabilities?	The Chelyabinsk meteor had a much larger energy release, producing a 300 kiloton blast similar to a nuclear explosion that broke windows and collapsed walls. In contrast, the Sudan asteroid (2008 TC3) was smaller at 4 meters wide and mainly burned up in the atmosphere. The Chelyabinsk event was detected only after impact through videos and sensor arrays, while 2008 TC3 made history as the first asteroid detected in space before hitting Earth, spotted 21 hours before impact by the Catalina Sky Survey.	"['Forensic examination of asteroid crash scene\nPosted: October 05, 2009\nThe four metre-wide asteroid that blew up in the sky above Sudan on 7 October 2008 was a tumbling, irregularly shaped piece of shrapnel from a larger body that had been bombarded with impacts billions of years ago before being destroyed.Asteroid 2008TC3 burnt up over Sudan one year ago this week.\nAsteroid 2008 TC3 is a unique case – it was spotted approaching Earth 21 hours before impact by the Catalina Sky Survey operating out of the Mount Lemmon Observatory in Arizona, and this was the first time an asteroid had ever been detected in space before colliding with Earth. Against all odds, Dr Peter Jenniskens of the SETI Institute and Mauwia Shaddad of the University of Khartoum led an expedition into the Nubian Desert to find fragments of the asteroid. In all, they found 280 pieces totalling 222 kilograms. After months of analysis, results being presented at the meeting of the Division of Planetary Sciences of the American Astronomical Society in Puerto Rico are beginning to tell us about the origin of this space rock.\nAstronomer Peter Scheirich of the Ondrejov Observatory and Charles University in the Czech Republic has combined observations of the asteroid as it approached Earth to judge its shape and rotation based on how it was reflecting sunlight. Scheirich reports that 2008 TC3 was wildly tumbling, and irregularly shaped ‘like a loaf of walnut-raisin bread’.\n“We have a gigantic jigsaw puzzle on our hands, from which we try to create a picture of the asteroid and its origins,” says Peter Jenniskens. “Now, Scheirich and his colleagues have provided us with a ‘composite sketch’ of the culprit, cleverly using eye-witness accounts of astronomers that saw the asteroid sneak up on us.”Scientists have been kept busy analysing the chemical composition of the meteorite fragments spawned from the asteroid.\nMore intriguing is the asteroid’s composition. It’s tagged as a rare ureilite asteroid, but even among ureilites it is a little odd. Parts of the asteroid fragments show evidence of intense heating up to 1,300 degrees Celsius, before cooling at a rapid rate of tens of degrees per hour. The inference is that the asteroid was subject to some kind of sudden violence, and the rapid cooling turned olivine into a metallic iron. Looking deeper at the fragments via X-ray tomography, Jon Friedrich of Fordham University in New York and Mike Zolensky of NASA’s Johnson Space Center have found myriad tiny pores coated with olivine that are the outlines of coarse to fine grains that were welded together in the tremendous heat. Furthermore, the carbon present in the asteroid has been cooked to such a degree as to form graphite and even nanodiamonds. The growing picture is that 2008 TC3 was once part of a larger body that found itself peppered with impacts which eventually smashed the asteroid apart billion of years ago. Since then, 2008 TC3 had been floating through space on its wild tumble before its final demise in Earth’s atmosphere last year.\nDespite all this, and in a boon to scientists who argue that the vital building blocks of life on Earth came from space, researchers at Stanford University have discovered that some organic molecules still survived in the fragments of 2008 TC3. Furthermore, Michael Callahan of NASA’s Goddard Space Flight Center even reports about the detection of amino acids in the fragments. Peter Jenniskens and Mauwia Shaddad now plan to return to the Nubian Desert to hunt for more fragments.\nFor an in-depth interview with Jenniskens, go to www.astronomynow.com/PeterJenniskensInterview.html', 'Blast from Russian Meteor Similar to Nuclear Explosion\nThe atmospheric blast from the meteor that struck near the Russian city of Chelyabinsk this morning released 300 kilotons of energy, similar to a nuclear explosion according to a NASA expert. The resulting shock wave broke windows and collapsed walls, injuring more than 1,000 people.\nBill Cooke of NASA\'s Marshall Space Flight Center said in a media teleconference this afternoon that the force of the blast was determined by measurements from a global network of sensor arrays called Infrasound. The Infrasound system of 60 sensor arrays around the world was designed to detect nuclear explosions as part of monitoring compliance with the Comprehensive Nuclear Test Ban Treaty. He said NASA used data from four of the sensor stations to determine the amount of energy released by the blast. He expects other sensor arrays also picked it up, but did not know how many.\nVideos of the meteor taken by cell phone and dashboard cameras by many of those who witnessed the event are posted on the Internet and tell more of the meteor\'s story, according to Cooke and Paul Chodas of the Jet Propulsion Laboratory (JPL).\nAsteroids are rocks in space. Those that enter Earth\'s atmosphere are called meteors and if they reach the ground they are meteorites.\nThis meteor is estimated to have been 15 meters in diameter with a mass of 7,000 metric tons and travelling at 18 kilometers per second (40,000 miles per hour). It penetrated the atmosphere at an angle of 20 degrees and streaked through the sky for 30 seconds before breaking apart 20-25 kilometers (12-15 miles) above the surface of Earth.\nChodas said this was a ""tiny"" asteroid and could not have been detected in advance not only because of its size, but because it came from the daylight side of Earth. Using Earth-based telescopes, asteroids can only be detected against the black background of space -- at night. Asteroids the size of this one reach the surface about once every 100 years, he said. Cooke said the Earth actually intercepts 80 tons of meteoritic material every day, with ""millions of millimeter size meteors striking Earth per day."" Chodas added that meteors the size of basketballs hit Earth every day on average, while those the size of a car hit every month or two.\nThe fact that an asteroid hit Russia on the same day as asteroid 2012 DA14 made a close pass of Earth was a rare coincidence, Chodas said, but the two were not related to each other. Asteroid 2012 DA14 travels in an Earth-like orbit, while the asteroid that hit Russia came from the asteroid belt. The Russian meteor came from the opposite direction and its velocity was ""much, much greater"" than DA14, he stressed. No verified fragments from the meteor have been located so far, but Cooke expects that it was a common stony asteroid, not one made of iron.\nRep. Lamar Smith (R-TX), chairman of the House Science, Space and Technology Committee, issued a press release saying the two events today ""are a stark reminder of the need to invest in space science,"" and promised to hold a hearing on ways to ""better identify and address asteroids that pose a potential threat to Earth."" A date for the hearing was not announced, only that it will be ""in the coming weeks.""\nCorrection: An earlier version of this article incorrectly stated that the energy released was 300 megatons, rather than 300 kilotons, of energy.\nSpacePolicyOnline.com has the right (but not the obligation) to monitor the comments and to remove any materials it deems inappropriate. We do not post comments that include links to other websites since we have no control over that content nor can we verify the security of such links.']"	['<urn:uuid:1c90a1a4-d3df-440c-bbde-e2b57e882048>', '<urn:uuid:fb78710d-2828-488e-b97d-878c47a5b3db>']	open-ended	with-premise	verbose-and-natural	similar-to-document	comparison	expert	2025-05-12T23:56:45.148498	33	83	1224
97	I keep hearing about 'prose' in my English class but I'm confused - what exactly counts as prose in everyday life?	Prose includes everything that is not poetry. Every utterance or written word that is not in verse form is prose, including casual conversations, speeches, dictionary definitions, philosophical texts, journalism, short stories, novels, academic writing, and regular conversations. Prose comes from the Latin expression prosa oratio, meaning straightforward or direct speech.	['Definition of Prose\nProse is a communicative that sounds natural and uses grammatical structure. Prose is the opposite of , or poetry, which employs a rhythmic structure that does not mimic ordinary speech. There is, however, some poetry called “prose poetry” that uses elements of prose while adding in poetic techniques such as heightened emotional content, high frequency of metaphors, and of contrasting images. Most forms of writing and speaking are done in prose, including short stories and novels, journalism, academic writing, and regular conversations.\nThe word “prose” comes from the Latin expression prosa oratio, which means straightforward or direct speech. Due to the definition of prose referring to straightforward communication, “prosaic” has come to mean dull and commonplace . When used as a literary term, however, prose does not carry this .\nCommon Examples of Prose\nEverything that is not poetry is prose. Therefore, every utterance or written word that is not in the form of verse is an example of prose. Here are some different formats that prose comes in:\n- Casual : “Hi, how are you?” “I’m fine, how are you?” “Fine, thanks.”\n- Oration: I have a dream that my four little children will one day live in a nation where they will not be judged by the color of their skin but by the content of their character. –Martin Luther King, Jr.\n- Dictionary definition: Prose (n)—the ordinary form of spoken or written language, without metrical structure, as distinguished from poetry or verse.\n- Philosophical texts: Whoever fights monsters should see to it that in the process he does not become a monster. And if you gaze long enough into an abyss, the abyss will gaze back into you. –Friedrich Nietzsche\n- Journalism: State and local officials were heavily criticized for their response to the January 2014 storm that created a traffic nightmare and left some motorists stranded for 18 hours or more.\nSignificance of Prose in Literature\nMuch of the world’s literature is written in a prose style. However, this was not always the case. Ancient Greek dramas, religious texts, and old epic poetry were all usually written in verse. Verse is much more highly stylized than prose. In literature, prose became popular as a way to express more realistic dialogues and present narration in a more straightforward style. With very few exceptions, all novels and short stories are written in prose.\nExamples of Prose in Literature\nI shall never be fool enough to turn knight-errant. For I see quite well that it’s not the fashion now to do as they did in the olden days when they say those famous knights roamed the world.\n(Don Quixote by Miguel de Cervantes)\nDon Quixote is often considered the forerunner of the modern novel, and here we can see Cervantes’s prose style as being very direct with some .\nThe ledge, where I placed my candle, had a few mildewed books piled up in one corner; and it was covered with writing scratched on the paint. This writing, however, was nothing but a name repeated in all kinds of characters, large and small—Catherine Earnshaw, here and there varied to Catherine Heathcliff, and then again to Catherine Linton. In vapid listlessness I leant my head against the window, and continued spelling over Catherine Earnshaw—Heathcliff—Linton, till my eyes closed; but they had not rested five minutes when a glare of white letters started from the dark, as vivid as spectres—the air swarmed with Catherines; and rousing myself to dispel the obtrusive name, I discovered my candle wick reclining on one of the antique volumes, and perfuming the place with an odour of roasted calf-skin.\n(Wuthering Heights by Emily Brontë)\nIn this prose example from Emily Brontë we hear from the narrator, who is focused on the character of Catherine and her fate. The prose style mimics his obsession in its long, winding sentences.\n“I never know you was so brave, Jim,” she went on comfortingly. “You is just like big mans; you wait for him lift his head and then you go for him. Ain’t you feel scared a bit? Now we take that snake home and show everybody. Nobody ain’t seen in this kawn-tree so big snake like you kill.”\n(My Antonia by Willa Cather)\nIn this excerpt from My Antonia, Willa Cather uses her prose to suggest the sound of Antonia’s English. She is a recent immigrant and as the book progresses her English improves, yet never loses the flavor of being a non-native speaker.\nRobert Cohn was once middleweight boxing champion of Princeton. Do not think I am very much impressed by that as a boxing title, but it meant a lot to Cohn. He cared nothing for boxing, in fact he disliked it, but he learned it painfully and thoroughly to counteract the feeling of inferiority and shyness he had felt on being treated as a Jew at Princeton.\n(The Sun also Rises by Ernest Hemingway)\nErnest Hemingway wrote his prose in a very direct and straightforward manner. This excerpt from The Sun Also Rises demonstrates the directness in which he wrote–there is no subtlety to the narrator’s remark “Do not think I am very much impressed by that as a boxing title.”\nThe Lighthouse was then a silvery, misty-looking tower with a yellow eye, that opened suddenly, and softly in the evening. Now—\nJames looked at the Lighthouse. He could see the white-washed rocks; the tower, stark and straight; he could see that it was barred with black and white; he could see windows in it; he could even see washing spread on the rocks to dry. So that was the Lighthouse, was it?\nNo, the other was also the Lighthouse. For nothing was simply one thing. The other Lighthouse was true too.\n(To the Lighthouse by Virginia Woolf)\nVirginia Woolf was noted for her stream-of-consciousness prose style. This excerpt from To the Lighthouse demonstrates her style of writing in the same way that thoughts occur to a normal person.\nAnd if sometimes, on the steps of a palace or the green grass of a ditch, in the mournful solitude of your room, you wake again, drunkenness already diminishing or gone, ask the wind, the wave, the star, the bird, the clock, everything that is flying, everything that is groaning, everything that is rolling, everything that is singing, everything that is speaking. . .ask what time it is and wind, wave, star, bird, clock will answer you: “It is time to be drunk! So as not to be the martyred slaves of time, be drunk, be continually drunk! On wine, on poetry or on virtue as you wish.”\n(“Be Drunk” by Charles Baudelaire)\nUnlike the previous examples, this is an example of a prose poem. Note that it is written in a fluid way that uses regular grammar and , yet has an inarguably poetic sense to it.']	['<urn:uuid:4d6514df-e988-489c-9779-51a4bd44ee6b>']	factoid	with-premise	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-12T23:56:45.148498	21	50	1145
98	I've been reading about different approaches to cardioversion and was wondering whether this treatment can be done outside of hospital settings - particularly the medication-based approach?	Cardioversion using drugs can be done outside the hospital. This treatment is most often used for people with atrial fibrillation that comes and goes. However, you will need to be closely followed-up by a cardiologist.	"[""The Brain and Spine Institute is made up of experts in the field of neuroscience in order to bring patients the best healthcare in East Tennessee for a full range of neurological diseases and disorders.\nCardioversion is a method to return an abnormal heart rhythm back to normal.\nCardioversion can be done using an electric shock or drugs.\nElectric cardioversion may be done with a device that gives off a shock. The device can be placed inside (internal) or the shock can be delivered from the outside (external) the body.\nExternal electric cardioversion uses a device called a defibrillator.\nEmergency external electric cardioversion is used to treat abnormal heart rhythms (arrhythmia) that can cause death, such as ventricular tachycardia or ventricular fibrillation.\nExternal electric cardioversion may also be used for non-emergency conditions. Heart rhythm problems, such as atrial fibrillation or paroxysmal supraventricular tachycardia (PSVT) that began recently or that cannot be controlled with medicines may be treated this way.\nAn implantable cardioverter-defibrillator (ICD) is a device that is placed inside your body. It is most often used in people who are at risk for sudden death from ventricular tachycardia or ventricular fibrillation, or who have had these heart rhythms before.\nCARDIOVERSION USING DRUGS (PHARMACOLOGIC)\nCardioversion can be done using drugs that are taken by mouth or given through an intravenous line (IV). It can take from several minutes to days for this treatment to work. If you are given drugs for cardioversion in a hospital, your heart rate will be regularly checked.\nCardioversion using drugs can be done outside the hospital. This treatment is most often used for people with atrial fibrillation that comes and goes. However, you will need to be closely followed-up by a cardiologist.\nAs with electrical cardioversion, you may be given blood thinning medicines to prevent blood clots from forming and leaving the heart (which can cause a stroke).\nComplications of cardioversion are uncommon, but may include:\nPeople who perform external cardioversion may be shocked if the procedure is not done correctly. This can cause heart rhythm problems, pain, and even death.\nEpstein AE, DiMarco JP, Ellenbogen KA, et al. 2012 ACCF/AHA/HRS focused update incorporated into the ACCF/AHA/HRS 2008 guidelines for device-based therapy of cardiac rhythm abnormalities: a report of the American College of Cardiology Foundation/American Heart Association Task Force on Practice Guidelines and the Heart Rhythm Society. J Am Coll Cardiol. 2013 Jan 22;61(3):e6-75. PMID: 23265327 www.ncbi.nlm.nih.gov/pubmed/23265327.\nLafuente-Lafuente C, Mah I, Extramiana F. Management of atrial fibrillation. BMJ. 2009; 339:b5216. PMID: 20032065 www.ncbi.nlm.nih.gov/pubmed/20032065.\nMiller JM, Zipes DP. Therapy for cardiac arrhythmias. In: Bonow RO, Mann DL, Zipes DP, Libby P. Braunwald's Heart Disease: A Textbook of Cardiovascular Medicine. 9th ed. Philadelphia, PA: Elsevier Saunders; 2011:chap 37.\nMorady F. Electrophysiologic interventional procedures and surgery. In: Goldman L, Schafer AI, eds. Goldman's Cecil Medicine. 24th ed. Philadelphia, PA: Elsevier Saunders; 2011:chap 66.\nMyerburg RJ, Castellanos A. Approach to cardiac arrest and life-threatening arrhythmias. In: Goldman L, Schafer AI, eds. Goldman's Cecil Medicine. 24th ed. Philadelphia, PA: Elsevier Saunders; 2011:chap 63.\nReview Date: 5/13/2014\nReviewed By: Michael A. Chen, MD, PhD, Associate Professor of Medicine, Division of Cardiology, Harborview Medical Center, University of Washington Medical School, Seattle, WA. Also reviewed by David Zieve, MD, MHA, Isla Ogilvie, PhD, and the A.D.A.M. Editorial team.\nThe information provided herein should not be used during any medical emergency or for the diagnosis or treatment of any medical condition. A licensed medical professional should be consulted for diagnosis and treatment of any and all medical conditions. Call 911 for all medical emergencies. Links to other sites are provided for information only -- they do not constitute endorsements of those other sites. 1997- A.D.A.M., Inc. Any duplication or distribution of the information contained herein is strictly prohibited.""]"	['<urn:uuid:9116fe1b-1562-4e51-8d9a-21458a183741>']	factoid	with-premise	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-12T23:56:45.148498	26	35	624
99	When do hummingbirds migrate and what dangers do they face during migration?	Ruby-throated hummingbirds begin their fall migration from late August to mid-October, with males starting around early July. They travel from as far as Canada to Panama, Mexico, and Central America. Migration is the most dangerous time for birds - during this journey, hummingbirds must maintain their extremely high metabolism (beating wings 75 times per second and hearts reaching 1000 beats per minute) while crossing large expanses of land and water. They need to find sufficient food sources like flower nectar, insects, and tree sap to sustain their energy during this tremendous journey of thousands of miles.	"['These flying jewels are one of the highlights of summer.\nBy Kevin Dickey, Conservation Chairman – Lakeland Audubon Society\nIt’s been a good year for hummingbirds so far in my yard. I’ve had them visiting my sugar-water feeders the day after I put them up, which was in the middle of May. People usually start spotting hummingbirds in Wisconsin come the beginning of May or end of April. You could say I was a little late this year putting the feeders out, but no worry, I’ve had plenty of activity at them. The same goes for the flower patches in my yard, I’ve noticed a lot of visits. although some of this activity can be attributed to the new plants that I added this year like Bee Balm, Foxglove and some Salvias, there are some other factors at play. One of those factors may be the wet weather that we’ve had this spring and summer, possibly increasing the birds energy requirements. Another may be that the birds have fared well over previous years in our area, allowing them to have greater reproductive success and increasing the local population. This would make sense because hummingbirds demonstrate natal philopatry and breeding-site fidelity to a small degree.\nSpeaking of timing, I’d like to point out that (prime time) for hummingbird garden activity is just around the corner. It starts the end of August and lasts until the middle of October. This is when the Ruby-throated Hummingbirds, the only hummingbird species regularly found in Wisconsin, undertakes its fall migration. This migration can span from Canada to Panama, quite a feat for such a small bird (3 to 3.75″ long). A small percentage of these birds will over-winter in Florida and other states in the deep south, as some live there year-round, but most will make the long haul to places in Mexico and central america. The birds that you’ll be seeing will be females and juveniles (this year’s offspring). Male Ruby-throated Hummingbirds have already started their southbound migration, usually about the beginning of July in our area.\nOne other thing well worth mentioning is that the forage base for insects has been especially good for the hummingbirds this year, again our weather may have been a factor. This year, more than in years past, I’ve observed a type of fly-catching behavior by hummingbirds both before and after visits to my sugar-water feeders. Sometimes I noticed it around my yard, as hummingbirds are insectivores. That said hummingbirds can definitely be a gardeners friend, it’s why I avoid using insecticides in my yard, as I want to keep the food chain intact. When insecticides are used they usually kill off all insect life including ones that are of some benefit to your garden and it’s visitors.\nFor those who wish to learn more about these unique and beautiful birds, there is a wealth of information available online. below I have listed some links to some of the best websites about birds (including hummingbirds) that I have come across over the years.\nThis link is of special interest to anyone who gardens for hummingbirds or would like to do so more effectively. It is Michael & Kathi Rocks website. They have been hummingbird gardening very passionately in Madison, WI for seventeen years.', 'Futures Project! About Bird Migration\nSome birds, like song birds, change their behavior when migrating. Normally, active in the daytime, songbirds migrate at night. They fly all night and land at sunrise to rest and look for food.\nBirds need to bulk up so they have the energy it takes to get where they are going...and some birds go a long way! They can lose 1/4 to 1/2 their body\'s weight during this time. Just imagine a poor songbird; they weigh less than 18 grams - about as much as three pennies!\nThe feather is one amazing piece of bird equipment. Lightweight, strong, adaptable, waterproof, streamlined - there is a feather for every need on a bird\'s body! It\'s thick, it\'s wet, most times it\'s noisy, it\'s green and it\'s teeming with life. The rain forest world is a paradise for bird life...and the numbers of species that call a rain forest home is astounding. For example, in Southern Peru a scientist found that when he stood in one place and ""without taking a step"" he could count more than 160 species of birds at one time! And in Ohio the forests are temperate, and they experience a different phenomenon...they have fewer species and higher numbers of each of those species.\nMigration is triggered by sunlight...diminishing or increasing day length tips off the birds and they feel that urge to travel! Bird migration is one of the most fabulous phenomena in all of nature. It is the great global strategy for survival that shifts millions of birds across hemispheres twice each year. Scientists believe that the incentive underlying migration is food availability and that this behavior evolved as an adaptive strategy whereby birds could maximize their chances for survival by optimal utilization of food resources. The numbers of birds that use this traveling trick are tremendous. Of the 650 or so bird species that nest in North America, 338 of them, or more than half, migrate back and forth from the tropics each year.\nThe Wing\'s of the Americas Program protects birds at risk by protecting critical habitat throughout the Americas. One of the goals of the program is to protect important breeding and wintering habitats of migratory birds.\nThe Edge of Appalachia Preserve System is a magnificent natural system encompassing more than 12,000 acres in south central Ohio. This system harbors an exceptional array of plant and animal species and is a haven for an extraordinary amount of migratory birds. The Nature Conservancy owns and manages the Edge of Appalachia Preserve System in partnership with the Museum of Natural History & Science, a division of the Cincinnati Museum Center.\nThere are a couple of key differences between the avian diversity in these two ecosystems. For example, all birds have territories...places they stake out as their own. They know them, mark them and defend them from intruders of their own species. On average, tropical birds have territories that are about ten times the size of temperate forest birds\' territories. But the diversity can remain very high since there is incredible overlapping of territories of different species. In general, the more structurally diverse the habitat, the more likely it is to contain a higher diversity of birds. That\'s because there are many more places to hide and find food in a diverse habitat. And there is no more diverse region in the world than the rain forests of Central and South America. Ornithologists estimate that over one third of all bird species live in these forests. And a diverse habitat provides myriad microhabitats, not just for birds, but for all the things they depend upon for food. There are more insects, fruits, flowers and seeds all year round in the tropics than anywhere else on Earth.\nWhen you think of a rain forest, you may think of parrots and toucans, but you should also think of ruby-throated hummingbirds and sharp-shinned hawks and scarlet tanagers. These birds call the United States or Canada home for part of their year. It is pretty amazing to have two such different addresses. But, both of their addresses, and some campsites between them, are imperative for the health of many species of birds that they think of as their own.\nWhat does a migration year look like?\nNeotropical Migrants are bird species that breed in North America in the summer and migrate in the fall to Central or South America where they spend the winter.\nOhio covers over 41,000 sq. miles, most of which is used for residential, agricultural or industrial purposes. Where do the birds fit in? The beach is not just for sunbathing. Migrating shorebirds need a healthy shoreline ecosystem to meet their feeding and resting needs as they travel to it twice a year.\nLet\'s look at the state of New Jersey and its rich migration pathway as an example: the initial fall migrants arrive just a few days after the first day of summer! There are certain shorebirds and sandpipers who breed very far north and have to travel over the equator and beyond. July sees the migration of other species of shorebirds. August includes songbirds on their way south. In September hawks and many other species increase the migration numbers to a high tide. October and November migrations include the waterfowl and seabirds. December urges the last remaining migrants. Even in January and February winter finches might be seen heading south just as the light begins to turn and the first north-bound birds pass in the sky. Hence, migration takes a while and the beginnings and endings actually overlap!\nOne benefit of this lengthy process is that birds can share key feeding and resting areas, because they are there at different times. When speaking of migration it is necessary to mention the all-time champion frequent flyer among birds. Arctic terns travel farther than any animal other on Earth; in fact, they spend more time migrating than doing anything else. Feeding on small animals in the cold, rich polar waters, these birds fly over 20,000 miles every year.\nMost migratory bird species that breed in the Edge of Appalachia Preserve System spend the winter south of the U.S. Border. Migratory birds have three very important places in their small lives. They need nesting habitats, stopover habitats and wintering habitats. If any one of these pieces is lost to them, they are lost. The reason these areas are so essential is that habitat is the single most important need of migrating birds. All their needs are met in each specific habitat area.\nBut now the rules have changed. People have entered the scene in force, and each spring and fall migrating birds play a deadly game of ""habitat musical chairs."" Just as in the popular children\'s game, where in each round there is one less place to sit, each season there are less and less places for many birds to feed, rest and nest. For instance, when 20 acres of woodland are converted into 20 one-acre suburban lots, perhaps five species of birds will be able to live there, in the very same area where 65 species of woodland birds lived just one year before. And that\'s just on this end of the migratory path. In the tropical rain forests of Central and South America an even a greater diversity of birds are adversely effected every time a 20-acre section of forest is cleared. As a result, populations of many species that just 20 years ago were common have been shattered--reduced in many places to remnants, or memories.\nHowever, even when all the natural elements are in place, migration is the most dangerous time for birds. For example, 60% of the songbirds hatched in spring fail to survive their first migration to make it to their first birthday; birds of prey experience even tougher odds. For example, only 25% of sharp-shinned hawks survive their first year.\nEven with all the travails of migration, if there is food available, the bird is healthy, it escapes predation, there is a constant breeding ground, known stopover places, and a wintering ground intact, then this high-energy system of migration works as a highly elaborate and complex survival strategy.\nRuby-throated hummingbirds are tiny birds with huge jobs. They have to fly to find flowers, from which they feed on the nectar, and that means crossing large expanses of land and water during migration. Hummingbirds are the smallest birds in the world but possess the highest metabolism; they beat their wings 75 times per second in forward flight, and their tiny hearts reach upwards of 1000 beats per minute. The ruby-throated hummingbird nests throughout much of North America, from southern Canada to Florida and the Gulf Coast and all the states in between. But they overwinter in Central American forests, from Mexico to Costa Rica. Hence their name in Spanish, ""Colobri de Paso,"" which means ""hummingbird of the passage.""\nFor these little birds to traverse thousands of miles twice a year is a Herculean accomplishment. But they don\'t migrate just for the flowers. Hummingbirds also eat small insects, spiders and even tree sap from holes drilled by sapsuckers. But they are most famous for their ability to hover in front of flowers while drinking as they fly. Their long, needle-like beaks cover even longer tongues which can be inserted deep into the throats of flowers to lap up the nectar. They even get their name, ""humming-bird"" due to this hovering capability. The hummers\' wings move so quickly that they are impossible to see in flight and actually produce a soft humming, or buzzing, sound. In order to hover still in the air, hummingbirds have specially adapted muscles and tendons that allow their wings to rotate in a figure-eight motion rather than just going up and down as many birds\' wings do. As a result, hummingbirds can get a double down stroke - one on each end of the figure-eight motion.\nHummingbirds are thought to have the fewest feathers of any bird, but they obviously use them very effectively since the annual transcontinental flights of ruby-throated hummingbirds are truly a miracle of migration.\nBirds are the most ubiquitous symbols of nature and wildlife around us. No matter where you live, it is a safe bet that you can see birds right out your window every day of your life. But many bird species are in decline, and it is going to take a lot of us, with knowledge and commitment, to keep birds in their lives in the future. This concern began with birdwatching, and now it will take more than binoculars.\nIt took years for scientists to notice the decline in migratory birds. It took more years to piece together the causes. Now comes the next step. Now they have to take measures to stop the slide.\nWhen habitats are at risk, the birds and wildlife that call them home are also in danger. In Ohio 90% of the wetlands have been destroyed, and the black tern, the prothonotary warbler and the little blue heron have been negatively effected by the shrinking. 95% of Ohio\'s of native prairies and the numbers of grasshopper sparrow, dickcissel and bobolink have declined as well. Though their woodlands have been increasing in the past decade, the diversity of these emerging forests is not as great as it originally was and such species as the golden-winged warbler, the cerulean warbler and the great crested flycatcher have felt the pressure of these habitat changes.\nSo, what\'s it going to take to save birds?\nIt takes a commitment in the private and the public sector to investigate the causes for the decline of bird species and to act upon ways to limit that decline. Research, increased awareness, and monitoring species are all proactive ways of showing commitment to avian diversity. However, the best way of showing this commitment is protecting habitat. In every state, they have to keep some wild places intact so that the birds can find them, whatever time of the year they are flying over.\nPete Dunne is one of the most renowned natural history writers in America. As Director of the Cape May Bird Observatory, he is a tireless organizer, advocate and communicator for the magic of wild areas.\nIt took a cloud of hawks on a September day in Pennsylvania to direct Pete Dunne\'s life to the beauty and the needs of birds the world around. Since that day when the fall migration captured his attention and his resolve, he has been spending his days observing, noting, and pointing out the wonders of birds and their specific requirements in a healthy, natural system. He spends much of his time on the eastern coast of the United States, in Cape May, New Jersey, writing and talking about birds and their needs. He also travels extensively to search, observe and understand the mysterious world of these animals that can lose gravity\'s grasp and fly away. The birds, the people who love them, and the world in which all of us live combine to influence this dedicated ornithologist and conservationist. His goal is a future that includes room for birds and the systems that support them.\n""They are all part of a community on the planet. I would like a planet that has a lot more richness than what they are heading for right now. The idea of a stark planet doesn\'t appeal to me at all. I don\'t want to be the only show in town. I don\'t want to go outdoors and see nothing but other people. I want to see a lot of diversity. That\'s why I\'m out there, to keep a lot of the elements of the mosaic."" - Pete Dunne Ornithologist']"	['<urn:uuid:95a36bc1-0933-4851-88c6-2ec040d65707>', '<urn:uuid:d8c0cdd4-09bc-4ac9-88da-1c403fbc7f8f>']	open-ended	direct	concise-and-natural	similar-to-document	multi-aspect	novice	2025-05-12T23:56:45.148498	12	96	2827
100	How do biocides perform in sales and what are their advantages over chlorine?	Biocides are the leading segment in RO membrane chemicals, reaching USD 600 Mn in 2017. Unlike chlorine, biocides (particularly bromine-based ones) work better in alkaline environments, don't react irreversibly with ammonia, and are less corrosive to copper alloys.	['Market Research Future (MRFR) expects the RO Membrane Chemicals Market to escalate at a decent rate of 7.88% from 2018 to 2025 (review period).\nIn response to the COVID-19 outbreak and the resultant lockdown, vendors had to temporarily suspend production, in line with lower product demand, disruptions in supply chain, and the need to maintain the safety of employees amidst the escalating SARS-CoV-2 cases. In the US, Germany, France, Spain and Italy, the demand for RO membrane chemicals has declined since the pandemic. Therefore, many of the companies are striving to revive operations by solidifying their supply chains and seek out new strategies to address the challenges brought by the novel coronavirus.\nIntense Demand for High-Quality Water among Industries to Foster Growth\nHigh-quality water is of utmost significance among several industries, which has raised the demand for high-grade RO membrane chemicals over the years. Reverse osmosis membranes are witnessing huge demand for producing pure water for multiple applications since these systems facilitate the removal of small as well as large colloids, ions, bacteria, pyrogens and organic substances from the feed water. The escalating use of RO membrane systems is ultimately leading to higher demand for RO membrane chemicals, as the latter helps get rid of several impurities that are present at the surface of the system during the operation. These chemicals ensure high membrane performance and are therefore, enjoying robust demand across a number of end-use industries.\nThe demand for high-quality water devoid of harmful microorganisms and bacteria has been mounting in the pharmaceutical sector, especially for applications like equipment cleaning, rinsing and manufacturing of active pharmaceutical ingredients (APIs), drugs, laboratory waters and non-compendial waters. The expanding application scope of RO membrane chemicals in the pharmaceutical sector and more, will most likely translate into considerable revenue generation in the following years.\nMiddle East & Africa to Offer Attractive Opportunities\nThe Middle East and Africa will offer attractive opportunities to leading vendors in the years ahead, given the heightened demand for water in view of the exploding population as well as agricultural activities. The RO membrane chemicals market is also presented with opportunities by the expanding desalination industry in the region.\nHigh Costs of Manufacturing RO Membranes to Hamper Growth\nHigh costs related to production of RO membrane and their short life span could restrain the market growth in the following years.\nNano Filtration Technology to Emerge as a Threat\nThe nano filtration technology will emerge as a credible threat as it is increasingly being used as an alternative to RO membrane chemicals for producing potable water.\nApplications in Membrane Fouling to Surge Rapidly\nSome of the major applications studied in the report are membrane scale control, membrane fouling and membrane cleaning. The membrane fouling category is in the lead and can even cross USD 1,100 Mn by 2025, while procuring an above-average growth rate. Membrane fouling is one of the most common complaints among consumers using RO membranes, which fosters the need for RO membrane chemicals.\nBiocides Segment Takes the Lead\nAcid membrane cleaners, biocides and alkaline membrane cleaners are the top RO membrane chemical types considered in the report. At present, the biocides segment controls the highest share in the market and in 2017; it had reached USD 600 Mn. It has maintained an impressive growth rate since then and should continue to do so during the review period. Biocides are important RO membrane chemicals that will continue to enjoy solid demand in the coming years. The alkaline membrane cleaner segment could surpass USD 400 Mn by 2025.\nAsia Pacific to Demonstrate Remarkable Growth\nAPAC controls more than one-third of the total share in the global market. In 2017, APAC had touched over 700 Mn and has been spearheading the global market ever since. India and China are extremely populated nations, not only in the region but across the world, a factor that has been crucial to the market’s strong growth prospects. Both these countries are increasingly adopting economic reforms, making them hotspots for growth among global stakeholders. Substantial growth in electrical and electronics, pharmaceutical and chemical industries in the region and the resultant rise in the product demand will also fuel the RO membrane chemicals market size in subsequent years.\nNorth America to Emerge as the Second Leading Market\nNorth America is the second-biggest gainer in the global market and is touted to procure a growth rate of 7.15% over the review period. Reverse osmosis membrane chemicals enjoy strong demand in the region most due to the rising need for potable water among the burgeoning population coupled with escalating mining needs, electric utility needs and agricultural needs, among others.\nFirms Adopt Product Launch as their Key Competitive Strategy\nManufacturers in the reverse osmosis membrane chemicals industry generally adopt product launch as a competitive strategy to foster their positions. Reputed firms with significant RO membrane chemicals market share also enter into partnerships and adopt acquisition as a key tactic to boost their global presence.\nAcuro Organics Limited is a highly renowned specialty chemicals manufacturing firm, with an extensive offering of advanced RO membrane chemicals known for their high efficiency and quality. The company aims to develop high-quality RO membrane chemicals that cater to international standards, backed by an impressive infrastructure with state-of-the-art technologies as well as a robust marketing expertise.\nFrequently Asked Questions (FAQ) :\nThe outlook of the global RO membrane chemicals market looks very promising.\nThe global RO membrane chemicals market is poised to expand at 7.88% CAGR during the review period (2018-2025).\nRising demand for purified water, Rapid increase in the global population.\nAsia Pacific holds the largest share in the global RO membrane chemicals market, followed by North America and Europe, respectively.\nAmpac USA, Lenntech B.V, American Water Chemicals, Inc., Applied Membranes, Inc., SUEZ, Kroff, Inc., Koch Membrane Systems, Inc., Acuro Organics Limited, AXEON Water Technologies, King Lee Technologies, Ecolab, and Aceepta Ltd., are some of the major players operating in the RO membrane chemicals market.\nThe global RO membrane chemicals market reached a valuation of USD 1,537.1 Mn in 2017 and is projected to exhibit a CAGR of 7.88% during the forecast period (2018-2025). Increased demand for purified water is primarily supporting the growth of the market. Today, purified water is not only used for drinking purposes but also in industrial applications. Some of the prominent industrial verticals that entail water purification include drinking water systems, industrial boilers, food and beverage processing, pharmaceuticals, aerospace, and microelectronics among others.\nGlobal supply of RO membrane chemicals has also spiraled upwards due to the spurring of desalination plants in various parts of the world. These plants are focused on meeting the rising demand for drinking water. The pressure on accessible fresh water sources are reaching maximum limits, which is prompting the requirement of desalination of see water to make it drinkable. Providing an apt solution to the rising scarcity of water is a tall order. In addition, rising industrial application of clean water further adds to the grievance. Seawater covers around 71% surface of the earth and comprises of around 97% of the world’s water hence there is a greater emphasis on adoption of seawater desalinization strategies. Such factors have created a tremendous market opportunity for RO membrane chemicals.\nOn the back of fast-expanding end-use industries such as oil and gas, food and beverage, and power generation the demand for purified water has also increased in emerging economies such as India, China, Brazil, and Mexico.\nThe segmental analysis of the market is based on type and application. On the basis of type, the market is segmented into biocides, acid membrane cleaners, and alkaline membrane cleaners. In 2017, the biocides segment accounted for the largest market share and reached a valuation of USD 621.4 Mn. The segment is projected to witness a strong growth over forecast period. This is mainly attributed to the increasing usage of biocides to control slime, microorganisms and biofilm. Biocides will remain a sought-after RO membrane chemical product throughout the assessment period. The alkaline membrane cleaner segment currently holds the second spot and is likely to retain its position over 2025. The segment stood at a market valuation of USD 478.8 Mn in 2017.\nBased on application, the global RO membrane chemicals market has been segmented into membrane fouling, membrane cleaning, and membrane scale control. The membrane fouling segment currently accounts for the largest market share. During the forecast period, the segment is expected to exhibit 8.60% CAGR to reach a market valuation of USD1,177.9 Mn. Membrane fouling is one of the major challenges faced in RO membrane water purification process due to deposition of biofilms, colloidal particles, and insoluble organic constituents at the surface of the membrane.\nBased on region, the market has been segmented into Europe, North America, Asia-Pacific, South America, and the Middle East & Africa (MEA). In 2017, the Asia Pacific accounted for 46.2% market share, standing at valuation of USD 715.5 Mn. The region’s market is expected to witness a strong growth over the next several years. The economic boom in countries such as China and India is providing an impetus to the market in the region. Growth of large-scale industries such as oil and gas, water treatment, food and beverage, pharmaceutical, and power generation in these countries is also paving the way for the APAC RO membrane chemical market. North America and Europe are expected to remain important business destination for market players during the forecast period. South America and the MEA are also presenting significant growth opportunities for the market. Construction of desalination plants in many of the CCG and South American countries due to rising demand for purified water is driving the market’s growth in these regions.\nKey companies functioning in the global RO membrane chemicals market include Ampac USA, SUEZ, Lenntech B.V., Kroff, Inc., Koch Membrane Systems, Inc., Ecolab, Aceepta Ltd., King Lee Technologies, AXEON Water Technologies, Acuro Organics Limited, Applied Membranes, Inc., American Water Chemicals, Inc.\nGlobal RO Membrane Chemicals Market: Competitive Landscape\nThe prominent players in the global RO membrane chemicals market are Ampac USA, SUEZ, Lenntech B.V., Kroff, Inc., Koch Membrane Systems, Inc., Ecolab, Accepta Ltd, King Lee Technologies, AXEON Water Technologies, Acuro Organics Limited, Applied Membranes, Inc., and American Water Chemicals, Inc.\nSUEZ, Ecolab, Koch Membrane Systems, Inc., Applied Membranes, Inc., and AXEON Water Technologies collectively hold the majority share of the global RO membrane chemicals market. Some of the key market players inorganic growth strategies such as agreements and acquisitions to meet the increasing demand for RO membrane chemicals in major end-use industries.\nSuez engages in offering water and waste management services through its subsidiaries. It operates through five segments: water Europe; recycling and recovery Europe; international; water technologies and solutions; and others The water and technologies solutions segment offers RO membrane chemicals which protect the membrane from scale, bacterial growth, and fouling. It offers Kleen MCT cleaners which are designed to remove organics, silt, microbiological accumulations and other particulate deposits from ultrafiltration (UF), reverse osmosis (RO), nanofiltration (NF) and microfiltration (MF) systems for improving the performance and durability of membranes. In November, 2017, SUEZ and SOLVAY joined forces for water treatment in China; it will help to treat brine from reverse osmosis desalination at Wanhua Chemical industry park in Yantai. This agreement is expected to provide technologies for the innovative treatment of effluents based on Advanced Oxidation Processes (AOP).\nEcolab is a global leader in water, hygiene, and energy technologies. The company operates through four segments—global industrial, global institutional, global energy, and others. The global industrial segment is further divided into NALCO water, food & beverage, paper, life sciences, and textile care. These operating segments provide water treatment, process applications, and cleaning and sanitizing solutions to various end-use industries, such as food & beverage, chemicals, power, and manufacturing. The company offers membrane chemicals which include, antiscalants that prevent mineral deposits on membrane, biocides, thermal desalination, and others. This comprehensive range of membrane cleaners is specifically formulated to remove mineral scale, insoluble scale, organic fouling, or microbial residue to restore membrane performance.\nKoch Membrane Systems Inc. designs, develops, and manufactures membrane filtration systems. It offers engineered systems and pre-engineered modular building blocks; and membrane products, such as spiral membranes, tubular membranes, hollow fiber membranes, and membrane cleaners. It offers products for municipal water and wastewater, metal finishing, power, oil and gas, pulp and paper, chemical, food and beverages, dairy, industrial biotechnology, pharmaceutical intermediate, automotive, and general industrial markets across the globe. It provides membrane cleaning products that help regenerate and revitalize membranes used in food, beverage, municipal, and industrial applications.\nApplied Membranes, Inc. is a manufacturer and distributor of reverse osmosis membranes, systems, and components under AMI label, for both commercial and residential. The company has formulated its own proprietary membrane cleaning chemicals. It also offers technical expertise and assistance in troubleshooting and cleaning of RO membranes for optimum system performance. It sells its products worldwide through original equipment manufacturers, company representatives, resellers, distributors, and dealers', 'November 21, 2017 0 Comments\nControl of the three major microbiological classes, bacteria, algae and fungi, and macroorganisms including zebra mussels, is essential for healthy cooling tower operation. For many years, chlorine was the treatment chemical of choice. However, chlorine use is declining due to environmental, safety and performance-related issues. This article examines the positive and negative aspects of chlorine and of replacement oxidizing biocides.\nMicrobiocides generally belong to one of two groups: oxidizers and non-oxidizers. The former attack cells by oxidizing (an electron transfer reaction) microorganism cell components. Non-oxidizers react with cell components via different chemical processes. Oxidizing biocides are still the most common biological control agents, and even though chlorine use is declining, it continues to be an important player in the cooling water treatment industry.\nWhen chlorine is injected into a cooling water stream, it disproportionates into hypochlorous and hydrochloric acid as follows:\nCl2 + H2O Æ HOCl + HCl\nHOCl is the oxidant that attacks cell structures. An increase in pH increases the dissociation of HOCl into the hypochlorite ion (OCl-):\nHOCl H+ + OCl-\nAlthough both HOCl and OCl- are oxidants, OCl- is a much weaker disinfectant, possibly because the charged OCl- ion has a more difficult time penetrating the cell wall. Chlorine`s biocidal efficiency greatly decreases as the pH rises above neutral. (See sidebar.)[Native Advertisement]\nFor years, the most popular cooling water treatment program at many facilities was low-level sulfuric acid feed to control calcium carbonate formation, with supplemental feed of chromate and zinc for corrosion inhibition. This suited chlorine as a microbiocide because the mildly acidic pH maintained the chlorine residual predominantly as HOCl. However, chromate discharges to the environment have been banned due to the potential release of toxic hexavalent chromium. Modern cooling tower treatment programs operate in the less corrosive alkaline range of pH 8.0 to 9.0, in which advanced calcium carbonate scale inhibitors have replaced sulfuric acid. Such programs do not favor chlorine as a microbiocide. This problem has been exacerbated by the development of more efficient cooling tower fill (Figure 1), whose close spacing makes the material susceptible to pluggage.\nSafety issues are another factor in chlorine`s reduced popularity. Chlorine gas is quite hazardous, and regulations governing its storage and leak detection are becoming increasingly stringent. Rather than deal with the safety requirements for gaseous chlorine, many plant managers are opting for alternatives.\nThe potential for formation of chlorinated organics has also become an important issue. Many halogenated organics are known or suspected carcinogens, and tighter restrictions are being placed on the amount of allowable halogenated organics. In 1979 the Environmental Protection Agency (EPA) set an interim maximum contaminant level (MCL) of 0.100 ppm for total trihalomethanes (TTHM`s). The agency has proposed to reduce the MCL to 0.080 ppm, and may lower the standards even further in the future.\nIn 1982, the power industry was required to meet optimized technology-based standards for chlorine use. The requirements limited the maximum chlorine discharge from cooling towers to 0.5 ppm, with an average discharge of 0.2 ppm for no more than two hours per day. In 1985 the EPA announced more stringent ambient water quality criteria, which applied to all industries. These guidelines limited fresh-water chlorine concentrations at the boundary of a calculated effluent mixing zone to 0.011 ppm over a four-day average, or 0.019 ppm average for one hour. Restrictions for salt water are even more stringent at 0.0075 ppm and 0.013 ppm, respectively.\nThe regulations have made it particularly difficult to use chlorine to control cooling water biological fouling. The situation has been further complicated by the spread of macrofouling species, the most notable of which are zebra mussels and Asiatic clams. Continuous or semi-continuous chlorination is necessary to control the growth of macrofoulers, especially adults, but continuous chlorination is expensive, particularly when bleach is the biocide. Continuous chlorination can also harm non-target organisms in once-through cooling systems. Many facilities must dechlorinate their cooling water prior to discharge in order to comply with water quality standards. This process typically requires the feed of a reducing agent, such as sodium bisulfite, into the effluent.\nA popular substitute for chlorine is bromine (Br2). Like chlorine, bromine reacts with water to produce a hypohalous acid, in this case HOBr. Bromine has nearly the same oxidizing power as chlorine, but it offers several advantages over chlorine in certain conditions. First, the dissociation of HOBr occurs at a higher pH than HOCl (Figure 2), which makes it more effective in alkaline environments. Second, bromine does not react irreversibly with ammonia as does chlorine. Chloramines are much less effective disinfectants than free chlorine, which makes chlorination of ammoniated waters problematic. Third, bromine is less corrosive than chlorine to copper alloys.\nBromine may be introduced into a cooling water system by several different methods. Most common is to react liquid sodium bromide (NaBr) with chlorine or sodium hypochlorite in a sidestream loop of the cooling water makeup. Chlorine activates the bromide salt to hypobromous acid as follows:\nNaBr + HOCl Æ HOBr + NaCl\nSodium bromide, being the bromine analog of common table salt (NaCl), is stable and may be stored in a simple bulk tank. NaBr is usually supplied as an aqueous solution of approximately 40 percent concentration. The sodium bromide and chlorine or sodium hypochlorite should be fed separately into the slipstream to obtain at least a 100:1 dilution. This prevents the formation of undesirable bromate byproducts.\nLike chlorine, bromine is toxic to non-target organisms and it can form halogenated organics. For these reasons plant cooling water discharges containing bromine are regulated similarly to chlorine, although some states or EPA regions have established more restrictive standards for bromine residuals.\nEven though the cost of sodium bromide adds to the total delivered cost of the oxidants, users often find it possible to reduce the overall quantity of oxidant required to achieve the equivalent performance. Frequently, the reduction in chlorine consumption more than offsets the cost of the sodium bromide, especially where liquid sodium hypochorite is the chlorine source.\nFor smaller cooling water systems, solid bromine donors may be a cost-effective alternative to the arrangement mentioned above. One of the most common solid biocides is bromo- chloro-dimethyl-hydantoin, or BCDMH, which releases bromine as it dissolves in water. Several of the major water treatment vendors supply solid bromine or chlorine donors in granules, pellets, or tablets along with a feed system. As water passes through the dissolving vessel, the BCDMH dissolves at a controlled rate to release HOBr and HOCl:\nC5H6O2N2BrCl + 2H2O Æ C5H8O2N2 + HOBr + HOCl\nSolid donor systems are also available for strictly chlorine-releasing products. Some of the most common chlorine-based solid donors include dichloro-dimethyl-hydantoin, calcium hypochlorite [Ca(OCl2)] and chlorinated isocyanurates. The latter two compounds are widely used as swimming pool chemicals, but will also work well in some cooling water applications. Specific feed systems are available for each halogen donor. All of these products are strong oxidizers and must be handled and stored properly; it can be hazardous to use one compound in a feeder designed for another.\nProminent advantages of the solid halogen donors are:\nHandling--no potential for liquid spills;\nStability--stable compared to bleach;\nEffectiveness--strong oxidizers that work well at alkaline pH and in the presence of ammonia;\nWater Chemistry--less corrosive to system materials; do not significantly alter cooling water pH; and\nEnvironmental and Safety Factors--no chance of toxic gas or liquid release.\nThe solid halogen donors are best for systems with a low or moderate chlorine demand, and where simple operation is desirable. Solid donors are generally more expensive than chlorine and even bleach, and can be slow to dissolve at water temperatures below 60 F.\nSodium hypochlorite (NaOCl) may be a suitable non-gaseous alternative. It comes in bulk solution, at a concentration ranging from 10 percent to 12.5 percent as NaOCl. The hypochlorite can be metered directly into the cooling system. An important point to remember about NaOCl is its effect on cooling water pH. Gaseous chlorine lowers the pH due to the production of both HOCl and HCl. Sodium hypochlorite tends to raise the pH.\nSodium hypochlorite will degrade over time to form sodium chloride, oxygen, and sodium chlorate (NaClO3). Temperature and impurities greatly affect decomposition. (See sidebar for specifications and storage guidelines for sodium hypochlorite.)\nThe improved safety and convenience of sodium hypochlorite versus gaseous chlorine has a tradeoff in cost. Chlorine gas in ton cylinders costs $0.15 to $0.20 per pound delivered. By contrast, 12.5 percent sodium hypochlorite costs around $0.60 per gallon ($0.059 per pound) delivered in bulk. This corresponds to $0.50 per pound on an equivalent Cl2 basis, or approximately three times the cost of gaseous chlorine.\nChlorine dioxide (ClO2) is a powerful oxidizer with excellent biocidal properties. It offers several potential advantages compared to chlorine. Chlorine dioxide:\ndoes not form halogenated organics,\nis less corrosive to copper alloys than chlorine,\ndoes not react with ammonia and primary amines,\nefficiently destroys phenols and sulfides,\nis not affected by pH like chlorine and works well in alkaline waters, and\nis more effective against mollusks.\nThese advantages come at a price, however. Chlorine dioxide is a very reactive compound that is hazardous to transport at practical concentrations. It must be generated on-site from other reactive chemicals that also present some handling risks. Chlorine dioxide does not react with water or ionize in solution, thus it remains as a dissolved gas that is easily stripped across a cooling tower. The principal reaction product, chlorite, affects some forms of aquatic life at low levels. Chlorite can be difficult to neutralize with reducing agents.\nChemical costs for sodium chlorite are typically in the $0.50 to $1.00 per pound range for a 25 percent aqueous solution. This corresponds to $2.00 to $4.00 per pound of active ClO2. The costs of bleach or acid for reaction, along with the 80 percent to 95 percent efficiency of the ClO2 generation reactions, can push the price above $3.50 per pound, or over seven times the cost of chlorine. Still, there are some situations where the effectiveness of chlorine dioxide may offset the added cost.\nOzone (O3) is a powerful, short-lived oxidant that is generated by passing air through an electric discharge. The air stream is then bubbled into the cooling water through a diffuser.\nOzone is too reactive to transport or store on-site, so it must be generated at the point of use. This requirement has so far limited ozone`s application to relatively small cooling systems. Ozone is the most powerful oxidant of all, but its oxidizing strength can be a mixed blessing. Ozone rapidly destroys biofilms and produces sparkling clear water, but it also breaks down most scale and corrosion inhibitors, and it slowly degrades plastic, rubber and gasket materials. Similar to chlorine dioxide, ozone does not ionize in water but remains a dissolved gas, which can be stripped during passage through the cooling tower. Ozone offers environmental advantages in that its residuals are short-lived, it does not produce halogenated reaction products, and it breaks down into oxygen, which can be beneficial. However, ozone can produce secondary oxidants if bromide is present, and it can also produce aldehydes and ketones via reaction with organics.\nOne of the major advantages of ozone is that no hazardous chemicals are transported, stored or handled on-site. For small cooling systems in sensitive locations, ozone can be an attractive alternative to chlorine. Researchers continue to investigate methods of ozone treatment for larger systems. p\nFigure 1. Cooling tower film fill.\nAt a pH of 6.5 tests have shown that a 1.0 ppm chlorine solution will kill 99 percent of all microorganisms within 30 seconds. At this pH, a large percentage of the dissolved chlorine exists as HOCl. The percentage rapidly decreases as pH rises.\nThus, in an alkaline cooling water treatment program with a pH between 8 and 9, the available hypochlorous acid is well below 50 percent (Figure 2).\nSodium hypochlorite will decompose into oxygen, sodium chloride, and sodium chlorate. The decomposition rate is affected by temperature and by the catalytic action of some metals, most notably iron and copper. A specification for bulk quantities of sodium hypochlorite should contain the following:\nIron concentration less than 0.5 ppm;\nCopper concentration less than 1.0 ppm; and\npH range from 11.0 to 11.2.\nTemperature can have a dramatic impact on hypochlorite solutions. For example, the half-life of a hypochlorite solution is reported to be 800 days at a temperature of 59 F. At 77 F the half-life drops to 220 days, and at 140 F, the half-life is only 3 days. Bulk storage tanks of sodium hypochlorite should be kept as cool as possible by sun-shading, painting them white, or both.\nFiberglass-reinforced-plastic is the recommended construction material for bulk storage tanks. Poly ethylene was once the material of choice, but cracking problems have been reported after exposure to hypochlorite.\nRead More: http://www.power-eng.com/articles/print/volume-102/issue-7/features/choose-the-right-cooling-tower-chemicals.html\nApril 19, 2023 0 Comments\nApril 17, 2023 0 Comments']	['<urn:uuid:b4b45ffe-61a6-458d-9322-63f467173bad>', '<urn:uuid:ff4e3185-1939-4132-b49f-590f081206ce>']	factoid	with-premise	concise-and-natural	similar-to-document	multi-aspect	novice	2025-05-12T23:56:45.148498	13	38	4309
