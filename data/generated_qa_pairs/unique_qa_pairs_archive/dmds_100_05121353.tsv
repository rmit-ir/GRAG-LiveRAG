qid	question	answer	context	document_ids	question_factuality	question_premise	question_phrasing	question_linguistic_variation	question_multi-doc	user_expertise-categorization	generation_timestamp	question_length	answer_length	context_length
1	traditional chinese medicine classification of food health effects dietary recommendations	Traditional Chinese medicine classifies foods according to their health effects. The Yellow Emperor's Inner Classic divides foods into four main groups: grains for nurturing qi, fruits for supporting qi, meats for increasing qi, and vegetables for completing qi. These should be combined with proper regard for their specific nature and unique tastes for optimal health benefits. The Chinese medicated diet approach prescribes special diets made from Chinese herbs, foods, and condiments, based on individual symptoms and conditions. This system emphasizes balanced combinations and appropriate cooking methods, avoiding dairy products and cold foods. Additionally, certain foods are believed to enhance specific abilities - for instance, grain consumption is associated with superior intelligence, while meat consumption is linked to bravery.	"['To Eat or Not? How Daoists Classify Food (1)\nLivia Kohn, PhD(1) From Livia Kohn, Daoist Dietetics: Food for Immortality (Dunedin, Fla.: Three Pines Press, 2010).\nIn traditional China, certain foods were seen to be conducive to certain abilities and connected to certain attitudes as expressed by different species. Thus, the Kongzi jiayu 孔子家語 (Kong Family Annals, 1st c. CE) says,\nThose who feed on water swim well and withstand cold.\nThose who feed on wood are strong but undisciplined.\nThose who feed on plants are good at walking but foolish.\nThose who feed on the mulberry are graceful and enterprising.\nThose who feed on meat are brave.\nThose who feed on qi are pure and long-lived.\nThose who feed on grains attain superior intelligence.\nThose who do not feed become divine and immortal.\n(Despeux 2007, 28)\nChinese medicine picks up the same idea and classifies food into four categories that serve different aspects of individual health. The Huangdi neijing suwen 黃帝內經素問(The Yellow Emperor’s Inner Classic: Simple Issues) has,\nPoisonous drugs are good for attacking wayward qi while the five grains will nurture [proper qi]. The five kinds of fruit support it, the five kinds of meat increase it, and the five kinds of vegetables complete it. As you combine these food groups with proper regard for their specific nature and their unique tastes and ingest them regularly, you supplement essence and enhance qi. (22.4)\nIn addition to drugs, this divides food stuffs into the four groups of grain, fruit, meat, and vegetables, each with a unique impact on qi-flow and health. All foods are seen as medically potent and understood in therapeutic terms, serving different aspects of the person and also different people within society. This is also obvious in the Han manuscript Wushier bingfang 五十二病方(52 Recipes for Diseases) which contains numerous concoctions that can just as easily be read as soup recipes (Harper 1998).\nDaoists similarly classify foods, focusing consciously on their potency for health and immortality. Although one will encounter drinking Daoists today, many historical sources are adamantly against the consumption of meat and wine. The Huangsu sishisi fangjing黃素四十四方經(Scripture of Forty-Four Methods of Yellow Simplicity), cited in the 7th-c. encyclopedia Sandong zhunang 三洞朱囊(Pearly Bag of the Three Caverns, DZ 1139), is one of the most radical:\nThe five kinds of meat are axes and hatchets that murder the organs. Wine and sex are inner and outer coffins that bury the body. Only if you eliminate the harm done by the axes, block the death represented by the coffins, and find inner restfulness can you walk on the path to long life and gradually follow the road to immortality. (4.5a)\nBefore that, the Taiping jing 太平經 (Scripture of Great Peace), classifies immortals according to food.\nQuestion: The upper, middle, and lower [immortals] who attain the Dao and go beyond the world—what do they eat?\nAnswer: Those of the first level absorb wind and qi; those of the second level ingest medicinal flavors; those of the third level eat little, reducing what passes through their stomach and intestines. (Campany 2005, 109)\nThis reflects the hierarchy of Daoists: those in the beginning stages eat vegetables and simple grains, digested in the normal way but supporting the balance of qi. More advanced ones supplement, and increasing replace, vegetables with concoctions or “herbal formulas” (yao 藥). Those moving closer to immortality eliminate all food and absorb qi, bypassing normal digestive processes to reorganize their internal system (Jackowicz 2006).\nThe same system is also, in some more detail, presented in the Laozi shuo Fashi jinjie jing 老子說法食禁戒經 (Prohibitions and Precepts on Ceremonial Food as Revealed by Laozi), a Tang-dynasty manual. It notes that “in high antiquity, people ate only primordial qi and managed to live for millions of years,” and states categorically that the highest form of eating—after not eating at all—is living on qi.\nBeyond that, however, the text ranks different kinds of food, placing the omnivore at the bottom, adding grains and mushrooms above the vegetable category, and redefining “herbal formulas” in terms of minerals:\nEating everything is not as good as eating vegetables. Eating vegetables is not as good as eating grains. Eating grains is not as good as eating mushrooms and tree fungi. Eating mushrooms and excrescences is not as good as eating gold and jade. Eating gold and jade is not as good as eating primordial qi. Eating primordial qi is not as good as not eating at all. By not eating at all, even though Heaven and Earth may collapse, one will survive forever. (Kohn 2004, 124-25)\nFollowing this, the text specifies five basic kinds of food: qi, herbal formulas, grain, fruits, and vegetables. Qi as a form of nourishment means practicing “healing exercises and embryo respiration,” as well as the Six Healing Breaths (see Despeux 2006). Herbal formulas include minerals and plants to “harmonize blood and body fluids, preserve and nourish body and spirit, calm the spirit soul and settle the will, and in general expel all wind and dampness, thus greatly enhancing life and extending old age” (Kohn 2004, 125).\nGrains include “corn, millet, hemp, wheat, wild and cultivated rice, as well as various kinds of beans,” useful for strengthening the organs, enhancing qi, and helping body harmony. The last two are fruits and vegetables: eat them in appropriate portions and well prepared. All these kinds of food make up “ceremonial food” (zhaishi 齋食), food eaten in Daoist institutions at the main meal before noon and shared ritually with donors, gods, and all beings.\nEating in the Daoist environment thus involves all kinds of foods used in Chinese dietetics, joining it in its exclusion of dairy products and cold foods, such as ice cream or sodas popular in the West. It follows the same principles as Chinese dietary therapy, selecting food combinations and cooking methods to balance the individual’s qi both in terms of personal tendencies and geographical or seasonal variants. Also like Chinese dietetics, Daoist cooking uses herbs and spices, selected for their qualities as much as for their taste, and emphasizes life-style basics, such as serenity of mind and moderation in sensory and culinary experiences.\nWhile building on a solid base of traditional Chinese dietetics and medicinal foods, Daoist eating also has its own peculiarities. For one, it favors the use of more subtle herbs and avoids highly heat-producing agents, such as garlic and onions. For another, it sees its goal as reaching beyond health and long life to a state of energetic and meditative transformation described as immortality. To this end, it encourages practitioners to reduce and eventually eliminate the ingestion of grains, replacing them increasingly with medicinal concoctions and breathing techniques. Ultimately Daoist eating becomes non-eating, the pure absorption of qi in accordance with the greater universe, the attainment of oneness with Dao and a subtler, more spiritual form of self-identity.\nCampany, Robert F. 2005. “Eating Better Than Gods and Ancestors.” In Of Tripod and Palate: Food, Politics and Religion in Traditional China, edited by Roel Sterckx, 96-122. New York: Palgrave MacMillan.\nDespeux, Catherine. 2006. “The Six Healing Breaths.” In Daoist Body Cultivation, edited by Livia Kohn, 37-67. Magdalena, NM: Three Pines Press.\n______. 2007. “Food Prohibitions in China.” The Lantern 4.1:22-32.\nHarper, Donald.. 1998. Early Chinese Medical Manuscripts: The Mawangdui Medical Manuscripts. London: Wellcome Asian Medical Monographs.\nJackowicz, Stephen. 2006. “Ingestion, Digestion, and Regestation: The Complexities of the Absorption of Qi.” In Daoist Body Cultivation, edited by Livia Kohn, 68-90. Magdalena, NM: Three Pines Press.\nKohn, Livia. 2004. Supplement to Cosmos and Community. Cambridge, Mass.: Three Pines Press. E-Dao Series (electronic publication).\nDr. Livia Kohn, is Professor Emerita of Religion and East Asian Studies at Boston University. A graduate of Bonn University, Germany, she has spent many years pursuing research on medieval Daoism and Chinese long life practices. She has written and edited over 25 books, taught many classes on Asian religions, and worked on a large variety of related projects. In addition, she has practiced taiji quan, qigong, meditation, yoga, and other cultivation methods for many years. These days, she lives on the Gulf Coast of Florida, and is a Daoist freelancer. She teaches workshops all over the world, runs international conferences on Daoist studies, and is executive editor at Three Pines Press and of the Journal of Daoist Studies. She has lived in Japan for a total of ten years and traveled widely in Asia, especially in China, Korea, and Thailand. Aside from her native German, she is fluent in Chinese and Japanese. To contact Professor Kohn, please e-mail email@example.com', 'Chinese Medicated Diet\nThe Chinese have a traditional belief in the medicinal value of food, as they believe that food and medicine share the same origin. This view could be considered a forerunner of nutritional science in China.\nChinese medicated diet is not a simple combination of food and Chinese herb, but a special highly finished diet made from Chinese herbs, food and condiments under the theoretical guidance of diet preparation based on differentiation of symptoms and signs of traditional Chinese medicine.\nChinese medicated diet has a long history. The ancient legend ""Shennong Tastes a Hundred Grasses ""shows that early in remote antiquity the Chinese nation began to explore the function of food and medicaments, hence the saying ""Traditional Chinese medicine and diet both originate from the practice and experience in daily life.""\nIn Shennong\'s Herbal Classic, which was published approximately in about the Qin and Han Periods and is the extant earliest monograph on materia medica, many sorts of medicaments which are both drugs and food were recorded, such as Chinese-date (Fructus Ziziphi Jujubae),sesame seed (Semen Sesami), Chinese yam (Rhizoma Dioscoreae), grape (Vitis), walnut kernel (Semen Fuglandis), lily bulb (Bulbus Lilii) , fresh ginger (Rhizoma Zingiberis Recens), Job\'s-tears seed (Semen Coicis), etc. in the East Han dynasty, some noted medicated diet recipes were recorded, such as Soup of Chinese Angelica root, Fresh ginger and Mutton (Danggui Shengjiang Yangrou Tang ), Decoction of Pig-skin (Zhufu Tang), etc., all of which now still have important values. Sun simiao, a well-known doctor in the Tang Dynasty, listed and discussed such questions as dietetic treatment, dietetic treatment for senile health care and health preservation.\nAccording to history books, up to the period of the Sui and Tang Dynasties about more than sixty kinds of books on dietetic treatment had been published. But unfortunately most of them are lost. Of all the prescriptions recorded in it, 70% are about medicated diet. It is emphasized in this book that ""dietetic therapy should go first for any senile diseases, and then followed by medicine if they are not cured."" Hu Sihui, a royal doctor in the Yuan Dynasty, oceans of medicated diet prescriptions and dietetic drugs were recorded; in addition, some questions, such as diet contraindication in pregnancy, diet contraindication for wet nurse, contraindication for drinking, etc. were also discussed in this book. In the Ming Dynasty, Li Shizhen collected and recorded many medicated diet prescriptions, dozens of which were about medicated gruel alone, another dozens touched on nothing other than medicated wine. Monographs on medicated diet treatment in the Qing Dynasty varied in characteristics. Over 300 species belonging to 7 phyla of medicated food and drink were introduced.\nMedicated diet can be used either to treat diseases or for healthy people to build up their health and prevent diseases. This is one of the characteristics in which medicated diet is different from treatment by medicine. Although medicated diet is something mild, it has a notable effect on the prevention and cure of diseases, health building -up and health preserving. Here are some of the achievements in scientific research of Shandong Traditional Chinese Medicine College:\nEight-Ingredient Food: It is prepared according to the experience in ancient dietetic treatment and health care of imperial court in the Qing Dynasty from eight dietetic Chinese drugs including Chinese yam (Rhizoma Dioscoreae), lotus seed (semen Nelumbinis), and hawthorn fruit (Fructus Crataegi). 97% of the children who took it for 30 days have whetted their appetite, and their growth has improved too.\nNourishing Extract of laiyang Pear and mushroom: It is made from the juice of Laiyang Pear (Malum Piri) and extract of mushrooms ( Lentinus Edodes) and tremella (Tremella). If the middle-aged and senile patients suffering from chronic diseases take it, not only can the symptoms of their illness be alleviated, but their blood-fat can be brought down too when they are suffering from hyperlipemia, and their immunology function can be improved.\nIt has not only the efficiency of medicine but also the delicacy of food, and can be used to prevent and cure diseases, build up one\'s health and prolong one\'s life.']"	['<urn:uuid:0af3a798-f98b-4546-9438-ce6b0005662d>', '<urn:uuid:be41f58a-1b9d-49d4-8a34-05a0a1b7b090>']	open-ended	direct	long-search-query	similar-to-document	three-doc	novice	2025-05-12T13:53:09.865574	10	118	2105
2	As an archaeologist interested in early human culture, I'd like to understand what are the physical characteristics of early stone tool artifacts, and how did their manufacturing techniques evolve over time?	"Early stone tools had distinct physical characteristics and showed evolution in manufacturing. The earliest Oldowan tools, from 2.5 million years ago, were made from hard water-worn volcanic creek cobbles and included core tools with flakes knocked off at one end, plus sharp-edged flakes used as knives. Later, by 1.8-1.5 million years ago, more sophisticated Acheulian tools emerged, featuring hand axes with elongated oval shapes, pointed ends, and sharp edges. These were made using both heavy hammerstones and later soft hammers (wood/antler/bone) for greater control in shaping. The manufacturing required precision grip, which only humans possessed among primates. Many tools also featured multiple indentations or pits of various sizes (from 1/16\"" to 6\""), with some showing evidence of rotary grinding in their formation."	"['Cupstones of Adair County, MO\nAdam Brooke Davis\nTruman State University\nDraft of 7-17-02\nVariously known as “cupstones,” “anvil stones,” “pitted cobbles” and “nutting stones,” among other names, these roughly discoidal or amorphous ground stone artifacts are among the most common lithic remains of Native American culture, especially in the Midwest, in Early Archaic contexts. They have received little study, perhaps because edged tools and weapons have more intrinsic interest to collectors, but closer study of them might reveal something of domestic practices and toolmaking technology.\nThe use of these items is unknown — although the ad hoc terminology implies function(s). Professor Betsy Delmonico of Truman State University has pointed out that very similar artifacts are known from the Indian subcontinent, often incorporated into clearly decorative and cultic objects, and the phenomenon has been observed in Celtic Europe and even in Australia and Israel. Some insist the items are “false” artifacts, that is, their form results from natural processes rather than human activity. However, no one has yet described processes that might both produce such effects and also explain the distribution of the effects and the objects. Certainly air-bubbles in stone, broken open and eroded, could produce some of these phenomena. The objects are familiar in Illinois, Ohio, Indiana, Arkansas, Kentucky, Tennessee, the Carolinas, Alabama and Mississippi, and occur elsewhere as well. Often they have been collected as oddities, and are found in residential rock-gardens. All of the stones pictured here were recovered from Adair County MO by Adam Brooke Davis, from private land, with permission, and none were in association with burials or sites of archaeological value.\nWhen not carried by natural forces into creekbeds, these objects are frequently surface-found on ridge-lines and at apparently random sites in the woods, frequently near streams and rock-shelters, suggesting a possible link to hunting, or with the combined activities of a seasonal hunting/gathering camp. Excavated specimens are associated with food-processing, including potsherds and food-remains. The author has found several near the remains of small and single-use fires, but the number of sites is insufficient to make a compelling case for the association. If used for mast-processing, one would expect the objects to be associated with relatively long-term occupation-sites. A camp-midden on the Chattahoochee River (http://www.cr.nps.gov/seac/benning-book/ch04.htm) yielded twelve specimens, along with grinding slabs and the hulls of acorns and hickory nuts, which were known in historic times to be prepared either as gruel or used to thicken soups. The pits may be adaptations for additional uses to implements primarily classifiable as other types, for example manos and metates. Interestingly, the only test using contemporary immunological analysis, carried out on a specimen from California, gave a positive result for trout residue alone (http://www.californiaprehistory.com/reports01/rep0015.html#anchorapp). Specimens found near Arkansas petroglyphs lead George Sabo III and Deborah Rowland Sabo of the Arkansas Archeological Survey to suggest the impressions were used to grind pigments for coloring rock art (http://rockart.uark.edu/whatisrockart.html).\nTwo uses not yet discussed include making fire by the bow and drill method, in which case a stone might have been used to anchor the upper end of the shaft, while a string, held taut with a bow and wrapped around the shaft, would provide rotary motion to create friction on a slab of wood on top of which tinder had been piled. Amateurish experiments have failed to demonstrate the principle, but the author makes no claim to fire-making skill under any circumstances. A few specimens show fire-marking, which may indicate that they served as the base-socket for the fire-drill, with tinder piled around the rotating shaft — or they may have found their way simply and accidentally into a fire. A much more comprehensive study, carefully correlating the closely observed features of these objects, is necessary.\nAnother possibility might be that the impressions provided a socket to hold the butt end of a shaft steady during peeling and straightening. The author has tested this hypothesis with a shaft-straightener or abrader found near one of the cupstones–\nand the method is at least practical. Larger indentations might have been used to steady spear-shafts. Multiple impressions might suggest communal, industrial manufacture of implements and weapons. Stones with multiple impressions of similar size, yet which would not be simultaneously accessible are difficult to explain. Most of the objects are of a size to be held in the hand, some as small as a walnut, but the writer has discovered one, left in situ in a stream bed, roughly a cubic meter of black rock entirely unlike any surrounding boulders, and weighing many hundreds of pounds. This is likely to be a cultic object of the sort discussed by U-MN anthropologist Kevin L. Callahan: Petroglyph Boulders and Sacred Stones of the Upper Midwest(http://www.geocities.com/Athens/Acropolis/5579/midwestboulders.html — the site includes a map of the distribution of these boulders throughout North America).\nThe pattern, size and number of concavities is not predictable, nor is material — impressions are found in soft sandstone and hard granite. Cupstones may exhibit a mixture of large and small indentations, perhaps indicating multiple uses over a considerable span of time. Indentations range from barely visible (1/16″ — much too small for any use thus far hypothesized) to 6″. In most cases the circumference of the impression will be roughly equal to the depth. Examination under magnification suggests the impressions were at least in some cases formed by rotary grinding. Typical impressions are of the simple pit type, though some cavities have been excavated to produce an opened-sphere type of pocket, by means and for reasons unknown — as in the specimen immediately below (4.5″ x 4″x3″; opening shown is .75″ across, widening to 1″ within). The object has another impression of equal width but only .25″ deep. It also shows signs of use on two faces for grinding against a slab, the scratches indicating both linear and rotary motions.\nA. approx. 13.5″ x 8″ x 6″, 28 lbs., 32 impressions of various depth, ranging from 1/16″ to1/2″\nB. 9″x7″x3″ This side is domed, and a flat, inclined surface may have been used for grinding or buffing. The cavity is 1.5″ wide; the reverse —\n— shows an incised trench leading to or from the cavity (1.75″), suggesting that some sort of fluid was channeled into or out of the cavity. Incised lines are not uncommon; a spedimen recovered from the Big Eddy site had over 300 such lines, perhaps for drainage and drying of wet material.\nC. 6″x 4″ x 2.5″ The cavity shown is 1″ deep. On the back of the stone (in relation to the angle of the photo) is a much shallower impression of approximately equal width.\nDA large, irregular block of weathered sandstone, very subject to fracture (though observation of edge-wear indicates none of the breaks are modern), 7″ x 7″ x 4″, 10 lbs. The dark spots to the left and right are connected in a sort of tunnel of varying width, incorporating a bend of about 100 degrees (the central dark spot is a trick of the light). The author speculates that it may have been used as a weight, perhaps to suspend provisions from a tree limb, out of reach of animals. It would make a practical anchor, though it was not found in a position likely ever to have been near water. The edges of the openings may show some slight degree of wear consistent with cordage. Below, the same stone shows a cluster of much smaller indentations (each about 1/4″). There is no reason but co-occurrence to assume a functional connection between the larger and smaller indentations.\nE. This object, broken on the side away from the camera in relatively recent times from some larger body (unrecovered), could well have been used for grinding nuts or pigments — the aperture is 1 7/8″ wide and a full inch in depth. It might well be a mortar.\nF. This flat specimen has fractured from some larger body, probably having originally had a bowl-shape. Again, the remnant, if any, was unrecovered; the author is not a trained archaeologist and does not dig for artifacts or remove them from undisturbed sites. The opening is 3.75″ across, one of the largest observed by the author. The original depth of the cavity is unknown; the relatively flat surface around the opening shows signs of grinding or hammering.\nHowever, the breakage did not necessarily end the object’s useful life. The specimen below (G) is similarly broken at some layer of material weakness from a larger body, and on the smooth, upper side, there is a single impression. But on the opposite side, the rough portion originally inside the stone, later activity has added a second cavity, connected at a tangent with the first so as to make some sort of straining activity possible (shown a second time with contrast enhanced); a very small pit (1/8″) is visible in the lower left quadrant, and a yet smaller one (1/32″) about 1/4″ inch to the right of the largest hole, in a line with the other two:\nBoth of the large indentations are of the spheroid type. On the side away from the camera, the rim of the single large opening is worn, and within the worn orbit are a number of pits so small as to be visible only under oblique light, and near the edge of the stone, another pit, drilled from a different direction, of 1/4″.\nConclusion: function and terminology\nThe most likely interpretation seems that these artifacts represent a single technique of shaping or adapting stone for multiple purposes, some unguessed (for instance, the function of the smallest pits) and that the objects could be used by single or multiple individuals over long periods of time, and for various purposes. Indeed, the apparent randomness of their distribution may indicate that they were left lying as modified natural resources, whether with benevolent intent or because they did not represent a sufficient investment of time and labor to justify transporting them (“opportunistic” tools). More simply, perhaps the users intended to return to the same area during the next year’s mast-gathering period. The now traditional term “nutting stone” may be justified, as may “straightening stone” or “shaft-anchor” within a larger class we might call “poculoliths,” (<L. poculus, “small pocket,” “cup”). While an equivalent to “pitted stone,” the proposed term has the advantage of wider comprehensibility among international scholars as the worldwide distribution of the form becomes increasingly evident.\nLinks and information on poculoliths:\nPublications and scholarship:\nA professional study of coastal California specimens:http://www.californiaprehistory.com/reports01/rep0015.html\nFountain. “Cupped or Pitted Stones” The Archaeological Society of New Jersey Bulletin#52 1997 (113 pp.) — $10.00 at http://home.earthlink.net/~glattanzi/asnj/back-issues.html\nPeacock, Evan 1989 “Microdebitage from Cached Pitted Stones.” Mississippi Archaeology 24(2):17-27.\nPyle, Robert L., “Mysterious Cupstones: A Secret of the Past,” Wonderful West Virginia,July 1985\nRitchie, William A. Hammerstones, Anvils and Certain Pitted Stones (1929). Rpt. From Coyote Press (http://www.coyotepress.com/page27.html)\nWatts, Steve. “The Nutting Stone” The Bulletin of Primitive Technology Spring 1997 (The Society of Primitive Technology: SPT Bulletin #13: Foods and Cooking). Available athttp://www.primitive.org/backissues.htm\n- Witthoft. “Pitted Stones and Cup-Shaped Markings.” Publications of the Archaeological Society of Maryland. Volume 5, #2 (September 1969).\nImages and commentary on the web:\nA specimen found in Caithness, Scotland:http://www.caithness.org/caithnessfieldclub/outings/broubsteraug2000/\nDiscussion of a find near Jerusalem, with commentary on the possibility — highly controversial — that chimpanzees also engage in such activity, maintaining toolkits of suitable nutting stones over time.\nSee also Goren-Inbar, N., et al. 2002. “Nuts, nut cracking, and pitted stones at Gesher Benot, Ya’aqov, Israel.” Proceedings of the National Academy of Sciences 99(Feb. 19):2455-2460. Abstract available at http://www.pnas.org/cgi/content/abstract/99/4/2455.\nExamples of central Texas stones associated with pestles. Dealer/owner believes the pattern of impressions on some of these stones is explained by gripping-points for fingers and thumb.\nAn impressive multi-pitted specimen from Indiana.\nDiagram of a Connecticut specimen.\n“In many parts of the world this type of artifact is usually associated with fall occupations.”\nPhoto of a Massachusetts specimen:http://www.memorialhall.mass.edu/collection/itempage.jsp?itemid=5243&img=0\nAn unusual, squared specimen from Madison Co. MS:http://home.att.net/~wjvd3/artpage25.html#Nutting stone', 'Early Human Culture\nParalleling the biological evolution of early humans was the development of cultural technologies that allowed them to become increasingly successful at acquiring food and surviving predators. The evidence for this evolution in culture can be seen especially in three innovations:\n1. the creation and use of tools 2. new subsistence patterns 3. the occupation of new environmental zones\nSome chimpanzee communities are known to use stone and wood as hammers to crack nuts and as crude ineffective weapons in hunting small animals, including monkeys. However, they rarely shape their tools in a systematic way to increase efficiency. The most sophisticated chimpanzee tools are small, slender tree branches from which they strip off the leaves. These twigs are then used as probes for some of their favorite foods--termites and ants. More rarely, chimpanzees have been observed using sticks as short thrusting spears to hunt gallagos in holes and crevices of trees where they sleep during the day time. It is likely that the australopithecines were at least this sophisticated in their simple tool use.\nOldowan tradition core tool (chopper)\nThe first unquestionable stone tools were evidently made and used by early transitional humans and possibly Australopithecus garhi in East Africa about 2.5 million years ago. While the earliest sites with these tools are from the Gona River Region of Ethiopia, simple tools of this kind were first discovered by Mary and Louis Leakey associated with Homo habilis at Olduvai Gorge in Tanzania. Hence, they were named Oldowan tools after that location. These early toolmakers were selective in choosing particular rock materials for their artifacts. They usually chose hard water-worn creek cobbles made out of volcanic rock.\nThere were two main categories of tools in the Oldowan tradition. There were stone cobbles with several flakes knocked off usually at one end by heavy glancing percussion blows from another rock used as a hammer. This produced a jagged, chopping or cleaver-like implement that fit easily in the hand. These core tools most likely functioned as multipurpose hammering, chopping, and digging implements. Efficient use of this percussion flaking technique requires a strong precision grip. Humans are the only living primates that have this anatomical trait. Probably the most important tools in the Oldowan tradition were sharp-edged stone flakes produced in the process of making the core tools. These simple flake tools were used without further modification as knives. They would have been essential for butchering large animals, because human teeth and fingers are totally inadequate for cutting through thick skins and slicing off pieces of meat. Evidence of their use in this manner can be seen in cut marks that still are visible on bones. Some paleoanthropologists have suggested that the core tools were, in fact, only sources for the flake tools and that the cores had little other use.\nA Handy Bunch: Tools, Thumbs Helped Us Thrive--audio recording of an NPR interview with\nanthropologists Erin Williams and Dennis Sandgathe concerning the relationship between stone tool\nmaking and the evolution of the human hand. This link takes you to an external website. To return\nhere, you must click the ""back"" button on your browser program. (length = 7 mins, 46 secs)\nIn addition to stone tools, Homo habilis probably made simple implements out of wood and other highly perishable materials that have not survived. In the 1940\'s, Raymond Dart suggested that australopithecines and early humans also used the hard body parts of animals as clubs, daggers, and other sorts of weapons. Dart proposed an entire tool making tradition which he named osteodontokeratic , based on the presumed use of bones (osteo), teeth (donto), and horns (keratic). This idea has been rejected by most paleoanthropologists today since there is a lack of evidence for the systematic shaping or even use of these materials for weapons or other types of tools at this early time. In addition, it is unlikely that the earliest humans were aggressive hunters. They most likely were primarily vegetarians who occasionally ate meat that was mostly scavenged from the leftovers of kills abandoned by lions, leopards, and other large predators. At times, they also may have hunted monkeys and other small game much as chimpanzees do today.\nHomo habilis made and used stone tools in the Oldowan tradition for nearly a million years but with gradual improvements over time. The early Homo erectus also used what could be described as advanced or evolved Oldowan tool making techniques. By 1.8 million years ago, the skills of some Homo erectus had increased to the point that they were making more sophisticated stone implements with sharper and straighter edges. Their tool kits were sufficiently advanced by 1.5 million years ago to consider them to be a new tool making tradition now referred to as Acheulian . It was named after the Saint Acheul site in southwest France where these kinds of tools had been discovered in the 19th century. However, the Acheulian tool making tradition was first developed in East Africa. Perhaps, the most important of the Acheulian tools were hand axes. They are rock cores or very large flakes that have been systematically worked by percussion flaking to an elongated oval shape with one pointed end and sharp edges on the sides. Since they were shaped on both faces, they are also referred to as biface tools. In profile, hand axes usually had a relatively symmetrical teardrop or broad leaf shape. Referring to these artifacts as hand axes may be misleading since we do not know for sure whether they were primarily axes in a modern sense or even if they were held in the hand. Based on tool edge wear patterns and the brittle fracturing lithic materials that were used to make them, it is likely that hand axes were multipurpose implements used for light chopping of wood, digging up roots and bulbs, butchering animals, and cracking nuts and small bones. In a sense, they were the Swiss Army knives of their times. They were reusable portable tools intended to be carried from place to place rather than made each time they were needed.\nAcheulian bifaces (hand axes)--the earliest known bilaterally symmetrical tools\nSome of the Acheulian tools were shaped by additional percussion flaking to relatively standardized forms. For instance, the surfaces of late Acheulian hand axes often had many relatively small flake scars, suggesting that these tools were not completely made with heavy hammerstones. Late Homo erectus or their immediate successors must have begun using softer hammers for greater control in the final shaping process. Pieces of hard wood, antler, or bone would have functioned well for this purpose.\nPercussion Flaking Techniques: hard hammer (left) and soft hammer (right)\nWhile hand axes are the most diagnostic of Acheulian tools, they usually make up only a small percentage of the artifacts found at Homo erectus sites. In fact, these early humans made a relatively wide variety of stone tools that were used for processing various plant and animal materials. Their tool kits included choppers, cleavers, and hammers as well as flakes used as knives and scrapers. It is quite likely that Homo erectus also made many implements out of more perishable materials such as wood, bark, and even grass, which can be easily twisted together to make string and rope.\nThe Acheulian tradition of tool making apparently began in East and South Africa by 1.5 million years ago. It spread into Israel and probably other parts of Southwest Asia by 1.4 million years ago. However, not all early Homo erectus leaving Africa had Acheulian tools. Apparently, some only had the older Oldowan tradition. Acheulian tool making reached Europe by at least 500,000 years ago and possibly as early as 900,000 years ago. Until recently, the lack of hand axes at Zhoukoudian and other East Asian Homo erectus sites suggested that the Acheulian tradition did not reach that far. It was thought likely that the same functions that hand axes performed in the west were being performed in the Far East by other kinds of tools, perhaps made of bamboo. However, 24 sites in southern China have now been found to contain Acheulian tools dating back about 800,000 years. There remains controversy as to whether they include true hand axes.\nThroughout most of the Homo erectus geographic range, there is clear evidence of progressive improvement in tool making over time. The late Homo erectus had more complex mental templates guiding them in the manufacture of their artifacts. In addition, the reliance on tools increased as the implements became more useful. By half a million years ago, major Homo erectus habitation sites commonly had tens of thousands of discarded stone tools.\nNew Subsistence Patterns\nAnthropologists use the term subsistence pattern, or subsistence base, to refer to sources of food and the way it is obtained. A clear measure of success in human evolution has been the progressive development of new food getting techniques and the inclusion of new food sources. These measures have made it possible for humanity to increase in numbers from a few thousand australopithecines in Africa three million years ago to perhaps hundreds of thousands of Homo erectus by a half million years ago. This trend of expanding and diversifying subsistence patterns making it possible for population growth continues to the present. In fact, it accelerated dramatically two centuries ago and is largely responsible for our burgeoning world population of seven billion people today. Our modern hybridization and genetic modification of food crops and farm animals is just the latest human attempt to solve this recurring problem.\nBased on the analysis of tooth wear patterns and food refuse evidence, it is likely that australopithecines and early transitional humans were primarily wild plant food collectors and occasional scavengers of meat and eggs. By the time of Homo erectus, small game hunting and large animal carcass scavenging were apparently becoming much more common. The evidence of this change in subsistence pattern can be seen especially at late Homo erectus sites such as Zhoukoudian. Literally tens of thousands of fragmentary food refuse bones were found there. They came from pigs, sheep, rhinoceros, buffalo, and especially deer. In addition, there were large numbers of bones from small animals including birds, turtles, rabbits, rodents, and fish as well as the shells of oysters, limpets, and mussels. Some of these bones ended up in the cave at Zhoukoudian as a result of large carnivorous animals rather than humans, but there is sufficient evidence to suggest that by a half million years ago, some Homo erectus were exploiting virtually every animal in their environment for food. They undoubtedly were harvesting vast amounts of wild plant foods as well. It would be a mistake to assume that Homo erectus had become an efficient specialized big game hunter. That development did not occur until more advanced forms of humans had evolved, several hundred thousand years later.\nOccupation of New Environmental Zones\nHomo erectus was the first species in our line of evolution to expand their range beyond tropical and subtropical environments into temperate climatic zones of the Old World where they encountered relatively cold winters. This occurred by at least a half million years ago in Asia and evidently a few hundred thousand years earlier in Southern Europe. It was made possible mainly by the success of new inventions and new subsistence strategies. The most important change may have been increased meat consumption as a result of hunting and more successful scavenging. The greatest difficulty living in temperate areas was probably not the cold weather but obtaining something to eat during the winter when fresh plant foods are scarce. It is in that season that meat would have been the most important calorie source.\nThe ability to use fire for cooking and heating may also have been significant in the successful colonization of colder regions. However, the first convincing evidence of regular fire use for these purposes does not come until 780,000-400,000 years ago, when Homo erectus were evolving into Homo heidelbergensis . The earliest suggestive evidence of fire being associated with humans was found at two sites in Kenya dating to 1.5 million years ago. In both cases, soil sediments appear to have been exposed to high temperatures. However, it is not necessary to assume that early humans were responsible. The burned soil could have resulted naturally from lightning started wild fires that are common in the grasslands of East Africa even today. Similar questionable evidence has been found in South Africa dating to about 1,000,000 years ago. There is no convincing evidence of human control of fire at this early time. A 790,000 year old site in Israel has more credible evidence, though there does not seem to have been any cooking or repeated fire creation. The first reasonably good evidence of cooking is in the form of burned bones and fire altered stones at the Chinese site of Zhoukoudian dating sometime between 780,000 and 400,000 years ago. All of these sites in Africa and Asia with uncertain fire use indications presumably would have been occupied by Homo erectus. We have no evidence as to how Homo erectus might have obtained fire or even if they had the ability to create it at will.\nThe cultural developments of Homo erectus essentially began a new phase of our evolution--one in which natural selection was altered by cultural inventions. This has been referred to as biocultural evolution. Culture can affect the direction of human evolution by creating non-biological solutions to environmental challenges. This potentially reduces the need to evolve genetic responses to the challenges. Normally, when animals move into new environmental zones, natural selection, operating on random mutations, causes evolution. In other words, the population\'s gene pool is altered as a result of adapting to a new environment. When late Homo erectus moved into temperate environments, nature should have selected for biological adaptations that were more suited to cooler climates. Such things as increased amounts of insulating body fat and insulating hair covering most of the body would be expected. Homo erectus evidently achieved much of the same adaptation by occupying caves, using fires, and becoming more capable at obtaining meat. By using their intelligence and accumulated knowledge, they remained essentially tropical animals despite the fact that they were no longer living only in the tropics. However, natural selection continued to select for increased brain size and presumably intelligence. This pattern of culture altering natural selection accelerated dramatically with the evolution of modern humans. Today, most of us live in cities and towns that are essentially unnatural environments and the rate of culture change has accelerated dramatically. We have occupied most environmental zones on land, and yet we are still essentially tropical animals physically. As a result, we perish rapidly if our cultural technology is taken away from us in environments in which the temperature drops to freezing.\nBecoming Human: Part 2--Nova episode on the biological and cultural\nevolution of Homo erectus. To return here, you must click the ""back""\nbutton on your browser program. (length = 51 mins 27 secs)\n© 1999-2012 by Dennis']"	['<urn:uuid:976d8c07-8510-4d8c-8bf7-fdc00e93be97>', '<urn:uuid:d9daef6b-49ed-450b-a11e-cf53bb464932>']	factoid	with-premise	verbose-and-natural	similar-to-document	multi-aspect	expert	2025-05-12T13:53:09.865574	31	122	4496
3	As a neuroscientist, I wonder: how do memory engram cells compare with island cells?	Memory engram cells and island cells serve different functions in memory processing. Memory engram cells are populations of neurons in the hippocampus that are activated during memory formation and undergo lasting physical or chemical changes. They can be triggered by specific stimuli like sights or smells and are involved in converting information from short-term to long-term memory. In contrast, island cells are excitatory neurons found in layer 2 of the entorhinal cortex that form circular clusters. They function by stimulating inhibitory neurons in the CA1 region that suppress memory associations between temporally separated events.	"['In a feat that calls to mind the memory-tweaking technology in the film ""Eternal Sunshine of the Spotless Mind,"" a team of researchers restored ""lost memories"" in the brains of mice.\nThe mice in the study were given a drug that prevented them from consolidating a fearful memory. But when neurons involved in encoding the memory were stimulated with pulses of light, the animals were able to retrieve the forgotten recollection.\nIn some forms of amnesia, past memories may not be erased, but may just be inaccessible for recall, said Susumu Tonegawa, director of the RIKEN Brain Science Institute in Japan and co-author of the study, said in a statement. The study was published today (May 28) in the journal Science. [5 Wild Facts About Your Memory]\nIf the findings are confirmed in humans, the knowledge could benefit people who suffer from retrograde amnesia, an inability to recall memories that were made before the amnesia, which is common in traumatic brain injury, Alzheimer\'s disease and other brain disorders.\nScientists have long debated whether retrograde amnesia results from damage to the neurons that store memories, or from a blockage of access to those memories. The majority of researchers support the storage problem theory, but this is ""probably wrong,"" Tonegawa said.\nWhen a memory is being formed, scientists think a population of neurons is activated and undergoes lasting physical or chemical changes. This collection of neurons is known as memory engram cells, and they can be triggered by a specific sight or smell, for instance.\nIn 2012, Tonegawa and his colleagues showed that a population of these engram cells exists in a brain region called the hippocampus, which is known to be involved in converting information from short-term to long-term memory. But, it wasn\'t clear if these groups of neurons undergo the chemical changes linked to memory consolidation.\nIn the new study, Tonegawa\'s team pinpointed a group of engram cells in the hippocampus of mice, using a technology called optogenetics. The technique involves injecting a virus into neurons that causes them to produce a light-sensitive protein, which makes the cells activate in response to light.\nThe researchers put mice in a chamber where they received a mild electric shock, and the animals quickly learned to associate the shock with the chamber. When the mice were returned to the same chamber a day later, they would freeze in fear.\nAfter the training, the scientists gave some of the mice a chemical called anisomycin, which inhibits memory consolidation. When the mice were placed in the chamber again, they no longer froze in place, suggesting the memory of the painful shock had not been consolidated.\nHowever, when the researchers used pulses of light to activate the neurons that encoded the electric shock memory, the mice would ""remember"" their fear, and freeze again when placed in the chamber.\nThe findings suggest that in the mice that received the memory-blocking drug, the fearful memory was not really ""lost,"" but rather access to the memory was simply blocked, the researchers said.\n""These findings are probably applicable to certain conditions of human amnesia, such as an early stage of some Alzheimer\'s patients,"" Tonegawa said.\n- 6 Fun Ways to Sharpen Your Memory\n- Top 10 Mysteries of the Mind\n- 7 Ways the Mind and Body Change With Age\nCopyright 2015 LiveScience, a Purch company. All rights reserved. This material may not be published, broadcast, rewritten or redistributed.', 'Suppose you heard the sound of skidding tires, followed by a car crash. The next time you heard such a skid, you might cringe in fear, expecting a crash to follow—suggesting that somehow, your brain had linked those two memories so that a fairly innocuous sound provokes dread.\nMIT neuroscientists have now discovered how two neural circuits in the brain work together to control the formation of such time-linked memories. This is a critical ability that helps the brain to determine when it needs to take action to defend against a potential threat, says Susumu Tonegawa, the Picower Professor of Biology and Neuroscience and senior author of a paper describing the findings in the Jan. 23 issue of Science.\n""It\'s important for us to be able to associate things that happen with some temporal gap,"" says Tonegawa, who is a member of MIT\'s Picower Institute for Learning and Memory. ""For animals it is very useful to know what events they should associate, and what not to associate.""\nThe interaction of these two circuits allows the brain to maintain a balance between becoming too easily paralyzed with fear and being too careless, which could result in being caught off guard by a predator or other threat.\nThe paper\'s lead authors are Picower Institute postdocs Takashi Kitamura and Michele Pignatelli.\nMemories of events, known as episodic memories, always contain three elements—what, where, and when. Those memories are created in a brain structure called the hippocampus, which must coordinate each of these three elements.\nTo form episodic memories, the hippocampus also communicates with the region of the cerebral cortex just outside the hippocampus, known as the entorhinal cortex. The entorhinal cortex, which has several layers, receives sensory information, such as sights and sounds, from sensory processing areas of the brain and sends the information on to the hippocampus.\nPrevious research has revealed a great deal about how the brain links the place and object components of memory. Certain neurons in the hippocampus, known as place cells, are specialized to fire when an animal is in a specific location, and also when the animal is remembering that location. However, when it comes to associating objects and time, ""our understanding has fallen behind,"" Tonegawa says. ""Something is known, but relatively little compared to the object-place mechanism.""\nThe new Science paper builds on a 2011 study from Tonegawa\'s lab in which he identified a brain circuit necessary for mice to link memories of two events—a tone and a mild electric shock—that occur up to 20 seconds apart. This circuit connects layer 3 of the entorhinal cortex to the CA1 region of the hippocampus. When that circuit, known as the monosynaptic circuit, was disrupted, the animals did not learn to fear the tone.\nIn the new paper, the researchers report the discovery of a previously unknown circuit that suppresses the monosynaptic circuit. This signal originates in a type of excitatory neurons discovered in Tonegawa\'s lab, dubbed ""island cells"" because they form circular clusters within layer 2. Those cells stimulate inhibitory neurons in CA1 that suppress the set of excitatory CA1 neurons that are activated by the monosynaptic circuit.\nThe researchers used optogenetics, a technology that allows specific populations of neurons to be turned on or off with light, to demonstrate the interplay of these two circuits.\nIn normal mice, the maximum time gap between events that can be linked is about 20 seconds, but the researchers could lengthen that period by either boosting activity of layer 3 cells or suppressing layer 2 island cells. Conversely, they could shorten the window of opportunity by inhibiting layer 3 cells or stimulating input from layer 2 island cells, which both result in turning down CA1 activity.\nThe researchers hypothesize that prolonged CA1 activity keeps the memory of the tone alive long enough so that it is still present when the shock takes place, allowing the two memories to be linked. They are now investigating whether CA1 neurons remain active throughout the entire gap between events.\nMore information: ""Island Cells Control Temporal Association Memory"" Science, 2014.']"	['<urn:uuid:8d66acee-0287-4e97-9e75-bfefe2033724>', '<urn:uuid:c54fd642-8448-4525-b98a-bc66aa779daf>']	open-ended	with-premise	concise-and-natural	distant-from-document	comparison	expert	2025-05-12T13:53:09.865574	14	94	1244
4	marble walls vs floors different uses maintenance requirements	While marble is excellent for wall applications where it creates dramatic visual impact without much wear, it's less practical for floors, especially in high-traffic areas. Walls don't require much maintenance since they aren't touched frequently, but marble floors need annual professional refinishing to maintain shine. For floors, marble is particularly problematic in wet areas as it becomes dangerously slippery and is prone to scratching, chipping, and cracking from heavy objects.	['Natural Stone Is Going Big and Bold in Interiors\nNatural stone is going big. Homeowners are asking for stone to be used on vertical surfaces indoors, especially slabs among high-end design projects, to make a bold design statement. New natural stone options are making it easier for homeowners to get creative.\nDesigners are starting to see natural stone used in new and refreshing applications. “We are noticing an increase in demand for the use of stone throughout people’s homes,” says Alyssa Bockman, design consultant with Stoneshop. “Even just in countertop applications, more customers are asking for waterfall panels and edge treatments to enhance the thickness and really create a ‘wow’ factor.” Wall applications, she says, have definitely become a trend.\nRebekah Zaveloff, co-founder and director of design of KitchenLab Design, also sees the trend for big and bold stone applications. Full-height marble or quartzite backsplashes and fireplace surrounds are trending, and slab materials are being used to wrap the inside frames of showers and niches on walls inside and outside the bathroom, she says.\nWhy are homeowners suddenly starting to go big with their natural stone applications?\nHomeowners are beginning to appreciate the texture and dimension in stone, which is part of the reason Brock Mettz, owner and lead designer at Brock Lane Mettz Design, believes clients are asking to use very large format stone in projects. For many clients, bigger means better. “This leads to the beauty of the stone speaking for itself and acting as the decoration, instead of having to add extraneous decorative elements into the design,” he says.\nMettz especially loves seeing manufacturers take a stone that they’ve been using in the industry for years, and then cut it from the stone block in an atypical fashion. “Depending on how the stone is cut from the large stone blocks, veins can be accentuated and new colors may pop that would have previously gone unnoticed,” he notes.\nWhen working with such large pieces, color matters. Sometimes it means you need to work with the color of the slab or what surrounds it. In most cases, designers will advise clients to consider the long-term decision of both color choices and the type of natural stone being used in a particular project. Choosing natural stone based solely on its color because it’s trendy isn’t something designers often recommend.\nWhen clients ask Zaveloff about color choices, she encourages them to stick with what’s timeless. Other colors in the room, such as paint color, are much easier to change.\nLauren Coburn, owner of Lauren Coburn, LLC, specializes in high-end residential interior design as well as interior architectural consulting, notes that when choosing natural stone, homeowners are making a big financial investment. “Choose a stone that can work with a bold color you like now, but one that will also work with more neutral colors down the line, should you choose to change the paint or wallcovering,” she says.\nMore Options to Go Bold with Natural Stone\nWhat’s even more exciting when it comes to color and design trends and natural stone is that people have more options to get creative.\n“There are entire cladding collections that offer various shapes, dimensions and textures,” says Mettz. “These dimensional and textured stones are excellent tools to create focal points and the offer seamless connection between inside and outside.”\nBockman is intrigued by all of the finishes being applied to stone. “They are introducing new options such as leathered, antiqued, flamed, and acid washed finishes to more and more stones,” she notes. “These finishes add another textured element to stone to create a more unique finished product in your home.”\nZaveloff notices people aren’t as afraid to use marble as they used to be. “When they ask about etching, staining, or chipping, I cite the use of marble in Italy, Spain, France, and all over Europe in public squares, roads, fountains, walls, buildings and inside,” she says. “People are becoming less obsessed with perfect and more open to patina.”\nCoburn adds that with more options, clients are also realizing there are endless ways to use stone on walls. Since these are areas that aren’t being touched a lot, more exotic and less practical materials can be used on them.\n“I think using stone on a wall can provide one of the most dramatic statements in creating an interesting focal point when entering a room,” says Coburn. “There are now many more interesting natural stone tiles and slabs being used on walls for aesthetic impact. They can take a room far in terms of the visual effect it has on the user.”\nCoburn notes that making a bold statement isn’t restricted to a foyer or main living area. It can take place in a room like a master bath. Taking stone all the way up the walls in a room like a master bath can create a high-end ambiance without it feeling heavy or overwhelming, if the right stone is integrated into the project.', 'Marble is a natural stone used in a variety of applications around the home. From tiling to walls, to countertops and splashbacks, marble is a premium material that gives your residence a unique and classy look. This natural stone forms when other sedimentary materials, such as limestone, experience heat and pressure. The result of this process is a harder stone, with beautiful veined patterns and colours.\nMarble suits any room in the home. However, this natural stone is soft, and it tends to chip and crack if you drop heavy objects on the surface of the tiles. Replacing marble tiles is costly, and you may have to lift the entire floor to repair the damage. If you drop a cast-iron pan on the tiles, you may chip multiple tiles, resulting in a costly replacement expense.\nIt’s for this reason that we don’t recommend marble tiles for kitchen floors, and prefer porcelain ceramics for this area of the house. However, marble tiles make fantastic splashbacks for the kitchen, and they’re great for walls tiles as well.\nAs mentioned, marble is a soft natural stone that’s prone to chipping, cracking and breaks. The best way to prevent damage to your marble floor is to ensure you use a professional installation service for fitment. Any gaps that remain between the subfloor and tiles creates weak points that are prone to cracking and breaks. However, if installed professionally, marble tile flooring is reasonably durable and robust, and it suits low-traffic areas in the home such as the lounge, dining room and libraries or conservatories.\nPolished marble tiles have a dangerously slippery surface when wet. However, marble flooring in the bathroom looks exquisite, providing a luxurious feel to the bathroom. We don’t recommend marble floors for seniors or parents with young children, as the surface increases the risk of a slip-and-fall.\nThe hard surface of the floor tiles may also cause injury during the event of a slip-and-fall, which may lead to broken bones or damaged joints. However, if you own a contemporary home, and you have no children or seniors living on the premises, marble is an excellent option. We recommend that you use non-slip mats around the shower, bath and sinks to prevent slips.\nWhen installed professionally and maintained, your new marble flooring will last a lifetime. However, this natural stone is somewhat soft, meaning that it may scratch easily. If you drag furniture on a marble floor, and debris like sand becomes trapped under the feet of the couch while moving, it may result in scratches.\nYou may be able to fill and polish out the scratches, but in some cases, the damage is permanent and requires a costly replacement. Marble needs refinishing annually by a trained professional to maintain its shine and lustre.\nMarble is one of the most expensive materials available. While the price of a set of marble tiles may seem affordable when you consider the trade-off between aesthetics and the cost, you need to take into account the fitment fees as well.\nInstallation and fitment of marble tiles can add up to more than the tiles themselves, and you’ll also need to take into account the maintenance fees for refinishing the floors each year. Marble deposits around the world are at all-time lows, and we expect the price of this premium material to soar in the coming years as supplies dwindle.\nMarble tiling is some of the most expensive architectural material available for your home. If you’re thinking about installing marble, you can expect to pay between £53.21/m2 and £65.36/m2, depending on the grade.\nFitment may end up costing you more than the tiles, depending on the surface area you need to cover. Marble is dense and delicate, and the last thing you want is for the tiles to chip or break when fitting them yourself. Using a professional, guaranteed, fitment service ensures that your new marble flooring will last for a lifetime.\nMarble is a scarce material, and deposits around the globe are running low on available stock for purchase by tiling manufacturers. The cost of excavating it from the quarry, cutting, and polishing adds to the production costs, which manufacturers pass on to the public. Some types of marble are more expensive than others, with Calacatta or Statuario marble tiles being far more costly than Carrara.\nMarble is a scarcer material than granite and has a higher demand for luxury décor. Granite is a durable and attractive material, with similar properties to marble, but it has a much harder surface that is challenging to scratch, even with knives.\nMarble can retail for around 40-per cent more than granite, but granite slabs with distinctive and unique colouring may fetch a higher price than Carrara marble.\nMost marble floor tiles measure 1-cm in thickness, and they come in sizes of 600mm x 600mm, or 593mm x 593mm.\nQuartz is another natural stone that looks fantastic around the home. Manufacturers crush quartz stone and combine it with a polymer resin to form the tiles. This manufacturing technique is different when compared to marble cut from a slab.\nQuartz is an affordable material when compared to other similar natural stones, such as marble and granite. However, it lacks the veining that makes every marble tile unique. If you’re looking to tile an upmarket, contemporary home, we suggest that you go with marble for the low-traffic areas, and use quartz for the high-traffic areas. The quartz will stand up to the abuse of wear and tear far better than marble.\nWhen cleaning your marble tiles, avoid the use of vinegar, bleach, and ammonia on the tiles. These cleaners can etch the surface of the tiles, leaving the marble looking lifeless and dull. Strangely enough, most commercially available household cleaners are not suitable for cleaning marble tiles either.\nMake sure that you don’t use any abrasive pads or cleaners on your tiles, as the rough bristles may scratch the surface. We recommend you look for professional marble cleaning products available on the Atlas Ceramics website.\nTreated and polished marble tiles are somewhat water-resistant, but you should clean up any spills as soon as possible to avoid permeation of liquids into the stone.\nLeaving water or other liquids on marble tiles overnight may result in staining and discolouration.\nIn our experience, we find that using hot distilled water provides the best shine for your tiles. Adding some specialist cleaner to the water helps to remove dirt and grime, bringing your tiles back to their original glory. Use a soft mop to clean the floor, and then buff it with a micro-fibre broom after cleaning to bring out the shine.\nWe recommend you use sealed marble tiles on areas in the bathroom and kitchen where moisture is a concern. While sealing your marble will not waterproof it 100-per cent, it provides you with a safeguard while you clean the affected area.\nCart has been replaced']	['<urn:uuid:13a641bc-8f34-46ee-b8a3-cb7a541bc98c>', '<urn:uuid:9a31293a-682c-4ae3-bf81-e7c184f00aaa>']	factoid	direct	long-search-query	similar-to-document	multi-aspect	expert	2025-05-12T13:53:09.865574	8	70	1979
5	How deep is the metro tunnel construction, and what safety equipment is required?	The metro tunnel construction occurs at a depth of 20 metres where TBMs are lowered. For safety during such construction work, workers on platforms must use railings, safety belts, and life lines to protect against falling. Additionally, proper eye protection including helmets with shields and goggles are required for welding operations.	"['- Urban Transportation\n- 3 min read\nPatna underground: Stage set for TBMs to create metro rail route\nPreparation is going on in full swing to launch the first tunnel boring machines (TBM)s for the construction of twin tunnels under Corridor II (Patna station-Patliputra Bus Terminal) of the Patna metro rail project. The Delhi Metro Rail Corporation Limited (DMRC) is planning to start underground tunnel construction of phase I from Moin-ul-Haq Stadium in the first week of March.\nA launching shaft has been prepared at a depth of 20 metres where the TBMs will be lowered to start digging holes for the twin tunnels, at a distance of 1-metre apart. The machines will be retrieved from Gandhi Maidan after construction of downline tunnel from Moin-ul-Haq Stadium to SK Memorial Hall, where retrieval shaft will be prepared. These shafts would eventually be integrated into the station itself.\nAccording to officials, the underground tunnel work between Rajendra Nagar to Patna Junction of Corridor II has been divided into phases. ""In the first phase, the TBMs will construct a 3.6-metre-long tunnel between Moin-ul-Haq Stadium and SK Memorial Hall. A launching shaft has been prepared and the launch will be held before Holi. Both the machines will run parallel in the same direction towards Gandhi Maidan via NIT More from the stadium,"" an official said.\n""In the second phase, the machines will be lowered at Gandhi Maidan to cover the distance of 1.4 km up to Patna Junction. Two more TMBs will be procured before the second phase, which will be lowered at Moin-ul-Haq Stadium and retrieved at Rajendra Nagar and cover the distance of 700 metres. The estimated time to construct the underground tunnel of Corridor II is 30 months,"" a source informed. TBMs can usually bore a maximum of 30 metres per day depending on the geological conditions.\nIf the conditions are tough, it could slow down the progress to 20-25m per day.\nThe machines are integral part of any metro rail project as it bores through the earth, builds tunnels and helps in creating the underground network for the rail system. It is specialized in such a way that the debris get cleared simultaneously. The work of making the tunnel rings has already started. The rings are precast segmental linings for underground tunnels that provide structure and strength.\n""When a TBM is used for boring beneath the ground, small segments of concrete set in a steel reinforcement cages are used to form a permanent lining of the tunnel.\nEach tunnel ring is completed by joining together 6 segments and locking the arrangement. In addition to this, it also allows the TBM to move forward,"" a metro rail source said. Corridor II will be 14.5 km long, including 6.6 km priority corridor - Malahi Pakri, Khemnichak, Bhoothnath, Zero Mile and New ISBT - which forms part of the elevated section. It will be ready by 2025. The work on the 7.9 km underground network will be over by 2026, with interchangeable station at Patna Junction. The other underground stations include Rajendra Nagar, Moin-ul-Haq Satidum, University, PMCH, Gandhi Maidan and Akashvani.', 'Welding, Cutting and Brazing Safety Program\nThis welding, cutting and brazing program is designed to protect life and property from fire, atmospheric contaminants, and other associated hazards that may occur during these operations. This program applies to all of those employees who may perform welding, cutting, or brazing as part of their job function.\nBasic precautions for fire prevention the object to be welded should be moved to a safe place, when possible. If the object cannot be readily moved, all movable fire hazards in the vicinity shall be moved to a safe location. If the object cannot be readily moved and all fire hazards cannot be removed, guards shall be used to confine the heat, sparks, and slag, and protect immovable fire hazards, ( ie. curtains). A fire watch is required whenever there is a possibility of fire developing. The fire watchers will have fire extinguishing equipment immediately available and shall be trained in its use. They will also be familiar with the methods used to sound an alarm. The fire watch must be maintained for at least ½ hour after welding operations have stopped.\nA fire watch is required whenever there is a possibility of a fire developing or any of the following conditions exist:\n- Appreciable combustible materials, in building construction or contents, are closer than 35 feet to the point of operation.\n- Appreciable combustibles are more than 35 feet away, but are easily ignited by sparks.\n- Wall or flooring openings within 35 foot radius expose combustible material in adjacent areas including concealed spaces in walls or floors.\n- Combustibles materials are adjacent to opposite side of metal patricians, walls, ceilings, or roofs and are likely to be ignited by conduction or radiation.\nIf the following requirements above cannot be followed, welding and cutting shall not be performed.\nHot Work Permits written must be completed by supervisory personnel prior to any welding, cutting, or brazing operations. This permit must be kept at the worksite while work is being performed. Completed permits shall be maintained in file for a period of one year. Special precautions which must be considered include:\n- Combustible Material: remove, or protect from sparks and hot slag.\n- Fire extinguishers: maintain for instant use.\n- Prohibited areas: Welding, cutting and brazing is not permitted in areas which have not been authorized.\nDo not weld, cut or braze in:\n- Atmospheres where flammable gases, vapors, liquids, or dusts are present\n- Storage areas where there are large quantities of exposed, readily ignitable materials\nWhen working on platforms, scaffolds, or runways, welders and their helpers shall be protected against falling by use of railings, safety belts, life lines, or other effective safeguards. Helmets or hand shields shall be used during all arc welding. All helpers & attendants shall be provided with proper eye protection. Goggles or other suitable eye protection shall be used during all gas welding or oxygen cutting operations. Spectacles with side shields and suitable filter lenses are required during gas welding operations on light work, torch brazing, and for inspections. Helmets and hand shields shall be arranged to protect face, neck, and ears from direct radiant energy from the arc.\nA confined space is defined as a relatively small or restricted space such as a tank, boiler, pressure vessel, or manhole. Ventilation is a prerequisite to work in confined spaces. Gas cylinders and welding machines shall be left outside. Heavy portable equipment mounted on wheels shall be securely blocked. Whenever a welder must enter a confined space through a small opening of manhole, means shall be provided to quickly remove him in the event of an emergency. Safety belts and lifelines used for this purpose shall be attached to the welder’s body so that his body cannot be jammed in a small exit opening.\nMechanical ventilation shall be provided when welding or cutting is performed on metals not listed below. These metals have their own specific allowable concentration/ventilation requirements: fluorine compounds, zinc, lead, beryllium, cadmium, mercury, cleaning compounds, and stainless steels. General requirements mechanical ventilation is needed when:\n- Space is less than 10,000 cubic feet per welder\n- Ceiling height in room is less than 16 feet\n- In confined spaces, or where welding space contains partitions or other structural barriers which may obstruct cross ventilation\nMechanical ventilation at a minimum rate of 2,000 cubic feet per minute per welder, except where local exhaust hoods, booths, or airline respirators are provided. Ventilation in confined spaces must be provided to prevent accumulation of toxic fumes or possible oxygen deficiency. This includes not only the welder, but also helpers and other the welder, but also helpers and other personnel in the immediate vicinity. All make up air that is drawn into the area of operation, must be clean and respirable.\n- General Information\n- Bloodborne Pathogens Program\n- Building Maintenance Safety Rules\n- Building Services Safety Rules\n- Central Receiving Safety Rules\n- Confined Space Entry Program\n- Fall Protection Program\n- Fire Safety and Fire Prevention\n- Forklift Operator Safety Guide\n- Grounds Maintenance Safety Rules\n- Hazard Communication / Right to Know Law / MSDS\n- Heating Plant Safety Rules\n- Aerial Highlift Operation Safety Rules\n- Lockout/Tagout Program\n- Machine Shop Safety Rules\n- Mechanical Maintenance Safety Rules\n- Office Secretarial / Clerical Safety Rules\n- Personal Protective Equipment\n- Respirator Protection Program\n- Transportation Services Safety Rules\n- Trenching & Excavation Safety\n- Vehicle Operation Safety Rules\n- Welding, Cutting and Brazing']"	['<urn:uuid:3d84e609-5e8b-4193-8699-601cecc4f46d>', '<urn:uuid:756890bc-ea6e-4514-90aa-1169e16e7ddb>']	factoid	direct	concise-and-natural	similar-to-document	multi-aspect	novice	2025-05-12T13:53:09.865574	13	51	1432
6	what investment options are available in share markets online	Share markets online allow investors to trade various instruments including options, stocks, ETFs, bonds, mutual funds and real estate. The Internet platform provides an opportunity to buy inexpensive assets and increase investment portfolio value.	['To spend is a term loosely put on the practice of loaning funds as well as spending them on certain projects or objectives with the intention of ultimately achieving some financial return on your initial financial investment. Therefore, to spend indicates to obtain funds and also utilize them for certain purposes with the purpose of earning a profit on your first investment. It’s quite basic actually. You place your money in a savings account, get interest on your financial savings and make use of that passion to make investments.\nThere are 3 fundamental types of financial investments: long term financial investment, short term investment as well as buy-sell choice investment. Long-term investment is made use of to safeguard assets such as property, gold and also precious jewelry. These assets generally need significant time to redeem their full value. Therefore, you ought to consider spending for the long term just after you have actually done your research as well as researched the market completely. rare earth filter\nShort term financial investments such as the buy-sell alternative entail the buying and selling of safeties, options or futures. This kind of investing can create earnings progressively over a time period but must be taken into consideration as an acting kind of earning cash. The primary goal of these kinds of financial investments is to rapidly generate capital so that you can use it for bigger purchases or in removing financial debt. Buy-sell alternative investments ought to be approached with caution as the major risk of these financial investments originates from the ability to benefit from a loss. This kind of financial investment likewise calls for significant time to recoup its funding value.\nAn alternate financial investment approach that can produce income even when the economic situation remains in economic crisis is the bond market. Bond market investing is related to equities, supplies and derivatives. While bonds ensure fixed interest rates on loans, stocks offer shares of ownership in a company as well as the two types of financial investments generally go hand in hand.\nA financial investment bank is an institution that provides cash to its customers. Many banks use investment lenders that spend the cash of their clients in various stocks, bonds, derivative instruments, financial instruments as well as property. An investment bank likewise develops the largest portion of the economic market. Several large investment banks are based in significant cities such as New york city, Tokyo as well as London. These financial institutions lend funds to services on the basis of their credit score ranking.\nAn on-line financial investment forum assists in the chance to network with fellow investors interested in dealing mutual funds, bonds and also other types of financial investments. The discussion forum helps you find out about spending essentials as well as gain an understanding of market patterns. You can additionally discuss investment methods and also market share info with expert investors. rare earth in concert vinyl\nThe Web additionally provides a beneficial platform to deal shares online. Share markets give capitalists an unique opportunity to buy inexpensive properties as well as raise their financial investment portfolio value. A large range of instruments are traded in share markets consisting of options, stocks, ETFs, bonds, mutual funds as well as property. With the help of the Net, investors can even discover more concerning buying assets.\nWhen you are intending to purchase equities or bonds for the first time, you need to look for skilled advice. A financial investment professional can aid you in analyzing the suitability of a particular company and related tools. Apart, from recommending you on ideal tools and services, a specialist investment consultant can additionally aid you in creating a repaired portfolio consisting of suitable financial investments. The major benefits of purchasing equities and also bonds are that they generate earnings and you can utilize them as a structure for building wealth.\nTo produce a solid investment portfolio, numerous financiers favor to invest in mutual funds, which merge investments from several capitalists. This guarantees that your profile is based on financial investment goals and techniques, and also you get the best returns on your financial investments. However, in order to make one of the most out of mutual funds, it is necessary to follow the best financial investment strategy. To aid you construct a solid portfolio, it is very important to comply with the financial investment approach of Warren Buffet’s Passive Earnings Technique.\nAn additional crucial approach is to minimize losses by preserving a good risk administration policy. This will assist you keep losses at minimum levels and also generate gains in preferable industries. Different financiers have various threat resistance levels, so it is essential to examine your own financial investment choices as well as take the chance of resistance levels and select the investment option that best matches your needs. When you are preparing to begin your very own financial investment endeavor, it is advisable to take the aid of an investment specialist. He/She can suggest you on the sort of financial investment that would certainly fit your needs, the sort of safety you might require to protect your funding, as well as help you make a decision where to spend your resources.\nThe last technique that several investors favor to adhere to is ‘share acquiring as well as share selling’. It is a simple method to move possession of your existing possessions to gain more revenues. For instance, you buy shares of the leading business in a specific sector, such as pharmaceuticals, at a price that you think is great. Then, you market those shares at a higher price, consequently decreasing the quantity of cash you had initially paid for the shares. Nonetheless, many people pick to purchase these sorts of systems only when they are already holding long term assets such as dealt with deposits or bonds. However, both alternatives might help you raise the worth of your portfolio.\nTo spend is a term utilized to describe a particular act or procedure whereby an individual or entity makes a financial investment. The primary aim is to generate income by utilizing economic instruments. In the past, individuals as well as organizations would pool their cash and invest it in order to create a profile that would certainly generate a greater rate of interest or a higher return. With time, investors have used financial investment plans in order to create monetary riches and also stability.\nHow you specify financial investment then is completely as much as you. Nonetheless, there are different kinds of financial investments. In broad terms, these consist of supplies, bonds, home, monetary instruments, gold and also equities. An individual can buy just about anything that they want. That stated, supplies and bonds are the two most common kinds of financial investment. risis democracy 4 rare earth\nBuying supplies can supply investors with higher returns in a reasonably much shorter amount of time than standard estate or various other monetary investments. Therefore, supply financial investment has actually ended up being very prominent with specific financiers and also despite institutional capitalists. Stocks can be invested in many different industries, such as production, framework, business and residential realty, as well as the oil and also gas sectors. There are also locations of the economic climate that do not normally see an increase in work or opportunities for work creation such as technology or state-of-the-art sectors. While these areas might not constantly be rewarding on a long-term basis, the changes in supply prices can usually lead to a greater return than other, more secure financial investments.']	['<urn:uuid:ba338f1d-f138-425c-b186-cd3543d480e8>']	factoid	direct	long-search-query	similar-to-document	single-doc	novice	2025-05-12T13:53:09.865574	9	34	1260
7	How much water is considered good practice for beer production in India?	In India, using 4 to 5 hectar litre (hl) of water per hl beer output is considered good practice.	['Cost Saving Opportunities for Breweries\nFactory Manager, YBL, Melli (Sikkim)\nBijay Bahadur has more than 29 years of experience in Indian and multinational breweries, IMFL bottling plants, brewery green-field and brown-field projects and factory operations such as maintenance, production, environment health and safety, and project management. He is also the author of Brewing – A Practical Approach, which is for practicing brewers, students pursuing careers in Food Technology, Biochemical Engineering or Brewing Science, and consultants who provide technical advice to breweries and entrepreneurs. He is a practicing brewer and specializes in the manufacturing of beer, including the formulation of recipes, overseeing new technical developments, implementing standard operating procedures, planning budgets, warehousing and inventory control, and liaising with Quality Assurance Department (QAD). He is a lifetime member and elected as FELLOW of the Institution of Engineers (India), the Indian Institute of Chemical Engineers and the Association of Food Scientists & Technologists (India). He has been authorized to use the style and title of Chartered Engineer (India) by the Institution of Engineers (India) as well as been elected as Professional Engineer by Engineering Council of India, New Delhi for a period of five years.\nBrewing industries are looking for opportunities to reduce production costs without negatively affecting product yield or quality. Uncertain energy prices in today’s marketplace negatively affect predictable earnings, a concern for the management of the beer industry. For breweries, increasing energy prices are driving up costs and decreasing their value add. Successful, cost-effective investment into energy-efficient technologies and\npractices meet the challenge ofmaintaining the output of a high-quality product despite reduced production costs. This is especially important, as energy-efficient technologies often include “additional” benefits, such as increasing the productivity per employee of the company.\nEnergy consumption is approximately 3–8 percent of the production costs of beer, making energy efficiency improvement an important way to reduce costs, especially in times of high energy price volatility. There are many methods to reduce energy consumption cost-effectively in the brewing industry. Since brewer’s value the quality, taste and texture of their beer, brewing industries are expected to continue spending capital on cost-effective energy conservation measures that meet these requirements.\nFor breweries, increasing energy prices are driving up costs and decreasing their value add. Successful, cost-effective investment into energy-efficient technologies and practices meet the challenge of maintaining the output of a high-quality product despite reduced production costs.\nOptions For Energy Efficiency\nA variety of opportunities exist within breweries to reduce energy consumption while maintaining or enhancing the product quality and productivity of the brewery. Few measures taken may be:\n- Regular maintenance and proper operation of motors, pumps and compressors, and replacement with more efficient models whenever possible.\n- Proper and efficient operation of the process, that is optimization and ensuring the most productive technology is in place.\n- Establishing a strong organizational energy-management framework to ensure that energy efficiency measures are implemented effectively.\nEnergy-Efficient Boiler Plant\nA blow down economizer can be added to the boilers to reclaim heat from excess boiler water. The heat can be reused to preheat feed water for the boiler.\nBy preheating the makeup water, the rate of heat input of the boiler drops while the rate of heat output remains the same.\nOxygen in the condensate is scrubbed before it returns to the boiler by a deaerator. This decreases the amount of boiler blow down and decreases makeup water, improving energy efficiency and hence appreciable reduction of requirement of chemicals to treat the makeup water.\nEnergy-Conservation In Brew House\nThe reduction of heat energyconsumption in the brewhouse by means of technology is an important contribution to the preservation of fossil fuel resources and to significantly reduce CO2emissions.\nThe carbon footprint of a brewery can be optimized further with spent-grain combustion and the use of solar thermal energy. The technology and applied technique of biomass combustion must be improved for use in the brewing industry.\nIn the brew house, energy recovery reduces the need for steam. Entire heat required for the brew house comes from steam supplied by the boiler. Heat lost from the boiling wort in the wort kettle can be recovered and used to pre-heat future batches of wort with a vapor condenser on the exhaust stack. This will translate into less energy demand, lower operational costs, and faster brew times.\nBesides reducing energy demand, there is another benefit to energy recovery – steam from the wort kettle condenses into water. In this way, vapor from brewing beer stays in the brew house and the area outside does not “smell like a brewery.”\nOne way is to explore using water flowing out of the pasteurizer as an initial rinse in the bottle washer section, or to collect and reuse it for makeup water back to the pasteurizers.\nRaising beer-out temperature limits on pasteurizers can also reduce pasteurizer water losses. Bottle rinse water can also be reclaimed and used for pasteurizers or as dilution water for conveyor lubrication systems.\nBottle rinse water can also be used as a source for virtually any cleaning-in-place rinse in the brewery.\nBeer, Energy and the Environment\nThe brewing process is energy intensive, especially in the brew house, where mashing and wort boiling are the main heat consuming processes. The attention to reduce energy consumption has led to the development of new processes and technical solutions that consume less energy.\nDynamic wort boiling with an internal boiler and use of the Jetstar (Huppmann GmbH, Germany) internal boiler for a simmering boil, with a submerged wort flow and stripping phase to reduce undesired volatility, is a good example of a sustainable improvement in wort boiling combined with reduced thermal stress and increased wort quality.\nThe target for every brewing company should be the development of a sustainable process with efficient energy consumption to achieve savings in fuel and energy costs. Furnace oil has been pushed continuously to higher levels (fluctuates on daily basis) and there is no sign of a significant price decrease in the future. The demand for heat energy in the brewery can be reduced through the use of waste heat as process heat or energy rich by-products or waste material for thermal energy. The combustion of spent grains is one possibility for generating thermal heat and electrical power. The installations for heat generation through spent-grain combustion require huge investment on the design and technique for partial dewatering of spent grains.\nThe sun can be seen as the lowest cost energy provider. Breweries located in sunny regions should think about installation of solar collectors to take advantage of cheap solar energy. It is expected that the cost and installation of such equipment will decrease rapidly because the demand for this technology will lead to an increase in production volume. Solar thermal energy can be used for heating processes in CIP plants, bottle washing machines, and pasteurizers or for cooling processes with absorption chillers.\nThe largest consumers of electricity in breweries are refrigeration (44%), packaging (20%), and compressed air (10%). In general, it is recommended to invest in insulation and check whether that is dry. Regular inspection of the pipe system for the compressed air supply and installed valves is necessary to avoid losses and will help reduce electricity costs with little effort.\nIn addition, to fuels and energy, water is the other resource that is limited in quantity and good quality. Therefore, breweries should always aim at efficient water consumption for cleaning and cooling purposes, the prevention of losses, and the reuse of treated wastewater.\nMany opportunities exist in the brewery to reduce water consumption or recycle water. In India, use of 4 to 5 hectar litre (hl ) of water per hl beer output is considered good practice. Like heat recovery and reuse, water conservation and reuse approaches seek to best match and reuse high quality, medium quality, and low-quality water in various applications. Reduced water use will not only reduce effluent charges, but will also reduce water purchase bills, water treatment costs, as well as energy for water treatment and pumping.\nOther opportunities include the installation of recirculation tanks with vacuum pump beer filling installations, optimizing bottle washing installations, cleaning in place plants (CIP), the reduction of rinse water after CIP, and cascading of water for various uses.\nBenchmarks For European Breweries\n|Fresh water consumption||hl/hl||3.7 – 4.7|\n|Thermal energy consumption||kwh/hl||23.6 – 33|\n|Electricity consumption||kwh/hl||7.5 – 11.5|\n|Kieselguhr consumption||g/hl||90 – 160|']	['<urn:uuid:27d0a9be-b3fa-46bd-88fd-a7c7b7e5c73d>']	factoid	direct	concise-and-natural	similar-to-document	single-doc	novice	2025-05-12T13:53:09.865574	12	19	1391
8	I'm researching lab equipment for elemental analysis and wondering about sample preparation methods. What types of sample forms can be analyzed using emission spectrometry and ICP techniques, and how must they be prepared?	For emission spectrometry and ICP analysis, samples can be handled in several forms: powdered samples and solutions are accepted for emission spectrometry, while ICP is primarily designed for liquid samples, though it can accommodate gases and solids with appropriate sampling systems. Rock samples specifically must be converted to either powder form or solutions before analysis. For ICP-MS analysis, samples often need to be dissolved in acid under proper ventilation conditions.	['At the Lab, we have several instruments that require proper laboratory conditions and safety equipment. Lab conditions can mean a number of things depending on the instrument, but here’s a quick idea of some of the things that are often required:\n- Stable temperature\n- Clean air, positive pressure\n- Ventilation of fumes\n- Fire Safety Cabinets\nOur Lab, Today\nWe have a small office space that we work out of today. It is a great space, but ultimately, not a laboratory. We do have several pieces of equipment within the space that are currently available:\n- One of, if not the only, publicly accessible Scanning Electron Microscopes in the US.\n- Optical Microscopy, capable of brightfield, as well as Phase-contrast, and Darkfield.\n- Gamma Spectroscopy Equipment\n- CNC Prototyping equipment, including 3D printing and access to an Abrasive Waterjet Machining Center.\nOur Lab, moving forward\nWe believe providing access to test, measurement, and analysis equipment is vital to advancing science, whether this is in the context of citizen science or academia. Often times, barriers to carrying out important research involve access to equipment and funding. Our mission is to facilitate that access.\nUnfortunately, some of these instruments cannot operate to their full potential, and others not at all, until we meet the requirements necessary to operate the equipment safely and properly. While we have accomplished a tremendous amount by pooling together our knowledge, resources, equipment and tools, the construction of a proper laboratory will require building materials, supplies and consumables for the equipment.\nFirst and foremost, we need to address fume extraction and ventilation.\nScanning Electron Microscopy\nAnalytics Lounge received a donation of a Leica S430 Scanning Electron Microscope, capable of secondary electron and backscatter imaging, as well as Energy Dispersive X-ray (EDX) spectroscopy, from Pumping Station: One, NFP. This enables imaging samples at scales smaller than the wavelength of visible light, as well as determining elemental analysis via EDX.\nWe are currently unable to image wet organic specimens. Generally accepted laboratory procedures to do so require first fixing the specimen using chemicals such as glutaraldehyde, paraformaldehyde, osmium tetroxide, etc., followed by dehydration in ethanol, critical point drying, and sputter coating. Analytics Lounge already owns a Hummer sputter coater and has a Tousimis critical point dryer on loan. However, fixing specimens safely requires use of a fume hood, as the chemistry necessary is toxic and volatile. We will need to acquire a fume hood and adequate ventilation.\nAnalytics Lounge acquired a Varian 810 ICP-MS as a donation from the Field Museum. We were told that this equipment is fully functional. It will enable elemental analysis, including detecting trace elements such as pollutants in drinking water or soil.\nICP-MS creates an extremely hot plasma. The machine itself requires significant ventilation. It also uses a water chiller, which produces heat that must be vented. This equipment cannot operate without dedicated ventilation. This must be addressed before we can operate this instrument. Additionally, samples often must be dissolved in acid. Doing this safely requires a fume hood.\nGraphite Furnace AAS\nAnalytics Lounge acquired two Perkin-Elmer graphite furnace Atomic Absorption Spectrophotometers. While neither are currently in a functional state, we have reason to believe that all critical systems in one of them are operational. Remaining work requires obtaining appropriate tubing, graphite tubes, and repairing the drive mechanism of the autosampler. This instrumentation is similar to ICP-MS in that it can quantify the presence of specific elements, which would be useful for trace elemental analysis. Having both ICP-MS and AAS functional would enable confirming results. However, this requires calibration solutions, often made by dissolving the element being measured in acid, and diluting it. This process requires a fume hood. We would also need an analytical balance to measure the mass of specimens and materials used for calibration solutions.', 'Geochemistry lab Group\nGeochemistry lab includes 3 labs of emission spectrometry,geochemistry,inductively plasma that rock samples is entered to 3 labs as powdered or solution.\nThe sample is placed on electrode and finally measured quantitatively by spectrometer.\nThe samples are melted and dissolved in the labs of atomic absorption and inductively coupled plasma and is used the got solution and present analysis systems to assign chemical elements scales.\nAtomic absorption system with flame of 2100-Perkin Elmer\nAtomic absorption spectrometry system with present flame in GSI is made of USA. This system can measure the following elements in detection limit of ppm.\nAtomic absorption spectroscopy with graphite furnace of 5100-Perkin Elmer\nApplication of electronormal atomizers is like furnace on the increase because of very low detection limit.\nBasically,all metallic elements with detection limit of about nanogram are measured by graphite furnace but working by furnace is so more difficult than flame and repeated results is got hardly but has very high sensitivity.\nAtomic absorption by hydride production system\nThe heavy elements of 4&5&6 groups of periodic table can not be measured by atomic absorption system with flame due to gas hydrides formation that isn’t constant in almost high temperatures,so,they organize volatile hydrides along with sodium boron&hydride in acidity medium that metallic atom becomes free in atomizer(quartz cell)and is accomplished atomic absorption by light absorption of involved lamp.\nThis method can be used just forTe,Sn,Se,Sb,Ge,Bi,Hg,As elements.Probability of interelement interferences is very low and it isn’t necessary to be used background correction because only a few elements form volatile hydride.Meanwhile,detection limit of the method is to extent of ng/m too that is accomplished on MHS-20 system.\nGSI is equipped with Perkiin Elmer 5100 or 2100 system that is installed.\nFlame emission system\nThis system doesn’t have bright source and atoms become aroused in it by flame heat.This system is used in GSI for measurement of following elements in ppm limit:Li,Na,K\nThis system is used for measurement of chlore amount in solutions or powdered samples that have been melted and it can measure the chlore amount by minimum 5ppm for solutions and 100 ppm for solid samples.The present system in lab,is made of Jenway company of England.\nMoreover the mentioned systems in atomic absorption lab,are used tetrasion method for measuring Mo&W,colorimetry method for assignment of B&Mg&Ca amount and precipitation for assignment of sulphate and sulfur amounts.\nEmission spectrometry lab\nThe spectrometry is a science that separates and analyzes radiant energy on the basis of wavelength or frequency and studies resulted spectrum in order to get physical and chemical data.\nSpectrograph and spectrometer present in GSI is Jarrell-Ash3&4,American.\nSpectrometer can measure the elements of\npercent limit.Spectrograph can recognize many elements.\nThis method has been planed on the basis of light absorption by molecules and is used in different limits of wavelengths considering type of the molecule that the noted element is in its structure and the wavelength absorbed by that molecule.\nSpectrophotometer used by UV-NIR3100 is made of Japan.This machine is used for measurement of following elements(after forming the chromatic complex of the noted element):Ti,Al,Si,P,Mn,Fe.\nIonic chromatography is accounted one of different methods of liquid chromatography with high effectiveness.\nIn this method is used very small sample(nearly 100micl).The existing system in Knauer lab of GSI is made of Germany.\nAt present,This system can measure the bellow elements with detection limit of ppm in natural and tap waters and so on: Na,K,Li,Br,No3,No2,Cl,F,Hpo4,So4.\nInductively coupled plasma lab(ICP)\nIt is a modern type of emission source that is been planed only for liquid samples.\nOf course,the sampling system is used for gases and solids too.One of the main benefits of this system is fast multi-element\nThe measurement of 50 elements or more is possible in simultaneous analysis,based on type of system in a sample by a polychromatic.The repetitive analysis is accomplished by monochromatic.\nThe existing machine in GSI(Plus JY70)is made of France and can measure the following elements at present:']	['<urn:uuid:0ae413e1-26f9-4e88-93f6-8697b80befcb>', '<urn:uuid:a7303159-6552-4c86-ac0d-beff39d0293e>']	factoid	with-premise	verbose-and-natural	distant-from-document	three-doc	expert	2025-05-12T13:53:09.865574	33	70	1285
9	black musician resting place 1963 newport graveyard	Elmore James (1918-1963), known as the 'king of the slide guitar,' is buried in the cemetery of the Newport Missionary Baptist Church. He was a highly influential blues guitarist who died of a heart attack in Chicago on May 24, 1963, and his body was sent back to Mississippi for burial.	['Elmore James - Ebenezer\nThe cemetery of the Newport Missionary Baptist Church is the final resting place of Elmore James (1918-1963), often described as the “king of the slide guitar.” James’ electric style built on the approach of Robert Johnson and later influenced many blues and rock guitarists. Also buried here is Lonnie Pitchford (1955-1998), known for his skills on the one-string guitar or “diddley bow” and his dedication to keeping alive older traditions of Delta blues.\nElmore James embodied the dramatic style changes in the blues associated both with the mass migration of rural Mississippians to Chicago and with evolving electronic technology during the 1940s and ’50s. Born Elmore Brooks on January 27, 1918, in Richland, he first played a one-string guitar, and locals recalled that he soon constructed a multi-stringed instrument with a lard can. In the late ’30s James began performing with Robert Johnson and Sonny Boy Williamson No. 2 in Belzoni. Johnson’s boogie bass runs and slide guitar style were integral to James’ approach to the guitar. James also played with his adopted brother Robert Holston, sometimes with bands featuring horns and amplifiers. James lived on various farms in Holmes and Humphreys Counties before serving from 1943 to 1945 in the Navy. He returned to Mississippi as a decorated veteran.\nJames, who learned more about electronically amplifying his guitar while working at Holston’s radio repair shop in Canton, played on radio shows with Williamson in Belzoni and Helena, Arkansas, and made his debut recording in 1951 for Jackson’s Trumpet label. Williamson played harmonica on James’ record, “Dust My Broom,” a tune recorded by Robert Johnson in 1936, and James also backed Williamson and Willie Love on Trumpet sessions. After “Dust My Broom” became a national R&B hit, James began touring and moved frequently between Mississippi and Chicago. He recorded for Meteor, Modern, Chess, Fire, and other labels over the next decade, scoring hits with “I Believe,” “The Sky is Crying” and “It Hurts Me Too.” James, who had a longstanding coronary condition, died of a heart attack on May 24, 1963, at the Chicago home of fellow musician Homesick James Williamson. Following a wake in Chicago, James’ body was sent home to Mississippi for burial.\nLonnie Pitchford, who often played songs by Elmore James and Robert Johnson, was born near Lexington on October 8, 1955. His parents, Willie Douglas and Rosie Pitchford, and his brothers Rosby, Willie Douglas, A. J. and Charles also played guitar. As a child Pitchford built one-string “diddley bows” using baling or broom wire and snuff cans. After he began playing a regular guitar, he joined a high school band and also played in churches with gospel groups in the area and while living in Chicago, Kansas City, and Kalamazoo. In the 1970s he began showcasing his one-string guitar skills under the guidance of folklorist Worth Long, who also helped him meet and learn from blues veterans Eugene Powell, Sam Chatmon, and Robert Lockwood. Pitchford performed across the U.S., toured Europe and Australia, appeared on several albums, and was featured in films and on TV. Around Lexington, he was sometimes joined by guitarist Curtis Price, who, like Pitchford, worked as a carpenter, recorded with the Star Lite Singers gospel group, and was buried here. Price, born on May 2, 1956, died in an auto accident on July 19, 2010. Pitchford died on November 8, 1998.\ncontent © Mississippi Blues Commission\n[ BACK TO TOP ]']	['<urn:uuid:8b435d10-0b92-47f4-b17c-663584a78703>']	open-ended	with-premise	short-search-query	distant-from-document	single-doc	novice	2025-05-12T13:53:09.865574	7	51	573
10	What were the symptoms of Black Death, and how did people try to control it?	The Black Death caused severe symptoms including fever, disorientation, depression, and various physical reactions. Victims experienced cramps, cold extremities, vomiting, skin lesions, breathing difficulties, blood-spitting, throat swelling, headaches, dizziness, and foul-smelling diarrhea. The disease was so deadly that people who went to bed healthy might not survive until dawn. Without modern medical knowledge, people didn't understand how the disease spread or how to effectively control it. They blamed it on factors like bad smells or God's wrath. Some control measures were attempted, including quarantine, sanitation, and travel restrictions between cities, but these weren't effective. The lack of knowledge about disease transmission and proper handling of the sick and dead bodies contributed to the plague's rapid spread. The disease was particularly deadly in its pneumonic form, killing 9 out of 10 infected individuals.	['We are searching data for your request:\nUpon completion, a link will appear to access the found materials.\nBy Kathryn Walton\nThe Black Death of 1347-51 was one of the worst pandemics in Europe’s history. It decimated the population, killing roughly half of all people living. After the ravages of the plague were finished, however, medieval peasants found their lives and working conditions improved.\nOne of the most famous pandemics in Europe’s history raged across the continent and around the world from 1347-51. The plague pandemic, coined The Black Death by a nineteenth century scholar, is generally thought to have been caused by a bacterial infection derived from the bacillus Yersinia pestis. The disease was transmitted by fleas who latched onto a human host after biting an infected rat. It swept across a huge portion of the globe. The Palestinian chronicler Abū Hafs Umar Ibn al-Wardī reports that it spread through China, India, Turkey, Egypt, Palestine, as well as Europe. You can see his account of its spread animated in the video below.\nThe disease was devastating. The physician and poet Abū Ja’far Ahmad Ibn Khātima, who lived on the southern coast of Spain, leaves us a very detailed description of the effects of the plague in his Arabic treatise A Description and Remedy for Escaping the Plague in the Future. It begins, as he says, with a fever that rises over the course of a few days making the patient disoriented and depressed. This is followed by some severe physical reactions:\ncramps; coldness in the extremities; frightful, bilious, recurring vomiting; diverse lesions on the skin; or: a tightness in the chest; difficulty in breathing; spitting of blood or stinging pain on the side or just below the breast, accompanied by inflammation and an intense thirst; coughing; blackness of tongue or swelling of the throat with complications of quinsy; and a difficulty or impossibility swallowing; or: headaches; fainting fits; dizziness; nausea and foul-smelling diarrhea.\nThis passage was translated by Suzanne Gigandet. You can read it is full as well as many of the documents that I refer to here in John Aberth’s The Black Death, The Great Mortality of 1348-1350: A Brief History with Documents.\nIt was a terrible disease that inspired a great deal of fear across Europe and around the world. The medical professionals of the time did not really know what caused it or how to contain it. It was often attributed to God’s wrath and blamed on such environmental factors as bad smells. There were some attempts made to control its spread. Quarantine and sanitation measures were put in place and travel between cities was restricted. But nothing really worked, and the plague spread rapidly.\nImpact on Peasants and Members of the Lower Classes\nIt affected everyone but was especially devastating for peasants and those in the lower classes. In the face of an outbreak, those who had enough money to finance relocating would simply leave the infected location. Those who did not died in greater numbers. The Italian poet Giovanni Boccaccio in The Decameron describes the plight of common people in cities who, not having the resources to leave, were forced to stay close to home. As a result, they “sickened daily by the thousands and because they received little help, they nearly all died with few exceptions.”\nThose outside of the cities also died in extremely high numbers. Peasant farmers tended to be more removed from the outbreaks, but as Boccaccio stresses, they had no access to physicians and often little help when they fell ill. As a result, they “died, not like men, but like animals, on the roads, in their fields or in their houses at all hours, by day and night.” These quotations come from the Project Gutenberg edition of Bocaccio’s text. I have modernized the language. You can access the full text here.\nIt was a devastating event. Millions of people around the world suffered and died. When the plague ended roughly half of the population of Europe was gone. The face of Europe was changed forever.\nBut for the peasant population, it was changed for the better.\nLives of Peasants Before the Plague\nPrior to the plague, medieval peasants were often extremely poor and had few freedoms. Peasants typically farmed a portion of an estate owned by a lord in return for the protection of that lord and the use of the land. But, as a result, peasants were often tied to the land and had to give up certain freedoms to hold on to it. They also had to turn over a portion of their harvest to the lord as payment. This arrangement absolutely benefited the lord over the peasant. The lord was able to amass great wealth from the work of his peasant farmers. The peasants were often barely able to produce enough to get by and had few means of improving their position in the world.\nIf you want to read more about the working conditions of peasants and the prevalence of serfdom in early medieval England, check out Lucie Laumonier’s column Who were the Peasants in the Middle Ages?\nThe Resulting Labour Shortage\nAfter the ravages of the Black Death were finished in Europe, however, there were suddenly far fewer people to farm the lands. Egyptian scholar Ahmad Ibn Alī al-Maqrīzī, described what this looked like after the plague had passed through Egypt: “When the harvest time came, there remained only a very small number of ploughmen.” There were some who “attempted to hire workers, promising them half of the crop, but they could not find anyone to help them.” The same was true in Europe, and crops remained unharvested and great revenues were lost for the local landowners because they couldn’t get anyone to do the work.\nLabourers and farmers were consequently suddenly in high demand. To maintain their estates and ways of living the lords needed peasants to farm their lands, and so, faced with a labour shortage, the lords were forced to pay peasants more for their work and enter into agreements that were more beneficial to the peasants. Peasants suddenly had more agency and more control over their working lives. They could dictate the terms of their contracts. They could simply leave their position if their lord treated them poorly or was unwilling to pay them more. They were able to acquire more wealth and freedom as the importance of their labour was increasingly recognized in the face of its loss.\nMany and various attempts were made by local governments and officials to block this upward movement. An Ordinance from Castile in 1351 condemns those who “wander about idle and do not want to work” as well as those “demand such great prices and salaries and wages.” It orders all able to do so to work for a set, pre-plague price. Another from Sienna condemns those who “extort and receive great sums and salaries for the daily labor that they do every day” and sets a fixed price of six gold florins a year.\nImproved Salaries, Freedoms, and Lifestyles\nThese ordinances show the anxieties of the governing members of society, but they were not always effective. Peasants continued to ask for and receive more money for their work and greater freedoms. Court records show that peasants and labourers frequently demanded more pay for their labour, left before the end of a contract, and abandoned one position if they were offered more money in another. They were charged for these offenses, but they kept doing them.\nAs working conditions and salaries improved, so did the lifestyles of the peasants. Goods and activities that had only been available to those with money were suddenly being taken up by peasants and other members of the lower classes. They used their newfound wealth to buy fancier clothes, eat nicer food, and take up leisure activities like hunting. The English poet John Gower lamented in his Mirour de l’Omme that labourers who were used to eating bread made of corn now were able to eat that made of wheat and that those who had previously drunk water were now enjoying luxuries like milk and cheese. He also complained about their new, fancier attire, and their choice to dress above their station. His attitude was common among some in the upper and middle classes who lamented the social improvements of the lives of peasants and the loss of the good-old-days before the plague when the world was “well-ordered,” and people knew their place (as Gower says).\nWhat the Black Death Tells Us\nPlagues and pandemics are terrible. But they usually end eventually. And the example of the Black Death shows that when they do, society can find itself changed for the better. The Black Death is often credited with catapulting the medieval world into the Renaissance. It is thought to have inspired the cultural, technological, and scientific innovations by which this period is typically defined. While many medieval scholars (myself included) question the extent to which the early modern period was uniquely innovative (there were many innovations taking place before that), there is no question that one of Europe’s greatest pandemics changed the continent and made a positive impact, for a time, on the lives of medieval peasants.\nTime will tell what the end of our current pandemic will bring. The Black Death shows that pandemics can bring positive social changes. Hopefully, COVID-19 will bring some too.\nKathryn Walton holds a PhD in Middle English Literature from York University. Her research focuses on magic, medieval poetics, and popular literature. She currently teaches at Lakehead University in Orillia. You can find her on Twitter @kmmwalton.\nTop Image: British Library MS Additional 18855 fol. 109v', 'Imagine an illness so powerful that people who go to bed healthy do not live until dawn. It kills most of the people exposed to it, depending on the particular strain. Imagine a plague that kills an estimated 35% of the entire population of Europe in a matter of three short years. Now imagine that you are living in the Late Middle Ages (1300-1450), modern medicine had not developed yet, and modern scientific processes explaining where the disease comes from and how it is transmitted is more than 400 years in the future. This is the situation in which the people of Europe found themselves in the mid-1300s, as the plague swept through Europe.\nBubonic plague, also known as Black Death or The Plague, was a deadly disease introduced to Europe by ships carrying rats infected with diseased fleas. There are few distinct forms of the plague, but bubonic was the most commonly seen and therefore lent its name to the epidemic as a whole. The name itself comes from the swelling and blackening of the lymph glands of the groin, armpits, or neck of the infected individual. These black lumps were known as buboes.\nThe infected person might also carry the disease in the bloodstream, resulting in the septicemic version of the plague. These forms of the illness were fatal most of the time. The third subtype of the plague, pneumonic, was the most deadly, taking the lives of nine of ten infected individuals. The illness created boils, which could ooze pus and blood, and also caused a fever, chills, vomiting, general malaise, or respiratory ills manifested through coughing and sneezing. Physical contact with an infected individual’s bodily fluids could also pass on the disease.\nFrom late 1347 until 1350, the Black Death ravaged Europe. It was most active in the spring, summer, and fall months and less active in the cold winter months, but all individuals were at risk of infection. The plague took the lives of more than half of the inhabitants of some cities. Peasants were found dead along roadsides, and ships would wash ashore after their crews perished at sea. Entire streets or families would succumb to the illness seemingly overnight.\nMap 1. Spread of the Black Death from 1347-1350. (Sayre, 2008)\nHistorical records from the time are not complete, so determining an exact number of victims is impossible. However, many estimates put the death toll at or above 25% of the European population during the height of the plague years alone. All of Europe was impacted. No one could be assured of being spared. Much of this was due to the fact that people did not know how the disease was spreading. They did not take basic precautions that would be encouraged in modern times to stop or slow the spread of disease.\nFig. 1 Pages with Three Living (left) and Three Dead (right), from the Psalter and Book of Hours of Bonne of Luxemburg. ca. before 1349 (Sayer, 2008)\nThe Black Death was carried by rats and fleas and transmitted by the bites of these animals. Although rats and fleas are not part of modern daily life for most individuals, in the fourteenth century, these creatures were part of day-to-day existence. Records show that there had been rumors of a plague sweeping through areas in the east in the years before it came to the European continent, but relatively little attention was paid to the tales.\nIt is widely believed the disease first appeared in Europe when ships coming from trading ports on the Black Sea returned to Genoa, Italy in 1347. Fleas, once their rat hosts died, would feed on other nearby mammals. In the case of rats on ships, the sailors became the victims. As the rats and their fleas literally jumped ship in Genoa, the plague began a reign of terror and continued throughout Europe for many years to come.\nThe people of Europe did not know how disease was spread or what precautions to take to overcome the diseases effects. Isolating oneself from the general public or large gatherings during times of disease was also an unknown practice, as it relates to reducing one’s exposure to disease. Likewise, isolating the ill from the well, and ensuring that the well did not come into contact with bodily fluids of the ill were not common practices. The treatment of the dead and the handling of corpses were also different from what is done in modern practice. The lack of knowledge about how the disease was transmitted and what could be done to slow or stop the spread contributed to the great number of deaths.\nThe impacts of the Black Death were many and varied. The initial decimation resulted in a decrease in the foods available at the market. It is also reported that animals were likely affected by the plague. Some reports note entire flocks of dead sheep in the fields. However, with fewer people for whom food needed to be produced, this temporary decrease was soon made up for as the remaining population took over the farmland of those who had perished.\nFig. 2 Black Death did not spear those it across, all were susceptible. (Sayre, 2008)\nEconomically the Black Death would hurt the nobles the most. Nobles were accustomed to collecting significant amounts of dues either in the form of crops or cash payments but eventually there were fewer serfs on whom they could depend for on ‘payments’. This decreased their power to demand payment for the privilege of working the nobles’ lands. Eventually, serfdom was replaced by a system in which the landowners paid those who worked their lands. The sociopolitical structure existing prior to the plague underwent significant changes.\nAnother effect of the Black Death was an increase in university enrollments at institutions where medicine was a field of study. Students who had seen the effects of the plague and survived brought with them new ideas about how diseases could spread or how they might be treated. At this time, there was also a push for the translation of major medical texts into vernacular languages from the more traditional Greek or Latin presentations.\nThe late Middle Ages were a time of change in every sense of the word and would give way to the Renaissance. Black Death, in essence, helped fuel much of the social, political and economic changes seen in later years. In many towns traditional burial services were not preformed and the dead were buried in mass graves. “By 1350, all of Europe, with the exception of a few territories far from traditional trade routes, was divested by the disease.” (Sayre, 2013, p. 200) As the push for better understanding about the natural world was thriving in the universities, the Middle Ages as the “age of faith” was giving way to “an ages of intellectual exploration”. (Sayre, 2013, p. 207) During this time humanist, individual interested in the recovery, study, and spread of art and literature of Greece and Rome, would emerge. These individuals would start to rebuild and revolutionize the Western course of history and change social behaviors to the greatest degree ever seen in the West.\nSayre, H.M.(2013). Discovering the humanities. (2nd. ed.). New York, NY: Pearson.']	['<urn:uuid:b5a5ec06-36d2-486e-b76b-71fecc272ee7>', '<urn:uuid:390e4d0f-3f9d-470e-b718-60f231dac93d>']	open-ended	with-premise	concise-and-natural	similar-to-document	multi-aspect	novice	2025-05-12T13:53:09.865574	15	132	2820
11	Which is warmer to wear, pure silk or wool clothing?	Both silk and wool have temperature-regulating properties, but they behave differently. Silk tends to wear warm, which is one reason people often avoid silk jackets. Wool, on the other hand, is breathable while retaining body heat, making it particularly suitable for winter sports like snowboarding and skiing. Wool can also absorb approximately 30 percent of its weight in water vapor while repelling moisture, contributing to better temperature regulation.	['Silk isn’t something you’d normally imagine for sport coats. Most us wear wool, linen, and cotton for our jackets, then reserve silk for finer accessories such as ties and pocket squares. Much of that is because silk has a natural sheen and is known to wear warm – and nobody wants to look like they’re baking in a polyester suit.\nIn the right weight and weave, however, silk can make for a great summer sport coat. Italian mills – who I think are particularly good at making livelier, more creative summer fabrics – often use silk to get more textured cloths. Wool in the summertime tends to be a bit finer and smoother, but with a bit of linen and silk mixed in, it can look as nubby as your favorite fall tweeds.\nJust see some of the photos above. The black and white images show the kind of silk suits and sport coats men used to wear a generation ago. Many silk jackets from that era were constructed from what’s known as Dupioni, a crisp, plain weave that’s been tightly woven from raw silk yarns (raw here means the silk hasn’t been chemically processed to strip it of its sericin, a bonding chemical that keeps the fibers together).\nThe problem with Dupioni is that it’s shiny and warms warm – the two qualities that drive men away from silk today. If you’re looking for a pure silk jacket, aim for something with a more open weave. Jeff Hilliard at The Armoury says he has something from Ring Jacket made from pure silk. “I find it wears comfortable even temperatures hit the mid-80s,” he says. “I like better than mohair, which many people recommend for summer.” The Armoury sells pure silk jackets through their various custom tailoring programs, and our sponsor Chipp can make sport coats out of Matka (which they currently use for ties).\nThe other option is to get a silk blend, which is what I prefer (if only because good silk blends are a lot easier to find than wearable pure silks). A silk-linen blend will wrinkle a little less than pure linen – allowing the jacket to drape more cleanly at the end of the day, rather than riding up on your body. I also really like wool-silk-linen mixes. Wool-linen tends to have a very dry look, but when you add just a touch of silk, it can have a nice, not-over-the-top sheen. Plus, silk gives a fabric a bit more strength, which is important for open weaves that would otherwise be too brittle.\nNo Man Walks Alone at the moment has a bunch of silk-blend jackets from Eidos and Sartoria Formosa. Even this plainer, brown silk jacket from Eidos sports a gummier finish – much like ancient madder – which to me just speaks to the uniqueness of silk cloths. The Armoury also carries some nice unstructured travel jackets made from distinctive wool-silk-linen blends (Armoury co-founder Mark Cho apparently choose the pink cloth based off a sport coat he commissioned years ago from Liverano & Liverano). I’m not usually one for dandier colors, but if you’re going to wear something as bold as pink, this sort of textured weave seems perfect.', 'Wool or Cashmere\n- Jul 06, 2017\nWool and Cashmere wool are fibers that can be blended together or combined with other materials to make garments and accessories. Cashmere and wool are soft, regulate body temperature and repel moisture — making these blends ideal choices for sweaters, hats, gloves and even socks. To maintain their positive features, wool and cashmere blends require cleaning and storage care.\n- What is Wool\nWool is a diverse natural fiber that is collected, sheared or clipped from sheep and other animals, such as goats, alpacas, rabbits and camels. Wool is an ideal textile fiber because of its water-resistant and insulating features. Wool can absorb approximately 30 percent of its weight in water vapor and repel moisture, unlike other fibers. Wool is very breathable while retaining body heat, making it ideal for clothing worn during winter sports, such as snowboarding and skiing.\n- What is Cashmere?\nCashmere is a luxury wool fiber that is taken from the fine undercoat of the Cashmere goat breed. Fibers are retrieved by combing or shearing during the spring season, when goats are molting. The collected fibers are washed to remove dirt and other debris. After the cleaning process, only the finest hairs are gathered by hand. The cashmere fibers are spun into thread, dyed any number of colors\nTypes of Blends\nCashmere is an elegant and comfortable material, but the fineness of its fibers as well as its color and length can dictate quality and softness. Although a garment may claim to be “100 percent cashmere,” manufacturers may blend wool fibers of poorer quality. High-quality pure cashmere blends tend to be made of long, thin fibers.\nIn addition to wool, cashmere is blended with silk material, which gives garments a soft luster. Cashmere can also be blended with cotton as an inexpensive material option.\nCashmere and wool can also be blended with manmade fibers. When wool is blended with acrylic (a synthetic fiber), the textile material can assume the positive characteristics of both fibers. For example, clothing of this blend can be extra warm and water resistant, yet lightweight and less likely to shrink.\nWool and cashmere blends are made of natural fibers, and more attention is required when treating, cleaning and storing these kinds of garments. When clothing is soiled, wool should be prepped before cleaning. Detach the entangled strands of fabric balls (known as pills) from the garment with a special sweater stone. Then turn garments inside out before washing to lengthen the lifespan of dyes.\nFine wool and cashmere should be hand-washed in warm or cold water with a gentle soap. For smaller clothing accessories such as hats and scarves, wool can be machine washed, but only on a gentle cycle with a mild soap.\nCashmere and wool should be not be machine dried, or shrinkage is likely to occur. Instead, press garments with clean towels to remove excess water and dry flat. This ensures that the garment maintains its shape.\nOnce completely air-dried, knitwear should be folded. If these special garments need to be hung, they can go on padded hangers. Cashmere tends to not wrinkle, though slight creases can be removed by steaming rather than pressing.']	['<urn:uuid:93f271bf-a392-4b82-9a55-fc8e59e0cffe>', '<urn:uuid:5fd67393-c74a-44ea-af7b-cf942daddd43>']	open-ended	direct	concise-and-natural	distant-from-document	comparison	novice	2025-05-12T13:53:09.865574	10	68	1068
12	For desalination, which technology produces more drinking water: MIT's passive solar system or Ampac's SW24K-LX watermaker?	Ampac's SW24K-LX watermaker produces significantly more drinking water than MIT's passive solar system. The SW24K-LX can produce 24,000 gallons per day (approximately 1,000 gallons per hour), while MIT's passive solar desalination system produces about 1.5 gallons per hour per square meter of solar collecting area.	"['Simple, solar-powered water desalination | MIT News ...A completely passive solar-powered desalination system developed by researchers at MIT and in China could provide more than 1.5 gallons of fresh drinking water per hour for every square meter of solar collecting area. Such systems could potentially serve off-grid arid coastal areas to provide an efficient, low-cost water source.\nMail: [email protected]\nOct 18, 2012 · Life-Cycle Costs of Rainwater Harvesting Systems: The IRC International Water and Sanitation Centre compares the costs and benefits of rainwater harvesting technologies to other water supply systems. How to Make Ferrocement Tanks : Akvopedia explains how to make ferrocement cisterns that can be used as a septic tank or rainwater catchment.(PDF) Solar powered water pumping systemsA solar powered water pumping system is made up of two basic components. gabon cave tank solar water engineering system technology pressure switch and tank and DC water pump gabon cave tank solar water engineering system technology April 2020 · International Journal for the History of Engineering gabon cave tank solar water engineering system technology\nSOLARVAP ® is the most sustainable water desalination system as it uses the suns energy to provide power to desalination plants, thus avoiding any GHE emissions. SOLARVAP ® is also an integrated and modular Zero Liquid Discharge solution, as it produces demineralized water from brines and wastewater.. Its the first industrial desalination solution, totally performed, using the suns gabon cave tank solar water engineering system technologySolar Water Pumping for Sustainable Water SupplyReview of Solar Photovoltaic Water Pumping System Technology This is the place to start when searching for academic literature on PVP. It covers a broad range of PVP-related issues, namely the current state of the technology, types of motors and pumps, technical performance, economic and environmental benefits, and initiatives in developing gabon cave tank solar water engineering system technologySolar Water Purification in India - energypedia.infoSolar distillation is a proven technology for water disinfection and the system can be customized from one person to community sized systems. They have a long life span of about 20 years and generally do not require moving parts.The water purification business in India is undergoing major changes, not just in terms of technology, but also in gabon cave tank solar water engineering system technology\nNov 23, 2013 · GROUNDWATER ENGINEERING Technology Data Sheet Solar Water Pumping Solar water pumping systems are a practical and affordable solution used to solve water shortage problems. Due to rolling blackout and the constantly rising cost of fuel, pumping of water from surface water and groundwater wells has become extremely difficult for farmers and gabon cave tank solar water engineering system technologySolar Energy Market Size, Trend | Industry Analysis and gabon cave tank solar water engineering system technologySolar Energy Market by Technology (Photovoltaic Systems and Concentrated Solar Power Systems), by Solar Module (Monocrystalline, Polycrystalline, Cadmium Telluride, Amorphous Silicon Cells, and Others), by Application (Residential, Commercial and Industrial) and End-Use (Electricity Generation, Heating, Charging and Lighting): Global Opportunity Analysis and Industry Forecast, 2019-2026Solar Powered Automatic Irrigation System - ECE ProjectsThe pump controller pumps water to the water tank at a particular time period as set in the control unit. This system is designed with 450W of power, which is capable of pumping 2000 liters of water within 60 minutes. This power capacity takes into account the height difference between the water tank and the solar submersible pump. The PV Panels\nSolar powered irrigation system can be a suitable alternative for farmers in the present state of energy crisis in India. This a green way for energy production which provides free energy once an initial investment is made. In this paper we propose an automatic irrigation system using solar power which drives water pumps to pump water from bore gabon cave tank solar water engineering system technologyWater Pump Dubai | Water Pump Suppliers in Dubai | GRP gabon cave tank solar water engineering system technologyOne of the world\'s leading manufacturers of pumps and pump systems for the building technology, water and industrial sectors with headquarters in Dortmund, Germany. Founded in 1872 as copper and brass factory by Louis Opländer, the company has over 60 subsidiaries in more than 50 countries and employs about 7,700 people worldwide.Automatic Irrigation System IEEE PAPER DESIGN Automation of watering the plants by sensing the moisture content of the soil. Automation of water tank filling by sensing the water level in the tank. Automation of finding leakage in water JOURNAL OF ENGINEERING SCIENCESRESEARCH TECHNOLOGY LOW COST SMART SOLAR POWERED AUTOMATIC IRRIGATION SYSTEM free download\nCHAPTER 9 SOLAR DESALINATION John H. Lienhard,1, Mohamed A. Antar,2 Amy Bilton,1 Julian Blanco,3 & Guillermo Zaragoza4 1 Center for Clean Water and Clean Energy, Room 3-162, Department of Mechanical Engineering, Massachusetts Institute of Technology, 77 Massachusetts Avenue, Cambridge, MassachusettsCommercial Vehicle Accident Reconstruction | Kimley-HornCommercial vehicle accidents are complex events involving multiple vehicles, mechanical systems, electronic data systems, and human factors. Unlike passenger cars, each commercial vehicle presents a unique electronic data system and requires special handling for proper preservation of evidence.Design and Development of 5MW Solar PV Grid 2.1 Solar PV Technology Solar PV Technology converts suns natural energy to useful electrical energy. Photo Voltaic modules are made of mono crystalline / polycrystalline solar cells connected in series and parallel modes. Type of solar panel used in this project is mono crystalline.\nStudents design ways to either clean a water source or find a new water source, depending on given hypothetical family scenarios. They act as engineers to draw and write about what they could do to provide water to a community facing a water crisis. They also learn the basic steps of the engineering Flow Rate Calculator | Spraying Systems Co.The specific gravity of water is 1. For more information on how to calculate specific gravity, contact your local sales person. Select standard 0.84 0.96 1.0 (water) 1.08 1.20 1.32 1.44 1.68Gabon National Infrastructure - A Master Plan - BechtelImplementing a strategic vision for Gabon. Gabons national infrastructure master plan (NIMP) involved establishing the countrys first public-works agency lAgence Nationale des Grands Travaux dInfrastructures (ANGTI) to deliver a pipeline of priority infrastructure projects, while raising construction standards of safety, quality, and project implementation to serve the nation\'s gabon cave tank solar water engineering system technology\nUnilec Power Systems is a company that manufactures diesel generator sets and Solar powered off grid and grid tied systems, and is based in Bloemfontein, South Africa. We have manufactured generator sets since 1998 and solar systems since 2013 and our technology and quality allows Unilec Power Systems to be a leader in the manufacturing of gabon cave tank solar water engineering system technologyHot Water Tank - an overview | ScienceDirect TopicsHot-water tanks serve the purpose of energy saving in water heating systems based on solar energy and in cogeneration (i.e., heat and power) energy supply systems. State-of the-art projects  have shown that water tank storage is a cost-effective storage option and that its efficiency can be further improved by ensuring optimal water gabon cave tank solar water engineering system technologyKinetico Water Systems""Our water system has made a huge difference in cooking and drinking. Water is excellent. Well worth the price. I recommend Kinetico to everyone."" Anastasia S. Dallas, TX ""Super happy! Water is crystal clear and for the first time in almost 20 years, I can drink my water\nLong Term Solar Energy System Performance Simplified Design Methods; Long Term Solar Energy System Performance Simplified Design Methods (Contd.) Monthly Average Daily Utilizability. Monthly Average Daily Utilizability; The phi(bar) - f chart method (Contd.) The phi(bar) - f chart method (Contd.) The phi(bar) - f chart method Tank Losses and gabon cave tank solar water engineering system technologyNew solar power nanotechnology material converts 90 gabon cave tank solar water engineering system technologyOct 29, 2014 · A multidisciplinary engineering team developed a new nanoparticle-based material for concentrating solar power plants designed to absorb and convert to heat more than 90 percent of the sunlight it captures. The new material can also withstand temperatures greater than 700 degrees Celsius and survive many years outdoors in spite of exposure to air and humidity.POWER AND WATER CORPORATION SOLAR/DIESEL in small solar/battery systems. Short-term energy storage is used to provide power over short periods, such as smoothing the intermittent output of a solar system in a solar/diesel mini-grid. There are various energy storage technology types suited to different applications including batteries, pumped hydro, compressed air, super-capacitors\nPassive solar design takes advantage of a buildings site, climate, and materials to minimize energy use. A well-designed passive solar home first reduces heating and cooling loads through energy-efficiency strategies and then meets those reduced loads in whole or part with solar energy. Because of the small heating loads of modern homes it is very important to avoid oversizing south-facing gabon cave tank solar water engineering system technologyPremises Liability | Kimley-HornKimley-Horn works with property owners, builders, insurance professionals, and attorneys to evaluate claims and injuries on a wide variety of properties.Pump Up the Storage | Do the MathThe main problem with gravitational storage is that it is incredibly weak compared to chemical, compressed air, or flywheel techniques (see the post on home energy storage options).For example, to get the amount of energy stored in a single AA battery, we would have to\nHow the system works. One sensor and automated irrigation device can work on one hectare, if it is a flat farmland. But, there should be availability of water in water tanks or dams as well as gabon cave tank solar water engineering system technologyRwanda: Young Innovators Develop Solar-Powered How the system works. One sensor and automated irrigation device can work on one hectare, if it is a flat farmland. But, there should be availability of water in water tanks or dams as well as gabon cave tank solar water engineering system technologySalt Production and Processing - Morton SaltSolar Evaporation MethodThis is the oldest method of salt production. It has been used since salt crystals were first noticed in trapped pools of sea water. Its use is practical only in warm climates where the evaporation rate exceeds the precipitation rate, either annually or for extended periods, and ideally, where there are steady prevailing\nJan 07, 2019 · Engineers have developed an innovative, low-cost technology to turn seawater into drinking water, thanks to the use of solar energy alone.Simple Water Level Indicator Alarm Circuit DiagramMay 15, 2015 · Water tank overflow is a common problem which leads to the wastage of water. Though there are many solutions to it like ball valves which automatically stop the water flow once the tank gets full. But being an electronics enthusiastic wouldnt you like an electronic solution for it? So here is a simple and handy DIY that will guide you to make a circuit which will detect the water level and gabon cave tank solar water engineering system technologySimple, solar-powered water desalination | MIT News gabon cave tank solar water engineering system technologyA completely passive solar-powered desalination system developed by researchers at MIT and in China could provide more than 1.5 gallons of fresh drinking water per hour for every square meter of solar collecting area. Such systems could potentially serve off-grid arid coastal areas to provide an efficient, low-cost water source.\nUnit 6: Solar Water Pumping Introduction to Basic Solar Water Pumping Applications of Solar Water Pumping Main Components of the Solar Water Pumping System Sizing & Designing a Solar Water Pumping System Installation Unit 6 Exercises 67 68 68 72 74 75 Frequently Asked Questions (FAQs) Appendix 87 91 Unit 7: Safety Precautions, Basic MaintenanceSolar Water Heater - Activity - TeachEngineeringSolar water heaters usually work in conjunction with an electric- or gas-powered water heating system, which kicks in if the solar water heater alone cannot meet demand. Reasons for the use of certain materials: The copper pipe and bottom of the collector are Stags Leap Wine Cellars Cave Entry & Shade Structure gabon cave tank solar water engineering system technologyStags Leap Wine Cellars Cave Entry & Shade Structure Napa, California gabon cave tank solar water engineering system technology the cave entry and shade structure that is a ventilated and screened enclosure for a cluster of fermentation tanks. Working in concert with the renowned eco-architect Javier Barba, we designed and executed a grand, yet contextually and environmentally sensitive gabon cave tank solar water engineering system technology\nIn contrast with solar PV, electricity generation by solar thermal technology is almost exclusively the province of large, utility-scale generators. Concentrated solar power (CSP) systems use mirrors or lenses to focus solar energy, heating a working fluid (such as water or oil) that drives an electricity-generating turbine.Training Manual for Engineers on Solar PV SystemTraining Manual for Engineers on Solar PV System TECHNICAL REPORT · JULY 2011 DOI: 10.13140/2.1.3156.9607 2 AUTHORS, INCLUDING: gabon cave tank solar water engineering system technology History of development of solar photovoltaic technology in Nepal 5 4. Basics of Electrical Engineering 11 gabon cave tank solar water engineering system technology Design aspects of water pumping systems 189 10.1 Introduction 191Video: Details of the Hyperion XP-1 hydrogen car emerge gabon cave tank solar water engineering system technologyAug 17, 2020 · The Hyperion XP-1 claims a range of 1,000+ miles per tank of hydrogen. Source: Hyperion The Hyperion XP-1 claims a range of 1,000+ miles per tank of hydrogen by means of an on-board proton exchange membrane fuel cell. This power unit converts stored hydrogen to electricity and propels the three-speed transmission vehicle from zero to 60 mph in just 2.2 seconds; top speed is\n900 water tank for concrete mixer , 26"" diameter , 48"" weld to weld , 100 gallon tank , stk #a18... China mixer truck part manufacturer, Truck Mixing Tank ...Sapre Parts Mixer Truck The Mixing Tank for Cement Mixer Truck Contact now The Clutch Pressure Plate (DZ91189160151) for Shacman M30\nice argon gas cylinder aluminum co2 bottles 99.999% industrial welding mixed 10l aluminium gas cylinder, 10l aluminium gas cylinder ...Largest factory supplier 10L high pressure aluminium alloy argon gas cylinder Liaoning Alsafe Technology Co., Ltd. Argon Gas Cylinder Suppliers, all Quality Argon Ga\nIstanbul, injuring two firefighters … Current Methods For Removing Heavy Metals From …Chemical oxidation and advanced oxidation are always used for the pretreatment of heavy metal wastewater containing organic compounds. Chemical Precipitation Chemical precipitation involves adding a precipitat\nnk Cap, Old Model JCB. 122-62400 JCB Diesel Tank Cap, Old Model Made to fit Bostech Aluminum Billet Fuel Filter Cap - Thoroughbred …We are also a real diesel repair shop that works on diesel trucks for free advice call toll free at 866-737-4966 or shop now for Ford Powerstroke 6.0L Aluminum Billet\nparts of a village. Scores more were injured in the accident in Sange ... More Than 60 Killed in Fuel Tank Explosion in Tanzania ...Aug 10, 2019 · In 2010, a fuel tanker overturned, caught fire and exploded in the Democratic Republic of Congo, killing more than 200 villagers, some of\nbillion ringgit ($477 million) oil storage and ship refueling site in … Oil and Gas Storage Tank Inspection, Audit ... - SGS MalaysiaAssure the integrity of your storage tanks by complying with local regulations and the relevant standards and codes; Trusted storage tank Inspection, audit and calib\nPlease describe your brand size and data volume in detail to facilitate accurate quotation\nCopyright @2020 Ezir. All Rights Reserved by HiBootstrap', 'Seawater Desalination Watermaker (Land Based) SW24000-LX (Dual 12,000 GPD Watermakers on one Skid)\nBrand: Ampac USA\nProduct Code: SW24K-LX\nMade in USA\nAMPAC USA Seawater Desalination Watermaker Land Based Model SW24K-LX\nMake of System:\nFully Automated Sea Water Desalination Watermaker Land Based 12,000 GPD | SW24K-LX sharing one skid capable of producing both a total of 24,000 GPD (Gallons per day) / (90m³/day) including Pre-Treatment, Sea Water Desalination Reverse Osmosis Process, Post Treatment, and On-Demand Delivery to Point of Use. This SW24000-LX is fully built on a Powder Coated Welded Aluminum Skid with Diamond Plate Base using good industrial practice and following manufacturer’s guidelines for every component as follows:\n- Production GPD: 12,000 x 2 = 24,000 Gallons Per Day\n- Production LPD: 3.8 m³/ Hr (90,840 Liters Per Day)\n- Grundfos On-Demand Feed Supply Pump\n- Spin Down Sand Pre-Filter\n- Ion Exchange Water Softener\n- Multimedia Carbon Pre-Filter\n- High Flow Sediment Pre-Filter\n- Triplex High Pressure Plunger Pump\nSea Water Membrane Elements\nAuto Fresh Water Flush\npH Neutralizer Alkaline Post-Filter\nSub-Micron Ceramic Post Filter\n- Ultra Violet Disinfection Sterilizer\n- Complete Panel for Easy Control\n- Inlet Actuator Valve with Bypass\n- Stainless steel liquid-filled pressure gauges\n- Low pressure cut off switch\n- Powder-coated, Welded Aluminum frame\n- Permeate and concentrate flow meters\n- Stainless Steel System Pressure Control\n- On/Off Main Power Switch\n- Dimensions: 18” wide x 18” deep x 44"" Height.\nProgrammable Logic Controller (PLC): All Ampac USA Seawater Desalination Watermakers are equipped with a Microprocessor Controller features an Alphanumeric Backlit LCD Screen to display operating conditions, and provides adjustable time delays and set points to accommodate varying field conditions in a NEMA 4X Rated Enclosure. The controller displays the permeate Salinity (TDS/Conductivity), water temperature, and operating hours along with the operating status of the RO unit. The PLC also monitors Low and High Pressure Switches, Tank Levels, and Pre-Treatment Equipment. It provides relay outputs for the Watermaker high pressure pump, inlet valve, membrane flush process, and optional relays for permeate divert or remote alarm and an auxiliary output.\nOn-Demand Feed Supply Pump: This Pump is designed to supply the Watermaker with Sea Water stored previously in a Settling Tank with the Required Flow and Pressure, This pump is a Multistage 316L Stainless Steel Jet High Pressure Pump with safeguards. This Pump is well known for its reliability and durability. It is are also equipped with a shaft seal and bearing system that can withstand extreme heat and friction for longer periods of time which makes it more forgiving if the pump does run dry.\nSpin Down Pre-Filter: A Manual Flush Clear See Through Sea Water Strainer with a cleanable Mesh Screen filter for ultimate corrosion resistance and large particulate removal.\nMultimedia Carbon Pre-Filter: Multimedia Pre-Filter will remove any excess Chlorine injected earlier, adjust pH and eliminate any excess bacteria. Since Multimedia filter has to backwash with raw water, therefore, rinse step has been provided in backwash sequence. The filters will automatically backwash, based on timer control.\nSediment Pre-Filter: Sediment Pre-Filter provides higher flow rates while removing dirt, sand and sediment from your water at high capacity.\nHigh Pressure Plunger Pump: These Triplex Plunger Pumps are designed for the Sea Water Desalination industry, resulting in pumps that deliver higher pressure and increased reliability, in fact, it will Boost the Sea Water Pressure up to 1200 PSI to ensure the best Desalination Process. A Motor Soft Start is Standard on all larger Watermakers from 4500 GPD and up that reduces start-up power by 60%.\nSea Water Membrane Elements: Ampac USA Integrates the Top Quality Filmtec by Down 8"" x 40"" Premium Membrane Elements designed to convert Seawater to Drinking Water at the highest Rejection and Productivity Technology has to offer.\nAuto Fresh Water Flush: This Process will flush the watermaker from the inside with fresh water after each use, ensuring no salt water corrode the system extending its service life, allowing you to optimize Watermaker Performance. This System will flush the watermaker every 24 hours if the system is not in use to prevent any bacteria growth inside the watermaker.\npH Neutralizer Alkaline Post-Filter: After the Desalination Process, the pH of the permeate (potable) water is expected to be in the range of 5.0 this is rather, acidic. This Post-Filter will adjust the pH level to Neutral 7.0 by Re-Mineralization right at the point of delivery.\nSub-Micron Ceramic Post Filter: In Many Locations of the world, Water may have contaminants which may affect the Watermaker, Ceramic Post Filters are designed to remove Particles from the water but leaves oxygen and mineral contents unchanged, which gives water it\'s spring-like freshness and taste. Pathogens of the most varied diseases which are reliably filtered from the water include; cholera, ecoli, typhus, dysentery, cryptosporidium, amoebic colibacillose or bilharzia, anthrax spores among others. Ceramic filtration technology is often called ""dead-end filtration” and ""depth filtration"".\nUltra Violet Sterilization Light: As a Final Stage, Ultra Violet Disinfection is introduced as Microorganisms in water can cause a multitude of health problems. Ultraviolet System is the natural way to disinfect water. UV light penetrates and destroys the harmful organism, disinfecting the water.\nNoise Reduction: All Ampac USA Watermakers comes equipped with an Accumulator Pulsation Noise Dampener to reduce noise and vibration to acceptable Decibel Noise levels.\nMonitors: All our Watermakers comes with the following Instrumentation Monitors: Stainless Steel Glycerin Filled Pressure Gauges: Installed after each Stage to monitor Pressure at every step of the desalination process.\n- Visual Flowmeters: Those Flowmeters are installed to monitor Productivity Permeate and Concentrate.\n- Salinity Monitor: Shows actual Product Water Quality, an Essential Tool for Product Water Monitoring.\n- Hour Meter: To maintain accurate logs of operation hours and keeping schedule preventative maintenance.\n- Temperature Monitor: To keep accurate logs of production capacity versus temperature of feed water supply.\n- All Ampac USA Watermakers are equipped with Low Pressure Sensors for failsafe operation.\n- All Ampac USA Watermakers are equipped with High Pressure Diverter Valves for Operator Saftey.\n- All Terminals are shielded and all high voltage components covered for end-user safety.\n- All Electrical Components are UL / CE Certified and enclosed in a NEMA4X Rated Enclosures.\n- All Water Quality Components are NSF Approved for Drinking Water Applications.\nService & Maintenance:\n- Ampac USA Watermakers are tested for tougher conditions and QA Certified by factory.\n- Ampac USA Watermakers are shipped from the factory ready to install and function.\n- A Comprehensive and Detailed Owner\'s Operation & Maintenance Manual in included with every Watermaker.\nProduction Based on the Following Feed water Conditions:\n|Water TDS||< 45,000 ppm|\n|Electrical||380V/460V/600V 50Hz/60Hz Single or 3 Phase power|\n|Frequecy||50Hz/60Hz Single or 3 Phase power|\n|Production||Over a 24-Hour Period.|']"	['<urn:uuid:3a1a7135-2dd7-40d5-a027-95845af13b0d>', '<urn:uuid:0f47123e-6e58-407a-ad9c-73eecc6f232f>']	open-ended	with-premise	concise-and-natural	distant-from-document	comparison	expert	2025-05-12T13:53:09.865574	16	45	3672
13	What are the technical implications of white balance settings for video recording, and how does it differ from photographing holiday lights in terms of color adjustment?	For video recording, white balance is permanently baked into the footage and difficult to correct in post-production if not matched between shots. It's measured in Kelvin, with 5500K matching midday sunlight, and should be frequently checked when shooting in changing daylight. In contrast, when photographing holiday lights, automatic white balance should actually be turned off to preserve the rich, saturated colors of the lights, as auto white balance would try to neutralize these desired color casts and result in dull, desaturated images.	"['I’ve made no secret that I’m a huge fan of vintage lenses. These old lenses …\nThis is one of the most important settings to get right in camera.\nUnlike your RAW still images, your White Balance is going to be baked into your image and it’s a real pain in the ass to correct in post if you don’t match these up from shot to shot.\nYour White Balance is how your camera determines what is White. It will ALL look white to human eyes- because we have incredibly dynamic vision and our brains interpret the light values that come in through our sensors and tell us “OH- this is white, based on everything around us”.\nThe camera can’t do that, so it’s important to take this into account when shooting under different lighting conditions. While the presets can do a pretty good job for you, using the Kelvin adjustment is my preferred method of NAILING your White Balance.\nYou’ll notice that your white balance is expressed in Degrees Kelvin. Kelvin is a way of reading absolute temperature, named after lord Kelvin. Absolute Zero Kelvin is where nothing is able to move anymore- not even atoms. The temperatures tat are used here display the color that IRON glows to when heated to that particular temperature. If you heat a piece of iron to 5500 degrees, it should give off the exact same color as the sun during mid-day. Colors are considered “warmer” and “cooler” based on this indicator, and that is basically all you need to know about white balance for now. Dial it in and check it frequently if you are suing daylight and the sun’s position is changing\nThis is an advanced ISO setting. It was once said that your Canon camera has a 160 “Native ISO”, and that all your ISO settings should bee in multiples of to get less noise in your images. While a little further research proves that that is not TECHNICALLY true, it still maintains that your images will have less noise when entered in multiples of 160. What your camera is actually doing is entering in an ANALOG ISO, and then doing a 1/3 stop “Digital Pull” to clean up the image a little bit. I have found that if I can, I use ISO in multiples of 160, but if I need to go higher or lower a touch, I don’t sweat it too much.\nIn your submenu you will have a few settings:\nEquivalent ISO: This is what your iso will end up looking like.\nAnalog ISO: This is what your iso ACTUALLY is.\nCanon Digital ISO: This is where you can see that your camera is pulling your iso down by a third of a stop when you go to 160, etc.\nML digital ISO: You can use this to REALLY get to the extremes of iso, anywhere from 50 ISO to 51,200 ISO.\nHighlight Tone Priority: This is a setting that lets you get a little more dynamic range in your highlights and will extend your iso. This is one of those features that sounds great on paper, but in practice, I find it gives me a noisier image and I am never happy with it. You should keep your highlight tone priority turned off in camera and try to find a better way to get the light if you can. If you can’t then there is this option for you.\nThis lets you micro- adjust your shutter speed settings.\nIf you set your Expo Override to ON, you can tune in your shutter speed to get you closer to 180 degree shutter (which is what you want to shoot in 99% of the time).\nAgain, if your Expo Override is on, you can set your aperture to adjust is 1/8 increments in Movie Mode. This lets you “split” your ISO the way a stepless aperture ring does. Obviously, this is for lenses that are being controlled by the camera. If you are using a manual or vintage lens, you will be adjusting exposure by hand.\nI love this feature. It will tell you what your picture style that you are recording in- but more importantly- it will let you PRE-SET your recording picture style. This will let you set up your picture and exposure with a “normal” picture style, and then it will AUTOMATICALLY switch it over to a different style (a flat one) once you start recording.\nNothing is worse than forgetting to switch picture profiles on a shot and not having it match up with the rest of your footage.\nThis will set your exposure metering up so that you are exposing to the right jus a bit to preserve your highlights. We will go into more detail with this feature in the MODULES section.\nI can see how some people would love this feature as it keep their exposure levels the same. What is does is adjust the points on your “Exposure Triangle” to maintain the sam amount of light automatically. I’m not a fan of this method. If I need more light, I want to know it before the camera bumps up the ISO/shutter speed/aperture and I end up with some shots that are noisier than others. Photography is about painting with light, and you want to control as many variables as you can to craft the image.\nIf you find yourself toggling through your menu instead of your click wheel to change these settings, turning this on can save you some menu hunting.\nThis is for a very specific style of Post Production Workflow, and we won’t go too much into it here. The camera alternates ISO between two different levels, and you can run it through some software that re-integrates the images to produce a final product that has more dynamic range. I have seen some beautiful samples out there, and if you are someone who loves the extended workflow of RAW, then I would highly recommend you look into this method of shooting as well. Be advised- you are COMMITTED to this post production workflow when you shoot this way- there is no backing out.\nSetting this to ON will override any exposure limitations that Canon has set in place.\nThis works in conjunction with your Exposure Override to let you see a more accurate rendition of what your image will look like when using Live View.\nTotally honest here- I have no idea how to actually use this in a production setting. I have a feeling this is a feature that will lay the groundwork for more modules in the future.', 'At this time of year, many of the world\'s cultures and religions celebrate holidays that involve lights.\nYears ago, taking great photographs of holiday lights was difficult because the films of yesteryear weren\'t very light sensitive.\nThey had difficulty recording an image in the low-light of a candle, for example. This is no longer the case as technology has solved these problems. Many DSLRs can be set to ISO 6400, 12,800 and even higher settings with little noise.\nIn addition, most photographers today rely on auto-exposure with their point-and-shoots or DSLRs. Unlike the light meters of old, which were often ""fooled"" by low-light situations, today\'s meters in auto-exposure cameras are able to give good readings even in low light.\nThis is an important point because holiday lights usually look their best when shot without added light. In fact, this is Rule One when it comes to getting good pictures of lights: Turn off your flash. Let\'s repeat that: For most pictures of holiday lights, turn off your flash!\nNote that we said ""most."" There are a few occasions when you will want to add light, but usually you won\'t.\nNow, let\'s remember one important point if you\'re taking a picture without flash: You\'re probably going to need a slow shutter speed. This means you may need to mount your camera on a solid unmoving surface to avoid camera-shake. A tripod is best.\nWhen else might you want to use your flash?\nLet\'s say the subject of your picture is your kids under the tree. How are you going to light their faces? On the one hand, you may find that the Christmas-tree lights are sufficient and give a very soft glow to their cherubic expressions. Or maybe it is Christmas morning, and they are lighted by window-light that is streaming into the room. In these cases, you don\'t need your flash. But, on the other hand, maybe you don\'t have enough light to really see their faces. Then you may have to use your flash. How do you know which way to go?\nOne approach is to shoot both ways, then select the better image. We think a better way is to plan ahead and meter your subject. Remember that Guideline One of the Three NYIP Guidelines for Great Pictures is to decide on your subject before you do anything else. In this case, you\'ve decided that the subject is the faces of the kids. Guideline Two is to draw attention to your subject. One method of drawing attention is to make sure your subject is well-exposed. So meter the light that falls on their faces from the lighted tree. Get in close and meter just the faces! If there\'s enough available light for a well-exposed picture, shoot it. If not, use your flash.\nNow let\'s move outdoors.\nHere we see elaborate lighting on apartments, stores, and the street. Again, if you want to capture the lights themselves, don\'t use your flash.\nOne other tip for outdoor lights — you\'ll get the best results when you shoot at twilight. That way, you\'ll capture some color in the sky, rather than the pitch-black tone that will be recorded on film later at night.\nBut what if you want to take a picture of your friend in front of a brightly lit display?\nYou want to capture both the bright lights and your friend. If you use flash, you get your friend, but you\'re in danger of minimizing the bright lights behind. On the other hand, if you don\'t use flash, you get better detail of the lights but your friend is reduced to a silhouette.\nThere\'s an answer. Many of today\'s point-and-shoot cameras have a Night Portrait Mode. This setting tells the camera that you want the flash to fire (which will light your friend in the foreground); but that you also want the lens to stay open long enough to record the lights in the background. Your solution to getting light on your friend\'s face and capturing the light display is to use this setting. The flash exposes the face. The long exposure captures the lights.\nBut, again, watch out here. The long exposure — typically, one-quarter of a second long — requires that you steady your camera to avoid camera shake. Once again, we advise you to use a tripod.\nTo take great holiday photos in this season of lights, we offer you these 4 tips:\n- Turn off your flash unless you have a very good reason to use it.\n- Use a fast ISO — we suggest ISO 800, 1600 or above.\n- Avoid camera shake.\n- Use a tripod...or, at least, brace the camera. Trust your camera\'s built-in meter.\nSome Special Considerations\nAmplifying a digital signal is like turning the volume up on your radio as loud as it will go. At the maximum volume every hiss, pop, and scratch is heard and, depending on the quality of the equipment, quality is diminished. The same thing happens in a digital camera. When the ISO setting is increased, every image artifact and defect is magnified.\nTo achieve the best image quality, you might try working with a slower ISO setting to start. If you are having trouble getting a good exposure, increase the ISO as needed. You might even try using the Auto ISO setting and see how the camera chooses to handle exposure.\nRegardless of the ISO setting chosen, most inexpensive digital cameras produce ""noise"" during long exposures. Noise is caused by the small electrical disturbances that are present in every electrical system. In order to capture a weak light signal, such as a subject in low-light, longer exposures are usually needed. The longer a digital camera shutter is open, the more electrical noise is recorded as well.\nSo, it seems we have a double-edged sword: Increase the ISO to achieve faster shutter speeds and you will amplify noise and other image problems. Reduce the ISO and shutter speeds are slower. As a result, you will record inherent noise that might not be seen in a ""normal"" exposure.\nLimited Dynamic Range\nTo make things worse, digital cameras have a limited dynamic range. Image sensors are only sensitive to a specific range of brightness. Anything outside of that range is recorded as pure white or pure black. This can result in an image without shadow or highlight detail.\nHere are a few ways to solve these problems. Noise can be reduced with software. In fact some cameras offer in-camera noise reduction features. Proprietary software is used exclusively, yielding uneven results. Test your camera\'s capabilities before committing to this feature. There are many noise reduction software products on the market today, some as stand-alone applications and others which are plug-ins that work in conjunction with your favorite image editor. This means you can select a camera with noise reduction or address any problems later in the digital ""darkroom.""\nTiming is Everything\nAs we noted earlier in this article, when shooting holiday lights outside, I find that the best exposures can be made at twilight. Twilight is after the sun has set but before the dark of night. This fleeting balance of light and shadow will yield the brilliance of the lights while maintaining details in the shadow. Don\'t underestimate shadow detail to help establish your composition. Consult your camera\'s manual for details on your white balance options and how to adjust them. In the finished photo the viewer will perceive the twilight photo to be taken at night.\nWhen shooting holiday lights inside, try turning on lights in the room to increase the ambient light, rather than using a flash. Flash can produce a harsh, high-contrast quality that obliterates the brilliance of the light. A carefully positioned incandescent light can work increase the ambient light without overpowering your holiday lights.\nShoot Two Exposures\nOne way to extend the tonal range of a digital image is by making two exposures of a scene. Shooting in Manual mode, make one exposure configured to capture the best highlight detail. Make a second exposure to capture the best shadow detail. Then combine the two exposures in Photoshop as separate Layers. Using the Eraser tool remove poorly exposed areas to reveal detail and take advantage of the best parts of each Layer/exposure. Using this technique you could extend the tonal range well beyond the possibility of any single exposure made with the same camera. Of course this requires a strong tripod to ensure both compositions match perfectly. Consider using a remote control to reduce the possibility of camera movement.\nAccomplished photographers may also create two separate images‚— one favoring highlights, the other shadows‚ — from a single RAW file.\nTurn Off Automatic White Balance\nIn many photographic situations white balance is a godsend. By automatically neutralizing extreme color casts, believable digital color is rendered without breaking a sweat. It is important to remember, not all photos require white balance. Tone down the rich, saturated colors of a sunset and you\'re left with nothing. Attempt to white balance a fireworks display and you end up with dull lifeless, de-saturated bursts and streaks of light. Holiday lights should be treated similarly. By turning off the auto white balance feature you are sure to capture the exaggerated colors the holidays have to offer.\nYou could try turning off white balance altogether or even experiment with any of the other manual settings to find a color balance that suits your visual needs. Either way is a better bet than giving the decision to the camera.\nTest, Test, Test\nThe immediate feedback of digital photography begs you to test your exposures to determine what works best. Take advantage of the metadata that most digital cameras embed inside every digital picture you make. Metadata can include camera make and model, exposure, flash, white balance and other important information that can help you to determine what works and what doesn\'t work. This means you don\'t even have to take notes! The Camera Data screen reveals shutter speed, aperture, ISO settings, lens focal length, flash settings and even the metering modes.\nHoliday lights are usually around for more than a couple of days each year, take advantage of this by shooting early in the season and then re-shooting if you have to.\nFor the past 100 years The New York Institute of Photography has been educating photographers of all backgrounds. We offer diverse photography classes, starting with our most comprehensive course: The Complete Course in Professional Photography. Study with us online, at your own pace. Learn more today!']"	['<urn:uuid:0d86d112-cd70-4e4e-8f00-485750dc95ec>', '<urn:uuid:7820c7ff-f857-4178-b5c5-7dd0a51ad6a0>']	factoid	direct	verbose-and-natural	similar-to-document	multi-aspect	expert	2025-05-12T13:53:09.865574	26	82	2860
14	As a genomics researcher, I'm curious about how the size of the wheat genome compares to that of the fruit fly (Drosophila melanogaster) - can you explain the difference and its implications for sequencing?	The wheat genome is significantly larger than the fruit fly genome. The bread wheat genome is approximately 16 Gigabases (about 5 times the size of the human genome), while the Drosophila melanogaster genome is only 1.3×108 base pairs. This massive size difference made wheat genome sequencing particularly challenging, requiring the genome to be broken down into 41 smaller, manageable pieces (40 chromosome arms and chromosome 3B) to make the sequencing task more approachable. Each piece was roughly comparable to sequencing a rice genome. The wheat genome's size and complexity, including its three ancestral genomes and high percentage of repetitive elements, complicated the assembly process, requiring special approaches like chromosome-based physical maps and the DeNovoMAGICTM software to achieve successful sequencing.	"['The Wheat Genome Sequence Odyssey\nPosted 9th August 2017 by Fabio Caligaris\nAs the world population is expected to reach 9.8 billion by 2050, it is crucial to have innovative genomics tools to address global food security in a sustainable way. At the 5th Plant Genomics and Gene Editing Congress: Europe, Kellye Eversole, Executive Director of the International Wheat Genome Sequencing Consortium (IWGSC), announced that a high-quality reference sequence of the wheat genome is now available for the research community. The reference sequence is an essential tool to accelerate crop improvement programmes and wheat genomics research.\nThis achievement is the result of 12 years of collaborative research, which began in December 2004 when Kansas Wheat and Kansas State University, under the leadership of Forrest Chumley, hired Kellye Eversole to establish an international consortium that would lay a foundation for a paradigm shift in wheat breeding. The IWGSC odyssey began in the spring of 2005 as four individuals – Kellye Eversole, Rudi Appels, Bikram Gil, and Catherine Feuillet – launched the International Consortium with a vision of completing a useful sequence of bread wheat for the breeding community.\nOne of the first steps was to determine what should be sequenced: progenitors of bread wheat, or one of the diploid, tetraploid, or hexaploidy wheats. Industry and growers made the choice simple. They unanimously supported sequencing what is growing on 95% of wheat fields, the hexaploid bread wheat genome, Triticum aestivum, and preferably the variety for which the most genetic stocks exist and which could be translated quickly into breeding programmes.\nBut, bread wheat is huge (~16 Gigabases – i.e. 5 times the size of the human genome), complex (three ancestral genomes – one of which is unknown), and contains a high percentage of repetitive elements that complicates assembly of genome sequences. At the time, only rice had a high-quality reference genome sequence available and the rice genome is equivalent to one of the smaller bread wheat chromosomes.\nIn the landscape of rapidly changing sequencing technologies, it was critical to select an approach that would be “technology neutral”, i.e. one that would allow them to build resources that could be used regardless of the sequencing technology available at the time. Then, the only technology neutral foundation was a BAC-based physical map. As most breeders rely on the information contained within individual chromosomes and as the Consortium was able to reduce the complexity of the genome by focusing on manageable pieces, chromosome-based physical maps were selected as the foundation that would underpin any sequencing technology.\nThus, the goal of the IWGSC was to produce a high-quality, physical map-based, ordered, and annotated genome sequence comparable in quality to the rice genome sequence. Having a complete, ordered sequence was considered key, as it would allow breeders to drastically reduce the time between gene discovery and commercially available variety.\n41 Rice Genomes\nLuckily, a laboratory in the Czech Republic led by Jaroslav Dolezel had developed a technology to flow sort chromosome arms, breaking down the huge bread wheat genome into 41 smaller, much manageable, pieces (40 chromosome arms and chromosome 3B). The challenge seemed more approachable and comparable to sequencing 41 rice genomes! The first BAC library was ready (3B) and the lab started working on the production of 40 chromosome arm specific BAC libraries.\nThe concept of building physical maps for each chromosome/chromosome arm of bread wheat was a daunting challenge and was viewed with much scepticism by most in the scientific community. However, scepticism turned to interest in 2008 with the completion of the high-quality physical map of the largest wheat chromosome – 3B, equivalent in size to the entire soybean genome. With this success, projects were launched in many countries to develop physical maps of chromosomes and, with financial support from Bayer CropScience, all physical maps were completed by 2015. Since they were working with chromosome-based physical maps, it was not necessary to wait until all the maps were finished before sequencing could begin. Work began in 2009 to sequence chromosome 3B and others followed as the maps were completed. This method also facilitated map-based cloning projects on these individual chromosomes.\nAs sequencing technologies became more efficient and affordable, the IWGSC established a side project in 2010 that would generate draft survey sequences of individual chromosomes. This would provide at least some information on each chromosome and would allow breeders to start isolating or refining regions of interest. The work on chromosome specific BAC-based physical maps and pseudo-molecule sequencing continued in parallel.\nThe real breakthrough came with the software DeNovoMAGICTM which was developed by the firm NRGene to be used to assemble Illumina whole genome sequence. With this, the IWGSC could produce a whole genome assembly of the 16Gb genome in 7 months and validate its quality against other sequence-based and chromosome-based resources developed by the IWGSC over the previous years. They released the whole genome assembly with Hi-C and POPSeq to the scientific community in June 2016. Although this was an impressive assembly, it did not completely achieve the high-quality standard that was the target for the IWGSC.\nSince June 2016, the IWGSC has integrated all chromosome-based resources (physical maps, genetic maps, whole-genome-profiling-WGPTM sequence tags, optical maps, and markers) and released in January 2017 IWGSC RefSeq v1.0, the first version of the high-quality reference sequence of bread wheat.\nHaving at their disposal all the chromosome-based resources and the WGPTM tags generated over the previous years proved invaluable as the quality of the assembly tripled with the addition of these resources. Most of these were used to refine the order of the sequence and to decrease the number of pieces per chromosome (to an average of 75 scaffolds per chromosome). The automated annotation process, using two different annotation pipelines to develop a high confidence set of genes, was completed and released to the community in June 2017. Final analysis is underway and the goal is to submit the manuscript by late summer 2017.\nWhat started with 4 people in 2005, has now grown to 1800 members working in more than 530 institutes or companies in 62 countries. The IWGSC reached its goal of generating a high-quality reference sequence of bread wheat, a significant milestone for agriculture and the scientific community and now work will focus on manual and functional annotation of the reference sequence as well as sequence improvement. All the IWGSC data are available under the Toronto agreement at the IWGSC data repository hosted by URGI-INRA (France).\nSo, what are the lessons learned from this odyssey?\n- Every crop of importance for food, feed and fibre should have at least one high-quality manually and functionally annotated reference sequence, preferably more.\n- BAC libraries are essential for generating high-quality references and are critical for map-based cloning.\n- Maintaining flexibility is crucial so one can adopt new technologies as they are developed without losing sight of the need for quality.\n- The key guiding principle is to never lose sight of the original vision even when the rest of the scientific community may not be supportive.\nView the agenda here.\nLeave a Reply', 'Individual differences |\nMethods | Statistics | Clinical | Educational | Industrial | Professional items | World psychology |\nBiological: Behavioural genetics · Evolutionary psychology · Neuroanatomy · Neurochemistry · Neuroendocrinology · Neuroscience · Psychoneuroimmunology · Physiological Psychology · Psychopharmacology (Index, Outline)\nIn biology the genome of an organism is its whole hereditary information and is encoded in the DNA (or, for some viruses, RNA). This includes both the genes and the non-coding sequences of the DNA. The term was coined in 1920 by Hans Winkler, Professor of Botany at the University of Hamburg, Germany, as a portmanteau of the words gene and chromosome.\nMore precisely, the genome of an organism is a complete DNA sequence of one set of chromosomes; for example, one of the two sets that a diploid individual carries in every somatic cell. The term genome can be applied specifically to mean the complete set of nuclear DNA (i.e., the ""nuclear genome"") but can also be applied to organelles that contain their own DNA, as with the mitochondrial genome or the chloroplast genome. When people say that the genome of a sexually reproducing species has been ""sequenced,"" typically they are referring to a determination of the sequences of one set of autosomes and one of each type of sex chromosome, which together represent both of the possible sexes. Even in species that exist in only one sex, what is described as ""a genome sequence"" may be a composite from the chromosomes of various individuals. In general use, the phrase ""genetic makeup"" is sometimes used conversationally to mean the genome of a particular individual or organism. The study of the global properties of genomes of related organisms is usually referred to as genomics, which distinguishes it from genetics which generally studies the properties of single genes or groups of genes.\nMost biological entities more complex than a virus sometimes or always carry additional genetic material besides that which resides in their chromosomes. In some contexts, such as sequencing the genome of a pathogenic microbe, ""genome"" is meant to include this auxiliary material, which is carried in plasmids. In such circumstances then, ""genomeey"" describes all of the genes and non-coding DNA that have the potential to be present.\nIn vertebrates such as sheep and other various animals however, ""genome"" carries the typical connotation of only chromosomal DNA. So although human mitochondria contain genes, these genes are not considered part of the genome. In fact, mitochondria are sometimes said to have their own genome, often referred to as the ""mitochondrial genome"".\nGenomes and genetic variation Edit\nNote that a genome does not capture the genetic diversity or the genetic polymorphism of a species. For example, the human genome sequence in principle could be determined from just half the DNA of one cell from one individual. To learn what variations in DNA underlie particular traits or diseases requires comparisons across individuals. This point explains the common usage of ""genome"" (which parallels a common usage of ""gene"") to refer not to any particular DNA sequence, but to a whole family of sequences that share a biological context.\nAlthough this concept may seem counter intuitive, it is the same concept that says there is no particular shape that is the shape of a cheetah. Cheetahs vary, and so do the sequences of their genomes. Yet both the individual animals and their sequences share commonalities, so one can learn something about cheetahs and ""cheetah-ness"" from a single example of either.\nGenome projects Edit\n- For more details on this topic, see Genome project.\nThe Human Genome Project was organized to map and to sequence the human genome. Other genome projects include mouse, rice, the plant Arabidopsis thaliana, the puffer fish, bacteria like E. coli, etc. In 1976, Walter Fiers at the University of Ghent (Belgium) was the first to establish the complete nucleotide sequence of a viral RNA-genome (bacteriophage MS2). The first DNA-genome project to be completed was the Phage Φ-X174, with only 5368 base pairs, which was sequenced by Fred Sanger in 1977. The first bacterial genome to be completed was that of Haemophilus influenzae, completed by a team at The Institute for Genomic Research in 1995. Many genomes have been sequenced by various genome projects. The cost of sequencing continues to drop, and it is possible that eventually an individual human genome could be sequenced for around several thousand dollars (US).\nComparison of different genome sizes Edit\n- Main article: Genome size\n|Organism||Genome size (base pairs)|\n|Virus, Bacteriophage MS2||3569 - First sequenced RNA-genome|\n|Virus, Phage Φ-X174;||5386 - First sequenced DNA-genome|\n|Virus, Phage λ||5×104|\n|Bacterium, Carsonella ruddii||1.6×105 - Smallest non-viral genome, Feb 2007|\n|Bacterium, Buchnera aphidicola||6×105|\n|Bacterium, Wigglesworthia glossinidia||7×105|\n|Bacterium, Escherichia coli||4×106|\n|Amoeba, Amoeba dubia||6.7×1011 - Largest known genome, Dec 2005|\n|Plant, Arabidopsis thaliana||1.2×108 - First plant genome sequenced, Dec 2000|\n|Plant, Fritillaria assyrica||1.3×1011|\n|Plant, Populus trichocarpa||4.8×108 - First tree genome, Sept 2006|\n|Nematode, Caenorhabditis elegans||8×107|\n|Insect, Drosophila melanogaster aka Fruit Fly||1.3×108|\n|Insect, Bombyx mori aka Silk Moth||5.30×108|\n|Insect, Apis mellifera aka Honey Bee||1.77×109|\n|Mammal, Homo sapiens||3×109|\nNote: The DNA from a single human cell has a length of ~1.8m.\nSince genomes and their organisms are very complex, one research strategy is to reduce the number of genes in a genome to the bare minimum and still have the organism in question survive. There is experimental work being done on minimal genomes for single cell organisms as well as minimal genomes for multicellular organisms (see Developmental biology). The work is both in vivo and in silico.\nGenome evolution Edit\nGenomes are more than the sum of an organism\'s genes and have traits that may be measured and studied without reference to the details of any particular genes and their products. Researchers compare traits such as chromosome number (karyotype), genome size, gene order, codon usage bias, and GC-content to determine what mechanisms could have produced the great variety of genomes that exist today (for recent overviews, see Brown 2002; Saccone and Pesole 2003; Benfey and Protopapas 2004; Gibson and Muse 2004; Reese 2004; Gregory 2005).\nDuplications play a major role in shaping the genome. Duplications may range from extension of short tandem repeats, to duplication of a cluster of genes, and all the way to duplications of entire chromosomes or even entire genomes. Such duplications are probably fundamental to the creation of genetic novelty.\nHorizontal gene transfer is invoked to explain how there is often extreme similarity between small portions of the genomes of two organisms that are otherwise very distantly related. Horizontal gene transfer seems to be common among many microbes. Also, eukaryotic cells seem to have experienced a transfer of some genetic material from their chloroplast and mitochondrial genomes to their nuclear chromosomes.\n- gene family\n- Genome Comparison\n- Genome project\n- Human genome\n- List of omics topics in biology\n- List of sequenced eukaryotic genomes\n- List of sequenced prokaryotic genomes\n- List of sequenced archeal genomes\n- Mitochondrial genome\n- molecular systematics\n- molecular evolution\n- Honey Bee Genome Sequencing Consortium\n- ↑ Fiers W, et al. (1976). Complete nucleotide-sequence of bacteriophage MS2-RNA - primary and secondary structure of replicase gene. Nature 260: 500-507.\n- ↑ Fiers W, Contreras R, Haegemann G, Rogiers R, Van de Voorde A, Van Heuverswyn H, Van Herreweghe J, Volckaert G, Ysebaert M (1978). Complete nucleotide sequence of SV40 DNA. Nature 273 (5658): 113-120.\n- ↑ Sanger F, Air GM, Barrell BG, Brown NL, Coulson AR, Fiddes CA, Hutchison CA, Slocombe PM, Smith M (1977). Nucleotide sequence of bacteriophage phi X174 DNA. Nature 265 (5596): 687-695.\n- Benfey, P and Protopapas, AD (2004). Essentials of Genomics. Prentice Hall.\n- Brown, TA (2002). Genomes 2. Bios Scientific Publishers.\n- Gibson, G and Muse, SV (2004). A Primer of Genome Science (Second Edition). Sinauer Assoc.\n- Gregory, TR (ed) (2005). The Evolution of the Genome. Elsevier.\n- Reece, RJ (2004). Analysis of Genes and Genomes. John Wiley & Sons.\n- Saccone, C and Pesole, G (2003). Handbook of Comparative Genomics. John Wiley & Sons.\n- Werner, E. In silico multicellular systems biology and minimal genomes, Drug Discov Today. 2003 Dec 15;8(24):1121-7. PubMed\n- DNA Interactive: The History of DNA Science\n- DNA From The Beginning\n- All About The Human Genome Project from Genome.gov\n- Animal genome size database\n- Plant genome size database\n- GOLD:Genomes OnLine Database\n- The Genome News Network\n- NCBI Entrez Genome Project database\n- NCBI Genome Primer\n- BBC News - Final genome \'chapter\' published\n- Software that maps an Artificial Genome sequence to a Network and to a Lineage tree\n- IMG The Integrated Microbial Genomes system, for genome analysis by the DOE-JGI.\n|This page uses Creative Commons Licensed content from Wikipedia (view authors).|']"	['<urn:uuid:891e7b67-3e2f-4465-bd20-1261c31f5d6b>', '<urn:uuid:e0258935-cde6-40fa-9c78-9201cd700937>']	open-ended	with-premise	verbose-and-natural	distant-from-document	comparison	expert	2025-05-12T13:53:09.865574	34	119	2625
15	In ancient Sanskrit wisdom, how does the tradition describe the relationship between humans who plant trees and the trees themselves?	According to Sanskrit texts, as the fruit and flowers of trees soothe humans, those who plant saplings are blessed by the trees in another world too.	['Sanskrit scriptures are full of texts describing the significance of trees. Here are some of the most Popular Trees Name in Sanskrit!\nFrom the Vedic ages, the trees have been considered very sacred and are referred to as “the treasure for the generations” according to the Rig Veda Samhita. Here’s an exclusive list of some of the most Popular Trees Name in Sanskrit!\nपुष्पिताः फलवन्तश्च तर्पयन्तीह मानवान् ।\nवृक्षदं पुत्रवत् वृक्षास्तारयन्ति परत्र च ॥\nAs the fruit and flowers of the tree soothe the humans, similarly, those who plant saplings are blessed by the trees in another world too.\nCheck out our article on fruit names in Sanskrit here\nPopular Trees Name in Sanskrit\n1. Jujube Tree/ Ber\nBotanical Name: Ziziphus mauritiana\nSanskrit Name: Badari\nThis deciduous tree has spiny branches that grow in a zig-zag pattern.\n2. Bael Tree / Bilwa\nBotanical Name: Aegle marmelos\nSanskrit Name: Bilva / Adhararuha / Sivadrumah\nIts thorny branches are covered with trifoliate foliage and nutritious fruits.\n3. Sandalwood Tree / Chandan\nBotanical Name: Santalum album\nSanskrit Name: Chandana\nNative to India, its fragrant woods and oil are used in religious rituals and aromatherapy.\n4. Teak Tree / Sagon\nBotanical Name: Tectona grandis\nSanskrit Name: Shak / Saka\nThis tropical tree is prized for its water-resistant and durable wood.\n5. Mango Tree / Aam\nBotanical Name: Mangifera indica\nSanskrit Name: Amram\nThis deep-rooted, evergreen tree is covered with glossy, green, and lanceolate leaves.\n6. Banyan Tree / Bargad\nBotanical Name: Ficus benghalensis\nSanskrit Name: Vat\nLong prop roots hanging from branches makes this tree extraordinary.\n7. Neem Tree\nBotanical Name: Azadirachta indica\nSanskrit Name: Nimba / Arista\nThanks to the insecticidal properties, its leaves have been used as a natural pesticide for ages.\n8. Sacred Fig / Bodhi / Peepal\nBotanical Name: Ficus religiosa\nSanskrit Name: Ashvattha / Bodhivriksha\nTouted for the bountiful medicinal properties, its spreading crown is covered in heart-shaped leaves.\n9. Flame of the Forest / Palash\nBotanical Name: Butea monosperma\nSanskrit Name: Kimshuka / Palasa\nThe display of its beak-shaped, orange blossoms offers an enchanting sight.\n10. Bamboo Tree / Baans\nBotanical Name: Bambusoideae\nSanskrit Name: Vetsah / Vamshah\nBelonging to the grass family, the resilient bamboo has hollow stems.\n11. Indian Cork Tree / Neem Chameli\nBotanical Name: Millingtonia hortensis\nSanskrit Name: Akash Nimba / Kawal Nimba\nIts scented flowers pop up during the night and shed in the morning creating a floral carpet.\n12. Royal Poinciana Tree / Gulmohar\nBotanical Name: Delonix regia\nSanskrit Name: Krishnachura / Raj Abharan\nThe scarlet orange flowers give out an interesting visual.\n13. Curry Tree / Kadhipatta\nBotanical Name: Murraya koenigii\nSanskrit Name: Kalashaka\nThanks to its aromatic and flavorful leaves, the tree is found in every Indian backyard.\n14. Indian Coral Tree / Pangar\nBotanical Name: Erythrina variegata\nSanskrit Name: Mandara / Paribhadra\nThe ornamental tree grows spectacular flowers in orange colors.\n15. Portia Tree / Paras Peepal\nBotanical Name: Thespesia populnea\nSanskrit Name: Parsvapippala / Gardabhandaka\nMostly found in the coastal regions, the tree is used in making musical instruments in southern India.\n16. Coconut Palm Tree / Nariyal\nBotanical Name: Cocos nucifera\nSanskrit Name: Narikel\nPride of the tropical areas, the tree has several uses!\n17. Kath Champa Tree\nBotanical Name: Plumeria rubra\nSanskrit Name: Punnaga / Swarn Champa\nThe tree is famous for its scented flowers that incorporate in ceremonial decoration and perfumery.\n18. Jackfruit Tree / Kathal\nBotanical Name: Artocarpus heterophyllus\nSanskrit Name: Panasa\nWhat makes this large and columnar tree interesting is its large fruits with spiny, rough skin.\n19. Gooseberry Tree / Amla\nBotanical Name: Phyllanthus emblica\nSanskrit Name: Amalaka\nIts fruits are a rich source of Vitamin C and are also widely used in Ayurveda.\n20. Tamarind Tree / Imali\nBotanical Name: Tamarindus indica\nSanskrit Name: Tintidika\nThe brown fruits growing under the bushy crown are used to impart tarty essence in cuisines.\n21. Lemon Tree / Nimbu\nBotanical Name: Citrus limon\nSanskrit Name: Jambirum\nThe canary yellow fruits of the tree have several uses and also make the tree look spectacular!\n22. Papaya Tree/ Papita\nBotanical Name: Carica papaya\nSanskrit Name: Madhukarkati\nPapaya is a powerhouse of nutrients!']	['<urn:uuid:546a8314-3fd7-4d6a-beaa-cdfb2babab01>']	factoid	direct	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-12T13:53:09.865574	20	26	696
16	meaning inclusive architecture design history	The definition of universal design has evolved over time. Initially, it focused primarily on physical accessibility in the built environment through small-scale design innovations. More recently, it has expanded to address broader social justice issues across multiple levels. This evolution reflects the field's development and has important implications for teaching universal design, particularly in interior design programs.	"[""The developing definition of universal design\nAbstractA review of scholarly work indicates a shift in the definition of universal design. Originally, the focus was placed on physical access to the built environment through design innovations that, while small in scale, resulted in significantly improved outcomes. This has developed to a more contemporary vision that addresses issues of social justice across multiple strata. This development is an indicator of the evolution of the field and has significant implications for those teaching universal design. In 2018, educators teaching in interior design programs accredited by the Council for Interior Design Accreditation (CIDA) in the United States were surveyed about the infusion of universal design content within their curricula. As part of the survey, participants were presented with four definitions and asked to assess their appropriateness in defining the term universal design. Responses revealed a generally high level of understanding regarding the definition of universal design. This article investigates the evolution of the definition of universal design, presenting each of the definitions in their historical context, presents the survey results of interior design educators’ perceptions of these definitions, and concludes with implications for universal design, particularly in the interior design discipline.\nClarkson, J. P., & Coleman, R. (2015). History of inclusive design in the UK. Applied Ergonomics, 46(PB), 235–247. https://doi.org/10.1016/j.apergo.2013.03.002\nConnell, B. R., Jones, M., Mace, R., Mueller, J., Mullick, A., Ostroff, E., Sanford, J., Steinfeld, E., Story, M., & Vanderheiden, G. (1997). The Principles of Universal Design. North Carolina State University, The Center for Universal Design. https://projects.ncsu.edu/ncsu/design/cud/about_ud/udprinciplestext.htm\nCouncil for Interior Design Accreditation. (n.d.) About CIDA. Retrieved February 17, 2020, from https://www.accredit-id.org/mission\nCouncil for Interior Design Accreditation. (n.d.) Our Story. Retrieved February 17, 2020, from https://www.accredit-id.org/cida-history\nCouncil for Interior Design Accreditation. (2018). Council for Interior Design Accreditation Professional Standards 2018. https://accredit-id.org/wp-content/uploads/2018/01/Professional-Standards-2018_Final.pdf\nCouncil for Interior Design Accreditation. (2000.) Council for Interior Design Accreditation Professional Standards 2000.\nFoundation for Interior Design Education and Research. (1996). FIDER 402R. In FIDER Accreditation Manual.\nInterior Design Educators Council. (n.d.) IDEC Regions. Retrieved March 8, 2021, from https://www.idec.org/i4a/pages/index.cfm?pageid=3292\nMace, R. (1985, November). Universal Design: Barrier Free Environments for Everyone. Designers West, 147–152.\nMace, R., Hardie, G. J., & Place, J. P. (1991). Accessible Environments: Toward Universal Design. In W. E. Preiser, J. C. Vischer, & E. T. White (Eds.), Design Intervention: Toward a More Humane Architecture (pp. 155–176). Van Nostrand Reinhold.\nOrmerod, M. G., & Newton, R. A. (2005). Moving beyond accessibility: The principles of universal (inclusive) design as a dimension in nD modelling of the built environment. Architectural Engineering and Design Management, 1(2), 103–110. https://doi.org/10.1080/17452007.2005.9684587\nPreiser, W. F. E., & Smith, K. H. (2011). Universal Design Handbook. In W. F. E. Preiser & K. H. Smith (Eds.), McGraw Hill (2nd ed.).\nSieberns, A. (2018). Universal Design and Human Rights: The UN Convention on the Rights of Persons with Disabilities (CRPD). In IFLA (Ed.), IFLA WLIC 2018 - Kuala Lumpur, Malaysia - Transform Libraries, Transform Societies (Issue August, pp. 1–5). IFLA. http://library.ifla.org/id/eprint/2269\nSteinfeld, E. & Maisel, J. (2012). Universal Design: Creating Inclusive Environments. New York. Wiley.\nTauke, B., Basnak, M, & Weidemann, S. (2016) Issue 2, Nordic Journal of Architectural Research, pp. 139-162.\nTauke, B. (2008). “Universal design – The time is now.” in Usability in Asia, Li C. (ed.) Apogee.\nUnited States Department of Justice. (2010). 2010 ADA Standards for Accessible Design. Title II. https://www.ada.gov.\nVanderheiden, G., & Tobias, J. (1998). Barriers, Incentives and Facilitators for Adoption of Universal Design Practices by Consumer Product Manufacturers. Proceedings of the Human Factors and Ergonomics Society 42nd Annual Meeting, 584–588.\nHow to Cite\nCopyright (c) 2021 Eric Dolph\nThis work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.\n- Authors retain copyright and grant the journal right of first publication with the work simultaneously licensed under a Creative Commons Attribution License that allows others to share or adapt the work with an acknowledgment of the work's authorship and initial publication in this journal. Use of the work for commercial purposes are not allowed.\n- Authors are able to publish the journal's published version of the work in other media (e.g., post it to an institutional repository or publish it in a book), as far as they inform the Journal of Accessibility and Design for All of that fact. When publishing their work in other sources, authors must mention the name of the Journal of Accessibility and Design for All, its ISSN, the number and issue in which the article was published and a link to the main page of the Journal of Accessibility and Design for All. Optionally, they can also include a link to the article published in the Journal of Accessibility and Design for All.\n- Authors are permitted and encouraged to post their work online (e.g., in institutional repositories or on their website), as it can lead to productive exchanges, as well as earlier and greater citation of published work.""]"	['<urn:uuid:232b982f-f358-429e-becb-2b98aeb4800d>']	open-ended	direct	short-search-query	distant-from-document	single-doc	expert	2025-05-12T13:53:09.865574	5	57	813
17	How do human interventions impact wildlife behavior and survival rates?	Human feeding causes wildlife to lose their natural caution around humans and their ability to forage, making them vulnerable to predator attacks and malicious acts. While some migration strategies might affect survival rates, studies of tundra swans show that populations with different migration distances (ranging from 1020 to 12720 km) can maintain high survival probabilities, demonstrating their adaptability to various landscapes and climatic conditions.	"[""Ordinance Prohibiting the Feeding of Wildlife\nVisitors and residents alike enjoy viewing the wildlife that call New Braunfels home. Deer, waterfowl, and squirrels are common types of wildlife that are seen throughout the city and within our parklands. Although it may be tempting to feed these animals so that you can get a closer look or snap a picture, feeding wildlife can be detrimental to both humans and animals that share urban spaces.\nThe City of New Braunfels (CoNB), with the help of local agencies and stakeholders, has developed a Watershed Protection Plan (WPP) for the Dry Comal Creek and Comal River watersheds to protect and preserve the water quality in these waterbodies. The WPP includes recommendations discouraging the feeding of wildlife in order to minimize bacteria loading to our waterways as well as multiple other reasons. One recommendation of the WPP that has been implemented by the CoNB is an ordinance prohibiting the feeding of wildlife within the city limits.\nThe ordinance was drafted by CoNB staff, approved by the City Council, and signed by the Mayor on September 10th, 2018. The ordinance granted a six (6) month grace period to allow the CoNB staff to coordinate educational workshops which will allow the community to become familiar with the new ordinance. Enforcement of the ordinance officially began March 10th, 2019.\nSummary of the Ordinance Prohibiting the Feeding of Wildlife Within the City Limits:\n- An offense is committed when food is made readily available by it being placed on the ground or within reach of wildlife;\n- 'Food' is defined as bread products, corn, fruit, oats, hay, nuts, wheat, soy products, salt blocks, grain, vegetables, and commercially sold feed; items that are exempt include naturally growing shrubs, live crops, plants, flowers, vegetation, gardens, trees, and fruit or nuts that have fallen on the ground or are in reach of wildlife;\n- 'Wildlife' is defined as undomesticated animals living in the wild;\n- Citizens are allowed to place food on the ground, in good faith, for the purpose of feeding domesticated animals or livestock located on their property;\n- Penalties include a warning for a first offense. Second and subsequent offenses will result in prosecution in Municipal Court. These violation are considered a Class C Misdemeanor punishable by a fine of $75 - $500;\n- Ordinance does not apply to the placement of food into feeders kept at a minimum of five (5) feet above the ground and intended for birds;\n- Ordinance does not apply to an animal control officer, veterinarian, peace officer, CoNB employee, or federal or state wildlife official who is acting in accordance with a lawfully authorized program to manage wildlife and who is acting within the established scope of said program;\n- Ordinance does not apply to those who possess a 'Land Hunting Permit' (Section 82-3(d)) and set out feed for the purpose of baiting and attracting game animals.\nIf you have any questions regarding the ordinance prohibiting the feeding of wildlife within the city limits, please contact the City of New Braunfels Watershed Management Division at (830) 221-4020\nORDINANCE NO. 2018 - 58\nAMENDING THE CITY OF NEW BRAUNFELS, TEXAS, CODE OF ORDINANCES CHAPTER 82- OFFENSES AND MISCELLANEOUS PROVISIONS, CREATING SECTIONS 82-24 TO 82-28, THAT WILL CONTAIN NEW PROVISIONS RELATED TO PROHIBITING THE FEEDING OF WILDLIFE; PROVIDING DEFINITIONS AND PENALTIES; REPEALING ALL ORDINANCES IN CONFLICT; CONTAINING A SAVINGS CLAUSE AND ESTABLISHING AN EFFECTIVE DATE.\nWHEREAS, the City of New Braunfels finds that feeding of wildlife has resulted in overabundant and highly concentrated populations of wildlife throughout the City and within City parks; and\nWHEREAS, the feeding of deer has been shown to increase the concentration of deer in urbanized areas, thereby increasing the likelihood of collisions between vehicles and deer, and increasing damage to residential and commercial vegetation and landscaping in the City; and\nWHEREAS, the City finds that overabundant deer and avian wildlife populations have contributed to an increase of bacteria pollution in the Comal River and Dry Comal Creek; and\nWHEREAS, the feeding of wildlife can cause concentrated areas of biological waste, containing bacteria, nitrogen and phosphorus, which can lead to water quality degradation, thereby impacting popular contact recreation waterways; and\nWHEREAS, the City and the Texas Parks and Wildlife Department find that discouraging and prohibiting the artificial feeding of wildlife is in the best interest of the health, safety and welfare of the community and wildlife populations.\nNOW, THEREFORE, BE IT ORDAINED BY THE CITY COUNCIL OF THE CITY OF\nNEW BRAUNFELS, TEXAS, THAT:\nThe findings and recitations set out in the preamble to this Ordinance are found to be true and correct and are hereby adopted by the City Council and made a part hereof for all purposes.\nThat Chapter 82, “Offenses and Miscellaneous Provisions”, as it currently exists is amended by creating sections 82-24 to 82-28, related to prohibiting the feeding of wildlife, to read as follows:\nSec. 82-24. Definitions.\n(a) “Food” means bread products, corn, fruit, oats, hay, nuts, wheat, alfalfa, salt blocks, feed, grain, vegetables, and commercially sold wildlife feed, or livestock feed, but excludes live naturally growing shrubs, live crops, plants, flowers, vegetation, gardens, trees, and fruit or nuts that have fallen on the ground or are within reach of wildlife.\n(b) “Wildlife” means undomesticated animals living in the wild.\nSec. 82-25. Feeding of wildlife prohibited.\n(A) Except as provided below in 82-26, (A) and (B), a person commits an offense if the person intentionally feeds wildlife by making food available for consumption on private or public property within the territorial limits of the city.\n(B) A person shall be deemed to have purposely fed or caused wildlife to be fed if the person places food, as defined in this section, in any form, (not including live vegetation such as ornamental landscaping or flowers) on the ground, or within reach of wildlife.\n(C) A person who violates any provision of this ordinance commits an offense.\nSec. 82-26. Exceptions; Affirmative Defenses\n(A) This ordinance does not apply to the placement of food into feeders kept at a minimum of 5 feet above the ground surface and intended for birds.\n(B) This ordinance does not apply to an animal control officer, veterinarian, peace officer, City employee, federal or state wildlife official, who is acting pursuant to a lawfully authorized program to treat, manage, capture, trap, hunt, or remove wildlife and who is acting within the scope of the person’s authority.\n(C) This ordinance does not apply to individuals who possess a “Hunting Land Permit” as described in Section 82-3(d) and set out feed for the purpose of baiting and attracting game animals.\n(D) It is an affirmative defense to prosecution under this section if a person places food, in good faith, for the purpose of feeding domestic livestock or domestic pets located on their property.\nSec. 82-27. Enforcement.\n(A) Animal Control Officers, Park Rangers, Code Compliance Officers and Police Officers are hereby given full power and authority to enforce this ordinance.\n(B) It is a violation to hinder, molest or interfere with anyone authorized or empowered to perform any duty under this ordinance.\nSec. 82-28. Penalties.\n(A) A person who commits a violation of this ordinance will first be given a warning and will be provided information on the negative impacts of wildlife feeding. A second offense will result in prosecution in municipal court. Any violation of this ordinance is deemed a Class C misdemeanor punishable by a fine of not less than $75.00 or more than $500.00. Each day any violation of any provision of this Code shall continue shall constitute a separate offense.\n(B) Nothing in this section shall be construed as to limit any civil action the city may take to enforce the terms of this ordinance.\nIt is hereby declared to be the intention of the City Council that the sections, paragraphs, sentences, clauses and phrases of this Ordinance are severable and, if any phrase, clause, sentence, paragraph or section of this Ordinance should be declared invalid by the final judgment or decree of any court of competent jurisdiction, such invalidity shall not affect any of the remaining phrases, clauses, sentences, paragraphs and sections of this Ordinance.\nAll provisions of the Code of Ordinances of the City of New Braunfels not herein amended or repealed shall remain in full force and effect.\nAll Ordinances or parts thereof in conflict herewith are repealed to the extent of such conflict only.\nIn accordance with the provisions of the City Charter, this Ordinance may be read and published by descriptive caption only. This Ordinance has been publicly available in the office of the City Secretary prior to its adoption.\nThis Ordinance shall become adopted and effective upon its second reading, signature required by City Charter, filing with the City Secretary’s Office and then following a six-month grace period that allows for community education and outreach. This Ordinance must also be published in a newspaper of general circulation at least one time within ten (10) days after its final passage, as required by the City Charter of the City of New Braunfels.\n• Feeding wildlife in an urban setting can have negative environmental consequences. Animal scat, or fecal matter, contains many types of bacteria, including E. coli. When wildlife congregates for feeding in areas near a body of water, such as long the banks of Landa Lake or the Comal River, they leave their feces behind after they feed. This waste is then readily washed into the lake or river during the next rain storm and contaminates the water with bacteria.\n• Just as it is unhealthy to feed your pets food that is designed for humans, foods like grilled meat and bread are not part of a typical wildlife diet. “People food” is often too tempting for wildlife to resist, but it cannot be properly digested and can cause potentially life-threatening consequences for animals.\n• Artificial feeding can cause wildlife to lose the ability to forage for food. It can also disrupt natural migratory patterns of waterfowl, such as ducks and geese.\n• Wildlife quickly become accustomed to receiving food from humans. As a result, animals lose their instinctive caution around humans. This change in their behavior makes wildlife more vulnerable to malicious acts and attacks from domestic animals.\n• Changes in the behavior of one type of wildlife can cause a ripple effect through the rest of the food chain. Artificial feeding makes wildlife more vulnerable to attacks by predators which they would otherwise avoid. These predators, in turn, can become a nuisance to the wildlife being fed or the humans doing the feeding.\n• The search for easy food puts wildlife in dangerous locations or in harm's way. Deer and waterfowl tend to congregate in areas where they are being fed, which is often close to roadways or waterways used for human transportation. Wildlife fed in these locations are more likely to be struck by vehicles and cause accidents.\n- The City of New Braunfels Animal Control Department reports that approximately 500-550 deer carcasses are removed from city streets each year as a result from auto collisions. The New Braunfels Police Department reports an average of 15 auto/animal collisions per year with police vehicles. The New Braunfels Fire Department reports an average of 3 auto/animal collisions per year with fire vehicles.\n• The unnaturally high density of the wildlife population caused by artificial feeding can increase the spread of diseases and parasites. In the wild, animals are spread out over larger areas and have less direct contact with each other. Artificial feeding causes them to come into direct contact with other animals and their waste, increasing the chances of transmitting or contracting disease."", 'Migration is a prominent aspect of the lifestyle history of of several avian variety, but the group effects away from adjustable migration strategies simply have infrequently already been investigated, and you can hardly when using progressive technological and analytical tricks for evaluating survival, way models, and much time-title production in the context of lifetime records theory. I tracked the fresh new fates out of fifty satellite-implanted tundra swans (Cygnus columbianus) over cuatro ages from five disparate breeding components inside the Alaska, and you may utilized known-future analyses so you can guess monthly success opportunities according to migration length, reproduction town, migratory flyway, reproduction condition, and you will ages. We specifically checked out whether or not migratory wild birds deal with a trade-from, wherein a lot of time-point migrants realize highest survival cost at the expense of all the way down efficiency on account of smaller go out toward breeding elements prior to birds one to move smaller ranges and you may spend more big date into breeding parts.\nAnnual migration ranges varied rather among reproduction section (1020 to help you 12720 kilometer), and you will was strongly negatively synchronised in the long run spent on breeding parts (r = ?0.986). Quotes from yearly endurance opportunities ranged of the wintering urban area (Pacific coast, Alaska Peninsula, and you will East seaboard) and you can varied away from 0.79 (95%CI: 0.70–0.88) to a single.0, dependent on requirements familiar with detect mortalities out-of radio disappointments. I don’t select evidence having an effective linear relationship between migration distance and success while the swans on the breeding section towards quickest and you can longest migration ranges met with the higher survival odds. Survival try reduced in the first season blog post-establishing than in next ages, however, there is not assistance for seasonal differences in endurance. Production ranged among reproduction communities and you will try fundamentally inversely correlated to emergency, although not migration point or big date allocated to reproduction components.\nTundra swans decided in order to a primary tenet off lifestyle record principle, given that populations to your highest survival generally encountered the lower production. The lack of good uniform matchmaking between day spent on breeding section and you will yields, or big date spent on wintering section and success, demonstrates activities aside from temporal money influence demographic consequences for the it species. Brand new immense assortment off migration procedures we identify from inside the Alaskan tundra swans, as opposed to obvious has an effect on towards the success, underscores the art of it types in order to comply with more surroundings and climatic regimes.\nMigration try a behavioural trait that is believed to have progressed to maximise exercise from inside the regular surroundings, that is a well known aspect of the life reputation of of many avian varieties [1–4]. Understanding the market outcomes off migration has long been a goal out-of avian ecologists, since the distinguishing the newest exercise expenses associated with additional behaviours is then the understanding of elements driving the fresh new evolution and repairs regarding avian lives background steps [5, 6]. Getting snowy-reproduction wild birds undergoing extended biannual migrations, the costs of these a power requiring actions may be large in terms of one another breeding and endurance [3, eight, 8].\nThe power price of a lot of time migrations is let me make it clear large having possibly large negative influences to the reproduction, just like the migrants need to harmony between playing with energy to own journey and you will space supplies to possess reproduction [nine, 10]. For example prices are almost certainly most readily useful during https://besthookupwebsites.net/video-dating/ the pure investment breeders, that rather than income breeders, you should never counterbalance the energetic weight regarding migration by the foraging into reproduction components. The price of migration, particularly a lot of time-distance migration, towards emergency are smaller clear but interesting, because the inhabitants fictional character off long-stayed variety are usually considering adult endurance [11, 12].\nThere are a few competing hypotheses towards market effects off much time length migration. Of numerous article writers has actually argued you to definitely enough time migrations need accurate a toll with respect to less endurance as compared to inactive species [seven, 13], and has now shown you to definitely wild birds carrying a whole lot more opportunity supplies (for example ready traveling farther) be a little more susceptible to predation than just slimmer wild birds [step three, 14]. Wild birds which have longer migrations can also endure improved mortality because they mix an elevated assortment out of terrain and generally are hence probably established in order to a more impressive suite out of predators than simply inactive varieties. On the other hand, anybody else has actually contended one wild birds move to help you places that mortality try faster, and they are thus likely to has highest success pricing than resident variety otherwise types you to take a trip faster much [15–18]. In fact, Greenberg advised one to migratory birds deal with a swap-out-of, whereby much time-point migrants discover high survival cost because they take a trip then so you can arrive at more safe wintering section, however, at the cost of straight down yields due to investing concomitantly less time into the breeding parts [15, 19]. The guy termed this dichotomy regarding investment brand new “Big date Allotment” theory hence predicts one to, in migratory wild birds, efficiency and you can emergency is dictated by the temporal investment, with one upsurge in period of the new reproduction season causing an effective ount of time getting occupying the brand new non-reproduction assortment. As such, you to anticipate is that populations during the higher latitudes, having much time migration distances, have to have high endurance costs and lower returns than simply owners otherwise short-range migrants [fifteen, 20]. Numerous studies have checked-out forecasts of time allowance theory with varying overall performance (come across analysis from inside the [19, 21, 22]).']"	['<urn:uuid:3fdaa634-ae67-405c-9aad-58a32968a62c>', '<urn:uuid:5aa8cf0f-e7e4-4808-aad7-3cf8f82eacdd>']	factoid	with-premise	concise-and-natural	distant-from-document	multi-aspect	expert	2025-05-12T13:53:09.865574	10	64	2932
18	What methods do vineyard workers use to check the sugar levels in grapes while they're still in the field?	In the vineyard, workers measure must density using a refractometer. They crush a few grapes between their fingers and let the juice drip onto the glass prism of the refractometer. While the refractometer actually measures refractive index, it is calibrated to display readings in various scales like Oechsle degrees.	"[""The Oechsle Scale is a hydrometer scale measuring the density of grape must, which is an indication of grape ripeness and sugar content used in wine-making. It is named for Ferdinand Oechsle (1774-1852) and it is widely used in the German, Swiss and Luxembourgish wine-making industries. On the Oechsle scale, one degree Oechsle (° Oe) corresponds to one gram of the difference between the mass of one litre of must at 20 °C and 1 kg (the mass of 1 litre of water). For example, must with a specific mass of 1084 grams per litre has 84° Oe.\nThe mass difference between equivalent volumes of must and water is almost entirely due to the dissolved sugar in the must. Since the alcohol in wine is produced by fermentation of the sugar, the Oechsle scale is used to predict the maximal possible alcohol content of the finished wine. This measure is commonly used to select when to harvest grapes. In the vineyard, the must density is usually measured by using a refractometer by crushing a few grapes between the fingers and letting the must drip onto the glass prism of the refractometer. In countries using the Oechsle scale, the refractometer will be calibrated in Oechsle degrees, but this is an indirect reading, as the refractometer actually measures the refractive index of the grape must, and translates it into Oechsle or different wine must scales, based on their correlation to refractive index.\nThe Oechsle scale forms the basis of most of the German wine classification. In the highest quality category, Prädikatswein (formerly known as Qualitätswein mit Prädikat, QmP), the wine is assigned a Prädikat based on the Oechsle reading of the must. The regulations set out minimum Oechsle readings for each Prädikat, which depend on wine-growing regions and grape variety:\n- Kabinett - 67-82 °Oe\n- Spätlese - 76-90 °Oe\n- Auslese - 83-100 °Oe\n- Beerenauslese and Eiswein - 110-128° Oe (Eiswein is made by late harvesting grapes after they have frozen on the vine and not necessarily affected by noble rot, botrytis, which is the case with Beerenauslese)\n- Trockenbeerenauslese - 150-154 °Oe (affected by botrytis)\nThe sugar content indicated by the Oechsle scale only refers to the unfermented grape must, never to the finished wine.\nIn Austria the Klosterneuburger Mostwaage (KMW) scale is used. The scale is divided into Klosterneuburger Zuckergrade (°KMW), and very similar to the Oechsle scale (1° KMW =~ 5° Oe). However, the KMW measures the exact sugar content of the must.\nThe Baumé scale is occasionally used in France and by U.S. brewers, and in the New World the Brix scale is used to describe the readings of a refractometer when measuring the sugar content of a given sample.\nSince a refractometer actually measures the refractive index of the grape must, it can be translated to many different scales (both related and unrelated to wine) based on their correlation to refractive index. Thus, all of these methods are similar and the differences are more cultural than significant, but all are equally valid ways to measure the density of grape must and other sugar-based liquids.\nThe Normalizovaný Moštomer (°NM) measures kg of sugar in 100 l of must and is used in Czech Republic and Slovakia.\n- By a slight abuse of physical terminology one says in German that the Mostgewicht (must weight) is measured rather than the must's density.\n- Deutsches Weininstitut: Must weights, accessed on March 26, 2009\n- Since the exclusion of degree Baumé from legal units in France by Decree No. 61-501 of 3 May 1961 relating to units of measurement and control of measuring instruments, the French regulation refers to sugars content expressed in grams per litre.""]"	['<urn:uuid:b24c83bf-ef47-44ec-87d1-b545f2d582df>']	factoid	direct	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-12T13:53:09.865574	19	49	616
19	How do wind-dispersed and water-dispersed seeds compare in their physical features?	Wind-dispersed seeds like thistle and dandelion have fluffy parachute structures or honeycomb patterns called balloon seeds, while water-dispersed seeds like those of water lilies have floating capabilities. Wind-dispersed seeds often feature specialized structures like wings (as in maple seeds) or intricate surface textures that help with mobility, whereas water-dispersed seeds are specifically adapted to stay buoyant in water until reaching suitable planting areas.	['The diversity and intricacy of shapes and sizes of seeds is extraordinary. Even more amazing is that within even the tiniest of seeds lies the complete genetic information required to birth and structure such organisms as the complex passion flower, or a 360 foot tall sequoia. Seeds are also amazing travelers, either with the help of the wind or by hitching rides with neighboring wildlife. If stored in ideal conditions, seeds can also spring to life, after hundreds of years of lying dormant.\nMore often than not, the smaller the seed, the more texture found on its surface. Image by Rob Kesseler, robkesseler.co.uk\nPortulaca seed (moss rose) as seen with a stereomicroscope, by Ms. Yanping Wang from the Beijing Planetarium in Beijing, China. olympusbioscapes.com Originally found at olympusbioscapes.com/gallery/2011/index.html\nPlant seed from freshwater pond, starting to sprout. Fluorescence, 10x by Dr. Daniel Stoupin, Moscow, Russia. olympusbioscapes.com Originally found at olympusbioscapes.com/gallery/2011/index.html\nLoasa Chilensis (a creeping flowering vine, native to Chile). Many wind-dispersed seeds have a honeycomb pattern, which are referred to as balloon seeds, this Chilean native has an extreme honeycomb. To create a scanning electron micrograph, a seed is coated with a microfine layer of gold or platinum and put into a vacuum chamber, where it is bombarded with electron particles. The electron beam measures the seed’s surfaces and translates these measurements into a digital image. Image by Rob Kesseler, robkesseler.co.uk.\nWild carrot seed.\nA sundrew seed from South Africa. Rob colors the images in Photoshop based on the colors of the original plant. Image by Rob Kesseler, robkesseler.co.uk.\nDelphinium pergrinum, Larkspar family. Texture helps the seed to both hug into its host surface and for mobility purposes. By Rob Kesseler: robkesseler.co.uk.\nAfrican Cabbage seed, a wildflower indigenous to Africa, but now considered a weed in many tropical locations around the world. Photo by Rob Kesseler. robkesseler.co.uk.\nSeed from a thistle of the Centaurea genus. Photo by Rob Kesseler. robkesseler.co.uk.\nA forget-me-not cousin, from the Trichodesma genus. Photo by Rob Kesseler. robkesseler.co.uk.\nIvy leafed toadflax seed. Image by Rob Kesseler, robkesseler.co.uk.\nFoxglove seed magnified.\nColoured scanning electron micrograph (SEM) of the highly sculpted coat of a foxglove seed (Digitalis purpurea). This balloon seed is wind dispersed. psmicrographs.co.uk\nCrassula pellucida, a succulent, in the jade family. Image by Rob Kesseler, robkesseler.co.uk.\nLamourouxia viscosa (a Mexican wildflower). Scanning electron microscopes, scan specimens with a beam of electrons and produces a series of precisely detailed files, which are then compiled into a single image. Image by Rob Kesseler, robkesseler.co.uk.\nGarden Strawberry (Fragaria x ananassa) covered in seeds (actually ‘achenes’). Image by Rob Kesseler, robkesseler.co.uk.\nKaffir lime (Citrus hystrix) longitudinal section through flower bud. By Rob Kesseler: robkesseler.co.uk\nArabidopsis Thaliana (a European cress). The image shows a small, six-day-old seedling of Arabidopsis thaliana under a scanning electron microscope and captures the essence of seed germination, the tiny and delicate beginnings of a plant. Love the textures. Image by: Mark Talbot. maxisciences.com\nDetail of a pod of the flowering legume “Prickly Caterpillar”\nby Viktor Sýkora. olympusbioscapes.com Originally found at olympusbioscapes.com/gallery/2011/index.html\nCastor Bean Seeds are poisonous to people, animals, and insects. Each seed is unique in design. Image by Mark Birkle, flickr.com\nThe largest known seed in the world belongs to the Coco de Mer palm (Lodoicea maldivica). The seed is found within an even heavier/larger nut. The seed itself can weigh up to 40 pounds, the largest fruit/nut weighed over 80 pounds. hutpedia.blogspot.com\nDandelion seeds have an efficient means of locomotion.\nFour Sunflowers Gone to Seed, 1887,\nby Vincent Van Gogh.\nKröller-Müller Museum, Otterlo, Netherlands.\nMore Info About Seeds\n- The Millennium Seed Bank Partnership is the largest ex situ plant conservation project in the world. Their focus is on global plant life faced with the threat of extinction and plants of most use for the future. www.kew.org\n- Video about the Millennium Seed Bank: youtube.com\n- A website devoted entirely to seeds: theseedsite.co.uk\nThe Best Photography Book About Seeds\nSeeds: Time Capsules of Life by Wolfgang Stuppy, Images by Rob Kesseler. (Preface by Prince Charles!)\nRed ants balancing mimosa tree seeds.\nCopyright: Eko Adiyanto, 500px.com/EkoAdiyanto\nlauren Domenia says\nThat is so cool! Look how different each of them are! The giant seed’s fruit weighs as much as I do!!! God’s glory is amazing!\nEd Hart says\nSo a god makes his mark of glory, in a tiny seed… whilst thousands of children starve each day, so man has the money to buy weapons and continue un-holy wars??\nYou really need to read more than one book.\nNo religion, no holy war.\nThank-you for sharing your photographs of our great and mighty designer–GOD.\ngustave lambert says\nJust GREAT ! Keep going on.\nGod can do any thing\nBeautiful images of nature’s artistry.\nHow can I order prints?\nPlease contact Rob Kesseler!\nAll seed images of Rob Kesseler’s in his book: Seeds: Time Capsules of Life (Insight Editions, 2012) text by Wolfgang Stuppy, Images by Rob Kesseler.\nphillips Evans says\nRob Sorensen says\nLooking at these microscopic structures reminds me of lunar landing craft images or better.\nHI, I am working on a little seed book for kids 6-9. What is the procedure for sharing these pix with the kids? I have the seed and fruit books by Rob, but might there be a way to add a few of these pix in the book? Or is it an impossible dream… They sure are amazing. Thanks for sharing. Just beautiful.\nDear Val, Yes, you need express rights from Rob Kesseler to reprint his images in a book that will be resold or distributed!\nWOW, incredible, I love seeds .\nI ran across this picture online. What are these? https://www.bing.com/images/search?view=detailV2&ccid=J4t0dzbK&id=5FD9BAFBA2CE96E6798698DD45B1CB1527A331E7&thid=OIP.J4t0dzbK3-mr8eeGSoVMlwHaG2&mediaurl=http%3a%2f%2f2ff8n03drmib1b12373aauek-wpengine.netdna-ssl.com%2fassets%2fimages%2fPhotography%2fSeeds%2fcastor%2520bean%2520seed.jpg&exph=647&expw=700&q=Cresijevec+bean+seeds&simid=608005682952667285&selectedIndex=30&ajaxhist=0\nOn the Loasa Chilensis, the name of the country is Chile, not Chili 🙂\nBir Bahadur says\nSEM provides microdetsils of seed coat and related structures. I have done good work on SEM of seeds of various species especially vsmall seeds. The patterns are so distinct and varied that its utility is better known in Taxonomy. The coloured images are just too good.Nature an evolution at work.\nSalvador Zablah says\nComo me comunico con ustedes necesito comprar semillas de loroco chipilin apio\nFantastic photographs Rob, amazing. I was wondering if you can say what type of seed the orange coloured seed top left on the first photograph is “Microscopic Images Of Seeds”? I have found a couple of seeds that look very similar to these in dust samples collected in houses. Thanks!!', 'This is the time of year we see a lot of seeds on the move! Much like parents pushing their children out of their house, plants want to spread their seeds, or their genes, as far as possible. Seed dispersal is a technique used by plants to distribute their seeds. Different species of plants have some clever ways of transporting their seeds. Watch out for these whenever you see seeds on the move.\nWant these articles delivered right to your inbox every week? Click here to sign up!\nPerhaps the most common method of seed dispersal is wind. Some plants we all know and love use wind to disperse their seeds. Thistle, maples and dandelion are some common species that use this method. Thistle and dandelion seeds are attached to a fluffy parachute that carries the plant far away. Maple seeds have little wings that have been nicknamed ‘helicopters,’ however the botanical term for them is a schizocarp. The seeds fly through the air using their ‘wings’ in hopes of spreading far from the parent tree.\nOther species rely on animal transport to disperse their seeds. There are two types of animal transport, active and passive. In active transport, some plants we enjoy eating, such as blueberries and strawberries, trick us into eating their seeds by wrapping them with sweet fleshy fruits. We consume the seeds along with the fruit, and then our bodies digest the fruit, removing the protective layer on the seed called the seed coat. Once the seed coat is removed, the seed can absorb valuable nutrients and start to grow! Additionally, the seed may travel far from the parent plant depending on the amount of time digestion takes.\nAnother method of animal transport is called passive transport. Some plants like to slyly attach their seeds to our pant legs or to the fur of animals. A species found locally that is guilty of this is called hound’s tongue. When you walk by a hound’s tongue plant, the seed has small hooked fibers, called a burr (similar to Velcro) that attaches to our clothes or to animal fur. Once the human or animal has walked around, the burr will fall off and be dispersed in a new area. One thing to note about hound’s tongue is that it is an invasive species. An invasive species is a species not native to the area that can take up valuable habitat from native species. If you find any hound’s tongue attached to your pants or to your dog, make sure to throw the burrs in the trash to stop the spread of this species.\nWater is another way plants transport their seeds. Plants such as water lilies who grow in water will typically use this method of dispersal. Their seeds have the ability to float. The water will carry the seed until it reaches an area where it can be planted.\nThe last, and most exciting method that seeds are dispersed by is through a method called explosive dispersal. Some species of plants, such as lupine or jewelweed, eject their seeds multiple feet away using gravity. When the seed pod is touched or ripens, the two halves of the seed pod holding the seeds peel back and eject the seeds. This is one of the more entertaining methods of seed dispersal!\nSince plants cannot move, they have to find creative ways of moving their species to new growing locations. As the summer comes to an end, try to catch a glimpse of some of these creative types of seeds on the move!\nRachel Holland is a naturalist intern at Walking Mountains Science Center in Avon, CO. She was previously an intern at the Betty Ford Alpine Gardens in Vail, CO, which is where she learned so much about plants! Besides plants, Rachel also enjoys horseback riding and hanging out with her guinea pigs.']	['<urn:uuid:4ddc8406-066b-43a1-96db-eb03f2fa906b>', '<urn:uuid:d31ad2e8-37d4-4f64-9bc3-9af267cc77b1>']	open-ended	direct	concise-and-natural	distant-from-document	comparison	expert	2025-05-12T13:53:09.865574	11	63	1718
20	What are the key differences in how UX and UI designers collect and analyze information about users compared to the empathic design research process?	The empathic design research process involves collecting subjective information through three main approaches: observing people in their natural context, having users participate and express thoughts/feelings, and trying things firsthand to gain personal insights. This data is then analyzed objectively by gathering materials, identifying themes, clustering data into categories, and summarizing findings. In contrast, UI designers focus specifically on design research around visual trends and interface needs, while UX designers conduct broader user research that includes conceptual planning and information architecture. While UI designers concentrate on optimizing the interface experience through visual elements and interactions, UX designers must understand the complete user journey and experience. Both UX and UI designers use prototyping and testing, but UX takes a more holistic approach to analyzing user needs compared to UI's specialized focus on interface elements.	['Empathy is the ability to understand and identify with another person’s context, emotions, goals and motivations. In order to design great experiences, successful design firms actively search for empathic insights into their target group. In a design context, empathy serves a distinct purpose: to inspire design decisions in the early stages of the process. At IDEO, for example, the design team is so convinced about the positive effect it has on their projects that they actively advocate it to inspire other designers and innovators. Here, you’ll learn how you can develop empathy for your target group.\nUsing empathy in the design process is on the one hand about collecting subjective information and on the other hand about objectively analysing it. The best way to collect the subjective information is to embed yourself in the context of your target group and gain personal insights into the experiences they have. There are three different approaches for you to use:\n- Looking at what people do\n- Asking people to participate\n- Trying things yourself\nYou should use them together to get empathic on an affective and a cognitive level. We will explain these approaches and how to use them. But first, we’ll take a closer look at the role of empathy in the design process and the four general steps you need to take in developing empathy for your target group.\n“Design empathy is an approach that draws upon people’s real-world experiences to address modern challenges. When companies allow a deep emotional understanding of people’s needs to inspire them—and transform their work, their teams, and even their organization at large—they unlock the creative capacity for innovation.”\n— Katja Battarbee, Jane Fulton Suri, and Suzanne Gibbs Howard from IDEO, 2014\nWhy is Empathy Important in a Design Process?\nBy the mid-2010s, the design profession had experienced another major shift. Once, the move had taken it from designing products to services; by this point, however, designing experiences was the name of the game. Each shift means that you design for a broader perspective, and each shift builds upon the existing knowledge of the previous perspective. Take biking, for example. In the past, when you wanted to make a biking trip, you had to get a map of the area: the simple product which you could use to plan your own route. Later, services started to appear that would take this planning work out of your hands. You could go to a place (online or in the real world) to have a route planned based on your preferences. Now, when planning a biking trip, you can join an online bike community. You can get inspired by other peoples’ experiences and share routes.\nAuthor/Copyright holder: Bureau of Land Management. Copyright terms and licence: CC BY 2.0\nBiking is an example of how the design profession has shifted from designing products, to services and now, experiences. Now, when planning a biking trip, you can join an online bike community and get inspired by other peoples’ experiences. This shift results in a bigger importance for developing empathy for your target group.\nIn order to design not only products and services but also experiences, you need to know different things about your users than you would if you were merely designing products. When you learn about people on an objective level, you can understand what they need for performing their tasks. When you learn about your target group on a subjective level, you can understand what they are aiming for and what they are feeling when they are trying to accomplish it. You need the latter for designing experiences. In the bike example, it is—therefore—less important to understand what steps people take to plan a biking trip than it is to know what emotions they would like to associate with it. Getting empathic insights is key in this process.\n“The aim of empathic design studies is not to seek solutions for recognized problems, but rather to look for design opportunities as well as develop a holistic understanding of the users. Design empathy is not only information and facts but also inspiration and food for ideas.”\n— Tuuli Mattelmäki, Finnish industrial designer, researcher & lecturer, 2003\nThe Four Steps in Developing Empathy for your Target Group\nAs we mentioned before, there are three approaches to collecting the subjective information that you need so as to gain empathy for your target group. Each approach involves four general steps. According to Froukje Sleeswijk-Visser, design researcher and co-creator of the context mapping method (a method that allows you to gather deep insights into what people feel and dream), these steps are:\n- Discovery: enter the user’s world and make contact with the user. This will help you get into the right mind-set to understand the user. Let’s say you’re designing a new workflow for employees working at a self-service food court to improve their efficiency. Maybe you have never exchanged more than a few words with the people behind the counters of a self-service food court. You don’t know them. Walking around behind the scenes and getting a glimpse of the hours they put in and the limited space they have to move around in helps you get into the right mind-set. It triggers your designer’s curiosity.\n- Immersion: wander around in the user’s world to collect qualitative data. This helps you take the user’s point of reference. When you start to collect data actively by participating as a member of the food court team, talking to them during coffee breaks and taking pictures of things that stand out to you, you start to experience the context from your users’ point of view.\n- Connection: resonate with the user, and recall your own experiences to connect and create meaning. This step may occur naturally while collecting the data. For example, when you find out how irritated the employees are by the lack of communication about changing menus and special offers, you might recall how it felt when you were in design school and teachers forgot to communicate clearly about changing mandatory literature for the next exam! Not having the right information to do your job properly may lead to a feeling of helplessness. You remember how it feels. You understand and identify with their context and feelings. You have empathic insights.\n- Detachment: step back into the role of designer, reflect and create ideas. While it may seem sufficient to get the empathic insights by following the previous steps, you need to look at your subjective data with a designer’s mind so as to translate the empathic insights into ideas. A feeling of frustration about the lack of communication may seem solvable by actions directed at the team manager at first. Even so, after creating an overview of the insights and reflecting on it more objectively, you can use the informal communication that is already used between team members to create solutions that will give them a stronger feeling of control.\nAuthor/Copyright holder: Ryan Lackey. Copyright terms and licence: CC BY 2.0\nWhen you’re designing a new workflow, for example for employees working at a self-service food court to improve their efficiency, you need to get empathic insights so as to understand who you’re designing for. In the discovery step, you just wander around to trigger your curiosity. In the immersion step, you start to collect qualitative data in the user’s context. In the connection step, you start to create meaning from the data you gather, by connecting them to your own experiences. You finally step back into the role of the designer to reflect and create ideas in the detachment step.\nThese steps reflect the balance you need between collecting subjective information on the one hand and objectively analysing it on the other. However, these steps are not terms that you are likely to use when you are trying to organise time and resources around the design research phase of a project. Rather than talking about immersion and detachment, you will be speaking in terms of collecting and analysing the qualitative data. Collecting information from your target group is the overlap between the immersion and connection steps. Analysis of the collected data is the detachment step. From here on, we will use these simpler terms and explain how to perform these steps in more detail.\nAuthor/Copyright holder: Priscilla Esser and Interaction Design Foundation.\nThe four steps in developing empathy for your target group are discovery, immersion, connection and detachment. In your day-to-day design process, you’re more likely to refer to these steps as collecting and analysing data. Adapted from Merlijn Kouprie and Froukje Sleeswijk-Visser, “A Framework for Empathy in Design: Stepping in and out of the User’s Life”. Journal of Engineering Design Vol. 20, No. 5, October 2009, 437–448\nHow to Collect the Data You Need to Develop Empathy\nJane Fulton Suri, partner emeritus and executive design director at IDEO, describes that collecting information by embedding yourself in the user’s context (the 2nd step, Immersion, and the 3rd step, Connection) can happen in three ways:\n- Looking at what people really do in their current natural context or with prototypes you expose to them — This is a matter of observation of behaviours, interactions and products. Depending on the design assignment, you can plan to focus on certain aspects of the context. In any case, you will record your observations for further analysis and communication. You can do this by using notes, sketches of routes on maps, photographs, videos, etc. For example, mapping medical equipment and nurses on a hospital ward can lead to insights into how to improve the efficiency of workflows which your target audience will experience. And recording a video of walking a route through a government building at the eye-level height of a wheelchair user can lead to insights into how to improve the experience of accessibility.\n- Asking people to participate by recording their behaviour and context or by expressing their thoughts and feelings — You can do this without embedding yourself in the user’s context by using a probes kit for context mapping (a collection of exercises designers give to a target group in a design project so as to obtain an understanding of their lives). However, embedding yourself in a context when asking people to participate may give deeper insights. For example, you might have seniors in a nursing home hand out cards with a pre-printed message which thanks the recipient, typically—in this case—a caregiver, an administration person or a member of the ancillary services (e.g., a janitor or cook). You could walk around with them when they give each one to a person they choose, thereby giving you enormous insights into the reasons behind their choices and the interactions these generate. Also here, you should use recording methods, such as filming or photographing, to preserve the data for later use.\n- Trying things yourself: to gain personal insights into the kinds of experiences others may have — This method is most time-consuming, but it may lead to different and more emotional insights. Resonating with the user on an emotional level may be easiest when you, for example, clean toilets in an office building for a few days and experience the mess people leave behind and the times people don’t greet you like they do their colleagues. It is possibly the most difficult data to capture, but diary-style notes can be a good basis.\nWhile all three approaches focus on gaining empathy, the first is more objective (more focused on cognitive aspects) and the last more subjective (more focused on affective aspects). Both are relevant in connecting with your users, so a mix of approaches will be most useful.\nAuthor/Copyright holder: Nate Grigg. Copyright terms and licence: CC BY 2.0\nTrying things yourself is a very powerful way to develop empathy. It lets you focus on how it feels to be the user. Sometimes, when the target group has specific physical characteristics, we—as the designers involved—might even need special suits so as to step into the user’s shoes more profoundly. Such suits exist for pregnant women or elderly people.\nRegardless of which mix of approaches you choose, selecting the right people and contexts to include in the data collection is important. All embedded approaches to collecting data for empathy take a substantial amount of time. Therefore, it is always more useful to focus on purpose than statistics when selecting the people and contexts to include in the data collection. For example, if you had a design project to improve the integration of immigrant children at school, you could embed yourself in a primary school class with two or three immigrant children. Looking at what the children do as well as how they interact and asking them to express their thoughts and feelings could give you valuable insights. You could even participate by taking the role of the school teacher for a day. This embedded research will easily take you a week of intensive data collection. Statistically, you would not be able to come to solid conclusions. However, as you’re interested in the insights from a design research perspective and need these to generate design ideas, the conclusions are very valuable. Having a statistically sound sample of more than one class or three immigrant children would simply take too much time without adding to the value of insights. So that they can still convince stakeholders of the relevance of findings, design teams at IDEO use data from desk research to back up the insights.\nHow to Analyse the Data Needed so as to Develop Empathy\nThe data you collect is very diverse, from personal impressions to pictures, quotes, maps and sketches. When analysing, your focus is on finding patterns or clusters that ‘stand out’ in some way as being an opportunity for design. For these patterns or clusters to emerge, you need to use your designer’s intuition, but you can help it along with techniques borrowed from qualitative research methods.\nBest practice for an analysis process:\n- Gather all data into one room. Lay the materials out on tables and walls so you can see everything. Get two or three members of your design team together for the analysis.\n- Look at the data and start to see if some have similar themes. You can base these themes on underlying problems, recurrence of negative feelings, or anything else that sticks out and seems relevant to your design problem. Don’t worry if you find it difficult at first. This step in the analysis process will get better with experience. Stick with it.\n- Label or cluster your data into categories, based on the themes you find. Use sticky notes and markers in different colours to indicate which pieces of data belong together.\n- Summarise the findings. At first, this could be an unorganised list of all conclusions. Then, you may add a hierarchy or (again) categories. Finally, you can summarise the findings in personas, requirements, mental models, scenarios, flowcharts or graphs. This will allow you to use the insights in any step of the remaining process and communicate them to stakeholders.\nAuthor/Copyright holder: Luca Mascaro. Copyright terms and licence: CC BY-SA 2.0\nAnalysing the qualitative data from embedded research is best done with a few designers, to allow discussion. Using different colours of sticky notes and markers, you and your fellow designers can indicate themes to create an overview.\nThe Take Away\nIn order to design great experiences, you need empathic insights. It is important to balance the steps of collecting subjective insights with objective reasoning and analysis. The best way to collect the subjective information is to embed yourself in the context of your target group and gain personal insights into the experiences they have. Three different approaches are available to you. Together, they enable you to get empathic on an affective and a cognitive level: observing people, asking them to express themselves and experiencing things yourself. You should take four steps in each approach: discovery, immersion, connection and detachment. When analysing the collected data, you can borrow techniques from traditional qualitative research and apply them so as to find opportunities for design. If you’re especially attentive and careful throughout these processes, you may access powerful insights into your target group’s way of seeing the world.\nReferences & Where to Learn More\nJane Fulton Suri, Empathic Design: Informed and Inspired by Other People’s Experience. In: Ilpo Koskinen, Katja Battarbee, and Tuuli Mattelmäki, eds. Empathic Design: User Experience in Product Design, 2003\nKatja Battarbee, Jane Fulton Suri and Suzanne Gibbs Howard, Empathy on the edge: Scaling and Sustaining a Human-Centered Approach in the Evolving Practice of Design, 2014: https://www.ideo.com/images/uploads/news/pdfs/Empa...\nMerlijn Kouprie and Froukje Sleeswijk-Visser, “A Framework for Empathy in Design: Stepping in and out of the User’s Life”. Journal of Engineering Design Vol. 20, No. 5, October 2009, 437–448', 'User Experience (UX) and User Interface (UI) – are they the same or different? Can we even compare them? Both of these issues affect product design. It is crucial to understand the difference between UX and UI – especially if you are interested in working in this field. Let’s investigate what relationships are between these two areas.\nUX and UI – table of content:\n- User Experience (UX) – the basics\n- User Interface (UI) – the basics\n- How are UX and UI Similar?\n- How are UX and UI different?\n- Comparing apples to oranges? The relationship between UX and UI\nUser Experience (UX) – the basics\nIn this field, designers work on the experience that users have while interacting with the product. Of course, the goal is to make the experience positive and smooth.\nThe UX designer must research the needs, goals, and struggles of the target users. The whole designing process includes skills like visual design, analytics, user research, project management, and UI!\nThe work of the user experience designer usually includes:\n- strategic planning,\n- user-research (primarily conceptual, not visual),\n- information architecture (organizing and planning the content),\n- wireframing, prototyping the product,\n- caring about the flow of the users (their journey),\n- testing with real users,\n- analysis of the whole process,\nUser Interface (UI) – the basics\nThe User Interface is everything that the user interacts with. Usually, it is a mobile app or website interface.\nThis includes designing screens, keyboards, sound and light effects, and whole logic standing behind the navigation of the product.\nThe job of the UI designer is to optimize the experience of interaction with (only) the interface – not the whole product.\nThe work of the user interface designer usually includes:\n- design research (trends, visual needs),\n- designing visuals (all the layout, colors, fonts, icons, buttons, etc.),\n- branding (part of the positioning of the product),\n- style guidelines, defining the visual rules,\n- caring about the responsiveness (smooth adjusting through the platforms) and interactivity and animations,\n- prototyping (just like UX experts, they need to test the effects of their work).\nHow are UX and UI Similar?\nBoth UX and UI are:\n- focused on the user (on needs, struggles, and desires),\n- based on optimization of the experience (to make it positive and easy),\n- demanding skills like designing, data analysis or user research,\n- usually in the tech world.\nImagine that we need to build a website for the delivery company.\nThe whole experience and logic of the service is mainly the job of the UX designers. They must research the needs and design a smooth and intuitive process for the customer.\nThe job of the UI designer is to focus on one part of the process (often working with the UX designer) – designing the interface that will be an easy path for the customer.\nHow are UX and UI different?\nThe main difference between UX and UI is the breadth of each fields of design.\nUser Interface focus on the digital devices, especially users’ ability to use them properly.\nUser Experience is a much broader term, containing whole products and overall strategy (not only building the visual element). User experience doesn’t even have to be about digital products.\nAnother thing is that UI is more focused on the look (of the interface). While UX also wants a smooth experience – logic is more important than visuals.\nTo achieve outstanding UX, both UX and UI designers must work hand-in-hand. Both are necessary for the creation success.\nSomething that looks fabulous but is a pain to operate is an example of great UI and poor UX. Something very usable that looks awful is an example of excellent UX and low-grade UI.\nComparing apples to oranges? The relationship between UX and UI\nAs you probably noticed at this point, UI is simply part of UX.\nThat relationship makes it hard to compare these two areas – it is like comparing the experience of sitting in a well-designed interior to the quality of the couch you are sitting on.\nUser Interface is a narrow element, the specialization, that (among other factors) works to achieve a good User Experience.\nThe UX designer often works on a more abstract level (for example, works on strategy and logic). At the same time, the UI designer puts these ideas into love by designing specific elements (the interface with its fonts, colors, spacing, and others).\nDespite the contrasts, UX and UI are not thoroughly detached things! Both are crucial and work hand-in-hand to determine how a product will look and function. One always influences the other.\nUX and UI – summary\nUser Experience (UX) and User Interface (UI) are some of the most confused and misused terms in the field. People are often mixing, interchanging, and confusing them. It may be a result of misunderstanding how broad the UX term is.\nPutting things simply– UI include elements that enable the user to interact with a product. UX is what the individual experiences while interacting with the product.\nThe ultimate UX Guide:\n- What is UX – and what it is NOT\n- UX and UI – are they comparable?\n- 7 factors of (outstanding) User Experience\n- Do you know what UX Design means?\n- Are you designing user experiences? Take care of these things!\n- 10 usability heuristics for UX design you need to know\n- The UX design process in 5 easy and simple steps\n- User-centered design and its main principles\n- Stages of User-Centered Design process\n- What is Customer Experience?\n- User Experience vs Customer Experience. A simple explanation of their relationship\n- What is a Brand Experience?\n- What is Human-Computer Interaction (HCI)?\n- Why UX is important?\n- Usability vs functionality in UX\n- Examples of good UX design']	['<urn:uuid:8b34c523-fb8e-46af-8ca5-3c5474ffd0b3>', '<urn:uuid:46a6003f-4deb-4a6a-8d22-521c28280bb4>']	open-ended	direct	verbose-and-natural	distant-from-document	comparison	expert	2025-05-12T13:53:09.865574	24	132	3778
21	reforestation plan environmental health benefits	An urban reforestation plan benefits environmental health through storm water remediation, heat island reduction, tree canopy increase, and total tree count increase. It also provides increased oxygen, reduces carbon-based pollution, improves quality of life, offers psychological benefits, raises property values, and supports plant, insect, and animal life.	['Urban Releaf founder and Director Kemba Shakur has joined the Environmental Justice Advisory Committee (EJAC), a group committed to helping the state of California develop its 5-year scoping plan around AB32, the Global Warming Solutions Act.\n“After 15 years of advocating for trees in communities of color and poor communities, we at Urban Releaf are well-suited to play a role in helping to shape the future of California’s environmental policy,” Shakur says, adding, “These are exciting times. California is on the cutting edge of a national push toward a clean energy economy, and urban forestry can play a big role in that socioeconomic shift.\n“Urban forestry is an integral part of a healthy ecosystem – it relates to air, land, water, energy and people. The benefits of urban forestry include increased air quality and mitigation of the urban heat island effect, as well as creating green jobs which can be part of youth workforce development efforts.”\nIn inner-city communities, Shakur adds, “the lack of trees affects people’s lives, particularly poor people, who are living in toxic, polluted, and otherwise unhealthy environments, next to the port, freeways, and diesel trucks routes.” To address this, Shakur maintains, “urban forestry needs to be instituted into every city’s climate action plan.”\nEJAC’s mission is to assist Sacramento legislators and state employees in developing best practices recommendations for the implementation of SB535/AB1532, which mandates that a portion of revenues generated by the Greenhouse Gas Reduction Fund (GGRF) be allocated to “disadvantaged” communities (as identified by CAL-EPA’s Enviro-Screen), also known as EJ, or Environmental Justice, communities.\nThe forming of the EJAC committee is an indication, Shakur says, that “the benefits of trees are beginning to be more widely known, as more emphasis is placed on policy around climate change and global warming.”\nUrban Forestry is one of five priority areas identified by the SB535 Coalition (Urban Releaf, Greenlining Institute, Asian Pacific Islander Environmental Network, Climate Change Action, and Public Advocates) to be targeted according to the criteria identified in the California Air Resource Board (CARB)’s Draft Investment Plan (available as a .pdf here) for the GGRF, also known as Cap-and-Trade auction proceeds. In addition to urban forestry, priority areas include energy (energy efficiency/renewable energy), transportation, and affordable housing next to transit.\n“We need to green communities most affected by poor air quality and the urban heat island effect,” Shakur says. Projects Urban Releaf would like to see developed under AB32 and SB535 include green jobs, training programs, research, partnerships, and collaborations, specifically:\n- Reforestation in low-canopy urban zones\n- Planting trees along transit corridors and high-traffic areas\n- Increased investment in urban gardening/farming/landscaping\n“An urban reforestation plan can be the centerpiece of a community-based environmental health campaign in disadvantaged/ EJ communities,” says Urban Releaf Program Manager Kevin Jefferson. This includes storm water remediation, heat island reduction, tree canopy increase, and a total tree count increase, as well as urban farming and small-scale renewable energy, such as rainwater catchment.\nIn addition to creating much-needed jobs for the community, the results of such campaigns, Jefferson notes, would include “increased oxygen, and a reduction in carbon-based pollution, as well as improving the quality of life, providing psychological benefits, raising property values, and supporting plant, insect, and animal life. Lastly, Jefferson adds, “there is a need for more education and research, which allows for more informed policy decisions to be made.”']	['<urn:uuid:f030abbe-f558-453e-a8a4-7ed8df030c02>']	open-ended	direct	short-search-query	similar-to-document	single-doc	expert	2025-05-12T13:53:09.865574	5	47	561
22	how does lighting work in photography and what drone features help with aerial shots	In photography, proper lighting is crucial - the sun shouldn't be behind subjects outdoors to avoid overwhelming the shot, and flash can be used to flood dimmed areas but may wash out subjects if too close. For aerial shots, drones require GPS navigation systems and inertial measurement units to determine location, as well as autonomous flight capabilities that allow them to maintain stable flight paths. They also need high-quality cameras with gimbal mounts to maintain camera position during turbulence.	['A remarkable or eye-catching photograph can go a lengthy way when advertisers are attempting to offer their product. This lesson will examine the types, strategies, and designs of digital photography.\nGlass Plates to Go-Pros\nPhotography has actually come a lengthy means considering that its invention by Louis Jacques Mandé Daguerre in 1839. No longer just for professionals, today’s video cameras permit everybody with a smartphone to capture pictures of the world around them. These photographs do not even have to be created; with a click of a switch, photos can be shared throughout the world.\nTypes of Digital photography\nThere are many different kinds of photos that marketers could utilize, so prior to you take a photo, you have to make a decision which kind of photo would certainly function best for your type of product. Let’s check out a few fundamental sorts of digital photography.\nAmong the most prominent sorts of photography is picture digital photography. Any type of photo with a face, from individuals to pets, is taken into consideration a picture. Pictures are typically utilized to market beauty products, like mascara or lipstick.\nAerial digital photography is made use of when taking overhanging shots of things like marathons or traffic. Action digital photography is typically utilized in sports sections, showing professional athletes participating in whichever occasion took place the night before. Both of these kinds could additionally be thought about docudrama digital photography, implying they are photos of events.\nIndividuals wanting to offer something usage building photography or business photography. These are photos of products or residences or buildings. Nature photos are considered magazines or web sites and also are typically of landscapes and pets.\nDigital photography Techniques\nAfter choosing what sort of photo you desire, you after that have to decide just what style you desire it to be. The most common data format is a JPEG, which most cams immediately utilize. RAW format is utilized when much more editing is needed, as well as the TIFF format is made use of for enlargements.\nAs soon as you have actually picked your style, then line up your shot. A good thing to bear in mind is the regulation of thirds, which is considering your subject and also aiming to think of that there’s a grid of 9 equal squares over your shot. This assists with positioning as well as framing so your pictures look even more balanced and all of the action isn’t to one side or the various other.\nIf you have an electronic camera, most will automatically adjust the exposure for you. Direct exposures make pictures lighter or darker, depending on how long the shutter is open. Modes automatically readjust setups when you take different sorts of photos. With the appropriate setting, sporting activities photos won’t look fuzzy, and you can record a shot of a bird in flight. The best perfume for young ladies project was a case study utilised by many photographers.\nIllumination is also crucial. If you are taking a photo of somebody outdoors, make certain the sun isn’t really behind them, due to the fact that possibilities are the sunlight will bewilder the shot, and also you will not have the ability to see the face of your topic.\nAlso important is the flash. In some cases the flash can be made use of to your advantage, flooding dimmed areas with light. Beware with the flash, however, because if you obtain as well near to your subject they’ll obtain washed out as well as look like they’re beautiful. You can also transform your flash off if you’re outdoors or someplace with a great deal of excellent illumination.\nPhotography Equipment as well as Editing\nIn addition to the flash that includes your cam, a separate flash system could also be bought. Expert digital photographers generally have these to add better illumination to their photos.\nOne means to maintain your photographs from looking fuzzy is to utilize a tripod or monopod. These can be attached to your camera to maintain your capturing. Tripods could likewise aid when you want to remain in your photo, as you can put your camera on your tripod, establish your timer, as well as enter the structure', 'A drone’s primary features include its camera, sensors, and navigation system. It also has an autonomy level. Each of these features will determine how smooth and safe its flight will be. These factors will help to decide which drone is right fit for you. Continue reading to learn more about what features you should look for when buying a drone.\nDrone sensors are an important part of a drone’s system. They gather information from the surroundings to keep the drone’s position, determine its speed, and avoid obstacles. They provide valuable data to drone designers. There are many sensors on the market, so it is important to choose the right one for you.\nAdvanced sensors on drones can collect specialized data. Researchers can combine multiple sensors to create a richer view of an area. This results in better data. A drone can create orthomosaics and 3D models using the right sensor. These data can be processed with algorithms to identify water quality and plant disease, and create surface composition surveys.\nAnother important sensor for drones is the accelerometer. These sensors measure linear acceleration in both the vertical and horizontal directions. These sensors are used to calculate the drone’s altitude, speed, direction, and altitude. They can also detect vibrations. These sensors, despite being tiny, are an essential part of a drone’s system. These sensors are essential for drones to maintain a precise altitude when hovering or flying.\nDrones are gaining a lot of attention. The technology is expected to improve our lives in many ways, from making us safer and more efficient. Drones must be stable and accurate, communicate well, and reach the desired height. It is crucial to ensure that your drones can do all you ask them to.\nYou can mount the sensors on a drone directly above or below the rotating rotors. This is because the airflow is stronger above and below the rotors. Different drone designs can use this airflow to their advantage. You can mount video imaging detectors above or below the drone’s body.\nA drone’s navigation system can be incredibly valuable, but it can’t fly without sensors. Fortunately, drone manufacturers are expanding the range of applications available for drones, including AI-based piloting and smarter sensors.\nThe navigation system of a drone is designed to keep track of its position in real time. The system consists of two main parts: the high-level controller (or controller) and the low-level one (or controller). The high-level controller is designed to enforce the drone’s path while the low-level controller is designed to make the drone respond to any input. It uses an artificial vector field and uses the drone’s mass as a parameter.\nA drone’s navigation system must be capable of identifying and navigating in 3D space. It is essential to ensure the safety of the drone and its operator. It must be able safely land and perform BVLOS missions. A robust navigation system will help protect a UAV from harm, and will make it possible for a drone to complete the mission safely without requiring the assistance of a pilot.\nOne of the most popular drone navigation systems is a GPS-based system, which is used to track the position of the aircraft and determine its direction. The GPS system must also be protected against jamming. Jamming of GNSS signals is possible and simple jammers can even be purchased online. Many drone developers have tried to develop safe landing protocols that allow drones to use GPS. While this method has had some success, it is not yet capable of providing accurate positioning data in all situations.\nCurrently, commercial drones rely on GPS signals and inertial measurement units to determine their location. Small drones are unable to carry heavy sensors, so they can’t be carried around with a lot of weight. Sensors must be small and lightweight. The navigation systems of these drones should not be able to be too complex and bulky. Small drones cannot fly long distances without a GPS signal.\nDrones can also be equipped with GPS and autopilot functionality. This enables the operators to plan the drone’s flight path before the actual flight begins. Operators can also use the autopilot feature on GPS drones to set autonomous flight instructions at waypoints such as hovering for a certain amount of time.\nAutonomy is a key characteristic of unmanned aerial vehicles. Customers can benefit from drones that are able to plan their flights, avoid collisions, take photos and videos without human intervention. Autonomy is also essential for ensuring the quality and consistency of the data captured. Autonomous flight planning reduces the cost of drone inspection programs and can ensure that drone data is accurate, consistent, reliable, and reliable.\nExyn drones are equipped with Level 4A autonomy, which allows them to fly autonomously at speeds of more than 2 meters per second and collect data about their environment. Drones equipped with Level 4A Autonomy are capable of covering an area up to 16 million cubic meters in one flight. This is equivalent to nine football stadiums.\nDelivery will be the most common use for drones. Aerial taxi services will require autonomy and self-flying capabilities. They will be able follow a target object and navigate towards its GPS coordinates. However, self-flying drones can go out of control and become a danger to human users.\nAlthough Level 3 autonomy doesn’t equal full autonomous flight, it is a major milestone in the development and use of pilotless drones. Most players in the UAV industry have attained Level 2 or 3 autonomy. However, they still need to communicate with a human operator to operate safely.\nAlthough autonomous flight sounds like a great use case for autonomous drones (and it is), farmers would be better off manually piloting the drone. Farmers who are inspecting their fence lines might find it very useful if the drone can self-pilot. Farmers may be better off taking a break if the drone is unable to self-pilot.\nA drone equipped with a camera is a great way to get aerial shots of the environment. However, there are many factors to consider before flying a drone for imaging purposes. First, decide what area of interest you wish to cover. Then you should consider how high to fly the drone. The altitude of the drone will affect the number of images that the camera can take. A higher altitude means more fields covered per image, but it also reduces the resolution of the images. The resolution of images will depend on the sensors and the altitude at which the drone is flying.\nWhile some drones come with in-built cameras, the highest-end models will let you mount specific camera equipment on the drone. This can be beneficial for those who plan on filming a film. You can also use a drone for inspection purposes, such as filming farmland or inspecting industrial equipment.\nA night vision lens is another feature you should look for in a drone. This lens can record thermogram videos at 30 frames per second. These thermal lenses also come with 16x zoom. You can also use picture in picture mode, which allows you to overlay thermal images on regular camera images.\nA drone camera’s ability to capture high-quality images is another advantage. A high-quality camera with a gimbal mount will be able to maintain the camera’s position even during turbulence. This is particularly useful if you are planning on aerial photogrammetry projects. The photographs can be used to map out a field or monitor crops. A high-end camera with a high-resolution sensor is important for this kind of project.\nPrivacy is another consideration. While drones are relatively cheap, they can pose privacy concerns. Some states have laws that prohibit aerial photography on private property.']	['<urn:uuid:f6f2f41f-378b-4853-8370-100543063dac>', '<urn:uuid:d06db51d-ca05-4f50-bb80-b6ef40ed0df1>']	factoid	direct	long-search-query	similar-to-document	multi-aspect	novice	2025-05-12T13:53:09.865574	14	79	1983
23	As someone designing eco-friendly homes, I'd like to understand how geothermal heat pumps integrate with other home systems - what are their applications beyond heating/cooling, and how do they contribute to environmental sustainability?	Geothermal heat pumps can be integrated with multiple home systems, particularly water heaters, by providing water from the geothermal heat loop to reduce energy consumption for hot water production. They can also be combined with other renewable energy solutions like solar water heaters, solar panels for powering HVAC components, and wind turbines to support home mechanical systems. From an environmental perspective, these systems are highly sustainable as they produce zero on-site emissions, helping reduce CO2 emissions from building heating, which currently accounts for 40% of CO2 emissions. When powered by clean electricity from renewable sources, the system can operate with zero carbon emissions.	"[""Geothermal AC systems are still some of the best options when you are looking for an energy-efficient HVAC solution for your home. Before you have a geothermal loop installed and the old AC replaced, there are several things that you will want to consider, such as the location and design of the heat-exchange loop and where the geothermal energy will be used to improve the efficiency of mechanical systems in your home. The following tips will help you choose the right geothermal design when replacing an old AC with more efficient technology.\n1. Deciding If Geothermal AC Is the Right Choice for Your Air Conditioner Replacement Project\nGeothermal heat exchangers may not be the right choice for every AC replacement project. Therefore, you will want to evaluate your home to determine if geothermal AC is right for you. The main thing that you will want to consider is if there is enough room for the geothermal loop or if a vertical loop can be drilled. You will also want to consider the cost of the installation and if it fits in your AC replacement budget.\n2. Choosing the Type of Geothermal Loop That Will Be Used for Your HVAC Heat Exchanger\nThere are several types of geothermal heat exchange loops that can be installed for your AC. The first and most common of these is a buried system, which will require enough space in your landscaping to bury the lines. If you do not have a lot of space, there are also options to drill for vertical loops. If you have a body of water like a pond or lakefront property, loops can also be installed deep at the bottom of the water to provide your AC with the geothermal heat exchange system it needs.\n3. Using Geothermal Heat Exchange to Provide More Energy to All the Mechanical Systems for a More Efficient Home Design\nWhile your geothermal system is mainly used to provide energy for the cooling and heating needs of your home, it can also be used by other systems. For residential applications, water heaters typically use it, and they can be provided with water from the geothermal heat loop to reduce the amount of energy that is needed to provide your home with hot water.\n4. Choosing Other Upgrades and Renewable Energy to Add to Your Geothermal HVAC Installation\nIn addition to the geothermal heat exchange loop, there may be other upgrades that you want to do when replacing the AC. These upgrades can include things like updating the ductwork and thermostats of your HVAC system. You can also add renewable energy with things like solar water heaters for heating, solar panels to power HVAC components, or wind turbines that help provide energy to your home's mechanical systems.\nThese tips will help you choose the right geothermal HVAC design to replace an old and inefficient air conditioner. If you are ready to replace your old system, contact an air conditioning service and talk to them about some of the options for installing a geothermal HVAC system in your home."", 'Ground Source Heat Pump - Domestic\nHow efficient is a ground source heat pump system?\nModern systems can be very efficient. For each kilowatt of electricity used to run the heat pump, three to four kilowatts of heat can be delivered to the building. The efficiency of a GSHP installation is very dependent on the quality of the design and installation. The efficiency of the installation is improved by utilising solar recharge of the ground.\nAre ground source heat pumps new?\nGSHP systems are common, particularly in the USA, Canada, Sweden, Switzerland and Germany. The principles of ground source heat pumps were first described by Lord Kelvin in the 1850s and continuous development since they were first used commercially more than 50 years ago has greatly improved their efficiency and reliability. They now provide a proven, cost-effective, safe and environmentally friendly alternative to fossil fuels.\nHow large are ground source heat pumps?\nA heat pump for a house is about the size of a large fridge. More powerful heat pumps for commercial buildings do not increase in size or price as much as they do in power output.\nCan a GSHP supply hot water?\nYes. Some domestic systems are able to heat domestic hot water via a modern high efficiency indirect water cylinder.\nCan GSHPs provide cooling?\nYes. Reverse-cycle heat pumps can deliver both heating and cooling very effectively. Cooling provided by heat exchange with cold ground is inherently more efficient than air conditioning which typically exchanges heat with hot air.\nCan a standard domestic electricity supply be used?\nYes. Heat pumps are designed to run on a standard UK single phase supply. However, a three-phase supply is a preferable option, and will be essential for larger installations.\nWould a ground source heat pump system be suitable for a well-insulated house?\nYes. Almost all new houses in the UK are designed to meet Building Regulations and should be able to benefit from a ground source heat pump. Building Regulations have been designed to conserve fuel, reduce heat losses and ensure greater energy efficiency, in order to ensure that all modern properties need less heating. For a well-insulated building the size of heat pump will be smaller, will need smaller ground loops and will therefore be less expensive. You should take advice from an installer with experience.\nMy architect suggests I install underfloor heating. Is this a good idea?\nYes. Ground source heat pump systems are ideally matched to modern warm temperature underfloor heating because a heat pump transfers heat at a higher coefficient of performance if it delivers to a large warm water circuit (like underfloor heating) rather than a small high temperature circuit (like wall mounted radiators).\nI have an older property. Can a ground source heat pump be installed?\nYes, but the cost of a system is directly related to the heat losses, which will generally be higher in older buildings. Money spent on upgrading insulation levels can save a considerable amount on the capital cost of a ground source heat pump system.\nCan radiators be used instead of underfloor heating?\nYes, but you will need larger radiators, sized for the typical 45°C to 50°C water temperatures obtained from efficient GSHP systems. If your house is well insulated they may be suitable. Your installer will need to check how big they would have to be and the space they would take up. Modern die cast aluminium radiators are very efficient and smaller than conventional radiators. Upstairs is usually less of a problem as bedrooms are normally kept at lower temperatures.\nCan the heat pump be installed outside or in a car-port, garage or basement?\nYes. There normally means the pump will be nearer to the pipe connections to your ground loops, which often makes the whole system easier to connect.\nWill long trenches have to be dug on my land for the ground loops?\nMy land is too rocky to dig trenches – can I still fit a heat pump system?\nI don\'t have enough land to dig long trenches – what do I do?\nVertical boreholes can be used for heat exchange with the ground instead of trenches.\nHow big are the trenches?\nA typical heating-only installation for a medium sized, new build detached house would need two narrow trenches, each 300 mm wide and 40 to 50 metres long and 2 metres deep. The trenches can be straight or curved and laid in any direction to suit your site, providing they are five metres apart. A standard excavator can dig the trenches and backfill them after the ground loops have been installed. Your installer would be able to do this work and plan it to ensure the minimum of disruption to your site. Once the ground loops are installed, pressure tested and buried, your renewable energy collection system should need no further attention. However, its location needs to be recorded to avoid it being accidentally disturbed!\nCan trenches be installed on a downward sloping site?\nYes, provided the trenches can be dug, a moderate downward slope is not a problem. Consideration needs to be given to purging air from a system with ground loops higher than the heat pump.\nI have a large plot of land but the ground is quite hard. Can a shallower trench be dug?\nYes, the ground loop coils can be laid so that the coils lie horizontally in the trench rather than vertically. This would need a wider but shallower trench depth to at least 1.2 metres. However, this is not as satisfactory as a deep trench in which the coils are vertical and you will need a special slinky configuration and probably longer trenches. Your installer will be able to advise you accordingly.\nI have some very wet land. Can I use this?\nYes, wet land is better at conducting heat so, as long as a trench can be dug, it is ideal.\nI have a large pond. I have a stream. Could this be used?\nYes, it is possible to use very large ponds and fast flowing streams as a heat energy source using an open loop system.\nAre GSHP systems environmentally friendly?\nYes. In the UK, there is now a strong move towards alternative technologies that are sustainable and environmentally much more acceptable. 40% of CO2 emissions are derived from the heating of buildings. By using renewable sources of energy to heat your property you can help to reduce these carbon emissions, particularly when compared to burning fossil fuels such as oil. Most electricity suppliers are now offering \'clean green\' electricity from a renewable energy source and, if you use this to power your heat pump, your property will be totally heated from renewable energy with zero carbon emissions.\nAre Ground Source Heat Pumps dangerous?\nThere are no hazardous gas emissions, no flammable oil, LPG or gas pipes, no flue or chimney and no unsightly fuel tanks. GSHP systems have absolutely NO site emissions. There is, therefore, no need for safety checks.\nAre Ground Source Heat Pumps noisy?\nNo, a ground source heat pump makes less noise than a gas boiler, and very much less than an air source heat pump which drives a fan to extract heat from ambient air.\nWhat about servicing and maintenance?\nAs with any valuable plant a ground source system should be covered by an annual maintenance agreement with the supplier. However, routine maintenace requirements are very low. A ground source heat pump can be expected to last over 20 years – longer than a combustion boiler – and the ground heat exchanger should have a life of over 100 years.\nGround source systems are automated. Because they come with low maintenance, low running costs, low noise and are out of sight, they are often referred to as ""invisible heating systems"".\nHow do running costs compare with conventional alternatives?\nIn a modern, well insulated house, a ground source heat pump can offer very high efficiency and low running costs. An oil-fired boilers cost considerably more to run, and electric heating is at least three times as expensive. Modern condensing gas boilers are more expensive to run at current gas prices, and gas prices are set to rise. Also, all fossil fuel boilers need regular servicing to maintain efficiency and check safety.\nWhat are the costs?\nThe initial purchase costs of a ground source heat pump system are more than a conventional oil or gas fired boiler. The initial capital expense is offset by lower running costs, lower maintenance and low servicing requirement. There is also the security of knowledge that the majority of your heating and cooling energy comes out of your ground, is under your control and will not increase in price.\nBe careful to avoid judging an installation on price alone. It is more important to ensure you have a well designed system if your aim is to save money over the life of the installation.\nIs Planning Permission required to install a GSHP?\nNo, a ground source heat pump installation is invisible, makes less noise than a gas boiler and issues no gases of any kind on-site: there is nothing for anyone to object to.\nAre grants available to reduce costs further?\nYes, the government introduced Renewable Heat Incentive for ground source heat pumps installed in domestic buildings at 18.8 p/kWhr on 9 April 2014. Heat pumps installed before April 2014 also qualify for RHI (if commissioned after 15 July 2009).']"	['<urn:uuid:fe9e5d2b-33a4-4ac1-aadb-a614607c4c73>', '<urn:uuid:ab813ab4-d1a1-4625-9cf9-ebf2cff7699c>']	open-ended	with-premise	verbose-and-natural	distant-from-document	multi-aspect	expert	2025-05-12T13:53:09.865574	33	103	2083
24	max power output unmanned aerial hybrid generator	The Boxer generator is capable of delivering 4 kW of energy.	['Avartek Boxer – Advanced Hybrid Power Technology\nAvartek Boxer Hybrid is a gasoline powered unmanned aerial system (UAS, UAV, RPAS or drone). The main feature of Avartek Boxer is the hybrid system that provides all the flight energy by transforming gasoline into electric thru its onboard power generator for much longer flight times while maintaining the heavy payloads of large LiPo powered drones.\nInstead of carrying heavy batteries the Avartek Boxer Hybrid is designed around a liquid cooled mini generator power plant that transforms gasoline into electrical power. Currently the Boxer generator is capable of delivering 4 kW of energy which translates to 5 kg of real payload and 2 hour flight times. This quadruples the flight mission lengths and provides easy on field operations due to the lack of battery management and charging problems.\nThe Boxer design is fully custom. The airframe was designed by Avartek in Solidworks and all parts are manufactured in Finland. Only motors, escs, the flight controller and other electronics are out sourced.\nThe whole copter is designed around the hybrid generator’s capabilities of producing 10x more energy than similar weight in LiPo batteries. 4 kg of gasoline provides 2 hours of flight time at MTOW 25kg, while a typical LiPo battery in this size of a drone of 11kg would only provide 30 minutes. 4 kg of gasoline (5 litres) equals 40 kg of LiPo batteries. On field operations greatly benefit from the very quick duty cycle of hybrid drone by offering easy refills instead of on battery management and recharging arrangements.\nAvartek Boxer’s Pixhawk flight controller provides an easy to use system with unparalleled options for customisation both from flight controller, sensor and add on hardware as well from the software perspective. Pixhawk 2 is 100% open system and compliant with latest technologies.\nTypical Payload Options\nAvartek offers ready made payload setups. Safe, quick mounting and fully suspensed – ready to mount the sensor, IMU and auxilaries, such as onboard PC and telemetry/cloud datalinks. In Boxer typically auxilaries are mounted inside the airframe while the IMU is securely attached to the sensor.\nQuicklocks provide quick mounting points to the hardware rail underneat the airframe. This provides quick access to the payload and allows for quick payload swaps in the field. The long payload rails and heavy lift capability makes the Boxer an ultimate multi sensor UAV. Boxer features a large deck that can accommodate payload auxiliary sensors such as hyper spectral camera irradiance sensors. Payload GPS antenna can be attached to the antenna tower. Cabling can be pulled thru the body with customisable deck covers.\nOptional retracting landing gear provides unrestricted field of view for most payloads and the front mounted FPV camera safety and video recordings of flown missions.\nFlight Controller: Cube Orange\nRemote Controller: Futaba 14ch\nESCs: T-Motor Flame 60A\nMotors: Avartek Boxer\nPower System: Avartek\nBattery: Lipo 12S 5Ah\nHybrid Power Management Unit: 4 kW\nFuel tank size: 5 litre\nFlight duration: @25kg TOW approx. 120 minutes\nFrame: Carbon fiber designed and manufactured by Avartek']	['<urn:uuid:a83f4190-c299-4ac8-b1cb-f4b5899ebf4a>']	factoid	with-premise	short-search-query	distant-from-document	single-doc	expert	2025-05-12T13:53:09.865574	7	11	505
25	effective planning strategies creative work comparing professional writers teachers methods benefits drawbacks	Professional writers and teachers share similar approaches to effective planning, emphasizing the importance of concrete, visualizable plans over mere goal-setting. For writers, this means being specific about works-in-progress without over-discussing them, creating concrete plans for their writing process, and using workshops strategically for feedback. For teachers, it involves creating visual aids like charts that break down steps clearly, co-constructing plans with students, and ensuring plans include specific when/where/how components. Both groups recognize that simply stating goals or needs without detailed implementation plans is ineffective - similar to wishing for money without a savings strategy. The key difference is that teachers' plans often need to work at both individual and group levels, while writers' plans are typically more individually focused.	['An Interview with New Member Gregory Frost\nBy Ron Breznay\nGregory Frost is a writer living in southeastern Pennsylvania. He has penned novels, short stories, articles, and book reviews in the fantasy, science fiction, and horror genres. Greg has an extensive education in writing. He is a graduate of the writing program at the University of Iowa and of the Clarion Writers Workshop, at which he was later an instructor. He attended many Sycamore Hill Writers Workshops, the Nameless Workshop, and the Philadelphia Stories Workshop. In addition, he was one of the rotating Fiction Writing Workshop Directors at Swarthmore College in Swarthmore, Pennsylvania.\nGreg’s work has been nominated for every major fantasy award. His novelette “Madonna of the Maquiladora” was a finalist for the James Tiptree Award, the Nebula Award, the Theodore Sturgeon Memorial Award, and the Hugo Award. His Shadowbridge duology was a finalist for the 2009 James Tiptree Award, and the American Library Association named the Shadowbridge duology one of the four best fantasy novels of 2008.\nHis novels include the two Táin books, Táin, (1985) and Remscela (1988), which retell the Irish epic Táin Bo Cuailnge; the books were later combined into one volume, Crimson Spear: The Blood of Cu Chulainn (1998). He wrote two novels in the Shadowbridge series, Shadowbridge (2008) and Lord Tophet (2008), which are fantasy novels set in a world of linked bridges and tunnels. His other novels include Lyrec (1984), about two interdimensional travelers on the hunt for a monstrous creature; The Pure Cold Light (1993), a satirical novel about an alternate Philadelphia; and Fitcher’s Brides (2002), a retelling of the story of Bluebeard.\nHe has written many short stories, some of which are included in the fantasy collection Attack of the Jazz Giants: And Other Stories (2005).\nGreg was a member of the HWA in the past and recently rejoined. Let’s give him a hearty welcome back to the Horror Writers Association.\nHWA: Your bibliography includes mostly fantasy and science fiction, but there are also several horror stories listed. Why do you occasionally dip into the waters of horror?\nGF: Actually, I think there’s more dark fantasy and horror in my biblio than anything else–certainly in the category of short fiction. I suspect it’s all due in part to growing up reading things like Playboy magazine, where the genres freely mixed and one could find John Collier, Frederick Brown, Roald Dahl, Arthur C. Clarke and Ray Bradbury all jumbled together.\nThat reading material and a lot of Friday night creature features, The Twilight Zone and The Outer Limits, all of it part horror, part science fiction, and part Roger Corman, which is likely its own subgenre. So I arose steeped in cross-genre material and I suppose I think that way. The two books I’m working with right now are full of ghosts and hauntings and curses.\nHWA: What are your works of horror? What sub-genre of horror do you prefer to write in?\nGF: The best known horror work of mine is probably Fitcher’s Brides, which was a finalist for Best Novel on both the World Fantasy Award and the International Horror Guild Award ballots. That’s a historical thriller set in 1843 in the Finger Lakes of New York, and is a recasting of Bluebeard, incorporating the real millennialist religious fervor of the time. So, you know, the world is famously supposed to end this year, and I’m just laughing about that, because it’s all occurred before with similarly disappointing results.\nI like to work a lot in psychological horror. I like stories that can leave you suspended at the end. The story’s done but you can’t stop thinking about it. I’m very fond of William Hallahan’s The Search for Joseph Tully for that very reason. It seems that my own horror writing tends to drift into the historical. The piece I have in Ellen Datlow’s Supernatural Noir, “The Dingus,” which has just come out, is set in 1950 in Philadelphia. Another, “That Blissful Height,” in John Kessel’s Intersections, was the result of encountering a portrait of an allbut-forgotten Philadelphia scientist who experimented with spiritualism in the 19th century. Another horror story, “Lizaveta,” was set in Russia in the early 20th century, and came about from reading Harrison Salisbury’s Black Night, White Snow. So…I enjoy history, but I am clearly wired for weirdness. Even when I read something purely historical, it invariably takes me down strange paths.\nHWA: What is interstitial fiction? And what is the Interstitial Arts Foundation?\nGF: IAF is an organization I don’t really have anything much to do with now. It was begun by Terri Windling, Midori Snyder, Ellen Kushner, Delia Sherman and others to promote works of art–fiction, painting, film, sculpture, etc.–that blend genres or mediums of expression: the art that falls between definable categories, the art of the borderlands.\nInterstitial fiction would be any fiction that all but defies classification, that mixes things up and produces work that you can’t quite classify. Kelly Link’s fiction, for instance. It bears some relationship to what Bruce Sterling years ago termed “slipstream fiction”–fiction that was borrowing across genres–early Paul Auster, Steve Erickson’s Days Between Stations, works like that. Sterling was looking at a specific one-way flow, but interstitial fiction is flowing in every direction, vertically, laterally, diagonally. Something like China Mieville’s The City & the City is part detective novel, part Bruno Schulz homage, part science fiction thriller. The pieces are integrated perfectly. It’s brilliantly liminal.\nHWA: Can you describe the Clarion experience in a nutshell?\nGF: A six week imprisonment during which time you’ll live at hyperspeed and be stuffed with about two years’ worth of experience, information, and potential development. Some of you will discover that this is not what you want to do. Others will develop the addiction and not be able to stop writing fiction ever after.\nHWA: Clarion is geared toward short stories. Would attending that workshop help someone interested in writing novels? How?\nGF: That would depend entirely on the makeup of the workshop, on who’s teaching, on whether they address and/or allow novel segments into the cycle of work. I think novels are very difficult to teach in a workshop environment anyway, much less one that directs you to produce something like a story a week (or in a few demented cases I’ve seen, twenty-five stories in five weeks). In terms of structuring a novel, I don’t know if Clarion is tremendously helpful. In terms of improving characterization, voice, dialogue, telling details, scooping out unnecessary exposition, understanding story arc in general–all easily relatable to the novel–it can provide tremendous growth.\nHWA: What are the most important reasons for a writer to attend a workshop?\nGF: Well, first, as a reason not to: If you plan to sail into a workshop in order to show off your absolute genius, you’re not going to have a good time. If you’re presenting something that is confounding or eluding you–maybe you’re writing a story or a novel that’s a stretch, that you don’t quite know how to accomplish yet–or else something that you’ve stared at, worked at for so long that you just can’t trust your own judgment any longer, then a workshop can provide critical feedback. But in the end you’re going to have six or twelve opinions on it, and you will still have to make the call as to which opinions help and which will ruin the story–what you will and what you won’t do with it. So don’t depend on the workshop as a crutch.\nI was just at a writing conference and a friend of mine, author Kelly Simmons, who was leading a workshop there, said she thought writers write for one of two reasons. Either for closure (writers who want to finish this work and move to the next project) or for achievement (and such writers look for validation). The workshop is maybe more useful to those looking for achievement. Just be careful not to become a workshop junkie, who just keeps hauling the same damned piece of fiction from one workshop to the next. That’s not achievement, that’s stagnation, and I’ve seen it happen.\nHWA: Why did you join the HWA and what benefits are you looking for from your membership?\nGF: I was a member of HWA years back but as you noted at the beginning of this, I was writing mostly fantasy and sf. I’ve steadily been moving into the realm of thrillers, supernatural fiction, and the darkest fantasy, both in my writing and in my reading habits, and so it seemed to me like it was time to re-up. I blame Rocky entirely for persuading me. I am not a joiner by nature, so I have to be prodded into things from time to time.\nHWA: Tell us about your latest work.\nGF: The latest is a short story, “The Dingus,” in Ellen Datlow’s Supernatural Noir. I also have stories out currently in Ellen’s Poe anthology, and in Darrell Schweitzer’s Full Moon City and Cthulhu Reigns anthologies, and in Clockwork Phoenix 3, edited by Mike Allen. I recently read a strange piece that’s interstitially horror for the NYRSF reading series in New York, and which isn’t finished (or titled) yet, so I’ve no idea where it’s going to end up.\nHWA: Tell us about your upcoming books.\nGF: I’m working on two at the moment. One’s a historical thriller, again set in the 1840s, rather an unusual haunted house tale; the other is a contemporary supernatural mystery that might be the first of a series. Both are in progress, so I don’t want to say too much more. I tend to be superstitious about discussing things in progress too much.\nHWA: Thanks, Greg. And, again, welcome back to the HWA.', 'In the NCTE position paper on Formative Assessment (October 21, 2013) there is a handy list of ten elements that make up formative assessment. Number five on the list reads:\nRequires development of plans for attaining the desired goals.\nHallelujah, we say! So often all we think about is what kids need, or what we need, without quite figuring out how to get there. Its like saying, “I need a million dollars” without having any actual plan to save money, increase your income, or play the lottery. Sad to say making a wish or stating a need alone does not get you the million dollars (but if it does, we will leave our contact information in the comments). Carol Dweck, author of Mindset (2007), and all around intellectual crush of Kristi’s and Marjorie both, speaks to this idea as well. She cites research from Peter Gollwitzer that finds just declaring you will change results in no change at all. Knowing how to get what you need is as critical as knowing what you need. More from Mindset:\nWhat works is making a vivid, concrete plan: “Tomorrow during my break, I’ll get a cup of tea, close the door to my office, and call the graduate school.” Or in another case: “On Wednesday morning, right after I get up and brush my teeth, I’ll sit at my desk and start writing my report.” … Think of something you need to do, something you want to learn, or a problem you have to confront. What is it? Now make a concrete plan. When will you follow through on your plan? Where will you do it? How will you do it? Think about it in vivid detail….These concrete plans – plans you can visualize – about when, where, and how you are going to do something lead to really high levels of follow through, which, of course, ups the chance of success (Dweck, p. 228).\nThis, dear friends, is where charts come in!\nCo-creating a personalized or class chart helps children visualize the attainment of whatever goal they have, which in turn will lead to increased follow through and success. We write down recipes and directions for a reason. It is not enough to know you want to make lasagna, you need the steps to be successful. Once your formative assessments have helped you and your students identify areas of need, charts help everyone get there, they provide the steps. We refer to these particular charts as process charts, and have more about them in our upcoming book, Smarter Charts for Math, Science and Social Studies.\n1. Use your goal (or destination) as your heading. This keeps the focus on the big idea, not the ticky tacky bits that make it up.\n2. Use numbers or arrows when appropriate, these small reminders help children be organized in their thinking and their work.\n3. Co-construct the chart so that the children visualize alongside you, using their language as much as possible to make the chart meaningful and personal.\n4. Use visuals that break down the steps quickly and easily.\nSupporting an Individual Child’s Growth in Reading\nStep 1: The Formative Assessment:\nKristi found that this student had a host of snap words he knew by heart in isolation, but when it came time to reading books, all that knowledge flew out the window. His running records showed many miscues for words that he knew on sight. Usage of these words as he read would help his comprehension and his accuracy. As an English Language Learner, this child was at a disadvantage in relying on his syntax, but sight words could be a strength for him to depend on.\nStep 2: The Plan\nKristi sat with this child to explain the conundrum, ending with the reason why snap words matter to readers. It helps us understand and read the book, saving our brain energy for the tricky words. The child and Kristi co-constructed a plan: first warm up to remember all the words he knows, then take a book walk to see if he could find any of those words in the book he wanted to read, then read the book.\nThe when: Before you read\nThe where: On the snap word list, and in the books\nThe how: Warm-up and then go!\nSupporting Whole Class Growth in Comparing and Contrasting\nStep 1: The Formative Assessment\nMarjorie asked a group of students to compare and contrast two photos of classrooms from long ago and today and found that many children struggled. Some did not know what to write, some just wrote about one photo, some described what they thought was happening.\nStep 2: The Plan\nMarjorie designed lessons around the lenses children could use to look at photos, emphasizing that when you look between two items, you always want to ask yourself: what is the same? what is different?\nThe when: Whenever you have two things in front of you, it is a worthy endeavor to figure out out how they are the same and how they are different.\nThe where: In social studies, science, reading, writing, math – any of these times could work for comparing two things.\nThe how: Go slowly and systematically, when you try to see everything you see nothing. Choose one lens at a time and repeat the plan as needed.\nJust One More Reason To Love Charts!\nCharts are not just descriptive: here is how we did something, they can also be prescriptive: here is how to do something. In a classroom you may have charts that represent both ideas, but the important thing is that you have charts. Charts serve as a way to grow independence, but also as models of ways to achieve success. A thoughtful recording of the where, when, and how is a skill that will help children (and teachers!) for a lifetime.\nShare your thoughts in the comments below! Happy Charting!\nKristi and Marjorie\nWe are so pleased to have the amazing Jennifer Serravallo back as a guest blogger this week sharing her expertise on reading comprehension with all of us. Jen is the author of the Independent Reading Assessment for grades 3, 4, and 5 in Fiction and Nonfiction (Scholastic, 2012, 2013) and of the Heinemann titles Teaching Reading in Small Groups (2010) and Conferring with Readers (2007). She’s a speaker and independent literacy consultant who worked for 8 years at the TCRWP. You can find her at http://www.jenniferserravallo.com or follow her @jserravallo. This week you can find her right here on chartchums! Welcome Jen!\nSo your students are starting to read chapter books!…\n(But although it looks like reading, are they really getting it?)\nIt’s that time of year in many primary classrooms. The time when readers go from reading and re-reading stacks of short books at lower levels…and start reading (drumroll please) **chapter books!**\nKids wear this chapter book reading identity like a badge of honor. Teachers marvel at how many levels the students have progressed. Every line of students’ reading logs are filled with a single series being read at school and at home. And parents, with pride, buy their kid every book in the entire series he or she is obsessed with.\nBUT…. But now our conferences get trickier. We sit down, say “how’s it going?” and find that it’s harder to know – really know – if the student is getting it. In fact, what does getting it even mean now?\nIn this post, I’ll offer you a few tips to make sure that you’re supporting students’ comprehension in chapter books. Having a May and June of engaged readers and a summer of self-directed reading depends on it! (check out my friend Chris Lehman’s May 11 post on summer reading: http://christopherlehman.wordpress.com/)\n1. Make sure you are looking at whole book comprehension\nThose running records you did at pre-chapter book levels meant kids were reading the whole book before retelling and/or answering some comprehension questions. But now that they’re in chapter book-land, they’re likely only reading an excerpt or a constructed passage for a running record. Comprehension questions don’t look at what happens across 60 pages – so now you need a new way to do that.\nConsider planting sticky notes inside of chapter books that ask children to reach back into earlier pages to demonstrate how well a reader is able to accumulate information from across many pages, synthesize that information, and make meaning. You can create a chart to share these questions with students as tools for them to self-monitor their own comprehension, too!\n- What is happening now? What caused this to happen?\n- Why is ______ acting like this?\n- How has the character changed from the beginning of the story until now?\n- What is a lesson you learned after reading the whole book?\n2. Make sure you know your library well enough to pull off your conferences\nIt’s impossible to expect that you’ll know every single book in your entire library. But the good news about early chapter books is that you don’t have to. Try to aim to know popular series and levels.\nIf you’ve read one Magic Tree House, you’ve read them all (sorry, Mary Pope Osborne). Early chapter book series are predictable on purpose: They are meant to support children new to stories of this length with characters they know and plots that feel startlingly similar one to the next. Try to read at least one book from of each of the popular series and you’ll feel like you know a whole section of your library.\nSecond, try to have a two-book-per-level touchstone text. Know two titles from each level and think about what makes that level more challenging than the one before it. I find it helpful to think in terms of four categories:\n- Plot and Setting – what’s new in this level about how many events happen within and across chapters? Is the plot linear? How familiar are the settings and how much support is there to know the settings?\n- Character – how well-developed are the characters at this level as compared to the prior level? What changes do the characters go through? How important are secondary characters?\n- Vocabulary and Figurative Language – how frequently will a reader encounter challenging words or phrases? How much support is there in the text to figure out their meaning?\n- Themes and Ideas – What are the messages and lessons a reader should take away from the text? How clearly does the reader understand these?\n3. Make sure your students have an image of what it means to really understand whole books.\nThe intersection between text complexity (what’s hard about the book) and a reader’s skill lies in what it looks like for the reader to truly understand. I meet fifth graders every week who describe a character in a book at level U as “nice.” To me, that’s level K work in a level U text. And that equates to not really getting the book.\nWe need to hold students to the expectation that they have to demonstrate their comprehension (whether written or oral) that shows they’re making meaning equivalent to the meaning that can be made given the level. For example, you can’t expect a reader to explain character change at level K where characters don’t really change. But if a reader at level N can’t articulate how the character’s changed, then he’s missing out on some meaning.\nConsider describing for students what it looks like to really be “getting it” and then showing an example. You might read aloud a book such as Judy Moody, and co-create rubrics that show varying levels of understanding. Kids can then monitor, and mentor, responses to their own books to those on the charts.\nHere’s one for Plot and Setting:\nOne for Character:\nAn example for Vocabulary and Figurative Language:\nAnd Themes and Ideas:\nHere’s to deeper comprehension, you chapter book readers!\nMarjorie and Kristi']	['<urn:uuid:94a32aba-fd9e-4af4-ac28-2fe360962b19>', '<urn:uuid:7529fe60-5be4-4013-af18-a6a97b4ab9d9>']	open-ended	with-premise	long-search-query	distant-from-document	multi-aspect	expert	2025-05-12T13:53:09.865574	12	119	3621
26	best product protect pontoon metal from water	Shark Hide is the go-to product for protecting pontoons, widely used by pontoon owners worldwide. It seals and protects aluminum pontoons from oxidation, rust, and stains. It also helps slow the accumulation of algae and maintains the shiny look of the pontoon. While Shark Hide is the most popular, there are alternatives like Alumetron, which claims to last up to 10 years, and ceramic coatings, though these are less commonly used on pontoon boats.	['How To Clean and Polish Your Aluminum Pontoon Boat For Max Shine\nIn this article, we will go into detail on how to clean and polish your aluminum pontoon boat for a mirror-like finish that lasts a long time!\nWhen you think about it, it is funny that you have to regularly wash something that spends most of its time in the water. Pontoons must have a weird sense of humor since they tend to get dirty very fast if they are not regularly maintained.\nMy guess is you have probably experienced this first hand since you are reading this article. The aluminum pontoons on pontoon boats can really get dirty after a few trips. Typically this does not affect the boat performance but it does impact the appearance of the boat. This is especially true since pontoons look really clean and shiny when they are new.\nCleaning your pontoon boat can get really expensive if you ask an expert to do it for you. Charges usually range from between $500-$600 depending on boat length.\nThis is a crazy price considering that this is a job that you can do yourself. The products that you need to clean and polish aluminum pontoons are cheap and readily available. In addition, these products are durable meaning that they won’t require quick replacement.\nYou can ensure that your pontoon looks clean and fresh by implementing five simple steps. These steps will require you to put in some considerable effort.\nBecause of this, make sure you dedicate enough time to this exercise. After the last step, your pontoon will be the cleanest pontoon around. It might even be mistaken for a new one once you are done.\nHow To Polish Pontoons In Five Easy Steps\nThis is perhaps the most crucial stage in this process. Skipping this stage will definitely mean that you won’t achieve that clean and shiny look that you desire. Preparation involves removing all the dirt on your pontoon. The most common things that people clean off are algae and scum. The buildup of algae and scum increases if your pontoon remains docked at sea after you use it. The salty sea conditions facilitate the formation and accumulation of algae and scum.\nYou can prevent the buildup of algae and scum by cleaning your pontoon after every trip. A light wash with a pressure washer after a trip will reduce algae build up. You can also choose to trailer your pontoon rather than leave it docked out at sea. This will eliminate the possibility of algae buildup.\nIf there is a lot of algae build up, then your preparation will take a long time. Algae and other sea debris can be notoriously difficult to remove.\nYou might have to go inch by inch with your pressure washer and this will take a lot of time. In addition, you might need to scrub off stubborn algae. If it comes to this, do not use hard material to scrub off the algae. It is very easy for you to damage the pontoon if you use hard material.\nIf the build-up of algae is low or minimal, a simple wash with a pressure washer will do just fine. If you don’t have a pressure washer you can wipe the pontoon with a wet rag. The second option will take longer and it’s a lot more work.\n2. Applying Cleaner\nThis is a crucial step in ensuring the longevity of your clean. If you skip this step there is a high likelihood that all your hard work will be undone once you get back into the water. In fact, it is a guarantee that your work will come to waste if you ignore this step.\n*This is how I have done it. You may choose to use a product like Toon Brite [Amazon Link] or other targeted product. Because I have not tried it I cannot give you a review at this point. The following is how I did it based on the recommendation of other pontoon boat owners:\nFrom my experience and at the recommendation of other pontoon boat owners, you can use a toilet bowl cleaner for this step. It achieves the same results as other cleaning methods. The best thing about using toilet bowl cleaner is that the product is cheap and readily available. I personally use the cheap dollar store brand toilet bowl cleaner.\nOther methods like acid baths require specific products that can prove to be really expensive and hard to find.\nAll you need to do is to mix the toilet bowl cleaner with water. After that, use a sprayer to apply the mixture on your pontoon. After that, let it sit on your pontoon to the point where it is almost dried up. After that, spray the mixture off with clean water.\nIf you let the toilet bowl mixture dry up, you will have to clean it out by going back to the first step. This can be extremely frustrating and time-consuming. To avoid this, spray your pontoon in sections. Spray it on a section, give it a few minutes and then rinse the solution out with clean water. Then proceed to the next section until you have applied the solution to the entire pontoon.\nAfter you rinse, you can choose to wipe the pontoon with a wet cloth, this will ensure that you have completely wiped off all of the solution. I like to spray everything down with a car wash or all purpose cleaner to help neutralize the chemicals in the toilet bowl cleaner. This is not a mandatory step but you can try it if you have time and you want to be thorough.\nThis is actually an extra step in this process designed for people who want to achieve a shiny look on their pontoons. The pontoon will be clean after the second step. This third step will add a shiny factor to the pontoon. You can skip this step and go straight to the last one if you only wanted to clean your pontoon.\nThis step will give your pontoon that shiny new glow. You first need to find proper polisher. There are a number of polisher options that you can choose from. Before you choose one, do a bit of research to see how people rate the polisher. You can find very useful reviews on sites such as Amazon.\nMakita and Dewalt are among the most common polisher brands that most people opt for.\nYou need to be careful with the polisher brand you go for. A poor-quality polisher will mean a poor-quality buff. Some low-quality polishers can even damage your pontoon. A high-quality polisher will do a high-quality job. You can choose a wool pad to go with your high-quality polisher.\n**Circular motions are the way to go when it comes to buffing. You should try to avoid up and down motions since they might leave noticeable lines.\nYou need to set aside about 2-3 hours to do this job properly. It might even take more time depending on the size of the pontoon. The best approach for buffing is not to have a set timeline. Take all the time you need to ensure that you’ve buffed all parts of the aluminum log.\n4. Applying Cleaner\nThat’s right, you need to repeat step two to ensure that your hard work doesn’t go to waste. You need to follow all the steps detailed in step 2.\nThe reason for repeating is that you need to clean out the polishing compound. If you leave it on, it will seal on to the pontoon. Once it seals on, it leaves a really unpleasant site.\nEnsure that you are thorough and that all the compound is cleaned out. Remember to rinse with enough water before the cleaner dries. You should be really careful to ensure that you do not mess up all the good work you have done before.\n5. Applying Shark Hide\nShark Hide is the go-to product for pontooners everywhere. Everyone associated with pontoons knows the value of Shark Hide. It is the product that protects pontoons around the world from the harsh elements of seawater and lake water too. Some pontoon owners begin using Shark Hide on their pontoons even before the pontoons hit the waves.\nBasically, Shark Hide seals and protects the aluminum pontoons. There is no doubt that Shark Hide works. There are lots of reviews on the internet that detail how good Shark Hide is. Every person who uses Shark Hide can approve of its use.\nShark Hide works to protect the aluminum logs from dangers such as oxidation, rust, and stains. It also slows the accumulation of algae but it does not eliminate it completely. In addition, Shark Hide helps you maintain that sharp shiny look on your pontoon.\nUnfortunately, Shark Hide does not come with clear instructions as to how you are supposed to use it. Most people prefer to mix Shark Hide and water in a ratio of 1:3.\nIs There an Alternative To Shark Hide?\nYes, there are other products that work, but Shark Hide is one of the most popular. While Shark Hide is popular, it is not the only option. Some pontoon boat owners and detailers are having some success with alternative products.\nThese alternatives include:\nAlumetron which claims it can last up to 10 years. I have not personally used Alumetron, but it gets fairly good reviews. Only one person said in their review that it did not last and started to come off shortly after use. In a reply from the manufacturer, it was claimed to be an installation problem.\nThis is a newer product and one that I use a lot on fiberglass boats, my daily driver vehicles and also on my vintage collector vehicles. I am a big fan of ceramic coatings and their protection can last years. On my fiberglass boat at the coast, the ceramic coating has lasted almost two seasons and still going strong.\nI mention this here as an alternative, but I have not found much about it being used on Pontoon boats yet. If you try it let me know your thoughts in the comment section below. I have used Marine 31’s Captain Coating and also McKee’s 37 Coating. The McKee’s is easier to apply.\nI think we have covered quite a bit of information in this article about making your pontoon boat look as good as new. It will not be an easy or quick job. If you can, set an entire day to clean your pontoon boat.\nIt might take a lot of time but you will be really impressed with the result. You can even have some friends over to help you with the job. That way you can do the job faster and you can be more thorough with your cleaning.\nIt is essential that you follow all the steps detailed above. If you skip a single step, you will not achieve that clean and shiny look that you are after.\nIn addition, make sure you follow all the instructions. It is the only way that you will ensure that the pontoons remain clean for a long time As previously stated, cleaning you pontoons can be a long and tiring exercise. You need to take good care of your pontoons to reduce the number of times you have to clean it. You can start by washing the pontoon with fresh water after every trip. In addition, you can choose to trailer your pontoon rather than parking it in the water.\nFollow the steps above and you’ll have the freshest, cleanest, and shiniest pontoon on the water.']	['<urn:uuid:43d7eb0c-09a4-40ec-8cb7-70ff82184a3a>']	open-ended	with-premise	short-search-query	distant-from-document	single-doc	novice	2025-05-12T13:53:09.865574	7	74	1946
27	covered storage manure benefits waterways fish	Covered manure storage buildings prevent nutrient runoff from entering waterways during rain events, as shown in the Grimone Farm case. This protection of waterways is crucial for fish habitat, as water quality (including chemical and physical properties) directly affects fish populations and their vital life functions.	"['CONSTRUCTED PROJECTS IN 2020\nBoat Launch - Barclay Complex\nThrough a grant secured from Western Pennsylvania Conservancy, the Cameron County Conservation District recently installed a boat launch on Sinnemahoning Creek at the Barclay Complex in Grove Township. A 150’ x 8’ concrete path was installed just downstream of the Wycoff Road Bridge to help visitors easily and safely access the Sinnemahoning Creek.\nAG - Water Tank Install\nIn December the Cameron County Conservation District assisted Bill and Cathy Lyon with the installation of a water tank on their Bryan Hill Farm. The water tank installation is a phase of a larger US Department of Agriculture, Natural Resource Conservation Service (NRCS) funded project to cost-share the installation of water troughs and fencing on the Lyon Farm pasture so that the Lyons can rotationally graze their cattle herd. Rotational grazing has a number of environmental benefits that occur by allowing pastures to adequately rest between grazing. Soil health improves, carbon is sequestered in the soil to increase its organic content and rainwater infiltration increases while reducing stormwater runoff and soil erosion. Farmers also see economic benefits to rotational grazing through increased forage production in pastures, an increase in drought resilience in pastures, decreased ""weed"" problems and an extended grazing season. Nelson Excavating and Electrical Contracting performed the water tank installation work at the Lyon Farm.\nAG - Manure Storage Building\nIn September the Conservation District built a manure storage building at Junior Grimone\'s farm in North Creek. The project was funded by a Growing Greener Grant received by Headwaters Resource Conservation and Development Council. The new manure storage building allows for the manure from the pigs on the Grimone Farm to be stored under a covered roof out of the rain and the elements. It eliminates nutrient runoff from the former manure storage area that was entering North Creek during heavy rain events. The new manure storage building will also allow the Grimone Farm to store the manure throughout winter so that it can be applied during the growing season in the spring, when the nutrients can be best utilized by the crops. By applying the manure during the spring growing season, it reduces the risk of runoff carrying manure from the fields into nearby waterways, while optimizing the fertility benefit of the manure and reducing the costs for purchasing and applying synthetic fertilizers. The manure storage building was constructed by James Hart Construction of Smethport.\nMay Hollow 49 Retrofit\nThe cleanup of the Sterling Run drainage has been a major goal of the Conservation District for well over 20 years. In the last year or so, our efforts have been strong enough to bring many of the streams we are working on up to Class A status including Finley Run, Portable Run, and Sterling Run. However some work is still needed in areas. In 2020 the District completed the Retrofit of our May Hollow 49 treatment system. Flows had increased coming out of the system ineffective during high flows. A third vertical flow wetland was installed to ramp up the treatment. Now the system is performing flawlessly.\nDriftwood Boat Launch Restoration\nIn 2018 the District installed a canoe launch in the Borough of Driftwood at the confluence of the Driftwood Branch and Bennetts Branch. Upstream on the Driftwood some erosion was occurring. This bank is approximately 300\' long and 8\' high. In 2020 the District installed a 300 foot long random log restoration. Two loads of logs were installed randomly and pinned together and rip rap was placed to stabilize the bank and hold down the logs as well. The randomness of the logs just added a diversity of pocket water against the bank and is great holding water for trout, bass and other inhabitants of the Driftwood.\nThe Morgan Stabilization consisted of a couple smaller sites within a larger property that totaled approximately 400 feet in length. Along this stretch various techniques were used to stabilize the banks and create high quality fish habitat. A log crossvane, two log framed stone deflectors, four single log deflectors and a 100 foot rootwad reclamation were installed.', 'Fish Habitat Restoration\nCARP undertakes a variety of complimentary projects that contribute to the conservation of native fish populations and the restoration of fish habitat. These projects typically include some combination of research, monitoring, restoration, and local ecological knowledge.\nIn order to make informed decisions we need information. In terms of fish and fish habitat conservation there is a wide variety of types of information that may be required, based on a project’s specific objectives. These types of information includes:\nWater quality: the chemical, physical and biological properties of water\nFish community structure: what species of fish are found in a given area\nBarriers to fish migration (e.g. culverts)\nHabitat suitability: how well can a given area support a species vital life life functions\nFish age & growth: this can be determined by examining scale samples\nMonitoring is a critical component in long term projects because it allows us to identify changes over time.\nWithout monitoring we would not be able to tell, with any certainty, whether our actions are having the desired effects. By evaluating the data obtained through monitoring programs we can also identify areas for improvement or other issues that need to be addressed.\nRestoration work involves making physical changes to the landscape, in order to return it to a more natural state, or to bring back natural functions that have been altered by human activities.\nThe installation of culverts or dams is a common action that leads to the alteration of fish habitat. Improper installation can cause a barrier to fish migration, cutting them off from upstream habitat. Clearing blocked culverts and installing fishways are two types of restoration work used to address this issue.\nDe-vegetation of streamside habitat is another common issue on the Annapolis River. Trees and shrubs provide shade, which helps regulate water temperature, which fish such as brook trout are very sensitive to. By re-vegetating rivers and streams we can create suitable fish habitat. Plants will also help in preventing soil erosion, and aid in filtering water.\nLocal Ecological Knowledge\nLocal anglers and other recreational users hold a wealth of knowledge about the rivers and species they fish. Anglers are often the people who interact most with fish and the habitats that support them. We are currently seeking anglers who are interested in sharing their knowledge with us. This knowledge might include where species were caught in the past and at present, where certain species are no longer found, and how river conditions have changed over time.\nCommunity members also have many great ideas about how to approach projects and the areas where work is needed is most. We want to establish a dialogue with community members so that we can exchange information, and work cooperatively to accomplish projects that are of mutual benefit.\nFragmentation of fish habitat is a prolific issue in the Annapolis River watershed and throughout Nova Scotia. Native fish species, such as brook trout and Atlantic salmon, require access to a variety of habitats in order to spawn, forage for food, and find cool water during warm summer months.\nOne of the predominant causes of aquatic habitat fragmentation is from watercourse crossings (such as culverts) that create barriers which restrict movement of fish through a river system, cutting off their access to important habitat.\nOver 70 % of the culverts that Clean Annapolis River Project has assessed since 2007 are barriers to fish passage. In order to address this issue, CARP has begun implementing a variety of restoration actions.\nCommonly Encountered Issues\nAccumulation of debris can block the inflow, outflow or inside of a culvert. Debris removals are conducted to restore water flow and maintain fish passage at such sites.\nLarge outflow drops\nThe outflow drop of a culvert refers to the vertical distance between the bottom of a culvert and the pool directly downstream (called the tailwater). Outflow drops create a barrier to fish movement when the elevation between the water level in a stream and the water level in a culvert is too great for fish to\nHigh water velocity\nWhen culverts are installed on too steep of a slope, the velocity of water passing through the culvert can exceed a fish’s swimming ability. In some cases, channel roughening can be used to slow water velocity\nthrough a culvert, or in more extreme cases, baffles can be installed.\nThanks to our 2018 program funders:\nNative salmonids of Nova Scotia\nBarrier culvert assessment\nBarrier culvert remediation\nSubwatershed management planning\nHabitat restoration and enhancement\nTraining and capacity building for NGOs and community organizations']"	['<urn:uuid:ed057ec1-b304-497e-bb6a-49a15b3799c9>', '<urn:uuid:7a29819a-1edf-46db-a6ca-ddd91ec4c9bd>']	factoid	direct	short-search-query	distant-from-document	multi-aspect	novice	2025-05-12T13:53:09.865574	6	46	1439
28	research lab measuring droplet spray equipment details how works	The spray characterization is accomplished using Phase Doppler Anemometry (PDA). The system involves a main airflow divided into two channels, where part of the flow passes through a siren and is excited at specific frequencies before mixing with the rest of the mass flow, which is bypassed through an air plenum. The combined flow travels through a 1.5 m long resonance tube before reaching an airblast prefilmer nozzle at atmospheric conditions. The airflow velocity and its fluctuations are measured using hot wire Constant Temperature Anemometry (CTA), which can achieve data rates as high as 100 kHz.	['Tel: +49(0)721 608-42571\nFax: +49(0)721 608-47770\nProbieren Sie auf dieser Seite unser Programm für die Berechnung des thermodynamischen Gleichgewichtes einer Gasmischung\nAktuelle Angebote für das Anfertigen von Bachelor- und Masterarbeiten finden sie auf der folgenden Seite.\nAir transportation is expected to grow persistently over the next decades. Clean combustion technology for aircraft engines is a key enabler to reduce the impact of this growth on ecosystems and humans’ health. The vision for European aviation is shaped by the Advisory Council for Aviation Research and Innovation in Europe in the Flight Path 2050 goals, which define stringent regulations on pollutant emissions.\nTo meet these goals, the major engine manufacturers develop lean premixed combustors operated at very high pressure. This development introduces a large risk for reduced reliability and lifetime of engines: pressure oscillations in the combustor called thermoacoustics.\nAviation industry encounters currently the fourth industrial revolution: cyber-physical systems analyze and monitor technical systems and take automated decisions. This industrial revolution is known as “Industry 4.0” in Germany and “Industrial Internet” in the USA. An essential enabler of the fourth industrial revolution is Machine Learning.\nThe ITN MAGISTER will utilize Machine Learning to predict and understand thermoacoustics in aircraft engine combustors, and lead combustion research a revolutionary new approach in this area.\nThe target of this experimental research is to produce a database of droplet characteristics during the prefilming airblast atomization process, under an oscillating flowfield.\nThe main airflow is divided into two different channels. A certain amount of the total air mass flow passes through the siren and is excited at determined frequencies before it is mixed with the rest of the mass flow, which is bypassed through an air plenum. The product airflow of the mixing flows through a 1.5 m long resonance tube before it reaches the airblast prefilmer nozzle at atmospheric conditions.\nThe designed and manufactured airblast atomizer consists of a stainless steel standardized symmetrical airfoil profile (NACA-0010), with a chord length of 73 mm and a trailing edge thickness, i.e. an atomization lip thickness of approximately 200 μm. The cavity on the inside hosts the liquid, which then emerges on the surface of the prefilmer through 40 equidistant drilled holes generating a uniform liquid film. The air is flowing on both sides of the prefilming atomizer while the liquid film covers only one side, replicating in this way the prefilming surface of a conventional airblast atomizer.\nThe airflow velocity and its fluctuation over time due to the siren was measured by means of hot wire Constant Temperature Anemometry (CTA). The data rate of this device can be as high as 100 kHz, which is one of the main reasons that it was preferred for measuring an airflow fluctuating at relatively high frequencies.\nThe characterization of the spray, i.e. the droplet velocity and diameter, was accomplished via Phase Doppler Anemometry (PDA).\nExperimental setup schematic.\nSiren and bypass plenum configuration.\nModel of prefilming airblast atomizer.\nFast Fourier Transform of the air velocity signal for 21 different rotational speeds of the siren.\nPhase averaging of velocity signal at 120.16 Hz.\nSMD fluctuation at 120.16 Hz in comparison with an unforced flow SMD at the average air velocity.\nSize-class separation for the phase averaged mean droplet velocity at 120.16 Hz.\nMean droplet velocity and SMD in different regions of the spray along a period of the fluctuation at 120.16 Hz.']	['<urn:uuid:2d1147c1-57b1-4cf2-8736-0dcd8622e286>']	open-ended	with-premise	long-search-query	distant-from-document	single-doc	novice	2025-05-12T13:53:09.865574	9	96	559
29	What makes induction cooking safer for children?	Induction is child-safe because the magnets need to sense metal to activate, so a child can't accidentally turn it on	"['Induction is still the best form of cooking. It is faster than a professional gas cooktop with a better simmer. It\'s easier to clean and vent, and fairly child safe.\nIn this article, you will learn all about the six best induction cooktops. You’ll see three brands you may know like years past, along with three newer names.\nWhy the change? Like every other appliance, buying an induction cooktop will be a problem due to availability issues.\nIn this list, you will have a few defaults to turn to if your favorite brand is not available. Also, you will learn the basics of induction, from how it works to the benefits.\nThen we will show you the best induction cooktops to consider, including the most reliable based on over 40,000 service calls completed by our service team last year. Lastly, we\'ll cover the answers to our clients\' top five induction questions.\nLet\'s get started.Short on time? Get our free Induction Cooking Buying Guide\nHow Does Induction Cooking Work?\nUnlike the glass on a traditional electric cooktop, the glass on an induction cooktop does not get scolding hot. Instead, a magnet excites the molecules in the pan so that the pan itself becomes the cooking surface, bypassing the glass.\nFor this reason, induction is the most efficient cooking method as there is little loss of heat.\nBenefits of Induction Cooking\nThermador Freedom Induction Cooktop Installed on a Kitchen Island\nInduction is the most child-safe because the magnets need to sense metal to activate. Thus, your child can\'t accidentally turn it on.\nAs previously said, induction is faster than a professional gas cooktop or range. Induction boils faster and can hold a better simmer than an electric or gas cooktop.\nInduction is also the easiest to clean. Food can\'t be baked onto your cooktop since elements don\'t heat the glass.\nIt also does not require a professional ventilation hood like a gas cooktop because there is less heat emission.\nMassachusetts Residents Take Note: Induction complies with Massachusetts Make-Up Air Laws requiring Make-Up air over 400 CFM (Cubic Feet Per Minute), whereas professional gas does not. That is huge, by the way. You can use an existing hood for induction but not a professional gas cooktop.\nBest 36-Inch Induction Cooktops for 2022\nThe best-known premium brands are Miele, Thermador, and Wolf for good reasons. Typically, they offer the best features and are the most serious about premium appliances like induction.\nHowever, you should expect to wait for these brands. Overwhelming demand and kinks in supply chains have hurt even the best prepared.\nMiele KM6375 - $3,899\nMiele has produced induction cooktops for many years. The most popular is Miele\'s flush mount cooktop, the KM6375.\nMiele\'s induction cooktop has a great configuration with five cooking zones, allowing various pan sizes to fit on the cooktop. You have a 4-inch round burner to a 9 x 15-inch rectangular burner.\nIt also has a power boost setting like most other induction cooktops. However, with the Miele, two of these inductors are used simultaneously on the 9"" x 15"" burner providing an incredible 7700 watts of power. It requires a 50-amp connection.\nThis unit will connect to a Miele hood by Bluetooth to turn it on as you begin to cook. It also must be mounted flush with the countertop providing an incredibly modern, sleek look.\nAdditionally, it comes with a one-year warranty. Due to the flush mount requirements, having a warranty is ideal for newer countertops as advanced preparation is required.\nWolf CI365TF/S - $3,410\nOur chef’s favorite induction cooktop based on performance is Wolf. This Wolf cooktop features an 11-inch burner that can use up to 3700 watts of cooking power on the boost setting.\nThe four left burners can be ""bridged"" or connected in four ways to allow larger or odd-shaped pots and pans. No other brand offers a four-element bridge burner.\nYou can simultaneously utilize all four smaller burners, creating a 17"" x 17"" cooking surface. It’s great for using large pots for lobster or large roasting pans for searing.\nWolf’s induction cooktop has a melt setting on one of the burners for simmering or melting chocolate. This setting is like the simmer feature on all their gas ranges.\nYou can buy this cooktop with a full beveled stainless trim to provide extra protection to the glass surface, or it can have a complete flush installation. But you will need a great countertop manufacturer and installer.\nWolf\'s cooktop has a full two-year part and labor warranty (three years with Yale Installation). Also, an important note, this unit will require a 50-amp electrical connection.\nThermador CIT365YB - $3,599\nThermador has an entry-level model, but this high-end Freedom model lets you put a pan anywhere to maximize cooking space. With this flexible setup, you can use multiple 10-inch pans, a large griddle, or a Teppanyaki-style pan up to 16 inches long.\nIt has 17 power modes to help dial in the exact temperature, and in boost mode, it can utilize up to 3600 watts of power.\nThermador’s cooktop has numerous smart features, including a Move mode sensing your pan movement and maintaining the same power setting on the next burner. It also has a heat shift setting like a French top.\nThis cooktop features a two-year warranty and requires a 50-amp connection.\nNewer Induction Brands\nAlthough Wolf, Miele, and Thermador will always be in demand, these newer brands will fill the immediate void. They all have decent features, prices, and great availability. You won’t have to wait eight months for delivery.\nBeko BCTI36510 - $2,319\nBeko is a newer Turkish brand, but they are widely sold and popular in Europe. Their dishwashers and laundry are popular in this country. Then again, Beko, like LG, has managed its supply chain better than most.\nThe unit is simple but good, with the burner in the middle and two flex units on either side. Every burner is 3700 watts.\nFisher & Paykel CI365PTX4 - $3,499\nIn a sea of stainless-steel appliances, Fisher & Paykel stands out with some unique styling (of course, style is only a matter of opinion). Along with style, you have two powerful 5500-watt burners on this cooktop.\nMiele has the most power, but Fisher & Paykel has two of the fastest burners on this list.\nHaving these two 5500-watt burners means that you can operate the two burners at maximum power without sacrificing any heat from the other burners.\nFisher & Paykel offers a free five-year warranty on their appliances. However, five-year warranties can be an issue. Independent service companies do not typically repair appliances under warranty due to low reimbursement rates. So, you may not pay for service, but you may not find it either.\nSignature Kitchen Suite SKSIT3601G - $3,999\nWhat\'s so impressive about SKS (Signature Kitchen Suite) is its parent company LG. From reliability to availability, LG has been the best for the same reason. They produce more of their components, so they don\'t have problematic supply chain issues like other companies.\nBy producing motors and other major parts, LG has become the most reliable brand sold at Yale, with a service rate of only 4.4% within the first year versus 9.5% for the average.\nThe cooktop specifications are pretty good with a 7,000-watt burner and three 3700-watt burners. SKS has Wi-Fi to monitor the burners and sync to an SKS hood through their reliable ThinQ App.\nLastly SKS has a full three-year warranty.\nWhat to Consider When Buying an Induction Cooktop\nFirst off, your pans need to be magnetic (do not worry, most are), and if you plan to buy some new pots and pans, you do not have to spend a fortune buying special pans.\nIf a magnet sticks to the bottom, you are good to go. We recommend any grade 5 or better. Induction cooking surfaces work well with pans with a high ferrous metal content at the base. Cast iron pans and any black metal or iron pans will work on an induction cooking surface.\nInduction Cooktops and Wall Ovens\nIf you plan on putting a wall oven below your induction cooktop, pay special attention to the manufacturer\'s specifications.\nOnly certain brands and models are approved to have an oven placed below in the same cabinet. Most can accommodate, but you always want to be sure.\nFor smart technology, you can sync your Miele or SKS cooktop to your ventilation hood, so it activates as soon as you turn on your cooktop. Smart is just basic for the moment on an induction top.\nAre Induction Cooktops Reliable?\nInduction cooktops require far less service than most appliances with a service rate of 6.1% within the first year of use. Induction cooktop reliability is excellent for all the major brands. The average appliance service rate is 9.5%.\nElectric, in general, has always been good because the burner is protected by glass. However, it\'s not an easy repair when you do need service. Check to make sure you have a capable service department in your area.\nInduction Cooktop Reliability from December 2020 to October 2021\nThese figures are based on a minimum of 20 cooktops sold per brand and over 400 total pieces.\nWolf and Thermador are the best on this list. Induction is 3% more reliable than appliances at 9.5% Then again, induction is under glass, so the chance for breakage is minimal. Most of these cooktops use 40-50 amps, so you want to plan your electrical properly.\nRead More: Most Reliable Induction Cooktops\nWhich Induction Cooktop Should You Buy?\nAll make compelling arguments for being the best cooktop. Of course, the best features now include availability because you can wait up to 15 months for appliances these days.\nThe Resident Chef at Yale loves the Wolf for its fast-heating response. It is the best cooktop for odd-shaped pans because of the four-burner bridge.\nMiele has the most power, while Thermador has the sensor moving the power when you move the pan. It is undoubtedly the most forward technologically.\nDo you take a chance on a newer brand? Fisher & Paykel has decent power and a five-year warranty. Warranties are great, but only if you get the unit repaired.\nSKS is an interesting choice because their parent company is so good. For a price with good features, then Beko should also be considered.\nIn your area, availability will probably cut this list in half. Then you want to choose features and who can fix induction near you.\nFrequently Asked Questions:\n1. Are induction cooktops better than gas or electric?\nInduction cooktops are better than gas or electric for a variety of reasons:\n- It is safer as the glass surface does not get hot (but there may be residual heat from the pan).\n- They require less ventilation due to less heat emission.\n- Cooking times are faster, saving energy and cooking time.\n- Response times are faster for specific recipes, and they will simmer lower.\n- Cleaning is easy because spills don\'t bake on.\n- Without a metal pan, induction can\'t activate. One of the values of this is a child can\'t power your cooktop by accident.\n2. Do induction cooktops use more electricity?\nInduction cooktops will also use less electricity due to their speed but will require higher watts and use 40-50 amps.\n3. How long do induction cooktops last?\nAs with most built-in appliances, the average lifespan of an induction cooktop should be around 10-15 years or more. The glass surface protects the working elements underneath, increasing its lifespan.\n4. What is Power Sharing?\nIn all the cooktops except BSH brands, if you turn on a burner on the highest level, it will ""share"" power with the burner behind it. So, that back burner will only be operating at 30% power, you can still warm food, but you are not cooking with both burners high in the same grid.\nFor an exact explanation, read Wolf\'s guide.\n""For induction cooktops, boost mode boosts power on one element by diverting power from an adjacent element. If the adjacent element is on a high, the power output will be reduced. The power reduction is displayed on the power level indicator of the adjacent element. Illuminates when an element is in boost mode. Boost mode deactivates automatically after approximately 15 minutes of continuous operation and can be reactivated if desired.""\n5. What is Power Boost?\nPowerBoost is for BSH brands such as Bosch, Gaggenau, and Thermador. It uses all the power of the back burner.\nFrom Thermador\'s Use and Care Manual:\n""The PowerBoost function enables you to heat large quantities of water faster than when using [the] heat setting. This function can be activated for a cooking zone, provided the other cooking zone in the same group is not in use.""\n6. Will induction affect your pacemaker?\nAlthough manufacturers claim induction is safe, you should check with the manufacturer of your pacemaker and your healthcare provider before making any purchase.\nRead our Induction Cooking Buying Guide for features, buying tips, and ratings of every available induction cooking product in the market. Well over 1 million people have read a Yale Guide. Induction is our most popular.\nSteve is the third-generation CEO of Yale and a lifelong Bostonian. He currently resides in Boston, one mile from where he was born. Despite being one of the worst goalies of all time, he is a huge hockey fan of college hockey and the Boston Bruins. The love of his life is his daughter Sophie.\nSteve has also been featured in numerous publications such as the New York Times, Consumer Reports, The Boston Globe, Bloomberg Radio, the New York Post, The Wall Street Journal, and Entrepreneur, for his knowledge of how to buy appliances and appliance repair.\nA Note About Pricing']"	['<urn:uuid:fb1d0ce4-7b32-43b5-a45a-7cafbf4df83a>']	factoid	direct	concise-and-natural	similar-to-document	single-doc	expert	2025-05-12T13:53:09.865574	7	20	2297
30	woman with full mutation fragile x versus down genetic transmission odds	If a woman has a full mutation of Fragile X, when passed on to children it will remain a full mutation, with a 50% chance of passing it to each child since only one of her X chromosomes typically has the mutation. For Down syndrome, the transmission risk is primarily related to maternal age, with advanced maternal age increasing the risk, though 80% of children with Down syndrome are born to women under 35 years old.	"['Chromosomes are like libraries for our genes.\nWe have thousands of genes that instruct our bodies on how they should develop, determining things like hair color, eye color, and body parts. These genes are organized into chunks called chromosomes.\nThe X chromosome is one of two sex chromosomes. Sex chromosomes help determine whether someone has the reproductive body parts of a boy or a girl. Typically, girls have two X chromosomes, and boys have an X and a Y chromosome.\nSomeone with XY sex chromosomes is typically a man, and XX a woman!\nChromosomes are passed down from generation to generation. One set comes from the egg, and one set comes from the sperm. Women (who have 2 X chromosomes) always pass down an X to their children. Men (who have an X and a Y) either pass down the X or the Y to their kids. If he passes down the X, the child will be a girl. If he passes down the Y, the child will be a boy.\nIf the dad passes the X chromosome down, the child will be female, and a Y, the child will be male! The sex of a baby is determined by the dad’s chromosomes, since the mom passes an X down.\nThere is one gene that is responsible for Fragile X syndrome, called FMR1. This gene is on the X chromosome. Usually this gene helps to make an important protein that helps with brain development.\nPeople with Fragile X syndrome inherit a version of FMR1 that does not work. People with Fragile X do not make the protein correctly. This lack of protein causes the condition.\nBut why doesn’t the gene work in some people?\nThe FMRI gene has a pattern called CGG repeats. In a typical FMR1 gene, there are less than 45 CGG repeats. When there are over 200 repeats, the FMR1 gene shuts down and does not work. So people with more than 200 CGG repeats have Fragile X syndrome.\nBoys with the full mutation will have Fragile X syndrome. Since they only have one copy of the X chromosome, they only need one full mutation to have Fragile X.\nUsually girls do not have the condition, even with the full mutation. This is because girls have 2 X chromosomes. Even though one of the genes is not working, she still has another on the other X that works and makes the protein. But some girls who have a full mutation may have difficulties learning or socializing.\nRepeats of DNA can expand\nThese repeats are unstable. This means that the number of repeats can change between a parent and a child! Sometimes the number of repeats will expand, and a child will end up with more repeats than their parents. The more repeats a person has, the more likely it is to expand. People with 45-54 CGG repeats have an intermediate form of the gene, but this does not cause Fragile X syndrome.\nWhen there are 55-200 CGG repeats, someone has a “premutation” which means that their FMR1 is not stable. This could expand to more repeats and could cause Fragile X syndrome in their children or grandchildren.\nThe chance of the premutation expanding to the size of a full mutation is related to how big the premutation is. The larger the CGG repeat number, the higher the chance it will expand to a full mutation.\nThe premutation is more likely to expand when it is passed on by a woman. A woman with a premutation often passes down a larger amount of repeats on to her children. But since typically only one of her X chromosomes has the premutation, she only has a 50% chance of passing it on to her kids.\nWhen a father passes down a premutation to a daughter, it does not usually expand to a full mutation and cause Fragile X syndrome. A father cannot pass down the premutation to his sons, since he only passes his Y chromosome to them (remember, the Fragile X gene is on the X chromosome!).\nIf a woman has a premutation and it is passed on to her kids, it can remain a premutation or it can expand to a full mutation. If she has a full mutation and it is passed on, it will remain a full mutation. The chances that it will expand all depend on how many CGG repeats the person has.\nBut why do the repeats expand?\nNow this is where it gets REALLY complicated. When there are an unstable amounts of repeats, the DNA has trouble copying when it makes new cells. When there are lots of repeats, the DNA may make loops which expand the new DNA. If you want to read more, the term to look up would be “replication slippage” or “trinucleotide repeat expansion”.', 'Home > Preview\nThe flashcards below were created by user\non FreezingBlue Flashcards.\nWhat is Down syndrome?\nA genitic condition that causes delays in physical and intellectual development\nincidence of down syndrome?\none in every 700 live births, most frequently occuring chromosomal disorder. NOT related to race, religion or socioeconomic status.\nCause of Down Syndrome?\nan error in cell division called nondisjunction. occurs at conception and is not related to anything the mother did during pregnancy.\nWhat increases the incidence of Down Syndrome?\nadvanced maternal age but 80% of children born to women under 35 yrs old.\nWhat is different about the chromosomes of individuals with Down Syndrome?\nThey have 47 chromosomes instead of 46.\n3 chromosomal patterns that result in Down Syndrome and which is the most common?\n- trisomy 21 (nondisjunction) - MOST common (95%)\n- translocation (3-4%)\n- mosaicism (1-2%)\nWhat is trisomy 21 caused by?\na faulty cell division that resluts in the baby having three #21 chromosomes instead of two. Prior or at conception, a pair of #21 chromosomes in either the egg or the sperm fails to separate properly. The extra chromosome is replicated in every cell of the body.\nWhat is translocation caused by?\npart of chromosome #21 breaks off during cell division and attaches to another choromosome. The presence of an exra piece of the 21st chromosome causes the characteristics of down syndrome. May indicate that one of the parents is carrying chromosomal material that is arranged in an unusual manner.\nWhat is mosaicism cause by?\nOccurs when nondisjunction of chromosome #21 takes place in one of the initial cell divisions after fertilization. when this happens, there is a mixture of two types of cells, some containing 46 chromosomes and some with 47. because of the mosaic pattern of the cells, the term mosaicism is used.\nWhen is Down Syndrome diagnosed?\n- before or at birth. Before birth, ultrasound 10-14 weeks gestation - thick neck (nuchal translucency)\n- initially the diagnosis is based on physical characteristics.\n- The diagnosis must be confirmed by a chromosome study (karyotype)\nCommon physical features of Down Syndrome?\n- Flattened nasal bridge\n- almond shaped eyes\n- flat occiput\n- short limbs, short broad hands and feet\n- high arched palate - protruding tongue\n- muscle hypotonia\n- jt hyperextensibility\n- simian line (transverse palmer crease)\nCommon medical manifestations of Down Syndrome?\n- hypothyroidism (8%) require medication\n- heart disease: (50%) defects may require medication or surgery\n- increased incidence of childhood leukemia (1%) and incidence of colds and infections.\nSecondary medical manifestations (after age 30-35) of Down Syndrome?\nobesity, diabetes, CVD, osteoarthritis, orstoporosis.\nby age 40 almost everyone with Down Syndrome will have symptoms of alzheimers.\nCommon orthopedic impairments of peopl with Down Syndrome?\nexcessive foot pronation, scoliosis, slipped capital femoral epiphyses (hip abduction with hypotonia), late hip dislocation (after age 2), patellofemoral disroders (patellar dislocation), atlantoaxial (C1-C2) instability.\nvision impairments of patients with Down Syndrome?\n35-60% have affected vision. Near or far sighted, esotropia (cross eyed) and/or cataracts. May require surgery or glasses.\nHearing impairments of patients with Down Syndrome?\n66-89% have hearing impairments. Ear (internal and external) deformities may lead to hearing loss. Regular hearing exams recommended.\nCognitive, communication, and learning impairments of people with Down Syndrome?\n""intellectually imapired"" can be mild to severe. Learning disabilities may be present requiring special education. Receptive and expressive language may be delayed requiring speech therapy, augmentative communication, and/or sign language.\nGross motor and mobility skills of people with Down Syndrome?\ndelayed due to low muscle tone, loose ligaments, and decrease strength. Walking usually occurs around age 2. Gross motor development continues throughout the lifespan, yet it remains delayed. Increased incidence of overweight with age may affect fitness level.\nGross motor clinical obsercations of patients with Down Syndrome?\nPoor upper extremity midline movements, slow reaction time, and slower postural reaction times.\nGait of people with Down Syndrome?\nShort steps, wide base of support, increased knee flexion in swing, increased knee flexion in swing and hyperextension in stance, Decreased single limb support.\nPrognosis and outcomes of patients with Down Syndrome?\nLife expectancy is approximately 55 years. Education and work training available, allowing great opportunity for productivity: many go on to college, have jobs, and live independently.\nWhat is atlantoaxial (C1-C2) instability?\n- Subluxation between C1 and C2. Most cases are asymptomatic. Cervical subluxation greater than 4.5 mm is an indicator for intervention (surgical).\n- Secondary to ligamentous laxity or poor development of the odontoid or abnormal syringomyelia.\nUpper cervical spine instability signs and symptoms?\nhyperreflexia, clonus, positive babinski\'s sign, loss of strength, changes in senstion, torticollis, loss of established bowel and bladder control, derease or loss of established motor skills.\nComplications of arthrodesis?\nbone graft reabsorption, wound dehiscence and infection, instability of adjacent motion segment, incomplete reduction of C1-C2, neurologic sequelae.\nWhat is the AA debate about?\nage for x-rays to identify AAI, reliability of x-ray results to identify AAI, surgical intervention.\nWhat do people need in order to participate in special olympics?\nThey need to be medically cleared for AAI. Need to communicate with local orthopedic surgeon.\nWhat activities should people with Down Syndrome avoid?\nDirect downward forces such as tumbling, diving, horse back riding, carnival rides, driving on poorly maintained road.\nWhat is PT treatment focused around?\nThere is no cure, treatment is focused on specific impairments. PT cannot change muscle tone.']"	['<urn:uuid:82f15b77-2899-435f-b731-4c246e11184b>', '<urn:uuid:1b4601bd-27ac-4646-820a-4337667a5bdb>']	factoid	with-premise	short-search-query	distant-from-document	comparison	expert	2025-05-12T13:53:09.865574	11	76	1700
31	As a nutritionist specializing in heart health, I'm curious about the relationship between eggs and cardiovascular health, as well as practical alternatives for my patients who need to avoid them. Could you explain both the latest research on eggs' impact on heart disease and the best substitutes for eggs in recipes?	Research shows that eggs don't significantly impact blood cholesterol levels as previously believed. A meta-analysis from 2016 found no clear link between egg consumption and heart disease risk, and may even decrease stroke risk by 12%. The real culprit for heart disease appears to be sugar and refined carbohydrates - studies show people with highest sugar intake nearly tripled their heart attack risk. As for egg substitutes, it depends on the egg's function in the recipe. For moisture, you can use 1/4 cup mashed banana or 3 tablespoons applesauce. For binding, try 1 tablespoon ground flax seed mixed with 3 tablespoons hot water. For leavening, options include using 2 tablespoons plus 2 teaspoons canned coconut milk with 1 teaspoon baking powder, or the classic combination of 1 tablespoon cider vinegar and 1 teaspoon baking soda.	['Going egg-free? How to Substitute Eggs in Recipes\nThere are a lot of reasons you may need to replace egg in your recipes. You or your child may have an egg allergy or sensitivity, maybe you’re baking for a friend who is vegan, or you want to mix up your menu a bit. Or maybe it is a day you simply ran out. Avoiding eggs doesn’t mean sacrificing your favorite foods or good flavor.\nThe most important thing to remember when replacing eggs is to think about what the egg is being used for in the recipe. Eggs supply moisture, act as a binder or are used to provide leavening so the recipe is fluffier. Do you need to replace a whole egg, or just a yolk or the egg white? This will help you decide what egg replacer to use. Some recipes that only require 1 to 2 eggs and make a flat product (such as pancakes) may not need a replacement at all, just 1 to 2 extra tablespoons of liquid to make up for the missing liquid from the egg.\nThe egg replacer I most often use in my baking is 1 tablespoon ground flax seed mixed with 3 tablespoons hot water. Set this aside for a couple of minutes until the flax seed mixture thickens. This mixture should be as thick and sticky as an egg white. If it isn’t, heat the mixture until it thickens. Allow to cool slightly before adding to your recipe. This mixture equals one egg. Flax mixture only replaces the binding property of an egg. If you are using it in a cookie, cake or quick bread recipe also add 1/4 teaspoon extra baking powder to provide the leavening needed.\nThere are many other things besides flax to replace eggs. I have them grouped by use. Some egg replacements, due to their flavor, may alter the taste or texture of your recipe, so use an egg replacer that will compliment the other ingredients. Have fun experimenting and find one that works for your family. Each substitution below equals one egg.\nWhen eggs are used as moisture it is the easiest substitution and used most often in baked goods such as cookies, muffins and quick breads.\n- 1/4 cup mashed banana, pumpkin puree or sweet potato\n- 3 tablespoons applesauce, pear sauce, apple butter, apricot puree or pureed prunes. Add one more tablespoon liquid to the recipe.\nIf eggs are used as a binder:\n- use the flax seed mix above. If you want to make a larger batch ahead of time, mix 1/4 cup ground flax seed with 3/4 cup water. Cook until thickened. Allow to cool. Store in the refrigerator in a covered container for up to 2 weeks. Use 3 1/2 Tablespoons flax mix for each egg.\n- Chia seed can be used the same as flax seed. If you can find chia seed online and at health food stores.\n- 1 1/2 tablespoons oil, 1 1/2 tablespoons water, and 1 teaspoon baking powder\n- Gelatin (unless you are vegetarian- gelatin is NOT a vegetarian product). Sprinkle the contents of a packet of unflavored gelatin over 1 cup of cold water. When the gelatin absorbs water, heat over medium heat until the gelatin completely dissolves. Allow mixture to cool. Use 3 tablespoons to replace one egg.\nReplacing eggs used as leavening. Eggs give texture providing lift. Egg-free baking has a tendency to be a bit heavier without the egg white, but there are several things you can do to lighten the texture of your baked good.\n- add 2 tablespoons plus 2 teaspoons canned coconut milk (NOT light) and 1 teaspoon baking powder to your recipe\n- use Ener-G egg replacer powder 1 packed tablespoon of powder mixed with 2 tablespoon warm water, whisking until frothy.\n- replace part or all of the liquid with carbonated water. Do not over mix after adding in order to retain the carbonation’s effect.\n- And don’t forget the old WWII trick of subbing 1 tablespoon cider vinegar and 1 teaspoon baking soda for eggs in cakes, cupcakes and quick breads.\nHopefully these egg replacers will help out the next time you need to replace an egg. Enjoy!', 'Ever wonder, “Are eggs healthy?”. You probably have. Especially, after seeing a recent headlines like this one from CNN: “Three or more eggs a week increase your risk of heart disease and early death, study says”.\nWhat CNN got wrong about eggs and heart disease\nA headline like that – “Three or more eggs a week increase your risk of heart disease and early death, study says“ – is enough to get people to shun eggs…without even reading the whole article!\nThe headline, although clickable, is misleading. The type of study mentioned in the article is unable to show cause and effect (which the headline suggests). It can only show an association. Plus, a solid body of research has debunked the “does dietary cholesterol raise blood cholesterol? question.\nDo eggs raise your cholesterol?\nYes, eggs contain dietary cholesterol. But no, they won’t significantly impact your blood cholesterol as is commonly believed.\nIt’s sort of like saying eating fat will make you fat. Which we also know, is not the case. (See: keto)\nWhat will significantly impact your cholesterol – and make you fat for that matter – is sugar and refined carbohydrates like bread, cereal, and pasta.\nThe egg study mentioned in the CNN article\nThe study that served as the basis of the CNN headline was recently published in JAMA. Researchers pooled results of 6 previous observational cohort studies involving a total of 29 thousand people. Participants recalled from memory what they ate over a period of 17.5 years on average. Any cardiac events, such as stroke or heart attack were also recorded.\nBased on their observations, the researchers stated: “Among US adults, higher consumption of dietary cholesterol or eggs was significantly associated with higher risk of incident CVD and all-cause mortality in a dose-response manner.”\nSpecifically, they found that consuming an additional 300 milligrams of dietary cholesterol per day was associated with a 3.2% higher risk of heart disease and a 4.4% higher risk of early death. Each additional half an egg consumed per day was associated with a 1.1% higher risk of cardiovascular disease and 1.9% higher risk of early death due to any cause.\nWhich, at best, is modest to begin with. But, seeing as heart disease is the number one cause of death not just in the US but globally, it’s important to explore further.\nRegardless, do you see, though, how the consumer media changed what the researchers said? The researchers said that egg consumption was “associated with” increased risk of heart disease. The media reported that egg consumption “causes” increased risk of heart disease.\nCohort studies can only offer clues about the causes of disease, rather than definitive proof of links between risk factors and health – which the headline would lead you to believe.\nWhat were those people eating with their eggs? Sauteed spinach and avocado? Or, white bread and butter?\nWhat were they eating the rest of the day? A Standard American Diet? Or, a Pegan Diet?\nDietary cholesterol VS. blood cholesterol\nHigh blood cholesterol levels are a known risk factor for heart disease.\nFor decades, nutrition guidelines have stated that dietary cholesterol in foods raises blood cholesterol and therefore increases the risk of heart disease.\nHowever, current research debunks this outdated hypothesis…and current USDA nutrition guidelines have been revised to reflect this new understanding of the association between dietary cholesterol and blood cholesterol.\nWhat is Cholesterol?\nCholesterol is a waxy substance that occurs naturally in the body. Perhaps surprisingly, it isn’t something “bad” that we want to eliminate completely.\nIn fact, your body needs cholesterol to make hormones and Vitamin D, and perform various other important functions. Cholesterol contributes to the membrane structure of every cell in your body.\nSo where do you get cholesterol? Your body makes it!\nYes, your body makes all the cholesterol it needs, but it also absorbs a relatively small amount from certain food such as eggs, meat, and full-fat dairy products.\nThe body tightly regulates the amount of cholesterol in the blood: when you increase the amount of cholesterol you eat your body makes less. When you eat less cholesterol, your body makes more. (1, 2)\nResearch debunking eggs as cause of increased cholesterol\nIn 1999, a study published in JAMA by Harvard researchers that tracked more than 37,000 adult men and 80,000 adult women for a period of 14 years, found that eating an egg a day was unlikely to have an impact on heart disease or stroke for non-diabetics.\nMany subsequent studies have reached similar conclusions. A meta-analysis published in 2016 found that there was no clear link between egg consumption and the risk of heart disease. In fact, they concluded that eating up to an egg a day may decrease the risk of stroke by about 12%. (7).\nThe connection between sugar & heart disease\nIf eggs and cholesterol don’t increase the risk of heart disease, what does?\nA rigorously done study published in JAMA in 2014 shows that those with the highest sugar intake nearly tripled their risk of heart attacks compared to those with the lowest intakes. TRIPLED! That’s nearly 300% not the 3.2% percent risk cited in the study in the CNN article on the association between eggs and heart disease.\nIn 2000, a study published by Harvard researchers found that women who consumed diets with a high glycemic load (generally made up heavily of refined carbohydrates and sugar which spike blood sugar) had an increased coronary heart disease risk. Those who consumed diets with the highest glycemic load increased their risk more than 200% during 10 years of follow-up.\nIn fact, starting in the 1960s the sugar industry paid scientists to play down the link between sugar and heart disease and instead shift the blame to saturated fat, as this landmark expose in The New York Times discovered, and I wrote about in The Real Food Grocery Guide.\nEggs don’t cause heart attacks. Sugar does.\nAre eggs a healthy part of the diet?\nYes, eggs are a healthy part of the diet for many people, and serve as a good source of protein and nutrients.\nThey are a common allergen , though, so they’re not for everyone. People who want to avoid eggs include those with auto-immune disease, leaky gut, or an allergy to them.\nWhat is the healthiest way to cook and eat eggs?\n- The healthiest way to cook and eat eggs is to eat the whole egg, yolk and all. That is where the bulk of the nutrition is.\n- Cook them in olive oil or another healthy fat, such as unrefined coconut oil or avocado oil.\n- Always choose organic and pasture-raised or free-range eggs to ensure you’re getting the most nutritious eggs. You can probably find them at a local farmer’s market, or of course, any health food store, and even many mainstream grocers. If you’re confused about the dozens of labels on eggs (vegetarian, omega-3 enriched, etc.) learn more in The Real Food Grocery Guide.\n- Serve with a generous portion of veggies and plant-based fats (such as avocado) instead of sides, like bacon, sausage, white toast, and butter.\n- Try this Superfood Scramble recipe. Essentially, you scramble 2 eggs with a copious amount of veggies, along with a blend of flavorful spices and herbs for a delicious, complete one-pan meal.\nWhat nutrients do eggs contain?\nEggs are a good source of choline, B vitamins, including B12, and Vitamin D but the nutrients are primarily found in the yolk, not the white.\n- Vitamin D is critical for bone health and immune function.\n- Choline is essential for normal functioning of all cells, but is particularly important during pregnancy to support healthy brain development of the fetus.\n- B-Vitamins impact your energy levels, brain function, and cell metabolism. They support cell health and the immune system.\n- Lutein and zeaxanthin are two antioxidants that are believed to reduce the risk of developing cataracts and slow the progression of age-related macular degeneration.\nEggs contain about 6g of protein each.']	['<urn:uuid:1de20d00-8cd8-4c43-be26-eafd83fc714e>', '<urn:uuid:5956cf0c-a39c-4d7d-987f-f71897705dbc>']	open-ended	with-premise	verbose-and-natural	distant-from-document	multi-aspect	expert	2025-05-12T13:53:09.865574	51	135	2041
32	what do thorny devils eat	Thorny Devils mostly consume ants and termites in their diet. Occasionally when ants are scarce, they can also eat some other small insects.	['The Thorny Devil is a species of lizards found in Australia. It is known for its unique spiny appearance and chameleon-like color changing abilities. It is the only species belonging to the genus Moloch and is known by various names such as the Mountain Devil, Thorny Lizard, Thorny Dragon as well as Moloch.\nThorny Devil Scientific Name\nThe scientific name for Thorny devil is “Moloch horridus”.\nThorny Devil Description\nThe Thorny Devils have got the most unique appearance among all lizard species. Here is a brief description of these creatures.\nLength: Thorny Devils grow up to almost 20 centimeters in length.\nWeight: These lizards weigh around 70 to 95 grams.\nSpines: Their bodies are entirely covered with mostly uncalcified conical spines which even extend up to their tails. They have spiny horn-like structures above their eyes and a spiny bump behind their head that acts like a false-head.\nColor: The bodies of Thorny Devils are covered with camouflaging shades of reddish-brown, orange, white, yellowish tan and black. These colors vary with temperature and surroundings, changing from paler shades in warm weather to darker shades during cold weather.\nSexual Dimorphism: The females are larger in size than the males.\nThorny Devil Distribution\nThorny Devils mostly reside in Central and Western Australia.\nPicture 1 – Thorny Devil\nThorny Devil Habitat\nTheir preferred habitats include shallow burrows in deserts and arid scrubs.\nThorny Devil Behavior\nHere are some common behavioral traits of these species.\n- In spite of having a fearful appearance, these lizards are one of the most harmless creatures on earth, preferring to evade predation through camouflage and illusions.\n- While walking, they raise their tail and move slowly with jerky motions. They often tend to freeze themselves in mid stride.\n- They prefer to eat their meals slowly, consuming only one ant at a time.\n- During nights, these lizards dig into the soil and bury themselves to keep themselves warm. In times of extreme heat, they create shallow underground burrows to protect themselves from blazing temperatures.\n- They often hide themselves behind small shrubs to escape anything that they consider disturbing.\n- Thorny Devils lead mostly a solitary life except when they choose to mate.\nThorny Devil Diet\nThorny Devils mostly consume ants and termites in their diet. Occasionally when ants are scarce, they can also eat some other small insects.\nThorny Devil Predators\nThorny Devil is a prey animal. Its list of predators includes foxes, goannas, bobcats, coyotes, bustards, brown falcons and snakes.\nThorny Devil Adaptations\nThese lizards have developed some unique features to adapt themselves well to their environments as well as to save themselves from their predators.\n- Their bodies are covered with spines which make it difficult for their predators to swallow them.\n- They can change their body color and camouflage themselves by blending with their environment.\n- They have a unique way of collecting drinking water which helps them to survive on dry lands. Narrow channels between scaly spines draw droplets of rain or dew and transport it to their mouths through capillary action.\n- When predators are near, they hide their real head between their front legs and project their spiny false head towards them.\n- They can also inflate themselves and look bigger than their actual size. This they do to scare off predators.\nPicture 2 – Thorny Devil Image\nThorny Devil Mating Season\nTheir mating season lasts from September to December.\nThorny Devil Reproduction\nThorny Devils start mating at an age of 3 years. The males attract females with elaborate courtship rituals which include head-bobbing and leg-waving. The females lay a clutch of 3 to 10 eggs around the months of September to December in an underground nesting burrow.\nThe burrows are dug by the females around 30 centimeters below the ground. The females lose nearly 40% of their body weight while laying the eggs. The eggs are incubated for about 3 to 4 months, after which the hatchlings are born.\nThorny Devil Life Cycle\nAfter coming out of the eggs, the young Devils dig their own way up to the surface. The newly born lizards are also equipped with spines just like their parents. Both the male and female lizards grow at same rates during the first year, after which the females start growing at a significantly greater pace. The growth rate varies from season to season and is slower during the winter. It takes at least 5 to 6 years for young Thorny Devils to reach full maturity.\nThorny Devil Life Span\nThorny Devils live up to 15 to 20 years.\nThorny Devil As Pets\nHousing: These creatures should be housed in an aquarium big enough for them to move around freely. Artificial sand dunes should be made inside along with some thorny bushes to provide them with a natural environment feel. Temperature should be maintained a dry one like their natural habitat.\nFeed: They can be fed some commonly found small insects and ants.\nCare: They do not need much caring. Human handling should be checked as they are not accustomed naturally to be handled. While handling them their spines can even prick the human hands.\nThorny Devil Conservation Status\nThorny Devil is not yet classified by the IUCN. However, their numbers are gradually decreasing in present times.\nThorny Devil Interesting Facts\nHere are some interesting facts about these lizards.\n- These lizards can consume more than a thousand ants at a time.\n- Thorny Devils eat almost 45 ants in a minute.\n- They can run at a maximum speed of 60 kilometers per hour.\n- Although Thorny Devils look fierce, they are not aggressive and would rather make use of their unusual adaptations to defend themselves.\nThorny Devil Pictures\nHere are some images showing these wonderful and interesting lizards.\nPicture 4 – Thorny Devil Picture']	['<urn:uuid:76beea31-9a34-4939-9a0f-bae8f3e62c65>']	factoid	direct	short-search-query	similar-to-document	single-doc	novice	2025-05-12T13:53:09.865574	5	23	970
33	polar a370 gps tracking how works	The Polar A370 uses assisted GPS functionality by connecting to your smartphone's GPS capabilities. This allows the device to track your speed, distance, and route during your training sessions.	"[""The Polar A370 is an updated version to the Polar A360. The A370 is an intelligent, powerful wrist-based fitness tracker with continuous heart rate readings without wearing a chest strap. You can even use the A370 as a heart rate sensor by pairing it to your favorite fitness app. The A370 utilizes your smartphone's GPS capabilities to provide you with critical data while you train. The sleep plus feature not only records your sleeping patterns but also detects when your sleep has been interrupted in order to provide you with more useful feedback.\nStrapless Heart Rate: Have the A370 intelligently track your heart rate through the twists and turns of everyday life.\nAssisted GPS: Use your phone’s GPS to track speed, distance, and route.\nImproved Sleep Analysis: Get the valued insight you need to get a good nights rest.\nBroadcast Heart Rate: The A370 can be used as an HR sensor. Pair it to your favorite fitness app.\n3rd Party Compatibility: Exercise and activity data is automatically sent and is available to be used in services where you allow it. Connect your Flow account for example to Apple Health Kit, Google Fit, and MyFitnessPal.\nMobile Connectivity: Seamless communication via Bluetooth Smart to Polar Flow app on mobile devices.\nSmart Notifications: Get an alert whenever you receive a call or a text.\nFeaturing Polar Smart Coaching\nPolar’s unique Smart Coaching feature offers the best possible guidance on how to develop your training as well as helpful feedback on your progress.\nSleep Plus: The A370 tracks not only the timing, amount, and quality of your sleep but also automatically detects when your sleep is interrupted.\nActivity Benefit: When it comes to an active lifestyle, even the small things make a difference. Learn how your everyday choices benefit your health and well-being.\nRunning Program: Whether training to set a personal best in a 5k or running your first marathon, set a race target and let our online program guide you towards your goal.\nTraining Benefit: Need some motivating feedback after your work out? Polar’s Training Benefit immediately explains what type of physiological benefit you gained from your training.\n24/7 Activity Tracking:\nTracks your daily activity at five intensity levels for 24 hours a day, seven days a week, and provides a complete picture of all of your activity. It counts your active time, daily burnt calories, steps, distance from steps and sleep.\nIt’s based on the analyses of the frequency, intensity and regularity of your movements together with your physical information.\nIntensity levels are:\n- Resting (sleep and rest, lying down)\n- Sitting (sitting or other passive behavior)\n- Low (standing work, light household chores)\n- Medium (walking and other moderate activities)\n- High (jogging, running and other intense activities)\nYou can also see how different activity intensities accumulate daily activity: the higher the intensity, the faster you’ll reach your activity goal. Find more examples for low, medium and high intensity activities in Polar Flow app and web service.\nTracking your activity is more than just counting steps. Polar A370’s wrist-based heart rate monitor intelligently tracks your heart rate 24/7, giving you a more accurate look at your daily activity and calories burned. Easily see how your heart rate responds to the peaks and valleys of your day.\n- Tracking your activity is more than just counting steps. Polar A370’s wrist-based heart rate monitor intelligently tracks your heart rate 24/7, giving you a more accurate look at your daily activity and calories burned. Easily see how your heart rate responds to the peaks and valleys of your day.\nProvide an easy way to adjust and monitor the intensity of your training. By using hear rate zones you can also follow heart rate-based training programs. The default zones are based on your HRmax.\nDifferent training intensities have different training benefits, for instance light intensity enhances basic aerobic endurance and hard intensity improves your body’s ability to sustain high intensity exercise and your maximal oxygen uptake.\nThe default heart rate zones are divided into five intensity zones based on the percentage of your maximum heart rate:\n- Very light (50–60% HRmax)\n- Light (60–70% HRmax)\n- Moderate (70–80% HRmax)\n- Hard (80–90% HRmax)\n- Maximum (90–100% HRmax)\nYou can define the zone limits yourself as you want. More detailed information about this can be found in the Polar Flow web service.\nProposition 65 Warning for California Consumers WARNING:\nContains lead and nickel - Cancer and Reproductive Harm - www.P65Warnings.ca.gov""]"	['<urn:uuid:22eb2fb8-c181-45b0-b6b2-e19d1badc24f>']	open-ended	with-premise	short-search-query	similar-to-document	single-doc	novice	2025-05-12T13:53:09.865574	6	29	744
34	why soil near volcanoes good farming	Soil tends to be quite fertile near plate boundaries because of volcanic activity. When volcanoes erupt, they release minerals into the environment and deposit volcanic soil. When lava cools and hardens, its weathering produces highly fertile soil. This is exemplified in southern Italy, where farmers grow crops on the fertile soil produced from Mount Vesuvius eruptions.	['Activity still exist and can be triggered when\nActivity Sheet1.You are in charge of locating a nuclear power plant in a geologically sound area that is free of volcanoes and strong earthquakes. Using the maps from the lecture part of this activity and perhaps other sources at your disposal, pick one of the locations below for your nuclear power plant site. Explain your reasons for thinking that the location you chose is a geologically safe area in terms of plate tectonics.a.St. Louis, Missourib.Tallahassee, Floridac.Anchorage, Alaskad.Seattle, WashingtonThe location that I would place a nuclear reactor in Tallahassee Florida. When looking at the tectonic plates, Tallahassee is located near the middle of the North American Plate which puts it far away from any fault lines that could affect it. Not being near any faults allows it not to have the risk of being affected by earthquakes or volcano eruptions. Also, according to, the U.S. Geological Survey, when looking at a map of seismic activity in the U.S., Tallahassee has one of the lowest hazard rates of seismic activity in the entire country.2. Based on what you know about the relationship between earthquakes and plate boundaries, how does the history of large earthquakes in South Carolina fit with the plate boundary-earthquake relationship? Don’t forget to use the maps linked in the reading part of this activity to help you.The history of large earthquakes in South Carolina fits in with the plate boundary- earthquake theory because tectonic plates have collided and moved around the earth for billions of years, and they have slowly broken up and recreated. A plate that was once a fault line or a mountain range may now just be hills. However, underneath the surface, the remains of the faults still exist and can be triggered when an earthquake occurs. These type of earthquakes are called intraplate earthquakes since they occur in the center of tectonic plates.3.Of the following 6 locations, which 3 locations are possibly excellent locations for geothermal power plants? Explain why you chose them.A. Buenos Aires, ArgentinaB. Hokkaido, JapanC. IcelandD. New YorkE. East AfricaF. Moscow, RussiaThe following six areas that are possibly excellent locations for geothermal power plants are Iceland; Hokkaido, Japan; and East Africa. These three locations are the best for geothermal power plants because all three are located on or near fault lines. These fault lines contain many volcanoes and can release geothermal energy. Iceland is already a well-known country for producing most of its countries power with geothermal energy, and Japan is located right next to the “ring of fire.” East Africa is located on the East African Rift System which has a high potential for geothermal energy.4. The Andes Mountains of South America were formed as part of the process of oceanic crust sliding underneath continental crust. The volcanic islands that compose Japan were produced by oceanic crust of one tectonic plate sliding underneath the oceanic crust of another tectonic plate. The Himalayans of southern Asia are the highest mountains in the world and are still growing. Answer the following questions: (The Shockwave activity found at http://www.pbs.org/wgbh/aso/tryit/tectonics/# can be helpful in determining your answers.)a. What is happening to cause the tremendous Himalayan orogeny (i.e. mountain building)?The tremendous Himalayan orogeny is occurring as a result of the collision between the Eurasian Plate and the Indian Plate. Around 225 million years ago, the Indian Plate started to move North and 40 to 50 million years ago it collided with the Eurasian Plate which has lead to the mountain building process that occurs to this day. Today, the Himalayas continue to grow by more than one centimeter a year.b. What tectonic plates are involved, and what is the nature of the plate boundary between these plates?The tectonic plates that are involved are the Eurasian Plate and the Indian Plate. The plate boundary between the two is a convergent boundary where the two plates have collided with each other and cause both to extend up and create a mountain range. The rate of growth by the mountain range has slowed since the Eurasian Plate has started to stretch out rather than stretch up.5. Many people around the world live near plate boundaries because of soil fertility. What logical reason explains why soil tends to be quite fertile near plate boundaries?Soil tends to be quite fertile near plate boundaries because this is the location where volcanoes are and after a volcanic eruption, many minerals are spewed into the environment and fertile volcanic soil is laid down. After lava from a volcano cools and hardens, weathering of the lava produces highly fertile soil. An example is in southern Italy where farmers grow on the fertile soil produced from eruptions by Mount Vesuvius. Without the volcanic soil, many environments may not have been able to be cultivated.6.In 1977, Dr. Robert Ballard, who also discovered the resting place of the Titanic, discovered a strange and bountiful world of life in the deep Pacific Ocean near the Galapagos Islands. The life was near hydrothermal vents whereby water was superheated by magma (i.e. molten rock) near the surface of the ocean floor. It came quite as a surprise to many biologists, who thought that life in the deep ocean was rather scarce. It is now assumed that life can be found anywhere on the deep ocean floor wherever there is heat and hydrogen sulfide, which, interestingly, is the base of the food chain of these light-deprived communities.Using the information above, let us now play make-believe. Let us pretend that you are captain of a ship transporting plutonium across the Atlantic Ocean to supply a European country with fuel for nuclear power plants. Just after you leave the east coast of the United States, your ship is hijacked by pirates who plan to take the plutonium to another country across the Atlantic for the purpose of making nuclear weapons; therefore, as captain, you must make a decision to save the world, so, you consider dumping the plutonium in the ocean as the lesser of two evils rather than it be delivered for criminal bomb-making. Now, you must decide where in the Atlantic to dump the plutonium. You want to dump it where there is the least likelihood of bountiful life, and you know there is perhaps plentiful life where there are hydrothermal events near where the ocean crust is rather thin and magma is near the ocean floor.Here’s the question: Would you dump the plutonium-a. 1?4 or 3?4 of the way across the Atlantic from the US east coastorb. 1?2 of the way across the Atlantic at about the midline of the Atlantic Ocean?I would dump the plutonium ¼ or ¾ across the Atlantic Ocean from the U.S. east coast. At this, distance, it is unlikely that any humans could be affected by the plutonium and relatively few sea life lives in this area as compared to option B. If I had taken option B, I would be dumping the plutonium of the Mid-Atlantic Ridge which has many many hydrothermal events along the fault line. Here the plutonium would have many more negative effects on countless amounts of sea life that live near the vents for survival.']	['<urn:uuid:632114ae-5ea5-4c30-be74-f4e35732bc89>']	open-ended	direct	short-search-query	distant-from-document	single-doc	novice	2025-05-12T13:53:09.865574	6	56	1192
35	healthcare ai replacing doctors study findings	Research shows that AI in medical devices is being used to support, not replace clinicians. While there is sometimes hype about AI taking over medicine, its use in medical devices is still limited in Australia, and healthcare workers are largely unaware of the different levels of device autonomy. The responsibility for decisions always remains with the clinician, not the AI.	['New research from the Australian Institute of Health Innovation at Macquarie University, an AAAiH Member, shows artificial intelligence (AI) is being used in medical devices to support, not replace clinicians, and for the first time has classified three levels of autonomy to improve safe use.\nWhile AI is sometimes hyped to be taking over medicine, its use in medical devices is still limited in Australia, and the workforce is largely unaware of the different levels of autonomy of a medical device, says Dr David Lyell, AI in healthcare expert from the Australian Institute of Health Innovation, Macquarie University. Dr Lyell’s research was nominated as editor’s choice by the leading international BMJ Health and Care Informatics Journal for its unique classification of AI in medical devices. A medical device is software, or a machine or instrument used to support the diagnosis and treatment of people in healthcare.\nWhile AI has the potential to support clinicians in their decision making, more awareness is required into the impact on patient safety and how the Australian workforce will be trained to use new devices. Patient safety is at risk if clinicians are not trained to understand the level of autonomy they are dealing with in the medical device and the specific circumstances it ha s been designed for. For instance, a device that supports decision making for diagnosis of adults is often not suitable for use with children.\nDr Lyell draws an analogy with driverless cars that while they are promoted as being self-driving, in reality they still require constant driver attention and a readiness to takeover should problems arise. Likewise, decisions made using AI supported medical devices should always be the responsibility of the clinician not the AI.\nThree levels of AI in medical devices were defined by the research, and importantly point to how the benefits of the technology can be leveraged while also making them safe for patients.\n- Assistive devices – these are characterized by an overlap between the device and clinician. For breast cancer screening both identify possible cancers, however clinicians are responsible for making decisions on what should be followed up and therefore must decide whether they agree with AI marked cancers.\n- Autonomous information – this is characterized by a separation between what the device and the clinician contribute to the activity or decision. An example is an ECG that monitors heart activity, interprets the results, and provides the information, such as quantifying heart rhythm, which clinicians can use to inform decisions on diagnosis or treatment.\n- Autonomous decision – this is where the device provides the decision on a clinical task that can be enacted by the device or the clinician. An example is the IDx-DR diabetic screening system in the US that can detect diabetic retinopathy. General practitioners can act on positive findings and refer those patients to specialists for diagnosis and treatment, without having to interpret retina photographs themselves.\nThe research was based on medical devices approved by the US Food and Drug Administration.\nThis peer-reviewed journal article is free to access here.\nReproduced with permission from Macquarie University.']	['<urn:uuid:70548ac9-7113-4fc8-b68a-d822e5ce0f5d>']	open-ended	with-premise	short-search-query	distant-from-document	single-doc	expert	2025-05-12T13:53:09.865574	6	60	515
36	how do hockey players support military families and what challenges do these families face during deployment	NHL players support military families through initiatives like Defending the Blue Line (DTBL), which provides free hockey equipment, camps, and financial assistance for military children. The NHLPA's Goals & Dreams fund has donated hundreds of sets of equipment to DTBL campaigns. Players regularly participate in meet-and-greets with service members and their families, helping ease stress during difficult times. As for challenges during deployment, military families face numerous stressors including legal issues, anxiety, and depression affecting both parents and children. Children particularly struggle with understanding why their parent has to leave, where they're going, and the length of absence. Families with existing medical, emotional, or behavioral problems find deployment especially difficult.	"[""Players Honour Military Members\nDefending the Blue Line just one example of how NHLPA members honour members of the military.\nOn November 11, the date on which the men and women of the armed forces, past and present, are honoured for their sacrifice and bravery, Shane Hudella will be reminded of the widespread and passionate support that his Defending the Blue Line (DTBL) organization receives from NHL players.\nHudella, who was on active duty for the Minnesota Army National Guard and was deployed for Operation Desert Storm in 1990, started DTBL in 2009.\nDTBL works to ensure that children of military members are afforded every opportunity to participate in the game of hockey, through free equipment for military kids, hockey camps, special events, and financial assistance for registration fees and other costs associated with hockey.\nThe NHLPA’s Goals & Dreams (G&D) fund, the largest grassroots hockey assistance program of its kind in the world, has strong ties to DTBL. In 2013, G&D donated 50 sets of brand new hockey equipment to the military youth supported by DTBL. Over the last five years, G&D has donated 325 complete sets of gear to their campaigns, including 25 at an event in Minnesota last year.\nNumerous players have lent their time and assistance to various DTBL initiatives.\n“From the military perspective, the support from the players is absolutely immeasurable,” said Hudella, who retired from the military on June 30, 2012, at the rank of 1SG (First Sergeant). “From advocating through the Goals & Dreams program to get us new gear each year, to the special appearances they make, both (U.S. and Canada) of our nation's heroes understand that the players are our lifeline. It's made such an impact for the kids especially to have that once in a lifetime opportunity to meet a pro hockey player, and that often helps soften the blow for the entire family that may be dealing with a deployment or serious injury.”For Hudella, that loyalty is appreciated, but certainly not unexpected.\n“What makes the hockey players so great? To me, it's that they are the ‘working class athletes.’ What I mean by that is that they worked hard to get where they are, and they haven't forgotten that. They are humble like our troops, and always have time for our heroes. I've witnessed a ton of the meet and greets personally, and it's so striking to me to see the athletes and the service members both looking and acting like they just met their hero.\n“The common theme after doing a player meet and greet is typically that of Christmas times 10!” continued Hudella. “The military members will commonly thank us for helping ease the stress and burden at home through these special experiences, and even if it's just for a couple hours, it's a huge relief for them to think of something other than the challenges that go along with serving your country.”\nDevin Smith, Chairman, G&D, is proud to see the strong bond that’s been established between the players, the program and DTBL.\n“Showing their support, while recognizing the bravery and sacrifice of members of the military, is extremely important to the players,” said Smith. “Many of the players, through their own families, have ties to the military, and have a deep respect for the men and women who selflessly serve their countries.”\nHudella knows he can always count on the players.\n“They are genuine in their caring and admiration of the heroes,” he said. “It doesn't matter if they had a bad game or a loss that night, they are always willing to take time with our troops to make sure they know how much they are appreciated. Additionally, as a whole, the players spend a tremendous amount of their precious down time helping us at various events.\n“Having been around the league now for seven years, I understand how much the players are away from home, too, so this is moving for me to see them take additional time away from their own families to help us out, and spend time with the troops.”"", 'Understanding the Needs of Children and Families Especially During Times of Military Deployment by United States Download PDF EPUB FB2\nThe children of military personnel face many challenges because of deployment to war. Kids need to understand why their parent has to leave, where they are going, and how long they will be away. Deployment to war creates additional issues for a family to handle. Families face a number of challenges before, during, and after deployment.\nThis emotional cycle of. Pre-deployment: During the days and months leading up to deployment, service members and their families may experience a variety of stressful events, such as dealing with legal issues, creating a will, or assigning a power of en may feel confused or anxious about what will happen to them.\nDeployment: When a parent is deployed, a child may experience a sense. Understanding the needs of children and families especially during times of military deployment: hearing before the Subcommittee on Children and Families of the Committee of Health, Education, Labor and Pensions, United States Senate, One Hundred Eighth Congress, first session on examining how effective the Army has been in making it easier for military families raising children and to determine what additional changes can be made to further assist military families.\nResearch suggests that deployments can be overwhelming for military families, and lead to problems with anxiety and depression in parents, spouses, and children 1,2. However, there are also several strategies that can help lessen this stress, and ensure the family continues to thrive in the midst of the uncertainty and change a deployment brings.\nIn the military, stress happens. But too much stress can have negative effects on performance, safety and well-being. During deployment, it is especially important to know the signs of stress and to be ready with good stress management techniques.\nFurther, military families are particularly vulnerable to the negative repercussions of the favorite child complex. In the book, The Favorite Child, I describe the impact on families when a. Sally Zoll of United Through Reading says, “Keeping military families connected during deployment is the core of our work.\nBrenda’s exceptional imagery allows military families to realize mindfulness–keeping the parent in the mind of the child and the child in the mind of the parent. Night Catch is the best of the best!”.\nreality for military families (Military One Source, ) in times of war and peace (Park, ). For example, the deployment cycle is continuous, affecting family members as they prepare for, experience and reunite after the deployment (Military One Source, ).\nIn the midst of these challenges, over half of military family. 3 Understanding the Military: The Institution, the Culture, and the People. noncombat situations. Active component service members and their families live on or near military posts or bases and are essentially transient, expecting to move every three to five years, a circumstance virtually unheard of in the civilian workforce.\nDuty locations are. Understanding the Returning Family Member Military deployments, especially in a combat zone, can significantly change an individual\'s life. Deployment involves the loss of many comforts that people back home take for granted: contact with family, comfortable living conditions, a variety of good food, time to relax, etc.\nDeployment Resources when you don’t live near a base. ASYMCA (Armed Services YMCA) offers programs and activities for military families, such as free membership at YMCA locations, deployment showers for pregnant spouses, and free childcare at respite locations.\nUSO (United Services Organization) hosts a variety of military-friendly events at locations around the country.\nDeployment Journal for Kids is a special journal created for children to record feelings and events during a loved one’s military deployment. H Is for Honor: A Military Family Alphabet.\nDevin Scillian (Author), Victor Juhasz (Illustrator). Families who have little or no contact with extended family and/or the military community may be especially vulnerable to stress.\nIn families with existing medical, emotional, or behavioral problems, a parent being away can be especially difficult. While most families and children manage successfully, it is important for parents to be aware of. reactions of children and youth is important.\nSuch topics quickly become a focus for daily discussions among people. Thinking of children’s reactions is especially important when the issues directly relate to their family life, such as the deployment of a parent for military service. Talking to Children About Armed Conflict Sean Brotherson, Ph.D.\nThis 8-page book’s subtitle is: Coping strategies for you and your child during deployment or when a crisis occurs. It outlines what parents may see in their babies and toddlers during stressful times and offers concrete guidance and activities to support their young children throughout these challenging events.\nMoving to a New Location. Getting ready for a deployment can be challenging — especially for children. It’s important to maintain open channels of communication with children so that they can ask questions and express emotions.\nThis begins with, but isn’t limited to, pre-deployment preparation. Deployment is heart wrenching for all military families, but especially for those with children.\nAs one parent tries to take on both parenting roles and cope with not having a partner for a long stretch of time, the kids have their own stress issues. Toddlers may not understand why mom or. We understand that each PCS, TDY, and deployment can disrupt your child\'s learning.\nA K12 education provides students with the consistency of personalized online learning, certified-teacher support, a quality curriculum, and a strong school community.\nLearn more about K12 online schools for military families. Operation Teammate provides a solution to ease the pain for military children during challenging times throughout the year and while their parents are away from home serving our great nation.\nWe welcome military families of all statuses and provide memorable sporting experiences to military children through Impactful Athlete Interaction. Helping Children Integrate the Parental Injury Experience within the Family.\nHealthcare and family support professionals should encourage families to: Seek out resources and instrumental support. Families may require that basic needs be met in the areas of finance, medical care, military concerns, housing, education, and child care. Military parents know there’s no way to make deployments easy for their kids.\nHowever, there are great resources available to help parents and children get through the months apart. Here are a few tried and true programs that have helped many military families survive – and thrive – during deployment.\nMore than million men and women currently serve in the U.S. military. Of those, roughly 55 percent are married and 43 percent have children. Here are 12 ""facts of life"" for today\'s U.S. military families: Over 2 Million U.S. Children Have a Parent Who Served in Iraq or Afghanistan And many of these parents have been deployed more than once.\nMilitary Family Resources After Deployment: Wellness resources for the military community, including sections on Families & Friendships and Families with Kids Blue Star Families: Blue Star Families was founded by military spouses in to empower families to thrive as they serve by connecting them with their civilian neighbors - people and organizations – to create strong communities of.\nThis book is designed to help children especially, but also their parents, during such difficult times. Based on many years of experience as a social worker, who has assisted military families experiencing stress, author Beth Andrews has created an excellent tool for allowing children and their loved ones to deal with the many emotions caused.\nA lot of military families skip this super important deployment prep step. Teachers. Why do they need to know. But teachers are spending over eight hours a day, five days a week with your kiddos. That’s a lot of time.\nRelated: Best Toys and Resources to Help Military Kids During Deployment. Set up a. A deployment can bring out strong emotions in family members and cause stress and anxiety, especially in children. By understanding how preschool and school-age children react during deployments and by preparing ahead of time for this big change, you can make sure each phase of the deployment is successful.\nMilitary ID cards allow family members to access important services and privileges, like TRICARE health insurance and the on-base commissary and exchange.\nIf your ID card expires during deployment, make sure you have a plan to update it. Read more about ID cards and connecting with the military community here. Finally, there is no book more important to understanding the underpinnings of race, racism and uprisings right now than a new book by William A.\nDarity Jr. and A. Kirsten Mullen, FROM HERE TO. Actively reaching out to children and families who are experiencing deployment difficulties during this phase can be helpful, especially if support includes the teaching of new coping skills in relation to specific problems.\nThe majority of families reach a “new normal” in. One of the most valuable education benefits available for military families is the Post-9/11 GI Bill. Service members have the option of transferring some or all of their GI Bill benefit to their dependent spouses and children.\nService members can choose to transfer the entire 36 month benefit to one family member, or divide it among their spouse and/or children. The death of a parent is a reality for many children in military families. behind during a deployment may also experience similar issues.\nwith friends and family, especially your partner.As a life-long educator, Dr. Biden spearheaded “Educate the Educators”–a commitment from more than colleges and universities to take steps to meet the unique needs of military-connected children–and championed the GI Comparison tool to help veterans and military family members choose high-quality post-secondary educational institutions.']"	['<urn:uuid:f90d2ff0-ef3e-4594-a2bc-02ba1d72644e>', '<urn:uuid:5e485012-a73f-4c69-a13e-c1d1563df7bd>']	open-ended	direct	long-search-query	distant-from-document	multi-aspect	novice	2025-05-12T13:53:09.865574	16	110	2280
37	My health plan may not work abroad. How much medical coverage exists?	Travel medical insurance can provide coverage limits of up to $500,000 per person for medical expenses including ambulance service, X-rays, lab work, medicine, doctor and hospital bills during your trip.	"['Confused about entry requirements for your destination Our interactive map shows current travel rules and restrictions for each destination, including info on COVID-19 testing, necessary travel documents and quarantine periods.\nWhether you\'re planning a week-long road trip or a weekend getaway, you never know what might happen. Travel insurance gives you access to our 24-Hour Assistance hotline for expert, personalized support in a crisis.\n*A travel supplier\'s cessation of operations due to its financial circumstances may not be available as a covered reason under all plans.*Rental Car Damage and Theft Coverage, when purchased as part of an annual plan, is not available to KS, TX, and NY residents. For WA residents, it may not be available in all plans. See your plan details for additional information.\nThe US government, through the Office of Foreign Assets Control (OFAC), regulates travel to the destination you have selected. To purchase this policy, you will need to mail Travel Guard a paper application for insurance, a Cuba Travel Compliance Certification (Travel Guard version) and, if you are traveling under a specific OFAC license, additional documentation. Please contact our sanctioned countries hotline at 866.375.2546 for forms and additional details.\nJust another expense, right Wrong. A travel insurance plan can cover you for unexpected costs incurred before or during your trip so that expenses can be less likely to come out of your own pocket. A vacation insurance plan from Travel Guard helps to protect your trip investment with coverages like trip cancellation and interruption, medical expense and evacuation, lost or delayed baggage and more.\nAs a bonus - most travel insurance plans also include 24/7 emergency assistance services to re-book flights and hotels on your behalf and act as a personal travel assistant while you are away from home.\nThe cost of travel insurance is based, in most cases, on the value of the trip and the age of the traveler. Typically, the cost is five to seven percent of the trip cost. You can get a free quote for your personalized travel insurance plan or call our representatives at 800-826-5248.\nThe Atlas Journey Premier plan provides decent coverage at a competitive price. Available upgrades include extra coverage for pets traveling with you, adventure sports, destination weddings, hunting and fishing equipment, and more.\nIt can be inconvenient, stressful and costly if your trip is delayed due to unforeseen events. That may be why the majority of travelers (68%) are concerned about flight delays and cancellations, according to a Forbes Advisor survey of 1,250 adults planning to take a vacation in the next six months and traveling by airplane.\nTravel medical insurance pays for ambulance service, X-rays, lab work, medicine, doctor and hospital bills, and other medical expenses during your trip. This is important coverage for travelers going abroad, where your U.S. health plan may have limited global coverage or no coverage. You can find generous coverage limits of up to $500,000 per person with some travel insurance policies, but you may decide that lower levels of coverage are adequate for your needs.\nIf you have to cut your trip short because of a reason listed in the policy, trip interruption insurance is valuable coverage to have. It can reimburse you for the non-refundable parts of your trip that you miss, such as a resort stay or prepaid scuba diving lesson. It can also pay for a last-minute one-way ticket home if you have an emergency.\nTravel insurance sales are mirroring this concern. Sales of travel insurance policies including baggage loss coverage jumped 101% from November to December, says Megan Moncrief, a spokesperson for Squaremouth, a travel insurance comparison provider.\nThe average cost of travel insurance is 6% of your trip cost, based on a Forbes Advisor analysis of travel insurance rates. The cost of travel insurance is usually mainly based on the age of travelers and the trip cost.\nMany health plans lack robust global coverage, or impose high out-of-network deductibles for care outside the U.S. Check your health plan details to see what it provides. Travel medical insurance fills the gap.\nThe average trip cost for Americans traveling within the U.S. increased 46% from 2019 to 2022 and is now slightly over $4,000, based on data from Squaremouth. So having trip cancellation insurance to safeguard your trip investment can be a smart move.\nIf you have lots of pre-paid, non-refundable deposits for activities, lodging and tours, it is especially important to have trip cancellation coverage. This holds true for trip interruption insurance as well.\nCoverage available to residents of U.S. states and the District of Columbia only. These plans provide insurance coverage that only applies during the covered trip. You may have coverage from other sources that provides you with similar benefits but may be subject to different restrictions depending upon your other coverages. You may wish to compare the terms of each policy with your existing life, health, home, and automobile insurance policies, as well as any other coverage which you may already have or is available to you, including through other insurers, as a member of an organization, or through your credit card program(s). If you have any questions about your current coverage, call your insurer or insurance agent or broker. Coverage is offered by Travel Guard Group, Inc .(Travel Guard). California lic. no. 0B93606, 3300 Business Park Drive, Stevens Point, WI 54482, www.travelguard.com. CA DOI toll free number: 800-927-HELP.\nThis is only a brief description of the coverage(s) available. The policy will contain reductions, limitations, exclusions and termination provisions. Insurance underwritten by National Union Fire Insurance Company of Pittsburgh, Pa., a Pennsylvania insurance company, with its principal place of business at 1271 Ave of the Americas, Floor 41, New York, NY, 10020-1304. It is currently authorized to transact business in all states and the District of Columbia. NAIC No. 19445. Coverage may not be available in all states.\nAmerican International Group, Inc. (AIG) is a leading global insurance organization. AIG member companies provide a wide range of property casualty insurance, life insurance, retirement solutions and other financial services to customers in approximately 70 countries and jurisdictions. These diverse offerings include products and services that help businesses and individuals protect their assets, manage risks and provide for retirement security. AIG common stock is listed on the New York Stock Exchange.\nAIG is the marketing name for the worldwide property casualty, life and retirement and general insurance operations of American International Group, Inc. All products and services are written or provided by subsidiaries or affiliates of American International Group, Inc. Products or services may not be available in all countries and jurisdictions, and coverage is subject to underwriting requirements and actual policy language. Non-insurance products and services may be provided by independent third parties. Certain property casualty coverages may be provided by a surplus lines insurer. Surplus lines insurers do not generally participate in state guaranty funds, and insureds are therefore not protected by such funds.\nOur licensed travel insurance agents are open and honest with every traveler to help you find the best plan for your trip. If you need to make a claim, our team can support you in the process and advocate on your behalf if necessary.\nThe U.S. government does not provide insurance for U.S. citizens overseas. We do not pay medical bills or unexpected cost. We highly recommend that you purchase insurance before you travel. Please review the country information page for your destination before you travel. For more information on health, visit our page on Your Health Abroad.\nLinks to external websites are provided as a convenience and should not be construed as an endorsement by the U.S. Department of State of the views or products contained therein. If you wish to remain on travel.state.gov, click the \\""cancel\\"" message.\nTravel insurance works by protecting your health and the money you spent for your trip. Travel insurance provides several different types of benefits that are important before and during your trip. This can include coverage for:\nTravel insurance is a limited benefit plan that covers you for illnesses and injuries that occur while you are traveling. Health insurance, on the other hand, covers medical treatment you may need on a continuing basis for routine and wellness health care, emergency care, and treatment of chronic conditions that exist without regard to a specific time frame or travel event.\nTravel insurance can include emergency medical benefits, which can help cover the cost of treatment if you become sick or hurt while traveling. It is important to note that your domestic health insurance might not provide coverage in another country if you are traveling internationally.\nThe medical benefits in your travel insurance will vary depending on which plan you purchase, so we recommend contacting a licensed travel insurance agent and reviewing your plan document carefully to understand what is covered in your plan.\nTravel medical insurance must be purchased at least one day prior to leaving your home country, although it is best to give yourself as much time as possible to review your options and make sure you understand your plan document to make sure you choose the best coverage for you.\nYes, especially for nonrefundable trips and travel during the COVID-era. Whether you purchase a comprehensive travel insurance policy or have travel insurance from your credit card, you shouldn\'t travel without having some sort of travel protection in place to safeguard you and your trip. Travel insurance can protect you in case of an unexpected emergency such as a canceled flight due to weather, a medical event that requires hospitalization, lost luggage and more. 59ce067264']"	['<urn:uuid:d97e49b2-70be-46d4-9a09-3a7637efe24a>']	factoid	with-premise	concise-and-natural	distant-from-document	single-doc	expert	2025-05-12T13:53:09.865574	12	30	1596
38	As someone designing a home office setup for remote work, what are the key lighting considerations for productivity and what cybersecurity measures should I take regarding device placement to prevent unauthorized access?	For lighting, daylight is the most balanced source of white light and you should maximize natural light in your workspace. If that's not possible, use a combination of general and task lighting with dimmer switches. Avoid placing overhead lighting directly above computer screens or putting screens in front of light sources to prevent eyestrain. For cybersecurity, you must never leave devices in unsecured areas - lock your screen when stepping away, lock your doors, and don't leave devices in your car. Additionally, ensure you work in a private space where screens aren't visible to unauthorized people.	"['Working from house is interesting considering that it supplies a chance genuine comfort and efficiency, however if the office is as well laid-back, or isn’t properly separated from the residence environment, peak efficiency might be shed.\nWhile convenience is vital in any sort of workplace, an office that is as well casual might seriously restrain the capacity to go things done. You have to discover a method to different on your own from the rest of the goings-on in the residence and to convey a feeling of “off limits” to all various other regular as well as organic house sounds and also disturbances.\nA distinction needs to be made relating to the bodily limits of this working area. One of the most effective method to do that is with the design of the room itself.\nAsk yourself these concerns before you begin:\nExactly what will you be doing in the area?\nJust what sort of job necessities to be done?\nWill outside clients be checking out the room?\nWill colleagues check out for collective work?\nWhat kind of products will be referenced and/or kept?\nWhat type of equipment is called for?\nWhen will I be doing the bulk of my job?\nWill I be making teleconference?\nWill I be video conferencing?\nThe answers to these questions will start to create the program for your house office.\nWhere are you going to place your office? You could be able to convert the guest area you only make use of a few times a year or one more underutilized location into your workplace.\nContinue all your operate in that space because it’s vital that you be able to find things, get things and be efficient within this space. You will certainly also wish to keep the non-office area in your house devoid of work products. This promotes healthy balance and also allows you to loosen up in the home when you are not at the workplace.\nSet up set hours for your work at home. This adds to your life equilibrium, and ought to also aid you be much more productive and organize your day. The biggest problem home workers have is the loss of difference in between job life and residence life.\nSeparating your day into identifiable sectors will assist. Establish a developed outline of time that you recognize you will certainly invest in your workplace. That will certainly aid you create a prepare for productivity.\nJust what are one of the most typical mistakes people make when they’re establishing up a residence office?\n- Thinking you can “ignore” the plasma display on the wall. Do not hang it anywhere near where you’ll be functioning.\n- Inadequate storage space elements.\n- Lack of area for recommendation materials.\n- Inefficient and also slow tools.\n- Inadequate cord administration (cables and cord spaghetti all over).\nJust what are one of the most essential five things to consider when you’re establishing up a home workplace?\nDevices. Rate and performance are crucial in the home. Make cautious choices. Inquiry whether that big shade copier is a genuine requirement or if a travel to the area Kinkos will be sufficient. Don’t pay for devices you will not make use of each day.\nExamine a wireless hub for your workplace so you have the adaptability to work with your laptop from your desk, your chair or a table, and also at both standing as well as resting elevations. This simple choice could improve your imaginative problem-solving as well as believing ability.\nYou’ll wish a different phone line to your office so no company partner or client acquires an active signal. Make certain your phone has the ability for messaging, conferencing and also speaker functions.\nBe sure you have a responsive and also regional computer assistance group that will make house service calls promptly. You have to recognize you can rely upon the tools you have to function.\nMake certain you purchase the fastest equipment readily available, so you do not spend your time hanging around for points to work.\nCost effective plans will guarantee your residence office tools in the event of a loss or catastrophe. Many insurance policy firms provide unique insurance coverage for those who work from home.\nDaylight is the most uniformly well balanced source of white light fixture available, in that sunshine has an about equivalent percentage of each shade of the range. The colour of organic light fixture likewise varies based on geographical location. It is consistently beneficial to have as much natural headlight as possible in the functioning area.\nA mix of basic and job illumination will be required if no daylight is readily available. A high-grade activity light fixture will certainly be vital for over cast days or late nights. If your residence office is in a basement or a space without windows, take a look at daylight-replicating light sources that will certainly give energy-efficient, full-spectrum lighting. Several ergonomic task-lighting components have dimmer buttons so you could control the amount of light.\nThe most efficient illumination brings out the max top quality of the colours brightened. If lights degrees are too low, there could be unfavorable emotional effects, consisting of depression. For human convenience, a yellow-cast lighting is most ideal. It is the color of illumination, and also midway through the color progression from awesome to heat.\nTo prevent glow, do not position overhead illumination straight over computer system displays, as well as do not place a computer screen directly before a light source. That will induce eyestrain.\nElectricity guidelines are causing new reduced-light levels in offices that are simpler on the eyes. One of the most critical element with illumination is the capability to manage its illumination and strength.\nPrivacy. No one can work successfully in a sea of noise or interruptions. When planning your workplace area, make sure that it pays for a level of personal privacy from surrounding programs. While headphones may offer to isolate specific sounds, no one intends to be required to put on headsets regularly. Portable screens could be used to protect the workplace from nearby activities. Divider panel wall surfaces that double as bookcases will certainly not simply split the location but give premium storage options.\nTo help in creating the silent needed for genuine concentration as well as job, a degree of white sound could be practical. Air filters as well as low followers will run at a quiet rate to muffle other noises.\nIf a door to the office location is not useful or available, it could be helpful to add signage (e.g., “No disruptions” or “Quiet please”) to advise others in the space that this is “job time.”\nLayout/organization. The aged rule, “an area for everything and also everything in its location” was coined to alleviate tension. If you have actually meticulously believed through your storage demands, you’ll have the area you need.\n- Your desk will likely be the location where you spend the most time. What is crucial for efficiency is an orderly workdesk that keeps pending job in order and avoids the chaos of disorganized heaps.\nSolutions are as easy as pencil cups or trays to continue all writing tools in one area, plus memo as well as business card owners so, actually, there is an area for every little thing. Shops such as The Container Store make it easy for you to go arranged and also remain that method. In this day and also age, there are a lot of choices for storage, the obstacle is much more in discovering exactly what functions ideal with your circulation of paper and job. Do you find yourself working from left to? Does your paper trail have a distinct circulation? When intending exactly how you store your items, remember compared to.\n- Chair suppliers have made substantial renovations in adjustability and convenience for computer individuals. They have actually also looked into the biomechanics of seating. Activity chairs mirror this study as well as are making individuals’ lives much easier also when they work with a computer the entire day. Keilhauer has created chairs that showcase a pelvis balance factor as well as cost-free shoulder innovation. They are really type to your back and also spine during computer system work. An additional favorite of ours is Humanscale. It has actually likewise taken a wonderful amount of time and initiative to learn the needs of the body when it comes to working. The company’s chairs are an investment you will be grateful for for numerous years if you are in a position where you compose or produce most of the time.\n- Take into consideration foot rests, ergonomic mouse instruments formed to fit your hand and soft keyboard pads that permit remainder and also leisure for the wrist, and foot rests. All enhance the work encounter and also make your time at the office much less difficult to your body. The goal is make work comfy for your body and to assist the areas of the human kind that are called into play with the job you do.\nWhat are the most effective colours for an office? The psychology of shade is real. Be mindful of the psychological impact of the colour you select for your house office.\nBlues, violets and eco-friendlies are considered amazing colors. These colors rouse feelings of peace and also relaxation. Blue can in fact make a space really feel cooler and could lull residents to sleep. It’s a perfect bedroom color, but not a suitable office shade.\nAs the leading colour in attributes, green is thought about a neutral. We are extremely comfy in green environments. Eco-friendly evokes natural, fresh, relaxing emotions and can promote concentration. Today’s new brand images showcase a lime environment-friendly color that incorporates yellow shades. This color could add quality and also vitality to a workplace. The addition of environment-friendly to an office location will enhance its equilibrium.\nYellow grabs interest. That’s why the most popular highlighters are yellow. It stands out like nothing else colour. It makes homeowner delighted and stimulates positive outlook. Yet a brilliant yellow could be subduing or sidetracking in a workplace area as well as could also create a degree of stress and anxiety.\nRed is energised as well as stirring. It usually creates sturdy feelings and also could produce excitement. If utilized in a house workplace, it needs to be used as an accent just.\nWhite, ivory, dirty and tan can carry subtle variants of shade. So they could be neutral with overtones of the colors you really feel most comfortable with, such as a cozy gray or a great grey. These colours do not sidetrack and also could be combined with accent shades for vigor and also electricity.\nAccents and also shades of purple have been verified to promote creative imagination. When concentration and also focus are required, Purple or jasmine tones go across the line in between cozy and amazing tones and can evoke a beneficial feedback.\nWith all colours, it’s vital to examine the colours on the wall surface in huge adequate areas to make sure compatibility.\nThere is no genuine difficult and quick formula for color associations. The color blending is subject to your desires.\nHow would you sum up the principle of home office layout?\nMake sure that your workplace reflects you and also that it has a favored things or photo that will certainly give you the break you need when you pause in your job. It is these tiny touches that assist you make the space your very own.\nYour workplace ought to be a connection to yourself, your spirit as well as your productivity. It should manage emphasis instead of diversion and be a place you wish to desire and also be to spend time in. That will positively affect you in the room and also enhance the work you do there.', ""Creating a cybersecure workspace — at home\nOur homes are more connected than ever. Our businesses are more connected than ever. With more people now working from home, these two internet-connected environments are colliding on a scale we’ve never seen before, introducing a whole new set of potential vulnerabilities that users must be conscious of.\nWhen you work at home, many of the information security controls and procedures that the University of Utah has put in place to protect you aren't available. However, you can take some simple steps to secure your home and reduce the risk of an attack succeeding.\nHere are five ways to be cyber smart while working at home.\n|If possible, use only your university-issued device for work. These devices are managed and have additional security controls in place to better protect you and your data. Do not let friends or family use university-owned devices. They are for your use only, in accordance with the university’s Acceptable Use Rule (4-004A). If you use a personal device to conduct business for the university, then you are responsible for ensuring that the device complies with Policy 4-004: University of Utah Information Security Policy.|\n|Stay on a private, secure Wi-Fi network. Do not use public computers for work, and avoid using public Wi-Fi. If public Wi-Fi is your only option, use a virtual private network (VPN) to create a private encrypted connection between your computer and the university's network. If you access restricted data as defined in the university’s Data Classification and Encryption Rule (4-004C), then using a VPN is required.|\n|Do not store sensitive or restricted data on your personal devices. Use university-approved storage solutions, such as Box. If restricted data is stored on a device, the device must be encrypted as defined in the university's Data Classification and Encryption Rule (4-004C).|\n|Stay vigilant for phishing attacks. Be suspicious of unsolicited phone calls, visits, or email messages from people asking about employees or other internal information. If an unknown individual claims to be from a legitimate organization, try to verify that person’s identity directly with the company. Do not provide personal information or information about your organization. Do not reveal personal or financial information in email, and do not respond to email solicitations for information, including following links sent in email. If you are suspicious of an email, don’t hesitate to forward it to firstname.lastname@example.org.|\n|Do not leave personal or university-issued devices in unsecured areas. Lock your screen when stepping away from your computer, lock your doors, and do not leave your devices in your car.|\nFor more information about securely working from home as a University of Utah employee, please review the Telecommuting: Best Practices guide.\nCreating a cybersecure home\nThe SANS Institute video below describes the steps that can be used at home to protect personal and work devices, Wi-Fi networks, and online accounts. It also covers the importance of information backups, such as cloud services or external hard drives, in the event of an attack, theft, or loss of a device. Secure behaviors at work often start at home, and are even more important when working from home.\nWe also recommend reviewing the Top 5 Steps to Securely Work from Home tip sheet from SANS.\n2020 Cybersecurity Awareness Month\nWhy so many phishing attacks succeed\nMeet the computer forensics experts who investigate the U's cybersecurity incidents\nWhat to do when an abuser uses technology against you\n8 simple tips to improve your online safety and security\nCommon scams — and how to spot them\nWeekly CSAM Scavenger Hunt\nJoin the conversation on Twitter! Follow @uofu_iso.""]"	['<urn:uuid:2bc49f71-9d1f-46b9-8869-2b9191da6d7d>', '<urn:uuid:83696ee6-aa7f-4121-b7eb-c6451a633d68>']	factoid	with-premise	verbose-and-natural	similar-to-document	multi-aspect	expert	2025-05-12T13:53:09.865574	32	96	2574
39	How do biblical poetry and vertical farming use different types of layers?	Biblical poetry uses layers of parallel ideas to clarify meaning through repetition, expansion, and contrast, while vertical farming physically stacks crops in vertical layers to maximize space efficiency and crop yields in urban settings.	['On day 25 we said that Bible poetry, “Draws readers into events and feelings of the writer’s life.” We’ll take a closer look at the poetry of the Bible today and consider some tips for how to understand it better. The books of Job through Song of Solomon are poetic books. You’ll also find poetry here and there in other books of the Bible.\nBiblical Poetry Presents Emotional Truth\nBiblical poetry is experience oriented. That is, it’s intended to stir the emotions and imagination of the reader, to draw the reader into the experiences of the writer. Teaching aims for the head, while poetry aims for the heart. Notice this contrast in the following passages:\n“And ye have forgotten the exhortation which speaketh unto you as unto children, My son, despise not thou the chastening of the Lord, nor faint when thou art rebuked of him: For whom the Lord loveth he chasteneth, and scourgeth every son whom he receiveth.” (Heb 12:5-6)\n“ O LORD, rebuke me not in thy wrath: neither chasten me in thy hot displeasure. For thine arrows stick fast in me, and thy hand presseth me sore. There is no soundness in my flesh because of thine anger; neither is there any rest in my bones because of my sin.” (Psa 38:1-3)\nThe passage from Hebrews plainly teaches that God disciplines those He loves. It states a fact, but it doesn’t really tell you how it feels when God disciplines you.\nThe passage from Psalms, on the other hand, focuses on the feelings of being chastened. To benefit fully from biblical poetry, you need to cooperate with its goal. That is, you need to share the experiences and feelings described. What does it feel like to have God chasten you? It is like having arrows pierce you. It is like being chrushed under a mighty hand. It is a spiritual experience that produces physical results.\nBiblical poetry sometimes presents emotional truth rather than literal truth. It accurately portrays how the experience feels, not necessarily how it is. For example:\n“O God, why hast thou cast us off for ever? why doth thine anger smoke against the sheep of thy pasture? Remember thy congregation, which thou hast purchased of old; the rod of thine inheritance, which thou hast redeemed; this mount Zion, wherein thou hast dwelt.”(Psa 74:1-2)\nClearly, God didn’t cast off His people forever (Rom 11:1-2), but it sure felt like it to the Psalmist. God had not forgotten His people – the teaching portions of the Bible make that clear, but the hardships Israel experienced made them feel like God had abandoned them.\nThe key here is to compare the writer’s experiences and emotions with the Bible’s teaching passages. That will help you know what doctrine feels like lived out. It will also help you distinguish between the true feelings poetry expresses and absolute truth.\nBiblical Poetry Often Uses Metaphors, Similies and Analogies\nSo we’re all on the same page, here are Webster’s definitions for the three terms I just used:\n- “a figure of speech containing an implied comparison, in which a word or phrase ordinarily and primarily used of one thing is applied to another (Ex.: the curtain of night, “all the world’s a stage:)”\n- “a figure of speech in which one thing is likened to another, dissimilar thing by the use of like, as, etc. (Ex.: a heart as big as a whale, her tears flowed like wine)”\n- “the likening of one thing to another on the basis of some similarity between the two.”\nLet’s take another look at that passage from Psalm 38:\n“O LORD, rebuke me not in thy wrath: neither chasten me in thy hot displeasure. For thine arrows stick fast in me, and thy hand presseth me sore. There is no soundness in my flesh because of thine anger; neither is there any rest in my bones because of my sin.”(Psa 38:1-3)\nThe second sentence isn’t literal. God didn’t literally shoot arrows at David. He didn’t press David to the ground physically. These are word pictures that David used to tell us what his experience was like. It’s important to remember, though, that the figurative language expresses a literal truth; God’s disciplines His sinning sons. His discipline is penetrating and painful. It can create an enormous sense of pressure in our lives.\nBiblical Poetry Uses Parallelism to Clarify and Amplify Thought.\nTypes of Parallelism\nHere are three types of parallelism you’ll see often in poetry:\n- An idea is expressed multiple times.\n- Expands on the original idea.\n- Explains an idea by contrast\n“Enter not into the path of the wicked, and go not in the way of evil men. Avoid it, pass not by it, turn from it, and pass away.” (Pro 4:14-15)\nSolomon warned his son to avoid the wicked path. He said the same thing six different ways so his son would get the message. The point here is that we’re not supposed to develop six different doctrines from this passage. Instead, we’re supposed to understand that God is making one important point. Do you see what I mean? Get it? OK.\n“The law of the LORD is perfect, converting the soul: the testimony of the LORD is sure, making wise the simple. The statutes of the LORD are right, rejoicing the heart: the commandment of the LORD is pure, enlightening the eyes. The fear of the LORD is clean, enduring for ever: the judgments of the LORD are true and righteous altogether.” (Psa 19:7-9)\nIn this example the benefits of the Bible are presented in parallel form. Each phrase uses some synonym for God’s Word (e.g. The law of the Lord). Then an attribute of God’s Word is declared (is perfect). Then a benefit of Scripture is listed (converting the soul). The passage builds line upon line to give us a full picture of the Bible’s nature and the nurture it gives us.\n“The proverbs of Solomon. A wise son maketh a glad father: but a foolish son is the heaviness of his mother. Treasures of wickedness profit nothing: but righteousness delivereth from death. The LORD will not suffer the soul of the righteous to famish: but he casteth away the substance of the wicked. He becometh poor that dealeth with a slack hand: but the hand of the diligent maketh rich. He that gathereth in summer is a wise son: but he that sleepeth in harvest is a son that causeth shame.” (Pro 10:1-5)\nIn this example, Solomon addresses five topics in five verses. Each topic is explained using the contrast of opposites. A wise son is contrasted with a foolish son. Seeing one side of a topic can leave you in the dark, but providing contrast by exposing its opposite is illuminating.\nRead More About It\nRead Psalm 1 and look for the poetic elements we’ve discussed today.', 'As urban populations continue to grow, entrepreneurs are going beyond traditional farming to find new ways to feed everyone while minimising the effect on our land and water resources. Vertical farming is one such method that has been used all around the world. Food crops may be conveniently farmed in urban settings using Vertical Farming by planting in vertically stacked layers to conserve space and require little energy and water for irrigation.\nVertical farming is the process of producing crops in layers that are vertically stacked. Controlled-environment agriculture, which tries to maximise plant development, and soil-less farming techniques such as hydroponics, aquaponics, and aeroponics, are frequently used.\nBuildings, shipping containers, tunnels, and abandoned mine shafts are among popular structures used to host vertical farming systems. There are approximately 30 hectares (74 acres) of functioning vertical farms around the globe as of 2020. Vertical farming, in conjunction with other cutting-edge technology such as customised LED lighting, has resulted in crop yields that are more than ten times greater than those obtained by standard agricultural methods.\nVertical farming is still in its early stages in India, but there are a few entrepreneurs and agri-tech enterprises aiming to revolutionise the area.\nVertical Farming Background and Concept\nGilbert Ellis Bailey originated the phrase “vertical farming” and published a book named “Vertical Farming” in 1915. William Frederick Gerick pioneered hydroponics at the University of California, Berkeley, in the early 1930s.\nke Olsson, a Swedish ecological farmer, devised a spiral-shaped rail system for growing plants in the 1980s and proposed vertical farming as a method of raising vegetables in cities.\nProfessor Dickson Despommier invented the concept of vertical farming in 1999. His idea was to grow food in urban areas, utilising less distance and saving time in transporting food produced in rural regions to cities.\nHe aimed to produce food in urban areas in order to have fresher goods available sooner and at a reduced cost. As a result, vertical farming is defined as the cultivation and production of crops/plants in vertically stacked layers and vertically inclined surfaces.\nThe plants are vertically piled in a tower-like form in the physical arrangement. This reduces the amount of space needed to cultivate plants. Following that, a combination of natural and artificial lighting is employed to ensure an ideal atmosphere for the plants’ effective growth. The third component is the plant’s growth medium. Aeroponic, hydroponic, or aquaponic growth media are employed instead of soil as the growing medium.\nAs the methodology gets more scientific, the process’s efficiency grows, and as a result, vertical farming becomes more sustainable, consuming 95 percent less water than previous agricultural methods.\nAlso Read, Oxagon: The World’s First Floating City in the World\nVertical Farming Techniques\nIt is a method of producing food in water without the use of soil by employing mineral fertiliser solutions.\nThe primary benefit of this strategy is that it lowers soil-related cultivation issues such as soil-borne insects, pests, and illnesses.\nAeroponics was inspired by NASA’s (National Aeronautical and Space Administration, USA) endeavour in the 1990s to develop an effective technique to grow plants in space. There is no growth medium in aeroponics, hence there are no containers for growing crops. Instead of water, mist or nutrient solutions are utilised in aeroponics. Because the plants are attached to a support and the roots are sprayed with nutritional solution, there is very little space, very little water, and no soil required.\nThe name aquaponics is derived from the combination of two words: aquaculture (fish farming) and hydroponics (the process of growing plants without soil in order to develop symbiotic interactions between the plants and the fish). The symbiosis is established by feeding nutrient-rich waste from fish tanks to hydroponic production beds called “fertigate.”\nIn turn, the hydroponic beds act as biofilters, removing gases, acids, and chemicals from the water, such as ammonia, nitrates, and phosphates. Furthermore, the gravel beds serve as a home for nitrifying bacteria, which aid in nutrient cycling and water filtering. As a result, the newly cleansed water may be recirculated back into the fish tanks.\nThe Benefits of Vertical Farming\nVertical farming offers various advantages, making it promising for agriculture’s future. The land need is fairly minimal, water usage is 80% less, water is recycled and stored, pesticides are not used, and in the case of high-tech farms, there is no true reliance on the weather.\nA vertical farm makes farming possible within the constraints of a metropolis. When the farms are close by, the food is delivered swiftly and is always fresh, as opposed to the chilled stuff commonly seen in stores. Transportation reduction minimises the cost of fossil fuels and the accompanying emissions, as well as transportation spoilage. Vertical farming, like anything else, has its limitations. The biggest issue is the initial capital expenses for building the vertical farming system.\nThere are further expenditures associated with building the structures as well as their automation, such as computerised and monitoring systems, remote control systems and software, automated racking and stacking systems, programmable LED lighting systems, temperature control systems, and so on.']	['<urn:uuid:d3724d87-5114-4c2c-9fc5-6679d64bf915>', '<urn:uuid:38abc93f-c15d-442d-abe3-4bcfbd141419>']	factoid	direct	concise-and-natural	similar-to-document	multi-aspect	novice	2025-05-12T13:53:09.865574	12	34	1993
40	What specific types of historical artifacts and prehistoric artworks were discovered inside the Cave of Chauvet-Pont-d'Arc when it was found in 1994?	Inside the cave, there were wall paintings and carvings depicting various animals including bison, bears, lions, and panthers. The cave also contained footprints of small children and animals, as well as hand prints. These artifacts had been sealed off by a rock slide for an estimated 25,000 years until the cave's discovery in 1994.	['- Aspect Ratio: 1.78:1\n- Video Codec: AVC/MPEG-4 (2D); MVC (3D)\n- Resolution: 1080p/24\n- Audio Codec: English DTS-HD Master Audio 5.1\n- Subtitles: English SDH, Spanish\n- Region: A (Region-Locked)\n- Rating: G\n- Run Time: 90 Mins.\n- Discs: 1 (1 x Blu-ray 3D)\n- Studio: MPI\n- Blu-ray Release Date: November 29, 2011\n- List Price: $34.98\nClick thumbnails for high-resolution 1920X1080p screen captures\n(Screen captures are lightly compressed with lossy JPEG thus are meant as a general representation of the content and do not fully reveal the capabilities of the Blu-ray format)\nFilmmaker Werner Herzog, known mainly for his documentaries such as the Oscar-nominated Encounters at the End of the World (2007) travels back in time, metaphorically speaking, in this latest documentary, Cave of Forgotten Dreams. In an exploration of the Cave of Chauvet-Pont-d’Arc in southern France, Herzog opens a window on a world of human history long lost to us, and it is spellbinding.\nThe cave had long been sealed off by a rock slide, for what scientists estimate to be 25,000 years, until its discovery in 1994. Inside, on the walls, is a virtual treasure trove of human history. Wall paintings and carvings, footprints of small children and animals, hand prints – things that no eyes had been privy to for many thousands of years. Inside these caves, the paintings on the wall are so delicate that even the human breath can damage them and access is extremely limited. Herzog and his crew navigate through much of the cave system single file on a narrow metallic walkway so as not to disturb te ground below.\nThe 3D production employed for Cave of Forgotten Dreams is mesmerizing, to say the least. It is as if the people who drew these paintings of bison, bears, lions, panthers, and other creattures on the walls to tell their stories are lurking around each undulating corner or breathing over your shoulder. This is the promise and strength of 3D on display without the crazy Hollywood budget and blue aliens to get in the way.\nThe 3D 1080p MVC transfer of Cave of Forgotten Dreams is a difficult one to review, I must admit. Captured originally in 3D, this is not some gimmicky Hollywood 3D conversion meant to suck you into the theatre and extra dough right out of your wallet. This is the real deal and there are many moments where it really shows. There is an amazing sense of natural depth both inside and outside of the cave. The bumps and pits on the cave wall almost seem to ebb and flow like the ocean tide. There is only one brief segment here where there is an unnatural use of the 3D effect, and that is early on where there is a CGI graphic of the 3D mapping of the underground caves shown, which has a good amount of pop-out.\nThe downside to this 3D transfer is, there are a lot of darkly lit areas, obviously, that don’t always lend themselves to great detail and some moments are shot with non-professional cameras due to the preservation requirements of the cave itself. This shows up as very noisy and not particularly strong in three-dimensionality. I also found this release to be one of the most difficult on my gear when it came to crosstalk. I saw medium to heavy ghosting from the very opening shot. I’ve seen enough 3D material now to know that this really varies wildly based on source material. Of course, it could very well be a combination of source material and my display.\nThe 2D HD was equally strong and detailed, but also suffered from the same issues with video noise in the same spots, as one would expect. Flesh tones were natural and shadow detail in the better captured scenes were good, but still showed some crush and softness. Even without the issues with crosstalk, however, this was definitely not as amazing to watch without that sense of depth that the 3D imparted.\nThe sole option offered on Cave of Forgotten Dreams is a DTS-HD Master Audio 5.1 soundtrack that is very effective in capturing the ambient sounds of the Cave of Chauvet-Pont-d’Arc. The surround channels ooze with the eeriness of the surroundings, a distant click, the tap of footsteps. Dialogue is clean, and, of course, the plaintive score by Ernst Reijseger is airy and dynamic.\nThe supplements are slight, but they are interesting nevertheless, including an in-depth featurette on the recording sessions for the film’s emotional score.\nThe supplements provided with this release:\n- Ode to the Dawn of Man (1.78:1; 1080i/60; 00:39:16) — This featurette follows the recordings in the Protestant Church of Haarlem, The Netherlands over the course of 2 days in July 2010 of the film’s musical score by Ernst Reijseger, the composer, who also plays cello.\n- Trailer (1.78:1; 1080p/24)\nThe Definitive Word\nAn insightful and delightful look into the past, Cave of Forgotten Dreams is an educational and introspective look at where humanity has come from, and perhaps where we are going. If you haven’t already seen this, I implore you to gather your family around and to sit down and watch it together.\nAdditional Screen Captures']	['<urn:uuid:8ed021f0-61e3-4a9b-88a7-55e8f2f46dc5>']	open-ended	direct	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-12T13:53:09.865574	22	54	869
41	Which improves soil quality more, peat or vermiculite?	Both materials improve soil quality but in different ways. Peat moss prevents soil compaction and provides a sterile growing medium. Vermiculite improves soil by increasing aeration, retaining moisture and nutrients, improving drainage, and helping with root spread. While both are beneficial, vermiculite offers more comprehensive soil improvement benefits.	['Peat moss is widely-used in gardens around the world, and for good reason. Plants thrive in peat because it provides a sterile growing medium and delivers highly-absorbent qualities;\nit retains water better than other types of soil and prevents soil compaction. There’s no doubt peat moss will make your gardens more productive than ever, but at what cost?\nBig Environmental Impact\nMany of us never stop to think about where peat comes from, or what kind of impact it has on our ecosystems. Despite the fact that peat moss grows naturally in bogs, digging it up for horticultural purposes comes at an unsustainable cost to the environment and to wildlife. As fast as it is to destroy, peat takes an incredibly long time to grow; it forms at less than one millimeter per year!\nNot only that, but peat stores a third of the world’s soil carbon; so draining the bog and removing the moss releases CO2 into the atmosphere. Peat bogs are also the breeding ground for Curlews, an endangered bird species.\nThe UK’s Peat-Free Movement\nThe book Gardening For Wildlife: A Complete Guide To Nature-Friendly Gardening has an eye-opening chapter on peat moss. There were originally 95,000 hectares of peat bogs in the British Isles; today, fewer than 5,000 hectares remain in good condition.\nAs a result, the government is pushing for peat-free home gardening in the UK by 2020, and a peat phase-out by professional growers by 2030. It’s completely voluntary, but according to Horticulture Week, if sufficient movement towards peat-free gardening hasn’t been made within the next two years, further measures could be taken. The Growing Media Association suggests financial penalties or even a total ban are possible.\nA Different Story In North America\nThe issue is somewhat muted in North America, where most of the peat moss sold comes from Canada’s vast number of bogs. The Canadian Sphagnum Peat Moss Association says peatlands cover 113.6 million hectares of land, and from that, only 29 744 hectares have been harvested — only 0.03% of the total number available.\nThe association also says special care is taken to restore the bogs, such as allowing them to re-flood and seeding them with shredded moss grafts. The grafts are transplanted from a donor site. By using this method, called the moss-layer transfer technique, bogs are said to grow back to their almost-natural states within 10-15 years.\nStill, there are other options out there; ones that don’t involve tearing up a natural habitat.\nFor those who would rather use peat-free mediums, a number of alternatives exist. In fact, soils containing bark and wood fibers are said to produce similar results to peat. Another excellent option is coconut fiber, known as coir. Coir retains water just as well, if not better than peat, and decomposes at a slower rate meaning your plants gradually get nutrients over time. Soils containing coir can be purchased at many garden centers, but if you can’t find it, you can simply make your own by combining one part homemade compost with one part coir, which can be found at many hydroponic shops.\nNever underestimate the power of kitchen compost. You can’t find a more perfect nutrient-rich food for your gardens. It provides plants with all the NPK they need, while also improving soil structure, water retention, and drainage. Better yet, compost is something we can all easily do at home for free!\nWhether you decide to buy peat-free soils or go ahead and make your own, it doesn’t matter. What matters is that you’re choosing a more sustainable way to care for your gardens with wildlife and future generations in mind.\nLatest posts by Catherine Sherriffs (see all)\n- The Art of Gardening: Looking To Nature For Inspiration - September 14, 2018\n- What’s In Our Food? Study Finds Traces Of Glyphosate In Some Products - September 12, 2018\n- Location, Location! Preparing Outdoor Plants For The Indoors - September 7, 2018', 'What is Vermiculite? What is it used for?\nIf you’re looking for an additive to improve the quality of your soil, or even entirely replace the soil, then vermiculite is an attractive option. It is commonly used in soil mixes, as well as by professional gardeners and nursery workers to improve seed germination success and encourage rapid root growth in cuttings.\nIt can also be invaluable in preventing plants from being overwatered and succumbing to root rot, as it has impressive moisture retention properties that release water in line with the plant’s needs. So what actually is vermiculite, and how can you use it for the benefit of your plants?\nWhat Is Vermiculite?\nVermiculite is a naturally occurring mineral that takes the form of glossy flakes, varying in color from dark gray to sandy brown. These flakes, which are more specifically a hydrated magnesium iron aluminum silicate mineral, get heated up in a purpose-built a commercial furnace, where they then expand and take on a concertina shape, almost like a tiny accordion.\nIt is this version of vermiculite that is used in horticulture most commonly as a means of improving soil quality or giving seedlings a helping hand to root more quickly.\nHow Is It Made?\nVermiculite in its natural form looks a lot like mica, with a layered rock appearance. It is mined in various regions throughout the world, including Russia, Australia, Brazil, Uganda, and the USA. Open-pit or open-cast mining is the technique employed to extract the vermiculite from the earth. This is because the minerals are found relatively close to the earth’s surface, and therefore, tunneling is not required.\nOpen cast mines look like giant craters in the ground, where the miners work to separate ore from vermiculite and other minerals, then sort them into different categories based on size. Following its extraction from the earth, the vermiculite is heated in industrial furnaces, where it will change in structure. This process is called ‘exfoliation.’ Exfoliated vermiculite transforms into small strands that look like worms, and this is how vermiculite got its name, from the Latin word ‘vernacular,’ which translates roughly to ‘to breed worms.’\nOnce the exfoliation is complete, the finished product will vary in looks, depending on its size. There are four sizes of vermiculite available, with the largest size having an obvious concertina shape. The smallest sizes to the human eye just look like large grains of sand.\nHow to Use Vermiculite in the Garden\nVermiculite produced for use in the garden will always be the exfoliated type of vermiculite. It has many useful qualities that can benefit your soil and plants. It is aerating, moisture-retentive, nutrient-retentive, lightweight, non-toxic, sterile, does not rot or mold, and has a neutral pH.\nVermiculite can be added to poor quality soil to improve it. If you have heavy, clay, poor-draining, or sandy soil in your garden, then most plants are going to struggle to survive, let alone thrive in this environment. You will often hear the phrase ‘improve your soil before planting,’ but how do you actually do this in practice? Vermiculite is your answer. Use around half the volume of the soil in vermiculite, and work it deep into the soil. The vermiculite will drastically improve the soil’s aeration, allowing plants to grow much better. It will also retain the necessary moisture and nutrients to help feed the plant.\nVermiculite is commonly used by those in the gardening trade to root cuttings. It can be used in various ways, either used alone, mixed with soil, or combined with bark for a soilless potting mixture. Whether used alone, or in a mix, propagating a cutting with vermiculite will promote anchorage for new roots, and speed up root growth. If you want to encourage a more rapidly rooting cutting and a higher propagation success rate, vermiculite is the preferred material to use (The Vermiculite Association).\nVermiculite can be used alone or in a potting mix for improved seed germination. Utilizing vermiculite for this purpose will see seedlings develop more quickly. If used alone, add only a small amount of water so as not to overwhelm the seeds.\nThe vermiculite will release the moisture to the seedlings as and when they need it. You should also add a few drops of weak fertilizer once leaves appear on the seedlings, to substitute nutrients which would ordinarily be supplied by the soil. When the seedlings are ready to be planted outside, they can easily be removed from the vermiculite without damage to the roots and potted on.\nVermiculite is an excellent addition to pots of soil, whether that be in outdoor containers or for houseplants. Mixing some vermiculite into your potting soil will improve aeration and moisture retention, resulting in a healthier root system that is better able to spread out and absorb nutrients, thereby creating a lusher plant. You will also need to water the plant less frequently as the vermiculite retains water and releases it when appropriate.\nAfter applying seed to your lawn, spread around a quarter inch of vermiculite over the top and water with a gentle sprayer. You should use approximately 3 cubic feet of vermiculite for every 100 square feet of lawn. This addition will increase the speed at which your seeds germinate, and increase the number of seeds that germinate, for a fuller-looking lawn. The vermiculite will help to maintain a consistently moist lawn, and also protect the seeds from heat.\nIf you like to create your own homegrown cut flower bouquets, vermiculite offers a great hack to use instead of a vase full of water. Simply fill your container with vermiculite and moisten with water, then add in your cut flowers. This eliminates the need to change stale water, will prevent potential spills and keeps the flowers looking fresh for longer.\nBulb and Root Storage\nFor plants that need to be overwintered indoors, vermiculite offers an easy storage solution that will keep the bulbs or root systems in their best condition. First, allow bulbs or roots to dry out for several hours after being removed from the ground. Then fill a container with vermiculite and tuck in your bulb or roots. The vermiculite will prevent rotting, which is a common problem for stored bulbs. It has absorption properties that will keep excess moisture away from the plant without stealing any of the plant’s own stored moisture.\nWhether you have grown your own plants from seed, or you have bought them home from the nursery, you will need to transplant them to their permanent home in the ground. Vermiculite will help your plant to settle in better, ensuring its ideal care needs are met.\nTo use it for transplanting, dig a hole several inches bigger than the plant’s current root system, and add in a mixture of vermiculite and topsoil. Position the root ball in place, then fill the hole with more vermiculite and topsoil. This will help to control moisture levels and improve aeration around the roots, thereby allowing for greater root spread.\nVermiculite can effectively be used as a mulch for some types of plants, including roses and tomato plants. Add just a few inches on top of the soil to improve moisture control and provide heat protection to root systems.\nHow to Use Vermiculite in Hydroponics\nVermiculite can be effectively utilized in a number of ways in hydroponics, essentially soil-free gardening. Though hydroponics gardeners do not use soil, they will often use other materials to support the growth of their plants. Vermiculite can be used in place of soil in various settings, including seed germination, or when rooting cuttings. It encourages more rapid root growth and helps to control moisture levels.\nMoisture control is especially important for young plants, who have weaker root systems, which more easily succumb to rot. Vermiculite helps to prevent this problem as it retains moisture, which is released when the roots need it, meaning you won’t have to keep such a close eye on watering the seedlings or cuttings. When used alone, you will need to add fertilizer to vermiculite to provide plants with the nutrients they would ordinarily withdraw from the soil.\nVermiculite is able to help plants more easily absorb nutrients, including magnesium, calcium, and potassium. It can also be combined with other non-soil materials such as perlite and pumice to create custom hydroponic growing media.\nIs Vermiculite Safe?\nIn the past, there have been health concerns over using vermiculite in homes and gardens. This worry stems from a vermiculite mine in Libby, Montana, USA, which at one time was the largest producer of vermiculite on the planet. The vermiculite mined at Libby was found to contain a dangerous type of asbestos, which naturally grew alongside the vermiculite, and the mine was permanently closed in 1990.\nVermiculite sold today is subject to strict industry protocols that ensure it is safe to use. It does not have any proven toxic or carcinogenic effects and does not contain any trace of asbestos or other harmful minerals. It is commonly used around the world in various forms, not just for gardening, without any negative human impact. Some people may still associate vermiculite with asbestos, but this is unfounded.\nPros and Cons of Vermiculite in Gardening\n- Impressive water retention\n- Neutral pH\n- Aerates soil\n- Improves root growth\n- Increases nutrient retention\n- Will not rot\n- Prevents mold and mildew\n- Helps root anchorage\n- Promotes rapid growth\n- Improves soil quality\n- Can be used alone or in mixes\n- Some associated health concerns\n- Not a renewable source\n- Can retain too much moisture\nHow Does Vermiculite Compare to Some Other Mineral Additives?\nVermiculite Vs. Perlite\nThese are both naturally occurring mineral additives that have many of the same qualities. They are both used in gardening to improve soil quality, especially aiding with aeration. Perlite is known to be more effective at aerating soil than vermiculite, while vermiculite is better at retaining moisture. It has a more expansion potential and is, therefore, able to hold on to greater amounts of moisture.\nMany gardeners combine vermiculite and perlite in custom gardening mixes, as they both offer benefits to growing plants. Due to their different moisture retention qualities, vermiculite is better suited to moisture-loving plants such as ferns that enjoy consistent moisture, while perlite would be more suitable for succulents and other plants that prefer a drier growing medium.\nPerlite is very lightweight, which means when used in hydroponics gardening, it will float away, rendering it useless. It can also be difficult to use when mixed with soil, as it can float to the top of pots and spill over the edge when they are watered. Vermiculite tends to be heavier, so it is ideal for use in bigger pots, which require some extra weight to prevent them from toppling over.\nVermiculite Vs. Pumice\nPumice is another lightweight mineral that can be added to gardens for the benefit of plants. It is excellent at retaining oxygen, therefore making it an ideal additive to improve aeration in heavy or poor-draining soil.\nMixing pumice with sandy or light soils will help to improve water retention while mixing it with clay soils can help to loosen the density of the soil and make it less compact. Similarly, to perlite, it can be too lightweight for use in hydroponics gardening. Pumice has minimal moisture-retention qualities, so if you are concerned about increasing moisture retention, then vermiculite would be a much better addition to your garden.\nVermiculite is a versatile, naturally occurring mineral that can be used alone or mixed with other growing mediums to improve plant health and plant growth. It helps with soil aeration and greatly improves soil quality, but where it really shines is with its ability to retain moisture, thereby ensuring roots have the moisture they need while preventing overwatering. Vermiculite can be expensive to buy but may prove itself to be priceless when it comes to the health of your plants.']	['<urn:uuid:1db3b9fc-68fd-43b2-a1fe-39c1a4d520db>', '<urn:uuid:653d2efd-a8a3-4a1e-95d0-f622ae2d4332>']	factoid	direct	concise-and-natural	distant-from-document	comparison	novice	2025-05-12T13:53:09.865574	8	48	2650
42	When were the original images at Sanjusangendo created?	The original images were created in 1164, when 124 statues were made.	"[""Sanjusangendo ('33-interval hall') in eastern Kyoto is known for its 1001 statues that has 11 heads and innumerable arms. These statues are housed in the 120m-long main hall, the longest wooden building in Japan, whose facade has 33 bays between the pillars. In the center sits a 3m-tall 1000-armed Kannon (the Buddhist goddess of mercy), flanked by 500 human-sized statues standing on each side.\nThe original building dates from 1164 when 124 these images were created. During the Kamakura period (1185-1333), the remaining 876 images were created by many sculptors, including well-known masters, to add up to 1000. Each of these 1000 image have different faces and costume and you may find one that look exactly like you.\nPurposeeasily accessible,surreal&cool,spiritual places,that you'll never forget,knows a lot about Japan,Japanese resort,shrine/temple,art\nAirport/Sta.Osaka International Airport (about 37.3km) Google Transit\nWe guide this spot.\n4.02 weeks ago\nThe temple itself offers nothing special. But what you find inside is.\nAfter removing your shoes you will be walking through a hallway. In the middle you will see a huge Buddah meditating. He is not alone as on his left are 500 statues, same of his right. It is nice to appreciate something a few hundred years old. If you pay attention you will see that each face is different! Quite a good work! For an impressive look, stand on one of either side of the room, align with the first row of statues, and look at them. The garden looks beautiful too. As of February 2020 the entrance fee for an adult is 600Y. Taking photos is prohibited inside the temple.\n5.02 months ago\nToday when we visited, we got to experience the annual archery contest. It was crowded, but so much fun. There were food stalls on the temple grounds which made it very festive. Normally this is a quiet temple with a beautiful pond area surrounded by cherry blossom trees (gorgeous during cherry blossom season). We were able to see the last archers and were given free entrance to the temple. We saw the 1,000 statues which is very neat to see all the different faces. The monks were also given blessings over anyone who came through to remove evil and provide healing, especially for headaches. It was a great experience overall.\n5.03 weeks ago\nWell worth a visit, not that far from the station. You need to pay on entry and once in you need to take off your shoes and either wear the slippers provided or walk with your socks.\nThe pathway to see the sculptures of the heavenly Gods and 1001 buddhas, no photos allowed but the whole visit feels very peaceful and calm and so very beautiful. There is a shop at the end.\nHighly recommend a walk round the gardens on the side and visit the little shrine behind which was in bloom with plum blossoms on our visit\n5.02 months ago\nAmazing history and very receptive of people with disabilities. They have ramps everywhere, braille and scaled statues/ buildings with similar textures to allow for people to feel the shape and texture of it all. Reading about the archery tournament was insane! Some of their souvenirs you can purchase for ¥100-300 cheaper elsewhere but you're not guaranteed to find it all. The incense burning at the entrance to the main hall smelled great but was quite overwhelming. If you have respiratory issues just be mindful!\n5.02 months ago\nAmazing place, 1001 Kannon statues is something hard to believe till you see by your own eyes.\nAlthough information is in Japanese some explanation can be found for some statues.\nI visited in January and I was informed about a event which happens every January related to an old archery event which happened during ancient times. Nowadays girls dressing beautiful traditional clothes fire their arrows (note: It's really short description, more information can be found on site).""]"	['<urn:uuid:9b9f3f2e-8048-4b98-a21d-c6a024557cec>']	factoid	direct	concise-and-natural	similar-to-document	single-doc	expert	2025-05-12T13:53:09.865574	8	12	648
43	I'm heading to some rough mountain terrain for bow hunting and I'm worried about my equipment getting damaged. What should I know about preparing my gear?	When hunting in rugged conditions, you should expect your equipment to take some bumps and knocks along the way. It's critically important that all your equipment - including optics, pack, bow, arrows, and other hunting gear - is durable enough to withstand abuse. The last thing you want is to hike uphill for hours only to find your archery equipment damaged and unusable. It's recommended to research the area ahead of time to understand what conditions you'll face and ensure your hunting gear and archery equipment are up for the challenge.	['4 Bow Hunting Tips for Rugged Terrain Hunts\nArchery hunting is often characterized as a sport that requires a high level of patience and persistence. Becoming an effective and efficient archer is not an overnight process. It requires a level of commitment and dedication that is virtually unmatched within the sport of hunting. With that said, success in the archery woods is often predicated on not only how sound you are as an archer, but also the conditions in which you are hunting. Making an effective shot with archery equipment can be tricky enough on level ground in ideal conditions. However, toss in the challenge of navigating uneven terrain, extremely variable winds, and difficult shooting angles, and you have certainly stacked the deck against you. Archery hunting big game in the mountain high country of the Western United States and Canada is where these situations are encountered. Here are a few simple bow hunting tips and techniques that you can employ that will help ensure that you are sending your best arrow down range despite hunting the difficult conditions.\nOf course, when discussing any type of hunting in rugged terrain one of the first “tips” must be to be in shape! Why? This video should be sufficient reason enough…\nArchery Tips for High Country Hunting\nBelow are 4 quick bow hunting tips that could drastically improve not only your experience with your high country bow hunt, but also that critical moment just before releasing your arrow.\nTip 1. It’s all in the Hips\nWithout a doubt, one of the biggest challenges of hunting in rugged terrain is overcoming the difficulty of shooting uphill or downhill. Though it may seem simple, shooting at an angle requires a little more thought than you might expect. The trick to mastering an uphill or downhill shot is all about bending at the hips and waist, and is an archery tip that you can master very quickly.\nThe proper technique for mastering a shot such as this, regardless of the angle, is draw the bow back as you would normally on level ground. Once you have your anchor point set, bend at the waist toward your target. This method will ensure that you maintain your form and your anchor point, which is critically important in maintaining your accuracy.\nTip 2. Keeping the Time\nShot timing is an important part of being an effective archer. From the time that the bow comes to full draw to the time the arrow leaves the bow is different for everyone. However, everyone has the window of 3 to 4 seconds when the arrow needs to be released. Push it too far one way or the other, and your rhythm and form can be off which can greatly affect your accuracy. Why is shot timing relevant to the topic of hunting in rugged terrain? When you have hiked all day and you have finally worked to within bow range of your target, the adrenaline can be pumping. As a result, you will most likely have a tendency to rush the shot. It is critically important that you remain patient and make sure that you are calm and ready to make the shot before drawing your bow. This will help you keep your shot timing as consistent and effective as possible. You want to do all you can to make that first shot count, it may be the only opportunity you will have.\nTip 3. Reduce Your Target Panic\nHopefully you are reading this months or weeks out from your western or high country hunt. If that is the case, taking the time now to reduce your target panic could drastically increase the chance that you make a well placed shot on the game animal your pursuing. Rugged terrain, long distance shots, high wind, and threading the needle through brush can, and probably will, be encountered on your hunt. If you have even the slightest bit of target panic at home, it will be compounded on the mountain. If left uncorrected, this feeling of anxiety and fear of poor shooting can spread to every time you draw your bow back. If you think it’s frustrating not hitting your mark on the target in your backyard, you will reach a new level of embarrassment and frustration when you miss your mark on your big hunt! So what can you do to fix it before it gets to that stage? Check out the archery tip video below.\nTips 4. Take a Hard Look at Your Hunting Gear\nArchery hunting in rugged conditions can be extremely hard on you and your archery equipment. Automatically assume that your equipment will take a few bumps and knocks along the way. Therefore it is critically important that everything from your optics and pack, to your bow, arrows, and other hunting gear is durable enough to withstand the abuse. The last thing you want is to hike uphill for several hours and finally get in a position to make a shot, only to find your archery equipment damaged and unusable. If you find yourself heading to the high country for the very first time, do your homework and take some time to research the area. This can help you get a feel for exactly what you will be facing when you step out of the truck and can help plan ahead and ensure that your hunting gear and archery equipment are up for the challenge!\nIf you have the opportunity to hit the high country with your archery equipment, toss your bow and hunting gear in the truck. Archery hunting in these landscapes can offer some of the most exciting experiences that an archer could ever ask for, and if you keep these 4 simple bow hunting tips in mind, you will set yourself up for success!']	['<urn:uuid:f3e901ec-4157-45b3-89f0-2fd7ae33144e>']	open-ended	with-premise	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-12T13:53:09.865574	26	91	969
44	storytelling methods indian classical performance	Indian classical performance uses various storytelling methods. In puppetry, stories are told through different types of puppets - string, shadow, rod, and glove puppets - drawing from folklore, mythology, and local legends. The puppeteer gives puppets human-like qualities including speech, singing, dancing, and behavior. In Kathakali, storytelling relies on Bhava/Rasa (facial expressions and eye movements), Mudras (hand gestures), Taalam (drum beats), and Ragam (classical voice notes). The performances typically present stories from epics like the Gita, Ramayana, and Mahabharata, with elaborate costumes and makeup enhancing the narrative.	['Indian puppetry is a centuries-old art of amusement. How did it originate? What are the different classifications of Indian Puppetry? Read further to know more.\nPuppetry is a form of visual animation. Due to the engaging nature of the experience and the low production and animation costs, it is a favorite among independent artists. This form of entertainment gives unrestricted freedom to artists in design, colour, and movements.\nThe puppeteer employs their talents to give the inanimate puppet human-like speech, singing, dancing, and behaviour.\nIt is regarded as one of the earliest genres of storytelling.\nOrigin of Indian Puppetry\nSeveral references to marionette theatre from around 500 BC have been found. The discovery of puppets with sockets at the excavation sites of Harappa and Mohenjo-Daro suggests that puppetry was a well-liked art form at the time.\nIn the Sangham age, Silappadikaram, which was composed in the first and second century BC, as well as the Mahabharata both mention puppetry.\nAlong with being an artistic medium, puppetry has philosophical significance in Indian culture. In the Bhagavad Geeta, God is compared to a puppeteer who manipulates the universe with the three cords Satta, Raja, and Tama.\nA broad variety of puppetry traditions have developed throughout India, each with its own distinct style of puppets.\nFolklore, mythology, and local legends served as sources of inspiration. Puppetry has been infused with other artistic mediums, including painting, sculpture, music, dance, and theatre, creating a distinctive form of artistic expression.\nHowever, this creative genre has been steadily diminishing in recent years because of a lack of devoted fans and financial uncertainties.\nClassification of Indian puppetry\nPuppetry in India can be classified into four categories:\n1. String Puppet\n2. Shadow Puppet\n- Togalu Gombeyatta\n- Tholu Bommalatta\n3. Rod Puppet\n- Putul Nachh\n4. Glove Puppet\nIn Indian culture, string puppets are also referred to as marionettes.\nThe puppets are typically chiselled wooden replicas that are eight to nine inches long.\nOil paint is used to colour the wood and add other facial features such as eyes, mouth, nose, and other facial traits.\nLittle wooden pipes are connected to the body to create the limbs.\nThe body is then stitched together and covered in brightly coloured little clothing.\nTo make it look more lifelike, tiny diamonds and other decorations have been added.\nThe strings that are tied to tiny holes in the hands, head and back of the body are moved by the puppeteer.\nEither leg, arm, and shoulder, as well as the lower back and each side of the head, are connected by strings. A hand controller in the form of the letters H or X is attached to the strings. In other instances, additional strings are connected to various parts of the marionette’s body.\nThe most prominent examples of string puppets are:\nKundhei is the name of the string puppets of Odisha.\nThey are made of light wood, and their skirts are long.\nThe puppeteer can move around with more ease because the puppets have more joints.\nThe strings are held together by a triangular prop.\nThe Odissi dance is prominently featured in Kundhei puppet shows.\nKathputli, a traditional string puppet from Rajasthan, derives its name from the Hindi terms for wood and doll, respectively, “Kath” and “putli.\nThe puppets wear colourful traditional Rajasthani clothing.\nThe presentation is accompanied by a dramatic folk music score, and the puppeteer’s finger is attached to the strings.\nThe absence of legs on the puppets is a defining characteristic.\nPuppetry called “bommalattam” has its roots in Tamil Nadu.\nIt combines elements of rod puppetry and string puppetry.\nThe puppeteer wears an iron ring on his head that is attached to the strings.\nWith some standing up to 4.5 feet tall and weighing up to 10 kilogrammes, the Bommalattam puppets are the biggest and heaviest marionettes in India.\nThe four distinctive stages of the Bommalattam theatre are Vinayak Puja, Komali, Amanattam, and Pusenkanattam.\nIt is a traditional puppet show from Karnataka.\nThey are modelled after the many characters from the Yakshagana Theatres.\nOne noteworthy feature of this puppet is the use of more than one puppeteer to control the puppets.\nShadow puppetry has a long history in India and has been handed down through the generations.\nFlat figures made of leather are used as shadow puppets.\nThe miniatures are painted identically on both sides of the leather.\nOn a white screen, puppets are positioned, and light is flashed on them from behind to cast a shadow.\nThe figurines are altered such that the silhouettes they produce on the white screen tell a compelling story.\nShadow puppet tradition is still prevalent in Tamil Nadu, Kerala, Andhra Pradesh, Karnataka, and Odisha.\na few well-known examples of shadow puppetry:\nIt is the renowned shadow theatre of Karnataka.\nA distinctive feature of Togalu Gombayetta puppets is the variation in puppet size based on social rank, with enormous puppets portraying monarchs and religious leaders and smaller puppets representing the underprivileged and slaves.\nThis style of shadow puppetry is the most dramatic, and it’s very well-liked in Odisha.\nThe puppets made of deer skin are posed in dramatic and bold.\nSince they don’t have any joints, learning this art is very challenging.\nIt is common to employ puppets that are not human, such trees and animals.\nBecause they have acquired in-depth instruction in their field, the Ravanchhaya artists are able to produce poetic and delicate theatrical narratives.\nIt is the shadow theatre of Andhra Pradesh.\nWith a classical musical background, the presentation focuses on legendary and holy stories from the Epics and Puranas.\nThe puppets have different colours on both sides and are larger.\nIn Eastern India, it is most often used. Rod puppet performances are well-known in West Bengal and Odisha.\nThese puppets are controlled by the puppeteer with the help of rods.\nThree joints normally make up these puppets.\nBoth hands are connected to the rods at the shoulder, and the principal rod supports the puppet’s head, which is connected to the neck.\nThe primary rod is concealed by the puppet’s attire. The action rods are connected to the puppet’s hands.\nThe puppeteer creates movement by moving their hands.\nBamboo, rice husk, and hay are used to create the puppet’s body and hands. The ingredients are mixed together and formed into the appropriate shape.\nThe following are a few well-known instances:\nIt is a typical rod puppet from Bihar.\nThe puppets often have no joints and are made of wood.\nIt is the customary rod puppet dance of the Bengal-Odisha-Assam region.\nTypically three to four feet tall, the figures are dressed as Jatra characters.\nDuring the performance, a musical group of three to four musicians uses a harmonium, cymbals, and tabla.\nOther names for glove puppets are hand, sleeve, and palm puppets. They are little figurines with a head, arms, and a skirt that is long and flowing.\nAlthough there are notable exceptions, most puppets are made of fabric or wood.\nThese puppets look like limp dolls, a talented puppeteer can make them move in a number of ways.\nThe head is made of papier-mache, linen, or wood, and two hands protrude from right below the neck. The rest of the body is covered with a long, flowing skirt.\nThe human hand manipulates the puppet by placing the first finger on the head and the middle and thumb on the puppet’s two other fingers.\nglove puppets are a common practice in Kerala, West Bengal, Uttar Pradesh, and Odisha\nIn Odisha, glove puppet shows focus on Radha and Krishna stories, in contrast to Uttar Pradesh where they primarily address societal issues.\nThe traditional glove puppet show called Pavakoothu is presented in Kerala.\nIt developed in the 18th century as a result of the influence of Kerala’s renowned classical dance-drama known as Kathakali on puppet shows.\nA puppet in Pavakoothu can be between one and two feet tall. Wooden arms and a wooden head are joined by thick fabric that has been cut and sewed into a small bag-like structure.\nThe puppets’ faces are adorned with paint, tiny pieces of thin gilded zinc, peacock feathers, and other decorations.\nThe musical instruments used during the concert were chenda, chengila, ilathalam, and shankh .\nIn the majority of the world’s areas, puppetry has been a crucial component of information exchange. Puppetry combines elements from a variety of artistic mediums, such as literature, painting, sculpture, music, dance, and theatre, and it gives pupils a creative out.\nArticle Written by: Aryadevi', 'Kerala Chronicles Part III. The saga of a dying legacy-Kathakali\nPrelude : A steady flame from a brass lamp illuminated the small, dim-lit amphitheatre with its soothing glow. A lingering fragrance of mildly scented incense sticks filled the room. A gentle symphony of the flute, tabla and sitar played in the background. Three plump men took to the centre of the stage. Holding a small mirror in one hand, and a brush in the other, they began painting their faces in green and orange, emphasising the eyes and brows with thick black outlines.\nA fragile man wearing a ‘mundu’* (supposedly, the make-up Master) perched at a corner with a cup filled with thick white paste, some cloth and a pair of scissors. One of the three artists, conceivably the senior, touched the feet of the Master with due respect and then lay in front of him. With utmost concentration, the Master created a beard by applying the white paste (made of rice and water) on to the layers of cloth strips, then carefully secured it to the artist’s jawline. The Master then swiftly manoeuvred his brush to draw delicate outlines and intricate designs to complete the look. The senior artist had dozed off during the task. After about an hour and a half, the session concluded and the faces disappeared back stage.\nThe Beginning :A large curtain was raised on the podium. Two drummers holding a pair of cane sticks each, secured the Maddalam* and Chenda* around their waists. Kathakali kicked off with the effortless beat of drums. A 60 year old man with his voice as smooth as silk sang verses in core classical ragas with precision. As the tempo gained momentum, the curtains dropped to reveal the main character of the play (in this case, the villain!). He wore a white pleated silk frock that resembled an oversized umbrella around his waist. His bare chest hid underneath a canopy of ornaments and his head wore a huge ‘Kireedam’*. I was amused by the long, conical silver nails that he wore and the bronze ghungroos that danced in his feet. His bright green face gleamed with sweat while those red eyes seemed to be oozing blood. The striking make-up perfectly complimented the elaborate and extravagant costume. The character looked so ravishing, that I could barely pull my eyes off!\nThe parody: The ‘Kali’ or story, was based on ‘Keechakavadham’ aka ‘Killing of Keechaka’- an excerpt from the legendary ‘Mahabharata’. Story has it that during their exile, the Pandavas had taken refuge in the kingdom of Virata which was ruled by Keechaka. Here, they had to conceal their identities by assuming various roles. Keechaka was attracted by the beauty Panchali who had taken up the role of a chaperon. He continued his advances despite her resistance. Aggravated by his behaviour, Panchali complains to Bheema, her husband; who had assumed the role of a cook at the palace. Acting as per Bheema’s plan, Panchali invites Keechaka for a secret meeting one night. Assuming it to be Panchali sleeping on the bed, he approaches her, only to find himself in the iron-like clutches of Bheema’s arms who finally chokes Keechaka with his tight grip until he falls dead.\nThe applause : Kathakali had lasted for 90 minutes. With just three characters, it had succeeded in grabbing the nerves of its audience right till the end, metamorphosing into a power-packed dramaturgy of actions, expressions and emotions that changed with every blink of the eye. Panchali had exhibited impeccable feminine shades through her subdued gait and expressions. It was impossible to believe that behind the curtain of her attire, was a man, who with his versatility, could have put any woman to shame! Bheema had done justice to his role with the right balance of love, command and rage. Howveer, Keechaka was the undisputed show-stealer, taking the audience through an unprecedented journey of ego, power, lust, pride, dominance, seduction, failure, pain, surprise and suffering. The demeanor of his gorgeous costume, the agility of his gestures, the ease of his facial movements and his unmatched display of emotions had successfully transported the audience to a by-gone era. My heart had skipped a beat when Keechaka, towards his end, let out a heavy sigh before falling to the ground..\nKathakali is one of the oldest traditional dance forms of Kerala that stands out from the others art forms like Mohiniattam and Theyyam due to its elaborate costumes and makeup. Kathakali split into ‘Katha’ and ‘Kali’ simply means Story Play in Malayalam. The performances revolve around the depiction of short stories and instances from the Gita, Ramayana, Mahabharata and other epics. It is believed that traditionally, the prep used to take upto 4 hours but is now reduced considerably. Crushed natural stones, rice, seeds and sandal wood form the base for makeup. Interestingly, the eyes get their color from a tiny, harmless seed inserted into the lids just before the play begins. Kathakali places total emphasis on Bhava /Rasa (expressions of the face and eyes), Mudras (finger and hand gestures), Taalam (beat of the drums ) and Ragam(classical voice notes) that follow high and low intonations depending on the mood and context of the play. The female characters are mostly played by the men themselves and this transformation is amusing to watch! The very essence of Kathakali lies in its vibes and needs to be experienced vis-a-vis. No blog or you-tube video can do justice to it. Though the art centres of Kerala are pulling substantial crowd, the weight of preserving this dying legacy, however, rests on a few shoulders…\nSpecial performance credits :\nKeechaka(main character), played by Krishnan Namboodri\nPanchali, played by Sujeesh Krao\nBheema, played by Suresh Kumar\nSingers : Vijayan/ Sucheendran\nDrummers : Haridas, Rajeesh\nWhere : Kerala Kathakali Centre, Fort Kochi.\nWhat : Kathakali and other dance and martial art performances. Tickets need to be blocked in advance. Contact +91 048-422-15827\nWhen : Everyday 3 pm onwards. Ticket cost : Rs. 350 per head for Kathakali, 250 for Kalaripayattu\nDo’s: Meet and greet the crew backstage. Spread the word. Experience an adrenaline rush with Kalaripayattu (traditional martial art form) performance.\nMundu- White dhoti/ lungi\nKireedam : Crown\nMaddalam/Chenda : Percussion instruments used on Kathakali. Maddalam is barrel shaped drum played vertically, while Chenda is cylindrical and played horizontally.']	['<urn:uuid:2f2c4bc9-4fb8-4912-a267-655ce86638cf>', '<urn:uuid:9a405e36-ed33-49f6-81e0-eeba560e655e>']	open-ended	direct	short-search-query	distant-from-document	multi-aspect	novice	2025-05-12T13:53:09.865574	5	87	2466
45	What's the difference between self-efficacy's role in overcoming challenges versus resilience's role in bouncing back from adversity?	Self-efficacy plays a crucial role in overcoming challenges by affecting one's beliefs about their capability to make and sustain change, with individuals having low self-efficacy being less likely to successfully overcome situations. In contrast, resilience functions as an ability to bounce back from adversity and can be developed through various pathways, with resilient people specifically sharing three traits: finding meaning in life, believing they can influence outcomes, and believing they can grow from both positive and negative events.	['Overcoming: A Concept Analysis\nThis article provides an operational definition of overcoming as a very first step in the systematic analysis of the concept. Using the method described by Walker and Avant (2005). the authors identify the attributes and characteristics of overcoming and its theoretical and practical application to nursing. Sample cases from clinical research illustrate the concept further. Further nursing research needs to test the theoretical relationships inbetween overcoming and outcome variables.\nNurses often work with individuals and populations with complicated health and social problems, assisting them to promote health, whether in terms of their mental or physical states, their environments, or their social habits, lifestyles, and choices. This interactive process can be fraught with nuanced meaning and approaches that may differ inbetween patients and providers. In a latest qualitative probe exploring the lives of homeless mothers, for example, probe participants often spoke of “overcoming” their situations as a desired outcome (Gulteken, Brush, Baiardi, Kirk, & Lapides, under review 2010). The discussion that then ensured included measures to reach that aim (e.g. securing stable housing and employment and/or completion of or furthering education) and what services and support were needed to promote them. As data from the concentrate groups was analyzed, moreover, it was also apparent that the perceptions of need inbetween providers and service recipients was discordant; that is, homeless women identified and prioritized barriers and obstacles they needed to overcome differently from those anticipated by the providers. Thus, while “overcoming” conjured up photos of participants’ rising above an undesirable situation and moving toward brighter and better futures for themselves and their children, the term’s definition in the literature remains vague and variable in meaning. Often used interchangeably with terms such as resilience, survival, adaptation, or resourcefulness, overcoming has yet to be systematically explored or defined as a concept in nursing.\nUtilizing the concept analysis method described by Walker and Avant (2005). we explicate the meaning of overcoming and examine its attributes and characteristics. Sample cases from our research and practice with homeless families illustrate the concept further and help us develop an operational definition. The results of this analysis will enhance understanding of the concept and its theoretical and practical implications for nursing more broadly.\nDefinitions and Uses of the Concept\nAccording to the American Heritage Dictionary (2009). the word overcoming is derived from the Old English word, ofercuman, and means to get the better of; to defeat (another) in competition or conflict; to conquer, prevail over, or surmount; or to overpower or overwhelm, as with emotion. Synonyms such as vanquish, get through, best, hammer, conquer, and hurdle and antonyms: give in, give up, relapse, and yield, connote a process of winning over losing, success over failure, or surmounting rather than giving way to.\nCertain individuals have come to symbolize the concept of overcoming and serve as models of inspiration to others. For example, Helen Keller, in the face of seemingly insurmountable physical disabilities, went on to become a preeminent author and activist who penned the now famous “All the world is total of suffering. It is also utter of the overcoming of it” (Keller, 2000 ). Like Keller’s victorious navigation over blindness and deafness, so too have others overcome significant social barriers and individual adversity to achieve success (Davis & Sturdevant, 2002 ), better health (Cameron, 2005), or ensured survival (Penner, Ferdinand & Carter, 2009 ).\nThe process of overcoming has also been popularized in songs of protest, activism and/or spiritual awakening as well as in a host of self-help books from binge eating (Hirschmann & Munter, 2008 ) to problems in everyday life (Kushner, 2006 ). The Civil Rights movement’s key anthem, “We Shall Overcome,” indicates surpassing barriers to racial discrimination. The song’s lyrics were adapted from Charles Tindley’s 1900 gospel song, “I’ll Overcome Someday,” which describes surmounting temptation and the “thousands of snares set for me” through prayer and faith (cite). Tindley’s prayerful discourse mirrors references to overcoming in the Bible’s Fresh Testament, Book of John, where it is noted that “For whatsoever is born of God overcometh the world: and this is the victory that overcometh the world, even our faith” (I John I Four,Five). References such as these highlight that one’s capability to overcome is a process that necessitates willpower, internal strength, and motivation to switch an existing condition for another more enlightened or more freeing one.\nTypically portrayed as a difficult process, overcoming is an active and conscious effort, made willingly and in response to a desire to stir beyond one state to a better alternative or situation. In some instances, the process of overcoming leads to recovery and reparation from the issue such that the condition is no longer problematic (Henderson, 2010 ; Polcin, Korcha, Bond, Galloway, & Lapp, 2010 ; Van Vliet, 2009 ). Indeed, the terms “adaptation,” “resilience,” and “survival” have been used interchangeably to describe the process of overcoming.\nEarvolino-Ramirez (2007) defined resilience as the capability to bounce back or cope successfully despite substantial adversity, implying that there has been a deviation from a more desired norm to which one hopes to comeback. Tusaie, Puskar, and Sereika (2007) used the term when describing rural adolescents’ capability to cope with emotional distress, describing the process as “the capability to adapt better than expected in the face of significant adversity or risk” (p. 54). Thus, resilience implies a process of hurdling resistance and, in doing so, gaining strength against future stressors, challenges, crises, or trauma, much like a microbe develops resilience over time to an antibiotic and ultimately adapts to and survives its environmental conditions. Survival in the case of the microbe is the capability to live despite a life-threatening event but survivorship has also been associated with life-altering incidents such as sexual manhandle, violence, and homelessness (Bender, Thompson, McManus, Lantry, & Flynn, 2007 ; Peck, 2008 ). Adaptation and survival are thus consequences of resiliency (Hernandez, Gangsei & Engstrom, 2007 ) while resiliency is an significant individual characteristic in the process of overcoming.\nDefining Attributes and Definition of Overcoming\nDefining attributes, similar to signs and symptoms, are critical characteristics that help to differentiate one concept from another related concept and clarify its meaning (Walker & Avant, 2005 ). Three key defining attributes have been identified for the concept overcoming: (1) an capability to recognize or acknowledge that a behavior, situation, event, or problem exists and is undesirable, impeding, or unhealthy; (Two) demonstrated readiness and determination to switch or surmount the behavior, situation, event, or problem; and, (Trio) belief that efforts to switch or surmount the behavior, situation, event, or problem will improve one’s future life quality. Overcoming is thus defined as a deliberate and thoughtful process of switching or conquering a self-perceived problematic circumstance, challenge, or adversity in order to live a healthier and more satisfied future.\nWalker and Avant (2005) define antecedents as the events or attributes that must arise prior to a concept’s occurrence. In the process of overcoming, an individual must very first identify the existence of and need to switch a current behavior, situation, event, or problem. According to Bandura (1977). behavior switch and maintenance are a function of one’s expectations about the outcomes of engaging in a behavior and the expectation about one’s capability to execute that fresh behavior. Thus, outcome and efficacy expectations include beliefs about whether or not the desired outcome will occur and the individual’s perceived capacity to perform relevant tasks toward that aim (Bandura, 1977 ). Self-efficacy thus plays a significant role in overcoming; individuals need to believe in themselves and their capability to make and sustain switch in their situations in order to overcome that situation. It is generally accepted that individuals with low self-efficacy are less likely than those with high self-efficiency to consider overcoming their situations and, when they do, to be successful (Bandura & Locke, 2003 ; Stretcher, DeVellis, & Becker et al, 1986 ; Vancouver, Thompson & Williams, 2001 ; Yeo & Neal, 2006 ).\nSwitch is paramount to overcoming, which, as delineated by Prochaska and DiClemente’s (1982) Stages of Switch Model, is a process that evolves through five distinct phases and denotes one’s readiness to engage in overcoming an identified behavior, situation, event, or problem. The very first stage, precontemplation, is a time when there is no foreseeable readiness to switch one’s current behavior, situation, event, or problem, largely because the individual is not fully aware of the need for remedy. Stage two, or the contemplation stage, represents a period when a person gives serious thought to overcoming a behavior, situation, event, or problem but does not commit to act. Should this stage be met, an individual next moves to the prep stage, in which he intends to make necessary switches and then commences to incorporate petite behavior switches into his life. Still, it is not until the fourth stage, the activity stage, that individuals modify their behavior or environment to overcome their situations. Modifications in this stage are visible and often receive outer recognition from others. The final stage is where individuals work utterly hard to maintain their behavioral switch and prevent relapse of the behavior. It is significant to note that no matter how well-intended an individual may be, relapse and recycling through the stages occurs frequently and is a well documented part of the fight to overcome (Prochaska, DiClemente & Norcross, 1992 ).\nIndeed, the reality of relapse requires that an individual be resilient and supple, particularly since the process of overcoming is neither linear or absolute on very first attempt. Overcoming also requires that individuals have optimism and hope for a better future than the present and past lives that define them. It is this hope that serves as motivation for the difficult stages of switch, thus helping to stir the individual beyond adapting to or surviving a difficult situation to acquire a life of purpose and meaning. Social support also serves as motivation. Once switch is in progress, individuals must believe that their achievements are supported by significant others, agencies, or systems.\nFor optimum success in overcoming an identified source, therefore, individual characteristics must ally with environmental factors to support the process. Social factors that predict one’s capability to overcome include access to services that can assist them with their individual needs, family or friend support, and a broader community social network. Albeit the need for environmental support may vary with the degree and complexity of the issue, problem, or situation at arm, the individual needs to perceive that it is available and helpful in the process of overcoming. Cone and Waters (2006) described the process of reconnecting in their grounded theory examine of formerly homeless mothers and found that social interactions were critical to resolving homelessness. Likewise, Tischler (2008). examining the resettlement and reintegration practices of single homeless mothers after rehousing, noted that improving one’s physical surroundings (e.g. living away from violent neighborhoods and/or relationships) helped one maintain the capability to overcome homelessness. Their findings mirrored many of the issues reported by women in our explore sample (Gulteken, Brush, Baiardi, Kirk, & Lapides, under review 2010). For example, several participants in our examine had been homeless numerous times. Individuals suffering from substance addiction, caring for numerous children, and lacking intimate fucking partner, family, or friend support were particularly vulnerable to repeat homelessness. The inability to overcome the challenges of these component issues precluded the capability to overcome homelessness as an outcome.\nIn her meta-synthesis of qualitative research regarding homeless women, Finfgeld-Connett (2010) described homeless women as “ill-prepared to prevent and resolve homelessness” (p. 462) unless they were able to overcome the multitude of sophisticated interconnected intrapersonal, interpersonal, and environmental stressors that led them to homelessness in the very first example. She defined three stages necessary in the process of overcoming homelessness: crisis, assessment, and sustained act. Similar to the Switch Model (Prochaska & DiClemente, 1982 ), these stages were iterative and often difficult to maintain in the face of social, individual, emotional, and environmental barriers. As she put it, “women who successfully extricate themselves from a homeless existence overcome self doubt and fear and are able to rally enough self-esteem to sustain them through numerous ordeals (Finfgeld-Connett, 2010. p. 464). In other words, women needed to be resilient in the face of obstacles to housing stability, be hopeful that they would attain their goals of housing stability, and have the necessary support in place to do so.\nConsequences are those events or incidents that can occur as a result of the occurrence of a concept and that can often stimulate fresh ideas or avenues for research pertaining to certain concepts (Walker & Avant, 2005 ). Possible consequences of overcoming include an individual’s comeback to a more stable and better quality of life, finding hope and meaning in life, and moving beyond a difficult situation or circumstance toward a healthier and more satisfactory future. This is generally a positive process yielding positive outcomes.\nEmpirical referents are measurable ways to demonstrate the occurrence of the concept (Walker & Avant, 2005 ). There are no measures of overcoming, however, measures of related constructs are available that may help quantify the process and its outcome. Below, we elaborate on the empirical referents for categories of the related phenomena of resiliency, hope, self efficacy, and perceived social support on the process of overcoming.\nConnor-Davidson Resilience scale developed in response to low generalizability of resilience scales (Connor & Davidson, 2003)\nDeployment Risk and Resilience Inventory,\nSuicide Resilience Inventory\nRichardson Model Richardson 1990 & Richardson 2002 ,\n[Bartone et al. 1989; Wagnild and Youthfull, 1993] not widely used', 'Resilience is the ability to bounce-back from an adverse event. The more resilient a person is, the better his or her coping mechanisms will be in the face of a challenging situation.\nNot everyone copes with disturbing events in the same way. Some people suffer to such an extent that are unable to recover. Others suffer as well but recover quickly. Some seem to recover quickly but then have a relapse. And others manage to endure the temporary crisis and are able to move on to new challenges with apparent ease.\nWhat you will be glad to know is that there is plenty of evidence that suggests that resilience is not for exceptionally healthy or strong people but rather that it is common and can potentially be reached by a variety of different pathways.\nThe inner strength\nSince the beginning of the nineties, the bulky-sounding concept of resilience has caused a stir in behavioural research.\nThe word, derived from the Latin resilio (rebound, jumping back), actually comes from physics and refers to “the property of a material that enables it to resume its original shape or position after being bent, stretched, or compressed.”\nBehavioural researchers have adapted the concept and transferred it to the human being: resilient is the one who creates the psychologically emotional resistance and is able to “bounce back” from difficult experiences. This resistance does not mean, though, that a person does not experience distress – in fact, some emotional distress may be needed in the process of becoming resilient.\nThe good news is that, according to the American Psychological Association, resilience can be learnt and developed through changes in our behaviour, thoughts and actions.\nResilience: The immune system of the soul\nWhether you are resilient or not can’t be said in advance because it depends mainly on how life unfolds. It’s only when you are pushed to face a difficult situation that your resilience (or, on the contrary, your vulnerability) will emerge.\n“That which does not kill us makes us stronger”, said Friedrich Nietzsche, which implies that resilience is based on personal experiences or misfortunes, meaning the harder our life has been, the stronger or more resilient we become.\n“A Smooth Sea Never Made a Skillful Sailor”\nBut there are those who disagree with that vision and argue that misfortunes do not make you stronger, that love and care do. Research shows, for example, that traumatized children are more likely to be traumatized again, proving Nietzsche’s saying wrong (or, at least, not totally accurate); and kids who grew up in tough conditions became weaker, not stronger.\nMisfortunes do not make you stronger; love and care do.\nThe fact is, a serious illness, a car accident, the death of a loved one, the loss of job or any other fatality can also crush the strongest. Sociologist Bruno Hildenbrand found that crisis in human life were “not the exception, but rather the norm.”\nSo if negative events are not exceptional but a reality in most people’s life, then the focus should be on how we react to them: we can either respond with fight, flight… or we can freeze.\nIn the face of an adverse or challenging situation which we assess we can defeat or overcome, we go into fight mode. Our brain releases adrenaline and pushes us to fight – and potentially succeed – against that negative situation.\nOn the contrary, if we assess the situation as too dangerous and significantly stronger than us, we go into flight mode and try to escape as quickly as possible for the sake of our own survival.\nBut it can also happen that we may conclude that we can’t either defeat the situation or run from it. We feel utterly helpless and freeze.\n“Paralyzing psychological phenomena as phobias, panic attacks, obsessive-compulsive behaviors, and various anxiety states can frequently be understood as symptoms of a freeze response that never had the chance to “let go” or “thaw out” once the original experience was over”, explains Leon F Seltzer, PhD.\nThe more we go over our feelings of anger, sadness or fear, the more anger, sadness or fear we will feel. This is when mindfulness comes in handy. According to research, the more mindful a person is and the more mindfulness meditation the person practices, the more resilient the brain becomes.\nResearchers Badri Bajaj and Neerja Pande concluded that “Mindful people … can better cope with difficult thoughts and emotions without becoming overwhelmed or shutting down (emotionally)”. “Pausing and observing the mind may (help us) resist getting drawn into wallowing in a setback.”\nBut how can I become more resilient?\nMore and more evidence shows that resilient people have three common traits: they are committed to find meaning in their life, they believe that they can influence their surroundings and the outcomes of events, and that they can learn and grow from both positive or negative events. These three beliefs makes them more confident, which consequently helps them to cope better with distress.\nResilient people have 3 common traits: they have a sense of purpose, they believe that they can influence their surroundings and that they can grow from both positive and negative events.\nLearn from life’s setbacks\nTake difficulties as a chance for growth and avoid self-pity.\nWe grow with experience, and self-reflection helps us see what challenges we have already faced and mastered, reinforcing our belief that we can do it.\nAccept and Adapt\nThings do not always go the way we plan. Resilient people know it and accept it and are able and open to adapt. The sooner you accept changes in your environment or situation, the more likely you are to see defeats as chances for personal improvement.\nSee what you can do to make your situation at least a little bit better and do it. Do not let yourself be paralyzed by negativity. Find things to do to keep you active and to help you release tension, like drawing, writing, meditation, or exercising.\nBuild stable relationships\nWe are social creatures and relationships are crucial for our well-being. Having positive and supportive people in our social circle will always make a difference. In times of hardship, having someone to laugh with makes a big difference.\nWrite down your feelings\nWriting down our problems and thoughts can help in the healing process as we become more conscious or aware of them and are able to see things more clearly.']	['<urn:uuid:cd5f7653-80c1-45bc-a00a-0a55a1f4c582>', '<urn:uuid:4cb1d7f5-f685-4d42-848f-c8cf365c2225>']	factoid	direct	verbose-and-natural	similar-to-document	comparison	expert	2025-05-12T13:53:09.865574	17	78	3324
46	What's the relationship between content ROI and complaint rates after innovation?	Content marketing ROI is measured through multiple indicators including exposure (tracked via Google Analytics), social shares, backlinks, and leads/sales generated. Meanwhile, customer complaint rates serve as a key metric for measuring the success of customer experience innovations - a ratio less than 1 between complaints after vs before an innovation indicates the changes successfully enhanced customer experience. Both metrics help evaluate if marketing and innovation strategies are effectively improving customer relationships and satisfaction.	['March 7, 2017\nBusinesses need to invest a lot of money into marketing if they want to attract and retain customers. Marketers need to work to keep the customers engaged and entertained by posting regular content and analyzing their behavior and preferences relative to the brand and products.\nNot all customers offer equal value so it’s important for businesses to prioritize customers and demographics that offer maximum return on interest. For that, you need to calculate the customer lifetime value and come up with a content marketing strategy based on the data collected.\nWhat is Customer Lifetime Value?\nThe customer lifetime value is the approximate projected revenue a newly acquired customer might provide over their lifetime as a customer. This concept looks at the future value of the customer instead of the past profitability. Unlike other metrics that focus on short-term profits, the customer lifetime value encourages firms to focus on developing good relationships and associations with their customers. This ensures that customers get the best possible service and you have a base that will provide consistent revenue.\nThis metric will also help you decide how much you should reasonably spend on your marketing to get returns on your investment. Some businesses spend too much money on marketing and don’t get enough income from their acquired customers.\nHow To Calculate Customer Lifetime Value?\nThere are many ways to calculate customer lifetime value. Some of these methods lead to vague predictions that provide very little value. Other customer lifetime value formulas are more sophisticated and provide better results. There are several factors involved in determining the lifetime value so it’s a good idea to hire a professional to help you. Here’s a step by step method to determine the customer lifetime value:\n- Average Variables – Before you calculate the customer lifetime value, you need to determine the current value of each customer. You would have to create a group of customers. Five to ten customers should be a reasonable number to get an accurate average. Determine the average amount spent per visit and the average number of visits per week. The current value of the customer per week (a) would be the average spends (s) multiplied by average number of visits per week (c).\n- Identify the Constants –The next step is to determine the average customer lifespan(t), customer retention rate(r), profit margin for every customer (p), and rate of discount or interest rates of the discounted cash flow analysis (i). All of these variables are required if you want to calculate lifetime value (m).\n- The Formula – Most companies use a number of different formulas to get the best results. The traditional lifetime value equation is m(r/1+i-r). This formula will give a fairly accurate prediction of the future customer lifetime value equation. There are other, easier or less accurate ways to calculate the customer lifetime value and you can find them with a brief Google search.\nThe customer lifetime value is just one metric out of many that you should keep track of. The more information you have on your customer’s behavior and potential, the better your marketing plans will be.\nIf you find that your customer lifetime value is too low or that the customers have a short association with your brand, you can use marketing to improve the value. Customers directly associate with content so you should shift focus to content marketing.\nWhy Content Marketing?\nContent marketing doesn’t just lure customers to your website, but also helps retain them. Great content with relevant keywords will rank high in search engines and consistently draw traffic to your website. If you keep posting good content, you’ll develop a good reputation, which can help you improve customer value. After all, the customer that keeps coming back to your website and is engaged by your brand is more valuable than an occasional window shopper.\nHowever, content marketing isn’t as easy as it sounds because search engines have implemented stricter rules to control quality. You need to constantly improve and optimize your content to get the best results. Some business owners don’t realize the full potential of their content and fail to keep track of their campaign’s performance. You should measure content ROI regularly to determine if you’re on the right path.\nHow to Measure Content Marketing ROI?\nContent marketing shouldn’t really be measured in dollar value because that’s not its true purpose. This strategy is used to draw customers to your website and establish your reputation. The latter can’t be measured or tracked easily but the former requires basic analytics to determine.\nYou can determine the dollar value of content marketing ROIby comparing the amount of traffic each piece of content generates and the average revenue per customer on that batch of traffic. Here are some things you should measure when you want to determine ROI of the content:\n- Exposure – Measuring exposure is simply a matter of looking at the numbers in Google Analytics. This platform will provide all the information you need about when, where, and how your target audience reach your content. As the tracking code is placed on every page of your website, Analytics will tell you how many people visit your content page and also how many of them move on to visit other areas of your website. You should also keep track of your content published on other websites to determine the right level of exposure.\n- Social Shares – You should also keep track of social shares. If you’re not concerned with the dollar value of these shares, you can simply look at the number of people who have shared your content on different forms of social media. However, if you want to know the dollar value, just create post engagement ads on Facebook, Twitter, and other such social media platforms. Choose a big amount that fits into your budget and let the ad go live. People will click on these ads to like your content and that will allow you to determine the proper dollar value of your social shares.\n- Backlinks – If your content is interesting and informative enough, it will be used as research by other content creators. They will link back to your content and bring more traffic to your website. Any effective link building tool will help you determine just how many people link to your content and how much exposure you get from every link. If you hire an SEO expert to do link building for you, the amount you spend per link on average will be how much converting traffic it brings; this will help you measure ROI.\n- Leads and Sales –Measuring leads and sales that originate from your content is very easy, especially if you place internal links in your content to direct your prospects to products or services relevant to the topic mentioned. You can set Goals on Google Analytics to determine leads and sales your content generates and know the dollar value of ROI.\nA good balance between the customer value and the content marketing ROI shows that you’re on the right track with your marketing. You should keep an eye on the two metrics to ensure they continue to perform well.\nPosted In: Blog', 'Table of Content\nIntroduction for customer relationship KPIs\nCustomer retention and acquisition are two fierce grounds of enormous competition between business firms in the contemporary corporate world. An interesting fact cited by Semrush is that the probability of selling to an existing customer is around 50 percent more than selling to a new customer. This explains why businesses lay great emphasis on customer relationships and for that, they need to track their performance across customer service metrics. The key performance indicators that evaluate customer relationship management performance in the most comprehensive manner are listed below.\nList of customer relationship KPIs with calculators\n1. Customer Retention Rate\nThe customer retention rate is a direct measure of the number of loyal customers a company is able to generate. Customer retention is the ability of the company to turn customers into repeat buyers such that the customers make repetitive purchases of the company products against switching to the competitors. In quantifiable terms, it is the percentage of a company’s customers who stick with it because of factors like pricing, product, and customer service. The higher the customer retention rate the more thriving and successful a business will be.\nCustomer Retention Rate as a KPI\nCompanies integrate a number of customer retention strategies such as loyalty programs, loyalty programs, personalization, and many others. To gauge the success rate of the strategies for driving a high customer retention rate, it is an effective KPI. If the consumers feel connected to the company, the retention rate will increase.\nHow to calculate Customer Retention Rate?\nTo calculate the client retention rate, the following parameters are needed-\n- Existing customers at the beginning of the time period taken into consideration (S)\n- Total customers at the end of the time period (E)\n- Newly acquired customers in the corresponding time period (N)\nFurther, the client retention rate can be computed using the formula-\nExisting customers at the beginning of a year (S)- 500\nLost customers - 70\nNew customers - 60 (N)\nNumber of customers at the end of the year- 490 (E)\nThe retention rate = 86 percent.\nCustomer Retention Rate Calculator\n2. Average Number of Referrals Per User\nThe average number of referrals per user is the ratio of the total number of referrals extended by users or customers over the total number of users. A higher number of referrals per user is a positive measure for a company as it would imply a greater number of leads likely to be converted into sales. Customers refer other people for the products and services if they feel the product and the service is up to the mark and the company is not leaving any stone unturned.\nAverage Number of Referrals as a KPI\nCompanies around the globe focus on referrals as it is the easiest and cheapest way to increase revenue and customer base. According to marketing statistics, 80% of people trust referral advertisements. Thus, referrals are a game changer if implemented in the right way by a business. Various unique strategies for increasing referrals are used by business organizations. They offer benefits such as building relationships, excellent customer support, and many others in terms of success in customer service metrics. Thus, to measure the success of these strategies the companies can use the average number of referrals as a KPI.\nHow to calculate the average number of referrals per user?\nThe average number of referrals per user is yielded by the formula-\n|Total number of referrals made by all users/customers|\n|Number of users|\nThe total number of referrals - 2000\nTotal users of the business- 400\nThe average number of referrals per user will come = 5\nAverage Number of Referrals Per User Calculator\n3. Client Summit Attendance\nClient summit attendance is the quantitative value of the number of customers or clients that attend client events organized by an organization. It is usually represented as a percentage of the targeted client attendance at a given event.\nClient Summit Attendance as a KPI\nClient Summit Attendance can be used as a KPI for a number of reasons as the companies invest heavily in making an event successful. The companies set up a target number of consumers that would attend the event and the average cost per attendee should be the least possible. So a number of strategies are implemented to increase the event strength and to measure the success of the event strategies Client Summit Attendance can act as a great measure.\nHow to calculate client summit attendance?\nThe client summit attendance is yielded by the following formula-\n|Number of client attendees||x 100|\n|Total number of clients invited|\nTotal number of clients invited- 400\nInvitees turning up for the event - 150\nThe client summit attendance = 37.5 percent.\nClient Summit Attendance Calculator\n4. Customer Complaints\nThe proportion of customer complaints is a KPI that gives a company a clear idea of the effectiveness of its innovations that are aimed at optimizing customer experiences. It compares the number of customer complaints before the incorporation of a specific innovation and the frequency of customer complaints after the implementation of the innovation. A value less than 1 implies that a given innovation has been successful in enhancing the customer experience.\nCustomer Complaints as a KPI\nIf a company is having trouble with the customer complaints pouring in and as a result, there is an exodus of customers, certain things need to be done before this turns into a disaster. There are a number of ways the companies can innovate in customer experience, that are aimed to reduce the number of complaints and earn greater customer loyalty. These ways can be deploying new technology, setting up new communication channels, and so on. All these innovations will cost the company and to make sure that the innovation is successful, customer complaints KPI must be implemented.\nHow to measure the KPI related to customer complaints?\nThe variance in customer complaints before and after the execution of an innovation is given by the formula-\n|No. of customer complaints after innovation|\n|No. of customer complaints before innovation|\nCustomer complaints after innovation is implemented - 40\nCustomer complaints before the implementation of innovation - 75\nRate of customer complaints- 0.53\nCustomer Complaints Calculator\n5. Number of Social Media Followers\nToday, social media has become an amazing platform for companies and consumer services. The number of social media followers gives an account of the number of people or users that are associated with a business through its social media handles on platforms like LinkedIn, Instagram, and Facebook. It depicts the magnitude of customer engagement and indulgence a brand has on social media platforms. To add, it facilitates a comparative analysis of the engagement rates in two consecutive periods.\nNumber of Social Media Followers as a KPI\nCompanies want organic growth and the best way to get organic traffic is to have a big chunk of consumers following your brand on social media platforms. There are a number of strategies to increase brand following and companies need to invest their time and money to acquire genuine followers. The success of these strategies is directly proportional to the increase in the number of brand followers and to measure the success of these activities, the “Number of Social Media Followers Ratio” can be used as a highly relevant KPI.\nHow to calculate the KPI related to the number of social media followers?\nThe measure of the social media engagement of a brand is given by the formula-\n|Increase in social media followers in current period|\n|Increase in social media followers in last period|\nThe total increase in social media followers in the current period - 600\nThe total increase in the last period -450\nThe rate of increase in social media followers in these periods = 1.33\nNumber of Social Media Followers Calculator\n6. Open Rate\nOpen rate is a crucial measure that helps companies understand if their email campaign or email marketing strategies have worked well to engage and attract customers. It takes into account the No. of total emails sent by a company to customers or potential customers and the number of emails actually opened.\nOpen Rate as a KPI\nMost of the people in the world have a plethora of unopened emails, while companies spend a lot of effort in designing, drafting, and sending these emails. A number of strategies can be encompassed by the companies to increase open rate but in the case of email marketing, no fixed strategy can work for every company. Thus, companies need to implement a try and reject/accept method to choose the best strategy. To know the outcome of a particular strategy, the open rate KPI is the best tool that will determine whether the strategy is an accepted one or a rejected one.\nHow to calculate the open rate?\nThe value of the open rate is yielded by the following formula-\n|Number of emails opened|\n|Total number of emails sent|\nTotal number of emails sent to customers and potential clients - 1200\nNumber of recipients who opened the emails- 800\nOpen rate = 0.66\nOpen Rate Calculator\n7. Rate of Referrals Per Customer\nThis key performance indicator quantifies the level of satisfaction that a company’s customers have with its products and services, pricing, and the value offered to customers as part of their experience.\nRate of Referrals Per Customer as a KPI\nConsumer referral is one of the most worthwhile and effective customer acquisition strategies. As said above, a number of strategies are used to increase referrals, and to know the success rate of these strategies, the most effective way is to check whether there is an increase in referrals per customer or not.\nHow to calculate the rate of referrals per customer?\nThe rate of referrals per customer is computed using the following two formulas-\n|1. Referrals per customer =||Total No. of referrals in a given period|\n|Total No. of customers|\n|2. Referrals in a given time period =||Total No. of referrals in a given period|\n|Units of time in the given period|\nThe total number of customer referrals over a period of time-1500\nThe total number of customers in that period - 400\nRate of referrals per customer = 3.75\nRate of Referrals Per Customer Calculator\n8. Number of Support Requests Per Product\nThis key performance indicator quantifies the ease or difficulty that customers of a company experience in terms of using their products. A higher number of support requests per product will signify that customers are facing complex challenges in using a product while a lower number of support requests per product will depict ease of product use.\nSupport Requests Per Product as a KPI\nSupport requests need resources such as finance, time, human resources, and at the same time, there is a chance that there will be an increase in the customer attrition rate. Companies need to make the customer journey as easy as possible marked by positive experiences. In order to do that, companies can invest in a number of ideas such as product information videos, content clusters, customer self-service tools, and many more. To know the success of these measures, the number of customer support requests as a KPI can be highly beneficial.\nHow to calculate the number of support requests per product?\nThe following formula can be used to obtain the number of support requests per product-\n|Total number of service requests|\n|Total units of product sold|\nThe number of service requests received by a company for a product - 2000\nTotal number of units sold - 9000\nNumber of support requests per product = 0.22\nNumber of Support Requests Per Product Calculator\n9. Number Of Customers Per Employee\nThis KPI gives a quantifiable measure of the magnitude of workload per employee and also determines how many customers are assigned to each employee on average. In other words, it quantifies the availability of a company’s employee bandwidth for each customer.\nNumber Of Customers Per Employee as a KPI\nHuman resource cost is a big factor in the total costs of the companies. Companies would like to use human resources as effectively as possible and at the same time would like to provide excellent service to the customers, such that an effective number of employees are employed to treat customers with ease. Employees sometimes need to put efforts to increase the number of customers they are serving and companies need to know if their customers are treated effectively by the employees or not. Both can be checked by knowing the number Of Customers Per Employee.\nHow to calculate the number of customers per employee?\nThe number of customers per employee is calculated by the formula-\n|Number of customers that an organization is dealing with|\n|Number of employees serving the spectrum of customers|\nThe total number of customers served by a company - 220\nThe strength of the workforce is- 80\nThe value of customers per employee = 2.75\nNumber Of Customers Per Employee']	['<urn:uuid:36674706-bff2-4e70-9782-f1142e7c662c>', '<urn:uuid:e8b88cd5-95c9-4450-aa75-79294391b8f1>']	open-ended	with-premise	concise-and-natural	similar-to-document	multi-aspect	expert	2025-05-12T13:53:09.865574	11	73	3365
47	fsbpt mission statement protect public	The FSBPT Mission is to protect the public by providing service and leadership that promote safe/competent physical therapy practice.	['CE for Therapy has compiled a comprehensive database of 100’s of Physical Therapy Continuing Competence Providers. Link to Physical Therapy Continuing Education Provider Directory The Provider Directory offers literally 1000’s of Physical Therapy Continuing Competence Opportunities, Techniques, Methods, Certifications, Specializations and Topics.\nPhysical Therapy Continuing Competence\nCE for Therapy’s mission is to provide a centralized resource of all Physical Therapy Continuing Competence opportunities. This enables Physical Therapists/Physical Therapy Assistants to identify all relevant, current and cutting edge opportunities that are available to them.\nWe launched CE For Therapy in June, 2017, and are scanning for new Physical Therapy Continuing Education opportunities continuously. As a result, the directory on the website is always as up-to-date as possible. If you are aware of any additional Providers of Physical Therapy Continuing Competence that you think should be included, please contact us.\nCE For Therapy has found a lack of standards and conformity with regards to CUE/CCU activity regulation and certification. Consequently, most Physical Therapy Continuing Education providers list whatever approval they have obtained, if any, on their website or brochure. The APTA does NOT certify CEU/CCU activity. Several state APTA chapters have their own approval processes. Consequently, some states have reciprocity with other states. The ProCert system is offered by The Federation of State Boards of Physical Therapy. Link to ProCert This is the most centralized and standardized certification process for Physical Therapy Continuing Competence that CE for Therapy is familiar with.\nPhysical Therapy Continuing Competence – ProCert\nThe ProCert system awards whole-number Continuing Competence Units (CCUs) values. These CCU values reflect compliance with 14 Standards for Continuing Competence Activities that the FSBPT has developed.\nAny provider of a physical therapy continuing competence activity registered as a Vendor in aPTitude may submit activity information to the online ProCert system. Furthermore, registering and recording activities in aPTitude is also free. Submitting for ProCert certification is voluntary, but is beneficial to providers of continuing competence activities. ProCert certification renders the activity as recognized or acceptable by multiple jurisdiction boards as meeting those jurisdictions’ requirements for physical therapists and physical therapist assistants. It also promotes that activity as having met comprehensive standards for purposes of promoting the activity to prospective participants.\nThe list of ProCert accepting jurisdictions now consists of 32 jurisdictions. These jurisdictions include: Alaska, Arizona, Arkansas, California, Colorado, Delaware, District of Columbia, and Georgia. Hawaii, Idaho, Illinois, Indiana, Kansas, Kentucky, Michigan, Minnesota, and Mississippi.\nAlso included are: Missouri, Montana, Nebraska, North Carolina, North Dakota, Oregon, Pennsylvania, and Puerto Rico. Finally, the jurisdictions of South Carolina, Tennessee, Utah, Vermont, Virginia, Wisconsin, and Wyoming are also included on the list.\nSeveral other jurisdiction boards are updating rules/regulations or policies to reflect the acceptance or recognition of ProCert. Therefore, we will frequently identify CE providers in our Physical Therapy Continuing Education Provider Directory who have received ProCert Approval for their educational offerings.\nPhysical Therapy Continuing Competence -FSBPT\nThe FSBPT Mission is to protect the public by providing service and leadership that promote safe/competent physical therapy practice. The FSBPT Vision is to achieve a high level of public protection through a strong foundation of laws/regulatory standards. FSBPT uses effective tools and systems to assess entry-level and continuing competence. it also fosters public and professional awareness of resources for public protection. FSBPT’s areas of focus guides it in the planning and budgeting process by keeping it focused on what is essential to forwarding the mission of the Federation. The areas of Focus were developed over time through membership surveys, two FSBPT summits, strategic planning sessions of the board of directors and additional feedback from committees and staff. The six areas of focus are listed below.\nExaminations: To ensure the ongoing excellence, reliability, defensibility, security and validity of the NPTE and related examinations. Membership: To enhance the Federation’s value to its membership by developing and maintaining programs and services responsive to membership needs. States’ Rights, States’ Responsibilities and Professional Standards: To identify and promote effective regulation in physical therapy that ensures the delivery of safe and competent physical therapy care, while respecting states’ rights and responsibilities. Education: To provide and promote educational programs and products for board members, administrators, the public and other stakeholders. Leadership: To broaden the Federation’s leadership role and recognition within the regulatory, professional and related communities. Organizational and Financial Stability To ensure the long-term organizational and financial stability and viability of the Federation.\nPhysical Therapy Continuing Competence -FSBPT\nFSBPT is a dynamic organization that promotes collaboration and teamwork between its various constituencies to ensure the best possible outcomes. Its member boards are at the top of the organizational structure. Furthermore, member boards typically include professionals, public members and administrators.\nDelegate Assembly: Each member of a board elects a delegate, an alternate delegate and an administrator. These individuals attend the annual delegate assembly, which includes a meeting of the council of board administrators. Policy and direction is set and provided to the board of directors and FSBPT staff at this annual event. The delegate assembly elects the board of directors, who represent the 53 member boards as a whole.\nOn the board of directors, there will be current members of member boards, former members of member boards. Furthermore, there are administrators of member boards and public members. The public member position brings an important perspective to the board when it considers what is best for public protection. The board also provides ongoing leadership to the Federation through a strategic planning and goal setting process. The delegate assembly and board of directors also elect or appoint members to committees and task forces. These volunteers take the initiative on various issues facing member boards and provide practical recommendations to the board of directors. The link to the FSBPT home page is: http://www.fsbpt.org/\nCheck out our Pain Management Courses post!']	['<urn:uuid:31c8e705-fffa-48dc-90ee-3cfd2405bd35>']	factoid	direct	short-search-query	distant-from-document	single-doc	expert	2025-05-12T13:53:09.865574	5	19	960
48	safety effectiveness sbrt radiation therapy side effects comparison traditional radiotherapy	SBRT (including CyberKnife) has proven to be both safer and more effective than traditional radiotherapy. Studies show SBRT is effective at controlling cancer more than 90% of the time, compared to traditional radiotherapy's 50% effectiveness rate. SBRT delivers over 100 radiation beams from multiple angles with a 1-5mm margin around tumors, whereas traditional radiotherapy uses only 2-7 beams with a 20-30mm margin, leading to more damage to healthy tissue. Regarding side effects, SBRT patients mainly experience mild fatigue, with only 13% showing any side effects at all. These side effects are typically low-level and heal on their own in 75-80% of cases. Common radiation therapy side effects can include skin problems, fatigue, appetite changes, and emotional impacts, but these vary based on treatment area and individual response.	"['10 Years of Use Proves the Safety and Efficacy of SBRT for Lung Cancer\nAccording to researchers from the Cleveland Clinic Foundation, a decade of lung cancer treatment with SBRT has proven that this focused radiation therapy is not only effective for controlling the growth and spread of lung cancer, it can also limit radiation exposure for the patient. The researchers tracked the results of SBRT for inoperable, early-stage lung cancer from 2003 to 2013. During that time, a mere 13 percent of the patients studied demonstrated any side effects, and even among those that did, symptoms were usually minimal.\nFor the purposes of the study, patients received what the researchers dubbed the “50-in-5 regimen” of SBRT, which consists of a total of 50 Gy of focused radiation delivered over the course of five sessions. Between October 2003 and December 2012, 300 patients received the 50-in-5 regimen to treat a total of 340 non-small cell lung cancer lesions. The average patient was 74 years old and over half the patients studied were women. A little more than 18 percent were cigarette smokers, although most of the patients were considered inoperable for other reasons.\nThe majority of the patients only needed a single course of SBRT for lung cancer treatment. Treatments were administered daily over a five-day period. Fifteen percent of the patients needed one or more additional courses of SBRT because their cancer came back. The short course of treatment with SBRT and the effectiveness of the treatment are why so many patients now choose CyberKnife for non-invasive lung cancer treatment.\nHigh Efficacy, Low Toxicity\nThough researchers did find that SBRT was effective at treating non-small cell lung cancer, they did point out that only 47 percent of the patients were alive at the five-year follow-up, largely due to patients’ advanced age and the occurrence of other diseases that affect survival. While SBRT did eliminate the cancer within the lung, a significant percentage of patients experienced a return of cancer in another part of the body.\nNevertheless, Cleveland Clinic Foundation radiation oncologist Dr. Gregory Videtic called the treatment “an amazing technology for a population of patients who previously had no other options.” He believes that this non-invasive, focused radiation treatment could extend the life spans of up to 20,000 people each year by giving those who aren’t healthy enough for surgery another option.\nFurthermore, SBRT is one of the safest forms of cancer treatment. A mere 13 percent of the patients studied exhibited any side effects at all due to the treatment, and all of those were low-level, minor side effects. In 75 percent to 80 percent of the cases, side effects were minor enough to heal on their own, and within a short time frame. Previous studies seemed to suggest that SBRT was very safe, but this study is important because side effects from radiation treatment can sometimes appear several years after treatment ends. The length of the study period allowed the researchers to evaluate the long-term safety of the procedure.\nAccording to the results of a new 10-year study from the Cleveland Clinic Foundation, SBRT is effective and remains safe, even in the long term. If you or someone you love is suffering from inoperable lung cancer, this non-invasive procedure could help you overcome cancer with just one short round of treatment.\n5 Trigeminal Neuralgia Surgeries Compared\nTrigeminal neuralgia pain most often occurs when a blood vessel compresses the trigeminal nerve near the bottom of the brain. The resulting malfunction causes pain to shoot through the teeth, jaw, cheek, gums, lips, eye, or forehead on one side of the face. While episodes may be mild and brief, they are known to become more frequent and more severe with time.\nMedications may be used to relieve the symptoms of trigeminal neuralgia, but they can come with side effects that include double vision, nausea, dizziness, confusion, or drowsiness. Even if you don’t experience side effects, medications may lose their effectiveness eventually. Fortunately, there are multiple surgical options you can choose to permanently reduce or eliminate trigeminal neuralgia.\n1. Radiosurgery With CyberKnife\nCyberKnife radiosurgery for trigeminal neuralgia pain delivers focused radiation to the trigeminal nerve, damaging it and reducing or altogether, eliminating its ability to malfunction and cause pain. The procedure is one of the least invasive surgeries for trigeminal neuralgia pain, and, unlike some other procedures, it can be repeated if necessary. That’s important, because trigeminal neuralgia pain can return after surgery. CyberKnife for trigeminal neuralgia is gaining popularity because it’s an effective, non-invasive treatment that requires no incisions. More trigeminal neuralgia sufferers than ever are using radiosurgery with CyberKnife to relieve symptoms.\n2. Microvascular Decompression\nIn this more invasive procedure, a surgeon makes a small incision near the base of the trigeminal nerve and then opens up your skull in order to physically move aside any blood vessels that may be compressing the nerve. It may be necessary to ensure that the blood vessels don’t come back into contact with the nerve by separating them from the trigeminal nerve with a small implant. It may also be necessary to remove a vein or sever the trigeminal nerve itself. Though microvascular decompression is usually successful, it carries risks, including:\n- Facial numbness\n- Hearing loss\n- Double vision\n- Facial weakness\n3. Balloon Compression\nIn this procedure, the surgeon uses a hollow needle and catheter to insert a balloon near your trigeminal nerve where it protrudes from the base of your skull. Once the balloon is inflated, it causes enough damage to the nerve to stop the pain signals it sends. Like other invasive procedures for trigeminal neuralgia, balloon compression can cause facial numbness. You may also experience weakness in the jaw, which can be permanent.\n4. Glycerol Injection\nA glycerol injection for trigeminal neuralgia pain involves inserting a needle through the face and into the skull where the trigeminal nerve passes through it. Once the needle is inserted, your doctor will inject sterile glycerol in order to damage the trigeminal nerve and relieve any pain. The pain can return, however, and numbness of the face or tingling can occur.\n5. Radiofrequency Thermal Lesioning\nFor the first part of this procedure, you’ll be sedated as your doctor guides a hollow needle into the opening through which your trigeminal nerve emerges from your skull. He or she will insert an electrode through the needle and administer an electric current. Your doctor will then bring you out of sedation so you can identify when and where the electric current causes a tingling sensation. The information you give will help the doctor determine which specific nerve fibers to damage in order to eliminate your symptoms. You may need to repeat the procedure and there may be some facial numbness afterward, but it usually isn’t permanent.\nIf you’re thinking of getting surgery for trigeminal neuralgia pain, you need to know all your options. Many of the procedures carry risks, just like any surgery. But with CyberKnife, you can experience non-surgical relief of trigeminal neuralgia pain with minimal recovery time and fewer side effects.\nHow Does SBRT Cyberknife Compare to Traditional Radiotherapy?\nCyberknife is a form of targeted radiation therapy known as SBRT. SBRT, or stereotactic body radiation therapy, was adapted from central nervous system stereotactic radiosurgery, a treatment technique that has been used to treat tumors of the brain and central nervous system for over 30 years. The only real difference is that SBRT is used to treat tumors throughout the rest of the body instead of specifically in the brain.\nHow does SBRT compare to traditional radiation therapy? SBRT delivers radiation directly to the cancerous tissue, sparing the healthy tissue around it. As a result, it can be administered in fewer sessions, with fewer side effects, and with higher success rates.\nHow Cyberknife Works\nIf your doctor has recommended Cyberknife to treat your cancer, you may be wondering, “What is Cyberknife?” After all, it’s only recently that Cyberknife and other SBRT treatments have become popular for the treatment of tumors outside of the brain. Cyberknife delivers a highly targeted dose of radiation that kills cancerous tissue as effectively as surgery. So if you’re not a candidate for surgery, you may be a candidate for Cyberknife SBRT.\nSBRT Administers More Radiation Than Traditional Radiotherapy\nBecause it delivers radiation directly to the cancerous tumor while minimizing radiation exposure to healthy tissue, SBRT uses a much stronger dose of radiation than traditional radiotherapy. Traditional radiation therapy delivers two to seven beams of radiation, while SBRT delivers over 100 beams of radiation from a much higher number of angles. That means SBRT is much more powerful.\nWith conventional radiotherapy, it’s not possible to aim the radiation beams directly at the cancerous tissue — that’s why so much less radiation is used, to minimize the damage to healthy tissue. Because SBRT allows doctors to administer a much more potent dose of radiation, far fewer sessions are necessary. Traditional radiotherapy requires daily sessions for several weeks. SBRT requires only one to five sessions.\nCyberknife Is More Accurate Than Traditional Radiation Therapy\nBecause it’s able to target diseased tissue, Cyberknife SBRT is much more accurate than traditional radiation therapy. SBRT can deliver radiation to a margin of one to five millimeters surrounding a tumor. Conventional radiotherapy has a radiation delivery margin of 20 to 30 millimeters. This much wider margin means that conventional radiotherapy is more likely to cause healthy tissue damage and side effects like radiation pneumonia. With SBRT, the most common side effect is mild fatigue following treatment.\nSBRT Is as Effective as Surgery\nNot all tumors can be surgically removed. That’s why SBRT has long been used to treat tumors of the brain and central nervous system — these tumors are more difficult for surgeons to reach. Even when surgery is an option, it requires the removal of a margin of healthy tissue around the cancerous tissue. SBRT is just as effective as surgery for removing cancerous tissue from the body, but eliminates the need to remove healthy tissue.\nWhen compared to conventional radiation therapy, SBRT is much more effective. Traditional radiotherapy is effective about 50 percent of the time. SBRT, on the other hand, is effective at controlling cancer more than 90 percent of the time.\nIf you’re not a good candidate for cancer surgery or simply want a less invasive treatment option, consider Cyberknife SBRT. With SBRT, doctors can administer potent, targeted radiation therapy that kills your cancer without harming the rest of your body. Find out what SBRT can do for you.\nDon’t Let Depression Sabotage Your Breast Cancer Treatment\nBetween 9 and 25 percent of women with breast cancer will also be diagnosed with depression. Even according to the most conservative estimates, women with breast cancer are twice as likely as the general population to be diagnosed with depression. And that’s a big deal, because depression is more than just an emotional phenomenon — it causes physiological symptoms that can make breast cancer harder to treat, and significantly raise your rate of recurrence.\nIt’s not unusual to experience feelings of depression following a breast cancer diagnosis. Being diagnosed with breast cancer fundamentally changes your life, and can force you to re-evaluate your priorities. If you’re diagnosed with breast cancer and experience feelings of depression, seeking treatment for your depression can be a matter of survival.\nThe Link Between Depression and Breast Cancer\nThe reason so many women with breast cancer are diagnosed with depression is because the two disorders are linked. While doctors don’t yet fully understand how one condition contributes to the other, they do know that cancer cells produce chemicals that can cause depression symptoms. Once depression sets in, it can promote the spread or recurrence of cancer. A depressed woman who does not have breast cancer is more likely than her non-depressed counterpart to be diagnosed with the disease. A woman with breast cancer who develops depression can experience a 25 to 35 percent increase in recurrence rates.\nThat’s because depression is, at its core, an inflammatory disease. It interferes with the immune system to cause breast cancer as well as other diseases. In a study performed at the University of Miami’s Miller School of Medicine, researchers discovered that women who have been successfully treated for breast cancer retain breast cancer cells within their bone marrow. A later illness, like depression, diabetes, or obesity, can cause those cells to activate.\nFighting Depression Caused by Breast Cancer\nIf you’re experience depression during breast cancer treatment, you need psychotherapy in order to combat it. Many women say they benefit the most from talk therapy, which can help them figure out how to best cope with their disease and care for themselves emotionally. Antidepressants are another option, and most doctors recommend regular exercise to help breast cancer patients fight depressed mood.\nBreast cancer treatment can affect your energy levels. When you get radiation treatment for breast cancer, or have surgery, it can leave your arms and chest feeling sore and stiff. Doctors recommend gentle exercise, like walking, to boost energy levels, combat fatigue, and stave off depression. Gentle activities that stretch and strengthen the arms, like yoga or tai chi, can also help boost mood, improve muscle tone, and support recovery.\nYou should try to get at least two hours of moderate exercise per week — two hours of brisk walking, for example, has been linked with a 40 percent reduction in risk of death among breast cancer patients and survivors. Don’t overdo it; excessive exercise during or immediately after cancer surgery or other treatment could impair your recovery. Avoid any activities that raise your body temperature, like hot yoga, since these could increase your risk of lymphedema.\nMany women who are diagnosed with breast cancer also struggle with depression; if you’re one of them, get help. Not getting depression help could seriously impact the success of your breast cancer therapy, but getting depression treatment could promote your recovery and protect you from recurrence.\n3 Ways to Make Sure Your Cancer Treatment Plan Works for You\nA cancer diagnosis can be one of the most overwhelming to receive, and if you’re like many patients, you may feel rushed to make decisions about your treatment. While your doctor may want you to start looking at treatment options as soon as you receive your diagnosis, you’ll most likely have some time to think things over and decide for yourself what treatment plan will work best for you. Remember that your ultimate decision doesn’t have to be set in stone — if you change your mind about treatment midway through the process, that’s okay, too.\n1) Don’t Face the Decision-Making Process Alone\nChoosing a cancer treatment center and a treatment plan is a big deal, and you need support. Your doctor can offer you the support of his or her expertise, but you can also get support from friends and loved ones. A support group or counselor can also help.\nIt’s okay to not want to make all of your treatment decisions — many people leave some or all of these decisions up to their treatment team or a designated friend or relative. Some people don’t even want to know details about the treatment they’re receiving or their chances of survival. Alternatively, you may want the final say on any decisions regarding your treatment.\n2) Choose a Hospital or Treatment Center\nWhether you ultimately go with a specialized cancer treatment center, like our cancer center in Los Angeles, or a community or academic hospital is up to you. A large, specialized cancer treatment center will give you access to many different treatment methods and cancer specialists in the same building, and will make it easier for your treatment team to collaborate. However, if you live far from such an institution, a local community or research hospital may be the best choice. Some things to consider when choosing a hospital include:\n- Is this hospital convenient to my home, and if not, can I afford to travel to it?\n- Will I be able to undergo clinical trials at this hospital?\n- Does the hospital offer support groups for me and my family?\n- Will my insurance cover treatment here?\n- Does the doctor who will be in charge of my treatment have a good reputation?\nResearch your cancer treatment options carefully, and understand the differences in treatment approach between a cancer center and a general hospital.\n3) Keep Talking to Your Doctor\nYour goals for and feelings about treatment may change as treatment progresses. Most cancer treatment options cause side effects that can affect your quality of life; your doctor will be more than willing to offer palliative care to help relive these side effects. If side effects are too severe or you have second thoughts about your treatment decision, you’re allowed to change your mind. Treatment can affect your health, career, and personal life in ways you might not expect. It’s part of your treatment team’s job to help you cope with these changes.\nWhile making a decision about cancer treatment can be daunting, it’s not something you should have to do alone. Friends, loved ones, and a supportive treatment team can help you make the best decision for you, and help you ensure that you’re pursuing the right options throughout your treatment.', 'While radiation therapy itself does not hurt, there can be short-term side effects to contend with, which can affect your hair, skin, sleep, appetite and emotions, too. Side effects vary from patient to patient. Depending on how your body responds to therapy, you may have no issues or experience some mild discomforts. Yet, some people may have more serious side effects—it depends mostly on the treatment dose and the part of your body that is being treated.\nYour general health also can affect how your body reacts to radiation therapy, including whether you have side effects and what kind. Before beginning your treatment, discuss with your radiation oncologist the short- and long-term side effects that might arise. Read on for answers to questions patients often ask our doctors about what to expect during treatment:\nWill side effects limit my activities?\n“Not necessarily,” says Yale Medicine radiation oncologist Lynn Wilson, MD, who is the chair of Therapeutic Radiology and a professor of therapeutic radiology at Yale School of Medicine. “It will depend on what side effects you experience—and how severe they are. Many patients are able to go to work, keep house, and enjoy leisure activities while they are receiving radiation therapy.” Others find that they need more rest than usual and therefore cannot do as much. You should try to do the things you enjoy, as long as you don\'t become too tired. Your doctor may suggest that you limit activities that might irritate the area being treated. In most cases, you can have sexual relations if you wish. However, your desire for physical intimacy may be lower because radiation therapy may cause you to feel more tired than usual.\nWhy do I feel fatigued?\nDuring radiation therapy, the body uses a lot of energy healing itself. Stress related to your illness, daily trips for treatment, and the effects of radiation on normal cells all may contribute to fatigue. Most people begin to feel tired after a few weeks of radiation therapy. “Feelings of weakness or weariness will go away gradually after your treatment is finished,” says Dr. Wilson.\nYou can help yourself during radiation therapy by not trying to do too much. If you feel tired, limit your activities and use your leisure time in a restful way. Do not feel that you have to do all the things you normally do. Try to get more sleep at night, and rest during the day if you can.\nIf you have been working a full-time job, you may want to continue. Although treatment visits are time consuming, you can ask your doctor\'s office or the radiation therapy department to help by scheduling treatments with your workday in mind.\nSome patients prefer to take a few weeks off from work while they\'re receiving radiation therapy; others work a reduced number of hours. You may want to have a frank conversation with your employer about your needs and wishes during this time. You may be able to agree on a part-time schedule, or perhaps you can do some work at home.\nWhether you\'re going to work or not, it\'s a good idea to ask family members or friends to help with daily chores, shopping, child care, housework, or driving. Neighbors may be able to help by picking up groceries for you when they do their own shopping. You also could ask someone to drive you to and from your treatment visits to help conserve your energy.\nHow can I manage skin problems?\nYou may notice that your skin in the treatment area begins to look reddened, irritated, sunburned or tanned. After a few weeks your skin may become very dry. Ask your doctor or nurse for advice on relieving itching or discomfort.\nWith some kinds of radiation therapy, treated skin may develop a ""moist reaction,"" especially in areas where there are skin folds. When this happens, the skin is wet and it may become very sore. It\'s important to notify your doctor or nurse if your skin develops a moist reaction. You might find it helpful to seek care from an onco-dermatologist, a doctor who specializes in caring for skin problems cancer patients encounter.\nBe very gentle with the skin in the treatment area. Avoid irritating treated skin, which can compromise the stratum corneum (the skin’s outermost layer, which serves as a barrier to the outside world). When you wash, use only lukewarm water and mild soap. Don\'t wear tight clothing over the treatment area. It\'s important not to rub, scrub or scratch any sensitive spots. Also avoid putting anything that is very hot or very cold—such as heating pads or ice packs—on your treated skin. Don\'t use any powders, creams, perfumes, deodorants, body oils, ointments, lotions, or home remedies in the treatment area while you\'re being treated or for several weeks afterward (unless approved by your doctor or nurse). That’s because many skin products can leave a coating on the skin that can interfere with radiation therapy or healing.\nAvoid exposing the area to the sun during treatment and for at least one year after your treatment is completed. Be vigilant about sun protection, and wear sunscreen every day. Also opt wear protective clothing (such as a hat with a broad brim and a shirt with long sleeves).\nIf your skin does react, the majority of skin reactions to radiation therapy should go away a few weeks after treatment is finished. In some cases, though, the treated skin will remain darker than it was before, due to changes in the melanocytes where skin pigment (melanin) is produced in the irradiated area.\nHow can I prevent hair loss?\nRadiation therapy can cause hair loss—also known as alopecia—but only in the area being treated. For example, if you are receiving treatment to your hip, you will not lose the hair from your head. However, radiation to your head may cause you to lose some or all of the hair on your scalp. Many patients find that their hair grows back again after the treatments are finished, but accepting the loss of hair—whether from scalp, face, or body—can be a hard adjustment. The amount of hair that grows back will depend on how much radiation you receive and the type of radiation treatment your doctor recommends. Other types of treatment, such as chemotherapy, also can affect how your hair grows back. For example, if your radiation therapy is for palliative care, your hair probably will grow back slowly. However, if the goal of your radiation therapy is to cure rather than to relieve the symptoms of your cancer, then your hair may not grow back, and if it does, it probably will have a very fine texture.\nYour scalp may be tender after the hair is lost, so you may want to cover your head with a hat, turban, or scarf. Also, you should wear a protective cap or scarf when you\'re in the sun. If you prefer a wig or toupee, be sure the lining does not irritate your scalp. A hairpiece that you need because of cancer treatment is a tax-deductible expense and may be partially covered your health insurance. If you plan to buy a wig, it\'s a good idea to select it early in your treatment, so that you can more easily match the color and style to your own hair.\nDoes radiation therapy affect immunity?\nSometimes radiation therapy can cause low white blood cell counts or low levels of platelets. These blood cells help your body fight infection and prevent bleeding. If your blood tests show this side effect, your treatment might be delayed for about a week to allow your blood counts to increase.\nWill my appetite be affected?\nMany side effects can cause problems with eating and digesting food, but you always should try to eat enough to help damaged tissues rebuild themselves. It\'s very important not to lose weight during radiation therapy so that your body can heal. Try to eat small meals often and eat a variety of different foods. Your doctor or nurse can tell you whether your treatment calls for a special diet and a dietitian will have a lot of ideas to help you maintain your weight.\nIf you have pain when you chew and swallow, your doctor may advise you to use a powdered or liquid diet supplement. Many of these products, available at the drugstore without prescription, are made in a variety of flavors. They are tasty when used alone, or they can be combined with other foods, such as pureed fruit, or added to milkshakes. Some of the companies that make diet supplements have produced recipe booklets to help you increase your nutrient intake. Ask your dietitian or pharmacist for further information.\nYou may even lose interest in food during your treatment. Loss of appetite can happen when changes occur in normal cells. Some people just don\'t feel like eating, because of stress from their illness and treatment or because the treatment changes the way foods taste. Even if you\'re not very hungry, it\'s important that you make every effort to keep your protein and calorie intake high. Doctors have found that patients who eat well can better handle both their cancer and the side effects of treatment. For ideas on how to increase your appetite during treatment, click here.\nWhat side effects occur with radiation therapy to the head and neck area? Some people who are having radiation to the head and neck have redness and irritation in the mouth, a dry mouth, difficulty in swallowing, changes in taste or nausea. Try not to let these symptoms keep you from eating.\nOther problems that may occur during treatment to the head and neck are a loss of your sense of taste, earaches (caused by hardening of ear wax), and swelling or drooping of skin under the chin. There may be changes in your skin texture. You also may notice that your jaw feels stiff and that you cannot open your mouth as wide as before your treatment. Jaw exercises may help this problem. Report any side effects to your doctor or nurse and ask what you should do about them. If you are receiving radiation therapy to the head or neck, you need to take especially good care of your teeth, gums, mouth and throat. Side effects from treatment to these areas most often involve the mouth, which may be sore and dry. Here are a few tips that may help you manage mouth problems:\n- Avoid spices and coarse foods such as raw vegetables, dry crackers, and nuts.\n- Don\'t smoke, chew tobacco or drink alcohol.\n- Stay away from sugary snacks that promote tooth decay.\n- Clean your mouth and teeth often, using the method your dentist or doctor recommends.\n- Do not use a commercial mouthwash; the alcohol content has a drying effect on mouth tissues.\nWhat side effects occur with radiation therapy to the breast and chest?\nRadiation treatment to the chest may cause several changes. You will notice some of these changes yourself, and your treatment team will keep an eye on these and others. For example, you may find swallowing to be difficult or painful. You may develop a cough. Or you may develop a fever, notice a change in the color or amount of mucus when you cough, or feel short of breath. It is important to let your treatment team know right away if you have any of these symptoms. Your doctor also may check your blood counts regularly, especially if the radiation treatment area on your body is large. Just keep in mind that your doctor and nurse will be alert for these changes and will help you deal with them.\nIf you are receiving radiation therapy after a lumpectomy or mastectomy, it\'s a good idea to go without a bra whenever possible. If this is not possible, wear a soft cotton bra without underwires. This will help reduce the irritation to your skin in the treatment area. You may have several other side effects if you are receiving radiation therapy for breast cancer. For example, you may notice a lump in your throat or develop a dry cough. Or, your shoulder may feel stiff; if so, ask your doctor or nurse about exercises to keep your arm moving freely. Other side effects that may appear are breast soreness and swelling from fluid buildup in the treated area. These side effects, as well as skin reddening or tanning, most likely will disappear in four to six weeks. If fluid buildup continues to be a problem, your doctor will tell you what steps to take.\nWomen who have radiation therapy after a lumpectomy may notice other changes in the breast after the therapy. These long-term side effects may continue for a year or longer after treatment. The redness of the skin will fade, and you may notice that your skin is slightly darker, just as when a sunburn fades to a suntan. The pores may be enlarged and more noticeable. Some women report increased sensitivity of the skin on the breast; others have decreased feeling. The skin and the fatty tissue of the breast may feel thicker, and you may notice that your breast is firmer than it was before your radiation treatment. Sometimes the size of your breast changes—it may become larger because of fluid buildup or smaller because of the development of fibrous tissue. Many women have little or no change in size.\nYour radiation therapy plan may include implants of radioactive material a week or two after external treatment is completed. You may have some breast tenderness or a feeling of tightness while the implants are in your breast. After they are removed, you are likely to notice some of the same effects that occur with external treatment. If so, follow the advice given above and let your doctor know about any problems that persist.\nAfter 10 to 12 months, no further changes are likely to be caused by the radiation therapy. If you see new changes in breast size, shape, appearance, or texture after this time, report them to your doctor at once.\nWhat side effects occur with radiation therapy to the stomach and abdomen?\nIf you are having radiation treatment to the stomach or some portion of the abdomen, you may experience an upset stomach, nausea or diarrhea. Your doctor can prescribe medicines to relieve these problems. Do not take any home remedies during your treatment unless you first check with your doctor or nurse.\nWhat side effects occur with radiation therapy to the pelvis?\nIf you are having radiation therapy to any part of the pelvis (the area between your hips), you might have one or more of the digestive problems already described. You also may have some irritation to your bladder. This can cause discomfort or frequent urination. Drinking fluids can help relieve some of your discomfort. Your doctor can prescribe medication to deal with these problems.\nThere are also certain side effects that occur only in the reproductive organs. The effects of radiation therapy on sexual and reproductive functions depend on which organs are treated. Some of the more common side effects for both men and women do not last long after treatment. Others may be long-term or permanent. Before your treatment begins, ask your doctor about possible side effects and how long they might last.\nDoes radiation affect the emotions?\nNearly all patients who receive treatment for cancer feel some degree of emotional upset. ""It\'s not unusual to feel depressed, afraid, angry, frustrated, alone or helpless,"" says Dr. Wilson. ""Radiation therapy may affect the emotions indirectly through fatigue or changes in hormone balance, but the treatment itself is not a direct cause of mental distress.""\nMany patients help themselves by talking about their feelings with a close friend, family member, chaplain, nurse, social worker or psychologist with whom they feel at ease. You may want to ask your doctor or nurse about meditation or relaxation exercises that could help you unwind and feel better. American Cancer Society programs can provide support. Groups such as the United Ostomy Association and the Lost Chord Club offer opportunities to meet with others who share the same problems and concerns. Some medical centers have formed peer support groups so that patients can meet to discuss their feelings and inspire each other.']"	['<urn:uuid:1243ec1c-d7c5-4090-a46d-5c52a6e38bc0>', '<urn:uuid:48774300-f771-4a69-b2b0-d29108d8b21a>']	open-ended	direct	long-search-query	distant-from-document	multi-aspect	expert	2025-05-12T13:53:09.865574	10	127	5614
49	pipe insulation prevent freezing condensation heat transfer effectiveness cost benefits explain	Pipe insulation serves multiple purposes in heat transfer control. From a heat conduction perspective, the rate of heat transfer depends on thermal conductivity, temperature difference, and the area through which heat is being transferred. Practical benefits include preventing freezing pipes in winter and controlling condensation ('sweaty pipes') in summer, which could lead to mold damage. Different materials offer varying cost-benefit trade-offs - while increasing insulation thickness reduces heat transfer and provides greater energy savings, it also adds to project costs. The choice of insulation material should balance between effectiveness (like foam's maximum protection from temperature loss) and practical considerations (like rubber's ability to expand and contract).	"['Heat conduction is the process of transfer of heat energy from one point to another within a solid material or between different materials in physical contact.\nWhat is Heat Conduction?\nConductive heat transfer occurs when heat is transferred through a material without any motion of the material itself. The heat is transferred from molecule to molecule due to lattice vibration and collision of molecules, transferring heat energy from one molecule to the next. This mode of heat transfer takes place in a stagnant medium.\nConduction is the most common mode of heat transfer in solids, and it occurs when there is a temperature gradient within a solid material. The heat flows from regions of high temperature to regions of low temperature to equalize the temperature throughout the material.\nThe rate of heat transfer through a material by conduction is dependent on the thermal conductivity of the material, the temperature difference across the material, and the area through which heat is being transferred. In general, materials with high thermal conductivity, such as metals, conduct heat more quickly than materials with low thermal conductivity, such as plastics.\nConductive heat transfer can be modeled using equations like Fourier\'s law of heat conduction.\nFourier\'s Law of Heat Conduction\nConduction of heat in a solid wall is expressed using Fourier\'s equation for heat conduction,\nT: Temperature at a point in the wall\nk: Thermal Conductivity of wall material\nA: Cross-sectional area of the element around the point\nx: Distance perpendicular to the area element\nFor steady-state heat transfer, this equation becomes,\nQ: Heat transfer rate\nA: Area of the wall\nThis equation can be further developed to express temperature profiles in various geometries with one-dimensional heat transfer.\nThermal Conductivity Values for Metals\nCheck this post for the list of thermal conductivity values for metals that can be used for heat transfer calculations around different applications.\nHeat Transfer Through a Wall\nLet\'s take a case of heat transfer across a flat wall as shown in the figure below.\nAssuming that thermal conductivity \'k\' is independent of temperature and location and A is independent of location, as is the case for a solid wall with a constant cross-sectional area.\nCheck below posts for solution of sample problems for different cases of conductive heat transfer though wall.\nConduction across a flat wall\nDetermine the rate of heat transfer by conduction per unit area, by means of conduction for a furnace wall made of fire clay. Furnace wall thickness is 6"" or half a foot. Thermal conductivity of the furnace wall clay is 0.3 W/m·K. The furnace wall temperature can be taken to be same as furnace operating temperature which is 6500C and temperature of the outer wall of the furnace is 1500C.\nConduction across a composite wall\nDetermine the overall heat transfer by conduction per unit area occurring across a furnace wall made of fire clay. Furnace wall has a thickness of 12"" or a foot. The wall is insulated from outside. Thermal conductivity values for the wall and insulation materials are 0.1 W/m·K and 0.01 W/m·K, respectively. The furnace operates at 6500C. Average ambient temperature outside the furnace wall is 300C and allowable temperature on the outer side of insulation is 800C. If the air side heat transfer coefficient is 0.4 W/m2·K, calculate the minimum insulation thickness requirement.\nHeat Conduction Through a Hollow Cylinder\nFor the radial geometry of a hollow cylinder, the following equation expresses the heat transfer rate.\nThe integral of this equation from inner radius r1 to outer radius r2 represents the total heat transfer across the cylindrical wall.\nN = length of the hollow cylinder\nT1 and T2 are the inner and outer wall temperatures of the hollow cylinder.\nInsulation thickness calculation for a pipe\nThe insulation layer helps to minimize the heat loss from the fluid flowing through the pipe and ensure that it maintains its desired temperature, which can be critical in many industrial applications.\nThe primary purpose of insulation is to reduce heat transfer through the pipe, which is determined by the thermal conductivity of the insulation material. Therefore, the thicker the insulation, the lower the heat transfer rate and the greater the energy savings. However, increasing insulation thickness also adds cost to the project, so it is essential to strike a balance between the cost of insulation and the potential energy savings.\nCheck this post for calculation of insulation thickness for a pipe.', 'Pipe Insulation Types in Shakopee, MNpipe insulation >> minnesota >> shakopee >> pipe insulation types\nPipe insulation helps prevent freezing pipes in the winter and sweaty pipes in the summer. Condensation sweat on plumbing pipes will eventually cause mold damage to your house. Frozen pipes can result in considerable flooding destruction and are going to lead to expensive repairs. By insulating your pipes, you will save not only on troubles, but you could also decrease your electricity and water usage.\nPresently there are several types of pipe insulation on the market today. Among the most well-known types are foam, rubber, fiberglass, and a combo insulation comprised of foam and reflective foil.\nFoam pipe insulation is produced from closed cell polyethylene which offers maximum protection from temperature loss as well as condensation. It is widely regarded as the best choice for insulating pipes because it has antimicrobial properties, is dust and fiber free and is offered in lots of tubular dimensions that are self-sealing. Its shortcomings include the fact that it is inflexible and does not expand and contract neither can it be applied in contact with heat cables or heat tape.\nRubber pipe insulation is a heavy duty type of insulation that will tolerate contact with heat cables and tape and expands and contracts. It is a durable and a more energy efficient alternative that is also offered in self-seal and non-self-seal versions.\nFiberglass pipe insulation is used for cold and hot pipes and has a temperature degree tolerance from in between -20 F to 1000F keeping it well-suited for extremely high temperature pipes even in industrial locations. This type has a built in wrapping which secures around the pipes using a self-sealing lap. It comes in fiberglass thicknesses from 1/2″, 3/4"", 2"" to 3″.\nProbably the simplest kind of pipe insulation to install is foam and foil insulation. The one step process involves winding the self-adhesive insulation around the hot and cold water pipes. This particular type of pipe insulation is also ideal for lessening plumbing pipe rattling and dampening water pipe noises throughout the entire home or building. In contrast, other types of pipe insulation call for connecting the butt ends of the segments of pipe insulation together with pipe insulation tape which adds in one more procedure to the insulating process.\nUltimately, the most effective kind of pipe insulation is the one that matches your job and the kinds of pipes that you have. You will want to marry the pliability of the pipe (copper, pvc, pex) to the overall flexibility of the insulation material. Similarly, you will need a more long lasting pipe insulation material, such as rubber or foam in outdoor applications such as for ac condensers.\nIn the past, contractors utilized asbestos pipe insulation because of its insulating and heat tolerance characteristics. It is recommended to contact an asbestos abatement specialist to remove asbestos as the fibers present a very harmful health hazard. Abatement experts may recommend encapsulating asbestos-wrapped pipes with fiberglass rewettable pipe lagging as an alternative to asbestos pipe insulation removal.']"	['<urn:uuid:fbad7596-f0e4-4f82-938e-e97aede9fc70>', '<urn:uuid:4a02b155-8808-4d73-8d62-557fecd88cf7>']	open-ended	with-premise	long-search-query	similar-to-document	multi-aspect	novice	2025-05-12T13:53:09.865574	11	106	1243
50	Do cramps and PCOS symptoms improve with age?	Primary dysmenorrhea (menstrual cramps) typically improves as women get older and after giving birth. In contrast, PCOS symptoms persist even after menopause, continuing to affect metabolism and increasing risks for obesity, type two diabetes, and cardiovascular disease.	['Polycystic Ovary Syndrome also known as PCOS affects an estimated 7 million women in the USA alone and is the most common hormonal condition in women. Although it’s always been thought of as a reproductive health concern, it’s actually a complex condition that not only affects a woman’s ability to ovulate or conceive, but has powerful effects on a woman’s metabolism and weight. It’s much harder to lose weight if you have PCOS, and also far easier to gain fat. Women with the condition tend to carry weight around their abdomen, and have increased risks for type two diabetes, obesity and cardiovascular disease — even after menopause.\nThe symptoms can vary from woman to woman, and its estimated that 50% of women with PCOS are unaware that they have it. In fact, many women don’t realize they have PCOS until they struggle to conceive – but the hallmark signs may have been present since childhood or adolescence.\nPCOS is diagnosed if a woman has two out of three criteria:\n- Long spans between ovulation, resulting in long periods of time between menstrual cycles (often longer than 35 days).\n- Excess androgenic hormones like testosterone. These are found either in blood testing, or present on the skin with symptoms of hirsutism (coarse hair growth on areas typically seen in men such as the chin), cystic acne, or male-pattern hair loss from the scalp.\n- Small ovarian “cysts” on a pelvic ultrasound. These are not true cysts but rather follicles which house the eggs that haven’t been ovulated”. As you can see, “cysts” are not required to diagnose PCOS, but rather it’s a complex condition that affects the metabolism and hormones in women.\nOne of the most central factors in PCOS is insulin resistance. Insulin resistance is associated with abdominal weight gain, appetite dysregulation, difficulty losing weight, and chronic health conditions like type two diabetes. It can also show up on the skin, causing dark, velvety pigmentation and skin tags.\nAll About Insulin\nInsulin is a storage hormone that is secreted in response to elevations in blood sugar after we eat. Insulin is a hormone which signals the cell to take up glucose from the blood and it also blocks the breakdown of fat, since directly after eating we have plenty of available energy to burn.\nInsulin Resistance in PCOS\nInsulin resistance occurs with weight gain, or when excess energy is provided to the cells long term. Overloaded fat cells spill fatty acids into the bloodstream which causes inflammation. In this environment of excess energy, the cells become resistant to insulin, as they are already flooded with glucose. Women with PCOS develop insulin resistance far more easily than other women due to genetic factors.\nWith cells that no longer listen to the messages from insulin, the pancreas tries to compensate by making more insulin to keep blood sugar under control. The end result is that most women with PCOS have higher amounts of insulin after they eat, between meals, and even fasting at night. Typically, insulin levels should go down after meals but in insulin resistant people they spike higher, stay high for longer, and often never going down to a low baseline even while fasting.\nThe Food Insulin Index\nAs we’ve just learned, when we eat a meal, blood sugar rises and the pancreas responds by releasing insulin to store it away.\nCarbohydrates are known to increase blood sugar levels, so it makes sense that they also cause significant insulin release. The measure of the effect of carbohydrate-based foods on blood sugar levels is known as the glycemic index.\nAlthough the glycemic index has long been helpful for managing diabetes, insulin resistance and PCOS it has certain limitations.\nThere is a new index, which may be more useful, particularly for PCOS where high insulin levels wreak havoc in the body. The insulin index tells us how much a consumed food raises insulin levels, rather than glucose levels. It includes a variety of foods including carbohydrates, proteins, fats and combinations. Most of the research on the insulin index has been conducted by the same researchers at the University of Sydney who developed much of our knowledge on the glycemic index. As a result, evidence for the insulin index sits atop many years of intensive research in nutrition.\nAs mentioned, foods that rank high on the glycemic index are also high on the insulin index since insulin is released in response to increases in blood sugar.\nSurprisingly however, some of the foods ranking highest on the insulin index are in fact very low on the glycemic index, and don’t raise blood sugar levels much at all.\nDairy and Protein\nMost people are surprised to learn that proteins provoke insulin release. In fact, one of the most insulin spiking of all are the branched-chain amino acids found in dairy protein. These amino acids have the ability to enter the bloodstream rapidly and cause a surge of insulin release.\nAs an example, 1 cup of low fat fruit yogurt provokes more insulin release than two slices of white bread! Each protein rich food has different insulinemic properties, for example beef increases insulin levels more than chicken, and whey protein powder is one of the highest foods on the insulin index. Protein does however have benefits for our metabolism and should not be viewed as inherently bad – consumption of protein is associated with weight loss, and increased satiety.\nIt’s also been found combinations of carbohydrates and fats can synergistically contribute to high post-meal insulin levels.\nFood Insulin Demand\nThe insulin index tells us how much insulin will be released when we consume 239 calories of a food. The food insulin demand (FID), a related index, is a points based system representing the amount of insulin that we release after eating a certain quantity of food – an exceptionally useful tool we can use to plan meals.\nInsulin counts of a few commonly consumed foods, healthy and otherwise, in the Standard American Diet.\nRather than avoiding all foods that rank high on the food insulin demand, it’s far more helpful to structure a meal based on understanding the effects of food on our metabolism, particularly if a woman is already insulin resistant. Keeping insulin levels in check can help the cells to become more sensitive to this important hormone and help recreate normal post-meal insulin responses with appropriate lowering of insulin at fasting and between meals.\nAn optimal meal structure involves choosing a protein, healthy fat, and vegetables for each meal, with a lower insulin demand carbohydrate depending on the level of insulin resistance.\nAn example of a meal structure for a woman with insulin resistance.\nSpinach-avocado omelette served with blackberries\n- 3 organic free-run eggs\n- 2 cups of spinach, coarsely chopped\n- ½ medium avocado, sliced\n- ½ tsp turmeric powder\n- ½ tsp paprika to taste\n- Sea salt, Pepper to taste\n- In a medium bowl, whisk eggs and add turmeric, paprika, salt and pepper\n- Warm ½ tsp of coconut oil onto skillet\n- Pour eggs into skillet, place avocado slices and spinach evenly over the surface.\n- Cook on medium heat until sides are browned\n- Take pan out and place under the grill until the omelette rises up.\n- Serve with 1 cup of fresh blackberries on the side.\nThe insulin resistance and inflammation in PCOS affect every aspect of health from ovulation and fertility to the lifelong risks for obesity, type two diabetes, and cardiovascular disease. Understanding the effects of nutrition on metabolism can improve health for the many women with PCOS throughout their entire lifespan.', 'What is dysmenorrhea?\nPain associated with menstruation is called dysmenorrhea.\nHow common is dysmenorrhea?\nDysmenorrhea is the most commonly reported menstrual disorder. More than one half of women who menstruate have some pain for 1-2 days each month.\nWhat are the types of dysmenorrhea?\nThere are two types of dysmenorrhea: primary dysmenorrhea and secondary dysmenorrhea.\nWhat is primary dysmenorrhea?\nPrimary dysmenorrhea is pain that comes from having a menstrual period, or “menstrual cramps.”\nWhat causes primary dysmenorrhea?\nPrimary dysmenorrhea usually is caused by natural chemicals called prostaglandins. Prostaglandins are made in the lining of the uterus.\nWhen does the pain associated with primary dysmenorrhea occur during the menstrual period?\nPain usually occurs right before menstruation starts, as the level of prostaglandins increases in the lining of the uterus. On the first day of the menstrual period, the levels are high. As menstruation continues and the lining of the uterus is shed, the levels decrease. Pain usually decreases as the levels of prostaglandins decrease.\nAt what age does primary dysmenorrhea start?\nOften, primary dysmenorrhea begins soon after a girl starts having menstrual periods. In many women with primary dysmenorrhea, menstruation becomes less painful as they get older. This kind of dysmenorrhea also may improve after giving birth.\nWhat is secondary dysmenorrhea?\nSecondary dysmenorrhea is caused by a disorder in the reproductive system. It may begin later in life than primary dysmenorrhea. The pain tends to get worse, rather than better, over time.\nWhen does the pain associated with secondary dysmenorrhea occur during the menstrual period?\nThe pain of secondary dysmenorrhea often lasts longer than normal menstrual cramps. For instance, it may begin a few days before a menstrual period starts. The pain may get worse as the menstrual period continues and may not go away after it ends.\nWhat disorders can cause secondary dysmenorrhea?\nSome of the conditions that can cause secondary dysmenorrhea include the following:\n- Endometriosis–In this condition, tissue from the lining of the uterus is found outside the uterus, such as in the ovaries and fallopian tubes, behind the uterus, and on the bladder. Like the lining of the uterus, endometriosis tissue breaks down and bleeds in response to changes in hormones. This bleeding can cause pain, especially right around menstruation. Scar tissue called adhesions may form inside the pelvis where the bleeding occurs. Adhesions can cause organs to stick together, resulting in pain.\n- Adenomyosis-Tissue that normally lines the uterus begins to grow in the muscle wall of the uterus.\n- Fibroids–Fibroids are growths that form on the outside, on the inside, or in the walls of the uterus. Fibroids located in the wall of the uterus can cause pain.\nWhat tests are done to find the cause of dysmenorrhea?\nIf you have dysmenorrhea, your doctor will review your medical history, including your symptoms and menstrual cycles. He or she also will do a pelvic exam.\nAn ultrasound exam may be done. In some cases, your health care provider will do a laparoscopy. This is a type of surgery that lets your health care provider look inside the pelvic region.\nHow is dysmenorrhea treated?\nYour doctor may recommend medications to see if the pain can be relieved. Pain relievers or hormonal medications, such as birth control pills, often are prescribed. Some lifestyle changes also may help, such as exercise, getting enough sleep, and relaxation techniques.\nIf medications do not relieve pain, treatment will focus on finding and removing the cause of your dysmenorrhea. You may need surgery. In some cases, a mix of treatments works best.\nWhat medications are used to treat dysmenorrhea?\nCertain pain relievers, called nonsteroidal anti-inflammatory drugs (NSAIDs), target prostaglandins. They reduce the amount of prostaglandins made by the body and lessen their effects. These actions make menstrual cramps less severe. NSAIDs (Ibuprofen, Motrin, Aleve, and Naprosyn) work best if taken at the first sign of your menstrual period or pain. You usually take them for only 1 or 2 days. Women with bleeding disorders, asthma, aspirin allergy, liver damage, stomach disorders, or ulcers should not take NSAIDs.\nWhat types of birth control methods help control dysmenorrhea?\nBirth control methods that contain estrogen and progestin, such as the pill, the patch, and the vaginal ring, can be used to treat dysmenorrhea. Birth control methods that contain progestin only, such as the birth control implant and the injection, also may be effective in reducing dysmenorrhea. The hormonal intrauterine device can be used to treat dysmenorrhea as well.\nWhat types of medication can be used to treat dysmenorrhea caused by endometriosis?\nIf your symptoms or a laparoscopy point to endometriosis as the cause of your dysmenorrhea, birth control pills, the birth control implant, the injection, or the hormonal intrauterine device can be tried. Gonadotropin-releasing hormone agonists (Lupron) are another type of medication that may relieve endometriosis pain. These drugs may cause side effects, including bone loss, hot flashes, and vaginal dryness. They usually are given for a limited amount of time. They are not recommended for teenagers except in severe cases when other treatments have not worked.\nWhat alternative treatments help ease dysmenorrhea?\nCertain alternative treatments may help ease dysmenorrhea. Vitamin B1 or magnesium supplements may be helpful, but not enough research has been done to recommend them as effective treatments for dysmenorrhea. Acupuncture has been shown to be somewhat helpful in relieving dysmenorrhea.\nWhen is surgery done to treat dysmenorrhea?\nIf other treatments do not work in relieving dysmenorrhea, surgery may be needed. The type of surgery depends on the cause of your pain. If fibroids are causing the pain, sometimes they can be removed with surgery. Endometriosis tissue can be removed during surgery. Hysterectomy may be done if other treatments have not worked and if the disease causing the dysmenorrhea is severe.']	['<urn:uuid:de857891-07d3-4202-89ba-a9589c6104c9>', '<urn:uuid:5e78e9da-36f6-4195-9fee-049d4a16627b>']	factoid	direct	concise-and-natural	distant-from-document	comparison	novice	2025-05-12T13:53:09.865574	8	37	2226
51	how many trains can cross at same time	The bridge was built with a double line of rails, allowing two trains to cross simultaneously, with footpaths on either side.	['The Forth Bridge is one of the great icons of Scottish engineering and the greatest achievement of Sir William Arrol’s life. It’s massive steel structure, spanning the estuary of the River Forth from South Queensferry to North Queensferry in Fife, is famous throughout the world. It was built to provide the fastest route from London, up the east coast Edinburgh and on to the North of Scotland, and the most direct route possible meant spanning the two wide estuaries of the rivers Forth and Tay. Apart from having to build these bridges across large distances, these estuaries presented other major challenges to the bridge builder. The Queensferry site was chosen for the Forth Bridge as the small island of Inchgarvie would provide a solid rock base on which piers could be built. On either side of the island though, the water was fast flowing and up to 200ft deep, presenting problems in sinking the pier foundations. Also the two channels were busy with shipping and would have to be kept open to traffic during construction.\nOriginally, a design by Thomas Bouch for a steel suspension bridge was chosen to be built and William Arrol was selected as the contractor to build it. Arrol started preparatory work on piers for the bridge in 1878 but this stopped following the Tay Bridge disaster in December 1879. The subsequent inquiry had indicated that Bouch’s poor design had contributed to the collapse of the Tay Bridge and another of his bridges, the South Esk Viaduct, had also been found to be unsafe. Having lost confidence in Bouch’s work, the Forth Bridge Company officially abandoned his bridge design in 1881 and looked for an alternative. John Fowler and Benjamin Baker’s design for a steel cantilever bridge was chosen and the contract to build it was awarded to William Arrol & Company in December 1882. It was an ambitious project, the first structure of it’s size to be built of steel, and having the 2 longest spans of any cantilever bridge ever built.\nThe main structure of the bridge consisted of 3 cantilever towers, each with 4 gigantic steel tubes, 343 ft high, supported on a masonry pier. The steel tubes of the great cantilever arms extended from the base and top of each cantilever tower forming a triangular shape and on either side of the central cantilever these were joined by a central girder. These cantilevers arms and towers were strengthened by numerous lateral and diagonal girders and tubes forming an intricate network of criss-crossing steelwork. Towards the south shore the cantilevers of the superstructure were met by viaduct of 10 spans and 4 arches supported on granite piers and from the north shore, an approach viaduct of 5 spans with 3 arches supported on granite piers. Running across the centre of the entire structure were lattice girders supporting a double line of rails with a footpath on either side. To ensure that there was a minimum height of 150 foot under the bridge at high water level, a gradient was built into the bridge to allow passage of ships in two main channels on either side of Inchgarvie Island. As a result, the full length of the completed bridge was 1.6 miles.']	['<urn:uuid:b18c86da-4c72-4fc0-a6fe-e5facb416c62>']	open-ended	direct	short-search-query	distant-from-document	single-doc	novice	2025-05-12T13:53:09.865574	8	21	538
52	what happens companies buy expensive equipment	When companies make decisions about buying expensive equipment through capital budgeting, these decisions have long-term effects on the company's profitability and are typically irreversible. Once a high-value asset is purchased, it cannot be sold at the same prices. These decisions also directly impact the business's cost structure by committing the company to costs like interest, insurance, rent, and supervision. If the investment doesn't generate the anticipated income, it could increase expenses and lead to losses.	['Meaning of Capital Budgeting\nCapital Budgeting is a process used for evaluating the long term investments that are of capital nature. It helps in finding out potential investments and expenditures that will provide a better return to business. Capital budgeting is also known as the investment appraisal process as it aims at increasing the return of business by choosing the most profitable project.\nIt analyses and finds out whether it is worth to fund through the firm capitalization structure the long term investments like purchase or replacement of machinery, new plants and products and project related to research development. It is an important process which helps managers in deciding out the most profitable capital projects by comparing all cash inflows and cash outflows of the project. It makes the choice clear that which project should be accepted and which should be declined.\nCapital budgeting process involves: Identification of investment opportunities, then evaluating and choosing the most profitable investment, now capital budgeting and apportionment and at last review of the performance. The different techniques of capital budgeting used by business are Net present value, Payback period method, Internal rate of return, accounting rate of return and Profitability index. Capital budgeting is termed as a predominant function of management. Features Features of Capital Budgeting of Capital Budgeting is described below:\nFeatures of Capital Budgeting\nCapital Budgeting is related to taking decisions requiring large funds. It is a process used for selecting the high-value capital projects by the management. Managers use capital budgeting for properly analysing different investment opportunities and take decision with proper care.\nThe decisions taken through the capital budgeting process are irreversible in nature. This process requires making choices for large fund investment in different capital projects available. A decision once taken becomes difficult to be amended as it involves the allocation of large funds and affects company growth. High-value asset once purchased can’t be sold at the same prices and at the same time.\nThere is a high degree of risk involved in the capital budgeting process. Decisions taken in this process are concerned with future return and the future is uncertain. Future unforeseen like change in fashion and taste, technological and research advancement may lead to higher risk. It, therefore, involves critical analysis before taking any decision as there are a large amount of funds allocated by business through this process.\nLong Term Effect on Profitability\nCapital Budgeting decisions have long term effects on the profit-earning capacity of the business. It involves decisions regarding large investments providing return to business. Decisions taken through capital budgeting affects both current and future earning potential of the company. Any unwise decision may affect business growth adversely and may be fatal. Therefore capital budget is termed us utmost function for every business which has great influence over its profitability.\nImpacts Cost Structure\nThe decisions taken through the capital budgeting process have a direct impact on the cost structure of the business. Through decision taken in this process, business commits themselves to costs like interest, insurance, rent, supervision etc. If the investment taken does not generate the anticipated income for the business, then it would increase the cost expenses and lead business to losses.\nDecisions taken through the capital budgeting process are difficult in nature. Decisions taken here are regarding the future which is uncertain and may have many unforeseen. It, therefore, becomes difficult for managers to choose the most profitable investment providing better return in future.\nAffects Competitive Strengths\nCapital budgeting process directly influences the future competitive strength of the business. Decisions taken in this process are regarding the profit generating investments and affects the company growth. A right decision taken can lead the company to great heights whereas a wrong decision may become fatal for the business. Therefore capital budgeting directly influences the strengths and weaknesses of a business.']	['<urn:uuid:52acb381-85fe-4288-96ea-e084ab1e66db>']	open-ended	direct	short-search-query	distant-from-document	single-doc	novice	2025-05-12T13:53:09.865574	6	75	638
53	When did UCF start its football team?	UCF started its football team in 1979, with their first game being played on a September Saturday in Dade City against St. Leo College.	"['UCF Director of Athletics: 1976-81\n|Hall of Fame:|\nClass of 2008\nTo the players on the University of Central Florida inaugural football team, it all began on a dreary and rainy September Saturday in Dade City where the new Fighting Knights were set to play St. Leo College in the 1979 season-opener. However, many of the players would tell you it really started much earlier, in March, when they learned that the UCF athletics director was hosting a meeting for prospective college football players on the university\'s golf driving range.\nThere stood Dr. Jack O\'Leary in front of an assorted crew of over 100 prospective players. Some were talented and some were not; some came ready and seasoned, while some were just too dumb to know any better. The group would spend the afternoon performing an audition in agility and physical fitness.\nDr. John T. ""Jack"" O\'Leary was the school\'s first full-time athletics director, hired by the university\'s founding president, Dr. Charles Millican, in August 1976 when the campus was still known as Florida Technological University. At the time, O\'Leary\'s mission was to continue to build on the successes of the school\'s first AD, Dr. Frank Rohter, who had began the FTU athletics program in 1969.\nMuch of O\'Leary\'s legacy today resides with the football program he begun in 1979. Yet, several of FTU\'s early programs saw great success during his five-year tenure that stretched five years, 1976-77 through 1980-81. Despite budget restraints, the program was able to move from five sports in 1975 to 15 sports in 1981.\nDuring O\'Leary\'s tenure men\'s basketball qualified for four NCAA Division II Tournaments, with an appearance in the 1978 NCAA National Championship game. From 1976-80, women\'s volleyball played in five straight NCAA Division II Tournaments, winning the 1978 National Championship. The women\'s soccer program, led by a pair of future UCF Athletics Hall of Famers in Coach Jim Rudy and star player Michelle Akers, advanced all the way to the National Championship game in their 1981 inaugural season. Baseball also qualified for its first NCAA Tournament in 1979.\nEven though FTU had no varsity football program at the time he was hired, O\'Leary brought a wealth of college football experience with him nevertheless, having served as an assistant, head coach and administrator for nearly 25 years prior. This included the 1968-70 seasons under Paul ""Bear"" Bryant while earning his doctorate at the University of Alabama.\nThis experience proved beneficial a couple of years later in 1978 when the university\'s second president, Dr. Trevor Colbourn, took office and spoke of the importance of starting a varsity football program during his January 15, 1979 inauguration speech. Colbourn felt having football would increase the visibility of a young university that opened its doors just over a decade ago, in addition to exposing its recent name change from FTU to the University of Central Florida.\nA new charge was there for O\'Leary. Working with Bill Goldsby, who managed the athletics business office, O\'Leary now focused on raising the necessary funds to make football a reality. He lined up a deal to play in the Tangerine Bowl in addition to media partners, WDBO and WKIS, to air public service announcements and eventually game broadcasts. During these first years of the team, O\'Leary served as radio announcer for all of the UCF games, making all the long road trips, all the while continuing his regular duties as the Director of Athletics. The Gridiron Club was formed alongside the athletic department\'s Black and Gold Club, today\'s Golden Knights Club, specifically to fundraise for the football program. He organized flyers to be sent out to area high schools, junior colleges and current UCF students advertising tryout dates.\nA one-day ""blitz"" was held on June 13 by the Orlando Chamber of Commerce Sports Committee in June that raised an excess of $40,000 through area businesses. Along with money raised at a luncheon hosted by Senator George Stuart, UCF had built enough funds to start its first football season. A day later, June 14, an eight-game home schedule, dubbed ""Saturday Knights Live"", was announced along with a season ticket campaign that promoted ""1949"" prices: $13 for the four-game package, with single game tickets available for $4 each.\nAt first, O\'Leary took on the job of being the team\'s head coach because there was no funding to hire anyone else. He was also able to lure a staff of six volunteer assistant coaches who were already on campus going to graduate school. UCF would eventually be granted access to play in Division III, but that didn\'t matter. Area players were ecstatic that there was now an opportunity to play in front of a hometown crowd. When the group of prospective players met with O\'Leary for the first time, they knew history was about to be made. O\'Leary gathered the players to a half circle while holding a brown paper grocery bag he slowly pulled out a football uniform for display and proclaimed ""We are going to look like Notre Dame."" With black jerseys, gold pants and solid gold helmets, the team would be known as ""The Fighting Knights.""\nHowever, the task of managing an athletics program, coupled with building a football team, was daunting. As a result, O\'Leary tapped former pro quarterback Don Jonas, who was working as a promotions specialist with the City of Orlando, to become the team\'s first head coach, with Jonas agreeing to do so in a voluntary capacity. The coaching hire completed a rather quick turnaround in starting football at UCF, which would be granted access to compete at the NCAA Division III level, less then a year after Colbourn championed the cause. With no money to hire a coaching staff, O\'Leary and Jonas were fortunate to lure good coaches to help, with Bugsy Engelberg, Tommy Bland and Tom Murphy, to name a few.\nIn 1981, with the football program moving forward, O\'Leary had requested a reassignment to a faculty role in the Department of Physical Education where he could continue to his passion for teaching. He would go on to teach golf to University of Central Florida students, in addition to serving as a teacher and mentor to the Physical Education Department interns.\nTragically, Dr. Jack O\'Leary died suddenly on December 2, 1983. He had a massive heart attack while driving his daughter to school. He was survived by his wife Ann, and their three children - Mike, Tom and Jackie.\nBorn and raised in Portsmouth, NH, O\'Leary would go on to serve as a lieutenant in the Army during the Korean War, where he did one tour of duty. He received both his Bachelor and Masters degrees from Colorado College in addition to playing varsity football and coaching JV basketball. From there he went to St. Mary\'s of the Plains College where he was the AD, as well as head basketball and football coach. At Tulane University, he was head football coach for the freshman and JV squads and offensive coordinator for the varsity squad. He went on to the University of Alabama where he received his Doctorate degree, and was an assistant football coach and recruiter for Paul ""Bear Bryant. After that O\'Leary served briefly as Athletic Director at Miami-Dade Community College before moving on to fill the same role at Colorado State University.']"	['<urn:uuid:6745cfbd-ad97-4fa3-99f2-82c9a9c9d400>']	factoid	direct	concise-and-natural	distant-from-document	single-doc	novice	2025-05-12T13:53:09.865574	7	24	1219
54	What causes king tides to rise, and how is sea level measured?	King tides rise due to several factors: melting polar ice caps raising ocean water volume, a warm water patch called 'the Blob' in the Pacific, and the El Niño system affecting weather patterns. Sea level is measured through tide stations monitored by NOAA, which have been recording fluctuations off San Diego since 1906, and through Digital Terrain Models that assign heights to land pixels for predicting water levels.	"[""Stay up to Date\nSubscribe to Ry Rivard's bi-weekly environmental news roundup (every other Monday)\nWhen a portion of the street near Midway Drive and Barnett Avenue in the Midway district flooded at the end of November, San Diego police moved quickly to rule out the usual flooding suspect: a broken water main.\nThe flooding, police said, was the result of a high ocean tide surging into the storm drain system.\nOn the morning of Dec. 23, the tide flowed over the beach at La Jolla shores, crested the seawall and flooded the boardwalk and parking lot. The next day, waves created by the incoming king tide badly damaged the famous surfer shack at Windansea Beach.\nThey are so-called “king tides,” the highest tides of the year. They’re a predictable phenomenon that typically happens throughout the November-February winter season; the next such tide is expected to arrive the week of Jan. 21.\nBut the water is reaching farther into San Diego than ever before. In late November, the swells reached historic heights.\nLocal scientists say the king tides are getting more severe and causing flooding more often. It could be a harbinger of a much larger problem: rising sea levels due to climate change.\nOn their website, the California Ocean Protection Council reported that the tide stations monitored by the National Oceanic and Atmospheric Administration, including those off of San Diego, recorded the highest sea levels ever on Nov. 25. The information gathered by the local tide stations cataloged sea levels up to half a foot higher than predicted. Combined with the El Nino and the warm oceanic conditions, these record-breaking water levels resulted in the abnormally large king tide and the Midway district flooding.\nKing tides happen naturally and have been a consistent annual event throughout San Diego’s history. Tidal forces typically push an inch or so of water up a storm drain or over a barrier to flood streets and parking lots. Once the tide goes back out, the water recedes, causing little damage.\nBut experts say it’s getting worse.\n“California broke a record late last month: sea levels at several tide stations in southern California reached higher elevations than ever measured before, including during major storms,” Abe Doherty, California’s climate change policy adviser, wrote in a memo about these findings published last month by the OPC. “Water levels were higher than the “King Tides” that were predicted by the National Oceanic and Atmospheric Administration, due to the ongoing El Niño, warm ocean temperatures and a minor storm.”\nSeveral related factors are contributing to the rise: Melting polar ice caps are raising the volume of water in the world’s oceans; a large and persistent patch of abnormally-warm surface water in the Pacific off the West Coast known as “the Blob” which is increasing the temperature and activity of the ocean surface; and most immediately, this winter’s large El Niño system, an irregular atmospheric event in the Pacific Ocean that affects barometric pressure and impacts seasonal weather systems. NASA are already calling this season’s El Nino “a monster.”\nIt’s having an effect on the local coastline. “Sea levels along the California coast have quite consistently been running several inches in excess of astronomical tide prediction,” said Dan Cayan, a climatologist at the Scripps Institute of Oceanography. “During the king tide late last month, La Jolla and other California coastal tide gage stations experienced record high levels. Fortunately, the minor storm was void of big waves.”\nDuring tidal flooding, it’s the larger and more powerful waves created by storm surges which cause most structural damage. Higher tide levels give these waves greater access to areas inland.\nWaves off San Diego’s beaches are already stronger in the winter than in the summer because of heavier winds and barometric pressure changes of seasonal storms. Combine those factors with the additional pressure changes of the El Niño system and the increasing volume of seawater, and you have a perfect formula for flooding. Similar circumstances in the winter of 1983 resulted in historic flooding in San Diego and other areas of the state, causing millions of dollars’ worth of damage.\nThe recent stronger-than-average king tides and accompanying flooding serve as a sign of the impact sea level rise and future El Niños might have on the San Diego coastline. “It is highly likely that global climate will warm, and in response, coastal flooding will increase in frequency and intensity over the next several decades,” said Cayan.\nAnd even though El Niño is a short-term event, local tide surges could continue after it’s over, Doherty believes.\n“Combining El Niño and the Blob, sea level anomalies seem likely to reach average levels of 1 foot this early winter and continue until Spring 2016, lower in the Summer 2016 and rise again temporarily during Fall 2016,” Doherty wrote in another memo (emphasis his). “The anomalous sea levels that California is experiencing this fall and that will likely be sustained through spring are approaching longer period increased levels that are projected under climate change for mid-century.”\nExactly how severe those changes will be remains unclear – there’s not much data on past events. While the NOAA tide stations have been recording sea level fluctuations off of San Diego since 1906, the record on the location and strength of tidal flooding incidents is sporadic at best. Oceanographers at Scripps say they’re working to correct this.\nThe Coastal Data Information Program at Scripps is building an online database and digital map documenting tidal flooding. One of the project’s goals involves matching photographs of flooding in early 20th century San Diego with wave and tide conditions recorded in newspapers, and other sources.\nSeveral environmental groups have also collaborated to create the California King Tides Project, a “citizen scientist”-based program dedicated to collecting photo data on king tides along the state’s coastline. Even with an only partially complete collection of data, the consensus of expert researchers and environmental organizations contacted for this story is we will face severe impacts in coastal areas.\n“In my opinion, our SoCal beaches are in for a world of hurt over the next decades,” said Robert Guza, a Scripps professor of oceanography. “It’s a matter of when, not if. An El Niño temporarily raises sea level by roughly the equivalent of 25 years of normal sea level rise. So this year is an interesting glimpse into the near future.”\nUnfortunately, solutions to future flooding are equally ambiguous. Lower-lying areas such as La Jolla, Mission Beach and Imperial Beach remain vulnerable. Local coastal marshes and sand barriers on the beaches help absorb the impact of tidal rises and storm surges, but they’ve been diminished by natural forces and human development.\nArtificial barriers such as seawalls and storm drains can help mitigate the damage from flooding, but they’re already failing to restrain the higher tides, and the city of San Diego hasn’t been in much of a rush to prevent El Niño flooding.\nKing tides and the flooding they cause demonstrate how rising sea levels affect San Diego. While it’s unclear as to whether the city faces sudden, destructive inundations or a slow tidal creep that gradually consumes the current sea level area of the coastline, it’s a scientific certainty that this current winter’s rise will be the new normal within a few decades. If a more permanent solution isn’t found, San Diego’s scenic beaches may become a thing of the past."", 'There have been many articles published recently predicting the future extent of tidal flooding and some show an horrific picture. It is important therefore to understand how these scenarios are derived. In simplistic terms we start with a “Digital Terrain Model” (DTM). This is the computer equivalent of a physical model of the land and every pixel is assigned a height. Then you take a “predicted” water level and you ask the computer to colour in everything below that level, which is very similar to taking a traditional Ordnance Survey map and colouring everything below the 5-metre contour.\nAs you will see there are assumptions that need to be understood to decide how useful the map is. Firstly, let’s look at “water level” predictions.\nWater level predictions\nAs we all know the water level around the coast is tidal, with high tides occurring twice daily, spring and neap tides on the Lunar Cycle and bigger springs at the equinox. There are other complicated factors that result in small variations over a longer cycle of 18.6 years. These tidal levels are shown in tide tables and can be predicted many years in advance. As they vary locally, tables are predicted for the nearest major port. However, if you read the tide table carefully you will find notes to the effect that tides are calculated under “average weather conditions” so, “tide table” tides take no account of unusual weather conditions.\nIf the atmospheric pressure is high, sea level is slightly depressed and vice-versa. However, there is a more pronounced effect when the low-pressure system moves at about the same rate as the natural tidal movement, producing what is known as a tidal surge or storm surge. In the case of the Solent, if a depression follows the English Channel it can result in the observed tide being up to about a metre above the tide-table tide.\nThe same low-pressure systems also generate strong winds; hence large waves, and the combined effect of storm surges and large waves can lead to flooding if there are not adequate defences. Surge predictions are produced continuously by the “National Tidal and Sea Level Facility” (https://www.ntslf.org/) and used, in combination with wave forecasting, by the Meteorological Office and the Environment Agency to generate Coastal Flood warnings.\nSea Level Rise\nThere is much talk about sea-level rise, but sometimes with little clarity about what it means in practice. There are two distinct mechanisms that produce a rise in local sea-level, geological (Isostatic) and climatic (Eustatic).\nFollowing the last Ice-age, which covered the North of England and Scotland, the northwest of Britain is rising and the southeast sinking, tipping about a line roughly from Cornwall to the Wash. This is why ordnance datum (ODN) is based at Newlyn in Cornwall, which shows no change. Before 1921 Ordnance Datum Liverpool was used and since Liverpool is rising there are variations between the two. In the Solent area the land is sinking by about 1mm a year, and this is fairly constant.\nThe Eustatic sea level rise has two major components, thermal expansion and melting of ice on land. As the sea temperature increases it expands and so the total volume of seawater in the world increases causing a general rise. As ice on land melts and drains into the sea it also causes an increase in the total volume of water in the oceans and consequently sea level rise. Melting of floating ice does not directly increase sea-level, but unfortunately it does have another effect. As seawater is much darker that ice, it absorbs more of the sun’s radiation and so creates a general rise in the temperature of the oceans.\nRates of Sea Level Rise\nThere are lots of different estimates of sea-level rise, both historically and for the future, but future predictions are only\nestimates and depend on assumptions made, particularly on Greenhouse Gas emissions. Historically, in the Solent there has been a consistent sea-level rise since the last ice-age of about 2mm per year, but there is strong evidence that this has now increased and is currently between 3mm and 4mm per year. In August 2021 the Intergovernmental Panel on Climate Change (IPCC) issued a major report on all aspects of Climate Change. Chapter 9, entitled “Ocean, cryosphere, and sea level change”, concludes that global sea-level rose faster in the 20th century than over the previous three millennia. IPCC estimate that global sea-level increased at a rate of 2.3mm per year at the start of the 20th century but further increased to 3.7mm per year from 1971 to 2018. These are global figures and local factors need to be added. IPCC conclude that by 2050 global sea level is likely to rise by about 200mm (6mm per year) increasing to 600mm (8.5mm per year) by 2100. The further ahead we look, the more uncertainty, as some factors are now impossible to mitigate. We\nneed to plan for these future increased sea levels.\nWe should also plan for flexibility as, with increased understanding, it is certain that the estimates will need to\nbe revised. The Further effect of Sea Level Rise As described earlier, flooding in most of England is caused by a\ncombination of tidal and meteorological events, so sea-level rise does not simply cause flooding, but increases the frequency of flooding. There are other effects which, in the longer-term, are also potentially serious.\nThe natural consequence of rising sea levels would be for marshes and beaches to move inland, however, since Victorian times, most of our coastline has been “managed”. In effect we have a Victorian coastline with a 21st century foreshore. This generally makes it difficult for natural processes to continue with the result that both marshes and beaches will be lost in a process known as “Coastal Squeeze”. This in turn allows larger waves to reach any sea defences and so cause an increased probability of both flooding and coastal erosion.\nWe have all seen the spray which results from a large wave hitting a near vertical seawall, but roughly the same amount of energy is also directed downwards and will erode the beach below. This will continue until the beach is below low-tide level. The same process happens with salt marsh, but in a low-energy environment (smaller waves) over a much longer timescale. The long-term effect, particularly if seawalls are retained in their current orientations, will be the loss of our beaches with all the economic consequences for coastal towns.\nThere is another effect that is often neglected. In all coastal towns the surface water from roads and sometimes rivers, is discharged to sea through sluices or tide-flaps. These allow water to drain out at low tide but stop the seawater coming back at high tide. Consequently, marshes have been drained and in some cases land “reclaimed” to only just above low neap tide level. The marshes at Bembridge are such an example. As the sea-level rises the period over which water can drain reduces and unless there are major changes in the surface and highway drainage systems, for example the installation of more storage or pumps, surface water flooding will occur more frequently. As almost all climate change scenarios predict increases in rainstorms, the combined effect will lead to more flooding, particularly in low-laying coastal towns. Sadly, this effect has not been widely recognised and it is likely that some serious incidents will occur before it is seen as a national priority.\nAuthor – Tim Kermode, TK Coastal, Member of the SPS Council.\nThis article first appeared in the Solent Protection Society Members’ Newsletter, Autumn 2021.\nFor details of how to become a member of SPS and received these articles hot off the press, take this link and get in touch.']"	['<urn:uuid:41dcd518-fb10-4a9d-bba1-1c127564290e>', '<urn:uuid:d7fb9191-7ee3-4cb2-b43d-ac588c8cb889>']	factoid	with-premise	concise-and-natural	similar-to-document	multi-aspect	novice	2025-05-12T13:53:09.865574	12	68	2522
55	differences between biting blood feeding flies larvae habitat preferred locations	Different types of biting flies have distinct preferred breeding locations for their larvae. Stable fly larvae develop in piles of rotting vegetable matter like haystacks, grass clippings, manure and shoreline vegetation. Black fly larvae attach to submerged stones in creeks and rivers. Biting midge larvae live in moist sand/soil, rotting vegetation, tree holes and damp areas near ponds and marshes. Deer fly and horse fly larvae are aquatic, living in water or moist locations. Sand fly larvae inhabit moist decaying plant matter, moss, mud or water. Horn flies specifically prefer to breed in fresh cow manure.	"['Nearly everyone has been bitten by a fly of one sort or another. Though there are many types of biting flies, mosquitoes account for most of the biting. This fact sheet focuses on other types of biting flies. For information about mosquitoes, see Mosquitoes and Disease at\nWhat is a fly? While most winged insects have four wings, flies have only two wings. A fly has mouthparts designed to suck up liquids and for piercing, if the fly is one that bites other animals.\nLike mosquitoes, biting flies locate humans and other animals by sensing certain substances, including the carbon dioxide and moisture in exhaled breath, dark colors and movement, warmth and perspiration. Once a suitable host is located, a biting fly inserts its piercing mouthparts, lacerates the skin, then injects its anticoagulant-containing saliva to keep the blood flowing.\nBiting flies transmit debilitating diseases to millions of people worldwide. Sand flies (Psychodidae) transmit sand fly fever, bartonellosis and leischmaniasis in many parts of the world. In the United States, one deer fly species (Chrysops discalis) can transmit tularemia. Biting midges (Ceratopogonidae) transmit a variety of diseases and, in the U.S., infect livestock with blue tongue virus. In addition, the bites of black flies (Simuliidae), horse flies (Tabanidae) and stable flies (Stomoxys calcitrans), can produce severe allergic reactions.\nIDENTIFYING BITING FLIES\nDEER FLIES and HORSE FLIES (Tabanidae)\nDeer flies are most prevalent in the spring. They are medium-size flies, approximately ¼-inch long, about the size of a house fly. They are typically yellow-brown to black with dark bands on their wings. The eyes of some deer flies and horse flies are iridescent green.\nThe maggot-like larvae (immature stage) of deer flies are aquatic. The adult flies are often encountered along trails near streams, lakes, ponds, marshes and swamps. They can be quite bothersome, buzzing around a person’s head, especially where large numbers are present. Both deer flies and horse flies bite with scissor-like mouthparts that cut into skin, causing blood flow which the flies lap up. Because of this relatively crude means of obtaining blood, the bites can be painful.\nHorse flies can be an inch or more long. Some are entirely black. Others, known as “greenheads,” are light brown with shiny green eyes. Horse flies are strong, fast fliers that feed on the blood of livestock and other animals. Like deer fly larvae, the larvae of horse flies usually live in water or moist locations where they prey on other insects, grow and migrate to dryer soil to undergo the pupal (cocoon) stage. The life cycle may take two years to complete.\nSTABLE FLY (Stomoxys calcitrans)\nThe stable fly is a about ¼-inch long and gray with four dark stripes on its thorax (behind the head). This fly looks like a house fly, except for the pointed proboscis beneath its head through which it sucks blood. They are most abundant in late summer and fall, and will fly several miles to bite livestock (hence the name), pets and people. They typically bite in early morning or late afternoon and often attack the ankles, inflicting a sharp, stabbing pain.\nStable flies lay eggs in piles of rotting vegetable matter, such as haystacks, grass clippings, manure and vegetation along shorelines. Like the adults, stable fly larvae are nearly identical to the larvae of house flies.\nBLACK FLIES (Simuliidae)\nAdult black flies are small, no more than 1/8-inch long with broad wings and a humpbacked appearance. Like other flies, black flies are creatures of moist environments. Also known as “buffalo gnats,” they are usually encountered near creeks and rivers where the larvae attach to submerged stones.\nBlack flies will fly up to 10 miles in search of blood. They do not transmit disease to humans in the United States. However, injury from black fly bites can threaten the lives of livestock and even people when present in very large numbers, typically in late spring and early summer. Deaths have been reported from allergic reactions and blood loss from the bites, and even from inhaling the flies. Black fly bites often cause considerable swelling and bleeding, may be itchy and slow to heal. They prefer to attack the head and where clothing fits tightly.\nBITING MIDGES (Ceratopogonidae)\nBiting midges should not be confused with other midges (Chironomidae) that are much larger and resemble mosquitoes but do not bite. The biting midges are much smaller, being no more than 1/32 of an inch long. They are also known as “punkies,” “no-see-ums” or simply “gnats.” Their tiny size allows them to penetrate window and door screens. Biting midges can be serious pests along the shores of oceans, lakes, ponds and rivers, and will bite during the day or at night.\nThe minute, worm-like larvae of biting midges live in moist sand or soil, rotting vegetation, tree holes and other damp situations often at the edges of ponds, marshes and lagoons. Several species will suck the blood of humans, while other species suck the blood of insects, including mosquitoes.\nSAND FLIES (Psychodidae)\nSand flies are related to non-biting drain flies (see House Fly and Other Filth Flies: < http://www.idph.state.il.us/envhealth/pcfilthflies.htm >).\nSand fly larvae are tiny and worm-like, living in moist decaying plant matter, moss, mud or in water. Adults are long-legged, no more than 1/8-inch long, hairy and brown to gray with wings that form a “V” shape when the flies are at rest.\nMost sand fly species feed on the blood of mammals, reptiles and amphibians at night. In many parts of the world, including southern Texas in the United States, certain sand fly species (Lutzomyia) are suspected of transmitting cutaneous leischmaniasis, a disfiguring protozoan disease of humans.\nMANAGING BITING FLIES\nArea-wide control of biting flies can be difficult due to the hidden habitats in which the larvae are found, and because some adult biting flies may fly miles from their larval habitats. Nevertheless, sanitation can be an important method of controlling some biting flies. The larvae of stable flies, for example, develop in piles of decaying hay, straw and other vegetation, including manure containing plant matter. These potential sites for larval development should be eliminated where practical. Other flies (biting midges and sand flies) may be controlled by disposing of decaying vegetation containing their larvae.\nExclusion also can be employed against biting flies. Stable flies are known to enter structures in search of blood meals, so screens should be installed and maintained on windows and doors. However, the mesh of standard household screens is not fine enough to keep out the tiniest biting flies and should be replaced with finer mesh where these flies are a problem.\nThe use of fly paper is limited as it is not as attractive to biting flies as are warm-blooded animals. Fans may be a more useful means to help keep small areas free of flies, especially smaller flies whose flight is affected by air currents. Similarly, burning candles and torches that produce smoke and air currents may help keep the smaller species away.\nPesticide application is of limited use in controlling biting flies. Ultra-low volume (ULV) treatments (such as “fogging” for mosquitoes) and space sprays of non-residual pesticides are best used where flies are numerous and concentrated in a relatively small area. These materials kill only on contact and quickly decompose, leaving the treated area unprotected soon after application.\nResidual pesticides can be used to spray surfaces where flies are resting, such as vegetation, the walls of barns and the exterior walls of houses. But this method will do little good if flies are not landing on these surfaces.\nAnother chemical control is larviciding, the application of pesticides designed to kill fly larvae. Formulations containing Bacillus thuringiensis (such as BTI) or growth regulators (such as methoprene) have been widely and successfully used against mosquito larvae living in the stagnant water of ditches, lagoons and catch basins. BTI has been used successfully against black fly larvae in streams.\nRepellents are the final line of defense against biting flies. Those containing the active ingredient DEET (N,N-diethyl-meta-toluamide) or picaridin are best. While effective against mosquitoes, repellents have been found to be less effective against some types of biting flies.\nThe use of repellents to combat biting flies should be supplemented with other preventive methods, such as avoiding areas inhabited by the flies, avoiding peak biting times, and wearing heavy-duty, light-colored clothing including long-sleeve shirts, long pants and hats. When black flies, for example, are numerous and unavoidable, netting that covers the head, like the “bee bonnets” used by beekeepers, can provide protection. Smaller biting flies, such as biting midges, may become stuck in heavy coatings of lotions or oils applied to skin.\nDespite the use of various control methods, control of biting flies is seldom complete. But by supplementing preventive measures with fly management, bites from these vexing pests can be avoided.\nPhotos and illustrations courtesy of the U.S. Centers for Disease Control and Prevention, Alex Wild (University of California, www.myrmecos.net ), Jim Kalisch (University of Nebraska) and Ohio State University.\nNOTE: When pesticides are used, it is the applicator’s legal responsibility to read and follow directions on the product label. Not following label directions, even if they conflict with information provided herein, is a violation of federal law.\nFor more information, contact the Illinois Department of Public Health, Division of Environmental Health,\nof Public Health\n535 West Jefferson Street\nSpringfield, Illinois 62761\nQuestions or Comments', ""A number of different flies will attack horses. The flies breed in the hot summer months, and this is the time when fly attacks occur. They are more prominent in tropical and subtropical countries than in countries with temperate climates, although even in temperate climates fly attack can be severe. Some flies, the nuisance flies, have mouthparts for lapping fluids and feed on the secretions around the eyes, nose, etc. Other flies, the biting flies, have mouthparts which can penetrate through the skin of the animal for the fly to feed on blood. The bites of the flies can be painful, but also, while feeding, the fly injects into the skin saliva and other substances which, for example, stop the blood from clotting as the fly feeds. Some horses can develop allergic or hypersensitivity reactions to the injected materials manifested by skin lesions, although why only a few and not all horses react in this way is not known. Flies also will transmit diseases either mechanically, simply by physically carrying the organism on the mouthparts from horse to horse, or as an intermediate host in the life cycle of the transmitted parasites.\nThere are four stages in the life cycle of the flies. The adult female flies lay hundreds of eggs. From these hatch larvae. The fly larvae are maggots, usually white, segmented and somewhat circular, increasing in breadth from front to back. They grow from about 1 mm to 10 mm in length. The larvae then pupate, frequently inside a hardened, protective pupal case. During the pupal stage the tissues of the larva dissolve and are re-formed to produce the adult fly. Once developed, the adult fly emerges from the pupa and is on the wing to attack horses.\nDifferent types of flies have preferred places (manure, water, etc.) in which they breed for the development of the larval stages. Therefore, to control flies adequately in a stable, it is important to know which types of flies are present. Most flies can be readily differentiated by a veterinarian from their size, color, patterns on their wings and structure of their mouthparts.\nThese are yellow-gray nuisance flies, which feed on the secretions around horses' eyes, nose, vulva and prepuce, and on wounds. They are common in stables as they prefer to breed in horse manure. The flies irritate the horse when they are present in any numbers, causing it to shake its head and swish its tail. Their irritation to the eye can cause excess tear formation, attracting other flies, which further damage the eye. In addition to the general control measures, fly veils attached to the browband can help to protect horses' eyes. The flies can transmit internal stomach parasite Habronema.\n30% Off First Contact Lens Order + Free Shipping Use code: 30NEW ( mfg. restrictions may apply)\nThese grayish-colored flies also are common in stables as they prefer to breed in wet bedding contaminated with horse urine and manure. During the day they can be seen resting on sunny walls and windows. Their bites can be quite painful and they will bite a horse several times or switch between horses to complete their feeding. They can be extremely annoying to the horse, which will stamp, kick and swish its tail. The bite often leaves a small nodule and scab and may bleed after the fly has fed, attracting other flies such as the house fly. Some horses can develop crusts on the back, chest and neck when bitten by many flies. Stable flies also will bite humans and dogs. Stable flies transmit a number of bacterial pathogens and parasites such as Trypanosoma and Habronema.\nThese small, dark gray flies are normally found biting cattle as they prefer to breed in fresh cow manure, but they can be very irritating to horses grazing with or near cattle. The flies often cluster on the horse's ventral abdomen. Their bites are painful, and they often stay in the same area for quite some time after feeding, causing the horse to become very agitated and repeatedly stamp its feet and kick at its belly. In some horses the flies cause discrete areas of crusts, perhaps ulcers, on the belly and hair loss. Apart from the general measures for fly control, often a thick coat of vaseline over the lesion will provide a barrier to prevent more fly biting.\nHorse, Deer and Buffalo Flies\nThese flies are recognized easily by their painful bite, their large size (up to 1 inch), brownish color and brightly colored eyes. They breed in mud and water and are most commonly seen flying near water on hot, sultry days, although some species can be active in woodlands. Their bites make horses restless, and they rub and bite at themselves to remove the flies, which will then repeatedly return to the same horse or to one very close by to finish feeding. The horses will try to move away from the flies or even stampede. They will stop feeding and lose weight if continually attacked.\nThe horse flies transmit equine infectious anemia (EIA) between horses, carrying the virus mechanically on the mouthparts. Since the flies will not move far to complete their feeding, separation of horses and separation of paddocks to prevent the flies feeding in quick succession on different horses will prevent transmission of EIA.\nThese are small, black, hump-backed flies which breed in fairly fast-running water in streams and rivers. They emerge to attack animals, particularly those grazing near water on warm days. Their bite is painful and they also inject a toxic substance, leaving behind a small, painful, fluid-filled blister or nodule. If the flies swarm and hundreds of them bite a horse, they can inject enough toxin to kill the animal.\nApplication of residual insecticides to premises are frequently used to control both house and stable flies. Longer-lasting residual insecticides provide control for an extended period when sprayed onto sites where adult flies congregate. Flies contact the insecticide when they land on the treated surfaces. Sides of buildings, inside and outside surfaces of stalls, and fences may be potential day or night resting sites for these flies. Observation of the barnyard situation will quickly indicate the favored testing sites for flies.\nKnockdown sprays are effective for killing adult flies present at the time of application. The chemicals used for these applications are usually short-residual insecticides that have a quick knockdown and high-contact toxicity. Several types of spray or fogging apparatus may be used. Wind velocities should be low at the time of application and the droplet or particle size should be small (50 to 75 microns) to ensure drift through the corral area. This method requires less application time, but the disadvantage is that it will only kill those flies present at the time of application and thus provides only short-term relief.\nDirect application of sprays and dusts to animals may be used in some situations to protect them. Materials used for direct\nanimal applications usually have short-residual activity and this type of application is labor intensive. Other methods of fly control, such as baits, electric grids, and traps, have some limited use for house fly control but are ineffective for the blood-feeding stable fly. Baits may be used effectively for house fly control in enclosed areas. Fly papers, cords, and strips may also help alleviate fly problems in these areas. Such methods are usually ineffective in open areas. Control of immature flies (larvae) is sometimes possible. Usually, the best approach is to remove the potential source of fly production with sanitation practices. When this is not possible, a larvicide can kill the developing flies. A larvicidal insecticide may be applied directly to places where eggs are laid and larvae develop.\n- Veterinary Notes for Horse Owners. Captain M. Horace Hayes\n- Equine Science. R. O. Parker""]"	['<urn:uuid:53a7d27c-f8a0-4dc1-af1d-00d446534afe>', '<urn:uuid:b7c640ab-070b-45b5-8f43-d98671d8e047>']	open-ended	with-premise	long-search-query	distant-from-document	multi-aspect	expert	2025-05-12T13:53:09.865574	10	96	2867
56	vancomycin dosage nephrotoxicity mrsa success rate	When targeting trough levels of 15-20 mg/liter, vancomycin achieves efficacy against MRSA but 55% of doses exceed the AKI risk threshold of 563 mg·h/liter. Studies show patients reaching target trough levels had better clinical responses against MRSA, but also experienced significantly more nephrotoxicity (12%) compared to those with lower levels.	['Recent evidence regarding vancomycin pharmacokinetics/pharmacodynamics has initiated a paradigm shift in vancomycin dosing from targeting trough concentrations to area under the concentration-time curve (AUC), specifically the 24-hr-AUC/MIC ratio.\nCompelling clinical data suggests that targeting a vancomycin 24-hr-AUC/MIC ratio of at least 400 mg · h/liter will ensure efficacy. The 2009 consensus committee on vancomycin TDM made the assertion that the vancomycin trough level is a good surrogate for the AUC, because in most adult patients a steady-state trough concentration of 15 to 20 mg/liter correlates with a 24-hr-AUC/MIC ratio of at least 400 for an organism with an MIC of 1 mg/liter or less.\nSince the implementation of the vancomycin consensus guidelines, several studies have documented a higher incidence of nephrotoxicity associated with the more aggressive trough goal. In contrast, a large meta-analysis suggested that a continuous infusion targeting a constant vancomycin concentration of 25 mg/liter is less nephrotoxic than standard intermittent dosing. This can be explained if we attribute the risk of vancomycin nephrotoxicity to the AUC, just as we do for efficacy.\nTo date the AUC threshold for vancomycin nephrotoxicity has not been clearly defined, 600 to 700 has been suggested. The goal of Chavada et al was to define the upper limit of the vancomycin AUC range. They found that a vancomycin 24hr-AUC of greater than 563 mg · h/liter was associated with significantly increased risk of AKI.\nOne of the features of APK that I am most proud of is the population analysis tool. Each time you save a consult based on serum level analysis, the pk parameters are saved. This data set is a goldmine of information about your patient population.\nThe data set presented below is from 1,671 adult general med-surg patients, with 1,078 in the subgroup of BMI less than 30. The vanocomyin pk model used for Bayesian analysis of this subgroup is similar to that used by Chavada.\nTotal=1078, F=486, M=592\n|SrCr (mg %)|\nThe patient specific pk parameters from this data set were then used to determine a dosing regimen based on either a target trough goal of 15 to 20 or a target AUC goal of 400 to 563. Dosing intervals were based on half-life and converted to a more practical 6, 8, 12, 18, 24 or 48 hours. Doses required to achieve the therapeutic goal were rounded to nearest 250mg whenever possible.\nAssuming an MIC of 1 or less, the minimum target AUC was determined to be 400. The upper limit of AUC was set to 563, as determined by Chavada. This target range is displayed within the shaded area in the figures below.\nTargeted trough dosing\nDoses required in this group ranged from 400 to 2000mg. As we often see in clinical practice, a significant number of regimens (91) did not achieve a trough of 15 within what is considered a safe dose range.\nAll dosage regimens in the targeted trough group achieved an AUC of at least 400, which confirms the goal of the 2009 guidelines. However, the majority of these doses, 597/1078 (55%), resulted in an AUC above the likely AKI risk threshold.\nTargeted AUC dosing\nDoses required to achieve the target AUC ranged from 400 to 1500mg.\nAll dosage regimens in the targeted AUC group also achieved an AUC of 400. No doses resulted in an AUC above the AKI risk threshold. This analysis also confirms previously reported studies which found that, in the majority of patients, an AUC of 400 can be achieved with a trough less than 15. In this analysis, 77% of dosing regimens (831/1078) achieved the AUC goal with a trough less than 15.\nAlthough controversy remains regarding whether vancomycin has a direct toxic effect, vancomycin-associated nephrotoxicity has been linked to troughs greater than 15. Targeted AUC dosing of vancomycin would be expected to reduce unnecessarily high exposure and thus reduce nephrotoxicity.\nChavada R, Ghosh N, Sandaradura I, Maley M, Van H. Establishment of an AUC0–24 threshold for nephrotoxicity is a step towards individualized vancomycin dosing for methicillin-resistant Staphylococcus aureus bacteremia. Antimicrob Agents Chemother 61 (5). 2017 Apr 24.', 'Podiatrists commonly encounter and treat skin and skin-structure infections (SSSIs), ranging from cellulitis to more complicated surgical site infections and infected diabetic foot ulcers. Aerobic gram-positive cocci, such as Staphylococcus aureus and streptococci, are the most common causative agents of skin infections.1\nWhile the treatment of simple and superficial infections is relatively straightforward with brief courses of oral antibiotics, many skin infections of the foot are complicated by diabetes.1,2 Foot ulceration, usually secondary to peripheral neuropathy or peripheral vascular disease, often leads to infection in the diabetic foot.2 Gram-positive aerobic bacteria are the most commonly isolated pathogens as S. aureus constitute almost half of all isolates, according to one study.3 However, chronic wounds and more severe infections are usually polymicrobial and may also involve anaerobes and gram-negative bacilli (see “An Overview Of Common Organisms In Chronic Foot Wounds” on page 25).1,2\nThe increasing prevalence of methicillin-resistant S. aureus (MRSA) infections in both the hospital and community setting is well documented. Bear in mind that MRSA is now involved in almost 60 percent of intensive care unit (ICU) infections in hospitals in the United States.4 Authors of a British study found that MRSA was isolated from 30 percent of outpatients with diabetic foot ulcers during 2001. This was twice the rate of MRSA found in patients three years earlier.3\nSince the emergence of MRSA in U.S. hospitals during the 1980s, vancomycin has been the standard of care for the majority of infections caused by MRSA.\nVancomycin helped fill the clinical need for an agent that could consistently cure the growing number of MRSA infections. However, when it comes to patients receiving vancomycin, one must monitor drug serum peaks and troughs in order to achieve the drug levels required to eradicate MRSA.5 One study of 95 patients, most of whom had MRSA pneumonia or bacteremia, found that those who had reached target serum trough levels were significantly more likely to have positive clinical responses to vancomycin than patients who had serum troughs below target levels.6 However, the study also found significantly more nephrotoxicity (12 percent) in the group of patients who achieved the target trough levels in comparison with the low level group.6\nIn the last several years, clinicians have detected MRSA isolates with reduced susceptibility and outright resistance to vancomycin after decades of successful clinical application. Although still very rare, the first documented case of vancomycin-resistant S. aureus (VRSA) in the U.S. involved a patient who had a polymicrobial diabetic foot infection in which vancomycin-resistant enterococci (VRE), containing the vancomycin resistance gene vanA, transferred resistance to MRSA.7 In addition, S. aureus strains with reduced susceptibility to vancomycin — so-called vancomycin-intermediate S. aureus (VISA) — also exist and may be linked to clinical failures.8,9\nPerhaps of even greater concern are reports that strains of MRSA that appear to be susceptible to vancomycin (based on susceptibility testing (minimum inhibitory concentration [MIC] ≤ 2 µg/mL)) may not actually respond to vancomycin therapy. For example, one study showed that among patients with MRSA bacteremia, those patients who had MIC levels < 0.5 µg/mL were more likely to have successful outcomes with vancomycin than those patients who had MRSA strains with MIC levels of 1 to 2 µg/mL.8\nGiven that vancomycin can no longer be considered a universally effective drug against MRSA, safe and effective anti-MRSA drugs are needed. However, there are only a few alternatives for patients who cannot tolerate vancomycin or fail vancomycin therapy.\nPodiatrists commonly use linezolid (Zyvox, Pfizer) as it is effective against MRSA in complicated SSSIs. However, one may need to limit the duration of therapy due to hematologic adverse events (suppression of blood cell counts).1 Newer options approved for use against MRSA in complicated SSSIs include tigecycline (Tygacil, Wyeth) and daptomycin (Cubicin, Cubist Pharmaceuticals). With this in mind, let us take a closer look at daptomycin.\nSpectrum Of Activity: What Does Daptomycin Offer?\nDaptomycin is the first antibiotic in a new class called the cyclic lipopeptides. Daptomycin binds to and depolarizes the cytoplasmic membrane of gram-positive bacteria, ultimately causing rapid cell death.10 It was approved in 2003 in the U.S. for the treatment of complicated SSSIs caused by S. aureus, including MRSA, as well as Streptococcus pyogenes, Streptococcus agalactiae, Streptococcus dysgalactiae subsp. equisimilis, and Enterococcus faecalis (vancomycin-susceptible isolates only). Recently, the label for daptomycin was extended to include the treatment of bacteremia, including right-sided endocarditis caused by S. aureus.11\nDaptomycin provides dose-dependent bactericidal activity against a wide range of aerobic and anaerobic gram-positive isolates (including multiresistant strains).12,13 In addition, it has demonstrated in vitro activity against methicillin-susceptible S. aureus (MSSA), MRSA and anaerobic gram-positive organisms (such as Finegoldia magna and Peptoniphilus asaccharolyticus) cultured from diabetic foot infections.13 Furthermore, an in vitro study demonstrated that 96 percent of 105 strains of S. aureus with reduced susceptibility to vancomycin, including VISA, were susceptible to daptomycin.14\nWhat The Literature Reveals About Daptomycin\nIn two multicenter, randomized phase 3 clinical trials, researchers compared daptomycin with standard therapy (penicillinase-resistant penicillins or vancomycin) in 1,092 patients with complicated SSSI and most of these were caused by S. aureus.15 The treatment duration was seven to 14 days. Researchers defined clinical success as the resolution of signs and symptoms to the point where antibiotic therapy is no longer required. They assessed clinical success six to 20 days after the last dose. These studies showed that clinical success rates were statistically comparable (“noninferior”) between those patients clinically evaluable in the daptomycin and comparator groups (83 percent versus 84 percent respectively).15 In the MRSA subpopulation, clinical success rates were 75 percent and 69 percent respectively for patients treated with daptomycin and vancomycin.15\nDaptomycin’s efficacy against other gram-positive pathogens (streptococci and enterococci) was also comparable to that of standard therapy.15 Patients receiving daptomycin had fewer days of therapy as 63 percent of these patients required four to seven days of therapy in comparison to 33 percent of patients in the comparator group.15 A post hoc analysis of the data from 103 clinically evaluable patients who had diabetic foot infections demonstrated that daptomycin was as effective as vancomycin or penicillinase-resistant penicillins in treating gram-positive infections.16 Bear in mind that the number of MRSA isolates in this subpopulation was modest with only one MRSA isolate in the daptomycin-treated group.\nWith all new antibiotics, there is concern about resistance but daptomycin resistance rates to S. aureus and other gram-positive cocci are low in vitro.17 In a few instances, MRSA isolates have been reported to have become nonsusceptible to daptomycin in vivo during treatment for bacteremia, endocarditis or osteomyelitis.18 Nonsusceptible isolates have not yet been reported in patients with complicated SSSI who received daptomycin treatment.18\nDaptomycin was well tolerated in these trials of patients with complicated SSSIs, and the frequency, distribution and severity of adverse events were similar between daptomycin and comparator drugs.15 For example, 2.2 percent of patients treated with daptomycin experienced renal failure in comparison to 2.7 percent of patients in the comparator group.15 The prevalence of adverse events was similarly small and comparable between treatment groups among those patients who had diabetic ulcer infections.16 In contrast, a recent phase 3 trial of daptomycin 6 mg/kg for the treatment of S. aureus bacteremia found significantly more patients had renal impairment with standard therapy (antistaphylococcal penicillin or vancomycin) (18 percent) than with daptomycin (7 percent).19\nIn regard to patients who receive daptomycin, one should monitor for the development of muscle pain and weakness, and also test creatinine phosphokinase (CPK) levels weekly or more often if necessary.11 However, elevations in CPK levels were comparable between daptomycin and comparator groups in the aforementioned complicated SSSI trials, and only two of 534 patients receiving daptomycin developed CPK levels that necessitated discontinuation of the drug.15\nThe approved dose of daptomycin for complicated SSSI is 4 mg/kg once a day by intravenous infusion for seven to 14 days. When it comes to patients with insufficient renal function, the dosing should be once every 48 hours.11 Since many foot infections are caused or complicated by diabetes, parenteral therapy is often necessary at least initially.1,2\nSince daptomycin is dosed once daily, it is a suitable modality for outpatient parenteral therapy. One study found that daptomycin is safe to use in a hospital-based outpatient setting. This provided the opportunity for patients to receive professional wound care in addition to drug administration.20\nIn summary, daptomycin has potent bactericidal activity against gram-positive bacteria, including MRSA. Given the currently available studies, it appears that this new antibiotic may provide a useful option for treating many skin infections of the foot.\nDr. Steinberg is an Assistant Professor in the Department of Plastic Surgery at the Georgetown University School of Medicine in Washington, D.C.\n1. Eron LJ, Lipsky BA, Low DE, et al. Managing skin and soft tissue infections: expert panel recommendations on key decision points. J Antimicrob Chemother 52 Suppl 1: i3-i17, 2003.\n2. Lipsky BA, Berendt AR, Deery HG, et al. Diagnosis and treatment of diabetic foot infections. Clin Infect Dis 39: 885-910, 2004.\n3. Dang CN, Prasad YD, Boulton AJ, Jude EB. Methicillin-resistant Staphylococcus aureus in the diabetic foot clinic: a worsening problem. Diabet Med 20(2): 159-161, 2003.\n4. National Nosocomial Infections Surveillance (NNIS) System Report, data summary from January 1992 through June 2004, issued October 2004. Am J Infect Control 32(8): 470-485, 2004.\n5. Stevens DL. The role of vancomycin in the treatment paradigm. Clin Infect Dis 42 Suppl 1: S51-S57, 2006.\n6. Hidayat LK, Hsu DI, Quist R, Shriner KA, Wong-Beringer A. High-dose vancomycin therapy for methicillin-resistant Staphylococcus aureus infections: efficacy and toxicity. Arch Intern Med 166(19): 2138-2144, 2006.\n7. Centers for Disease Control and Prevention. Staphylococcus aureus resistant to vancomycin--United States, 2002. MMWR Morb Mortal Wkly Rep 51(26): 565-567, 2002.\n8. Sakoulas G, Moise-Broder PA, Schentag J, et al. Relationship of MIC and bactericidal activity to efficacy of vancomycin for treatment of methicillin-resistant Staphylococcus aureus bacteremia. J Clin Microbiol 42(6): 2398-2402, 2004.\n9. Howden BP, Ward PB, Charles PG, et al. Treatment outcomes for serious infections caused by methicillin-resistant Staphylococcus aureus with reduced vancomycin susceptibility. Clin Infect Dis 38(4): 521-528, 2004.\n10. Silverman JA, Perlmutter NG, Shapiro HM. Correlation of daptomycin bactericidal activity and membrane depolarization in Staphylococcus aureus. Antimicrob Agents Chemother 47(8): 2538-2544, 2003.\n11. Cubist Pharmaceuticals. Cubicin® (daptomycin for injection) prescribing information. 2006. Lexington, MA.\n12. Rybak MJ, Hershberger E, Moldovan T, Grucz RG. In vitro activities of daptomycin, vancomycin, linezolid, and quinupristin-dalfopristin against staphylococci and enterococci, including vancomycin-intermediate and -resistant strains. Antimicrob Agents Chemother 44(4): 1062-1066, 2000.\n13. Goldstein EJ, Citron DM, Warren YA, et al. In vitro activities of dalbavancin and 12 other agents against 329 aerobic and anaerobic gram-positive isolates recovered from diabetic foot infections. Antimicrob Agents Chemother 50(8): 2875-2879, 2006.\n14. Sader HS, Fritsche TR, Jones RN. Daptomycin bactericidal activity and correlation between disk and broth microdilution method results in testing of Staphylococcus aureus strains with decreased susceptibility to vancomycin. Antimicrob Agents Chemother 50(7): 2330-2336, 2006.\n15. Arbeit RD, Maki D, Tally FP, Campanaro E, Eisenstein BI. The safety and efficacy of daptomycin for the treatment of complicated skin and skin-structure infections. Clin Infect Dis 38(12): 1673-1681, 2004.\n16. Lipsky BA, Stoutenburgh U. Daptomycin for treating infected diabetic foot ulcers: evidence from a randomized, controlled trial comparing daptomycin with vancomycin or semi-synthetic penicillins for complicated skin and skin-structure infections. J Antimicrob Chemother 55(2): 240-245, 2005.\n17. Silverman JA, Oliver N, Andrew T, Li T. Resistance studies with daptomycin. Antimicrob Agents Chemother 45(6):1799-1802, 2001.\n18. Garau J. Management of cSSTIs: the role of daptomycin. Curr Med Res Opin 22(11): 2079-2087, 2006.\n19. Fowler VG, Jr., Boucher HW, Corey R, et al. Daptomycin versus standard therapy for bacteremia and endocarditis caused by Staphylococcus aureus. N Engl J Med 355(7): 653-665, 2006.\n20. Nguyen HH, Hoze MD. Hospital-based Oupatient Parenteral Antimicrobiol Therapy (OPAT) at a University Hospital. Presented at Infectious Diseases Society of America (IDSA) 44th Annual Meeting, held October 12-15, in Toronto, Ontario, Canada. Abstract # 221.\nFor related articles, check out the archives at www.podiatrytoday.com.']	['<urn:uuid:39f96486-24f8-4169-9987-a483b2c273d0>', '<urn:uuid:14c059f7-4b59-4873-8a1f-47f0ae6242f0>']	factoid	with-premise	short-search-query	distant-from-document	multi-aspect	expert	2025-05-12T13:53:09.865574	6	50	2667
57	I'm building an advanced simulation setup and need advice on screen selection and mounting. How do viewing angles and screen placement affect image quality for both front and rear projection, and what mounting considerations are important for different screen types?	For viewing angles, front projection allows flexibility but can be impacted if the screen is mounted at too steep a downward angle - mounting a display on a front-slanted surface would create a problematic viewing angle. With back projection screens, the image is designed to be brighter on the front viewing side, with the image barely visible from the rear. For mounting, front projection screens can be placed just inches from the viewing area (as close as 2 inches from the front edge in a cockpit setup), while back projection requires careful consideration of the mounting structure, potentially using rigid screens that can be suspended on thin wire for certain installations.	"['I’ve been getting some questions about which USB hubs I use. I have several of the “Sabrent 7 Port USB 2.0 HUB + 2 Charging Ports with 5V/4A Power Adapter (HB-UST9)” hubs. They work fine, have charging ports as well as data ports, and you can attach them to the panel base with Velcro tape. Remember not to attach more that four devices at a time or you’ll get unreliable results (assume each device needs 500mA of power). They are here on Amazon.\nYesterday I was able to build the center pedestal console I’ve been wanting to build for some time, and I thought that today it would be nice to share my plans here as a holiday gift to the cockpit builders who frequent the site, and as a thank you for their readership. So here they are (and this is a preview of what will be in the guide I’m writing). Happy holidays!\nThe new panel is done, at least for the most part. The placard stickers didn’t make it from the old one (the were tearing when I tried to remove them), but other than that it’s up and running, and there’s a short video below.\nIn other news the list of sim projects I have underway seems to keep growing, and right now the to-do list of work underway includes:\n- Figuring out the final on / off switch config for the new radios (so they light up when I flip the avionics switch on the panel).\n- Designing my first home-built airport for X-Plane (KOQN, my home patch).\n- Building a center console for the sim that will hold the trim wheel, throttle quadrant, intercom, fuel switch (and perhaps a couple of cup holders) – and I hope to do this today.\n- Lots and lots of “How To Simulate” flights and viewer request flights.\nAnd of course, I’m still working on the still-lengthening guild to building a GA home cockpit. Yesterday was good for this, as it gave me fresh recall on a bunch of panel-related items, and gave me the chance to snap some photos that will help illustrate things in the book.\nSo it’s good the holiday season is here with some time off!\nI’ve been trying to post more and more information that can help folks build their own Basement Simulator, and have finally decided to take the plunge and write a guide on the topic. I do NOT want to offer something that goes into significant detail about the software, hardware, and PC side of things, as Sim Samurai’s Ultimate Guide To Advanced Flight Simulation achieves that with far greater detail than I’ll ever have to offer. (And if you’re planning to build a home sim and haven’t purchased the UGTAFS, I can say it was one of the first things I did when I got started, and it’s worth the price.) Rather, I want to offer something that describes in reasonable detail the design I’ve used, choices I’ve made, and lessons I’ve learned in building the Basement Sim — including plans, tools, and parts — so that others who wish to build a similar GA cockpit can more easily do so. My vision is something that will be enough of a detailed resource that someone could use it to build and start flying in a sim like mine.\nI began producing the guide yesterday, and have 18 pages written so far, including side, front, top and back plan elevations. I hope to complete it sometime next week. Because of the time and energy invested, I do plan to offer the guide for sale, and expect to do so for somewhere around $30 with a full money-back guarantee if people who buy the guide aren’t satisfied with it. I figure the experience I’ve put into it is probably worth that, but we’ll see.\nFor those who are curious, here’s the current table of contents, and I presume each of these sections will make it into the final draft:\n- OVERALL DESIGN\n- TOOLS & PARTS\n- COMPUTING EQUIPMENT\n- TVS & PROJECTORS\n- On Resolution\n- The Projector\n- Projector Or TV Front View?\n- The TVs\n- INSTRUMENTS, CONTROLS, AND AVIONICS\n- The Wonderful FIP Gauges By Tom Tsui\n- The Importance Of USB Hubs And Proper Power\n- Final Thoughts On Avionics And Controls\n- BUILDING THE FRAME\n- Basic Frame Plans\n- Side Elevation\n- Top Elevation\n- Front Elevation\n- Back Elevation\n- The Panel\n- SIDE PANELING\n- UPHOLSTERY & CARPET\n- THE GLARE SHIELD\n- Placards & Stickers\n- Real-World Parts\n- INTERCOM & HEADSETS\n- OTHER TOPICS\n- FSX, P3D, or X-Plane?\n- GoPro and Video\nSo stay tuned! I hope it will be a valuable resource for others looking to pursue the hobby as I have.\nReaders have been asking for my plans since I put the site online, but my early Google SketchUp files were rough and I made some changes during construction, so I haven’t posted them. Today I took the time to get them in order, and here they are. I will put together a more detailed set that includes the basic supplies I used as well, but in the meantime I figure this will help those looking to build their own basement simulators. I’ve been really flattered by the number of simulations enthusiasts who have started building their own based on what they’ve seen here, so if this can help them and others on their journey, I happy to offer it.\nFirst, the lumber (and remember to measure twice, cut once!) …\nCut from 1 1/2″ x 1 1/2″ studs:\n- Six 4′ cuts\n- Two 3′ 10″ cuts\n- Four 4′ 8″ cuts\n- Two 3′ 7″ cuts\n- Two 4′ 10″ cuts\n- Two 2′ 1″ cuts\n- Two 1′ cuts\n- Two 2′ 9 1/4″ cuts\nCut from 1 1/2″ x 3 1/2″ studs:\n- Four 10″ cuts\n- Two 11 1/4″ cuts\n- Two 1′ 8 1/2″ cuts\n- Four 2′ 1″ cuts\n1 piece 3/4″ x 11′ x 48″ MDF for the panel base\n1 piece 1/4″ x 18″ x 46″ MDF for the panel itself\nIn terms of other supplies, I used long wood screws to connect the frame pieces together, and metal L-brackets to brace the corners (screwed in with 1/2 inch wood screws). Note that I DID NOT attached the panel base to the cockpit frame with screws. It simply sits on top, which makes it easy to adjust and take in and out.\nAnd here are the basic plans: a .JPG here and a .PDF here. The panel template (which is a life-sized C172 panel schematic as a PDF) is here. Note that the panel PDF is 42″ across, and that I cut the template in half so I could make it 46″ wide. I hope it helps, and good luck!\nI’ve been saving for this and finally pulled the trigger. Here’s a quick look at the Basement Sim’s new avionics from FlightIllusion (http://www.flightillusion.com). I can’t wait to start flying with them! Thanks for watching.\nI get this question quite a bit here and on YouTube, and recently answered in the question thread for a post here, so I thought I’d add the answer here as well. This is slightly amended from the original.\nThe reason is field of view. While the front window of the cabin is about 46″ in diagonal, from the seats in the cockpit the actual field of view is much wider, especially if you want both the left and right chair to have an immersive view without seeing the edges of a screen. The projection screen hangs just two inches in front of the front edge of the cabin. It’s a 100-inch screen, and even with a screen of that size if I lean forward too much over the glare shield I can see the edge of the screen. One option would be to tilt-mount a big display to the cabin’s front-slanted lumber, but that would probably not look immersive as the viewing angle would be at a significant down-facing degree. I would love to have a TV for the front view just to have similar view quality all way around, but 100-inch TVs are a bit out of the price range right now (NEC makes one for $33,000 – the price of a nice used Cessna 172l; Sharp makes a 90 inch for six grand). So I go with the projector. I use an ultra-short throw because with the height of my ceiling and the height of the cabin, a projector mounted too far back casts a shadow over the screen as the beam hits the top of the cabin. So the projector needs to be really close to the screen (in my case, just about 24 inches). Finally, I also like the projection screen because I can look around the edge of the window a bit to find the field on final approach, just like in the real world.', ""Back Projection Screens\nProjection screens for years have commonly been known as front projection or standard projection, however over the last 10 plus years back projection screens have actually become a substantial part of the projection screen market and are more common place in today’s technology display uses.\nBack projection screens allow you to project an image onto the front of the projection screen from the rear or back side of the screen; on this note it is important to realize that front projection screens cannot be used as rear projection screens as they are not designed for that purpose. Most screens are designed for either front or back projection use and there are also dual purpose projection screens available that you can use as either.\nBack Projection Example - click here\nYou have probably heard in your lifetime this statement “use the right tool for the right job” and we mention it because as you begin your quest for a back projection screen surface we will help you understand some common uses and practices of back projection screens so you too can use the right screen for the right project. So what are some of the uses of back projection screens?\n- Live events\n- Storefront digital window displays\n- Training facilities\n- Concerts and shows\n- Outdoor movie showings\n- Video trucks\n- Street level advertising\n- Trade show displays\n- Churches and House of Worship\n- Corporate demonstration rooms\nWhat are the downsides or drawbacks to back projection screens? As with any product you should know the limitations and best practices; the biggest downside to back projection screen is the space needed. In order to project on the rear surface of your screen and fill it you need to plan accordingly and be sure that you have enough space to fill the screen. With the advancements in the technology of both projection screens and projectors you can accomplish more with less today; to give you an idea of the distance requirements and how they vary depending on your project and application we have a couple of examples for you.\nOVERVIEW - A city council chambers wanted to replace their 20 year old front projection screen for a state of the art back projection screen display. They currently had a 112” screen that was in use and wanted to upgrade to a 133” rear projection display; the challenge they presented us with was they wanted it to stay in the same space requirements which were 3.5 feet off the wall. We had to put a system together using both a custom mirror rig and short throw projection lens to accomplish this but we managed to do it with a fair amount of calculation and technology.\nOverview – A corporate client was participating in a tradeshow and wanted a floating back projection screen as their centerpiece when customers walk through the door, they had a structure setup and wanted an image to be suspended in the middle of it. For this application we recomended using our rigid back projection screen suspended on thin wire.\nHow does a back projection screen show the image correctly on the front side of the screen you might be asking yourself? The screen is just the display surface and does not contain the technology to turn the image around so you can see the words etc. properly; we receive so many calls the first time people go to setup their new projection screen and are wondering why the words are backwards. The answer to this question actually is found in the projector itself and not in the screen; inside of most projectors available in the market is what is called “mirror settings” and this gives them the ability to flip the image as needed for the following installations –\n- Ceiling mounted front projection applications\n- Ceiling Mounted back projection screen applications\n- Desk mounted front projection applications\n- Desk mounted back projection screen applications\nInside the projector and available from the menu functions you can find the functions to do flip the image to the correct position for your application. Although it varies from one projector manufacturer to another, typically you choose front or rear projection and then desk or ceiling mounting and this will correctly alter the image for display on your screen based on your setup. For a video of how to properly flip the image in your projector for a back projection screen application click here.\nWhy is the image brighter on the front than on the rear side of the screen?\nWell this is a question that has a lot more to it then we have time to go into in this article but the bottom line is that the screen is specifically designed to retain the light on the front side of the screen and many times the image is barely if at all visible on the back side of the screen. Everything has its proper function and the back projection screen is specifically designed to capture the light from the rear in short.\nWhat are the benefits of using back projection screens and how can you utilize this technology properly and get the most out of it? In the world of projection it is good to understand the basics of both front and rear projection surfaces and how they work, for more information and details on both technology types please click here but for now we will give you the quick overview.\nBack projection allows the light path coming from the projector to continue through the projection screen towards the viewing audience; in contrast front projection screens reflect or bounce the image off of the projection surface and back to the viewers.\nBack projection screen surfaces can provide a higher quality image with less firepower usually, as you don’t need to work as hard to get the image to the viewing audience. Most front projection screen surfaces are technologically lacking and contain inherent problems if you are fighting a lot of ambient light or real world circumstances; if you are not careful you can end up with a big nasty hot spot that seems to follow you around as you move. To learn more about hot spots click here.\nThere are many different kinds of back projection screen technology ranging from fabric to rigid or hard screens and even thin back projection films. As with any product available there are many different levels of technology when looking for a rear projection screen and you should educate yourself properly before you decide on which to purchase for your application; additional information on back projection screen technologies can be found by BACK PROJECTION SCREENS.\n- Video on Glass\n- Projection Screens\n- Touch Screens\n- Touch Tables\n- Electric Glass\n- Projector Enclosures\n- Interactive Floors\n- Real Estate Software\n- Transparent LCD's\n- Custom Products\n- SSI Store\n- Holographic Projection Screens\n- Front Projection\n- Interactive Floor\n- Projection Systems\n- Rear Projection Film\n- Multi-Touch Screens\n- Rear Projection Screens\n- Spherical Projection Screens\n- Anti-Glare Film\n- Digital Window Displays\n- Electric Glass\n- Industrial Scoreboard\n- Mobile Touch Screens\n- Multi-Touch Tables\n- Projector Enclosures\n- Real Estate Touch Display\n- Transparent LCD\n- Free Samples""]"	['<urn:uuid:0140dc0d-42cb-43ec-a44b-cc651fef9775>', '<urn:uuid:13d5146b-a361-494b-b76c-5b0c458496cc>']	open-ended	with-premise	verbose-and-natural	similar-to-document	multi-aspect	expert	2025-05-12T13:53:09.865574	40	111	2719
58	Do both professors have experience teaching graduate students?	Yes, both professors teach at the graduate level - Dr. Stake has supervised student research projects in women's studies, while Dr. Ireland is the Course Director for the MSc Forensic Psychology program since 2009 and supervises PhD students.	"['Department of Psychology: Jayne E Stake, Ph.D.\nJayne E. Stake, Ph.D.\nDepartment of Psychology\nUniversity of Missouri -\nOffice: 213 Stadler Hall, 8001 Natural Bridge Road, St. Louis, MO 63121\nOffice Hours: By appointment\nProfessional Affiliations and Activities\nof Recent Student Research Projects\nUniversity of California, Los\nAngeles: B.A., Psychology, 1966\nCalifornia State University-Long\nBeach: M.A., Psychology, 1971\nArizona State University: Ph.D.,\nClinical Psychology, 1974\nMissouri Psychology License\nMissouri Health Service Provider\nAffiliations and Activities\nFellow, American Psychological\n35: Society for the Psychology of Women\nMember, Missouri Psychological\nMember, St. Louis Psychological\nEditor, Psychology of Women\nChair, American Psychological\nAssociation Accreditation Site Visit Committees for Doctoral Programs\nin Clinical Psychology, 1990 - present\nMy research is focused on issues\nrelated to the self-concept and empowerment of women. Much of my work\nhas centered on the role of self-esteem in women\'s behavior and decision\nmaking. I have developed a self-esteem measure, the Performance Self-Esteem\nScale, to explore these issues and to evaluate interventions for the development\nof women\'s potential. The three related areas of my current research are\ndescribed below. I have involved students in each of these areas of research.\n1. The role of women\'s\nand gender studies as an intervention for the empowerment of women\nhas been on student outcomes of women\'s and gender studies and the feminist\npedagogy (teaching emphases, goals, and methods) that brings about these\noutcomes. My research associates and I have found that women\'s and gender\nstudies courses influence performance self-esteem, career attitudes, attitudes\ntoward women and other marginalized groups, and activism for women\'s issues\nand other social causes. We have developed a measure of feminist pedagogy\nto assess processes in the women\'s and gender studies classroom from both\nthe student and instructor perspectives. Our findings have implications\nfor recent public debates regarding the nature and outcomes of women\'s\nand gender studies programs. Overall, our results provide strong support\nfor the role of women\'s and gender studies in advancing women\'s and men\'s\ncollective and individual well-being.\n2. The promotion of science\ncareer confidence and motivation in gifted high school girls\nwomen have made major gains in the fields of medicine, the law, and other\nprofessions, they continue to be very underrepresented in science, math,\nand engineering. There are many reasons for this gender gap, most importantly\nthat science in our society has continued to be stereotyped as a male\ndomain, and girls have continued to feel that science is not ""their space.""\nI have been researching the value of extracurricular, nonsexist science\nprogramming for supporting high school girls\' interest and confidence\nto ""do science."" We have found that science enrichment programs are particularly\nbeneficial for girls; they not only provide useful instruction but allow\nan opportunity for girls to expand their career horizons and to develop\na social niche of like-minded peers who can support them in their science\n3. Androgyny from a situation-based\nandrogyny theory, people with a balance of both masculine and feminine\ntraits were believed to be better functioning and to have better mental\nhealth than those who had more traditional gender orientations. These\npredictions were not confirmed by previous empirical research, which was\nfocused on personality traits of individuals. I have been reconsidering\nthis question in a series of studies from a situation-based perspective.\nWhen situational demands for traditionally feminine (i.e., expressive)\nand masculine (i.e., instrumental) behaviors become the focus of study,\nwe have found support for the original androgyny hypothesis. That is,\nthe psychological outcomes for people who are in situations that demand\nboth expressive and instrumental behaviors are more positive than are\nthe outcomes of situations with other gender-role expectation patterns.\nWe have found further that the ""androgynous"" situation is more likely\nto result in positive psychological outcomes if the individual responds\nandrogynously to the situation. Our results provide evidence, contrary\nto previous personality trait research, that expectations for, and the\nimplementation of, primarily instrumental behaviors are associated with\nless positive personal adjustment than androgynous settings and behavior.\nListed is a sample of recent\nStake, J.E., Roades, L., Rose,\nS., Ellis, L., & West, C. (1994). The women\'s studies experience:\nImpetus for feminist activism. Psychology of Women Quarterly, 18,\nStake, J.E. (1994). The long-term\nimpact of women\'s studies on students\' personal lives and political activism. Psychology of Women Quarterly, 18, 403-412.\nStake, J. E., Huff, L., &\nZand, D. (1995). Trait self-esteem, positive and negative events, and\nevent-specific shifts in self-evaluation and affect. Journal ofResearch\nin Personality, 29, 223-241.\nStake, J. E., Zand, D., &\nSmalley, R. (1996). The relation of instrumentality and expressiveness\nto self-concept and adjustment: A social context perspective. Journal\nof Social and Clinical Psychology, 15, 167-190.\nSmalley, R., & Stake, J.\nE. (1996). Evaluating sources of ego-threatening feedback: Self-esteem\nand narcissism effects. Journal of Research in Personality, 30, 483-495.\nStake, J. E. (1997). Integrating\nexpressiveness and instrumentality in real-life settings: A new perspective\non the benefits of androgyny. Sex Roles, 37, 541-564.\nHoffmann, F. L., & Stake,\nJ. E. (1998). Feminist pedagogy in theory and practice: An empirical investigation. Journal of the National Women\'s Studies Association, 10, 79-97.\nHousman, L.M., & Stake,\nJ.E. (1999). The current state of sexual ethics training in clinical psychoogy:\nIssues of quantity, quality, and effectiveness. Professional Psychology:\nResearch and Practice, 30, 302-311.\nStake, J. E., & Hoffmann,\nF. L. (2000). Putting feminist pedagogy to the test: The experience of\nwomen\'s studies from student and teacher perspectives. Psychology of\nWomen Quarterly, 24, 30-38.\nStake, J. E. (2000). When situations\ncall for instrumentality and expressiveness: Resource appraisal,\ncoping strategy choice, and adjustment. Sex Roles, 42, 865-885.\nKaysen, D., & Stake, J.\nE. (2001). From thought to deed: Understanding abortion activism. Journal\nof Applied Social Psychology, 31, 2378-2400.\nStake, J. E., & Hoffmann,\nF. L. (2001). Changes in student social attitudes, activism, and personal\nconfidence in higher education: The role of women\'s studies. American\nEducational Research Journal, 38, 411-436.\nStake, J. E., & Mares, K.\nR. (2001). Science enrichment programs for gifted high school girls and\nboys: Predictors of program impact on science confidence and motivation. Journal of Research in Science Teaching, 38, 1065-1088.\nWise, D., & Stake, J. E.\n(2002). Effects of social support and self-esteem on the relation between\nsocial expectations for instrumentality and expressiveness and well-being. Journal of Social Psychology, 142, 109-119.\nStake, J. E. (2003). Understanding\nmale bias against girls and women in science. Journal of Applied Social\nPsychology, 33, 667-682.\nStake, J. E. (2003). Students\'\nquality of experiences and perceptions of intolerance and bias in the\nwomen\'s and gender studies classroom. Psychology of Women Quarterly,\nSevelius, J., & Stake, J.\nE. (2003). The effects of prior attitudes and attitude importance on attitude\nchange and class impact in women\'s and gender studies. Journal of Applied\nSocial Psychology, 33, 2341-2353.\nMalkin, C., & Stake, J.\nE. (2004). Changes in social attitudes and self-confidence in the women\'s\nand gender studies classroom: The role of teacher alliance and student\ncohesion. Sex Roles, 50, 455-468.\nStake, J. E., & Mares, K.\nR. (2005). Evaluating the impact of science enrichment programs on adolescents\'\nscience motivation and confidence: The splashdown effect. Journal\nof Research in Science Teaching, 42, 359-375.\nStake, J. E., & Stanton,\nS. D. (2005). Adolescent girls\' and boys\' science peer relationships and\nperceptions of the possible self as scientist. Sex Roles, 52, 1-11.\nStake, J. E. (2006). Pedagogy\nand student change in the women\'s and gender studies classroom. Gender\nand Education, 18, 199-212.\nStake, J. E. (in press). The\ncritical mediating role of social encouragement for science motivation\nand confidence among high school girls and boys. Journal of Applied\nStudent Research Projects\nThe role of teacher alliance\nand student cohesion in determining the impact of the women\'s studies\nclass on student attitudes toward self and others.\nModerating effects of self-esteem\nand social support on the relationship between dual expectations (instrumentality\nand expressiveness) and well-being.\nPeer influences on gifted high\nschool girls\' motivation and confidence for science education and careers.\nGender differences in self-concept\nacross the adult life span: Relationships to gender roles and life events.\nPredicting resistance to attitude\nchange in the women\'s studies classroom: The nature and importance of\nPredictors of abortion attitudes\nand social activism: The role of performance-self-esteem, social ties\nto activists, biographic constraints, and attitudes toward women.\nThe impact of expressive, instrumental,\nand dual (androgynous) expectations on mental health outcomes.\nGender role adoption and sexual\nfunctioning in women.\nPredictors and mediators of\nfeminist activism in the women\'s and gender studies classroom..\nThe link between gender role\norientation and the experience of premenstrual symptoms on daily and retrospective\nParent and peer relationships\nas predictors of student reactions to their women\'s and gender studies\nMale gender role prescriptions\nand willingness to seek psychological help.\nThe impact of diversity content\nand instruction on the impact of women\'s and gender studies in African\nAmerican, White, and other student groups.\nBody image concerns among African\nAmerican and European American women.\nLinks between indenpendence,\ninterdependence, self-esteem, and life satisfaction.\nThe relation between multicultural\nclass content and changes in social attitudes in the gender studies classroom.\nComparison of self and observer\nratings of expressivity and instrumentality on well-being and adjustment.\nThe benefits of the development\nof feminist attitudes and a feminist identity: Self-esteem and disordered\nFeminist role models as a moderator\nof the relation between the development of quality relationships in the\nwomen\'s studies classroom and class outcomes.', ""Dr Carol A. Ireland\nReader in Aggression\nSchool of Psychology and Humanities\nDr. Carol A. Ireland is a Reader in Aggression. She is also a consultant chartered psychologist, a forensic psychologist and a chartered scientist. She is a Registered EuroPsy Psychologist. She works in clinical practice as well as at the university. Her clinical expertise matches her research interests, including working with clients in regard to aggression, sexual aggression, deliberate self-injury/suicidal ideation, trauma and critical incidents. She is also an accredited EMDR (trauma) therapist.\nDr. Carol A. Ireland publishes widely on the topics of aggression, sexual aggression, sexual exploitation, critical incidents, deliberate self-injury/suicidal ideation and trauma. Dr. Ireland is the Course Director for the MSc Forensic Psychology, and has been in this role for many years (since 2009). She also supervises various PhD and research projects, all fitting within her areas of interest. Dr. Ireland is also the Senior Research Lead at the Ashworth Research Centre (ARC), which is funded by Mersey Care NHS Trust.\nDr. Carol A. Ireland worked for many years in HM Prison Service and in the NHS as a Forensic Psychologist, working full time in the Dispersal Prison Estate (high risk) and then working full time in high secure psychiatric services. Dr. Ireland specialised during this time in working with clients who presented with extensive levels of aggression, sexual aggression and those involved in critical incidents (e.g. barricades, roof top protests and hostage taking). She has maintained her clinical case load by working part time in clinical practice, as well as at the University. She currently works for part of her time at the Coastal Child and Adult Therapeutic Services (CCATS), and which is a large provider of child and adult therapeutic services across the UK. She is a lead clinician in this service, and is also lead for the CCATS International Research Centre.\nShe also maintains links with Mersey Care NHS Trust, and continues to support them as the psychological lead for critical incident management, where she develops the training and trains staff to be critical incident negotiators, and where she further support the management of live incidents as a critical incident advisor. She has been involved in this area of work for over 20 years. She further continues to support the prison estate in the completion of psychological reports for parole hearings for prisoners, as well as engaging as an expert witness in family, civil and criminal court. She further works with victims of abuse, and completes psychological assessments as part of personal injury claims.\nAs a researcher and consultant psychologist, Dr. Ireland is keen to regularly use research to inform teaching for students, and by doing so, to promote excellence and support research impact. This includes ensuring teaching is always research-led, where students are exposed to various research methodologies that they can critique and understand as part of the teaching process (e.g. group led discussions). This has included a variety of Dr. Ireland's research areas, such as sexual exploitation, critical incidents, aggression and deliberate self-injury. Furthermore, a number of Dr. Ireland's past students are/have been forensic psychologists in training/forensic psychologists, and Dr. Ireland has supervised their research post MSc for qualification; a number of the students have progressed on to PhD’s as where Dr. Ireland is keen to support a research culture with students, and do so at various opportunities (e.g. via direct teaching, career events).\n- BSc (Hons) in Applied Psychology, University of Central Lancashire, 1995\n- MSc in Psychology and Criminal Psychology, the Manchester Metropolitan University, 1997\n- Doctor in Philosophy, Thesis titled ‘Problems in Adapting to Prison Life’, University of Central Lancashire, 2001\n- Masters in Business Administration (MBA), Open University, 2010\n- Graduate Certificate with Commendation in Professional Practice in Law: Approved Clinician Training, Northumbria University, 2011\n- Medical LiveWire Global Awards Winner 2016\n- Functions and motivations in regard to offending behaviour (e.g. aggression, sexual aggression)\n- Secondary and vicarious trauma in staff\n- Functions of critical incidents\n- Trauma in victims\n- Chartered Psychologist with the British Psychological Society\n- Associate Fellow of the British Psychological Society\n- Accredited EMDR Therapist with EMDR UK Association\nDr. Ireland focuses mainly on writing on multi-study and longitudinal papers that are considered to meet high standards for the Research Excellence Framework. This allows for high quality research that can inform the research and clinical field more effectively, looking at the application of such work to clinical practice.\nUse the links below to view their profiles:\n- View their unique and persistent identifier on the ORCiD registry\n- Full list of publications and articles on CLoK\n- Forensic Research Group\n- Secondary and Vicarious Trauma in Forensic Staff\n- Secondary and Vicarious Trauma in Police Officers\n- Child Sexual Exploitation cia technology\n- Various projects of Child Exploitation\n- Various projects on Deliberate Self-Injury\n- Funding secured for 3 part-time PhD students, paid for from Mersey Care NHS Trust, various dates\n- Internal grant, University of Central Lancashire, Research Catalyst Scheme, £8,000, 2019\n- 3 year fully-funded PhD scholarship from Mersey Care NHS Trust, 2015\n- Generate income for the Ashworth Research Centre to the University of Central Lancashire, approx £30,000 for 2016 - 2019\n- Secured funding for CQUINN research from Mersey Care NHS Trust for UCLan, £60,000, 2018 - 2019.\n- Ireland, C.A. (2018). INVITED PAPER. Critical incidents in forensic secure care: Motivational themes and implications, 27th September 2018, Violent and Sexual Offenders Conference: Assessment, Treatment and Management, Regents University, London.\n- Ireland, C.A. (2018). KEYNOTE. Staff exposure to psychologically traumatised young people: A systematic review, 28th September 2018, CCATS Excellence Driven Conference, Poulton-le-Fylde, UK.\n- Ireland, C.A. and McKenna, D. (2017). INVITED PAPER. Critical incidents in forensic secure care: motivational themes and implications, 9 – 15th July, International Congress on Law and Mental Health, Charles University, Prague.\n- Ireland, C.A. (2017). INVITED PAPER. Harmful Sexual Behaviour in Male Youth: Developmental factors and overlap with general criminality, Harmful Sexual Behaviour in Children and Young People: Sex, Crime and Punishment conference, South West Yorkshire Partnership, NHS Foundation Trust, 18th October 2017, Wakefield, UK.\n- Ireland, C.A. (2016). KEYNOTE. Harmful sexual behaviour in male adolescents. Harmful sexual behaviour in children and young people: from policy to practice Conference, South West Yorkshire Partnership, NHS Foundation Trust, 10th November 2016, Wakefield, UK.\n- Ireland, C.A. (2014). KEYNOTE. Engagement with aggressive individuals who have cognitive impairment. Royal College of Psychiatrists Section of Neuropsychiatry Meeting, 4 – 5th September, Lady Margaret Hall, Oxford.\n- Ireland, J.L., Ireland, C.A, Wilks-Riley, F and Pinschof, J. (2012). INVITED PAPER. Evaluating Expert Witness Psychological Reports in Family Court. International Association for the study of Attachment Conference, Germany, Frankfurt, 14 – 16th September.\n- Ireland, J.L. and Ireland, C. A. (2012). INVITED PAPER. Getting the best out of your psychology assessment. Merseyside Family Justice Council Day Conference, LACE Conference Centre, Liverpool, 18th October 2012.\n- Ireland, C.A. (2010). INVITED PAPER. Crisis Negotiation: Role of the Crisis Negotiator Advisor. A Flavour of Psychology: British Psychological Society, Nottingham University, November 2010.\n- Ireland, C.A. (2009). INVITED PAPER. Crisis Negotiation: Role of the Crisis Negotiator Advisor. A Flavour of Psychology: Northern Ireland Branch of the British Psychological Society, Queens University, 4th March 2009.\n- Ireland, C. A. (2009). INVITED PAPER. Cognitive Impairment in Sex Offenders. Care and Adoption: Assessments for the Family Courts. Evening Seminar: Family Law, Family Law Chambers, London, 8th December 2009.\n- Ireland, C. A. (2009). INVITED PAPER. Crisis Negotiation: Role of the Crisis Negotiator Advisor. Flavour of Psychology Conference: Northern Ireland Branch of the British Psychological Society, Queens University, Belfast, 4th March.\n- Ireland, C. A. (2008). KEYNOTE. Application of Crisis Negotiation to Mental Disorder. One day workshop. FBI Academy. Washington DC, September.\n- Ireland, C.A. (2008). INVITED PAPER. Crisis Negotiation: Application to Personality Traits, Characteristics and Cognitive Impairment. Police North-West Conference, November 2008, Llandudno, Wales.\n- Ireland, C.A. (2008). INVITED PAPER. Crisis Negotiation: Application to Mental Disorder – challenging traits/behaviours. Division of Clinical Psychology Annual Conference,10 -12 December, Congress Centre, London, UK.\n- Ireland, C.A., & Pitman, I. (2003). INVITED PAPER. The impact of cognitive functioning on intervention work with individuals who have committed sexual offences, Paper presented at Partnerships in Care psychology conference, Reebok Stadium, Bolton, November\nUse the links below to view their profiles:""]"	['<urn:uuid:966e5a0c-a2e9-4f1c-a2bf-8135f245ed8a>', '<urn:uuid:ef6a51c3-23ab-48cb-82ec-5e4c97baad0b>']	factoid	with-premise	concise-and-natural	similar-to-document	comparison	novice	2025-05-12T13:53:09.865574	8	38	2931
59	dash diet sodium reduction recommendations effects	The DASH diet (which includes 7-8 servings of grains, 4-5 servings of vegetables and fruits, and 2-3 servings of low-fat dairy) combined with sodium reduction to 2,400 mg/day can substantially lower blood pressure. However, recent studies suggest that very low sodium restrictions (below 1,500 mg/day) may not be necessary for most people, as most individuals average around 3,400 mg/day without adverse effects.	"['Presentation on theme: ""Hypertension Blood pressure levels are a function of cardiac output multiplied by peripheral resistance (the resistance in the blood vessels to the flow.""— Presentation transcript:\nHypertension The major factors which help maintain blood pressure (BP) include the sympathetic nervous system and the kidneys. Optimal healthy blood pressure is a systolic blood pressure of <120 mmHg and a diastolic blood pressure of <80 <120/80.\nHypertension Approximately one in four American adults has hypertension. As many as 2.8 million children also have high blood pressure. The prevalence of hypertension increases with age.\nPrevalence of Hypertension by Age Age 18-29 30-39 40-49 50-59 60-69 70-79 80+ % Hypertensive 4 11 21 44 54 64 65\nHypertension When the normal regulatory mechanisms fail, hypertension develops. Hypertension is so dangerous because it gives off no warning signs or symptoms.\nUntreated hypertension can result in: Arteriosclerosis--Kidney damage Heart Attack--Stroke Enlarged heart--Blindness\nFactors Influencing the Development of Hypertension High-normal blood pressure Family history of hypertension African-American ancestry Overweight\nFactors Influencing the Development of Hypertension Excess Consumption of Sodium Chloride Certain segments of the population are ‘salt sensitive’ because their blood pressure is affected by salt consumption\nFactors Influencing the Development of Hypertension Alcohol consumption\nFactors Influencing the Development of Hypertension Exercise Less active individuals are 30- 50% more likely to develop hypertension.\nFactors Influencing the Development of Hypertension Other Dietary Factors Potassium: Calcium: Magnesium:\nTreatment for Hypertension Maintain a healthy weight, lose weight if overweight. Be more physically active. Drink alcoholic beverages in moderation. Reduce the intake of salt and sodium in the diet to approximately 2400 mg/day.\nThe DASH Diet DAS H The D ietary A pproaches to S top H ypertension clinical trial (DASH) Diet rich in fruits, vegetables, and low fat dairy foods, can substantially lower blood pressure in individuals with hypertension and high normal blood pressure.\nDash Study Control: Ca, Mg, & K ~ 25% of US diet Macronutrients and fiber ~ US average Fruits and Vegetables Fruits and vegetables increased to 8.5 servings K and Mg to 75% Combination: Add 2-3 servings low-fat dairy to fruit & vegetable diet. Ca, K and Mg increased to 75%\nDash Study Outcomes Fruit and Vegetable Diet: Decrease in systolic and diastolic blood pressure in entire study group and in the hypertensive subgroup. Combination Diet: Significant decrease in both systolic and diastolic blood pressure in both groups. Greatest drop was in systolic BP in hypertensive group (11.4 mmHg)\nDash Diet Implications Combination diet affects comparable to pharmacological trails in mild hypertension. Population wide reductions in blood pressure similar to DASH results would reduce CHD by ~ 15% and stroke by ~27% Great potential in susceptible groups: African Americans and elderly.\nThe DASH Diet DASH Diet The DASH Diet includes: 7-8 servings of grains and grain products 4-5 servings of vegetables 4-5 servings of fruits 2-3 servings of low fat dairy products 2 or less servings of meat, poultry and fish 2-3 servings of fats and oils Nuts, seeds and dry beans 4-5 times /week Limited ‘sweets’ low in fat.\nEffects of increasing Calcium-Rich Dairy Food in Black Hypertensives Increases urinary sodium excretion Decreases volume Decreases peripheral vascular resistance Decrease blood pressure Reduces left ventricular mass and risk of left ventricular hypertrophy Effects sustained for one-year period of study\nSodium in Foods Conversion of milligrams to milliequivalents (mEq): mg/atomic weight x valence = mEq. Atomic weight sodium = 23, valence = 1 2400 mg/23 x 1 = 104.3 mEq sodium\nReducing Sodium in the Diet Use fresh poultry, fish and lean meat, rather than canned or processed. Buy fresh, plain frozen or canned with “no salt added” vegetables. Use herbs, spices and salt-free seasoning blends in cooking and at the table; decrease or eliminate use of table salt. Choose ‘convenience’ foods that are lower in sodium.\nReducing Sodium in the Diet When available, buy low- or reduced- sodium or ‘no-salt-added’ versions of foods like: Canned soup, canned vegetables, vegetable juices cheeses, lower in fat condiments like soy sauce crackers and snack foods like nuts processed lean meats\nFood Labels ClaimAmount Low Sodium>140 mg/serving Very Low Sodium>35 mg/serving Sodium Free>5 mg/serving Reduced Sodium25% less than original', 'This article is a collaboration between MedPage Today® and:\nEfforts to reduce the sodium intake in children and teens had little impact on blood pressure in adolescence, even though the average teenager gets well above the recommended allowance of salt, a new study says.\nWhen researchers looked at the eating pattern of girls aged 9 to 10, and tracked them for a decade, they found that potassium was a more important indicator of blood pressure than sodium.\nHigher sodium intake (3,000 mg/day or greater versus less than 2,500 mg/day) did not appear to adversely impact blood pressure in the prospective study, and longitudinal mixed models even found girls who consumed higher levels of sodium to have lower diastolic blood pressures than girls whose sodium intake did not exceed recommended levels, Lynn L. Moore, DSc, of Boston University School of Medicine, and colleagues wrote online in JAMA Pediatrics.\nHigher potassium intake was inversely associated with blood pressure change throughout the teen years. Girls in the highest category of potassium consumption had lower systolic and diastolic blood pressure in late adolescence (P=0.02 for systolic and P=0.05 for diastolic).\n""Blood pressure rises with age, and we wanted to find out if sodium intake influenced blood pressure through adolescence,"" Moore told MedPage Today. ""We found no evidence of an impact, but higher potassium intake did predict lower blood pressure.""\nAHA Sodium Goal is <1,500 mg/day\nLast fall, the U.S. Centers for Disease Control and Prevention reported that nine out of 10 U.S. children consume more sodium than is healthy. Federal dietary guidelines currently recommend that adults and children consume less than 2,300 mg/day of sodium and the report found that the average child eats about 3,300 mg/day with much of it in children\'s diets coming from processed foods.\nIn an effort to address an epidemic of hypertension among adults and increasing high blood pressure incidence among children, the American Heart Association is recommending a stepwise reduction in sodium intake, with the goal of lowering consumption to less than 1,500 mg per day by 2020.\nAHA spokeswoman Linda Van Horn, PhD, who is a professor of preventive medicine at Chicago\'s Northwestern University Feinberg School of Medicine, said the newly published observational findings do not change this recommendation.\n""The research has shown over and over again that there is really nothing healthy about a high sodium diet and that the majority of the population is consuming far more sodium than is needed,"" she told MedPage Today.\nShe added that processed foods are the main source of sodium in the American diet, and that it is especially important to promote the consumption of whole foods for children and teens to establish healthy eating patterns early.\nMoore pointed out that there is little evidence that restricting sodium intake to less than 1,500 mg/day protects against cardiovascular disease and death. She cited a 2013 Institute of Medicine expert committee report which suggested that this level of restriction may be harmful for some people.\n""The fact is, very low sodium intake is not very sustainable at a population level and it may not be necessary for most people,"" Moore said. ""Despite the recommendations, most people still average around 3,400 mg/day of sodium.""\nIntake Was Self Reported\nVan Horn argued that self-reporting of sodium intake in the study cohort, which included children enrolled in the National Heart Lung and Blood Institute\'s Growth and Health Study, was a significant study limitation.\nDietary assessment was conducted using 3-day diet records on two weekdays and one weekend day during eight of the 10 study years. The study participants were taught by nutritionists how to estimate portion sizes.\n""These researchers used some of the best methodology available, but they did not measure 24-hour urine sodium levels so it is not clear if their measures are accurate,"" Van Horn said.\nThe recommended daily intake of potassium for adults is 4,700 milligrams, but few adults or children achieve this goal, Moore said.\nClose to one in five (19%) girls in the study averaged ≥2,400 mg/day, while a similar percentage averaged 2,100 to <2,400 mg/day; 26% of study participants averaged 1,800 to <2,100 of potassium a day and 36% averaged <1,800.\nGirls who consumed 2,400 mg/day or more of potassium in the study had the lowest adjusted late-adolescent systolic and diastolic blood pressure, and the trend was seen in both black and white study participants.\nBeans, dark leafy greens, dried fruit, avocados, yogurt, bananas and fish are good dietary sources of potassium.\n""The interaction of sodium and potassium could alter blood pressure through a number of mechanisms that involve effects on the kidney, fluid volume, mediators of vascular resistance, vasoconstriction, the renin-angiotensin-aldosterone system, and the sympathetic nervous system,"" the researchers wrote. ""Potassium has been shown to affect response to dietary sodium in both normotensive and hypertensive individuals.""\nThis research was funded by the National Institute of Diabetes and Digestive and Kidney Disease, the National Dairy Council, and the Dairy Council of California.\nThe researchers disclosed no other relevant relationships with industry.']"	['<urn:uuid:8140e59d-ede2-47eb-a8d9-500df172c6fa>', '<urn:uuid:64b8fa71-2b76-47c9-bdaf-26a75f3fe858>']	factoid	with-premise	short-search-query	similar-to-document	multi-aspect	novice	2025-05-12T13:53:09.865574	6	62	1524
60	As a stage lighting professional, I'm intrigued by puppet theater's evolution. How have puppet slams integrated modern lighting technology, and what role do these performances play in contemporary entertainment?	Modern puppet slams exist as underground events featuring short-form puppet and object theater for adult audiences, often performed late at night in small venues, nightclubs, and art spaces. They represent an alternative to mainstream digital media, combining elements of vaudeville, burlesque, and performance art. Regarding lighting technology, these performances can now leverage revolutionary LED lighting fixtures, introduced since 2006, which provide sophisticated color-mixing capabilities and can be installed in restricted spaces. These LED fixtures are particularly effective for subtle and carefully timed gestures, allowing for more naturalistic and dynamic lighting that supports the dramatic values of performances.	['On April 2nd, 2011, I presented The New American Vaudeville: The Puppet Slam Network, at Puppetry and Postdramatic Performance – an International Conference on Performing Objects in the 21st Century hosted by the University of Connecticut in Storrs, CT. In The New American Vaudeville I contextualized growing field of puppet slams – evenings of short-form puppet and object theater for adult audiences. The presentation was informed by my position as co-founder of the Puppet Slam Network which ran from 2005 to 2016.\nUnderground puppet slams have been popping up everywhere. They feature contemporary short-form puppet and object theater for adult audiences, often late at night in small venues, nightclubs, and art spaces. Puppet Slams exist at the nexus of vaudeville, burlesque, and performance art through the intersection of experimental theater, art, music, and dance as a viable alternative to the culturally homogenous digital mass media.\nWhen was the very first puppet slam? Surely there must have been Paleolithic Slams or something like them with cave people projecting shadows onto their walls by torchlight to communicate the location of food. (Read More)\n- June 13, 2012 – National Puppetry Conference,\nEugene O’Neill Center (Waterford, CT)\n- April 2, 2011 – Puppetry & Post Dramatic Performance,\nUniversity of Conneticut (Storrs)\n- July 6th, 2010 – Winnipeg Puppet Collective (Winnipeg, Manitoba)\n- July 2009 – National Puppetry Festival, Georgia Tech (Atlanta, GA)\n- July 2007 – National Puppetry Festival, Concordia University (St. Paul, MN)\nThe New American Vaudville was part of Puppet Theatre in New Contexts, a session chaired by Tim Dugan of St. Francis College. Panelists for Puppet Theatre in New Contexts included:\n- Rick Mitchell from California State University, Northridge with The Ventriloqual Condition (Unplugged)\n- Nenagh Watson from the Central School of Speech & Drama in the United Kingdom with, Ephemeral Animation\n- Janni Younge of Handspring Puppet Company (best known for the puppets in War Horse) from South Africa with Creating Resonance in Emptiness with Puppetry\nFrom the Puppetry and Postdramatic Performance website:\nContemporary developments in theatre, the visual arts, and new media are transforming the artistic, critical, conceptual, and commercial landscape for puppetry, one of the world’s oldest art forms. Today, the term puppetry can be applied to a wide range of objects and images presented in live and mediated performance. These performing objects and animated images continue to appear in traditional venues, but are also exploiting new territories, crossing between artistic worlds, even as traditional boundaries between the arts themselves break down. While theatrical theory is just awakening to the post-dramatic, puppetry has always thrived independently of a dependence on dramatic text. This conference seeks to explore new approaches to critical thinking and theorizing about puppetry and performing objects of all kinds and to bring new multidisciplinary views to bear on the subject of puppetry—conceived in the broadest terms—in order to enrich, expand, and enliven the field of discourse. This conference is the first international scholarly puppetry conference in the U.S.\nTHE NEW AMERICAN VAUDEVILLE PRESENTATION HISTORY\nJune 2012 – Eugene O’Neill Center (Waterford, CT)\nApril 2, 2011 – Puppetry & Post Dramatic Performance Conference, UConn (Storrs)\nJuly, 2010 – Winnipeg Puppet Collective (Winnipeg)\nJuly 2009 – Georgia Tech (Atlanta)\nJuly 2007 – Concordia University (St. Paul)', 'Revolutions in Tech\n50 years of advances in technology and production\nThe stunning pace of technological development since 1970, the year of OPERA America’s founding, has radically altered the process of putting opera onstage and continually expanded the field’s range of production possibilities. In three primary areas especially — lighting, video projections, and sound — the changes have been so revolutionary that they would have been all but unimaginable 50 years ago.\nThe decade of the 1970s was a period of expansion of the role of lighting, as part of the increased emphasis being placed on opera’s dramatic values. “Lighting became more naturalistic and dynamic,” says lighting designer Rick Fisher. “The new theatricality demanded color and nuance to support the drama.” In the late 1970s and early 1980s, computer control boards started making their way into opera houses, their more elaborate cueing giving designers a tool to cultivate more sophisticated lighting plans.\nThe era saw much experimentation with individual light sources, as manufacturers worked to develop fixtures that emitted more light while giving off less heat. ETC’s Source Four fixtures and dimming systems, introduced in 1992, used innovative lamps, along with a reflector, to push more light forward while letting heat pass through the back. It was the beginning of a revolution in lighting sources, moving toward more versatile, powerful equipment.\nThe revolution continued with the rollout of LED lighting fixtures, starting in 2006. In their early years, these went through growing pains: consistency problems in color mixing and range, limited ability to blend with standard fixtures. But in the last decade, their role has matured. Their color-mixing capabilities provide a more responsive palette, and their compact profile allows installation in restricted spaces. Designer York Kennedy notes that LED fixtures are especially effective in bringing out accents in scenery architecture and in throwing even light onto cycloramas and drops. “The new LED fixtures are a great tool for the subtle and carefully timed gestures that opera demands,” Kennedy says.\nLED technology has had a decisive impact on the rig for a production. One fixture — even one in a fixed position — can now do many things. If moving lights can be incorporated into the space and budget, they can expand possibilities for color, beam shape, patterns, and movement. The switch to LED isn’t easy: It means rethinking the infrastructure of opera-house lighting arrangements. The fixtures themselves carry onboard controllers for color, brightness and, in some cases, movement, relegating standard dimmer controlling to the past. “You need more data cable for control and less dimmer room capacity,” notes designer Duane Schuler. It also requires a new level of skill and training for lighting professionals, who must have a deep knowledge of computer controls and complex lighting-control computer networks.\nIn the past half-century, projection technology has become integrated into opera production in ways previously unimagined. All one needs to do is look back at recent examples such as The Dallas Opera’s Moby Dick and Everest, or Santa Fe Opera’s The (R)evolution of Steve Jobs and The Golden Cockerel. Washington National Opera’s recent mountings of Don Giovanni and Samson and Delilah both used the same modular set, but with projections to give the two shows very different looks. In cases like these, projected imagery has become an integral part of production design; indeed, another character within the piece.\nThe burgeoning use of projection stems from breakthroughs in the technology involved. Early projectors were bulky and noisy. It was difficult to place the equipment in a spot where it would be hidden and where the sound could be baffled, while still keeping the lamps cooled. Over the past decade, LED projection technology has changed all that. Current projectors are brighter and more compact. They are also quieter, which makes them easier to hang in locations closer to the audience, such as the front rail of the balcony: the optimum spot for front projections.\nVideo design used to be an analog process. In order for an image to be reworked, using the Pani and Pigi projectors prevalent from the 1970s to the early 2000s, film had to be perforated and spliced: a labor-intensive technique. “The reworking of an image often involved the use of complicated hand-cut masks and the reshooting of film,” says projection designer Elaine J. McCarthy. “You needed a three-day turnaround to see if the changes were correct. Each edit had to be carefully weighed in terms of the time available and the expense of the new slide.” Digital processes, McCarthy notes, have eased turnaround time, and correspondingly lessened the impact on the bottom line.\nPowerful media servers, emerging in the early years of this century, allow for real-time previewing and simultaneous video editing. Designer Driscoll Otto notes that these servers allow production teams to build and preview their work in 3D before they ever enter the theater. This is an especially welcome development in light of the need to share limited rehearsal periods with other production personnel; if the projections are ill-prepared, it steals time from directors and other designers. “While a Broadway production typically has three to four weeks before opening, an opera may only have 10 to 15 hours onstage to coordinate the design elements with the cast and the music,” notes Rick Fisher.\n“As the imagery moved from tape to the digital world, the creation of imagery has moved forward in leaps and bounds,” says designer Ben Pearcy. “Computers and software have allowed much more creativity in design, as well as a much faster response to production needs.”\nOnce only discussed behind closed doors, audio amplification has become in some cases an overt element in opera performance. The modern era of miking in opera began with the 1987 premiere Nixon in China, in which John Adams called for amplification in his scoring. Since then, composers like Adams, David T. Little, and Mason Bates have written works with complex, layered orchestrations that demand voice enhancement. Meanwhile, opera is now being staged in sonically challenging venues: chamber works in black box theaters not designed for music; site-specific productions in spaces chosen for their dramatic appropriateness rather than their acoustic properties. Often, their acoustics demand technological intervention.\nTechnological advances have helped integrate amplification into the mainstream. Clunky, highly visible sound equipment is a thing of the past. Line array loudspeaker systems allow designers to sculpt sound coverage, balance frequency response, and send sound to all areas of the theater, so that the amplification truly augments natural voices rather than just making them louder. Wireless mics are easier to conceal than in the past — an especially important factor in the era of HD filming — and they’re also more reliable and responsive to the broad dynamics of the human voice, resulting in a more natural sound.\nToday’s digital mixing consoles allow for efficient setups, and their recall abilities promote consistency from performance to performance. New digital processing equipment lets designers adjust sound system parameters from anywhere in the theater. “These systems help me quickly address the concerns of the performers, as well as any problems that might be audible to the audience,” says designer Kai Harada.\nKarl Kern, Santa Fe Opera’s A/V director, notes that today’s programmable boards and speaker systems not only enhance the quality of performances, but also keep his budget under control: The process of moving systems in and out of repertory is much less labor-intensive than in the past. Moreover, as with lighting and video, today’s sound design tools allow for comprehensive preplanning and for previewing sounds without chewing up valuable staging time. “The equipment helps us meet deadlines and minimize errors in operation,” Kern says.\nIt isn’t just the instruments that have improved; sound designers now have a more sophisticated understanding of the art and science of amplification. “Savvy and sensitive designers have emerged who use their backgrounds in music, along with the new audio technologies, to build appropriate sound environments and enhance the audience experience,” says sound designer Mark Grey.\nFor all the innovations in sound, lighting, and projection, the technologies that have had the greatest impact on opera production are those that have transformed every aspect of our lives. Consider that in the 1970s, the fax machine represented the cutting edge in professional communication, allowing nearly immediate sharing of contract drafts, measurement charts, and show inventories. To relay information, technical directors put together fax trees, with each recipient forwarding the fax on to a number of others, with the hope that the messages would get through the complicated routing and result in answers.\nIn the age of the computer and the smartphone, faxing seems all but prehistoric. The internet has also made access to advice from other shops and vendors nationally and internationally much simpler. Videoconferencing lets design departments share imagery remotely. File-sharing platforms like Dropbox have streamlined the process of vetting materials and sharing inventories for co-productions and rentals. “It saves a lot of time over sending out slides and discs,” says Corinna Bakken, costume designer at Minnesota Opera. All of this represents a quantum leap in efficiency, as well as a significant cost savings compared to the days of long-distance bills and FedEx charges.\nYork Kennedy relates an instance when he had left a production, and last-minute changes to the show’s blocking necessitated a quick alteration of lighting cues. The theater was able to set up a Facetime stream that allowed him to watch the stage and then work with the programmer and stage manager to adjust the timings to the new staging. “Not ideal by any stretch, but we were able to make it work!” he says.\nTrue, communication advances have not entirely eliminated the need for shipping or for direct, face-to-face contact, but projects can now move along at a much faster clip. Facebook costume groups and OPERA America’s listservs abet the process. “If we are looking for new construction techniques or specialty resources, the world is at our fingertips,” says Marsha LeBoeuf, costume designer at Washington National Opera.\nPhones allow shoppers in the costume and props shops immediately to share images of potential purchases with designers. Another change in the costume-design process has been dictated by the market. Fabric stores have been cutting back on their stock; quite a few stores have disappeared altogether. Vendors that do custom fabric printing are to some extent filling in the gap, and current technology lets shops provide their own artwork. “This keeps costs down and gets us the imagery that the specific designs require,” says Daniele McCartan, costume director at San Francisco Opera.\nFrom an audience standpoint, the most visible technological innovation of recent decades has been the introduction of supertitles, beginning with a Canadian Opera Company Elektra in 1983. In the years since, the creation and use of subtitles have evolved from a time-intensive process, involving making, editing, reprinting, and reordering stacks of projector slides, to an easy-to-manage system of digital projectors and software programs. In 1995, the Met introduced the first seat-back titles, followed soon after by Santa Fe Opera. Titles — both back-of-the-seat and overhead — have been responsible for bringing a new level of accessibility to the art form and arguably for expanding the audience for opera.\nA technician is no longer somebody who carries a wrench or a hammer or a pair of scissors. Today’s production personnel need to have mastery of a vast toolkit of technological resources. Whether it is drafting a show for the scene shop, preparing a high-resolution image for printing a backdrop or run of fabric, or coordinating production elements during a tech rehearsal, they need a sophisticated understanding of computer technology. Fifty years ago, at the birth of OPERA America, this might have seemed pure science fiction. Now it’s a reality.']	['<urn:uuid:9b8349cb-023d-4610-9bb2-c86397387109>', '<urn:uuid:9353321b-6a01-49ea-be1f-b9ac5d2089a4>']	factoid	with-premise	verbose-and-natural	distant-from-document	multi-aspect	expert	2025-05-12T13:53:09.865574	29	97	2489
61	What activities can tourists find at Djemaa El-Fna square?	At Djemaa El-Fna square market, visitors can find food vendors, holistic healers, henna tattoo artists, snake charmers, astrologers, acrobats, and Gnaoua drummers and male belly dancers who perform during dinner time.	"[""Cheap flights to Marrakech, Morocco\nHang on tight – the magic carpet flight to Marrakech will land you in a world of Sultans, Princes and Kings. This Moroccan country, set against a backdrop of mountains and filled with the sights and sounds of centuries past, is full of drama, excitement and a little mystery.\nOften referred to as the “The Rose City,” or “The Jewel of the South,” Marrakech is a country built on symbolism. The jewel symbolizes Marrakech’s importance as Morocco’s trading place. The rose references the city’s pink-painted buildings and landscape. The journey to this ancient country starts on your flight to Marrakech and ends with one of the many festivals that celebrate this city’s grand history and culture. With Berber, Arab, and African influence present in Marrakech, it’s no wonder the country is known as the heartbeat of Morocco.\nFinding cheap flights to Marrakech allows travelers to spend extra cash touring the country. Start in the old city and let your nose guide you. The scents and aromas that fill the air will lead you through open shops and markets throughout the city. Watch the human spectacle take place at the famous Djemaa el-Fna square, perhaps the greatest open-air market in the world, where businessmen walk alongside magicians and snake charmers perform underneath flying acrobats. Window shop on your way to the tanneries, where the money you saved on buying cheap flights to Marrakech will come in handy. Tour the historic monuments and mosques before resting while watching the colorful Moroccan sunset.\nYou’ll find yourself in wonderment with all that Marrakech has to offer. And don’t be surprised if you spot some ancient artifacts along the way… rub the genie lamp and let your magic carpet take you on another flight to Marrakech.\nA land of extremes, Marrakech offers exciting intensity outside. Summers can reach up to 100F in July, and the desert wind whips through the terrain as if on a raid. You may find though, that wind has a bit of a split personality depending on where and when you book a flight to Marrakech. If you’re traveling in April, the Sirocco wind lifts fine sand and dust in the form of nasty sand storms, and but if you’re Oceanside in August, the wind is nothing more than a cooling sea breeze, dragging temperatures to a more tolerable level in the low 80’s. Spring and autumn remain relatively humid, and the winter months, while producing pleasant temperatures in the 70’s, also call for heavy rainfall a few days a week.\nBest Time to Fly to Marrakech\nSummer time brings intense heat, so if you’re booking flights to Marrakech between the months of May and September, be sure to plan strenuous outdoor excursions in early morning or evening to avoid the sun’s powerful rays.\nPeak Season: Despite the serious heat, July and August pack the tourists in, so for some fun in the sun, book flights to Marrakech with most other travelers in the summer time. You’ll also see a great quantity of French tourists making their way to the city during Christian Holy Week to celebrate the Easter holiday. If you’re interested in seeing the city during the religious festivities, be sure to book flights to Marrakech in advance to secure you’re spot in the revelry.\nOff-peak Season: To escape the crowds and enjoy the relaxation that cool evenings bring, book cheap flights to Marrakech between September and December. While dropping temperatures make for chilly nights, the daytime breeze is enough to awaken the senses and refresh the soul. Another autumn attraction is the Muslim Holy month of Ramadan. Most travelers aim to avoid visiting at this time (mid October to mid November) because shops and restaurants close, but it’s also an opportunity for a quieter travel experience.\nGetting around Marrakech\nOnce your flight to Marrakech arrives, you’ll be rearing to go and see the sights. The best way to get straight from the airport to the city’s center is via taxi. With two kinds available, Grands and Petits, you’ll get where you’re going in no time. Most Grands taxis are available outside the airport terminals, and use a set fare system to ensure you’re not being overcharged. Petit taxis are easy to spot because of their uniform beige color, and will take you within city limits, once you get there. Up to three passengers with baggage are welcome aboard, and fares on these are negotiable. If you’re riding at night, decide with your driver on a set fare, because nighttime prices are known to skyrocket.\nOnce you’re in the heart of it all, you may just want to walk around in order to truly take in the sights, smells, and, sounds of such a unique place. When you do, notice that the streets in Gueliz have French names, and are wide enough for two cars to easily pass each other, while in the Medina, more narrow streets are named in Arabic, so pay close attention to keep your bearings. The nearby parks are worth exploring for an afternoon, and both maps and guides are available for your convenience.\nIf you’re going a bit further than you’d like to travel on foot, take advantage of the public bus system. Regular schedules also help get you from place to place in a safe and quick manner. Cheap, frequent, and expansive, it runs from dawn to dusk, and provides night buses for the most popular routes. During rush hour, buses become crowded and boarding can be difficult. Keep calm and move in order. For a more tourist-centered experience, hop on the City Sightseeing Bus. The bright red, open top double-decker has continuous hop-on, hop-off service, and deals on a first-come, first-serve basis. With multilingual tours (in English, French, Italian and Japanese), you’ll roll passed golf courses, monuments and other scenic views within Gueliz and Hiyemage.\nBiking is another popular rental option, but hiring a car is not, especially if you’re unfamiliar with the area’s unmarked, one-way street system.\nMarrakech Travel Information\nAgdal Gardens: Settled in the heart of the Kasbah, the Agdal Gardens serve as a place where Moroccan sultans have greeted dignitaries for more than eight centuries. If you’re booking cheap flights to Marrakech for a brush with royalty, then this is the place for you. Historical conversations have surfaced among the many fruit trees, dense olive orchards, and gorgeous reflecting pools. Looking into the water, you might see a school of carp thirsting for a feed – throw bits of bread in to make their day. Among the beautiful grounds, there are still ceremonies held frequently, but keep an eye on the schedule, because the king can close the garden at any moment, whether he happens to be there or not.\nDjemaa El-Fna: Forget malls and supermarkets and live in the now. Visiting the Djemaa el-Fna square market will plant you in the core of a lively quarter of authentic foods being seared to perfection, sold every moment, and devoured immediately. Dive in to get the full hands-on experience, or find an outdoor seat at a café to watch the commotion unfold. Orange juice vendors next to holistic healers next to henna tattoo artists are only mirrored by other sundry services like snake charmers, astrologers, and acrobats. Around dinner time, you’ll want to stay seated close by, because Gnaoua drummers and male belly dancers will serenade and seduce you right into the Moroccan culture. If you plan on making this a stop on your first night, forego the meal on your flight to Marrakech and bank on an excellent array of local fare.\nEnsemble Artisanal: For a one-of-a-kind shopping experience, head to the state-run complex called Ensemble Artisinal, where set-price boutiques sell everything from hand-crafted tea trays to knitted beanies. Watch colorful strings become woven masterpieces, vibrant fabrics turn into elaborate carpets, and raw materials become baskets and purses. Irregular hours and exceptional bargains make this shopping axis an artery for quality crafts, metals, and ceramics – if you saved money by booking a cheap flight to Marrakech, this is the place to spend your savings. Just make sure to leave baggage room for your return Marrakech flight.\nTea Time: Those who thought tea-time was limited to British afternoons embedded somewhere in a classic novel will be pleasantly surprised when stumbling into a teashop in the medina. Even though your flight to Marrakech might leave you anxiously wanting to check off sights and flash away at scenic views, there’s always a time and a place to remove yourself from the lens, settle into a chair, and steep in the daylight. Take the in atmosphere as “atei banna’na” (hot mint tea) is ceremoniously poured from a small pot into your glass. The aroma, the ritual, and the relaxation are all worth the pause. Most teas are presweetened, so if you’re not a sugar fan, make sure to order it “la sukka.”\nJoin for free and get our tailored newsletters full of hot travel deals.Sign up now\nFlight deals to Marrakech\nUSA departure airports for flights to Marrakech\nSelect the airport or region closest to you to compare the prices of cheap flights to Marrakech\n- New York (NYC)\n- Boston (BOS)\n- Orlando (MCO)\n- Houston (IAH)\n- Detroit (DTT)\n- Chicago (CHI)\n- Dallas (DFW)\n- Memphis (MEM)\n- Miami (MIA)\n- Washington (WAS)\n- Moline (MLI)\n- Tampa (TPA)\n- Los Angeles (LAX)\n- Kansas City (MCI)\n- Raleigh (RDU)\n- Seattle (SEA)\n- Newark (EWR)\n- Denver (DEN)\n- Minneapolis (MSP)\n- San Francisco (SFO)\n- Phoenix (PHX)\n- Baltimore (BWI)\n- Austin (AUS)\n- Cincinnati (CVG)\n- Atlanta (ATL)\n- Mobile (MOB)\n- Philadelphia (PHL)\n- Richmond (RIC)\n- Salt Lake City (SLC)\n- San Jose (SJC)\nThis is useful information about Marrakech\nMore useful information about Marrakech\n- Morocco's climate is moderate and subtropical, cooled by breezes off the Mediterranean Sea.\n- Marrakech, the “red city”, sits against the High Atlas Mountains.\n- Visitors take last minute flights to Morocco for the country’s impressive crafts.\n- Book a direct flight to Morocco and go to one of the colorful outdoor markets in Marrakech, Fès or Rabat.\n- Rabat, the capital, overlooks the Atlantic. Tourist must-sees include the Mausoleum of Mohammed V and Hassan Tower.\n- Shared taxis carrying up to six passengers are very popular and are a cheap way to get around the country.\n- On the Atlantic-Mediterranean coastline, June through September are the most pleasant times to visit.\n- One way flights to Morocco will allow you to see the Fes el-Bali (Old Fes) medina that dates from the 8th century.""]"	['<urn:uuid:c25d3f4d-4251-4ed0-b1d6-f306a94db75d>']	factoid	direct	concise-and-natural	similar-to-document	single-doc	expert	2025-05-12T13:53:09.865574	9	31	1772
62	aristotle natural theology relationship revealed religions cosmological arguments	Aristotle's approach to natural theology was unique because he lived before the emergence of Judaism, Christianity, and Islam. Unlike later thinkers who treated natural theology as an inquiry about the source of divine self-revelation, Aristotle's conception of God was more detached and uninvolved, similar to the gods of Epicurus. His God came closest to prescribing human conduct in the Nicomachean Ethics, where he suggests that the divine life consists in contemplation. Later cosmological arguments, developed by medieval Islamic, Jewish, and Christian thinkers, took different approaches, such as the kalam argument which tried to prove the universe had a beginning, and the Thomist argument which sought to prove an Uncaused Cause or First Cause of existence.	"['Naturalism and Religion\nKai Nielsen\'s quest to explain the roots of atheism, reviewed by Antony Flew\nThis is an enormous book of somewhere between two hundred and two hundred and fifty thousand words. Nielsen explains that in it he ""seeks clearly to articulate and render plausible naturalism and, what ineluctably goes with it, atheism. It seeks, that is, not only to articulate and explicate to perspicuously display naturalism, but as well to give sound and rounded defence of naturalism. It seeks to provide a narrative, replete with argument and with a vision of things, that makes being a naturalist something desirable to be.""\n|NATURALISM and RELIGION|\nWhat gives me pause is the word \'ineluctably\'. For here the word \'nature\' is presumably construed as referring to the Universe and everything in it, the total possible subject matter of all possible human sciences. But the God (or Gods) of all the three great deisms is (or are) the essentially external initiating and sustaining cause (or causes) of the existence of the Universe itself. So why should we think that the study of nature, in the present understanding, warrants a positive as opposed to a negative atheism; an atheism, that is to say, in which the \'a\', of the word \'atheism\' is construed as it is in the words \'atypical\', \'amoral\' and \'asymmetrical\'?\nMost recent contributions to natural theology, both positive and negative including my own have paid scant attention to the founder of that field of study. Thus the index to Nielsen\'s book contains no entry for Aristotle. And if you look up the four for Plato you will find no actual mention of any dialogue. Aristotle, described in the Middle Ages as ""the Master of all that know"", is here crucially important for what he did not know.\nFor Aristotle lived before the emergence of any of the three great revealed systems, Judaism, Christianity and Islam. But since then almost everyone who has given sustained attention to natural theology has treated it as an enquiry about the existence of the logically presupposed source of a putative self-revelation; and for such enquirers accounts of these putative self revelations have been handed down and made familiar by generations of parents and pedagogues, of priests and rabbis, of imams and ayatollahs.\nSurely to anyone who was for the first time and without prejudice entertaining the hypothesis that our Universe is the creation of an omnipotent and omniscient personal Being it would appear obvious that everything which occurs or does not occur within it must, by the hypothesis, be precisely and only what its Creator wants, indeed causes, to occur or not to occur. What scope is there for creatures in such a Universe to defy the will of their Creator? What room even for the concept of such defiance? For a Creator to punish creatures for what by the hypothesis that Creator necessarily and as such (ultimately) causes them to do would be the most monstrous, perverse, unjust and sadistic of performances.\nAbsent revelation to the contrary, the expectations of natural reason must surely be that such a creator God would be as detached and uninvolved as the gods of Epicurus. Indeed some Indian religious thinkers not prejudiced by any present or previous Mosaic commitments are said to describe their monotheistic God as being essentially and in the nature of the case, ""beyond good and evil"". And the closest which Aristotle\'s God comes to prescribing or proscribing any kind of human conduct and it is almost as far as it would possibly be from actually doing so is when in his Nicomachean Ethics (not Aristotle\'s God but) Aristotle tells us that ""the divine life, which surpasses all other in blessedness, consists in contemplation.""\n* * *\nSince my own two anti-theological books were both written long before either the development of the Big Bang Cosmology or the introduction of the Fine Tuning Argument from the physical constants, I will seize this chance to indicate my response to these arguments. It is that while neither can provide substantial evidencing reason for accepting the existence of God, both may constitute impressive confirming evidence for beliefs already held.\nThus the Big Bang Cosmology appears to reveal that the Universe had a beginning. It therefore confirms an essential of traditional Roman Catholic teaching. When Aquinas developed the Five Ways, which did not even attempt to prove this essential, it was apparently rumoured that he had thus lapsed into heresy. He responded, in a pamphlet happily entitled \'Concerning the Eternity of the World Against the Murmurers\', that although he was unable to produce a philosophical argument to prove that the Universe had a beginning he of course believed it as a truth of the Catholic faith.\nThe Fine Tuning Argument is believed by its sponsors to constitute a powerful evidencing reason for believing in a God who intended that the Universe He created should contain a planet upon which the human race could and would evolve. While again not accepting that this constitutes such a reason for unbelievers, I would again insist that believers are right to see it as confirmation.\nTo illustrate these points about confirmations of antecedent beliefs I recommend a book recommended to me by Richard Dawkins for its total discrediting of Michael J Behe\'s Darwin\'s Black Box: The Biochemical Challenge to Evolution (New York: Simon and Schuster, 1996). That book is Kenneth Miller\'s Finding Darwin\'s God (New York: Harper Collins, 1999). Miller is a cradle Catholic, but that does not prevent him from destroying Behe\'s argument point by point, and making scathing comments on Behe\'s failure to attend to recent relevant research findings in what is after all Behe\'s own field.\nNaturalism and Religion is available from Amazon UK', 'Overview of the Cosmological Argument\nWilliam Lane Craig\nIn contrast to the ontological argument, the cosmological argument assumes that\nsomething exists and argues from the existence of that thing to the existence of a\nFirst Cause or a Sufficient Reason of the cosmos. This argument has its roots in\nPlato and Aristotle and was developed by medieval Islamic, Jewish, and Christian\nthinkers. It has been defended by such great minds as Plato, Aristotle, ibn Sina, al-Ghazali, ibn Rushd, Maimonides, Anselm, Aquinas, Scotus, Descartes, Spinoza,\nBerkeley, Locke, and Leibniz. The cosmological argument is really a family of\ndifferent proofs, which can be conveniently grouped under three main types.\nThe kalam cosmological argument originated in the attempts of Christian thinkers\nto rebut Aristotle’s doctrine of the eternity of the universe and was developed by\nmedieval look at the formulation of this argument by al-Ghazali (1058-1111). He\nreasons, “Every being which begins has a cause for its beginning; now the world is\na being which begins; therefore, it possesses a cause for its beginning.”1 In\nsupport of the first premise, that every being that begins has a cause for its\nbeginning, Ghazali reasons: anything that begins to exist does so at a certain\nmoment of time. But since, prior to the thing’s existence, all moments are alike,\nthere must be some cause that determines that the thing comes to exist at the\nmoment rather than earlier or later. Thus, anything that comes to exist must have\nThe second premise is that the world, or the universe, began to exist. In support\nof this premise Ghazali argues that it is impossible that there should be an infinite\nregress of events in time, that is to say, that the series of past events should be\nbeginningless. He gives several reasons for this conclusion. For one thing, the\nseries of past events comes to an end in the present–but the infinite cannot come\nto an end. It might be pointed out that even though the series of events has at\none end in the present, it can still be infinite in the other direction because it has no\nbeginning. But Ghazali’s point may be that if the series is infinite going back into\nthe past, then how could the present moment arrive? For it is impossible to cross\nthe infinite to get to today. So today could never arrive, which is absurd, for here\nwe are! Second, if the number of past events were infinite, that would lead to\ninfinites of different sizes. For suppose Jupiter completes an orbit once every\ntwelve years and Saturn once every thirty years and the sphere of the stars once\nevery thirty-six thousand years. If the universe is eternal then each of these\nbodies has completed an infinite number of orbits, and yet one will have completed\ntwice as many or thousands of times as many orbits as another, which is absurd.\nFinally, if we take the orbits completed by just one of these planets, we may ask,\nis the number of orbits it has completed odd or even? It would have to be one or\nthe other, and yet it is absurd to say the infinite is odd or even. For these reasons,\nthe universe must have had a beginning.\nTherefore, the universe must have a cause of its beginning, which Ghazali identifies\nwith God, the Eternal.\nThe Thomist cosmological argument is based on the impossibility of an infinite\nregress of simultaneously operating causes. It seeks a Cause that is First, not in\nthe temporal sense, but in the sense of rank or source. Although Thomas Aquinas\n(1225-74) did not originate this line of reasoning, he is famous for his clear\nsummary of it in his Five Ways of proving that God exists.2 We shall look at his\nfirst three ways, which are different versions of the argument for a First Cause.\nThe First Way is the proof for an Unmoved Mover based on motion. We see in the\nworld that things are in motion. But anything that is in motion is being moved by\nsomething else. For a thing that has the potential to move cannot actualize its\nown potential; some other thing must cause it to move. But this other things is\nalso being moved by something else, and that is also being moved by something\nelse, and so on. Now this series of things being moved by other things cannot go\non to infinity. For in such a series, the intermediate causes have no power of their\nown but are mere instruments of a first cause. It is important to keep in mind that\nAquinas is thinking here of causes that all act simultaneously, like the gears of a\nmachine, not successively, like falling dominoes. So if you take away the first\ncause, all you have left are the powerless instrumental causes. It does not matter\nif you have infinity of such causes; they still could not cause anything. Aquinas\ncontend, in effect, that a watch could not run without a spring even if it had an\ninfinite number of gears, or that a train could not move without an engine even if it\nhad an infinite number of box cars. There must be a first cause of motion in every\ncausal series. For all self-moving things–including humans, animals, and plants–this\nwould be the individual soul, which is an unmoved mover. But souls themselves\ncome to be and pass away and thus cannot account for the eternal motion of the\nheavenly spheres. In order to account for this cosmic motion, we must postulate\nan absolutely Unmoved Mover, the First Cause of all motion, and this is God.\nThe Second Way attempts to prove the existence of a First Cause of existence\nbased on causation in the world. We observe that causes are ordered in series.\nNow nothing can be self-caused, because then it would have to bestow existence\non itself, which is impossible. Everything that is caused is therefore caused by\nsomething else. Aquinas thinks here of the same sort of simultaneous causal\nseries as he did in the First Way, except that here the causes are of existence, not\nmotion. The existence of any object depends on a whole array of contemporary\ncauses, of which each in turn depends on other causes, and so forth. But such a\ncausal series cannot go on to infinity, for the same reason I explained above.\nTherefore, there must be a First Cause of the existence of everything else, which is\nsimply uncaused; and this everyone calls “God.”\nThe Third way is the proof for an Absolutely Necessary Being based on the\nexistence of possible beings. We see in the world beings whose existence is not\nnecessary but only possible. That is to say, these beings do not have to exist, for\nwe see them come to be and pass away. If they were necessary, they would\nalways exist. But all beings cannot be merely possible beings, for if everything\nwere merely possible, then at some point in time everything would cease to exist.\nAquinas here presupposes the past eternity of the world and appears to reason\nthat in infinite time all possibilities would be realized. Hence, if every being, including\nmatter i8tself, were only a possible being, then it is possible that nothing would\nexist. Thus, given infinite past time, this possibility would be realized and nothing\nwould exist. But then nothing would now exist either, since out of nothing, nothing\ncomes. Since this is obviously absurd, not all beings must be possible beings.\nSome being or beings must be necessary. In fact, Aquinas believed that there\nwere many necessary beings: the heavenly bodies, angels, even matter itself.\nNow, he continues, where do these necessary beings get their necessity–from\nthemselves or from another? Thomas here distinguishes between a thing’s\nessence and existence. A thing’s essence is its nature, that set of properties which\nit must possess in order to be what it is. For example, the essence of man is\n“rational animal.” If anything lacked either of these properties, it would not be a\nman. A thing’s existence, on the other hand, is its being. Now if a being is not\nnecessary in itself, this means that its essence is distinct from its existence. It\ndoes not belong to its nature to exist. For example, I could think of the nature of\nan angel without ever knowing whether or not an angel actually exists. Its essence\nis distinct from its existence. Hence, if such a being is to exist, something else\nmust conjoin to its essence an act of existence. Then it would exist. But there\ncannot be an infinite regress of necessary beings that get their existence from\nanother. (The reasoning is the same as that in the First Way, against an infinite\nregress.) So there must be a First Being, which is absolutely necessary in itself. In\nthis Being, essence and existence are not distinct; in some mysterious way its\nnature is existence. Hence, according to Aquinas, God is Being itself subsisting\n(ipsum esse subsistens). God is pure Being and is the source of being to\neverything else, whose essences do not involve their existing.\nThe Leibnizian cosmological argument was developed by the German\nmathematician and philosopher G.W.F. Leibniz (1646-1716) and is often confused\nwith the Thomist cosmological argument. But Leibniz does not argue for the\nexistence of an Uncaused Cause, but for the existence of a Sufficient Reason for\nthe universe.3 The difference will become clear as we proceed.\n“The first question which should rightly be asked,” wrote Leibniz, “will be, Why is\nthere something rather than nothing?” That is, why does anything at all exist?\nThere must be an answer to this question, because “nothing happens without a\nsufficient reason.”4 Leibniz’s famous Principle of Sufficient Reason holds that there\nmust be a reason or rational explanation for the existence of one state of affairs\nrather than another. Why does the universe exist? The reason cannot be found in\nany single thing in the universe, for these are contingent themselves and do not\nhave to exist. Nor is the reason to be found in the whole aggregate of such things,\nfor the world is just the collection of these contingent beings and is therefore itself\ncontingent. Nor can the reason be found in the prior causes of things, for these\nare just past states of the universe and do not explain why there are any such\nstates, any universe, at all. Leibniz asks us to imagine that a series of geometry\nbooks has been copied from eternity; such an infinite regress would still not explain\nwhy such books exist at all. But the same is true with regard to past states of the\nworld: even should these be infinite, there is no sufficient reason for the existence\nof an eternal universe. Therefore, the reason for the universe’s existence must be\nfound outside the universe, in a being whose sufficient reason is self-contained; it is\nits own sufficient reason for existing and is the reason the universe exists as well.\nThis Sufficient Reason of all things is God, whose own existence is to be explained\nonly by reference to Himself. That is to say, God is a metaphysically necessary\nThis proof is clearly different from the Thomist argument: there is no reference to\nthe distinction between essence and existence, nor to the argument against an\ninfinite causal regress. Indeed, Leibniz is not seeking a cause at all but an\nexplanation for the world. Thomas concludes to an Uncaused Cause, but Leibniz to\na Self-Explanatory Being. Many philosophers have confused these and come up\nwith God as a Self-Caused Being, which neither Aquinas nor Leibniz defended.\nThus, there is a variety of cosmological arguments, which need to be kept distinct,\nfor arguments against one version may prove inapplicable to another.\nFootnote numbering has been adjusted for this excerpt\n1. AL-Ghazali, Kitab al-lqtisad fi’l-tiqad, p. 203\n2. Thomas Aquinas Summa Theologiae 1a.2, 3; cf. Idem Summa contra gentiles\n3. G.W.F. von Leibniz, “On the Ultimate Origin of Things,” pp. 527-28; idem,\n“Monadology,” p. 540; idem, Theodicy, p. 127.\n4. Leibniz, “Nature and Grace,” p. 527.\nTaken from Apologetics: An Introduction (pgs. 62-66) by William Lane Craig. Copyright © 1984 by\nThe Moody Bible Institute of Chicago. Permission kindly granted to Faith and Reason Forum by\nMoody Publishers, 820 N. LaSalle Blvd., Chicago, IL 60610-3284.']"	['<urn:uuid:3568a190-c626-4ca8-afe3-bac26593690f>', '<urn:uuid:b5a54c64-c5ff-4b2c-aa3c-4a15d3e2b8e8>']	open-ended	direct	long-search-query	similar-to-document	multi-aspect	expert	2025-05-12T13:53:09.865574	8	115	3020
63	How do you mark decimal numbers and what's their measurement precision?	Decimal numbers are marked with a point as the decimal separator. For measurement precision, when taking multiple readings, the precision depends on the instrument's markings - for example, burets are marked in 0.05 mL steps and measurements should be reported with the last digit being the only uncertain one.	"[""If your text contains a numeric expression that you do not want to use in the calculation, use quotation marks (”...” or '...'). The content between quotes shall not be computed. Similarly, you can use the division of the text by a colon (:) all text before the colon will be neglected.\nYour operations will be calculated according to the correct mathematical order. So, if you entered 100+100/100 the result will be 101, and not 2, since division has precedence over addition. Parentheses can be used instead, in order to discern order of operations , for example: (100+100)/100, which will trigger the result of 2.\nThe program uses the point as decimal separator, as shown in the system settings. You can check this option in the System Settings.\nThe first version of Numi delineates the input of a title and an expression. With version 2, you can say goodbye to such a limitation. If you still want to use titles with numbers, simply use quotation marks or a colon, as described above.\nNumeric expressions might have a suffix that will be displayed with a smaller font size. To use this feature, the suffix must immediately follow the number (without spaces).\n20things × $100\nNumi uses regular operation keys and formats them accordingly. So, for example, you will use '/' for division, and it will be automatically formatted as '÷' in Numi. The same rule applies for multiplication: you will use the '*' sign, and this will be formatted as '×' in Numi. The multiplication sign is very similar to the 'x' from your keyboard, but using the x letter will mean to Numi just regular text.\nSome fonts do not inherently contain glyphs for mathematical symbols. In this case, instead of multiplying or dividing signs, you will see random characters, or even blank signs.\nIn order to fine-tune the precision of your results, go to Preferences and enter the number of digits to be displayed after the decimal point.\nWhen you click on a result, the value will be instantly copied to the clipboard. When you copy text, for selected rows the result will be copied, as well.\nTo declare variables use the equal sign (=). Using variables in calculations is allowed only after they are declared (i.e., below declaration).\nPrice = $100\nTotal = price + 18% tax\nIn order to use both text and variables, use quotation marks or colon. The variable names are not case-sensitive. To declare multiple variables on the same line, use a semicolon as a delimiter.\nTrigonometric functions. Argument by default in radians:\nTo use argument in degrees, use the sign ° as suffix (Alt + Shift + 8 on Mac OS, Alt+248 on Windows). For example:\nsin30° sin(30)° not sin(30°)\nOther operations and constants:\nTo calculate 100% of a value, if only part of it is known, divide by the percentage:\n25÷10% → 250 25 — is 10% of the value.\nTo calculate a percentage of a value, multiply by a percentage:\n25×10% → 2,5 Find 10% of 25."", 'Calculating Error In Chemistry\nRebecca Sims 2,681 views 4:12 Professor Hunter- Epic Chemistry Teacher - Duration: 2:58. The 10 milliliter burets used are marked (graduated) in steps of 0.05 mL. Brian Lamore 46,677 views 18:37 Chemistry Percent Error - Duration: 2:08. This means that the true value of the volume is determined by the experiment to be in the range between 8.95 and 9.01 mL Multiplication and division: Uncertainty in results depends http://bestwwws.com/how-to/calculating-experimental-error-chemistry.php\nHe obtains the following results: 101mL, 102mL, and 101mL. Appendix A of your textbook contains a thorough description of how to use significant figures in calculations. Brightstorm 176,797 views 5:17 Percent of Change - Duration: 6:29. The confidence interval is defined as the range of values calculated using the following equation (6) where t is the value of the t statistic for the number of measurements averaged http://sciencenotes.org/calculate-percent-error/\nCalculating Standard Deviation Chemistry\nIn this case, the main mistake was trying to align one end of the ruler with one mark. Let\'s consider the following table of results. Here are two examples: A.\nYou might also enjoy: Sign up There was an error. Favorite Favoriting this resource allows you to save it in the “My Resources” tab of your account. Low accuracy, high precision On this bullseye, the hits are all close to each other, but not near the center of the bullseye; this is an example of precision without accuracy. How To Determine Experimental Error In fact, if you run a number of replicate (that is, identical in every way) trials, you will probably obtain scattered results.As stated above, the more measurements that are taken, the\nFinally, the error propagation result indicates a greater accuracy than the significant figures rules did. Calculating Uncertainty Chemistry For result R, with uncertainty σR the relative uncertainty is σR/R. Most analysts rely upon quality control data obtained along with the sample data to indicate the accuracy of the procedural execution, i.e., the absence of systematic error(s). http://chemistry.about.com/od/chemistryquickreview/a/experror.htm Precision of Instrument Readings and Other Raw Data The first step in determining the uncertainty in calculated results is to estimate the precision of the raw data used in the calculation.\nIf it is less than the true value, the percent error will be negative. How To Find Error In Science Sign in to make your opinion count. In general, results of observations should be reported in such a way that the last digit given is the only one whose value is uncertain due to random errors. The key terms are ""accurately weigh"" and ""about 0.2 g"".\nCalculating Uncertainty Chemistry\nYou measure the sides of the cube to find the volume and weigh it to find its mass.\nPlease try again. Calculating Standard Deviation Chemistry Relative uncertainty expresses the uncertainty as a fraction of the quantity of interest. Calculating Error Physics Review Your Chemistry Concepts Percent Error Definition See How To Calculate Absolute and Relative Error Quick Review of Experimental Error More from the Web Powered By ZergNet Sign Up for Our\nProfessor Heath\'s Chemistry Channel 4,699 views 3:33 IB Physics: Uncertainties and Errors - Duration: 18:37. click site For example a result reported as 1.23 ± 0.05 means that the experimenter has some degree of confidence that the true value falls in between 1.18 and 1.28. • When significant This eliminates the systematic error (i.e., the error that occurs in each measurement as a result of the measuring process itself) that aligning one end with one mark introduces. Otto\'s measurements are ___________. Percent Error Chemistry\nDMSFlippedMath 21,730 views 7:11 Calculating Percent Error & Increase - Duration: 8:29. This could be the result of a blunder in one or more of the four experiments. The difference between the actual and experimental value is always the absolute value of the difference. |Experimental-Actual|/Actualx100 so it doesn\'t matter how you subtract. http://bestwwws.com/how-to/calculate-error-chemistry.php Gossett, who was an employee of Guinness Breweries and who first published these values under the pseudonym ""A.\nIt is often used in science to report the difference between experimental values and expected values.The formula for calculating percent error is:Note: occasionally, it is useful to know if the error How To Calculate Percent Error Chemistry Experiment If this was your experiment, the results would mean that you have determined the concentration to be, at best, 0.119 ± 0.001 M or between 0.118 and 0.120 M. The standard deviation of a set of results is a measure of how close the individual results are to the mean.\nView all posts by Todd Helmenstine → Post navigation ← Direct Image Of Exoplanet Sets New Record Using Stem Cells and Herpes To Fight Brain Cancer → 3 thoughts on “Calculate\nThank you,,for signing up! Now have an ""accurately known"" sample of ""about 0.2 g"". Now for the error propagation To propagate uncertainty through a calculation, we will use the following rules. Calculating Percent Yield Chemistry Just to be on the safe side, you repeat the procedure on another identical sample from the same bottle of vinegar.\nConsider three weighings on a balance of the type in your laboratory: 1st weighing of object: 6.3302 g 2nd weighing of object: 6.3301 g TheChemistrySolution 147,057 views 5:52 Loading more suggestions... The standard deviation is given the symbol s and can be calculated as follows: (4) The standard error of the mean is a measure of the uncertainty of the mean and More about the author Furthermore, they are frequently difficult to discover.\nSign in to report inappropriate content. Returning to our target analogy, error is how far away a given shot is from the bull\'s eye. About Todd HelmenstineTodd Helmenstine is the physicist/mathematician who creates most of the images and PDF files found on sciencenotes.org. With multiple measurements (replicates), we can judge the precision of the results, and then apply simple statistics to estimate how close the mean value would be to the true value if\nFor limited data sets (n = 3 to 10), the range (Xn-X1), where Xn is the largest value and X1 is the smallest value, is a good estimate of the precision The Q test involves dividing the difference between the outlier and it\'s nearest value in the set by the range, which gives a quotient - Q. The actual amount of tea in the mug is 120mL. Kandra Auwerda 870 views 2:08 Percent of Change - Duration: 7:11.\nIf an analytical balance has a calibration error of +0.04 grams, then: Key Term Reference acid Appears in these related concepts: The Halogens (Group 17), Basic and Amphoteric Hydroxides, and Calculating Calculate Percent ErrorLast modified: January 28th, 2016 by Todd HelmenstineShare this:GoogleFacebookPinterestTwitterEmailPrintRelated This entry was posted in Measurement and tagged example problems, experiments, homework help, measurement, percent error on May 16, 2014 The balance allows direct reading to four decimal places, and since the precision is roughly 0.0001 g, or an uncertainty of ± 1 in the last digit, the balance has the Did you mean ?\nAccuracy and Precision The accuracy of a set of observations is the difference between the average of the measured values and the true value of the observed quantity. Similarly, readings of your Celsius (centigrade) scale thermometer can be estimated to the nearest 0.1 °C even though the scale divisions are in full degrees. Thanks, You\'re in! The uncertainty in the mass measurement is ± 0.0001 g, at best.']"	['<urn:uuid:8e054da8-ddee-428c-a79a-0735a750096d>', '<urn:uuid:37ec2cea-1e85-4088-8733-2aa4d198aa05>']	factoid	direct	concise-and-natural	similar-to-document	multi-aspect	novice	2025-05-12T13:53:09.865574	11	49	1724
64	basic elements biological neural network	The basic elements of the neural network system are neurons, axons, dendrites and synapses.	['We want our machines to learn everything on their own as much as possible. Over the past few decades, researchers have come up with many theories and formulations about how we can achieve this in the best possible way. This realm is called machine learning. We come up with algorithms to teach the machines how to learn. I have discussed more about machine learning here. Human brain seems to achieve this rather effortlessly. Our ultimate goal is to make the machines as good as our brains, or even better. The formulation of Artificial Neural Network (ANN) is an attempt towards this.\nWhat is a neural network?\nNeural networks refers to the central nervous system in the human brain. It consists of neurons, axons, dendrites and synapses. These are the basic elements of the system and each of them have different functionalities. The transfer of information in the brain occurs with the help of electrical signals and neurons are responsible for this. Neuron is an electrically excitable cell which helps in the transfer of information to and from the brain. The interconnections between neurons form the biological neural network. There are about 100 billion neurons in a human brain.\nWhat is an artificial neural network?\nNow we take inspiration from the human brain and try to mimic the functionality using a mathematical formulation. Even after all the advances in technology, human brain is still very obscure and we don’t completely understand how it functions. ANN refers to a mathematical model which is inspired by the biological neural network. It consists of artificial neurons, which act as simple processing elements. ANNs are parallel cascaded systems, which means that information is processed simultaneously by multiple processing elements and the output is fed to the next stage of neurons. Most ANNs are adaptive and they change their structure based on the input, output and the feedback, just like the neurons in our brain.\nHow do we use this in machine learning?\nANNs are mainly used as pattern classifiers in the realm of machine learning. Since it is adaptive, each parameter can change during its operation and it is deployed for solving the problem at hand. This is called the training phase. ANNs need a lot of training data to come up with a robust model.\nANN is developed with a step-by-step procedure which optimizes a criterion commonly known as the learning rule. The input/output training data is fundamental for these networks as it conveys the information which is necessary to discover the optimal operating point. This concept is a bit similar to Reinforcement Learning. If you have read my previous blog about machine learning, I use the analogy of a baby named John. Just like how John updates his knowledge based on his experiences, an ANN also updates itself using the feedback. In addition, the non linear nature makes neural network a very flexible system.\nAn ANN is basically a system which receives an input, processes the data, and provides an output. Once an input is presented to the neural network, and a corresponding desired or target response is set at the output, an error is composed from the difference of the desired response and the real system output.\nThe error information is fed back to the system which then makes all the required adjustments to its parameters in a systematic fashion. This process is repeated until the desired output is acceptable. It is important to notice that the performance hinges heavily on the data. What I mean to say is that if you don’t provide a wide variety of data, then the ANN might fail in a few scenarios.\nIf we consider the example of baby John discovering eating items, we can say that the error will be more if he chews something really hard by mistake. It means John will have to be very careful about these kind of objects. But if he chews something soft which is not a fruit, the error is not that large. This object didn’t cause any harm to his teeth, it’s just that he cannot bite it off and eat it. If he already knew that such objects exist, he will probably not attempt to eat them. This is why ANNs need wide variety of data to train.\nThere are many different types of ANNs and all of them have their own algorithms and formulations. ANNs are one of the more recent machine learning algorithms to be developed. The field of work is very interdisciplinary. They are being increasingly used to find patterns in data and in the field of artificial intelligence in general.']	['<urn:uuid:b838e831-44a5-4e7c-9e5d-5e709c77c5c7>']	factoid	direct	short-search-query	similar-to-document	single-doc	expert	2025-05-12T13:53:09.865574	5	14	768
65	time waiting expect improvement child ear infection cefdinir treatment begin	You should expect improvement within 48 to 72 hours after starting cefdinir for an ear infection. If improvement is not seen within this timeframe, contact your doctor to discuss switching to another antibiotic, such as ceftriaxone or clindamycin.	"[""Cefdinir is an antibiotic used to treat many different types of bacterial infections in children. You might see a brand name such as Omnicef on the label. It belongs to the cephalosporin family of antibiotics (“cousins” to the penicillins). This antibiotic comes as strawberry and cream flavored liquid or as capsules.\nEither form can be given with or without food. However, cefdinir should be taken at least two hours before any multivitamins with iron, iron supplements, or antacids that contain magnesium or aluminum, because these can interfere with the absorption of the antibiotic. Infant formula with iron does not pose a problem.\nLiquid cefdinir should be shaken before giving each dose. To get the correct dose, skip the silverware spoon and use a measuring spoon or dose-measuring device (ask your pharmacist for one if you don’t have one). It may be stored at room temperature. Discard any unused cefdinir 10 days after it was first prepared by the pharmacist.\nCefdinir is a recommended first antibiotic for some children with ear infections who are allergic to amoxicillin. It can be taken once or twice a day. Taking the dose once a day is usually as effective as dividing the dose in two, but the smaller doses may be gentler on the stomach. If you happen to miss a twice-a-day dose, you can go ahead and give it late, but try not to give once-a-day doses within about 12 hours of each other. If you happen to give too much at once (more than two doses), seek medical advice.\nIf your child is taking cefdinir for an ear infection, you should expect improvement within 48 to 72 hours. If not, contact your doctor to discuss switching to another antibiotic, such ceftriaxone or clindamycin.\nDo Not use cefdinir if your child is known to be allergic to this or to any of the cephalosporin antibiotics, such as cephalexin, cefuroxime, or ceftriaxone. Other antibiotic options might include azithromycin, clarithromycin, or clindamycin. Be sure the prescribing doctor knows if your child has any other medication allergies (especially to penicillins), or has kidney disease, intestinal problems. Be sure to report any other medicines your child might be taking.\nDiarrhea is a common side effect of antibiotics. Whenever antibiotics are given, consider also giving your child probiotics (beneficial bacteria). Out of ten well-designed studies, nine showed significantly less diarrhea in the children receiving probiotics (the studies used between 5 and 40 billion cfu per day). Probiotics are available as supplements or in some foods and beverages (yogurt, kefir, juice). Whatever you choose, look for at least 5 billion colonies.\nGet emergency care if your child is showing signs of a serious allergic reaction, such as difficulty breathing, spreading hives, or swelling of the lips, tongue, or throat.\nOther side effects are possible with this or any medication. Be sure to report unexpected new symptoms to your healthcare provider. Whether they are caused by the antibiotic or by the illness getting worse, unexpected symptoms are important to report.\nAAP Clinical Practice Guideline. Diagnosis and management of acute otitis media. Pediatrics, May 2004, 113(5):1451-1465.\nJohnston BC, Supina AL, Ospina M, Vohra S. Probiotics for the prevention of pediatric antibiotic-associated diarrhea. Cochrane Database of Systematic Reviews 2007, Issue 2. Art. No.: CD004827. DOI: 10.1002/14651858.CD004827.pub2.\nSign-up for DrGreene's Newsletter\nAbout once a month we send updates with most popular content, childrens' health alerts and other information about raising healthy children. We will not share your email address and never spam.""]"	['<urn:uuid:137b2f58-e1a6-4775-bdba-3d68eb3322fd>']	factoid	direct	long-search-query	distant-from-document	single-doc	expert	2025-05-12T13:53:09.865574	10	38	579
66	open wetlab escherichia coli safety procedures	In the Open Wetlab, they work with non-pathogenic E. coli strains like K-12 or DH5alpha, which are safe as they cannot grow in humans or produce toxins. Safety procedures include wearing personal protection equipment (lab coats, safety goggles, nitrile gloves), ensuring all users complete safety training, and treating liquid bacterial cultures with chloride before disposal. The lab maintains Biosafety Level 1 standards and requires all experiments to be performed inside laminar flow chambers under aseptic conditions to prevent contamination.	"[""What is the Open Wetlab?\nThe Open Wetlab is a laboratory for open-source, open hardware and creative biotechnology. All projects in the lab are documented on a freely accessible website, as a contribution to the global open-source biotechnology community.\nApart from these facilities the Open Wetlab runs a research programme in bio art, bio design and art science collaborations.\nWhat is happening in the Open Wetlab?\nCollaboratively the users of the Open Wetlab work on biotechnological experiments, installations, exhibitions, workshops and debates. Activities include for example: molecular genetics, biochemistry, microbiology, spectrometry, microscopy, PCR, bioprinting, microbial fuel cells, algae reactors, in vitro tissue culturing, biomaterials, synthetic biology, systems biology, EMG, EEG neurology, brain computer interfacing, DNA computing, microfluidics and more.\nLearning-by-doing and debating-by-making are the core methodologies in our public programme. Interns of several (international) universities conduct their research in the lab.\nWho is working in the Open Wetlab?\nLucas Evers and Roland van Dierendonck are in the lab on a daily basis, and supervise the users of the lab. Please take a look on the Open Wetlab meetup group to see who else is an active member.\nWhen can I use the lab?\nHow can I stay up-to-date?\nThe Open Wetlab activities are announced on the Waag website. Via the Open Wetlab meetup group you can quickly engage with users of the lab and start a discussion on the forum. Reports and blogposts are regularly published on the Waag website.\nWhat equipment is available in the Open Wetlab?\nThe following machines can be found in the lab:\n- Light microscopes with camera\n- (UV-VIS) spectroscope\n- (bio) 3D printer\n- Analytical scale\n- (Micro) pipettes\n- OpenPCR machine\n- DNA gel electrophorese kit\n- Microwave and oven\n- Fridge and freezer\n- EMG and TENS equipment\n- EEG devices (MindWave and eMotiv)\n- pH meter\n- Sterile hood\nWhat chemicals are on stock?\nIt’s best to visit the lab to get a complete overview of the current stock. Most of the time the following is available:\n- Ingredients for bacterial, yeast and algea growth media\n- Buffers (Tris, Borax, Phosphate)\n- Acid (HCl) and base (NaOH)\n- DNA gel ingredients, stains and buffers\n- PCR ingredients (Polymerase, dNTPs, primers)\n- Antibiotics (Amp, Pen, Strep)\nThe use of chemicals is not for free.\nI have an idea, where can I start?\nPlease visit an open event or workshop.\nWhere can I find more of these labs?\nThere is an international network of somewhat similar facilities:\n- DIYBio Groningen\n- BiologiGaragen Copenhagen\n- Biotinkering Berlin\n- London Biohackers\n- MadLab Manchester\n- Open Biolab Graz\n- La Paillasse Paris\n- DIYBio Tours\n- Brmlab Biolab Prague\n- Biodisplay Hungary\n- Biotehna Ljubljana\n- Finnish Society for Bioart\n- BossLab Boston\n- GenSpace New York\n- BioCurious Mount View\n- Lifepatch Yogyakarta\n- Bioart Taiwan\n- Art Science Bangalore\n- Symbiotica Perth\n- Syntechbio Sao Paulo\nHow do I get started?\nThe successful completion of the Safety Instructions training is required before you are allowed to work in the lab independently. Also a project proposal must be discussed with the lab manager. If necessary, additional safety precautions will be taken into account. The main prerequisite is the full documentation of the project on the web, under an open-source license.\nWhat type of activities can be done in the Open Wetlab?\nThe lab may be used for activities that are legally allowed and do not pose any threat to the environment, lab users or yourself. For example you may cultivate non-pathogenic organisms, analyse DNA or other biomaterials, build Open Source Hardware lab equipment or design bio informatic systems.\nWhat type of activities cannot be done in the Open Wetlab?\nExperiments that include highly flammable, explosive or polluting chemicals are not allowed. The use of pathogenic, illness-causing organisms is prohibited and experiments that required molecular genetic modifications are not allowed.\nDo you make bio weapons or train terrorists?\nWhat kinds of organisms are used in the Open Wetlab?\nWe solely work with non-pathogenic organisms. This means that exposure leaves no chance of disease to healthy humans and animals. For example E. coli strain K-12 or Dh5alpha. Yeast and natural strains of slime molds are also used. Always ask for permission before bringing an organism to the lab.\nThe E. coli strains do not pose a threat to human health because they do not have the capability to grow in humans and do not produce toxins. The strains are commonly used in laboratories around the world. We do not use the natural occurring E. coli, which is a known pathogen.\nIf you would like with an other organism in the lab, it is fine as long it is non-pathogenic, not a living mammal or other large animal such as reptiles and birds, and do not require a lot of space.\nIs recombinant DNA technology or cloning allowed?\nNo, the Open Wetlab does not have a permit for recombinant DNA experiments. Only natural mutagenic methods are allowed. If your experiments require recombinant DNA, you will have to find a suitable lab.\nDo you culture human tissue?\nNo, culturing of human tissue is not allowed in the Open Wetlab. If you are interested in such experiments, we may introduce you to labs that are capable of supporting it.\nHow do you handle biological waste?\nAnything that is grown in the lab is supposed to be killed before it leaves, or kept in a sealed container. All liquid bacterial cultures are treated with chloride.\nIs the Open Wetlab a 'biohazard'?\nNo. We do not cultivate pathogens.\nWhat kind of safety measurements can be found in the Open Wetlab?\nPersonal protection equipment, such as lab coats, safety goggles and nitrile gloves can be found in the lab. Fire extinguishers and eye washers are available too. Most importantly, every user of the lab has completed the safety training, or is supervised by someone who did.\nWhen can I get safety training?\nThe safety trainings are scheduled by appointment only.\nWith whom is the Open Wetlab collaborating?\nThe Open Wetlab collaborates with many different parties in the citizen science community, biotech industry, institutes, schools and universities."", ""Safety of the researcher, environment, manufacturer and the consumer is of utmost importance in each of the processes from strain development experiments to manufacturing and packaging of the final product. To ensure the same, consideration of all the precautions and safety measures must be taken to make the work environment, manufacturing environment and consumer product safe and to prevent any hazardous situations. Material safety data sheets for all reagents should be kept handy (List of reagents used have been given in the handbook).\nFigure 1: Safe chassis bacteria\nOur entire project requires a Biosafety Level 1 (BSL-1) laboratory. This is because our project has proposed the use of Biosafety level 1 bacteria (Escherichia coli DH5alpha and Escherichia coli Nissle 1917) as our probiotic chassis iGEM - safety risk groups and therefore we consider our project to be harmless to researchers in this aspect. None of the designed experiments are expected to increase the pathogenicity of the bacteria.\nThe bacteria Escherichia coli Nissle 1917 is an extremely well studied probiotic strain with no known negative effects on health Pradhan, S., & Weiss, A. A., 2020. It does not have the ability to become an aerosol and has no known pathogenic effects on animals and plants as well. It is responsible for producing fitness factors called ‘colicins' that are toxic to other Escherichia coli strains. In our case, it would be an advantage as we want our bacteria to compete while it stays in the gut. Furthermore, its ability to form biofilms increases its long-term persistence in the gut.\nWe would not reveal important information like activation mechanisms, etc to ensure that dual use does not occur (unless it has all the required clearances).\nBiosafety & Biosecurity\nFigure 2: Dual Use\nTeam Bielefeld-CeBiTec 2015 proposed a detailed analysis of biosecurity, particularly the dual use issue, with respect to the iGEM competition in which they have mentioned several aspects and questions to be considered Bielefeld-CeBiTec, 2015. Some of the questions which we have answered are given below (More can be found in the handbook).\nCan you imagine any malevolent use of the knowledge and sequences published on your team's wiki? Could the knowledge you provide be used for the creation of products or organisms that pose a danger to humans or the environment?\nOur project involves the release of an anti-inflammatory cytokine (IL-10) whose release is regulated by a control mechanism involving SoxS and SoxR genes. The SoxR gene is also regulated to be released only in the presence of methylmercury using the MerR-PmerT mercury responsive genes.\nSelective mutation of any of these control mechanisms could lead to release of IL-10. This could lead to reduced immune response to pathogens. IL-10 also down regulates transcription and secretion of IL-1β, IL-6, IL-8, TNF-α, and G-CSF by activated monocytes and macrophages. This could lead to cancer Schreiber S, 1997. IL-10 upregulates ICAM-1 within neural tissues. This promotes massive macrophage influx, demyelination due to inflammation and subsequent loss of neural tissue, resulting in muscle weakness and paralysis Dru S., 2009.\nWho will use your product? If your product is successful, who will receive benefits and who will be harmed?\nOur product if successful will be used by people who are at risk for methylmercury poisoning. We have made sure to not use any allergens or preservatives which could potentially harm consumers.\nWHO also has a self-assessment questionnaire to ensure that good quality, ethical research activities are conducted in safe and secure facilities. Some of the important question relevant to biosecurity and biosafety aspects have been answered below (more in handbook) WHO - Responsible life sciences research for global health security :\n|Pillar 3: BIOSAFETY AND LABORATORY BIOSECURITY|\n|An assessment of the risk associated with research activities is conducted||Yes. The team has documented a Safety Handbook that covers various safety aspects and a detailed risk assessment for each experiment|\n|Risk assessments are able to identify requirements for risk reduction measures including the level of containment required||Yes. The Safety Handbook covers not only the risk reduction measures but also the level of containment required for each stage of the research that will be conducted.|\n|Legislation/regulations regarding hazardous waste disposal are followed||Yes. The team will strictly follow the regulations pertaining to hazardous waste disposal. (No Lab Experiments were performed this year)|\n|Valuable biological material is safely and securely stored||Yes. The team will ensure that the valuable biological material is safely and securely stored for future use. (No Lab Experiments were performed this year)|\nFigure 3: Methylmercury is extremely toxic.\nAll forms of mercury, both organic and inorganic are highly toxic. Exposure to mercury even in small amounts can causes severe health issues and can even affect the development of the child in utero and early in life WHO - Mercury and health.\n- To avoid mercury poisoning by accidental inhalation, ingestion, injection or absorption through the skin while working with it, the use of appropriate type of gloves (Nitrile (8 mil) over Silver Shield) and other essential lab attire like Chemical goggles/face shield, lab coat with full sleeves, full-length pants, and closed toe shoes must be ensured.\n- Mercury spill kits must be kept handy in the lab in case of an emergency.\n- All mercury containing waste must be disposed of separately by packing in a container with a hazardous waste label and chemical name on it.\n- We have taken into consideration all the hazardous waste disposal laws in India and have also enlisted the ones in the US for reference in our safety manual.\nIn the USA: Paraquat is categorized under ‘restricted use' by the US Environmental Protection Agency. Only those with a license are allowed to use this chemical. A blue dye and sharp odor are added as a warning, and another agent is added to induce vomiting in case of ingestion Paraquat dichloride-EPA.\nIn India: CIBRC (Central Insecticide Board and Registration Committee) has categorized paraquat dichloride as highly toxic Conditions of paraquat use in India - Pan-India.\nTo ensure safety while handling paraquat protective clothing, including gloves, safety glasses, respiratory equipment, full-sleeved lab coat, full-length pants, and closed-toe shoes must be worn. During disposal, suitable incineration and chemical treatment in accordance with local regulations must be followed (by a licensed professional).\nFigure 4: Gloves\nTo maintain aseptic conditions, all experiments must be performed inside the laminar flow chamber while ensuring the UV light doesn't cause any problems to the person performing the experiment.\nPrecautions must be taken while working with the autoclave and handling of hot autoclaved equipment must be done using appropriate heat proof gloves. Aseptic conditions must be maintained in order to prevent contamination by unwanted DNA or organisms. Gloves must be used not only for handling hot equipment and chemicals but also for cold samples taken out of the freezer to avoid cold burns. The stains and other hazardous substances should be handled with care during gel electrophoresis, sonication and gas chromatography.\nLabs must be equipped with an emergency shower, eyewash station, and a first aid kit and workstation must be cleaned. Disposal of all waste materials must be done properly.\nIsolation of all electronic components from any conducting media should be ensured. All wiring connections should be insulated properly, and care must be taken to avoid spilling or leakage of chemicals or fluids onto the motors.\nAfter experiments which involve methylmercury and paraquat, the dialysis tube must be discarded and other equipment components should be thoroughly cleaned following the handling protocols. Any leakage into the incubator should be prevented by placing the entire set up in a closed air tight container. All of the components used in the design are checked for temperature and pH resistance.\nFigure 5: Specialized disposal\nAll the experiments designed are relatively safe. The bacteria used should be highly tested for any safety concerns. However, any unexpected results or modifications must be handled with extreme care.\nGrowth Media experiments which utilize hazardous substances like mercuric oxide, concentrated HCl etc. must be handled in the fume hood in rooms with adequate ventilation. Protective equipment must be worn at all times. Disposal of inorganic peroxides and oxidants as well as bromine and iodine should be done by rendering them harmless by reducing it with acidic thiosulphate solution. Disposal of contaminants should be done separately with adequate labeling.\nInitially, we identified the worst cases in pharmaceutical cleaning validation Identification of worst case in cleaning validation- Pharmaceutical guidelines.\n- Potency of product\n- Solubility of Active Pharmaceutical Ingredient (API) in water\n- Toxicity of API\n- Concentration of API\n- Contact surface area\n- Product excipients\n- Manufacturing process\nThe quality and quantity of the API (bacteria) must be maintained at recommended safe levels (CFU count) ensuring optimal potency. The water released during drying or other process must be sterilized before discarding. The API in our case is Escherichia coli Nissle 1917 which is a non-pathogenic known probiotic strain. The API concentration must be at recommended levels for a probiotic. The equipment used must have minimum surface area and should be sterilized regularly with non-harmful substances. The excipients used must not contain any known allergens as well as preservatives. Contamination of the product must be prevented by repeated cleaning and sterilization of all components including air, equipment, media etc.\nSince the volume of the microorganisms present in bioreactors is much larger, extreme care must be taken to prevent the contamination of the bioreactor itself and also the surrounding environment.\nThere are possibilities of liquid spills and aerosol formation for some widely used bacterial chassis. However, the bacteria we have proposed is Escherichia coli Nissle 1917 which is a risk 1 non-pathogenic organism and does not have the capability to form aerosols.\nThe proximity of large volumes of liquid and mains electrical equipment (eg, from heaters, aerators, sensors, etc) presents a hazard. Commercially-designed equipment from a reliable source should prevent access to live conductors.\nIn case of any gas production, the gases must be vented out to prevent high pressure build up, and it should be kept away from fire.\nThe quality and safety of the manufactured product should be a key concern in order to ensure the client's safety Prevention of microbial contamination during manufacturing- Pharmaceutical guidelines.\n- Air filtration and air change rates must be set and done regularly.\n- In case of contamination in one area, the plant should have a HVAC system which would remove and prevent contaminants from spreading to other areas.\n- Ventilation dampers should also be positioned away from the production area for maintenance purposes.\nFigure 6: Personal Protective Equipment\n- The personnel handling the production must be trained on the importance of hygiene and it should be ensured that they would wear protective clothing such as hair cover, overshoes, over garments, beard covers, etc. to prevent any sort of contamination.\n- It is required to ensure that direct contact with the product or an equipment which comes in contact with the product is avoided.\n- Cleaning agents must be of a suitable grade to minimize any health risks. Cleaning and disinfection should be done regularly. Rotation of different disinfectants should be done to prevent any resistance development. The disinfectant must be sterilized using a 0.2 micron membrane filter in sterile conditions. The hold time of the disinfectants must also be validated.\n- The equipment for cleaning should not have direct contact with the pharmaceutical product.\n- The cleaning practice must be validated.\nEquipment maintenance and cleanliness must be ensured and all guidelines must be followed.\nA controlled area for pharmaceutical manufacturing would be maintained. Any harm to the manufacturers due to dust particles or micro-organisms should be avoided by providing quality equipment, adequate hygiene training and regular cleaning and sterilization. The capsule integrity and sterility must be ensured during filling. Quality control of capsules should be done at each key stage. Different processes must be performed at different sections of the plant to prevent contamination.\nThere are four different levels at which a sterile pharmaceutical company should grade its control production: A B C and D. Grade A should be the zone for high risk operations like filling zone and zone for making aseptic connections; this zone should have laminar airflow systems with homogeneous airspeeds. Grade B is the background environment for grade A that allows for aseptic preparation and filling. Grade C and D are classified areas that handle the less critical stages of SPM Controlled areas in sterile manufacturing - pharmaceutical guidelines.\nFigure 7: Packaging\nBlister punching machine is closed at the manufacturing part, thus remaining tamper resistant. The packaging must maintain the integrity and safety of the product.\nWaste Management & Recycling\nPharmaceutical waste is categorized into 2 categories An overview of waste management in pharmaceutical industry - pharma journal\n- Hazardous waste (any contaminants or chemicals).\n- Non-hazardous waste\nAn important method of waste management is the prevention of waste material being created, also known as waste reduction. Before processing, any unnecessary waste generation must be checked and adequate measures should be taken.\nRe-use means the use of a product on more than one occasion, either for the same purpose or for a different purpose, without the need for reprocessing. Re-use avoids discarding a material to a waste stream when its initial use has concluded. The integrity of the product or equipment must not be sacrificed.\nRecycling involves the treatment or reprocessing of a discarded waste material to make it suitable for subsequent reuse either for its original form or for other purposes. Unused or haphazardly filled capsules should be recycled keeping in mind sterility. Discard water must be sterilized and used for some other purposes.\nPlease refer to the full safety handbook for all details.\nThe Safety Handbook includes detailed and complete safety considerations of every reagent, process, experiment, device, equipment, etc described in the other handbooks as well as biosecurity and biosafety issues of our project.\nTo download this document, click here.""]"	['<urn:uuid:5ad80906-0d6d-434b-ae51-f0d084f9d6a6>', '<urn:uuid:2a27203c-a30b-4801-918b-3b46181abf4a>']	open-ended	direct	short-search-query	similar-to-document	comparison	novice	2025-05-12T13:53:09.865574	6	79	3339
67	compare gemba action workout vs pdsa cycle workflow steps process improvement	Gemba Action Workout (GAW) and PDSA cycle are different process improvement approaches. GAW is a short 1-3 day workshop specifically for shop floors in producing companies, applying lean methods like 5S, SMED, and space utilization. In contrast, PDSA cycle is a more structured four-step approach: Plan (plan the change and expected results), Do (test the change), Study (analyze results and compare to expectations), and Act (decide whether to adopt, adapt, or abandon the change for next cycle). While GAW focuses on immediate shop floor improvements, PDSA provides an iterative framework for testing and implementing changes gradually.	['Applying Lean and Six Sigma to ensure efficient and effective processes\nDaily project work shows that companies, whose quality systems and processes are under fire of authorities, very often tend to focus on compliance only. Normally these efforts do increase compliance but very much at the expense of efficiency. Additional process steps, quality checks and rework loops are just not the right answer but still a very common approach. Compliance improvements must bear in mind the associated effects on the daily work and of course the implied costs.\nSome questions Process Excellence can answer:\n- How can we make sure that we always produce on time, in-spec and always stay compliant?\n- How can we achieve complexity reduction by eliminating process waste without making concessions regarding compliance?\n- How can we identify and eliminate the root causes for quality problems in order to minimize, deviations, investigations and rework?\n- How can we design high quality processes without adding additional process steps?\n- How can we make sure that process improvements last and continue to contribute to operating results?\nHow uQualize+ can help\nWe cover all aspects of Lean Six Sigma for core as well as enabling processes. We combine the bottom-up approach in our projects with the top-down perspective to tackle extremely detailed problems and reach high-impact solutions:\n- Eliminating the primary cause for process quality issues\n- Aligning processes strictly with customer expectations\n- Reduction of defects, scrap, inventory as well as waiting time\n- Optimization of transport, material and information flows\n- Balancing value stream planning and flow\n- Streamlining process interfaces\n- Finding best solutions by performing as few experiments as possible\nThe focus in Lean Manufacturing is to improve the production and material flow of manufacturing processes. At uQualize+ we cover all classical methods of Lean Manufacturing (including SMED, TPM, Poka Yoke/Jidoka, Workplace-/ Cell-Design, 5S, Visual Workplace, Pull-JIT, tact-time analysis and many other methods) and integrate them into custom solutions.\nWe lever on the advantages of Lean Management to increase efficiency of processes in services companies. 5S, value stream mapping with waste analyses, capacity control, space organization (spaghetti diagrams), visualizations and respective target definitions are some tools we work with in the office environment.\nThe Lean Action Workout® (LAW) is a proprietary development of ifss that has evolved from the integration of the GE Workout® and the Toyota Kaizen workshops. The LAW is a short-focused project format that concentrates on reducing process waste and finding Lean solutions in just a few days. During a Lean Action Workout, the existing value stream of a process is analyzed and improved and the future value stream is developed.\nGemba Action Workout (GAW) is a special form of the Lean Action Workout® (LAW) that is particularly useful for shop floors in producing companies. The proven lean methods 5S, SMED, space utilization, etc. are applied in these short workshops (1-3 days).\nThe DMAIC cycle (an acronym for the 5 project phases Define / Measure / Analyze / Improve / Control) contains the most relevant Six Sigma tools. ifss has developed a customized DMAIC cycle with 15 steps, giving project teams the freedom to choose exactly what tools to apply. DMAIC is the right toolset for completing broader improvement projects that require data analysis for the root-cause elimination. DMAIC can also be enhanced with Lean tools.\nFor specific problems, some clients prefer applying a specific tool instead of completing an entire DMAIC project. We achieve specific short-focus improvements with methods such as Design of Experiments (DOE), Measurement System Analysis (MSA), Failure Mode and Effects Analysis (FMEA), among others.\nProcess excellence sometimes means creating new processes from scratch. By performing projects focused on Design for Six Sigma (DFSS) we launch new processes, Greenfield.', '“Quality improvement methodologies are frequently used to improve health care delivery, but can also be leveraged to improve research processes. If your study team is facing a research barrier, we can help you to select and use the appropriate tools and strategies to overcome it.”\nDenise Daudelin, RN, MPHDirector, Research Process Improvement\nThe Center for Research Process Improvement builds the capacity of research teams to conduct efficient, cutting-edge research across the translational spectrum. This program helps researchers use methods already proven in industry and health care to increase efficiency and quality of research by addressing challenges and barriers in the research process.\nProcess improvement methods include a systematic approach to resolving problems and reducing barriers. The following list contains some examples of quality improvement tools and why a researcher might use them:\n- Process Mapping: Helps teams understand the steps involved in a process.\n- Failure Modes and Effects Analysis (FMEA): Identifies possible failures in a process and allows team to rank steps based on severity, likelihood of occurrence, and likelihood of detection.\n- Cause-and-effect Diagram: Clarifies the underlying causes of a problem.\n- Key Driver Diagram: Visually displays conditions that need to be met in order to achieve a project aim. Includes brainstormed change ideas.\n- Plan-Do-Study-Act (PDSA) Cycles: Iterative tests of change that allow teams to start small and gradually increase the size of their test as their confidence in the change builds. These rapid cycles are ideal to receive quick feedback before a team is ready to implement the change system-wide.\n- Runcharts: Captures data over time in the form of a line graph. Using statistical rules, it can help teams decide what is common cause variation and what is a change that is likely attributable to the idea tested. Also allows teams to track their progress over time.\nConducting a PDSA Cycle\nHere are the steps to conduct a Plan-Do-Study-Act (PDSA) Cycle:\n- Plan the change your team will test. Who will do what and by when? What do you expect will happen?\n- Do the test.\n- Study the results. Did you achieve your expected result? Why/why not?\n- Act. Decide if you’ll adopt, adapt, or abandon this change for the next cycle.\nWho is eligible?\nThe Research Process Improvement Program helps individuals and teams to improve research processes and offers consultations on using improvement methods in research studies. Faculty and trainees at Tufts CTSI partner and collaborator institutions are eligible for these consultation services.\nTraining, consultation, and coaching are available to career development awardees, investigators and research teams. Services are tailored to the needs of each research team. In addition, our interactive education website, I LEARN, includes several RPI seminars to get you started using improvement methods right away.\nThe Research Process Improvement Toolkit (PDF) is now available! The Toolkit highlights quality improvement tools that can be used in research. Worksheets and templates are included to assist research teams with their improvement projects.\nWondering whether you should conduct a survey? Should I Conduct a Survey? (PDF) one-page resource.\nReview our Case Studies on How to Improve Clinical Recruitment Rates and our clinical trial metric dashboard, Collecting and Using Clinical Trial Metrics to Improve Trial Performance.\nTo request RPI assistance, please complete our service request form.\nTo contact us, please submit a service request.\nDenise Daudelin, RN, MPH\nDirector, Research Process Improvement\nAlyssa Cabrera, MPH\nSenior Project Manager']	['<urn:uuid:7a9ca082-479b-499f-8c48-9a5e85c48f78>', '<urn:uuid:210deacb-24b0-487e-ab8a-5efd740b3089>']	open-ended	direct	short-search-query	similar-to-document	comparison	expert	2025-05-12T13:53:09.865574	11	96	1183
68	trapped miners rescue tools advantages	The Gemini-Scout Mine Rescue Robot enables rescue teams to scout ahead and advance into collapsed areas more quickly while keeping humans safe. It can provide relief in the form of food, water and communication to trapped individuals, and can assess air quality and structural integrity before human rescue teams enter dangerous areas. It is more capable than other rescue robots, being specifically designed for rugged, unstructured environments found in collapsed structures or mining areas.	"['First responders searching the rubble of collapsed buildings following an earthquake, terror attack, or even attempting to reach trapped miners following a cave-in work not only against the clock but against poisonous gases, flooded tunnels, explosive vapors and unstable roofs and walls.\nEngineers at Sandia National Laboratories are trying to beat that clock, and the elements, with an easy-to-use robot that can be sent into close, dangerous quarters first to survey the situation so disaster managers can plan rescue operations.\nThe unit, called the Gemini-Scout Mine Rescue Robot, can also provide relief in the form of food, water and communication to those trapped.\n""After a mine accident, the advance of rescue teams into any portion of the mine is limited by the lack of information regarding the air quality and structural integrity of the mine,"" said project manager Jon Salton.\nSalton said Gemini-Scout will enable teams to scout ahead and advance into collapsed areas more quickly while at the same time keeping humans out of harm\'s way.\nGemini-Scout is designed to navigate through 18 inches of water and climb 45-degree boulder and debris inclines, and its suitcase size (4 feet long by 2 feet wide by 2 feet high) allows it to go places where people sometimes can’t.\nThe robot is operated remotely via a standard Xbox 360 controller, making it easy for new users to control. Its electronic components are housed in water-proof, explosive-proof casings, so flooding, methane or other gas explosions can’t disable the unit.\n""The robot is intended to make mine rescue operations both safer and faster to the rescue teams, since the teams should be able to advance into and assess post-accident areas of a mine before it’s deemed safe enough for human teams to do so,"" Salton said.\nSalton told Homeland1 that currently there is only one rescue robot approved by the Mine Safety and Health Administration, but it isn\'t designed for the rugged, unstructured environments found in collapsed structures or mining areas. It’s also about twice the size of the Gemini-Scout.\n""Gemini-Scout has extreme mobility capabilities for both structured and unstructured environments and is rugged enough to withstand the heat, standing water, deep mud and debris found in mines,"" Salton said.\nWhile the robot was designed with mine rescue in mind, other responders may find uses for it.\n""We anticipate that this technology is broad enough to be appealing to other first responders, such as police, firefighters and medical personnel,"" Salton said. ""Gemini-Scout could easily be fitted to handle earthquake and fire scenarios, and we think this could provide real relief in currently inaccessible situations.""\nAbout the author\nSince leaving a withering aerospace engineering career in 1994, Doug Page has been writing about technology, medicine, and marriage peril from the Panic Room in Pine Mountain, Calif. He won a 2006 Tabby Award for a story titled ""Life in a Disaster Morgue"" that appeared in the January 2006 issue of Forensic Magazine. From 1998-2008 he was the Technology Correspondent for Fire Chief Magazine. Page is also a former contributing editor for Homeland Protection Professional and Science Spectra magazines.\nThe comments below are member-generated and do not necessarily reflect the opinions of FireRescue1.com or its staff. If you cannot see comments, try disabling privacy and ad blocking plugins in your browser. All comments must comply with our Member Commenting Policy.']"	['<urn:uuid:a0a7a6b1-8b2f-4ff8-9bb6-8191e5e4c46e>']	open-ended	with-premise	short-search-query	distant-from-document	single-doc	novice	2025-05-12T13:53:09.865574	5	74	554
69	I just moved to a new apartment and have to park on the street. What can I do to protect my car from parts being stolen when I can't park in a garage?	When parking on the street, there are several strategies to help prevent catalytic converter theft. Try to park in brightly-lit areas under street lights, and choose locations with high foot traffic where thieves would be more likely to get caught. Look for spots that are visible to security cameras. You can also install a protective device specifically designed to prevent catalytic converter theft - while these devices and their installation cost a few hundred dollars, they make it impossible for thieves to cut off your catalytic converter and could save you thousands in replacement costs. Some newer vehicles also have security settings that trigger an alarm when they sense vibrations like those caused by sawing.	['Here at Chapel Hill Tire, we work to keep our customers up-to-date on automotive industry insights. While some weeks we get to share uplifting information, this week we are here to discuss a more serious problem facing drivers: catalytic converter theft. Here is everything you need to know about this issue and what you can do to stay protected.\nWhy Are Catalytic Converters Being Stolen?\nYour catalytic converter is an essential part of your vehicle, designed to reduce the pollutants and toxic gas your emissions system produces. It uses precious metals like platinum, rhodium, and palladium to complete this process. People have been stealing catalytic converters off of cars to sell these metals for scraps.\nWhile this has been happening for years, a recent uptick in catalytic converter theft may be motivated by economic turbulence from the pandemic. Additionally, the reduced foot traffic during this time may make it easier for thieves who feel less likely to be caught. It takes just a few minutes for a thief to saw the catalytic converter out of your car and leave you with thousands of dollars in damage.\nWhich Cars Are Targeted for Catalytic Converter Theft?\nThe Toyota Prius is the most targeted car for catalytic converter theft. As a low-emissions vehicle, Prius converters contain larger amounts of the precious metals platinum, rhodium, and palladium.\nThieves can fetch as much as $700 per converter from unscrupulous scrap yards. And unfortunately, this can leave Prius owners with bills as high as $2,000.\nTrucks and SUVs are also common targets of catalytic converter theft because they are raised off the ground. This makes it easier to climb under and saw through the metal. However, every vehicle on the road is susceptible to a stolen catalytic converter.\nWhat To Do When Your Catalytic Converter Is Stolen\nStep 1: Contact the Authorities\nIf you find your catalytic converter is missing, you should immediately contact the authorities. They will check local security cameras and work to see if they can help catch the person who stole your converter. Additionally, a police report may be essential to your insurance coverage.\nStep 2: Contact Your Insurance Company\nDepending on your coverage, your car insurance may cover your catalytic converter replacement. You can contact your insurance agent to see what your options are and whether or not you are covered.\nStep 3: Visit a Mechanic\nFinally, you should bring your vehicle to a mechanic for service. An expert can discuss your repair options with you and prevent you from driving without your catalytic converter.\nWhat Happens When You Drive Without A Catalytic Converter?\nWhen facing the recovery costs of a stolen “cat,” many customers wonder, “Can I drive without my catalytic converter?”\nThe answer is both yes and no. Technically, a car can function without a catalytic converter. However, this is not a sustainable long-term option. Here are some of the troubles you will face when driving without a catalytic converter.\nLoud Vehicle Noises and Missing Catalytic Converter\nThe first sign of a stolen catalytic converter is incredibly loud vehicle noises. You will find that when driving without your catalytic converter, it will sound like your vehicle is roaring—especially when starting or giving it gas.\nRough Driving and Acceleration\nAs your exhaust goes unregulated, your vehicle will drive more roughly. Your engine usually forces your exhaust through your catalytic converter. Without this component in place, this forceful exhaust push will lead to jarring, uneven acceleration.\nAnnual Vehicle Inspection Failure\nWithout your catalytic converter, you will fail both your NC safety inspection and your NC emissions inspection. While the emissions inspection failure may seem obvious, you might be wondering why a missing catalytic converter would cause you to fail your safety inspection.\nYour annual safety inspection includes an exhaust system check, which checks specifically for removed and tampered components. This includes your catalytic converter, as well as your muffler, exhaust pipe, PCP valve, and EGR valve, among others.\nAs such, you will be unable to renew your vehicle registration without a catalytic converter. You can find more information on exhaust system checks here on our list of everything checked during your annual safety inspection.\nHarmful Car Emissions\nYour catalytic converter is named as such because it converts toxins into less harmful byproducts, such as water vapor and carbon dioxide. Without this component, your vehicle will no longer be filtering and reducing harmful emissions, including hydrocarbons, nitrogen oxides, and carbon monoxide. Not only is this bad for the environment, but it can also lead to harmfully poor air quality. When you park in your garage, for example, these toxic pollutants can find their way into your home.\nAvoiding a $250 Fine\nNot everyone who drives without a catalytic converter is the victim of theft. Some individuals choose to remove their catalytic converters to boost their horsepower. If authorities find that you removed your catalytic converter on purpose, it can lead to a hefty fine of $250.\nThis does not apply to stolen catalytic converters. The fine is delivered “for instructing or allowing a person to tamper with an emission control device of the vehicle so as to make the device inoperative or fail to work properly.” However, if your catalytic converter was, in fact, stolen but you try to avoid replacement with workarounds, your efforts might resemble the efforts of a driver trying to tamper with their emissions system. This is also why it is important to report a stolen catalytic converter right away.\nHow Can You Prevent Catalytic Converter Theft?\nThankfully, there are a few preventative measures you can take to deter the theft of your catalytic converter.\nInstall a Protective Device\nCatalytic converter theft has become so prominent that companies have started to sell protective devices. These installations make it impossible for anyone to cut off your catalytic converter. Unfortunately, high-quality devices and their installation will likely run you a few hundred bucks. However, it could save you thousands of dollars on catalytic converter replacement.\nSome newer vehicles have a security setting that triggers the alarm when it senses vibrations. The sawing of your catalytic converter will be enough to set off these alarms.\nWhen you are at home, you can park in the garage to help avoid catalytic converter theft. What about when you are on the go? When your garage is not an option, here are some parking tips to keep in mind:\n- Brightly-lit areas: Parking under street lights or in brightly-lit locations can help deter theft.\n- Highly populated locations: If the lot or parking garage you are in is seeing a lot of foot traffic, it will be hard for someone to steal your catalytic converter without being caught.\n- Security camera: Keep an eye out for security cameras in your parking area and try to find a spot visible to the cameras.\nAt best, these practices can deter the theft of your catalytic converter. Otherwise, it may help the authorities catch the individual who stole your vehicle parts.\nChapel Hill Tire Catalytic Converter Services\nChapel Hill Tire has the catalytic converter protective devices you need to maintain your peace of mind and keep your vehicle protected. We sell and install these devices to help our drivers prevent catalytic converter theft.\nIf your catalytic converter has been stolen, contact the authorities right away to report this theft. You can also visit Chapel Hill Tire to discuss your options for repair. We proudly serve the greater Triangle area, including Raleigh, Durham, Chapel Hill, Apex, and Carrboro through our 9 locations. We also serve surrounding cities like Wake Forest, Pittsboro, Knightdale, Garner, and beyond. Make your appointment here online to get started today, and stay safe!']	['<urn:uuid:462e80cc-ab42-44ca-a05a-6ca603860449>']	open-ended	with-premise	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-12T13:53:09.865574	33	115	1279
70	How do tax havens like the Cayman Islands facilitate tax evasion through shell companies, and what are the key characteristics that define these jurisdictions as tax havens?	Tax havens like the Cayman Islands facilitate tax evasion through shell companies by setting up sham structures that hide beneficial ownership. For example, Cayman National Trust set up trusts and shell companies with local mailing addresses that were nominally controlled by trust officers but actually controlled by US taxpayer-clients. These structures allowed US clients to trade securities without submitting required W-9 forms, helping hide over $130 million in offshore accounts. As for the characteristics that define tax havens - they typically have very low or no capital tax, special tax regimes for shell companies (called ring-fencing) that exempt them from taxes and accounting obligations, and a lack of transparency regarding ownership. They are usually small countries (under 1 million population) with high GDP per capita and good governance scores. This is evidenced by places like the British Virgin Islands, which has just 19,000 residents but 830,000 registered companies.	['Two Cayman Island financial Institutions plead guilty to aiding US taxpayers in hiding more than $130m in offshore accounts.\nBY GARY S. WOLFE, ESQ.\nIn March, 2016 the US Dept. of Justice announced guilty pleas for Two Cayman Island Financial Institutions Cayman National Securities, Ltd. (“CNS”) and Cayman National Trust Co., Ltd. (“CNT”). CNS and CNT are affiliates of Cayman National Corp., which provides investment brokerage and trust management services to clients including US Taxpayers. CNS & CNT pleaded guilty to a criminal Information charging them with conspiring with many of their clients whom were US taxpayers to hide more than $130m in offshore accounts from the IRS and to evade US taxes on the income earned in the accounts. The plea agreements require the companies to produce account files of non-compliant US taxpayers and pay a total of $6m in penalties which consists of the forfeiture of gross proceeds of their illegal conduct, restitution of the outstanding unpaid taxes from US taxpayers who held undeclared accounts at CNS & CNT and a fine. The guilty plea is the first conviction of a non-Swiss financial institution for tax evasion conspiracy.\nFrom 2001-2011, CNS and CNT assisted US taxpayers in hiding accounts from the IRS and evading their US tax obligations. At their high-water mark in 2009, CNS & CNT had approximately $137m in assets under management relating to undeclared account held by US taxpayer clients (on which they earned over $3.4m in gross revenues).\nThe tax evasion conspiracy included the following:\n- Setting up sham Caymanian companies and trusts (“Cayman structures”) to hide US taxpayer beneficial ownership of the accounts;\n- Using these Cayman structures to trade in US securities (treating them and not the US persons as the account holders) and failing to disclose to the IRS the identities of the US beneficial owners who were trading in US securities in contravention of CNS obligations under its Qualified Intermediary Agreement with the IRS.\n- After learning about the IRS investigation into UBS (Swiss bank) in 2008, for assisting US taxpayers to evade their tax obligations, CNS and CNT continued to knowingly maintain undeclared accounts for US taxpayer-clients.\nThe sham Cayman structures CNT set up for US taxpayer-clients included trusts, which were nominally controlled by CNT trust officers but which were in fact controlled by US taxpayer-clients. CNT managed companies acting as directors/officer, which were “shell companies” for which CNT provided a Cayman mailing address. CNS treated these sham companies as the account holders and then permitted the US taxpayer-clients to trade in US securities without requiring them to submit Form W-9s (IRS forms required that identify individuals as US taxpayers as CNS was obligated to do under its QI obligations for accounts held by US persons that held US securities. CNS & CNT agreed to maintain these structures for US taxpayer-clients after many of them expressed concern that their accounts would be detected by the IRS.\nAs part of their plea agreement CNS & CNT have agreed to provide documents and client files up to 95% of US clients they serviced. IRS Chief Richard Weber stated: “The veil of secrecy has been lifted from what was once a common place for criminals to hide their money offshore. The IRS and DOJ work aggressively to require banks to follow the laws and not turn a blind eye to criminal activity. When individuals and entities hide behind shell corporations and numbered bank accounts, they are not only cheating the US government, they are cheating the honest, taxpaying citizens who are obeying the law and doing the right thing”.\nAsst. Atty. General Stuart Goldberg said: “Today’s convictions make clear that our focus is not on any one bank, insurance company or asset management firm, or even any one country. The Department of Justice and the IRS are following the money across the globe- there are no safe havens for US citizens engaged in tax evasion or those actively assisting them.”\nManhattan US Attorney, Preet Bharara said: “The guilty pleas of these two Cayman Island companies today represent the first convictions of financial institutions outside Switzerland for conspiring with US taxpayers to evade their lawful and legitimate taxes. The pleas agreements require these Cayman entities to provide this Office with the client files, because we are committed to finding and prosecuting not only banks that help US taxpayers evade taxes, but also individual taxpayers who find criminal ways not to pay their fair share. We will follow them no matter how far they go to hide their accounts, whether it is Switzerland, the Cayman Islands or some other tax haven.”\nABOUT THE AUTHOR:\nGary S. Wolfe, Esq.\nThe Wolfe Law Group represent U.S. Taxpayers for IRS Tax Audits, U.S. Investors who have International Investments, and Foreign Persons who invest in the United States. We have over 30 years of experience, specializing in IRS Tax Audits and International Tax Matters including: International Tax Planning/Tax Compliance, and International Asset Protection.\nTel: 323-782-9139 Email: firstname.lastname@example.org', 'WHAT IS A TAX HAVEN?\nOrganizations like OECD, TJN etc. have come out with list of tax havens from time to time. The basic criteria used by these organizations for listing the tax havens can be summed up in the following four points :\n1. Very low or no capital tax on income: The primary aim of tax havens is to attract foreign investment and hence they have to give the foreign investors incentives to do so. But the existence of low or zero tax regimes is not by any means a sufficient condition though it is a necessary one. In fact, the OECD recognizes that every jurisdiction has a right to determine whether to impose direct taxes and, if so, to determine the appropriate tax rate. The following three criteria have to satisfied for a country to be classified as tax haven.\n2. A very special tax regime for shell companies (ring fencing): A shell corporation is a company which serves as a vehicle for business transactions without itself having any significant assets or operations. The number of companies in these countries (tax havens) per capita is much greater than in many industrially and financially developed countries. British Virginia Island which has a population of 19000 has 830 000 companies registered. This is apart from the unknown number of trust, banks etc. registered there. The scope of such registrations is best gauged by the fact that a small office building in George Town (in Cayman Islands) serves as the registered address for more than 18 000 companies.\nThe truth is that these companies are shell companies with no or very limited local business activity. Typically such companies are denied privileges such as they cannot own or rent real property, their owners cannot reside locally or transact in local currency etc. Tax havens are generally characterized by tax and regulatory regimes that distinguishes between locals and these shell companies (foreign investors) with regulations being favorable to the latter in many ways. Such a regime is known as ring-fenced. Companies governed under such a regime are wholly or partially exempted from paying taxes, have no obligation regarding accounting and auditing, have no duty to preserve important corporate documents, and they can shift to other jurisdictions with minimum of formalities. In fact, these companies have only one obligation as far as the tax haven in which they are registered is concerned- pay the required registration or administration fees and this is how these countries earn their revenues from them.\n3. A lack of transparency concerning the ownership and no effective exchange of information on tax issues with other countries and jurisdictions: the legal framework in tax havens is designed to conceal the identity of the owner, the company’s actual activity and transactions form the authorities in the country in which business transaction really takes place. Secrecy is reinforced by the absence of public registries particularly of those companies which intend to do business in other countries. Whatever information is present is also difficult to access. Considering the above points, it is clear that those countries which are affected by the operation of these companies and have claims against their owners have no way of knowing what is actually happening\nDharmapala and Hines gave the following criterion to judge whether a country is tax haven or not\na) The tax haven countries are generally small in size, commonly below 1 million in population. This is so because small countries are price takers in the world scenario. As a result they can’t transfer their tax burden to the foreigners. Moreover, the high rate of corporate taxes may well lead to reduction in wage rates, land prices and deadweight losses due to inefficient taxation which further harm the domestic factors. Dharmapala and Hines (2006) used the Hines-Rice definition and compiled summary statistic of the size of a country (in terms of population and area) for tax havens and non-tax havens separately and confirmed the fact stated here. They found the average population of tax havens to be 1145.69 thousand while for non-tax havens this figure was 126475.9 thousand.\nb) Those countries which are affluent tend to be tax havens. Affluence of a country is measured in terms of its GDP per capita. Countries with greater affluence (i.e. higher gdp per capita) are more likely to be tax havens than other countries with lesser affluence other parameters remaining same. This is again confirmed in Dharmapala and Hines (2006) which found out the average GDP per capita (US $ in PPP terms) of tax haven countries to be 18.51 thousand and 9.55 thousand for non-tax havens.\nc) Countries with good governance are more likely to be tax havens. Tax haven countries have a mean government index of 0.73 which is quite higher than that of the non-tax haven countries (.13) (Dharmapala and Hines, 2006). This is because the returns of becoming tax havens are more for countries with good governance. The high foreign investment and the economic growth which it brings with it result in lowering of taxes in well governed countries, one if the most basic conditions to be satisfied by a tax haven country.\nAlthough there are 20 plus tax havens across the world but I am listing top 10 tax havens here:\n- Cayman Island']	['<urn:uuid:6786e71c-e396-4e4d-b841-f4c1736ebbe2>', '<urn:uuid:72c2b620-063a-4948-9434-d8df6c2a64fa>']	open-ended	direct	verbose-and-natural	similar-to-document	multi-aspect	expert	2025-05-12T13:53:09.865574	27	148	1710
71	protein summer pasture grass versus winter haylage	Summer pasture grass starts with high protein content at the beginning of summer but declines rapidly by mid-summer, while haylage can measure up to 19 percent crude protein year-round.	['ELORA, Ont. — The University of Guelph’s beef research program is receiving a $15.2 million investment designed to create state-of-the-art facilities and expand re-search on key questions like feed efficiency and sustain-ability.\nLocated at Elora. Ont., the 300-head cowherd is also likely to go through some changes as well, said Katie Wood, an assistant professor who researches beef nutrition at the university.\nPast research saw an infusion of Piedmontese in the university research herd. The idea was to see if the tenderness calpastatin gene in Piedmontese could be transferred. One of the results was overly large cows.\nSome cows in the research herd may be a quarter Piedmontese but once they come to the end of their productive lives, they will be removed, she told a tour group last month.\n“We routinely had one ton cows here, which is way too big for a commercial setting. We are going to work hard to get our cow size more manageable and we will be culling out those very large cows,” she said.\nThe beef division shares feed with the nearby dairy research centre. Feed supplies are produced locally and because the forages are so rich, the cows on site are plump.\nHaylage may measure up to 19 percent crude protein, which suits lactating dairy cows, but the beef cows are approaching a body condition score of four to 4.5.\n“Routinely in our cow rations, we will see 40 to 45 percent straw in a TMR (total mixed ration) to try and dilute that down,” she said.\nThe plan is to build a more moderate Angus based cow herd.\nThe program also had a high twinning rate linked back to the 1980s when there were twin experiments. They still see about 10 percent twins, she said.\nBecause the cows are so large, there were few calving problems.\nThe cows are artificially inseminated with commercially available semen so they know which sires are responsible for the calves born on site. DNA is also collected on all the research animals.\nThe facility will be an H shape design where all the cattle are housed indoors. A cow-calf area, feedlot, hospital and maternity wing will be incorporated along with office space and laboratories.\nCattle placed in feeding trials are monitored with the Grow Safe and Insentec feeding systems. Electronic ear tags activate the computer sensors so they can monitor feed intake, animal weights and behaviour.\nWith the computerized feeding systems, they found steers may visit the feeders a couple times a day or as many as 100 times a day.\n“They are not necessarily eating a lot but they are true snackers.”\nResearchers want to know if the snackers are more or less efficient than full meal eaters.\n“Sometimes I think they are bored.”\nOther projects are looking at relationships between feed efficiency and reproductive efficiency.\nThey are comparing what happens when animals are on feed, graze pastures and then return to a finishing diet. They want to know if the fatty acids change in the meat when they switch feeding systems.\nAnother trial starting later this year is looking at enzymatic feed additives to improve fibre digestibility in the backgrounding and finishing diet. Yeast products may be added to test in a natural production system.\nIn summer, pasture research is conducted at the same site. Once the new buildings are completed, pasture renovation is the next project.\n“We try and get 96 of our cows on the rotational pasture. It is 100 acres and is divided into 16 paddocks and each paddock has eight cells,” she said.\nIn this area one acre can support a cow-calf pair but often more space is needed.\nOriginally, the university pastures were set up with four different varieties of forage blends. Over time those merged together and they want to reseed the paddocks to get more relevant research results.\nIn winter, all the cattle are moved indoors and by calving time in March, scours emerges as a major issue every year. Vaccination is used.\n“Whether or not it is effective is hard to say. Certainly, it wards off some infection but scours remains one of our challenges,” she said.', 'Cattle owners come to us every day needing simple, actionable advice about the different types of cattle feed that are available. What they need is straightforward advice about what to feed their cattle, when, and why.\nIf you have these questions too, then read on.\nWhat, Exactly, Do Beef Cattle Eat?\nIn this article, we’re talking specifically about beef cattle (a.k.a. cows). Some cattle are easier to feed than others. Some require more feed and some need feed that provides more (or less) nutrients than others.\nMost of a cow’s life is spent eating grasses and hay. During the spring and summer, when the grass grows plentifully, beef cattle eat more pasture grasses. During the late fall and through the winter cattle are fed hay. In a perfect world, this rotation—grass in the growing season and hay through the fall and winter—would be enough.\nThe problem is that several factors affect the protein and energy content of grass and hay, which change depending on the season and the sun.\nFor example, summer pasture grasses are high in protein at the beginning of the summer, but the protein content declines rapidly towards the middle of the summer. During a drought or in the winter, pasture grass is severely lacking in energy (calories). The harsh weather also causes cows to graze far less. In fact, this lack of grazing time is in most cases a more significant cause of your cattle’s insufficient energy consumption than the low-quality winter pasture grass.\nIn short, while your herd does get some nutrients and energy from grasses and hay, it’s often not enough. That’s why cattle need supplemental feed.\nWhen Do Cattle Need Supplementary Feed?\nAs we’ve seen, various factors affect the nutrients and energy found in pasture grasses and hay. It’s both a quantity issue and a quality issue.\nKnowing these factors is vital.\nThe QUANTITY of Reachable, Edible Forage\nThe quantity of forage available to your herd is paramount to their health and longevity. With insufficient forage, cattle need feed. You should take action right away if you know that your herd’s grazing will be limited.\nYou could simply reduce the number of cows in your herd, which would immediately reduce the amount of supplemental feeding the remaining cows require. But as the weather gets colder or the drought worsens, the opportunity to graze slowly decreases, the quality of your cattle’s diet will suffer. At some point, supplementing with feed becomes unavoidable, even if you’ve reduced the number of animals in your herd.\nThe QUALITY of Reachable, Edible Forage\nProtein and nutrient deficiencies are the other main reasons your herd may need supplemental feed. Low-quality forage is defined as forage that contains less than 7% crude protein (CP) and has lower than 50% total digestible nutrients (TDN).\nIf the forage your cows have access to is low-quality, the amount they will be able to eat also drops significantly. In short, when the forage is depleted and they eat less of it, the need to give your cattle supplemental feed increases dramatically.\nDon’t know the daily requirements for beef cattle? Here’s an easy rule of thumb. Cattle eat between 1.5% and 3.0% of their body weight in feed per day. Most cattle fall in the middle of this range, eating between 2.0% and 2.5% of their body weight in a single day.\nThe Level of Your Cattle’s Body Condition\nBody condition scoring is an easy and low-cost way to determine the body fat percentage of a cow. There are three different condition types that all create different nutritional needs that you should know about:\n• Low Body Condition: Low body condition equals low fat, and cows with low-fat levels have a significantly increased need for supplemental feed.\n• Moderate Body Condition: Cattle with moderate body condition will need less supplemental feed. Sometimes they need no supplemental feed at all.\n• High Body Condition (a.k.a. “fleshy”): Fleshy cows have the highest amount of fat. In most cases, high body condition cows require no supplemental feed to stay healthy. It’s even possible to increase their production if you keep their foraging high. As a result, they will also be able to maintain and, under some circumstances, even increase their stored energy reserves.\nWhat Are the Different Types of Cattle Feed?\nSeveral different types of cattle feed are available. They all provide protein, energy, and other vital nutrients. The main types of cattle feed are cattle cubes, pelleted cattle feed, and textured cattle feed.\nCattle cubes help your herd maintain both their weight and condition because they are formulated to supplement fair and low-quality forage. Cattle cubes provide the protein, minerals, and vitamins a cow’s forage sometimes lacks. Cattle cubes come in several different sizes, making them easier for your cattle to eat. Most cattle cubes contain 20% crude protein but also can be found in higher protein percentages.\nTIP: To reduce competition among your herd, your best choice is to feed them with ground, free-choice cattle cubes.\nPelleted Cattle Feed\nPelleted cattle feed is made from a combination of grains like cottonseed meal, corn, wheat midds, and various types of other energy sources. It can vary in size but is generally small, making it more easily digestible than other feed options.\nAnother reason pelleted cattle feed is more digestible is the thermal process used to manufacture it. The thermal process locks in amino acids and other nutrients, providing better nutritional benefits for your cattle. Pelleting also decreases dust and waste, a valuable side benefit. A final benefit to pelleted feed is that it can also be medicated, so you can control coccidiosis while improving the feed’s efficiency and potency.\nTextured Cattle Feed\nTextured cattle feed is made from flaked corn, molasses, protein pellets, and several other energy sources. It is also fortified with macro and micronutrients, vitamins, and other natural ingredients. Because it contains molasses, textured cattle feed is often referred to as “sweet feed.” Today’s textured cattle feed, which uses less molasses than in the past, still provides an advantage; it makes the feed more palatable, which is good news for your cattle.\nLast Words about Cattle Feed\nKnowing how to feed your cattle and when to give them supplemental feed is vital to their health and the success of your operation. When choosing between the different types of cattle feed, remember that the nutrition found in the formula you choose is typically more important than the type of feed you choose.\nKnowing your herd and keeping track of its overall health is paramount to your success. Choosing the correct feed with the optimal nutrition for your cattle will keep them healthy, in good body condition, and producing.']	['<urn:uuid:8629e3ed-4b3b-4bf8-8cc3-f017e5d2309d>', '<urn:uuid:fcfd841b-aff4-475d-9604-6d09d9051113>']	factoid	direct	short-search-query	similar-to-document	comparison	expert	2025-05-12T13:53:09.865574	7	29	1803
72	convert modus tollens rule into modus ponens rule what are steps proof conversion	A modus tollens argument can be converted to modus ponens through these steps: 1) Start with the material implication premise 'If P, then Q', 2) Use transposition to derive 'If not Q, then not P', 3) Use the premise 'Not Q', 4) Finally, derive 'not P' using modus ponens	"['|Rules of inference|\n|Rules of replacement|\nIn propositional logic, modus tollens (or modus tollendo tollens and also denying the consequent) (Latin for ""the way that denies by denying"") is a valid argument form and a rule of inference.\nThe inference rule modus tollens, also known as the law of contrapositive, validates the inference from implies and the contradictory of , to the contradictory of .\nThe modus tollens rule can be stated formally as:\nwhere stands for ""P implies Q"", stands for ""it is not the case that Q"" (or in brief ""not Q""). Then, whenever """" and """" each appear by themselves as a line of a proof, """" can validly be placed on a subsequent line. The history of the inference rule modus tollens goes back to antiquity.\nThe modus tollens rule may be written in sequent notation:\nwhere and are propositions expressed in some formal system;\nor including assumptions:\nthough since the rule does not change the set of assumptions, this is not strictly necessary.\nMore complex rewritings involving modus tollens are often seen, for instance in set theory:\n(""P is a subset of Q. x is not in Q. Therefore, x is not in P."")\nAlso in first-order predicate logic:\n(""For all x if x is P then x is Q. There exists some x that is not Q. Therefore, there exists some x that is not P."")\nStrictly speaking these are not instances of modus tollens, but they may be derived using modus tollens using a few extra steps.\nThe argument has two premises. The first premise is a conditional or ""if-then"" statement, for example that if P then Q. The second premise is that it is not the case that Q . From these two premises, it can be logically concluded that it is not the case that P.\nConsider an example:\n- If the watch-dog detects an intruder, the watch-dog will bark.\n- The watch-dog did not bark\n- Therefore, no intruder was detected by the watch-dog.\nSupposing that the premises are both true (the dog will bark if it detects an intruder, and does indeed not bark), it follows that no intruder has been detected. This is a valid argument since it is not possible for the conclusion to be false if the premises are true. (It is conceivable that there may have been an intruder that the dog did not detect, but that does not invalidate the argument; the first premise is ""if the watch-dog detects an intruder."" The thing of importance is that the dog detects or doesn\'t detect an intruder, not if there is one.)\n- If I am the axe murderer, then I can use an axe.\n- I cannot use an axe.\n- Therefore, I am not the axe murderer.\nRelation to modus ponens\nEvery use of modus tollens can be converted to a use of modus ponens and one use of transposition to the premise which is a material implication. For example:\n- If P, then Q. (premise -- material implication)\n- If not Q , then not P. (derived by transposition)\n- Not Q . (premise)\n- Therefore, not P. (derived by modus ponens)\nLikewise, every use of modus ponens can be converted to a use of modus tollens and transposition.\nJustification via truth table\nThe validity of modus tollens can be clearly demonstrated through a truth table.\n|p||q||p → q|\nIn instances of modus tollens we assume as premises that p → q is true and q is false. There is only one line of the truth table—the fourth line—which satisfies these two conditions. In this line, p is false. Therefore, in every instance in which p → q is true and q is false, p must also be false.\nVia disjunctive syllogism\n|3||Material implication (1)|\n|4||Disjunctive syllogism (2,3)|\nVia reductio ad absurdum\n|4||Modus ponens (1,3)|\n|5||Conjunction introduction (2,4)|\n|6||Reductio ad absurdum (3,5)|\n- University of North Carolina, Philosophy Department, Logic Glossary. Accessdate on 31 October 2007.\n- Copi and Cohen\n- Moore and Parker\n- Sanford, David Hawley. 2003. If P, Then Q: Conditionals and the Foundations of Reasoning. London, UK: Routledge: 39 ""[Modus] tollens is always an abbreviation for modus tollendo tollens, the mood that by denying denies.""\n- Stone, Jon R. 1996. Latin for the Illiterati: Exorcizing the Ghosts of a Dead Language. London, UK: Routledge: 60.\n- ""Stanford Encyclopedia of Philosophy: Ancient Logic: The Stoics""\n- Susanne Bobzien (2002). ""The Development of Modus Ponens in Antiquity"", Phronesis 47.\n- Modus Tollens at Wolfram MathWorld']"	['<urn:uuid:fb84c237-b01a-4071-b138-ee27a5327971>']	factoid	with-premise	long-search-query	similar-to-document	single-doc	expert	2025-05-12T13:53:09.865574	13	49	754
73	As a vineyard owner, how can these Hoplia beetles harm my crops?	Hoplia beetles, specifically the western species Hoplia callipyge LeConte (also known as grapevine hoplia), feeds on the young leaves, flowers, and fruit of grapes. The adults emerge from the soil as early as mid March in southern California and can be present for about a month, during which time they damage the plants. Their larvae also burrow in the soil and feed on the host plant roots.	['Hoplia beetles are close relatives of the dreaded Japanese and Chinese Beetles. They are day flyers and prefer the flowers of white to whitish flowers. The adults are small about 1/4 inch to 3/8 inch long and somewhat squarish and dorsally flattened in shape. Their ventral surface are covered with silvery and coppery colored scales while the elytra and dorsal surface is brownish to reddish brown in color. Silvery scales are also found on the dorsal surface giving the dorsal surface a mottle appearance on various shades of brown. There is only one generation per year with the adults emerging from mid March through May in areas from Palm Springs and Cathedral City in southern California to Redding in northern California.\nThere are several species of Hoplia beetles throughout the United States. The western species, Hoplia callipyge LeConte, is also known as the grapevine hoplia and it appears to be the only species of this group that attacks roses. According to Essig (1926:445) this beetle also feeds on the young leaves, flowers, and fruit of grapes, peaches, and almonds and on the flowers of ceanothus, greasewood, calla lilly, California poppy, magnolia, lupine, olive, orange, and willow, and on the leaves of beans, horse beans, peas, and vetches. On roses the beetles feed on the petals of opening white and light colored roses by chewing small holes and leaving the petals with a lacey appearance. In my garden, they prefer the white flowers of Sally Holmes, Popcorn, Irresistible, Grace Seward, Class Act, and the Apricot Nectar, a peach colored rose.\nLIFE CYCLE: Adult beetles emerge from the soil in as early as mid March in southern California and they can be common from late April through mid May in norhtern California. They are present for only about a month in any one area of California depending on the weather. Mating orgies take place on host flowers. The gravid females oviposit in the soil near host plants and upon hatching the larvae burrow in the soil and feed on the host plant roots. They overwinter as a larvae and continues development in the spring. The full grown larva or grub is white. Pupation occurs in the spring. The hoplia beetle has only one generation per year.\nCONTROL: Scouting or monitoring for the presence of hoplia beetles is very important for adequate control. Adults are readily attracted to many light colored roses and other flowers. Light colored roses should be inspected from mid March through May for skeletonized petalsthrough July, the foliage should be inspected for skeletonized rose petals and for the presence of adult beetles tucked inside the flowers between the rose petals.\nHoplia beetles can be handpicked and destroyed if the infestations are light. They can also be handpicked and drowned by dropping them into a bottle filled with soapy water. Satisfactory control can be achieved with the application of insecticides such as carbaryl (Sevin), acephate (Orthene), diazinon, and chlorpyrifos (Dursban), Merit, etc. Please read the insecticide label throroughly and as some insecticides such as diazinon can cause phytotoxic reactions to new foliage if applied when the weather temperatures are above 80 degrees F.\nEssig, E. O. 1926. Insects of Western North America. The MacMillan Company, NY, p. 445.\nJohnson, Warren T. and Howard H. Lyon. 1988. Insects that Feed on Trees and Shrubs, 2nd edition, Cornell University Press, Ithaca, NY., pp. 236-37.\nDreistadt, S. H. 2001. Integrated Pest management for Floriculture and Nurseries. UC Statewide IPM Project. Division of Agriculture and Natural Resources, Publication 3402, 422pp.\nIf you have any questions or constructive comments, I would love to hear from you, please send e-mail to Baldo Villegas\n[ Home ]\n[ Rose Pests Master List]\n[ Rose Diseases ]\n[ Insect, Mites, and other\nAnimal Pests ] [ Abiotic\nRose Problems ]\n[ Weed Pests ] [ Hawaii Pests ] [ The Good Guys ] [ Help! Rose IPM ] [ Horticulture Links ]\nCopyright© 1995-2002 by Baldo\nLast updated: June 3, 2002']	['<urn:uuid:8904de2e-6b19-4607-bd56-c440cb0f0a11>']	open-ended	with-premise	concise-and-natural	distant-from-document	single-doc	expert	2025-05-12T13:53:09.865574	12	67	663
74	How does the standard classroom teaching approach often limit student engagement in English language learning?	The learning process commonly used in the classroom puts the teacher as a center of learning, where the teacher dominates the teaching rather than focusing on how learners learn effectively. This makes learners passive and less interested in following the course of learning.	['Using Pictionary Game to Increase Learners’ Vocabulary Mastery in English Language Instruction\nThis article aims at sharing information on how pictionary game is used to increase the learners’ vacabulary mastery in the process of teaching and learning. It is clear that vocabulary is one of components of English language. When the learners are reading, they need to master vocabulary related to certain topic. Therefore vocabulary is important thing in learning English. However, mastering English vocabularies is not easy. English is foreign language in which learning English is often considered to be difficult to comprehend. This problem can be seen from the unsatisfactory result when learning English. The learning processs commonly used in the classroom just puts the teacher as a center of learning. It means that the teacher always dominates him/herself to teach, not to focus on how the learners learn effectively. This makes the learners passive and less interested in following the course of learning. In fact the learners’ interest is the most important factor in the study. Interest can be developed if the learning process run with fun, vary, and conducive athmosphere. There are many factors that can support the existance of an increase in the study, i.e. teachers, learners, materials, media, methods, and other learning sources. One factor that can help the learners learn vocabulary is the use of pictionary game. In this study, pictionary game is a classic game of drawing and guessing pictures. Pictionary game can also increase the imagination of learners, where learners are asked to draw according to the word given by the teachers. Things that are needed to play pictionary game are a list or card of vocabulary items, whiteboard, calkboard, or smart board and markers. Pictionary game will help learners to get involved in classroom activities. Other advantages of using pictionary game can be concluded that it provides fun language practice in the various language skills.\nBrown, H. Douglas. (2004). Langauge Assessment: Principles and Classsroom Practice. United States of America: Longman.\nDaller, Helmut, et al. (2007). Modeling and Vocabulary Knowledge. New York: Cambridge University Press.\nDwi, L. E. (2017). Improving StudentsVocabulary Mastery through Pictionary Board Game at Grade IV B Of Elementary School 36 Pekanbaru. Al-Ishlah: Jurnal Pendidikan, 9(2), 1-15.\nFrazee, Bruse M., & Rudnitski, Rose A. (1995). Integrated Teaching Methods; Theory, Classroom Applications, and Field-Based Connections. United States of America: Delmar Publishers.\nHeinich, R., et al. (1996). Instructional Media and Technologies for Learning. United States of America: Prentice-Hall, Inc.\nHiebert, E., & Kamil, M. (2005). Teaching and Learning Vocabulary. London: Laurence Erlbaum Associates.\nMutiah, Diana. (2010). Psikologi Bermain Anak Usia Dini. Jakarta: Penerbit Kencana.\nNist, S. L., & Mohr, C. (2002). Improving Vocabulary Skills, West Berlin: Townsend Press Inc.\nNunan, D. (2015). Teaching English to Speakers of Other Languages. New York: Routledge.\nSimpson, James. (2011). The Handbook of Applied Linguistics. London: Routledge.\nStahl, Steven A., & Nagy, William E. (2005). Teaching Word Meaning. New Jersey: Lawrence Relbaum Associates, Inc.\nThornbury, S. (2002). How to Teach Vocabulary. England: Pearson Education Limited.\nCopyright (c) 2019 Welliam Hamer\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\nThe names and email addresses entered in this journal site will be used exclusively for the stated purposes of this journal and will not be made available for any other purpose or to any other party. Journal of English Education Studies (JEEP) allow the author(s) to hold the copyright and to retain publishing rights without restrictions.']	['<urn:uuid:9bb2570d-1279-450f-bd34-916230a52179>']	factoid	direct	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-12T13:53:09.865574	15	43	573
75	What motivated civilians to join the Bangladesh liberation movement?	Multiple factors drove civilians to join the Bangladesh liberation movement. The immediate catalyst was the brutal military crackdown by West Pakistan, particularly Operation Blitz authorized by General Yahya Khan and the indiscriminate use of force beginning March 25, 1971. There were also underlying reasons, including the rejection of the Awami League's election victory by West Pakistan and the attempted imposition of Urdu language on the East. The formation of civilian resistance groups, particularly the Gono Bahini component of the Mukti Bahini, drew volunteers from diverse backgrounds, including well-educated students from refugee camps. The commitment of these civilians is exemplified in accounts like Jahanara Imam's diary, which documents how ordinary citizens provided shelter, food, and support to liberation fighters despite grave personal risks.	['By Nachiket Midha\nThe Indian subcontinent represents one of the classic problems of post-colonial state-making—the coexistence of diverse groups. The underlying basis for the partition of the subcontinent was religion. The status quo in 1947 was two Pakistans on the opposite ends of the subcontinent separated by their fiercest enemy, India, by thousands of miles. In essence, the then ‘new’ Pakistan was “…two Wings without a body, sundered by the land-mass of its greatest foe, joined by nothing but God . . .”\nThis belief in God was tested in the year 1971 when the people of East Pakistan—in response to the increasingly authoritarian and brutal posture of West Pakistan—demanded political autonomy. The solution, not reached amicably or politically, made way for an inevitable military conflict in the subcontinent. Most scholarly works place the Indian Army and its Pakistani counterpart at the helm of the conflict, and more often than not, the Mukti Bahini, or the ‘freedom fighters’ as they are known, were marginalised in the footnotes of popular narrative(s). To that end, this article, first, aims to analyse the character of the Mukti Bahini and consequently, understand its history and origin. At the same time, it also aims to discern the different perceptions about/around the Mukti Bahini. Last, and as a result of the earlier, it aims to formulate a framework to contextualise the role of the Mukti Bahini in the 1971 Bangladesh war.\nContextualising the Mukti Bahini: The Origins and the Structure\nThe story of the actual conflict starts from the takeover of the reign by Gen. Yahya Khan in (West) Pakistan in 1969. Gen. Yahya took over the control from Gen. Ayub Khan, and interestingly, one of the justifications for this takeover was the ineffectiveness of the state machinery in East Pakistan, paralyzed by various civilian expressions. Though he occupied the highest office in the land, he nevertheless pushed for elections to the National assembly, and thus, gradually towards a civilian government.\nThe elections were subsequently held in the year 1970. In these elections, the Awami League, led by “…the fiery and hugely ambitious Sheikh Mujib Rahman,” created a formidable victory by winning 160 seats (just two less than the total number of seats contested by the party).\nThe rejection of this victory by the West Pakistan establishment, in conjunction with its continued policy of imposition of Urdu on the East, added impetus to the popular resistance. In addition to this, when all political negotiations broke down, the consequence was the authorization of Operation Blitz by Gen. Yahya.\nNow, both the political and military context favoured the formation of the Mukti Bahini. So, in effect, the creation of the Mukti Bahini is owed to two different sets of reasons, one immediate and one underlying.\nThe direct/immediate cause was the dispersion of military use through military operations in East Pakistan. Specifically, “…the indiscriminate use of force by the Pakistan Army…[that began] on March 25, 1971,” acted as a watershed point.\nThe underlying reason was the culmination of a more extensive and rising discontent in the East due to their hegemonic political and socio-cultural suppression—both the language question and political autonomy. Therefore, the formation of the Mukti Bahini has a conscious historical process behind it.\nIn this context, it seems that the Mukti Bahini was not just a political movement but a movement for broader self-determination for the people of East Pakistan. Thus, it becomes critical to acknowledge that the Mukti Bahini did not emerge out of impulsive frivolity.\nSegueing into understanding the character and structure of the Mukti Bahini, one comes across its two components. The first, consisting of the regular forces, was the Niyomito Bahini. The fighters in the Niyomito Bahini consisted of those who were experienced in either the police, military, or paramilitary. More importantly, some of the soldiers were the dissenters from the East Bengal Regiment of the Pakistan Army. The second part of the Mukti Bahini was the Gonobahini. It constituted those volunteers who were not from a military/police background but nevertheless, wished to join the liberation forces.\nMore often than not, the perceptions of the different stakeholders in a war or war-like situation towards a particular actor/event enable readers of history in the contemporary moment to retrospectively understand how that actor/event might have had a more decisive role than made out to be in actuality.\nThe Mukti Bahini is an example of this. Here, reflecting on two perceptions—the Indian and the Pakistani—becomes imperative to discern the actuality of the situation as it unfolded, and comprehend the role played by Mukti Bahini in it.\nAs noted in the previous section, the use of force by the Western establishment against the East prompted resistance by the people in the Eastern unit. However, “it also produced a flood of Bengali refugees into India, so transforming an ‘internal’ Pakistani affair into a regional and humanitarian crisis.” It is due to this refugee situation that India became an active player in the war, and thus, India’s perceptions of the Mukti Bahini become indispensable from an analytical viewpoint.\nTo begin with, the Indians understood the Mukti Bahini as a resistance force, and for them, it consisted of the ‘Mukti Fouj’ and the “civilian freedom fighters” or the Gono Bahini as noted earlier. It is imperative to understand that India’s intervention in the war, support for the Mukti Bahini, and consequently the perception, could’ve been very well shaped by the refugee crisis.\nTo bolster this assertion, one must look at how the issue “…touched off outrage among the Indian people and enhanced the domestic pressures weighing on the government…[with the added] deleterious impact on the economy.” Added to all this was also the tension of a more considerable demographic debate regarding Hindu-Muslim composition and the threat it posed to the ruling government in terms of political calculus.\nThis was how India perceived the situation, and thus, to a certain extent, it seems plausible that India was not hesitant to aid the Mukti Bahini. In other words, a conjunction of the refugee crisis and the military/training needs of the Bangladeshi fighters prepared a context for shaping the Indian perception of the conflict and subsequently, the Mukti Bahini.\nShifting to understand the Pakistani perception towards the Mukti Bahini, an uncomplicated claim can be made, i.e., it was irrefutably hostile.\nAt another level, however, what influenced the Pakistani view of the Mukti Bahini was the relationship between the latter and the Indian establishment. It has also been pointed out that the Pakistani Army “…looked upon MB merely as Indian stooges, who were no match for the mighty Pakistan army.”\nThis is not to say that the Pakistani Army and the West Pakistan establishment were unsuccessful in reckoning with the force that Mukti Bahini was. Instead, more importantly, there is an analytical problem as to how we study this perception, viz., as something fixed in time. It is vital to apprehend that this perception, as opposed to being stationary in time, was in a state of constant evolution. For instance, the initial view might have been that the Mukti Bahini was merely an instrument of the Indian establishment (the “stooges” proposition). This perception carried weight since there was a prevalent view regarding the supposed racial superiority of the Pathans and Punjabis—who comprised the majority of the West Pakistani Army—over and above their Bengali counterparts in the East.\nThe view gained traction because of the general unanimity of this viewpoint ubiquitously that “…ordinary Bengalis were afraid of Pakistani soldiers, whether they were Pathans, Punjabis or Sindhis. If they were not, ten million people would not have fled from occupied Bangladesh and sought shelter in India.” The said perception, however, was not interminable since the Mukti Bahini, trained under the Indian Army, soon turned out to be a formidable force, a force to reckon with.\nNavigating the Murky Waters: Politics and Legitimacy\nThis section deals with understanding the Mukti Bahini as a full-fledged fighting force and its material contributions to the conflict. Simultaneously, the focus here will also be to determine the underlying politics involved in the functioning of the Mukti Bahini.\nOne of the single most significant contributions of the Mukti Bahini is in the form of its militaristic determination. What I mean by this is their unwavering commitment to the liberation cause through arms.\nThis assertion becomes more emphatic when one looks at the actual empirical evidence. A trend that bolsters this assertion is that “from the beginning of Pakistani military crackdown on Bangladesh till the end of the war, there was not a single day when the Mukti Bahini did not carry out offensive operations against Pakistan Army.”\nAdded to this was the professional heft that commanders like Colonel M.A.G Osmany brought to the fore. A leader like Osmany, who effectively headed the liberation forces, played a decisive dual role both as a member of the Awami League and as a retired senior officer.\nFurthermore, the Mukti Bahini, with the aid of the Indian Army, not only gained ammunition and skillset but also increased its personnel strength. A point noted in this regard was the presence of “volunteers for the Mukti Bahini [who] were not hard to find in the swelling refugee camps and many were of high calibre, such as well-educated student…”\nWhile moving on to comprehending some broader concerns regarding the landscape of legitimacy and politics vis-a-vis the Mukti Bahini, some natural questions arise: How did Mukti Bahini navigate the political ground? How did it establish its legitimacy? In order to answer these questions efficiently, one must be able to tease the characteristic differences between the Mukti Bahini and the main political force like the Awami League.\nThe Awami League performed some functions—acting as a government in exile, maintaining diplomatic communications, and more importantly, providing legitimacy to the liberation movement—that stood beyond the scope of Mukti Bahini.\nIn a similar vein, the Mukti Bahini was what one might label as “the actual fighting” arm of the liberation movement. Unsurprisingly, the political and the ground realities are different, so the experience that the Mukti Bahini had in terms of the ‘on-ground’ reality had far greater military capital.\nThis experience could partly be the reason for tensions between the Awami League and the Mukti Bahini since the latter thought that the League was nothing but “…a do-nothing-group living in luxury in Calcutta.” A sympathetic posture divorced from the specificities of quotidian politics towards Mukti Bahini will make this fact more cogent.\nThe Mukti Bahini, thus, appears as the most indispensable facet of the Bangladesh liberation movement. Its strength lies in its character, structure, and its ability to mobilise. The broader historiography generally looks at the 1971 Indo-Pak war as a struggle between two regional powers.\nHowever, it is imperative to analyse the role of supposed non-state actors like the Mukti Bahini for two main reasons. First, they provide a context-specific way of understanding history that fosters relatability for the general audience. Second, in terms of tangible efforts and outcomes, one can confidently conclude that the absence of Mukti Bahini from the 1971 war would have resulted in a consequently different historical moment.\nFinally, over and above these, Mukti Bahini represents a praxis of self-determination through resilience and pertinacity.\nNachiket is a second-year undergraduate at Ashoka University studying Political Science and International Relations.', 'Ekatorer Dinguli by Jahanara Imam is historical war-time literature of Bangladesh. The word Ekattorer Dinguli means the time of seventy-one. It means the time of 1971 when the bloody liberation war of Bangladesh took place. The writer of this book is Jahanara Imam. This book is one of the best creations of the wartime literature of Bangladesh.\nThis book is also famous in many countries worldwide. This is not only a book. This is also a live diary of a mother and a wife and a fighter for the country. This live diary about the bloody war of Bangladesh was written from 25th March 1971 to 17th December 1971. The book was written till the victory of Bangladesh with the war against Pakistan.\nThe history of the war is a different topic. Today we won’t describe that. But will try to go deeper into this historical book. Writing about this book also makes me feel good because I have read this book several times.\nAnd I hope that I will be able to write down and provide you with the summary properly. So let me begin. First of all, let’s know about the writer Jahanara Imam first. Then we will move on to the book.\nAbout The Author Jahanara Imam\nJahanara Imam was born on 3rd May 1929 in Murshidabad. Her father’s name is Sayed Abdul Ali. He was a Deputy Magistrate at that time. Jahanara Imam completed her B.A from a College in Kolkata. After that, she moved to Dhaka.\nShe was the headmistress of Dhaka Shiddheswari Girls School. And then, she completed her degree of M.A and B.Ed from Dhaka University and joined as a teacher in Dhaka Teachers Training College.\nJahanara Imam’s first son Rumi joined the liberation war of 1971. Jahanara Imam helped Rumi and his team fight against the oppressors by sheltering them, food, guns, etc. Her son Rumi died fighting against the West Pakistan army. And then Jahanara Imam became ‘Shaheed Janani.’\nThe word Shaheed Janani means the mother of martyrs. Jahanara Imam wrote her experience throughout the war in 1971. She started writing the history book on 25th March 1971.\nWhen the West Pakistan army first attacked. And still getting the victory, she kept writing the book. Later the book became a part of the history of the bloody war of 1971. Jahanara Imam also wrote some other books. She got the Bangla Academy prize for literature.\nInside The Book: Ekattorer Dinguli\nThe book is a day-by-day record of the bloody liberation war in 1971. Jahanara Imam wrote many things in the book that shows how brutal the oppressors were and how people reacted. The book holds a live diary of every day during the war. It starts on the 25th March 1971.\nWhen the West Pakistan army first attacked East Pakistan. They named this bloody operation as Operation Searchlights. Jahanara Imam witnessed the day, and she was in Dhaka at that time. From the book, I’ll show you a short diary of her.\n5th September: Sunday 1971\nSharif (Jahanara Imam’s husband) and I have been a dilemma about deciding on a complicated issue for the last two days. Sharif’s friends are thinking about getting Rumi (Son of Jahanara Imam) out. Two of Sharif’s friends said that – If Sharif sent a mercy petition begging the life of Rumi, Rumi might get released by the oppressors.\nFirst, I agreed on this because I was deeply anxious for Rumi primarily. But Sharif doesn’t agree to this. Rumi will not forgive us if we do this because Rumi was bravely fighting against the brutal West Pakistan army; Rumi won’t like it if we sent a mercy petition to the oppressive army.\nSharif’s two friends tried to manage Sharif, saying that the life of his son Rumi is much essential. They said that a brilliant son like Rumi needs to stay alive for the country’s sake. But still, Sharif is not agreeing. If the mercy petition is sent to the murderer’s government (West Pakistan in 1971), it will disrespect the ideology of Rumi. Sharif didn’t sleep for two nights.\nOnce I said, ‘You are right, we shouldn’t send a mercy petition to the murderer government”. And again, I’ve said crying, ‘send the mercy petition to save Rumi’s life.’ That’s how we spend two nights in a dilemma.\nAt last, Sharif decided that he wouldn’t send a mercy petition for his son to the oppressive government. I agreed to Sharif with eyes full of tears. We will try to get Rumi out but not by sending a mercy petition.\nThis diary of one day says all. I was astonished reading the book by Jahanara Imam. How brave someone can be and how much love people can have for their country. The book holds a great sacrifice of a mother and father—sacrificing their son for the country’s sake. By the war, Jahanara Imam had lost her son and her husband, Sharif.\nThat’s pathetic. Still, she didn’t give up. You have to read the whole book to know what’s actually in it. No more today explaining. It is tough to explain the book in one article. It is not possible. This is how Ekattorer Dinguli holds a great history of the liberation war in 1971.\nFor a final suggestion for book readers, don’t just read so many motivational books; we should also read history and other non-fiction. Take care.']	['<urn:uuid:5699314e-6cfb-41b2-9ce6-ffc676b8c0c8>', '<urn:uuid:7d7c77e7-0665-43bd-840f-ddd0f63a734e>']	open-ended	direct	concise-and-natural	distant-from-document	three-doc	expert	2025-05-12T13:53:09.865574	9	122	2779
76	I've been studying elite athlete development, and I'm curious about how modern technology is reshaping our approach to talent identification and training methodologies. What insights do we have about the relationship between natural ability and tech-enhanced training?	The traditional nature versus nurture debate in athletics has evolved with technological advances. While some athletes may appear to be 'naturals,' research shows success requires both genetic components and proper training. Modern technology provides comprehensive tools for talent development - from sophisticated data analytics for performance optimization to virtual reality for immersive training environments. Wearable technology and biometric equipment help fine-tune training strategies, while predictive analytics can assess injury risks. The science shows that characteristics previously assumed to be purely innate, like fast reactions in baseball, aren't entirely genetic, while aspects thought to be purely voluntary, like training drive, may have genetic components. Technology now allows for more precise understanding of how biological endowments interact with training environments.	"[""The sports gene : inside the science of extraordinary athletic performance / David Epstein.\n- ISBN: 9781591845119 (hardcover) :\n- ISBN: 1591845114 hardcover) :\n- Description: xiv, 338 pages ; 24 cm\n- Publisher: New York, New York : Current, 2013.\n- 17 of 18 copies available at NOBLE (All Libraries).\n- 1 of 1 copy available at Gloucester. (Show all copies)\n0 current holds with 18 total copies.\n|Library||Location||Call Number||Status||Due Date|\n|Gloucester||Adult Nonfiction||613.71/Epstein (Text to Phone)||Available||-|\n|Beverly Farms||Adult Nonfiction||RC 1235 .E58 2013 (Text to Phone)||Available||-|\n|Beverly Main||Adult Nonfiction||RC 1235 .E58 2013 (Text to Phone)||Available||-|\n|Danvers||Adult Nonfiction||RC 1235 E58 2013 (Text to Phone)||Available||-|\n|Endicott College||General Collection||RC 1235 .E58 2013 (Text to Phone)||Available||-|\n|Lynnfield||Adult Nonfiction||RC 1235 .E58 2013 (Text to Phone)||Checked out||12/08/2016|\n|Marblehead||Adult Nonfiction||613.71 EPSTEIN 2013 (Text to Phone)||Available||-|\n|Melrose||Nonfiction (Second Floor)||613.71 Epstein (Text to Phone)||Available||-|\n|Merrimack College||Stacks (3rd)||RC1235 ‡b.E58 2013 (Text to Phone)||Available||-|\n|Peabody Main||Adult Nonfiction||RC 1235 .E58 2013 (Text to Phone)||Available||-|\n|Next 10 »|\n|General Note:|| Includes bibliographical references (pages 295-328) and index.\n|Contents Note:|| In search of sports genes -- Beat by an underhand girl: the gene-free model of expertise -- A tale of two high jumpers (or: 10,000 hours plus or minus 10,000 hours) -- Major league vision and the greatest child athlete sample ever: the hardware and software paradigm -- Why men have nipples -- The talent of trainability -- Superbaby, bully whippets, and the trainability of muscle -- The big bang of body types -- The vitruvian NBA player -- We are all black (sort of): race and genetic diversity -- The warrior-slave theory of Jamaican sprinting -- Malaria and muscle fibers -- Can every Kalenjin run? -- The world's greatest accidental (altitudinous) talent sieve -- Sled dogs, ultrarunners, and couch potato genes -- The heartbreak gene: death, injury, and pain on the field -- The gold medal mutation -- The perfect athlete.\n|Summary:|| This book explores the roles of both genetics and training in athletic success, arguing that both are equally necessary components of athletic achievement while considering such topics as race, gender, and genetic testing.We all knew a star athlete in high school. The one who made it look so easy. He was the starting quarterback and shortstop; she was the all-state point guard and high-jumper. Naturals. Or were they? The debate is as old as physical competition. Are stars like Usain Bolt, Michael Phelps, and Serena Williams genetic freaks put on Earth to dominate their respective sports? Or are they simply normal people who overcame their biological limits through sheer force of will and obsessive training? The truth is far messier than a simple dichotomy between nature and nurture. In the decade since the sequencing of the human genome, researchers have slowly begun to uncover how the relationship between biological endowments and a competitor's training environment affects athleticism. Sports scientists have gradually entered the era of modern genetic research. In this exploration of athletic success, the author, a senior writer at Sports Illustrated magazine tackles the great nature vs. nurture debate and traces how far science has come in solving this great riddle. He investigates the so-called 10,000-hour rule to uncover whether rigorous and consistent practice from a young age is the only route to athletic excellence. Along the way, he dispels many of our perceptions about why top athletes excel. He shows why some skills that we assume are innate, like the bullet-fast reactions of a baseball or cricket batter, are not, and why other characteristics that we assume are entirely voluntary, like an athlete's will to train, might in fact have important genetic components. Through on-the-ground reporting from below the equator and above the Arctic Circle, revealing conversations with leading scientists and Olympic champions, and interviews with athletes who have rare genetic mutations or physical traits, the author forces us to rethink the very nature of athleticism.\nSearch for related items by subject\nAthletic ability > Genetic aspects."", 'Technology has permeated every aspect of modern life, and the world of sports is no exception. From enhancing athletic performance to revolutionizing the spectator experience, technology has fundamentally changed the way we engage with sports. In this article, we will explore the significant impact of technology on sports, from wearable devices to virtual reality.\nWearable Technology and Performance Enhancement\n- Fitness Trackers: Wearable fitness trackers like Fitbit and Apple Watch have become ubiquitous, allowing athletes and enthusiasts to monitor their physical activity, heart rate, and sleep patterns. These devices provide valuable data for tracking progress and optimizing training routines.\n- Smart Clothing: Advances in smart textiles have given rise to clothing with embedded sensors that monitor vital signs, body movement, and muscle activity. Athletes can wear these garments to gain real-time insights into their performance and reduce the risk of injury.\n- GPS and Tracking Devices: GPS technology enables athletes to track their routes, speed, and distance accurately. This data is particularly valuable in sports like running, cycling, and soccer, where precise performance metrics are crucial.\nData Analytics and Performance Optimization\n- Data-Driven Coaching: Coaches and athletes now have networthhive access to sophisticated data analytics tools that analyze performance metrics, biomechanics, and game statistics. This data-driven approach allows for more precise coaching and training regimens.\n- Predictive Analytics: Predictive analytics algorithms can forecast an athlete’s likelihood of injury based on data, helping teams implement preventive measures and reduce the risk of injuries.\n- Performance Simulation: Technology enables athletes to simulate game scenarios and practice under various conditions. This is particularly valuable in team sports where tactical preparation is critical.\nVirtual Reality (VR) and Augmented Reality (AR)\n- Training and Simulation: Virtual reality and augmented reality are used to create immersive training environments, allowing athletes to practice in realistic scenarios. This is particularly beneficial in sports like golf, where players can practice on virtual courses.\n- Fan Engagement: AR enhances the fan experience by overlaying digital information and graphics onto the live sports broadcast. Viewers can access player statistics, replays, and additional data in real time.\nInnovations in Sports Equipment\n- Advanced Materials: Sports equipment manufacturers are developing materials that are lighter, more durable, and designed to optimize performance. This includes carbon fiber in tennis rackets and aerodynamic designs in cycling.\n- Biometric Equipment: Athletes use biometric devices, such as heart rate monitors and muscle oxygenation sensors, to fine-tune their training and racing strategies.\nInstant Replay and Referee Assistance\n- Video Review: Video replay technology allows referees and officials to review key moments in a game, ensuring accurate decisions in real time.\n- Goal-Line Technology: In soccer and other sports, goal-line technology determines whether a ball has crossed the goal line, eliminating controversy over disputed goals.\nFan Engagement and Virtual Stadiums\n- Virtual Stadiums: With the advent of virtual stadiums and 360-degree camera views, fans can enjoy an immersive experience from the comfort of their homes.\n- Interactive Apps: Sports apps provide real-time updates, live streaming, and interactive features like virtual cheers and fan engagement polls.\nChallenges and Ethical Considerations\nWhile technology offers many benefits, it also presents challenges, including data privacy concerns, potential overreliance on technology, and issues related to equitable access to advanced equipment and training methods.\nThe impact of technology on sports is profound, influencing athlete performance, coaching methods, fan engagement, and the overall sports experience. As technology continues to evolve, the boundary between sports and innovation will blur further, providing new opportunities and challenges for athletes, fans, and sports organizations alike. Whether it’s wearables that help athletes monitor their health or virtual reality that immerses fans in the action, technology is shaping the future of sports in exciting and transformative ways.']"	['<urn:uuid:ff4fa200-c92c-474a-8857-5f6e91fcadc8>', '<urn:uuid:4054d352-5490-4b79-adcf-c360469da7ff>']	open-ended	with-premise	verbose-and-natural	distant-from-document	three-doc	expert	2025-05-12T13:53:09.865574	37	118	1262
77	how does social media change way people organize protests compared traditional activism	Social media has transformed protest organization in several key ways compared to traditional activism. The convergence of internet and media has expanded how people communicate and participate in movements by enabling easy information sharing without political or geographical boundaries. It allows for coordinating activities, recruiting new activists, planning protests and sharing strategic information more efficiently. However, the transformation goes beyond just technical benefits - it changes the psychology of participation and media literacy itself. The new media creates different forms of engagement like clicktivism, hacktivism, and cyberdisobedience. Analysis of hashtag movements shows activists often engage with multiple causes simultaneously and try to attract attention of prominent figures and institutions. While this enables rapid transnational organizing, critics argue it may create less sustainable movements compared to traditional offline activism.	['Connectist: Istanbul University Journal of Communication Sciences\nRich (New) Media Poor Activism Debates on Activism Movements in New MediaAkan Yanık, Mikail Batu\nThe convergence of the Internet and the media has enormously transformed the way in which the communication and interaction potential not only of the people, but also of the machines with their surroundings, and expanded their forms of participation. While the new media, which is the result of this convergence, has come to the forefront with its functional benefits as a catalyst such as information searching, expressing ideas, socializing and entertainment, its transformational role on media literacy and communication behaviours should also not be overlooked. Today, it is not difficult to predict that this transformational role will have much wider effects considering that people from every generation are heavy new media users and that even offline world interactions are virtual. In this study, we thought that it is vital to investigate how the activism ability of humans that made them the subject of their era will be transformed with the new media and what the effects will be, especially in the\nlight of ideological theories. Therefore, by studying the effects of the new media within the scope of activism, we tried to present the new media-activism relations, new types of digital activism, differences between these types and discussions under different perspectives. In this study, which tries to shed light on the effect of online cyber activism on real-life activism, firstly cyber activism types were gathered under a typology and then discussions on these types were tried to be presented with the interpretations of two different fronts. The discussions between ‘media carta’ approach, which sees the new media as the new tool of democratization and points out to its success on recent international examples, and ‘slacktivism’ approach claiming that cyber activism creates a sense of misunderstanding and undermines real-life activism were interpreted.\nYeni Medyada Aktivizm Hareketleri Üzerine Zengin Medya Kısır Aktivizm TartışmalarıAkan Yanık, Mikail Batu\nİnternet ve medya yakınsaması yalnızca insanların değil makinelerin de çevreleriyle olan iletişim ve etkileşim kurma potansiyelini önemli ölçüde dönüştürmüş ve katılım biçimlerini genişletmiştir. Bazı yakınsamaların sonucu olan yeni medyanın bir katalizör olarak, bilgi arama, fikirleri ifade etme, sosyalleşme ve eğlence gibi fonksiyonel faydaları öne çıksa da medya okuryazarlığı ve iletişim davranışları üzerindeki dönüştürücü rolü gözden kaçmamalıdır. Günümüzde farklı yaşlardan kişilerin, yoğun bir şekilde yeni medya kullanıcısı olduğu ve çevrimdışı dünya etkileşimlerinin de sanal olabildiği göze alındığında bu dönüştürücü rolün çok daha geniş etkilere sahip olacağını tahmin etmek mümkündür. Bu çalışmada, özellikle ideoloji kuramları ışığında, kişileri, döneminin öznesi yapan aktivizm yeteneğinin günümüzde yeni medyayla nasıl bir dönüşüm geçirdiği ve etkilerinin ne olduğu yönündeki araştırmanın büyük önem taşıdığı düşünülmektedir. Dolayısıyla yeni medyanın etkilerini aktivizm çerçevesinden inceleyerek, yeni medya-aktivizm ilişkisi, yeni dijital aktivizm türleri, bu türler arasındaki farklılıklar ve tartışmalar, farklı bakış açıları altında sunulmaya çalışılmıştır. Çevrimiçi siber aktivizmin gerçek yaşam aktivizmi üzerindeki etkisine ışık tutmaya çalışan bu çalışmada, öncelikle siber aktivizm türleri bir tipoloji altında toplanmış daha sonra bu türler üzerindeki tartışmalar iki farklı cephenin yorumlarıyla sunulmaya çalışılmıştır. Yeni medyayı demokratikleştirmenin yeni aracı olarak görüp uluslararası güncel örneklerdeki başarısını işaret eden ‘medya carta’ anlayışı ile siber aktivizmin yanlış bir fark yaratma duygusu yaratıp gerçek yaşam aktivizmini baltaladığını iddia eden ‘slacktivizm’ anlayışı arasındaki tartışmalar yorumlanarak ele alınmıştır.\nThe most obvious benefit of the new media emerging as a result of convergence is that it begins to easily convey all the information, ideas and facts, without any political, social and geographical boundaries. Although this benefit more often enables the transformation and globalization of communication systems, it has also made possible the rise of global protest networks (Ayers & Maccaughey, 2003). Today, the potentials offered by the new media for social collective movements are more likely seen in practices such as co-ordinating activities, meeting and mobilizing new activists, planning protests and publicizing highly strategic information. However, recent studies emphasize that new media should focus not only on cost-effective solutions created in communication techniques, but also on new motivations, creative and tactical potential, propagation speed, participation frequency and power of legitimacy which are added to the collective actions. However, the detailed literature review in this study shows that although the technical and functional relationship between new media and activism is explicit, its effects on activist participation psychology and the capacity to create sustainable solutions are highly controversial. While the studies focusing on the intensity of online participation and the frequency of messages created by the new media in social movements shows an optimistic table, studies focusing on offline participation forms, sustainability and psychological details emphasize pessimistic results.\nAccording to techno-supporters who focus on the process of technologysupported cognitive demonstrations and who are optimistic about the relationship between activism and new media, the new media has created an activist approach that forms creative collective identities with the opportunities it offers, calls for transnational support by transcending borders, and organizes demonstrations against political pressures. Thus, the new media is the new intersection point between the social context, the political objective and the actional stance, which create social movements. At this point of intersection, the new media first settles into daily practices with functional benefit and then transforms the practices of creating needs, ideas, and actions with new usage behaviours and transformed media literacy. In other words, as a result of mobility, advanced interface and multimedia supported infrastructure, firstly the practices and media literacy changes, and subsequently the typographic and phonetic signification practices in communication begin to transform. Techno-supporters argue that this transformation process directly supports the idealistic concepts such as multicenterism, liberty, disconnection, cooperation and accessibility in the ideological infrastructure of social movements (Tarrow, 2011). The techno-supporter front, who views the new media as the most important center of media democracy and symbolizes it as ‘media carta’, supports this argument by the emergence of new types of digital activism and by the fact that the actions it carries out can create sensational effects. The optimistic approaches of the techno-supporters have been tried to be conveyed under the umbrella of cyber activism via new activist methods such as clicktivism, netactivism, smartmob, cyberdisobedience, hacktivism, cybervigilantism, netwarism and cyberterrorism.\nTechno-critics address the new media with the critical theories put forward by the representatives of Marshall McLuhan and the Frankfurt School, and seeing it as a global ideological device, state that it is an area that needs to be carefully managed. In addition, it is emphasized that the level of autonomy that the new media, which is announced as the new instrument of revolution in the events like Arab Spring and seen as the new fourth force, provides for such powerful promises is highly controversial. That is to say, the liberties and the opportunities offered for the production of content provide an asymmetric autonomy for the access and distribution of the created content. For example, it is completely enigmatic when a content spreading through popular monopolized platforms such as Google, Facebook, Instagram, and Twitter will pass through Sandbox-style filter algorithms placed on search consoles, and on which page or how often it will be accessed after being ranked. According to Horkheimer and Adorno (2002), as the sovereignty of this intelligent digital status quo, developed by algorithms, becomes legitimate, the presentations in the media will be seen as the only reality, and this situation, as predicted by techno-supporters, will result in a homology that imposes uniformity under the name of harmony rather than diversity of ideas. From this point of view, some techno-critics consider the analogous mass, called the new subject, as populist intellectuals with low self-consciousness and interpret cyber activism as ‘slacktivism’, i.e. activism of the lazy (Christensen, 2011). Consequently, two basic facts lie in the essence of the techno-critics’ thoughts. First, focusing on the potential benefits of the new media with complex adaptive and SPIN characteristics but ignoring the tyrannies it might legitimize may cause huge fallacies and consequences. The second point of criticism emphasized by the techno-critics is ignoring the fact that the change that the media will initiate in the reading style would cover a large area such as media literacy and have psychological effects. Techno-critics, pointing out to conformist individualization as those rushing to leave a mark behind by Gramsci (1997) emphasize that an activism that develops based on the belief in feeling good and not the belief in making a difference is a conformist approach and the enthusiasm and motivation directed by the media as the subject cannot make the actions sustainable.\nIn conclusion, this study provides a technical and theoretical explanation that focuses on the effect of new media on the social, communicative, psychological and ideological dynamics underlying the collective social movements. Therefore, the perceptions and motives that enable the individual to participate in collective or individualistic networks in contemporary society, the debates between passive digital participation and active participation suggested as the new model of activism, and the important paradoxes in digital collective social movements will be further clarified.', 'Of serial activists and sock puppets: The relevance of language, topics and politics on Twitter\nDoes the Internet cause revolutions? Frequently that is being suggested, whether in the discourse surrounding the Arab Spring, Stuttgart 21, or the Occupy movement. The Internet, conventional wisdom assumes, is a global village that enables seamless and open communication. Social media such as Facebook and Twitter allow to rapidly exchange information and disseminate views, something that was arguably more difficult to accomplish in the past. But critics such as Malcolm Gladwell and Evgeny Morozov call this into question – clicktivism alone doesn’t make a revolution, they counter.\nHow does political activism in hashtags work?\nIn a conference paper my colleagues Marco Bastos, Rodrigo Travitzki and I recently explored this question. We analyzed 455 hashtags on different topics and in different languages (mostly English, Spanish and Portuguese tweets) , with a total of over 1 million different contributing users.\nOne of our findings is that there are forms of serial activism: in many cases the same users tweet on a variety of issues. In itself this is not surprising, but the intensity is significant – roughly 70% of all users in our dataset tweeted under at least two different hashtags. Political hashtags are especially popular among users tweeting about multiple causes (for example Occupy and the Spanish Indignados movement). This engagement does not automatically translate into political activism outside of Twitter, of course. But users inside our sample who tweeted under political hashtags often did so for multiple causes.\nAnother interesting finding is the addressing and mentioning of well-known users and institutions under activism-related hashtags. Users such as @barackobama, @occupywallst or @cnn appear in a large number of tweets of other users without contributing themselves. It is difficult to tell why exactly this happens. Tweets referring to news items are often commented on and redistributed under activist hashtags, but this alone does not explain the phenomenon. It seems likely that activists want to recruit prominent users for their cause (or at least catch their attention). For example, passive users total almost 20 million followers – five times as many as the actively tweeting users in out data. On the other hand, even without tweeting, such sock puppets can generate attention, for example when users actively search for tweets related to (i.e. mentioning) Barack Obama, without clarifying that he does not necessarily endorse the cause he is associated with through the tweet.\nThe importance of language\nUnsurprisingly language plays an important role when examining how closely individual hashtags relate to one another (measured by the users they share). The figure below shows the hashtags colored according to the language that is dominant in them (blue for English, red for Portuguese, green for Spanish). The closest association is between hashtags that share the same language, although Spanish and English hashtags are somewhat closer associated than those in English and Portuguese. Thematic groups are also clearly visible: the Occupy movement, Kony2012 and the Spanish Indignados (15M) movement are both connected internally and to each other. This transcends language barriers, a pointer to their character as transnationally followed events.\nSummary: the activist strategies of individual communicators transcend language barriers\nThe results of our study suggest that political movements such as Occupy and 15M are driven on Twitter by highly active and politically engaged users who communicate about a range of issues and transcend language barriers.\n– Bastos, M., Puschmann, C., Travitzki, R. (2013). Tweeting Across Hashtags: Overlapping Users and the Importance of Language, Topics, and Politics. Proceedings of 24th ACM Conference on Hypertext and Social Media, 1–3 May 2013, Paris.\nCornelius Puschmann is an associate researcher at HIIG.\nThis post represents the view of the author and does not necessarily represent the view of the institute itself. For more information about the topics of these articles and associated research projects, please contact email@example.com.']	['<urn:uuid:5081f827-76c1-424b-a074-a0e5ce8bf816>', '<urn:uuid:dda8b5e5-0891-451a-a5b1-fdbf706405b4>']	open-ended	direct	long-search-query	similar-to-document	three-doc	novice	2025-05-12T13:53:09.865574	12	128	2123
78	aruba banks seychelles flora islands comparison	Aruba serves primarily as a financial and maritime hub where banks can enforce mortgage rights through vessel sales in court, with procedures based on Dutch law allowing for quick execution of vessel arrests and sales. The Seychelles islands, on the other hand, are characterized by their rich endemic flora, including one endemic plant family, 12 endemic genera, and 72 endemic species from approximately 233 native plants. While Aruba focuses on maritime commerce and banking services, the Seychelles' significance lies in its unique plant life, such as the famous coco-de-mer palm that produces the world's largest nuts weighing over 22 kg.	"['Under the increasing pressure of a declining economy and plummeting oil prices, more and more shipowners, specifically those in the oil- and drilling industry, find it harder and harder to keep afloat. With mortgage obligations towards financing companies (usually one or more banks), heavy maintenance and operational costs, and a declining number of available contracts, many shipowners sink deeper into debt. As a result, banks are more often required to enforce their right of mortgage through summary execution.\nBoth Curaçao and Aruba are considered favorable locations for a judicial sale of seagoing vessels. As the Law in these jurisdictions is based on and similar to Dutch Law, it is relatively easy to place a vessel under arrest (both attachment before judgment and executory attachment are easily realized in these jurisdictions). Furthermore, a sale can often be effected within a month from the moment the vessel was placed under arrest.\nFor many years, VanEps Kunneman VanDoorne has been assisting banks and other mortgagees with the judicial sale of ships in these jurisdictions.\nIn Curaçao and Aruba the judicial sale of a vessel is generally effected before the court. The vessel is auctioned publicly by the court, resulting in the adjudication of the vessel by the court to the highest bidder, under the condition of payment of the purchase price. In this respect, the courts of these jurisdictions will usually allow a prospective buyer to provide a bank guarantee as substitution for payment of the purchase price. According to the shared Civil Proceedings Code of Curaçao and Aruba (and also Sint Maarten, Bonaire, Saba and Sint Eustatius), a vessel is adjudicated to the buyer free and clear of all mortgages, attachments, and other encumbrances. There are, however, several things to consider when effecting a judicial sale.\nThe courts do not issue a ‘bill of sale’, however the judgment and adjudication record issued by a court serve as evidence of the judicial sale and are generally (sometimes accompanied by a legal opinion from the attorneys of the executing party) accepted worldwide, therefore allowing the buyer to (re-)register the vessel. This brings into question the ‘moment’ when ownership of the vessel is transferred.\nAccording to Dutch Law and the Law of Curaçao, Aruba, Sint Maarten, Bonaire, Sint Eustatius and Saba a legal transfer of ownership can only be achieved on the basis of (1) a valid title and (2) ‘delivery’ pursuant to said title. The title is provided by the adjudication judgment, however the Law of these respective jurisdictions does not provide any specification on how the delivery should be effected to complete the transfer of ownership.\nLarge seagoing vessels are generally (in many jurisdictions worldwide) classified as property subject to registration. Consequently, transfer of ownership of these vessels usually requires entry in the appropriate public registers. However, large seagoing vessels are by nature characterized by their international aspects. These vessels are usually registered in one state (often Panama, Liberia, Bermuda or the Marshall islands due to the favorable climate for shipowners), owned by a company registered in another state, and financed by one or more (international) banks.\nWhen a foreign vessel (i.e. not registered in Curacao, Aruba, Sint Maarten, Bonaire, Sint Eustatius or Saba as the jurisdiction it is currently in) is sold through a judicial auction before a court in one of these jurisdictions, it does not qualify as registered property (registergoed) since it is not registered in these jurisdictions. This implies that delivery of a vessel after it has been sold by court auction would have to be effected in the same way as would be the case for delivery of any other movable property.\nIn practice, it is generally presumed that the adjudication of the vessel by the court to the buyer also constitutes the required delivery of the vessel. This is however not the case, as has been accurately pointed out in a judgment of the Court of First Instance of Sint Maarten (such a judgment has an immediate effect in Curaçao or Aruba, since the Law on this matter is identical and therefore the same arguments apply).\nAccording to Dutch private international law, the delivery required for the legal transfer of ownership of a registered vessel is governed by the Law of the State where that vessel is registered (section 10:127, paragraph 2 of the Dutch Civil Code). The Law of Curacao, Aruba, Sint Maarten, Bonaire, Sint Eustatius and Saba respectively, does not provide for a similar rule. In these jurisdictions, delivery of possession was simply believed to be achieved through the ‘granting of possession’ (bezitsverschaffing) of the vessel by the executing party to the buyer.\nIn a judgment dated 9 February 2016, the Court of Sint Maarten found that the provision of Dutch private international law, as mentioned above, is also applicable to the unwritten private international law of Sint Maarten, based on the ‘concordance principle’: civil and commercial law in the Netherlands, Curacao, Aruba, Sint Maarten, Bonaire, Sint Eustatius and Saba are to be regulated in concordance with each other (Article 39 of the 1954 Charter of the Kingdom of the Netherlands). Where the Law of Curacao, Aruba, Sint Maarten, Bonaire, Sint Eustatius and Saba lacks certain regulations, they are to be coordinated with Dutch Law as much as possible. In theory this principle only creates an obligation for the legislature, however local courts have also referred to it to interpret the (system of) the Law where it lacks clarity, as the court of Sint Maarten has done in this case.\nThe judgment of the court of Sint Maarten is good news for banks and other mortgagees, acting as executing parties in a judicial sale of a vessel in Curaçao, Aruba, Sint Maarten, Bonaire, Sint Eustatius and Saba. Until now, the moment ownership of a vessel is transferred was presumed to be the moment of payment, after adjudication of the vessel by the court. This posed a problem with regards to insuring the vessel, as insurance companies required the transfer of the vessel to the new owner to be registered before the vessel could be insured. With the judgment of the Sint Maarten court, the transfer of ownership is clearly marked by registration of the sale in the flag state, which closes the insurance ‘gap’ and reduces the risk for prospective buyers.\nVanEps Kunneman VanDoorne has extensive experience in all legal aspects of the shipping industry, such as disputes related to chartering, cargo claims, collision, general average, as well as ship financing, employment, ship repair, ship registration, drafting general terms and conditions, international debt collection, ship arrest and auctions.\nWe assist many players in the industry, such as ship owners, shipyards, agents, insurance companies, brokers, mortgagees and cargo owners.\nThis article is written by Carlos Winkel. Carlos was a highly talented and a passionate lawyer. Moreover, he was a very beloved colleague, until he died unexpectedly and far too young in March 2017.', 'Location and General Description\nThe Seychelles Islands are located in the middle of the Indian Ocean, about 5 degrees south of the equator and 930 km northeast of Madagascar. The 115 islands in the group can be divided into two types: granitic islands and low limestone islands. The 42 granitic islands are peaks on a largely submarine plateau, situated in the northeastern part of the archipelago. Mahé, the largest and tallest island in the Seychelles (145 km2; 905 m), is typical of the granitic islands. A mountain ridge runs the length of the island. The lower regions have been developed for residential and agricultural use, and the upper regions are still largely forested. The granitic islands have steep sides and impressive peaks, shaped by weathering and erosion. The erosion of the steepest inclines has produced large rocky outcrops, or ""glacis."" The islands experience a humid tropical climate with little seasonal variation in temperature. They receive heavy monsoon rains from November to February, and in the cooler months the trade winds blow steadily from the southeast. Mean annual rainfall varies with elevation, and on the granitic islands rainfall ranges from 2,300 to 5,000 mm (Stoddart 1984). The abundant rainfall and warm temperatures, along with soil enriched by guano, allowed lush palm forests to develop on the islands, most of which have now been cleared.\nAt elevations below 610 m, palms, pandans and hardwoods characterize the natural forests of the granitic islands. Above this elevation, there is cloud forest, rich with tree-ferns and mosses. Forest composition varies somewhat from island to island within the Seychelles, but common tree species include: Phoenicophorium borsigianum, Albizzia falcata, Pterocarpus indicus, Adenanthera pavonina, Morinda citrifolia, Phyllanthus casticum, Pisonia grandis, and introduced coconut palms. Tree-ferns, palms, orchids and an endemic species of pitcher plant (Lalyann potao) are all also relatively common. Although the Seychelles flora boasts many interesting species, the most famous of these is the coco-de-mer palm (Lodoicea maldavica) that is found only in the Vallée De Mai on Praslin Island. This palm grows up to 30 m tall, with leaves up to 6 m long by 4 m wide. Even more striking are the nuts: the coco-de-mer produces the largest nuts in the world, with some specimens weighing more than 22 kg.\nDue to their age, geography and isolation, the Seychelles supports a variety of endemic taxa. In the plants there is one endemic family, 12 endemic genera, and 72 endemic species from a flora of about 233 native plants (White 1983, Procter 1984, Robertson, 1989). The palms are a particularly unique group, with 6 endemics classified into 6 monotypic genera. The pandans are also unusually diverse, with the granitic islands hosting 8 species, of which 5 are endemic. Unfortunately, many of the unique plants of the Seychelles have small populations and restricted distributions. For example, the jellyfish tree (Medusagyne oppositifolia) has a total population of fewer than 30 plants scattered over three hilltops on Mahé. It is the sole representative of the endemic family, Mesdusagynaceae, and is currently one of the rarest plant species in the world. It was thought to be extinct until it was rediscovered in 1970.\nThe flora shows affinities with that of nearby islands, Madagascar and the Mascarenes, as well as with mainland Africa and Asia. The Seychellian species of Impatiens, Psederanthemum, and Rothmannia are more closely related to species found on the African continent then they are to species that live on Madagascar and the Mascarenes. And although Asia is twice as far away as mainland Africa, several species are found only on the Seychelles and in Indo-Malaysia and Polynesia. For example, Amaracarpus pubescens grows only in the Seychelles and in Java. These strange distribution patterns are thought to be relictual, reflecting the islands’ geological history, when they were linked with Asia (Friedman 1994).\nUnlike many other mid-oceanic island groups, the Seychelles are inhabited by a diverse herpetofauna. The most famous native species are the giant land tortoise (Dipsochelys arnoldi on the granitic Seychelles and Dipsochelys dussumieri on Aldabra (Bourn et al. 1999). Giant tortoises were once abundant on both the granitic and coralline islands throughout the Seychelles, but the populations on the granitic Seychelles were decimated following human settlement. In addition to the tortoises, there are several native terrapins, 7 species of legless caecilians, 4 native frogs, 3 native snakes, an endemic chameleon, and several species of geckos and skinks. One endemic mammal species is found here, the critically endangered Seychelles sheath-tailed bat (Coleura seychellensis) (Hilton-Taylor 2000).\nThe landbird fauna of the Seychelles is particularly unique. There are 12 endemic species found here, including two species, the Seychelles Scops-owl (Otus insularis CR) and the Seychelles paradise-flycatcher (Terpsiphone corvine CR), which are confined to single islands. Other endemics are the Seychelles kestrel (Falco araea VU), Seychelles blue-pigeon (Alectroenas pulcherrima), Seychelles swiftlet (Collocalia elaphra VU), Seychelles bulbul (Hypsipetes crassirostris), Seychelles magpie-robin (Copsychus sechellarum CR), Seychelles warbler (Acrocephalus sechellensis VU), chestnut-sided white-eye (Zosterops mayottensis), Seychelles white-eye (Zosterops modestus CR), and Seychelles fody (Foudia sechellarum VU). Two endemic subspecies of note are the black parrot (Coracopsis nigra barklyi) and Seychelles turtle-dove (Streptopelia picturata rostrata).\nIn the past, there were more endemic bird species on the Seychelles, but these have gone extinct (one species and one subspecies). The extreme rarity of some other taxa (Gerlach 1997, Stattersfield et al. 1998, Hilton-Taylor 2000) indicates that further extinctions are possible (at least in the wild). Intensive species recovery programs have helped the survival of some birds, including the recolonisation of some parts of their former range, e.g for Seychelles Warbler (Komdeur 1994) and Seychelles Magpie Robin (McCulloch 1996).\nMost of the lowland forests of the Seychelles granitic islands have been disturbed or destroyed. Coconut, vanilla and cinnamon plantations occupy most of the coastal plateaus (Sauer 1967). The mountain forests are certainly not pristine, however, there is still some native forest in the higher reaches of the granitic islands. The Vallée de Mai on Praslin Island provides the best example of intact native forest and has been declared a World Heritage Site. The Morne Seychellois N.P. (35 km2) contains important mountain mist forest. Other important reserves are Aride Special Reserve (0.7 km2), Cousin Special Reserve (0.3 km2), La Digue Veuve Special Reserve (0.1 km2) and Curieuse National Park (15 km2). Although extremely small the reserves do a good job of protecting critically endangered species as well as the habitats they rely upon. For example, an intensive recovery program has helped increase the total population of the Seychelles warbler from 30 to 500 individuals. Intense management efforts have helped build up the populations of the Seychelles magpie robin on Frégate Island, and to translocate it to other islands.\nTypes and Severity of Threats\nDespite efforts to protect the flora and fauna of the Seychelles, there are still a number of threats to the native biota. Anthropogenic disturbance of native habitats is still a problem, and human-facilitated introduction of exotic species is a continuing threat. Alien species now comprise 57 percent of the total flora of the Seychelles, and this percentage is likely to increase with time (Procter 1984). Introduced goats, pigs and cattle inhibit regeneration of native forest; and introduced cats, dogs, common mynah (Acridotheres tristis) and tenrecs prey upon native species, particularly birds, lizards, caecilians and invertebrates. Introduced plants also outcompete the native vegetation and provide unsuitable habitat for the endemic animals. Aside from land clearance and introduced species, the main conservation concern in the Seychelles is the vulnerability of small populations with restricted ranges. Although many native species have probably always had small populations, the majority of them were spread over several islands. Following human settlement, one species after another has been reduced to one or two relict populations. The endemic land birds all occupy a mere fraction of their historic range. Small populations in single locations are especially vulnerable to stochastic events and have a high probability of extinction. Translocation efforts have helped mitigate the risks inherent in having spatially restricted populations, but not without their own risks. In summary, the Seychelles government, in cooperation with international agencies, is doing a good job of protecting the unique biological heritage of the islands. However, the long-term survival of many species and habitats is still far from certain.\nJustification of Ecoregion Delineation\nThe long isolation of the granitic islands of the Seychelles Archipelago and the exceptionally high levels of endemism in both flora and fauna warranted their classification as a unique ecoregion. Endemism at higher taxonomic levels is particularly notable, including the families Medusagynaceae and Sooglossidae.\nBourn, D., C. Gibson, D. Augeri, C.J. Wilson, J. Church, and S. Hay 1999. The rise and fall of the Aldabran giant tortoise population. Proceeding of the Royal Society Biological Sciences B266: 1091-1100.\nFriedman, F. 1994. Seychelles. Pages 288-292 in S.D. Davis, V.H. Heywood, and A.C. Hamilton, editors. Centres of Plant Diversity, Volume 1, Europe, Africa, South West Asia, and the Middle East. IUCN Publications Unit, Cambridge, UK.\nGerlach, J., editor. 1997. Seychelles Red Data Book 1997. Nature Protection Trust of the Seychelles, Mahe.\nHilton-Taylor, C. 2000. The IUCN 2000 Red List of Threatened Species. IUCN, Gland, Switzerland and Cambridge, United Kingdom.\nKomdeur, J. 1994. Conserving the Seychelles Warbler Acrocephalus seychellensis by translocation from Cousin Island to the islands of Aride and Cousine. Biological Conservation 67: 143-152.\nMcCulloch, N. 1996. The Seychelles Magpie Robin: first steps on the road to recovery. Bull. African Bird Club 3: 81-84.\nProcter, J. 1984. Vegetation of the granitic islands of the Seychelles. Pages 193-208 in D.R. Stoddard, editor. Biogeography and ecology of the Seychelles islands. Junk Publishers, The Hague.\nRobertson, S.A. 1989. Flowering plants of Seychelles. Royal Botanic Gardens, Kew.\nSauer, J.D. 1967. Plants and man on the Seychelles coast. University of Wisconsin Press, Madison, Miluakee and London.\nStattersfield, A. J., M. J. Crosby, A. J. Long, and D. C. Wedge. 1998. Endemic Bird Areas of the World. Priorities for biodiversity conservation. BirdLife Conservation Series No. 7. BirdLife International, Cambridge, United Kingdom.\nStoddard, J.W. 1984. Impact of man in the Seychelles. Pages 641-654 in D.R. Stoddard, editor. Biogeography and ecology of the Seychelles islands. Junk Publishers, The Hague.\nWhite, F. 1983. The vegetation of Africa, a descriptive memoir to accompany the UNESCO/AETFAT/UNSO Vegetation Map of Africa (3 Plates, Northwestern Africa, Northeastern Africa, and Southern Africa, 1:5,000,000). UNESCO, Paris.\nPrepared by: Winnie Roberts\nReviewed by: In progress']"	['<urn:uuid:62c71821-9320-4ac1-9e97-74b327b31693>', '<urn:uuid:487acae9-65f1-419b-b9b2-0f8cd0d725a8>']	open-ended	direct	short-search-query	similar-to-document	comparison	novice	2025-05-12T13:53:09.865574	6	100	2868
79	What are the key differences between filing a standard compensation claim versus pursuing legal action against an employer, and what specific circumstances would lead to choosing one path over the other?	A standard workers' compensation claim is a no-fault insurance system where employees receive medical benefits and wage replacement (2/3 of salary) without having to prove employer negligence, but they give up their right to sue for negligence. However, employees may pursue legal action through employer liability claims in specific circumstances, such as when workers' comp is deemed inadequate or when employer negligence is involved. Legal action can cover additional claims like third party over actions, loss of consortium, dual capacity suits, and consequential bodily injury. In cases of company insolvency, employees must go through the government's Redundancy Payments Office for compensation, but if the employer hasn't entered formal insolvency, employees may need to bring a tribunal claim to receive payment.	['What rights do workers have once they have been made redundant by an employer that has gone into administration or liquidation? Coodes Solicitors Employment Lawyer Philip Sayers comments, in light of the latest news from troubled café chain Patisserie Valerie.\nIn the latest in a stream of headlines about Patisserie Valerie, it has now been revealed that the company has failed to pay hundreds of its redundant workers.\nIf a company becomes insolvent, some or all of its employees may be made redundant. This is what has happened in the case of Patisserie Valerie. When an employee is made redundant, he or she will retain certain rights and entitlements, even if the employer is unable to pay them.\nEmployees who have been made redundant due to insolvency have the right to know how their job is affected and what they should do next. An insolvency practitioner will step in to handle a number of employment procedures. Their role includes providing each employee with a RP1 form and a case reference number to use when applying for any money owed. Depending on the situation, an employee can apply to the government’s Redundancy Payments Office for a number of outstanding monetary arrears due from their employer.\nWithin six months of being made redundant, an employee can apply to the government for the following:\nEmployees should have been continuously employed by the insolvent business for a minimum of two years to claim redundancy payment, which is capped at £508 a week. An employee under the age of 22 can be eligible for half a week’s pay for each year they completed at that age. This rises to one week’s pay for each year for employees aged between 22 and 40 and one and half week’s pay for each year if the employee is 41 or older, to a maximum of 20 years.\nAfter being made redundant, an employee can get paid for holiday owed. This includes any holiday days which they were not paid for in the 12 months before the insolvency for up to six weeks of holiday days. This is capped at £508 a week.\nAn employee who has been made redundant may also be able to claim for outstanding payments, such as unpaid wages, overtime and commission. This is also capped at £508 a week and an employee can receive up to eight weeks’ worth of outstanding payments.\nAn employee is entitled to a paid statutory notice period, capped at £508 a week, even if it is not in their contract. An employee will be paid one week’s notice for every year they were employed, up to a maximum of 12 weeks.\nMore information, and details on how to apply, can be found on the government’s website.\nThese rights and compensation are only available when the employer enters into a formal insolvency event, which can include administration, liquidation or Company Voluntary Arrangements (CVA).\nOne problem I have encountered when advising clients is when an employer runs out of money and ceases trading but fails to enter into a formal insolvency event. In that situation for all sums except a redundancy payment, an employee will have to bring about a tribunal claim and get a judgment against the employer before the Redundancy Payments Office will pay out.', 'What is the Difference Between Workers’ Comp and Employer’s Liability?\nPersonal injury blog\nUnderstanding the basics of workers’ compensation and employer’s liability is the best way to differentiate the two.\nAs workers’ comp attorneys, we are often asked the difference between the two, so you are not alone if you are not sure yourself.\nBoth workers’ compensation and employer’s liability deal with injuries in the workplace and the compensation received by the injured employee.\nIn this article, we will break down both matters, provide different examples for each, and give an in depth overview of how they are different.\nWhat is Workers’ Compensation?\nWorkers’ compensation, also known as workers’ comp, is a form of no-fault insurance.\nIt is purchased by employers and provides medical benefits and wage replacement to employees who were injured while working or in the workplace. In a workers’ compensation case, the employee does not have to show that the employer’s negligence caused their injury.\nIn exchange for medical benefits and wage replacement, the injured employee gives up their right to sue their employer for negligence.\nWorkers’ compensation insurance can cover more than just medical care and income replacement. It can also include compensation for permanent injuries and retraining costs, but it does not cover pain and suffering.\nIncome replacement is typically 2/3s of the employees current salary or income, but there is a fixed maximum amount that benefits will not exceed.\nThese benefits are not taxed and usually begin quickly after an injury on the job.\nMany different types of employers can be covered by workers’ compensation insurance such as; volunteers, business owners, independent contractors, farmers, and more.\nWorkers’ compensation is mandated by each state and can vary based on the type of injury or illness. In the state of Missouri, any company with five or more employees must carry workers’ compensation insurance. The only exception is in the construction industry, in which you much have workers’ compensation insurance if you have one or more employees.\nHere is a simple example of a workers’ compensation case.\nA waitress trips and falls while serving food at a restaurant. As a result of the fall, she broke her ankle. Her medical expenses to treat the broken ankle are $2,400. She also missed a month of work while her ankle was healing, resulting in a loss of $4,000 in income. Workers’ compensation would cover $6,400 for the medical expenses and loss of wages.\nWhat is Employer Liability?\nEmployer liability insurance is a type of business insurance that can cover compensation costs and legal fees if an employee files a lawsuit for injury or illness caused by their work.\nAn example of employer liability would be:\n- A manager tripping over a cable in their office causing a severe injury.\n- The injured manager then hires a workers’ compensation lawyer and files a compensation claim against the employer.\n- The court rules that the employer needs to pay costs for the injury and compensation.\nEmployer liability insurance would cover not only the compensation amount, but also the legal fees accrued during the lawsuit.\nEmployers’ liability comes into play when there is a possible lawsuit. It covers four major types of claims: third party over actions, loss of consortium, dual capacity suits, and consequential bodily injury. Once in court, the employee must show that the employer was negligent to receive any additional benefits.\nThird Party over Actions\nThird party over actions is when a third party files a lawsuit because they are being held liable for an employee’s injury. For example, a construction worker was using a piece of equipment that the employer did not maintain properly. The poorly maintained equipment injures the employee and the employee sues the manufacturer of the equipment. In return, the manufacturer sues the company for contributory negligence for their failure to maintain the equipment.\nLoss of Consortium\nLoss of consortium is a claim for damages suffered by a family or spouse of an employee who was injured or killed because of negligent or intentional acts.\nDual Capacity Suits\nThis type of suit is when the employee sues the employer as a supplier of a product, owner of premises, or provider of service.\nConsequential Bodily Injury\nIn this type of suit, a member of an injured employee’s family claims to have an injury that is a direct result from the employee’s injury.\nOverall, most employers are required to have employers’ liability coverage to cover these potential types of claims. The cost of employers’ liability insurance depends on the type of business and number of employees.\nSo What is the Difference Between Workers’ Compensation and Employer’s Liability?\nWhen a company purchases workers’ compensation insurance, they are also purchasing employer’s liability insurance.\nThey are both typically purchased together under a company’s overall business insurance policy. Workers’ compensation covers statutory obligations that are covered under a state’s specific compensation laws. Employers’ liability provides coverage when an employee does not feel that the workers’ comp policy provides adequate coverage, and that the employer was negligent.\nFor example, a factory worker believes that he needs a steel step stool to do his job.\nThe employer, disagrees and thinks a wooden step stool is better and requires that a wooden step stool is used. The factory worker uses the wooden step stool and it breaks, resulting in severe injury. After filing a workers’ compensation claim, the factory worker believes that he is not being properly reimbursed. He files a claim against his employer, claiming that the employer was negligent because he was required to use a wooden step stool. Employers’ liability would cover the costs of the claim.\nFrom an Employee’s Point of View\nIf you have been injured or sick due to work, it is important to report the injury or illness to an employee or supervisor immediately. Typically, the time frame to report an injury or illness is within 30 days to potentially receive any workers’ compensation benefits.\nIf you feel like you were mistreated by an employer after a work injury, speak with a work injury attorney today.']	['<urn:uuid:c624ca46-ce89-4a2b-89a2-db16c4ac312c>', '<urn:uuid:decd0701-35cb-4770-b269-fd9e38efdd4b>']	open-ended	direct	verbose-and-natural	distant-from-document	three-doc	expert	2025-05-12T13:53:09.865574	31	120	1555
80	I've been researching post-Soviet transitions, and I'm wondering how Poland's forced integration into the Soviet sphere after WWII compares with Russia's voluntary isolation after 1991 - what were the key differences in their approaches to international engagement?	The approaches were markedly different. Poland was forcibly integrated into the Soviet sphere through a fraudulent Soviet-controlled election in 1945, despite Polish citizens' anger and antipathy toward Soviet control. In contrast, post-1991 Russia voluntarily chose isolation, taking a 'go-it-alone' approach that deprived it of many global economy benefits. While Poland was forcibly made part of the communist network against its citizens' wishes, Russia actively chose not to participate in the transformation of former Warsaw Pact states and rejected European integration because it would require surrendering some sovereignty and Great Power status. This self-imposed isolation made Russia an outlier in most fields, fundamentally different from Poland's forced Soviet integration.	"[""An American diplomat on the ground in 1991 explains why pushing back the reactionary coup 20 years ago was the easy part.\nBoris Yeltsin and Mikhail Gorbachev at the extraordinary fifth session of Peoples' Deputies of the Soviet Union On the 3rd Septemberб 1991. Photo: ITAR TASS\nTwenty years ago in Moscow popular opposition defeated the reactionary putsch intended to turn back the clock of reform in the dying Soviet Union. The experience was, initially, similar to the recent ‘Arab Spring’.\nWhat went right?\nThe putsch failed quickly, sparing Russia a trauma like Syria or Libya today. Crucially, the Russian armed forces remained professional, sparing Russia the militarization of politics seen in Germany in the Twenties or Yugoslavia in the Nineties. Yeltsin jettisoned the past quickly – both the Communist Party and the Soviet empire – to focus Russian efforts and resources on Russia’s future. Doors previously closed to the outside world were opened for Russians to explore new lands and ideas. Freedom of speech and the media attained heights never seen in Russia before or, sadly, since. Youth was welcomed into the halls of power. The Cold War, radically scaled back by Gorbachev, was abandoned. Russia turned West and sought a genuine European identity.\nWhat went wrong?\nIt is vastly easier – and surer – to tear down a poor edifice than to design and build a replacement. The vacuum of power at all levels and in all fields attracted both the best and the worst, with the former a distinct minority. Youth and former dissidents demonstrated their talent at debate, but not at organization, administration or compromise. Ideologies and reform experiments imported from the West – especially in economic stabilization – often proved woefully wrong for Russia and deepened the damage left by the Soviet collapse. Economic failures tarnished nascent efforts at political reform. This led to a vacuum of democratic legitimacy and ultimately to the restoration of the ‘vertical of power’: neither neo-Soviet nor proto-democratic. A genuine threat to Russian integrity in Chechnya provoked a cure worse than the disease. As Aleksandr III once declared Russia’s only friends were its army and navy, today the state rests on the pillars of oil and gas, which corrupt even as they enrich.\nWhy did things go so wrong?\nSeven decades of Soviet misrule infected almost every field of public policy: agriculture, industry, energy, investment, infrastructure, security, politics, civil society, religion, health, education, media. The Soviet Union was not so much under-developed as critically mis-developed, with fundamental reform needed in every sector. Where to start? Historian General Dmitriy Volkogonov once told me that many good people were needed in every field, but there simply were nowhere near enough to go around.\nExpectations of a new and improved standard of living – “to live like normal people” – were high while understanding of the challenges was low. How do you quickly reform an economy lacking even double-entry bookkeeping to know whether an enterprise adds or destroys value? Some Russians were less willing than their Chinese counterparts to learn from the outside world, while many continued to believe “here is better.”\nRussia did not take part in the transformation of former Warsaw Pact states, in part because Europe could not afford it, but in large part because Russia chose not to. European integration requires significant surrender of sovereignty and of pretensions to Great Power status. Russia took a go-it-alone approach that deprived it of many benefits of a global economy. Russia remains today an outlier in most fields, by choice.\nRussia’s reforms – even under Yeltsin – were less radical than they appeared. Elites preferred ‘managed democracy’ to rule of law. Political parties never matured, while a free media withered. Russians today enjoy vastly greater freedoms than did their parents, but these are personal freedoms divorced from genuine political liberty. Russians know the difference and judge their leaders on the basis of material progress rather than legitimacy. Millions of the most talented younger people have sought new lives abroad. Their loss reflects the continuing alienation of Russia’s ruling elite from its own people – an old Russian story.\nFinally, the outside world, including the United States, was timid in engaging the new Russia to fulfill the rhetoric of a “Europe whole and free”. Europe and America welcomed the demise of Cold War institutions in the East, but maintained them in the West, especially NATO. As reforms failed in Russia, Western advocates of unworkable policies – the “Washington consensus” – blamed the failures on inherent Russian dysfunction rather than on bad policies.\nSome observers of Russian affairs, both at home and abroad, believe the country is approaching another historical turning point, perhaps a revolutionary shift. If so, the ‘Russian Spring’ of the early Nineties teaches that revolution is easy, but reform is hard. Discarding the Soviet past required courage, enthusiasm and hope. Building a better Russia demanded realism, patience and stamina – and still does.\nE. Wayne Merry was the American Foreign Service Officer in charge of reporting and analysis on Russian domestic politics at the United States Embassy in Moscow, 1991-94."", 'Polish Antipathy towards the Soviet Union\nAfter the conclusion of the Second World War, the victorious Allies were showered with the spoils of their success in the conflict. The victorious nations - the Soviet Union, United States, Great Britain, and France -- were left to decide what to do with the war ravaged countries that remained throughout Europe and Asia. The major question on the minds of the leaders and politicians remained: how to divide up the crumbled nations of the broken continent? When dividing up the spoiled nations, the job was broken into different geographical tasks: Europe, Asia, and the third world countries (Gaddis, 1997).\nIn February 1945 the leaders from the big three countries - Franklin Roosevelt (President of the United States), Winston Churchill (Prime Minister of Great Britain) and Josef Stalin (Soviet Premier) met in the City of Yalta to discuss how to divide Europe (Judge & Langdon, 1999). The Soviet Red Army had already occupied Poland and established a Soviet-sponsored provisional government (Judge & Langdon, 1999). The Polish people were in favor of being run by a Soviet-sponsored government or of being recognized as a central Soviet state.\nWith the war in Japan far from over, Roosevelt believed that conceding Poland to the Soviet Union would help gain Russian support against the Japanese (Judge & Langdon, 1999). Churchill and Roosevelt tried to obtain the best arrangement they could on Poland, but it would be a futile process as the Soviets would go on to occupy Poland (Judge & Langdon, 1999). Historically, this is noted as the point that the Western leaders sold out the Poles to the Soviets. The Polish citizenry and political leadership were left upset that they were just given to the Soviets as a bargaining chip in World War II.\nThe Yalta Conference essentially made the country of Poland a Soviet territory. The three powers decided to recognize the Polish Provisional Government of National Unity. In 1945 - as promised by Stalin - Poland would hold democratic elections (Dziewanowski 1987). The elections, controlled by the Soviets, were a fraudulent act used to claim Soviet legitimacy over Poland (Dziewanowski 1987).\nWith the Soviet sponsored government in place, the Polish people would be officially part of the communist network. The citizens of Poland were angry at being sold out to the Soviets and would develop feelings of antipathy toward the Soviet Union. The feelings of antipathy would cause superior conflict between the Polish people and the Soviet-sponsored state. The communist-backed Polish Provisional Government of National Unity would have to intervene to try to end the antipathy that the population of Poland felt towards the Soviets.\nThe steps taken by the Polish Provisional Government of National Unity were meant to stop antipathy, and succeeding in suppressing anti-communist views with the threat of violence and the creation of the Polish Constitution of 1952. This was used to ease the transition of Poland into a central Soviet state, and was coupled with an interjecting of Soviet influence into the daily lives of their citizens -- what was in essence an effort to try to make the Polish people more appreciative of the Soviet Union.\nSuppression through Violence\nDuring the Cold War there were two ideologies around the world for government and for way of life. One was the capitalist system that promoted democracy and freedom; the second was a socialist system that promoted communism and equality for all in society (Gaddis, 1997). When a country became communist, they would do so with guidance from the Soviet Union and would establish a socialist system as both a government and a way of life (Gaddis, 1997).\nThe Polish Provisional Government of National Unity was completely under the control of the Soviet Union (Kersten, 1991). Many top Polish government officials spent time training and developing communist skill sets and ideologies. The Soviet Union believed that, by teaching others the way of communism, they would continue the process of implementing it into their societies (Dziewanowski1987). Furthermore, the Soviet Union...\nStalin often had people with non-communist views disposed of through murder or relocation (Dziewanowski1987). There was no room, according to Stalin, for any differing ideology in the Soviet-controlled countries. Dissenting views would be a problem, and the Polish people remained angry and held onto conflicting viewpoints about the Soviet Union and Stalin.\nWhen taking control over Poland, Stalin made it perfectly clear that the only ideology the Polish people would follow would be that of communism (Dziewanowski 1987). The Soviet Union took control of the elections in Poland, thus demonstrating that the Soviet system of communism and socialism would be the only life for the Polish citizens (Dziewanowski 1987). There were two ways the Soviets knew how to be successful imposing influence or will on another county, and these ways existed through brute force or anti-communist legislation. The actions taken by the Soviets were often of force and completely unacceptable to many of the Polish citizens.\nUnder Soviet influence, the Polish Provisional Government of National Unity would begin a process of eliminating anti-communist viewpoints. After the elections in 1947 the communist Polish Provisional Government of National Unity controlled 417 out of 434 seats in the parliament, thus forcing the established Polish government official out of office. By using force to control the elections, the communist government of Poland had controlled 96% of the Polish Provisional Government of National Unity. The Western powers did not protest leaving the anti-communist leaders in Poland powerless -- and this is a point that has remained contentious among the Polish to this day.\nEither through force or through legislation (Polish Constitution of 1952), the communist viewpoint would be the supreme law of the land in Poland (Kersten, 1991). One way of forcing people to covert to communism was through salami tactics. Salami tactics allowed communists to legally dismember any person or group that provided opposition. It thus became a tactic that gave the Polish Provisional Government of National Unity and the Soviet Union absolute control over Poland. With people in Poland fearing dismemberment, they were left to remain quiet and accept communism or to flee the country for freedom elsewhere.\nThe salami tactics used against Jozef Pilsudski (a major force in Polish politics) ended his reign of political influence. The tactics helped to rip Pilsudski\'s Polish Socialist Party apart and eventually allowed it to fall into the communist regime (Kersten, 1991). At first Pilsudski\'s party split into two factions, but later through legislation and force, became fully in supportive of the communist opposition. This activity forced Pilsudski and others in his party to flee Poland (Kersten, 1991). When the citizens of Poland saw that established political officials were fleeing or being executed, they were further enraged at the communist regime.\nWith the salami tactics in full effect, there would be little - if any - opposition to the communist Polish Provisional Government of National Unity. Polish reality would fall to a position of rule under the influence of Stalin as a central Soviet state. Stalin was known to have anti-communists executed or sent to prison camps in which they would live a life of hard labor until their deaths (Dziewanowski 1987). Many anti-communist parties and their supporters were forced to become communist or to flee Poland in fear of their lives or freedom.\nStalin\'s system of suppression was also adept at using military force when necessary to express communist views. The Soviet Union\'s Red Army was a well trained and massive militia that reported directly to Stalin himself (Dziewanowski 1987). If a group wanted to demonstrate an anti-communist or anti-Stalin viewpoint, the Red Army would likely be called into duty. Stalin\'s brute force controlled many European countries. This strategy was effective because of the fact that many opposed to Stalin were fearful of both him and of the threat of brute force that he brought down on others (Dziewanowski 1987).\nAlthough the Polish people were angry and did not want to be a part of the central Soviet state, the first step taken by the communist Polish Provisional Government of National Unity to stop antipathy against the Soviet Union was to drown out the voice of any who dared to oppose them. This was done through brutal force. In September 1980 the Solidarity was formed; this was the first non-communist political party in Poland. The Solidarity was created as a social movement against communism, and they displayed civil resistance in an attempt to change the culture that encompassed workers rights.\nPolish Constitution of 1952\nThe second step taken by the Polish Provisional Government of National Unity to stop antipathy against the Soviet Union was to enact the Polish Constitution of 1952. The constitution was also known as the July Constitution or the Constitution of 1952 because it was signed into law on July 22, 1952. The Polish Constitution of 1952 was modeled after the 1936 Soviet Constitution. The model posited several key features, including a definition of the…\nCommunism & Nationalism Communism Communism is a society without money (For Communism) 1, without a state, without property and without social classes. People come together to carry out a project or to respond to some need of the human community but without the possibility of their collective activity taking the form of an enterprise that involves wages and the exchange of its products. The circulation of goods is not accomplished by means\nOverall, it can be said that the fall of the communist systems around Europe has had different effects and repercussions. These determined the historical evolution between economic success and disarray. Poland is a good example for the effects Western countries had on its economic and political scene, whereas Yugoslavia represents a country still facing the chains of transition, with little European prospects. Bibliography BBC News. ""Profile: Serbia and Montenegro.""BBC World. 2006. 6\nExecutive-Legislative relations in Post-Communist Europe There are two main methods for appointing the executive, the one used in parliamentary systems, the other one in presidential systems. According to the parliamentary method the people first elects the legislature, which, in turn, appoints the executive. In a pure parliamentary system the executive, furthermore, can remain in office only as long as it enjoys the support, or confidence, of a majority in the legislature.\nBut help is on the way. A Belgian theologian is cited as saying: \'It is important and healthy for women, for families, for societies, that we are dealing with the return of the human male, almost from the dead\'."" (2007) It is interesting to note that there appears to be great fear among the Polish majority mindset that the strong role of men in their society will somehow be\nAlso, Anna finds more lies as she analyses William\'s past, concluding that lies play a vital role in people\'s lives. The fact that even William\'s mother had to lie relating to her son\'s real father convinces Anna to think less about William\'s life. Ursula having similar beliefs to Anna contributes to them wanting to find out more about William\'s past, and, to try to understand it. When finally deciding to\nPolish Companies Reacted to Ethical Issues and Changes in Business Standards Since the Fall of Communism in 1989? Poland\'s Economy Pre-Communism\'s Fall Poland\'s Natural Resources Minerals and Fuels Agricultural Resources Labor Force The Polish Economy Under Communism System Structure Development Strategy The Centrally-Planned Economy Establishing the Planning Formula Retrenchment and Adjustment in the 1960s Reliance on Technology in the 1970s Reform Failure in the 1980s Poland\'s Economy After the Fall of Communism Poland After the Fall of Communism Fall of Communism Marketization and Stabilization Required Short-Term Changes Section']"	['<urn:uuid:32f0bf8c-ea2b-4c68-92c3-4fceeab7b896>', '<urn:uuid:0abff520-f651-4b5d-86a2-88b63d2942b8>']	open-ended	with-premise	verbose-and-natural	similar-to-document	comparison	expert	2025-05-12T13:53:09.865574	37	108	2781
81	How does the financial aspect of buying property work, and what legal protections exist for both buyers and property users?	The financial aspect of property buying involves mortgage payments based on supply and property demand. Before purchasing, buyers must review their financial situation, credit score, and financial stability of investments. While mortgages are the most common financing option, other alternatives exist. Properties are often sold below market value using present value approach. As for legal protections, there are laws to protect consumers from fraudulent deals, and lenders may decline loans in certain areas. For property users, there are premises liability laws that hold property owners responsible for injuries caused by unsafe conditions or hazards on their property. Additionally, security deposits are often required but are refundable depending on property condition, and tenants have specific rights and obligations under lease agreements.	['There are a number of sorts of Property. Residential property consists of single-family homes, homes, condos, townhouses, and vacation homes. Industrial real estate describes land utilized for company purposes, including office complex, going shopping malls, and hotel as well as restaurant properties. Industrial realty includes industrial buildings and farmland. The latter is used for a selection of functions, from making to research and development. It likewise consists of a huge amount of land that is presently undeveloped.\nHome mortgage settlements stand for the economic feature of real estate, based on the supply of residential property and also efficient demand for home mortgages. Land is generally sold for less than its market value, making use of the present worth approach, in which the lender sets the mortgage repayment as settlement for loss or damage. A property owner might call for a security deposit for a residential or commercial property leasing, which is refundable depending on the problem of the residential property. In addition to property, the cost of running a sewage-disposal tank pit might be connected with the sale of a piece of land, such as a house.\nWhen you acquire residential property, you need to consider what the customer’s demands are. The residential property’s price can be considerably influenced by the type of trade fixtures used for business. You need to also think about whether the lease is triple-net, indicating that the tenant has to pay all operating costs. A count on action resembles a home mortgage, however entails three celebrations. A broker establishes a depend on fund account and deposits funds turned over to him.\nWhile real estate agents stand for the customer, representatives are not straight pertaining to the vendors. Using a property representative can cost you a considerable payment, but a property agent can help you get a greater cost or market your home quicker. By offering it by yourself, you can save up to 5 to six percent on the compensation charge. So, make sure to do your study and also learn about the profession prior to dedicating. You’ll rejoice you did.\nWhen it concerns the lawful terms for renting property, occupants’ commitments as well as responsibilities are essential. A residential proprietor is required to keep their leased premises in a habitable state. On the occasion that a property owner passes away, his or her heirs acquire the home under the legislations of descent. Typically, a residential or commercial property is called a “high rise” if it has 6 or more stories. If you’re taking into consideration renting your residential property, you should ask a Realty expert to review the contract. A lease will certainly contain numerous terms and conditions.\nReal estate is commonly the subject of suits and legal actions. There are legislations in place to shield customers from deceitful deals, and also lending institutions decline to make loans in highly-integrated or varied locations. Several of these regulations are designed to punish negative habits, such as failing to repay home loans. On top of that, landlords typically require lessees to pay a security deposit to protect a lease. Sometimes, this cash is refundable if the occupants are content with the problem of the building.\nPrior to purchasing property, you must review your monetary situation. Given that loan providers will certainly want to see your credit rating and also the financial security of your existing as well as previous investments, you will intend to ask for a copy of your debt record. By doing this, you’ll have the ability to identify whether you can manage a specific property. When you have determined the cost and place of your property, you’ll need to protect financing. One of the most common sort of funding genuine estate acquisitions is a home mortgage, yet there are various other options that may be much better matched to your needs.\nOne more important location of realty is the residential property itself. Realty includes buildings, air civil liberties above or listed below the land, and also also below ground rights. Real estate is a wide principle that covers both the buying and selling of physical properties. It’s a significant motorist of financial growth in the U.S., and also many people buy and sell residential property because of its potential to raise their income. Actually, the united state Constitution restricted the right to vote for proprietors of realty.\nThe term “property” is frequently used reciprocally with “real property.” This term refers to the land and also structures on which residential property lies. Real estate also includes rights of use as well as enjoyment. Sometimes, occupants can reside in land and buildings, yet these are not real property. In these situations, the customer or vendor should have a license to exercise property. The contract needs to have all relevant as well as required language. This write-up covers one of the most vital elements of property transactions. View website\nGenerally, real estate is land. It also includes permanent renovations such as structures, frameworks, as well as roads. This consists of natural deposits also, such as minerals and also oil. It’s likewise possible to buy building as a company. It’s not difficult to see why property is such an important investment. The industry is among the fastest-growing fields in the United States, and also real estate worth is a great indicator of the wellness of an economy.', 'What Is Premises Liability?\nAt first glance, terms such as premises liability and premises liability accidents are confusing. How can premises be liable for accidents? In short, these are legal terms that refer to instances when you or a loved one gets injured while on someone else’s property because of an unsafe condition or hazard.\nThese accidents can happen anywhere: an apartment complex, event venue, grocery store, hotel lobby, work environment, or even an amusement park.\nIn this article, our Dallas injury lawyer highlights the most common premises liability cases that our team has handled throughout their legal careers and shares some easy ways to prevent them from happening to you.\nWhenever a company or property manager chooses to ignore any complaints or red flags regarding the safety of their establishment and surrounding area, anyone who sets foot on the property is at risk of serious injury or death.\nInadequate security injuries are the result of their inaction or negligence on the part of the company or property owners. We typically see these types of cases involving apartment complexes that don’t have functioning security gates, proper lighting in public areas, or adequate security measures to keep their residents safe.\nWe also see high volumes of inadequate security cases at bars, clubs, and event venues that serve alcohol. When alcohol and large groups mix, tempers can flare and violent fights can erupt. Retail and grocery stores can also be dangerous for shoppers because of dark parking lots that are unsafe at night. Safety assessments at all of these establishments can easily help companies identify potential threats to residents and patrons.\nFollowing the evaluation, adding security measures such as functioning surveillance cameras, security patrols, and additional lighting can often do the trick to protect workers and customers alike.\nLack of Maintenance\nAs we shared earlier, unsafe conditions or hazards cause premises liability accidents. Often, a lack of property maintenance is the reason behind the accidents. For example, there’s a slip-and-fall accident. Let’s say that a shopper is in a grocery store near the produce section. A misting nozzle is broken, and instead of spraying heads of broccoli and lettuce, the mister is drenching the grocery store floor in water, making it slippery. If a shopper slips in the puddle and falls on the hard floor, that is considered a lack of maintenance. The grocery store is responsible for facility upkeep and fixing or replacing faulty equipment like the produce misters to avoid situations such as shoppers slipping and falling on wet floors.\nYou might be surprised to see dog-bite injuries on our premises liability case list. In Texas, premises liability laws classify pets as a type of property. People who are attacked by a dog or dangerous animal can seek compensation for their injuries based on the dog owner’s negligence, lack of sharing their dog’s history of dangerous behavior, violation of leash laws, or intent to harm someone. Owners must be aware of their pooches’ behavior and temperament—especially when left in a fenced yard, taken to a dog park, or accompanying the owner in public, including eating at a restaurant patio or running errands—to ensure they do not hurt other people.\nAmusement Parks and State Fairs\nAmusement and theme parks can be fun destinations for families to celebrate birthdays, holidays, and milestone occasions like the last day of school. However, accidents are on the rise at large parks, from those with fixed rides to water parks to even temporary carnivals like the State Fair of Texas and Houston Rodeo. Accidents at these spots can be caused by improper maintenance, ride-operator errors, defective ride restraints, inadequate employee training, and dangerous property conditions like slick surfaces and poor lighting. In an effort to prevent accidents, amusement, theme, and water parks in Texas are required to get compliance stickers for all rides, which they are eligible for after passing an inspection by the park’s insurance company, submitting a quarterly injury report, and meeting other requirements. Parks should also conduct thorough employee training throughout the year and designate supervision days to ensure all workers are knowledgeable and properly following safety protocols.\nSoaring summer temperatures in Texas force many people to seek relief in swimming pools at hotels, apartment complexes, daycares, private clubs, or a friend or family’s home. However, slippery pavement, sharp edges, harsh chemicals, pool drains, and other hazards can lead to injuries. Before the summer season, high-use pools open to the public should conduct thorough safety assessments to identify any issues that could harm a pool patron. This way, there is plenty of time to fix chemical levels, malfunctioning equipment, and the area surrounding the pool before the rising temperatures hit. At private homes, installing a safety fence that makes the pool area inaccessible to small children and hiring lifeguards for parties with family members and friends can provide peace of mind and additional eyes to keep guests safe.']	['<urn:uuid:87c61e19-5031-47a8-80bd-81fab1726202>', '<urn:uuid:041cb020-560d-4368-8903-52d9035b26e7>']	open-ended	direct	verbose-and-natural	similar-to-document	multi-aspect	novice	2025-05-12T13:53:09.865574	20	120	1705
82	what raw materials used make environmentally safe 3d printing materials	Bioplastics used in biodegradable 3D printing are derived from renewable sources such as corn starch, sugarcane, and other plant-based materials.	['biodegradable resin 3d printer\nbiodegradable resin 3d printer, also known as a sustainable or eco-friendly 3D printer, is a revolutionary technology that aims to address the environmental concerns associated with traditional 3D printing. This article will delve into the concept of biodegradable resin 3d printers, their advantages, applications, and potential future developments.\nThe conventional 3D printing process involves the use of various plastic filaments, such as ABS (Acrylonitrile Butadiene Styrene) and PLA (Polylactic Acid), which are non-biodegradable. These filaments, when discarded, contribute significantly to plastic waste, which takes hundreds of years to decompose. biodegradable resin 3d printers, on the other hand, utilize an alternative type of filament made from eco-friendly materials that can break down naturally over time.\nOne commonly used material for biodegradable resin 3d printers is bioplastics. Bioplastics are derived from renewable sources such as corn starch, sugarcane, and other plant-based materials. These materials not only decompose faster but also have a lower carbon footprint compared to traditional plastics. Bioplastics, once used as filaments in 3D printers, can degrade within a few months to a few years, depending on the specific material used.\nThe advantages of using biodegradable resin 3d printers go beyond the sustainability aspect. Bioplastics have similar physical properties to traditional plastics, allowing for high-quality print outputs. They are also less toxic and emit fewer harmful gases when melted, making the printing process safer for users and the environment. Furthermore, biodegradable resin 3d printers can contribute to the circular economy by promoting the use of recyclable and compostable materials.\nThe applications of biodegradable resin 3d printers are vast and diverse. One significant area is product prototyping, where designers and engineers can create three-dimensional models quickly and efficiently. biodegradable resin 3d printers are also used in the medical field for producing customized, biocompatible implants, prosthetics, and surgical models. Additionally, they are utilized in the fashion industry to create sustainable accessories, such as jewelry and footwear.\nAs the demand for eco-friendly alternatives increases, the development of biodegradable resins and biodegradable resin 3d printers continues to evolve. Researchers are exploring new materials that are not only biodegradable but also possess enhanced mechanical properties for a wider range of applications. Efforts are also being made to improve the printing speed and resolution of biodegradable resin 3d printers to compete with traditional printing methods.\nThe future of biodegradable resin 3d printers looks promising. As technology advances, it is possible that biodegradable resin-based materials will become the mainstream choice for 3D printing. In addition, the integration of sustainable manufacturing processes with biodegradable resin 3d printers may lead to the development of fully circular production systems, reducing waste and minimizing the environmental impact of manufacturing.\nIn conclusion, biodegradable resin 3d printers offer a sustainable and eco-friendly solution to the environmental challenges posed by traditional 3D printing. The utilization of biodegradable materials, such as bioplastics, not only reduces plastic waste but also maintains the quality and functionality required for various applications. As the technology continues to advance, biodegradable resin 3d printers have the potential to revolutionize industries and contribute to a greener future.']	['<urn:uuid:88aae5a4-54d8-4813-bff9-d9c1f2684c52>']	factoid	direct	long-search-query	distant-from-document	single-doc	novice	2025-05-12T13:53:09.865574	10	20	509
83	bronze age europe important settlements	La Bastida was the most advanced settlement in Bronze Age Europe (around 2200 BCE), comparable only to the Minoan civilization of Crete, while Mycenae became the wealthiest palatial center in Greece during its peak in the Late Bronze Age (1350-1200 BCE).	"[""The archaeological excavations carried out this year at the site of La Bastida (Totana, Murcia) have shed light on an imposing fortification system, unique for its time. The discovery, together with all other discoveries made in recent years, reaffirm that the city was the most advanced settlement in Europe in political and military terms during the Bronze Age (ca. 4,200 years ago -- 2,200 BCE), and is comparable only to the Minoan civilisation of Crete.\nThe discovery was presented today by Pedro Alberto Cruz Sánchez, Secretary of Culture of the Region of Murcia and Vicente Lull, professor of Prehistory of the Universitat Auṭnoma de Barcelona (UAB) and director of the excavation. The event also included the presence of Iván Martínez Flores, executive administrator of the research and head of the UAB Area for Strategic Projects.\nThe fortification consisted of a wall measuring two to three metres thick, built with large stones and lime mortar and supported by thick pyramid-based towers located at short distances of some four metres. The original height of the defensive wall was approximately 6 or 7 metres. Until now six towers have been discovered along a length of 70 metres, although the full perimeter of the fortification measured up to 300 metres. The entrance to the enclosure was a passageway constructed with strong walls and large doors at the end, held shut with thick wooden beams.\nOne of the most relevant architectural elements discovered is the ogival arched postern gate, or secondary door, located near the main entrance. The arch is in very good conditions and is the first one to be found in Prehistoric Europe. Precedents can be found in the second city of Troy (Turkey) and in the urban world of the Middle East (Palestine, Israel and Jordan), influenced by the civilisations of Mesopotamia and Egypt. This indicates that people from the East participated in the construction of the fortification. These people would have reached La Bastida after the crisis which devastated their region 4,300 years ago. It was not until some 400 to 800 years later that civilisations like the Hittites and Mycenaeans, or city-states such as Ugarit, incorporated these innovative methods into their military architecture.\nA Construction Designed for Combat\nThe fortification of La Bastida is an impressive construction due to its monumentality, the expertise demonstrated in architecture and engineering, its antiquity and because it helps us today to learn about such a distant past which is also easily recognisable in the present. It also represents an innovation in the art of attacking and defending fortifications, especially on the military front. The construction was designed solely for military purposes, by people experienced in fighting methods unknown in those times to the West.\nThe towers and exterior walls denote advanced knowledge of architecture and engineering, with slopes of over 40 per cent. The lime mortar used offered exceptional solidity to the construction, strongly holding the stones and making the wall impermeable, as well as eliminating any elements attackers could hold on to.\nThe postern gate, as a hidden and covered entrance, demanded great planning of the defensive structure as a whole and of the correct engineering technique to fit it perfectly into the wall.\nContinental Europe's First Bronze Age City\nThe latest excavations and the result of Carbon 14 dating indicate that La Bastida was probably the most powerful city of Europe during the Bronze Age and a fortified site since it was first built, in circa 2,200 BCE, with a defence system never before seen in Europe.\nThe fortification was not the only discovery made. From 2008 to 2011, excavations unearthed large residences measuring over 70 square metres distributed throughout the city's four hectares. These large houses and public buildings were alternated with other smaller constructions, all separated by entries, passageways and squares. A large pool held by a 20-metre dyke with a capacity for almost 400,000 litres of water also clearly denotes that the city's population was of a complexity and that it used advanced techniques incomparable to other cities of its time.\nThe discoveries made at La Bastida reveal a military, political and social rupture: the establishment of a violent and classist ruling society, which lasted seven centuries and conditioned the development of other communities living in the Iberian Peninsula. Overall, archaeologists are redefining what is known of the origin of economic and political inequalities in Europe, as well as military institution and the role played by violence in the formation of identities.\nA Unique Archaeological Park in Spain\nThe excavations at La Bastida are directed by the Research Group in Mediterranean Social Archaeoecology (ASOME) of Universitat Auṭnoma de Barcelona (UAB), formed by lecturers Vicente Lull, Rafael Micó, Cristina Rihuete and Roberto Risch. The research group receives the support and funding of the Department of Culture Regional Cultural Ministry of Murcia, the UAB, and the Totana City Council. The Spanish Ministries of Industry, Trade and Tourism, and of Economics and Competitiveness also give financial support to the project.\nLa Bastida will be systematically excavated with the aim of becoming a unique archaeological park open to the public and consisting in a monographic museum, a research and documentation centre, and part of the site open to visitors. Advancing and maintaining this project will depend on the commitment shown by the different public institutions and social agents taking part in the excavation of La Bastida.\nMore information on La Bastida: http://www.la-bastida.com/LaBastida/\nCite This Page:"", 'Strategically located between two Peloponnese hills in southern Greece, the fortified site of Mycenae has entered collective consciousness mainly due to its mention in Homer’s the Illiad and the Odyssey which describes Mycenae as the kingdom of the mythical King Agamemnon. Mycenae became a Greek settlement between 1700 and 1200 BC, during the Late Bronze Age, with its monumental architecture being constructed at the pinnacle of the Mycenaean civilization from 1350 BC. During this era, archaeologists hold that it was the wealthiest palatial center in Greece, before being abandoned over 2,000 years ago.\nAn interpretation from the Odyssey where Odysseys taunts the Cyclops Polyphemus as he escapes the island of the Cyclopes. According to legend Perseus brought the Cyclopes to build the fortified walls at Mycenae. ( Public domain )\nMythology Surrounding Mycenae\nAccording to Greek mythology, Mycenae’s story goes back to the hero Perseus, the demigod son of Zeus and Danae, who was said to have founded the city of Mycenae. Many mythical features are assigned to Perseus within the ancient Greek legends, like the famous winged shoes of Hermes which allowed him to fly and the helmet of Ares (Mars) which could make him invisible.\nPerseus’s accomplishments included killing the sea monster sent by the god Poseidon to destroy Aethiopia, thus freeing Andromeda and killing the mythical beast Medusa, whose head could turn anyone looking at it to stone. Is it possible that Perseus did exist? And, if he did, was he truly connected to gods?\nIllustration showing Perseus delivering Medusa’s head. ( Public domain )\nThere are several stories about why the city was named Mycenae. One claims that the city was named by Perseus after his sword’s mykes (a part of the handle of a sword) fell at the site. The name of the city was then given to the Mycenaean civilization which has been remembered as one of the most important civilizations of Greek prehistory.\nGreek mythology holds that the descendants of Perseus reigned from Mycenae for three generations, the last in the lineage being Eurystheus, after which Atreus rose to power. Mycenae later became home to the kingdom of Agamemnon, son of Atreus and the legendary commander in chief of the Greek contingent in the Trojan War . Brother to Menelaus the king of Sparta, King Agamemnon was considered to be one of the greatest leaders of his era (not to be confused with the distorted Hollywood portrayal of him in the film Troy).\nThe Lion’s Gate, main entrance to the ancient city of Mycenae in Greece. ( Haris Andronos / Adobe Stock)\nThe Architecture and Artifacts of Mycenae\nThe descriptions of Mycenae in ancient Greek mythology are accurate. Even today, you can still see the walls and be amazed by the huge stones—some weighing up to 120 tons—that comprise them. Known as Cyclopean Walls, legend has it that the walls around the city were so named because Perseus brought the mythical beings Cyclopes—or one-eyed giants—from Asia to construct the large fortified walls using stones no human could lift.\nTiryns, the other great city of the Mycenae civilization, has a similar story where King Proetus—another mythical king—used the Cyclopes to build its fortified walls. In 1999, both Mycenae and Tiryns were together recognized as UNESCO World Heritage sites .\nLocated strategically to afford control of the Argolid Plain, Mycenae was built almost 280 meters (918 ft) above sea level. The city was strong military and financial power, especially in the Bronze Age around 1400 to 1200 BCE when the Gate of Lions was built and new buildings were added in the area. The Lion Gate, the primary entrance to Mycenae, is one of the earliest examples of relief sculpture in ancient Greece, and is a large triangular stone on the top of the entrance to the citadel that depicts two lions.\nThe golden death-mask known as the Mask of Agamemnon which was found in Tomb V in Grave Circle A at Mycenae by Heinrich Schliemann in 1876. (Xuan Che / CC BY 2.0 )\nIn Mycenae you can also find the Treasury of King Atreus, also known as the Tomb of King Agamemnon, a large and glorious dome-shaped tomb, called a tholos in Greek, which is one of nine in the area. At the time, these were the tallest domes on Earth, until the Romans constructed the Great Baths of Baiae over a thousand years later.\nThe famous golden mask of Agamemnon, an artifact discovered by Heinrich Schliemann in 1876, was found in one of these tombs and is one of the most famous artifacts to have been found all over the world. The purpose of the mask was to cover the face of the dead during burial, though not all archaeologists agree that the mask belonged to Agamemnon.\nThe archaeologists Heinrich Schliemann and Wilhelm Dörpfeld at the Lion’s Gate, main entrance to the ancient city of Mycenae in Greece. ( Public domain )\nExcavating the Mythical City of Mycenae\nHaving been abandoned for centuries, the archaeological site of Mycenae became part of the jurisdiction of the Greek Archaeological Society in 1837. At this point, the first ever excavations were conducted by the Greek archaeologist Kyriakos PIttakis in 1841, who is known for having uncovered the famed Lion Gate.\nIn 1874 Heinrich Schliemann began his excavations at the mythical site, during which he unearthed the graves in what has come to be known as Grave Circle A, a funerary enclosure containing shaft graves used for Mycenaean elite. It is worth mentioning that Schliemann also discovered Troy and helped academia to realize that Troy was not a myth. Schliemann—even before his discoveries—was convinced that all the stories and legends were not myths but had to be partially true.\nOver subsequent decades and up into the 2000s a plethora of archaeologists continued excavations, and in the 1950s the Greek Archaeological Society archaeologist George Mylonas excavated Grave Circle B as well as other sites. There are many elements still buried underground. Those interested in learning more can visit either the Mycenae Museum next to the Mycenae citadel or the National Archaeological Museum of Athens, which is home to many of the artifacts that have been uncovered such as gold objects discovered within burials.\nStudies have concluded that the area was occupied as far back as the 7th century BC and was reoccupied by different settlements afterwards. The monumental construction of the Mycenaeans took place later some time between 1350 and 1200 BC, with the city walls dating back to about 1350 BC. The decline of the Mycenaean civilization began around 1200 BC, and the city itself was abandoned about 100 years later. While there are many theories for its demise, experts are still unclear as to what happened.\nGrave Circle A, at Mycenae in Greece. (Andy Montgomery / CC BY-SA 2.0 )\nMycenae is one of the most important archaeological sites in Greece. It can be reached from Athens in about two hours, and is located near to Nafplio. Touring the site takes anywhere from two hours. Once there it’s important to visit the Archaeological Museum where you can view many of the artifacts which have been excavated at the site. You can find more information about entry prices, tickets and opening hours at the Ministry of Culture and Sports .\nTop image: Mycenae, near Nafplio in Greece, in the north-eastern Peloponnese. Source: Irina Rogova / Adobe Stock\nBy John Black']"	['<urn:uuid:a2fb8446-a9c8-4ac2-8fbe-ee0a11afbfac>', '<urn:uuid:f21c678f-330c-49ea-8020-20d80ea6f8fe>']	factoid	direct	short-search-query	distant-from-document	comparison	expert	2025-05-12T13:53:09.865574	5	41	2136
84	peru trek lodges amenities elevation effects	The trek to Machu Picchu features comfortable high-altitude lodges placed at strategic elevations between 6,600 and 11,800 feet, equipped with amenities like hot tubs and fireplaces to help trekkers recover. These elevations can affect the body as altitude sickness typically occurs above 2,800 meters (9,200 ft). The lodges provide essential comforts for managing altitude effects, including access to coca tea and facilities for rest and recovery. Each lodge is positioned to allow proper acclimatization, with the Soraypampa lodge at 11,800 feet offering mountain views and outdoor whirlpool tubs, while the Collpapampa Valley lodge sits lower at 10,300 feet in the cloud forest, helping travelers follow the 'hike high, sleep low' principle for better adaptation.	"['DESTINATION ENTRY REQUIREMENTS\nThere are currently special requirements for travelers to this region. Learn more.\nPeru Lodge-to-Lodge Family Trekking Tour - 20s & Beyond\nTrek from Cusco to Machu Picchu\nPeru is vibrant. Intoxicating. Brimming with fascinating history and awe-inspiring landscapes. And thanks to our longtime friendships here, we\'ll reveal the region\'s deep cultural roots and introduce you and your family to our favorite places—from remote indigenous villages to mystical Machu Picchu—as an honored guest.\nTHIS ITINERARY: 9 days, 8 nights\nACCOMMODATIONS: Premiere Hotels\nStart/End locations may vary. Do not book flights until your trip details are confirmed.\n- Trek unencumbered from lodge to lodge, with porters and mules handling your luggage and leaving you free to soak up the scenery\n- Hike the famed Incan Salkantay Pass route to 15,200 feet for breathtaking views of the dramatic snow-covered Andes\n- Discover a stunning bird\'s-eye view of Machu Picchu from Llactapata Trail and join our local guide for a visit to Machu Picchu\n- Relax in style after a great day of hiking at comfortable high-altitude lodges—many complete with hot tubs!\n9 Days Premiere Hotels\nTake in stunning vistas of the Cusco Valley as you trek to the Inca sites of Q\'enko, Temple of the Moon and fortress-temple Sacsayhuamán with a local expert | Pay a visit to the Museum of Pre-Columbian Art to view unique artifacts from ancient Peruvian civilizations.\nLocated between the San Blas arts district and Cusco\'s vibrant main square, this serene oasis mixes contemporary fixtures with traditional design. A Relais & Châteaux member.\nHike along a route used by the Inca in the 15th century | Ascend to the high-altitude grasslands of Soraypampa with breathtaking mountain and valley vistas, including your first look at Humantay Mountain | Rest your legs as you soak in our lodge\'s outdoor whirpool tub or sit by the fireplace with a cup of coca tea | Hike up to a glacial lake or opt for a horseback ride—either way, savor the views of towering glacier-covered Salkantay Peak, Inca mythology\'s most sacred mountain | Try pisco sours, the country\'s national drink | Savor Peruvian cuisine prepared by our personal chef, who travels with us from lodge to lodge.\nThis stylish mountain lodge, set at 11,800 feet, welcomes you with a hot tub and incomparable views of Salkantay, the region\'s highest peak.\nGet ready for today\'s exhilarating high-altitude trek to Huayraccmachay via Salkantay Pass | As you travel up the Río Blanco Valley, circling Humantay Peak, look for condors soaring overhead | Descend through a lush subtropical landscape above the Salkantay River before passing a patchwork of orchards and coffee plantations.\nOvernight at ""the place where the wind lives"" and enjoy a hot tub soak at 12,000 feet.\nMake your way into the cloud forest—one of the world\'s most fascinating and threatened ecosystems | Look for frogs, hummingbirds, parrots and beautiful flowers, including orchids, asters and begonias amid the Ceja de la Selva (or ""eyebrow of the jungle"") | Ready to eat like a local? Try cuy (guinea pig) at a traditional Andean Pachamanca feast.\nThis lodge features a hot tub and rests in a cloud forest at 10,300 feet in the Collpapampa Valley.\nHike through an incredible portion of the Santa Teresa River Valley | Trek through wild highland landscapes to the river, up a picturesque mountainside | In the town of Playa, try specialties like giant avocados and exotic granadilla fruit | Hike on a restored ancient Inca trail to our serene lodge, nestled amid coffee plants and banana, avocado and eucalyptus trees.\nSavor spectacular views from this lodge, built right into the mountainside and flanked by an avocado orchard.\nGaze upon Machu Picchu from the seldom-traveled Llactapata Trail | Weave through bamboo forests to the Vilcanota River | Take a scenic train ride to Aguas Calientes and explore its markets and shops | Get an early start for our full day in Machu Picchu | Take the morning to explore the ruins with your family | Trek to the Gate of the Sun or up Machu Picchu Mountain for an impressive overview, then get up close as our local guide reveals secrets of Machu Picchu\'s discovery | Learn about native orchids, birds and tea plantations with our hotel\'s naturalist.\nThis eco-friendly hotel\'s Andean-style casitas blend seamlessly into the surrounding cloud forest. (pool, spa)\nThe earlier you book, the more choice you\'ll have and the lower your price. And you can always change your mind — you won\'t be charged to transfer to a different trip before your final payment is due. View cancellation policy\nClick on dates for pricing, itinerary variations and to book your trip. Price is per person, double occupancy.\nActivity Level: 3-5\nEvery Backroads trip is designed to appeal to a wide variety of interests and fitness levels. Several routes and a range of levels are offered each day so you can choose how much or how little activity you want to do. Learn more about how we determine activity levels.\nThe terrain on this trip includes a mix of village and archaeological site walks, Inca stone jungle and mountain trails. Overnight trekking lodges are located at elevations of 6,600–11,800 feet and trekking routes reach up to 15,000 feet. The altitude and rugged terrain can make the routes feel more challenging than the mileage may suggest. Some routes involve substantial elevation loss.\nDaily Route Options\n- All breakfasts, 8 lunches, 8 dinners\n- Expertise and services of our experienced Trip Leaders\n- Snacks and beverages between meals\n- Additional guides and experts from the region on many trips\n- Van shuttles to support a variety of route options\n- Comprehensive Travel Planner with detailed pre-trip information\n- Private guided tours at museums, historic sites, wineries and other select attractions as noted in the Travel Planner\n- All gratuities at hotels and restaurants\n- Special events, including wine tastings and other select attractions as mentioned in the Travel Planner\n- On biking and multi-adventure trips, use of fully equipped Backroads titanium bike plus helmet and accessories\n- Trailercycles, carriers, and kid-sized helmets for Family Trips\n- Equipment and experienced guides for kayaking, rafting, snorkeling, sailing and canoeing as described\n- Park and other entry fees\n- Fares for trains, ferries and other modes of travel as listed in the Travel Planner\n- Select coach transfers\n- Baggage transfers and porterage\nWe want to make sure you\'re on the right trip and that you have the best experience possible. Every Backroads trip is unique and this one is no exception.\nOne of our hikes requires the Machu Picchu Mountain Inca Trail permit that Backroads will obtain on your behalf (included in your trip price). Therefore, we recommend booking your trip at least 7–9 months prior to departure to have the best chance of securing your permit. Without it, you will miss this portion of the Trail but will still do the full Machu Picchu Citadel tour within the ruins.\nOur hikes through Peru\'s captivating rugged terrain climb rocky and sometimes uneven paths, many of which are remote and do not intersect with roads. Vehicles will get us to and from the trailheads, but the nature of these trails is such that we won\'t see our vans along the route. Ample trail support in the form of water, snacks and encouragement is provided by your Backroads leaders and local guides.\nThis trip has been designed to offer as many hiking options as possible. Since many of the trails are unmarked, we recommend that you hike with the company of a Backroads leader or one of our local support staff. On the few days when we\'re in national parks, regulations require you to hike in the company of one of our certified park guides.', 'High Altitude Climbing and What is Altitude Sickness?\nHigh Altitude climbing may bring on altitude sickness, the reaction of the body adjusting to decreasing amounts of oxygen. Normally, the higher the altitude, the less oxygen available for the body to carry on normal functions. Altitude sickness most commonly occurs from above 2,800 metres (9,200 ft) but this is different for everyone.\nThere is simply no way of knowing your own susceptibility prior to being at altitude thus it is vital you monitor your own health. Symptoms may be mild and subside/go away after a day’s rest, or if it is ignored it could lead to death.\nSymptoms of altitude sickness\nSymptoms can appear within 1-2 hours although most often appear 6-10 hours after ascent and generally subside in 1-2 days as the body adjusts to altitude. They may reappear as you continue to go higher. Symptoms usually occur gradually and can be one or a combination of the following:\n- Loss of appetite\n- Disturbed sleep or drowsiness\n- Swelling of hands, feet & face\nIf the body is unable to adjust to altitude these symptoms will persist and, if they are left untreated, altitude sickness may progress to High Altitude Cerebral Edema (HACE) or High Altitude Pulmonary Edema (HAPE). Both can be fatal if ignored.\nSymptoms of HAPE (fluid on the lungs):\n- A dry cough, developing to a wet one with blood-tinged discharge or saliva.\n- Tightness in the chest & blueness/darkness of face, lips & tongue\n- Low fever up to 38°C/100°F\n- Severe fatigue, progressing to coma\nSymptoms of HACE (fluid on the brain):\n- Severe headache symptoms not relieved by painkillers or lying down\n- Confusion, disorientation & drowsiness\n- Loss of balance or coordination\n- Blurred or double vision/retinal hemorrhage\nHow to avoid Altitude Sickness (AMS) Certain medical conditions (such as respiratory disease) or medications (such as sleeping pills) can increase the risk of altitude sickness – it is important that you inform your leader of any medical conditions or medications before ascending to altitude. You can help your body to acclimatize and avoid altitude sickness by:\n- Avoiding alcohol, tobacco and substances that can interfere with good delivery of oxygen to the body or cause dehydration.\n- Eating small, frequent meals high in carbohydrates.\n- Drinking plenty of water – at least 4 litres per day\n- Taking it easy or have a rest. Walk at a slower pace than you would at sea level and avoid overexertion.\n- Check with your health care provider to see if Diamox would be appropriate for you to take while climbing. See below.\n- If possible, don’t fly or drive to high altitude. Start below 10,000 feet (3,048 meters) and walk up. If you do fly or drive, do not over-exert yourself or move higher for the first 24 hours.\n- Hike high and sleep low. You can climb more than 1,640 feet (500 meters) in a day as long as you come back down and sleep at a lower altitude.\nTreatment Most travelers are able to successfully acclimatize by following the previously mentioned guidelines. However, there are instances where medical treatment is required. Ultimately, the best treatment for acute altitude sickness is to descend to a lower altitude. There may be times when your leader makes the decision that you or a member of your group is at risk of serious altitude sickness and for safety insists that you cannot ascend further – please respect that they are within their rights to do so and are making that decision in the best interests of your health and well-being. If you are experiencing any altitude sickness symptoms, we encourage you to discuss them with your leader straight away so you both can follow your acclimatization progress or seek the advice of a trained medical professional if necessary. Everyone will have a different perception of the severity of their symptoms, the key is to personally assess whether your symptoms are improving or worsening. If in doubt, go down!\nDiamox (Acetazolamide) allows you to breathe faster so that you metabolize more oxygen, while high altitude climbing, thereby minimizing the symptoms caused by poor oxygenation. This is especially helpful at night when respiratory drive is decreased. Since it takes a while for Diamox to have an effect, it is advisable to start taking it 24 hours before you go to altitude and continue for at least five days at higher altitude. The recommendation of the Himalayan Rescue Association Medical Clinic is 125 mg. twice a day (morning and night). (The standard dose was 250 mg., but their research showed no difference for most people with the lower dose, although some individuals may need 250 mg.) Possible side effects include tingling of the lips and finger tips, blurring of vision, and alteration of taste. These side effects may be reduced with the 125 mg. dose. Side effects subside when the drug is stopped. Contact your physician for a prescription. Since Diamox is a sulfonamide drug, people who are allergic to sulfa drugs should not take Diamox. Diamox has also been known to cause severe allergic reactions to people with no previous history of Diamox or sulfa allergies. Frank Hubbell of SOLO recommends a trial course of the drug before going to a remote location where a severe allergic reaction could prove difficult to treat. It is very important that you make yourself aware of the cause and effects of traveling at altitude, monitor your health and seek assistance accordingly.\nThe above is for information purposes only and is in no way intended to replace the advice of a trained medical professional. As such, BenefacTours Inc. is unable to accept responsibility for any loss, injury or inconvenience sustained by any person, caused by errors and omissions, or as a result of the advice and information given here.']"	['<urn:uuid:455b5708-e4c5-450a-b664-11fa5ee3d3be>', '<urn:uuid:ff43dea7-c47c-4133-bcb7-48f28c25697a>']	open-ended	with-premise	short-search-query	similar-to-document	multi-aspect	expert	2025-05-12T13:53:09.865574	6	114	2269
85	indoor air quality improvement methods air purifier effectiveness natural solutions	Indoor air quality can be improved through multiple methods, including using HEPA air purifiers, maintaining proper humidity levels, regular floor cleaning with microfiber mops, and using natural cleaning products instead of chemical ones. While air purifiers with true HEPA filters can effectively remove particles like dust, pollen, and smoke, they have limitations in filtering gaseous pollutants. The effectiveness of air purifiers depends on factors like room size, installation, and proper filter maintenance with replacement every three months. Additionally, natural solutions like using lemon and baking soda for cleaning, stopping indoor smoking, and conducting radon tests can significantly improve indoor air quality.	"[""Fresh and breathable air is essential for all living beings. Since the industrial revolution, our air has become increasingly contaminated with innumerable toxins.\nIf you think air pollution is something that only happens outdoors, think again! You’d be surprised to know that air inside your home or office can be more contaminated than the air outside.\nIn fact, according to the Environmental Protection Agency (EPA), the air inside your house is 3-4 times more contaminated than the air outside your house.\nWhy Indoor Air Quality is Important\nIndoor Air Quality (IAQ) is the quality of air inside buildings, such as houses, offices, factories etc., and is related to the health of the inhabitants of those buildings.\nWhen it comes to time spent in homes, offices, and other building sites, the EPA reported that 90% American spend their times indoors. Hence, IAQ can severely impact the well-being of an individual.\nThe lack of good air quality results from a buildup of gases, chemicals, and other pollutants that cause allergies, headaches, eye infections, fatigue, nausea, and even account for chronic illnesses.\nResearch has also revealed that the growth of bacteria and fungi in such areas is promoted by moisture and humidity, which humans also like to a certain degree. These microbes and fungi can serve as bio-pollutants.\nGood IAQ is vital for health as it prevents several environmental toxins and health issues, such as asthma, which affects 25 million people annually.\nWhy Indoor Air Quality Isn't as Good as You Think\nIf you think your indoor air quality is good enough, think again. Most people don’t have any idea how their house’s IAQ is affecting them.\nYour own activities around your house or office may be the culprit behind the indoor air pollution. Your indoor air quality isn’t as good as you think because:\n- Chemical cleaning products like floor cleaners and sprays release hazardous fumes into the air\n- Air fresheners and scented candles can freshen up the aroma in your house, but at a deadly cost; most of them contain potential cancer-causing agents\n- Sealing your home tight might lead to heat conservation, but a tightly-insulated house prevents air circulation, which can reduce the air quality\nFactors That Reduce Indoor Air Quality\nAlthough many factors may be involved in worsening indoor air quality, the popular ones might be:\n1. Chemicals :\nMost chemicals – whether solid, liquid, or gas – are the recognized causes of allergies and bad odors. Bad smells may cause discomfort, but toxic chemicals induce lasting impacts on health and may become the cause of long-term diseases, such as cancer.\n2. Radon :\nRadon is known as a common gas pollutant that enters inside via cracks and weak seals of the building. It is known to cause lung cancer.\n3. Suspended Particles :\nParticles suspended in the air, whether those are dust or smoke, can have a devastating impact on health. The particles enter the buildings as a result of outdoor pollution, but can also be produced inside the house via cooking, smoking, and using synthetic products.\n4. Microorganisms :\nFungi, viruses, and other harmful microorganisms are a crucial factor in worsening the air quality inside buildings. The problems relating to microbes become even worse when the atmosphere inside the building is damp.\n5. Pets and Insects :\nRoaches, mites, ticks, and mice are the main carriers of diseases indoors. The not only contaminate the living area but also allow for the development of bad air quality. Pets, of course, can also be the cause of allergies.\n6. Temperature and Humidity :\nOther factors include lack of ventilation and fluctuating temperature and humidity, which bring health-related discomfort.\n5 Ways to Improve Air Quality in Your House\n1. Keep the Floor Clean\nTo improve indoor air quality, you can clean the floors using a vacuum with a powerful HEPA filter. By doing so, you might be able to reduce the concentration of poisonous chemicals, particles, and other allergens.\nYou might want to start by vacuuming the same area several times and remember to include walls, carpeted floors, and furniture.\nThe next thing you can do is to use a microfiber mop to reach out for areas you couldn’t vacuum. With their minute filaments, microfiber mops can capture more dust and don’t require any sort of chemicals for cleaning later.\nAlso, you can use doormats to reduce the chance of getting pollutants and dirt entering through people’s feet. You may also place a shoe rack by the entrance and use slippers and socks for use in the home only.\n2. Maintain a Healthy, Moderate Humidity Level\nKeeping your home or office dehumidified in summer season can prevent the air from getting moist and growing harmful organisms. You can install a dehumidifier to control allergens and prevent health problems. Moreover, using an air conditioner can be a plus as it can filter out contaminants and reduces humidity.\nYou may also use an exhaust fan or an open window to let the air exchange. It’s not common in the US, but you can purchase an air exchanger for your house that does this automatically. You may also want to look for leaking pipes or other sources of moisture to avoid dampness.\n3. NO Smoking Inside the House\nSmoking is one of the reasons why children develop allergies and breathing problems in the first place. Smoking enhances indoor pollution as it contains more than 4,000 chemicals. Ceasing smoking inside the house is an effective measure to overcome indoor pollution.\nIf you need help with smoking cessation, try visiting your doctor and join local support groups and rehab therapies. If you cannot quit smoking, at the very least you should buy a specifically designed air purifier for smoke.\n4. Radon Test\nAs radon is a radioactive gas and might enter houses through fissures and cracks, you might want to take a radon test. It is a simple, inexpensive, and quick test which determines the levels of this gas. You can easily get the radon levels reduced by installing a remediation system.\n5. Use Naturally Good Smelling Products\nIn place of using chemicals to clean your house, you may want to use natural products that are naturally fragrant and promise a clean house. You should stop using conventional fresheners, laundry detergents, soaps, polishes, and sprays. Use natural products instead, such as lemon and baking soda in your kitchen and mild cleansers free of chemicals.\nAir is a gift which can become a curse when it’s polluted. Reducing outdoor and indoor pollution are equally important priorities. Taking these effective measures is the one way indoor atmospheric pollution can be improved and health issues can be alleviated."", 'Oransi Finn Hepa And Uv Air Purifier With Negative Ionizer\nDo Air Purifiers Really Work?\nProfessionals weighs in on whether or not purifiers can actually filter out germs, dust, smoke, mold, and more.\nHow do air cleansers work?\nAir purifiers generally consist of a filter, or numerous filters, and a fan that absorbs and distributes air.\nAs air moves through the filter, pollutants and particles are recorded and the tidy air is pushed back out into the home. Generally, filters are made of paper, fiber (frequently fiberglass), or mesh, and require regular replacement to keep performance.\nWhat are air cleansers supposed to filter out and do they in fact do it?\nThe majority of filters on the market are created to record particles like dust and pollen, however don’t capture gases like VOCs (unpredictable organic compounds) or radon. That would need an adsorbent, like activated carbon. The Environmental Defense Agency (EPA) cautions that the functionality of air cleansers is restricted in terms of filtering out gases, and that you should regularly replace filters for ideal functionality, typically about every three or so months.\nNumerous air cleansers are good at filtering toxin particles out of the air (dust, smoke, pollen, etc.), but they are not always very good at getting rid of gaseous toxins like VOCs or radon from the air that may accumulate from adhesives, paints, or cleaning products. Irritants that are embedded into furnishings or floor covering are also not captured by them.\nAdditionally, the efficiency of air cleansers in real-world scenarios most likely will not mimic those of controlled conditions in a lab (what those “99% efficiency” claims are referring to!). The area, installation, circulation rate, and the length of time it is operating for will all vary, as will the conditions in the space. In addition, there are other things taking place in your house that may effect the effectiveness like ventilation (open or closed windows), and new particles are constantly emerging, so the air may not as filtered as the claims might have you believe.\nIf you are worried about mold, we ‘d advise buying a dehumidifier or humidifier to assist keep the proper moisture levels in your house and stave off mold growth problems. Air cleansers do not avoid mold growth, so it is needed to get rid of the source of wetness that is permitting it to grow.\nCan air purifiers filter the outside air that enters your house?\nSometimes, non-organic air pollutants like the VOCs we discussed formerly can stem from outdoors your home. “There are all sorts of scenarios in structure fires where large dosages of smoke inhalation might result in cyanide toxicity. But that would largely require to be somebody who was standing straight in or near the fire: Those people are brought to emergency clinic right away,” Dr. Roten discusses. “Generally, outside contamination or smoke or short-term bad air isn’t a continuous issue for bystanders.” The ideal kind of cleanser can attend to any environmental air qualities in your place. Utilizing neighboring wildfires as an example, Dr. Roten includes that a HEPA filter-equipped cleanser is your best bet: “Anything that has a real HEPA filter in it is probably appropriate sufficient to filter out most all the large particles that would be concerning,” he states. “Most of the smoky odor will also be attended to as well.”\nWhat should I search for in an air cleanser?\nCADR (clean-air shipment rate) ranking. This measures the cleansing speed of the purifier for getting rid of smoke, dust, and and pollen. Try to find a CADR of a minimum of 300, above 350 is truly excellent.\nFor correct efficacy, you need a design developed to work in the room size. Pick a design that is developed for an area larger than the one you are equipping it for if you wish to operate it at a lower, quieter setting.\nAHAM (Association of House Device Manufacturers) Verified mark AHAM’s standards are design to ensure the security, efficiency and efficiency of lots of house care devices, consisting of air cleansers. The standards are developed to offer a common understanding between manufacturers and customers to help make the purchasing process simpler. While voluntary, most credible air purifiers have actually undergone this certification program, which often supplies a CADR ranking and size guidelines.\nTrue HEPA. True HEPA filters work at eliminating ultra fine particles (think: dust, dander, pollen, mold and other typical allergens in the home). The market requirement for such is that the system should be able to remove a minimum of 99.97% of particulates determining 0.3 micron size in a lab setting. Remember, it is important to keep in mind that in reality settings, the real efficacy of these devices would be far less as brand-new contaminants are constantly emerging. Note that there is no industry requirement for the terms “HEPA-like” or “HEPA-type,” and are mainly utilized as marketing ploys to get consumers to buy the product.']"	['<urn:uuid:a5167d84-574d-49d3-9370-709c67a27b27>', '<urn:uuid:8490de1e-a3ca-4662-b127-0d6747e84388>']	open-ended	direct	long-search-query	similar-to-document	multi-aspect	expert	2025-05-12T13:53:09.865574	10	101	1933
86	demographic differences time money prioritization retirement happiness research findings gender income age	Research findings show interesting demographic patterns in time-money prioritization and its relationship to happiness. Age emerges as a significant factor, with older individuals more likely to value time over money compared to younger people, as they seek to spend time in more meaningful ways. Gender and income level do not affect whether individuals are more likely to value time or money, though the studies did not include participants at poverty level who might need to prioritize money for survival. In retirement specifically, gender does play a role in positive affect, with women showing higher levels. These relationships between demographics and time-money priorities remain consistent across multiple studies with different population samples.	['Burr, Andrew and Santo, Jonathan B. and Pushkar, Dolores (2009) Affective Well-Being in Retirement: The Influence of Valuers, Money and Health Across Three Years. Journal of Happiness Studies . ISSN 1389-4978\nPDF (post-print: final draft post-refereeing)\n- Published Version\nOfficial URL: http://dx.doi.org/10.1007/s10902-009-9173-2\nIn this study, personal values, health and financial status were investigated as determinates of affective well-being in a sample of 371 recent retirees across 3 years. Personal values, measured with the Portrait Value Questionnaire (Schwartz et al. in J Cross Cult Psychol 32:519-542, 2001), were hypnotized to show direct links to positive effect (PA) and negative affect (NA) as well as to moderate the association between financial and health status and affective well-being. Using structural equation modeling, higher PA was predicted by female gender, better finances, fewer illnesses, and higher self-transcendence (SE) and lower OC values. SE and OC also moderate the association between financial status and PA. Longitudinal analysis indicated a relatively stable pattern of associations across 3 years. While the impact of finances on affect was stable over time, the effects of health and values increased across 3 years.\n|Divisions:||Concordia University > Research Units > Centre for Research in Human Development|\nConcordia University > Faculty of Arts and Science > Psychology\n|Authors:||Burr, Andrew and Santo, Jonathan B. and Pushkar, Dolores|\n|Journal or Publication:||Journal of Happiness Studies|\n|Date:||10 November 2009|\n|Digital Object Identifier (DOI):||10.1007/s10902-009-9173-2|\n|Keywords:||Values, Subjective well-being, Retirement, Finance, Health|\n|Deposited By:||DOLORES PUSHKAR|\n|Deposited On:||23 Feb 2010 16:16|\n|Last Modified:||24 Aug 2016 21:26|\nAckerman, S., Zuroff, D. C., & Moskowitz, D. S. (2000). Generativity in midlife and young adults: Links to agency, communion, and subjective well-being. International Journal of Aging and Human Development, 50, 17–41.\nAn, J. S., & Cooney, T. M. (2006). Psychological well-being in mid to late life: The role of generativity development and parent-child relationships across the lifespan. International Journal of Behavioral Development, 30, 410–421.\nBowlby, G. (2007). Defining retirement (Statistics Canada catalogue # 75001-XIE). Retrieved February 2, 2009, from the Statistics Canada website: http://www.statcan.gc.ca/bsolc/olc-cel/olc-cel?lang=eng&catno=75-001-X20071029584.\nBrown, T. A., Chorpita, B. F., & Barlow, D. H. (1998). Structural relationships among dimension of the DSM-IV anxiety and mood disorders and dimensions of negative affect, positive affect, and autonomic arousal. Journal of Abnormal Psychology, 107, 179–192.\nBrown, K. W., & Kasser, T. (2005). Are psychological and ecological well-being compatible? The role of values, mindfulness, and, lifestyle. Social Indicators Research, 74, 349–368.\nBurroughs, J. E., & Rindfleisch, A. (2002). Materialism and well-being: A conflicting values perspective. Journal of Consumer Research, 29, 348–370.\nCaprara, G. V., Caprara, M., & Steca, P. (2003). Personality correlates of adult development and aging. European Psychologist, 8, 131–147.\nCarstensen, L. L., Isaacowitz, D. M., & Charles, S. T. (1999). Taking time seriously: A theory of socioemotional selectivity. American Psychologist, 54, 165–181.\nChan, R., & Joseph, S. (2000). Dimensions of personality, domains of aspiration, and subjective well-being. Personality and Individual Differences, 28, 347–354.\nDeci, E. L., & Ryan, R. M. (2000). The “what” and “why” of goal pursuits: Human needs and the self-determination of behavior. Psychological Inquiry, 11, 227–268.\nDiener, E., & Oishi, S. (2000). Money and happiness: Income and subjective well-being across nations. In E. Diener & E. M. Suh (Eds.), Culture and subjective well-being (pp. 185–218). Cambridge, MA: MIT Press.\nDiener, E., Sandvik, E., & Pavot, W. (1991). Happiness is the frequency, not the intensity, of positive versus negative affect. In F. Strack, M. Argyle, & N. Schwartz (Eds.), Subjective well-being: An interdisciplinary perspective (pp. 119–139). Elmsford, NY: Pergamon Press.\nDiener, E., & Seligman, M. E. P. (2004). Beyond money: Toward an economy of well-being. Psychological Science in the Public Interest, 5, 1–31.\nDiener, E., Suh, E. M., Lucas, R. E., & Smith, H. L. (1999). Subjective well-being: Three decades of progress. Psychological Bulletin, 125, 276–302.\nErikson, E. (1959). Identity and the life cycle. New York: International Universities Press.\nEyal, T., Sagristano, M. D., Trope, Y., Liberman, N., & Chaiken, S. (2009). When values matter: Expressing values in behavioral intentions for the near vs. distant future. Journal of Experimental Social Psychology, 45, 35–43.\nGold, D. P., Andres, D., Etezadi, J., Arbuckle, T., Schwartzman, A., & Chaikelson, J. (1995). Structural equation model of intellectual change and continuity and predictors of intelligence in elderly men. Psychology and Aging, 10, 294–303.\nHellevik, O. (2003). Economy, values, and happiness in Norway. Journal of Happiness Studies, 4, 243–283.\nKashdan, T. B., & Breen, W. E. (2007). Materialism and diminished well-being: Experiential avoidance as a mediating mechanism. Journal of Social and Clinical Psychology, 26, 521–539.\nKasser, T. (2004). The good life or the goods life? Positive psychology and personal well-being in the culture of consumption. In A. P. Linley & S. Joseph (Eds.), Positive psychology in practice (pp. 55–67). Hoboken, NJ: Wiley.\nKasser, T., & Ahuvia, A. (2002). Materialistic values and well-being in business students. European Journal of Social Psychology, 32, 137–146.\nKasser, T., & Ryan, R. M. (1993). A dark side of the American dream: Correlates of financial success as a central life aspiration. Journal of Personality and Social Psychology, 65, 410–422.\nKasser, T., & Ryan, R. M. (2001). Be careful what you wish for: Optimal functioning and the relative attainment of intrinsic and extrinsic goals. In P. Schmuck & K. M. Sheldon (Eds.), Life goals and well-being: Toward a positive psychology of human striving (pp. 116–131). Ashland, OH: Hogrefe & Huber.\nKasser, T., Ryan, R. M., Couchman, C. E., & Sheldon, K. M. (2004). Materialistic values: Their causes and consequences. In T. Kasser & A. Kanner (Eds.), Psychology and consumer culture: The struggle for a good life in a materialistic world (pp. 11–28). Washington, DC: American Psychological Association.\nKim, J., & Moen, P. (2001). Is retirement good or bad for subjective well-being? Current Directions in Psychological Science, 10, 83–86.\nKunzmann, U. (2008). Differential age trajectories of positive and negative affect: Further evidence from the Berlin Aging Study. Journals of Gerontology. Series B, Psychological Sciences and Social Sciences, 63B, P261–P270.\nLarsen, R. J., & Prizmic, Z. (2008). Regulation of emotional well-being. In M. Eid & R. J. Larsen (Eds.), The science of subjective well-being (pp. 258–289). New York: Guilford Press.\nMcAdams, D. P., de St.-Aubin, E., & Logan, R. L. (1993). Generativity among young, midlife, and older adults. Psychology and Aging, 8, 221–230.\nMuthén, L. K., & Muthén, B. O. (2006). Mplus: Statistical analysis with latent variables (4th ed.). Los Angeles, CA: Muthén & Muthén.\nOishi, S., Diener, E., Suh, E., & Lucas, R. E. (1999). Value as a moderator in subjective well-being. Journal of Personality, 67, 157–184.\nOreg, S., Bayazit, M., Vakola, M., Arciniega, L., Armenakis, A., Barkauskiene, R., et al. (2008). Dispositional resistance to change: Measurement equivalence and the link to personal values across 17 nations. Journal of Applied Psychology, 93, 935–944.\nPavot, W. (2008). The assessment of subjective well-being. In M. Eid & R. J. Larsen (Eds.), The science of subjective well-being (pp. 124–140). New York: Guilford Press.\nPiazza, J. R., Charles, S. T., & Almeida, D. M. (2007). Living with chronic health conditions: Age differences in affective well-being. Journals of Gerontology. Series B, Psychological Sciences and Social Sciences, 62B, P313–P321.\nPinquart, M., & Schindler, I. (2007). Changes in life satisfaction in the transition to retirement: A latent-class approach. Psychology and Aging, 22, 442–455.\nPushkar, D., Arbuckle, T., Rousseau, F., & Bourque, P. (2003). Réussir sa vieillesse: La vision des aînés [Successful aging: The eye of the beholder]. Revue Québécoise de Psychologie, 24, 155–174.\nPushkar, D., Etezadi, J., Chaikelson, J., Conway, M., Giannopolous, C., Li, K., et al. (in press). A continuity model of retirement satisfaction incorporating reasons for retirement and sources of enjoyment. Journals of Gerontology: Psychological Science.\nRyan, R. M., Sheldon, K. M., Kasser, T., & Deci, E. L. (1996). All goals were not created equal: The relation of goal content and regulatory styles to mental health. In J. A. Bargh & P. M. Gollwitzer (Eds.), The psychology of action: Linking cognition and motivation to behavior (pp. 7–26). New York: Guilford Press.\nSagiv, L., Roccas, S., & Hazan, O. (2004). Value pathways to well-being: Healthy values, valued goal attainment, and environmental congruence. In A. P. Linley & S. Joseph (Eds.), Positive psychology in practice (pp. 68–85). New York: Wiley.\nSagiv, L., & Schwartz, S. H. (2000). Value priorities and subjective well-being: Direct relations and congruity effects. European Journal of Social Psychology, 30, 177–198.\nSchimmack, U. (2008). The structure of subjective well-being. In M. Eid & R. J. Larsen (Eds.), The science of subjective well-being (pp. 97–123). New York: Guilford Press.\nSchwartz, S. H. (1992). Universals in the content and structure of values: Theoretical advances and empirical tests in 20 countries. In M. Zanna (Ed.), Advances in experimental social psychology (pp. 1–65). New York: Academic Press.\nSchwartz, S. H., & Boehnke, K. (2004). Evaluating the structure of human values with confirmatory factor analysis. Journal of Research in Personality, 38, 230–255.\nSchwartz, S. H., Melech, G., Lehmann, A., Burgess, S., Harris, M., & Owens, V. E. (2001). Extending the cross-cultural validity of the theory of basic human values with a different method of measurement. Journal of Cross Cultural Psychology, 32, 519–542.\nSchwartz, S. H., & Rubel, T. (2005). Gender differences in value priorities: Cross-cultural and multimethod studies. Journal of Personality and Social Psychology, 89, 1010–1028.\nSheldon, K. (2005). Positive value change during college: Normative trends and individual differences. Journal of Research in Personality, 39, 209–223.\nSheldon, K., Elliot, A. J., Ryan, R. M., Chirkov, V., Kim, Y., Wu, C., et al. (2004). Self-concordance and subjective well-being in four cultures. Journal of Cross-Cutural Psychology, 35, 209–223.\nSilfver, M., Helkama, K., Lönnqvist, J. E., & Verkasalo, M. (2008). The relation between value priorities and proneness to guilt, shame, and empathy. Motivation and Emotion, 32, 69–80.\nSingh-Manoux, A., Adler, N. E., & Marmot, M. G. (2003). Subjective social status: Its determinants and its association with measures of ill-health in the Whitehall II study. Social Science and Medicine, 56, 1321–1333.\nStatistics Canada. (2005). Population projections for Canada, provinces, and territories, 2005 to 2031. Retrieved February 2, 2009, from http://www.statcan.gc.ca/daily-quotidien/051215/dq051215b-eng.htm.\nStatistics Canada. (2006). A portrait of seniors in Canada. Statistics Canada catalogue # 89-519-XIE. Retrieved August 29, 2009, from http://www.statcan.gc.ca/bsolc/olc-cel/olc-cel?lang=eng&catno=89-519-X.\nSzinovacz, M. E., & Davey, A. (2004). Honeymoons and joint lunches: Effects of retirement and spouse’s employment on depressive symptoms. Journals of Gerontology. Series B, Psychological Sciences and Social Sciences, 59B, P233–P245.\nTorelli, C. J., & Kaikati, A. M. (2009). Values as predictors of judgments and behaviors: The role of abstract and concrete mindsets. Journal of Personality and Social Psychology, 96, 231–247.\nVan Solinge, H., & Henkens, K. (2008). Adjustment to and satisfaction with retirement: Two of a kind? Psychology and Aging, 23, 422–434.\nWang, M. (2007). Profiling retirees in the retirement transition and adjustment process: Examining the longitudinal change patterns of retirees psychological well-being. Journal of Applied Psychology, 92, 455–474.\nWatson, D., Clark, L. A., & Tellegen, A. (1988). Development and validation of brief measures of positive and negative affect: The PANAS scales. Journal of Personality and Social Psychology, 54, 1063–1070.\nWyler, A. R., Masuda, M., & Holmes, T. H. (1967). Seriousness of illness rating scale. Journal of Psychosomatic Research, 11, 363–374.\nRepository Staff Only: item control page', 'Valuing your time more than the pursuit of money is linked to greater happiness, according to new research published by the Society for Personality and Social Psychology.\nIn six studies with more than 4,600 participants, researchers found an almost even split between people who tended to value their time or money, and that choice was a fairly consistent trait both for daily interactions and major life events.\n“It appears that people have a stable preference for valuing their time over making more money, and prioritizing time is associated with greater happiness,” said lead researcher Ashley Whillans, a doctoral student in social psychology at the University of British Columbia. The findings were published online in the journal Social Psychological and Personality Science.\nThe researchers found an almost even split with slightly more than half of the participants stating they prioritized their time more than money. Older people also were more likely to say they valued their time compared to younger people.\n“As people age, they often want to spend time in more meaningful ways than just making money,” Whillans said.\nThe researchers conducted separate surveys with a nationally representative sample of Americans, students at the University of British Columbia, and adult visitors of a science museum in Vancouver. Some of the studies used real-world examples, such as asking a participant whether he would prefer a more expensive apartment with a short commute or a less expensive apartment with a long commute. A participant also could choose between a graduate program that would lead to a job with long hours and a higher starting salary or a program that would result in a job with a lower salary but fewer hours.\nA participant’s gender or income didn’t affect whether they were more likely to value time or money, although the study didn’t include participants living at the poverty level who may have to prioritize money to survive.\nIf people want to focus more on their time and less on money in their lives, they could take some actions to help shift their perspective, such as working slightly fewer hours, paying someone to do disliked chores like cleaning the house, or volunteering with a charity. While some options might be available only for people with disposable income, even small changes could make a big difference, Whillans said.\n“Having more free time is likely more important for happiness than having more money,” she said. “Even giving up a few hours of a paycheck to volunteer at a food bank may have more bang for your buck in making you feel happier.”\nFunding: The research was funded by Time Sharing Experiments for the Social Sciences.\nSource: Annie Drinkard – SPSP\nImage Source: The image is in the public domain\nOriginal Research: Abstract for “Valuing Time Over Money Is Associated With Greater Happiness” by Ashley V. Whillans, Aaron C. Weidman, and Elizabeth W. Dunn in Social Psychological and Personality Science. Published online January 7 2015 doi:10.1177/1948550615623842\nValuing Time Over Money Is Associated With Greater Happiness\nHow do the trade-offs that we make about two of our most valuable resources—time and money—shape happiness? While past research has documented the immediate consequences of thinking about time and money, research has not yet examined whether people’s general orientations to prioritize time over money are associated with greater happiness. In the current research, we develop the Resource Orientation Measure (ROM) to assess people’s stable preferences to prioritize time over money. Next, using data from students, adults recruited from the community, and a representative sample of employed Americans, we show that the ROM is associated with greater well-being. These findings could not be explained by materialism, material striving, current feelings of time or material affluence, or demographic characteristics such as income or marital status. Across six studies (N = 4,690), we provide the first empirical evidence that prioritizing time over money is a stable preference related to greater subjective well-being.\n“Valuing Time Over Money Is Associated With Greater Happiness” by Ashley V. Whillans, Aaron C. Weidman, and Elizabeth W. Dunn in Social Psychological and Personality Science. Published online January 7 2015 doi:10.1177/1948550615623842']	['<urn:uuid:311f3cec-20dc-4649-aca5-85043d5f6be0>', '<urn:uuid:92929252-a5be-4ef0-87b0-1d89d04e1518>']	open-ended	direct	long-search-query	similar-to-document	three-doc	expert	2025-05-12T13:53:09.865574	12	111	2530
87	What connects healthy brain growth and cancer spreading?	Both healthy brain development and cancer spreading rely on a cellular migration process called epithelial-mesenchymal transition (EMT). This process is controlled by the protein ZNF827, which enables cells to move to specific locations. In brain development, EMT allows neurons to migrate and build proper neural networks. However, cancer cells exploit this same EMT mechanism to spread throughout the body and form metastases. The process involves complex protein interactions, including over 500 proteins in cell adhesion complexes that regulate how cells stick together or separate.	['Unlocking the complexity of cell adhesion\nMany biological processes depend on the ability of cells to stick to one another. The formation of multicellular organisms and precise embryonic development rely on this property, as does the maintenance of healthy tissue. Defects in the ability of cells to adhere to one another have been found in many diseases, such as cancer, Alzheimer’s disease and cardiovascular disease. In the case of cancer, ineffective cell adhesion allows tumour cells to detach and invade other tissues, thereby spreading cancer throughout the body.\nCell-cell adhesion is made possible through various cellular structures that are collectively known as cell-cell adhesion complexes. The most prominent cell-cell adhesion complex is the Adherens Junction. Central to adherens junctions is a protein known as E-cadherin, or epithelial cadherin. E-cadherin spans the cell membrane, providing a link between the interior, and exterior of the cell. Outside the cell, E-cadherin binds to other E-cadherins from neighbouring cells in a mechanism that can be described as a ‘cellular handshake’. On the inside of the cell, E-cadherin binds to linker proteins known as catenins, which attach to a structural scaffold that lies adjacent to the adhesion site, the actin cytoskeleton. This physical link between the cytoskeletons of neighboring cells allows for the generation and transduction of mechanical signals.\nDespite their importance in cell-cell adhesion, scientists have yet to fully understand how the cadherin-catenin-actin complex forms and is regulated. To extend the idea of cell adhesion being like a ‘cellular handshake’, imagine walking along a crowded street while holding hands with a partner. Moving together with the flow of people, navigating obstacles, adjusting your speed and responding to changes in conditions must all be considered if you are to reach your destination without letting go. Similarly, cells must maintain their adhesion while facing varying stresses and biochemical conditions. Hence, the adhesive structures are regulated and adjusted, via a complex network of structural and regulatory proteins. Where defective adhesion has led to a certain disease it is essential to understand where the problem lies and this requires stepping back and looking at the whole picture.\nTo better identify the components of this wider network in maintaining and regulating adhesion, researchers at the Mechanobiology Institute, National University of Singapore, applied a combination of experimental and computational techniques to reveal and dissect the complex network of proteins that interact with E-cadherin. To achieve this, E-cadherin was labelled with an enzyme that, when activated, releases a small cloud of a tagging molecule to flag all other proteins in the immediate vicinity. When coupled with quantitative proteomics, this provides a list of proteins interacting with E-cadherin, thus capturing many of the proteins that influence the adhesive properties of the cell.\nOverall 561 proteins were found to be associated with E-cadherin, and remarkably 419 of these interactions were completely novel. Using a protein interaction database, the researchers created a map of the E-cadherin interactome that contains information on the function of each protein and its interactions with other proteins within the network. The majority of proteins found were identified as adaptor proteins, which serve as scaffolds within the Adherens Junction. Other proteins involved in cellular transport and protein synthesis were also identified. Interestingly, the researchers found that most of the proteins that associated with E-cadherin did so independently of cell-cell adhesion.\nThis study highlights that cell adhesion results not only from the formation of a cadherin-catenin-actin complex, but from the activity of more than 500 interacting proteins. Successful cell adhesion requires a cascade of events involving these proteins and any breakdown in this cascade could lead to impaired cell adhesion, and disease. With the E-cadherin interactome now described in detail, researchers can finally step back and view the complex picture that is cell-cell adhesion. This will allow disease related defects to be identified, and new targets researched to understand this vital biological process.\nsource : http://www.sciencedaily.com/releases/2014/12/141203083700.htm', 'Protein essential for healthy brain and cancer metastasis development\nAn international research team has discovered how a newly identified molecular pathway protein for both brain development It is necessary as well as a change in its path for the spread of cancer can proceed. New findings may lead to earlier diagnosis and a more targeted one treatment Causes brain diseases and cancer.\nThe team reports that the protein ZNF827 is essential for a healthy brain, but also as a cause of cancer metastases. The new findings, from the participation of researchers at the University Medical Center Mainz, could improve the diagnosis and treatment of brain diseases and cancers. The results of the study were published in the journal “Nature Cell Biology” free.\nAccording to message The international research group, which involved scientists from the First Medical Clinic and Polyclinic and the Institute for Physiological Chemistry of the University Medical Center Mainz, identified a protein that is important for both the formation of healthy brain cells and the development of cancer metastases. Is.\nresearchers found that Protein ZNF827 These two cellular processes control a mechanism that enables cell migration: the so-called epithelial–mesenchymal transition (EMT).\ncells can migrate\nEpithelial-mesenchymal transition (EMT) as described in communication epithelial cells, which are firmly fused into the tissue to form the so-called mesenchymal cells. They have the special quality of being able to grow.\nabout MechanismLittle was previously known about what controls EMT and the cell migration it enables.\nWith their study, researchers from Belfast (UK), La Jolla (USA), San Diego (USA), Montpellier (France), Stockholm (Sweden) and Mainz are now able to prove that zinc finger protein ZNF827 is mainly responsible for the regulation of EMT.\nEMT ensures that the newly formed brain neurons Go to a specific location and build an intact neural network. If this migration process is disrupted, nerve cells do not connect properly.\nAs part of their research work, the scientists were able to show that if there is a deficiency in the protein ZNF827, fewer new nerve cells are made and cell migration falls rapidly.\nIf there is an excess of ZNF827, cells grow too quickly and can result in Damage originates in the brain. From these findings, experts have concluded that the protein ZNF827 is an essential factor for healthy brain development.\nless metastases spread\nEMT mechanism also plays a role in cancer major role, Tumors use mechanisms to further grow, encapsulate and set their cells in motion.\nIn this way, cancer cells can spread throughout the body and undergo a process known as metastasis. one in particular. In late stage During cancer, EMT causes tumors to grow aggressively and spread metastases.\nwhile checking breast cancer cells The researchers were able to prove that the protein ZNF827 – similar to nerve cells in the brain – also conclusively determines the EMT of tumor cells: if ZNF827 is deficient, tumors grow only more slowly and have fewer metastases in the lungs. spreads out.\nAccording to the research team, these new findings represent a significant advance in understanding the molecular processes involved in EMT. They open up new perspectives for innovation Diagnostic and therapeutic approach in brain diseases and various cancers. (advertisement)\nAuthor and source information\nThis text matches the requirements of medical specialist literature, medical guidelines and current studies and has been checked by medical professionals.\n- University Medicine Mainz: ZNF827 – a protein with two faces: essential for a healthy brain and the cause of cancer metastases, (Accessed: September 3, 2022), University Medicine Mainz\n- Sahoo S, Aguire E, Inayatulla M, Mahesh A, Tiwari N, Lavin DP, Singh A, Strand S, Dicken M, Luco RF, Belmonte JCI, Tiwi VK: a complex epigenome-splicing crosstalk controlling epithelial-to-mesenchymal transition. does. metastasis and brain development; In: Nature Cell Biology, (Published: 2022-08-08), Nature Cell Biology\nThis article contains general advice only and should not be used for self-diagnosis or treatment. He cannot take the place of visiting the doctor.\nWeb guru. Amateur thinker. Unapologetic problem solver. Zombie expert. Hipster-friendly travel geek. Social mediaholic.']	['<urn:uuid:0005083b-6328-42df-a15d-b94d51d3553e>', '<urn:uuid:e9db127d-0444-42c4-8477-02628b0f3a42>']	factoid	direct	concise-and-natural	distant-from-document	multi-aspect	novice	2025-05-12T13:53:09.865574	8	84	1313
88	As a chemist studying mental health treatments, can you explain how oxidation numbers in molecules relate to depression treatments?	The oxidation numbers in molecules are determined by electron distribution between atoms, with more electronegative atoms receiving more electrons. However, this concept is separate from depression treatments, which primarily involve psychotherapy, antidepressant medications, and complementary approaches like meditation. While oxidation numbers help understand chemical reactions, depression treatment focuses on managing symptoms through therapy, medication, and lifestyle changes to address persistent sadness, loss of interest, and other emotional/physical symptoms.	"['How can nitrogen have an oxidation state of +4\nThe Oxidation numberNox (also oxidation level, oxidation value) indicates how many elementary charges an atom has formally taken up or given off within a compound, for example in a redox reaction. It therefore corresponds to the hypothetical ion charge of an atom in a molecule or the actual charge of monatomic ions.\nAnother definition reads: The oxidation number of an atom in a chemical compound is formally a measure for specifying the proportions of the electron density around this atom. A positive oxidation number indicates that the electron density is reduced compared to its normal state, a negative one indicates that the electron density around the atom has increased.\nThe oxidation number is a useful formalism for chemical considerations that often has little to do with the real charge of an atom. It is quite possible that atoms in a compound are assigned a negative formal oxidation number, although they also carry a positive formal charge. In covalent compounds, the oxidation number differs from the concept of valency.\nThe oxidation numbers are used in redox reactions to better recognize the processes. The transfer of electrons from one atom to another can be seen in the fact that the oxidation number of one (which emits electrons) increases and that of the other (which accepts electrons) decreases. Often it is only through the determination of the oxidation numbers of individual atoms that it becomes clear which chemical reaction is taking place.\nSpecification of the oxidation number\nOxidation numbers are written in Roman numerals over the atomic symbols in compounds (e.g. O−II). If the element symbol is on its own, they are often written as Arabic numerals as with ions. According to IUPAC, signs are only set for negative oxidation numbers.\nDetermination of the oxidation number\nThe oxidation number can be derived using the following rules:\n- Atoms in the elementary state always have the oxidation number 0 (but 0 is also possible in compounds).\n- In the case of monatomic ions, the oxidation number corresponds to the ion charge.\n- The sum of the oxidation numbers of all atoms of a polyatomic neutral compound is equal to 0.\n- The sum of the oxidation numbers of all atoms of a polyatomic ion is equal to the total charge of this ion.\n- In the case of covalently formulated compounds (so-called valence line formulas, Lewis formulas), the connection is formally divided into ions. It is assumed that the electrons involved in a bond are completely taken over by the more electronegative atom.\n- Most elements can occur in several oxidation states.\nIn practice, it has proven helpful to formulate a few rules for determining the oxidation number:\n- The fluorine atom (F) as the element with the highest electronegativity always has the oxidation number −I in compounds.\n- Oxygen atoms get the oxidation number −II - except in peroxides (then: −I) and in connection with fluorine (then: + II).\n- Other halogen atoms (such as chlorine, bromine, iodine) generally have the oxidation number (−I), except in connection with oxygen or a halogen that is higher in the periodic table.\n- In compounds, metal atoms always have a positive oxidation number as ions.\n- Alkali metals always have + I and alkaline earth metals always + II as the oxidation number.\n- Hydrogen atoms get the oxidation number + I, except when hydrogen is directly connected to more ""electropositive"" atoms such as metals (hydrides) or to itself).\n- In the elementary state, the oxidation number is always 0 (e.g. I.2, C, O2, P4, S.8).\n- In ionic compounds (salts) the sum of the oxidation numbers is identical to the ionic charge.\n- In covalent connections (molecules) the binding electrons are assigned to the more electronegative binding partner. Identical binding partners each receive half of the binding electrons. The oxidation number thus corresponds to the assigned binding electrons compared to the number of external electrons normally present.\n- The highest possible oxidation number of an element corresponds to the number of major or minor groups in the periodic table (PSE).\nGraphic determination of oxidation numbers\nAs an example, the phosphoric acid (H.3PO4) serve:\n- First the Lewis formula is recorded.\n- Then the electrons are assigned to the atoms according to electronegativity\n- The oxidation number can then be calculated based on the valence electrons. Example: Oxygen normally has 6 valence electrons (VI. Main group). Due to the higher electronegativity of oxygen, the binding electrons between oxygen and hydrogen (or phosphorus) can be assigned to oxygen. In the balance sheet, the oxygen receives two additional electrons in addition to the 6 available. Hence the oxidation number is −II. Phosphorus is in main group V, so it normally has 5 valence electrons. Since these are all assigned to oxygen, it “lacks” five electrons and it receives the oxidation number + V.\nAnother example shows on the one hand how one and the same atom (here the carbon atom) has different oxidation numbers, and on the other hand how oxidation numbers change during the reaction (here using the example of the Tollens sample / silver mirror sample):\nCategories: Chemical Bond | Chemical reaction\n- What exactly is artificial intelligence\n- Is Tata Manza good to buy\n- Why are pistol grips so deadly\n- Do you know misophony\n- I qualify as a small company\n- Are Target and Walmart direct competitors\n- What is a leverage ratio\n- Why and how did feudalism come about\n- What is a scalable programming language\n- How can we get more traffic\n- What Bollywood movie do you hate\n- What is the origin of the trojan\n- How many hotels are there in Manhattan\n- Which is famous for Tanjore\n- What are asexual flowers\n- Feminists find porn degrading for women\n- What is the best concierge\n- Can teenagers get type 2 diabetes\n- Toners are meant to prick your skin\n- What is 260 and 280 ratio\n- What causes did Martin Luther King support?\n- What are the side effects of ARV\n- Which IRC channels do you use frequently\n- Indians equated religion with ethics', 'Depression is a mental health disorder characterized by persistent feelings of sadness, hopelessness, and a lack of interest or pleasure in activities. It goes beyond temporary feelings of sadness that everyone experiences from time to time. Depression affects how a person thinks, feels, and behaves, and it can lead to a variety of emotional and physical problems.\nThe symptoms of depression can vary from person to person, but some common signs include:\nPersistent sadness or emptiness\nLoss of interest or pleasure in activities once enjoyed\nChanges in appetite and weight (either significant weight loss or weight gain)\nDifficulty sleeping or sleeping too much\nRestlessness or irritability\nFatigue or loss of energy\nFeelings of worthlessness, guilt, or hopelessness\nDifficulty concentrating or making decisions\nThoughts of death or suicide\nDepression can be caused by a combination of genetic, biological, environmental, and psychological factors. It is a complex condition, and the exact causes can vary from person to person. Some common risk factors for depression include a family history of the disorder, certain medical conditions, traumatic life events, chronic stress, and certain medications.\nIt is important to note that depression is a treatable condition. Treatment options may include psychotherapy (such as cognitive-behavioral therapy), medication (such as antidepressant medications), or a combination of both. Lifestyle changes, such as regular exercise, maintaining a healthy diet, and getting enough sleep, can also be beneficial in managing depression.\nMeditation can be a helpful tool in managing and reducing symptoms of depression. Here are some of the benefits that meditation can offer:\nStress reduction: Meditation has been shown to reduce stress levels by activating the body’s relaxation response. This can help alleviate the physical and emotional symptoms of stress that often accompany depression.\nImproved emotional well-being: Regular meditation practice can enhance emotional well-being by increasing positive emotions and reducing negative emotions. It can promote feelings of calmness, inner peace, and contentment, which can be particularly beneficial for individuals struggling with depression.\nIncreased self-awareness: Meditation cultivates a sense of self-awareness, allowing individuals to observe their thoughts and emotions without judgment. This heightened self-awareness can help identify negative thought patterns and behaviors that contribute to depression, enabling individuals to develop healthier coping mechanisms.\nEnhanced focus and concentration: Depression often affects concentration and cognitive function. Meditation practices, such as mindfulness meditation, can improve focus and concentration by training the mind to stay present and redirect attention to the present moment. This can help counteract the cognitive difficulties associated with depression.\nRegulation of mood: Regular meditation practice has been shown to positively impact mood regulation. It can help individuals develop skills to navigate and regulate their emotions, reducing the intensity and duration of depressive episodes.\nImproved sleep: Depression can disrupt sleep patterns, leading to insomnia or excessive sleep. Meditation techniques, such as progressive muscle relaxation or guided imagery, can promote relaxation and better sleep quality, which can indirectly alleviate depressive symptoms.\nIncreased self-compassion: Depression often involves self-critical thoughts and feelings of low self-worth. Meditation practices, such as loving-kindness meditation, can foster self-compassion and self-acceptance. This can counteract the negative self-perception common in depression and promote a more positive relationship with oneself.\nIt’s important to note that while meditation can be a helpful adjunct to treatment for depression, it is not a substitute for professional help. If you’re experiencing symptoms of depression, it’s essential to consult with a mental health professional for a comprehensive evaluation and appropriate treatment plan.\nIn addition to mindfulness meditation, which is commonly associated with depression, there are several other types of meditation that can be beneficial for managing depression. Here are a few examples:\nLoving-Kindness Meditation (Metta): Loving-kindness meditation involves directing positive thoughts, well-wishes, and compassion towards oneself and others. It can help cultivate feelings of love, kindness, and empathy, which can counteract the negative self-perception and social isolation often experienced in depression.\nTranscendental Meditation (TM): TM is a form of meditation that involves the use of a mantra, a specific word or sound, repeated silently to oneself. It aims to quiet the mind and access deeper levels of consciousness. TM has been found to reduce symptoms of depression and anxiety and improve overall well-being.\nYoga and Yoga Nidra: Yoga combines physical postures, breath control, and meditation to promote relaxation, flexibility, and mental clarity. It can help alleviate symptoms of depression by reducing stress, improving mood, and enhancing self-awareness. Yoga Nidra, also known as “yogic sleep,” is a guided meditation technique that promotes deep relaxation and can be particularly helpful for individuals with depression-related sleep disturbances.\nBreath-focused Meditation: This type of meditation involves focusing on the breath as a point of concentration. It can help bring the mind to the present moment, reduce rumination on negative thoughts, and induce a state of calmness and relaxation.\nBody Scan Meditation: Body scan meditation involves systematically directing attention to different parts of the body, noticing physical sensations without judgment. It can promote relaxation, body awareness, and release tension, which can be beneficial for individuals with depression-related physical symptoms or somatic complaints.\nWalking Meditation: Walking meditation involves bringing mindfulness and awareness to the experience of walking. It can be done indoors or outdoors and can help promote relaxation, grounding, and a sense of connection with the body and the environment. Walking meditation can be particularly useful for individuals who find it challenging to sit still for traditional meditation practices.\nIt’s important to remember that different types of meditation work for different individuals, and it may be helpful to explore and experiment with different techniques to find what resonates best with you. It is also recommended to learn meditation techniques from qualified instructors or through guided meditation resources such as books, apps, or online programs.']"	['<urn:uuid:7a41f8d5-47be-45ae-941d-67d86cac672a>', '<urn:uuid:76f248bd-2697-43e4-b96e-77d227b79446>']	open-ended	with-premise	concise-and-natural	similar-to-document	multi-aspect	expert	2025-05-12T13:53:09.865574	19	68	1973
89	Which approach works better for preventing squirrels from accessing bird food - using hot pepper treatments or installing physical barriers?	Physical barriers are more effective than hot pepper treatments. While hot pepper suet can discourage rodents while being harmless to birds, the most reliable method is using physical barriers. Specifically, pole-mounted feeders should be placed 5 feet off the ground with cone-shaped baffles (at least 17 inches diameter) and located at least 10 feet from any structures. Additionally, weight-sensitive feeders that automatically close when heavier animals try to access them provide another effective physical barrier against squirrels.	['If you love bird feeders, then you know one of the tasks of any bird feeder owner is to make sure that pests stay far away from the precious bird food. One of the most annoying–not to mention yucky–pests that are attracted to bird feeders is rats. However, squirrels and mice might look cuter but will still create problems for you and your yard. If you want to know how to keep these rodents far away from your bird feeder, consider the following tips and tricks to keep the them at bay.\n1. Weight Sensitive Feeder\nWeight sensitive feeders will shut down any animals–such as squirrels and of course, rats–who try to get a nibble. How do they work? These feeders have a small hole that allows seeds to eaten from by small birds. However, if an animal of significant weight such as a squirrel, blackbirds and rodents attempt to eat from the feeder the hole will shut. The perch itself is weight sensitive and once a certain weight is applied the perch will lower and bring down a wall that blocks the feeder. Clever!\nYou can greatly reduce the chances that rodents will make a feast of your bird food by ensuring that they can’t reach it. Use a taller freestanding pole with a baffle feature to block any climbing animals who try to reach the seed. Ensure that any nearby building or branches do not offer any easy access to jump to your feeders. Rodents, in particularly squirrels are agile and will leap over great distances to reach food.\nBaffles such as this Squirrel Guard are known to work best against all types of rodents. They have an exceptionally slippery texture and do not rust at all.\n3. Peppermint Oil\nPeppermint Oil, Cayenne Pepper, and Chili flakes have all be known to deter rodents from visiting your bird feeder. Rodents find these smells potent and offensive and will keep away. Put a mixture of these ingredients in a blender with some water. Spray the puree over the column of your bird feeder or on any branches that can give access to the feeder itself.\nEnsure that these product do not get too close to the feeder itself as many birds also find these smells to be offensive. Follow this article to learn more about what smells keep birds away.\n4. Hot Pepper Suet\nRodents tend to stay away from hot peppers, whereas birds won’t be affected by them. You can discourage rodents from gnawing on your bird food by choosing hot pepper suet or seed mixes with hot pepper treatment, which will be distasteful (but not harmful!) to mammals while still being delicious for birds.\nThese hot pepper suet nuggets have worked in the past for many people I know!\n5. Clean Yard\nOne way to reduce the chances of rats showing up at your bird feeder is to reduce the chance that they’ll be in your yard at all! To do this, make your outdoor space as unappealing to rodents as you can. Make sure that openings around your home are plugged up, remove any piles of debris, stacked wood, as well as ground-covers that rats and mice love to nest in. You should also make sure there aren’t any rodent-friendly food sources around, such as pet food stored outdoors, open garbage, or even dog waste.\n6. No Food on the Ground\nIt can be tempting to leave bird seed on the ground, especially since you get to see plenty of birds hopping around on your lawn, but if you find that rodents love your yard then you need to clean the food up as much as possible. Food on the ground is free pickings for rats, so the more often you clean, the less you’ll see them around.\nCan bird feeders attract rats and mice to your yard?\nNo, unless you are careless. Ensure that all food is elevated and away from the reach of rodents. Stay away from tray feeders if you suspect rodents are in the area.\nBirds eating from feeders can often make seeds fall to the ground. It’s important that the area under the feeder is cleaned regularly to ensure that rodents do not have an easy and reliable food source in your yard. Follow Tip 6 in the list above for more information. Further information on different types of bird feeders available could help you choose the best one for you!\nAre mice bad for your yard?\nMice can be of great benefit to your yard if their numbers are kept under control. Mice eat many invasive insects and weeds that can be very helpful for many gardeners. In addition, mice are a great food source for birds of prey like Owls, Hawks and Eagles. If you’re looking to attract these majestic birds to your yard then cultivating a healthy mice population will be very beneficial for you. If you’d like to learn more about Attracting Owls to your yard or Attracting other birds of prey, give these articles a read!\nThere is great enjoyment in anticipating your strawberries ripening in the garden so you can\nWe are avid bird-watchers who recently retired, allowing us more time to travel the world. Fortunately, we have managed to visit numerous countries around Europe, Asia, and America. Watching and photographing birds has been a passion for many years and we are making the most of the extra time on our hands!', '1) Locate bird feeders at different levels\nSparrows, juncos, and towhees usually feed on the ground, while finches and cardinals feed in shrubs, and chickadees, titmice, and woodpeckers feed in trees. To avoid crowding and to attract the greatest variety of species, provide table-like feeders for ground-feeding birds, hopper or tube feeders for shrub and treetop feeders, and suet feeders well off the ground for woodpeckers, nuthatches, and chickadees.\n2) Offer a variety of seeds in separate feeders\nA diverse mix of seeds will attract the greatest variety of birds. To avoid waste, offer different seeds in different feeders. Black oil sunflower seed appeals to the greatest number of birds. Offer sunflower seeds, nyjer (thistle) seeds, and peanuts in separate feeders. When using blends, choose mixtures containing sunflower seeds, millet, and cracked corn—the three most popular types of birdseed. Birds that are sunflower specialists will readily eat the sunflower seed and toss the millet and corn to the ground, to be eaten by ground-feeding birds such as sparrows and juncos. Mixtures of peanuts, nuts, and dried fruit attract woodpeckers, nuthatches, and titmice. A relatively few species prefer milo, wheat, and oats, which are featured in less expensive blends.\n3) Provide suet during cool weather only\nSuet (beef fat) attracts insect-eating birds such as woodpeckers, wrens, chickadees, nuthatches, and titmice. Place the suet in special feeders or net onion bags at least five feet from the ground to keep it out of the reach of dogs. Do not put out suet during hot weather as it can turn rancid; also, dripping fat can damage natural waterproofing on bird feathers.\n4) Mix peanut butter and corn meal\nPeanut butter is a good substitute for suet in the summer. Mix one part peanut butter with five parts corn meal and stuff the mixture into holes drilled in a hanging log or into the crevices of a large pinecone. This all-season mixture attracts woodpeckers, chickadees, titmice, and occasionally warblers.\n5) Provide fruit for berry-eating birds\nFruit specialists such as robins, waxwings, bluebirds, and mockingbirds rarely eat birdseed. To attract these birds, soak raisins and currants in water overnight, then place them on a table feeder, or purchase blends with a dried fruit mixture. To attract orioles and tanagers, skewer halved oranges onto a spike near other feeders, or supply nectar feeders.\n6) Provide nectar for hummingbirds\nMake a sugar solution of one part white sugar to four parts water. Boil briefly to sterilize and dissolve sugar crystals; no need to add red food coloring. Feeders must be washed every few days with very hot water and kept scrupulously clean to prevent the growth of mold.\n7) Store seed in secure metal containers\nStore seed in metal garbage cans with secure lids to protect it from squirrels and mice. Keep the cans in a cool, dry location; avoid storing in the heat. Damp seeds may grow mold that can be fatal to birds. Overheating can destroy the nutrition and taste of sunflower seeds. For these reasons, it’s best not to keep seed from one winter to the next.\n8) Discourage squirrels from consuming feeder foods\nSquirrels are best excluded by placing feeders on a pole in an open area. Pole-mounted feeders should be about five feet off the ground and protected by a cone-shaped baffle (at least 17 inches diameter) or similar obstacle below the feeder. Locate pole-mounted feeders at least 10 feet from the nearest shrub, tree, or other tall structure. Squirrel feeders stocked with blends that are especially attractive to squirrels and chipmunks can reduce competition for high-priced foods offered at bird feeders. Place squirrel feeders far from bird feeders to further reduce competition.\n9) Locate feeders to reduce window collisions\nIn the United States, approximately one billion birds die each year from flying into windows. Protect birds from collisions by placing feeders within three feet of windows, if possible. Mobiles and opaque decorations hanging outside windows also help to prevent bird strikes. Or attach fruit tree netting outside windows to deflect birds from the glass.\n10) Keep cats indoors\nCats kill hundreds of millions of birds annually in the United States, often pouncing on ground-feeding birds and those dazed by window collisions. Responsible and caring cat owners keep their cats indoors, where they are also safer from traffic, disease, and fights with other animals. Outdoor cats are especially dangerous to birds in the spring when fledglings are on the ground. Bells on cat collars are usually ineffective for deterring predation.\n11) Clean feeders and rake up spilled grain and hulls\nUneaten seed can become soggy and grow deadly mold. Empty and clean feeders twice a year (spring and fall), or more often if feeders are used during humid summers. Using a long-handled bottlebrush, scrub with dish detergent and rinse with a powerful hose; then soak in a bucket of 10 percent non-chlorine bleach solution, rinse well, and dry in the sun. In early spring, rake up spilled grain and sunflower hulls.']	['<urn:uuid:caf741fc-55fe-4604-82e6-6e0539ec49f2>', '<urn:uuid:e826e9b7-1f1c-42c3-93fc-eb46fa1388b7>']	open-ended	direct	verbose-and-natural	distant-from-document	comparison	novice	2025-05-12T13:53:09.865574	20	77	1736
90	basic ingredients components make traditional chinese community meal soup	The six essential components for hot pot are: 1) Broth (which can be chicken, tom yum, mushroom, or spicy Chongqing style), 2) Vegetables (such as leafy greens, mushrooms, and root vegetables), 3) Meat (thinly-sliced beef, pork, or lamb), 4) Seafood (including shellfish, fish, and fish balls), 5) Noodles (like udon, vermicelli, or chow mein, added at the end), and 6) Condiments (such as soy sauce, sesame oil, peanut sauce, herbs, and chili paste). The broth is particularly important as it's used to cook all other ingredients.	['A bowl of selfmade soup will heat you up on a cold night, however in the event you’re on the lookout for a comfy meal that may feed a complete group — and convey everybody nearer collectively — it’s onerous to beat a scorching pot recipe.\nReady to have your personal scorching pot expertise?\nWe’ve detailed all the things it is advisable find out about making this versatile, shareable dish.\nWhat Is Hot Pot?\nHot pot is a communal eating expertise that includes a metallic pot stuffed with simmering broth in the course of the desk, surrounded by a wide range of uncooked meat, seafood, and greens ready to be immersed and cooked.\nHot pot originated in China and is in style all through Asia.\nIt’s a flexible meal stuffed with prospects — there’s no particular scorching pot recipe, and the important thing components can differ extensively between areas.\nYou can put no matter you need in your scorching pot and make it as wholesome as you need it to be.\nThe most essential ingredient of scorching pot is the social expertise. Sometimes in comparison with an Asian model of fondue, scorching pot is supposed to be shared with a gaggle of pals or household somewhat than eaten alone.\nThe History of Hot Pot\nHot pot has been round for greater than 1,000 years. It’s believed that the partitioned pots used to make scorching pot date again to the Three Kingdoms Era (220 to 280 AD).\nThere are many alternative regional variations of scorching pots, utilizing several types of broths and meats.\nFor instance, Sichuan scorching pots are highly regarded and use spicy components, whereas Cantonese scorching pot makes use of loads of recent seafood.\nWhat Tools Do You Need For Hot Pot?\nBefore you head to the grocery retailer to refill on components, be certain you’ve gotten the right instruments to place collectively your scorching pot.\nThe most essential instrument is a tabletop burner so you’ll be able to simmer your broth and prepare dinner your meals on the desk. You can simply discover a gas-powered or electrical scorching pot burner on-line.\nHere are another instruments you’ll want:\n- Pot: Look for a divided stainless-steel pot, as that is the standard vessel used for warm pot.\n- Chopsticks: Everyone ought to have at the least two pairs of chopsticks — one pair that can be utilized for transporting uncooked meals into the broth, and one pair that can be utilized for consuming.\n- Strainers with handles: Small strainer spoons are obligatory for eradicating cooked meals with out taking all the broth with you!\n- Extra gasoline canisters (if utilizing a gasoline burner): Hot pots aren’t meant to be quick, that means your burner might run out of gasoline at the least as soon as throughout the night. Keep further canisters readily available so you can begin issues proper again up once more.\n- Bowls and plates: Small, shallow bowls and plates are obligatory, together with spoons for anybody who’s having bother consuming with chopsticks.\n6 Essential Hot Pot Ingredients\nWhen it comes to assembling the best scorching pot, the extra meals, the higher. It’s additionally pretty straightforward to make a scorching pot wholesome.\n“A hot pot that contains vegetables, a protein source, a starchy food (like noodles), and other flavor enhancers (that are high in macronutrients and antioxidants) would be an example of a balanced meal,” says Lisa Hugh, M.S.H.S., R.D., L.D.N., CLT, founder and CEO of Single Ingredient Groceries.\nThe broth is arguably crucial half because you’ll use it to prepare dinner the remainder of the meals.\nA divided pot makes it straightforward to make use of two several types of broth, and many individuals like to supply one spicy possibility and one gentle possibility.\n“In order to make a hot pot healthier, select a lower sodium broth,” says Sandy Younan Brikho, M.D.A., R.D.N., of The Dish on Nutrition.\nPopular broth choices embody:\n- Chicken broth: Low-sodium rooster broth is a straightforward and in style method to go.\n- Tom Yum: For a giant increase of taste, do that Thai-inspired broth, which is made with lemongrass, chili peppers, fish sauce, galangal, lime juice, and lime leaves.\n- Mushroom: Savory mushroom broth could be a good vegetarian possibility.\n- Spicy: The in style Chongqing selection is full of warmth and contains Sichuan peppercorns, crimson chilies, preserved mustard greens, and extra.\n“Add more vegetables in order to make it healthier!” Younan Brikho says. “This will increase your fiber intake and increase your fullness with minimal calories.”\nYou can choose any veggies you need. Tomatoes can add a lot of taste, and snap peas can provide a pleasant crunch.\nBut there are such a lot of nice choices:\n- Leafy greens: Spinach, lettuce, and watercress prepare dinner shortly and simply. Heartier greens, like Napa cabbage and bok choy, are nice as effectively and can take longer to prepare dinner.\n- Mushrooms: Mushrooms add a ton of taste to your scorching pot and are an excellent vegan and vegetarian add-in. Popular varieties embody Shiitake, enoki, button, and portobello.\n- Root greens: Carrots, daikon radishes, lotus root, and turnips are all nice selections. Be positive to chop them into small items since they’ll take a very long time to prepare dinner.\nMeat is a scorching pot must-have (until you’re vegan or vegetarian, in fact). Younan Brikho recommends choosing lean cuts of meat or protein to maintain issues on the more healthy aspect.\nThinly-sliced meat — particularly beef, pork, or lamb — is principally a necessity. Paper-thin slices supply the most effective consistency and prepare dinner the quickest.\nChicken can also be an possibility, though it takes longer to prepare dinner.\nSeafood is a scrumptious scorching pot ingredient that provides loads of taste and cooks fairly shortly. Popular selections embody:\n- Shellfish: Whole, unpeeled shrimp cooks shortly, tastes scrumptious, and is normally a crowd-pleaser. Other choices embody lobster, clams, oysters, mussels, and crab.\n- Fish: Thinly-sliced salmon, halibut, monkfish, and bass (amongst others) will prepare dinner shortly and make an awesome protein supply.\n- Fish balls or fish muffins: Round fish balls could be manufactured from shrimp, lobster, and cuttlefish, and you may select selfmade ones or pre-made ones which are already cooked and simply must be heated up.\nNoodles ought to be dropped in on the finish when there’s a ton of taste within the broth, so the starch can choose all the things up and style as scrumptious as doable.\nYou can use any kind of noodle you want. Common picks embody udon, vermicelli, chow mein, and shirataki. For a gluten-free various, take into account corn, potatoes, or taro.\nCondiments are a scorching pot important for 2 causes: They make the meal extra enjoyable and add a ton of taste!\n“Hot pots tend to include spices, seasonings, and ingredients that might not be consumed in a typical rotation of meals,” Hugh says.\nTry utilizing issues like soy sauce, sesame oil, peanut sauce, herbs, chili paste or oil, tahini, eggs, and scallions.\nYou can add a few of these on to the broth or use them as dips for cooked meals. Just remember to use soy sauce and oils sparsely to manage sodium and fats consumption.\nKeep These Hot Pot Rules in Mind\nWhen sharing a scorching pot, there are a couple of correct etiquette ideas to remember.\n- Keep tabs in your meals: Make positive you watch the meals you place in and solely take away what’s yours. It’s not well mannered to take another person’s meals out of the new pot.\n- Don’t transfer meals from one kind of broth to the opposite: There are separate broths accessible for a purpose — some individuals don’t like a spicy broth and solely need gentle, for instance.\n- Have enjoyable: Hot pots could be a nice social expertise. As scrumptious because the meal could also be, don’t overlook to maintain the deal with the individuals you’re sharing it with!']	['<urn:uuid:c42943e8-7ed4-42d0-bf6c-8a9b5245c11b>']	open-ended	direct	long-search-query	distant-from-document	single-doc	novice	2025-05-12T13:53:09.865574	9	86	1326
91	I'm building a PC - what affects speed more, CPU or graphics card?	The graphics card (GPU) affects speed and FPS the most since it directly controls how quickly graphics are displayed on screen. While the CPU is also important and handles tasks like character movements and game physics, its impact is secondary to the GPU. However, both need to work together - if your CPU is too weak compared to your GPU, it can create a bottleneck and limit performance. The CPU acts as the brain handling calculations and coordinating components, while the GPU specifically handles graphics processing and frame rates.	['CPU is the brain of a computer system. All major calculations and comparisons performed by a computer are carried out inside its CPU. CPU is also responsible for activating and controlling the operations of other units of a computer system. Hence, no other single component of a computer determines its overall performance as much as its CPU.\nIn order to be able to evaluate a computer’s capabilities quickly, it is important to know how CPUs are internally structured, how different CPUs differ from each other, and how CPU speed is evaluated.\n- [#1] – Introduction to Computer Fundamentals\n- [#2] – Basic computer organization\n- [#3] – Number systems\n- [#4] – Computer Codes\n- [#5] – Computer Arithmetic\n- [#6] – Processor and Memory\n- [#7] – Secondary Storage Devices\n- [#8] – Input-Output Devices\n- [#9] – Computer software\n- [#10] – Planning the Computer Program\n- [#11] – Computer Languages\n- [#12] – System Implementation and Operation\n- [#13] – Operating Systems\n- [#14] – Application Software packages\n- [#15] – Business Data Processing\n- [#16] – Data Communications and Computer Networks\n- [#17] – The Internet\n- [#18] – Multimedia\n- [#19] – Classification of Computers\n- [#20] – Introduction to C Programming Language\nPoints To Remember:\n- CPU is the brain of a computer system. All major calculations and comparisons performed by a computer are carried out inside its CPU. CPU is also responsible for activating and controlling the operations of other units of the computer system. Hence, no other single component of a computer determines its overall performance as much as its CPU.\n- The two basic components of a CPU are the control unit and the arithmetic logic unit.\n- The control unit (CU) of a computer’s CPU acts as the central nervous system for all other components of the computer. It manages and coordinates the entire computer system including the input and output units. It obtains instructions from the program stored in the main memory, interprets the instructions, and issues signals that cause other units of the system to execute them.\n- The Arithmetic Logic Unit (ALU) of a computer’s CPU is the place where the actual execution of the instructions takes place during data processing operation.\n- Every CPU has built-in ability to execute a set of machine instructions, called its instruction set.\n- As instructions are interpreted and executed by a computer’s CPU, there is movement of information between various units of the computer. In order to handle this process satisfactoriluy and to speed up the rate of information transfer, a number of special memory units called registers are used. These registers are used to hold information on a temporary basis and are part of the CPU (not main memory).\n- The speed of a processor is related directly to a computer’s clock speed. Which is the number of pulses produced per second by the built-in electronic clock. This clock speed is measured in megahertz (MHz) or gigahertz (GHz).\n- The three commonly known processor architectures are CISC (Complex Instruction Set Computer), RISC (Reduced Instruction Set Computer), and EPIC (Explicitly Parallel Instruction Computing).\n- Multicore processor technology enables building of computers with better overall system performance by handling more work in parallel. In this technology, a processor chip has multiple cooler-running, more energy-efficient processing cores instead of one increasingly powerful core. Multiple programs/threads can be run at the same time on a multicore chip each core handling a separate program/thread. To take advantage of multicore chips, applications must be redesigned so that the processor can run them as multiple threads.\n- Every computer has a temporary storage area built into the computer hardware. Instructions and data of a program reside in this area mainly when the CPU is executing the program. This storage space is known as primary storage, main memory, or simply memory.\n- Any storage unit of a computer system is characterized and evaluated based on following properties – storage capacity, access time, cost per bit of storage, volatile, and random access.\n- A primary storage or main memory of a computer system is made up of several small storage areas called locations or cells. Each of these locations can store a fixed number of characters (equal to its word-length in bytes). In these computers, storage space is always allocated in multiples of word-length. On the other hand, in a character-addressable computer each numbered address can store only a single character (A,B,1,2,+,- etc.).\n- Main memory capacity of large computer systems is normally more than that of smaller systems. This capacity is defined in terms of the number of bytes a computer system can store. Memory capacity of a computer system is stated normally in terms of kilobytes (KB), which is equal to 1024 (210) bytes of storage, or megabytes (MB), which is equal to 1,048,576 (220) bytes of storage, or gigabytes (GB), which is equal to 1,073,741,824 (230) bytes of storage.\n- A computer’s main memory is built of volatile RAM chips.\n- A special type of RAM, called read-only memory (ROM), is non-volatile memory chip in which data is stored permanently and cannot be altered by the programmer. There are two types of read-only memory (ROM) – manufacturer-programmed and user-programmed. The latter is commonly known as Programmable Read-Only Memory (PROM) because a user can program it.\n- Once information is stored in a ROM or PROM chip it cannot be altered. However, Erasable Prgrammable Read-Only Memory (EPROM) chips can be reprogrammed to store new information. EPROM chips are of two types – Ultra Violet EPROM (UVEPROM) and Electrically EPROM (EEPROM). EEPROM is also known as flash memory.\n- Cache memory is an extremely fast and small memory between CPU and main memory. Its access time is closer to the processing speed of CPU. It acts as high-speed buffer between CPU and main memory and is used to temporarily store very active data and instructions during processing.\nList of Questions\n- List the main functions of CPU in a computer system.\n- What are the two main components of CPU of a computer system? List the main functions of each of these components.\n- Describe the role of decoder of a CPU.\n- What is a microprocessor?\n- What is an instruction set of a computer system? Do computers made by different manufacturers generally have the same or different instruction sets?\n- Machine language programs written for one computer will generally not run on another computer with a different CPU. Explain why.\n- What is a family of CPU? When do two CPUs belong to the same family?\n- When do we say that a computer is backward compatible with another computer? How this feature is useful for the users of these computers?\n- What are registers? Name some commonly used registers and briefly describe the function of each.\n- What does length of a register mean? What are the commonly used register-lengths in modern computer systems? Why is a larger register length desirable?\n- List the main steps involved in execution of an instruction by a computer’s CPU.\n- What is clock speed of a computer system? How does it influence the overall speed of a computer system?\n- Differentiate between CISC and RISC processors.\n- List the relative advantages and disadvantages of CISC and RISC processors.\n- What is a multicore processor? How does it differ from a single-core processor?\n- Explain the limitations of current transistor technology that has forced processor manufacturers to shift form making more powerful single-core processors to multicore processors.\n- Explain how a multicore processor can handle the execution of multiple simultaneous tasks more efficiently than a single-core processor.\n- Multicore processor technology adds to extra work for programmers. Explain why.\n- List the main advantages and current limitations of multicore processor technology as compared to single-core processor technology.\n- Why multicore processor technology is also referred to as energy-efficient or power-aware processor technology?\n- Why software licensing is a key issue with multicore chips?\n- List the key properties used to characterize and evaluate storage units of computer systems.\n- Explain the difference between volatile and non-volatile memory. Write an example of each type of memory.\n- Explain the difference among random access, pseudo-random access, and sequential access storage units. Write an example of each type of storage unit.\n- Differentiate among a bit, a byte, and a word.\n- Explain the difference between memory read and write operations.\n- Explain why it is advantageous to have more number of bit per word instead of having more words of shorter length in the memory architecture of a computer system.\n- Distinguish between word-addressable and character-addressable computers. Discuss their relative advantages and disadvantages.\n- How many bytes will be required to store the word ‘MEMORY’ in (a) a character-addressable computer, (b) a word-addressable computer having word-length of 64 bits?\n- Name some commonly used units for stating memory capacity. Roughly, how many characters does each unit represent?\n- A computer has 512 MB of memory. How many characters can be stored in its memory at a time?\n- What is a ROM? Why it is so called? Write few typical uses of ROM.\n- What is a micro-program? Write an example of a micro-program that is a good candidate for storage in the ROM of a computer system.\n- Differentiate between PROM and EPROM.\n- Differentiate between UVEPROM and EEPROM.\n- What is a flash memory? why it is so called?\n- Differentiate among RAM, ROM, PROM, and EPROM.\n- What is a cache memory? How it is different from a primary memory?\n- Explain how a cache memory helps in improving the overall processing speed of a computer system?\n- Write short notes on:\nCentral Processing Unit (CPU)\nArithmetic Logic Unit (ALU)\nStorage evaluation criteria\nVolatile and Non-volatile storage\nFixed and Variable word-length memory\n- Write the full form of the following abbreviations:', 'When building a PC there are many different parts that affect the FPS. However, some affect the FPS more than others.\nIn this article, we will talk about what PC parts affect FPS the most and which parts you should worry about upgrading first in order to enhance your PC’s performance.\nSo, what PC part affects FPS the most?\nThe GPU directly affects the FPS being displayed on your screen. The faster the graphics on your screen get updated, the faster FPS you will have. The CPU also plays a role in increasing FPS because it needs to be on par with GPU performance to prevent bottlenecks.\nThis shows that even though your GPU/graphics card is the main component in your computer that increases FPS, it is not the only part that matters.\nThe other parts in your PC can help assist your GPU so that you can squeeze the most FPS out of your game.\nHow Much Do Graphics Cards Affect FPS?\nBy far a good graphics card can enhance your FPS a lot and it is the most important computer part when it comes to gaming and performance.\nThe reason for this is that the graphics card is made to display graphics onto your computer screen.\nWhen you have movement and videos involved, they can only move as fast as your graphics update. That is why having a good graphics card is important.\nA good graphics card will allow your displayed graphics to update faster granting a higher FPS.\nThis is why a graphics card directly correlates with your FPS.\nFPS stands for frames per second. The frames are what is displayed on your computer screen and every time your graphics card updates your screen it changes to the next frame.\nIf your graphics card can only update the graphics 60 times a second then you will be capped to 60 frames per second.\nHowever, if your graphics card updates 120 times a second then you will be able to run your game at 120 frames per second.\nHaving a good graphics card will allow your game’s graphics to display much faster causing an FPS increase.\nEven if your other computer components are high-end they won’t be able to perform past the speed of your graphics card because they will become bottlenecked to your graphics card’s speed.\nAn example of this is if you have a high-end CPU that can produce up to 150 FPS. If your graphics card is only able to display 60 FPS, then you will only be able to see and use 60 FPS, and your CPU will be bottlenecked by the graphics card.\nSo even though it is important to have well-performing PC components, if your graphics card isn’t able to display what your CPU, RAM, or Monitor is able to display then you won’t see the FPS increase.\nHow Much Do CPUs Affect FPS?\nYour CPU does have a major role in increasing computer FPS, but you need it to work side-by-side with your GPU.\nAlthough the CPU doesn’t have as big of an impact on FPS as your GPU does, having a high-performance CPU will still aid in performance especially if you are playing a CPU-intensive game.\nMany game developers build games that focus on using more power from the CPU than the GPU. Even still your GPU plays the main part in increasing FPS, but a good CPU will allow you to play these types of games at an even higher FPS and boost your performance.\nWhile the GPU works on displaying characters, events, and movements on your screen. The CPU works in the background to make characters move, attack, and give objects properties such as collision properties, or barriers in a game.\nWithout the CPU your character wouldn’t be able to move or interact with anything on your screen.\nOnce the GPU knows what your CPU is doing to the characters and environment in the game it can then display it on your screen.\nThis is why it is very important to have a good CPU, so it can execute these movements and interactions in the background so it can be displayed faster and smoother on your screen, increasing your game’s FPS.\nIf your CPU is underperforming, then it won’t be able to execute these tasks in time for your GPU to display them, causing a CPU bottleneck, this is why it is very important to get a CPU that is as good or almost as good as your GPU, so you won’t experience this bottleneck.\nTo learn more about how your CPU affects FPS and performance (click here).\nHow Much Does RAM Affect FPS?\nRAM is another component that plays a role in increasing your FPS and performance in the game.\nAlthough, RAM is not as important to increasing your FPS as a CPU and GPU are. Having a good set of RAM can help squeeze that extra performance you aren’t already getting from your CPU or GPU.\nThere are a few factors that come into play when buying and installing RAM on your computer.\nThe first is the amount of RAM you buy and use. With so many different sizes and amounts of RAM, you can buy it can be a tricky decision to decide how much is the best for you.\nI would say that the minimum amount of RAM you could get away with in most modern games is about 8GB of RAM. As this is what is usually the recommended minimum for most games.\nHigher demanding games will work better with higher amounts of RAM because of the amount of information that is being produced and changed every second.\nRAM is used to store temporary memory in whatever program you are using. Having enough RAM to support these games is very important if you want the game to run fast and smooth.\nHowever, you should also note that having too much RAM is possible as well.\nIf you have too much RAM then you will see no performance benefit when gaming.\nTherefore, if you have 32GB of RAM installed on your PC but your game only requires 16GB of RAM, then the game will only use 16GB of RAM. This means that the extra 16GB of RAM you have left in your computer is useless and not doing anything.\nYou should note that most games can run on 8GB of RAM, but even if that’s the minimum requirement it is recommended to get a little bit more RAM installed on your PC, as the game can fluctuate on the amount of RAM it uses sometimes using 9 or 10GB of RAM.\nYou should also have extra RAM for background programs on your computer. This is because every program even if it is running in the background still uses some of your RAM memory. So if you have 8GB of RAM, your game is really only using 6GB more or less.\nEven if you have no programs running in the background your operating system such as Windows, and Mac needs to use some of your RAM memory in order to run.\nSo opting for about 16GB will benefit you greatly, and help improve your FPS.\nAnother way RAM improves FPS is through channels. The way you install your RAM plays a big role in this.\nThis is because having your RAM in dual-channel mode will allow your RAM to split its productivity into two, giving you more FPS.\nIf you want to learn more about RAM and Dual-Channel mode here is an article that goes into great detail on How RAM Improves Performance and FPS.\nHow Much Does Cooling Affect FPS?\nBelieve it or not, having a good cooling system in your computer can help boost FPS. This is because good cooling can allow your other PC components to work harder without overheating.\nThe harder and faster a computer part such as the GPU or CPU works, the more heat it produces.\nIf the cooling system in the PC is not efficient enough to keep up with the amount of heat your PC is producing then your computer parts will start to overheat.\nThis creates FPS and performance drops, as well as possible damage to your system.\nHaving a sufficient cooling system will also allow you to overclock your PC.\nOverclocking your PC will increase the performance of your computer and FPS by a good amount, and the better your cooling system, the higher you can overclock your PC. Thus, boosting FPS even more.\nIf you want to know more about overclocking and how it increases performance (click here).\nHow Much Does Your Monitor Affect FPS?\nNext, is your computer monitor.\nYes, your computer monitor can go hand in hand with the amount of FPS you are “seeing” being used on your computer.\nEvery monitor comes with a different refresh rate. The higher the refresh rate the faster your monitor can refresh the screen.\nSimilar to the GPU that produces the graphics on your screen. The monitor helps sync those graphics on display and allows them to run smoothly.\nIf you have a really good system that produces let’s say 120 FPS, but your monitor has a 60Hz refresh rate then only 60 frames will run smooth.\nYou want your monitor Hz to match the amount of FPS you are getting from the rest of your computer system.\nSo if you are getting 120 FPS, then you will want a 120Hz refresh rate monitor, that way you are getting the most out of your computer system.\nIf your refresh rate is too low compared to the FPS you are getting, then you will experience screen tearing.\nIf your refresh rate is too high compared to the FPS you are getting then the same frame might be refreshed twice. Cutting performance.\nHere is an article that goes more in-depth on “The Difference Between Refresh Rate and FPS”\nHere is an article that talks more about 60Hz, 144Hz, and 240Hz Monitors.\nWhat Part Of Your PC Should You Upgrade First For Better FPS?\nYou should upgrade your graphics card first in order to get the best FPS gain out of your PC, then your CPU, then your RAM. This is because the graphics card is most important when it comes to FPS.\nYour CPU also plays an important role in performance, so that is why you should upgrade it second, and RAM still helps improve FPS, but it is not as significant as your GPU or CPU.']	['<urn:uuid:ed12f433-2551-4de4-b984-5ff61d8a7f7f>', '<urn:uuid:1ee78d8f-09ad-4269-ae4c-a6a8abe0f859>']	open-ended	with-premise	concise-and-natural	distant-from-document	comparison	novice	2025-05-12T13:53:09.865574	13	89	3404
92	what person inspired name tunnels inside enterprise starship	The Jefferies tubes were named after Matt Jefferies, the designer of the original USS Enterprise and the Art Director of Star Trek: The Original Series.	"['This page contains information regarding Star Trek: Discovery, and thus may contain spoilers.\nOn Starfleet vessels, Jefferies tubes are internal maintenance conduits that are used to provide crew access to various ship\'s systems. In emergencies, they are also used for moving around the ship if turbolifts are not functional. Doors within the Jefferies tubes can be sealed for safety or security reasons. On all ship displays of internal structure, Jefferies tubes are not displayed, and in some cases show no sign where they could actually fit within the ship. During the 22nd and 23rd centuries, Jefferies tubes were usually referred to as access tubes, access tunnels, or service chutes, although the term was in use as early as 2256. (DIS: ""Context Is for Kings"") In the 24th century, the single term was generally favored, though some officers referred to them as ""service crawl-ways"". (TNG: ""Disaster"")\n22nd century Edit\nDuring the 22nd century, starships were outfitted with long and small service tunnels, which would later be known as Jefferies tubes. These were hard, cold, cramped, and poorly lit. Tunnels on some ships joined at a variable gravity ""sweet spot"". (ENT: ""Broken Bow"")\nVertical tubes Edit\nNX-class ships had vertical tubes to help their crew manually reach decks above them or below them. These tubes were circular from one end to the other. Each tube was equipped with a single one-way ladder for crewmen to climb or descend. The ladders had dim lights behind them so the crew could see where to step. (ENT: ""The Crossing"", ""Regeneration"")\nHorizontal tubes Edit\nThe horizontal tunnels were not very different from the vertical ones. They were also circular and narrow. Crewmen had to bend their knees and crouch down at a bent posture while walking inside these specific tubes. A majority of the tube\'s space was filled with long and thick engineering pipes that went from one end to the other. These tubes were lit from the floor so a person could follow a path. (ENT: ""Acquisition"", ""Vanishing Point"", et al.)\n23rd century Edit\nIn the 23rd century, Jefferies tubes were still round and small, but they were better lit by that time and no longer simply a means to get around. They served many different functions and purposes. It was not uncommon to find many technicians and engineers tinkering inside them.\nDiagonal tubes Edit\nMany diagonal tubes were scattered all throughout starships. These tubes were always densely connected with important system controls, relays, various conduits, and vital engineering circuits. Some of these tubes led to crawl-way junctions, while some even continued on inside a nacelle pylon to one of the ship\'s actual warp nacelles. At the entrance of each tube were two red bars so a crewman could pull him or herself inside. A soft, yet strong light was always emitted from the top and filled the entire tube. Certain tubes had multiple functions, while others had single functions like the tubes which were only designated engineering circuit bays. Each diagonal tube was equipped with stairs for crewmen to walk up or down. (TOS: ""Charlie X"", ""The Doomsday Machine"", ""Journey to Babel""; ENT: ""In a Mirror, Darkly, Part II"")\nVertical tubes Edit\nThe vertical tubes on a starship, also known as gangways, allowed manual access to decks both above and below. These particular tubes were easily accessible in the open hallway alcoves located on every deck. On the walls of these tubes, there was a reflective material that perfectly illuminated the entire tunnel. The tubes were equipped with a single ""three-way ladder"" to allow more than one crewman to climb or descend. (TOS: ""Amok Time"", ""The Doomsday Machine"", ""The Way to Eden"")\nHorizontal tubes Edit\nThe horizontal crawl-ways on starships allowed manual access to various parts of a starship. These tubes were also densely connected with important system controls and vital engineering circuits. Some of these tubes even led to the matter-antimatter reaction chamber. Every few feet, a bright light could be found, shining down. Crewmen usually had to crawl while traveling in some of them due to the cramped size. Other horizontal tubes were still cramped, but crewmen could still walk freely up straight in posture. This was especially true late in the 23rd century. Late in that century, the horizontal tubes were extremely well lit, with lights coming from both above and below. (TOS: ""That Which Survives""; Star Trek V: The Final Frontier)\nTube junctions Edit\nOn a starship, the Jefferies tubes had junction service crawl-ways. They served as interconnected points linking all the different tubes. On Constitution-class vessels, these junctions also gave access to critical starship systems, like plasma flow regulators and warp and power relays. (ENT: ""In a Mirror, Darkly, Part II"")\n24th century Edit\nDuring the 24th century, Jefferies tubes became more simple, less intricate, and not as thoroughly filled with vital systems.\nVertical tubes Edit\nThe vertical tubes on starships allowed manual access to decks both above and below, which were labeled inside these particular tubes. Dim lights were located behind the main ladder and other lights were found on every deck. These tubes were equipped with a single one-way ladder for crewmen to climb or descend.(citation needed • edit)\nHorizontal tubes Edit\nThe horizontal crawlways on starships allowed manual access to various vital parts of a ship or station. Dim lights were located near the floor and on each side of the tube. Crewmen usually had to crawl while traveling in them due to the cramped size. Inside these tubes were removable panels to important system conduits and engineering controls.(citation needed • edit)\nIn 2374, The Doctor sent the EMH Mark II to Jefferies tube 17 aboard the USS Prometheus to release a neurozine gas. The EMH Mark II never accessed a Jefferies tube and The Doctor told him that, traditionally, such a Jefferies tube is accessed head first. (VOY: ""Message in a Bottle"")\nTube junctions Edit\nOn 24th-century starships, all Jefferies tubes had junction service rooms. They served as interconnected points, linking all the different tubes. Every room had exposed conduits on the walls, sometimes with panels to access various power conduits or relays.\nAlien variant Edit\nOn several alien starships, similar tunnels and tubes were used, known as crawlways and access tubes. Aboard the Vulcan D\'kyr-type combat cruiser Seleya, they were known as crawlways. (ENT: ""Impulse"")\n- DIS: ""Context Is for Kings""\n- TAS: ""The Practical Joker""\n- ""Learning Curve""\n- ""Fair Trade""\n- ""Before and After""\n- ""Worst Case Scenario""\n- ""The Gift""\n- ""Scientific Method""\n- ""Year of Hell""\n- ""Waking Moments""\n- ""The Killing Game, Part II""\n- ""Course: Oblivion""\n- ""Someone to Watch Over Me""\n- ""The Voyager Conspiracy""\n- ""Blink of an Eye""\n- ""The Haunting of Deck Twelve""\n- ""Renaissance Man""\n- Star Trek: First Contact\nBackground information Edit\nThe Jefferies tubes were probably named in honor of the 22nd century Starfleet engineer W.M. Jefferies. In reality, this character was named after Matt Jefferies, the designer of the original USS Enterprise and the Art Director of Star Trek: The Original Series. (Star Trek Encyclopedia (4th ed., vol. 1, p. 386))\nThe name ""Jefferies tube"" was originally an in-joke, already in use during the production of The Original Series, but only came to be canonically mentioned on a number of occasions in the later Star Trek: The Next Generation television series, the first time being in that show\'s third season episode ""The Hunted"". Jefferies himself had indicated, ""Somebody hung the name Jefferies Tube on it. It wasn\'t me, but the name stuck and I used it in some of my sketches!"" (Star Trek: The Original Series Sketchbook, p. 72; Star Trek Encyclopedia, 4th ed., vol. 1, p. 386) The first recorded use of the nomenclature was a ""SHOT – JEFFERIES TUBE"" script reference in the draft of 14 September 1967 of ""Journey to Babel"" (scene 36, p. 21, where the body of Gav was stashed), though it was not heard in the episode. Set Designer John Jefferies, the younger brother of Matt and who, with his team, had to build his brother\'s design, recalled the construction of the Original Series Jefferies tube; ""It was the only part of that set that was moved on [note: meaning it was a mobile set, mounted on rollers] that was on an incline, and it was made out of a Sona Tube that we cut and expanded a little bit. Sona Tubes were large cardboard tubes that could be purchased. They were used for forming concrete and we would buy these in either eight- or ten-foot lengths and they came in many varying diameters. They ran about a half an inch thick and they were wrapped cardboard. Well, we found these marvelous for pieces of set and curved walls, because they were quick."" (""Designing the Final Frontier"", TOS Season 2 DVD special features)\nThe access tubes have changed appearance many times in the past fifty years, while still maintaining their basic function for both the series and films. The tubes were commonly used as a last-minute deus ex machina, whether it was a relay circuit inside that needed to be repaired, or a straightforward means of physical escape.\nThe most unusual variation of the Jefferies tube was a vertical tube shown in the original Star Trek series. This access tube had a ""three-way"" ladder that allowed three people to climb simultaneously. This was no doubt convenient during red alert when crewmen needed to get to battle stations quickly. Unfortunately, this concept was never expanded upon, so we never saw a four- or even a six-sided hexagon-shaped ladder. Instead, the ladders in the Jefferies tubes of the 24th century were only capable of supporting one individual.\nAn in-joke reportedly appearing in the Jefferies tube sets on the original Star Trek series (although written so small as to be invisible to the audience) were labels on pipes, marked ""GNDN"". This stands for ""Goes Nowhere, Does Nothing"". The marking also appeared on various sets for the Star Trek films.\nTraditionally, Jefferies tubes were cramped crawling spaces, but in Star Trek Nemesis, a particularly spacious one was featured. Commenting on this large Jefferies tube, Star Trek archivist Penny Juday explained (in 2002), ""The Jefferies tube is used even today [....] So, Herman Zimmerman has made sure that the name sticks [....] Almost all the time – not in every episode of course – but when we need a crawl space, that\'s exactly what we use; it\'s always called a Jefferies tube."" (""Designing the Final Frontier"", TOS Season 2 DVD special features) The canonization of the term ""Jefferies tube"", however, fell to Zimmerman\'s successor, Richard James, to implement in the aforementioned episode ""The Hunted"". Chronologically, the reference in DIS: ""Context Is for Kings"" establishes it to have been referred to in that way as early as 2256.']"	['<urn:uuid:ad6e9def-716f-44d8-9eab-ecbb6cfdc8b3>']	factoid	direct	long-search-query	distant-from-document	single-doc	novice	2025-05-12T13:53:09.865574	8	25	1798
93	What determines regional variations in extreme rainfall changes?	Changes in winds, and not water vapor, determined the region-to-region variations in the change in extreme rain intensity. The severity of rainstorms is influenced by how local wind patterns change in strength.	['If global average temperatures rise by 4 degrees Celsius over the next hundred years, as many climate models predict given relatively high CO2 emissions, much of North America and Europe would experience increases in the intensity of extreme rainfall of roughly 25 percent. Some places such as parts of the Asian monsoon region would experience greater increases, while there will be smaller increases in the Mediterranean, South Africa and Australia.\nThere are a few regions that are projected to experience a decrease in extreme rainfall as the world warms, mostly located over subtropical oceans that lie just outside the tropical, equatorial belt.\nThe study, published today in Nature Climate Change, finds that the varied changes in extreme precipitation from region to region can be explained by different changes in the strength of local wind patterns: As a region warms due to human-induced emissions of carbon dioxide, winds loft that warm, moisture-laden air up through the atmosphere, where it condenses and rains back down to the surface. But changes in strength of the local winds also influence the intensity of a region’s most extreme rainstorms.\nPaul O’Gorman, a co-author on the paper and associate professor of atmospheric science in MIT’s Department of Earth, Atmospheric and Planetary Sciences, says being able to predict the severity of the strongest rain events, on a region-by-region basis, could help local planners prepare for potentially more devastating storms.\n“There is interest around the world in the question of whether to adjust codes to adapt to a changing climate and precipitation, particularly for flooding,” O’Gorman says. “We found there are regional variations in the projected precipitation response because of changes in winds, and of course if you’re interested in the impacts of precipitation extremes, you’d want to know what’s happening in your region.”\nA global grid view\nSince the 1990s, scientists have predicted based on climate models that the intensity of extreme rain events around the world should increase with rising global temperatures. Current observations have so far verified this trend on a broad, global scale. But knowing how extreme storms will change on a more specific, regional scale has been a trickier picture to resolve, as climate data is not equally available in all countries, or even continents, and the signal of climate change is masked by weather noise to a greater extent on the regional scale.\n“The observations are telling us there will be increases [in extreme rainfall] at almost all latitudes, but if you want to know what’s going to happen at the scale of a continent or smaller, it’s a much more difficult question,” O’Gorman says.\nHe and his colleagues began their study by taking a global perspective. They first looked through a massive archive of global simulation runs, known as the Coupled Model Intercomparison Project Phase 5 (CMIP5), which aggregates outputs, or predictions, made by different climate models, for everything from local air pressure to the thickness of sea ice in response to changing climate.\nFor this study, the researchers culled the CMIP5 archive for specific outputs, including daily accumulated surface precipitation and temperature, vertical wind velocity and pressure, and daily atmospheric humidity. These outputs were simulated by 22 climate models, for the years 1950 to 2100, under a scenario in which there are relatively high emissions of CO2.\nThe team looked at each of the 22 models’ outputs on a regional, grid-by-grid basis. Each model simulates climate conditions by dividing the globe up into a grid, with each grid cell’s side measuring 100 to 200 kilometers. For each cell in each model, the researchers identified the maximum daily rainfall per year and compared this to the average global temperature for that year.\nAll 22 models predicted that the highest increases in extreme rainfall will occur over parts of the Asian monsoon region such as India and over parts of the equatorial Pacific, with more moderate increases in North America, Central America, the Mediterranean, and Australia.\nO’Gorman says that while the spatial pattern of change was robust across the models, the magnitude of the change was much more uncertain in tropical regions, and higher-resolution modeling is needed to narrow down this uncertainty.\nTo see what was influencing the region-to-region variability in rainfall increases, the team plugged the outputs into a physics-based formula that relates the amount of surface precipitation to the vertical winds and the amount of water vapor in the atmosphere. They found that, overall, it was the changes in winds, and not water vapor, that determined the region-to-region variations in the change in extreme rain intensity.\nThe researchers also found decreases in extreme rainfall amounts over subtropical ocean regions, where the overlying atmosphere is generally dry, producing relatively weak storm systems.\n“It’s kind of striking,” O’Gorman says. “Almost everywhere, there’s an increase in precipitation extremes, except for these ocean regions.”\nHe suggests this may be partly due to the ongoing expansion of the tropics, and the associated changes to a atmospheric circulation system known as the Hadley cell, in which air rises near the equator and descends farther poleward. As the climate has warmed in past decades, researchers have noted that the climate at the equator has spread towards the poles, creating a much wider tropical belt. As the tropics and the Hadley cell continue to expand, this would affect the pattern of extreme precipitation, especially in the subtropics.\n“The subtropics are generally dry, and if you move the region of descending air poleward, you would get some regions with increases, and others with decreases [in extreme rainfall],” O’Gorman says. “However we found that this only explained half of the decreases from changes in winds, so it’s still something of a mystery as to why you get a decrease in precipitation extremes there.”\nO’Gorman is currently investigating whether the duration of extreme rainfall events changes with increasing temperatures, which could have practical implications for determining the resilience of buildings and infrastructure.\n“Given an extreme precipitation event, how long does it last, say in hours, and does that time change with climate warming?” O’Gorman says. “We think the intensity of an event changes, and if the duration also changes, that could be significant too.”\nThis research was supported, in part, by the National Science Foundation.\nImage courtesy of MIT News Office']	['<urn:uuid:6e2002a6-9152-448a-905a-4e1492306675>']	factoid	direct	concise-and-natural	distant-from-document	single-doc	expert	2025-05-12T13:53:09.865574	8	32	1040
94	How do linear and nonlinear approaches differ in understanding toxicity, and what specific evidence should be considered when identifying unspecified toxic chemicals as a cause of harm?	Linear approaches view toxicity as a direct relationship where higher doses lead to greater impacts, following the 'dose makes the poison' principle. Nonlinear approaches consider multiple variables like system state, timing, gender, and epigenetic programming. When identifying unspecified toxics, evidence should include presence of point/non-point sources, physical signs like water discoloration, abnormal water quality characteristics, and biological effects such as fish mortality or behavioral changes.	"['What Are Toxins?\nA toxin is typically thought of as skull and crossbones, something that can kill you. A toxin has what is called an LD50, that is the amount that will kill half (50%) of the population of species it is exposed to. Toxins typically have a very specific mechanism of action unique to the toxin. Which is why, just like snake venom has an anti-venom, a toxin has an antitoxin. Antitoxins are antibodies (or proteins) produced by the body that counteract a toxin. However, anything, even something as essential as water, can be toxic at excessive amounts. That is a different mode of toxicity. For that mode of toxicity anything can be a toxin if it overwhelms our body’s ability to process, absorb, balance, metabolize or eliminate it. Most substances that go by the term “toxin” however, have very specific action of detriment. There are over 700 known toxins.\nPrimary and Secondary Actions\nThere are two different ways to look at toxins. The typical toxicology as stated above is that a toxin can kill you. This is the primary action of a toxin, the very direct and linear action. There are also secondary actions of toxins. This is both the amount of oxidative (or nitrosatic) stress the toxin creates in the body AND also how the body senses and reacts to the toxin. When the body senses that a toxin becomes a threat to the system it creates a stress adaptation response. The primary action of a toxin is subdued by an antitoxin, but the secondary action of a toxin is subdued by adaptation, stress reactions and antioxidants.\nThe differences between linear and nonlinear approaches\nIt also helps to understand that there are generally two major ways to approach scientific problems. One is call a linear approach and the other is a nonlinear approach. As you might be able to infer from the names one is very straight and direct and the other is much more inclusive of multiple variables and outcomes. Much like the primary and secondary actions of toxins.\nThe nonlinear approach not only looks at multiple variables but also looks for initial conditions (individual differences). In a nonlinear perspective one cause could lead to many outcomes, whereas in a linear perspective we expect one cause to have the same outcome.\nIn a linear model of toxicity there is primary and single source and action of a toxin. We measure when that substance becomes dangerous via the rule of thumb of “the dose makes the poison”. The higher the dose the greater the impact, below a certain point there would be no impact. That is a linear model. As the dose goes up, the influence goes up. A linear perspective tells us that a certain amount is toxic.\nWhereas a nonlinear model of toxicity the amount is more variable depending on the state of the system, timing of the assault, gender of the individual, the nutritional state and current state of epigenetic programming. Epigenetic programming can come from early life or even before life. An earlier stress can create a greater response to future stresses. This is described in research showing that multiple “hits” to a system can create greater reactions to otherwise innocuous stresses.\nA nonlinear perspective tells us that toxicity depends on the person and the situation as to what amount is toxic. In a nonlinear model we look at the action from a stress perspective.\nNonlinear Systems from Wikipedia:\nNonlinear problems are of interest to engineers, physicists and mathematicians and many other scientists because most systems are inherently nonlinear in nature. As nonlinear equations are difficult to solve, nonlinear systems are commonly approximated by linear equations (linearization).\nThis is an important concept because linear solutions aren’t wrong necessarily, they just aren’t whole answers. They are parts of a larger whole.\nDefinition of Linear vs Nonlinear Dynamics from the Free Dictionary:\nUnlike a linear system, in which a small change in one variable produces a small and easily quantifiable systematic change, a nonlinear system exhibits a sensitive dependence on initial conditions: small or virtually unmeasurable differences in initial conditions can lead to wildly differing outcomes.\nWhile we think of stress as social stress that creates anxiety, the linear perspective. Stress is also a framework. It is new rules to apply so that we can understand how stress creates many of the outcomes in chronic health issues. Instead of looking at particular toxins as culprits, we look instead at the reaction and state of the individual as to why that substance became stressful enough to create reactions and adaptations that shifted the system into an unbalanced state.\nCurrent mainstream medicine takes mostly a linear approach to disorders, while stress, which is the core of most modern disorders, is a nonlinear concept. So we are very absent in our ability to communicate about this next level of science… but we are getting closer. Nonlinear models are very important for understanding autism and many other chronic lifelong stress adaptation disorders. A Stress Model for Autism is necessary to move the conversations forward and provide adequate and comprehensive solutions for those on the spectrum.', 'CADDIS Volume 2: Sources, Stressors & Responses\nUnspecified Toxic Chemicals\nOn this page\nAuthors: S. M. Marcy, G.W. Suter II\nThe toxicity of a substance refers to its potential to harm living organisms. Toxicity is a function of concentration and duration of exposure, and varies by species, age and condition of exposed organisms. Toxic chemicals, as considered here, are individual chemicals or mixtures of chemicals and their by-products that originate from human activities (Figure 1). These are toxic chemicals have not yet been identified in the assessment and are capable of adversely affecting living organisms. They may be unknown because they have not been measured or measurement is difficult (e.g., due to episodic occurrence, unique chemistry, or low concentrations). Their effects may be suspected but, because of absent or incomplete chemical monitoring data, exposure cannot be confirmed. Under these circumstances, ""toxic chemicals"" should be listed as a candidate cause. Note that toxic metals, insecticides, and herbicides are treated separately.\nToxic chemicals as addressed in this module should be listed as a candidate cause when potential human sources and activities, site observations, or observed biological effects support portions of the source-to-impairment pathways in the conceptual diagram for unspecified toxics (Figure 2). This diagram and some of the other information also may be useful in Step 3: Evaluate Data from the Case.\nThe checklist below will help you identify key data and information useful for determining whether to include unspecified toxics among your candidate causes. The list is intended to guide you in collecting evidence to support, weaken, or eliminate toxic compounds as a candidate cause. For more information on specific sources and activities, site evidence, and biological effects listed in the checklist, click on checklist headings or go to the When to List tab of this module.\nConsider listing toxic chemicals as a candidate cause when the following sources and activities, site evidence, and biological effects are present:\n- Non-point sources from industrial, agricultural, mining, logging, urban and residential activities, and related development\n- Historical sources and landfills\n- Spills and illegal dumping\n- Point source discharges from industries, municipal treatment facilities, animal husbandry operations\n- Odors, sheens, discoloration of water\n- Deposits on stream banks or bottoms\n- Abnormal levels of water quality characteristics such as pH, conductivity, hardness, or dissolved oxygen\n- Reports of past chemical spills or episodes of toxic releases, such as treatment plant failures\n- State, county records of pesticide applications, business operations\n- Abrupt increases in fish or invertebrate mortality\n- Other significant community changes, such as large reductions in species richness or abundance\n- Abnormal behaviors, such as fish leaping from the water, gasping at the surface, or crowding into tributaries\n- Gross pathologies not typical of pathogens, such as tumors, deformities, or sloughing of gill tissues\n- Appearance of new parasites, disease\n- Toxic effects in tests of effluents, ambient waters or sediments\nConsider contributing, modifying, and related factors as candidate causes when toxic chemicals are selected as a candidate cause. These factors can influence concentration and toxicity, and are important for understanding the dynamics of distribution and effects of toxic chemicals:']"	['<urn:uuid:a6a70f58-c2b3-4dce-b855-58371f98576f>', '<urn:uuid:15f925fc-02d0-4d6b-b552-781e84548aae>']	factoid	direct	verbose-and-natural	similar-to-document	multi-aspect	expert	2025-05-12T13:53:09.865574	27	65	1375
95	why river tiber important ancient rome	The River Tiber was important to ancient Rome because it was navigable from the sea inland, creating a highway for transporting goods, crops, and materials. The river also had natural crossing points at Tiber Island where gravel shoals allowed roads to cross.	"['Skip to 0 minutes and 0 seconds[THEME MUSIC]\nSkip to 0 minutes and 26 secondsWhy did this wonderful city grow so big, so rich, and so powerful? Well, one answer has to be the site that the early Romans chose to found their city. Rome famously is a city of hills-- the seven hills of Rome. Well, in fact, if you count them they are rather more than seven, and no one seems able to agree which seven you should include. But leaving that idea aside, we can say with confidence that this is a city of hills and valleys. Now, down in the city centre it\'s actually rather hard to tell that.\nSkip to 0 minutes and 51 secondsAnd if you\'ve got the experience of wandering around Rome, you might well have realised that over the years, as inundation from the Tiber, and years and years of continuous habitation and demolition, have raised the ground level up in places in the city. We\'ll see that the modern ground level is five or six metres above the ancient ground level. And that\'s why we\'ve come up here to this lovely Pincio hill on the northern edge of the city, with a wonderful view behind me. And you can see there that difference in elevation.\nSkip to 1 minute and 20 secondsSo thinking about the landscape of Rome, we have hills and we have the river valley. The River Tiber, navigable from the sea inland, up to this point, and well beyond here, creating a highway from the sea, inland for the transport of goods, crops, and materials. As well as transport by river, the site of Rome is well connected by land. A number of major routes passed through here or close by. And where the river shallows out into gravel shoals on either side of Tiber Island, there is a natural crossing point where the roads can get over, so it really is a pivotal point of connection. And really what these hills are, are spurs of a volcanic plateau.\nSkip to 1 minute and 57 secondsOver the years, tributary streams winding down to the main river, the Tiber, below us, have cut grooves or valleys in the side of this plateau, forming finger like spurs that are the hills of Rome-- the Aventine, the Palatine, the Capitoline, the Caelian, and so on. And these hills were where the earlier settlers decided to build their first habitations, because the hills offer lots of advantages. They are high up, they\'re defensible, they\'re away from enemies, from predators. So this place was in the perfect spot.\nSkip to 2 minutes and 23 secondsA transport hub, a nexus, a central point in this crucial, central part of Italy, where people coming and going, trading and settling, could gather and turn this city quite rapidly from a series of little villages into a town, from a town into a city, and eventually into a global superpower. It really is all in the location.\nSkip to 2 minutes and 51 secondsThe early history of Rome is complex and fascinating. But the evidence we have is limited and some of it conflicts. So to try and make sense of it, I\'ve come to this research academy, the British School at Rome, to talk to its director, Professor Christopher Smith.\nSkip to 3 minutes and 9 secondsSo, as we think about the city in this part of Italy, who are the first Romans and what do we know about them? It\'s likely that the first Romans actually thought of themselves, perhaps, as members of individual communities inside the city. We have evidence for settlement early on in the Palatine Hill, from say the eighth century BC. We\'ve the postholes of huts up there. We think we\'ve got evidence from some of the other hills to the Capitoline hill. There are beginning to be some quite interesting things on Quirinal hill. And this settlement, and some burial evidence, and some fortification evidence, would seem to suggest that there may be discrete communities on the each of the hills.\nSkip to 3 minutes and 53 secondsThat goes a long with priests that are connected with individual hills, and festivals that seem to be connected with individual hills. So we\'ve talked about the site of the city and you\'ve mentioned archaeological evidence like postholes and burials. But of course, there\'s also a rich literary tradition and mythical tradition about the origins of Rome. How do those two things fit together? It\'s a huge question about whether you can actually make a literary record map up to the archaeological record. What Romulus and Remus is said to do is to create a single community.\nSkip to 4 minutes and 25 secondsAt some stage, in the eighth century, you see a lot of investment of energy and effort into the Forum of Rome, which is the natural depression between the hills. From the 8th century onwards-- the idea of a synoecism-- a bringing together of these communities does seem to work. They develop tighter, and closer, and stronger senses of citizenship over time, and that what we think of as a city-state, where the broader community takes a strong position vis-a-vis families or individual communities.\nSkip to 5 minutes and 3 secondsSo these people, whether we call them Romulus and Remus, or we think of them as the inhabitants of this area, wherever they\'ve come from, they\'ve started fortifying the hilltops, growing into a town, developing themselves into a city-- but lots of places are doing this as we\'ve heard. So, what is it about Rome, in particular, that takes off, that grows to be a city that dominates the world. It has a couple of things that really work well. The river flowing through the middle of the city is useful for access for water. It\'s got good access down through to the sea.\nSkip to 5 minutes and 32 secondsIt sits on a good fording point across the Tiber, sufficiently far inland that if there\'s any piracy or any disruption from the sea, it\'s defended. But there are always two reasons why a city grows, and one of them is going to be about geography. The other one is going to be what you do with those natural advantages. It\'s clear that for some reason or another, Rome has a particular attitude towards allowing people to join its community, which allows it to grow its military strength in a way that other cities don\'t do. The classic Roman mechanism, when they conquer someone, is to allow them to be part of the Roman army as allies.\nSkip to 6 minutes and 13 secondsSo, as Rome begins to grow, by conquest of its nearest neighbours, at the same time it becomes stronger. So there\'s an ambition there, and that ambition is taking Rome to a very significant position amongst its peer-group.\nSkip to 6 minutes and 33 secondsHere\'s A Roman historian called Livy, who\'s putting a speech into the mouth of a figure in the city\'s history, explaining why the city is so well-located. ""Not without cause,"" he says, ""did gods and men select this place for establishing our city, with its healthful hills, its convenient river by which crops would be floated down from the midland regions, and foreign commodities brought up,"" --so that idea of trade and transport again. ""Yet sea, near enough for use, yet not exposing us by too great propinquity to peril from foreign fleets. A situation in the heart of Italy, a spot, in short, of a nature uniquely adapted for the expansion of a city.""\nSkip to 7 minutes and 8 secondsAnd expand it certainly did, from this tiny on edge villages, growing out on the separate hilltops, down into the valleys, where the marshes were drained and the ground paved and made good for building-- we\'ll see that in the Forum-- eventually expanding to a city of a million or so people, maybe three to five kilometres across. They can never get too big because they didn\'t have motorcars, they had to walk everywhere. So the Ancient City is actually quite compact and we can stroll around it, but nonetheless, by ancient standards, in terms of the size of its population, a huge, densely-inhabited, teeming city, pullulating with human life and activity.\nSkip to 7 minutes and 42 secondsThose hilltops, where the early settlers lived, took on a sense in the later city, the imperial city, of being elite residences. The cool breezes, the healthful air, the views, all of these meant that this was the place where the elite Romans, the emperors on the Palatine, built their villas. In the valley bottoms, the busy arterial roads, all those roads leading to Rome and from Rome, carrying people, waggons, carts, and goods, along the roads out of the city. And down in those valleys, crowded apartment blocks, street corners, fountains, warehouses, shops, restaurants, the everyday Rome where most people went about their daily lives. [THEME MUSIC]\nPart I – ‘Not without cause did gods and men select this place for our city’\nRome is a city of hills and valleys. This, together with the River Tiber, must have been important reasons why the area’s first inhabitants chose to settle there. In this video, I explain why ‘it’s all in the location’ and how this landscape was pivotal to the early success and expansion of ancient Rome.\nI also meet with Professor Christopher Smith, former Director of the British School at Rome, to ask what we know about these early inhabitants through archaeological.\nAs you watch this video, you may like to consider the following topics:\nWhy do you think the Romans told so many stories about their original founders?\nWhat does Livy’s paragraph tell us about the importance of communication networks to ancient Rome?\nShare your thoughts on these discussion points in the comments area below.\nLater this week, you’ll investigate just how important the transport links I mention in the video, were to the expansion for the Roman empire.\n© University of Reading']"	['<urn:uuid:efa02ea3-5412-4e8d-b369-abcc0032948b>']	factoid	direct	short-search-query	similar-to-document	single-doc	novice	2025-05-12T13:53:09.865574	6	42	1682
96	what equipment needed for outdoor work protection gear and business insurance coverage details	For outdoor work protection, essential equipment includes proper safety gear like protective headwear/veils and backup tools/spares. For business protection, you need general liability insurance which covers bodily injury, property damage, medical payments, and legal defense costs. A business owner's policy (BOP) combines liability coverage with commercial property insurance and business interruption insurance. Professional liability insurance is also important to protect against negligence claims. Workers' compensation insurance is typically required if you have employees, and commercial auto insurance is needed for business vehicles.	"['Recently I had just two minutes to gather my thoughts after being asked to give a talk about ‘preparing for an apiary visit’ at a training program. There are many days when I work bees, but I rarely think much about ‘preparing’ for the visit since I keep bees near the barn where just about everything I hope I will ever need is stored and can be located with a minimum of searching. This sense of security sometimes shatters when I am teaching or visiting in another location, and need to rely upon what I have in my vehicle, or what is on hand at the host beekeeper’s site. Sometimes what I need is nowhere to be found. To prevent this we all need to have a few containers of items we need in the apiary, the contents will vary by the job at hand.\nMost of us MUST have a minimum list supplies when we are in an out-apiary. My list is this:\n1. Smoker, fuel and matches or lighter. I have found more and more beekeepers who never use smokers. Yes, I agree that smokeless colony inspections encourage careful hive manipulation technique, but too often I have seen dangerous situations—to bee and beekeeper—when beekeepers don’t use smoke. The most stings I have ever received have been those times when no smoker was lit! Most of the time I don’t win the argument that I can get into and out of colony before the bees notice. Somehow they know someone was messing in their hive and that I was the person doing it. They reward me with venom therapy.\nI argue that the proper use of smoke saves bees, as you can use smoke to move bees from the ends of frames as you work a hive, and reduce the piles of bees in strong hives that develop when hive bodies and supers are taken off the hive and later reassembled when the inspection is complete. Rather than crushing hundreds of bees, a little smoke removes the pile of bees and minimizes their slaughter.\nSmoke interferes with bee-to-bee communication and stimulates bees to engorge with honey and become less defensive, and thus less likely or able to sting. When I teach I insist on having a smoker lit that is large enough to produce smoke for 45-60 minutes minimum. My three favorite fuels are white or Southern pines needles, untreated bailing twine, and untreated burlap. A roll of wax paper provides a paper product that will light under most conditions (even when raining), followed by one of the three other materials. I avoid cardboard and other products that produce acrid smoke. I know that I have to breathe this smoke, so some dried herbs provide a nice finish to the smoke. There are folks using gas torches and small electronic devices to light their smokers. It’s great to see these new ideas that simplify smoker lighting and guarantee smoke when you really need it.\n2. Veil. I use a headpiece veil all of the time. I didn’t always, but lately the bees seem to see my large, balding head and aim for the eyes. When I get stung around the eyes I do a pretty sad imitation of a puffer fish. So now it is easy on and easy off with the veil. A jacket and veil combo is great when the weather is cool. It also provides extra pockets for queen cages, if needed. (That reminds me that I need to soak my veil in a soap and non-Clorox bleach solution over night to get rid of some staining and spotting. I do like white veils!) Why not keep a spare in case you have someone visit who offers to help lift supers!\n3. Hive tool and maybe a spare for your helper.\nYard toolbox or kit\nMake up a bucket or tool box to hold a more extensive list of items you may need in the apiary, and will have on hand ‘just in case.’ There are some ‘bucket belts’ sold at home improvement you may want to consider. There are some great tool belts that you could wear around your waist if it doesn’t make your pants ride around you knees.\nHere is a list of items that make sense:\n- Water-tight container of fuel and matches\n- Veil, maybe a spare.\n- Hive tools (2) and a small hammer for those well glued hive bodies\n- Empty queen cages, with candy or marshmallow, to confine an extra queen (swarm queen, or any ‘extra’ queen you find).\n- Marking pen for new queens (yellow in 2012).\n- Apiary notebook or clipboard.\n- Permanent marker to record data on hive lid or pencil for writing in your notebook (pen ink often fades when it gets wet, which it will).\n- Plastic bags for samples for examination at home, or to ship samples of suspected disease to the USDA Beltsville Bee Lab for analysis.\n- Bee brush or soft paintbrush to remove bees from comb or queen cells.\n- A hive body and super (if different sized) and frames and …', 'All businesses, regardless of industry, face risks that should be covered by insurance. The most common and comprehensive type of policy business owners invest in is general liability insurance (or CGL).\nSome of the risks CGL insurance covers are:\n- Bodily injury\n- Property damage\n- Medical payments\n- Legal defense and judgment\n- Personal and advertising injury\nWhile businesses aren\'t legally required to carry general liability insurance, operating without it is extremely risky. If your business is sued, you could end up facing fees totaling hundreds of thousands of dollars (or more). Having a sufficient CGL policy in place to help compensate for these damages is the only way to prevent this type of event from devastating your business.\nLearn more about the risks covered by general liability insurance.\nCOMMON SITUATIONS THAT GENERAL LIABILITY INSURANCE WOULD COVER FOR A DRONE PHOTOGRAPHY BUSINESS\nExample 1: You are taking photographs of a wedding party with your drone when you lose control of it. The drone crashes into the bride, causing her serious injury. She sues your business. Your general liability insurance policy will cover the cost of your legal defense, including the cost of settling out of court if it is necessary to do so.\nExample 2: A potential client is visiting your place of business to see your drones when he trips over a power cable and falls. He breaks his wrist and requires medical care. He asks that you pay for his medical treatment. Your general liability insurance policy will likely cover this cost.\nExample 3: You have been using a new logo for your business that you feel really represents it well. Unfortunately, another business decides that your logo is too similar to their own and sues your company. The general liability insurance policy you carry will pay for your legal defense in such a situation as well as cover the cost of any settlement.\nOf course, this is not an exhaustive list of perils a general liability insurance policy will cover, and some conditions may result in a particular peril not being covered. It\'s always best to talk to your agent in-depth about the specifics of your policy to avoid blind spots in coverage.\nOn average, drone photography businesses in America spend between $300 - $600 per year for $1 million in general liability coverage.\nCheck out the chart below for a snapshot of average CGL expenditure across a variety of industries:\nSeveral factors will determine the price of your policy. These include your:\n- Number of employees\n- Per-occurrence limit\n- General aggregate limit\nYou may be able to acquire general liability insurance at a discounted rate by purchasing it as part of a business owner\'s policy (BOP) rather than as a standalone policy. A BOP is a more comprehensive solution that includes multiple forms of coverage, such as business interruption and property insurance.\nWhile general liability is the most important type of insurance to have, there are several other forms of coverage you should be aware of. Below are some other types of insurance all drone photography businesses should obtain:\nProfessional Liability Insurance\nA professional liability insurance policy offers protection specific to your business for liability related to negligence claims due to mistakes or failure to perform. There is always the possibility that a client could claim that your work caused him or her injury and sue your business. If this happens, your professional liability policy will pay for your legal fees.\nCommercial Property Insurance\nYou have invested a lot in your drones, photography equipment, and editing equipment. If you were to lose most or all of this property due to an unforeseen disaster like a fire, it would be costly to replace. But if you have a commercial property insurance policy, you can likely get help with replacement costs as long as your loss was caused by a covered event.\nIn addition to the policies outlined above, there are a few other types of coverage your drone photography business may require depending on certain aspects of your operations. Some of these might not apply to you, so be sure to ask your agent which policies are right for your business.\nWorkers’ Compensation Insurance\nIf you have employees, your state most likely requires you to carry workers’ compensation insurance. A workers’ comp policy provides much-needed protection for your employees if they are injured performing job-related duties. If they are hurt and need medical care, the workers’ comp policy will pay for that treatment. It will also help to pay for the lost wages that they miss out on while recovering from their injuries.\nCommercial Auto Insurance\nIf you have an automobile that you use primarily for business, you need a commercial auto policy to ensure that you meet the legal requirements for auto insurance in your state. Your policy will help to pay for damage to your vehicle and other vehicles if you are in an accident, and it will pay for medical treatment for the injured as well.\nAlthough it\'s easy (and essential) to invest in business insurance, it should not be your frontline defense. Yes, insurance will compensate for your business\' financial losses after an incident occurs, but it\'s much better to avoid losses altogether.\nWith this in mind, here are three things you can do to better protect your business:\n- Use legally robust contracts and other business documents. (We offer free templates for some of the most common legal forms.)\n- Set up a limited liability company (LLC) to protect your personal assets. (Refer to our guide for step-by-step instructions on how to form an LLC in your state.)\n- Streamline your business\' internal processes. This will remove unnecessary variables from common tasks and create a safe, consistent environment for conducting business.\nWhat is included in a business owner’s policy?\nA typical business owner\'s policy includes general liability, business interruption, and property insurance. However, BOPs are often customizable, so your agent may recommend adding professional liability, commercial auto, or other types of coverage to your package depending on your company\'s needs.\nWhat is the difference between business insurance and general liability insurance?\n""Business insurance"" is a generic term used to describe many different types of coverage a business may need. General liability insurance, on the other hand, is a specific type of coverage that business owners need to protect their assets.\nDo I need insurance before I start a business?\nYou should invest in coverage for your business before your first interaction with a customer. Although the cost of insurance may seem high for a brand new business, it\'s best to be proactive when it comes to protecting your assets. After all, you can\'t buy insurance to cover a loss that has already occurred.\nWill insurance protect my business from everything?\nNot necessarily. Certain exceptions may be written directly into your policy, and some perils may be entirely uninsurable. Be sure to discuss the scope of your policy in-depth with your agent to avoid being blindsided by holes in your coverage.']"	['<urn:uuid:42d93f0a-94ac-49c2-832d-47fe0fa6ae8d>', '<urn:uuid:101248c1-1c86-49af-9d1e-0ce110fe2eea>']	factoid	with-premise	long-search-query	distant-from-document	multi-aspect	novice	2025-05-12T13:53:09.865574	13	82	2023
97	romance languages vs viking speech origin	Romance languages emerged from Vulgar Latin dialects that developed during the Middle Ages into distinct languages like Portuguese, Spanish, and French, spreading throughout the Roman Empire. In contrast, Vikings spoke Old Norse, a North Germanic language used in Scandinavia and their overseas settlements from approximately the 7th to 15th centuries.	"['Although selected through an inherently inexact process, prize-winning texts are more likely to embody general characteristics of literature than bestsellers of genre fiction (e.g., romance and.\nIn addition, there is a module introducing students to the grammatical systems of certain less-studied Romance languages. Students deepen their linguistic knowledge and analytic skills by applying what they have learned in other Linguistics courses to this language family, and learn how data from Romance languages have contributed to our understanding of how language works in general.\nthe inclination is that Dari is spoken when people from these two linguistic backgrounds communicate between them. Bahry (2013) adds that such an “asymmetrical bilingualism” is seen not only between.\nThe conceptual side of value is made up solely of relations and differences with respect to the other terms of language, and the. 118. same can be said of its material side. The important thing in the word is not the sound alone but the phonic differences that make it possible to distinguish this word from all others, for differences carry.\nThe principle difference between PSYOP and IO is. In the coldly abstract language of Information Operations, civilian casualties were regarded merely as “IO challenges.” As Lieutenant-General Metz.\nFrench is a Romance language , but it has a number of characteristics that set it apart from the other members of its linguistic family. Here is an extremely simplified synopsis of its development: There has always been an important linguistic difference between the north and south of France.\nSocial Media Has Its Own Linguistic Style Jan 18, 2019. Here\'s our list of the must-know social media trends for 2019 that your. While every network has its own native analytics, no social media. Colleges With Mass Communication Media Studies Major The Edward R. Murrow College of Communication has three distinct academic fields of study in our undergraduate program: Communication & Society, Journalism & Media\nAquinas On Simplicity: An Investigation Into The Foundations Of His Philosophical Theology Yale School Of Public Health Academic Calendar Master of Public Health (M.P.H.) · Why an MPH?. Academic Support. Professor of Clinical Public Health. MPH, Yale University School of Medicine DrPH. Cornell\'s colleges and schools encompass more than 100 fields of study, with locations in Ithaca, New York, New York City and Doha, Qatar. General Board Higher Education And\nCollege Search: Romance Languages, Literatures, and Linguistics, Other Majors Years. 4 year. 2 year. Type. Public Private Private For-Profit. X Romance Languages, Literatures, and Linguistics, Other Majors C. University of Chicago. Chicago, Illinois • Private 4 Year.\nSteven Pinker’s essay is itself. ""Science, after all, is a branch of literature; and working on science is a human activity like building a cathedral,"" he wrote. ""Labouring the difference between.\nEnormously popular with college students, the show is a hot topic in classrooms, where it offers lessons in areas as diverse as story structure, languages and cultures. So how much of a difference.\nBy the 1980s most or all of these names would make up a virtually common syllabus of graduate studies in French, English, and most other modern languages and comparative literature departments.\nThe British Academy covers the humanities (archeology, classics, literature. between complex behaviours like altruism, aggression, intelligence, mathematics or language, on the one hand, and.\nThe null hypothesis is that there is no difference between. but also other knowledge, such as the visceral pleasantness of flowers or the gender distribution of occupations. These results lend.\nThe Romance languages derive from Vulgar Latin. As and after the Latin language spread throughout the Roman Empire, it separated into dialects. Those dialects eventually came to diverge during the Middle Ages into distinct languages that we know today as Portuguese, Spanish,\nOne must grant that there are patent problems in making general use. for all of J. The other problem with the theory is linguistic, an issue to which the German scholars have paid scant attention.\nDec 16, 2010 · Finally, language has other characteristics such as Duality referring to the two systems of sound and meaning, Displacement which means the ability to talk across time and space, Humanness which means that animals cannot acquire it, Universality which refers to the equilibrium across humanity on linguistic grounds, Competence and Performance which means that language is innate and.\nThis summer in Paris, a French Army general handed me a missing piece of the puzzle. Serval trumpet the “return of Airland Maneuver in Depth.” A key difference, of course, between Barrera and.\nMar 06, 2015 · Because it belongs to the group of languages called Romance Languages. The group also includes French, Spanish, Portuguese, Romanian, Catalan and some others. They are called so because they take their beginning from Roman Empire and share many fe.\nDiscuss the differences between the first column. and how this identity differs from that of most other nations, which often base their identity on such things as ethnicity, race, religion, class,\nChapter 5: Language. A literary tradition is A) a form of a language used for official government business. B) a form of a language spoken in a particular area. C) a collection of languages related to each other. D) the written form of a language. E) the variety of dialects in a language.\nIt has been emphasised that they were just one of many ethnic and linguistic groups centred in the. requiring an ancient language A-level, than any other subject: between 2012 and 2014, for the.\nI learned, for example, that I do not have to move closer and closer during a conversation as the other. between Americans and Russians in the understanding of space and time, values and.\nLiterature and Linguistics Tracks We are especially proud of having literature and linguistics tracks for our graduate program. The University of Florida is one of the rare institutions in the country to offer advanced degrees in French linguistics.\nThe average total number of students of all degrees engaged in this specialty is 34 or more and 29.4% of students are men. 11.8% of students studying the Romance Languages, Literatures, and Linguistics program are non-residents of the United States. Amherst.\nOver 1000 languages, or 15% of the world’s languages, are spoken in the Pacific (primarily in Melanesia). So you can see that it’s difficult to answer such a broad question. In general, excluding the Papuan languages of Papua New Guinea (and 4 in the Solomons), all Pacific languages are Oceanic, so they are part of the same family.\nIntroduction to the formal analysis of human language, including sounds, words, sentences, and language meaning, plus child language acquisition, language change over time, social attitudes toward language, and similarities and differences among languages. Other topics may include writing systems, animal communication, and language analysis by computers.\nAlong with other great Italian names. about Cremona fiddles, and the difference between a Stradivarius and an Amati”. Certainly, he demonstrated the same Victorian collector’s enthusiasm as Mr.\nThe creatures, he says, talk to each other using ""the most sophisticated animal language that has been decoded."" The animals have word-like phonemes, combining those into sentence-like calls. They.\nIn the United States and an increasing number of other countries around the world (e.g. Singapore, Israel, Korea, Malaysia, Philippines and others), there is in addition to specific exceptions a.\nThey will also develop expertise in the linguistics of two other Romance languages and specialize in an area of general or applied linguistics. This, together with some basic training in Latin, will prepare them for the comparative Romance linguistic work that is required for the Qualifying Examination.\nRomance Languages (B.A.). They are encouraged to take as much work as possible in the literatures of other languages, both ancient and modern, as well as in history, philosophy, linguistics, art, and music. Students may also take courses in Italian language, literature, and culture in the Wayne summer program in Gagliano Aterno, Italy.\nIn his general linguistics. it’s the language of the other,” said Alghbban, who is obviously an advocate of the peaceful approach. “One cannot be blamed for being Jewish or speaking Hebrew,” he.\nDescribe What Ethnography Entails Pdf – definition of the ethnography and briefly naming a few distinctive characteristics of the ethnographic approach, which basically comprises conducting interviews and doing fieldwork – three perspectives from which one could look at the advantages and disadvantages of adopting an ethnographic approach to. Where the project is interdisciplinary or team-based, these may be co-authored. Alternatively, they may describe\nThe linguistic study of word structure and how this relates to other components of the grammar of a language (phonology, syntax, semantics). Theoretical issues and problems in the study of morphology will be discussed in connection with the analysis of data from a wide variety of languages.\nIf Boym’s biography oscillates between. linguistic backgrounds. Through readings of Soviet and post-Soviet art, literature, and everyday cultural production, she meditated on how we refashion.\nMark Amengual Bilingualism and language contact, acoustic phonetics, sociophonetics, second-language acquisition, language variation and change, Spanish and Romance linguistics Bryan Donaldson Word order variation in second-language French, medieval French and medieval Occitan through the lens of.\nThis community area is for Foreign language & Linguistics, which is a category of majors that includes ""Germanic Languages, Literatures, and Linguistics, Other"". The complete list of specific majors that fall under this general category follows below.', 'What was the main reason for the fall of the Western Roman Empire?\n1. Invasions by Barbarian tribes. The most straightforward theory for Western Rome’s collapse pins the fall on a string of military losses sustained against outside forces. Rome had tangled with Germanic tribes for centuries, but by the 300s barbarian groups like the Goths had encroached beyond the Empire’s borders.\nWhat are the economic reasons for the fall of the Western Roman Empire?\nRome fell through a gradual process because poor economic policies led to a weakened military which allowed the barbarians easy access to the empire. In the third century, Rome’s emperors embraced harmful economic policies which led to Rome’s decline. First, the limitation of gold and silver resources led to inflation.\nWhy did the Byzantine Empire survive and Western Rome fall?\nIn any case, the Byzantine Empire managed to survive after the decline of the Western Roman Empire due to a number of advantageous circumstances. Combined with a lack of mass Germanic migration into their territories, the Eastern Roman Empire was thus in a much better position to survive the collapse of the Empire.\nWhat were three problems that led to the fall of the Western Empire?\nThe Roman Empire lost the strengths that had allowed it to exercise effective control over its Western provinces; modern historians posit factors including the effectiveness and numbers of the army, the health and numbers of the Roman population, the strength of the economy, the competence of the Emperors, the internal …\nWhy did Constantinople survive for so long?\nThe main reason why the Eastern Roman Empire lasted for nearly 1000 years after the fall of the west is because it was simply impossible to breach the walls of Constantinople until the advent of gunpowder artillery. Constantinople had 3 layers of defensive walls and a large moat.\nWhich empire lasted the longest?\nEastern Roman Empire\nWhat enabled Byzantium to last for so long?\nWhat made the Byzantine Empire rich and successful for so long, and why did it finally crumble? Constantinople sat in the middle of a trade route,sea and land. Its wealth came from trade and its strong military. Constantinople remained secure and prosperous while cities in western Roman empire crumbles.\nWhat language did they speak in the Byzantine Empire?\nThough Byzantium was ruled by Roman law and Roman political institutions, and its official language was Latin, Greek was also widely spoken, and students received education in Greek history, literature and culture.\nWhen did they stop speaking Latin?\nTo oversimplify the matter, Latin began to die out in the 6th century shortly after the fall of Rome in 476 A.D. The fall of Rome precipitated the fragmentation of the empire, which allowed distinct local Latin dialects to develop, dialects which eventually transformed into the modern Romance languages.\nDid Romans speak Italian?\nOriginally Answered: Ancient Romans spoke Latin. Modern Italians speak Italian. In fact in different regions, where different invaders settled, they bring different “dialects” even if in those times they were only variations from basic Latin.\nWhat language did the Vikings speak?\nOld Norse, Old Nordic, or Old Scandinavian was a North Germanic language that was spoken by inhabitants of Scandinavia and their overseas settlements from about the 7th to the 15th centuries.\nHow do you say I love you in Viking language?\nek elska þik An affirmation of romantic feeling to a lover or spouse.\nDid Vikings marry English?\nThe Vikings most likely married into Anglo-Saxon families over time, yes maybe the children of the Scandinavians were raised by Anglo-Saxon servants, as was the case among white American children in the southern states, where African slaves took care of white children.\nWho was the greatest Viking?\n6 Viking Leaders You Should KnowRollo: First ruler of Normandy. Erik the Red: Founded Greenland’s First Norse Settlement. Olaf Tryggvason: Brought Christianity to Norway. Leif Eriksson: Beat Columbus to the New World by 500 years. Cnut the Great: England’s Viking King. Harald Hardrada: The Last Great Viking Leader.\nWhat religion were the Vikings?\nViking Religion and Beliefs. The ancient Norse Vikings had what was commonly known as a pagan religion. This means that they had a religion that was not one of the primary religions like Christianity, and they did not acknowledge those religions or their belief systems.']"	['<urn:uuid:dc3f7232-959e-475e-8007-9085ada23f80>', '<urn:uuid:e0fa0155-05e4-4715-bf60-807964608834>']	open-ended	direct	short-search-query	distant-from-document	comparison	novice	2025-05-12T13:53:09.865574	6	50	2261
98	online fundraising platform options nonprofits internal recordkeeping rules maintain compliance	For online fundraising, nonprofits can use platforms like GoFundMe, which allows organizations to raise money for specific campaigns, sell tickets and collect event registrations. Donately offers fundraising tools to accept online gifts from any location. For internal compliance, nonprofits must maintain thorough records including annual board meeting minutes, updated bylaws, conflict of interest policies, financial performance reviews, next year's budget, and elections for officers and directors. Good recordkeeping is essential for audits and donor confidence.	['A non-profit is defined as an organization that exists to take donations, providing a service for their constituents, or people who use that nonprofit. You have to file to start a nonprofit at a state and federal level, while at the same time defining and implementing policies and procedures that your nonprofit needs to design in order to make success happen. Nonprofits hold a tax-exempt status in the eyes of the IRS. It is necessary to consult a local attorney or an accountant who understands what a nonprofit does in your state. You need to know about how charitable organizations are formed within your state’s legal structure.\nEach state has a specific method of incubating your nonprofit idea in a way that is practical for fundraising and less expensive. There are at least five steps that require making a decision for your nonprofit idea. The very first step in starting a nonprofit using crowdfunding is to research what your community needs in a nonprofit. There are 1 million nonprofits in operation in the United States that are considered charitable organizations that struggle to attract funding.\nNonprofits are bound by specific rules that they cannot make a profit off of their services, which is why it is called a not-for-profit organization. There are potential risks with different ways of making money if you do not know the rules surrounding how to raise money. Indiegogo and GoFundMe help raise money by allowing a non-profit to broaden their support system since an organization can operate in one city and receive their funds from another city in another state precisely because of their fundraising objective.\nThirty-nine states and the District of Columbia have various laws governing charitable solicitation, which is technical jargon for a gift a nonprofit receives that is going to be used by that nonprofit for charitable purposes, such as getting the homeless toiletries. Some states do require a nonprofit to register their intent to get charitable solicitations in that state. As an example, California does not require registration until the funds or property are received, while thereby the nonprofit must register within 30 days of receiving charitable assets that will be used to further the goals of the nonprofit.\nFailure to register a nonprofit could lead to civil and criminal punishments that vary across states, with potential penalties including state fines. The nonprofit has to then return all solicited funds. Crowdfunding platforms such as Donately offer a solution for a nonprofit to launch specifically tailored-to-their-needs campaigns. Donately offers a stress-free way to start a campaign. Donately has created a simple way to launch a crowdfunding campaign. Donately offers fundraising tools to accept gifts online, letting your team process donations from any location you see fit. Donately takes a 3% fee from the first $100,000 and they also have a credit card processing fee of 2.9% + $0.30 for each donation made. The ACH processing fee is 0.8% with a cap of $5.00. ACH refers to an electronic payment from an originating institution.\nThe rules for using online fundraising platforms for non-profits are determined by the solicitation requirements present in each state. The Charleston Principles mean that a nonprofit has to be registered for online charitable solicitations while the nonprofit solicits donations through what is called an “interactive website” such as GoFundMe. Nonprofits have to follow up with their donors through email or a paper letter that verifies the tax-deductible donation because of targeting a resident of that state, which would make the registration requirement fall into place.\nGoFundMe For NonProfits\nGoFundMe for nonprofits gives nonprofits the option to raise money for specific campaigns, while also given that they sell tickets and also collect registration for events. Nonprofits want fundraising tools that match the branding they have put together, Paypal also has a donate button option. A nonprofit called March for Our Lives raised $3,531, 110 on April 12th, 2018, after the Stoneman Douglas High School Shooting by Cameron Kasky for a march, the funds going to the victims of the shooting. Nonprofits are governed by many rules that a founder of a nonprofit has to learn in order to make sure that the nonprofit is being adequately funded. However, GoFundMe may take a large chunk of fundraising profits from organizations it is raising money for. GoFundMe is effective as a fundraising tool however because it defines the very idea of fundraising being able to raise more money online than through other, snail mail derived methods of fundraising. Raising the money necessary for a nonprofit has become easier these days with the Internet but nonprofits need to be aware of the rules in each state that governs having a nonprofit status acknowledged by the State the nonprofit is started in. Fundraising for a nonprofit is governed by many rules as it is a tax deduction.', 'By James Gilmer\nAs the end of the year approaches, it’s time to take stock of your nonprofit’s compliance requirements of the past year and also to begin planning for the year ahead. Nonprofits are held to high standards of government regulation and public oversight, so staying compliant is critical to keeping your nonprofit running smoothly.\nNonprofits are commonly required to manage multiple requirements across federal and state government agencies, and also to maintain documentation in the event of an inquiry or audit. Compliance can be generally grouped into two categories: filings that are submitted to government agencies and records that should be kept internally.\nThe following is a brief overview of the tasks that most nonprofits must complete at the end of the year. Keep in mind that not all of these items will apply to all organizations and that this list is not exhaustive.\nYour nonprofit is required to file reports periodically with the Secretary of State in which it is incorporated and any states it is qualified as a foreign corporation. The annual report updates the public records with changes to your nonprofit’s address, registered agent, and leadership each year. Report due dates vary by state, so pay attention to your state’s deadline and check if you have filed your most recent report. If your nonprofit is registered in multiple states, make sure you have adequate systems in place to track the various due dates. Failure to file periodic reports can incur steep penalties and result in your nonprofit’s registration being revoked.\nYour nonprofit is also required to maintain a registered agent in each state where it has registered to do business. If you have appointed individuals, make sure they are aware of their appointment and can reliably serve as your nonprofit’s agent. If you have appointed a registered agent service company, make sure you renew your service.\nLastly, conduct a review to see if qualification (Secretary of State registration) is necessary in any other states. Common reasons include hiring a new employee, purchasing property, opening a physical location, and as required to meet state charitable solicitation requirements.\nState Fundraising Compliance\nDepending on your state and fundraising activities, your nonprofit may be required to register with the state’s Attorney General for charitable solicitation (a.k.a. fundraising). You generally have to renew this registration annually, so make sure you have filed this year in each state. Failure to register or renew can again lead to strict penalties. Most importantly, your donors can and do search state databases to see whether your charity is legitimate.\nFundraising registration and renewal is a complex topic, and your individual requirements will vary depending on your finances and activities. For more state-specific information, you can review this Fundraising Compliance Guide. At the end of the year, review your fundraising activities, including specific initiatives and all states in which you ask for contributions. Having done so, it is possible you need to register in one or more states, or to file a renewal shortly after your fiscal year ends.\nIRS Compliance and Form 990\nEvery year, your nonprofit must file a return with the IRS, known as the “990.” There are several versions of the 990 return, and the form you file depends on your organization’s revenue. It updates the IRS with changes to your leadership, contact info, mission, activities, and finances.\nIRS Form 990 is due each year exactly four months and fifteen days after the end of your fiscal year. For nonprofits on a calendar year, this is May 15th. Failure to disclose your organization’s information in full, or failure to file at all can lead to a loss of your hard-earned federal tax exemption and/or penalties that accumulate daily. By the way, if you have incorporated in this fiscal year, and you have yet to receive your 501(c)(3) determination, you still must file IRS Form 990, or you can jeopardize becoming tax exempt from the outset.\nInternal Compliance and Recordkeeping\nIt’s important to keep thorough records of meetings, and changes to your organization, leadership, and activities. Not only will good recordkeeping help you stay organized, but it may come to your defense in the event of an audit. Your individual list will vary, but here is a brief list of items to review annually:\n- Hold annual board meeting, and keep minutes\n- Ensure bylaws are in place and up to date\n- Review all policies, including conflict of interest and executive compensation policies\n- Conduct financial performance review and reporting\n- Create and approve next year’s budget\n- Hold elections for officers and directors\nNot only does the IRS want you to keep good records, but your donors may as well. For instance, if you apply for a grant, or are trying to gain the support of a prominent donor, they may request records, including financial statements. Being able to readily produce such records help your donors to feel secure in their gift to a responsible, compliant organization.\nThe Value of Compliance\nWe’ll admit, “end of year compliance” is a bit of a misnomer. Compliance responsibilities are ongoing, from constant recordkeeping to staggered due dates of government applications and renewals, so make sure you have the right people and systems in place to manage it all. However, many of these activities coincide with preparing the 990, so the end of the year is a logical time to conduct a full review of compliance and plan for the year ahead. With a proactive approach to meeting the requirements briefly outlined in this article, your nonprofit will set itself up for success in the year ahead.\nStaying compliant adds tremendous value to your organization. Staying in good standing with the state and the IRS will avoid loss of tax exemption, and loss of limited liability protection for the officers and directors. Perhaps most importantly, donors, foundations, and other contributors want to give to responsible, credible, and fully registered organizations. By choosing to stay compliant, you make choosing your organization much easier for them!\nJames Gilmer is a compliance specialist for Harbor Compliance, which establishes 501(c) nonprofits and helps them stay compliant. Harbor Compliance assists charities in every state and several countries abroad. James serves on the Board for two nonprofits in Lancaster, Pennsylvania.']	['<urn:uuid:7c5e3f60-912c-4717-b2d2-93c242ec2709>', '<urn:uuid:b3eb6d28-e478-47a1-958f-80ca8179e254>']	factoid	direct	long-search-query	distant-from-document	multi-aspect	expert	2025-05-12T13:53:09.865574	10	75	1843
99	structural engineer interested in fire safety and wind resistance compare ferrari world abu dhabi and burj al arab protective design features against environmental factors	Ferrari World and Burj Al Arab employ different protective design features. Ferrari World uses a modular unitised facade system with prefabricated glass panels in steel trusses, incorporating double trusses and movement joints to address seismic and thermal issues. Its smoke management treats the 40m high enclosure as 'external space' with natural venting through the roof. For wind resistance, Burj Al Arab features a double curve membrane design with PTFE-coated fiberglass containing air gaps at regular intervals, plus expansion joints on the right side to handle wind pressures and horizontal stresses. Both buildings underwent wind studies - Ferrari World conducted wind pressure and tunnel testing, while Burj Al Arab's specific geometry and sail-boat design helps protect against changing wind loads.	"[""Ferrari World in Abu Dhabi is the World’s only Ferrari theme park. Sixty of our engineers worked on the four-year project and were involved in every aspect of the park's unique design from concept to completion.\nThe leisure oasis of Yas Island is 25 sq km in area, with a beach front shoreline of some 30km. This is the home of the vast theme park as well as a retail complex and Formula One racetrack.\nThe theme park project was driven by its fast track design and construction programme, and using our engineers and specialists across Ramboll's network of offices, we provided a responsive service that ensured that the tight programme challenges were met.\nOur early involvement with the theme park focused on the schematic design of its 90,000 sq m roof. Below the roof are three concrete frame levels — the undercroft at ground level, a mezzanine and the Plaza level, where most of the Ferrari-themed attractions are located. Columns are set on a grid of 10.75m x 8.65m, matching the piling grid below. This supporting structure takes the weight of the 19 separate steel frame buildings that house the rides.\nWhile the lower part of the structure is open to the air, the Plaza level is enclosed. Our façade engineers worked on this and the glass funnel at the centre of the roof. Two sets of huge rollercoasters are located at the roof's extremities and we are engineering their foundations and station buildings.\nFerrari World theme park is a central feature of the Yas Island leisure oasis. Our building services engineers worked on concept design for the project and have further liaised with the theme park designers over detail design, helping to insure the integrity of the concept through to completion.\nOur brief involved the park’s internal spaces — an area of some 200,000 sq m accommodating an array of Ferrari-themed attractions at Plaza level. At 45 MVA, the power requirement is significant. Co-ordinating closely with the local authority, we developed a robust solution that incorporates a chain of substations to ensure continuity of supply and protect existing infrastructure from any undue pressure.\nVentilation design for the scheme faced the specific local challenges of high temperatures and concentrations of sand in the air, as well as increased humidity caused by indoor water rides. Our solution uses low-level outlets for both displacement cooling and ventilation. Internal temperature control is further supplemented by a slab cooling system that uses chilled water available from Abu Dubai’s existing district cooling system.\nThe fast track programme was the key driver in engineering the plaza level façade of the Ferrari World theme park. A modular unitised system accelerated construction while being economical, simple and effective.\nThe external façade slopes outward and graduates in height from 20m to 12m. Prefabricated glass panels with aluminium frames have been set within steel trusses every 10m. Double trusses and movement joints were introduced following the joint location in the slab because of Abu Dhabi’s seismic and thermal issues.\nA steel frame forms the basis of the 30m high, 100m diameter funnel-shaped roof glazing around a ride in the centre of the plaza. A secondary aluminium unitised frame holds the glass panels in place. Repetition of the panels, all around 2m x 2m in size, minimised manufacture, transport and handling costs. Steel bracings spiral up the funnel giving the impression of an opening flower.\nSolar radiation studies were conducted using software that calculates the amount of energy heating façades based on daily sun positions. This was used to determine the optimal shape and position of louvres to shade or reduce glare. A series of these fitted to the external façade resemble the front grill of a Ferrari. Folded triangular plates are fitted to the top of the funnel, which receives the most extreme radiation.\nOur building services team used the solar studies to optimise energy use throughout the year. Our façade engineers assisted with wind pressure and wind tunnel testing.\nfire & safety\nRamboll provided a full range of engineering services for the design of Ferrari World – the enclosed F1 theme park in Abu Dhabi. One of Yas Island’s central features, the park has 25 rides and attractions under its 200,000 sq m iconic roof and a maximum capacity for 12,000 occupants. Using National Fire Protection Association (NFPA) standards, our fire engineers undertook a 'Life Safety Evaluation' to determine and optimise the park’s fire strategy.\nDetailed computer analysis mapped the movements of people under normal and emergency conditions to help identify evacuation routes and perimeter exits. A fire management plan was formed to ensure controlled departure from rides and buildings with the assistance of trained staff and a voice alarm system. Results from modelling confirmed the predicted time taken to clear the building is more than ample to satisfy compliance requirements.\nFerrari World’s complex structure demanded a customised approach to smoke management. A combination of hand calculations, zone modelling and computational fluid dynamics demonstrated the vast 40m high enclosure should be treated as ‘external space’. Analysis proved a smoke-free layer could be maintained to allow safe evacuation of the population and access for fire-fighters. The internal buildings have mechanical ventilation to discharge smoke into the enclosed volume, where it will vent naturally through the roof.\nStructural fire analysis confirmed the steel roof supports are adequate to provide 60 minutes of fire resistance, but additional protection was specified where columns punched through the plaza and mezzanine floors. An automatic sprinkler system is installed throughout the park – except in the roof area where it could adversely affect the smoke management design. Landing valves, hose reels and extinguishers are provided for fire fighting and externally, there is a standpipe system with inlet bridge connections at access points. Hydrants are located strategically along the perimeter access road."", 'Burj Al Arab is the world’s tallest iconic and most luxurious hotel. This building has received numerous recognitions around the world, and is mainly known by its design which resembles the shape of a sail boats mast.\nThis 321 meter high building was built on a man-made island only 280 meters from the coast, giving all visitors a 360o view of the bay. Construction began in 1993. Engineers created a surface with a layer of rocks, which is circled with a honey-comb pattern which protects the surface and foundation from erosion. The building contains more than 70 000 m2 of concrete and 9 000 tons of steel. It took only two years to construct the building and three years to construct the foundation on beach sand, making this a geotechnical wonder.8\nGeotechnical Engineering entails to obtain information of the physical properties of the soil and rock on a proposed site known as site exploration. This information combined with the mechanics of soil can assess the risks presented by the site conditions that must be concluded in the design process of foundations, earthworks and retaining walls.\nBurj Al Arab has one of the rarest and most interesting foundations, earthworks and retaining wall phenomena’s. This include building an island 280 meter off coast as a foundation for this 321 meter high sea shore wonder.1 Throughout this report we will look at which soils are found in Dubai, as well as the properties thereof including the construction of this hotel foundation.\nIf you need assistance with writing your essay, our professional essay writing service is here to help!Essay Writing Service\nConstructing the Burj Al Arab hotel\nThe design of the Burj Al Arab has been constructed with a specific geometry which supports the sail boat like design by protecting the building from changing wind loads. The outermost wall of the building has been constructed by the use of PTFE coated fibreglass which contains air gaps at regular intervals. This double curve membrane design is able to withstand wind pressures easily.3\nAdditional cables have been provided onto the structure to prevent any deflection in materials. On the full height of the building expansion joints were provided on the right side of the building to ensure the building can withstand the wind load pressures as well as the horizontal stresses that may occur during construction and operation. The material that was used for this sail boat like structure is not only robust but it also protects the buildings’ interior from the sun by using light defusion.3\nAfter seventy thousand cubic meters of concrete and ninety thousand tons of steel, this great engineering wonder is noted as the heart of Dubai. This spectacular feature of the Burj Al Arabhotel, with its two hundred and two rooms, is located 280 meter off shore from the coast of Dubai and recognised as the best in the world. 2\nConcept Architect: Tom Willis-WrightimagesCAHJ41BO.jpg\nConstruction Engineer: WS Atkins and Partners Overseas – Multidisciplinary Consultancy.\nInterior designers: Khuan Chew, Design Principal of KCA International (London).\nLocation: Jumeirah Beach Road, Jumeirah, Dubai, United Arab Emirates.\nType/Structure: Luxury 7 stars* rating hotel/resort\nSize: 321m x 280m (1,053 ft)\nMedium: steel, glass, cement, steel cables, piles\nFrom: Antonino Terranova. The Great Skyscrapers of the World. Special gatefold edition, page 269-279.\nFigure 1: Burj Al Arab hotel\nDubai’s Soil Profile\nThe topography of Dubai (which lies within the Arabian Desert) is different from the southern portion of the UAE. Its landscape consists of sandy desert patterns consisting mostly out of crushed shell and coral and is clean and white, whereas gravel dominates in the southern regions of the country. 2 When looking at the soil properties of Dubai, it’s weak and will most probably move outwards in the case of any construction on it. See figure 1 Dubai soil map. 3\nStudies also show that Dubai’s possibility of a tsunami is minimal, due to the Persian Gulf water that is not deep enough to trigger a tsunami. Thus Dubai is classified as a stable zone, whereas the nearest seismic fault line is 120 km from the UAE, making it unlikely for Dubai to be hit by a seismic impact.2\nFigure 2: Dubai soil map.\nThe moment when Dubai laid focus on the development of this world wonder, they knew it would be an engineering challenge. Many elements must be taken in consideration in geotechnical engineering to build the world’s 15th tallest building on seabed, where its properties are known as a collapsible soil due to a lack of silt and clay.\nThe collapse phenomenon can be defined as a soil which can withstand somewhat large stresses, with little settlement at low in situ moisture content which will show signs of a decrease in volume and associated settlement with no increase of load if the moisture content rises. Therefore the change in volume goes hand in hand with the change in the soil structure.\nIt is thus evident that a number of conditions need to be met before collapsing begins: 6\nThe soil must have a collapsible fabric in its structure. This is where the specified soil has a high void ratio and yet has relatively high shear strength at low moisture content due to a coating (Colloidal) around each grain.\nPartial saturation is essential. This is where collapse settlement will not occur in soils which are located under the water table.\nIncrease of moisture content. This could be seen as the cause for the collapse to take place. With the increase of moisture the colloidal coating loses its strength and thus forces the grains to a denser state with reduction in void ratio.\nSubjected to an imposed load greater than their overburden pressure before collapse can take place. This is only applied to certain collapsible soils.\nThe typical problem associated with a collapsible soil to a building is that although it is dependent on the increase of the moisture content, collapse can take place years after construction has taken place. 6 Large magnitude settlements can occur beneath lightly loaded structures as well as collapse settlement is regularly localised due to defects in foundation, drainpipe leakage and where ponding occur during rainfall.\nThe engineering properties which most affect the cost of a construction are strengthening compressibility. Both can be enhanced by reducing the voids in the soil. Water must be displaced from the saturated soils in order to reduce the void volume. This can take months if the permeability of the type of soil present is low.\nThe following engineering solutions to the mitigation of the collapse problem are listed below: 6\nAvoidance by stopping the triggering mechanism (increase in moisture). This can be made possible by ensuring that water does not penetrate the collapsing soil horizons.\nDesign for collapse. This could be possible in certain scenarios to design a structure which could withstand the predicted collapse settlement.\nChemical stabilisation. This is to make use of a stabilising agent which could reduce the settlement.\nPiled or pier foundation. This is used only when the soil comes from a transported origin which means that the bedrock is covered with a shallow layer, making it possible to rather build on piers or piles.\nRemoval and compaction. This could be done by removing the collapsible soil to a certain depth and replace it through compacting the removed soil in layers.\nIn situ densification by surface rolling. Surface rolling can be done by making use of an impact or vibrating roller for compaction.\nBeach sand is one of many soils that have a collapsible grain structure, where its surface contains large quantities of calcium carbonate which in more defined terms are remains of microscopic plants and animals that thrive on nutrients in the water surface, where it ultimately settles to the floor.\nThe strength and the behaviour of this soil are thus dependent on the calcareous particles which it contains. These grain particles’ is well rounded due to it being rotated and shaped by the waves and is poorly graded (i.e. having a narrow particle distribution). This contributes to the high void ratio, meaning that the soil is very loose and can be seen as not a good bonding material. 6\nTable 1: Transported soil and possible engineering problem.\nTransported Soil Type\nAgency of transportation\nProblem to anticipate\nCollapsible grain structure\nTests to be performed on beach sand\nA large amount of data can be generated from soil, but it can all be wasted if the most important step of sampling is not carried out properly. Thus, in order for an analysis to be of significance to a proposed project, it should represent the bulk material of the site. Additionally, soil samples must be taken in abundance and at random, to ensure that the overall characteristics of the soil are effectively represented. See table 2 for properties beach sand.\nThe following tests were used in classifying beach sand (collapsing soil structure):3\nParticle size distribution. This test is performed to measure the particle size distribution of the soil sample by passing it through a set of sieves. This is in order to produce a grading curve for the soil, which is used to find out its classification. The solid particles in a soil can have different shapes and sizes, and these characteristics thus have a significant effect on its engineering behavior. By making use of this test one can clearly note whether the soil is well or poorly graded. As for beach sand it is known to be a collapsible soil due to it having a poorly graded grain structure and affected by an increase in moisture.\nOur academic experts are ready and waiting to assist with any writing project you may have. From simple essay plans, through to full dissertations, you can guarantee we have a service perfectly matched to your needs.View our services\nAtterburg limits. This test makes use of three separate tests namely Liquid limit test, Plastic limit test and Shrinkage limit test. This test is used to determine a relationship between the soils consistency and its moisture content. If the soil has low moisture content, it would aim to break before deformation takes place, whereas if the moisture content is too high, the soil will deform more easily. This test is of great importance due to it having an impact on settlement underneath a proposed structure. The test can be used to distinguish between the presence of silts and clays. This is important as silt has much less cohesion than clay.\nDry density. This can easily be determined in a laboratory by measuring its physical dimensions and by weighing them. The dry density of a collapsible soil lies between 900-1600 kg/m3.\nOedometer test. When a structure is build on a soil it produces settlement due to compression within the soil profile, which depends on the soil’s properties such as self-weight and also the type of load the soil is experiencing. This test makes use of a series of loads in order to measure the corresponding settlement of the soil. By knowing the soil’s stress and strain properties will allow the prediction in settlement and swelling of the soil.\nCollapse Potential test. This test is used to determine the collapse parameters in order to design accordingly. The CP (Collapse Parameters) is given in percentage, to determine the level of severity.\nTriaxial test. This test is similar to the unconfined compression test, except that the sample is surrounded by a waterproof membrane and installed in a pressure chamber (cell). This test is thus performed to estimate the stress and strain parameters of the specific soil.\nPermeability. This test is used to determine the ease of which water can flow through a soil profile, which is important for geotechnical engineers in projects.\nTable 2: Soil properties of silt sand.9\nBulk Density (Mg/ M3)\nDry Density (Mg/ m3)\nLiquid limit (%)\nPlastic limit (%)\nEffective cohesion (kPa)\nAngle of friction (deg)\nConstruction of Burj Al Arab Foundation\nConstructing a building on sea, an artificial island is needed to design and build the foundations. As many elements need to be taken into account to build an off shore structure, it is therefore important to ensure the protection of the foundation. This can only be done by evaluating all apposed loads to a structure. Seafloor stability regards to the bearing capacity and the sliding resistance thereof must be evaluated for static and combined static, operational and environmental (Like horizontal, vertical loading and overturning moments of the environment which have a return period of up to 15 seconds) loads. Structures with more or less a 150 meter depth could experience horizontal loads of 15-35% of the vertical loading, whereas the overturning moment can be ranging from 100 to 500 million kN/m.8 The change in vertical load during a storm can range from 10 – 40 % of the static vertical load. This means that the foundation needs to be strong to be able to obtain these loadings. Luckily these loadings were much less when Burj Al Arab was constructed, due to it only being 7 meters in depth.8IslandConstruction1.jpg\nFigure 3: Piling of the Burj Al Arab hotel\nThe first step in constructing the island was to place 230 concrete piles (see Figure 3), each one 40 meter in length, which was drilled into the sea bed. The foundation is therefore held in place by the friction of the sand and silts along the length of the piles, rather than the conventional bedrock. The surface was then made by using large rocks that were put together in a specific concrete pattern (honey-comb pattern) which serves as a shield to minimise erosion to the foundation.\nMaking the platform on which the building would be constructed, tube files and sheet files were drilled deep into the sea to support various boundary rocks. Once this was completed the sea water was displaced to fill the inside with concrete slabs as seen on table 3. IslandConstruction2.jpg\nThe structure was then surrounded with a temporary concrete structure to protect the island and the base of the structure, which was filled with a concrete plug slab. Lastly the concrete walls was made where the main basement floor of the building was build (See Figure 4).3\nFigure 4: Burj Al Arab Excavated Basement\nTable 3: Foundation of the Burj Al Arab\nThe Burj Al Arab being a geotechnical wonder is due to its size as well as its ability to withstand the environment and the impacts thereof. This building is only carried by a sandy soil which contains broken shells. Its ability under shear strength and pressure is very low, especially since it is located 280 meters of shore. Thus the building stands only on piles which are held into place by just the friction between the soil and the piles, making this project one of the most remarkable foundation types in history. The design of this foundation on this type of soil is breaking barriers in the building industry, making Dubai a leading country in development.\nDue to South Africa not being a first world country it is impossible for us to be compared to a city which encourages ultimate engineering in structural, hydraulic and geotechnical engineering. Therefore we cannot compare the infrastructures of their country with ours. South Africa could always strive to be a first world country by focusing on infrastructure as well as the inequality of societies. This would encourage tourism and affect the economy positively.\nCite This Work\nTo export a reference to this article please select a referencing stye below:\nRelated ServicesView all\nDMCA / Removal Request\nIf you are the original writer of this essay and no longer wish to have your work published on UKEssays.com then please:']"	['<urn:uuid:7ab43a66-c1d0-4fe0-b8d2-e8f6b6311131>', '<urn:uuid:c03a22c6-b8cb-4901-a631-3e39e83ec2a6>']	open-ended	with-premise	long-search-query	similar-to-document	comparison	expert	2025-05-12T13:53:09.865574	24	119	3579
100	What connects nonconformity and sustainable tourism development?	The historical American tradition of individualism and nonconformity, as exemplified by Thoreau and Emerson, emphasized authenticity rather than merely being different. Similarly, sustainable tourism development focuses on preserving authenticity while benefiting local communities - it involves protecting the environment, creating jobs for local people, and ensuring development improves quality of life without compromising future needs, rather than simply following mass tourism trends.	"['The James Luther Adams Papers\nThe Unitarian Universalist Christian, Vol. 48, nos. 3-4, Fall/Winter 1993\nPart 10: Originality\nThe drifting of the individual with the tide of the group has always been accompanied by the struggle of each against all. Human nature has followed and revolted against conventions ever since people became gregarious. The types radical and conservative are perennial, and both seem to make for advance. In general, we assume that the great changes in the world have taken place because of the reformers and revolters. We have heard so much about the dependence of the world’s progress upon revolt that we, at least theoretically, look with some interest and even favor upon the insurgents, though their interests may conflict with our own. We may feel that the revolter is a painful necessity.\nIt is easy to find the reason for this admiration of the nonconformist. We are proud to be the inheritors of a great tradition of individualism that comes down to us from the early days of colonial America. We also look back to Thoreau, Emerson and Hawthorne as great prophets, and feel a certain kinship with them and their ideals. Individualism is one of the distinctive characteristics of the American. We strive for originality. This is not a purely local ideal, of course, but our tradition is one that has stressed it as a philosophy of life.\nEmerson wrote in his Journal: “Societies, parties are only incipient stages, tadpole states of man, as caterpillars are social, but the butterfly not. The true and finished man is ever alone…. Alone is wisdom. Alone is heaven.” For Emerson imitation is suicide. What another announces I must find true in me, or wholly reject. I can accept nothing else. The only right is what is after my own constitution; the only wrong is what is against it. So is everything that tends to limit us—creeds, parties, accepted ideals, teachers, books, and our own past even.\nIn actual practice, Thoreau was a more thorough going individualist then Emerson. For instance, he refused to pay even his poll tax. He was put in jail once on this account, for one night. As he stood considering the walls of solid stone, two or three feet thick, and the iron grating which strained the light, he said: “I could not help being struck with the foolishness of that institution which treated me as if I were mere flesh and blood and bones, to be locked up. I wondered that it should have concluded at length that this was the best use it could put me to, and had never thought to avail itself of my services in some way. I saw that if there was a wall of stone between me and my townsmen, there was a still more difficult one to climb or break through before they could get to be as free as I was. I did not for a moment feel confined, and the walls seemed a great waste of stone and mortar. I felt as if I alone of all my townsmen had paid my tax. They plainly did not know how to treat me, but behaved like persons underbred. In every threat and in every compliment there was a blunder; for they thought that my chief desire was to stand on the other side of that stone wall. I could not but smile to see how industriously they locked the door on my meditation, which followed them out again without let or hindrance, and they were really all that was dangerous. As they could not reach me, they had resolved to punish my body; just as boys, if they cannot come at some person against whom they have a spite, will abuse his dog. I saw that the State was half-witted, that it was timid as a lone woman with her silver spoons, and that it did not know its friends from its foes; and I lost all my remaining respect for it, and pitied it.”\nUndoubtedly this old ideal of individualism has had something to do with our present straining for originality. Not only in the arts, but also in personal and social relations, the cry is made continuously, “Be original,” “Be original.”\nWhat does it mean to be original?\nProbably the first thought that comes to our minds is that it means to be different. It is something unusual, something strange, something rare, unfamiliar, unique. We are always fascinated by tales of new lands, new peoples, the unparalleled, the unprecedented. “What is news?”is our daily inquiry, and whoever can answer it will get our ear. This yearning for the exotic is not a new thing by any means. In fact, it is very characteristic of much of the thinking of the last century with respect to originality. Jean Jacques Rousseau, the French Romanticist, struck the note that has been heard repeatedly down to the present day. In almost the opening sentence of his Confessions, he said “If I am not better than others, at least I am different.”\nIt was only a few years until Byron became the idol of Europe, the leader of the new originality cult. Numerous followers of the cult imposed upon themselves a painful discipline in order to appear abnormal. We are told that some of them even succeeded, after a trying ordeal, in giving themselves consumption. This failure to discriminate between the odd and the original has persisted. I remember hearing a disillusioned admirer of Carl Sandburg saying, “Why, he looks just like an ordinary business man.”\nThe ideal of originality received much of its impetus in the last century from such writers as Emerson, Mill, and Carlyle. “Whoso would be a man must be a non-conformist. What have I to do with the sacredness of traditions, if I live wholly from within? No law can be sacred to me but that of my own nature. I hope in these days we have heard the last of conformity and consistency.” Such was Emerson’s Declaration of Independence, and as such, one cannot deny that it had great value; but we should remember that Emerson did not think that this policy of non-conformity was the whole story. He himself said, “It is the fault of our rhetoric that we cannot strongly state one fact without seeming to belie some other.” It was simply, as he said, that one cannot spend the whole day in explanation. The drastic quality of such counsel for independence called for some modification, and Emerson suggests it in the same essay, Self-Reliance, when he says that there is nevertheless a law that abides. “If anyone imagines this law is lax, let him keep its commandments for one day.” Oliver Wendell Holmes referred to this sentence as Emerson’s way of guarding his proclamation of self-reliance as our guide.\nIf originality is not simply being different, if it is not mere novelty nor pronouncement of independence or non-conformity, what is it?\nWe have heard many times that human nature is old and unchanging. There is little that is new about religious experience, or love, or friendship, war, danger or death. These are at the core of human experience. Nevertheless, we can compare our age with any age in the past and find ourselves infinitely superior in inventions, in material civilization, in accumulated knowledge; but compare any modern thinker with Aristotle or any modern mystic with Augustine, and the result is totally different. It is not that we have fallen below the standards of those ages, but we are not definitely above them.\nNevertheless, when someone comes who shows us again what life can be, we hail him or her as great, as original. Originality is excellence, the excellence of the oldest experiences. Originality is a playing upon the old themes—a living of life at its center. Examples of this originality which consists in the remolding of the old are legion in both the arts and in the history of humanity. The story of Romeo and Juliet was told many times before the seventeenth century when Shakespeare transformed it into an immortal drama. There were many attempts to portray the American Indian before Cooper; nevertheless, The Last of the Mohicans found its place in the affections of people near and far.\nOne of the most persistent attempts in the history of music to remold the old to perfection is found in the work of Johannes Brahms. Probably no young composer ever received such hearty welcome into the musical world as did young Brahms at the age of 20. Schumann, one of the leaders in the musical world at the time, proclaimed the advent of a “genius in whom the spirit of the age should find its consummation and its fulfillment; a master by whose teaching the broken phrases would grow articulate, and the vague aspirations gather into form and substance.” At last a leader had arisen who should direct the art into new paths and carry it a stage nearer to its appointed place. Brahms now found himself suddenly famous. He was discussed everywhere. His pieces were readily accepted by publishers, and his new compositions were awaited with great interest. He was expected to go on producing; he was almost under obligation to justify his impressive introduction. When we consider the temptation it must have been to him to continue these easy triumphs, when we imagine the inward enthusiasm of creation which must have fired him, we are ready to appreciate the next event in the drama. That event was withdrawal from the musical world and the initiation of a long course of the severest study. Thus in spite of world-wide recognition, Brahms, when a little over 21, imposed upon himself some five years of arduous training and self-discipline. He commanded himself to forego for a while the eloquent but ill-controlled expression hitherto his, in order to acquire his broad firm style, which we love today. Brahms was not so much interested in striking out new paths as he was in knowing and using anew the old forms to perfection.\nLet us consider the founder of our religion, Jesus. We often think of him as a person who brought much that is new into the world. One of the most astounding truths which modern scholarship discovered is that practically all of the teaching of Jesus can be found in the literature of Judaism of the preceding two centuries. Arthur Cushman McGiffert, the historian of Christian thought who was President of Union Theological Seminary, concluded: “Summing it all up, we may say that Jesus’ idea of God was wholly Jewish. At no point, so far as we can judge from the Synoptic Gospels, did he go beyond his people’s thought about God. His uniqueness, so far as his teaching goes, lay not in the novelty of it but in the insight and unerring instinct with which he made his own the best in the thought of his countrymen. His piety seems to have been nourished particularly on Deuteronomy, the Psalms, and Isaiah; and it is the ideas of God found in those writings that are chiefly reflected in his words.”\nHowever, Jesus stamped his personality upon those teachings so securely that, in spite of innumerable theological makeshifts, his immutable spirit has survived. It cannot be said that his great value for us consisted in giving us something new, but he was original in the highest sense of that word. It is because of him that we know the highest meaning of love and courage and fellowship with God.\nA sequence of such original people interpreting life is like a succession of virtuosi playing the music of Mozart and Beethoven. Their renderings will be different, but the music is the same, and we know it by heart. The player who calls our attention to the most beauty in it will be original and unique in the only way that life or art permits. Life is music already composed. It has been there a long time, and it had already become ancient history when the first heroes began to play it. In the concert hall, the amateurs listen spellbound when the master plays to perfection a piece with which they have struggled. This is more to them than the loveliest of new sonatas, for it is their own world in a new light. It is because the subject is not new that the audience can decide how well it is portrayed.\nThe great and original people of history have brought upon the stage the old procession of sorrows, passions, and delights. They loved life for its own sake and sought to live life at its best. Consider Dante’s expression at the end of The New Life: “A wonderful vision appeared to me, in which I saw things which made me resolve to speak no more of this blessed one (Beatrice) until I could more worthily treat of her. To attain this I study to the utmost of my power, as she truly knows. If it shall please God through whom all things live that my life be prolonged for some years, I hope to say of her what was never said of any women.” Dante did not set out to write a new kind of book, for women had been praised before, as he implied, and there had been poems of vision and pilgrimages through hell. His hope was to excel. Originality is not so much the creation of something wholly new but the revival of something old. We are most truly individual when we build upon what is common to us and to our kind. Our purpose is not that we should express ourselves but that life should be expressed through us. We must lose ourselves in a greater, higher life. That is what religion means.', 'Presentation on theme: ""Tourism Revision -We will revise the main points in the Tourism Topic""— Presentation transcript:\n1Tourism Revision -We will revise the main points in the Tourism Topic -We will know how to use questions as part of our revision\n2Knowledge Check List Reasons for global increase in tourism Potential of cities, mountains and coasts for tourism developmentEconomic importance of tourism to contrasting parts of the worldContribution of tourism to the UK economyImpact of external factors on visitor numbers to the UKTourist area/ resort life cycle modelThe meaning of mass tourismThe positives and negatives of mass tourismStrategies for maintaining tourism and reducing the impacts of itThe attraction of extreme environmentsThe impact of tourism on extreme environmentsThe need for stewardship and conservationHow tourism can help sustainable development\n4Growth in Tourism Why is tourism growing? 1) 2) 3) 4) 1) 2) 3) Why are some areas getting more popular?1) 2) 3) 4)1) 2) 3)\n5Growth in Tourism Why is tourism growing? Why are some areas getting more popular?1) More disposable income around the globe 2) More paid holiday / holiday entitlement 3) Travel is cheaper / Technology is better 4) Holiday Providers and range of holiday destinations up 5) Media / TV1) Improvement in transport 2) Better marketing 3) Improved infrastructure\n6What’s the attraction? Type Coast/ City/ Mountains Attractions Examples\n7What’s the attraction? Type Coast/ City/ Mountains CITY MOUTAINS COSTALAttractionsCULTUREENTERTAINMENTSHOPPINGSCENERYWALKINGCLIMBINGSKIINGSNOW BOARDINGSWIMMINGSNORKELLINGFISHINGWATER SPORTSSEA SIDE RESORTSExamplesLONDON, NEW YORK, PARIS, ROMEALPS, ROCKIESCARRIBEANTHAILAND\n8Theory- Importance of Tourism Creates jobs for local people which helps the economy growIncrease the income of businesses that supply tourismImportant to rich and poor countries in bringing in money and jobsPoorer countries are more dependent on tourism (UK 3% of GNP Vs 15% of Kenya)\n9Questions...Give two reasons why tourism is an important economic activity (2 marks).__________________________________________________________________________________________________________________________Contrast the economic importance of tourism in rich and poor countries (2 marks).\n10UK Tourism Churches, Cathedrals & Castles Countryside and Historic LandmarksUK Tourism£114 billion into UK economy& 1.4 million jobsHalf of visitors to UK go to London\n11Explain why the UK is a popular tourist destination. (4 marks) ________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________Key Ideas: -Transport links & infrastructure -Attractions -Marketing\n12Explain the factors that lead to increasing and decreasing tourism in the UK Cheap package flights to the Mediterranean since 1970 allowed UK working classes the chance of guaranteed hot sunny weather.Higher expectations by the paying public.Traditional bucket and spade holidays lose their fashionable appeal.Longer holidays allow fortnight bookings, encouraging overseas holidays.Lack of investment from local authorities causes the infrastructure to become run-down eg flaky paintwork and graffiti – discouraging future visits.\n13Annotate the Butler Life Cycle Model TimeKey Ideas:Exploration, involvement, development, consolidation, stagnation, rejuvenation, decline\n14UK Case Study: Blackpool Stages:1860s – seaside becomes fashionable for the affluent/wealthy as railways make coastal resorts accessible.1890s – Day trippers include factory workers helped with bank holiday excursion trains.1920s – One week factory holidays increases the tourists/staying visitors.1950s – increased paid holidays with a post-war economic boom.1970s – decline due mainly to overseas package tours.1980s – resort either:-declines eg Herne bay;rejuvenates itself eg BlackpoolUncovers niche market eg oyster festival at Whitstable\n15UK Case Study: Blackpool To counter the Mediterranean competition Blackpool now:-Offers wet weather facilities such as indoor swimming pools,Extended the ‘illuminations’ season through until November,Diversified with year round activities such as Business Conferences,Built a range of night clubs to successfully tap into the ‘stag-do-hen-party’ market,Expanded the range of rides such as the rollercoaster.\n16UK Case Study: Blackpool Voted UK’s favourite seaside resortWinter Illuminations ‘breathtaking’1.3 million visitors at least per year19,000 tourist related jobsNB Football team gaining promotion into the Premier League helps.\n17Mass TourismDefinition: refers to the act of large numbers of people staying in the same place such as the Spanish Costas in the 1970s and 80s.\n18Mass Tourism“Mass tourism is organised tourism for large numbers of people.”PositivesNegativesEconomic ImpactsSocial ImpactsEnvironmental Impacts\n19Mass Tourism“Mass tourism is organised tourism for large numbers of people.”PositivesNegativesEconomic ImpactsBring money to local economyCreates jobs for localsBoost local economy supplying tourismA lot of the profit is kept by the large travel companiesSocial ImpactsMore jobs= young people stay in areaImproved roads, communications and infrastructureTourism income can be invested into community projectsTourism jobs available to locals badly paid and seasonalTraffic congestion & inconvenienceBehaviour of some touristsEnvironmental ImpactsIncome from tourism can be reinvested in protecting environmentTransportation releases green house gasIncreased litter and pollutionDestruction of local wild life e.g. Boats damage coral\n20Increasing Tourism and Reducing the Impact Maintaining TourismWays to reduce negative impacts:B R A C I O\n21Increasing Tourism and Reducing the Impact Maintaining TourismWays to reduce negative impacts:1. Improve public transport less congestion & pollution 2. Limit numbers to sensitive sites 3. Provide bins for litterBuild new facitlites Reduce impacts that make tourism less effective Advetise and market Cheaper to visit Improve transport infrastructure Offer new activites\n22Extreme Tourism (Holiday to Extreme Environment) AttractionsDamage to the EnvironmentExtreme TourismReasons for Increasing\n23Extreme Tourism (Holiday to Extreme Environment) Trees cut down for fuelFootpath erosionDifferent & excitingAdventure holidaysRiskWater pollution- SewageDeforestation destroys habitatsSceneryAttractionsWildlifeDamage to the EnvironmentExtreme TourismAdverts & TV programmesReasons for IncreasingDeforestation leads to floodingImproved transportMore disposable incomeLess roots leads to soil erosionLast chance to see\n24Extreme Tourism (Holiday to Extreme Environment): Case Study - Antartica Why?scenery, wildlife, activities like cruises, kayaking, climbing, helicopter rides.Why has it increased in popularity?more thrill seekers, more activities, more accessible, appeals to tourists, ship sizes increased tourists in 1992 has grown to in 2006 and in 2008 and the numbers are expected to double over the next 10 years companies offer extreme holidays to Antartica.Impacts: sea pollution, littering, fragile resources.Sustainability: supervision of tourists means; no littering, no contact with animals, no walking on lichens, no trespassing, permit must be gained for activities.can be more sustainable by increasing the amount of people per boat and increasing the amount of supervisors.\n25Antartica/Southern ocean Sustainable management Extreme Tourism (Holiday to Extreme Environment): Case Study - AntarticaGlacial landscapes , wildlife – seals whales and penguins6700 in 199245,000 in 2009Why go?Visitor NumbersCruise Shipsresearchers a yearCase Study:Tourism inAntartica/Southern oceanOver-flightsDamage – natural causesCampingCode of conductNaturalist, photographers, journalistsSustainable managementOver flying causing stressImpactsNo litterAntarctic tourism shows environmental concernTerncoloniessuffer disturbancesFoot prints remain for a long timeScott Polar research\n26Ecotourismviewing small benefits environment local responsibility protecting conserving harmTourism that does not __________ the environment and __________ the __________ peopleInvolves:Conservation: __________ & managing __________Stewardship: Taking __________ for __________ environmentShould involve local people & local organisationsNormally __________ scale with a small number of touristsActivities often involve wildlife __________ and walking\n27EcotourismTourism that does not harm the environment and benefits the local peopleInvolves:Conservation protecting & managing environmentStewardship Taking responsibility for conserving environmentShould involve local people & local organisationsNormally small scale with a small number of touristsActivities often involve wildlife viewing and walking\n28Environmental Benefits Economic BenefitsBenefits for local peopleSustainable Development\n29Environmental Benefits -Local people encouraged to conserve the environment-Reduces poaching and hunting-Reduce the use of fossil fuel-Waste is carefully disposed ofEconomic Benefits-Creates jobs for local people-Additional local employmentBenefits for local people-Locals have better more stable income-Many schemes have a community projects fundSustainable Development-Improve quality of life but doesn’t stop the future getting that they need-Aids local development-Development without damage to the environment\n30Review... Reasons for global increase in tourism Potential of cities, mountains and coasts for tourism developmentEconomic importance of tourism to contrasting parts of the worldContribution of tourism to the UK economyImpact of external factors on visitor numbers to the UKTourist area/ resort life cycle modelThe meaning of mass tourismThe positives and negatives of mass tourismStrategies for maintaining tourism and reducing the impacts of itThe attraction of extreme environmentsThe impact of tourism on extreme environmentsThe need for stewardship and conservationHow tourism can help sustainable development']"	['<urn:uuid:a2bddcb3-65e9-401a-92a5-7f8a85f965db>', '<urn:uuid:746c5166-5195-4f0b-bc6a-1089db41c2d6>']	factoid	direct	concise-and-natural	distant-from-document	multi-aspect	novice	2025-05-12T13:53:09.865574	7	62	3559
