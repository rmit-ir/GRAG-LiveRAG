qid	question	answer	context	document_ids	question_factuality	question_premise	question_phrasing	question_linguistic_variation	question_multi-doc	user_expertise-categorization	generation_timestamp	question_length	answer_length	context_length
1	decisive military leadership examples world war ii pacific theater intelligence gathering methods	During World War II, military leadership required both decisiveness in combat and effective intelligence gathering. In the Pacific theater, MacArthur's command established sophisticated intelligence operations through ATIS, which systematically collected and analyzed Japanese documents, providing crucial tactical and strategic information. The Japanese's confidence in their language barrier as security proved to be a weakness, as ATIS used captured records to build comprehensive intelligence about enemy forces. This intelligence gathering was complemented by strong leadership principles, particularly decisiveness in combat situations, as emphasized by historical examples like Admiral Farragut's 'Damn the torpedoes, full speed ahead' and General McAuliffe's defiant 'Nuts' response to German surrender demands at Bastogne.	"['By Capt. Ron Roberts\nConflicts and setbacks allow leaders to develop abilities and characteristics that play a vital part in their future leadership. Past generals such as George Patton, who had dyslexia, and Douglas MacArthur, whose application to West Point was rejected twice,1 remind today\'s military leaders that experiencing challenges is part of leadership and does not hinder the ability to lead. As Gen. Dennis J. Reimer, Army Chief of Staff from 1995 to 1999, said, ""The role of leadership is to turn challenges into opportunities.""2\nThus, in the concluding article, we discuss the final four leadership principles — student of the past, decisiveness, determination, and strong character.\nBe a Student of the Past\n""The only right way of learning the science of war is to read and reread the campaigns of the great captains.""\nHistory offers a wealth of information to those who have the foresight to examine it. In addition to obtaining vital technical and tactical knowledge, Soldiers can learn by studying how past leaders performed in the fog of war.\nGen. George Patton was a consummate warrior, known for studying history and acquired an impressive library of professional military books during his lifetime. At an early age, he chose to become a Soldier. His father nurtured him in the classics, as well as the lore of the Patton family, which was composed of military leaders including two uncles who were Confederate officers killed in battle.3\nUnfortunately, Patton had dyslexia, a learning disability not well known or diagnosed at the time. He realized, however, that with determination and constant effort, he could pursue military studies and achieve his goal of becoming a great leader.\nHe understood the military profession required immense technical competence, knowledge of weapons and equipment, tactics and operations, and maneuvers and logistics. Therefore, he expended vast amounts of time and energy in reading and making copious notes in the pages of his books,4 making him not only familiar with field and technical manuals of his time, but also knowledgeable about history.5\n""In any moment of decision, the best thing you can do is the right thing, the next best thing is the wrong thing, and the worst thing you can do is nothing.""\n—President Theodore Roosevelt\nIn war, lack of decisiveness can have fatal consequences. Once you make up your mind, stick to your decision. Never show yourself to be indecisive.\nWhen Julius Caesar refused to lay down his military command and return to Rome at the end of Gallic Wars, he said, ""The die is cast,"" thus making it clear that his choice was irrevocable.6\nIn 1805, during the Napoleonic Wars, Napoleon\'s empire was threatened by England, Russia, and Austria. During this period, Napoleon was able to compel the Austrian Army to surrender without firing a shot through rapid marching and maneuvers.7\nAs a final example, in 1862, at the Battle of Mobile Bay during the American Civil War, Confederate mines blocked Union Adm. David Farragut\'s path during an attempt to attack a Confederate Navy squadron to seize three forts guarding the bay entrance.8 In a decisive statement, he said, ""Damn the torpedoes, full speed ahead.""9\n""You are never beaten until you admit it.""\n—Gen. George S. Patton Jr.\nA leader must show determination even when others do not. This ""never say die"" attitude is necessary for your Soldiers to be tirelessly persistent during desperate, bleak, or challenging situations.\nBrig. Gen. Anthony McAuliffe, acting commander of the 101st Airborne Division during the Battle of the Bulge in World War II, is an excellent example. In December 1944, at Bastogne, Belgium, the Germans sent a demand for his surrender. He responded by saying, ""Nuts.""10\nTo articulate the resolve and determination of his countrymen, Winston Churchill, the British Prime Minister, gave a number of inspiring speeches during World War II:11\nBlood, Toil, Tears and Sweat\n""I would say to the House, as I said to those who have joined this government: I have nothing to offer but blood, toil, tears and sweat. We have before us an ordeal of the most grievous kind. We have before us many, many long months of struggle and of suffering.\nYou ask, what is our aim? I can answer in one word: Victory. Victory at all costs — Victory in spite of all terror — Victory, however long and hard the road may be, for without victory, there is no survival.""12\nWe Shall Fight on the Beaches\n""We shall fight in France, we shall fight on the seas and oceans, we shall fight with growing confidence and growing strength in the air. We shall defend our island, whatever the cost may be, we shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and in the streets, we shall fight in the hills; we shall never surrender.""13\nTheir Finest Hour\n""Let us therefore brace ourselves to our duties, and so bear ourselves, that if the British Empire and its Commonwealth last for a thousand years, men will still say, \'This was their finest hour.\'""14\nBe Strong of Character\n""Duty, Honor, Country. Those three hallowed words reverently dictate what you ought to be, what you can be, what you will be.""\n—Gen. Douglas MacArthur\nGen. of the Army Douglas MacArthur was a historical leader who embodied the definition of strong character. He was a renowned general who won many battles against numerically superior and better-equipped foes and was awarded the Medal of Honor for defending the Philippines during World War II.\nMacArthur did not accept anything but the best, even during times of peace, which was evident when he trained the 1927 American Olympic team. With his commanding presence, he pulled together a strong team, retorting, ""Americans never quit,"" in response to the U.S. boxing team manager who wanted to withdraw from the competition due to an unfair decision.15\nIn his acceptance speech for the Sylvanus Thayer Award, one of the most eloquent expressions of leadership principles ever delivered, MacArthur\'s words speak to today\'s Soldiers, especially NCOs who are ""warrior-leaders of strong character"":16\n""Duty, Honor, Country. Those three hallowed words reverently dictate what you ought to be, what you can be, what you will be ... They build your basic character. They mold you for your future roles as the custodians of the Nation\'s defense. They make you strong enough to know when you are weak, and brave enough to face yourself when you are afraid.""17\nRelated: Click here to read General MacArthur\'s Thayer Award speech in its entirety.\nIt is a tremendous honor, as an NCO, to lead Soldiers and along with this honor comes the responsibility to do it well. An ideal Army NCO has a sharp intellect, physical presence, professional competence, high moral character, and serves as a role model. He or she is willing to act decisively, within the intent and purpose of those appointed over them and in the best interest of the organization. They recognize organizations built on mutual trust and confidence accomplish peacetime and wartime missions.18\nAn NCO, who is proficient in some of these 12 principles, but deficient in others, will have a detrimental effect on mission success, morale, and the efficacy of leadership. It is therefore imperative that all leaders build competency in all principles and become well rounded.\nThe men and women of the U.S. military have made countless sacrifices in the service of our great nation. They deserve the best leadership we can offer, and it is our sacred duty to give it to them.', 'Allied Translator and Interpreter Section activated\nSept. 19, 1942\nAfter the bombing of Pearl Harbor on Dec. 7 1941, President Roosevelt declared war on Japan the next day. Three days later, Hitler declared war on the United States. Thus the American military was thrust suddenly into World War II, fighting in two different theaters, against vastly different enemies.\nGen. Douglas MacArthur, who had been commanding forces in the Philippines, arrived in Australia in March 1942 and was soon thereafter appointed as the supreme commander of all Allied forces in the Southwest Pacific Area, or SWPA.\nThe SWPA was constituted on April 18, 1942, by agreement among the Governments of Australia, the United Kingdom, the Netherlands and the United States. On that date, MacArthur assumed command and proceeded to establish his General Headquarters at Melbourne.\nMacArthur’s assistant chief of staff for Intelligence was Col. Charles Willoughby, who oversaw the complex intelligence network of the SWPA Theater.\nWilloughby set up a number of Allied intelligence collection organizations under his direct control. The Central Bureau handled cryptologic functions. Human Intelligence came from the Allied Intelligence Bureau, whose mission was to collect intelligence through clandestine operations behind enemy lines, conduct sabotage operations and recruit aid from the natives. The Allied Geographical Section was formed to collect and assemble topographic information, and to prepare and publish reports and locality studies on areas of immediate tactical interest. The most productive single intelligence agency established under the G2 of the SWPA was the Allied Translator and Interpreter Service, or ATIS, which was organized on Sept. 19, 1942.\nATIS effectively neutralized the Japanese language barrier — one of the greatest advantages possessed by the Japanese, as it was almost as effective as a secret code. The G2 employed hundreds of second-generation Japanese-Americans, called Nisei, in linguist detachments under ATIS. They accompanied assault landing forces across the beachhead and on inland, conducted spot interrogations, translated captured maps and plans, and gave the psychological warfare planners excellent insight into the morale problems of enemy soldiers through the exploitation of letters and diaries. Other captured and translated documents revealed the enemy’s food and supply problems, his order of battle, the effects of Allied air attacks and the effectiveness of both Allied and Japanese weapons.\nThe Commander of the ATIS, Col. Sidney Mashbir, in his book “I Was an American Spy,” called the ATIS document translation process a “brain-power quantity production line.” He stated that by the end of the war, ATIS had interrogated 14,000 prisoners, translated almost two million documents, and published more than 20 million pages of Japanese intelligence.\nThe irony was that the Japanese kept scrupulous records, which they rarely encrypted, having absolute confidence in the security the language barrier afforded. ATIS used this to their complete advantage, compiling nearly complete sets of unit papers, including war diaries, organizational rosters, intelligence reports, pay books, postal-savings books, correspondence and personal possessions. Using these captured items, they slowly and patiently built up a mosaic picture of the enemy force.\nBy the time the American forces reached Manila in January 1945, Mashbir boasted that [ATIS] “literally knew more about the Japanese Army than most of its own officers, because, as a matter of fact, we had their records. This was equally true of the Navy and Air Force.” Over the course of the war, ATIS issued thousands of printed documents, providing intelligence of immediate operational importance as well as overall strategic value.']"	['<urn:uuid:59ac5b75-92b3-4233-ba0a-c88836589eac>', '<urn:uuid:e25cb3d7-6f38-493d-8cc7-305414eb0591>']	open-ended	direct	long-search-query	similar-to-document	multi-aspect	expert	2025-05-13T01:50:22.828293	12	106	1823
2	I'm a manager looking to improve my team's performance reviews. What's the best way to evaluate team members - should I focus on individual achievements or team performance?	Performance systems should include a team component, with a portion of each employee's review based on their teamwork. The best approach is to review the team as a unit and give each member the same team score. This motivates employees to help the team succeed rather than just focusing on individual goals. Focusing solely on individual contributions can actually undermine what's best for the project, team, and organization by creating a culture of blame and shame.	['High-performing teams don’t appear overnight. They develop when conditions are right, with the combined actions of senior leaders, team leaders and team members.\nWhile we are biologically wired to connect with others, we must meet critical conditions to drive peak team performance. Recent discoveries in neuroscience illuminate what differentiates the highest-performing teams from the rest. Because brain science is universal, these discoveries apply to all people, cutting across generations and gender as well as race and nationality.\nLet’s look at some overarching principles that can guide everyone who cares about maximizing team performance.\n1. Honor the Power of Biology With In-person Interactions\nWhile technology makes it possible for us to work with others through a video screen or phone, our brains were built for in-person interactions. Our brain reads meaning and intent in others through micro-muscular changes in the face, body language and even pheromone signals — almost all of which is lost when we communicate through technology. Even video conferencing loses the third dimension that can make the difference in accurately reading another’s meaning.\nIn-person interactions provide the most data to the brain. When teams are in the early, trust-building stage of their time together, best practice prioritizes in-person interactions, because all members can participate using their full set of biological tools for connecting and communicating. If you can’t bring people together physically, then it’s important to counterbalance the deficit with more frequent and in-depth interactions that intentionally fill in the gaps by helping them get to know one another and build trust.\n2. Select or Develop Leaders Who Cultivate Collaboration\nEffective team leadership requires emotional intelligence (EQ) and collaborative intelligence — the ability to bring out the best in a group. Traditionally, we select team leaders based on their successes as individual contributors. However, that background can harm the growth of a team if the person doesn’t know how to make the vital shift from performer to facilitator.\nInstead, look for people who are already natural facilitators, and amp up their team leadership abilities through training and coaching. Look past the star performers to the people who have rapport with a lot of different people. Find the person whom others are already turning to for guidance or support — the person who creates cohesion and brings out the best in others. These individuals are hidden gems waiting to be tapped for leadership roles.\nAlso be sure your performance review system evaluates team leaders based on the right set of criteria. Measure success based on how well they create psychological safety and enhance employee engagement and retention and on their team’s performance on important metrics like successful task execution, collaboration and innovation.\n3. Build Psychological Safety\nHarvard professor Amy Edmondson first identified the concept of psychological safety, and several subsequent studies have shown that psychological safety is the core element of thriving teams.\nPsychological safety is not the mere absence of intimidation or harassment. Dr. Edmondson’s research shows that it’s what creates the climate for teams to do their best work. She defines psychological safety as “a sense of confidence that the team will not embarrass, reject or punish someone for speaking up with ideas, questions, concerns or mistakes. It is a shared belief that the team is safe for interpersonal risk-taking. It describes a team climate characterized by interpersonal trust and mutual respect in which people are comfortable being themselves.”\nGoogle replicated Edmondson’s findings in a global study on teams, discovering that psychological safety was more important to team success than any other factor, including the quality or performance level of the individual members. Specifically, the best teams do two things:\n- Ensure that every member is heard by going beyond inviting people to share their thoughts to actively and consistently seeking out every member’s contributions.\n- Consistently engage with each other with empathy, noticing each other’s emotions and reaching out to connect.\nIt’s important to note that psychological safety is not about being universally liked by others nor being protected from others’ opinions or beliefs. The members of the group might disagree or find what others say uncomfortable, but a healthy team welcomes their input, because it might just be a game-changer.\nThe way a group of people comes together to work can activate trust or a climate of conflict and blame. Employees need to learn about psychological safety and the skills to create and maintain it. They need to know how to ask the kinds of questions that safely broaden and deepen the conversation. In particular, it’s important for leaders to learn how to counterbalance the barrier that power creates.\nTeaching psychological safety is only the beginning. It’s vital to then watch for signs that the team is moving forward in a healthy way. If you see signs of problems, like increased complaints to human resources (HR), more sick days and turnover, or decreasing engagement, it’s important to take action to help the team course-correct. Otherwise, you risk creating a team paralyzed by learned helplessness, which can be very difficult to shift.\n4. Invest in Team Training and Team Building\nTeam leaders are not the only ones who create a high-performing team. Members also play an important role, and they need the tools and skills to do their part. To facilitate this understanding, it’s important to understand the difference between team training and team building.\nTeam training refers to learning the knowledge and skills needed to work well as a team and perform a task successfully. These skills include group development, work styles, inclusion, psychological safety, communication, project management, execution and conflict resolution, to name a few.\nDid you know that conflict about a task correlates positively with creativity, but interpersonal conflict has a negative relationship with creativity? Conflict resolution skills are vital to team health, because they help team members wrestle with diverse ideas and work styles without harming trust.\nTo this end, it can be valuable to create a team playbook — a document that provides a centralized overview of your process to help teams navigate the combined task and relationship elements of their work. For example, a playbook can help a team establish ground rules and clarify the roles each member will play. It can also become a tool for holding each other accountable and for getting back on track when and if things go “wonky.” Most importantly, it can define how to handle inevitable conflict productively.\nTeam building, on the other hand, is the process and interactions through which team members learn about each other, both personally and professionally, as they begin to build trust. It takes several forms, sometimes unfolding over regular meetings or off-site retreats. Rather than digging into an assigned task, team building is about intentionally creating experiences that build relationships and trust. Trust is vital for when the work becomes difficult; it enables members to tussle with challenges and maintain psychological safety.\nTeam building is often shortchanged in the rush to jump into a task or project. However, investing in it up front will more than pay off in the group’s development and project execution later on.\n5. Hold Teams Accountable as a Unit\nEnabling a diverse range of work styles, skills, motivations and personalities to work cohesively can become more challenging when we inadvertently undermine people’s motivation for working together by not holding them accountable as a unit. Every member of the team needs to know that they are responsible, together, for successes and failures and will share equally in the rewards and consequences.\nMost performance management processes focus on individual contributions, motivating team members to prioritize their own goals and outcomes to preserve job security. In other words, it rests on proving their individual value, which often undermines what is best for the project, the team and, ultimately, the organization.\nPerformance systems should have a team component, with a certain portion of an employee’s review based on his or her teamwork. The best way to support teams as they work through differences and recover from mistakes is to review the team as a unit and give each member the same team score. This approach motivates employees to help the team succeed and tangibly acknowledges the value that teamwork brings to the organization. Lack of team accountability can create a culture of blame and shame, which can cripple an organization.\nThere are many ways to set up this kind of performance system. Some models have leaders or supervisors assess or evaluate the team’s performance, taking into account both the task and the collaboration or cohesiveness of the group. Another approach is to have each member evaluate the group as a whole. This method can be valuable, because team members must address and take responsibility for their own role as well as everyone else’s.\nBy leveraging new insights from neuroscience, you can approach team development in new and more effective ways. We all have the ability to build teams that thrive and succeed. Brain science can be a particularly helpful tool for bringing out the best in people and organizations.\nParts of this article were excerpted from the author’s book, “Wired to Connect: The Brain Science of Teams and a New Model for Creating Collaboration and Inclusion.”']	['<urn:uuid:cfcb58ca-8868-4262-833f-6c992fd2cb87>']	factoid	with-premise	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-13T01:50:22.828293	28	76	1529
3	baltic birch plywood vs cake flour structure effects	"Baltic birch plywood and cake flour have different structural properties in their respective uses. Baltic birch plywood has no voids which allows its edge to be sanded and finished nicely, and despite being thin at 1/8\"", it remains strong enough for intricate details. In contrast, cake flour has a lower protein content compared to other flours, which creates a more fluffy and soft structure in cookies, and weighs less than other flours requiring more quantity to achieve the same structural integrity."	"['As is the case with many of the projects on this site, I created the wooden star pattern to help out a friend. Some friends of his were making Christmas trees out of old pallets to sell in their vintage shop and needed stars to adorn the tops of the trees. Having already had some pretty good success cutting snowflakes out of 1/8"" baltic birch plywood, this seemed like it should be pretty simple.\nThe star design really is pretty simple. But it still needed to be suitable for cutting on the CNC and have a pleasant shape. If you look at the dimensioned PDF drawings (yeah, I did go that far for a star), you\'ll see notes about radiusing the edges outward slightly. This bears a little bit of explanation.\nThe design really is just a basic star at its core. There are five outer points and five inner points all connected by straight lines. However, the straight lines and sharp corners were a little too stark and didn\'t allow for the router\'s round cutter.\nTo fix the straight lines I simply added a bit of a radius, arching outward from the center of the star. That gives it a slightly softer and more pleasant shape. As for the cutter radius, I added a mere sixteenth of an inch radius. I\'ve been using a 1/16"" diameter router bit for cutting snowflake shapes out of the same material so figured that would give a nice detail and provide plenty of clearance for the bit.\nOther than that, the only other design consideration was size. The folks who were making the Christmas trees needed various sizes for their project so I sized them accordingly while keeping the same tight radius at all of the corners.\nFor your project the star pattern should be good for any material from paper to wood or even plastic. In fact, if you check out my Etsy shop you can get the STL files to run these on a 3D printer. For this project, however, I used 1/8"" baltic birch plywood.\nIf you\'re not yet familiar with baltic (or Russian) birch plywood, I highly recommend you try it out. It typically comes in 5 foot square sheets. That sounds a little odd, but the size is optimized for european cabinet box sides. I have found it in 4x8 foot sheets as well, but the cost per square foot is much higher.\nOne of the great features of baltic birch plywood is that it has no voids so the edge can be sanded and finished nicely. The 1/8"" seems very thin, but is plenty strong for even intricate details.\nAs mentioned earlier, these stars were cut on the CNC router using a 1/16"" diameter router bit from Think & Tinker, LTD. That\'s a pretty small bit so I take four passes to make it all the way through the 1/8"" plywood. I did figure out a little trick that helps create a super clean cut on the top and the bottom. For the first two passes I use a down spiral bit and for the final two passes I use an up spiral bit. I know that\'s not rocket science, but it has helped quite a bit.\nWhether you make wood stars for pallet Christmas tree, or foil stars for an Independence Day craft on the 4th of July, I hope you enjoy this simple set of patterns. You can either grab the JPEG from above, or if you\'d like a fully dimensioned set of drawings click here or the image to the left. As always, remember that you\'ll need the Adobe reader to view the file.\nIf you like the look of the stars and would like to purchase one or more already cut for you, then please have a look at what\'s available on my Etsy shop. The stars are great for Christmas ornaments and decorations, or even for the Fourth of July. They\'re available in all five sizes seen in the drawings, 3.5"", 4.5"", 5.5"", 6.5"", and 7.5"".', 'Learn how to create a cookie recipe of your own. This is my process and formula in creating an original baking recipe specifically for cookies.\nI am the kind of person who is fascinated with the science of baking. Each time I try a new recipe, I try to learn about each element in the ingredient list and how they are affecting the final product. Some ingredients are important to the structure, some add sweetness, some cause the baked good to rise, some add moisture, and some are mostly just for flavoring.\nMy fascination with this has helped me learn how to create my own recipes from scratch. They don’t always work exactly they way I want, but with a little knowledge of the science of baking you can get pretty close and then tweak things from there.\nThe Cookie Wars Recipe Contest is currently up and running and accepting entries, I thought this would be a good time to share with you my process when creating an original cookie recipe so that this task might not seem so daunting. This process isn’t fool proof and you may not get your exact desired results on the first try, but mistakes are how we learn!\nI hope this helps you have more confidence in creating your own original recipe and I can’t wait to see what everyone comes up with!\n(This is by no means and all inclusive guide to creating a cookie recipe. There are endless ways to approach this. This is just what works well for me and the way I most frequently approach this process.)\nStep 1: Choose Your Flavor Profile\nBefore I even start delving into creating the recipe, I always decide on a flavor profile. I feel this sets the tone for what kind of cookie I want to create. So get that nailed down before doing anything else! This would be the perfect place to decide on your two\nchallenge ingredients if you are entering Cookie Wars!\n- Extracts: vanilla, almond, anise, coffee, maple…\n- Fruit Juices or Zest: lemon, orange, lime, grapefruit…\n- Spices: cinnamon, nutmeg, allspice, clove, cardamom, cayenne powder, Ginger, Paprika …\n- Herbs: mint, basil, thyme, Rosemary…\n- Alcohol: whiskey/bourbon, gin, beer, tequila, spiced rum…\n- Other Mix-ins: cocoa powder, chocolate chips, dried fruits (cranberry, raisin, mango) oatmeal, nuts, vanilla bean…\n- And endless more…\nStep 2: Choose Your Cookie Style\nAfter choosing the flavor profile choose your cookie style and texture.\nThe most common kind of cookie is what I refer to as “drop cookies.” This is most commonly a chocolate chip cookie but can be easily modified with other flavors and mix-ins. It is also important to have an idea of the texture you are looking for during the next few steps as certain ingredients will produce various textures.\nSome Cookie Styles:\n- Drop Cookies\n- Sandwich Cookies\n- Cut Out Cookies\n- Iced Cookies\n- Cookie Bars\n- Slice and Bake Cookies\n- Spritz Cookies\n- Cookie Cake or Skillet Cookie\nStep 3: Choose your Fat\nAlmost all cookie recipes start with a fat or a fat substitute. A fat (or fat substitute) is important for the structure of the cookie, the moisture in the cookie, and sometimes the flavor.\nTypically when creating a cookie recipe I start with about 1/2 cup of my fat. This is generally the amount of fat needed for a batch of cookies that will make about 1 dozen large cookies or 2 dozen small cookies.\nWhen choosing a fat you can also mix and match. I often use some butter and some yogurt. Or banana and a nut butter. But good old standard butter is my most frequent choice. Try different things and see what you can come up with.\nTypical Fats Used:\n- Butter (Can produce a crunchy, chewy, or soft cookie based on the other ingredients chosen. Will give the cookie a buttery flavor)\n- Shortening (Is more neutral in flavor than butter. Will generally produce a very soft and tender cookie)\n- Butter Flavored Shortening (Will also generally produce a very soft and tender cookie but adds the buttery flavor)\n- Vegan Butter Substitute such as Earth Balance (Will produce a similar result as shortening)\nOther Fats and Fat Substitutes:\n- Yogurt (will add moisture and flavor depending on the flavor used. Plain yogurt will add a tanginess)\n- Apple Sauce (Adds moisture, and a slight apple flavor)\n- Mashed Banana (Will add a distinct banana flavor, holds moisture in the cookie well, and creates a soft cookie)\n- Nut Butters (Can produce a crunchy or soft cookie and a distinct flavor depending on the flavor used.)\n- Oil (canola, olive, vegetable) (Can create a very moist cookie. Cookie is usually more flat and crisp. Olive oil will add a slight flavor)\n- Sour Cream (will add moisture and a tanginess)\n- Pumpkin (Will add a distinct pumpkin flavor, holds moisture in the cookie well, and creates a soft cookie)\nStep 4: Choose a Sweetener\nIf you’ve made cookies enough times, I’m sure you notice that they almost all start with creaming a fat and sweetener together. Most frequently this involves butter and sugar. The sweetener chosen is important for the texture of the cookie, the flavor, the structure, and obviously the sweetness.\nWhen deciding on how much sweetener to use, it really depends on which kind you choose. If I’m using traditional sugar, I usually keep it to 1/2 cup – 1 cup when using a 1/2 cup fat.\nIt really depends on what other things I am adding to the recipe and how sweet they are as well as how sweet I am wanting the cookie to be. I also often use a combination of white and brown sugar or sometimes sugar and maple syrup if I am wanting to add a maple flavor.\n- Granulated Sugar (a high ratio of granulated sugar to brown sugar, or using all granulated sugar, will produce a more crisp cookie)\n- Brown Sugar (brown sugar adds moisture and chew to the cookie and will also give it a more rich flavor)\n- Dark Brown Sugar (dark brown sugar adds even more moisture and chew to the cookie and will also give it a more rich flavor)\n- Honey (Will add more moisture and therefore more flour may be needed. Has a distinct flavor)\n- Maple Syrup (Will add more moisture and therefore more flour may be needed. Has a distinct flavor)\n- Agave Nectar (Will add more moisture and therefore more flour may be needed. Has a mild flavor)\n- Coconut Sugar (Similar in flavor as brown sugar but will not add as much moisture and chew as brown sugar. Has a lower glycemic index and tastes a little less sweet)\n- Dates (Less sweet than most other sweeteners, brings an earthy flavor)\n- Imitation Sugar such as Splenda and Stevia (usually more sweet than traditional sugar, can add a bitter aftertaste)\nStep 5: Choose Binders/Leavening Agents\nNot all cookies need a binder or leavening agent, though most cookies do. Eggs are the most common binder but also do some leavening in the cookie as well as adding tenderness and moisture. Baking soda and baking powder are also leavening agents.\nI usually start with 1 egg for this size of recipe and about 1 tsp of baking soda. Read this post for a more in depth look at baking powder and baking soda…If you want a flat crumbly cookie, such as shortbread, you don’t need eggs or any leavening agents.\n- Eggs (Raises the baked good, binds well, adds moisture and chew. Egg white makes a more crisp cookie)\n- Ener-G Egg Replacer (Vegan egg replacer, Binds well but does not add as much chew as a regular egg)\n- Applesauce (Adds moisture and helps with binding, does not raise the baked good)\n- Banana (Adds moisture and softness, does not raise the baked good. Adds a distinct banana flavor)\n- Chia or Flax Egg (Binds well, adds moisture, and chew. Does not raise the baked good)\n- Baking Soda (Add to cookie recipes with an acidic component already present)\n- Baking Powder (Add to cookie recipes with no acidic component or along with baking soda to produce more rise to a baked good)\nStep 6: Add Salt and Liquid Flavorings\nNotice how I didn’t give you the choice about salt? In my mind it isn’t a question if there will be salt in my cookie recipes. There always is. I guess that is your call, I’m not a person to demand you to do anything. But if you are asking me, add salt!\nI suggest about 1/4 – 1/2 tsp for this size of recipe. Salt is an ingredient that only affects the flavor and enhances the other flavors. It does not affect the texture of the cookie.\nSame goes for extracts. If you are going to use vanilla or other extracts know that it is only affecting the flavor. I get that question a lot. People will ask if they can omit an extract and the answer is always “yes.” It will change the flavor, but the cookie will still turn out.\nUse 1/4 tsp- 1/2 TBSP for this size of a recipe. If I want a strong vanilla flavor I go with 1/2 TBSP, but other extracts that are stronger such as almond I would go with much less such as 1/4-1/2 tsp.\nStep 7: Choose a Flour\nFlour is a no-brainer. All cookie recipes, minus a very few flourless recipes, have some kind of flour! All-purpose if the most common flour used, but there are other great options depending on the texture you are looking for!\nFor this size of recipe about 3/4 cup-1 1/2 cup total flour is needed. Start with less and add more flour to get the desired dough consistency.\nI often use a combination of all-purpose flour and wheat flour or oatmeal flour depending on my desired texture.\nTypical Flour Choices\n- All-Purpose Flour (A very versatile flour that works well in most cookie recipes)\n- Bread Flour (Will add more chew to the recipe due to a higher protein content)\n- Cake Flour (Will create a more fluffy and soft cookie due to a lower protein content. Weighs less than other flours and therefore requires more to create the same structure as all-purpose flour)\n- Whole Wheat Flour (Adds a great texture and flavor when used in part combination with white flour. Can create a dryer cookie and less flour is needed compared to all-purpose flour. Also creates a taller cookie.)\n- Oatmeal Flour (Adds great texture and lots of chew. Is often used in combination with other flours)\n- Gluten-Free Flour Blends (Endless different blends and varieties with varying results.)\n- Cocoa Powder (Though not technically a flour, it sort of acts as such. If you are using cocoa powder in your recipe to create a chocolate cookie, reduce the amount of flour used accordingly.)\nStep 8: Add Mix-ins\nAfter the dough is the desired consistency, add any mix-ins (chocolate chips, nuts, dried fruit, etc…) For this size of recipe about 3/4 cup – 1 1/2 cups total mix-ins typically works well.\nStep 9: Baking Time and Temp\nCookies are usually baked in at a temp somewhere between 325-375 degrees F. A lower cooking temp will allow the fat to melt slowly before the cookie sets usually resulting in a flatter cookie. A high cooking temp will set the cookie before the fat melts, usually resulting in a taller cookie.\nBaking time will vary on temperature and ingredients chosen Set a timer for 5 minutes and check on them. You can then estimate how much longer they will need. Typically a sheet of cookies will cook somewhere between 8-14 minutes.\nStep 10: Make Fillings or Frostings if Desired\nAlways fill or frost cookies when completely cooled.\nStep 11: Taste and Adjust\nThis process has been pretty successful for me and often the first round of my recipe creation comes out about the way I had hoped (with only a few minor adjustments needed), though sometimes it doesn’t.\nWhen the cookies are cooled, taste them and make notes. Notice the flavor profile. Is everything balanced or do you need more or less of specific flavors? How is the texture? Do you need more moisture or less?\nMake notes and changes. Try not to change too many different things in each round of experimenting or it can be difficult to determine what is working and what isn’t. But trial and error is the best way to become great at creating your own original recipes!\nA few of my favorite cookie creations are…\nProducts I use and recommend for cookie baking!\nDisclaimer: This post contains affiliate links.']"	['<urn:uuid:2f13c3ed-0be9-41d3-bf4e-3cdd35769a31>', '<urn:uuid:ef0efff2-9959-4ef9-a587-5f4294fc47ff>']	open-ended	with-premise	short-search-query	similar-to-document	comparison	expert	2025-05-13T01:50:22.828293	8	81	2808
4	distance helix nebula earth light years	The Helix Nebula lies about 700 light-years away from Earth.	['Here are some beautiful space photos and videos that have been posted on the Internet recently. The photos are from NASA’s “Astronomy Picture of the Day.” Enjoy!\nStunning emission nebula IC 1396 mixes glowing cosmic gas and dark dust clouds in the high and far off constellation of Cepheus. Energized by the bright, bluish central star seen here, this star forming region is 3,000 light-years from planet Earth.\nAssembled from high-resolution scans of the original film frames, this panorama sweeps across the magnificent desolation of the Apollo 11 landing site on the Moon’s Sea of Tranquility. Taken by Neil Armstrong looking out his window of the Eagle Lunar Module, the frame at the far left (AS11-37-5449) is the first picture taken by a person on another world.\nGlobular clusters of stars, such as M72, once ruled the Milky Way. Back in the old days, back when our Galaxy first formed, perhaps thousands of globular clusters roamed our Galaxy. Today, there are less than 200 left. Many globular clusters were destroyed over the eons by repeated fateful encounters with each other or the Galactic center. Surviving relics are older than any Earth fossil, older than any other structures in our Galaxy, and limit the universe itself in raw age. There are few, if any, young globular clusters in our Milky Way Galaxy because conditions are not ripe for more to form. Pictured above by the Hubble Space Telescope are about 100,000 of M72’s stars. M72, which spans about 50 light years and lies about 50,000 light years away, can be seen with a small telescope toward the Name A Star Live constellation Aquarius (the Water Bearer).\nThis is the ultimate cute, space video — “A Toy Train in Space” — a story of a father who sends his son’s toy train to the edge of space.\nThis is an absolutely beautiful video called “Purely Pacific Northwest” that features views of the Northern Lights and the Milky Way. View this one after a hard day’s work!\nHere are some beautiful space photos that have been posted on the Internet in recent weeks. Enjoy!\nWill our Sun look like this one day? The Helix Nebula, located in the Name A Star Live constellation Aquarius, is one of brightest and closest examples of a planetary nebula, a gas cloud created at the end of the life of a Sun-like star. The outer gasses of the star expelled into space appear from our vantage point as if we are looking down a helix. The remnant central stellar core, destined to become a white dwarf star, glows in light so energetic it causes the previously expelled gas to fluoresce. The Helix Nebula, given a technical designation of NGC 7293, lies about 700 light-years away and spans about 2.5 light-years. The above picture was taken in three colors on infrared light by the 4.1-meter Visible and Infrared Survey Telescope for Astronomy (VISTA) at the European Southern Observatory’s Paranal Observatory in Chile.\nOrbiting in the plane of Saturn’s rings, Saturnian moons have a perpetual ringside view of the gorgeous gas giant planet. Of course, while passing near the ring plane the Cassini spacecraft also shares their stunning perspective. The rings themselves can be seen slicing across the middle of this Cassini snapshot. The scene features Titan, largest, and Dione, third largest moon of Saturn. Remarkably thin, the bright rings still cast arcing shadows across the planet’s cloud tops at the bottom of the frame. Pale Dione is about 1,100 kilometers across and orbits over 300,000 kilometers from the visible outer edge of the A ring. Dione is seen through Titan’s atmospheric haze. At 5,150 kilometers across, Titan is about 2.3 million kilometers from Cassini, while Dione is 3.2 million kilometers away.\nCosmic dust clouds ripple across this infrared portrait of our Milky Way’s satellite galaxy, the Large Magellanic Cloud, which is visible in the southern hemisphere constellations Dorado and Mensa. In fact, the remarkable composite image from the Herschel Space Observatory and the Spitzer Space Telescope show that dust clouds fill this neighboring dwarf galaxy, much like dust along the plane of the Milky Way itself. The dust temperatures tend to trace star forming activity. Spitzer data in blue hues indicate warm dust heated by young stars. Herschel‘s instruments contributed the image data shown in red and green, revealing dust emission from cooler and intermediate regions where star formation is just beginning or has stopped. Dominated by dust emission, the Large Magellanic Cloud’s infrared appearance is different from views in optical images. But this galaxy’s well-known Tarantula Nebula still stands out, easily seen here as the brightest region to the left of center. A mere 160,000 light-years distant, the Large Cloud of Magellan is about 30,000 light-years across.\nGalaxies are fascinating not only for what is visible, but for what is invisible. Grand Spiral Galaxy NGC 1232, captured in detail by one of the new Very Large Telescopes, is a good example. The visible is dominated by millions of bright stars and dark dust, caught up in a gravitational swirl of spiral arms revolving about the center. Open clusters containing bright blue stars can be seen sprinkled along these spiral arms, while dark lanes of dense interstellar dust can be seen sprinkled between them. Less visible, but detectable, are billions of dim normal stars and vast tracts of interstellar gas, together wielding such high mass that they dominate the dynamics of the inner galaxy. Invisible are even greater amounts of matter in a form we don’t yet know – pervasive dark matter needed to explain the motions of the visible in the outer galaxy. The Grand Spiral Galaxy is located in the constellation Eridanus, right below the Name A Star Live constellation Taurus.\nIn late January 2012 a strong solar storm hit Earth’s atmosphere. Charged particles from the sun interacted with the Earth’s magnetic field to create spectacular night shows of green light — the “Northern Lights,” or “Aurora Borealis.” See a beautiful video of the Northern Lights shot in late January from Norway!']	['<urn:uuid:46c0b57c-e498-4892-85ff-6e8683d16abf>']	factoid	with-premise	short-search-query	similar-to-document	single-doc	expert	2025-05-13T01:50:22.828293	6	10	1006
5	I heard that Majestic makes some nice percussion instruments, but when did they actually start making them? I'm curious about their history.	The Majestic brand name was introduced in 1960, starting with drum kits which were popular among rock bands in the Netherlands.	"['Introducing the Majestic Grand Classic hammered copper deep cambered timpani\nThe Grand Classic Series epitomises the peak in timpani performance. The best sound, projection, and long lasting quality ensures a timpani perfectly suited to the most demanding professional orchestras and recording percussionists. Grand Classic timpani are available with either a clutch pedal or ratchet pedal depending on your preference.\nPlease note: these can be supplied in a German setup upon request.\nQuality hammered copper kettle\nCopper kettles are a time tested, extremely popular choice - and for good reason. Not just aesthetically pleasing, they also produce a fantastic sound with a rich overtone series. These kettles have been hammered using an accurate computerised process that hardens the copper, opening up the sound. The fully suspended kettles promote maximum resonance for a warm sound with generous projection. Precisely tuned, and made with a deep camber these timpani produce an even and powerful tone across the full range.\nThe ratchet pedal system\nThis mechanism is named as such due to the ratchet style teeth that are utilised to lock the pedal in place. To adjust, the player disengages the pedal with a sideways motion of the foot, moves the pedal up or down to the required position, and the re-engages the pedal at this new point to lock it into place. This system creates tension that is felt via the pressure of the pedal so the timpanist can \'feel\' the tuning of the drum. It does allow for a certain amount of fine tuning, however if you require \'infinite\' fine tuning possibilities we would recommend the clutch pedal system Grand Classic timpani.\nSymphonic series timpani are equipped with the well known and eye-pleasing Majestic tuning gauges, which are extremely accurate and easily adjustable. These timpani are also fitted with fine hand tuners, offering a greater range of control for professional players.\nRange and sizes available\nEach timpani is tuneable within a 1 octave range and come in the following sizes: 20"", 23"",26"", 29"", & 32"". Like all Majestic timpani, they are supplied with an international setup as standard, but can be supplied with a German setup upon request.\nREMO® timpani heads\nThe heads used are the Remo Renaissance timpani heads so you can be assured of long lasting quality with a great response and tone right from the start.\nMajestic is a brand of thoughtfully designed instruments for the professional, the educator, and today’s percussion student utilizing carefully constructed ideas born from both traditional percussion instrument heritage and a culture of innovation. The family firm was founded in 1921, supplying organs, pianos and wind instruments with the production of percussion following shortly after.\nIn 1960 the Majestic brand name was introduced, starting with drum kits which were prevalent among rock bands in the Netherlands. Orchestral and marching percussion soon became the corner stone of the brand, with timpani, marching drum and tuned percussion becoming areas of speciality for Majestic.\nTo this day product development, engineering, and production are overseen by family members and every model must adhere to stringent standards of craftsmanship and performance.\nPlease note: all large tuned percussion instruments such as xylophones, marimbas, and vibes etc. are delivered boxed and require assembly.']"	['<urn:uuid:d2636d9d-e04a-4c24-a568-7ca910b6f811>']	factoid	with-premise	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-13T01:50:22.828293	22	21	532
6	How do proper storage methods differ between crystal-growing solutions and hazardous laboratory chemicals, and what emergency protocols apply when handling these materials?	For crystal solutions, they should be stored in clean glass jars, covered with waxed paper or coffee filters to prevent dust while allowing evaporation, and placed in undisturbed locations. For hazardous chemicals, they must be stored in fire-resistant cupboards, with flammable liquids kept separate from oxidizing agents, and large bottles of corrosive materials stored below waist level. Emergency protocols include having first-aid kits readily available, maintaining clear emergency exits, treating minor injuries with first aid before seeking medical attention, and for major injuries, keeping the victim warm and quiet to minimize shock. In case of poisoning, large amounts of water should be given to dilute the poison while awaiting medical help.	['Make Salt Crystals Science Project\nThis article has information on how to make a salt crystals as a science project. You will also find an second project on how to make sugar crystals. Doing both allows comparison of the salt crystal science project and the sugar crystal science project.\nThis article presents a project for making salt crystals and an extension in which you make sugar crystals and compare the two.\nMake Salt Crystals\nIn this project, students observe crystal formation as they make salt crystals.\n- Clean, wide-mouthed glass jar\n- Non-iodized table salt (up to ½ c)\n- A pencil\n- Sturdy string\n- A spoon\n- Put tap water in the jar up to about the halfway point.\n- Add several Tbsp of salt and stir with a spoon until the salt dissolves. Continue adding salt, about a tsp at a time, until is starts collecting rather than dissolving.\n- Tie a length of the string around the center of the pencil. Adjust the string so that it ends just above the water.\n- Place the jar in a place where it will not be disturbed.\n- Check the jar after one day, and then every day or every other day (whichever you like) for up to 3 weeks. Record the progress of the crystal formation. Also note the change in the height of the water.\nNote: do not eat the salt.\nMake Salt Crystals Extension\nIn this project, students observe crystal formation as they make rock candy.\n- 4 c granulated sugar\n- 2 c water\n- a saucepan\n- a heat-proof spatula\n- a clean glass jar\n- waxed paper or a coffee filter\n- Heat the water to a boil.\n- Pour in the sugar, stirring continuously, until it is clear.\n- Remove the saucepan from the heat, and cool the mixture.\n- Use the mixture to dampen the string, then either let it dry for a day or roll it in dry sugar, shaking off excess. Either of these techniques will prime the surface of the string for the growth of larger crystals.\n- Pour the contents into the jar (this may be best done in a sink).\n- Tie the string to the center of the pencil. Rest the pencil across the top of the jar, with the string extending into the center of the jar, not touching the sides.\n- Cover the top of the jar with a piece of waxed paper or a coffee filter, neither of which will prevent evaporation, but will keep dust, etc. out.\n- Carefully place the jar somewhere in which it can sit undisturbed for up to a week.\n- Check the growth daily, removing any sugar crust the form on the surface.\n- Compare the growth and the crystals to the salt: how are they similar? how do they differ?\n- Remove the rock candy when you are happy with its size. It can be eaten as is or dried first.\n- If crystals are tending to form on the jar, rather than on the string, you can gently remove the string and reheat the syrup, which will dissolve the crystals. Cool the syrup, pour it into a clean jar, and rehang the string (if you hang the string in warm syrup, the crystals that have already formed may begin to dissolve).\nTo extend the project, you can consider the following:\n- Add food coloring to the water in which you make either salt or sugar crystals.\n- Experiment with different lengths of string, i.e., hanging the string so that it is partially in the water as you create salt crystals.\n- Hang a string into the salt or sugar water with a paper clip tied to the end.\n- Hang multiple strings into the water close together. Hang multiple strings farther apart. What happens?\n- Drop a length of string entirely into the salt water and see what happens.\n- Try heating the water before putting it in the jar to make salt and compare the results.\n- Try using different types of salt, such as iodized salt, sea salt, Kosher salt, and Epsom salts.\n- Try adding flavoring to the sugar.', 'SOP On Safety In Quality Control Laboratory\nThe purpose of this SOP is to lay down a procedure for describe safety aspects and precautions during working in the department.\nThis SOP on Safety in Quality Control Laboratory is applicable for guidelines regarding safety hazards occurring during laboratory working and to guide on safe handling of various reactions during analysis, and handling some of corrosive and poisons like Potassium Bromide in Quality Control Department at manufacturing site.\n- Analyst or his designee shall be responsible for follow the SOP.\n- The Head of Quality Control Department or his designee shall be responsible and implementation of the SOP.\n- BASIC SAFETY PRACTICES – SOP on Safety in Quality Control Laboratory\n- Keep the work area clean before and after each activity/analysis.\n- Deposit garbage, wastes etc. in the appropriate dustbins meant for them. Keep the floors dry by mopping up any spillage soon after it occurs.\n- Keep all gangways, emergency exits and staircases free from obstructions. Make sure that all fire-fighting equipment is readily accessible.\n- Collect broken glass pieces with a broom and dustpan. Broken pieces of glass must be picked up from the floor by using a wet cloth and ‘never with bare hands’. All broken glassware should be collected in a separate dustbin. At the end of the week or as and when required, all broken glassware should be disposed in the scrap yard.\n- Do not eat, drink or smoke in the laboratory. Do not store food in the work areas and do not keep food or drinking water in refrigerators that are used to store chemicals, reagents and biological materials. Do not drink water kept in laboratory wash bottles.\n- Wash the hands thoroughly with soap and water or where necessary with cleaning agents, after leaving the work area.\n- Wear suitable protective gear such as helmets, safety goggles, face shield, safety foot wear, gloves (acid proof, alkali proof and Kevlar) etc., while doing hazardous jobs and during sampling in the Stores area.\n- Always use a rubber bulb or pump to withdraw solutions. Use a dispenser to withdraw corrosive liquids like strong acids or alkalis.\n- When boiling a solution in a test tube keep the mouth of the test tube away from the co-worker next to you and away from yourself.\n- Handle hot glassware carefully e.g. distillation assembly, articles removed from muffle furnace, driers etc. (Hot glass looks exactly the same as cold glass). Always wear Kevlar hand gloves while handling hot glassware.\n- Never carry out unauthorized experiments and never taste, smell or inhale any chemicals in the laboratory.\n- An open flame may be ignited only when no flammable solvents are in the vicinity.\n- BENCH OPERATIONS – SOP on Safety in Quality Control Laboratory\n- Do not start an experiment on a bench already crowded with apparatus or equipment. Clear the workbench of unwanted chemicals and reagents.\n- Before starting a test, familiarize yourself with the known hazards of the material (Refer Material Safety Data Sheet) and the operations to be performed and equip yourself with the necessary protective gear and devices.\n- Ensure that all reagent bottles, containers and other glassware in use are correctly and clearly labeled.\n- Pour liquids in a direction away from the label to avoid damaging the label. If any liquid spills over the sides of the container, wash or wipe the surface with water before returning it to the shelf.\n- Examine all glassware for damage before use. Do not use cracked, chipped or any other defective glassware.\n- Support all large glass flasks adequately. Additional support at the base improves stability.\n- Use lubricant and a cloth for protection when inserting glass tubing rods and thermometers into bungs or tubing. While cutting a glass tube or rod, use gloves and safety goggles.\n- To remove tight glass stoppers, tap alternately on each side of the stopper or sonicate. If this does not work and the contents of the bottle are not flammable or toxic, gently warm the neck of the bottle.\n- Carry out tests involving hazardous and fume-generating chemicals only in a fume hood with proper exhaust systems.\n- SOLVENT EXTRACTION – SOP on Safety in Quality Control Laboratory\n- When using a separating funnel for solutions containing solvents release the pressure developed on shaking by inverting the funnel with the stopper securely held and opening the tap with care. Point the funnel away from the eyes and any source of heat such as a naked flame or heating mantle.Ensure that the condensing system above a Sox let extraction unit is adequate to cope with the solvent in use.Removal of solvents in an experiment involving flammable solvents should be carried out using a water-bath or electrically heated bath.For low-boiling liquids such as liquor ammonia, ether etc., cool the container before opening, using protective equipment such as gloves and safety goggles.\n- HANDLING OF GAS CYLINDERS\n- Store cylinders in a well-ventilated place in an area where no flammable substances are stored.\n- Protect cylinders from direct sunrays and avoid storage on wet ground.\n- Never drag or roll a compressed gas cylinder. Use a handcart to transport cylinders.\n- Use cylinders in an upright position. Always secure and chain them to prevent accidental knocking over.\n- Always use a pressure-reducing regulator free from oil and grease, attached to the cylinder valve. Keep the metal cap in place to protect the cylinder valve. Before removing a regulator from the valve, close the valve and release the gas from the regulator.\n- Do not use an oxygen cylinder with oily hands or oily gloves as even a small amount of oil or grease may ignite violently in the presence of oxygen released under pressure.\n- HAZARDOUS CHEMICALS\n- Wear safety goggles, and nose masks where considered necessary. Use a face shield and protective gloves while handling hazardous chemicals.\n- Transport containers of capacity of one liter or more in stainless steel carriers and containers of capacity five liters or more on a trolley and do not carry the chemicals in open containers.\n- FLAMMABLE LIQUIDS\n- Store bare minimum stock of solvents in the laboratory. Store liquids that are not in use preferably in a suitable fire resistant cupboard or bin, made of steel or wood. The cupboard must be robust, properly labeled and not used for any other materials.\n- Return the solvent bottles to the storage area after use.\n- Do not store flammable solvents in the refrigerator as the electrical control and switches in the refrigerator may cause sparks, which could be a source of ignition for flammable vapors. Do not store flammable liquids near oxidizing agents such as chromic acid, permanganates, chlorate and per chlorates.\n- Isolate experiments which require large amounts of flammable solvents and ensure that adequate fire-extinguishers are available. Use a water-bath or electric heating mantle when large amounts of flammable solvents are to be heated. Do not pour out solvents near a naked flame.\n- If any spillage of flammable solvents occurs, use a suitable absorbent to absorb the liquid and dispose off the contaminated absorbent by incineration in a pit.\n- Do not pour water-immiscible solvents down the drains.\n- Never mix miscible and immiscible waste solvents in a common bottle or carboy.\n- CORROSIVE CHEMICALS\n- While handling corrosive chemicals, use safety apparel such as nose masks, rubber gloves, safety goggles, rubber aprons etc. Avoid contact of the chemical with body surfaces, including the alimentary and respiratory system.\n- Do not store large bottles of acids and other corrosive materials above waist level.\n- Do not leave apparatus containing corrosive materials at the sink, to be washed; always drain out the contents and rinse the apparatus with tap water before leaving it for washing.\n- HANDLING OF POISONOUS CHEMICALS\n- Handle poisonous chemicals with abundant caution. Ensure that the containers are well sealed after use and only then placed in the cupboard.\n- Carry out the work involving poisons in the fume hood only and do not inhale poison fumes. Wear gloves if large volumes are to be handled.\n- After working with poisonous chemicals wash the work place and contaminated glassware with dilute alkali solutions followed by water.\n- Keep antidotes for each poisonous chemical (up to the extent possible) in the laboratory.\n- Wash any contacted skin area with soap and water at once.\n- ELECTRICAL HAZARDS\n- See that all wires are properly insulated and instruments well earth.\n- Ensure that no water points or rubber connections carrying water are allowed to leak on to electrical plugs and switches.\n- Ensure that worn or damaged cables, sockets and plugs are replaced promptly.\n- BACTERIAL HAZARDS\n- Place contaminated glassware in a chemical disinfectant immediately after use and before cleaning and reusing.\n- Decontaminated waste, including specimens of bacteria, by effective means prior to disposal as refuse or seal in sturdy, impervious containers for incineration.\n- Sterilize culture plates and tubes adequately before washing or discarding them.\n- Clean bench tops, incubators, furniture and floors that may be contaminated, at least weekly with an effective disinfectant.\n- Clean and disinfect any spillage immediately.\n- FIRE SAFETY\n- Ensure proper use, storage and disposal of flammable and combustible liquids/ solids used in the laboratory.\n- Equipment and instruments to be inspected periodically for electrical wiring, earthing and general cleanliness.\n- Check regularly all fire-fighting equipment and ensure that they are in operating condition. Ensure that a sufficient number of people are trained in the use of the equipment.\n- If any fire is small immediately control it with a fire extinguisher. If it is of a more serious nature, raise the alarm and follow the factory drill for fighting fires.\n- Use carbon dioxide or any other suitable fire extinguishers for instruments.\n- Identify the safety squad and train them.\n- In case of an emergency know the location and operation of\ni. Fire extinguishers\nii. Safety air shower, Eye washer\niii. Fire alarm\n- Ensure that there is a first-aid kit in the laboratory and that it is adequately stocked with the basic supplies of first- aid materials.\n- In an emergency follow the laid down factory procedure and have first aid rendered by people trained in first-aid techniques.\n- Keep the emergency exit free of obstructions.\n- Do not use lift for evacuation during an emergency.\nUse the staircase.\n- Treat minor injuries by rendering first aid and then send the victim to a medical center for further treatment.\n- For major injuries arrange for immediate medical aid. Do not move the person except to a position of less danger. Keep the person warm and quiet to minimize the effects of shock.\n- In the event of poisoning immediately give large amounts of water to dilute the poison and call for a doctor. In the case of gas poisoning transfer the victim into fresh air surroundings immediately and if breathing has stopped give artificial respiration. If person is unconscious, do not give anything from mouth.\n- In case of electric shocks switch off the main switch and push the victim away from the electric wires with a dry non-conducting material, by standing on a dry board or a rubber mat. Do not touch the victim until contact with the source of current is broken.\n- Treat eye injuries by flushing with water immediately for about 15 minutes and rush the victim to a doctor for treatment.\nTrainer : Head – Quality Control\nTrainees : Quality Control chemist / Sectional Heads\n- REFERENCES(S) :']	['<urn:uuid:30436780-1f76-4981-a736-7a3ff274451f>', '<urn:uuid:6c0f6980-7c63-4c61-999d-e464fd1d22b1>']	open-ended	direct	verbose-and-natural	distant-from-document	multi-aspect	expert	2025-05-13T01:50:22.828293	22	111	2632
7	Who speaks earlier, Towsley or Mwangola at their respective events?	Dr Mshaï Mwangola performs before the inaugural panel at the Climate.Culture.Peace conference, while Don Towsley gives his keynote at 1:10pm during the PMHO workshop. Without knowing the exact time of the Climate.Culture.Peace conference's inaugural panel, it cannot be determined who speaks earlier.	['Join us in the sharing of stories, experiences and viewpoints on global climate change, which affects us all.\nWe are excited to announce that you can now register for free to attend the Climate.Culture.Peace conference using this link.\nClimate.Culture.Peace is a unique initiative looking to explore the interconnections between climate change, culture and heritage, peace and conflict, and disaster resilience. The conference (24-28 January) will foster a welcoming and interactive digital space, where we will host a diverse range of interesting and informative sessions to exchange knowledge and share experiences, practices, and research.\nThis initiative is generously supported by the British Council’s Cultural Protection Fund (CPF) in partnership with the Department for Digital, Culture, Media and Sport (DCMS) and seeks participation from all CPF target countries.\nKicking off the conference is our inaugural panel on “Culture for a Liveable Future”, connecting leadership, research, policy and action. Culture and heritage bring together the full range of human experience from the past into the present and help create a liveable future. We are honoured to be joined by a diverse group of distinguished leaders, policy advisors, influencers and scientists, who will share vital insights from their own work, recognizing that what we know about climate change, culture, sustainability and peace, must include the processes as well as history of how we know it.\n- Dr Webber Ndoro, Director-General ICCROM\n- Honourable Minister, Mr. Simon Kofe, Minister for Justice, Communication & Foreign Affairs, Tuvalu\n- Her Royal Highness Princess Dana Firas, UNESCO Goodwill Ambassador for Cultural Heritage and President of Petra National Trust, Jordan\n- Mr Ernesto Ottone Ramírez, Assistant Director-General for Culture, UNESCO\n- Dr Alexandra Xanthaki, United Nations Special Rapporteur in the field of cultural rights\n- Mr Tim Badman, Head of Heritage, Culture, Youth, IUCN\nThe inaugural panel will be preceded by a performance by a widely renowned Kenyan performance scholar, peacebuilder, storyteller and oraturist, Dr Mshaï Mwangola. She is known for her storytelling work connecting the performing arts, conflict transformation, development, and gender and environmental protection. (TedX Talk)\nA conference featuring global voices\nThe global reach of the conference, with our 55 partners and over 150 contributions coming from 56 countries, seeks to gather diverse knowledge holders, policy advisors, practitioners, as well as community and youth leaders, and foster a dialogue on culture as the missing link in climate action.\nOur range of interactive sessions has something for everyone\n- Youth Forum “Voices of Now and Future”: Sessions organized and led by youth organizations active in climate change\n- Interactive Workshops: Training opportunities on climate, culture, peace\n- Thematic Presentations: Sharing of Knowledge, practice, and/or research based upon interconnected themes, and followed by a Q&A discussion.\n- Discussion Forums: Guided 60-minute discussions to explore regional issues and questions\n- Panel Presentations: A round-up of current issues that seek to advance knowledge and fill information gaps by utilizing multi-sectorial thinking\n- Ignite Talks: Speedy talks that will briefly introduce ideas, issues, and/or solutions in order to spark further discussion\n- Positive Change Envisioning Exercise: Join a virtual activity that encourages different approaches to hope, inspiration, and the future.\n- Climate Open Mic: An open space for discussion and reflection on the day’s events.', 'PPoPP Workshop on Principles of Memory Hierarchy Optimization (PMHO)\nVideo recordings of this year’s talks:\nKEYNOTE: Advances in Modeling and Optimization of Caches. Don Towsley.\nCARL: Compiler Assigned Reference Leasing. Chen Ding.\nCaching With Delayed Hits. Nirav Atre.\nDelayed Hits in Multi-Level Caches. Benjamin Carleton.\nA Study on Modeling and Optimization of Memory Systems. Xian-He Sun.\nLHD: Improving Cache Hit Rate by Maximizing Hit Density. Nathan Beckmann.\nOn the Impact of Network Delays on Time-to-live Caching. Karim Elsayed.\nSaturday 4/2/2022 1pm to 5pm US EDT (GMT -4), 6pm to 10pm Germany, 10:30pm to 2:30am India, 1am to 5am China, 2am to 6am Korea\nZoom Link: https://acm-org.zoom.us/j/92042756839?pwd=TllNMlVaeXQybkpWczh3ZnMxVDdFZz09\nMeeting ID/Passcode: 920 4275 6839 / PPoPP@2022\nRecent Advances in the Modeling and Optimization of Caches\nDonald F. Towsley, Distinguished Professor, University of Massachusetts Amherst\nThe keynote lecture covers the following results.\n- An optimization-based approach to caching\n- A simple, very accurate model of LRU and variants\n- A new approach to bounding performance of caching policies based on a very simple ordering of failure rates of request distribution along with an application to on-line caching.\nThe material is based on the following publications: Deghgan et al. “A Utility Optimization Approach to Network Cache Design,” IEEE/ACM Transactions on Networking, 27(3), 1013-1027, June 2019; “Sharing Cache Resources among Content Providers: A Utility-Based Approach,” IEEE/ACM Transactions on Networking, 27(2), 477-490, April 2019; Jiang et al. “On the Convergence of the TTL Approximation for an LRU Cache under Independent Stationary Request Processes”, ACM TOMPECS, 3(4), 20:1-20:31, September 2018; Panigrahy et al. “A new upper bound on cache hit probability for non-anticipative caching polices,” IFIP WG 7.3 Performance 2020; and Yan et al. “Learning from Optimal Caching for Content Delivery,” Proc. CoNEXT 2021, December 2021.\n|PPoPP Workshop on Principles of Memory Hierarchy Optimization (PMHO)|\n|Saturday 4/2/2022 1pm to 5pm US EDT (GMT -4), 6pm to 10pm Germany, 10:30pm to 2:30am India, 1am to 5am China, 2am to 6am Korea|\n|Welcome and Introduction (1pm)|\n|Keynote (1:10pm to 2:00pm)|\n|Don Towsley: “Recent Advances in the Modeling and Optimization of Caches”.|\n|Session 1 (2:00pm to 2:40pm)|\n|Xian-He Sun: “A Study on Modeling and Optimization of Memory Systems”. JCST Jan. ’21. (2:00pm to 2:20pm)|\n|Karim Elsayed: “On the Impact of Network Delays in Time-To-Live Caching”. Unpublished. (2:20pm to 2:40pm)|\n|Break (2:40pm to 2:50pm)|\n|Chen Ding: “CARL: Compiler Assigned Reference Leasing”. TACO March ’22. (2:50pm to 3:10pm).|\n|Nirav Atre: “Caching with Delayed Hits”. SIGCOMM ’20. (3:10pm to 3:30pm)|\n|Benjamin Carleton: “Evaluating the Impact of Delayed Hits in Multi-Level Caches”. SOSP ’21 SRC Undergraduate Winner. (3:30pm to 3:40pm).|\n|Break (3:40pm to 3:50pm)|\n|Nathan Beckmann: “LHD: Improving Cache Hit Rate by Maximizing Hit Density”. NSDI ’18. (3:50pm to 4:10pm)|\n|Wesley Smith: “Beyond Time Complexity: Data Movement Complexity Analysis for Matrix Multiplication”. Under review. (4:10pm to 4:30pm)|\n|Ke Yang (Video): “Random Walks on Huge Graphs at Cache Efficiency”. SOSP ’21. (4:30pm to 4:45pm)|\n|Open discussion (4:45pm to 5:00pm)|\nFor people who cannot attend, we plan to make the talk videos available as we have done in the 2021 workshop.\n- Chen Ding, University of Rochester\n- Nathan Tallent, Pacific Northwest National Laboratory\n- Wesley Smith, University of Rochester\nCall for Presentations\nData movement is now often the most significant constraint on speed, throughput, and power consumption for applications in a wide range of domains. Unfortunately, modern memory systems are almost always hierarchical, parallel, dynamically allocated and shared, making them hard to model and analyze. In addition, the complexity of these systems is rapidly increasing due to the advent of new technologies such as Intel Optane and high-bandwidth memory (HBM).\nConventional solutions to memory hierarchy optimization problems are often compartmentalized and heuristic-driven; in the modern era of complex memory systems these lack the rigor and robustness to be fully effective. Going forward, research on performance in the memory hierarchy must adapt, ideally creating theories of memory that aim at formal, rigorous performance and correctness models, as well as optimizations that are based on mathematics, ensure reproducible results, and have provable guarantees.\nFormat and Topics\nPMHO is an annual specialized and topic-driven workshop to present ongoing, under review, or previously published work related to the following non-exhaustive topic list:\n- Mathematical and theoretical models of memory hierarchies including CPU/GPU/accelerator caches, software caching systems, key-value stores, network caches and storage system caches\n- Algorithmic and formal aspects of cache management including virtual memory\n- Programming models and compiler optimization of hierarchical complex memory systems\nThere will be no formal peer review process or publication, and presentations will be a mix of selections from submissions and invited presentations.\nThe 2022 workshop will take place online during the weekend of April 2 (Exact date TBD). It is hosted by the PPoPP 2022 conference.\nSubmit your presentation proposal to email@example.com. Submissions should consist of an one-page abstract of the topic you intend to present alongside any (optional) pertinent publications or preprints.\nThe submission deadline is Monday March 7, 2022 AOE.']	['<urn:uuid:c8f11e0f-d6f2-4514-b180-e0be6bf5d0ab>', '<urn:uuid:5d502915-fdde-4b3c-92ae-b74e40aec563>']	factoid	direct	concise-and-natural	distant-from-document	comparison	expert	2025-05-13T01:50:22.828293	10	42	1352
8	researching unesco sites qatar where ancient fort zubarah located distance from doha	Zubarah, also referred to as Al Zubarah or Az Zubarah, is a ruined and ancient fort located on the northwestern coast of the Qatar peninsula, about 105 kilometers (65 miles) from the Qatari capital of Doha.	['Qatar is a sovereign country located in Western Asia, occupying the small Qatar Peninsula on the northeastern coast of the Arabian Peninsula.\nThe official name of the country is the State of Qatar.\nQatar has one land border with Saudi Arabia to the south, and the rest of its territory is surrounded by the Persian Gulf. A strait in the Persian Gulf separates Qatar from the nearby island country of Bahrain, as well as sharing maritime borders with the United Arab Emirates and Iran.\nThe official language of Qatar is Arabic, but English is the second language and is very widely spoken.\nAs of 1 January 2017, the population of Qatar was estimated to be 2,415,588 people.\nIt is the 158th largest country in the world in terms of area with an area covering 11,437 square kilometers (4,416 square miles).\nDoha is the capital city and most populous city of the State of Qatar. The city is located on the coast of the Persian Gulf in the east of the country. It is Qatar’s fastest growing city, with over 50% of the\nnation’s population living in Doha or its surrounding suburbs, and it is also the economic center of the\nQatar’s terrain is mostly a flat and barren desert covered with loose sand and gravel, with some low hills and a central limestone plateau.\nQurain Abu al-Bawl is the highest point of Qatar, with an altitude of 103 meters (343 feet).\nQatar has 563 kilometers (350 miles) of coastline.\nQatar has established 5 terrestrial protected areas accounting for about 18% of the total land area, and 3 marine protected areas.\nAl Reem Biosphere Reserve is an inhabited area of 120,000 hectares (296,526 acres) in northwest Qatar that includes semi-arid desert landscapes that are home to gazelles and Arabian oryx. It is one of 24 UNESCO Biosphere Reserves in the Middle East. It was established in 2005 and accounts for approximately 10% of Qatar’s land area. It was recognized by UNESCO in 2007.\nQatar has 1 UNESCO world heritage site.\nZubarah, also referred to as Al Zubarah or Az Zubarah, is a ruined and ancient fort located on the north\nwestern coast of the Qatar peninsula about 105 kilometers 65 miles from the Qatari capital of Doha. It was founded by Al Bin Ali , main and principal Utub tribe in the first half of the eighteenth century. It was designated a UNESCO World Heritage Site in 2013.\nSouq Waqif is a souq in Doha, in the state of Qatar. The souq is noted for selling traditional garments,\nspices, handicrafts, and souvenirs. It is also home to dozens of restaurants and Shisha lounges. Although it dates back at least a hundred years, it was renovated in 2006 to conserve its traditional architectural style.\nThe Museum of Islamic Art is a museum located on the Corniche in the Qatari capital Doha. The iconic building was designed by architect I. M. Pei. The museum is influenced by ancient Islamic architecture, yet has a unique design. It was the first of its kind in the Arab States of the Persian Gulf and has a very large collection of Islamic art, plus a study and a library.\nKatara is a cultural village in Doha. There are many cultural activities including art exhibitions, indy\nfilms, operas, orchestras and festivals. Built to replicate a traditional Qatari village with a few twists\nthrown in, such as the newly-built Falcon Museum, shaped like a falcon hood.\nThe Imam Abdul Wahhab Mosque more commonly known as the State Grand Mosque, this is the largest mosque in Qatar with 90 domes, 18 entrances and capacity for 30,000 people. Built in 2013, it was named after the 18th century Islamic theologian and inaugurated by the Former Emir Sheikh Hamad bin Khalifa al-Thani.\nThe Pearl-Qatar in Doha is an artificial island spanning nearly 400 hectares. It is the first land in Qatar\nto be available for freehold ownership by foreign nationals. It has residential accommodation, hotels,\nmarina, and retail areas.\nThis oil-rich nation, under British protection until 1971.\nIn 1971, Qatar was to join the other emirates of the Trucial Coast to become part of the United Arab Emirates. But both Qatar and Bahrain decided against the merger and instead formed independent nations.\nQatar has exported oil since 1949, and as reserves decline, the nation has turned to its natural gas.\nQatar has the world’s third largest natural gas reserves and oil reserves.\nQatar is the leading exporter of liquefied natural gas.\nAs of 2016, Qatar has the fourth highest GDP per capita in the world, according to the International Monetary Fund.\nQatar is a constitutional monarchy headed by Emir Sheikh Hamad bin Khalifa al- Thani.\nQatar is classified by the UN as a country of very high human development and is the most advanced Arab state for human development.\nQatari cuisine is made up of traditional Arab cuisine. It is also largely influenced by Iranian and Indian cuisine.\nMachbūs, a meal consisting of rice, meat, and vegetables, is the national dish in Qatar.\nKarak tea is served after meals; the rich milky tea is laced with Cardamom.\nThe national flower of Qatar is Qataf.\nThe national animal of Qatar is the Arabian oryx.\nThe national bird of Qatar is the falcon.\nSport in Qatar is primarily centered on football in terms in participation and spectators. Additionally,\nathletics, basketball, handball, volleyball, tennis, camel racing, horse racing, cricket and swimming are\nalso widely practiced.\nQatar will host the 2022 FIFA World Cup, becoming the first Arab country to do so.']	['<urn:uuid:b7594583-b059-4547-9807-69b707248dc9>']	factoid	with-premise	long-search-query	similar-to-document	single-doc	expert	2025-05-13T01:50:22.828293	12	36	926
9	Which loses more water: average household leaks or garden irrigation?	Garden irrigation uses significantly more water, requiring approximately 45,000 gallons per season for a 50x50 foot lawn, while the average household's leaks account for about 10,000 gallons of water lost yearly.	"['All across the country, water conservation is more important than ever. One of the simplest ways to only use the water you need is to not let any go to waste behind the scenes. While the average household’s leaks can account for nearly 10,000 gallons of water lost every year, 10% of homes have leaks that waste 90 gallons or more a day.\nAs of July 13, 38.9% of the U.S. was in a drought—a 1.1% increase from June. But, even if you are not in an area affected by such conditions it is still important to be aware of ways we can improve our water usage footprints. And, one simple way to start is to identify the symptoms of an already-occurring leak, and some of the hidden causes of potential leaks around the house.\nHere are some tips for managing your home in a way that will prevent leaks and/or catch them early:\n- Test your toilet. Your toilet can be a source of a leak in the home. To test for one, put a drop of food coloring into the toilet tank. After 10 minutes, if any color shows up in the bowl, you have a leak.\n- Listen. One of the easiest ways to check in on your pipes is to listen for drips from faucets or showerheads and running water from your toilet.\n- Stay alert during drastic changes in weather. If the temperature outside is going from hot to cold or vice versa, pipes will expand and contract. This reaction can cause pipes to crack. If you notice a change in water pressure or air in the water line during seasonal changes check your consumption patterns and call a professional to see if you have a leak.\n- Keep an eye on your yard. One of the biggest menaces to service lines in your yard are tree roots. They can intrude on pipes and cause moisture to seep out into the yard. Watch out for new tree growth and look for new wet patches or sinkholes, especially in combination with a sudden drop in water pressure.\n- Be a conscientious gardener. If left on even a little bit, garden hoses can result in wasted water over time. Meanwhile, irrigation systems have the potential to leak underground, so keep an eye out for mushy sod or pooling.\n- Find a good, licensed repairman. One way to prevent leaks from ever happening is to make sure the right person is working on your pipes. Check with a reliable source before embarking on a DIY fix, and, when looking for help, be wary of those prices that seem too good to be true. Remember that spending a little more now can save more money, and water, in the long run.\nAs we see droughts across our country, it reminds us just how important our daily actions can be, especially when it comes to water. Because, when you boil it down, taking better care of our homes can, in return, take better care of our Earth.', 'Most of us don\'t think much about the dripping faucet, leaky hose, running toilet or swampy sprinkler head we may live with for months. But those continuous forms of water waste add up faster than you might think. The tables below illustrate how a tiny leak can turn into a big water bill.\nThe following table uses the same calculations to estimate the consumption with common household measurements.\n|Water Waste Adds Up: Common Measures|\n|If a leak as a continuous flow of:||It wastes the following number of gallons in:|\n|1 Hour||1 Day||1 Year|\n|1 cup (1/16 gal) per minute||4||90||32,850|\n|1 pint (1/8 gal) per minute||8||180||65,700|\n|1 quart (1/4 gal) per minute||15||360||131,400|\n|2 liters (about 1/2 gal) per minute||32||761||277,698|\n|1 gallon per minute||60||1,440||525,600|\nA leak measured in cups is an obvious problem that few of us would ignore. A dripping faucet is harder to measure and easier to let go “for now.” As “for now” stretches to weeks, the water waste adds up, often much faster than we imagine.\nThe amount of water dripping slowly from a faucet is difficult to measure. Not only do drop sizes vary, but terms like “slow drip” vary from person to person. Still, as long as a faucet is leaking, it’s wasting water. And that waste will add up. If all of Denver Water’s single-family residential households found and fixed a one-drip-per-second leak, they would save about 82 million gallons a year.\n|Water Waste Adds Up: Drips Turn Into Gallons|\n|If a leak has a continuous flow of:||It wastes the following number of gallons in:|\n|1 Day||1 Year|\n|5 drips in 30 seconds||1||347|\n|10 drips in 30 seconds||1.9||694|\n|15 drips in 30 seconds||2.9||1,041|\n|20 drips in 30 seconds||3.8||1,389|\n|25 drips in 30 seconds||4.8||1,736|\n|30 drips in 30 seconds||5.7||2,083|\n|35 drips in 30 seconds||6.7||2,430|\n|40 drips in 30 seconds||7.6||2,777|\n|45 drips in 30 seconds||8.6||3,124|\n|50 drips in 30 seconds||9.5||3,472|\n|55 drips in 30 seconds||10.5||3,819|\n|60 drips in 30 seconds||11.4||4,166|\nToilet leaks add up, too\nA leaking toilet pouring water down its outflow tube can easily waste 100 to 250 gallons per day. A stream of water the thickness of a pencil, from a faucet or sprinkler head, filling a cup in 30 seconds equals 1 pint per minute and more than 65,000 gallons per year. Denver Water\'s usage table, ""Where Your Water Goes,"" shows consumption averages for household use.\nLandscape efficiently to prevent waste\nLandscape irrigation typically uses at least half of a household’s total consumption. Kentucky bluegrass, a common type of turf used for lawns in Colorado, will use about 1.5 inches of water in the heat of the summer. Less water use is required in the cooler spring and fall seasons. One gallon of water will cover a one square-foot area of lawn 1.5 inches deep. For the irrigation season, up to 18 gallons per square foot of lawn is required to supplement natural precipitation. As natural precipitation increases, supplemental irrigation demand decreases. Hence, a 50- by 50-foot lawn will require approximately 45,000 gallons per irrigation season (six months).\nSeeding your lawn with native grasses can cut this consumption in half, and planting low-water-use plants can make a big impact in your outdoor water usage too.']"	['<urn:uuid:fa1eb068-0bf9-41a9-a3c4-ae972865d4da>', '<urn:uuid:3041d14d-471f-431d-965f-8ac8199fa3b3>']	factoid	with-premise	concise-and-natural	similar-to-document	comparison	novice	2025-05-13T01:50:22.828293	10	31	1039
10	hip bones cracked effects long term	A pelvic fracture can lead to several long-term complications, both temporary and permanent. These complications can include reduced mobility, chronic pain, internal bleeding, damage to internal organs, problems with urination or bowel movements, and sexual dysfunction.	"[""A pelvic fracture is defined as one or more breaks, also known as fractures, of the bones that make up the pelvis. Several organs, blood vessels, and nerves are located in this area. Because of this, a pelvic fracture is a serious injury that needs immediate care to prevent current and future complications.\nCopyright © Nucleus Medical Media, Inc.\nPelvic fractures are caused by:\nFactors that may increase your chance of a pelvic fracture include:\nA pelvic fracture may cause:\nYour doctor will ask about your symptoms and medical history. A physical exam will be done to assess the extent of your injury. You may be referred to a doctor who is a trauma specialist and/or a doctor who is a bone specialist.\nTests may include:\nImaging tests can evaluate the pelvic region and surrounding structures. These may include:\nA pelvic fracture is a serious injury that may be complicated by injuries to other parts of the body. Proper treatment can prevent long-term complications. Treatment will depend on how serious the fracture is, but may include:\nInitial treatment focuses on managing life-threatening problems, such as bleeding or shock. The fracture may be held in place with a sheet wrap or an external fixation device. With an external fixation device, screws are inserted through the bones and connected to a frame on the outside of the body.\nTraction may be used realign and stabilize the fracture if surgery can't be done right away.\nStable fractures will heal without surgery. Unstable fractures are treated with surgery. Some fractures can be set with an external fixation device. Others may require repair with internal pins, screws, or plates.\nExtra support may be needed to protect, support, and keep the pelvic bone in line while it heals. A walker or crutches may be needed to keep weight off the pelvis.\nPrescription or over-the-counter medications may be given to help reduce inflammation and pain. Blood thinners reduce the risk of blood clots.\nHealing time varies by age and overall health. Young people and those in better overall health heal faster. It may take several months for an unstable fracture to heal.\nComplications of a pelvic fracture can be temporary or permanent. These include:\nActivities will need to be adjusted while your pelvic bone heals, but complete rest is rarely required.\nPhysical therapy or rehabilitation will be used to improve range of motion.\nTo help reduce your chance of a pelvic fracture:\nThe American Pediatric Surgical Association\nOrtho Info—American Academy of Orthopedic Surgeons\nCanadian Orthopaedic Association\nWomen's Health Matters\nCollinge C, Tornetta P III. Soft tissue injuries associated with pelvic fractures. Orthop Clin North Am. 2004;35(4):451-456.\nFemoral shaft fracture—emergency management. EBSCO DynaMed Plus website. Available at:http://www.dynamed.com/topics/dmp~AN~T910561/Femoral-shaft-fracture-emergency-management. Accessed August 30, 2017.\nFracture management of unstable pelvic fractures. American Association of Orthopaedic Surgeons website. Available at: http://www.aaos.org/news/aaosnow/jul09/clinical8.asp. Accessed August 30, 2017.\nFrakes MA, Evans T. Major pelvic fractures. Crit Care Nurse. 2004 Apr;24(2):18-30.\nGrotz MR, Allami MK, Harwood P, et al. Open pelvic fractures: epidemiology, current concepts of management and outcome. Injury. 2005;36(1):1-13.\nMcCormack R, Strauss EJ, et al. Diagnosis and management of pelvic fractures. Bull NYU Hosp Jt Dis. 2010;68(4):281-291.\nMohanty K, Musso D, Powell JN, Kortbeek JB, Kirkpatrick AW. Emergent management of pelvic ring injuries: an update. Can J Surg. 2005;48(1):49-56.\nPelvis fractures. American Academy of Othopaedic Surgeons Ortho Info website. Available at: http://orthoinfo.aaos.org/topic.cfm?topic=a00223. Updated February 2016. Accessed August 30, 2017.\nQuick TJ, Eastwood DM. Pediatric fractures and dislocations of the hip and pelvis. Clin Orthop Relat Res. 2005;(432):87-96.\nTornetta P III, Templeman DC. Expected outcomes after pelvic ring injury. Instr Course Lect. 2005;54:401-407.\nLast reviewed August 2017 by EBSCO Medical Review Board Warren A. Bodine, DO, CAQSM Last Updated: 8/29/2014""]"	['<urn:uuid:32503a0b-5c5f-40c2-a434-c4d59f91fe8b>']	open-ended	with-premise	short-search-query	distant-from-document	single-doc	novice	2025-05-13T01:50:22.828293	6	36	614
11	As a cybersecurity analyst, I need to better detect potential data breaches - how can graph databases help identify malicious activities?	Graph databases are effective for cybersecurity because they can model connections among millions of Internet domains, sites, and servers. By analyzing connectivity patterns (like similar registration details, geographic proximity, or routing paths), transaction patterns (such as sources of denial of service attacks or phishing attempts), and links to known malicious sites, you can detect signs of attempted data breaches. The graph approach can also help identify potentially malicious sites and patterns of behavior indicative of criminal activity.	"['Graph Databases for Analytics (Part 2 of 4): Practical Applications\nIs a graph database the solution to your business problem? In this article we\'ll explore the common characteristics of practical applications for graph databases.\n- By David Loshin\n- July 26, 2016\nWe live in an ever-more-connected world. Smart mobile devices are ubiquitous, and many industries are implementing a wide array of sensors, controllers, and similar devices across different domains.\nThese devices are continuously broadcasting streams of data that contain important information about connections. Relational database systems can represent these links but can\'t capture the characteristics of the links, so this explosion of Internet-connected devices is an opportunity for graph-oriented applications.\nAs discussed in Part 1, graph data processing engines can ingest and represent the qualitative characteristics of both the entities and the links among them. The captured information is embedded in the connections between things, not just the characteristics of the things themselves.\nBusiness environments suited to a graph data processing solution share these general features:\n-- Connectivity: First and foremost, the environment involves documenting and understanding connected entities.\n-- Entity volume: There are a large number of entities that can possibly be connected, such as the number of e-commerce website visitors and the products they view.\n-- Entity variety: There are entities with different characteristics, such as individuals with different job skills using a recruiting application.\n-- Link attribution: There are relevant characteristics associated with the connections between entities. For example, a person may have an employment relationship with a company, and that relationship may have a title, a duration, a location, and a salary.\nWithin such environments, graph databases are best used for solving business problems that involve answering questions related to the topology, or shape, of the graph. Some examples include:\n-- Proximity and distance: How close are two entities to each other within the graph?\n-- Centrality: To what extent is an entity ""important"" in a network; for example, who is the most influential person in a social network?\n-- Density: What entities have the least or most connections?\n-- Communication paths: What are the best ways to propagate information between sets of entities?\n-- Similarity and differentiation: How do the characteristics of the relationships expose similarities or differences among the entities? Can clustering be done using network distance metrics?\nUses for Graph Databases\nIf your enterprise collects connected data elements and needs to answer these types of questions, you can probably think of some applications for graph processing. Uses for graph databases include:\nSocial network analytics for marketing and advertising: Identifying influential individuals within a social network helps target your advertising. If you understand the structure of the connections within self-organized communities, you can customize your promotions to maximize responses and increase revenues.\nCybersecurity: The graph paradigm is a good fit for modeling the connections among millions of Internet domains, sites, and servers. You can detect telltale signs of an attempted data breach by analyzing the connectivity patterns (e.g., similar registration details, geographic proximity, or routing paths), transaction patterns (e.g., sources of denial of service attacks or phishing attempts), and links to known malicious sites. Patterns of connectivity can also identify possibly malicious sites as well as behaviors indicative of criminal activity.\nLogistics: A supply chain demonstrates hierarchical relationships that can be graphed, such as items per container, containers per pallet, pallets that fit into trucks, the truck routes between delivery points, and the types and quantities of deliveries made at each location. The links contain relevant attributes such as the distance between origin and delivery or the aggregate weight of the pallets on a truck. You can use graph models to optimize travel time, improve fuel efficiency, and verify that each item was delivered to the right location.\nSmart buildings: Understanding the interoperation of connected sensors and controls (such as thermostats) within a facility is another opportunity for graph processing. Investigating these connections could lead to reducing energy costs, improving air quality, and using predictive models for preemptive maintenance.\nIn this case, the relevant information is associated with the proximity of devices (such as temperature, humidity, and CO2 sensors within a room, or rooms on a building floor). The graph approach is nicely suited to modeling the dynamic relationships embedded within the hierarchies of device connections among the different facilities within a complex.\nIn each of these example cases we see similar features -- each contains a variety of connected things in a context where understanding the connections can lead to business opportunities. In the next article in this series, we will look at some graph analytics and algorithm basics.\nRead Part 3 of the series here.\nAbout the Author\nDavid Loshin is a recognized thought leader in the areas of data quality and governance, master data management, and business intelligence. David is a prolific author regarding BI best practices via the expert channel at BeyeNETWORK and numerous books on BI and data quality. His valuable MDM insights can be found in his book, Master Data Management, which has been endorsed by data management industry leaders.']"	['<urn:uuid:47b34771-3254-4c28-9ce3-f672fda963e5>']	open-ended	with-premise	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-13T01:50:22.828293	21	77	843
12	I'm researching China's actions in the seas near Japan - what kind of military and non-military ways does China use to gain control, and how has the US responded to these actions?	China employs a complex mixture of military, quasi-military, and civilian assets in its maritime expansion, including naval forces, coastguard vessels, and civilian fishing boats and activists. In disputed areas, China has established new administrative authorities, increased use of military and para-military assets, created artificial islands with military facilities, and established air defense zones. The US has responded by focusing its concern primarily on Beijing since 2010, though without formally taking sides in sovereignty disputes. While maintaining its role as security guarantor, the US has aimed to deter Chinese actions through military presence, although it has generally avoided direct confrontation with Beijing.	"['From ‘Three Blocks’ to ‘Three Islands’: The Thin Line Between Police and Military Operations in Contested Maritime Spaces\nThe current undeclared war in the Pacific has often featured not only conventional military assets, but also coastguards and equivalent state agencies[i], together with civilian actors, both fishermen[ii] and “activists”. The role of fishing boats are a reminder of the high economic stakes at play, whereas activists provide a way for Beijing to develop a wider pan-Chinese narrative, incorporating “compatriots” from Hong Kong, Macau, and Taiwan.[iii] The 50th anniversary of the tragic loss of John F. Kennedy, a president who stressed the need for the military to develop a wide range of capabilities enabling it to effectively fight all sort of wars and not just large conventional conflicts[iv], and the arrival to Tokyo as U.S. Ambassador of his daughter Caroline[v], together with the recent amphibious drills conducted by Japan’s Self-Defense Forces (JSDF)[vi], provide a good reason to examine the issue of police capabilities in contested maritime spaces.\nSince an invasion of the Senkaku Islands could take place at the hands not only of a conventional military force, but also of unarmed activists supported by naval and air assets, it is imperative to ask whether Tokyo has the capability to use non-lethal force to recover control of one or more contested islands. One of the most difficult challenges of contemporary war fighting is the need to be prepared for very different scenarios, to be trained and equipped for each, and to prevail in all of them at the same time. We are not just talking about preparing for different kinds of warfare, but to be able to conduct them simultaneously, and not just in different theaters or fronts, but a few yards apart. The traditional way of referring to this in the U.S. Marine Corps is the “Three Block War” concept, “the possibility of humanitarian missions, stability activities, and combat occurring simultaneously during a single operation and in a single city”. This is a scenario, where “units have three dramatically different types of actions ongoing over distances measured in a few hundred meters”, which “is virtually unrecognized in doctrine today”.[vii]\nSome military planners and politicians have defended the notion that non-conventional operations should be avoided if at all possible, with retired U.S. Army colonel Douglas Macgregor suggesting in an Armed Forces Journal article that America should simply “refuse battle” in scenarios where her vital interests are not at stake. It is a “strategy” which “has long resonated with U.S. military culture and its preference for the Weinberger-Powell Doctrine”. However, other authors and officers, sometimes labelled the “Utility Infielder School” recognize “the need to deal with strictly conventional tasks and irregular threats” and the resulting imperative to “cover the entire spectrum of conflict and avoid the risk of being optimized at either extreme”. Retired USMC officer Frank G. Hoffman believes “the current bifurcation of the spectrum of conflict between irregular and conventional wars is a false choice and intellectually blinds us to a number of crucial issues”[viii]\nThis debate has traditionally concerned land operations, and the above quotes clearly have those in mind. However, at sea we are clearly observing how China employs a mixture of naval, coastguard / quasi-military, and civilian (fishermen and activists) assets in pushing forward her maritime claims. Thus, Japanese forces may find themselves having to deal with very different realities in islands a few miles apart. There is no reason why Beijing may not decide to land activists in one island and conventional forces in another.\nConfronting an entrenched unit of the PLA, ready to open fire, is not the same as confronting a group of Chinese activists, with the usual addition of a few Hong Kong and Taiwan “compatriots”, with their placards and slogans. Are Japan\'s Self-Defense Forces ready to react to both scenarios, and even to both in different islands at the same time? Do they have the necessary training, equipment, and doctrine for this? Was the recovery of an island in the hands of unarmed activists backed up by naval and air assets included in the latest drills earlier this month? These are questions that need to be asked and explored.\nThe U.S. Marine Corps has recognized the need to acquire a police capability, a lesson learned in Iraq and Afghanistan. It has set up two active-duty law enforcement battalions (LEB) and one Reserve battalion (the 4th LEB, headquartered in Minneapolis). Marine Major Roberty Lafferty, Co. D, 4th LEB commander, explained the reasons for the move, saying that ""In this case, the Force Structure Review Group decided they needed more law enforcement because of the last decade in Iraq and Afghanistan, where we built up the police capabilities of those host nations"", adding that ""They realized they needed more Marines to carry out that mission"".[ix]\nOf course, the situation in the Senkaku Islands is different, first of all because there is no native population. We are thus not talking about law enforcement in the traditional sense of the word, nor about mentoring and helping build local police forces as part of a wider nation-building exercise. However, the fact that Japan may be confronted by the need to eject a non-armed enemy contingent means that it does not suffice to only develop conventional amphibious capabilities. These must go hand in hand with police capabilities, with the kind of skills and equipment that we may find in riot police units, rather than in conventional infantry or Marine units. It is a need that has already been perceived in, for example, peace keeping operations where troops may have to deal with demonstrations and other non-armed (albeit sometimes violent) disturbances.\nOne of the potential legal controversies concerning non-lethal force against unarmed activists may be the employment of riot-control gases. While Article I(5) of the 1993 Chemical Weapons Convention states “Each State Party undertakes not to use riot control agents as a method of warfare”, this has not been universally interpreted as imposing a complete ban on the use of such substances by military units. For example, the U.S. Operational Law Handbook (1993) states “This prohibition does not preclude the use of herbicides or riot control agents by U.S. forces in wartime when authorized by the President of the US or his delegate”, and The U.S. Naval Handbook (1995) states that “The United States considers that use of riot control agents in armed conflict was not prohibited by the 1925 [Geneva] Gas Protocol. However, the United States formally renounced first use of riot control agents in armed conflict except in defensive military modes to save lives. Uses of riot control agents in time of armed conflict which the United States considers not to be violative of the 1925 [Geneva] Gas Protocol include:\n1. Riot control situations in areas under effective U.S. military control, to include control of rioting prisoners of war.\n2. Situations in which civilians are used to mask or screen attacks and civilian casualties can be reduced or avoided.\n3. Rescue missions involving downed aircrews or escaping prisoners of war.\n4. Protection of military supply depots, military convoys, and other military activities in rear echelon areas from civil disturbances, terrorist activities, or paramilitary operations.\nSuch employment of riot control agents by U.S. forces in armed conflict requires NCA approval.” (Bold type by author.)[x] This is just one example of some of the legal, operational, and doctrinal issues, that Japan should ideally address before finding herself having to react to such combined military-civilian attacks.\nDeveloping the necessary doctrine, equipment, and training, to deal with civilian or mixed military-civilian landings is even more important in the age of the internet, mobile recording devices, and fast decentralized news generation. In other words, in an age where the shooting of an unarmed “activist” would soon be broadcast globally. We should not forget that Tokyo’s (well-meaning but potentially destabilizing in the light of Beijing’s growing aerial activities[xi]) decision not to permanently deploy land troops on the Senkaku Islands, choosing instead to quarantine them with her Coast Guard, means that in the event of a successful Chinese landing it may be up to Japan to conduct the first opposed landings. This could prompt difficulties at the legal, political domestic, and political international levels. Legally, because some voices may label the subsequent operations as offensive, rather than defensive, and thus contrary to Article 9 of the Japanese Constitution. Domestically, for the same reason, a portion of the Japanese public may be reluctant to employ force, disregarding the fact that Tokyo was reacting to an attack, albeit to one whose guiding principle may be to avoid casualties, thus making it much more difficult for Japanese authorities to respond. Something similar may be said about Japan’s allies, and the U.S. in particular. Washington is committed to helping defend Japanese territory, and has explicitly said that this includes the Senkaku Islands, but at the same time the U.S. takes no sides on the ultimate sovereignty dispute.[xii] This means that there is a very real potential for miscalculation, since Beijing may be tempted to think that if she succeeds in bloodlessly inserting an occupation force on the Senkaku Islands and force Japan to negotiate, dragging her feet, the passage of time will make it politically difficult for Washington and Japanese domestic public opinion to support a counterstrike, which would then look as an offensive, rather than a defensive, action, and therefore contrary to Article 9 of the Japanese Constitution. Furthermore, lawyers may even argue that since Tokyo had lost actual control over the Senkaku Islands, they no longer fell under the U.S.-Japan security treaty, once no longer under “the administration of Japan”.\nA look to the South Atlantic in 1982 shows a similar miscalculation. As reflected in the Argentinian Navy’s orders[xiii] the Argentine Junta seemed careful to try not to inflict any casualties when invading South Georgia and the Falklands and sought to drag the U.S. into mediating talks. That was one of the reasons why then British Prime Minister Margaret Thatcher felt compelled to dispatch a task force at once, and why then Falklands Governor Sir Rex Hunt ensured the small British military contingent in the Falklands (two platoons of Royal Marines) did not surrender without first offering a reasonable measure of resistance. Troops in South Georgia also engaged the invaders before surrendering, damaging the ARA Guerrico with small arms and recoilless rifle fire. It is no coincidence that Japanese Prime Minister Shinzo Abe has incorporated references to the Falklands in his public speeches, and that some British experts on the war have travelled to Japan to lecture on the subject in recent years, while Japanese officers attended conferences on the conflict in the UK.\nThus, in order to avoid a stand-off, with the Japanese unable or ortherwise reluctant to eject unarmed occupants from one or more of the islands in dispute, and Beijing gaining time to consolidate her hold and make it increasingly difficult for Tokyo to garner the necessary domestic and international support to counterstrike, it may be advisable to develop, within Japan’s amphibious forces, the necessary police units. The resulting capabilities may also be useful in other scenarios, such as humanitarian assistance in natural disaster-struck areas, with the resulting necessity to deal with crime and a breakdown of law and order. This wider need could also facilitate securing the necessary political support to take the step. It is illustrated by the trouble experienced by the JSDF’s medical units currently deployed in the Philippines due to the breakdown in law and order in the areas hit by Typhoon Haiyan / Yolanda.[xiv]\nPast experience in the South and East China Seas shows China employing a complex mixture of military, quasi-military, and civilian (fishermen and activists) assets, in her gradual yet relentless expansion campaign. This means that one of the ways in which Beijing may try to conquer the Senkaku Islands would be by employing civilians, in conjunction with its military. In order to minimize the scope for a prolonged stand-off, which may make it difficult for Tokyo to secure the necessary domestic and international support to counterstrike, it may be advisable for the JSDF to develop specialized police units. This would reflect the fact that expelling unarmed personnel required different training and equipment than that of conventional marine units. The presence of these specialized police units within larger marine-like formations, rather than reliance on civilian police, is necessary since a combined attack can only be met effectively by an integrated defense, in what amounts to a translation to island and amphibious environments of the Three-Block Doctrine. From Three-Block to Three-Island.\n[i] Which China consolidated earlier this year. “Taming the Five Dragons? China Consolidates its Maritime Law Enforcement Agencies”, China Brief, Volume 13, Issue 7, The Jamestown Foundation, 13 March 2013, available at\n[ii] For an in-depth examination of the role of fishing fleets in China’s strategy see “Strategic Implications of Chinese Fisheries Development”, China Brief, The Jamestown Foundation, Volume 9, Issue 16, 5 August 2009, available at http://www.jamestown.org/programs/chinabrief/single/?tx_ttnews[tt_news]=35372&tx_ttnews[backPid]=25&cHash=090511d03c\n[iii] For a comparison between Taiwan and the Senkaku Islands, see Alex Calvo ""Island Democracies Under Threat: Taiwan, The Senkaku, And The Falklands"", Papers for the Ninth Annual Conference of the European Association of Taiwan Studies (EATS), 1 June 2012, presented on 20 June, European Association of Taiwan Studies (EATS), available at http://admin.eats-taiwan.eu/uploads/uploaded_3716801Calvo_Alex_IslandDemocraciesUnderThreat.pdf.pdf\n[iv] For John F. Kennedy’s views on counterinsurgency and unconventional warfare Andrew James Birtle, U.S. Army Counterinsurgency and Contingency Operations Doctrine 1942-1976, (Washington: US Army Center of Military History, 2012), pp. 223-231, available at http://www.history.army.mil/html/books/us_army_counterinsurgency/CMH_70-98-1_US%20Army_Counterinsurgency_WQ.pdf, and “Chapter 6: The Kennedy Crusade. A Dynamic National Strategy To Defeat the Communists” at Michael McClintock, Instruments of Statecraft: U.S. Guerilla Warfare, Counterinsurgency, and Counterterrorism, 1940-1990, (:Pantheon Books, 1992), pp. , available at http://www.statecraft.org/chapter6.html\n[v] “Japan pins hopes on Kennedy”, The Japan Times, 16 November 2013, available at http://www.japantimes.co.jp/news/2013/11/16/world/japan-pins-hopes-on-kennedy/#.UohrFuK83wp\n[vi] Alex Calvo ""We shall fight them on the beaches: Japan looks at UK for inspiration as she readies for amphibious drills"", Bulletin of the Center for Strategic Studies of Catalonia, 5 November 2013, available at http://www.ceec.cat/catala/articles/we-shall-fight-them-on-the-beaches-japan-looks-at-uk-for-inspiration-as-she-readies-for-amphibious-drills/\n[vii] “Chapter 2: Doctrine”, Denying the Widow-Maker: The RAND-DBBL Conference on Military Operations on Urbanized Terrain, RAND Corporation, 24-25 February 1998, available at http://www.rand.org/content/dam/rand/pubs/conf_proceedings/CF143/CF143.chap2.pdf\n[viii] Frank G. Hoffman “Striking a balance: Posturing the future force for COIN and conventional warfare”, Armed Forces Journal, July 2009, available at http://armedforcesjournal.com/article/2009/07/4099782\n[ix] David Bedard “Marine infantrymen switch to law-enforcement mission”, Joint Base Elmenodrf-Richardson Public Affairs, 15 February 2013, available at http://www.jber.af.mil/news/story.asp?id=123336693\n[x] “Practice Relating to Rule 75. Riot Control Agents”, website of the International Committee of the Red Cross, 2013, available at http://www.icrc.org/customary-ihl/eng/docs/v2_rul_rule75\n[xi] Alex Calvo ""The third dimension of warfare and tactical stability in the Senkaku Islands"", Birmingham ‘on War’: The blog of the postgraduate students at the Centre for War Studies, University of Birmingham, 09 January 2013, Birmingham University, available at http://warstudies.wordpress.com/2013/01/09/the-third-dimension-of-warfare-and-tactical-stability-in-the-senkaku-islands/\n[xii] Last year, the US Senate unanimously passed an amendment to the 2013 National Defense Authorization Act which reads “While the United States takes no position on the ultimate sovereignty of the Senkaku Islands, the United States acknowledges the administration of Japan over the Senkaku Islands. The unilateral actions of a third party will not affect United States acknowledgement of the administration of Japan over the Senkaku Islands” Section 1286, “National Defense Authorization\nAct for Fiscal Year 2013”, website of the US Senate, 2 January 2013, available at http://www.hsgac.senate.gov/download/?id=C09BA30E-2FBF-4687-A1DB-A69FBB8F593E-2560k For a wider look at the US position on the territorial dispute, see Mark E. Manyin, Senkaku (Diaoyu/Diaoyutai) Islands Dispute: U.S. Treaty Obligations, Congressional Research Service, 22 January 2013, available at http://www.fas.org/sgp/crs/row/R42761.pdf\n[xiii] The orders are referenced in a monography by an Argentinian officer, where he also offers a summary of the standard view of the conflict by his country’s military: Leonardo Arcadio Zarza, Malvinas: The Argentine Perspective of the Falklands Conflict, (Kansas: School of Advanced Military Studies, United States Army Command and General Staff College, 2010), available at http://www.dtic.mil/dtic/tr/fulltext/u2/a523209.pdf\n[xiv] Etsushi Tsuru “Japanese medical workers, SDF frustrated in typhoon-hit Philippines”, The Asahi Shimbun, 15 November 2013, available at http://ajw.asahi.com/article/behind_news/social_affairs/AJ201311150068', 'Thank you very much Mr. Chairman.\nSince roughly 2007–2008, the People’s Republic of China has clearly taken a more active, assertive stance toward its longstanding territorial claims in the South China Sea (SCS) and East China Sea (ECS), both bordering its long maritime coast. Such activities have included, among others:\n- Strong statements criticizing the actions and claims of other disputants, especially Japan (in the East China Sea) and Vietnam and the Philippines (in the South China Sea)\n- The establishment of new administrative authorities charged with managing various aspects of the claimed land and sea features\n- The increased use of military and especially para-military air and naval assets to challenge the activities of other claimants in disputed areas, and sometimes even in what are generally regarded as “open ocean” areas or within the exclusive economic zones of other nations\n- The establishment of an air defense identification zone over the East China Sea that includes disputed territories with Japan\n- The creation of artificial islands in the Spratly Islands and the deployment of air defense weapons systems and the construction of dual-use civilian-military facilities on those islands\nWhile not taking any formal position in support of any claimant’s sovereignty position, Washington has clearly focused the vast majority of its concern, and its actions since roughly 2010, on Beijing. This has led many in China to conclude that the United States is actively supporting the other disputants while attempting to undermine China’s position and influence in the disputed areas.\nThe obvious danger presented by this situation is that increasing numbers of U.S. and Chinese air and naval assets operating in close proximity to one another, or perceived provocations of various sorts including further military deployments onto islands or rocks or possible clashes between China and other disputants, could produce escalating crises. These might draw the United States into direct confrontation with Beijing, as the latter acts excessively to strengthen its position and thereby deter or counter perceived provocations (perhaps out of an exaggerated sense of its growing power) and the former overreacts to such a perceived challenge in an effort to reaffirm its predominant position and maintain its credibility as a security guarantor.\nThis danger is reinforced by the absence of any serious dialogue among the claimants and between the United States and China regarding limits on the level and type of militarization occurring in disputed maritime areas, and the failure of China—and to a lesser extent other disputants—to clarify their specific claims regarding various waters, particularly in the South China Sea. Contrary to widespread claims in the media, Beijing has yet to define exactly what the so-called Nine-Dashed-Line denotes regarding the waters within it.\nThe resulting uncertainties stimulate worst casing about motives and behavior, thus leading to further escalation. And of course the fact that sovereignty issues are generally zero-sum in nature and elicit strong nationalist emotions further adds to the dangers.\nManaging this complex and potentially volatile issue requires a clear understanding of the stakes involved for all sides (both now and in the future), the likely foundations of long-term stability, and the probable resources available to the United States to manage this issue.\nMaritime Motives and Stakes\nChina’s ultimate motives in expanding its influence and presence in nearby disputed maritime areas are not entirely clear, despite what some observers argue is a clear effort to “control” these areas and push the United States out of East Asia.\nIn truth, the historical dynamic at work in the disputed maritime areas has long involved an interactive tit-for-tat rivalry among the claimants, made possible by the absence of any clear and commonly accepted code of conduct (beyond the voluntary, nonbinding, and vague 2002 Declaration on the Conduct of Parties in the South China Sea signed between China and ASEAN) and driven by deep-seated suspicions and strongly felt nationalist impulses on all sides.\nIn the South China Sea competition (which focuses mainly on the southern Spratly Islands since China has firmly held the northern Paracel Islands for many years), Beijing is by far the biggest player. There, it is seeking to use its growing capabilities to more effectively defend and advance what it regards as its indisputable claims to the land features and undefined adjoining waters of the area, as well as certain also undefined historical rights. Other claimants are doing virtually the same thing, except their capabilities and claims are not as extensive, their actions not as effective, and hence their activities do not generate as much attention. In general, they are hopelessly outmatched by Beijing in this competition.\nIn recent years, however, Beijing has certainly gone beyond a proportional tit-for-tat interaction to apparent attempts to establish itself as the dominant claimant in the Spratly Islands, arguably to deter future perceived provocations by others and to establish a strong position in future negotiations. This impulse is driven even further by the fact that Beijing has historically held a very weak position in that area compared with Vietnam, the other claimant to virtually all the land features within the South China Sea.\nIn the case of the East China Sea dispute with Japan, Beijing has also departed from its past basic tit-for-tat stance in an attempt to establish itself in recent years as an equal claimant to Tokyo over the Senkaku/Diaoyu Islands, thereby supposedly correcting years of Japanese dominance.\nRegardless of its motives, China’s more recent, escalatory behavior has contributed significantly to the buildup in tensions in the disputed maritime areas. At the same time, when measured against the metric of a supposed direct challenge to the U.S. position in Asia, Beijing’s actions appear at least somewhat cautious. It generally avoids the use of warships to assert its claims, has given assurances that it does not intend to militarize the Spratly Islands beyond the placement of what it calls “defensive capabilities,” and has certainly not attempted to seize land features long held by other claimants to assure its control of the area.\nMoreover, Beijing continues to insist that it is dedicated to a peaceful, negotiated solution of the disputes and supports the peaceful objectives of the 2002 declaration. Most recently, it has supported reaching a basic framework for a more detailed Code of Conduct by mid-2017. In general, one can say that it is attempting to increase its influence in both seas without greatly increasing the chance of armed conflict with the United States or other claimants.\nThis could change, of course, as China’s power and presence in the area increase. Those in and out of the U.S. Government who call for a zero-sum confrontation with Beijing over the maritime disputes assert that it certainly will, allegedly because China’s caution thus far conceals its “real” expansionist and aggressive motives.\nThis is pure speculation, but of a dangerous sort, since if accepted as a basis for U.S. policy it would basically lock in a zero-sum interpretation of every assertive Chinese action, thereby justifying an equally zero-sum U.S. move in response. And of course, such actions would indeed cause Beijing to eventually adopt precisely the threatening motives that some observers insist (in my view incorrectly) are already present.\nBeyond basing itself on a purely speculative and dangerous set of assumptions about Chinese motives, a zero-sum, confrontational argument calling for a doubling down of U.S. capabilities in the Western Pacific also employs another highly dubious (at best) set of assumptions regarding American and Chinese defense spending relevant to Asia.\nBarring an unlikely near-total collapse of the Chinese economy and/or a major surge in the overall U.S. GDP, Washington will not possess the capacity to greatly exceed the kind of military and economic capabilities that China will be able to bring to bear in its nearby maritime areas over the coming years.\nIn fact, projections by myself and other scholars at the Carnegie Endowment for International Peace, along with other reputable sources, predict a much more likely movement toward parity between U.S. and Chinese capabilities in that region, in other words, a de facto strategic equilibrium or balance of power.1\nOf course, the United States could devote a much larger share of its available economic resources to defense spending, and to spending in Asia in particular, in an attempt to remain clearly dominant militarily in the Western Pacific near China. However, that would likely require either considerable belt-tightening elsewhere, especially in vital social welfare or entitlement areas, or a huge expansion in the government deficit. Neither of these is politically feasible at present or for the foreseeable future, absent a truly major increase in public perceptions of the threat posed by China.\nDisputes over rocks and islands in the far reaches of Asia are unlikely to motivate such a level of alarm, unless a crisis in that region escalates to a genuine Sino-U.S. military clash of serious proportions. While certainly possible, such a hypothetical crisis should not be assumed and likely could not a priori alter threat perceptions.\nThe Most Feasible and Viable Way Forward\nThe complexity of the maritime disputes in the East and South China Seas, involving a) economic resources; b) differing interpretations of applicable international law and historical rights; c) overlapping jurisdictional claims based on continental shelves, exclusive economic zones, and other relevant legal zones; and d) domestic political factors rooted in strong nationalist sentiments, together suggest that any resolution, if at all possible, will take many years, and perhaps decades, to achieve.\nIn the meantime, a stable, enduring modus vivendi among all relevant parties is needed, centered on mutual restraint in asserting local sovereign or special rights as well as an effective, peaceful process for handling incidents.\nSuch an understanding ideally should consist of several elements. The first is an initial shift away from military and para-military competition and maneuvering toward an emphasis on diplomacy, primarily via an initial set of interim (short- to medium-term) understandings among the claimants and between Beijing and Washington regarding levels and types of militarization and the non-use of force. This must be based on clear, agreed-upon definitions of acceptable and unacceptable military behavior and clear, specific proscriptions on the unprovoked display and use of force.\nAs a part of this negotiation process, some level of mutually acceptable long-term equilibrium in the military capabilities of the claimants within the Spratly archipelago in particular must be achieved, as a stable ceiling against future militarization. This might involve permission for claimants other than China (such as Vietnam) to upgrade or expand their facilities on land features in the Spratly Islands to bring them up to a par with those that Beijing has constructed.\nWithout such an understanding, any transition toward diplomatic efforts on claims, jurisdictions, resource development, and an eventual long-term code of conduct for both the East China and South China Seas will remain virtually impossible, as all sides continue to maneuver militarily to deter one another.\nThe United States and China must take the lead in this effort, based on a common recognition of the need to remove the maritime issue as a driver of their deepening strategic contention. That said, a Chinese acceptance of such limits would doubtless prove conditional, based on the eventual acceptance by the other claimants.\nSuch agreements will require overcoming domestic military and paramilitary resistance to any restraints on military activities in disputed areas, including limits on the frequency of Freedom of Navigation (FON) operations by the U.S. Navy. They will also require overcoming the argument that any agreement to eschew an unprovoked use of force would undermine the sovereignty claims of China and the other claimants.\nSecond, a staged diplomatic process is necessary for clarifying the precise content and legal or other rationale of the many claims involved, that is, the jurisdictional disputes involving both sovereignty issues and non-sovereignty (but privileged) rights over resource extraction, such as fishing. Washington should do more to facilitate this effort.\nThis could proceed on a bilateral or multilateral basis but should gradually expand to eventually include all extant claims across the East China and South China Seas. During this process, Beijing would need to clarify the meaning of the nine-dash line, and all claimants would specify their claims to land or underwater features and corresponding waters as they relate to relevant legal (that is, based on the United Nations Convention on the Law of the Sea) definitions, as well as so-called historical rights. When the status of specific features (as islands, rocks, reefs, and so on) is clearly in dispute, the parties concerned must negotiate a compromise or petition for a ruling from the International Tribunal for the Law of the Sea (ITLOS) under UNCLOS.\nThird, on the basis of such clarification of claims and jurisdiction, all parties must reach an agreement on those areas subject to joint resource development and a procedure for implementing such development. Although often called for, joint development cannot actually occur unless all disputants clarify those areas that are subject to such development, and this cannot occur until the specific areas of overlapping claims are identified and agreed upon.\nIn principle, joint development of disputed maritime areas is already accepted by most if not all disputants as a valid interim means of exploiting resources before any resolution of claims, although some compromise and agreement on the division of proceeds is required. Hence an agreement on such development, once the areas of overlapping claims have been identified, should not prove excessively difficult to achieve.\nFourth, on the basis of the previous actions, the claimants must eventually negotiate elements of a binding code of conduct for limiting levels of militarization and handling future incidents over the long term. This code must build on: a) previously agreed-upon, clear definitions of prohibited activities of all kinds, military and nonmilitary alike (the existing 2002 Declaration on the Conduct of Parties in the South China Sea is extremely vague on this point); b) a process for identifying and interpreting such activities; and c) a means of punishing violations.\nSome observers might argue that the formulation of a binding code of conduct should precede these steps, as a necessary precondition. However, it is almost certainly the case that the willingness of highly assertive states locked in contentious sovereignty disputes to agree confidently to a binding code will require a prior increased level of trust, a reduced propensity for military competition, and a clear understanding of the nature and extent of competing claims that can only result from the above steps.\nObviously, many obstacles would confront any efforts to greatly reduce disputes over maritime territorial claims as a source of Sino-U.S. tension or conflict, including distrust among virtually all the parties concerned, nationalist domestic pressures, and deeply entrenched bureaucratic interests. And American leverage is extremely limited by its failure to ratify UNCLOS. How can Washington seriously press China and others to abide by UNCLOS rulings and establish a Code of Conduct when it refuses to subject itself to such scrutiny? In addition, more extensive confidence-building measures (CBMs) and crisis management mechanisms (CMMs) are also likely to constitute necessary preconditions, to reduce distrust and strengthen confidence in the enforceability of a legally binding code of conduct.\nOn the U.S. side, political leaders will also need to reassure Manila and especially Tokyo that any agreement Washington makes with Beijing to limit the content or scope of its military activities in disputed areas will not place those countries at a disadvantage either militarily or with regard to sovereignty claims.\nU.S. leaders will also need to clarify what constitutes unacceptable coercion or intimidation. Not all forms of Chinese assertiveness would necessarily threaten the U.S. interest in a stable and peaceful environment. Similarly, on the Chinese side, limits on the use or display of force and clarifications of existing claims will require, on both sides, a determined and strong leadership able to manage backlashes by nationalists and the military and a clear sense of what constitutes unacceptable coercion.\nIn sum, the only effective way to create a more stable environment in the maritime areas near China is for the United States to lead a serious diplomatic dialogue with Beijing and other claimants aimed at establishing mutually acceptable restraints, accompanied by strong U.S. and allied deterrence signals, ideally as part of a larger effort to create a regional balance of power. Such deterrence signals should involve clear indications of the adverse consequences for China (and for regional stability) that would result from a failure to reach an agreement. A unilateral, near-term doubling down on military deployments, a drastic increase in defense assistance to those powers opposing China, or a drawing of high stakes “lines in the sand” directed at Beijing on their own will not achieve this objective and could make the situation much worse.\n1 For details, see Michael D. Swaine with Wenyan Deng and Aube Rey Lescure, Creating a Stable Asia: An Agenda for a U.S.-China Balance of Power, Carnegie Endowment for International Peace, Washington D.C., 2016.']"	['<urn:uuid:88b3e101-b1e4-429e-92be-fbe85b1a8b33>', '<urn:uuid:339eed49-87fb-466c-8816-cfc5d004203c>']	factoid	with-premise	verbose-and-natural	distant-from-document	multi-aspect	novice	2025-05-13T01:50:22.828293	32	101	5472
13	How do bubbles help clean metal, and what safety measures control radiation exposure?	Bubbles help clean liquid metals through flotation - when gas bubbles are injected or generated in liquid metal baths, they increase collision probability between solid inclusions, forming larger aggregates. These inclusions attach to bubbles and float to the surface where they can be removed by slag. For radiation safety, exposures must be controlled through a detailed Radiation Safety Program that includes both internal and external exposure controls. This involves monitoring requirements, contamination surveys, controlling time spent near NORM materials, maintaining distance, using appropriate PPE, and following the ALARA principle to keep exposures as low as reasonably achievable.	['Removal of inclusions in liquid metals by flotation\nMotivation and background\nIn metallurgy, the control of inclusion populations plays a key role to improve and ensure cleanliness of structural materials, e.g. aluminium alloys or steels. From the material-scientific point of view, non-metallic inclusions having a means diameter of around 10 µm act as defects in the metallic microstructure and therefore impair the material’s properties as well as the final product quality. Commonly used industrial processes, like ladle refining in steel production, are applied to reduce the inclusion size and concentration within the bulk material. Heated up above the melting temperature, the liquid metal alloy is stirred by gas bubbles which are generated due to chemical reactions inside the metal bath or are injected into the ladle additionally. As a consequence, the probability of collisions between solid inclusions is increased and bigger inclusion aggregates are formed. Inclusions attached to bubbles are floated up towards the free surface of the liquid metal bath, get absorbed by the slag and can finally be removed.\nWithin the FLOTINC project, founded by the French (ANR) and German (DFG) research agencies, the research topic is focussed on inclusions in gas-liquid experiments. Liquid metal is employed as the experimental fluid, because of significantly higher surface tension compared to water. “Cold” gallium-based metal alloys which are already liquid at room temperature (~ 25 °C) are used to perform model experiments without additional heating. In our labs at HZDR we are able to apply different X-ray imaging setups. Moreover, neutron imaging studies have been started at the Swiss Spallation Neutron Source (SINQ) of the Paul Scherrer Institute (PSI), Switzerland. The experimental investigations aim to image gas bubbles as well as solid particles, and to study their dynamics within the opaque liquid metal.\nExperimental investigations by X-ray and neutron transmission imaging\nThe measurement principle for both X-ray and neutron imaging is based on the material-dependent attenuation of the transmitted X-ray respectively neutron beam intensity. The output of all imaging experiments are grey-scale image sequences showing the two-dimensional (and hence depth-limited) projection of rising bubbles and moving particles within the liquid metal volume. The lateral and temporal resolution for transmission imaging by means of X-ray or neutron radiation strongly depends on the imaging setup as well as the design of the flow experiment.\nMeasurement principle based on Beer-Lambert law\nExperimental setup for X-ray or neutron transmission imaging\nX-ray imaging can provide quantitative analysis of two-dimensional bubble flows in liquid metal, including data about bubble trajectories, diameter and velocity. The material selection for suitable particles is limited, since the attenuation characteristics for X-ray imaging are closely related to the particles’ mass density which strongly affects their flow behaviour, too.\nX-ray imaging of bubble chain in liquid gallium alloy; quantitative analysis by fitting of bubble projections as elliptical shape (Video).\nX-ray imaging of spherical hard metal particles in liquid gallium alloy during gas injection.\nNeutron imaging enables visualizing and tracking of submillimetre-sized particles made of gadolinium. This element exhibits outstanding attenuation characteristics for neutron radiation, plus the mass density is similar to the density of the liquid gallium alloy. Hence, compared to X-ray imaging, the required particles tend to be smaller. This allows adjusting the flow conditions depending on the particle size and shape.\nNeutron imaging of different submillimetre-sized gadolinium particle fractions, in contrast to liquid gallium alloy.\nZhang, L. F., Thomas, B. G. (2003). State of the art in evaluation and control of steel cleanliness. ISIJ International, 43(3), 271-291. doi:DOI 10.2355/isijinternational.43.27', 'Radiation Safety is the protection of workers\nfrom the harmful effects of radiation.\nIndustries that produce NORM can concentrate the radioactive materials found in our environment to levels that exceed Canada’s Radiation Protection Regulations. Exposures to radiation cannot be prevented, however they can be controlled. A proper Radiation Safety Program will control both internal and external radiation exposures. Radiation Protection Programs or safe work practices are required by regulations.\nIn the Oil and Gas Industry we have seen levels as high as 450 µSv/hr on contact of waste and 50 µSv/hr at 1 meter. An incidentally exposed worker could not spend more than 20 hours within 1 meter of the waste without exceeding the regulatory limit for an external exposure. We have also seen waste with activity levels up to 28,600 Bq/g. Inhalation or ingestion (Internal Exposure) of a volume less than the size of the tip of a pencil would exceed regulatory limits.\nImplementation of a Radiation Safety Program will ensure workers maintain exposures to levels that are well below regulatory limits and maintained under the principle of ALARA (As Low As Reasonable Achievable). This principle is recognized by all levels of governments and a requirement under the Radiation Protection Regulations. This principle means the following:\n“All radiation exposures are considered potentially hazardous to health regardless of any regulatory limit. A regulatory limit is an exposure that should not be exceeded. It is simply not acceptable to just maintain worker exposures to values below regulatory limits. Organizations must maintain exposures as low as reasonable achievable social and economic factors taken into consideration.”\nMany organizations have NORM policies and procedures that outline the appropriate PPE to be worn when working with NORM impacted materials or waste. These types of policies only prevent inhalation or ingestion exposures. A detailed Radiation Safety Program will include:\n- Identification of who is in charge of overall radiation safety for the organization. This is not necessarily the person on a NORM site but rather the person workers can call to address radiation safety concerns. This person is typically called the corporate Radiation Safety Officer (RSO) and must have extensive knowledge and experience in radiation protection.\n- Outlines the corporations requirements on surveys to identify NORM impacted waste and materials as well as monitoring requirements and will include the following:\n- Gamma radiation surveys requirements for detection of NORM impacted materials and waste.\n- Contamination surveys to identify objects that require cleaning or need to be controlled. These types of surveys prevent NORM accumulations from being spread around a worksite giving potential for workers to ingest.\n- Air monitoring requirements to detect levels of radon gas in the work area or low level radioactive dusts (LLRD’s). Health Canada has established maximum concentration limits of radon in air that a workplace cannot exceed. Monitoring for LLRD’s determines the need for respiratory protection and dust control measures. If LLRD’s cannot be eliminated, air monitoring is required to verify the internal exposures of workers in the event of respiratory malfunction.\n- Radiation Survey requirements. Radiation surveys are required to verify if external exposures in a work area need to be controlled. Control of these work areas are typically completed by controlling the amount of time workers may spend in that area.\n- Identifies how internal exposures will be controlled within the organization. This may include engineered controls at specific sites or administrative controls such as NORM policies, procedures or codes of practice. These policies outline how contamination will be controlled to prevent ingestion such as setting up control area’s and how inhalation will be prevented by dust control measures and appropriate PPE. A control area is an area where exposure to radiation may occur and is identified by signage. Special policy and procedures are required within this area to control radiation exposures.\n- Identifies how external Exposures will be controlled within the organization. External exposures cannot be eliminated only controlled as we live in a world where radiation is all around us (i.e. Gamma rays from the sun). External exposures can be controlled from NORM impacted materials or waste through the following means:\n- By controlling the amount of time we spend around the NORM impacted materials or waste.\n- By keeping our distance from the NORMN impacted material or waste such as putting up fencing and restricting access to NORM impacted areas.\n- Shielding the NORM impacted materials or waste to prevent the gamma rays from reaching workers. This method typically is not practical in the oil and gas industry for NORM impacted materials or waste. It is however common with man-made sources where the size of the source is small and can be housed in materials such as a lead lined enclosure.\n- Defines record keeping requirements. Exposures to workers are based off yearly exposures. As such records must be maintained from exposures do to daily work activities in order to compile these yearly assessments. A radiation safety program outlines how these records will be maintained to verify worker exposures.\n- Defines training requirements for workers.\n- Defines transport requirements and procedures. NORM impacted materials or waste with activities greater than 70 Bq/g fall under the requirements of the packaging and transport of nuclear substances regulations (PTNSR). NORM Waste or materials with activities less than 70 Bq/g fall under provincial authority and only require a manifest. This activity of 70 Bq/g assumes a single radionuclide. NORM waste can have radionuclides from both the U238 and Th232 decay series and as such are considered a mixture of radionuclides. The PTNSR outlines the method for determining the activities of mixtures to verify if the PTNSR apply for the mixture.\nNote: Prior to shipment you must determine the activity of the waste to verify appropriate regulations applicable to the shipment. Laboratory analysis can verify the activity of a NORM impacted shipment or estimates, by a qualified radiation expert, can be utilized.\nNormtek has a mobile laboratory for completing sample analysis prior to transport. The CNSC requires transporters of NORM impacted materials or waste have a written Radiation Safety Program if activities fall under their regulatory control (Radiation Protection Program Design for the Transport of Nuclear Substances GD-314).']	['<urn:uuid:0231afc7-86ee-4751-ac66-23c947d34129>', '<urn:uuid:45207f5c-c811-48b7-a0af-2769444e4bd7>']	open-ended	with-premise	concise-and-natural	distant-from-document	multi-aspect	expert	2025-05-13T01:50:22.828293	13	97	1606
14	I'm doing research for my tropical fish club and was wondering how long these Danio fish usually survive when people keep them as pets?	Domesticated Danio fish live on average 3.5 years, with the oldest individuals surviving up to 5.5 years.	"[""Classification / Names\nCommon names | Synonyms | Catalog of Fishes (gen., sp.) | ITIS | CoL | WoRMS | Cloffa\nActinopterygii (ray-finned fishes) > Cypriniformes\n(Carps) > Cyprinidae\n(Minnows or carps) > Danioninae\nEtymology: Danio: Vernacular name fron India and Sri Lanka . More on author: Hamilton.\nEnvironment: milieu / climate zone / depth range / distribution range\nFreshwater; benthopelagic; pH range: 6.0 - 8.0; dH range: 5 - 19. Tropical; 18°C - 24°C (Ref. 1672); 33°N - 8°N, 66°E - 98°E\nAsia: Pakistan, India, Bangladesh, Nepal and Myanmar (Ref. 41236). Reported from Bhutan (Ref. 40882). Appearance in Colombian waters presumably by escape from an aquarium fish rearing facility (Ref. 1739).\nLength at first maturity / Size / Weight / Age\nMaturity: Lm 2.5\xa0 range ? - ? cm\nMax length : 3.8 cm SL male/unsexed; (Ref. 41236)\nVertebrae: 31 - 32. Five uniformly, pigmented, horizontal stripes on the side of the body, all extending onto the end of caudal fin rays. Anal fin distinctively striped. Lateral line absent. Rostral barbels extend to anterior margin of orbit; maxillary barbels end at about middle of opercle. Branched anal fin rays 10-12. Vertebrae 31-32.\nAdults inhabit streams, canals, ditches, ponds and beels (Ref. 1479). Occur in slow-moving to stagnant standing water bodies, particularly rice-fields (Ref. 4832); and lower reaches of streams (Ref. 58912). Common in rivulets at foot hills (Ref. 41236). Feed on worms and small crustaceans (Ref. 7020); also on insect larvae. Breed all year round (Ref. 58913). Appears to be primarily an annual species in the wild, the spawning season starting just before the onset of the monsoon (Ref. 72224). Domesticated zebrafish live on average 3.5 years, with oldest individuals surviving up to 5.5 years (Ref. 58923). Spawning is induced by temperature and commences at the onset of the monsoon season (Ref. 58913). Food availability also acts as cue for breeding (Ref. 58913). Growth rate is a vital guiding environmental factor for sexual differentiation for this species as observed in a study (Ref. 58948). In this same study, frequency and amount of food prior to and throughout gonadal differentiation period resulted in more individuals differentiating to become females and is more pronounced in hybrid than pure bred groups (Ref. 58948). Often used for mosquito control (Ref 6351). Popular for aquarium purposes (Ref. 44325). Used as a model system (=organism) for developmental biology (Ref. 47810). Aquarium keeping: in groups of 5 or more individuals; minimum aquarium size 60 cm (Ref. 51539).\nBreed all year round (Ref. 58931). From Johnson (1932), 'a female never extrudes eggs during active courtship until the genital organ comes in contact with that of the male, whereupon a small stream of eggs is ejected' (Ref. 205). Violent dashing and chasing characterise courtship finally culminating in eggs being shed a few at a time, settling freely without adhering to the bottom surface (Ref. 205).\nTalwar, P.K. and A.G. Jhingran, 1991. Inland fishes of India and adjacent countries. vol 1. A.A. Balkema, Rotterdam. 541 p. (Ref. 4832)\nIUCN Red List Status (Ref. 120744)\nCITES (Ref. 118484)\nThreat to humans\nFisheries: of no interest; aquarium: highly commercial\nEstimates based on models\nPhylogenetic diversity index (Ref. 82805\n= 0.5000 [Uniqueness, from 0.5 = low to 2.0 = high].\nBayesian length-weight: a=0.00724 (0.00330 - 0.01589), b=3.07 (2.89 - 3.25), in cm Total Length, based on LWR estimates for this (Sub)family-body shape (Ref. 93245\nTrophic Level (Ref. 69278\n): 3.1 ±0.1 se; Based on diet studies.\nResilience (Ref. 120179\n): High, minimum population doubling time less than 15 months (tmax=5.5 (in captivity); tm<1; multiple spawning per year; Fec=400-500).\nVulnerability (Ref. 59153\n): Low vulnerability (11 of 100) .""]"	['<urn:uuid:ddece2b7-8f9d-44a8-a204-d7b996199047>']	factoid	with-premise	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-13T01:50:22.828293	24	17	606
15	What types of metals work for backsplashes and how do their colors change?	Several metals work well for backsplashes including stainless steel, punched or hammered tin, copper, and brass. Copper and brass evolve over time - copper turns a greenish color while brass takes on a muted tan or grey tone when exposed to air and moisture, creating attractive patterns and striations.	"['Metal Backsplash Ideas\nFanciful swirling metal pulls, fun red sculptural wall elements and a copper backsplash break free of the ordinary. Two sinks and two pullout trash containers eliminate prep conflicts. Generous counter areas avoid bottlenecks for large prep, along with two appliance garages.\nBacksplash materials run the gamut from tile to stone to wood, but metal kitchen backsplash ideas abound as well, and they can add a substantial, modern feel to any kitchen design.\nThere are several types of metal that lend themselves particularly well to backsplash designs, and each comes with a range of pros and cons.\nA good place to start when planning to add a metal backsplash to your kitchen design is with the overall scope of the project. You\'ll need to define the square footage the backsplash will cover in order to estimate the amount of metal and other materials you\'ll need for your backsplash. Obviously, this scoping exercise will go a long way to defining the required budget for your project, so you\'ll want to make sure it\'s the first step you take. To calculate the amount of material you\'ll need, first decide if you want your backsplash to cover the entirety of the wall space above your countertops or just a portion thereof. Once you\'ve decided on the amount of coverage, mark the area off and measure the square footage.\nWhen the scope of the metal backsplash project has been defined, you\'ll want to begin thinking about which metal you want to feature in your backsplash design. One of the more common metal backsplash choices is stainless steel. Popular in recent times as an appliance feature, stainless steel has begun to appear more and more in backsplashes as its bright, reflective, easy-to-clean surface makes it an attractive and efficient choice.\nPunched or hammered tin is another metal that\'s becoming more common in backsplashes—it can add a great deal of texture and weight to any kitchen design, and it\'s also durable and easily maintained. Copper and brass are two more metals that many homeowners feature in backsplashes. Each of these metals offers the added benefit of ""evolving"" over time—exposure to air and moisture can cause slight or even drastic color variations over time, often deepening their hue or resulting in attractive striations and patterns.\nOne you\'ve decided on the right metal for your kitchen backsplash design, it\'s time to begin construction. You\'ll have two options here—hire a contractor to install the metal backsplash for you, or go the DIY route and install it yourself (or, if you\'re lucky, with some assistance from friends and family). Depending on the complexity and size of the project, you may be able to save a considerable amount of money by installing the backsplash yourself. On the other hand, hiring a contractor will save you time, and you won\'t have to break a sweat; this is an especially attractive option if you\'ve never installed tile before or aren\'t particularly handy.\n- Kitchen Backsplash Design Ideas\n- Backsplash Patterns\n- Tile Backsplash Ideas\n- Stainless Steel Backsplashes\n- Tin Backsplashes\n- Facade Backsplashes\n- Picking a Kitchen Backsplash\n- Inexpensive Backsplash Ideas\n- Backsplashes for Small Kitchens\n- Backsplash Ideas for Granite Countertops\n- Stove Backsplash Ideas\n- Cool Backsplash Ideas', 'How to Create a Petina on Metals\nPatinas on copper and brass are thin films that form on the metals from either weather or exposure to natural elements or through a chemical process. When done properly the patina gives the metal a “seasoned’ tone and look that accents many forms of decor. Copper will turn a greensih color while brass will take on a muted tan or grey when put through the process. Many southwestern style homes use patina copper or brass on kitchen counter tops or as wraps for lamps, sconces, bedposts or bookcases. The patina effect is a beautiful tone that gives any room a timeless and “antique” feel. For home crafters, make your own patina designs on copper and brass patterns. It is also possible to use the chemical patina method to achieve an etched design. This is done using a chisel or etching tool and then treating with the patina chemicals. Some enjoy the ability to carve in unique designs that are enhanced via the patina.\nIn order to create a successful patina, the following materials are needed:\nDistilled Water (Distilled water is preferred over tap as it is consistent in the patina sheen)\nMixing Buckets and Containers\nSpray Bottles and Brushes\nEye Goggles, Smock and Rubber Gloves\nMetal Cleaning Supplies and Towels\nScouring Pads – Steel wool\nIndustrial Sand Blaster (optional)\nWell-Ventilated Work Space\nC-Clamps and Bench\nMix the acetic acid and water in one of the larger mixing buckets or containers. Remember to “do as you out to and add acid to water.” This means adding the acid last. This prevents high splash back and is the safe method of mixing. Use a mix of 10:1 of water: acid. Be sure to wear the eye goggles, rubber gloves and smock any time you use the acid or mixture. Leave the mixture off to the side. Any acid mix that gets spilled needs to be wiped up quickly to prevent damage to the surface it lands on.\nPosition the copper or brass pieces on the workbench and use C-clamps to tighten them in position if necessary. Use the towels and wash off the metal. Clean it using mild soap and water then towel off the excess fluids. Let the metal pieces dry completely.\nScour the outer edges of the metal using steel wool pads or other scouring agents. Experiment. Use different pads, agents and brushes to get different textures and designs on the metal. The purpose is to mar and scour the metal in distinct shapes and swirls with the metal-scouring agents. For large jobs, consider using an industrial sand blaster to get the metal adequately roughed up and scoured.\nBrush off the metal with a clean towel. Be sure to have rubber gloves on at all times. Do not allow any oils from the palms and fingers get onto the metal surface.\nSoak a towel in the patina mixture bucket. Remove and wring out thoroughly. Again, be sure to have all protective clothing and gear on any time the acid mix is handled and used. Rub the wet towel over the metal on the sides that have been scoured. Leave this to dry for at least 24 hours. Return to the metal and wet another towel in the patina mixture. Repeat the wiping and wetting of the metal with the patina chemical mix. Leave the metal for another 24 hours.\nScrape any precise designs or etchings onto the metal using small metal brushes, chisels or punches if a precise design is desired. Fill a spray bottle with the patina mixture. Spray the patina mixture into the etched or chiseled designs to set the patina acid into the chipped out metal.\nWipe down the metal with a dry and clean towel. Add one last application of the patina mixture to the metal, as wet as possible. Turn on the heat gun and let it preheat to at least 240 degrees Fahrenheit.\nApply the heat gun to the patina chemical side of the metal. Move slowly back and forth with the heat gun approximately 2 inches off the surface of the metal. Move up and down and watch as the metal that has been scoured begins to turn a soft and subtle green, contrasting with the brass and copper colors. Take particular care to apply the heat over the etched and chiseled areas of the metal. When dry, if the color is not to satisfaction spray more patina mixture into the etched areas and then reapply the heat gun. As mentioned prior, when etching into the metal, once the patina chemicals are added it creates a distinct design in the metal and patina.\nLeave the metal to cool and dry on the workbench. If the metal’s patina is not uniform or to your liking, go back and re-scour and chisel out the design. Go through the mixture application process again and let the metal dry. It is important that the acid mixture have time to oxidize and treat the metal to achieve the weathered look that the metal would take on if left out in the elements for extended periods of time.\nInspect the metal and use a small sponge brush to apply touch-up patina mixture to spots that are not uniform with the design. Continue until the metal piece has the desired look.\n* If doing large pieces of metal, consider hanging them laterally and spraying the patina side down with the mixture. Let it run and drip down the side to achieve a one of a kind appearance on the metal. Like the other method, go through after it has dried to make sure the desired pattern or design is achieved.\nPour the remaining patina mix down a work sink drain and wash out all items that came in contact with the mixture. Store any excess acetic acid in a plastic jug in a cool, dark and dry room like a basement, cellar or backroom in a workshop.\nUse tin snips to cut the metal into whatever shape or design desired. Apply it to counter-tops, or whatever item it is that should have the accented metal. Always clean patina-copper or -brass with mild soap and warm water. Never use household chemical-based cleaners for the patina metals as this may alter the design or dull the patina you worked so hard to achieve. Enjoy your home design and bask in the knowledge that you helped create the warm and timeless feel that now graces your chosen room.']"	['<urn:uuid:e9a26315-052c-43b2-99e1-2705ecd59a96>', '<urn:uuid:d37cc665-ce7b-4ff8-8873-cbd00e642746>']	factoid	direct	concise-and-natural	distant-from-document	multi-aspect	expert	2025-05-13T01:50:22.828293	13	49	1623
16	What makes stem cell therapy safe for animals?	Stem cell therapy is safe because the cells are collected from the patient themselves, which eliminates the risk of cross patient infections and maximizes the viability of the stem cells.	['At the Animal Surgical Center of Michigan we use the latest in veterinary technology to diagnose and treat your pet. By utilizing the latest in technology we can diagnose and treat your pet with less invasive techniques. More information is available below on the technologies we utilize.\nDigital thermography is a diagnostic test that provides a surface scan of the patient and shows emitted radiated energy. Thus, the hotter the area, the greater the emission of radiated energy. Areas on the body that are inflamed will show as hot spots. This is particularly useful to localize the causative area of a pet’s lameness. Forelimb lamenesses in particular can be very difficulty to sort out in our canine friends. With digital thermography, the guess work is taken out of the picture. The scan of this dog shows increased emitted radiated energy from the elbow joint; she had a fractured coronoid process within the elbow joint. Red and white colors are areas of most intense inflammation.\nOur hospital is equipped with the latest in technology, which allows our doctors to conduct tests that are needed to diagnose your pet’s condition. CT scan is a diagnostic that allows us to thoroughly evaluate your pet’s condition by imaging the bones and internal soft tissue structures of the body. This test produces cross-sectional images of the inside of your pet’s body which are then studied for abnormalities. Using advanced computer technology, data obtained from a CT scan can be used to reconstruct the patient’s anatomy so that a 3D model can be processed (see image to the right of a dog that has multiple fractures of the bones of both hind limbs). If needed, a 3D printer can be used to make a model of the structure so that the surgery can be planned out and practiced prior to the actual surgery. Patients that benefit from CT scan include those that have tumors, undiagnosed internal organ issues, nasal discharge, lameness, vomiting, and urinary issues to name a few. Because of the speed of our CT machine, the CT scan is commonly completed and a diagnosis provided during your pet’s initial visit.\nMagnetic resonance imaging is a very useful diagnostic modality used to diagnose musculoskeletal conditions, cancer, and neurological conditions. Planning of a surgery can be more accurately made with MRI. In or practice we most commonly use this modality for orthopedic and cancer patients. The image here shows a torn Achilles tendon. MRI is now available on site at our hospital.\nDigital ultrasound provides great insight into internal organs of the abdomen and does not require anesthesia. Second, we commonly use ultrasound to diagnose tears of ligaments and tendons that support joints. Third, ultrasound of the neck is used to find suspected masses (thyroid, parathyroid, or enlarged lymph nodes). Third, ultrasound-guided biopsies of tumors allows us to target areas of the tumor that are more likely to provide a diagnostic tissue sample, thus provide a correct diagnosis of the pet’s condition.\nFlexible endoscopy is used in our hospital allows us to look into the esophagus, stomach and intestines; during this procedure a flexible tube that has a small camera on its end is passed into the gastrointestinal tract either via the mouth or the rectum. This is a noninvasive method of examining the upper and lower gastrointestinal tract and can be used to look for tumors and to remove ingested foreign bodies. Furthermore, flexible endoscopy is used to obtain small biopsy samples of the gastrointestinal tract to diagnose infiltrative bowel disease such as inflammatory bowel disease.\nArthroscopy is the use of a slender rigid camera (1.9 mm or 2.7 mm) that is used to look inside of a joint. With this type of technology, only two small incisions are made, resulting in less pain for your pet. In addition, the camera provides a very magnified image of the joint and its structures, thereby allowing the surgeon to more accurately diagnose and treat the condition. The image to the right is a fractured bone piece within a joint (called a fragmented coronoid process).\nLaparoscopy is the examination of the abdominal organs with a camera on a rigid scope. A variety of surgical procedures can be done with this technology. Commonly, in our practice, laparoscopic liver biopsies, stomach tacking, spaying and removal of undescended testicles is performed with this minimally invasive surgery. The photo to the right shows an abdominal testicle that is being removed.\nVideo-Assisted Thoroscopic(VAT) Surgery is a state-of-the-art surgery that allows the surgeon to operate within the chest cavity via very small incisions. This procedure allows the surgeon to remove masses from the lung, biopsy masses within the chest, biopsy lymph nodes and other structures within the chest, remove foreign bodies from the chest cavity, and treat collapsing lungs (due to spontaneous pneumothorax). The benefit of this type of surgery is that the patient is much less painful after the procedure, as the ribs are not spread apart during the procedure.\nStem Cell Therapy/Platelet-Rich Plasma(PRP) Therapy is another cutting edge technology used at the Animal Surgical Center of Michigan. These magic elixirs of healing are very useful for patients that have joint, ligament and tendon injuries. Both stem cells and PRP is collected from the patient which eliminates the risk of cross patient infections and maximizes the viability of the stem cells. Stem cells transform into tissue that is damages (cartilage, bone, ligament/tendon tissues). PRP contains abundant growth factors that turn stem cells on to heal tissues. As a result, we commonly combine these treatments when treating various conditions. When treating ligament and tendon conditions, ultrasound-guided injection of stem-cells/PRP is used to insure that the treatment is administered right where it is needed.\nMinimally Invasive Osteosynhthesis is a minimally invasive method of fracture repair that is performed at our hospital to minimize surgical pain and maximize healing. Two small incisions are used to perform the procedure called minimally invasive osteosynthesis (MIO). A button-hole incision is made at the top and bottom ends of the fractured bone. A stainless steel surgical plate, that is almost the length of the bone, is slid under the skin and over the bone. Four to six screws are used to secure the bone plate to the ends of the bone. Because MIO mandates that no surgical incision is made directly into the fracture site, there is minimal disruption of the initial blood clot that is surrounds the fracture. Thus, the important healing substances (growth factors) at the fracture site are preserved. MIO also may be performed with an interlocking nail. Implant removal only requires two button hole incisions to remove the implants, thus the procedure is usually done on an outpatient basis.']	['<urn:uuid:84f8af81-d5e3-4fd1-a485-94d41a6eb580>']	factoid	direct	concise-and-natural	distant-from-document	single-doc	expert	2025-05-13T01:50:22.828293	8	30	1113
17	fluorescein vs bodipy fl donor acceptor comparison	Fluorescein and BODIPY FL serve different roles in fluorescence assays. In LanthaScreen assays, fluorescein acts as an acceptor species paired with terbium as the donor. In contrast, in the MraY inhibitor assay, BODIPY FL functions as a donor fluorophore that works with LRPE as the acceptor. These different configurations enable measurement of specific molecular interactions through energy transfer processes.	"['LanthaScreen Technology Overview\nTime Resolved-Fluorescence Resonance Energy Transfer (TR-FRET) is a preferred fluorescent assay formats in drug discovery laboratories. TR-FRET assays are less susceptible to compound interference than other assay formats and may be applied to multiple target classes. To support this technology focus, Invitrogen has developed LanthaScreen kinase activity assays. Invitrogen uses two sets of FRET-pairs in developing our LanthaScreen Assays: Terbium/Fluorescein (or GFP) and Europium/AlexaFluor 647.\nThe LanthaScreen kinase activity assay format is based on the use of a long-lifetime terbium or europium chelate as the donor species and fluorescein as the acceptor species. When terbium (or europium) and fluorescein (or AlexaFluor 647) labeled molecules are brought into proximity, energy transfer takes place causing an increase in acceptor fluorescence and a decrease in donor fluorescence. These fluorescent signals can be read in a time-resolved manner to reduce assay interference and increase data quality.\nThe time-resolved spectra above illustrate energy transfer occurring when terbium and fluorescein are brought into proximity via biomolecular interactions. The TR-FRET value is determined as a ratio of the FRET-specific signal measured with a 520 nm filter to that of the signal measured with a 495 nm filter, which is specific to terbium. The inset shows the time-resolved spectra in the absence of energy transfer.\nOvercome compound interference using LanthaScreen Assays\nTR-FRET assays offer advantages over fluorescent polarization (FP) assays when background fluorescence is a problem. In FP assays, background fluorescence due to fluorescent library compounds is often depolarized. Background signal due to scattered light, like that from precipitated compounds, is often polarized. Either phenomenon can lead to a false positive or false negative result, depending on the assay configuration. Because the donor species used in a TR-FRET assay has a fluorescent lifetime that is many orders of magnitude longer than background fluorescence or scattered light, energy transfer can be measured after the interfering signal has completely decayed. Additionally, unlike FP assays, TR-FRET assays can be formatted using limiting receptor and excess tracer concentrations, driving potential cost savings. Our LanthaScreen assays are resistant to interference from color quenchers, light scatterants, and fluorescent compounds.\nLanthaScreen Tb exploits Terbium as the donor chemistry\nMany TR-FRET assays use europium as the ‘long lifetime label’ doner paired with various far-red acceptors (including allophycocyanin (APC)). Due to the large molecular mass of APC (>100 KD) it has typically been used as a streptavidin conjugate, to in-directly couple to the biotinylated substrate in a trimolecular FRET complex. In contrast, LanthaScreen Tb utilizes terbium as the long lifetime label, enabling direct coupling to fluorescein as the acceptor species. This has the immediate advantage of being able to overcome several issues common to use of APC as the acceptor:\n- Simplify assay optimization. Since the donor-acceptor pair in a terbium-based TR-FRET assay does not require a biotin-avidin mediated interaction, three-compound matricies are not required to determine optimal reagent concentrations.\n- Avoid problems due to steric bulk associated with the large streptavidin-APC reagents including long incubation times to reach equilibrium.\n- Reduce assay cost by replacing streptavidin-APC with fluorescein (as well as remove lot-to-lot variations in streptavidin-APC).\nUse of LanthaScreen Tb also enables the use of GFP as the acceptor molecule, which allows for:\n- Development of protein substrates expressed as GFP-fusion proteins.\n- Development of cell lines expressing GFP-fusions for detection of phosphorylation which has occurred in a live-cell context via TR-FRET.\nIf a traditional Europium/Far Red FRET pair is preferred, Invitrogen offers all of our peptide-based substrates and matched antibodies with this alternative dye pair. Please contact us at email@example.com for more information.', ""- Inhibitors of peptidoglycan synthesis represent antibacterial drug targets\n- A FRET-based assay was developed to find MraY inhibitors\n- The simultaneous dual emission detection capability of the PHERAstar®FS enhances high-throughput\nTable of contents\nThe bacterial enzyme N-acetylmuramoyl-pentapeptide translocase (MraY) is a potential target of antibacterial drugs. It attaches UDP-N-acetylmuramoylpentapeptide (UNAM-pp) to lipid undecaprenyl phosphate (C55P), an essential step during bacterial cell wall biosynthesis. A FRET-based approach detects substances that inhibit MraY and can be read on BMG LABTECH's PHERAstar®. The HTS-suitable assay embeds the donor fluorophore (BODIPY FL), the MraY enzyme and C55P in a micelle. Acceptor-labelled (LRPE) UNAM-pp is then transferred by MraY to the micelle-standing C55P and FRET can occur with the micelle-embedded BODIPY FL.\nIn presence of MraY activity, the resulting fluorescence of the acceptor depends on reaction time and acceptor concentration. The assay allowed for determination of the IC50 value of the MraY inhibitor tunicamycin A. The ratiometric analysis eliminates fluctuations between measurements and makes it a robust assay with a high Z' value.\nPeptidoglycan is an important structural component of the bacterial cell wall. The continual synthesis of peptidoglycan and remodelling of the cell wall is essential for most bacteria. Since the enzyme phosho-N-acteylmuramoyl-penta-peptide translocase (MraY) catalyzes one of the last cytoplasmic steps in the peptidoglycan biosynthesis, it represents a target for antibacterial drugs. This integral membrane protein catalyzes the attachment of soluble UDP-N-acetyl-muramoylpentapeptide (UNAM-pp) to the lipid undecaprenyl phosphate (C55P) which is membrane bound.\nIn this application note we want to present a novel homogeneous FRET-based assay to monitor the activity of MraY. A donor fluorophore (BODIPY-FL) is attached to UNAM-pp (B-UNAM-pp) while the acceptor fluorophore-labelled 1,2-dipalmitoyl-sn-glycero-3-phosphoethano-lamine-N-(lissaminerhodamine B sulfonyl) (LRPE), is embedded in micelles which also contain MraY and the lipid substrate C55P (Figure 1).\nMraY translocase activity will attach B-UNAM-pp to C55P bringing FRET acceptor and donor close to one another. Excitation at 485 nm will result in energy transfer, reducing donor fluorescence (at 520 nm) and increasing acceptor fluorescence (590 nm).\nMaterials & Methods\n- PHERAstar FS microplate reader (BMG LABTECH)\n- Optic module (Ex:485 nm; Em: 520/590)\n- Chemicals were obtained from commercial sources\n- 384 well, low-volume, black, polystyrene plates (Matrix Tech)\nPreparation of UNAM-pp and cloning, expression of MraY in E.coli as well as subsequent preparation of membranes from E.coli overexpressing MraY is described in the literature.\nA 6 µL mixture containing 0.06% Triton X-100, C55P and E.coli membranes containing MraY was preincubated for 30 min. Addition of 3 mL of B-UNAM-pp +/- UMP initiated the reaction. Reaction buffer consisted of (final concentrations): 50 mM Tris-HCl (pH 7.5), 100 mM KCl, 50 mM MgCl2, 1 mM dithiothreitol and 0.05% Triton X-100. Final concentration of reactants: 20 mM C55P, 50 mg/mL membrane protein, 2 µM B-UNAM-pp with 0-24 µM LRPE and 0 or 5 mM UMP.\nTriplicate MraY assays were performed at room temperature. Fluorescence was excited and simultaneous dual-emission measured using 20 flashes for each reading at a focal height 10.6 mm. Measurements were made every minute for 1 hour and triplicate time courses averaged.\nTo test the effect of storage at room temperature, MraY assay reagents were stored at room temperature in the dark in the presence or absence of 0.5M trehalose. Reagents were mixed after 0, 2.5 and 5 hours of storage at room temperature and triplicate F590/F520 data were collected at the 1 hour time point. Z’ calculations could then be obtained from samples with (MAX) and without (MIN) membranes.\nTo study tunicamycin inhibition, reactions contained 16 µM LRPE, 0 or 15 µg/mL MraY-containing E. coli membrane protein, 0.1 µM B-UNAM-pp and 10 µM C55P in assay buffer containing 0.5 M trehalose. Tunicamycin was diluted with assay buffer and average progress curves without membranes were subtracted from the average progresscurves with membranes to obtain D(F590/F520) and DF520 measurements. Percentage inhibition and IC50s were calculated.\nResults & Discussion\nWhen the reaction is exposed to fluorescent excitation at 485 nm a time-dependent decrease in 520 and increase in 590 emission is observed (data not shown). Ratiometric measurements were used as they have less noise than individual fluorescence intensity measurements (Figure 2). This is due to the elimination of fluctuations that equally affect both measurements. The ratio change exhibits an increase in a time and LRPE dependent manner.\nWhen reactions are performed in presence of 5 mM UMP the change in fluorescence ratio is negligible (data not shown). In the absence of UMP a large increase in fluorescence ratio is observed with time (Fig. 2). This effect indicates that the signal observed in the assay is due to the MraY reaction.\nThe effect of trehalose, a sugar stabilizer, on storing the reagents at room temperature was also assessed. Figure 3 shows that Z’ values decrease when assays are stored at room temperature for as little as 2.5 hours. However the addition of 0.5 M trehalose blocks this effect.\nThe sensitivity of this assay to inhibition was studied using tunicamycin (Figure 4). The results show that IC50s measured using Δ(F590/F520) are lower and exhibited less of an increase with reaction time than those measured with ΔF520.\nThis assay has several advantages over those previously reported. First: it uses no radioisotopes so no special training, handling and disposal are required. Second: it uses a donor fluorophore with an excitation wavelength in the visible rather than UV part of the spectrum. This reduces interference from test compound auto-fluorescence and absorption. Finally: a FRET assay using the ratio of the emission of acceptor and donor fluorescence intensities upon donor excitation yields greater precision.\nThe use of Δ(F590/F520) over ΔF520 is advantageous due to greater sensitivity to inhibition, resistance to loss of sensitivity to inhibition and a higher signal-to-noise ratio. Furthermore a Z’ of greater than 0.7 indicates that this approach will be suitable for high throughput screens.""]"	['<urn:uuid:80c1c19f-393a-4633-b91d-10338ee48363>', '<urn:uuid:667727e9-3485-4ba0-8511-016f74b84877>']	open-ended	with-premise	short-search-query	similar-to-document	comparison	novice	2025-05-13T01:50:22.828293	7	59	1556
18	As a climate researcher studying fire impacts, I'm wondering how wildfires in California and bushfires in Australia differently affect air quality monitoring and measurement approaches?	In California, air quality monitoring approaches include technologies like Clarity's network of over 70 devices across UC campuses that use smaller, cheaper, solar-powered technology for localized monitoring that can function during power outages. Meanwhile, in Australia, air quality monitoring relies more on government systems and apps like AirRater that provide state-level updates, with major cities like Sydney using air quality index measurements that can detect levels exceeding 12 times the hazardous threshold of 200. Both regions emphasize the importance of local, real-time monitoring, but California appears to be developing more innovative technological solutions through projects like CITRIS's initiatives.	['Wildfires have shaped California’s landscape for centuries, but increased urbanization and development encroaching into formerly forested land is posing risks to life and property. Climate change is accelerating conditions that can lead to devastating effects. According to the California Department of Forestry and Fire Protection (CAL FIRE), California is experiencing the deadliest and most destructive wildfires in its history. To date this year, 9,639 fires have contributed to the burning of 4,177,524 acres of land.\nResearchers from CITRIS and the Banatao Institute are bringing technological innovation to combat the worst effects of wildfires on human populations and the built environment. The projects below highlight CITRIS’s contributions in researching fire mitigation and support efforts, from our earliest to most recent work.\nIn the early 2000s, CITRIS Principal Investigator and former Director Paul Wright worked on a series of “smart mask” research projects for firefighters to improve communication and information efficacy in real-time. The FIRE/FireEye/SmokeNet projects focused on equipping first responders with a head-up display on helmet face shields which provided direct contact with incident commanders via simple text. Project prototypes were tested with the Chicago Fire Department and Berkeley Fire Department.\nIn 2016, CITRIS provided seed funding to the Comparative Adaptive Management and Ecosystem Response Assessment (CAMERA), a project to photograph vulnerable natural landscapes in California’s Sierra Nevada. An ongoing research project, CAMERA offers substantial information resources so that communities living in forested areas and natural resource management experts can communicate the effects of climate change on regional public lands and watersheds.\nCITRIS PI Jovan Pantelic received a CITRIS Seed Award in 2018 to explore the use of Internet of Things (IoT) measurements, combined with survey-based information, to evaluate the resilience of air quality management in buildings to extreme outdoor particulate episodes. His building-specific air quality research focuses on the impact of particulate matter from wildfire emissions on health. His technology was tested on the UC Berkeley campus in student-centered buildings like Wurster Hall. This effort was a response to California’s 2018 Camp Fire in Butte County.\nAlso in 2018, Katia Obraczka and a team of researchers received CITRIS Seed Funding for P.A.N.T.H.E.R. (Persistent Autonomous Monitoring for Timely Detection of Wildfires) to design, deploy, test, and evaluate a novel IoT system to enable accurate, timely, and scalable wildfire detection and prediction. Due to the size of sensitive areas that need to be monitored in California, automation is a scalable answer to persistent and accurate predictions and timely detection and alerts.\nIn spring 2019, CITRIS visiting scholar Louise Comfort joined a yearlong study to develop efficient ways to evacuate small towns such as Bolinas, California that are accessible only by narrow roads. Comfort and other UC Berkeley researchers studied optimal evacuation routes, traffic strategies, and alternative, operable communication methods in order to maximize the safety of residents during a fire and attendant power outages. The interdisciplinary research team found that having informed residents and learning from prior fire experiences are two essential elements to mitigate damage.\nCITRIS PIs Yu Zhang and Scott Moura are developing predictive software that models fire risk regions. Their 2019 CITRIS seed-funded project analyses multi-hazard risks to inform distribution-grid upgrades for reliability and resilience, using artificial intelligence and machine learning tools to run simulations of electrical damage from natural disasters. “Right now, I don’t think PG&E has a scientific framework for trying to do this in a systematic way,” says Zhang.\nThe “Health, Wildfires & Climate Change in California” white paper, published by the CITRIS Policy Lab in October 2019, describes both the extent to which California’s wildfire readiness is lacking and recommendations for next actions. This collaborative effort between Bruce Riordan at the Climate Readiness Institute and CITRIS has been widely circulated in state-level policy circles.\nIn early 2020, CITRIS Foundry company Clarity deployed over 70 network devices across every UC campus to prepare air quality monitors for wildfires. Clarity integrates smaller, cheaper, solar-power technology into air monitoring devices to provide air quality information at a localized level. Clarity’s revolutionary approach in this field supplements the sparsely populated, expensive sensors currently in place that are also vulnerable to power outages. Clarity has also recently partnered with Blue Forest Conservation, one of California’s leading private forest management facilitators.\n“It is crucial to have access to local and current air quality data, especially during wildfire season when air quality can change rapidly. It is not enough to know the regional AQI. Local monitoring is needed so people can know what air quality is like right outside their door and decide whether it’s safe to bring their loved ones out for a walk or to play in the park. That’s really what we are envisioning for the future,” says Clarity Founder David Lu.\nThe CITRIS + CIEE EcoBlock project builds zero-carbon energy, deep water conservation, and resilient city structures on a block-by-block level. The pilot site in Oakland’s Fruitvale District was announced in April 2020. Motivated by pressing environmental issues and California’s mandate to achieve 50 percent of its electricity from renewable sources by 2026, EcoBlock provides an affordable and cost-effective solution to California’s outdated power system. PI Alexandra “Sascha” von Meier argues that Ecoblock’s locally sourced solar power network will mitigate fire risk because it does not require easily damaged overhead power lines.\n“In the face of wildfires and power shutoffs, urban microgrids can be a truly innovative solution. The Oakland EcoBlock project is developing a new way for keeping the lights on in the neighborhood even when the grid goes down, using shared solar energy,” von Meier says.\nIn fall 2021, the CITRIS Foundry Resource Sustainability X-Lab will host an innovation challenge to research wildfire prevention and measuring methods. Sponsored by Lotusland Investments, the challenge allows student innovators and researchers – from various backgrounds and disciplines – to collaborate, explore, and develop new technical solutions for early wildfire detection and mitigation.\n“We are focused on finding new ways to detect wildfires and respond rapidly. Students with various levels of experience, backgrounds, and interests are encouraged to participate,” says Thomas Azwell, CITRIS Foundry Fellow and Director of the Resource Sustainability X-Lab. In the meantime, the team is developing a robust wildfire resiliency research program that will include technology evaluation and testing as well as landscape modeling.\nWorking with leading faculty, researchers, and students along with partners from industry, first responders, and civil society, CITRIS is proud to catalyze these projects that provide social benefit for Californians.\nThe Center for Information Technology Research in the Interest of Society (CITRIS) and the Banatao Institute drive interdisciplinary innovation for social good with faculty researchers and students from four University of California campuses – Berkeley, Davis, Merced, and Santa Cruz – along with public and private partners.\nTo learn more about CITRIS, sign up for our newsletter: bit.ly/SubscribeCITRIS', 'Bushfire season in Australia is getting worse and worse. These fires directly affect Australians in more ways than we can count — thousands of homes have been lost, communities are being flattened, and tragically, lives have been claimed. While many brave firefighters and everyday Australians have been battling the blaze in their own backyards, others have experienced the fires from afar in the form of hazardous smoke.\nSince the devastating fires of 2019-20, we’ve received a lot of questions regarding air quality and the smoke from bushfires, and the impact of climate change on air quality overall. Here, we’ve answered a few of those questions, and provided some tips on looking after your health when air quality is poor.\nHow does climate change impact air quality?\nClimate change is caused by greenhouse gas emissions released from the burning of fossil fuels: coal, oil, and gas. Burning fossil fuels not only drives dangerous warming, it also has a significant impact on air quality and human health. In Australia, air pollution—primarily from burning fossil fuels—already causes about 3,000 premature deaths per year.\nClimate change affects air quality in a range of ways, including through its influence on pollutants such as ozone and particulate matter (fine particles in the air), and aeroallergens, such as pollens and moulds. Climate change also indirectly influences particulate matter levels by increasing the frequency and severity of bushfires and dust storms in regions that are projected to be hotter and drier. Bushfires and dust storms are the main cause of extreme pollution events in areas such as Sydney.\nHow does poor air quality affect health?\nPoor air quality, especially from bushfire smoke, creates a range of health problems, especially for those with pre-existing heart or lung conditions. Bushfire smoke contains very fine particles and carcinogens (cancer-causing substances) such as formaldehyde and benzene. Fine particulate matter is particularly damaging to health because it can travel deep into the lungs and even into the bloodstream. As smoke can travel for thousands of kilometres and cover large areas — like we’ve seen across Australia during the current bushfire crisis — large populations can be exposed to it.\nUsually, healthy people can tolerate low levels of air pollution, although it can cause temporary irritation of the eyes, nose and throat. People with a heart condition or a lung condition such as asthma may experience a worsening of their symptoms. But with higher levels of air pollution, anyone can experience adverse health effects. Because of the ongoing and dense bushfire smoke blanketing some parts of Australia, the Australian Medical Association has warned that even previously healthy people may develop serious illnesses. Heat, fatigue, stress, and mental health impacts, driven by the ongoing bushfire crisis, increase health risks even further.\nSmoke from bushfires blankets Manly Beach in Sydney\nWho is most vulnerable to the impacts of bushfire smoke and poor air quality?\nPeople with existing heart or lung conditions such as asthma, children under the age of 14, people over the age of 65, and pregnant women are among the groups most vulnerable to the impacts of bushfire smoke and poor air quality.\nAnyone who develops breathlessness, wheeziness, chest tightness, or a persistent cough should seek medical attention immediately.\nRecent conditions in Australian cities\nNew South Wales, Victoria, Queensland, Tasmania, South Australia and Western Australia have all faced dangerous air quality conditions this bushfire season. Bushfire smoke haze has been affecting the air quality for millions of people, including those in major cities such as Sydney, Melbourne, and Canberra. In November 2019, parts of Sydney experienced air quality more than 12 times the hazardous level of 200. On 1 January 2020, the air quality index in parts of Canberra (Monash) reached 4,650 — more than 23 times the hazardous threshold.\nThe best way to stay up to date on the conditions in your location is to consult your local air quality information. The Bureau of Meteorology provides links to smoke and air quality information for each state and territory. The free AirRater app provides information and updates on air quality covering most states and territories. Some states and territories such as NSW also provide real-time air quality updates that you can subscribe to on your phone.\nHow can I protect my health in poor air quality conditions?\nThe best way to protect your health from bushfire smoke and poor air quality is to limit your exposure when conditions are dangerous. This includes staying indoors with the doors and windows shut, and avoiding vigorous exercise outdoors. When conditions are rated as ‘hazardous’, avoid all exercise outdoors. As a rule of thumb, even healthy people should avoid exercising outside when there is visible smoke in the air. People in vulnerable groups or who are particularly sensitive to the smoke should take extra care.\nWhile staying inside is the most effective way to protect your health, face masks rated for P2 particles can help if fitted properly. While ordinary paper masks do not protect against poor air quality, P2 (or N95) masks do filter some smoke and particulate matter. However, masks are not completely effective and require an airtight seal — for example, if you have a beard, this will create leakages around the sides of the mask. The downside is that wearing a mask can make it more difficult to breathe easily (reducing the amount of oxygen available) and the moist environment can cause bacteria to collect on masks. If you are suffering from smoke inside your home, you may also find some protection from an air purifier, although note that it must have a high-efficiency particulate air (HEPA) filter to remove particles from the air.\nWhat must our leaders do to address our worsening air quality?\nWorsening climate change is increasing the frequency and severity of bushfires and their associated impacts on health and air quality. While the Federal Government is failing to adequately respond to the climate crisis and the escalating bushfire threat, Australians from all walks of life are demanding action, including doctors and other health professionals. The main sources of air pollution are also the main sources of greenhouse gas emissions, which are driving climate change. Acting on climate change and reducing these emissions is key to ensuring healthy air for our communities.\nThe government must develop an urgent plan to:\n- Prepare Australian communities and health and emergency services for escalating fire danger; and\n- Rapidly phase out the burning of coal oil and gas, which is driving more dangerous bushfires and their associated air quality and health impacts.\nYou can read more about climate change and bushfires here and here.\nAir quality resources by state and territory\nNew South Wales\nCurrent and forecast air quality – https://www.dpie.nsw.gov.au/air-quality\nBushfire Smoke Health Information – https://www.health.nsw.gov.au/environment/factsheets/Pages/bushfire-smoke.aspx\nBureau of Meteorology Air Pollution Report – http://www.bom.gov.au/catalogue/warnings/air-pollution.shtml\nBushfire Smoke Alert – https://www.health.qld.gov.au/news-events/health-alerts/bushfire-smoke-health-alert\nBushfire Smoke and Your Health – https://www.qld.gov.au/health/staying-healthy/environmental/after-a-disaster/bushfires/bushfire-smoke-and-your-health\nEPA Air Watch – https://www.epa.vic.gov.au/for-community/airwatch\nBushfire Smoke and Your Health – https://ref.epa.vic.gov.au/your-environment/air/smoke/bushfire-smoke-and-your-health\nAir Monitoring – https://www.epa.sa.gov.au/data_and_publications/air_quality_monitoring\nSA Health – Bushfires\nEmergency WA – https://www.emergency.wa.gov.au/\nHealth WA – Smoke Hazard from Bushfires – https://healthywa.wa.gov.au/Articles/S_T/Smoke-hazard-from-bushfires\nTasALERT – http://alert.tas.gov.au/Pages/Home.aspx\nBushfire Smoke and Your Health – https://www.dhhs.tas.gov.au/publichealth/air/bushfire_smoke\nAustralian Capital Territory\nAir Quality in the ACT: https://www.health.act.gov.au/about-our-health-system/population-health/environmental-monitoring/monitoring-and-regulating-air\nACT Air Quality Updates – https://www.health.act.gov.au/public-health-alerts\nOutdoor Smoke – Health Impacts – https://www.health.act.gov.au/sites/default/files/2019-12/Outdoor%20Smoke%20%20Health%20Impacts%20Factsheet%20-%20Dec%202019%20-%20FINAL_0.pdf\nBushfire Alerts and Warnings – https://denr.nt.gov.au/bushfire-information-and-management/bushfire-alerts-and-warnings/alerts-warnings\nNT EPA – http://ntepa.webhop.net/NTEPA/Default.ltr.aspx\nAir Pollution in Australia: Real- time Air Quality Index Visual Map – https://aqicn.org/map/australia/\nAir Quality Australia –\nGlobal forecasting of air quality (WACCM): https://www.acom.ucar.edu/waccm/forecast/']	['<urn:uuid:f7737491-6b6f-4bd5-964a-d0134ef4e1c2>', '<urn:uuid:dc445cdb-0dd0-45b8-9db6-0cb50e5651dc>']	open-ended	with-premise	verbose-and-natural	similar-to-document	comparison	expert	2025-05-13T01:50:22.828293	25	98	2367
19	how much jizya tax dhimmi christians raqqa province pay isis different income levels	Under the dhimmi pact, adult male Christians must pay jizya tax at different rates based on income levels: wealthy individuals pay 4 dinars of gold, middle-income individuals pay half that amount (2 dinars), and poor individuals pay a quarter (1 dinar). These payments must be made twice per year.	"['Christians who remain in Syria\'s Raqqa province may now be subject to a ""dhimmi pact."" In classical Islamic law a dhimmi, or “protected person,” is allowed to live in Muslim lands provided he pays the jizya, a residency tax, in a state of submission and abides by other restrictions. Jews and Christians, because they are “people of the Book,” are given the offer to accept dhimmi conditions.\nMuslims are obligated to protect dhimmis, but if dhimmis breach the pact, all bets are off. Aymenn Jawad Al-Tamimi, a student at Brasenose College, Oxford University, and a Shillman-Ginsburg Fellow at the Middle East Forum, who appears to have first reported the pact on Feb. 26, notes: ""The Qur\'anic basis for this arrangement is 9:29. In practice of course, the dhimmi pact, far from being a model of historical multiculturalism and tolerance as hailed by Western Islamic apologists . . . is actually equivalent to Mafia racketeering, as failure to pay \'jizya,\' whose financial burdens often proved heavy historically, leads to a loss of \'protection\' by the state.""\nExactly how many people will be affected by this dhimmi agreement is unclear. There may not be many Christians who have stayed in Raqqa province now that it has fallen under the control of the Islamic State of Iraq and ash-Sham, I.S.I.S., a group so notoriously brutal even Al Qaeda refuses to associate with them. In the statement annoucing the dhimmi pact, circulated on Islamist websites, I.S.I.S. members said that some 20 Christian leaders had agreed to the terms, but asked that there names not be revealed.\nJawad Al-Tamimi provided a translation for the agreement:\nThis is what the servant of God- Abu Bakr al-Baghdadi, the Commander of the Faithful [NB: this is the title of a Caliph] has given to the Christians concerning the pact of protection. He has given them security for themselves, their wealth, their churches and the rest of their property in the province of Raqqa: their churches should not be attacked, nor should anything be taken [by force] from them, nor from their domain, nor anything from their wealth, and there should be no compulsion against them in religion, and none of them should be harmed.\n1. That they must not build in their town or the periphery a monastery, church or monk’s hermitage, and must not rebuild what has fallen into disrepair.\n2. That they must not show the cross or any of their scriptures in any of the roads or markets of the Muslims and they must not use any means to amplify their voices during their calls to prayers or similarly for the rest of their acts of worship.\n3. That they must not make Muslims hear recital of their scriptures or the sounds of their bells, even if they strike them within their churches.\n4. That they must not engage in any acts of hostility against the Islamic State, like giving housing to spies and those wanted for a reason by the Islamic State, or whosoever’s brigandery is proven from among the Christians or others, they must not aid such persons in concealing or moving them or other such things. If they know of a conspiracy againt the Muslims, they must inform them about it.\n5. That they must not engage in any displays of worship outside the churches.\n6. That they must not stop any of the Christians from embracing Islam if he so wishes.\n7. That they must respect Islam and Muslims, and not disparage their religion in any way.\n8. The Christians must embrace payment of the jizya--on every adult male: its value is 4 dinars of gold…on the Ahl al-Ghina [the wealthy], and half that value on those of middle income, and half that on the poor among them, on condition that they do not conceal anything from us regarding their state of affairs. And they are to make two payments per year.\n9. They are not allowed to bear arms.\n10. They are not to deal in selling pork and wine with Muslims or in their markets; and they are not to consume it [wine] publicly--that is, in any public places.\n11. They should have their own tombs, as is custom.\n12. That they must accept the precepts imposed by the Islamic State like modesty of dress, selling, buying and other things.\nA side note of interest: According to Jawad Al-Tamimi, ISIS\' official Twitter account for Raqqa province noted the imposition of the dhimmi pact with a small (ish) bit of braggadacio: ""Today in Raqqa and tomorrow in Rome.""']"	['<urn:uuid:a1de035d-5c2c-4dc9-9520-f3759a66a657>']	factoid	with-premise	long-search-query	similar-to-document	single-doc	expert	2025-05-13T01:50:22.828293	13	49	758
20	compare roving unspun wool vs knitted stitch strength durability properties	Roving (unspun wool) and knitted stitches have very different durability properties. Roving consists of wool fibers laying in the same direction with barely any twist, making it very fragile, easy to pull apart, and prone to shedding and pilling. The shorter fibers can fall out easily, and it can be destroyed quickly by pets walking on it. In contrast, a knitted stitch is a basic unit of intermeshing that consists of three or more intermeshed needle loops, creating a more durable structure. The knitted stitch has the center loop drawn through the head of the lower previously-formed loop and is intermeshed through its head by the loop above it, providing structural integrity.	"['Knitting terms and definition\nFabric forming process\nWeaving is the interlacement (Fig.a) of two sets of threads (i.e. warp and weft) at a right angle.\nInterlooping (Fig.c) consists of forming yarn(s) into loops, each of which is only released after a succeeding loop has been formed and intermeshed with it.\nIncludes a number of techniques, such as braiding and knotting, where threads are caused to intertwine (Fig.c) with each other at right angles or some other angle.\nKnitting is a technique to turn thread or yarn into a piece of cloth. Knitted fabric consists of horizontal parallel courses of yarn which is different from woven cloth. The courses of threads or yarn are joined to each other by interlocking loops in which a short loop of one course of yarn or thread is wrapped over the another course.\nKnitting is a process of fabric forming by the intermeshing the loops of yarns. When one loop is drawn through another, loops are formed in horizontal or vertical direction.\nTypes of Knitting\nThere are two of knitting-\n- Weft knitting\n- Warp Knitting\nWeft Knitting is a method of forming a fabric in which the loops are made in horizontal way from a single yarn and intermeshing of loops take place in a circular or flat form on across wise basis.\nWarp Knitting is a method of forming a fabric in which the loops are made in vertical way along the length of the fabric from each warp yarns and intermeshing of loops take place in a flat form of length wise basis.\nThe series of loops those are connected horizontally, continuously are called as course.\nThe horizontal row of loops that are made by adjacent needles in the same knitting cycle.\nThe series of loops that intermeshes vertically are known as Wales.\nVertical column of loops that are made from same needle in successive knitting cycle\nFeatures of wales\nWhen loop transfer occurs it is possible to transfer a wale of loops from one needle A to another B.\nIn warp knitting a wale can be produced from the same yarn if the same warp guide laps the same needle at successive knitting cycles.\nWales are connected together across the width of the fabric by sinker loops (weft knitting) or underlaps (warp knitting).\nWales show most clearly on the technical face and courses on the technical back of single needle bed fabric.\nParts of a loop\nEach knit stitch (knit loop) is a basic unit for the knitted goods\nH: Head or Crown or top arc\nL: Side limbs or Legs\nS: Bottom arc or Sinker loop\n→A complete loop=Needle loop+Sinker loop\nNeedle loop is the upper part of the loop produced by the needle drawing the yarn.\nThe lower part of the knitted loop is technically referred as sinker loop. It is the connection of two legs belonging to neighboring stitches lying laterally.\nThe open loop is one in which the loop forming yarns do not cross at the bottom of the loop.\nIn closed loop the legs cross at the bottom, so that the loop closing takes place.\nFace loop and technical face\nDuring loop formation, when the new loop emerges through the old loop from back to the face side then it is termed as face loop or weft knitted loop.\nThe side of the fabric which contains all face loops or weft knit loops is known as technical face.\nBack loop and Technical Back\nDuring loop formation, when the new loop passes from the face side to the back of the previous loop then it is termed as back loop or purl loop.\nThe side of the fabric which contains all back loops or purl loops is known as technical back.\nThe knitted stitch is the basic unit of intermeshing. It usually consists of three or more intermeshed needle loops. The centre loop has been drawn through the head of the lower previously-formed loop and is, in turn, intermeshed through its head by the loop above it.\nKnitting notation is a simple, easily-understood, symbolic representation of a knitting repeat sequence.\nIts resultant fabric structure that eliminates the need for time-consuming and possibly confusing sketches and written descriptions.\nNotations are used to express the knitted fabric structure and design.\nNotations are of four types:\n2.Line diagram/ Looping diagram\n3.Diagrammatic notation/ Chain notation\nThe length of yarn required to produce a complete knitted loop (i.e Needle loop and sinker loop) is known as stitch length or loop length.\nStitch length is a length of yarn which includes the needle loop and half the sinker loop on either side of it.\nGenerally, the larger the stitch length, the more extensible and lighter the fabric and the poorer the cover and bursting strength.\nA course length\nIn weft knitted fabrics, a course of loops is composed of a single length of yarn termed a course length.\nDefinition: The length of yarn required to produce a complete knitted course is known as course length.\nCourse length= No. of loops per course X Stitch length\nCourse length= No. of needles X Stitch length\nStitch density refers to the total number of loops in a measured area of fabric.\nIt is the total number of needle loops in a given area (such as a square inch\nStitch density= Wales density x Courses density\n=Wales per inch X Courses per inch\n= WPI X CPI\nUnit: number of loops per square inch\nOr, SD= CPC x WPC (cm scale)\nA knitted fabric is technically upright when its courses run horizontally and its wales run vertically, with the heads of the needle loops facing towards the top of the fabric and the course knitted first situated at the bottom of the fabric.\nSingle jersey & Double jersey\nSingle jersey or plain fabric: The weft knitted fabric (Tubular/flat) which is produced by one set of needles.\nDouble jersey: The weft knitted fabric (Tubular/flat) which is produced by two sets of needles.\nThe fabric loops are always drawn from the needles on the side remote from their hooks. When two sets of needles are employed, the fabric will be produced and drawn away in the gap between the two sets.\nNeedle bed or needle carrier\nNeedle bed or needle carrier is the place where the needles are located or mounted in a knitting machine. Needle moves up and down in the trick of a needle carrier.\nTwo types of needle carrier:\n- Cylindrical or circular\nCylinder and Dial\nCylinder is a circular steel bed having grooves / tricks /cuts on it’s outer periphery into which the needles are mounted.\nWith reference to the tricks, the needles move vertically up and down by their butt being in contact with the cam track.\nThe diameter of the cylinder also varied based on the type and width of the fabric.\nMaximum diameter of the cylinder: 46 inches.\nDial is the upper steel bed used in double knit circular machines.\nInto the grooves of the dial, the needles are mounted horizontally and are allowed to move radically in and out by their dial cams.\nThe number of grooves per unit space conforms with the cylinder gauge in most of the cases.\nMachine gauge or Needle gauge\nThe number of needles present in one inch of a needle bed is called machine gauge. It is denoted by G or E.\nThe distance between two neighboring needles\nSpace required for each needle.\nFeeders are the yarn guides placed close to the needles to the full circumference of the knitting zone.\nThe feeders feed the yarn into the needle hooks and control the needle latches in their open position while the needle attain their clearing position.\nA selvedge fabric is one having a “self edge” to it and can only be produced on machines whose yarn reciprocates backwards and forwards across the needle bed so that a selvedge is formed as the yarn rises up to the next course at the edge of the fabric.\nCut edge fabric usually produced by slitting open a tube of fabric produced on a circular machine. A slit tube of fabric from a 30” diameter machine will have an open width of 94”(πd) at knitting & before relaxation.\nThis may be produced in double faced or single faced structures on circular machine, or in a single faced from on a straight machines with two sets of needles provided each needle set only knits at alternate cycles and that the yarn only passed across from one needle bed to other at the two selvedge needles at each end, thus closing the edges of the tube by joining the two single faced fabrics produced on each needle set together.\nMain features of a knitting machine\n- The frame, normally free standing and either circular or rectilinear according to needle bed shape, provides the support for the majority of the machine’s mechanisms.\n- The machine control and drive system co-ordinates the power for the drive of the devices and mechanisms.\n- The yarn supply consists of the yarn package or beam accommodation, tensioning devices, yarn feed control and yarn feed carriers or guides.\n- The knitting system includes the knitting elements, their housing, drive and control, as well as associated pattern selection and garment-length control device.\n- The fabric take-away mechanism includes fabric tensioning, wind-up and accommodation devices.\n- The quality control system includes stop motions, fault detectors, automatic oilers and lint removal systems.\nHow to write a machine specification?\nWeft knitting machine\n→Single jersey circular knitting machine.\n→Rib circular knitting machine.\n→Interlock circular knitting machine\n→Socks circular knitting machine.\n→Double cylinder purl knitting machine\n→Flat knitting machine\n→ V-bed flat knitting machine\n→ Straight bar frame\nPowered by Facebook Comments', 'After days of research and talking with several yarn makers, I would like to share a bit of information regarding the recently popular Giant Stitch Blankets. Some of the information will be quite disappointing especially concerning the blankets made of roving, but rest assured that we have several wonderful solutions for you.\nTo begin, there is a consensus among knitters, manufacturers and designers that roving style blankets such as the Giganto Blanket (seen above) and the Extreme Knitted Blanket are very, very fragile. These blankets are made of roving, or unspun wool, which consists of wool fibers laying the same direction with barely any twist to keep them together. Roving is what the manufacturers use to make yarn.\nPlease enjoy these images. Left: Carded Wool at Green Mountain Spinnery, Middle: close up on roving, Brown Sheep Co., Right: Roving ready to be spun at Brown Sheep Co.\nWhile it is stunning to see, this is not yarn! It is delicate and can easily be pulled or ripped apart (such as accidentally standing up on the corner of the blanket). The shorter fibers in the roving are known to fall right out, and items made from pure roving are known to pill and shed substantially. If you have cats or dogs, they can destroy a roving blanket in a matter of hours just by walking on it.\nIf you have already made a roving blanket and it is destroyed, I highly recommend that you either spin it into yarn yourself, donate it to a friend who can spin, or contact a yarn company to return the wool so that it can be recycled and made into new yarn. A single blanket can take up to 7 lbs of roving which equates to almost 11 skeins of yarn. We would love to help facilitate this so please contact us for help.\nSo why do these blankets exist considering how impractical they are? Visually, they are lovely! Also, this is the cheapest way to get that much wool. A large roving blanket to fit a king size bed costs roughly $135-154 for Brown Sheep Wool Top (unprocessed; it still has to be split and felted together into a single strand). To prolong the life of these blankets, use it as a piece of wall art, or place it in a rarely used room. When not in use, store it inside of a large pillow case or trunk to keep the dust out of the fibers.\nNow that we understand what roving is, how do they make roving into yarn? Roving is twisted and pulled on industrial machines or spinning wheels to lock the fibers together, and then plied (where 2 or more twisted strands are wound together) for further strength.\nLeft: Pin Drafter at Brown Sheep Co starting to mix colors together. Middle: Making Pencil roving (roving divided into strands the size of a pencil) at Green Mountain Spinnery, Right: Pencil rovings spun into yarn at Green Mountain Spinnery.\nNow the wool is strong enough to take abuse without pulling apart easily. The plied yarns resist pilling the most (that is why we recommend them for sweaters). The strongest wool is felted so that all of the little scales stick together like velcro.\nWool Yarns-Single Ply Jumbo Yarn\nMany will still prefer a single-plied yarn for their blanket to give it that fluffy, monotonous texture. This option is my personal preference because it preserves the beauty of the single strand with the strength of real yarn. This is an expensive option, but considering how much you dream of having this blanket, it is worth the price. Luckily, Yarn Loop is sourcing 3 excellent choices for you in Jumbo size!\nWool Yarns-Multi Plied\nFor a truly usable and washable blanket, especially if you have children or pets, we recommend loosely twisting 3-4 strands of super bulky yarn together to make your own jumbo plied yarn as seen in the Basketweave Arm Knit Blanket (shown in last section by Flax & Twine). Another option is to crochet a long chain to make a chainette style yarn. The Giant Super Chunky Knit Blanket above is a very good example of a chainette bulky yarn that has been knit afterwards. Here are our selections for truly beautiful work:\nYou will need to weave in the ends or felt the strands together for a seamless join (kits available here).\nWe also have crochet kits available with hooks or as hand crochet. The Hand Crochet Chunky Blanket also by Flax & Twine shown below is done entirely with your hands while holding 4 strands of yarn together. It is easy enough for a true beginner to create a 36""x46"" blanket in about 1 hour!\nWool Blends-characteristics of yarn briefly described\nKnit Along to be announced!\nYarn Loop will be hosting its first knit along in the following weeks on a gigantic stitch blanket! Demonstrations on different needles and hooks will be presented, and lucky Texans will have the opportunity to schedule a knitting party to make the blankets in person with a minimum of 4 participants. Each knitting party will have the option to borrow all supplies from Yarn Loop for a minimal fee as well. Knit Along participants and party participants will be entitled to special discounts, so keep in touch and look for the KAL schedule shortly. Until then, use NEWKITS15 for 15% off blankets through Black Friday!\nA special thank you to the following sources: Sheep Shed Studio, Flax & Twine, Ravelers, Green Mountain Spinnery, Cascade Yarns, Brown Sheep Co and pattern designers with their respective photographers. For extra information, please see this blog by Brown Sheep Co to see examples of roving.\nComments will be approved before showing up.']"	['<urn:uuid:5251662e-079d-47bf-bd23-bd6935466349>', '<urn:uuid:6bf3b896-3c26-4d56-9d06-c8bc608ca760>']	open-ended	direct	long-search-query	similar-to-document	comparison	expert	2025-05-13T01:50:22.828293	10	112	2573
21	What's the difference in stability between a central force orbit and argon atoms - which one changes more easily?	Argon atoms are more stable and resistant to change. The documents show that argon is extremely unreactive and won't react with air, strong acids (HNO3, HCl) or bases (NaOH). In contrast, central force orbits can be perturbed and modified by various forces as shown by the orbital equations that describe their dynamics.	"['Orbit equation - Wikipedia, the free encyclopediaConsider a two-body system consisting of a central ... In polar coordinates, the\norbit equation can be written as. Central, inverse-square law force - Low-energy trajectories - Categorization of orbits\n19 Lecture 19: Central forces and the orbit equation87. 19 Lecture 19: Central forces and the orbit equation . In the previous lecture\nwe studied the motion under the influence of a conservative central force. We first\nOrbits in Central Force Fields IConsider the central force field F(r) associated with a spherical density ...\nMultiplying the second of these equations with r yields, after integration, that d dt.\n(r. 2 ˙ ..... Hamilton\'s equations now become. ∂H. ∂r. = − p. 2 θ r3 +. ∂Φ. ∂r. = −\n˙ pr .\nCentral Force Motion: Orbits - MIT OpenCourseWareLecture L16 - Central Force Motion: Orbits . In lecture L12, we derived three basic\nrelationships embodying Kepler\'s laws: • Equation for the orbit trajectory, r =.\nMechanics, central orbit /force question - Physics ForumsMechanics, central orbit /force question in Calculus & Beyond Homework is being\n... From this the differential equation of central orbits is found:\nDifferential equation of the orbit .A general method of finding the orbit is to integrate the differential equations and\nthen ... Conversely, equation (3.25) can be used to find the law of central force ...\nChapter 5: Motion under the Influence of a Central ForceEquation (5.1.1) clearly means that the total angular momentum of the test\nparticle does ..... angular motion of the particle as it orbits the central source.\nPossible potentials responsible for stable circular relativistic orbits .pdfproduce stable, circular orbits in the relativistic central force problem has ... we\nfirst set up the relativistic orbit equation for a particle in a central .\nCentral Forces and Orbital Mechanics - UCSD Department of Physicswhere F(r) = −dU(r)/dr is the magnitude of the central force. This second order\nequation may be reduced to a first order one using energy conservation: E = 1. 2.\nA phase space approach to closed orbits in central potentialsconservative central force fields is one of the oldest subjects counted among\nphysics. ... equations for the orbit , the various proofs of the theorem mentioned .....\nequation B2 in a compact vector form. d dt. . . r θ pr pθ. . .\n0211472.ps.gzIt is well known that the P-R effect produces only changes in the orbital ... The\nrelativistic equation of motion for a perfectly absorbing spherical dust ...\nosculating orbital elements based on central gravity force alone, are relevant\nChemistry: The Central Science, Chapter 6, Section 9... or 16 We see that the beautiful structure of the periodic table reflects this orbital\nstructure. .... Write a balanced chemical equation for the reaction of solid boron\nBSc Maths fine - University Of Madras, Institute Of Distance Educationcoefficient; Sum of rth powers of roots; Reciprocal equations ;. Transformations of\n..... Central orbit as plane curve, p-r equation of a central orbit , finding law of ...\nDepartment of Mathematics Madras Christian College (Autonomous)Radius of curvature in polar coordinates – p-r equation – Envelopes (definitions\n..... Central Orbits : Central forces, Differential equation of a central orbit , Pedal ...\nIntegration of the primer vector in a central force field - Deep Blueoptimal solutions for orbital transfer when the central force field has a more ....\nThe adjoint p~, and Pr must satisfy the adjoint equations . ~pv/at = -p, ,. (12).\nPossible potentials responsible for stable circular relativistic orbits Bertrand\'s theorem in classical mechanics of the central force fields attracts us\nbecause of its predictive power. It categorically proves that there can only be two\nHOMOCLINIC ORBITS OF THE FITZHUGH-NAGUMO EQUATION The central idea of singular perturbation analysis is to use information ..... 0.0024\n= ¯ pr , two equilibria on the boundary of this p interval and one equilibrium ...\nNewtonian Dynamics - Home Page for Richard Fitzpatrick - The 5.12 Motion in a General Central Force-Field . ... 5.13 Motion in a Nearly Circular\nOrbit . ..... analysis, ordinary differential equations , and linear algebra. On the ...\nNotes on Hydrostatic Equilibrium.The Equation of Hydrostatic Equilibrium and Scale Heights ... massive central\nobject. This could be a proto-planetary disk in orbit about a young proto- ..... (31),\nequations (43) and (45) give us the volume VR and boundary pressure PR of a.\nAn introduction to Molecular Orbital TheoryRevision of Bohr model of atoms and Schrödinger equation . Lecture 2 ... 1)\nRutherford (1912) model of the atom (Planetary model with central ..... n – l – 1 →\n2p =0 , 3p =1. – Ensures 2p and 3p orthogonal. )2. (. 62. 1. )2( r re. pR . −. = )32(. 3\nThree Types of Chaos in the Forced Nonlinear Schrödinger Equationparabolic resonance ) in Hamiltonian perturbations of the nonlinear Schrödinger (\nNLS) .... orbits , having either central or winged configuration.\nAdvances in Difference Equations | Full text | Homoclinic orbits for 1 Department of Mathematics, Huaihua College, Huaihua, Hunan, 418008, P.R.\nChina. 2 School of Mathematical Sciences and Computing Technology, Central ...\nApproximate Kepler\'s Elliptic Orbits with the Relativistic Effectsbounded orbits of equations are determined. Secondly ... a central mass m ... By\na simply algebraic computation, we have. 2 2. 2 2. 2. 2 2. 2 2. 2. , . crp r. c r. p r .\nknotted periodic orbits in dynamical systems-i: lorenz\'s equationsinvestigate a system of ordinary differential equations which determines a flow on\nthe .... It remains a central problem to deduce these properties from (1.3) (or to ...\nA compact invariant set K for a flow pr is said to have a hyperbolic structure.\nelliptic orbits and the growth of the third law with newton - jstorand does not seem to have been at first found for central forces in .... PR under\nthe influence of an attractive force to the fixed .... equation of theorbit which is.\nEAS 4505: Orbital Mechanics: Central Florida (UCF): KoofersEAS 4505 ECS-MMAE 3(3,0) Orbital Mechanics: PR : EGN 3321 and a ""C"" (2.0) ...\nTwo-body problem, orbital equations , orbital transfer, earth satellite operation.\nDifferential Equations , Dynamical Systems, and an Introduction to CHAPTER 10 Closed Orbits and Limit Sets 215. 10.1 Limit ... 13.4 The Newtonian\nCentral Force ... most important behavior of solutions of differential equations .\nThree types of chaos in the forced nonlinear Schrödinger equationand parabolic resonance ) in Hamiltonian perturbations of the nonlinear\nSchrödinger (NLS) are ... tion of chaotic orbits in the perturbed, undamped two-.\nClassical orbits and semiclassical wavepacket propagation in the where qt and pr satisfy the classical Hamiltonian equations of motion ..... 24, 31,\n321. In this case the central orbit conesponds to a quantum number of n = 60.\neffects of direct and indirect solar radiation pressure in orbital the central body, in the absence of any disturbing influences, has the following\nform [1-2]: ... planetary equations , expressed in Keplerian orbital elements terms.\n.....  J. Qiu, PR Goode, E. Pallé, V. Yurchyshyn, J. Hickey, P. Monta˜nes Ro-.\nA STUDY FOR ORBIT REPRESENTATION AND ... - QUT ePrintsYing Fu Zhou. B.Eng. Central South University of Technology, China ....\nintegration of satellite orbital motion equations and measurements to the\nsatellites. Orbit .\nCO- ORBITAL MOTION WITH SLOWLY VARYING ... - LESIA˙ pr = −. ∂H2. ∂r. , and occurs over a typical time scale Torb, the orbital period of\nthe .... changes of mass will accelerate the central body and cause indirect accel-\n... ϵs in Equation (14) is actually a non-dimensional measure of the torque ex-.\nstability of circular orbits in noncommutative schwarzschild spacetimealized uncertainty principle on the classical orbits of particles in a central ... The\ngeodesics of this spacetime are given by the following equations  ..... pr . (1 +\nβp2) . (38). The radius of orbit r and the magnitude of the momentum p = √p2 are\nExistence of multiple periodic orbits of Hamiltonian systems on The main result is an existence theorem of multiple periodic orbits for\nHamiltonian v. ... for a special Hamiltonian function, and central gravity of the\nproof relies on a delicate ... to the study of periodic solutions of ordinary\ndifferential equations .', '|Classification:||Argon is a noble gas and a nonmetal|\n|Melting point:||-189.3 oC, 83.85 K|\n|Boiling point:||-185.8 oC, 87.3 K|\n|Neutrons in most abundant isotope:||22|\n|Electron configuration:||1s2 2s2 2p6 3s2 3p6|\n|Density @ 20oC:||0.001784 g/cm3|\n|Atomic volume:||22.4 cm3/mol|\n|Structure:||fcc: face-centered cubic when solid|\n|Specific heat capacity||0.520 J g-1 K-1|\n|Heat of fusion||1.188 kJ mol-1|\n|Heat of atomization||0 kJ mol-1|\n|Heat of vaporization||6.447 kJ mol-1|\n|1st ionization energy||1520.5 kJ mol-1|\n|2nd ionization energy||2665.8 kJ mol-1|\n|3rd ionization energy||3930.8 kJ mol-1|\n|Minimum oxidation number||0|\n|Min. common oxidation no.||0|\n|Maximum oxidation number||0|\n|Max. common oxidation no.||0|\n|Electronegativity (Pauling Scale)||–|\n|Polarizability volume||1.586 Å3|\n|Reaction with air||none|\n|Reaction with 15 M HNO3||none|\n|Reaction with 6 M HCl||none|\n|Reaction with 6 M NaOH||none|\n|Atomic radius||71 pm (measured)|\n|Ionic radius (1+ ion)||–|\n|Ionic radius (2+ ion)||–|\n|Ionic radius (3+ ion)||–|\n|Ionic radius (1- ion)||–|\n|Ionic radius (2- ion)||–|\n|Ionic radius (3- ion)||–|\n|Thermal conductivity||1.77 x 10-2 W m-1 K-1|\n|Electrical conductivity||0 mS cm-1|\n|Freezing/Melting point:||-189.3 oC, 83.85 K|\nDiscovery of Argon\nArgon was the first noble gas to be discovered.\nThe first hint of its existence came from English scientist Sir Henry Cavendish as far back as 1785. Cavendish was unhappy that so little was known about air. He was particularly unhappy about the lack of information about the fraction of air (the majority) which was not oxygen. (1)\nHe knew the nitrogen in air could be reacted with oxygen to form, ultimately, nitrous acid. He aimed to find out if ALL of the air that was not oxygen or carbon dioxide could be converted to nitrous acid. If it could, he would know that air was entirely oxygen, carbon dioxide and nitrogen.\nCavendish used an electric spark in air to react the oxygen and nitrogen to form nitrogen oxides. He then added additional oxygen until all the nitrogen had reacted.\nNitrogen oxides are acidic. Cavendish used aqueous sodium hydroxide to remove them from the apparatus. [This would also, of course, have removed any carbon dioxide that was present.] He removed the remaining oxygen using potassium polysulfides.\nA small bubble of gas remained [mostly argon]. Cavendish wrote that this bubble “was not more than one hundred and twentieth of the bulk of the phlostigated air [nitrogen].” (1) So, Cavendish is saying that air is at least 99.3 percent nitrogen/oxygen/carbon dioxide with a maximum 0.7 percent of something else. We now know that the ‘something else’, argon, is very unreactive; this enabled Cavendish to find it, but it also prevented him finding out more about it. (The giant advances in spectroscopy made by Gustav Kirchhoff and Robert Bunsen lay 85 years in the future.)\nIn hindsight, we can say Cavendish slightly underestimated the part of air that isn’t oxygen, nitrogen, or carbon dioxide. Despite this, he was ahead of his time. After his experiment, more than 100 years passed until scientists again began to think that something about air didn’t quite add up.\nIn 1892 English physicist John William Strutt (better known as Lord Rayleigh) announced that no matter how it was prepared, oxygen was always 15.882 times denser than hydrogen. This very precise work had taken ten years to complete.\nContinuing to work with great attention to detail, he found that the ‘nitrogen’ in air was always denser by about 0.5 percent than nitrogen sourced from nitrogen compounds. (2), (3) How could this be explained? In 1893 he wrote to Nature, announcing the problem to the world. Any scientist who responded to that challenge actually had the chance of discovering a new element. None did!\nIn April 1894 Rayleigh wrote an academic paper about the nitrogen problem. Funnily enough, Rayleigh viewed pure nitrogen, containing no argon, as ‘abnormally light nitrogen.’ He stored it for eight months and retested it to see whether its density would increase. (4)\nRayleigh’s paper awakened the serious interest of Scottish chemist William Ramsay, who had already been aware of the problem.\nRayleigh and Ramsay carried out further experiments, keeping in touch with one another about their progress.\nIn August 1894 Ramsay took air and removed its components – oxygen, carbon dioxide and nitrogen. He removed the nitrogen by reacting it with magnesium. After removing all the known gases from air, he found gas remaining that occupied one-eightieth of the original volume. Its spectrum matched no known gas.\nRayleigh and Ramsay wrote a joint paper in 1895 notifying the world of their discovery. The new gas wouldn’t react with anything, so they named it argon, from the Greek ‘argos’, meaning inactive or lazy. (5)\nIn his Nobel Prize winning address, Rayleigh said: “Argon must not be deemed rare. A large hall may easily contain a greater weight of it than a man can carry.” (6) William Ramsay discovered or codiscovered most of the other noble gases: helium, neon, krypton and xenon.\nHe was responsible for adding an entire new group to the periodic table. Radon was the only noble gas he didn’t discover.\nInteresting Facts about Argon\n- Lord Rayleigh said: “Argon must not be deemed rare. A large hall may easily contain a greater weight of it than a man can carry.” On a planetary scale, we can calculate that Earth’s atmosphere holds 65 trillion metric tons of argon. That’s more than 9 metric tons of argon per person on Earth.\n- Until 1957, argon’s chemical symbol was A. In 1957, IUPAC agreed that the symbol should change to Ar. Argon was not the only element whose symbol changed in 1957. IUPAC also changed mendelevium from Mv to Md.\n- Most people are familiar with carbon dating, which uses the decay of the radioactive carbon-14 isotope to find the ages of things that were once alive. Carbon-14′s half-life is about 5730 years and the technique is not useful for material more than about 60 thousand years old. Potassium-argon and argon-argon dating allow us to date rocks that are much older than this. Potassium-40 decays to argon-40 and calcium-40, with a half-life of 1.25 billion years. The ratio of potassium-40 to argon-40 trapped in rock can be used to determine how long it is since the rock has solidified. More recently, the ratio of argon-39 to argon-40 has been used in precision dating.\n- The vast majority of argon on Earth comes from the radioactive decay of potassium-40, producing stable argon-40. Over 99% of Earth’s argon is argon-40.\n- Away from Earth, argon-36 is the most abundant isotope, synthesized in the silicon burning phase of stars with a mass of about 11 or more Earth suns. During silicon burning, an alpha-particle adds to a silicon-32 nucleus to make sulfur-36, which can add another alpha-particle to become argon-36, some of which can become calcium-40, etc.\nAppearance and Characteristics\nArgon is considered to be non-toxic.\nArgon is a noble gas. It is colorless, odorless and extremely unreactive.\nIt is, however, not completely inert – photolysis of hydrogen fluoride in a solid argon matrix at 7.5 kelvin yields argon fluorohydride, HArF.\nUses of Argon\nAs a result of its unreactiveness, argon is used in light bulbs to protect the filament and to provide an unreactive atmosphere in the vicinity of welding.\nIt is also used in the semi-conductor industry to provide an inert atmosphere for silicon and germanium crystal growth.\nArgon is used in medical lasers, in ophthalmology for example to correct eye defects such as blood vessel leakage, retinal detachment, glaucoma and macular degeneration.\nAbundance and Isotopes\nAbundance earth’s crust: 3.5 parts per million by weight, 1.8 parts per million by moles\nAbundance solar system: 0.01 percent by weight, 3.3 parts per million by moles\nCost, pure: $0.5 per 100g\nCost, bulk: $ per 100g\nSource: Argon is produced when 40K present naturally in the earth’s crust undergoes radioactive decay to 40Ar. The argon makes its way into the atmosphere. Argon is produced commercially by fractional distillation of liquefied air with (for high purity argon) catalytic burning of left over traces of oxygen.\n1. Encyclopaedia Perthensis, or, Universal dictionary of the arts, Sciences, Literature, &c., 1816, vol 1, p231-232, John Brown.\n2. John H. Wolfenden, The Noble Gases and the Periodic Table: Telling it like it was., J. Chem. Educ., 1969, 46 (9), p569.\n3. Mary Elvira Weeks, The Discovery of the Elements. XVIII. The Inert Gases., J. Chem. Educ., 1932, 9 (12), p2065.\n4. Lord Rayleigh, On an Anomaly Encountered in Determinations of the Density of Nitrogen Gas., Proc. Roy. Soc. London, 1894, 55, p340.\n5. Vivi Ringnes, Origin of the Names of Chemical Elements, J. Chem. Educ., 1989, 66 (9), p731.\n6. Lord Rayleigh, The Density of Gases in the Air and the Discovery of Argon, Nobel Lecture, December 12, 1904. (pdf download.)\n7. Robert L. Kelly, David Hurst Thomas, Archaeology., Sixth Edition, 2012, Wadsworth, p137.\n8. Image by Deglr6328.\nCite this Page\nFor online linking, please copy and paste one of the following:\n<a href=""http://www.chemicool.com/elements/argon.html"">Argon Element Facts</a>\nTo cite this page in an academic document, please use the following MLA compliant citation:\n""Argon."" Chemicool Periodic Table. Chemicool.com. 15 Oct. 2012. Web. <http://www.chemicool.com/elements/argon.html>.']"	['<urn:uuid:c010ba5e-766b-4ab7-91ee-2d2540c60b7a>', '<urn:uuid:76d0945a-42a0-4300-b89a-0b4c184f4069>']	factoid	direct	verbose-and-natural	distant-from-document	comparison	novice	2025-05-13T01:50:22.828293	19	52	2869
22	soil types malaysia fertility differences	In a study conducted in Segamat, Johor, Malaysia, three soil series (Rengam, Durian and Padang Besar) were compared. The Rengam series contained higher total carbon and clay compared to Padang Besar and Durian series. The Soil Fertility Index (SFI) showed that Rengam soil's fertility status was significantly higher than the other two soil series, indicating it is more fertile.	['Comparing the Fertility of Soils under Khaya ivorensis Plantation and Regenerated Degraded Secondary Forests\nYetti Heryati, Arifin Abdu, Mohd Noor Mahat, Hazandy Abdul-Hamid, Shamshuddin Jusop, Nik Muhamad Majid, Ika Heriansyah, Leslie Ajang and Khairulmazmi Ahmad\nDOI : 10.3844/ajassp.2011.472.480\nAmerican Journal of Applied Sciences\nVolume 8, Issue 5\nProblem statement: It is widely accepted that conversion of natural forest to other land use types leads to deterioration of soil fertility and increased soil compaction which consequently become degraded secondary forests. Degraded secondary forest or forestland is indicated by low in soil fertility and organic matter due to imbalance input and output from original vegetation. Forest plantation through planting fast growing exotic species is usually implemented to curtail degradation of secondary forest or forestland and improve the soil fertility through organic matter accumulation. However, fundamental information on degraded forestland being converted to forest plantation using exotic species such as Khaya ivorensis is not available. The objectives of this study were: (1) to characterize the properties of three degraded soils under rehabilitation using K. ivorensis; and (2) to evaluate their fertility status by Soil Fertility Index (SFI) and Soil Evaluation Factor (SEF). Approach: This study was concentrated on three soil series (Rengam, Durian and Padang Besar) found under K. ivorensis plantation and at the adjacent secondary forest in Segamat, Johor, Malaysia. To characterize and evaluate the soil fertility status for each soil series, three plots (30 x 40 m) were randomly established on each soil series. Soils for each series were sampled at the depth of 0-10 cm (surface soil) and 20-30 cm (subsurface soil). They were randomly collected at six different points for each replicate. Soil analyses were carried out accordingly. Results: The soils both in planted and secondary forests were moderately acidic to slightly acidic with low content of exchangeable bases and available P but high in Al saturation. The Rengam series under K. ivorensis plantation contained higher total carbon and clay compared with those of Padang Besar and Durian series. Clay and total carbon contents were highly correlated with the Cation Exchange Capacity (CEC), indicating the potential of negative charge produced by the clay and organic playing an important role in supplying and holding plant nutrients. The SFI result revealed that soil fertility status of Rengam soil was significantly higher than the other two soil series. There was no significant difference observed for SEF. Based on SFI and SEF values, there were no significant differences of fertility status between the planted and secondary forests for both soil depths. Conclusion: This study revealed that Rengam soil is more fertile than the other two soils. Using SFI and SEF it can be concluded that fast growing exotic species of K. ivorensis has the potential to improve site productivity and soil fertility.\n© 2011 Yetti Heryati, Arifin Abdu, Mohd Noor Mahat, Hazandy Abdul-Hamid, Shamshuddin Jusop, Nik Muhamad Majid, Ika Heriansyah, Leslie Ajang and Khairulmazmi Ahmad. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.']	['<urn:uuid:821e7c75-5b82-447b-9bb6-4133b9971c78>']	open-ended	direct	short-search-query	distant-from-document	single-doc	novice	2025-05-13T01:50:22.828293	5	59	516
23	What were some of the major theatrical productions performed at the Theatre on the Balustrade in Prague during the 1960s, and who directed them?	At the Theatre on the Balustrade (Divadlo na zábradlí) in Prague, notable productions included Ubu Roi by Alfred Jarry directed by Jan Grossman in 1964, and Waiting for Godot by Samuel Beckett directed by Václav Hudeček in 1964.	['Standard delivery 3 to 7 days\nPublication date : 2021/11/25\n96 pages, 210 x 250 mm\n58 black and white photographs\nSoftcover with flaps\nText by Tomáš Pospěch\nDesign concept by Aleš Najbrt and Josef Koudelka\nDesign : Studio Najbrt, Prague.\nLanguage : French and English\n“Moving among the actors on set, I was able to take the same scene, multiple times, but differently. It taught me how to get the most out of a given situation, and I have continued to apply this method to my work.”\ndelpire & co is pleased to publish Koudelka Theater, a presentation of 58 newly edited photographs by the photographer, accompanied by a text by photography historian Tomáš Pospěch.\nIn his own words, Josef Koudelka was not particularly interested in theatre in his youth. When he arrived in Prague from his Moravian village in the late 1950s, his focus was on his studies. His interests were airplanes, folk music, and photography, which he practiced as an amateur. A classmate recommended that he meet his uncle, who worked in the editorial staff of the magazine Divadlo (Theatre), then looking for a photographer. It was in this context that Josef Koudelka, soon to become an aeronautical engineer by profession, became a theatre photographer.\nIn the 1960s, Prague theatres were one of the rare places in Soviet Czechoslovakia where relative freedom of expression continued. The playwright and essayist Vaclav Havel, future President of the Czech and Slovak Federal Republic (1989-1992) was particularly active there, notably at the Theatre on the Balustrade (Divadlo na zábradlí). Known for its presentation of the Theatre of the Absurd, where directors such as Jan Grossman interpreted Ubu Roi, by Alfred Jarry (1964), Waiting for Godot, by Samuel Beckett, and Intermezzo by Jean Giraudoux. Following the Prague Spring (1968), these stages were forced to close, and their animators dissented or left the country.\nThere is a rich correlation of levels between Koudelka’s theatrical photography and his later way of conceiving his images as a reflection on the theatre of the world.\nEverything that we know of his practice of the image can be found from his beginnings in the work he did in Prague in the 1960s: his attention to graphic composition, his ease of working in tight spaces among people in movement and in difficult lighting situations, his obsession with returning again and again to the same motif, the same gestures and rituals.\nIt was during the 1960s that he also documented the lives of the gypsies. These two series, created in parallel and over the long term, have many links.\n“With the Gypsies, it was theatre too. The difference was that the play had not been written and there was no director – there were only actors. It was reality, it was life. It was a different kind of theatre – it was the theatre of life. I didn’t need to do anything with it. Everything was there. All I had to know was how to react.”\nQuote taken from Otomar Krejča, ‘Divadlo, Zkušenost z představení’, in Josef Koudelka, Prague: Torst, 2006.\nKoudelka Theatre includes photographs of important productions in two major theaters, the Theatre on the Balustrade and the Theatre Behind the Gate, as well as images made for the covers of Divadlo (Theatre).\nThe design of the book is inspired by the work of the leading graphic designer and scenographer in the theatrical community in Prague at the time, Libor Fára (1925-1988), husband of Anna Fárová, curator and historian of photography who helped Koudelka at the start of his career.\nThe typography was created by Studio Najbrt in 2020, from an old typewriter of the time evoking Samizdats, clandestine works banned by Soviet censorship.\n*Interview given, Bryn Cambell, World Photography, London, 1981.\nQuote taken from Josef Koudelka, L’Epreuve Totalitaire, by Jean-Pierre Montier, Delpire Éditeur, Paris, 2004.\nPhotographs : © 2021 Josef Koudelka / Magnum Photos\nFrom top to bottom : Ubu Roi (Král Ubu), by Alfred Jarry, directed by Jan Grossman, Divadlo Na zábradlí (Theatre on the Balustrade), Prague, 1964.\nIntermezzo, by Jean Giraudoux, directed by Otomar Krejča, Divadlo za branou (Theatre Behind the Gate), Prague, 1967.\nWaiting for Godot – En attendant Godot (Čekání na Godota), by Samuel Beckett, directed by Václav Hudeček, Divadlo Na zábradlí (Theatre on the Balustrade), Prague, 1964.\nMasks from Ostend (Maškary z Ostende), by Michel de Ghelderode, directed by Otomar Krejča, Divadlo za branou (Theatre Behind the Gate), Prague, 1965.\nAn Hour of Love (Hodina lásky), by Josef Topol. Directed by Otomar Krejča, Divadlo za branou (Theatre Behind the Gate), Prague, 1968.']	['<urn:uuid:0761cda7-1761-4742-8c56-c07363fda277>']	factoid	direct	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-13T01:50:22.828293	24	38	760
24	What are the economic implications of forest conservation versus forest conversion in Indonesia, and how do these relate to both carbon markets and ecosystem services?	Forest conservation in Indonesia presents compelling economic opportunities through both carbon markets and ecosystem services. Research shows that a carbon price of just $16 per ton of CO2 would make forest conservation more profitable than conversion, and in peat-soil forests, this threshold drops to only $6 per ton. Additionally, ecosystem services from standing forests account for 21% of Indonesia's GDP and 75% of rural poor GDP, with 99 million Indonesians depending on these services for their livelihoods. While forest conversion has been pursued for economic development, it ignores multiple benefits of forests including clean water, local climate regulation, and flood prevention.	"['""Saving orangutan habitats and other forest lands has the potential to make a major contribution towards reducing global warming.""\nErik Meijaard, former senior ecologist for The Nature Conservancy in Indonesia\nBy Erik Meijaard\nOrangutans are known worldwide as “the people of the forest” and the face of Indonesian conservation. The orangutans of Borneo and Sumatra are uniquely beautiful, undeniably compelling…and incredibly endangered. These precious creatures should be well protected as both a cultural icon and an endangered species.\nBut not nearly enough is being done to save orangutans. The time to act is now, or this precious animal will be lost forever. The recent discussions on global climate change have provided a great opportunity to effectively protect orangutan habitats — using the mechanism of carbon markets to make conserving those habitats financially attractive.\nWhy Carbon Markets Make Forest Conservation Lucrative\nHow are orangutans and carbon markets linked? Consider these two facts:\n- Annual forest loss in Indonesia amounts to some 1.8 million hectares — helping to make Indonesia one of the biggest CO2 emitters in the world.\n- And forest loss in Indonesia over the last three decades has directly or indirectly killed some 3,000 orangutans every year.\nMuch of the forest conversion has happened under the guise of economic development. This development has ignored the muiltifaceted benefits of forests: how they provided many local communities with livelihoods as well as clean water, local climate regulation, and flood and erosion prevention.\nHowever, those benefits did not clearly translate into financial gains for the state, local governments and business involved in Indonesian forest conversion. But the lack of financial incentive to protect forests might now change — because it will now be possible to make protection and sustainable management of forests pay for itself through carbon markets:\n- A carbon price of $16 per ton of CO2 would make forest conversion less lucrative than forest conservation, according to research by The Nature Conservancy and other groups.\n- And for forests growing in Indonesia\'s extensive peat soils — which contain large amounts of carbon — a carbon price of only $6/ton would make conservation economically competitive with even the most profitable agro-industrial developments.\nMost of Kalimantan’s remaining orangutans occur in these peat-soil forests. And whereas sustainable agriculture on drained peat soils is a myth, forest conservation can provide economic benefits for a very long time.\nHow Orangutan Conservation Could Help\nCurrent conversion plans for Indonesia\'s peat swamps as well as its mineral-soil forests pose a grave threat to orangutans and the climate.\nThis is where the orangutan comes into the picture. By protecting orangutans, the Indonesian government would make a major contribution towards reducing global carbon emissions.\nAnd if payments for avoided deforestation become an official mechanism in global climate agreements, then carbon buyers will likely compensate Indonesia for its forest protection. Protecting orangutans will then lead to increased Indonesian economic development.\nSuch a triple-win situation is not a dream. With some political will, it can soon be reality.\nPrevious commitments, even at a presidential level under Soeharto, were not backed by real action steps and supporting legislation.\nBut now the Indonesian government is taking orangutan conservation seriously: In December, the president of Indonesia launched the Indonesian Orangutan Conservation Action Plan.\nThe plan is the first road map in 30 years of orangutan conservation efforts that works towards stopping the continuous loss of orangutan habitat and carbon-rich forests. The plan is not just words on paper: It clearly defines the roles and responsibilities in orangutan conservation for both government and non-governmental organizations.\nThe Conservancy has pledged $1 million to this effort. With this plan, the Indonesian government is taking the in situ and ex situ management of one of their protected species seriously.\nA Global Canary in the Coal Mine\nAs a globally recognizable species, the orangutan is a compelling icon for sound stewardship of Earth’s resources. With respect to climate change, the fate of the orangutan in tropical forests — as with that of the polar bear in the Arctic — is a global ""canary in the coal mine.""\nBut unlike polar bears, which can only wait and hope that somehow humanity will stop their icy hunting grounds from disappearing, orangutans are a living symbol of a direct solution.\nPolar bears represent the problem; orangutans are the symbol of what we can do about it. Saving orangutan habitats and other forest lands has the potential to make a major contribution towards reducing global warming.', ""Indonesia’s rainforests are one of earth’s most biologically and culturally rich landscapes. The world’s largest archipelago, Indonesia consists of almost 18,000 islands spanning between the Pacific and Indian Oceans. Containing the largest expanse of rainforest in all of Asia, it is home to hundreds of distinct Indigenous languages and over 3,000 animal species including Sumatran tigers, pygmy elephants, rhinoceros and orangutans.\nThis photo is from an investigative report from Rainforest Action Network that found wood fiber linked to the clearing and conversion of Indonesia’s rainforests in the paper of some of America’s favorite children’s books. Photo: David Gilbert\nAs recently as the 1960s, about 80 percent of Indonesia was forested. Since then, however, demand for commodities like pulp, paper, plywood and palm oil has combined with corruption, political croneyism, uncertainty about land rights and poorly enforced policies to create the conditions for a massive land and resource grab by large corporate interests. This profit driven resource rush is moving across the island chain, clear cutting rainforests, destroying critical habitat for endangered species, and sowing social conflict with communities that depend on the forests for their livelihoods.\nSadly, Indonesia has one of the highest deforestation rates in the world, and just under half of the country’s original forest cover now remains. Although estimates vary widely, conservative studies suggest more than a million hectares (2.4 million acres) of Indonesian rainforest is cleared and lost each year, with about 70% occurring in forests on mineral soils and 30% on carbon-rich peatland forests.\nIndonesia has skyrocketing environmental and social problems resulting from all of this forest clearing. Too many unique species like the Javan tiger are already extinct and many others, like the orangutan, are gravely threatened. Burning to clear rainforests is widespread, emitting a thick haze of smoke that shuts down regional air traffic and provokes public health alerts in urban areas hundreds of miles away. Pesticides and factory run-off are polluting the waterways and local soils. Growing corporate control of land is responsible for serious human rights abuses and persistent conflicts between companies and local communities.\nA legally questionable logging corridor built by Asia Pulp and Paper inside the traditional home of the Orang Rimba, one of Indonesia's last nomadic cultures. Jambi Province, Sumatra, Indonesia. Photo: David Gilbert/RAN\nEconomic Value of Rainforests\nContinued clearing of natural forests and drainage of peatland is creating serious economic losses as well. Indonesia’s standing forests provide innumerable services, most of which have been poorly valued economically and are only just starting to be appreciated.\nAccording to the authoritative Economics of Ecosystems and Biodiversity initiative, 99 million Indonesians are dependent on ecosystem services for their livelihoods, and they account for 21% of Indonesia’s GDP. Ecosystem services account for 75% of the GDP of Indonesia’s rural poor. Indigenous people have sustained and been sustained by these forests for many centuries. Now they are bearing witness to their destruction in less than a generation.\nRainforest Destruction and Climate Change\nThe scale of destruction of Indonesia’s rainforests is so large that it is now having significant impacts on the global climate. Rainforest and peatland ecosystems store billions of tons of carbon, and their demolition releases huge emissions into the atmosphere. Indonesia is now the world’s third largest emitter of greenhouse gasses after the U.S. and China, with 85% of its emissions profile coming from rainforest and peatland degradation and loss. Five per cent of all global greenhouse gas emissions are now coming from Indonesia, which is more than the combined emissions from driving all the millions of cars, trucks, trains, and buses in the U.S. each year combined.\nRecent clear cutting and burning inside Asia Pulp and Paper's PT Wira Karya Sakit pulpwood forest license. Jambi Province, Sumatra, Indonesia. Photo: David Gilbert/RAN\nThe Indonesian government and industry have plans to convert tens of millions of acres of rainforest to palm oil and pulp plantations over the next decade, making Indonesia perhaps the most critical region to challenge tropical forest destruction in the world today.\nRainforest Action Network is working with Indonesian partners to change the policies and practices of the agribusiness and pulp and paper sectors to end their contribution to this destruction. RAN works to help create conditions where community rights and land tenure are respected and upheld, and to support implementation of low carbon, ecologically sustainable and equitable development.""]"	['<urn:uuid:5bbf1cf7-c292-4d48-a87d-6ea23ac3736d>', '<urn:uuid:6f1e57eb-3ea6-4900-85e2-7e649edefc76>']	open-ended	direct	verbose-and-natural	similar-to-document	multi-aspect	expert	2025-05-13T01:50:22.828293	25	101	1464
25	airplane ice storm signs dangers	Ice formation on aircraft can be difficult to detect visually but poses severe dangers. In the 1991 incident, pilots only observed a thin line of rime ice on wing edges and 3/8 inch on the windscreen wiper, yet experienced catastrophic effects including severe vibration, loss of altitude control, and extreme rolling oscillations with bank angles up to 68 degrees. According to technical analysis, ice accumulation can be 'gentle and insidious,' occurring without triggering stall warnings and well above normal stall speeds. The most dangerous form is clear or glaze ice, which is often the hardest to detect visually. Warning signs include vibration, airspeed reduction, and decreased climb rate, though these symptoms can be masked when using autopilot, making the situation even more dangerous.	"[""ATP, en-route, Oxford UK, 1991\nATP, en-route, Oxford UK, 1991\nOn 11 August 1991, an British Aerospace ATP, during climb to flight level (FL) 160 in icing conditions, experienced a significant degradation of performance due to propeller icing accompanied by severe vibration that rendered the electronic flight instruments partially unreadable. As the aircraft descended below cloud, control was regained and the flight continued uneventfully.\nOn 11 August 1991, a British Aerospace ATP being operated by British Midland Airways (BMA) on a scheduled passenger flight from East Midlands to Jersey, Channel Islands and climbing to cleared level FL160 in day IMC was unable to maintain altitude and as this level was approached and the flight crew temporarily lost control with uncontrollable roll oscillation and a high rate of descent leading to a loss of altitude of 3000 feet. A PAN was declared to ATC but as the aircraft descended below cloud, control was regained and the flight continued without further event. None of the 63 occupants were injured and the aircraft was undamaged.\nThis is an extract from the Report (4/92) the serious incident investigation published by the Air Accidents Investigation Branch (AAIB) UK on 16 September 1992:\nThe commander set the propeller revolutions per minute (rpm) to 85% after take-off and to 82% on passing FL80 in the climb to the assigned level of FL160. He controlled the ITT [intermediate turbine temperature] to a maximum of 720°C throughout the climb. The aircraft entered cloud just below FL130 at 160 kts and a rate of climb around 500 ft/min. […] when the aircraft was at approximately FL150, over a two minute period, the indicated airspeed (IAS) reduced to 142kt and rate of climb fell at times to zero. During the period that the aircraft was in cloud the crew observed sleet and rain. At FL154 the commander requested Air Traffic Control (ATC) for reduction in his cleared cruise flight level to FL140 but the controller was unable to approve the lower level immediately because it had been allocated to another aircraft. In the event the maximum level achieved by the Advanced Turbo Prop (ATP) was FL156.\nThe engine and propeller ice protection systems had remained switched on from take-off and both pilots had been looking for signs of airframe ice, in order to determine if operation of the airframe de-icing boots was necessary. The only indication was a thin line of what they described as rime ice on the leading edges of the wings and three eights of an inch of rime ice on the windscreen wiper arm. The outside air temperature (OAT) was between -2°C and -5°C and the total air temperature (TAT) was calculated to have fallen to -2°C. The aircraft was being flown by autopilot in the heading mode with the attitude being controlled by the autopilot pitch wheel.\n[…] When the aircraft was at FL156, it began to experience vibration which rapidly increased in severity. The vibration was thought by the cabin attendants to be more severe in the rear of the aircraft than at the front. Both pilots had experienced propeller icing and associated vibration on an ATP before but on this occasion they thought it to be more extreme. The commander said that while the severe vibration lasted, the upper half of the attitude display on the electronic Primary Flight Display (PFD) showed intermittent blank bands and he was unable to read the alphanumeric characters on the Electronic Flight Instrument System (EFIS) displays.\nShortly after the onset of the vibration the left wing dropped and the aircraft began to descend. The aircraft initially pitched down approximately 15° and began a rolling oscillation. The commander said that at the point of initial wing drop he disengaged the autopilot and flew the aircraft manually. He felt that the aircraft was slow to respond to aileron control inputs and large bank angles were reached, particularly to the left, where a single peak of 68° of bank was recorded. He described the aircraft as wallowing with light aileron control forces.\nDuring the period of roll oscillation and rapid descent the first officer transmitted a “Pan” call and altered the transponder to emergency code of 7700. He also switched the airframe de-icing to ON.\n[…] The crew reported that at no time during the incident were they aware of a warning from the pre-stall warning (PSW) system.\nFull control of the aircraft was regained at FL120. At this altitude, and clear of icing conditions, the flight continued uneventfully.\nThe characteristics of the stall are described in the report. They are derived from data retrieved from FDR and sent for additional assessment. The following assessment on the nature of the stall is made by the Defence Research Agency (DRA) and is included in the report:\n“At approximately 250 seconds the aircraft entered the stall. However, this stall was gentle and insidious. […] it occurred without triggering the stall warning system and well above the normal stall speed. The aircraft was under autopilot control which further masked its effects. Perhaps the only real clue was the severe vibration (presumably post-stall buffet) which was experienced throughout the duration of the stall, but which the crew attributed to propeller icing. Overall it is not surprising that the crew did not recognise the stall’s abnormally benign longitudinal characteristics”.\nThe Report identifies the following factors as causes of the incident:\n- The rapid accumulation of glaze ice, which was not evident to the crew, but which produced significant aerodynamic degradation.\n- The difficulty of assessing visually the thickness of ice on the wing leading edges from the flight deck.\n- The BMA standard procedure to use a maximum ITT of 720°C in the climb discouraged the commander from applying power to counteract the loss of performance.\n- Use of autopilot in the pitch mode during climb which hampered recovery from the subsequent loss of control.\n- The propeller vibration which disguised the onset of the stall.\nThe Report's 14 Safety Recommendations, beginning on page 41 of the Report, also address institutional and organisational issues (see Further Reading).\n- Ice Formation on Aircraft,\n- Aircraft and In Flight Icing Risks,\n- Accident and Serious Incident Reports: WX: a selection of accident and serious incidents in which Weather (WX) was a factor.\n- AT73, en route, Roselawn IN USA, 1994\n- AT43, en-route, Folgefonna Norway, 2005 (WX LOC)\n- DH8D, en-route, South West of Glasgow UK, 2006 (LOC HF)\n- SH36, vicinity East Midlands UK, 1986 (WX LOC)\nFor further information see the serious incident report published by AAIB UK."", ""If you wish to contribute or participate in the discussions about articles you are invited to join SKYbrary as a registered user\nIce Formation on Aircraft\nThis article aims to address the basics of ice formation on aircraft and in their engine air inlets. It does not consider the formation of frost which is created by sublimation, the process by which water vapour freezes directly onto sub zero surfaces. With this exception, the formation of ice attached to the external surface of an aircraft or to the surfaces within its engine air intakes, requires that liquid water drops impact the surface involved. Usually, that moisture must be supercooled, that is it must be in liquid form below 0°C273.15 K\n491.67 °R. There are a couple of specific variations in this general scenario which will be considered later:\n- issues relating to the difference between the temperature of the aircraft skin and the temperature of the air through which it is, has been or will be passing, especially during climb and descent and in the temperature range +/-10 degrees Celsius.\n- issues arising from the temperature and/or pressure difference between the ambient air and air within engine air inlets, most often reductions in air pressure or increases in air temperature.\nIce from Supercooled Moisture\nIce which accretes on the external parts of an aircraft is most often the result of the impact of supercooled water droplets of various sizes on that aircraft. This may happen within cloud or when flying through precipitation. The reason why water droplets do not all freeze as soon as the ambient temperature falls below 0°C273.15 K\n491.67 °R is the release of latent heat as water changes state to ice. So much latent heat is released that the change of state is slowed down so that it takes place progressively as temperature continues to fall. This continues until, by about -20°C253.15 K\n455.67 °R, most of the by now supercooled water has turned to ice. Ice grains which have already fully formed and are dry when they impact an aircraft do not adhere but simply bounce off. Therefore, the relative severity of ice accretion can be expected to progressively decrease as ambient temperature reduces below 0°C273.15 K\n491.67 °R so that little, if any, risk of accretion remains below -20°C253.15 K\n455.67 °R. Two factors are important in respect of supercooled water droplets:\n- the extent of their presence, which will affect the rate of any ice accretion; and\n- their size, which will affect the severity of that accretion by adversely influencing its rate.\nBoth the quantity and, perhaps unsurprisingly, the droplet sizes of supercooled water in cloud are greatest at temperatures just below 0°C273.15 K\n491.67 °R and both decrease as temperature falls. The size of the supercooled water droplets is very important in respect of the potential to induce ice accretion. Larger droplets have greater inertia and are less influenced by the airflow around the aircraft than smaller droplets so they will impinge on more of the aircraft surface than smaller droplets. This is especially the case in respect of the in-flight air flow around the leading edge of wings and empennage. It is also the larger droplets which produce clear or glaze ice which is well recognized as the ice form of most concern and is often also the most difficult to detect visually.\nClouds and Supercooled Moisture\nThe majority of supercooled droplets in clouds are between 1 micron (0.001mm) and 50 microns (0.05 mm) in diameter. [For comparison, the thickness of the average human hair is approximately 100 microns]. Layer (stratiform) clouds typically contain average droplet diameters of up to 40 microns. Vertically developed (cumuliform) clouds of moderate scale typically have average droplet diameters of up to 50 microns (0.05mm) but large Cumulonimbus clouds often contain much more liquid water, including large quantities in droplets with diameters up to and beyond 100 microns (0.1mm).\nFreezing Rain and Freezing Drizzle\nPrecipitation droplets that are clear of cloud are much larger than those within cloud and, if they are supercooled, they are described as creating Freezing Drizzle where droplets have a diameter of between 50 and 500 microns (0.05mm and 0.5mm) and Freezing Rain where the droplets exceed 500 microns (0.5mm) in diameter. Freezing Rain often has much larger droplets of 2mm diameter or more, although if they get much beyond 6mm in diameter, they will tend to break up.\nFreezing rain below cloud forms when rain droplets are supercooled by passage through a layer of air which has a sub-zero temperature. Since air temperatures normally increase as altitude reduces, freezing rain implies the existence of an air temperature inversion. Such conditions can occur below an advancing warm front or a warm occlusion where a relatively warm air mass is overrunning colder air. The existence of freezing rain normally means that there will be warmer air (above 0°C273.15 K\n491.67 °R) above.\nThe smaller supercooled droplets of freezing drizzle can also form in this way but it is generally considered that they more commonly arise by a different process called the collision-coalescence process. When, through condensation, some droplets in a cloud grow to approximately 30 micrometers in diameter, they begin to settle, falling fast enough so that they collide with some smaller droplets. If the droplets then coalesce, a larger droplet is produced and this now has an even better chance of ‘capturing’ smaller droplets. Under favorable conditions, this process can produce drizzle-size drops in a supercooled cloud, usually near the top, where the largest droplets generally are found in any cloud. Data capture has varied but some studies have reported that freezing drizzle in non-convective clouds forms more than 80 percent of the time by the collision-coalescence process. So, importantly, when in freezing drizzle, it cannot be assumed that warmer air (above 0°C273.15 K\n491.67 °R) will exist above it.\nThe term ‘icing severity’ is essentially about the rate at which significant ice accretion occurs. The descriptions of supercooled water droplets so far have been in terms of their size. These comparative diameters are important - typical drizzle droplets have a diameter 10 times that of typical cloud droplets and typical rain droplets have a diameter 100 times that of typical cloud droplets. Size as described by diameter is, though, not what matters most in terms of the potential for ice accretion through impact. What really makes the difference is the volume (or mass) of water contained in a droplet since this is what controls the amount of water which will impact the aircraft and also how far aft of the airflow stagnation point ahead of a leading edge surface that droplets will strike the aircraft. This latter point is of considerable importance since large droplets may impact far beyond the leading edges in areas which are not anti iced or de iced and may also turn to ice as they are flowing aft in contact with the surface initially hit.\nIt is important to note that the volume of a droplet is not proportional to its diameter but to approximately the cube of half the diameter (i.e. the radius). Therefore, if 20 microns (0.02 mm) is taken as a typical diameter for a cloud droplet and 2000 micrometres (2mm) is taken as the typical diameter of a freezing rain droplet, then although the diameters of these droplets differ by a factor of only 100, their volume, and therefore their mass, differ by a factor which is of the order of 1,000,000.\nIt is this vastly greater mass of supercooled water droplets in freezing precipitation compared to those in cloud, even cumulonimbus cloud, which precludes any aircraft undertaking a significant period of sustained flight - and in most cases any flight - in freezing precipitation clear of cloud.\nDifferences between ambient and aircraft skin temperature\nThere are a number of factors which vary the propensity for ice to accrete on an aircraft:\n- When any aircraft moves through the air, the resultant kinetic hearting due to both compression at points of air obstruction and friction at surfaces of air passage raises the aircraft skin temperature above that of the ambient air in the vicinity. The extent to which this occurs, and therefore the extent of its significance to ice formation, has been calculated to be directly proportional to the square of 1/100 x the true airspeed in knots. Pilots will be aware of the consequent difference between SAT and TAT which can be observed to increase with speed since the effect of TAS increase is greater than the opposite effect of air density decrease.\n- If an aircraft is climbing into colder air and frozen or semi frozen deposits are resting on the upper surfaces of the wings or horizontal tailplane surfaces or in related flight control hinge gaps, the possibility exists that these deposits might freeze fully and attach to the airframe in situ. However, this will usually only be a significant problem if the climb is made concurrently into conditions likely to produce independently significant ice accretion.\n- When an aircraft is descending from high altitude, the increase in the structure surface temperature as the ambient air warms is likely to lag behind the ambient air temperature increase, especially in the case of wings used as fuel tanks which still contain a significant quantity of fuel. This will particularly apply where fuel is ‘tankered’ for use on the next flight sector in preference to uplifting at the initial destination. The significance of fuel is its tendency for temperature to recover from prior cold soak more slowly than the structure containing it. One particular effect of this is the formation of ‘fuel ice’ on the lower surface of a wing because this is where the cold fuel is in direct contact with the wing structure. Such clear ice is often still present during the subsequent turnaround even when OAT is several degrees above freezing.\nEngine Air Inlet Icing\nAll aircraft certificated for flight in icing conditions are fitted with anti-icing systems. These prevent air intake lip and guide vane ice formation by use of electrically heated mats, circulated hot engine oil or bleed air extracted from the engine. However, further inside an air inlet, ice can form in unprotected areas even when an aircraft is not flying in icing conditions as presently defined for engine certification purposes. There are two such circumstances: the cooling of moist air above freezing temperature by pressure reduction in piston engines; and the melting of ice crystals which are warmed after entering turbine engines.\nIn the first case, moist air entering a piston engine intake at a temperature above 0°C273.15 K\n491.67 °R is then accelerated by a suction effect through a reduced channel. This ‘venturi’ effect reduces its temperature causing the moisture load to condense out and be precipitated on the walls of the air channel as ice. See Piston Engine Induction Icing for more detail. This article also describes two other types of induction icing which occur in piston engines.\nIn the second case, high densities of very small ice crystals in very cold, high altitude air are ingested into high bypass gas turbines. They then either temporarily freeze and detach as larger pieces of ice causing engine airflow disruption, or cause mechanical damage either as pieces of ice or via discrete throughputs of liquid water. For further information, refer to High Level Ice Crystal Icing: Effects on Engines.\nThere are no definitions for absolute icing severity in aviation forecasting. However, the relative qualifications light, moderate and severe are generally used (in respect of airframe icing risk only) in a way which has at least reasonable consistency regionally in the context of the type of forecast in which they are used. It is understood by most forecasters that a term like ‘light icing’ will be interpreted rather differently by a commercial transport flight crew and a private pilot wondering whether they are likely to be able to undertake their planned flight clear of all icing conditions. As a consequence, low level icing forecasts are usually presented in such a way that they are specifically accessible to pilots of light aircraft vulnerable to the effects of any icing. However, the forecasts provided primarily for commercial air transport will use moderate and severe icing in terms which reflect their likely significance to aircraft which are certificated for routine flight in ‘icing conditions’ because they are equipped with appropriate ice protection systems. This use of higher level forecast presentations by general aviation can produce misunderstandings about the icing conditions that might be expected, and sometimes lead to inappropriate flight planning. The point is that the relative forecasts of icing severity cannot and do not take account of their user and the aircraft they are flying, so the interpretation of forecasts is as much a matter of judgement as monitoring the apparent icing reality once in the air.\nWith all the above caveats, a brief look at the usual ‘descriptions’ and ‘definitions’ of icing conditions used by forecasters may still be helpful. The descriptions all assume that an aircraft is certificated for “flight in icing conditions”.\n- Light Icing is often described as conditions such that ‘no change of course or altitude is necessary and no loss of airspeed occurs. It has been more rigorously defined by some as a rate of ice accretion per hour on outer wing of between 0.25 inch and 1 inch (0.6 to 2.5 cm).\n- Moderate Icing has been typically described as ice accretion which continues to increase but not at a rate sufficient to affect the safety of the flight unless it continues for an extended period of time, but air speed may be lost. A definition based upon an ice accretion rate per hour on the outer wing of 1 to 3 inches (2.5 to 7.5 cm)\n- Severe Icing has been variously described as ice accretion:\n- in which either the icing rate or ice accumulation exceed the tolerance of the aircraft;\n- which continues to build and begins to seriously affect the performance and manoeuvrability of an aircraft;\n- at a rate such that ice protection systems fail to remove the accumulation of ice and ice accumulates in locations not normally prone to icing;\n- such that an immediate exit from the condition is necessary to retain full control of the aircraft.\nIt is generally accepted that, although aircraft certification for flight in icing conditions rarely includes any stated restrictions, no aircraft is approved for flight in severe icing conditions, and that severe icing conditions may occur at any ice accumulation rate.\nIn North America, the terms clear, rime or mixed are more often used in forecast material than elsewhere and are both intended and taken as a proxy for droplet size regardless of other factors such as temperature and liquid water content. In this use, a forecast of rime icing indicates smaller drop sizes and a forecast of mixed or clear icing indicates larger drop sizes but with only a vague and undefined boundary between the two.\nFinally, a “clean aircraft” at rotation is an essential requirement for flight in or into icing conditions for those aircraft so approved. It is achieved by the use of appropriate ground de-icing or anti-icing fluids which have a sufficient holdover time for the prevailing conditions. Anti Icing is nearly always achieved by thickened fluids which adhere to the airframe and then progressively shear off during the take off roll so that they have all been shed by 100KIAS. There is no approved fluid protection against freezing rain or freezing drizzle conditions and so departure in them is generally not possible.\n- In-Flight Icing\n- Icing - Collection Efficiency\n- Aircraft and In Flight Icing Risks\n- Piston Engine Induction Icing\n- Freezing Rain\n- Aircraft Ground De/Anti Icing\n- Ice Protection Systems\n- High Level Ice Crystal Icing: Effects on Engines\n- Extract from Transport Canada Aviation Safety Letter 1/2007: The Adverse Aerodynamic Effects of Inflight Icing on Airplane Operation\n- Aircraft Icing Handbook, Version 1 by Civil Aviation Authority of New Zealand\n- Appendix C 'Icing Conditions' to CFR 14 Part 25, FAA, 2014""]"	['<urn:uuid:f6bfc5dc-147f-430f-a98b-353b8eb9d5c8>', '<urn:uuid:feb0abc0-d768-40b0-ab94-269ded9eeac1>']	open-ended	with-premise	short-search-query	distant-from-document	multi-aspect	novice	2025-05-13T01:50:22.828293	5	123	3787
26	compare apollo 9 david scott and pavel belyayev space missions differences manual control procedures	While both were accomplished space pioneers, their manual control experiences differed significantly. David Scott served as Command Service Module pilot on Apollo 9, performing complex docking maneuvers in Low Earth Orbit. In contrast, Pavel Belyayev had to perform a complete manual re-entry during the Voskhod 2 mission when the automatic re-entry system failed, requiring him to use the Vzor navigation device while lying across the seats to orient the capsule. Belyayev was notably the first cosmonaut to bring his mission back to Earth using manual control, as he later disclosed to Scott during their meeting at a Paris air show in 1967.	"['Today is the 50th anniversary (50 years and one day for those of us on this side of the dateline) of the Apollo 9 mission and it’s probably the one that will have almost no fanfare, which is a shame because it was absolutely critical to the success of Apollo 11. The mission achieved a number of firsts in the Apollo programme, including the first test of the Lunar Module (LM) in space, the first independent life support system on a space suit test and the first flight of the Command Service Module (CSM). It was a complex mission conducted in Low Earth Orbit (LEO) over a ten day period that started on the 3 March 1969. A few months ago we wrote an article on the Apollo 8 mission that was also ground breaking as it was the first time humans orbited the Moon. Apollo 9, though it didn’t test the transit to the Moon, it did test the complex docking and and other flight manoeuvres required for the actual Moon landing.\nThe crew was commanded by James McDivitt, who was a serving United States Air Force officer at the time of the Apollo missions. He had seen service in the Korean War and flew 145 combat mission. He joined the space programme in 1962 as part of the Astronaut Group 2 cohort. McDivitt took part in the Gemini programme and retired from the USAF in 1972 in the rank of Brigadier-General (Air Commodore equivalent). One of his crew members was another USAF officer, David Scott, who later went on to command Apollo 15 and became the seventh person to walk on the Moon. Scott flew into space for the first time on Gemini 8 with Neil Armstrong as his crew mate. For Apollo 9 he was the Command Service Module pilot. He retired from the USAF in 1977 in the rank of Colonel (Group Captain equivalent). The Lunar Module pilot was Russell (Rusty) Schweickart. Unlike McDivitt and Scott he was not a serving USAF officer at the time of Apollo 9 but had spent 7 years flying jet aircraft with the USAF and Air National Guard prior to joining NASA and being selected for Astronaut Group 3. Apollo 9 was the only spaceflight for Schweickart who went on to be on the backup crews for Apollo and later Skylab missions.\nThe Apollo 9 mission was the first test of the entire assembly that would eventually go to the Moon in Apollo 11. This included the Saturn V rocket used successfully for the Apollo 8 mission. The rest of the assembly included the Command Service Module and the Lunar Module. Spider was the name given to the LM and Gumdrop was the name given to the CSM. One of the test flights included flying the LM nearly 180km from the CSM before turning around and returning for a docking manoeuvre. This was the first time that a spacecraft, that wasn’t intended to return to the Earth’s surface, was crewed. This was also the first mission where the spacesuit was tested that would be used by astronauts on the Moon. This required a suit that operated independently of the spacecraft so the crew could do extended operations. This meant the spacesuit had to have all of the life-support for the astronaut contained in the suit.\nThe mission was a complete success and paved the way for the Apollo 10 and 11 missions. Well done Apollo 9 crew and all of the thousands of people who supported the mission!', 'Pavel Belyayev in 1965\n26 June 1925|\nChelishchevo, Soviet Union\n|Died||10 January 1970\nMoscow, Soviet Union\nTime in space\n|1d 02h 02m|\n|Selection||Air Force Group 1|\nPavel Ivanovich Belyayev (Russian: Павел Иванович Беляев; 26 June 1925 – 10 January 1970), was a Soviet fighter pilot with extensive experience in piloting different types of aircraft. He was the first commander of the cosmonaut corps and the cosmonaut who commanded the historic Voskhod 2 mission which saw the first man walk in space in 1965.\nPavel Belyayev was one of 6 children and was known as Pasha to his family and friends. He was born on 26 June 1925, in Chelishchevo, in what is now Babushkinsky District, Vologda Oblast. In 1932 his family moved to the nearby village of Minkovo. His father was a physician\'s assistant and his mother worked on a collective farm. Belyayev began his schooling at the age of 7 in 1932. Physics and geography were his favourite subjects. As a boy he enjoyed playing hockey and hunting. Just before his 13th birthday the family moved to Kamensk-Uralsky region. He continued his education at the Gorkogo secondary school.\nIn 1942, Belyayev took on temporary work as a turner in a factory and later became a check operator in the Sinarsk pipes factory in support of the war effort. He applied to the special air force school in Sverdlovsk but failed to gain admission. He then attempted to join a fighting ski unit as a volunteer, but was again rejected because he was too young. In 1943, just prior to turning 18, he was called up. He then entered the 3rd Sarapul School where he began training as a naval pilot. He graduated in 1944 and then moved to the Stalin Naval Air School.\nAir Force career\nBelyayev graduated as a military pilot in 1945 with the rank of junior lieutenant. The war had ended in the west, so Belyayev was sent to defend Russia\'s eastern regions. He flew Yak, Lavochkin and MiG fighters in the final days of the war against the Japanese. Belyayev remained in the East for the next decade, being stationed largely in Siberia. He was promoted to lieutenant in 1947. In 1948 he married Tatyana Prikazchikova. In 1950 he was promoted to senior lieutenant. During this time he flew seven different aircraft types and came to be considered one of the Soviet Union\'s most gifted commander pilots. He was awarded the Distinguished Combat service medal in 1953. In 1954 he was promoted to captain. While he remained fond of hunting, he also enjoyed more academic pursuits in his downtime including reading and writing poetry and playing the piano and accordion. In 1956 Belyayev succeeded in gaining entry into advanced studies at the Red Banner Air Force Academy. He graduated in 1959 as military pilot second class and with the rank of major.\nDuring Belyayev\'s final studies at the Red banner Air Force Academy he had been interviewed and tested for possible inclusion in the space program. The selectors were impressed by his ability to withstand high g-Forces. Belyayev was sent to Air Squadron 661 4th IAD of the Black Sea Fleet. A month later he was appointed commander of the regiment\'s 241st squadron. By the time he was finally selected he had logged over 1,000 hours flight time in both piston and jet aircraft and had also completed approximately 40 parachute jumps. Belyayev reported for assignment at the newly formed TsPK (cosmonaut training centre) on 25 March 1960. At 34, he was the oldest candidate accepted into the program. As a major he was the highest ranking candidate and the only one to have seen active service in World War II. Because of his senior rank, Belyayev became the first commander of the cosmonaut corps. Belyayev and Vladimir Komarov (2 years Belyayev\'s junior) were the only candidates to have Air Force Academy training. Yuri Gagarin nicknamed the two senior officers ""The Professors"" In August Belyayev fractured his lower leg just above the ankle in parachute training, an accident that delayed his progress by approximately 12 months and excluded him from any early space flights. Due to the severity of the injury it seemed unlikely that Belyayev would be re-admitted to the program, but he worked constantly to recover and regain his fitness. After a year\'s absence he passed his medical and returned to training.\nAfter the success of the first Voskhod mission in 1964, a second more technically demanding mission was planned for 1965. Its primary aim was to have a cosmonaut leave the capsule and ""space-walk"". Belyayev was confirmed as prime crew commander of Voskhod 2 just 3 days prior to launch. There had been concern about his mission fitness following a poor performance in the altitude chamber testing 2 months before. It was his crewman Alexei Leonov who finally reported that ""Those responsible for the malfunction were the factory specialists supporting the equipment"", and that Belyayev had successfully corrected the fault himself, thereby also taking responsibility for the problem himself. Leonov, who had been chosen to perform the space walk described how he preferred to have Belyayev as his mission commander over Khrunov. ""I lobbied hard for Pasha, whom I thought more capable than Khrunov. I had worked with him more; I trusted him.""\nVoskhod 2 launched with Belyayev and Leonov on board on 18 March 1965. Belyayev\'s call sign was Diamond (Russian: Алмаз) and his designation as mission commander was 1.\nAfter Leonov successfully performed the first space walk, Belyayev prepared to return to Earth. Belyayev had to perform a manual re-entry when the automatic re-entry system failed. This required Belyayev to use the equipped Vzor navigation device to orient the capsule. Due to the cramped conditions inside the capsule and its poor design, Belyayev had to lie across the seats to use the Vzor while Leonov held him in place. Belyayev asked Leonov to check the craft\'s attitude, a move which caused the craft to overshoot its intended landing area by approximately 2,000 km because of the extra time this took. Upon landing Belyayev had to force open the hatch after the explosive bolts failed to open it. Belyayev then had to pull Leonov, whose legs had become jammed under the TV screen console, out of the capsule. After spending a night back inside the capsule in extremely cold conditions, the crew were met by an advance rescue party the following morning. It took another day to clear a spot in the forest for a rescue helicopter to land 9 km from the landing site.\nApollo 15 commander, astronaut David Scott recalled meeting Belyayev in Paris at a biennial air show in 1967 when he and other NASA representatives visited the Russian pavilion. ""He was really gracious…Belyayev was a very positive, thoughtful guy, a real leader; I liked him a lot."" On a reciprocal visit to the American pavilion, Belyayev disclosed that he had been ""the first cosmonaut to bring his mission back to Earth on manual control"".\nBelyayev has been commemorated with other prominent figures from the early Russian space program with a bust on Cosmonauts Alley in Moscow. Pavel Belyayev was awarded the Hero of the Soviet Union (23 March 1965), Order of Lenin, Order of the Red Star, numerous medals and foreign orders. He also bore the title of the Hero of Socialist Labor of Bulgaria, Hero of Vietnam, and Hero of Mongolia.\nAccounts of Belyayev\'s life and space career appear in the 2003 book ""Fallen Astronauts"" and the 2007 book Into That Silent Sea, both by Colin Burgess. Belyayev is also used as a character in Judith and Garfield Reeves-Stevens 2005 novel, Freefall, in which he is the first person to land on the moon, hours before Apollo 11.\nPavel Belyayev appeared on various stamps. In 1965, he appeared on stamps from the Soviet Union, Cuba, Bulgaria, East Germany, and Hungary. In 1966, he appeared on stamps from Bulgaria, Mali, and Mauritania.\nHonours and awards\n- Hero of the Soviet Union Medal ""Gold Star"" (23 March 1965)\n- Title Pilot-Cosmonaut of the USSR\n- Order of Lenin (23 March 1965)\n- Order of the Red Star (17 June 1961)\n- Medal for Combat Service (11 November 1953)\n- Medal ""For the Victory over Germany in the Great Patriotic War 1941–1945"" (9 May 1945)\n- Medal ""For the Victory over Japan"" (30 September 1945)\n- Medal ""For Valiant Labour in the Great Patriotic War 1941–1945"" (25 May 1965)\n- Medal ""For Development of the Virgin Lands"" (19 March 1965)\n- Hero of Socialist Labour (Bulgaria, 1965)\n- Order of Georgi Dimitrov (Bulgaria, 1965)\n- Hero of Labour (Vietnam, 1965)\n- Hero of Mongolia\n- Order of Sukhbaatar (Mongolia, 1967).\n- Order of Karl Marx (East Germany, 1965).\n- Order of the Syrian Arab Republic with diamond.\n- Jubilee Medal ""Twenty Years of Victory in the Great Patriotic War 1941–1945""\n- Jubilee Medal ""30 Years of the Soviet Army and Navy""\n- Jubilee Medal ""40 Years of the Armed Forces of the USSR""\n- Medal ""For Impeccable Service"" 1st and 2nd class\n- Chelishchevo is now in Babushkinsky District, Vologda Oblast\n- Pasha is the Russian diminutive form of Pavel.\n- This, including his birthplace, is stated at www.warheroes.ru, and vologda-oblast.ru. Burgess and Hall say that he grew up in Minkovo, ""Leninsky District"", but this is possibly a mistake.\n- Burgess and Hall, p.33\n- Burgess and Hall, p.34\n- Burgess and Hall, p.35\n- Hall and Shayler\n- Hall and Shayler, p.115\n- Hall and Shayler, p.109\n- Tsymbal, Nikolai, ed. (1984), First Man in Space, Moscow: Progress Publishers Moscow, p. 75\n- Burgess, Colin; Doolan, Kate; Vis, Bert (2003). Fallen Astronauts. University of Nebraska Press. p. 180. ISBN 0-8032-6212-4.\n- Harford, James (1997). Korolev. John Wiley & Sons. pp. 184–5. ISBN 0-471-32721-2.\n- Scott, David; Leonov, Alexei. Two Sides of the Moon. p. 98. ISBN 0-312-30865-5.\n- Scott & Leonov, p 114\n- Harford, James (1997). Korolev. John Wiley & Sons. p. 185. ISBN 0-471-32721-2.\n- Scott & Leonov, pp. 117–119\n- Scott & Leonov, p 120\n- Scott & Leonov, p. 203\n- Scott & Leonov, p. 204\n- Schmadel, Lutz D. (2003). Dictionary of Minor Planet Names (5th ed.). New York: Springer Verlag. p. 164. ISBN 3-540-00238-3.\n- Burgess, Colin; Hall, Rex. The First Soviet Cosmonaut Team: Their Lives, Legacy and Historical Impact.\n- Hall, Rex; Shayler, David. The Rocket Men: Vostok & Voskhod, The first Soviet Manned Spaceflights. ISBN 1-85233-391-X.\n- ""S. P. Korolev. Encyclopedia of life and creativity"" - edited by C. A. Lopota, RSC Energia. S. P. Korolev, 2014 ISBN 978-5-906674-04-3\nMedia related to Pavel Belyayev at Wikimedia Commons']"	['<urn:uuid:72212271-d0a5-488e-a5d2-8dc43c3c0ab9>', '<urn:uuid:a51cbc9c-92b6-4911-93be-e17d0bb55e8c>']	open-ended	with-premise	long-search-query	similar-to-document	comparison	expert	2025-05-13T01:50:22.828293	14	102	2365
27	what music genres klezmer combined with	Klezmer music was combined with multiple genres during the performances. These combinations included klezmer with Latin charanga (by Roberto Rodriguez Octeto Masada), klezmer with Gypsy music influences (by the Masada String Trio), klezmer with Middle Eastern surf-rock (by Banquet of the Spirits), and klezmer with jazz-rock featuring violin interludes (by Secret Chiefs 3). The music also incorporated elements of electric jazz, laptop electronics, and percussion.	['Power chords and pizzicato. Cha-cha and chamber music. Funk and free jazz. Klezmer and cacophony. All of those, and many more, turned up during a marathon of John Zorn’s Masada works at the N.Y.U. Skirball Center on Sunday.\nIn four and a half hours of music by 13 ensembles and soloists, the concert celebrated Mr. Zorn’s 60th birthday, which was Sept. 2. He has been marking the occasion with concerts around the world that have reaffirmed his astonishing productivity and multifarious connections. Mr. Zorn was sampling and mashing up idioms long before computers made it easy; he was also, well before the Internet, setting up improbable but fruitful networks of musicians and ideas.\nThe concert drew on a fraction of Mr. Zorn’s Masada repertory: two sets of melodies, the first 200 of them from the 1990s and another 316 tunes he wrote in three months in 2004. (Nearly all of the program came from the second group, “The Book of Angels.”) The Masada pieces are based in klezmer, with its modal scales, odd meters and zigzagging melodies. And like klezmer itself — a fusion of what Jewish musicians brought with them and picked up in travels through Eastern Europe and then America — the tunes are flexible.\nThey were brittle, perpetual-motion jazz in Uri Caine’s piano solos; blistering psychedelic jams — powered by bass riffs plucked on a Moroccan gimbri — in the hands of Abraxas; and sleek bachelor-pad music as played by Bar Kokhba. Krakauer set David Krakauer’s clarinet wailing over funk vamps. Mycale, a four-woman a cappella group, turned them into intricate, ingenious, glowing pan-Mediterranean songs.\nMuch of Mr. Zorn’s music revolves around the idea of genres, investigating how they’re recognized, how they connect or contrast, how far they can be stretched, how they can be juxtaposed or intercut. He approaches genres as a connoisseur, a strategist, a trickster and sometimes a vandal; if a genre is seen as a set of rules, he might play by them, toy with them or tear them apart. Behind the musical elements are the associations of genres with eras, places and people; his music pulls free of them.\nErik Friedlander turned Masada tunes into impassioned cello solos recalling the techniques of Bach suites. Malphas, the duo of Mark Feldman on violin and Sylvie Courvoisier on piano, played them as splintered chamber music: a series of brief, precise, suddenly contrasting passages lasting only a few seconds each. The Roberto Rodriguez Octeto Masada mingled klezmer with Latin charanga, and invited the audience to dance. The Masada String Trio gave its tunes a hint of Gypsy music. Dreamers cast the melodies as smoothly shimmering jazz. Cyro Baptista’s Banquet of the Spirits charged into one melody as a kind of Middle Eastern surf-rock, and Secret Chiefs 3 cranked its tunes up to burly jazz-rock with klezmer violin interludes.\nElectric Masada, with Mr. Zorn on alto saxophone, had the last set, and it was a gleeful, eventful one, moving amid hurtling electric jazz, eerie laptop electronics and squalls of percussion and dissonance, cued on the spot by Mr. Zorn. And all through the marathon, a paradox persisted. With all the transformations and idioms, the Masada tunes held on to some klezmer identity: one stubborn genre indeed.']	['<urn:uuid:fc6f2586-7703-416b-8c46-8ef8e444407e>']	open-ended	with-premise	short-search-query	similar-to-document	single-doc	novice	2025-05-13T01:50:22.828293	6	65	540
28	Could you explain the specific storage requirements and stability conditions for Alhydrogel adjuvant 2%, and what are its key physical characteristics?	Alhydrogel adjuvant 2% should be stored at room temperature and remains stable for 6 months. It's important to note that it should NOT be frozen. The product appears as a white gelatinous precipitate and is provided as a ready-to-use, sterile wet gel suspension. It has an aluminum content of 9.0-11.0 mg/ml and is tested for both pyrogenicity and sterility. The product is sterilized by autoclavation and aseptically filled.	"[""Alhydrogel® adjuvant 2%\nVaccine Adjuvant: Aluminium hydroxide gel\nAlhydrogel® adjuvant 2%, referred to as alum, is an aluminium hydroxide wet gel suspension. Alum induces a Th2 response by improving the attraction and uptake of antigen by antigen-presenting cells (APCs). It can also activate innate immunity pathways triggered by pattern recognition receptors (PRRs).\nAlhydrogel® adjuvant is sterilized by autoclavation and aseptically filled.\nInvivoGen only sells products for research use\nAlhydrogel® is a trademark, which belongs to Brenntag Nordic A/S (Brenntag Biosector A/S), and which is registered in a large number of countries and regions worldwide.\nSpecificity: Th2 response\nWorking concentration: 1:9 - 1:1 (Alhydrogel:antigen)\nCAS number: 21645-51-2\nAluminium content: 9.0 – 11.0 mg/ml\nAppearance: White gelatinous precipitate\n- Alhydrogel® adjuvant 2% is tested for pyrogenicity and sterility.\n- Adjuvanticity of Alhydrogel® adjuvant 2% was evaluated by assessing the levels of total mouse IgGs (mIgGs) and the mIgG1 and mIgG2 isotypes after two subcutaneous injections of EndoFit™ Ovalbumin/Alhydrogel® adjuvant 2% (1:1, v/v) in mice. Results were compared to mice which received EndoFit™ Ovalbumin alone.\n• 250 ml Alhydrogel adjuvant 2%, provided as a ready-to-use, sterile wet gel suspension\nAlhydrogel adjuvant 2% is shipped at room temperature and should be stored at room temperature. Product is stable for 6 months. DO NOT FREEZE.\nAlhydrogel adjuvant 2% is an aluminium hydroxide (referred to as alum) wet gel suspension. Alum acts primarily through the formation of a depot at the injection site, enabling enhanced antigen availability, activation of antigen presenting cells (APCs) and uptake by immune cells . It can also activate innate immunity pathways triggered by pattern recognition receptors (PRRs). The NLR pathway has been recently described as an important mechanism in alum adjuvancy . Alum has been shown to activate the NLRP3 inflammasome although its role in alum-induced antibody response is controversial .\n1. Morefield GL. et al., 2005. Role of aluminum-containing adjuvants in antigen internalization by dendritic cells in vitro. Vaccine 23(13): 1588-95.\n2. Li H. et al., 2008. Cutting edge: Inflammasome activation by alum and alum's adjuvant effect are mediated by NLRP3. J Immunol. 181(1):17-21.\n3. Franchi L. & Nuñez G., 2008. The Nlrp3 inflammasome is critical for aluminium hydroxide-mediated IL-1beta secretion but dispensable for adjuvant activity. Eur. J. Immunol. 38(8):2085-9\nRecent articles using InvivoGen Alhydrogel® adjuvant 2%\n- 2014 - Nat Biotechnol., 32(4):356-63\nComplete humanization of the mouse immunoglobulin loci enables efficient therapeutic antibody discovery.\nLee EC, Liang Q, Ali H, Bayliss L, Beasley A, Bloomfield-Gerdes T, Bonoli L, Brown R, Campbell J, Carpenter A, Chalk S, Davis A, England N, Fane-Dremucheva A, Franz B, Germaschewski V, Holmes H, Holmes S, Kirby I, Kosmac M, Legent A, Lui H et al.\n- 2014 - J Virol., 88(12):7045-53.\nA conformation-dependent neutralizing monoclonal antibody specifically targeting receptor-binding domain in Middle East respiratory syndrome coronavirus spike protein.\nDu L, Zhao G, Yang Y, Qiu H, Wang L, Kou Z, Tao X, Yu H, Sun S, Tseng CT, Jiang S, Li F, Zhou Y.\n- 2013 - PLoS One, 8(4):e61034\nThe hedgehog receptor patched1 in T cells is dispensable for adaptive immunity in mice.\nMichel KD, Uhmann A, Dressel R, van den Brandt J, Hahn H, Reichardt HM\n- 2013 - Clin Vaccine Immunol., 20(6):892-9\nEvaluation of RevA, a fibronectin-binding protein of Borrelia burgdorferi, as a potential vaccine candidate for lyme disease.\nFloden AM, Gonzalez T, Gaultney RA, Brissette CA\n- 2013 - Semin Oncol., 40(3):347-60\nPerspectives on immunotherapy in prostate cancer and solid tumors: where is the future?\nSnyder A, Tepper JE, Slovin SF""]"	['<urn:uuid:fecb0979-0680-48ba-ba05-429e626a1a8b>']	open-ended	direct	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-13T01:50:22.828293	21	68	581
29	As a music theory student, which note was deliberately avoided in Pizza Guy?	The F# note was deliberately avoided in the track, which creates ambiguity between G Major and C Major keys.	['Ableton Liveschool trainer Michael Di Francesco has many many projects and equally many talents. In between albums and touring for Van She, one of his aliases, Touch Sensitive, managed an eight-week stint at number 1 on the Beatport indie chart in 2012 with his Anna Lunoe collab “Real Talk”.\nMichael recently dropped his latest Touch Sensitive track “Pizza Guy” and it’s already caught over 300,000 plays on soundcloud. “Pizza Guy” is in G Major, but has an intriguing mood, so we picked is brain on the music theory behind this.\n[soundcloud url=”http://api.soundcloud.com/tracks/87943423″ params=”” width=” 100%” height=”166″ iframe=”true” /]\nMichael: “The whole track is based on one simple idea, the ostinato melody that just repeats and repeats while the bass line moves around under it….the long release times of the synth playing the ostinato melodies notes gives the impression there are chords there when there aren’t really any”\nMichael’s ostinato melody is G-E-G-D-G-E-G-D repeated. The long release times on the synth makes these notes blend together and implies the presence of a chord. As the G is being played twice as often as the E or D in this melody, it’s reinforcing G as the home note (the root of G Major).\nMichael: “The overall effect of this melody combined with the bass notes gives it a particular mood”\nThe bass line in Touch Sensitive – ‘Pizza Guy’ is E-D-C, E-B-C. The emphasis here is on the C note as it’s being played twice as often as any other (and held longer also), this emphasis makes the C note feel like a second home. If we add the C note that the bass line revolves around to the ostinato melody, we’d have C, E, G and D – which together make a C Major add 9 chord. So before reading further, let’s re-iterate that the most played note in the ostinato melody is G, while the most played note in the bass line is the C.\nMichael: “I avoided using the F# note which really affects the mood”\nNow on to the really interesting part, Michael has avoided using the F#, let’s discuss that! Thinking about the circle of 5ths, we know that G Major is next to C Major, which means (amongst other things) that these two scales share all but one note. That one note of difference is the F# (if you’re in G Major) or the F (if you’re in C Major). So while Michael’s song is in G Major, by avoiding the F# note he’s also implying that he could be in the C Major key, which adds complexity and interest to the piece as it creates a feeling of playing in two keys at once. This technique of avoiding certain notes and as a result creating ambiguity as to which key your song is pretty simple, but can be really effective in creating a unique an interesting mood. The ambiguity between G Major and C Major has been further intensified in Pizza Guy by the how ostinato melody focuses around the G (implying the G as the root note), while the bass line focuses around the C (implying C as the root note). It really brings to mind Miles Davis’ classic quote “it’s not the notes you play, it’s the notes you don’t play”.\nWant to try it at home? Take a look at the circle of fifths and pick two adjacent keys, for example E Major & A Major. Work out which is the note of difference between them (in the case of E Major and A Major it’s the D / D#) and completely avoid using this note in your track. Then make some elements of the track focus around the E, while others focus around the A to further emphasize the ambiguity of which key your track is in. Good luck!\nFor another track breakdown check out Elizabeth Rose’s tutorial on the music theory considerations behind writing the hooks and melodies for her single “The Good Life”.\nSubscribe to our newsletter to keep up with our latest free tutorials, samples, video interviews and more.\nLearn more about Music Theory for electronic music.']	['<urn:uuid:0af485ed-d9e2-4b86-8ba0-c72cca180494>']	factoid	with-premise	concise-and-natural	similar-to-document	single-doc	expert	2025-05-13T01:50:22.828293	13	19	689
30	As a bereavement counselor, I often discuss memorial options with families. What are the most thoughtful condolence messages for the loss of a loved one, and what are the different permanent memorialization options available for cremated remains?	For condolence messages, it's important to keep them short and meaningful by acknowledging the loss, expressing sympathy, sharing a brief memory if applicable, and ending with a thoughtful wish. Some appropriate messages include 'Your mother is with you always, first in her lifetime, then in your memory forever' or 'Fathers may pass but their hopes, dreams and lessons live on in us forever.' For cremated remains, there are numerous permanent memorialization options: interment in a cemetery plot, placement in a columbarium niche, scattering in a cemetery's garden, or ground burial of the urn with either a bronze memorial or monument. These permanent locations serve as a focal point for remembrance and provide future generations with a place to visit, helping bring closure and allowing the healing process to begin.	['Death is never an easy topic to talk about. If someone you know is dealing with the loss of a loved one, it is appropriate to send a letter or card expressing your sympathy for their pain.\nWhile there are no words adequate enough to express sorrow for a loss, a brief condolence message can mean a great deal to the recipient during the mourning period.\nHow to Write a Meaningful Condolence Message\nKeep the condolence message short, refer to the deceased by name and share personal experiences when appropriate. These tips and general guidelines below will help you create a meaningful and appropriate sympathy message.\nFollow these guidelines to show respect for the recipient’s time and emotional wellbeing:\n- Acknowledge the loss of the deceased.\n- Express your condolences or sorrow for the recipient’s loss.\n- Share a brief memory of the deceased (if applicable).\n- Include a thoughtful wish to end the note.\nCondolences for the Loss of a Mother\nThe pain caused by the loss of a mother can be overwhelming. Use these simple messages to craft a heartfelt condolence that will comfort the recipient during their mourning.\n- Your mother is with you always, first in her lifetime, then in your memory forever.\n- Moms hold a special place in our heart –– (name) will be with you always.\n- Extending my sincere condolences for the loss of your mother and thinking of you during this difficult period in your life.\n- Mothers are the most significant figures in our lives. (Name) loved you unconditionally and will always be near.\n- (Name) was an incredible woman who held a special place in my heart. Please know I’m a phone call away if you need anything.\n- To lose a mother is to lose the lighthouse that guides you through darkness, but (name) will always watch over you and protect you.\nCondolences for the Loss of a Father\nFathers are such powerful figures in our lives, so their passing can be especially difficult for their children. Express your sympathies and love with help from these messages.\n- Dads are symbols of strength and warmth to their children –– (name) shared these traits with everyone who knew him.\n- Never has a more kind and loving man than (name) graced with world with his presence. He will be missed by us all.\n- In this time of loss, please accept my heartfelt condolences for the loss of your father.\n- Fathers may pass but their hopes, dreams and lessons live on in us forever.\n- (Name) gave so much love and kindness to everyone in his life. I am so sorry to hear of his passing and your loss.\n- Expressing my deepest sympathies for the loss of your wonderful father. (Name) was very dear to me and will be missed.\nCondolences for the Loss of a Child\nIt is said that a parent should never go through the pain of losing a child. These condolence messages can help you express your sorrow in a meaningful and appropriate way.\n- It is said there is nothing more painful than the loss of a child. We are right beside you during this time of heartache.\n- There are no words to express the darkness brought on by the loss of (name). Extending my deepest condolences and wishing you a peaceful heart.\n- I have been so blessed by the contagious joy (name) brought to everyone (he/she) knew. Praying for your comfort and peace.\n- The loss of a child is more heartbreak than should be possible. Sending my love and prayers to you and your family.\n- Words aren’t enough, so know that I’m a phone call away. Here for you always.\n- Truly sorry for the loss of (name). There was no happier spirit in this world –– (he/she) will be missed deeply.\nCondolences for the Loss of a Pet\nOur pets are the best companions in our lifetimes. Here are some messages you can use when someone you know has lost a furry friend.\n- I am so sorry to know that (pet name) has passed on. The joy (he/she) brought to us all will always be in our hearts.\n- Losing a pet causes indescribable heartache. Thinking of you and your family during this time.\n- Our pets never really leave us. They become our guardian angels to watch over us.\n- Thinking of you as you mourn (pet name). (He/She) was a true joy and manifestation of unconditional love.”\n- Losing a true friend like (pet name) is never easy. Sending my love and thoughts to you.\n- So sorry to hear about the passing of (pet name). Such a loyal friend will always be by your side.\nShort Condolence Quotes\nFinding the right words to express sympathy can be challenging. Using a quote or saying can help you appropriately send your condolences.\n- “Like a bird singing in the rain, let grateful memories survive in time of sorrow.” – Robert Louis Stevenson\n- “It is not length of life, but depth of life.” – Ralph Waldo Emerson\n- “There is no greater sorrow than to recall happiness in times of misery.” – Dante\n- “A human life is a story told by God.” – Hans Christian Andersen\n- Unable are the loved to die, for love is immortality.” – Emily Dickinson\n- “There are no goodbyes for us. Wherever you are, you will always be in my heart.” – Gandhi\nWhile death is a painful subject, sending a quick note or meaningful gift to show your love and support can mean the world to someone going through loss.', 'What are my options for memorialization for cremation remains?\nWith cremation, your options are numerous. The cremains can be interred in a cemetery plot, i.e., earth burial, retained by a family member, usually in an urn, scattered on private property, or at a place that was significant to the deceased. (It would always be advisable to check for local regulations regarding scattering in a public place.) Cremation is just one step in the commemorative process—the preparation of the human remains for memorialization. Today, there are many different types of memorial options from which to choose. Memorialization is a time-honored tradition that has been practiced for centuries. A memorial serves as a tribute to a life lived and provides a focal point for remembrance, as well as a record for future generations. The type of memorial you choose is a personal decision. The limit is set only by your imagination.\nWhat is memorialization for a cremation?\nYou might choose ground burial of the urn. If so, you may usually choose either a bronze memorial or monument. Also available at many cemeteries are cremation niches in columbariums. They offer the beauty of a mausoleum setting with the benefits of above ground placement of remains. Many cemeteries also offer scattering gardens. This area of a cemetery offers the peacefulness of a serene garden where family and friends can come and reflect.\nWhat is a columbarium?\nA columbarium, often located within a mausoleum or chapel, sometimes free-standing, either indoor or outdoor, is constructed of numerous small compartments (niches) designed to hold urns containing cremated remains.\nIf I’m going to be cremated, why would I want my remains to be placed in a columbarium, or interred or scattered at the cemetery? Why shouldn’t I just have them scattered in the sea or in some other place of my choosing?\nAs long as it is permitted by local regulations, the cremated remains can be scattered in a place that is meaningful to you. This can, however, present difficulties for your survivors. Some people may find it hard to simply pour the mortal remains of a loved one out onto the ground or into the sea. If you wish to be scattered somewhere, it is therefore important to discuss your wishes ahead of time with the person or persons who will actually have to do the scattering. Another difficulty with scattering can occur when the remains are disposed of in an anonymous, unmarked or public place. Access to the area may be restricted for some reason in the future, undeveloped land may be developed, or any of a host of other conditions may arise that could make it difficult for your survivors to visit the site to remember you. Even if your cremated remains are scattered in your backyard, what happens if your survivors relocate sometime in the future? Once scattered, cremated remains cannot easily be collected back up. Having your remains placed, interred or scattered on a cemetery’s grounds ensures that future generations will have a place to go to remember. If remains are scattered somewhere outside the cemetery, many cemeteries will allow you to place a memorial of some type on the cemetery grounds, so survivors have a place to visit that will always be maintained and preserved.\nWhy is having a place to visit so important?\nBecause it provides a focal point for memorializing the deceased. To remember, and be remembered, are natural human needs. Throughout human history, memorialization of the dead has been a key component of almost every culture. The Washington Monument, Tomb of the Unknowns and Vietnam “Wall” in Washington, D.C are examples of memorialization which demonstrate that, throughout our history, we have always honored our dead. Psychologists say that remembrance practices, from the funeral or memorial service to permanent memorialization, serve an important emotional function for survivors by helping to bring closure and allowing the healing process to begin. Providing a permanent resting place for the deceased is a dignified treatment for a loved one’s mortal remains, which fulfills the natural human desire for memorialization.\nIf I am cremated, can I be buried with my spouse even if he or she was in a casket?\nYes — Depending upon the cemetery’s policy, you may be able to save a grave space by having the cremains buried on top of the casketed remains of your spouse, or utilize the space provided next to him/her. Many cemeteries allow for multiple cremated remains to be interred in a single grave space.\nCan I take the cremated remains home?\nYes. The remains are normally placed in an urn. Most families select an urn that is suitable for placement on a mantle or shelf. Urns are available in a variety of shapes, sizes and materials.\nHow big of a price difference is there with cremation compared to standard ground burial?\nThe cost depends on the type of permanent memorial, location of the memorial, urn and placement selected.']	['<urn:uuid:4305acc0-6cff-4244-b336-a4ab1755a1ba>', '<urn:uuid:a1248454-b758-4316-92e3-b84df3fbf2b5>']	open-ended	with-premise	verbose-and-natural	similar-to-document	multi-aspect	expert	2025-05-13T01:50:22.828293	37	129	1766
31	How do construction payment methods differ between historical churches and porches?	Historical church construction, as exemplified by Bethel Methodist Church in 1952, operated with partial upfront funding, having only $20,000 on hand when construction began on a $75,695.09 project. Modern porch construction, however, is calculated strictly by square footage, with labor rates charged per square foot rather than by hour, and contractors often use flat-rate budgets.	['History of Bethel United Methodist Church\nBethel Methodist Church was formed in the year of 1912 by a small group of saintly men and women. The name “Bethel” was chosen because of the scripture of Genesis 28 meaning “House of God.” Mr. C. G. Hill of Cannon Mills Corporation (now Parkdale Mills) donated a lot on the corner of Hinkle and Fisher Ferry Streets and the late Mr. C. A. Russell, Sr. helped build the small frame building, which served this congregation for over forty years. A very prominent banker of Thomasville, Mr. R. L. Pope, donated the bell for the church, which was later electrically installed in the current church by the late George Smith.\nBethel held its first service on Sunday evening, May 10, 1912 by a Reverend Parker. The Reverend Z. T. Bell was the first conference minister and the Reverend McRae Crawford was the last conference minister to serve in this building.\nThe church was outgrowing this small building so on May 9, 1944 the Official Board authorized the Reverend D. A. Oakley and C. J. Myers to find a suitable building site for a new church building. Through the faith and leadership of the late Reverend C. O. Plyler a new building was on the drawing board and Craver and Essick Construction Company of Lexington, NC was hired to build the present structure. The church treasurer had only $20,000.00 on hand when construction began.\nOn December 18, 1951, the footings were poured. The building was finished in 1952 at a cost of $75,695.09. The Reverend McRae Crawford held the first service in the new church on July 27, 1952. The church debt was paid off, the church dedicated, and the cornerstone laid on August 12, 1956. What seemed to be an impossible dream became a reality.\nA fellowship hall, consisting of a kitchen, large assembly-dining room and two rest rooms was constructed in 1957 under the leadership of the Reverend Harley Cecil. Construction was begun on September 16, 1957 at a cost of $10,000.00 and the mortgage was retired on August 16, 1959. Today, the building is being used by our Youth as a meeting and recreation facility and is now called “Youthtopia”.\nThe year 1959 was the beginning of Bethel Methodist Church as a station church with its first full-time minister. Also in 1959 a wooded lot was purchased and a brick parsonage was built. This was done under the leadership of the late Reverend W. C. Clark. The mortgage on this building was retired in 1967. Bishop Earl G. Hunt, Jr., Dr. Charles G. Beaman, Jr. and the Reverend Grady N. Dulin held the dedication of the new parsonage on February 25, 1968.\nBethel Methodist Church became Bethel United Methodist Church in 1968 when the General Conference made the ruling to merge the Methodist Church with the Evangelical United Brethren Church, thus adding United to the Methodist Church.\nIn 1969 several improvements were made to the sanctuary building: a steeple, a colonial style porch, air-conditioning, new carpet, downstairs paneling, and a granite church sign.\nA few years later another remodeling program began and the choir loft and pulpit area were changed making the sanctuary more beautiful and functional. In 1984 a large wooden, lighted cross was constructed and erected directly behind the pulpit area and donated to the church by Bob Johnson in honor of Charlie Tobin.\nIn 1998 the lot beside the church (the Moore property) was purchased. Several years later we purchased the adjoining land behind the church from Parkdale Mills. Other projects that have enhanced the ministry of the church include the purchase of a church van, a church bus, a new lighted marquee, a handicap ramp and a playground.\nIn 2003, we purchased the Jean Jarrett house as our new parsonage. Extensive renovations to the new parsonage were completed within a few months.\nWith God’s guidance and the leadership of Reverend Ben K. Shepherd, we began construction of a new Family Life Center in May 2004. This was a long-awaited dream come true for the faithful members of Bethel. The new building was first used on November 20, 2004 for the Pansy McClamrock Benefit Dinner. The $1.1 million dollar debt was paid off on November 23, 2008. Our new building is used in a variety of ways including weekly Sunday School classes, choir rehearsals, church services, weekly and special event meals, children’s programs and activities, dramas, IFHN, wedding ceremonies and receptions, etc…\nBethel is growing and for all things accomplished and for all things to come, both spiritual and material, we give the praise and glory to God, through our Lord Jesus Christ.', 'How Much Does It Cost To Build A Porch?\nPorch Addition Costs\nPorches are a great outdoor space to add to any home. The cost to build a porch will depend on the design, location, and whether it is being added on to an existing home or built as a part of new construction.\nBuilding a porch addition is calculated by square footage. Even labor rates will be charged by the square foot rather than by the hour. Some projects or contractors will have a flat-rate budget for your porch construction. It all depends on where you live and which companies you work with. There are also multiple parts to a porch that have to be considered in creating your cost estimate.\nFinally, you have your choice of different styles of porches, including the Florida room, screened porch (also called a sunroom), rain porch, portico (small front door porch), veranda, lanai, stoop, wraparound porch, and prefabricated porches that come in prebuilt sections.\nPorch addition: 16’x20’, foundation, walls, columns or railings, windows and doors, screens, a roof or awning, and required labor, as well as other materials.\n|Labor||$20-$40 per square foot|\n|Demolition and debris removal||$4-$15 per square foot|\n|Walls (optional)- brick, stone, siding, wood, or composite materials||$4-$15 per square foot|\n|Railings||$150-$5,000 per 10-foot section|\n|Foundation||$5-$8 per square foot|\n|Deck/Floor||$6-$10 per square foot|\n|Screens||$4-$7 per square foot|\n|Porch Roof-aluminum or wood||$500-$10,000|\n|Average Total Porch Addition Cost||$22,000-$50,000|\nOther considerations and costs\n- Many people choose to add accessories like ceiling fans, lights, electrical outlets, and other features. These will all add to the cost of your porch addition.\n- Before you plan any addition, you need to make sure that your homeowner’s insurance is going to cover the new space and whether or not your premiums will go up as a result of adding on. Policies are sometimes based on square footage, and your insurance provider will want to make sure that the work is done properly and to code.\nCheck out our guide if you need a loan for your home improvement project.\nYou may be able to assist with demolition, cleanup, finishing details, or other aspects of your porch addition to help reduce your labor costs. You may even be able to provide your own (cheaper or more desirable) materials. However, you need to leave this project in the hands of a qualified contractor to get the best outcome.\n- Craftsman Estimator Costbook, complete series year 2019.\n- Latest prices found on Home Depot and other vendor Web sites.\n- Literature review of DIY Web sites.\nEnter your zip code to get estimates\nCost by city\n- New York, NY$57,829\n- Bronx, NY$47,520\n- Brooklyn, NY$39,606\n- Philadelphia, PA$49,409\n- Washington, DC$42,875\n- Atlanta, GA$38,791\n- Miami, FL$35,280\n- Fort Lauderdale, FL$36,956\n- Minneapolis, MN$43,354\n- Chicago, IL$50,512\n- Houston, TX$52,101\n- San Antonio, TX$34,974\n- Austin, TX$39,601\n- Denver, CO$33,459\n- Phoenix, AZ$35,301\n- Las Vegas, NV$38,745\n- Los Angeles, CA$43,656\n- San Diego, CA$39,616\n- San Jose, CA$47,852\n- Seattle, WA$35,033\nLocal costs have been calculated by accounting for labor and material cost differences across different cities. To get accurate cost estimates, indicate yours:']	['<urn:uuid:d085b719-4b0d-46e1-98aa-086d5db13225>', '<urn:uuid:0b6a689d-6968-4b20-8dd5-b5e26f71e09a>']	open-ended	direct	concise-and-natural	distant-from-document	comparison	expert	2025-05-13T01:50:22.828293	11	55	1299
32	natural pest control methods spider mites garden	Several natural methods can control spider mites in gardens. Cultural controls include maintaining plant moisture and using strong water blasts on infested areas. Biological control through Western Predatory Mites (Phytoseiulus) is highly effective, as these predators establish themselves and continue controlling spider mites as long as prey is available. Other natural solutions include pruning heavily infested leaves, using insecticidal soap for severe cases, and ensuring proper plant nutrition and watering. Neem oil applications every 3 days help destroy eggs, while encouraging beneficial insects can help maintain long-term control.	"[""Who doesn’t want to grow the perfect tomato? After all, tomatoes are the quintessential summer food that we're all eager to get on our tables. Unfortunately, tomato pests are equally as excited to eat the delicious fruits.\nTomatoes are one of the most popular garden crops. My friends and family have an ongoing contest to see who can get them to the table first. Not only does this mean I need to get an early start, but I have to make sure my tomatoes are growing pest free.\nKnowing what type of tomato pest is attacking your garden is the first step to tackling the problem. This guide will help you figure out what's pestering your plants and give you a few methods for getting the situation under control.\nCommon Insect Pests That Affect Tomatoes\nAt some point, every gardener encounters aphids. The tiny, green, pear-shaped bugs leave a sticky honeydew secretion behind them. They're notorious sapsuckers of not only tomatoes but many other vegetables. A few aphids aren't a problem, but when you start seeing clusters of them, it's time to take action. An infestation will interfere with nutrients and water flowing up to your tomatoes leaves.\nFortunately, getting rid of aphids is not hard. They have soft bodies and no way to protect themselves. You can squish them with your thumb like a demi-God if you need an ego boost. Or you can take a more traditional route. Several OMRI and NOP sprays kill aphids. However, they're mostly soap and fats, something you can mix up yourself at home on the cheap.\nAme’s Homemade Bug Spray\nHere's the mixture that I use. The mineral oil suffocates the aphids while the dish detergent dehydrates them. The peppermint oil acts as a natural repellent.\n- Two cups of water\n- Two tablespoons of food grade mineral oil\n- Three drops of dish detergent\n- Three drops of peppermint oil\nMix the ingredients in a spray bottle and apply to your plants. Shake the mixture frequently while applying because the oil will separate.\nNatural Aphid Controls\nDo you want Mother Nature to assist you with killing those aphids? Then encourage lady beetles. Lady beetles (or ladybugs) eat aphids when they are in the larvae stage. You can attract ladybugs to your garden by planting dill, chives, cosmos, marigolds, and yarrow. They also need places like trees and shrubs to hide from predators.\nFlea beetles are tiny black insects with a hard exoskeleton. They can jump (hence the name flea beetle) and spread through your garden rapidly.\nFlea beetles are my kryptonite! I'm convinced they spend all winter daydreaming of sucking the life out of my plants. They especially love to eat tomatoes and their cousins, eggplant and pepper.\nYou can identify flea beetle damage by the irregularly shaped pits and holes in the leaves of your tomatoes. Extensive damage makes the plant's leaves look like lace. It sounds pretty, but it can destroy your plant.\nFlea beetles lay eggs in the soil. The larva live underground and eat the plant's roots. They typically don't cause serious damage at this stage. As adults, they move above ground and eat the plant's leaves. This stage is when they can cause monumental destruction.\nControlling Flea Beetles\nYou can help prevent flea beetles from attacking seedlings by using row covers when you transplant. Make sure to secure the row cover at ground level.\nSticky traps are an excellent way to control adults. I've seen diatomaceous earth (DE) recommended for flea beetles, but my experience is that it's not effective. DE works best on soft-bodied pests. Diatomaceous earth consists of aquatic fossils. These ground-up organisms feel like flour in your hand. However, the microscopic jagged edges are lethal knives to soft-bodies critters. You can also t\nFlea beetles are attracted to radishes, which you can plant as a trap crop and then use traps or an insecticide to kill the tomato pests.\nRoot Knot Nematodes\nThere are thousands of varieties of nematodes, but the ones that mutilat your tomatoes are root-knot nematodes. These microscopic roundworms cause bumps or galls on the roots of your plants.\nThese galls interfere with the plant's ability to take up nutrients. They may cause the plant to stop growing and turn yellow from lack of nutrients. Nematodes are widespread, but they're more common in the south and coastal areas with warm winters.\nPrevention of Nematodes\nThe best prevention is a strict crop rotation system. Nematodes can't travel far, so removing hosts plants lowers the population. Leave three years between planting tomatoes in one spot.\nYour grandmother, like mine, may have told you to plant marigolds with your tomatoes. That's because marigolds act as a trap crop to attract nematodes. Research shows that the French types such as lemon drop, yellow boy, and tangerine are the most effective.\nYou can also purchase tomato varieties that are resistant to nematodes. When looking in catalogs, you may see VFN after a tomato variety. The N stands for nematode and means that type will be resistant.\nPrevention of nematodes starts in the fall, so be sure to take steps to stop them from becoming a problem.\nWhiteflies are small flying insects. They feed on the sap of your plants much the way aphids do. Whiteflies spread many types of fungal diseases among your plants.\nThe nymphs look like small white pods and hang out on the underside of the leaves. Adults are yellow colored insects with white wings. Whiteflies tend to be a greater problem in greenhouse production of tomatoes because they love a warm, moist environment.\nThe best prevention for whitefly is weeding. Whiteflies breed and lay eggs in decaying plant matter.\nYou can also try silver colored mulch. Research shows that silver mulch confuses whiteflies so that they don't\nFinally, try an insecticidal soap such as Safer, or Ames Homemade recipe above.\nThe tomato hornworm strikes fear in even the bravest of gardeners. The larvae are large, typically three to four inches long, with a black “horn” on their butt. These caterpillars will undergo metamorphosis into the Carolina sphinx moth, also known as the tobacco hawk moth.\nThe brown pupae overwinter and emerge as adults in the spring. The adults mate and lay eggs which hatch into caterpillars. They produce two generations each growing season, so you need to keep on top of things if these show up in\nNatural Hornworm Control\nThe best control is hand picking these tomato pests off your plants. You can dispose of them in a bucket of soapy water. Better yet, feed them to your poultry for a treat.\nEnlist your children in the task. When I was a kid, my father paid us a penny for each hornworm we nabbed. You can also recruit your poultry flock. Chickens have sharp eyes and are willing participants. You will have to keep an eye on them so that they don't eat the tomatoes, though. Ducks are an efficient caterpillar control as well.\nSprinkle DE on the ground around your young plants when you transplant them. As they grow, sprinkle the leaves to protect them.\nBe sure to till your garden in the fall. Tilling\nIf your infestation is severe, you can use commercial organic products. Both Safer Garden Dust and Monterey Insect Spray will kill the young caterpillars.\nColorado Potato Beetle (CPB)\nThe Colorado Potato Beetle doesn't only live in Colorado, and they munch on more than potatoes. They also love tomatoes and plants in the Solanaceae family. It's one of the most destructive tomato pests out there.\nThe adults emerge in spring and lay clusters of orange eggs on the underside of plants. The eggs can survive for several years. Larvae will hatch dependent on weather conditions.\nThe Colorado Potato Beetle starts its life as a caterpillar-like larva. They are a dark red with black spots and gradually become a lighter red color. The adults are orange colored and oval shaped. They have a hard exoskeleton which protects them.\nBoth the larvae and adults can quickly defoliate your plants. Adults can fly and move around your garden.\nHow To Protect Your Tomatoes From Colorado Potatoes Beetles\nHandpick CPB and d\nFor organic controls, azadirachtin (neem oil) and spinosad (Monterey Insect Spray) both help control populations. Neither of these will outright kill the adult CPB as their hard shell protects them, but they can destroy the larva.\nTomato fruitworm, also known as corn earworm and cotton bollworm, usually first shows up at as a black hole at the base of tomato fruits. Once you cut into the tomato, you'll see tunnels throughout the fruit. The larvae have tan heads and striped bodies. As adult moths, they are olive in color with a dark spot and bands on their wings.\nGetting Rid of Tomato Fruitworm\nDispose of any infested fruit and avoid planting near corn because having two food sources can be an even more enticing lure for tomato fruitworm. Parasitic wasps can help control populations, and you can also sprinkle plants with diatomaceous earth. If all else fails, you may need to turn to chemical pesticides.\nCutworms are large gray or brown caterpillars with black or yellow spots. As adults, they are mottled brown or gray moths. If you notice large holes in your tomatoes, cutworms could be the culprit. Cutworms have smooth skin and reach about 2-inches at their full size. They are easiest to spot at night when they are active. During the day, they like to hide in soil or under debris around plants.\nThese aggressive tomato pests can mow down an entire garden overnight, so if you have them, get serious about control.\nKeep the area around your plants clean and till the soil before planting. You can also place cardboard collars around your plants to prevent the worms from being able to nibble. Diatomaceous earth is effective against them, and you can head out to your garden in the evening with a flashlight to spot and destroy them. Moth traps are effective for catching the adults.\nTo prevent them from taking hold, be sure to rotate your crops and till the soil in the fall.\nGreen and Brown Stink Bugs\nThere are several different kinds of bugs that attack tomatoes, but the damage they do and the method of controlling them are similar. Stink bugs are about 1/2-inch long and have a distinct shield-shaped body and are usually brown or green. They emerge in the garden in the spring. If you don't spot the critters first, you'll notice pinpricks on your tomatoes surrounded by lighter colored areas that eventually turn yellow. They can carry diseases, including mold, that can destroy your garden. If you suspect you have an infestation, shake your tomato plant and examine the ground for the bugs.\nControlling Stink Bugs\nTo get a handle on these tomato pests, remove the weeds that stink bugs prefer to hide or overwinter in, like thistle, bramble, mustards, and mallow. Spray plants with water every day to knock them off your tomatoes and then hand pick them off the ground. If all else fails, try treating plants with kaolin. Try not to use commercial insecticides because they can kill the beneficial insects that will help keep your garden healthy.\nSpider mites are teeny-tiny arachnids that suck the life out of plants. Although they are small, a heavy infestation can wreak havoc on your garden. You'll probably first see their delicate webbing all over your tomato plants. If you look on the underside of leaves, you'll spot clusters of them hanging out. They can cause leaves to turn yellow and fall off. This can reduce yields.\nGetting Rid of Spider Mites\nPrune off heavily infested leaves and then spray the plant with a strong stream of water. Treat tomato plants with neem oil every 3 days to destroy the eggs. You can also use insecticidal soap if things are bad.\nTo help prevent them from returning, make sure your tomatoes get ample water and fertilizer because healthy plants can better fight off these pests. You also want to encourage beneficial insects to hang out in your garden, because they love to snack on aphids.\nTortoise beetles like to nibble on the underside of tomato leaves. They can kill off seedlings, and a massive infestation can reduce yields by filling with tiny holes. The beetles are pretty distinct at about 1/4-inch long with a round or oval body that looks similar to a ladybug at first. The difference is that a tortoise beetle shell extends over its head. They come in all colors, from red and orange to metallic green and blue.\nControlling the Tortoise Beetle\nHandpick beetles if you spot them on your plants and drop them into soapy water. Then, scour your plants weekly for the clusters of eggs that the females lay. Scrape them off or snip off the host leaf. If things are still bad, use insecticidal soap to spray plants. Keep tomato plants well watered and fed, because healthy plants can fight off a small infestation.\nSlugs and Snails\nSlugs will eat just about anything in the garden and tomatoes are no exception. You probably know what a slug looks like, but if you don't catch them in the act, you'll know you have them if you see a hole nibbled into the fruit with surface feeding around the hole.\nControl Slugs in your Tomato Garden\nDematiaceous earth is an effective first-line defense against slugs. Sprinkle it around your plants. You can also put lava rock around plants.\nAdjusting your watering schedule can do wonders. Water in the morning, so the soil is dry by the evening, which is when moisture-loving slugs are most active.\nIf you want to tackle your slug problem aggressively, head outside at night with a flashlight and some salt. Sprinkle every slug you see with some salt. Be cautious not to use too much, or you can harm your plants. You can also try commercial slug repellants.\nTarnished Plant Bug\nThe tarnished plant bug is a small insect – about 1/4-inch big. It's mottled yellow and brown, with a black tip on each wing. These tomato pests suck the juice from plant stems, leaves and fruits. You'll often first know you have them when you see black spots all over your plant. They'll also cause\nControl Tarnished Plant Bug\nThere are five generations of this bug each year, so you need to keep on top of things. Your first line of defense is to keep weeds like mustard, pigweed, mullein, and ragweed away from your garden. Then, be sure to till your garden before planting.\nUse floating row covers and white sticky traps around your garden at 2-feet above the ground. Make sure the covers are sealed at the soil level. Spray plants with a garlic spray while the bugs are active. You also want to encourage parasitic wasps.\nDiagnosing Your Tomato Pests\nAre you still stumped as to what's killing your tomatoes? It's well worth the time to spend studying some articles or websites to help you figure out which tomato pest is plaguing your plants. That way you can act quickly to nip it in the bud so to speak.\nOnline insect guides can be a great asset in your arsenal. You can look up your state and extension office to see what is available in your area. Here are a few resources based on location:\n- For those on the west coast The Pacific Northwest Pest Management Handbook\n- For the Northeast, the University of Maine has an extensive insect guide\n- The deep south offers some unique challenges to bug control. University of Florida Extension has a guide to help.\nThe best way to protect your plants is to be an observant gardener. I like to take evening walks in my garden. I examine the plants and make notes of what needs weeding, spraying or harvesting. In this way, I keep up with my garden chores before things get out of hand."", 'Spider Mites - Tetranychus\nBy SCMG Coby Lafayette-Kelleher\nBaby it’s cold (and wet) outside. Too cold, one would think, for any self-respecting insect. It’s mollusk weather, so we expect to see worms, snails and slugs busy turning last season’s plant material into compost. But insects? This time of the year, they are keeping a low profile.\nDon’t let your guard down, though. They’re out there, waiting. This is especially true of our bug of the month—Spider Mites. A point of clarification before we go much further: Spider Mites aren’t really bugs or insects; they are actually tiny little Arachnids. Thus, the “Spider” part of Spider Mites. Just so we’re clear.\nAnyway, up close, really close, these tiny mites do look rather spider-y with their eight bristly legs and tear-drop shaped bodies. And, while you can see them clearly with a hand lens, it’s the evidence of their presence that usually gets your attention. Your first clue to the presence of Spider Mites is probably going to be a fine, silk-like webbing on leaves, twigs, and fruit of infested plants. They are particularly fond of vines, berries, and fruit trees, although ornamentals are vulnerable too.\nSpider Mites feed on their host plant by piercing plant leaf cells and sucking out the contents. So, it isn’t surprising that leaf stippling is actually the first sign of damage to your plant/s. Stippling is subtle and easily overlooked. Consequently, most people don’t “discover” a Spider Mite infestation until the webbing starts showing up.\nSpider Mites are colonial Arachnids, meaning that they occur in large groups; generally, an infestation suggests itself by the presence of mite activity on the under-side of plant leaves. Strong, healthy plants can usually hold their own against a few colonies of mites. But, bear in mind that in favorable conditions, mites can complete an entire life cycle in just one week. Really.\nSo, when all evidence points to the presence of Spider Mites, it’s time to take action. With moderate infestations, cultural controls can be quite successful in reducing and discouraging these mites. They like it dusty, so keep areas around plantings moist. A more direct method of controlling Spider Mites is the tried-and-true forceful blast of water on infested leaves and twigs.\nIf cultural controls fail or the infestation is severe, consider biological controls. Turns out Spider Mites have a number of natural enemies. The most significant are predatory mites in the Genus Phytoseiulus; common name Western Predatory Mite. These mighty mites are not much bigger than Spider Mites, but are extremely good at their job and once established tend to stick around as long as they have something to eat.\nPredatory Mites are generally available these days through most nurseries. But, if your nursery doesn’t sell them, don’t despair. The California Department of Pesticide Regulation has a list of “Suppliers of Beneficial Organisms in North America” available on their website here.\nHere in California, Rincon-Vitova Insectaries carries a number of Predatory Mites.\nLet it be said though, that when it comes to Spider Mites, an ounce of prevention is worthy of consideration. These critters, like most “pests,” are opportunists. So, keep your plants healthy, well-watered and free of insect infestations. It’s a good idea too, to routinely look for stippling and check the under-sides of leaves for evidence of Spider Mites, such as webbing or colonial aggregations.\nBut don’t let your guard down, because while you are waiting out the winter, so are Tetranychus, safely tucked into leaf litter somewhere in your garden.\nOne more thing: a much longer and more detailed version of the material shared in this feature can be found at the University of California’s Online Integrated Pest Management Website.']"	['<urn:uuid:35e7f537-afff-4178-9f2e-6fa7600e7371>', '<urn:uuid:0164876a-2f15-4576-b7c7-0fabbfb25423>']	open-ended	direct	short-search-query	similar-to-document	multi-aspect	expert	2025-05-13T01:50:22.828293	7	88	3285
33	Did Cheyenne and Haida tribes both use seasonal housing?	Yes, but in different ways. The Cheyenne moved between small mobile bands in late summer and large settlements during hunting season, while the Haida lived in permanent winter villages of large plank-built houses that could hold 20-50 people, with separate seasonal camps for food gathering.	"['David Graeber and David Wengrow write:\nStonehenge, it turns out, was only the latest in a very long sequence of ritual structures, erected in timber as well as stone, as people converged on the plain from remote corners of the British Isles, at significant times of year. Careful excavation has shown that many of these structures – now plausibly interpreted as monuments to the progenitors of powerful Neolithic dynasties – were dismantled just a few generations after their construction. Still more strikingly, this practice of erecting and dismantling grand monuments coincides with a period when the peoples of Britain, having adopted the Neolithic farming economy from continental Europe, appear to have turned their backs on at least one crucial aspect of it, abandoning cereal farming and reverting – around 3300 BC – to the collection of hazelnuts as a staple food source. Keeping their herds of cattle, on which they feasted seasonally at nearby Durrington Walls, the builders of Stonehenge seem likely to have been neither foragers nor farmers, but something in between. And if anything like a royal court did hold sway in the festive season, when they gathered in great numbers, then it could only have dissolved away for most of the year, when the same people scattered back out across the island.\nWhy are these seasonal variations important? Because they reveal that from the very beginning, human beings were self-consciously experimenting with different social possibilities. Anthropologists describe societies of this sort as possessing a ‘double morphology’. Marcel Mauss, writing in the early twentieth century, observed that the circumpolar Inuit, ‘and likewise many other societies . . . have two social structures, one in summer and one in winter, and that in parallel they have two systems of law and religion’. In the summer months, Inuit dispersed into small patriarchal bands in pursuit of freshwater fish, caribou, and reindeer, each under the authority of a single male elder. Property was possessively marked and patriarchs exercised coercive, sometimes even tyrannical power over their kin. But in the long winter months, when seals and walrus flocked to the Arctic shore, another social structure entirely took over as Inuit gathered together to build great meeting houses of wood, whale-rib, and stone. Within them, the virtues of equality, altruism, and collective life prevailed; wealth was shared; husbands and wives exchanged partners under the aegis of Sedna, the Goddess of the Seals.\nAnother example were the indigenous hunter-gatherers of Canada’s Northwest Coast, for whom winter – not summer – was the time when society crystallised into its most unequal form, and spectacularly so. Plank-built palaces sprang to life along the coastlines of British Columbia, with hereditary nobles holding court over commoners and slaves, and hosting the great banquets known as potlatch. Yet these aristocratic courts broke apart for the summer work of the fishing season, reverting to smaller clan formations, still ranked, but with an entirely different and less formal structure. In this case, people actually adopted different names in summer and winter, literally becoming someone else, depending on the time of year.\nPerhaps most striking, in terms of political reversals, were the seasonal practices of 19th-century tribal confederacies on the American Great Plains – sometime, or one-time farmers who had adopted a nomadic hunting life. In the late summer, small and highly mobile bands of Cheyenne and Lakota would congregate in large settlements to make logistical preparations for the buffalo hunt. At this most sensitive time of year they appointed a police force that exercised full coercive powers, including the right to imprison, whip, or fine any offender who endangered the proceedings. Yet as the anthropologist Robert Lowie observed, this ‘unequivocal authoritarianism’ operated on a strictly seasonal and temporary basis, giving way to more ‘anarchic’ forms of organisation once the hunting season – and the collective rituals that followed – were complete.\nScholarship does not always advance. Sometimes it slides backwards. A hundred years ago, most anthropologists understood that those who live mainly from wild resources were not, normally, restricted to tiny ‘bands.’ That idea is really a product of the 1960s, when Kalahari Bushmen and Mbuti Pygmies became the preferred image of primordial humanity for TV audiences and researchers alike. As a result we’ve seen a return of evolutionary stages, really not all that different from the tradition of the Scottish Enlightenment: this is what Fukuyama, for instance, is drawing on, when he writes of society evolving steadily from ‘bands’ to ‘tribes’ to ‘chiefdoms,’ then finally, the kind of complex and stratified ‘states’ we live in today – usually defined by their monopoly of ‘the legitimate use of coercive force.’ By this logic, however, the Cheyenne or Lakota would have had to be ‘evolving’ from bands directly to states roughly every November, and then ‘devolving’ back again come spring. Most anthropologists now recognise that these categories are hopelessly inadequate, yet nobody has proposed an alternative way of thinking about world history in the broadest terms.\nQuite independently, archaeological evidence suggests that in the highly seasonal environments of the last Ice Age, our remote ancestors were behaving in broadly similar ways: shifting back and forth between alternative social arrangements, permitting the rise of authoritarian structures during certain times of year, on the proviso that they could not last; on the understanding that no particular social order was ever fixed or immutable. Within the same population, one could live sometimes in what looks, from a distance, like a band, sometimes a tribe, and sometimes a society with many of the features we now identify with states. With such institutional flexibility comes the capacity to step outside the boundaries of any given social structure and reflect; to both make and unmake the political worlds we live in. If nothing else, this explains the ‘princes’ and ‘princesses’ of the last Ice Age, who appear to show up, in such magnificent isolation, like characters in some kind of fairy-tale or costume drama. Maybe they were almost literally so. If they reigned at all, then perhaps it was, like the kings and queens of Stonehenge, just for a season. [Continue reading…]', 'EYAK, TLINGIT, HAIDA & TSIMSHIAN\nWHO WE ARE\nThe Eyak, Tlingit, Haida and Tsimshian share a common and similar Northwest Coast Culture with important differences in language and clan system. Anthropologists use the term ""Northwest Coast Culture"" to define the Eyak, Tlingit, Haida and Tsimshian cultures, as well as that of other peoples indigenous to the Pacific coast, extending as far as northern Oregon. The Eyak, Tlingit, Haida and Tsimshian have a complex social system consisting of moieties, phratries and clans. Eyak, Tlingit and Haida divide themselves into moieties, while the Tsimshian divide into phratries. The region from the Copper River Delta to the Southeast Panhandle is a temperate rainforest with precipitation ranging from 112 inches per year to almost 200 inches per year. Here the people depended upon the ocean and rivers for their food and travel.\nAlthough these four groups are neighbors, their spoken languages were not mutually intelligible.\nEyak is a single language with only one living speaker\nThe Tlingit language has four main dialects: Northern, Southern, Inland and Gulf Coast with variations in accent from each village\nThe Haida people speak an isolate (unrelated to other) language, Haida, with three dialects: Skidegate and Masset in British Columbia, Canada and the Kaigani dialect of Alaska\nThe Tsimshian people speak another isolate language, Sm’algyax, which has four main dialects: Coast Tsimshian, Southern Tsimshian, Nisga’a, and Gitksan.\nEyak occupied the lands in the southeastern corner of Southcentral Alaska. Their territory runs along the Gulf of Alaska from the Copper River Delta to Icy Bay. Oral tradition tells us that the Eyak moved down from the interior of Alaska via the Copper River or over the Bering Glacier. Until the 18th century, the Eyak were more closely associated with their Athabascan neighbors to the north than the North Coast Cultures.\nTraditional Tlingit territory in Alaska includes the Southeast panhandle between Icy Bay in the north to the Dixon Entrance in the south. Tlingit people have also occupied the area to the east inside the Canadian border. This group is known as the “Inland Tlingit”. The Tlingits have occupied this territory, for a very long time. The western scientific date is of 10,000 years, while the Native version is “since time immemorial.”\nThe original homeland of the Haida people is the Queen Charlotte Islands in British Columbia, Canada. Prior to contact with Europeans, a group migrated north to the Prince of Wales Island area within Alaska. This group is known as the “Kaigani” or Alaska Haidas. Today, the Kaigani Haida live mainly in two villages, Kasaan and the consolidated village of Hydaburg.\nThe original homeland of the Tsimshian is between the Nass and Skeena Rivers in British Columbia, Canada, though at contact in Southeast Alaska’s Portland Canal area, there were villages at Hyder and Halibut Bay. Presently in Alaska, the Tsimshian live mainly on Annette Island, in (New) Metlakatla, Alaska in addition to settlements in Canada.\nHOUSE TYPES AND SETTLEMENTS:\nBefore and during early contact with the non-aboriginal population, the people built their homes from red cedar, spruce, and hemlock timber and planks. The houses, roofed with heavy cedar bark or spruce shingles, ranged in size from 35’-40’ x 50’-100’, with some Haida houses being 100’ x 75’. All houses had a central fire pit with a centrally located smoke hole. A plank shield frames the smoke hole in the roof. Generally, each house could hold 20-50 individuals with a village size between 300-500 people.\nThe people had winter villages along the banks of streams or along saltwater beaches for easy access to fish-producing streams. The location of winter villages gave protection from storms and enemies, drinking water and a place to land canoes. Houses always faced the water with the backs to the mountains or muskeg/swamps. Most villages had a single row of houses with the front of the house facing the water, but some had two or more rows of houses.\nEach local group of Eyak, Tlingit, Haida and Tsimshian had at least one permanent winter village with various seasonal camps close to food resources. The houses held 20-50 people, usually of one main clan. In each Eyak village, there were two potlatch houses, outside of which was a post topped with an Eagle or Raven. The dwelling houses were unmarked. The southern Tlingit had tall totem poles in the front of their houses. The Northern Tlingit houses had fewer and shorter frontal totem poles.\nTOOLS AND TECHNOLOGY:\nSoutheast Alaska’s environment is a temperate rain forest. This environment produces many tall and massive trees. Wood was the most important commodity for the people. Houses, totem poles, daily utensils, storage and cooking boxes, transportation, ceremonial objects, labrets (worn by high status women), clothes all were made of wood and wood products. The tools to make the wood into usable items were adzes, mauls, wedges, digging sticks and after contact, iron. To cut the wood people used chipped rocks, bones, beaver teeth, and shells. For light, the Eyak used a clamshell with seal oil or pitch, and a lump of fat for a wick in the sleeping room. Dried ooligan were used as candles. Also, hollowed sandstone with cotton grass fashioned into wicks.\nVarious means were used to harvest the seasonal salmon runs. Fish weirs (fences) and traps were placed in streams. Holding ponds were built in the inter-tidal region. Dip nets, hooks, harpoons and spears were also used to harvest salmon during the season. A specialized hook, shaped in a ‘V’ or ‘U’ form allowed the people to catch specific sized halibut.\nVarious baskets were used for cooking, storage, and for holding clams, berries, seaweed and water. The Tsimshian used baskets in the process of making ooligan (a special of smelt) oil. Basket weaving techniques were also used for mats, aprons, and hats. Mats woven of cedar bark were used as room dividers and floor mats, as well as to wrap the dead prior to burial or cremation. The inner cedar bark was pounded to make baby cradle padding, as well as clothing such as capes, skirts, shorts and blankets (shawls).\nThe Nass River Tsimshian are credited with originating the Chilkat weaving technique, which spread throughout the region.\nNo central government existed. Each village and each clan house resolved its differences through traditional customs and practices; no organized gatherings for discussions of national policy making took place. Decisions were made at the clan, village or house level, affecting clan members of an individual village or house. The people had a highly stratified society, consisting of high-ranking individuals/families, commoners and slaves. Unlike present day marriages, unions were arranged by family members. Slaves were usually captives from war raids on other villages.\nAll four groups had an exogamous (meaning they married outside of their own group), matrilineal clan system, which means that the children trace their lineage and names from their mother (not their father as in the European system). This means the children inherit all rights through the mother, including the use of the clan fishing, hunting and gathering land, the right to use specific clan crests as designs on totem poles, houses, clothing, and ceremonial regalia.\nThe Eyak were organized into two moieties, meaning their clan system is divided into two reciprocating halves or “one of two equal parts”. Their moieties, Raven and the Eagle, equated with the Tlingit Raven and Eagle/Wolf and with the Ahtna Crow and Sea Gull moieties. The names and stories of the clans in these moieties show relationships with the Tlingit and Ahtna.\nIn the Tlingit clan system, one moiety was known as Raven or Crow, the other moiety as Eagle or Wolf depending upon the time period. Each moiety contained many clans.\nThe Haida have two moieties, Eagle and Raven, and also have many clans under each moiety. The clans that fall under the Haida Eagle would fall under the Tlingit Raven. One example: Tlingit Raven/Frog; Haida Eagle/Frog. The Tsimshian had phratries (four groups instead of two groups). There are four crests: Killerwhale (Blackfish), Wolf, Raven and Eagle. However Fireweed, Wolf, Raven and Eagle are the Gitksan’s phratry names. The Tsimshian Killerwhale and Wolf are one side and their opposite side are the Eagle and Raven. However, the Gitksan have Fireweed and Wolf as their opposites to Eagle and Raven.\nAll four groups used animal fur, mountain goat wool, tanned skins and cedar bark for clothing. Hats made of spruce roots and cedar bark kept the rain off the head. After western trading, wool and cotton materials were common.\nThe main means of travel was by canoes. The people traveled regularly for seasonal activities such as subsistence and trading. The Haida canoes, made from a single cedar log up to 60 feet in length, were the most highly prized commodity.\nTRADITIONAL AND CONTEMPORARY:\nContemporary subsistence activities and traditional ceremonies are still essential and important to the Eyak, Tlingit, Haida and\nTsimshian people’s cultural identity.\nThe water supplied their main food. One of the most important fish is salmon. There are five species: King (chinook), silver (coho), red (sockeye), chum (dog salmon), pink (humpback or humpy). Steelhead, herring, herring eggs, and ooligans (eulachon) were also caught and eaten. Southeast waters produce an abundance of foods including a variety of sea mammals and deepwater fish. Some sea plants include seaweed (black, red), beach asparagus, and goose tongue. Some food resources are from plants (berries and shoots), and others from come from land mammals (moose, mountain goat, and deer).\nTraditionally, clans owned the salmon streams, halibut banks, berry patches, land for hunting, intertidal regions, and egg harvesting areas. As long as the area was used by the clan, they owned the area. The food was seasonal and therefore had to be preserved for the winter months and for early spring. The food was preserved by smoking in smokehouses or was dried, either by wind or sun. These subsistence patterns are still a crucial part of Southeast Alaska Native people’s cultural identity.\nThe Eyak, Tlingit, Haida and Tsimshian are known for a ceremony called the “potlatch” and feasts. Potlatches are formal ceremonies. Feasts, a less formal but similar event, are more common with the Haida, in which debt was paid to the opposite clan.\nHigh-ranking Eyak, Tlingit, Haida and Tsimshian clans and/or individuals were expected to give potlatches. However, a potlatch could be given by a commoner who could raise his position by doing so. Except in the Haida tradition, the host would not raise his personal status, but rather the status of his children. Potlatches were held for the following occasions: a funeral or memorial potlatch, whereby the dead are honored; the witness and validation of the payment of a debt, or naming an individual; the completion of a new house; the completion and naming of clan regalia; a wedding; the naming of a child; the erection of a totem pole; or to rid the host of a shame. Potlatches might last days and would include feasting, speeches, singing and dancing. Guests witness and validate the events and are paid with gifts during the ceremony. In potlatches, there would be a feast, however, a feast does not constitute a potlatch.\nRegalia worn at potlatches were the Chilkat and Raven’s Tail woven robes, painted tanned leather clothing, tunics, leggings, moccasins, ground squirrel robes, red cedar ropes, masks, rattles, and frontlets. Other items used at potlatches inducle drums, rattles, whistles, paddles, and staffs. Only clan regalia named and validated at a potlatch could be used for formal gatherings.\nThe Chilkat robes were made of mountain goat wool and cedar warps. The Chilkat weaving style is the only weaving that can create perfect circles. The Raven’s tail robe is made of mountain goat wool. Some of the headpieces had frontlets that would also have sea lion whiskers and ermine. After contact, robes were made of blankets, usually those obtained from the Hudson Bay trading company, adorned with glass beads and mother-of-pearl shells, along with dentalium and abalone shells.\n“A Tlingit myth tells that the people were\ninspired to carve totem poles after finding a carved log washed up on\nthe beach. The Haida tell of a master carver who created a house front\nand several poles overnight and then taught the villagers how to carve.\nTo understand totem poles, a deeper, more thorough knowledge of Native people and their history is necessary.\nThe Tlingit and Haida Indians are each divided into two matrilineal groups called moieties or phratries. These divisions are represented by the raven and eagle (wolves) in totem art. Within these moieties are smaller clans, whose members are more closely related. These clans are further subdivided into lineages or house groups, which is the fundamental social unit, tracing the matrilineal descent to a common ancestor.\nEarly Tlingit and Haida poles are often distinguishable by their layout. Haida figures interconnect and overlap more than Tlingit figures, which are isolated from each other and present a more rounded and sculptured apperarance.”\n|CONTINUED on PG 3|\nBelow are Links to Native American People/Tribes Pages']"	['<urn:uuid:d5fb4231-34e5-4bff-b127-0eb044989ab3>', '<urn:uuid:a4f594e1-102d-4772-878c-2ab553d5c8bd>']	factoid	with-premise	concise-and-natural	similar-to-document	comparison	novice	2025-05-13T01:50:22.828293	9	45	3177
34	How do different asset types get treated in personal bankruptcy?	In bankruptcy, different assets receive varying treatment. Retirement accounts that are ERISA-qualified and Social Security benefits are generally protected and not considered part of the bankruptcy estate. For other assets, some exemptions apply - you can keep portions of equity in vehicles, real estate, household goods, and family heirlooms, as well as clothing, pensions, and alimony. In Chapter 7, the trustee typically only sells high-value items where the sale effort is worth the return. In Chapter 13, you can keep property with loans, but must maintain payments and make up any past-due amounts, penalties, and interest - otherwise the property may be liquidated.	"['What is Bankruptcy?\nBankruptcy allows individuals or businesses (debtors) who owe others (creditors) more money than they\'re able to pay to either work out a plan to repay the money over time or completely eliminate (discharge) most of the bills.\nWhat\'s the difference between secured and unsecured debt?\nSecured debt is a claim that\'s secured by some type of property, either by an agreement or involuntarily with a court judgment or taxes. Creditors can generally claim the property that secures the debt in the event of bankruptcy. Unsecured debt is not tied to any type of property, and the creditor doesn\'t have a claim to their property. A mortgage is a secured debt on your property.\nBankruptcy Frequently Asked Questions\nWhich kind of bankruptcy should I file?\nConsumers typically file Chapter 13 bankruptcy, where repayment is made to creditors, or Chapter 7 where the debts are dismissed. Each chapter of bankruptcy spells out: what bills can be eliminated, how long payments can be stretched out, and what possessions you can keep. The type depends on your circumstances and if you have assets available to repay all or part of your debts. Bankruptcy laws can be tricky and involved, so determining if, when and which type of bankruptcy you need should be made with careful thought or the input of a bankruptcy lawyer.\nCan I change from one chapter of bankruptcy to another?\nGenerally, you can convert a case one time to any other chapter you\'re eligible for. The request to convert can be a simple one-sentence document. Watch out for issues, such as moving from a Chapter 13 to a Chapter 7, you\'ll need to review whether you have acquired items that are now be considered property of the estate under Chapter 7 that weren\'t part of the previous filing. Ask the trustee or a bankruptcy lawyer for additional issues.\nWhat happens at the 341 Creditor\'s Meeting?\nSee our Creditor Meeting Information Page for a detailed discussion of what to expect.\nDo you have to have a certain amount of debt to file?\nNo. However, some situations may not warrant filing for bankruptcy. If your financial situation is temporary, you may consider making arrangements with individual creditors for a change in payment amounts or a reduction in the total amount due. If you have little property or money, filing bankruptcy may not be necessary, as the creditor may not be able to collect the debt.\nWhat is a reaffirmation agreement?\nA reaffirmation agreement is a contract between a Creditor and Debtor stating that a debt will survive bankruptcy. This is usually done for a home mortgage or vehicle loan. They can be a good thing because when a debt is reaffirmed and paid on time, it will report well on your credit report. But, a reaffirmation agreement can be bad, because if you later default on a debt that you reaffirmed, you will still be liable for the debt and your bankruptcy will have no effect on the reaffirmed debt. This why a lot of people don\'t reaffirm mobile homes.\nWhat is a Discharge Order?\nAt the end of a successful bankruptcy the Court will enter an Order stating that all the debts eligible for discharge are eliminated and that creditors are prohibited from collecting on a discharged debts. The Discharge Order is the main reason you file bankruptcy. In order to receive your bankruptcy discharge and have your debts wiped out you must take a Debtor Education Course - which is separate from the first credit counseling course you take before you file. Like the Credit Counseling Class, you can take the Debtor Education course on-line by clicking on the following link Debtor Education\nHow does Bankruptcy effect my credit?\nThe bankruptcy will show on your credit report for 10 years, but potential creditors will also see that since you filed bankruptcy and no longer owe any debts, your ability to repay a new loan should be great. See the Establishing Credit After Bankruptcy page for information on how to get your credit score back on track within months of your bankruptcy.\nWhat happens if one spouse files for bankruptcy and not the other?\nIf one spouse files and the other doesn\'t, the one who doesn\'t file could be responsible for the debts. Review this carefully before filing.\nDoes my divorce decree protect me from creditors if my ex files for bankruptcy?\nNo. If you are a co-signor with your ex-spouse on a debt acquired while married, the creditor can require the entire payment of that debt from you even though the divorce decree assigns the full debt to your ex-spouse. Your divorce decree may address any recourse you may have against your ex-spouse should he default on the loan obligations.\nCan a co-signor of a loan be responsible for a debt if the other person has declared bankruptcy?\nYes. The lender can require the co-signor to make payments on a loan once the principal has declared bankruptcy on the credit. This makes it extremely important when considering co-signing a loan: Be ready, and able, to pay the loan in the event that the principal signor defaults.\nDo I have to file bankruptcy on all the accounts I owe, or can I keep some?\nYou must include all the debts you owe in your petition and schedules. You may opt to keep some debts by ""reaffirming"" the specific debt, but they still have to be listed in your bankruptcy.\nWill I lose my retirement accounts or payments from social security?\nGenerally, no. Retirement accounts that are ERISA-qualified aren\'t considered property of an estate and aren\'t taken into consideration as assets. Social Security benefits are protected from assignment or garnishment for debts in bankruptcy. Once paid, the benefits continue to be protected only as long as they can be identified as Social Security benefits. For example, money in a bank account where the ""only"" deposits into the account are direct deposits of Social Security benefits are identifiable and generally protected.\nHow often can you file for bankruptcy?\nChapter 7: Can be filed every 8 years from a previous chapter 7 filing or 6 years from a prior chapter 13 filing. Chapter 13: Can be filed 4 years from a prior Chapter 7 filing or 2 years from a prior Chapter 13 filing.', 'Even if you don’t owe a dime to a soul, it’s important for you to understand the difference between chapter 7 and chapter 13 bankruptcy .\nBecause somebody might owe you money and you better understand what happens if they declare the “Big B.”\nA loyal Pilgrim reader happens to be a very friendly and helpful attorney (yes…it is possible) and she’s agreed to shed some light on this otherwise confusing subject.\nHere’s Kimberly’s guest post. You can contact her on LinkedIn.\nBankruptcy is a gut-wrenching and emotional process, but as evidenced from recent statistics, is also an oft-used solution for debt problems. Bankruptcy is a means for one to shed debts in an orderly fashion that is fair to creditors so that the debtor may obtain a fresh start. Bankruptcy is far better than the original option, debtor’s prison, which was largely abandoned in the United States in 1833.\nThe bankruptcy process takes place in specialized courts within the greater federal court system and is overseen by a trustee from the Department of Justice. There are two chapters of the Bankruptcy Code which individuals use: chapters 7 and 13. In chapter 7, the trustee liquidates all assets to pay debts, and any remaining debt is erased (called a discharge). Some items are exempt from sale, such as clothing, pensions and alimony. A portion of the equity in vehicles, real estate, household goods and family heirlooms is also exempt. Practically speaking, the effort of selling often exceeds the return, so the trustee typically only sells high value items. Debtors who wish to use chapter 7 are subject to a monthly disposable income ceiling determined by a “means test,” otherwise they must use chapter 13.\nIn chapter 13, property is retained and a portion of debt is repaid over three to five years according to a plan. Monthly expenses allowed under the plan is a lifestyle greater than spartan living, but excludes spa days and vacations. While the debtor may keep property subject to loans, the debtor must afford the loan payments and also make up past-due payments, penalties and interest, lest the property be liquidated.\nCreditors are paid in a priority scheme, starting with tax authorities, domestic support and case administration costs. Lenders that retain title in financed property are paid either through a return of the property or through collecting loan payments. Finally, unsecured creditors are paid (e.g. credit card companies, medical providers, utilities and the underwater portion of a loan for which the secured property was returned). In a marriage, one or both persons may file for bankruptcy, but if only one files, joint debts are not discharged.\nIs there a difference between chapter 7 and chapter 13 in bankruptcy?\nAfter paying debts through a chapter 7 or 13, most remaining debts are discharged. Taxes, DUI-related debts and domestic support payments are not discharged, nor are debts acquired in bad faith, i.e. in anticipation of shedding the debt in bankruptcy. Student loans are rarely discharged. After the completion of the bankruptcy process, creditors of discharged debt can no longer attempt to collect. A bankruptcy filing is reported on a credit report for about seven years. While it is not impossible to obtain credit after a bankruptcy, credit is much more expensive. This is a little perverse because an individual fresh out of bankruptcy has fewer debts so is more likely to repay the lender than before the bankruptcy.\nThe Bankruptcy Code is exceedingly more complicated than described above. Because the process relies on a combination of bankruptcy, federal and state law, it is advisable to consult an attorney or reliable debt counselor before filing. Few attorneys will take a case pro bono because every client claims an inability to pay. Bankruptcy is an extremely emotional process because one must lay open their financial affairs in a public setting where the court requires copies of all bank and credit statements and pay stubs. While the result of filing is not life-shattering (credit is only necessary for a lease or loan), it does hamstring financial flexibility and high-level job prospects (unless you are Donald Drumpf or Dan Snyder).\nAll that said – when is bankruptcy a good option? As a last resort when there is no viable way of repayment such as illness, disability, divorce or job loss. Before filing, exhaust all options such as cutting expenses, increasing income, returning secured property, debt consolidation and negotiating with creditors. There is no one-size-fits-all answer to whether it is a good idea to file for bankruptcy, due to differing debt instruments, situations, and state laws. While these are big options to weigh, the worst action is inaction.\nThanks, Kimberly. This is a subject I (thankfully) know little about, yet it’s really important. So…Pilgrims…have you ever been through this process? What was it like? Have you had someone who owed you money declare bankruptcy? What happened to the money they owed you?']"	['<urn:uuid:95ccf79e-a713-4857-93d0-7afda815abba>', '<urn:uuid:ddacae1e-41eb-45b9-add7-bdc7b685b68f>']	open-ended	with-premise	concise-and-natural	distant-from-document	three-doc	expert	2025-05-13T01:50:22.828293	10	103	1871
35	How did the architectural design of the ancient tabernacle implement different levels of access through its curtains, and what was their spiritual purpose?	The tabernacle had three distinct curtains that created different levels of access: First, a curtain at the courtyard entrance that could be passed by any ritually pure Israelite bringing a sacrifice. Second, a curtain between the courtyard and Holy Place that only priests could cross. Third, an inner curtain between the Holy Place and Holy of Holies that only the High Priest could cross, and only on the Day of Atonement. This inner curtain was the finest and featured cherubim images, which symbolically restricted access to God's presence, similar to how cherubim guarded the Garden of Eden. The curtains thus served to create a graduated system of restricted access to God's presence.	"['by Doug Ward\nThe Gospel of Matthew records that at the time of Jesus\' death on the cross, ""the curtain of the temple was torn in two from top to bottom"" (Matt 27:51, NIV).\nThe tearing of the temple curtain, or ""veil,"" always has been viewed by Christians as symbolic and highly significant. However, Matthew does not pause in his narrative to discuss the meaning of this event. Neither do Mark or Luke, who also mention it (Mark 15:38; Luke 23:45).\nBecause the Gospels do not provide explicit interpretations of the curtain\'s rending, there has been room for plenty of speculation, and many possibilities have been proposed over the centuries.1 In this article I will survey some of the leading proposals, with the goal of describing as much as possible of what Matthew 27:51 has to teach us.\nTorn Body and Torn Tunic\nThe most familiar interpretation of the torn curtain is one that appears elsewhere in the New Testament, in the Epistle to the Hebrews. The author of Hebrews encourages his readers based on the implications of this event:\n""Therefore, brothers, since we have confidence to enter the Most Holy Place by the blood of Jesus, by a new and living way opened for us through the curtain, that is, his body, and since we have a great priest over the house of God, let us draw near to God with a sincere heart in full assurance of faith, ... ."" (Heb 10:19-22)\nThe author of the epistle identifies the torn curtain as the one at the entrance to the temple\'s Most Holy Place and sees the curtain as symbolic of Jesus\' torn body. According to this symbolism, the tearing of the curtain points to a key consequence of Jesus\' sacrificial death: Christians, no longer cut off from God, can come freely before God\'s throne of grace in heaven (Heb. 4:14-16).\nViewing the curtain as representing Jesus\' body is not the only possibility, though. Further symbolism is suggested by the wording of Matt 27:51. Scholar David Daube2 observes a connection between Matt 27:51 and 2 Kings 2:12, where the prophet Elisha rips apart his cloak in mourning when his mentor Elijah is taken away from him in a whirlwind. Daube notes that the Aramaic word for the Temple curtain can also denote a tunic, giving a linguistic basis for associating the curtain with a garment.\nA connection between Matt 27:51 and 2 Kings 2:12 makes sense in the context of Matt 27. Matthew relates that when Jesus quoted from Psalm 22:1 on the cross (vv. 45-46), bystanders thought he was calling for Elijah. Someone joked, ""Let\'s see if Elijah comes to save him"" (v. 49). In this context, the tearing of the curtain could be saying, ""Here is a prophet even greater than Elijah. Elijah\'s departure was mourned by the tearing of Elisha\'s cloak. But Jesus, who will soon depart to his Father in heaven, is mourned by the tearing of the very curtain of the holy temple.""\nDaube shows that additional meanings are suggested when we consider the ancient custom of tearing a garment as a sign of mourning. A rabbinic tradition based on 2 Kings 2:12 and 2 Samuel 1:11-12 says that it is appropriate to leave a torn garment unrepaired when it is ripped for certain special reasons. According to the Talmud (b. Mo\'ed Qatan 26a),\n""These tears on the garments are not to be sewn up again: he who makes a tear for his father or his mother, his master who taught him wisdom, a patriarch, a principal of the court, for having bad news, for having heard blasphemy, when a scroll of the Torah has been burned, for seeing the ruined cities of Judea, the holy house, or Jerusalem.""\nSeveral of the items in this list can be connected with the crucifixion. The torn temple curtain can be seen as mourning the death of a great teacher of the Torah who conveyed wisdom to his disciples. Since Jesus prophesied the coming destruction of Jerusalem and the temple, the tearing could also be a confirmation of that prophecy. One document from the early centuries of Christianity, the Clementine Recognitions, gives such an interpretation. Book 1, Chapter 41 of this document states that ""the veil of the temple was rent, as in lamentation for the destruction impending over the place.""\nDaube also mentions the possibility that the tearing of the curtain was an answer to the high priest Caiaphas, who tore his clothes in response to what he saw as blasphemy by Jesus (Matt 26:65-66). According to this interpretation, the torn curtain was responding, ""Here is the real blasphemy, that the Messiah was put to death.""\nSymbolism of the Curtains\nDaube\'s analysis is impressive, but it turns out that much more can be said about the message of Matt 27:51. More recently, Daniel M. Gurtner has carried out an in-depth study of this subject in his doctoral dissertation.\nthe curtains at the Jerusalem temple were patterned after those from Israel\'s\ntabernacle in the wilderness, Gurtner begins his investigation with a study of\nthe tabernacle curtains, first described in the book of Exodus.3\nThere were three such curtains:\n1. One curtain was placed at the entrance to the courtyard of the tabernacle (Exod 27:16-17). The courtyard could be entered by any Israelite who was in a state of ritual purity and brought a sacrifice.\n2. A second curtain separated the courtyard from the Holy Place (Exod 26:36-37). It could be crossed only by priests, not by ordinary Israelites.\n3. A third curtain stood between the Holy Place and the Holy of Holies (Exod 26:31-33). It could be crossed only by the High Priest, and only on the Day of Atonement.\nAll three of the curtains were carefully constructed from beautiful materials of the highest quality. The third, inner curtain was the finest of all. Sewn into it were pictures of cherubim, a detail of symbolic significance. Cherubim traditionally are guardians and protectors, going back to the Garden of Eden (Gen 3:24). As cherubim restricted access to the tree of life in Eden, the inner curtain restricted physical and visual access to the presence of God.\nDr. Gurtner notes that katapetasma, the Greek word for the curtain in Matt 27:51, is used in the Septuagint translation of the Hebrew Scriptures five times for the curtain at the courtyard entrance, twice for the curtain between the courtyard and the Holy Place, and thirty one times for the inner curtain. When the word appears in the Septuagint without any qualification, it always refers to the inner curtain. Taking into account this data and the symbolic importance of the inner curtain, Gurtner concurs with the traditional view that the curtain referred to in Matt 27:51 is the inner curtain.\nGurtner goes on to investigate the meanings attached to this curtain in Second Temple Judaism. He shows that the curtain came to be associated with the ""firmament"" of Gen 1:6. In this connection the curtain was seen as a barrier between heaven and earth, behind which were hidden divine secrets. The idea of temple curtain as firmament is based on Psalm 104:2 and Isa 40:22, which picture God spreading out the heavens like a curtain. In describing the curtain, the first-century historian Josephus wrote, ""On this tapestry was portrayed a panorama of the heavens, the signs of the Zodiac excepted"" (War 5:214/v.4).\nAccording to Gurtner\'s findings, the inner temple curtain served to restrict access to God\'s presence and to heavenly secrets. Presumably, the ripping apart of the curtain would indicate that the curtain could no longer carry out those functions. Therefore, the torn curtain may be proclaiming that the death of Jesus brings increased access to God\'s presence and revelation of heavenly secrets.\nHints from Matthew 27\nGurtner demonstrates that these insights are confirmed and extended when we take into account the additional signs that accompanied the rending of the curtain. In Matt 27:51-54, we read that at the time of the crucifixion (a) the earth shook; (b) rocks split; (c) tombs broke open; (d) saints were restored to life; and (e) Roman soldiers recognized Jesus as the Son of God.\nGurtner asserts that Israelites who witnessed these events would have been reminded of two passages from the prophets. One is Zechariah 14, where rocks split and saints are resurrected at the coming of the messianic age (Zech 14:4-5). So the signs accompanying Jesus\' death can be taken as a statement that the messianic age had begun.\nThe second scripture connected with these signs is Ezekiel 37, which pictures the earth shaking (v. 7) and graves opening (v. 12). Ezekiel 37 predicts a national resurrection of Israel in the messianic age, with the nation saved, cleansed from sin (v. 23) and living in the presence of God (vv. 24-28). The signs of Matt 27 are thus saying that the fulfillment of Ezekiel 37 is brought about by the work of Jesus on the cross. Verses earlier in Matthew\'s Gospel state that Jesus ""will save his people from their sins"" (Matt 1:21) and that his blood ""is poured out for many for the forgiveness of sins"" (Matt 26:28). These verses connect well with Ezek 37:23. The torn curtain promises increased access to God\'s presence, as pictured in Ezek 37:24-28.\nGurtner notes that other passages from Matthew support the idea that the torn curtain symbolizes the possibility of closer fellowship with God. For example, Matt 5:8 says that the pure in heart will ""see God"", and it is Jesus\' work on the cross that brings forgiveness of sins and thus purity of heart.\nMoreover, the signs in Matt 27 suggest that heavenly secrets are being revealed. Specifically, Matt 27:53 says that the resurrected saints appeared in ""the holy city"", a designation for Jerusalem previously used in Matt 4:5, where the devil calls into question Jesus\' identity as the Son of God. In Matt 27:54, a centurion who sees the signs accompanying the crucifixion confirms that Jesus is indeed the Son of God. He has been shown an important secret.\nThe tearing of the curtain, with its pictures of cherubim, may also predict the reopening of Eden. Rev 2:7 and 22:14 promise access to the Tree of Life for the saints.\nThe findings of Daube and Gurtner suggest that the torn temple curtain of Matt 27:51 has multiple meanings, corresponding to the manifold implications of Jesus\' death on the cross. The curtain is a garment, torn in mourning that a great prophet and teacher has died, and that Jerusalem and its Temple will soon be destroyed. It is sewn with pictures of cherubim that guard Eden and God\'s presence, so that its tearing indicates a reopening of Eden and an opportunity for closer fellowship with God. (Note that this aspect of the curtain\'s symbolism backs up the message of Heb 10.) It represents the heavenly firmament, so that its tearing announces the revelation of divine secrets. With the other signs of Matt 27 it announces the inauguration of the messianic age, bringing the restoration of Israel and resurrection of the saints.\nGenerally speaking, ""more is better"" in the world of biblical symbolism. Since biblical symbols teach spiritual truths, it is a good thing if a symbol points toward multiple truths. On the other hand, not all proposed meanings for a symbol are necessarily valid. A valid meaning must be supported by the text of scripture.\nIn the case of the torn curtain, I do not believe that all meanings that have been proposed over the centuries are valid. For example, I do not believe that the torn curtain necessarily announces the obsolescence of the sacrificial system. On the contrary, Gurtner (The Torn Veil, chapter 5) shows that in Matthew\'s Gospel, Jesus gives a positive portrayal of temple worship, although he strongly corrects those who are in charge of the temple. The early Jerusalem Christians were active participants in temple worship, as the book of Acts shows. Prophecy also suggests a future role for worship in a new temple (e.g., Ezek 40-48).\n1Dr. Daniel M. Gurtner compiles and classifies a number of these possibilities in the first chapter of his book, The Torn Veil: Matthew\'s Exposition of the Death of Jesus, Cambridge University Press, 2007.\n2The New Testament and Rabbinic Judaism, University of London, Athlone Press, 1956, pp. 23-26.\n3See The Torn Veil, chapters 2 and 3.\ntranslated from TEX by TTH,\nOn 03 Jul 2012, 17:58.']"	['<urn:uuid:69a9bfe5-0568-49b8-9c7d-70e5f4d94b4d>']	open-ended	direct	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-13T01:50:22.828293	23	112	2071
36	powder metal net shape benefits manufacturing safety risks	Net shape powder metal manufacturing offers benefits like zero waste production, reduced turnaround time, and lower production costs. However, it comes with safety risks including respiratory hazards from airborne powder particles, burn risks from hot curing ovens, and dangers from high-voltage equipment. Operators must wear protective gear like goggles and dust masks.	"['Many people working with small components have heard the term “near net shape” thrown around. This term refers to when a vendor can, with its primary process, manufacture a result close to the final size and shape your plans called for. That means the part requires minimal machining or other secondary processes afterward.\nBut what if you could drop the “almost” and create a truly net shape component with powdered metal? You can!\nMaybe you’ve already had some of the potential benefits pop in your head. Here are some of the biggest, along with a definition of what powder metal experts consider net shaping capability.\nWhat’s a Net Shape Part?\nWith powder metallurgy, you identify your powder of choice and your vendor pours it into the die, which is shaped as the mirror image of your design. Since you can control where you put the powder and how much, when it’s compacted it turns out exactly how you want the final version to look.\nThe part will still need sintering and, occasionally, some other fine tuning like drilling holes. Nonetheless, you can -- with minimal or no machining -- benefit from a process that goes directly from sintering/pressing to final use!\nOn to those benefits:\nAdvantages of Net Shaping Capability\nThe more raw resources your vendor needs, the more it’s going to affect your bill.\nIf an engineer starts with a bar of steel and machines a gear from it, the gear may only use 60% of the original bar. The rest is on the floor as waste (called turnings in the powder metal industry).\nPowder metallurgy can make you that same gear with zero waste (or at most a few percentage points).\nThe making of modern transmission carriers is a prime example of a wasteful process. Even with casting, your manufacturer has to throw away a lot of material to achieve the final result.\nNot with a precise powder metal process like sinter-brazing!\n2. Turnaround Time\nNot only are you wasting material with machining away all that excess material, you’re also wasting time. Powder metal’s net shaping ability can speed up your supply chain and lead times.\n3. Production & Labor Costs\nThe shorter the processing time, the less you’ll fork over for production and labor costs. Having your components practically market-ready after the first process cuts costly finishing from your manufacturing run. You won’t have to pay for someone to run all those secondary process, plus the machines to help him do it.\n4. Combined Shapes\nThere are certain geometries you can achieve with a single powder metal net-shaped part that would require multiple operations if you used machining instead.\nNeed a big gear on top and a small gear on the bottom. Powder metallurgy can handle that in a single process thanks to its shape-combining ability.\nWith powder metal you can add a hub or other features to your part -- it doesn’t have to be a simple round shape or a gear. Multipiece assemblies can be made as a single part without the need to weld, braze, or stake the additional parts. This same reduction in pieces is very apparent in soft magnetic composite parts, where you can often reduce the number of components from 1,300 pieces to under 10.\nWhile less dramatic, transmission carriers are again a good example of a product that can be streamlined with sinter bonding or brazing net-shaped parts. Your manufacturer can make the top and lower sections separately, then braze them together\nAt Horizon, for the tube assembly pictured above, the stainless tubing and two copper-infiltrated powdered metal parts are all brazed together. When we say infiltration, we mean melting copper into the part to fill the porosity.\nNew Possibilities With PM\nThere’s no need to start your project with that depressing thought of “How much material am I paying for that’s going to get thrown away?” Instead, with the right powder metal process, you can be thinking of the endless design and cost-cutting possibilities you’ve opened up.\nThere’s a reason 65-70% of the powder metal industry’s output is non-machined parts. It’s simply more cost-efficient. It’s also why nearly all of what Horizon produces is non-machined -- more than 90%!\nTo see the additional design benefits of powder metal, check out these resources:\n- What Is Soft Magnetic Composite?\n- Soft Magnetic Composite Vs. Lamination Steel: Uses & Limitations\n- Introducing 1P, 3P & 5P: Powder Metal Materials Optimized at Last', ""The Importance of OH&S and Work Safety in Powder Coating Equipment Manufacturing, Usage and MaintenanceMay 25, 2017\nAs an inherently nontoxic parts-finishing process, powder coating technology does not threaten the environment. But, and this is an important point, the equipment and materials do pose a threat to an operator. Just like any area that's reserved for a manufacturing operation, there are risk factors to address. Starting with the workshop premises, there are OH&S (Occupational Health and Safety) guidelines that exist to keep everyone and everything safe.\nDetermining The Risk Factors\nA safe working environment comes before all other considerations. In order to maintain that safety margin, the hazards associated with every stage of the process must be known in some detail. Again, this is essentially a work-congenial process, but it is a manufacturing technique, so a few hazards will always be in play. A hot curing oven, for example, will cause serious burns if it's mishandled. Likewise, the tiny powder granules are airborne, which means they could be breathed in until they cause respiratory problems. Finally, high voltages and corrosive stripping chemicals exist in different sections of the workshop, so only authorised personnel should be walking these floors.\nSatisfying Regulatory Concerns\nA few of the next regulatory dealings may sound like self-evident facts, but there's always one contractor out there who favours a short cut. The OH&S directives don't tolerate shortcuts, not in any form. Anyway, back to safeguards. All of those cleansing agents and caustic scrubbing chemicals need to be stored properly. At best, they could exude a vapour that burns a sensitive eye. At worst, however, they represent a fire hazard. Over at the processing cubicle, the equipment bay requires a sealing hood, a covering that stops the powder from leaking. Exhaust fans and powder reclamation systems take care of the airborne particles, but protective gear, especially goggles and a dust mask (www.worksafe.au), must be worn at all times during the application stage. Remember, these airborne particles are not usually toxic, but the fine dust will irritate an operator's respiratory airways.\nOnce out in the field, in the place the workpiece will function, it's certain to be dry and weather-resistant. However, the manufacturing equipment that produces this eco-friendly product does possess the potential to harm an inattentive operator. Additionally, the strong airflow and electrostatic charge used in the powder coating cubicle requires careful consideration, for there are commercial-grade air compressors and high-voltage appliances providing powder drive energy. Keep all of these discrete system parts in mind, and remember that all of this equipment requires maintenance if it's to work safely and efficiently.\nGP Industries Pty Ltd\n1 Regal Court,\nVermont South VIC 3133\nPhone: (03) 9802 1355\nFax: (03) 9802 6027\n20 Burgess Road,\nBayswater North VIC 3153\nPhone: (03) 9761 7676\nFax: (03) 9761 7671\nOptimized by NetwizardSEO.com.au\n- Powder Coating in Sheet Metal Processing\n- Powder Coating for Automotive for Best Finished Results\n- Is Powder Coating Better than Spray Paint?\n- Differences between Metal Plating and Powder Coating\n- Sustainable Powder Coating\n- Why Do You Need to Use High Temperature Masking Tapes When Powder Coating?\n- Benefits of the Powder Recovery System\n- Why You MUST Remove Moisture before Powder Coating\n- Electrocoat and Chemical Dipping Plants\n- Things to Look for When Buying Powder Coating Ovens\n- Process of Metal Pretreatment in Powder Coating\n- How to Judge a Perfect Powder Finish: What Should You Look For?\n- Dust Collectors and Cyclones in Relation to Powder Coating\n- Functions of Overhead Conveyors in Powder Coating Equipment\n- Keeping Corrosion Off Your Equipment: How Powder Coating Helps\n- The Role of Hot Ovens in the Powder Coating Process\n- Potential Cure Cycle Problem Areas in Powder Coating\n- Causes of Peeling and Pinholes in Powder Coating\n- Common Powder Coating Gun Problems and Solutions\n- Is It Possible to Apply Powder Coating Over Wet Paint?\n- What are the Differences between Electro Coating and Powder Coating?\n- Reliable Powder Coating Equipment Manufacturer and Supplier in Melbourne\n- Powdercoating Failures: What Causes Air Bubbles, Cracks and Peeling?\n- Is It Possible to Powder Coat Chrome Materials?\n- Pre-Treatment Process of Materials before Powder Coating\n- View all articles…""]"	['<urn:uuid:9519c61e-2182-4569-b4b6-35f129a01887>', '<urn:uuid:6f9a433e-1925-45b5-a20d-234eb911f05a>']	factoid	direct	short-search-query	similar-to-document	multi-aspect	expert	2025-05-13T01:50:22.828293	8	52	1444
37	How do HDMI zone features work in these modern AV systems?	The HDMI zone features work in two distinct ways across these systems. The TX-8390 has Zone 2 mode that can share video from HDMI inputs 1-3 to a second TV, allowing different content on each screen, while its Sub Out mode supports signals from all HDMI inputs to both displays simultaneously. Meanwhile, Yamaha's Advanced HDMI Zone Switching goes beyond standard HD video sharing between zones - it allows selection of all audio and video sources for playback in either zone, with an on-screen interface for easy content browsing and selection regardless of what's playing in the main zone.	"['Entrega em 5 a 15 dias\nAviso: Poucos items em stock!\nPrevisão de disponibilidade:\nPremium audio-video features with a hi-fi focus\nThis luxuriously appointed component fits a wealth of audio-video capabilities into robust stereo architecture, energizing TV entertainment, games, and music with 200 W + 200 W of speaker-driving power. The linage of the Onkyo Pure Hi-Fi family is reflected in the 5 mm-thick aluminum front panel and controls, custom power supply, and dual 10,000 μF capacitors. Quad-core SoC supports a multi-technology audio platform over 802.11ac 2x2 MIMO Wi-Fi® including Chromecast built-in, AirPlay 2, and DTS Play-Fi®. The receiver is Works with Sonos and Works with Alexa certified, and can be controlled by voice using Siri, Google Assistant, and Alexa-enabled devices. Popular music-streaming services are built in. Bluetooth® wireless technology, phono input, and Hi-Res Audio support including MQA expand your entertainment possibilities even further.\nVIDEO & AUDIO SUPPORT\n*1 FlareConnect is a proprietary network protocol that shares select audio sources between supported components. Please visit the Onkyo website for product compatibility information. *2 Availability of services varies with region and services may require a paid subscription. *3 Future firmware update required. *4 Some countries or regions have regulations that affect wireless signal strength and the use of Wi-Fi channels. *5 When playing MQA files, irrespective of the setting of the Direct function, the Direct function is automatically enabled at all times. *6 DSD playback over the wireless home network cannot be guaranteed. Supported sampling rates may vary depending on the network environment. *7 Available free at the App for iPhone and iPad, and on Google Play store for Android devices. Please check device and OS requirements before installation. *8 Requires a Sonos Connect (sold separately). *9 Voice control requires a device featuring the Google Assistant. *10 Voice control requires a device supporting Siri. *11 HDMI Zone 2 Out mode can transmit the same or different A/V signals simultaneously from MAIN OUT and Sub/Zone 2 Out. Input signals are limited to HDMI inputs 1–3. HDMI Sub-Out mode transmits the same A/V signal from any HDMI input to both displays simultaneously via MAIN OUT and Sub/Zone 2 Out. *12 In Zone 2 mode, HDMI audio is available via HDMI inputs 1–3. SPDIF and HDMI support PCM signals only. Simultaneous playback of multiple audio sources is enabled.\nConnect your sources to sublime sound\nCrafted in exacting detail to tempt hi-fi enthusiasts, the TX-8390 has connections to amplify all forms of TV-based entertainment, music, and audio sources. Inputs include HDMI®, analog and SPDIF audio, phono, Wi-Fi®, Bluetooth® wireless technology, and USB audio. A companion smartphone app gathers multi-room audio, streaming service management, and playback controls into one simple interface. GUI with transparent OSD simplifies setup and operation.\nDynamic Audio Amplification\nDAA is our original amplification system. It’s been refined over decades to reproduce the source as-is while freeing the emotion in music. Compelling sound is achieved by tuning each custom part by ear, so the amp not only measures well, but sounds amazing too. Fast dynamics, wide frequency response, and an earth-shaking 200 W + 200 W of analog power are realized with a high-current drive and original amp topology. High current improves speaker control, extending driver travel to articulate the entire sound-wave while tracking each note with absolute precision.\nOriginal custom-built components\nParts such as the High-Current Low-Noise Power Transformer and 10,000 μF high-current smoothing capacitors are fabricated to Onkyo’s exclusive specification. Two transistors on the voltage-amplification stage of each power amp circuitry boosts current for deep, powerful bass, while the non-phase-shift amp topology focuses sound through layers of finely resolved detail. And the extruded aluminum heat sink, which has heat-dissipating anodized coating, helps suppress vibration together with the 5 mm-thick aluminum front panel. This material is complemented by aluminum controls with a firm, fine actuation.\nBuilt to limit noise\nA number of measures contribute to excellent S/N performance. HDMI board features short signal-paths and well-finished grounds to assure clean potential. The SoC is isolated to reduce interference on analog signals. VLSC™ output-filter circuitry, meanwhile, erases ultra-high-frequency pulse-modulation noise. The result is clearer sound, improved instrument separation, and a large, airy soundstage.\nPersonalized listening with My Input\nMy Input front-panel selector gives easy access to any four inputs you choose. Save your desired start-up volume, listening mode, and tone settings to each so your audio starts playing exactly how you like it in seconds.\nHi-Res Audio in PCM, MQA, or DSD formats\nD/A conversion by AKM supports Hi-Res Audio playback up to 384 kHz/32-bit as well as DSD256, DSD128, and DSD64. The receiver also includes MQA technology, which enables you to play back MQA audio files and streams, delivering the sound of the original master recording. Albums in MQA can be streamed from supported online services or downloaded to USB memory or PC/NAS and played back via the TX-8390.\nNote: DSD is converted to PCM. When playing MQA files, irrespective of the setting of the Direct function, the Direct function is automatically enabled at all times.\nEnjoy your choice of multi-room audio platform\nThe TX-8390 is the heart of your home entertainment. Streaming content from Amazon Music, Spotify®, TIDAL, Deezer, and TuneIn can be shared to the TX-8390 and other supported speakers as part of a multi-room system via Works with Sonos, Chromecast built-in, AirPlay 2, DTS Play-Fi®, and FlareConnect™. Alternatively, you can bring a world of high-quality digital radio to your living space with built-in DAB+/FM radio with station presets for instant enjoyment.\nChromecast built-in with the Google Assistant\nStream any music from your smartphone, laptop, or PC to the receiver with ease. Control playback with Chromecast-enabled apps you know and love from your Android™ phone or tablet, Chromebook, Windows® PC, or iPhone, iPad, or Mac. If you have a device with the Google Assistant, you can find, play, and control music through this and other supported components just by using your voice.\nWorks with Alexa\nAlexa lets you use your voice to control TX-8390 by directing your requests through an Alexa-enabled device. Just ask your Alexa-enabled device, such as an Amazon Echo, to play, pause, and skip titles or control the volume. You can enjoy music playback via Amazon Music and make selections by song title, artist name, release year, or genre.\nNote: Requires a future firmware update.\nWorks with Sonos\nThe TX-8390 can fit seamlessly with your Sonos Home Sound System: just pair it with a Sonos Connect. The receiver wakes, changes inputs, and plays at the desired volume on command from the Sonos app.\nNote: Sonos Connect sold separately. Sonos app is available free for iPad, iPhone, and Android at the App Store and Google Play.\nMusic by voice with AirPlay 2 and Siri\nAirPlay is an Apple technology designed to control home audio systems and speakers in any room — with a tap or by just asking Siri — right from iPhone, iPad, HomePod, or Apple TV.\nQuad-core SoC supports 802.11ac Wi-Fi®\nA quad-core SoC (System on a Chip) processes multiple tasks at once and evolves network functions with support for the high-speed 802.11ac 2x2 MIMO 5 GHz/2.4 GHz Wi-Fi®.\nNote: Some countries or regions have regulations that affect wireless signal strength and the use of Wi-Fi channels. Performance will vary depending on environment.\nAccuEQ Stereo with Subwoofer EQ\nThis is the first Onkyo hi-fi receiver to benefit from AccuEQ room-acoustic calibration, a technology developed for our multichannel A/V receivers. AccuEQ creates a harmonious sound-field even if your speakers aren’t optimally placed. After detecting speaker size and distance from a measurement position and setting sound-pressure levels, the system selects a subwoofer crossover and applies EQ. Enjoy the ideal listening environment akin to a treated audio listening room.\nHDMI Sub/Zone Out modes\nThe second HDMI output has two modes. Zone 2 mode shares video from players connected to the receiver to a second TV and you can watch the same or different content on either screen. In this mode, the sub display can access video from HMDI inputs 1–3 only. Sub Out mode is ideal for projector connection, as it supports signals from all HDMI inputs. Sub Out can play a single source to either or both displays simultaneously.\nSpeaker A/B Drive\nSpeaker A/B Drive lets you connect two pairs of speakers at once. Switch between the speakers you prefer for hi-fi music listening and those for general entertainment. Or place speakers in a different area and switch playback to that room (or both). Alternatively, speaker terminals can be used to bi-wire compatible loudspeakers for potential gains in mid- and high-range sound.\n1 099,00 € 1 499,00 €\n1 099,00 € 1 499,00 €\n1 099,00 € 1 499,00 €\n1 699,00 €\n399,00 € 529,00 €\n1 099,00 €\n129,00 € 199,00 €\n199,00 € 299,00 €\n149,00 € 199,00 €\n399,00 € 599,00 €\n249,00 € 299,00 €\n299,00 € 399,00 €\n349,00 € 499,00 €', ""DTS:X™ is the next generation object-based, multi-dimensional audio technology from DTS.\nUnbound from channels, DTS:X conveys the fluid movement of sound to create an incredibly rich, realistic and immersive soundscape - in front of, behind, beside and above the audience - more accurately than ever before. The combination of DTS:X and Yamaha AV receivers will fill the room with multidimensional sound that makes you feel as if you are right in the middle of the story unfolding on the screen.\n*DTS:X™ playback capability will be available via future firmware update.\nEnter a new world of sound with Dolby Atmos®. It transports you from an ordinary moment into an extraordinary experience with captivating, multidimensional sound that fills your room with amazing richness and depth. Music, people, and objects come alive in breathtaking detail and flow in precise choreography all around you, making you feel like you are truly there. The combination of Dolby Atmos and Yamaha AV receivers will fill the room with multidimensional sound that makes you feel as if you are right in the middle of the story unfolding on the screen.\nYamaha provide multiple placement patterns for presence speakers that support Dolby Atmos, creating a sound field that’s ideal for your setup. Any layout can be appropriately reproduced, including the three-dimensional space of CINEMA DSP as well as Dolby Atmos.\nFurthermore YPAO R.S.C. which optimises the listening environment and fundamental high quality audio design takes full advantage of the detailed spatial localisation capability of Dolby Atmos.\nThe combination of Dolby Atmos and Yamaha AV receivers will fill the room with multidimensional sound that makes you feel as if you are right in the middle of the story unfolding on the screen.\nThe CX-A5100 is our flagship AV preamp, featuring the latest versions of 3D surround formats, advanced network functions such as WiFi and Bluetooth® compatibility, and full 4K support with HDCP2.2 compatible HDMI for the 4K era. In combination with the MX-A5000 power amplifier, you can enjoy not only a premier 3D sound field CINEMA DSP HD3 11.2channel full-spec reproduction but also new dimensions of surround sound as found in the newest movie theatres — in your own home.\nThe CX-A5100 supports the latest surround sound playback formats such as Dolby Atmos and DTS:X. In addition to conventional channel-based audio, it is possible to create a 3D space in which separate acoustic elements can move freely, giving a sensation of the motion of “objects” above the viewer’s head that fully realises the filmmaker’s intentions. What’s more, the revamped CINEMA DSP HD3 features newly developed signal processing algorithms to increase their appeal even further. With three sets of high performance processors for CINEMA DSP, it is possible to maximise the theatre sound effect, accurately reproducing a new dimension of realism for a sound field with a rich sense of presence unlike any system you’ve ever experienced. And by supplementing the limited number of speakers in a home system with CINEMA DSP to create the effect of a movie theatre space with alarge number of speakers, you can experience a realistic cinema sound field with the sense of truly being immersed in a movie scene.\nThe broad array of surround sound programmes, including 10 featured in the flagship Z11 receiver, features six Movie choices, including Spectacle for movies with strong visual and audio impact, Sci-Fi for SFX movies, Adventure to emphasise the sound of action movies, and Drama. Seven Entertainment programmes match the audio characteristics of sources such as sports, music videos, action games and roleplaying games. Compatibility with the Dolby Atmos and DTS:X sound formats means you hear the full potential of every movie and music source\nAll channels use ultra high performance ESS ES9016 DACs, which provide 192kHz/32-bit compatible superior SN ratio and dynamic range, ensuring faithful reproduction from Blu-ray and other players, as well as from high resolution sound sources input through networks. Matched to the design of the DAC circuit, which achieves stable ground potential (DAC on Pure Ground), they provide high precision D/A conversion. A new Volume IC realises low noise and superior sound orientation, and a superior low jitter clock circuit is used for clear and vivid network audio. In addition, the internal design separates the power supplies to the analogue circuit boards, eliminating high frequency noise interference from the digital circuits. The shielded power supplies restrict noise radiation and the large power transformer minimises vibration.\nYPAO analyses room acoustics and performs speaker angle measurements, then calibrates audio parameters to achieve the best sound atany of several listening positions. The height of the presence speakers is also measured, to optimise the 3D sound field. R.S.C. (Reflected Sound Control) corrects early reflections for studio-quality sound. YPAO also uses 64-bit EQ Calculation for realising the most natural room acoustics possible.YPAO 3D provides automatic sound parameter optimisation that maximises the 3D sound field effectiveness of CINEMA DSPHD3 as well as Dolby Atmos.\nThe AVENTAGE line of high-performance AV receivers is based on the audio design concept of providing a massive, full-bodied sound for movie sound effects and the accurate reproduction of music sources. By expertly harmonising traditional and advanced technologies, every factor that affects sound quality, from materials and parts to construction, layout, vibration damping (unique foot) and “fine-tuning” the sound, is handled with no other thought than to achieve the best possible audio quality. As a result, every AVENTAGE model has the ability to reproduce the most subtle details of high-definition sound, so that listeners can enjoy a truly high-class sound studio experience at home.\nAs part of the no-compromise design policy, Yamaha created an advanced chassis with strong rigidity. Chassis stiffness is enhanced by an H-shaped cross frame that boosts mechanical strength, by adopting aluminium side panels that increase the stiffness of the housing, and by a three-ply structure with independent top cover and side panels. Any external vibration from the rack or other sources is damped by heavy insulators. The A.R.T (Anti-Resonance Technology) Wedge in the centre of the bottom cover acts as an additional vibration countermeasure and firmly supports the internal circuits and delicate parts. In addition, this model has a double bottom chassis and rigid bottom frame to further enhance chassis rigidity and reduce the transmission of vibration produced by the large power supply and other internal components.\nElectrical noise may be generated due to connection with other AV components and even to the connection between them, as well as from other sources of external noise. To ensure that the CX-A5100 is not affected by this distortion, it uses balanced connections that are highly noise resistant—the same type generally used in pro audio equipment. Even the RCA unbalanced connection uses a ground sensing transmission method that achieves simple balanced transmission. Even when each channel is used independently, the impact of noise flowing between the preamp and power amp is removed, minimising sound quality deterioration due to the connection. XLR terminals allow use of the long cables that may be needed to connect a subwoofer. The CX-A5100 also allows balanced audio input connection to high grade source components such as CD players.\nThis AV receiver is equipped with Bluetooth functionality to let you enjoy easy wireless music playback from smartphones and other devices. Yamaha Compressed Music Enhancer is now optimised for Bluetooth audio transmission to ensure that your music will have vivid, lively sound quality even during wireless playback.\nThis AV receiver completely supports with the latest HDMI standards. Thanks to transmission of 4K video at 60 frames per second pass-through, you can fully enjoy the high definition video quality of 4K without degradation. It also adheres to the HDCP2.2 copyright protection standard for 4K video transmission, and supports HDR (High Dynamic Range) Video which provide enhanced picture quality by simultaneously enabling greater detail for both the dark and bright parts of an image.\nFurthermore it supports wider color gamut of BT.2020 pass-thru.\n*Firmware update is required to enable HDR, and Firmware update schedule is to be decided.\n*Firmware update is required to enable HDR, and Firmware update schedule is to be decided.\nThe 21:9 aspect ratio support is designed to show films recorded in the Cinema Scope format. When these films are viewed in the usual 16:9 ratio, you see black bars at the top and bottom of the screen; 21:9 eliminates these bars. By supporting 21:9 resolution, this model will be able to pass it through so that movies and games feel much more immersive.\n*This feature is not supported with some PC monitors with specific IT specification design.\nMusicCast is a new revolution in network audio, use all your MusicCast products together or separately, it’s completely up to you. Control it, all from one app, designed to be intuitive, quick and simple to use. Use a soundbar, a wireless speaker, an AV Receiver, HiFi audio whichever suits you best, mix and match then expand your MusicCast system as time goes on. All new from Yamaha, the MusicCast system brings everything to everywhere for everyone.\nMusicCast employs a high performance wireless network to deliver music and audio enjoyment. It can stream digital music content from your smartphone, PC or NAS to other MusicCast devices in your home. It can also share the music from external devices such as a TV or BD player connected to the CX-A5100. Audio content from Bluetooth-connected smartphones or tablets can also be streamed to MusicCast devices in multiple rooms.\nThe CX-A5100 is equipped with the latest Bluetooth technology, making wireless operation more convenient than ever. You can stream music from the CX-A5100 to Bluetooth headphones for private listening or to Bluetooth speakers.\nWi-Fi Built-in capability allows wireless connection with your household wireless router, greatly simplifying system connections to enjoy network audio and music streaming services. If no Wi-Fi router is available, the unique Wireless Direct feature not only allows you to stream music directly from your smartphone or tablet via AV Controller App's Music Play feature, iOS's AirPlay etc, but also control your receiver using the AV Controller app\nHi-bit high-sampling extension up to 96 kHz / 24-bit can be applied to lossless 44.1 / 48 kHz content such as from a CD (2-channel PCM) or a FLAC file for further heightening of the musicality in the original content.\nThis AV receiver provides a variety of network functions that enable you to access more sources and also enhance operation. You can connect the receiver to your home network or internet to enjoy Internet Radio, Spotify*, Pandora®* or music stored on a NAS and home PC. The AV Controller app (from iTunes App Store or Google play) lets you control various functions from your iPod, iPhone, iPad or Android phones / tablets.\n*Music service availability varies by region.\nThis AV receiver lets you use the Yamaha AV Controller app that is downloadable from the iTunes App Store or Google Play to control power on / off and volume, select input and DSP modes and operate other functions from an iPhone or Android devices. You can also use in as many as 23* different languages and customise the interface by hiding unused icons and renaming functions. A tablet version is also available.\n*As of spring 2014\nThis AV receiver is equipped with a variety of sound programmes that utilise Yamaha's original DSP technology. They allow you to easily create sound fields like actual movie theaters or concert halls in your room and enjoy natural stereoscopic sound fields. Now you can use the AV Controller app to adjust DSP parameters to your preference to match the type of music / movie or the mood you want to achieve. There are two modes, Basic and Advanced, that you can choose according to the type of adjustments you want to do.\nThe AV Controller app is extremely useful for controlling various functions in multi-zone installations. Zone selection is easily done by choosing zone icons, which can be changed (bedroom, kitchen, etc.). You can control power on/off, input selection and the volume level in each zone, and also rename the zones. The app also shows when the Party mode is being used, and allows volume control of the Party function.\nThis AV receiver supports AirPlay, which means they can accept wireless music streaming from iPod touch, iPhone or iPad, as well as from iTunes on Macs or PCs. This makes it easy to enjoy music from your mobile devices or computer on your home theater system. You can use view metadata such as song title, artist name as well as album art* via AV receiver's on-screen display.\n*Some models don't support album art display.\nWith the Spotify app on your smartphone, you've got instant access to millions of songs. And now you can stream those songs to your Yamaha system by using Spotify Connect. Just hit play to start streaming music. What's more, when you've been listening on your smartphone outside and come inside, the song immediately streams to your AVR—like magic, you enjoy uninterrupted music. You can also personalise playlists and receive phone calls while listening to music.\n*The Spotify app and premium account are required. Visit spotify.com for more details.\nTry Spotify Premium for free on your Yamaha Home Entertainment System for 30 days.\n*Spotify service availability depends on regions.\nA USB port on the front panel allows convenient connection of an iPod / iPhone, which also charges when connected. Because the digital signal from the iPod / iPhone is transmitted directly to the AV receiver, there is no signal loss or interference, so you enjoy the best possible sound quality. In addition, you can use the receiver’s remote control unit to operate the iPod / iPhone music playback functions.\nMany live and classical albums have no gaps in the music. Gapless playback ensures that there are no pauses between audio files. This provides playback with no interruptions, the way it was meant to be heard.\n* Compatible with WAV, FLAC and ALAC file formats, and input from USB / PC / NAS.\nAV Setup Guide is an app that makes it much easier to perform receiver setup, and also assists you with cable connections between the AV receiver and source devices. It guides you through various settings such as speaker connections, TV and source device connections and power amp assignment. System illustrations and actual AV receiver images help you understand how to make the connections between devices, for much quicker system setup. It is available in multiple languages. Designed for iOS and Android tablet.\nYamaha’s high-end video projector engineering expertise has produced various advanced processing techniques that are applied to this AV receiver. These include edge adaptive deinterlacing to smooth out jaggy noise, motion adaptive deinterlacing to detect moving or still images for precise pixel-by-pixel processing and multi-cadence detection including 3-2 pull-down. Proper processing makes viewing enjoyment complete no matter what video source or content.\nYamaha’ s latest Graphical User Interface has a high resolution display with clear, easy-to-use menus and also includes a selectable Status Bar that shows input source, volume level, DSP mode and audio format. The GUI provides a choice of eight languages: English, French, German, Spanish, Italian, Russian, Japanese and Chinese, and can be displayed over both normal and 3D pictures.\nThe SCENE PLUS function simplifies operation by providing one touch power-on along with selection of the desired source and the appropriate DSP programmes. SCENE PLUS offers a choice of 12 SCENE selections, four of which can be assigned to the second zone in a multi-zone system. SCENE PLUS can be selected from the front panel, remote control, GUI and even from the AV Controller app.\nHuman ears have less sensitivity to high and low frequencies, especially at lower volumes. YPAO Volume applies loudness EQ correction to automatically adjust high and low frequency levels as volume changes. Using the YPAO measurement results, EQ correction is optimised to your system settings and listening environment.\nThe Virtual Presence Speaker function makes full use of centre and surround speakers to create virtual presence speakers. Enjoy CINEMA DSP 3D Mode surround sound even in environments where speaker installation is limited. In addition, This model also features a Virtual Surround Back Speaker function. Even without using surround back speakers, you can experience more natural sound from behind you.\nEven when it is impossible to install surround speakers behind the listening position, Virtual CINEMA DSP reproduces virtual 7-channel surround sound filled with realism, from only two front speakers. The Virtual CINEMA FRONT feature lets you place two surround speakers and a centre speaker at the front to enjoy virtual 7-channel surround sound with even higher quality and resolution, as well as superior rear virtual sound localisation. Adding two additional front presence speakers provides a three-dimensional sound field that gives you a feeling of its height and depth and of the vertical movement of the sound. You get more flexibility to arrange your speakers inside the room, along with easy enjoyment of high quality surround sound.\nWhen music is encoded into a digitally compressed format like MP3, the frequency response suffers. Yamaha’s Compressed Music Enhancer employs sophisticated digital signal processing using exclusive algorithms to restore what was lost, so the music always sounds the way it should.\nWhile standard HDMI zone switching can only send HD video programmes to the main and second zones, Yamaha’s Advanced HDMI Zone Switching adds the capability to choose from all audio and video sources for playback in either zone. An on-screen graphical user interface makes it easy to browse and select content to enjoy from the second zone no matter what is being played in the main zone.\nThe CX-A5100 provides two Trigger Out jacks that enable control of connected component functions such as power on/off and input selection. The MX-A5000 or another amplifier or subwoofer with a Trigger In jack can be connected to allow use of the convenient Trigger function.""]"	['<urn:uuid:13b69608-bc46-4d37-b06b-17a00dbdf782>', '<urn:uuid:74fd438c-83b6-4561-8c3e-2045532ecae3>']	open-ended	with-premise	concise-and-natural	similar-to-document	multi-aspect	expert	2025-05-13T01:50:22.828293	11	98	4445
38	evergreen plants winter protection methods and what causes them to die	Evergreen plants are especially vulnerable to winter death because they don't drop their leaves. They can die from desiccation when they lose water through transpiration while unable to replace it from frozen ground. To protect evergreens, several methods can be used: 1) water well before ground freezes, 2) use anti-desiccants to reduce moisture loss from leaves (except on 'waxy' blue conifers), 3) erect screens on windward and south sides of plants, 4) ensure they're covered with snow, and 5) consider moving them to sites more protected from winter sun and wind. It's also crucial to keep plants healthy through summer for better winter survival.	"['You’ve removed late-autumn weeds, layered on the mulch, pruned appropriately, possibly even covered or wrapped your plants – so why do some still die in the winter, despite all your well-meaning efforts?\nMany plants die during winter because they dry out, or desiccate. As temperatures drop, the ground freezes and plant roots cannot take water from the soil, no matter how much snow may fall. This causes the plant to use stored water from the leaves and stems as part of the transpiration process, during which water exits the plant through the leaves. If the sun is shining or the wind is blowing, transpiration increases and more water exits the leaves. If no water is available and transpiration continues, the plant will soon die. Because evergreen plants do not drop their leaves, they are especially susceptible to this death.\nHow can you help your plants stay well-hydrated through the frozen drought of winter? The first step is to remember healthy plants in the summer survive the hardships of winter far better than sickly or stressed plants. Through the spring, summer and fall, you should always be on the lookout for signs of pests, diseases and damage, and take all necessary steps to keep your plants thriving.\nSecond, be sure to water well even when temperatures begin dropping below freezing. Later, if the ground thaws, water before the ground refreezes. Water slowly to provide a deep drink without waterlogging the roots, however, so they are not damaged by ice.\nThe third step is to use an anti-desiccant, also called an anti-transpirant, to reduce the moisture loss from the leaves and needles. Because broadleaf evergreens such as boxwood, aucuba, holly, rhododendron, many laurels, Japanese skimmia and leucothoe do not drop their leaves, they are especially vulnerable to winter death. Using a product such as Wilt-Pruf to reduce transpiration by protecting the pores will save many broadleaf evergreens.\nWhen using any horticultural product, be sure to check the label and follow all instructions properly. Some conifers such as cedar, cypress, juniper and pine may benefit from these products. However, be sure to read the instructions to prevent burning specific conifers. Also, do not use on “waxy” blue conifers, such as blue spruce, which already have an oily protective film on the nettles.\nHere are a few reminders to get the best protection from an anti-desiccant:\n- Plan to apply when day temperatures begin dropping below 50⁰ Fahrenheit. Apply when temperatures are above freezing on a dry day with no rain or snow anticipated within 24 hours. This allows the product to thoroughly dry. Spraying in freezing temperatures will cause plant damage.\n- Do not spray conifers until thoroughly dormant, generally in late winter. This prevents trapping moisture in the needles which could burst when frozen.\n- Generously apply to dry leaves and needles. Don’t forget the undersides. Spray from several angles to ensure complete coverage.\n- Because the anti-desiccant will break down in light and warmth, reapply in late winter on a dry day when temperatures are above freezing for at least 24 hours.\nBeyond Winter Drought\nOther than protecting your landscape evergreens from winter drought, there are other uses for anti-desiccants. Many gardeners use it to protect newly transplanted shrubs from drying winds and sunshine as they settle in. It also provides protection to tender bulbs going into storage. A quick spray in early winter protects rose canes and hydrangea stems. Spraying onto live or cut Christmas trees and carved pumpkins slows the drying process, making them last longer for greater holiday enjoyment.\nTo answer your questions, or to choose the best product for your landscape plants, come in to discuss anti-desiccants with one of our friendly and knowledgeable staff members. Together, we can reduce the number of plants you lose to the dryness of winter and keep your garden beautiful and healthy.', ""PROTECTING TREES AND SHRUBS FROM COLD\nDr. Leonard Perry, Extension Professor\nUniversity of Vermont\nCold damage can injure plants through sun scald, dieback, root injury, and frost heaving. A few cultural practices in fall can help prevent such damage from occurring.\nSun scald is caused by the bark heating up on cold winter days, then chilling rapidly when the sun goes down or is blocked such as from trees and clouds. The heating causes the growing tissue in the bark, near the surface, to become active. The sudden drop in temperature then kills this tissue. The result is sun scald, or sunken, elongated, darkened areas of the bark. This is usually on the south sides of trees where the sun has warmed the bark.\nSun scald is most common on young trees with thin bark. Older trees, with thicker bark, are less sensitive to such temperature extremes. Plants that have been pruned to expose previously shaded bark also can be injured more easily. Certain species with thin bark are more prone to sun scald, including cherry, crabapple, honey locust, linden, maple, and mountain ash.\nTo prevent sun scald, wrap the bark of susceptible trees in late fall with either tree wrap tape, plastic tree guards, or similar light colored material. These can be found in complete garden stores. Remove the wrap in the spring after the last frost, to avoid insects living under the material during the summer. Wrap newly planted trees or young trees for at least two winters. Wrap thin-bark trees for at least five winters.\nCold also can injure evergreens through discoloration, particularly in late winter. Anyone with rhododendrons in cold climates has probably seen this. It appears as browned leaf tips, large areas, or browning of needles of conifers. Such browning is often referred to as “dessication”, or a drying out of leaves. Sunny days in winter, or wind, can cause evergreen leaves to lose water or “transpire”. Since the ground is frozen, roots can’t take up replacement water, so the result is the leaves drying out and browning.\nSimilar to sun scald on bark, warm days can stimulate cells to be active in leaves, only to be killed by sudden temperature drops when the sun disappears. In fall before plants are fully hardened, or in spring as new growth is occuring, low temperatures can injure non-hardened tissues.\nOne obvious solution is to make sure evergreens go into the winter well-watered. If there is less than an inch or two of rain a week in mid fall, make sure you water such plants. Another solution is to wrap dense evergreens such as Alberta spruce in burlap (not plastic that can heat up and cook the plants), or erect a screen around evergreens such as rhododendrons. Such screens should be on windward sides of the plants, and on the south sides to lessen sun heating.\nSnow is one of the best protectors, so low evergreens can be protected by making sure they are covered with snow. You can lightly shovel snow on them, or place holiday boughs and trees next to them to trap the snow. If you have evergreens that usually get damage, consider moving them if possible next season, or planting new ones in sites more protected from winter sun and wind. Sprays to protect the foliage from drying out, called “anti dessicants” have been recommended in the past. Most studies seem to show they are not effective though.\nDieback is simply plant parts, such as twigs and buds, being killed by cold. This is often seen on deciduous shrubs, or those that lose their leaves. Many plants such as forsythia have flower and leaf buds, the latter being much more hardy. This is the reason in some years with extreme cold you see the plants leaf out but with no flowers above the snow line where they were protected. Not much can be done to protect such plants, except to select more hardy varieties. Make sure next season in late summer you don’t overwater, prune, or fertilize. All may stimulate vigorous growth which wont harden properly.\nIf a tree or shrub is injured from dieback, don’t be too eager to prune off the apparent dead branches. Often these only may be dead on the surface, with living tissue underneath which will produce buds. So wait until mid-spring to prune such branches, especially on less hardy roses which often show at least some dieback.\nRoots can be injured by cold soil temperatures, generally at about 10 degrees (F) or lower. The good news is that due to latent heat in the soil, snow, and other factors, root and soil temperatures seldom get this low. Dry soils can get colder than moist soils, so fall watering will help to prevent not only dessication of tops, but also cold injury of roots.\nMaking sure any cracks in the soil around newly planted trees or shrubs are filled will help. Covering the root zone with up to six inches of organic mulch, such as bark or pine needles, will keep roots warm much longer in the fall. Mulched soils also fluctuate less in temperatures during winter, which is better for root hardiness. Make sure and keep such mulches away from trunks and shrub stems, otherwise mice may live in this material and feed on the bark.\nA final way cold may damage trees and shrubs is through repeated freezing and thawing of soil in spring, called “frost heaving.” Such expanding and contraction of soil around roots can damage them, and raise new plantings or “heave” them from the soil. Mulching, as well as planting early in the season so plants can be well-rooted by fall, minimizes frost heaving.\nIn addition to such tips on cold damage, an online publication from the University of Minnesota describes how to prevent other winter damage to trees and shrubs from snow and ice, road salt, and animals.\nReturn to Perry's Perennial Pages, Articles""]"	['<urn:uuid:2ad5c424-599b-49ab-b03a-677385a46618>', '<urn:uuid:5fba4bf6-3e3c-4746-83cc-ce64b1b1a7ef>']	factoid	with-premise	long-search-query	similar-to-document	multi-aspect	novice	2025-05-13T01:50:22.828293	11	104	1632
39	anthropology graduates employment opportunities institutions	Graduates can find employment as staff with expertise in anatomy, human biology and anthropology at biology- and medicine-centered academic institutions, museums, and archeological institutions.	"[""doc. RNDr. Miroslav Králík, Ph.D.\nNature through culture.\nAnthropology is an integral scientific discipline, the Science of Man, studying mankind from its origins until the present. In contrast to scientific disciplines which specially focus on a detailed study of particular areas of human life, anthropology concentrates primarily on the usually ignored connections between biological, social and cultural aspects of human nature. Anthropology regards these bio-socio-cultural interactions as the core for the unique human evolution, as the substance of groundbreaking turns in history and also as a chance for our kind to survive in the future. Anthropology studies the origins and mechanisms of the variations of human biological, social and cultural forms and their relationships in the process of adaptation of Man to the changing environment. The mission of the study program of Anthropology is to prepare highly qualified specialists in the field of integral anthropology, adhering to the above stated concepts.\nThe study program is suitable for students driven to searching for the essence of Man; students with a wide perspective, with versatile abilities and dedication to intensive study. During the three-year Bachelor's program students are educated in the main anthropological concepts, they acquaint themselves in great detail with the structure and functions of the human body and obtain insight and understanding of the mankind’s socio-cultural evolution from the prehistory until the modern era. Students also gain proficiency in standard methods in the sub-fields of biological anthropology and archeology and in basic procedures of elaboration and presentation of results. Anthropology is a global discipline, therefore one of the goals of the study program is to make the students acquainted with English terminology basics. Some lectures in selected courses are presented in English. Practical training forms an integral part of the studies allowing students to acquire experience in realistic work-duty conditions at potential employers’ facilities. Students apply the acquired theoretical and practical skills in the preparation of their Bachelor's theses to wrap up their studies.\nStudents of this program should gain orientation in the topics of anthropology, acquire extensive systematic knowledge of human biology, society and culture and learn to apply it to completing anthropological assignments. Theoretical and practical knowledge obtained within the Bachelor's study program represents the foundation for the follow-up in the Master's degree program in Anthropology.\nPractical training is an obligatory part of the curriculum in the extent of six weeks during this Bachelor's study program - commonly two weeks per academic year. After completing (and/or being in the process of completing) their practical training assignments, students enroll in a mandatory course Bi6502 On-site Training during the spring semester in the 3rd year of their studies for which they receive credits.\nPractical training tuition is centered on archeological excavations of skeletal burial grounds provided by the Department of Anthropology. There, under expert supervision, students acquire hands-on experience of the entire scientific research procedure – a preliminary prospection and localization of the site, excavations of skeletal remains and artifacts, their written, measured and photographic documentations, reconstruction and analysis of the uncovered remnants, interpretation of results and finally formulation of conclusions in the final report. The final stages of the procedure are performed in the laboratory. The Bachelor's program students are primarily trained in basic on-site techniques of burial site (grave) preparation and schematic drawing documentation. At least one week of this on-site training is obligatory during their Bachelor's studies. The remaining practical training can be carried out at other selected workplaces (archeological institutions, scientific departments, museums, hospitals, Police of the Czech Republic departments, etc.) where anthropology-oriented activities take place. Such practical training allows students to establish professional contacts with potential employers. The relevance of the practical training to student's study program is assessed by a guarantor. The certification of completion for the practical training (Bi6502 On-site Training) with a credit value is based on the consensus of the subject teacher and the head of the research (and/or of the organization where the practical training took place).\nWeb pages of the Department of Anthropology:\nWeb pages of the the Laboratory of Morphology and Forensic Anthropology:\nThe graduates of Anthropology Bachelor's study program at the Faculty of Science can find employment as staff with expertise in anatomy, human biology and anthropology, especially at biology- and medicine-centered academic institutions, in museums and archeological institutions. Graduates can offer their potential future employers the following: detailed and extensive knowledge of the human body structures and their complex organization, a vast socio-cultural perspective and experience with experimental data evaluation. The educational process at the Faculty of Science MU in the Anthropology program introduces a vast range of situations and prepares students to face the possibility of uncommon tasks, which require searching for new solutions. The major part of graduates is expected to follow their studies in the Master's study program where they will extend their knowledge in synthesizing courses and expand their practical skills by gaining proficiency in additional special methods.\nData from the previous admission procedure (1 Nov 2020 – 28 Feb 2021)\nThe part of admission process is a written test, which includes a Learning Potential Test and a Special Test of Biology with Basics of History and Social Sciences. Can be used any TSP done on every faculty of MU. (Czech only)\nResults of the Learning Potential Test and of the Special Test of Biology with Basics of History and Social Sciences\nThe knowledge required to pass the Learning Potential Test is not obtained by studying specific information sources. Examples of previous years' tests can be found on http://www.muni.cz/study/admission/tsp For succesful passing of the special test is enough to have knowledges of grammar school curriculum of the subject.\nStudents have a pre-defined list of required courses, which are supplemented with selective and elective courses. The student pays full attention to the single field of study chosen.\nAn example of your study plan:\nAfter completing the Bachelor’s study program, students can follow their studies in any Master’s study program (the students must comply with admission criteria of the particular program). There is a direct follow-up Master’s study program in Anthropology.\n|Provided by||Faculty of Science|\n|Type of studies|\n|Standard length of studies||3 years|\n|Language of instruction||Czech|""]"	['<urn:uuid:c5f08fd0-5d00-49df-a3e8-3ac09b283743>']	factoid	with-premise	short-search-query	similar-to-document	single-doc	expert	2025-05-13T01:50:22.828293	5	24	1022
40	achilles myth medical relevance greek history	The Achilles tendon has mythological origins and practical medical significance. In Greek mythology, Achilles was a warrior whose only vulnerability was his heel, where his mother held him while dipping him in the River Styx. This weak spot led to his death when struck by an arrow. In modern medicine, the Achilles tendon is the longest tendon in the body, connecting the calf muscle to the heel bone. It's prone to inflammation (tendinitis) from overuse or trauma, which can occur suddenly or gradually. Additionally, the name Achilles is also connected to the medicinal plant yarrow (Achillea millefolium), though tales of Achilles using this herb to heal wounds may be apocryphal.	['‘Twas the last day of July, and the big meadow at Eagle Beach State Rec Area was decorated with white flowers. Tall, flat-topped inflorescences of cow parsnip ringed the edge by the trees. Shorter and lacier inflorescences of hemlock-parsley came next and filled an area near the old dunes. On slightly lower, more central ground, the single flowers of northern grass-of-Parnassus spangled the field. And weedy little yarrow fit itself in wherever it could.\nThis grass-of-Parnassus (Parnassia palustris), also known as bog star, has a wide geographic range across North America and Eurasia. Inside the saucer-shaped flower are five stamens bearing pollen, five staminodes (sterile stamens) that bear droplets on their branched tips, and a single ovary with a stigma where pollen is deposited. The droplets do not contain nectar but may help attract small flies and bees that do the pollination. Nectar is produced at the bases of the stamens and staminodes, according to a scholarly report (resolving the contradictions and confusions found on general internet sources). Insect visitations, moving pollen within a flower or bringing it from another one, are reported to be necessary for pollination and seed set. Seeds are spread by wind and water.\nThe taxonomy of Parnassia is confusing too. Our field guides place the genus in the family Saxifragaceae. However, several internet sources place it either in its own family or in the family Celastraceae (along with burning bush, Oriental bittersweet, and others).\nI was interested to learn how this plant got its English name. It’s not a grass, so that is a misnomer. But what does Parnassus have to do with this plant?– the name appears in both the common and the scientific names.\nMount Parnassus is a fairly large mountain in Greece, not as big as Olympus and not as important in mythology. Nevertheless, in ancient Greek mythology, Parnassus was sacred to Dionysus, the god of grape harvest, wine, debauchery, and madness. The mountain was also a sacred haunt of Apollo, who was a multifaceted god of light, music, town-building, and prophesy—and a hero, a protector of flocks and crops, a lecher, a bisexual, and an archer. Parnassus was also visited by the Muses—goddesses of song, poetry, history, and dance, as well as other minor deities.\nThen, about two thousand years ago, a Greek physician and botanist named Dioscorides wrote a huge set of books on medicine, useful plants, and related matters. He wrote in Greek; his books were translated into Latin and Arabic and, eventually, into other languages. They constituted the basis of the practice of western medicine for centuries. Supposedly, Dioscorides gave grass-of-Parnassus its name, having found it growing on the Mountain. I have no access to this doctor’s original opus, but it seems unlikely that he really confused this plant with the grasses; perhaps he merely said it was like a grass in some way. Then, somewhere along the line, some taxonomist just decided to apply the inappropriate name of grass when naming this species.\nThe generic names of two of the other white flowers in the meadow also hark back to Greek mythology. Heracleum lanatum (cow parsnip) refers to Heraclites (Hercules, in Latin)—known for his prodigious strength. As penance for his crime of murdering his wife and children in a fit of madness, he was given the fabled twelve Labors of Hercules (killing or capturing some monsters, cleaning the Augean stables that were full of manure, etc.). The very robust plants of cow parsnip might reflect his strength.\nAchillea millefolium (yarrow) is related in name to Achilles—he of the vulnerable heel. Legends say that Achilles’ mother held her baby by a heel and dipped him in the river Styx to make him invulnerable, but the heel didn’t get wet, leaving it unprotected. After many adventures, including killing Hector in the Trojan war, Achilles was killed by an arrow in this heel. Yarrow indeed has good medicinal properties, but the tales telling that Achilles used this herb to heal wounds may be apocryphal.\nBefore I leave Greek mythology, here are two more quick examples; both are orchids with representatives in Southeast. The genus Cypripedium (moccasin flower or lady’s slipper) is named for the foot of Kypris (later known as Aphrodite in Greek, Venus in Latin; the ‘ped’ refers to foot in Latin). In variable forms, she was the goddess of love and lust, beauty, fertility, and marriage. Calypso bulbosa (fairy slipper) is a showy orchid. The ‘bulbosa’ part of the plant’s name refers to a bulbous corm at the base of the plant. In Homer’s epic poem, Calypso was a goddess-nymph who successfully seduced Ulysses (Odysseus in Greek) for seven years. Perhaps she was really bulbous when bearing two children by him!\nAnd how do all these mythical creatures get into taxonomy at all? Well, one reason is that, historically, all young scholars, including future taxonomists, were well schooled in Greek and Latin classics, so the names and stories were very familiar to them.', 'The Achilles tendon gets its name from Greek mythology.\nA famous warrior, Achilles was vulnerable only in the narrow part behind the ankle where his mother grasped the baby when she dipped him in the River Styx, to shield him from mortal harm.\nThe tiny ankle not coated in magic water was his undoing, as an arrow from his enemy caught him in the Achilles tendon and led to his death.\nMythology aside, the Achilles tendon is a site of modern injuries, common but treatable. The Achilles is the longest tendon in the body, running down the back of the leg from the calf muscle to the heel bone. It enables us to lift the heel off the ground so we can walk.\nAchilles tendinitis is an inflammation of this ligament that can be caused by overuse or trauma. The condition can come on gradually or with a loud ‘pop’ that sounds ominous. If left untreated, Achilles tendinitis can lead to the development of bone spurs or a ruptured tendon.\nCertain kinds of movement can cause sudden damage to the Achilles. Think of a tennis player rushing the net and then pedaling backward to hit an overhead smash.\nMore often, we see Achilles tendinitis in people who spend long hours on their feet, such as teachers or waitresses.\nThen there are the weekend warriors who fight their battles only once weekly, while the rest of their days are spent sitting in automobiles or in cubicles.\nA sudden increase in training or an abrupt change in technique can also trigger inflammation of the Achilles tendon.\nTreating an Inflamed Achilles Tendinitis\nBefore we can design a treatment plan, we first must determine the nature and severity of the injury.\nThere are two general types of Achilles tendinitis: non-insertional and insertional.\nThese terms refer to whether the inflammation is concentrated in the place where the muscle inserts into the bone, or whether it is located in the fibers in the middle part of the tendon.\nWhile x-rays help the doctor see whether the lower part of the tendon has calcified (indicating insertional tendinitis), an MRI is useful in cases where surgery is being considered.\nWhile most cases of Achilles tendinitis can be treated with nonsurgical therapy, Achilles tendinitis is notoriously slow to heal. If you had pain for several months before calling the clinic, it could take up to six months for the treatment to take effect.\nOur first recommendation is to stop the activity that’s causing or exacerbating the pain. If you are a runner or you engage in some high-impact sport such as tennis or soccer, switch to a different activity that places less stress on the tendon. Biking and swimming are possible cross-training alternatives.\nPrognosis Depends on Patience\nNonsurgical options rely on reducing the irritation that caused the inflammation in the first place. Icing the injured leg can help. Anti-inflammatory drugs are sometimes advised. There are exercises that help strengthen the calf muscles and relieve stress on the tendon, but one must be careful because some exercises can actually worsen the strain on the Achilles. Check with your doctor or physical therapist before launching any Achilles-related exercise therapy.\nCortisone injections are seldom recommended because they have been known to cause the tendon to rupture.\nInsertional Achilles tendinitis can be alleviated by wearing a specific type of heel, or heel lifts. For patients with a great deal of pain, a special boot is sometimes prescribed. Long-term use of the boot is not recommended, because it can actually weaken the calf muscle.\nIf the tendinitis hasn’t responded after six months of conservative treatment, we may discuss orthopedic surgery. While most patients are able to return to the activity or sport they love after Achilles tendinitis, there is a small chance that you will not have that option— still another reason to investigate cross-training.']	['<urn:uuid:ef14eba4-cee6-447e-b231-4bf241895a59>', '<urn:uuid:74e162a8-d029-4038-aee1-0fe6c3921b01>']	open-ended	direct	short-search-query	distant-from-document	multi-aspect	novice	2025-05-13T01:50:22.828293	6	110	1466
41	single hand vs two hand use medieval swords senlac regent difference	The Senlac and Regent swords represent different handling approaches. The Senlac is specifically designed as a single-hand sword with a fairly short grip intended solely for single-hand use. The Regent, on the other hand, is a hand-and-a-half sword (also known as a bastard sword or longsword) featuring a longer grip that can be used with either one or two hands, offering more versatility in combat situations.	"[""A Resource for Historic Arms and Armour Collectors\nAlbion Armorers Next Generation Senlac Sword\nA hands-on review by Bryan Heff\nIn the year 1066, during the twilight of the Viking Age, a desperate struggle for control of England came to a head. Duke William of Normandy, with claims to the throne of England, landed his Norman army consisting of mixed troops that included a large contingent of heavy cavalry on the Southeastern coast of England. King Harold II of England and his Saxon army, fresh from a hard fought battle and difficult march from the north, had quickly returned south in an effort to stop this Norman challenge to his throne. The Saxon took up a defensive formation with a traditional shield wall, high atop a hill along the London road in an effort to block the Normans' march north and bring them to decisive battle. Several weeks before, this same Saxon army with its Huscarl core of heavy infantry had successfully smashed an invading Viking army at Stamford Bridge. The fate of the island now lay at the feet of these two armies. By the end of battle a victor would emerge and history would be set. The Battle of Hastings was about to unfold and its outcome would help set the stage for European battle tactics for years to come. The battle was fought on a hill called Senlac, and swords similar to the subject of this review would have been used on both sides. Whether being swung from horseback or from behind large shields, these slashing cutting blades designed to oppose mail and textile armour were the order of the day.\nAlbion Armorers Next Generation Senlac is a long bladed single-hand medieval sword best described using Ewart Oakeshott's typology as a Type Xa, a cousin to the broad cutting blades of Type X. Being slightly longer, having a fuller that is not quite as wide and with a more pronounced profile taper is what essentially differentiates the Type Xa subclass. While potentially more suited to a thrust than a Type X, its primary purpose would be in the cut. Albion produces three swords all using the same blade. Those swords are the Senlac, Norman and Knud. The Norman and Senlac are very similar, differing most significantly in the cross-guard only. The riser patterns on the grip are also different between the two but not greatly so. The Senlac is a no-nonsense sword with little adornment. It is a sword that soldiers could have worn at their hip from Hastings all the way to the gates of Jerusalem during the First Crusade. This is a sword a man could rely on with confidence.\nMeasurements and Specifications:\nReplica created by Albion Armorers of Wisconsin.\nThe Senlac is a long-bladed weapon with a fairly short grip intended solely for single-hand use. These combined factors could create a sword that is sluggish. This is not the case here. The handling is really quite nice. No cutting was done with the sword prior to this review, just basic dry handling movements to gauge how it feels; smooth would be the word most adept at describing its overall characteristics. To borrow from boxing terminology, the blade could be described as a middle-weight. The point of balance is not particularly close to the hilt so it displays nice blade presence. It is a weapon that allows quick attacks and recovery but still has enough heft to deliver vicious slashing and hewing cuts as well.\nOften swords like this would have been used as side arms, not necessarily the primary weapon. The handling speaks volumes to this kind of usage. It is a sword agile enough to be used for a long period of time if need be while being light enough to wear on long campaign marches; it has enough punch to get its wielder out of a jam.\nFit and Finish\nOne aspect of the blade that really stands out is the slight convex curvature of the profile the final 1/3 of the blade. Many production swords available today have very straight lines along the blade's profile until the final tip is formed. The ever so slight convex curve of the Senlac's profile really gives it a beautiful blade presence and is one of the subtle details that helps make what seems like a simple sword much more.\nThe pommel is a disc-shaped Oakeshott Type G. It is simple in form, not overly complex, and could be easily described as quite plain. It does however have some rounding of the faces from the center out to the edges which gives it an element of complexity that differs from a flat disc. It is also not a perfectly round circle in shape but comes out of round ever so slightly where the pommel meets the grip. The peen is blended into the pommel so well that you simply cannot see it unless the light hits it in just the right way. The convex sides of the pommel are not perfect in terms of symmetry, but come very close to it and I think provide a good example of the hand work on the sword. This is not a criticism so much as an observation. It adds a warm handmade look and feel.\nThe guard is a straight, very basic Oakeshott Style 1a. The guard slot is expertly cut and fitted to the blade with extremely tight tolerances. The guard is rectangular in cross-section where the blade slot is located and then tapers down to a thinner square as it moves away from the blade. What struck me right away is how thin the cross-guard is compared to heavier/bulkier cross-guards more common on lower-priced swords. It's almost elegant in its utilitarian and lean design. There is not a lot of extra unneeded steel in the guard, just enough to accomplish its purpose.\nThe Senlac is unquestionably a simple and plain sword at first glance. This may be a deterrent to some sword enthusiasts especially at its price point. I think the argument could be made that along with their Bayeux and Hospitaller models, it is the least adorned medieval sword Albion Armorers produces in terms of hilt components. With all that in mind this reviewer has come to the conclusion that the Senlac is simply and clearly a classic medieval cruciform sword. It is perhaps the classic sword type for this post-Viking Age time period and it makes perfect sense that Albion would want such an iconic design as part of its Next Generation line. The straight guard and disc pommel are function over form in its purest sense. There is beauty in that simplicity. Its clean and straight lines are pleasing to the eye. It has an overall balance in both looks as well as handling that hit the mark on stylistic sensibilities that subscribes to the less is more ideal and it delivers on that extremely well. The Senlac is a beautifully understated but classic sword design.\nAbout the Author\nBryan Heff is a Systems Analyst living in the Philadelphia suburbs with his wife and 2 sons. He has always been intrigued by the European sword as a work of art, symbol and weapon of war. His main area of interest is rooted in the 8th to 14th centuries but he has interests in other time periods as well. In addition to adding to his small but growing collection of swords, he enjoys modifying and customizing swords in his compact basement workshop, hiking and exploring historic sites and trying to get his boys to do their homework.\nPhotographer: Bryan Heff"", 'Albion Armorers Next Generation Regent Sword\nA hands-on review by Patrick Kelly\nDuring the high Middle Ages, roughly during the mid-thirteenth century, a new type of sword came into use. Developed in the German countries, this sword (then known as the Grete Swerde or War Sword) was designed to be used with effect against the improving mail armor of the day. The War Sword featured a longer grip that could be used with either one or two hands as well as a correspondingly larger blade. While some variants of the type possessed a serviceable point, they were primarily dedicated to the cut. This general pattern of swordalso known as a hand-and-a-half, bastard sword, and longswordwas to become a permanent fixture on the battlefield throughout the medieval period.\nAs the Middle Ages progressed, this versatile hand-and-a-half design continued to evolve according to the battlefield requirements of the day. The dedicated cutting designs of the thirteenth century gave way to the thrusting oriented patterns of the late fourteenth century. By the middle of the fifteenth century, the type had reached what can arguably be considered as the complete refinement of its design. Not only did the fifteenth century longsword possess a blade profile that allowed for effective thrusting, it also retained a large measure of its earlier ancestor\'s cutting ability. Not only did the late medieval longsword possess a great degree of versatility in its design, but it also reached a level of aesthetic refinement which resulted in one of the most visually attractive swords extant.\nThe medieval longsword has long been a popular staple of literature and the cinema. Many of our favorite heroic figures have used these manly and imposing weapons. Consequently, the longsword has also been a regular figure on the replica sword market. Some of these attempts at replication have met with success. Others have not. Recently some of the finest recreations of the type have been coming from the Wisconsin-based workshop of Albion Armorers.\nIn mid-2003, Albion made the decision to take their product line in a new direction. Their line of swords at that time (now known as the First Generation) was generally well received by the arms collecting community. With a decision to offer a new batch of swords with even more historical authenticity, they announced the Next Generation line. To read more about the details and philosophy behind this new product line, please see our hands-on review of the Next Generation Baron sword.\nThe Next Generation line seems to have become Albion\'s most successful line to date. One of the most exciting members of this lineup is a recreation of a late medieval Longsword. This sword, known as the Regent, is the subject of this review.\nMeasurements and Specifications:\nReplica created by Albion Armorers of Wisconsin.\nFit and Finish\nThus far I have been impressed by the hilt construction of Albion\'s Next Generation line. In the case of the Regent, while the hilt is impressive, the most exciting feature is the blade, because the blade is hollow-ground. Hollow-grinding is nothing new in the field of production swords, but I believe that Albion Armorers is the only company that is doing it correctly. Several lower cost sword makers use a manufacturing process that results in a hollow-ground blade. In this case, however, the hollow-grinding is a by-product of the technique not an intentional design detail. On the other hand, the Regent is a sword that has been designed from the ground up to feature an accurately constructed blade of this type. When viewed in cross-section, the Regent\'s blade exhibits a distinct hollow-grind that curves deeply from the blade\'s central ridge. As this curvature nears the edge it begins to slope upward until it comes to within .156 inch of the edge terminus. The edge then slopes downward to its terminus, thereby creating a secondary bevel. This is the key aspect that sets the Regent apart.\nWhile we have come to consider a secondary edge bevel to be an undesirable feature in European edge geometry, it is a key and important feature of the Regent\'s blade. Other hollow-ground production blades will feature a continuous slope downward from the central ridge with no secondary bevel. In terms of edge geometry, this results in a blade that is weak in terms of edge structure. This may be fine in knife design; however, this will result in a sword that lacks the needed material to support the blade\'s edge. The edge will then be weak, and will buckle or chip during use. The secondary bevel present on the Regent\'s blade provides an edge geometry that is as strong as that found on other non-hollow-ground blades. According to Albion\'s Master Cutler Eric McHugh, all medieval hollow-ground blades exhibit this feature. The only difference lies in the fact that the ridge defining the secondary bevel would be smoothed out on more expensive blades. For reasons of cost, Albion chose to leave this ridge visible on the Regent. I actually prefer this, as the ridge is evenly machined for the entire length of the blade. This results in a nice bit of visual detail. The blade terminates in a point that is very acute, yet at the same time adequately reinforced for use against fully armored opponents.\nThe blade is very evenly machined throughout its entire length. The central ridge is very straight and precise, with no wobbles or curves whatsoever. Finally, the entire sword is finished in Albion\'s signature satin finish. I have come to prefer this finish on all of my swords, as it is very attractive yet highly practical as well. The Regent\'s components of blade, guard, grip, and pommel all flow together in a beautiful harmony of design and proportion. This is a sword that looks ""fast"" just sitting still.\nAll of the nice detail and polishing in the world won\'t amount to much if the sword\'s handling qualities are found wanting. In the case of the Regent, the modern swordsman will want for nothing. Ewart Oakeshott listed swords like the Regent as the Type XVIIIa in his typology. As such, the Regent represents the final refinement of late medieval longsword design. While designing the Regent, noted swordsmith Peter Johnsson drew inspiration from the swords used in the medieval countries that fell under Germanic influence. The Regent is not a direct recreation of any one particular sword, yet receives its design elements from many swords of this type that Peter has examined.\nThe Regent performed well in all cutting exercises that were executed upon soft cutting mediums. The sword tracked well into and out of the cut, and no undue resistance or vibration was felt. No cutting tests were performed on harder mediums that would have simulated use against a shield or some form of armor. However, due to the blade\'s strong geometry I have no doubt that the Regent would have given service equal to its medieval ancestors. I found the Regent to be very responsive and easily controlled during thrusting maneuvers. The sword follows the point with little effort. The blade exhibits a non-linear distal taper. This taper maintains its rate of decline for approximately three-quarters of the blade\'s length. It then increases its rate of decline further until it terminates at the point. When combined with the blade\'s profile taper as well as overall mass distribution, this results in a very nicely balanced blade. This design also provides for a pivot point that is fairly close to the tip. The overall result is a sword that is decisive in the cut, yet highly agile in the thrust.\nI ran the Regent through several drills compiled from Christian Henry Tobler\'s book, Secrets of German Medieval Swordsmanship. This work provides an excellent outline of the techniques of medieval German Master Johannes Liechtenauer. The Regent represents a type of sword that was designed specifically around this German school of swordsmanship. Consequently, it is no surprise that I found the sword quite responsive in use. Even though the Regent\'s design is centered on the German school, I believe that it would serve equally as well if used in the Italian methods as taught by Fiore dei Liberi.\nI found the Regent to be everything a medieval longsword should be. It exhibits excellent construction and outstanding handling characteristics as well as a level of workmanship that will give the owner much pride in its possession. Albion Armorers continues to set new standards for production quality with its Next Generation line. With the introduction of a longsword that features an accurately hollow-ground blade, that standard has leapt even farther down the path. The Regent is expensive, but as they say, quality isn\'t cheap. I consider this sword to be money very well spent.\nAbout the Author\nPatrick is a State Trooper serving with the Kansas Highway Patrol. He has been fascinated with edged weapons, particularly the medieval sword, since early childhood. Not only is Patrick thankful for any opportunity to indulge in his favorite hobby, he is also blessed with a wife who tolerates a house full of sharp pointy things.\nPhotographer: Nathan Robinson']"	['<urn:uuid:9a7aa7bd-203d-45b3-bab1-63a32baf3d37>', '<urn:uuid:6d91d537-f86a-44f0-aaf7-992ceda41b2f>']	open-ended	direct	long-search-query	similar-to-document	comparison	novice	2025-05-13T01:50:22.828293	11	66	2780
42	what difficulties face early wool production australia	Great difficulties were experienced in promoting the fine wool industry. Meat was expensive, and most sheep breeders preferred selling for mutton rather than wool growing. They resented the introduction of Spanish breed sheep. Additionally, there were endless obstacles in obtaining sufficient land grants and necessary labor for increased flocks.	"['3 corrections, most recently by anonymous - Show corrections\nFOUNDER OF WOOL\nCentenary of John MacArthur.;\n, The wool industry in Australia has grown to such, enormous proportions, arid .become of such vital importance, that it is not meet that April 10th, the- centenary of the death of its founder, V- Macarthur, of Camden, should go unremarked, and the Royal Society of Australia will hold a sym- posium at Canberra to commemorate\nthe occasion. ;\n- John .Macarthur was born near\nPlymouth, in Devonshire, in. 1767, and joined the British"" Army as an ensign in 1782, but being placed on half pay the following: year went to live on a farm near Holsworth on the borders of Cornwall and Devonshire, where it is said he took a great interest in rural occupations, and also spent much time in .reading: books on legal subjects. He intended retiring from the army with the object of \'being;\ncalled to the Bar. > * . | *\nHowever, in 1789 he was appointed\\ a lieutenant in the New. South Wales Corps and came out to . Port Phillip."" Even while still engaged in soldiering he became interested in.- agricultural pursuits, .and it is recordedthat/he received small . grants of land as! a reward .for attempts , .""to raise food\nfrom the. land.""\n: Much- information :? concerning Mac arthur is to be gleaned from the - let ters of his wife, and it is in one of these that the. first mention: of ^ sheep is made, ""Our stock of cattle is:large; we have now .fifty head, a dozen horses and about a \'thousand sheep.l\'\nIn 1794\' Macarthur had purchased\nsome - hair ? bearing- sheep ; .from >the Cape, and - soonv . aft\'er. some coarse woolled Irish sheep, and, to. quote his own words,""By crossing the two breeds I had the satisfaction to see the lamb.s of the Indian ewes bear a mingled^fleece\' of hair rand wool-this circumstance originated the idea of producing .fine .wool,;;!:in:..-:-..iNewv;-::South AVales.\'.\'So t in 1796 .he . obtained from the Cape four Merino ewes and two ramSj - "".which \' were jcarefully- guarded against- an Impure mixture* vand in \'creased\'in number and improved in, . the- quality of their: .wool,\'\': and a year\nor\' two\' later 1,200 sheep of the com mons,Gapei\'breed; were purchased*^ Colonel Foveaux,\' . ^\nMacarthur visited England in. 1801, taking1 specimens of the pure Merino wool, arid of the best of the crossbred, and submitted,; them \'to a Committee of = Manufacturers; /who reported that the Merino was equal to any Spanish Wool, and the crossbred of consider able value. Thus encouraged he pur chased rams and a ewe from ; the Royal Flock at Kew, and it was from these; foundations that his . flock was built up.\nGreat difficulties Were \' experienced by Macarthur. in his endeavours to promote the .fine wool industry;- Meat Was dear, and; most of the other.; sheep breeders were more interested in sel ling: . for mutton than;.,in wool growing-, ?and resented the: introduction. of the\nSpanish breed. This: was: not the only .: difficulty lie-* had; to -- contend; with;\' There were seemingly -endless\' \'\'ob stacles before he obtained grants of sufficient land : and the- labour neces sary for his increased flocks.\n-Although in 1804, after a personal appeal to the Privy \'Council for en couragement in his enterprise; Lord Camden,: Secretary for State ordered Governor King to grant - liim 5,000 acres in the. Cowpastures (now Cam: den), and: promising another similar grant, it was not until . 1825 that- the second grant was actually, made.\nMacarthur stillhad -to make a wod niarket for his wool; and there is re corded ? much .correspondence on this matter: with his son John, a barrister inV^Liondon, -Avho- supervised the sale; of the wool. ; The fine wool from the Electorate\' of Saxony appears to have been in great demand by buyers, and young* .Maqarthur made- an extensive study of the . Saxoni methods- of,sheep husbandry and getting up- the, wool\nfor market\' with the -object of\':eauall-/\nirig the Saxon jvool: How wejl he suc\nceeded is evidenced ;by-= a gold -medal\nissued to him by :tlie Society .of Arts: for importing fine \' wool;;; eaual T: to> the best Saxon, from New South. Wales..\nGreat strides have .been -made in the breeding of fine woolled.. sheep, isirioe the days of Macarthur,. but\' Australia owes a debt of gratitude to the main who founded -and devoted his. life -to the industry: i. tv -\nHe died at Camden on April 10th; 1834, just a hundred years ago: \'\nAmy: ""Why did Miss Antique dis \'charge her butler?,\'\' i Mamie\':-i ""He* boasted that he had\'1 grown; grey-,in .her\' service.""']"	['<urn:uuid:1bd88ca3-857d-481f-906b-44f32e7adce5>']	factoid	direct	long-search-query	distant-from-document	single-doc	novice	2025-05-13T01:50:22.828293	7	49	791
43	As a therapist, how do CBT and Schema therapy differ in treating cognitive disorders?	CBT focuses on changing negative thought patterns and developing healthy coping skills in the present, while Schema Therapy integrates CBT with attachment theory and other approaches to explore emotions, maladaptive coping methods, and mental health origins. Schema Therapy uniquely involves a therapist acting as a parental figure providing emotional stability, and uses specific techniques like imagery, chair work, flash-cards and diaries.	['Imagine that you’ve just been diagnosed with Borderline Personality Disorder. Although you familiarize it with Bipolar Disorder, you’re corrected and told that they are indeed different disorders. As a kid, you were diagnosed with Conduct Disorder and now as an adult, you have Borderline Personality Disorder. Among the research that you do, treatments are the main objective that you focus on. There are so many options, but which one is the best for you?\nBorderline Personality Disorder (BPD) is a cluster B disorder. It is described as “an extreme sensitivity to perceived interpersonal slights, an unstable sense of self, intense and volatile emotions and impulsive behaviours” (Gunderson et al., 2018). BPD is fairly prevalent in society, but more so in the psychiatric community and it can be difficult to diagnose (Bryne et al., 2018). Borderline Personality Disorder is commonly developed during childhood and proceeds into adulthood. There are four categories of symptoms of Borderline Personality Disorder: interpersonal instability, behavioral dysregulation, cognitive and affective. Interpersonal instability is described as an individual having profoundly unstable relationships as well as avoidance behaviors pertaining to abandonment (Gunderson et al., 2018). Behavioral dysregulation as described by Gunderson and colleagues is characterized by an individual being impulsive and susceptible to harm (2018). Cognitive symptoms are described as the individual being paranoid or having identity disturbance, and affective symptoms are described as the individual having feelings of anger, emptiness, or instability of mood (Gunderson et al., 2018). In each sub-category of Borderline Personality Disorder, the symptoms are usually extreme and are harmful to the individual.\nThere are many treatments for Borderline Personality Disorder. Most treatments align with Cognitive therapy due to the fact that Borderline Personality Disorder is a pattern of thoughts and behavior. One of these treatments is Schema Therapy, which is characterized as the integration of “elements from cognitive behavioral therapy, attachment theory, and a number of other approaches, [to explore] emotions, maladaptive coping methods, and the origin of mental health concerns” (Santangelo et al., 2017). The basis of Schema Therapy is to target events and thoughts that cause the individual to perform harmful actions and to replace them with good thoughts and actions. The role of the therapist is to be an almost parental-like figure and to provide emotional stability and validation. Schema therapy can include imagery, chair work, flash-cards and diaries. The effectiveness of Schema therapy is thought to be well supported and is backed by several articles. One study lasted 30 weeks and out of the 16 participants in the experimental group, 15 reached Borderline Personality Disorder remission compared to the 75% of participants in the control group. Another study comparing Transference Focused Psychotherapy (TFP) and Schema Therapy concluded that Schema therapy worked better with an average of 29% more participants in remission.\nMentalization-based therapy (MBT) is another treatment. It is based on the attachment theory, which suggests that there is a critical time period in an individual’s life to make attachments and if not made, it can negatively affect that individual’s life and development such as by reducing intelligence and increasing anger. MBT focuses on creating diverse meaningful perspectives along with the individual’s own perspectives to create a coherent self that is reimagined through these techniques (Bryne et al., 2018). A study found that MBT compared to general treatments was effective in improving depression and anxiety, and decreasing self harm in individuals.\nLastly, there is no way to automatically know which treatment will work best, rather it operates on a case-by-case basis, but knowing available options tends to ease the obscurity of an unknown future for those with Borderline Personality Disorder.\nByrne, G. & Egan, J. (2018) Clinical Social Work Journal, 46, 174. https://doi.org/10.1007/s10615-018-0652-y\nGunderson, J. G., Herpertz, S. C., Skodol, A. E., Torgersen, S., & Zanarini, M. C. (2018, May 24). Borderline personality disorder. Retrieved from https://www.nature.com/articles/nrdp201829#management\nMcLeod, S. A. (2017, Feb 05). Attachment theory. Retrieved from https://www.simplypsychology.org/attachment.html\nSantangelo, P.S., Koenig, J., Funke, V. Parzar, P., Resch, F., Ebner-Priemer, U., & Kaess, M. (2017). Journal of Abnormal Child Psychology, 45, 1429. https://doi.org/10.1007/s10802-016-0249-2', 'Cognitive-Behavioral Therapy (CBT) for Addiction and Substance Abuse\nCognitive behavioral therapy, or CBT, is a form of psychotherapy that is effective in treating a range of mental health issues including mood disorders, anxiety disorders, and substance use disorders.1 CBT emphasizes changing negative thought patterns to change behaviors, as well as developing and implementing healthy coping skills into one’s life.1\nThis article will break down the clinical conditions that CBT addresses, how it helps those struggling with substance use disorders and other mental health conditions, and who this type of treatment might be right for.\nAmerican Addiction Centers offers cognitive behavioral therapy along with a variety of other therapies recommended for the safe and effective treatment of drug and alcohol addiction. To learn more about our program offerings and our various nationwide treatment centers, call\nWhat Is Cognitive Behavioral Therapy?\nCognitive behavioral therapy is a form of behavioral therapy and a well-established treatment intervention for people suffering from a wide range of mental health disorders. Cognitive behavioral therapy focuses on cognition, or how your thoughts can influence your mood – not vice-versa.2 CBT is a goal-oriented type of therapy that addresses cognitive issues such as dysfunctional automatic thoughts, maladaptive thinking (or cognitive distortions), and underlying core beliefs.2 Most therapists who use CBT customize the therapy to the specific needs of each patient.2\nCognitive behavioral therapy was developed in the 1960s by psychiatrist Aaron Beck.2 CBT originated when Beck’s perspective changed on mental health conditions from viewing depression and anxiety as mood disorders to viewing these conditions as cognitive disorders.2\nFor example, if a CBT patient’s automatic interpretation of a situation is seen through a negative lens of cognition (thoughts and beliefs), then it is likely to impact their mood negatively.2 Maladaptive thinking or cognitive distortions, such as overgeneralizing, catastrophizing, or personalizing situations, can cause errors in logic and misguided conclusions, sometimes resulting in or worsening of symptoms of depression, anxiety, and other mental health conditions.2\nUnderlying core beliefs can shape someone’s life and be the foundation for automatic thinking. Someone’s ways of thinking and perceiving can undoubtedly shape the way that they interpret the world around them (and their role in it).2\nBeck believed that dysfunctional, automatic thinking, even if it exaggerated or distorted, plays a significant role in mental and behavioral disorders.2\nThe ultimate goal of CBT is to address these negative patterns of thinking and subsequent behaviors to create positive change in a person’s life for the better.2\nAlthough CBT is effective in treating mental disorders, CBT can be helpful for anyone looking to make a shift in the quality and health of their thinking or improve their mood.\nHow Does CBT Work?\nThe fundamental principles of CBT are:1\n- Psychological disorders are based, in part, on inaccurate ways of thinking.\n- Psychological disorders are also based on learned patterns of negative behavior.\n- People suffering from psychological disorders can learn better ways of coping, thereby relieving their symptoms and subsequently creating positive changes in their lives.\nTherapists may also help clients by using role-playing techniques to develop a plan for how to deal with potentially problematic situations in the future.1\nFor example, creating a pros and cons list of reactions to various situations can help people gain an understanding of how their thoughts and actions may make things better or worse. It is important to play out those scenarios in therapy before they need to draw on them in life. Having a plan of action before a person needs this plan can help people feel more prepared and confident. Every person’s challenges in life are unique, so it is up to both the therapist and patient to develop a treatment strategy to address the patient’s needs. What works for one person may not work for another.1\nCBT with a trained therapist helps clients take control of their cognition and develop healthier ways to think, emote, and behave independently and through tangible exercises. The therapist and client work collaboratively to develop strategies to not only have an awareness of negative thought patterns and beliefs but to learn to problem solve and change their behaviors.1 It is a solution-based form of therapy focused less on the past and more on the present and what to do now to make things better.1\nGoals of CBT\nThe goals of CBT will include developing an awareness of one’s misguided thinking patterns that are creating problems in their life and re-evaluating such thinking in light of reality.1 CBT also encourages people to understand the motivation and behavior of themselves and others, as well as using realistic problem-solving techniques to solve problems.1 As a result, this should build a person’s confidence in their abilities to manage stressful situations.\nAnother goal of CBT treatment is to help people learn how to calm their mind and body and begin to face their fears instead of avoiding them.1 CBT can be an empowering tool to help people realize that they can manage their emotions and various situations they may encounter throughout their lives in a healthier manner.\nBenefits of Cognitive Behavioral Therapy\nCBT is a practical, goal-oriented form of therapy. It is a collaborative effort between the therapist and patient that can help the patient improve many aspects of their life.2 Treatment is individualized, so cognitive behavioral therapy may look different for different people. CBT has been shown to be beneficial in treating anxiety, depression, and even ADHD.2 It is also a form of short-term therapy, with weekly sessions typically lasting 2-3 months.2\nIs CBT Covered by Insurance?\nThe short answer is yes, cognitive behavioral therapy is typically covered by insurance. The Affordable Care Act mandates that health insurance companies must cover mental health and substance use disorders on par with coverage for medical or surgical procedures.5\nHowever, individual plans and coverage will vary depending on carriers. If you have questions about your coverage, call the number on your insurance card to find out more information about your specific plan. Some cognitive behavioral therapists accept insurance, but others may not accept insurance. Others may be out-of-network (OON) but offer patients the option of paying their therapy costs up-front and then sending a superbill to their insurance company for reimbursement. In that case, the therapist gives the client the paperwork necessary to submit their insurance claim directly to their provider.\nIs CBT Covered by Medicare and Medicaid?\nMedicaid is the largest payer for mental health services in the United States.6 The Affordable Care Act also expanded Medicaid benefits to millions of Americans that didn’t previously qualify. All Marketplace plans cover both mental health and substance use disorder treatments as “essential health benefits.7\nCBT is considered an evidence-based treatment option for mental health and SUDs. To find a provider in your area who accepts Medicaid and Medicare, click here to be directed to the U.S. Department of Health and Human Services webpage, which provides links to various resources and information regarding providers who accept these types of insurance.8']	['<urn:uuid:91ebc62c-89f0-4baa-853c-e3c62f6fc29b>', '<urn:uuid:9d5b97de-4c8a-441a-bd22-e316530a9cfe>']	factoid	with-premise	concise-and-natural	similar-to-document	three-doc	expert	2025-05-13T01:50:22.828293	14	61	1830
44	How does swimming ability relate to disease resistance in salmon?	Good swimmers naturally have higher disease resistance than poor swimmers when tested for infectious pancreatic necrosis (IPN). However, poor swimmers show the largest improvements from physical training - they can achieve similar resistance levels as good swimmers with optimal training, though they may worsen with non-optimal regimes due to lower adaptation capability.	['Aerobic exercise gives more robust smolt\nFarmed salmon smolts become more robust and more likely to survive if they undergo optimal aerobic exercise training prior to sea transfer. This was the main message from Chilean Vicente Castro in his doctoral defense in Norway recently.\nRobust smolts are characterized by Castro as smolts that have improved disease resistance associated with a strengthened cardiovascular system and better growth.\nStart while they are young\nCastro and his colleagues at Nofima measured the extent to which these parameters were improved by different physical training regimes in salmon juveniles (pre-smolts) in fresh water, thereby improving smolt robustness.\nOverall, his work demonstrates that by subjecting pre-smolts to physical exercise, there is a strong potential for the aquaculture industry to produce more robust smolts.\nThis can in turn result in lower mortalities caused by infectious diseases. Production losses are particularly high the first months after sea transfer, so preventive health measures must be initiated in juvenile fish during the freshwater stage.\nHow to train a fish\nAs salmon swim constantly, aerobic exercise training is achieved by changing the water velocity and flow conditions in the tanks so that the fish are motivated to swim in a controlled way and at higher speeds than normal over time.\nIn the trials at Nofima (the Norwegian Institute of Food, Fisheries and Aquaculture Research), several different training regimes with intervals and continuous flow were tested.\nGreatest benefit for poor swimmers\nIn one trial, Castro split the salmon population into two groups: good and poor swimmers. Interestingly, the fish that were categorized as good swimmers had an overall higher disease resistance than poor swimmers on a controlled infectious pancreatic necrosis (IPN) challenge test. After undergoing the physical training programs, the largest effect on disease resistance was recorded in the group of poor swimmers, with two outcomes.\nTheir performance was either improved through an optimal regime (achieving similar resistance level as good swimmers), or worsened through a non-optimal regime. This suggests that poor swimmers have lower capability to adapt than good swimmers.\nThe range of swimming velocity that appears to be optimal for improving overall robustness has been narrowed down by Castro and the research group. While it was earlier thought that 0.5-1.5 body lengths per second was optimal, they now have data that shows that 0.8-1.2 body lengths per second is optimal when including improved disease resistance.\n“In conclusion, aerobic exercise is good for all salmon but the weakest 50 percent of the fish may have the greatest benefit from swimming activity,” says Castro.\nPhysical exercise improved the growth rate, mainly because of an increased feed intake, meaning that fish will reach a given size faster when undergoing training programs than if they are not subjected to such programs.\nWhy training is good\nTo understand why training strengthens the disease resistance of the fish, Castro performed functional genomics studies, which uses genetic information to describe the functions and interactions of genes.\nThese studies showed that favorable physical training reduced inflammation levels in the heart and the innate immune system was strengthened through activation of several responses. These responses were probably instrumental in the researchers being able to find a lower reproduction of the virus in fish that had undergone physical training. Furthermore, results suggested that physical exercise had a strong effect on enhancing the cardiovascular capacity of the fish, an important factor in achieving high levels of robustness.\n“In future research, we need to further optimize the physical training regimes, so we can implement protocols with the potential of large benefits for the fish, the industry and the consumers,” Castro emphasizes.\nPossible utilization of this knowledge may also include improving the genetic material in breeding programs by sorting fish based on swimming performance.\nVicente Castro is 31 years old and is from Chile. On 29 June 2012, he defended his thesis entitled “Aerobic exercise training for improving robustness of Atlantic salmon (Salmo salar)” at the Norwegian University of Life Sciences. His supervisors were Senior Researcher Dr. Harald Takle from Nofima and Professor Dr. Ståle Helland from the Department of Animal and Aquacultural Sciences and Nofima.']	['<urn:uuid:9a92ee78-8d0e-4b92-b474-fd91166b19d9>']	open-ended	direct	concise-and-natural	similar-to-document	single-doc	expert	2025-05-13T01:50:22.828293	10	52	683
45	I'm from Texas and curious - what makes beans so special in Nigeria?	In Nigeria, cowpea (commonly known as beans) is the most economically important indigenous African legume. It is an extremely versatile crop that feeds people, livestock, enriches the soil, and supports other crops. Nigeria is actually the world's largest producer of cowpea, contributing 58% of worldwide production. The crop is widely consumed across Nigeria in various forms like moin-moin, bean cake, and bean soup. It's particularly nutritious, containing 20-25% protein and 64% carbohydrate, making it valuable for addressing malnutrition among the poor.	['This is a placeholder. Remove this element to add top adverts or real content\nCowpea is the most economically important indigenous African legume and most versatile African crop which feeds people, their livestock, the soil and other crops. In Nigeria it is simply known as ‘beans’. If you ask a layman in Nigeria what cowpea is, you would have a hard time finding the right answer but once you say Beans, they know exactly what you mean. There are two major varieties that are popularly known to people in southwest Nigeria; sweet beans or honey beans (ewa oloyin) and Nigerian brown beans (ewa drum).\nBotanically, it is called Vigna unguiculata and is grown in the semi-arid tropics which cover Asia, Far East, Africa, Central and South America. Cowpea has its root in Africa most especially South, West and East Africa but the name Cowpea probably emerged when it got to the United States of America and was used as an important feed for Cow.\nThere are a lot of great reasons why one should cultivate this crop; it can tolerate low rainfall and shortage of water, performs well in a wide variety of soils, and being a legume, it replenishes low fertility soils when the roots are left to decay, which makes it an ideal crop for crop rotation.\nCowpea is an annual herb which has a growth form that varies; it can be bushy, trailing, erect or climbing. Its root is a taproot which is quite strong and with many spreading lateral roots in surface soil. The stems of cowpea are striate, smooth or slightly hairy. Its leaves are in alternate pattern and are trifoliate, the colour of the leaves is dark green and shape varies from linear-lanceolate to ovate. Cowpea seeds also vary in size, shape and colour and the number of seeds per pod also varies.\nCowpea is an important economic crop, because of its various attributes such as: ability to adapt to different type of soils and suitability for intercropping, it grows and covers the topmost soil which in turn prevents erosion, all parts of Cowpea are useful even the leaves which can produce 9 times the calories, 15 times the protein, 90 times the calcium and thousands of times more vitamin C and beta-carotene of cowpea seed. Cowpea also complements a lot of cereal crops.\nClimatic condition requirements for cowpea- During growing season the temperature range for cowpea is between 280C-300C, its rainfall range is between 500-1200mm/year but some variety can thrive in areas with less than 500mm, in a nutshell this means cowpea will still survive in areas with low rainfall, although Cowpea requires enough moisture during the germinating period.\nCowpea does well on any soil but the best soil for cowpea is well-drained Sandy loam soil or Sandy soil with a soil pH in the range of 6 to 7, although its sensitive to water-logging conditions.\nCowpea is propagated by seeds.\nThe farm land should be cleared, removing shrubs and especially stubble; it can be sprayed with herbicide to stop the emergence of weed on the land, it should be plowed or harrowed for good root growth, you can also make ridges if you want. In a situation where the soil is fragile and prone to erosion one can make use of Zero tillage (this a process whereby one uses herbicides to control weeds and maintains crop residue on the soil surface)\nThe soil should be well tilled or pulverized (act of grinding to powder or dust) to ensure that the root of the Cowpea which is a taproot does not encounter any obstacle such as hardpan (a hardened layer, which happens in the soil and impairs drainage and affects plant growth), for easy penetration into the soil. The topsoil can either be ridged or left flat as seedbeds.\nCowpea does not necessarily need nitrogen fertilizer, but in cases where\nby the land has been used continuously for farming purposes, application of starter dose of Nitrogen up to 20kg/ha is good, especially when the organic matter is as low as 1%. For soils in Sudan and Sahel region in Africa, they are very low in phosphorous and potash and therefore phosphorous should be added as a single superphosphate, it does not only increase yield but also nodulation in Cowpea.\nThe inter-row and intra-row spacing depends on the type of variety of cowpea grown and the growing pattern, but generally for grain production, a plant population of 200,000 to 300,000/ha at 30 to 50cm inter-row spacing is preferred.\nThe seed should be planted at 3cm to 4cm deep. Planting should be timed in relation to the maturity period, such that the crop is harvested in bright dry weather. It’s best to sow when the soil is moist or wet, i.e. when the rainfall is reduced. The date of planting should be timed in such a way that will allow the crop to escape from periods of high pest, and harvesting to coincide with the period of dry weather because harvesting under humid cloudy weather favours pod rot.\nIf the farmer is to plant cowpea twice in a year it is advised for the first crop be planted in April and the second in late July to mid-August, if planting the same variety the older seeds should be planted not the recently harvested seeds, because seeds that are not properly dried fail to germinate well and plant stands are reduced. Also, seeds that will be planted must be sorted to make sure that they are free from insect damage that is it has no holes or wrinkles and are disease free.\nWeeds are unwanted plants which causes harm to a plant by competing for nutrients, lights, water and sunlight. Cowpea cannot easily withstand the competition of weed, especially at the early growing stage, if the weed is not well managed or controlled, it can accommodate pest and also reduce the yield and quality of the Cowpea. The type of control measure carried out, should be based on the nature of the weed. The weeding should be done 2 weeks after germination, but if a pre-emergence herbicide (this a chemical used to subdue weed) is used, the first weeding should be 4 weeks after. It is best to complete weeding by the 6th week, when the crop is already covering the ground. The two types of parasitic weeds that affect Cowpea are Striga and Alectra.\nCowpea is affected by a variety of diseases - fungal, bacterial and viral disease and these affects cowpea in different ways at different stages of growth.\nRoot Rot is caused by fungi, due to either damp weather or too much of moisture in the soil.\nStem Rot is caused by Phytophthora vignae, it occurs mainly in wetter coastal and sub-coastal areas, also occurs on waterlogged soils.\nMosaic virus affects leaves, the infected leaves are smaller than the healthy ones, and edges of the leaf are curly, generally the infected plants are more dwarfed and bushy, than non-infected plants. The disease also affects the formation of the pod.\nFusarium Wilt affects the leaves, it causes the lower leaves on one side of the plant to turn yellow, and plants infected are usually stunted and wilted. In order to control Mosaic virus and Fusarium Wilt it is s best to plant tolerant or resistant varieties. Although in the case of Fusarium Wilt root-knot nematode control practices should be followed since nematodes increase plant susceptibility to Fusarium wilt, and Cowpea is susceptible to nematodes, so it should not be planted consecutively on the same land. Other major and common diseases of cowpea are Anthracnose, Sclerotium stem, Damping off, Cercospora leaf spot, Septoria leaf spot, Scab, Bacteria blight (Xanthomonas vignicola) etc.\nSome general control measures include:\nCowpea is attacked by various Insect pests, during different phases of its lifecycle even down to storage. This is a major constraint to Cowpea production especially in West Africa, because the\nir damage can be as high as 80-100% if not well managed.\nThese are some of the major and important pests of cowpea :\nAphid (Aphis craccivora) - This insect pest does not just cause direct damage to the Cowpea, it also acts as a vector in transmitting of Cowpea aphid-borne mosaic virus. It damages the plant by sucking sap from the under surface of young leaves and stem issues, and on the pods. Sometimes it is recommended, not to control the insect pest until it is considered large i.e.when its infestation is threatening the crop, but if its few they can be easily pulled out, burnt or fed to livestock. The decision to treat is based on visual counts and the stage of crop development. Commercial pesticides are used to control aphids and the most effective are systemic pesticides, also heavy rains do reduce aphids.\nThrips (Megalurothrips sjostedti) - This pest attacks the flowering stage of cowpea. It can cause complete crop loss and in some cases where infestation is severe plants do not produce flowers or flowers appear distorted and discoloured, flower buds and flower can fall prematurely in some cases without forming any pod. This insect pest can be controlled by using insecticide or recommended chemicals.\nPod sucking bugs (Anoplocnemis curvipes): This pest attacks the pods of Cowpea. It causes a yield loss which varies from 30% to 70%\n,.They suck the sap from the green pods, causing them to shrivel and dry prematurely, which results in seed loss. It can be controlled using pesticide during podding period.\nCowpea weevil (Callosobruchus maculatus): It’s a serious Cowpea pest which affects it\nin during the storage period ,. it can completely destroy the grain within 6 months, although it’s considered medically harmless to humans. Hermetic storage (process of removing oxygen present in the atmosphere) technologies can also aid in controlling the pest. Freezing also can help control the pest.\nCowpea should be intercropped or mixed cropped and also grown as a cover crop for average yields to be attained. Cowpea should be harvested when the pods are fully mature and dry, but these pods do not mature at the same time because of its staggered flowering period. Cowpea varies in its growth habit from erect to semi erect types. Cowpea that is grown for vegetable purposes are picked 4 weeks after planting. One can either use hand or combine harvester to harvest the crop. More than 11 million hectares are harvested annually worldwide, 97% is from Africa and Nigeria harvests 4.5 million hectares annually. After harvesting, it is best to sun dry the pods and then thresh them immediately. This is important because drying reduces the moisture content of the grains\n, before storage in order to avoid the seed getting mouldy.\nAfter drying the seeds to about 10% or less and threshing the seeds, pods should be stored. It\n’ is advised to store the seeds using Hermetic storage techniques, the store should be cleaned before loading in new seed and also the seeds should be sorted before storing.\nIITA (2009) noted that there is a big market for the sale of Cowpea grains and fodders in West Africa and in Nigeria farmers who store Cowpea fodder for sale at the peak of the dry season have been found to increase their annual income by 25%. It also serves as income generating avenues for other value chain actors within the cowpea chain. Cowpea ensures returns for both the marketers and producers which in turn aids sustainability of the system.\nAbout 5.4 million of tons of dried cowpeas are produced worldwide from 11 million hectares, Africa produces nearly 5.2 million and Nigeria harvests 4.5 million hectares annually.\nNigeria is the largest producer of Cowpea worldwide\n, as 58% of worldwide production comes from this country yet Nigeria is still the largest consumer of the crop. To supplement our production, substantial amounts of Cowpea come into Nigeria from Cameroon, signifying that we are still not producing enough Cowpea to feed our nation.\nIn most parts of Nigeria Cowpea is been processed into other by products such as moin-moin, bean cake, bean soup etc. It contains 20%-25% of protein and 64% carbohydrate and has potential for poverty alleviation and malnutrition amongst the poor; also all parts of cowpea are useful, its vegetative part is good feed for cattle. This shows that all over Nigeria Cowpea is consumed in so many forms, thereby increasing the demand for cowpea.\nCOWPEA: Post-Harvest Operations culled from http://www.fao.org/\nhttps://csirsavannah.wordpress.com (PRODUCTION GUIDE ON COWPEA)\nAll data and information provided on this site is for informational purposes only. agriculturenigeria.com makes no representations as to accuracy, completeness, correctness, suitability, or validity of any information on this site and will not be liable for any errors, omissions, or delays in this information or any losses, injuries, or damages arising from its display or use. All information is provided on an as-is basis.']	['<urn:uuid:ed013e74-184d-4353-84c2-33cff6557f95>']	open-ended	with-premise	concise-and-natural	distant-from-document	single-doc	novice	2025-05-13T01:50:22.828293	13	81	2144
46	business verification risks mitigation strategies costs	Business verification through due diligence and cybersecurity audits serves two key purposes. For risk mitigation, due diligence provides comprehensive auditing of assets, examining corporate matters, material contracts, property rights, and legal compliance. This helps identify and assess existing and future transaction risks. Meanwhile, cybersecurity audits evaluate security measures, test networks/systems, and identify vulnerabilities to prevent costly data breaches. The costs vary - due diligence typically takes several days to weeks depending on audit scope, while cybersecurity audits require ongoing investment in assessments, employee training, and security infrastructure upgrades.	"['Due diligence is a comprehensive audit of an asset in order to identify and assess existing and possible future risks that may arise from transactions / operations with this asset.\nSuch audit is usually carried out by independent consultants:\n- in mergers and acquisitions transactions;\n- upon acquisition of shares or an interest in the company - target of the transaction;\n- when issuing credit or borrowed funds;\n- when creating joint ventures;\n- in transactions for the acquisition of real estate;\n- when attracting large investments (in particular, when entering an IPO);\n- when buying and selling an existing business.\nWhat is the scope of legal due diligence?\nDepending on the subject matter of the transaction and the objectives of the legal due diligence initiator, the scope and methods thereof may vary.\nFor example, in the case a credit is granted or funds are borrowed, the initiator of due diligence is most often a bank or other lender, in order to make sure of the proper status and stable financial position of the borrower. The scope of the audit, as a rule, is limited to such issues as the proper establishment and payment of the authorized capital of the borrower, the existence of risks of compulsory liquidation (as a result of material violations of the law) and challenging the transaction by third parties, net assets, the need for approval of the transaction by the management bodies of the borrower and / or by third parties (often referred to as ""corporate matters"" for convenience).\nIn the event of a sale of a business, the seller – its management and / or owner (s) of shares in the company may initiate due diligence for the purpose of justifying the assessment of the value of business and determining what terms of the transaction, i.e. price, the procedure for its payment and liability are fair and is any leverage to negotiate them with the buyer. The seller can also use the results of due diligence to improve the condition of the assets and minimize / eliminate risks, which ultimately leads to an increase in the value of the asset and improves the bargaining position in relationships with other potential buyers.\nIn M&A transactions, due diligence is usually initiated by an investor - buyer.\nThe scope of legal due diligence in transactions for the sale and purchase of a business as a going concern where 100% (or a controlling stake) of shares / interests in the target company is purchased, covers a wider range of issues.\nIn addition to the corporate matters, the following are analyzed:\n- the seller\'s rights to shares / participation interests, whether or not such rights are encumbered (including pledges and seizures); in particular, were there any violations sustained of the legislation in force at the time when the seller acquired shares / participation interests, including the need to obtain prior consent to the transaction from other shareholders / participants or the target company itself;\n- the need to obtain the prior consent of the Federal Antitrust Service of the Russian Federation or the government commission on strategic investments for the transaction, based on the value of assets and proceeds from the sale of goods, works and services of the target company, the buyer and their groups of persons, as well as the types of activities that the target company conducts;\n- the availability and validity of licenses / permits / membership in self-regulatory organizations, etc., necessary for the target company to conduct its activities; inspections by authorized bodies and detected violations of the licenses/other authorizations\' terms and conditions;\n- material contracts, including those providing for financial obligations (credit, loan agreements, etc.), in particular, their provisions in connection with the change of the company - target\'s ownership;\n- rights to immovable and substantial movable (fixed production assets) property, encumbrances of such rights (including pledges and seizures) and risks of claims of third parties (for example, a shareholder - a former owner of immovable property granted this property as a contribution to the authorized capital of the target company when it had signs of bankruptcy; in the event of initiation of a bankruptcy management procedure against the former owner, the liquidator can challenge the capital contribution as an invalid transaction and then sue the target company to recover the property from its illegal possession);\n- judicial and enforcement proceedings, signs of bankruptcy;\n- compliance by the target company with industry specific legislation - depending on the scope of its activity (on environmental protection, industrial safety, on the subsoil, etc.), risks of administrative liability;\n- intellectual property rights (patents, know-how, trademarks, service marks, commercial designations, etc.) of the target company and the observance of the intellectual rights of third parties by the target company;\n- compliance by the target company with labor legislation, employment contracts with top management, labor disputes.\nBased on the risks identified in the course of legal due diligence and the recommendations of external consultants to eliminate / minimize the consequences of such risks, the buyer gets broader negotiating opportunities:\n- to influence the price of an asset and the terms of its payment (for example, to provide in the contract for the retention of a part of the price within certain term after the closing of transaction and its payment subject to certain conditions subsequent);\n- to stipulate the seller\'s representations in connection with its corporate status and rights to the asset;\n- to provide for indemnities - the seller\'s obligations to reimburse the buyer for losses that may arise after the closing of the transaction in connection with claims by third parties or state authorities against the buyer and / or the target company.\nHow does the due diligence initiator obtain information and documents?\nWhen due diligence is conducted by the buyer, the information and documents are provided directly to the buyer\'s team which conducts the due diligence - as a rule, to external consultants, based on the checklist they prepare which is handed in to the seller and the target company.\nDocuments and information are most often provided electronically in a virtual information room; or, in the case of exclusive confidentiality, by granting to the due diligence team access to originals or copies of such documents, without the right or with the right of limited copying.\nThe due diligence team also receives information about the target company and the seller from publicly available sources, including open registers: the Unified State Register of Legal Entities, the Unified State Register of Real Estate, the Unified Federal Register of Bankruptcy Information, Open Registers of Rospatent, etc.\nDue diligence, as a rule, is limited by strict time frames - from several working days to several weeks, depending on the scope of the audit.\nIf the verification team is not provided with any of the requested documents and information due to their absence, this may, to one degree or another, influence the conclusions and recommendations regarding the identified risks.\nHow are the results of due diligence presented?\nBased on the results of legal due diligence, a report is prepared, which usually includes the following sections:\n1) Introduction, which describes: the transaction planned to be concluded; target company and areas of its economic activity; scope of due diligence and sources of information; limitations on the liability of external consultant that conducted due diligence; the right of the recipient of the report to disclose it to third parties (or prohibition to carry out such disclosure), the main contact persons of the external consultant if questions arise in connection with the content of the report; the date on which the due diligence report is issued, as well as the applicable assumptions (that all information provided as part of due diligence contains correct data, that the submitted copies of documents correspond to the originals, signatures and seals on documents are genuine, etc.).\n2) Brief conclusions on the results of due diligence (executive summary): this section contains a description of the most significant risks identified during due diligence, taking into account the provisions of applicable legislation and law enforcement practice, the estimated level of such risks (low - medium - significant) and recommendations for their elimination / minimization of consequences. For example, a due diligence may reveal several violations by the target company of industry legislation with an unexpired statute of limitations for prosecution, each of which may involve a significant administrative fine or suspension of activities; in this case, the report indicates the maximum amount of administrative fines and other penalties that may be incurred by the target company.\n3) The main part of the report, the structure of which is based on the due diligence scope, i.e. corporate matters, litigation, material contracts of the target company, containing a more detailed description of the identified risks, especially when it comes to the history of the acquisition by seller of its shares, history of acquiring rights to immovable and material movable property by the target company, terms and conditions of material agreements and labor contracts with top management, etc.\n4) Schedules to the report include:\n- a list of documents that were analyzed by the due diligence team;\n- a list with a brief description of the most important decisions of the management bodies of the target company (on the appointment of the sole executive body, the election of members of the board of directors and the management board, decisions on the approval of major transactions, transactions in which there is an interest, on increasing the authorized capital and admitting new participants, etc.);\n- a list with a brief description of the terms and conditions of material contracts (i.e. price of the contract, its validity period, governing law and jurisdiction, the possibility of unilateral termination of contracts);\n- a list of real estate assets (usually in the form of a table containing the following data: the name of the real estate object; location; cadastral number; area; details of state registration of rights; encumbrances with the rights of third parties (mortgages, etc.) ); rights to the land plot on which the corresponding immovable property is located, etc.;\n- a list of intellectual property rights, including the rights to software (drawn up in the form of a table containing: name and type of asset; right holder; encumbrances with third party rights; validity period of the right);\n- a list of judicial proceedings involving the target company.\nThe content of this article is intended to provide a general guide to the subject matter. Specialist advice should be sought about your specific circumstances.', 'In today’s fast-paced technological world, cyber threats have become a common occurrence for businesses of all sizes. From hacking to data breaches and identity theft, the potential risks are endless. That is why maintaining a secure online environment has become crucial for any business that wants to ensure the protection of its intellectual property, customers’ personal information, and remain legally compliant.\nKeeping up with the ever-evolving digital landscape requires forward thinking organizations to prioritize cybersecurity. Regular cybersecurity audits are an integral part of any business’s security strategy, and in this article we’ll dive into what they entail and why they’re so important.\nThe importance of cybersecurity audits cannot be ignored in today’s business landscape. Cybersecurity risks are becoming increasingly sophisticated, and businesses need to take proactive measures to protect their sensitive data and systems from potential breaches.\nA cybersecurity audit is a comprehensive assessment of an organization’s information security policies, procedures, practices, and systems designed to uncover vulnerabilities that could be exploited by cyber attackers.\nRegular cybersecurity audits help businesses stay up to date with the latest threats and continually improve their security posture. These audits also ensure compliance with legal regulations related to data privacy such as GDPR or HIPAA. Some other key benefits of cybersecurity audits include identifying gaps in defenses before they can be exploited, increasing employee awareness about security best practices, and establishing a baseline for future improvements.\nConducting regular cybersecurity audits is vital in protecting your business from the ever-evolving cyber threats that exist today. It not only helps prevent costly data breaches but also promotes trustworthy relationships with customers who entrust company information through online transactions. As technology continues to change rapidly over time, these periodic assessments become even more crucial for maintaining strong protection against unforeseen malicious attacks on critical infrastructure within any organization.\nA security audit is an assessment that aims to evaluate the effectiveness of a company’s cybersecurity measures. It involves comprehensive testing and analysis of various aspects, including software programs, networks, servers, databases, access controls, policies and procedures to identify potential vulnerabilities or weaknesses that hackers could exploit. This type of evaluation provides key insights into areas where an organization needs to improve its security strategies.\nThe purpose of conducting regular cybersecurity audits is not only to identify current threats but also to proactively anticipate potential future attack scenarios. These evaluations help companies stay ahead of emerging threats by keeping their systems up-to-date with the latest patches and protections against malicious activities. Regular assessments can also identify gaps in staff training or suggest additional measures for reducing risk factors adequately.\nWhen preparing for a cybersecurity audit, there are several crucial factors to consider. First, it is important to choose an experienced and reputable company that specializes in cybersecurity. The auditor should have the knowledge and expertise necessary to identify potential vulnerabilities and assess risk within your specific industry or area of business.\nDuring the audit process, the auditor will likely review your organization’s security policies, procedures, controls, systems architecture, and incident response plans. They may also conduct penetration testing to determine whether there are any weaknesses in your networks or applications that hackers could exploit.\nAnother important consideration when preparing for a cybersecurity audit is ensuring that all necessary documentation is available and up to date. This includes policies and procedures related to data privacy and protection, employee training materials on cybersecurity best practices, incident response protocols, disaster recovery plans, etc.\nProactive measures like conducting periodic cybersecurity reviews with a reliable external auditor and staying informed of the most up-to-date compliance requirements for data privacy, such as GDPR and CCPA, are key to shielding businesses from costly security breaches. Taking these steps helps ensure that any potential vulnerabilities can be detected and addressed immediately, so companies stay ahead of ever-evolving cyber threats.\nImplementing regular cybersecurity audits is an essential step for any organization that wants to safeguard its assets from potential cyber threats. These audits involve evaluating the company’s network infrastructure, policies, and procedures to identify any vulnerabilities and areas that need improvement. To implement these audits effectively, it is important first to develop a comprehensive security plan based on industry best practices and regulatory compliance standards.\nNext, organizations can work with their IT teams or hire third-party professionals specialized in cybersecurity auditing to conduct thorough assessments of their systems regularly. The audit should cover various aspects such as password management protocols, access controls, software updates and patch management systems, firewalls configuration checks among others.\nAfter conducting a detailed audit, an analysis report outlining all the found vulnerabilities that need to be addressed will be generated. Timely and effective corrective action should be taken to mitigate or reduce any potential risks of attacks from external sources like ransomware attackers. These attackers can encrypt your files, demanding payment in exchange for them being opened up again. Such situations may harm the reputation of your business and lead to mistrust from clients; therefore, preventive measures must be taken to protect against this now and in the future.\nRegular cybersecurity audits play a crucial role in keeping businesses safe and secure from ever-changing cyber threats. As digital technology continues to advance, the importance of staying ahead of potential risks cannot be overstated. These audits serve as an essential component in identifying vulnerabilities, assessing gaps, and implementing proactive measures against cyber-attacks.\nConducting frequent audits not only prevents financial losses but also helps maintain customers’ trust by safeguarding their sensitive data. While investing time and resources into cybersecurity audits may seem daunting for some organizations, it is imperative to view them as an investment in the long-term viability of the business.\nCybersecurity is no longer optional for most companies; it’s a necessity in today’s increasingly digitized world. Organizations that prioritize conducting regular cybersecurity assessments will gain peace of mind knowing they have taken all necessary steps towards maintaining healthy security hygiene while preventing potentially devastating breaches or losses.\nEssential Steps for Restoring Your Network and Rebuilding Trust\nThe True Cost of a Data Breach\nEducating Employees as the First Line of Defense\nEnter your details below and we will contact you within 1 business day.\n""*"" indicates required fields']"	['<urn:uuid:02179dd4-e98a-4bb8-8493-7dc12a429399>', '<urn:uuid:ee1a90ee-9bc1-4a29-8ef0-e3673db2ff2b>']	open-ended	direct	short-search-query	distant-from-document	multi-aspect	expert	2025-05-13T01:50:22.828293	6	88	2777
47	What role do external pressures play in business decision-making?	External pressures fundamentally shape business decision-making in several ways. The business environment, consisting of all external forces like social, economic, political and technological factors, provides critical information that becomes the basis for organizational decisions. These external factors are uncertain and dynamic, requiring businesses to continuously monitor and adapt their decisions. Location-related external pressures such as transportation logistics, workforce availability, and economic incentives influence major decisions about where to establish, expand or relocate operations. Companies must also consider external pressures when making operational decisions, as factors like supplier access, customer reach, and infrastructure quality affect productivity and costs. The interrelated nature of these external forces means that changes in one area often impact multiple aspects of the business, making it essential for companies to consider the full range of environmental factors in their decision-making process.	"['Meaning of Business Environment\nThe business environment refers to all the external forces which affect business decisions. It mainly consists of social, economic, political, and technological factors. All these factors which affect the business environment are beyond the control of business progress. Business organizations can control all these only up to a certain level.\nIn other words. the business environment can be termed as the total of all the external forces. That affects the business functioning and are beyond its control. They are due to this is uncertain in nature. Business environments are actually dynamic in nature, which means that it keeps on changing and do not remain constant.\nIt changes according to the change in various factors. Like changes in preferences of customers, Coming to better competition and improvement in technology, etc. An important feature about the business environment to be noted is that it is uncertain and is challenging to predict hence necessary steps to take actions according to conditions should be taken.\nThe study of the environment of the business helps us to detect the strengths, weakness, threats, and opportunities. Once these are detected necessary steps can be easily taken. These factors analysis is better for proper growth and continuity of the business.\nObjective of Business Environment\nIdentify Business Opportunities\nThe business environment helps the business to find opportunities in the market. Change in the market condition, customer behaviour, technology, and other factor, business need to finding new opportunities. Business needs to change to survive in the market. Business needs to identify the problem of the market and solve it to gain the customer.\nThe company is a group of activities undertaken with the possibility of a sale to make a profit. The business environment helps to improve sale and profit. The main aim of any business is to make a profit. If the sales grow it leads to an increase in profit. Higher profit means the performance is also increasing.\nBasis of Decisions\nThe business environment provides information about inside and outside of the organization. The information related to change in culture, fashion, trends, customer purchasing power, and others. This information becomes the basis of the decision of any organization.\nSurvive in the Business\nSurvive in the market is very difficult in the time of competition. The business environment helps the business to find out information about the internal and external environment. So that the business can make Good decisions to survive in the market.\nMaking of Policies\nThe business makes policy according to the market conditions. The market condition can find out by analyzing the environment of the business. This is how the business environment helps in the making policies of the organization.\nAssistance in Planning\nPlanning is the fundamental management function, which involves deciding beforehand, what is to be done, when is it to be done, how it is to be done, and who is going to do it. The business environment provides enough information to make a plan for the future.\nFeatures of Business Environment\nInfluence Business Planning And Performance\nThe business environment directly influences the planning and performance of business organizations. Business planning and the environment go together. All plans and policies of business are framed in accordance with situations of environment.\nThe environment provides the basic framework within which business is required to operate. It influences the performance by providing various opportunities or obstructions. Business is able to operate efficiently with the support of their environment in which they exist.\nBusiness for its continuity and growth is required to adapt to environmental changes. In order to survive, business needs to works in accordance with its environment. Every change in the business environment brings several opportunities and threats to it.\nIt affects their performance and profitability. The business needs to continuously monitor these changes and should take all corrective measures accordingly. These changes are in terms of change in customer taste or preferences, technological improvements, and entry of various new competitors.\nSeveral factors that make up the business environment are interrelated with each other. Change in any one of the factors of the business environment will bring changes in several other factors. With the rise in the price of raw materials, the final price of products will also go up due to which customers will either stop buying or will buy less of products thereby reducing the overall revenue of the business. In this way, all factors are connected to each other.\nThe business environment is uncertain in nature and cannot be predicted. Factors that constitute business environment changes very rapidly and no one can determine them in advance. Prediction of several future conditions that affect business is quite difficult because no one knows what is going to happen in the future. These changes occur too frequently like change in IT, fashion, demand, technology, economic conditions etc.\nBrings Strengths And Weakness\nEnvironmental changes bring certain strengths and weaknesses to business. They may pose unfavorable situations or threats to business and may even bring opportunities for business. The business should keep an eye on all environmental changes to detect all opportunities as early as possible for taking maximum benefits out of it. Also in case of any unfavorable situations businesses can make effective plans timely to minimize the losses.\nRelative In Nature\nThe business environment differs from business to business or from country to country. The environment of business have relativity to place where it operates. It changes in accordance with local conditions of the area in which business exists.\nThe business environment varies from place to place, region to region, and country to country. The technology used in different countries differs from each other and accordingly business need to frame their policies. The nature of products demanded will vary from country to country like shalwar kameez will be in more demand in India than in the U.S.A.\nThe environment around the business is dynamic in nature. It keeps on changing regularly. The business environment does not remain the same for a longer period of time and changes frequently. It is due to several factors that constitute the environment and their ever-changing nature. All these always changing factors bring changes in character and shape of the business environment making it dynamic.\nMutual Interdependence Between Business And Environment\nBusiness and its environment are interdependent on each other. Business depends on its environment for various inputs like raw materials, labor, machinery, capital, etc. In the same way, the environment is dependent on the business organization for various goods and services manufactured by it. Businesses manufacture goods and deliver them to the environment in return for inputs supplied by them.', 'Choosing the right location for your business not only helps increase sales and reduce costs, it can also help you increase productivity. Creating goods and services faster, while maintaining high quality, is a key piece of the profit-maximization puzzle. Where you locate your company can affect your ability to efficiently move people, materials and finished goods through your facility.\nSupply chain management is key to maximizing productivity. If one part of the supply chain is interrupted, the rest of the sales, production and distribution processes can stall. When businesses launch, expand or relocate, they consider their need to get raw materials into their production facilities. When managing the business site selection process, companies look at rail, air, road and sea transportation logistics to determine how effective these will be for receiving supplies. Companies also consider how easy it will be for customers and suppliers to reach the location for business meetings. Even for small local businesses, such as restaurants, banquet halls, delis or caterers that need to get fresh-baked bread, meats and vegetables several times a week, efficient access to suppliers is key to productivity.\nCompanies that ship their goods to wholesalers, distributors, retailers and direct customers rely on efficient outbound logistics. They might need to send samples to customers and suppliers on a regular basis for approval. Sales reps will be more productive if they have access to road systems and airports that are cost-effective and reduce travel time. An efficient outbound logistics system improves productivity by reducing travel time and costs, allowing companies to respond to customer and distributor needs faster, and deliver finished products to market quicker.\nEconomic Development Incentives\nCities, towns, counties, corridors and states offer relocating businesses a variety of incentives to come to their areas. These can include tax credits, reduced utilities costs, infrastructure improvements and free or low-cost buildings. Infrastructure improvements might include a new road created to service a new manufacturing or distribution facility, or a rail spur built to a specific location to help with distribution. Locations that help businesses streamline the permitting process, offer to re-zone properties or reduce operating hour restrictions help improve productivity.\nAbility to Attract Workers\nMore qualified workers and higher retention employee rates improve productivity through more innovation, better efficiency, and reduced employee replacement and training costs. Long daily commutes decrease the quality of life for employees and raise their out-of-pocket costs to work at a company. Air travelers who can’t get nonstop flights can spend long days in airports, decreasing their job satisfaction. A business location offering affordable, accessible public transit, a short road commute or a nearby airport with nonstop flights to frequently traveled cities can help businesses recruit and retain better workers. Locations offering a higher quality of life, such as good weather, low personal income taxes, good schools and natural and commercial attractions help attract and retain more productive workers.\n- Photo Credit Elena Elisseeva/iStock/Getty Images\nWhy Is Business Location Important?\nIn the world of business, analysts always say, ""Location is everything."" Is that really true? Can the location represent the single factor...\nHow Does a Region\'s Geography Impact its Economic System?\nGeography plays a major component in the development of a country\'s economic systems. Economic geography, a subset of human geography, is based...\nThe Impact of Location on Business Success\nThe location of a person\'s business is one of the most important variables in determining potential success. Businesses need to establish locations...\nHow to Select a Business Location\nWhen starting a business, choosing your business location is one of the most important decisions you will make. A great location can...\nThe Environmental Factors That Affect a Business\nThe environment, or the uncontrollable factors that affect how a business operates, can have significant effects on an organization\'s productivity and success....\nHow Taxes Affect Businesses\nTaxes affect businesses in a variety of ways, from influencing the particular legal structure of the business to where the business chooses...\nSocial Factors Affecting Retail Business\nSocial factors that affect the retail business come in a broad range of categories. Most importantly, there are key factors that retailers...\nHow Does the Geography of a Region Affect Its Economy?\nGeography plays a substantial role in the development and success of an economy. Historically, economies near ports and travel routes grew rapidly...\nFactors that Contribute to Business Success\nWhile it is impossible to declare with certainty what new businesses will succeed and which will fail, certain factors can indicate that...\nEnvironmental Factors Affecting Business Decisions\nTo be successful, both new and existing businesses use several factors in the environment to gauge the direction in which they should...']"	['<urn:uuid:e043f0ae-62d8-49b5-b5fd-f2896376cb61>', '<urn:uuid:8df58c72-3c94-4881-9825-88eb745fd0a0>']	open-ended	with-premise	concise-and-natural	distant-from-document	three-doc	expert	2025-05-13T01:50:22.828293	9	134	1872
48	Which faces more challenges - Monaco's cramped territory or La Palma's alleged tsunami threat?	Monaco's high population density of 25,718.1 people per square kilometer represents a real and present challenge, making it the most densely populated country in the world within its tiny area of under 1 square mile. In contrast, La Palma's tsunami threat is largely unfounded - scientific organizations like the Canarian Volcanic Institute, Southampton Oceanography Centre, and The Tsunami Society provide evidence against it. The possibility of a devastating tsunami reaching places like Florida is negligible, as even a 20-meter high Lisbon earthquake tsunami was barely measurable across the Atlantic. The La Palma tsunami story appears to be speculation for commercial purposes rather than a genuine threat.	"[""||La Palma Tsunami\nThe mega-hyped tidal wave story\n|Visit La Palma|\n|La Palma photographs and tourist information|\n| ..... more information|\n|The list of scientific organisation with contra-evidence now includes:|\n|*||Canarian Volcanic Institute|\n|*||Southampton Oceanography Centre|\n|*||The Tsunami Society|\n|*||Charles L. Mader, Tsunami expert|\n| .... more information|\n|The original arguments:|\n|The proposed theory is basically that if volcanic activity1 occurs on a large enough scale water trapped2 in the volcanic rocks will be super-heated under pressure3 and will suddenly explode4 with such force that a huge chunk5 of La Palma will suddenly and very very rapidly6 drop into the sea and cause a Mega-Tsunami7 that would grow in size and cause damage8 when it reaches Florida.|\n|Point 1: volcanic activity|\n|'La Palma is the most active volcano in the Canary Islands'.|\nIt sounds dangerous doesn't it. It isn't. In comparison with Japan, Hawaii and Italy the La Palma Cumbre Vieja volcano is almost dead.\nWhen you talk to people about active volcanoes they immediately image a large pointed mountain with a crater in the top with red hot lava, steam, smoke, boiling mud pools, and they imagine that new ash and smoke comes out every few days.\nLets get this into perspective. There is no big pointed mountain with a smoking crater on La Palma. People point to the Caldera de Taburiente as if it is a volcano, but it isn't. It was formed by a volcano but is not a volcanic crater. The hole in the middle was formed over the centuries by erosion and not by a volcano or a sudden massive collapse. It is the worlds largest erosion crater and well worth a visit.\nThe volcanic cones on La Palma are small and completely dead. It is a spectacular landscape but there is no steam, no smoke, no bubbling pools and no red hot lava. There used to be one very small area where the earth felt warm but even that has cooled down now.\nSome reports refer to La Palma, Mount St. Helens and Krakatoa in one breath. This is disinformation at its worst. There is no comparison between these volcanoes. It's like comparing lions, tigers and hamsters ... they all have teeth so they must be dangerous man-eaters 'Buy hamster-mauling insurance before its too late!' 'Invest in hamster hazard-warning systems now!'.\nThe original report states that all volcanoes previous to 1949 have not caused any longitudinal rift in La Palma. The 1949 appears to have caused a 4km long scratch at the surface. Proof that it is 2km deep is not in evidence.\nLa Palma is constantly monitored and no seismological movements have been registered on the Cumbre Vieja volcano since 1949.\n|Points 2 and 3 : trapped water under pressure|\n|There is lots of water in the rocks of La Palma, just as there is in most of the world's porous rocks. This is not unusual, it is perfectly normal and most of the world gets its water from water contained in rocks. No problem.|\nFor the 'exploding super-heated water under pressure theory' to be realistic there would have to be 2 parallel, solid vertical walls of impermeable granite or basalt both extending for 25km along the length of La Palma to a depth of at least 2km and without any breaks. To enable the required pressure to build up there would have to be a solid layer on top of these two 25km walls to keep the pressure in. Without all these conditions there is no possibility of a pressure build-up. The rocks on La Palma are very porous; they allow the water to get in and out at will.\nWithout the 2 walls and the solid roof it would be like boiling water in a frying pan.\n|Point 4: explode|\n|Exploding volcanoes are the basis for several Hollywood movies. In reality there have been very few occurrences. This is because a special type of magma (underground molten lava) and millennia long subterranean and superficial build up of rock formations is required to develop the circumstances in which a volcano will catastrophically explode.|\nThese conditions do not and will not exist on La Palma. La Palma volcanoes cannot explode.\n|Points 5 and 6: huge chunk, suddenly and very very rapidly falling into the sea|\n|This is where reality and statistics suddenly start to take giant leaps away from each other. The researchers problem was, of course, to figure out how much water would need to be moved to create damage (in the future) and panic (now) in Florida. Enough panic to sell lots of insurance and generate investment in further research projects on which they are dependent.|\nThe answer is that it would need a very large amount of rock to break off La Palma and slide into the sea with enormous speeds and as one great big block. Only if this happens would there be a splash big enough to reach America.\nThe researchers point to 2 large piles of rubble under the sea next to La Palma as evidence that this has happened before. The problem is that the rubble only proves that rock from La Palma has fallen into the sea. It does not provide evidence that all the rock fell into the sea as a single massive block and cause a tsunami. It is much more likely that this pile of rubble is caused by continual natural erosion as occurs all over the world. The researchers who have spent 20 years studying these rocks were not consulted on the Mega-Tsunami theory. After seeing the documentary they issued a statement stating that a single event collapse of the west side of La Palma was very unlikely and the physical evidence points to a series of small landslides over a very long period of time.\nSo where is the evidence for the boundaries of the rock slide used in the mathematical model??\nHaving shown that there is a fault line on the west side of the Cumbre Vieja you would expect that this would be the line used in the model. WRONG. The line used in the model is situated 2 to 3km to the EAST, on the opposite side of the Cumbre Vieja. Why? .. otherwise the splash wouldn't be big enough?\nThen there are the Northern and Southern extents of block. Where are they? Firstly the physical evidence on the ground is of a 4km long split. The claim is that this split is the upper edge of a fault line extending 2km under the ground. No evidence has been presented to support this theory. It could just as easily be a scratch on the surface extending just a few meters below the surface. But in any case the length of the split used in the model is 25km. WHY? There is evidence for 4km so they added 21 extra kilometres for which there is no evidence what so ever? The answer is getting boring ... because without this unjustified exaggeration the boats in the harbour on the next island wouldn't even start to rock.\nHow deep would the lower boundary of the block be? In the original report it is stated that there is no physical evidence by which to estimate the base of the block. Despite this lack of evidence a guess of 2 to 3km below the surface was used in the mathematical model.\nAnd then there is the question of the speed of the block. If this is not fast enough there will be no tsunami. A speed of 100 meters per second was used. A comment in the report shows that this cannot occur when a rock block slides over rocks. There has to be a lubricating substance at the base of the block otherwise nothing happens!! The suggestions are mud (at 2-3km under the ground?), water pressure (in the open lava on La Palma?) or heat from horizontal dykes which would have to be red hot, several meters thick and suddenly push their way through solid rock at the correct downward angle over a length of 25km, and travel 10km towards the sea almost instantaneously.\n|Point 7: cause a Mega-Tsunami|\n|This assumption is very debatable. The evidence that tsunamis are caused by landslides is limited. The evidence of destructive tsunamis is only present when the landslide occurs in a bay or enclosed channel between landmasses. La Palma is not in a bay. La Palma has no other landmass between it and Brazil/Caribbean/Eastern USA, there is no enclosed space.|\nThe 'classic' mega-tsunami occurred in 1958 in Lituya Bay, Alaska. There are 3 theories about how it was caused, one of which is an unproven catastrophic landslide theory. The tsunami caused much damage in the narrow inlet but did not travel great distances and caused only local damage.\nOther recorded tsunamis were caused by earthquakes and not landslides. Comparisons of La Palma with Krakatoa and Mount St.Helens are incorrect and (deliberately?) misleading.\nSuggestions that the strange position of boulders and chevrons in the Bahamas is related to the collapse of El Hierro in the Canary islands are pure speculation and are NOT based on scientific research. In fact the author of the original report suggested in 2001 that geologists should start looking for evidence of the effects of a possible tsunami on the East coast of America, Brazil and the Bahamas, which is a sure indication that no such evidence existed at that time. Even mentioning a possible link can only be described as deliberately misleading. Geologists in the Bahamas insist that the chevrons could not have been caused by a tsunami.\n|Point 8: damage in Florida|\n|A tsunami created in La Palma will not reach Florida. Even the 20 meter high Lisbon earthquake tsunami was hardly measurable when it reached the other side of the Atlantic.|\nThe algorithm used to prove that it will is based on evidence from linear under-sea earthquakes and is not valid for single-point events like a landslide on La Palma. The volume of water which might be displaced will not travel as a straight line which inherently maintains its height and volume. It will travel as ripples which rapidly dissipate to insignificant levels within a very short distance.\nExample: If the amount of water is displaced is 10 meters high and travels as part of a massive linear wave then that mass will remain supported by the block next to it and retain its height over great distances. The base area of that water will remain roughly constant. In a single-point the wave radiates out over 180 degrees and the same amount of water will be spread very thinly over a wide area.\nImagine filling a 10 metre long and 10cm high balloon with water and pushing it along the road. Provided the balloon doesn't burst the balloon will stay 10cm high until it meets an obstacle. That is what happens in an earthquake-induced tsunami. In a landslide-induced tsunami the ends of the balloon would go off at (say) 90degree angles. For every meter the balloon goes forward it will be stretched in length and the height of the balloon would be reduced very quickly.\n|The evidence for a total and sudden collapse of the western flank of La Palma is not based on provable facts. The chance of a total failure of the dimensions suggested is negligible. The probability that anything will happen in the next 1000 years is a very small. |\nThe La Palma Tsunami story is just that, a nice horror story to frighten people into buying insurance and to frighten governments into investing in hazard research and hazard warning systems.\nI believe it to be speculation and scaremongering for commercial purposes."", 'While the world’s population continues to increase year on year, some highly-populated states have become record holders when it comes to population density.\nThese aren’t necessarily the countries with the highest population numbers, but more often the countries with a small land surface where population has boomed in recent years, driving architects to come up with ever more inventive ways to find housing for everyone.\nLet’s have a look at the world’s most densely populated countries.\nList of Most Densely Populated Countries\nThe tiny country of Monaco often gets overlooked as a country altogether! Situated on the French riviera, the principality covers under 1 square mile, but is a highly desired place to live because of its tax rules, and mild climate. As such, lots of professional athletes have flocked to live in Monaco, particularly cyclists who enjoy its winding roads for training (and proximity to great cycling locations in France, too).\nThe population density of Monaco is 25,718.1 people per square kilometre, making Monaco the most densely populated country in the world.\nThe city state of Singapore embodies the architectural symbol of over-population. Its high-rise buildings are emblematic of this destination. Moreover, to handle its large population, Singapore has an excellent public transport system.\nThe land covered by Singapore is 277.6 square miles and its population density is 8,226.7 people per square km.\nBahrain is a rich Middle Eastern country and extends over only 295 square miles, making it the third smallest country in Asia after Singapore and the Maldives. Population density is 1969.2 people per square km, making Bahrain third most densely populated country on earth.\nThe Kingdom of Bahrain is exceptionally wealthy and also relies not just on oil for its economy, unlike many of its neighbours. They have invested heavily in banking and tourism, so many international financial institutions are represented there, which will explain additions to its heavily populated status. Bahrain also has a Formula 1 race track and started hosting the Bahrain Grand Prix in 2004.\n4. The Vatican\nAs a country in its own right, Vatican City actually has a very large population compared to the surface it covers. There are around 1,000 people registered as living in the Vatican, and its surface is only 110 acres. This means that population density is 1,818.1 people per square km, on top of the thousands of tourists who crowd here every year to visit the sights.\nVatican City is an ecclesiastical and sacerdotal-monarchical state, unique in the world as it is ruled by the Pope who is the head of the Catholic Church. All its top functionaries are also Catholic clergy from all over the world. The country’s economy relies heavily on the tourism income from people visiting the famous St Peter’s Basilica, the Sistine Chapel, and other museums. The Vatican also gets an income from stamps, souvenirs, and sales of publications.\nThe small nation of Malta is part of the European Union and a popular tourist destination in the Mediterranean. Its capital city is the smallest in Europe at 0.8 square km – La Valletta.\nMalta places fifth on our list of most densely populated countries with population density of 1,364.6 people per square km. This former British colony is part of the Commonwealth and a popular tourist destination with great climate and some interesting UNESCO World Heritage Sites.\nWhilst previous countries occupy a relatively small surface, Bangladesh covers 56,980 square miles and still has a density of 1,252 people per square km. This is close to three times the density of India which we are all used to thinking of as a densely populated state. Bangladesh is also the 8th most populous country in the world, with c. 161 million people living there. Despite challenges like corruption and climate change, Bangladesh is actually a growing economy where one can expect that the GDP per capita will continue to grow, and the country has recently been upgraded by the World Bank to the status of a middle-income country.\nThe Republic of Maldives is a small island nation and one of the most densely populated countries in the world. Located in the Arabian Sea, the Maldives are a very popular holiday destination due to their exotic landscapes and beautiful beaches, but little do tourists realise that the permanent population of this small country is actually so dense. Over only 115 square miles, the population is just under 400,000 people, hence population density is 1,102.5 people per square km. The Maldives’ capital, Malé, is the busiest city. The Maldives are also one of the world’s most geographically dispersed states because the country itself is made up of an archipelago of islands.\nThis Middle Eastern country has a whopping population density of 1,450.4 people per square km. It’s a relatively small country, but has a rich and diverse culture after a history of being ruled by the Ottoman Empire and then colonised by France. The Lebanese diaspora is very influential and many cultural figures obtained their education in France and went on to play an important role in the development of the Arab world. Lebanon also used to be known as the “Switzerland of the East” as it was very wealthy during the 1960s. Unfortunately, civil war wreaked havoc with the economy in 1975-1990 and the country is still recovering from the setback.\nWith only 167 square miles of surface, Barbados is a tiny country. However, its 227,821 people mean that its population density is 660 people per square km, one of the highest densely populated countries in the world. Independent since 1966, Barbados used to be a colony of the British Empire and is now part of the Commonwealth. Despite being geographically labelled as an Atlantic island, Barbados is seen as part of the Caribbean, and it’s one of the top tourist destinations in the Atlantic Ocean.\nThere you have it – the world’s most crowded countries, some tiny city states and some isolated islands where the population has congregated close together. If you’re looking for peace and quiet, these destinations would be the exact opposite, but they make for interesting sights nonetheless!\nI hope that this article on countries with the highest population density was helpful. If you are interested, visit the Country Rankings Page!']"	['<urn:uuid:34ccea20-48eb-41e8-866d-d55e285816bc>', '<urn:uuid:c7c75d9c-1f2b-421b-9294-e88c8ee1beac>']	open-ended	with-premise	concise-and-natural	distant-from-document	comparison	expert	2025-05-13T01:50:22.828293	14	106	2988
49	Who was the first person to invent perfume making?	The first recorded chemist was a Mesopotamian woman named Tapputi-Belatikallim. According to a cuneiform tablet from the second millennium B.C., she was the first to document the process of distillation. She held an important position in the Mesopotamian court as a 'female palace overseer' and created fragrant waters, tinctures, scent extractions, and cold enfleurage for the royal family and religious ceremonies.	"['You may not think about it too much when you\'re dabbing on your favorite fragrance but scent has played an important role in societies for thousands of years. Used to stimulate memories, seduce, and bewitch, the farther back you go, the use of scent becomes more complex and tied to more than just simply smelling sweetly.\nLimestone relief fragment of a perfume press – ca. 2051–2030 B.C. Egypt, Tomb of Neferu\nThe ancient Egyptians and Mesopotamians were making fragrance as far back as 3000 BC, using aromatic resins and incense in most of their oil based fragrances. The very first chemist on record was in fact a Mesopotamian woman named Tapputi-Belatikallim. A cuneiform tablet from the second millenium B.C. describes Tapputi\'s process as a perfume maker and is the first documentation of the process of distillation. Tapputi held a position of great importance in the Mesopotamian court, Belatikallim a title meaning roughly ""female palace overseer"", and created fragrant waters, tinctures, scent extractions, and cold enfleurage for the royal family and the religious ceremonies carried out at court.\nLeft: Egyptian perfume vessel in shape of a monkey, 1550–1295 B.C. Right: Egyptian Perfume bottle in the shape of a hes-vase inlaid with the figure of a princess, 1353–1336 B.C. Travertine (Egyptian alabaster), carnelian, obsidian,gold, and colored glass inlay\nAt this time, perfume would have communicated a person\'s station in society more than their desire to beguile - the poor wore no fragrance at all and the precious ingredients used to make the nobilities perfume would have been an olfactory ""reveal"" about the wearer\'s class and affluence. Perfume was also a major driver of international trade relations as Egyptians imported many of their ingredients, such as aromatic woods, incense and myrrh, from Punt, a region in Africa, and other ingredients from Arabia, the Middle East, and India.\nLeft: Bronze incense burner, Southwestern Arabia – ca. mid-1st millennium B.C. Right: Greek thymiaterion – 2nd half of 4th century B.C.\nOther ancient societies saw fragrance as less of a societal divider and more of a powerful purifier. Though the ancient Chinese did wear some fragrance, they mostly burned scented incense to purify sacred spaces, honor their ancestors through ritual, and to treat certain ailments using an early form of aromatherapy.\nRoman fresco of a girl pouring perfume into a small vase, from the Villa Farnesina in Rome, 1st century\nHeavily influenced by the Egyptians, wealthy Greek and Roman royalty and clergy also used scent to denote class but the use of perfumes for personal enjoyment became more widespread. The Greeks too were believers in the power of scent to heal and used fragrance to improve health, stamina, and mood. Hippocrates even falsely believed that a ""miasma"" of bad and foul air was responsible for sickness and plague and used aromatic fumigations in an effort to keep affliction at bay.\nGreek glass alabastra, late 6th–5th century B.C.\nThousands of years later, a natural and inspired fragrance is still a revered treasure. Drawing upon the craft of our early ancestors, today\'s scents are created to trigger nostalgia, clear heads, open minds, relax the body and improve mood. Find your next go-to in our natural apothecary, including the captivating collection of scents from Richmond\'s Na Nin – artisanal perfume oils and candles in unusual scents like Cannabis Opium Den and their heady blend of palo santo, sandalwood and musk, Mujer Fuerte.\nTop image: The making of lily perfume, fragment from the decoration of an Egyptian tomb – 4th century B.C.']"	['<urn:uuid:4514ddf5-e352-4478-bd13-dfbd90dde2fb>']	open-ended	with-premise	concise-and-natural	distant-from-document	single-doc	novice	2025-05-13T01:50:22.828293	9	61	582
50	As a marine biologist studying ocean health, I'm curious about how rising CO2 levels affect both fish populations and chemical changes in seawater. What is the connection between overfishing impacts and ocean acidification effects on marine life?	Overfishing has caused a 90% decline in large predator fish populations over the last 50 years. While some areas have shown recovery through better management (like the Gulf of Mexico's red snapper populations tripling since 2007), this issue is compounded by ocean acidification. As the ocean absorbs about 30% of atmospheric CO2, it creates chemical reactions that increase hydrogen ions, making water more acidic. This acidification particularly affects shell-building marine organisms, as it reduces carbonate ions needed for shell formation and can make their shells dissolve more readily. The pH of ocean water has decreased from 8.2 to 8.1 since industrialization, representing a 26% increase in acidity. This affects not only individual species but entire marine food webs, from plankton at the base to larger predatory fish.	['Humans have subsisted on fishing for millennia, however, technological advancement has broadened the scope of our nets with disastrous results. Fisherman focus on catching large species like cod, swordfish, and tuna. Business wise, this makes sense, a bigger fish will be worth more. However, over the last 50 years, the number of large predator fish like tuna has dropped by 90%. The good part is that overfishing can be prevented with better management systems. In places like Belize, Denmark & the United States, the implementation of fishing rights has transformed struggling fisheries. In the Gulf of Mexico, red snapper populations are three times what they were in 2007 after fishing rights were introduced. Marine life is good at bouncing back, but only if humans take the necessary steps to give them a fighting chance.\nWe have previously written about the massive dead zone that is wreaking havoc in the Gulf Of Mexico. Human runoff increases the amount of nitrogen and phosphorus in the water. These two chemicals cause Cyanobacteria to bloom, and since plankton and animals can’t eat Cyanobacteria, it quickly spreads to epidemic levels. When it dies, bacterial degradation consumes the oxygen from the water creating a state of hypoxia, or lack of oxygen. While some fish can escape, many are rendered unconscious too quickly to take evasive action. One of the major issues with dead zones isn’t the fish that are dying; it’s the fish that aren’t. Jellyfish can thrive in dead zones and the absence of predators attracts massive blooms of them. The mucus and waste produced by the jellyfish lead to major changes in the food webs in the ocean.\nWetlands are filled in to accommodate urban development, runoff wreaks havoc on reefs and coastal areas, and inland dams decrease nutrient-rich runoff. These are just a few of the ways marine habitats are being destroyed. The effects of this destruction have serious implications both in the oceans and on land. Salmon, for example, are struggling to complete their migration in the face of water diversions, dams, and logging. But this isn’t just a problem for the salmon, it’s also a huge problem for the bears that need to eat the salmon in order to bulk up before their winter hibernation.\nAs Earth’s temperature rises, the excess heat is primarily absorbed by the oceans. The increased temperature melts ice caps, kills coral and forces species to move into new territories. This also has significant effects on humans. The altered distributions of fish can pose a serious threat to food security and people’s livelihoods worldwide. It also leads to more intense hurricanes that can cause widespread disaster. Warm water is the primary source of energy for hurricanes, so the increasing ocean temperatures have resulted in more frequent and more intense hurricanes in recent years causing massive destruction and loss of life.\nThe ocean absorbs about 30% of the carbon dioxide that’s released into the atmosphere. When absorbed by seawater, the CO2 causes a series of chemical reactions that result in increased concentrations of hydrogen ions, making the water more acidic and decreasing carbonate ions. This is significant because carbonate ions are crucial building blocks for seashells and coral. More acidic waters also affect some species’ abilities to detect predators and find safe environments.', 'What is Ocean Acidification?\nSince the beginning of the Industrial Revolution, when humans began burning coal in large quantities, the world’s ocean water has gradually become more acidic. Like global warming, this phenomenon, which is known as ocean acidification, is a direct consequence of increasing levels of carbon dioxide (CO2) in Earth’s atmosphere.\nPrior to industrialization, the concentration of carbon dioxide in the atmosphere was 280 parts per million (ppm). With increased use of fossil fuels, that number is now approaching 400 ppm and the growth rate is accelerating. Scientists calculate that the ocean is currently absorbing about one quarter of the carbon dioxide that humans are emitting. When carbon dioxide combines with seawater, chemical reactions occur that reduce the seawater pH, hence the term ocean acidification.\nCurrently, about half of the anthropogenic (human-caused) carbon dioxide in the ocean is found in the upper 400 meters (1,200 feet) of the water column, while the other half has penetrated into the lower thermocline and deep ocean. Density- and wind-driven circulation help mix the surface and deep waters in some high latitude and coastal regions, but for much of the open ocean, deep pH changes are expected to lag surface pH changes by a few centuries.\nOcean acidification and global warming are different problems, but are closely linked because they share the same root cause—human emissions of carbon dioxide. The atmospheric concentration of carbon dioxide is now higher than it has been for the last 800,000 years and possibly higher than any time in the last 20 million years. Humans have thus far benefited from the ocean’s capacity to hold enormous amounts of carbon, including a large portion of this excess carbon dioxide. Had the ocean not absorbed such vast quantities of carbon dioxide, the atmospheric concentration would be even higher, and the environmental consequences of global warming (sea level rise, shifting weather patterns, more extreme weather events, etc.) and their associated socioeconomic impacts would likely be even more pronounced. However, the oceans cannot continue to absorb carbon dioxide at the current rate without undergoing significant changes in chemistry, biology, and ecosystem structure.\nMeasuring ocean acidification: Past and present\nScientists know that the oceans are absorbing carbon dioxide and subsequently becoming more acidic from measurements made on seawater collected during research cruises, which provide wide spatial coverage over a short time period, and from automated ocean carbon measurements on stationary moorings, which provide long-term, high-resolution data from a single location.\nThese records can be extended back through time using what are known as chemical proxies to provide an indirect measurement of seawater carbonate chemistry. A proxy is a measurement from a natural archive (ice cores, corals, tree rings, marine sediments, etc.) that is used to infer past environmental conditions. For example, by analyzing the chemical composition of tiny fossil shells found in deep ocean sediments, scientists have developed ocean pH records from ancient times when there were no pH meters. Furthermore, because the ocean surface water is in approximate chemical balance, or equilibrium, with the atmosphere above it, a record of historical ocean pH can be inferred from atmospheric carbon dioxide records derived from Greenland and Antarctic ice cores, which contain air bubbles from the ancient atmosphere. Such evidence indicates that current atmospheric carbon dioxideconcentrations and ocean pH levels are at unprecedented for at least the last 800,000 years.\nGoing back deeper in Earth history to the Paleocene-Eocene boundary about 55 million years ago, scientists have found geochemical evidence of a massive release of carbon dioxide accompanied by substantial warming and dissolution of shallow carbonate sediments in the ocean. Although somewhat analogous to what we are observing today, this carbon dioxide release occurred over several thousand years, much more slowly than what we are witnessing today, thus providing time for the oceans partially to buffer the change. In the geologic record, during periods of rapid environmental change, species have acclimated, adapted or gone extinct. Corals have undergone large extinction events in the past (such the Permian extinction 250 million years ago), and new coral species evolved to take their place, but it took millions of years to recover previous levels of biodiversity.\nHow is ocean acidification affecting ocean chemistry?\nSeawater has a pH of 8.2 on average because it contains naturally occurring alkaline ions that come primarily from weathering of continental rocks. When seawater absorbs carbon dioxide from the atmosphere, carbonic acid is produced (see Box 1), reducing the water’s pH. Since the dawn of industrialization, average surface ocean pH has decreased to about 8.1.\nBecause the pH scale is logarithmic (a change of 1 pH unit represents a tenfold change in acidity), this change represents a 26 percent increase in acidity over roughly 250 years, a rate that is 100 times faster than anything the ocean and its inhabitants have experienced in tens of millions of years.\nAcidification can affect many marine organisms, but especially those that build their shells and skeletons from calcium carbonate, such as corals, oysters, clams, mussels, snails, and phytoplankton and zooplankton, the tiny plants and animals that form the base of the marine food web.\nThese “marine calcifiers” face two potential threats associated with ocean acidification: 1) Their shells and skeletons may dissolve more readily as ocean pH decreases and seawater becomes more corrosive; and 2) When CO2 dissolves in seawater, the water chemistry changes such that fewer carbonate ions, the primary building blocks for shells and skeletons, are available for uptake by marine organisms. Marine organisms that build shells or skeletons usually do so through an internal chemical process that converts bicarbonate to carbonate in order to form calcium carbonate.\nExactly how ocean acidification slows calcification rates, or shell formation, is not yet fully understood, but several mechanisms are being studied. Most hypotheses focus on the additional energy an organism must expend to build and maintain its calcium carbonate shells and skeletons in an increasingly corrosive environment. In the face of this extra energy expenditure, exposure to additional environmental stressors (increasing ocean temperatures, decreasing oxygen availability, disease, loss of habitat, etc.) will likely compound the problem.\nThese effects are already being documented in many marine organisms, particularly in tropical and deep-sea corals, which exhibit slower calcification rates under more acidic conditions. The impact on corals is of great concern because they produce massive calcium carbonate structures called reefs that provide habitat for many marine animals, including commercially important fish and shellfish species that use the reefs as nursery grounds. Coral reefs are vital to humans as sources of food and medicine, protection from storms, and the focus of eco-tourism. In addition to corals, studies have shown that acidification impairs the ability of some calcifying plankton, tiny floating plants and animals at the base of the food web, to build and maintain their shells. Scientists have also observed increased larval mortality rates of several commercially important fish and shellfish.\nWhat can we expect in the future?\nOcean acidification is occurring at a rate 30 to100 times faster than at any time during the last several million years driven by the rapid growth rate atmospheric CO2 that is almost unprecedented over geologic history. According to the Intergovernmental Panel on Climate Change (IPCC), economic and population scenarios predict that atmospheric CO2 levels could reach 500 ppm by 2050 and 800 ppm or more by the end of the century. This will not only lead to significant temperature increases in the atmosphere and ocean, but will further acidify ocean water, reducing the pH an estimated 0.3 to 0.4 units by 2100, a 150 percent increase in acidity over preindustrial times. Assuming a “business-as-usual” IPCC CO2 emission scenario, predictive models of ocean biogeochemistry project that surface waters of the Arctic and Southern Oceans will become undersaturated with aragonite (a more soluble form of calcium carbonate) within a few decades, meaning that these waters will become highly corrosive to the shells and skeletons of aragonite-producing marine calcifiers like planktonic marine snails known as pteropods.\nAlthough ocean acidification has only recently emerged as a scientific issue, it has quickly raised serious concerns about the short-term impacts on marine organisms and the long-term health of the ocean. Scientists estimate that over the next few thousand years, 90 percent of anthropogenic CO2 emissions will be absorbed by the ocean. This may potentially affect biological and geochemical processes such as photosynthesis and nutrient cycling that are vital to marine ecosystems on which human society and many natural systems rely. At the same time, marine organisms will face the enormous challenge of adapting to ocean acidification, warming water, and declining subsurface-ocean oxygen concentrations.\nNews & Insights\nWHOI working to address ocean acidification; protect region’s vital shellfish industry\nA new report addresses the impacts of ocean acidification in Massachusetts and New England coastal waters on the region’s vital seafood industry.\nOcean acidification gets a watchful eye in New England aquaculture ‘hot spot’\nShellfish aquaculture is thriving in New England, but future growth in the industry could be stunted as coastal waters in the region become more acidic. Researchers at WHOI have developed…\nOcean acidification causing coral ‘osteoporosis’ on iconic reefs\nScientists Pinpoint How Ocean Acidification Weakens Coral Skeletons\nClimate Change Will Irreversibly Force Key Ocean Bacteria into Overdrive\n[ ALL ]\nWHOI in the News\nThe Top Eight Ocean Stories of 2022\nThe $500 Billion Question: What’s the Value of Studying the Ocean’s Biological Carbon Pump?\nEcology Research: Ocean acidification causing coral ‘osteoporosis’ on iconic reefs\nDisentangling influences on coral health\n[ ALL ]\nFrom Oceanus Magazine\nOcean acidification is no big deal, right?\nWHOI’s Jennie Rheuban discusses the very real phenomenon of an increasingly acidic ocean and the toll it’s taking on marine life.\nTo Tag a Squid\nHow do you design a tag that can attach to a soft-bodied swimming animal and track its movements? Very thoughtfully.\nHow Do Corals Build Their Skeletons?\nWHOI scientists discovered precisely how ocean acidification affects coral skeletons’ a factor that will help scientists predict how corals throughout the world will fare as the oceans become more acidic.\nSearching for ‘Super Reefs’\nSome corals are less vulnerable to ocean acidification. Can the offspring from these more resilient corals travel to other reefs to help sustain more vulnerable coral populations there?\nGraduate student Hannah Barkley is on a mission to investigate how warming ocean temperatures, ocean acidification, and other impacts of climate change are affecting corals in an effort to find…']	['<urn:uuid:4ffa13ad-e589-4022-85d8-03191823ff2f>', '<urn:uuid:51ca6f21-f0f4-4343-8b14-a7f059f0fe69>']	open-ended	with-premise	verbose-and-natural	distant-from-document	multi-aspect	expert	2025-05-13T01:50:22.828293	37	127	2275
51	holiday lights series vs parallel wiring reason	Holiday lights are wired in parallel because if one bulb burns out, the other bulbs remain lit. In contrast, if holiday lights were wired in series, one burned-out bulb would cause the entire strand to turn off, and each individual light would need to be checked to determine which one is not working.	"['Presentation on theme: ""Do Now for 6/10/13 Open books to page D-69 HW: Complete Group Procedure.""— Presentation transcript:\nDo Now for 6/10/13 Open books to page D-69 HW: Complete Group Procedure\nD66 Connecting Circuits Introduce activity and read background (page D-69) Complete Part A Design your own procedure for second part of Part A\nD66 Connecting Circuits What places in your home have electrical circuits? – Circuit – Any path along which electrical energy can transfer. A circuit depends on the quality of the materials it’s made of to conduct electricity. – Electricity flows easier through conductors. – In general, materials that are good heat conductors are also good electrical conductors.\nD66 Connecting Circuits We will be exploring the which materials are good electrical conductors in Part A. – Build a simple electrical circuit. Draw a diagram of the completed circuit using the symbols on page D-70\nD66 Connecting Circuits Diagram of a simple circuit that we created using the symbols from page D-70. Battery Wire Light bulb\nD66 Connecting Circuits – Design a procedure and data table to test which materials conduct electricity (steps 4,5,6.) – Complete student designed procedure for HW\nD66 Connecting Circuits – Qualities of a good procedure. Clearly written Concise (direct and to the point) Each step has a specific purpose towards completing the task. Allows us to gather the information needed quickly and easily. THE READER MUST ALSO TAKE RESPONSIBILITY FOR THE SUCCESS OF THE LAB!!!\nDo Now for 6/12/13 Take out your procedure HW: Analysis 1 and 2\nD66 Connecting Circuits Check HW Review Procedures – Your procedure must be approved by me prior to starting. Gather materials Gather data (Steps 5 and 6) Return your materials and begin Part B (Steps 7 through 11) – Make sure you make and record observations in steps 8,9, and 10 Clean up – make sure all materials are returned to their proper locations. Discuss results Analysis 1 and 2\nD66 Connecting Circuits- Sample Data Table MaterialConductivity PredictionConductivity as Tested with the Motor\nD66 Connecting Circuits 1. Which materials were the best conductors? Explain how you know these materials conducted electricity better than other materials. – The metals were all good conductors, and other materials were not. Students should have found that the aluminum strip, copper strip, iron strip, zinc strip, magnesium ribbon and carbon rod were all conductors. The glass rod, granite piece, polystyrene plastic strip, ceramic tile, and wood were insulators.\nD66 Connecting Circuits 2. Describe the transfer and transformation of energy involved in a battery that lights up a bulb and runs a motor in a circuit. – Energy is transformed in the battery from potential chemical energy to electrical energy. Through conducting wires, the energy is transferred to the bulb and motor. At the bulb, the electrical energy is transformed into light and heat. At the motor, electrical energy is transformed into motion. The light, heat, and motion are transferred to our senses, and we see, hear, and feel the energy.\nDo Now for 1/6/12 Take out HW HW: Complete 3, 4\nD66 Connecting Circuits Check and discuss HW Review Procedure for Part B Gather data Discuss results Analysis 3 and 4\nD66 Connecting Circuits – Compare what happens when bulbs are added or removed from series or parallel circuits. – Complete steps 12 through 17. Make sure you make and record observations in steps 13 through 17. – Clean up – Analysis 3 and 4\nSeries and Parallel circuits are not the same. Series When you remove a bulb from a series, all the other bulbs go out. As you add bulbs to a series circuit, they all get dimmer. Only one path for the electricity to travel. Parallel When you remove a bulb from a parallel, all the other bulbs stay lit. All the bulbs in a parallel circuit glow the same. Multiple paths for the electricity to travel.\nD66 Connecting Circuits 3. Create a larger version of the Venn diagram shown below. Record the similarities of series and parallel circuits in the space that overlaps. In the labeled spaces that do not overlap, record differences between the circuits.\nD66 Connecting Circuits\n4. Holiday lights are light bulbs that are wired in a parallel circuit. Why is this a better idea than putting them in series? – Lights, such as holiday lights, are often wired in parallel because if one bulb burns out, the others are not affected. If they were to be in series, one burned bulb would turn off the whole strand, and each light would have to be checked to determine which one is out.\nD66 Connecting Circuits – Key Concepts 1. Electrical circuits are a means of transferring electrical energy. 2. Students apply evidence when developing descriptions, explanations, predictions, and models.\nD66 Connecting Circuits - Vocabulary 1. Circuit: A path along which electrical energy can transfer. 2. Parallel circuit: A circuit in which the components are set up so that the electrical energy has more than one conducting path from the electrical source. 3. Series: Anything that consists of a set of successive components arranged end-to-end. See series circuit. 4. Series circuit: A circuit in which the components of the circuit are connected in succession to the power source so there is only one path for the electrical energy in the circuit.']"	['<urn:uuid:e95e3d7b-5708-48b6-9b55-39224bfb142e>']	open-ended	with-premise	short-search-query	distant-from-document	single-doc	expert	2025-05-13T01:50:22.828293	7	53	886
52	How do both Richard Hamilton's 'Kent State' print and the Richters Patterns installation demonstrate the transformation of original images through multiple technical processes?	Both works involve complex transformation of source images through multiple technical steps. Hamilton's 'Kent State' went through numerous processes - from TV footage to photograph to 13 nylon grids and 15 layers of paint screening. Similarly, Richters Patterns takes photographs of an abstract painting and transforms them through cutting, reflection and replication using special software to create evolving patterns, demonstrating how both artists use technical processes to dramatically alter original images	['Fig. 1 Kent State (1970)\nRichard Hamilton (1922-2011) was a British artist and art commentator. He was a co-founder of the Independent Group in 1956, a collection of people working in various media (including painting and architecture). The group was interested in technology and contemporary culture (Hamilton, 2003: 742), and Hamilton exhibited work which led directly to the term ‘Pop art’ in Britain. Hamilton saw pop art as a way of appropriating the subjects of popular culture and mass media, into the business of fine art, and was necessary if the artist was to avoid becoming redundant (Hamilton, 2003:743).\nOther writers such as Lawrence Alloway had similar views. Alloway fought against the idea of artistic elites, and championed the ideas and art of the masses. He believed that the industrial revolution had increased the importance of the masses (the working class?), and that rapid changes in popular culture and popular art forms were better descriptions of life than the more conservative and academic artistic elite.\nHe directly criticised Clement Greenberg over his use of the word Kitsch to describe ‘a mass art which was destined for ‘those who are insensible to the values of genuine culture.’ (Alloway. 2003: 715). He thought the ‘rejection of the mass produced arts is not, as critics think, a defence of culture but an attack on it’. (Alloway, 2003: 717).\nWithin this context of mass culture Hamilton produced art from photographs, paintings, and reproduction techniques such as printing and lithography. His ideas drew upon mass media such as newspapers, magazines, TV and advertisements. Fig. 1 shows a print (one of 5000) based on a photograph that Hamilton took whilst watching TV news. It depicts a shooting of a university student by the national guard, during an anti-war demonstration in the USA. Hamilton thought it was a powerful image and developed it further (Tate online, n.d).\nThe artist described the many routes and processes through which the original information had passed in order to arrive at the final prints. This involved a cine camera (at the scene), taking chaotic and shaky footage, satellite broadcast by the USA, UK TV station broadcast, electrons in Hamilton’s TV screen/cathode ray tube exciting the pixcels into different amounts and colours of light (ref). Then, once the artist took the picture of the TV screen, it was transformed additionally through a long process of mechanical reproductions into the final prints. This included the use of a process camera to transfer several different images into different patterns on 13 nylon grids. Each grid was used via the process of print screening, to transfer 15 layers of differently arranged and coloured transparent paint onto each final print paper (2 grids were used twice) (Tate online, n.d).\nFig 1. Shows an image which is both real and abstract to a degree. It is still recognisably a picture of a person who is lying prone, with others around them. The print is in a format which suggests the average TV screen, and the grid of the screen is detectable within the image- echos of the original circumstances when Hamilton first engaged with the scene. However, the complexity of the information transmission process has caused a loss of some information and a consequent blurring and fuzziness. This has been augmented by the overlapping of different coloured transparencies which, at the edges, have given a feeling of movement- almost reinstating the life of the original footage. Despite this ghostly appearance, the wounds are powerfully described using a very vivid red to suggest blood. During the transformation this image has become less like a photograph, and much more artistic, more colourful, subtle, and painterly.\nIt is interesting to analyse this work in terms of both the artists feelings and those of the thinker Walter Benjamin. The original subject here was a violent act against a student protester. The authentic object from Benjamin’s point of view was probably the original footage on cine camera. This scene, viewed through the camera lens by the photographer alone may have contained characteristics of the immediate shock and chaos felt by all involved. This usefully corresponds to Benjamin’s aura of the original (Benjamin, 1999: 76). Hamilton described the process of change starting at his camera,\nIn spite of the many transmogrifications, what’s left always has a kind of validity. So every change that I have made, so long as my hand didn’t come into it, and as long as I didn’t tamper with it in a physical way, had its own authenticity, too. (Tate online, n.d)\nThis is a classic restatement of Benjamin’s discussion that process reproduction (as opposed to manual reproduction) does not destroy authenticity completely (Benjamin, 1999: 73-4). Benjamin also states that the loss of aura involves both things becoming closer physically and humanly, and a loss of uniqueness of an object (Benjamin, 1999:75). This too is applicable to the violent scene which Hamilton saw on his TV screen that night. The loss of aura through transmission to another person, is also accompanied by a reactivation of something else- not tradition, something different (Benjamin, 1999: 74). Hamilton was shocked by the scene- but no doubt it did not make his heart race and his skin crawl, as it might have done to the camera operator ( perhaps the true presence of the aura here).However he was moved to highlight the political aspects via his artistic method. His process transformed the scene for a different audience, an artistic one – one perhaps more ostensibly ‘cultured’, powerful, and political than many TV consumers.\nFig. 2 Grauwald (2008)\nGerhard Richter (b.1932) is an artist who has worked in a whole variety of different styles, but at times has seemed obsessed with both photographs and painting. He, and his thoughts on these disciplines seem a little enigmatic, sometimes inconsistent, and perhaps ‘melodramatic’.\nIn ‘Notes 1964-65’ he seems to turn the thinking of certain writers on it’s head. For example he believes in the precision of the photograph (Richter, 2003: 757), but in stark contrast to Brik, who believes in the supremacy of the photograph as a record, over the painterly and artistic progress (Brik, 2003: 473), Richter states that the photo is meaningless as a record of reality (Richter, 2003: 759). And yet, Richter also sees that photos have taken on religious overtones, with people using pictures of family or friends in quasi- religious ways (Richter, 2003: 757). By acknowledging this he acknowledges that photos have a religious or ‘magic’ characteristic which Walter Benjamin believes to be a sign of authenticity (Benjamin, 2003: 76). This seems absurd if the subject is indeed meaningless.\nRichter’s work almost universally uses photographs as a source material, but the emphasis is on the painting process and the materials he uses. He seems to be making a firm statement for the supremacy of the painting (the object) over the photograph (the subject). He uses the photograph simply to suggest artistic elements to him, all that interests him are ‘ the grey areas, the passages and the tonal sequences, the pictorial spaces, overlaps and interlockings.’ (Richter, 2003: 759). In fact it seems that if he had the power simply to imagine such elements, he would simply paint abstracts from his imagination.\nFig 2 shows one of the artists ‘painted over photographs’. This seems to suggest painting’s supremacy over the photo in several ways. Firstly paint is placed directly on top of the photo, a very physical and painterly sign of dominance. Secondly the photograph, of a wood, has been obscured by the paint till it is almost unrecognisable- as a photo. Furthermore, the grey paint is monochrome and hence less real compared to the colours of the source photo- which emphasises paint- over photography (and Brik’s faithful camera reproduction (Brik, 2003:471)). Even the title Grauwald (Greywood) puts paint and the monochrome grey rather clumsily and surprisingly before the more familiar call to reality contained in the word Wald (wood).\nThis artist works between the borders of science and art. She is a research fellow at Sussex university and investigates the Neurophysiology of Lucid Dreaming, and her own personal sleep consciousness (Haill, 2016 a.). Her installation ‘Sleep cycles’ includes several different objects. Fig.3 and 4 show part of the artwork.\nFig. 3 Sleepcycles (2016) I.\nFig. 4 Sleepcycles (2016) ii.\nFig 3 shows a digital representation of the brainwaves (The EEG-electroencephalogram) recorded during a subject’s vivid dream, superimposed on a weighty book. The artist has said that the wave pattern indicated light REM sleep, close to waking. The waves shown include some corresponding to rapid eye movement, and a dream in which the subject recalled riding a unicorn along a beach (Haill, 2016 b.).\nI find the artistic impression of fig. 3 to be rather weak however. It does not give me a palpable pleasurable feeling which I get when I like art or music, be it modern or traditional. This is a strong litmus test for me, although within this test may lurk the problems of personal prejudice and/or laziness in my artistic response. The juxtaposition of the old and new is certainly striking though.\nI do think the new potential for art to be expressed using physical manifestations of our thoughts (both conscious and subconscious- previously little known to us), is massively powerful. This artist is interested in exactly what scientists are interested in- with a different artistic slant. The revolution in psychology and psychiatry has involved both it’s beginnings in the subconscious and ‘the interpretation of dreams’ by Sigmund Freud, but latterly a drive to connect thoughts with physically identifiable entities- whether EEG waves or the status of anatomical areas of the brain.\nThe use of advanced imaging such as MRI (Magnetic Resonance Imaging) is a modern modality of ‘seeing’- not with white light (as in human vision), nor using X-rays (as through X-ray pictures- which the artist Francis Bacon was interested in), but with quite different physical magnetic waves. It is a continuation of the scientist’s urge to visualise with increasing resolution and power, and the use of these modalities for recreation and learning in art is intriguing. These possibilities of vision are extensions of the idea discussed by Benjamin, that the camera and it’s photograph introduced us to ‘unconscious optics as does psychoanalysis to unconscious impulses….’ (Benjamin, 1999: 78).\nReturning to the installation, Fig. 4 shows a second part and includes rolls of pianola paper, several antique-looking books, and a 14 million year old rock fragment in two hemispheres contained within a glass jar, which has an extinguished candle attached, and a trail of hardened melted wax. The rock sections look like a dissected brain to the novice. The candle, the rock, and perhaps also the pianola, are interesting objects from the perspective of physical manifestation of duration and a physical process which is nevertheless ‘nebulous’. The wax trail illustrates the life of the burnt candle, the different rock areas perhaps the duration of the physical processes which formed them; even the pianola paper translates something physical (marks on the page) into a different form (sound and music). Perhaps these objects reference the idea of capturing the physical trail of a nebulous thought or dream?\nFig. 1 Hamilton, R. Kent State (1970) [screenprint on paper]. Online at: http://www.tate.org.uk/art/artworks/hamilton-kent-state-p77043 [accessed 16th February 2017]\nFig. 2 Richter, G. Grauwald (2008) [Lacquer on colour photograph]. Online at: https://www.gerhard-richter.com/en/art/overpainted-photographs/grauwald-79/12108-grauwald-16544/?&categoryid=79&p=1&sp=32 [accessed 16th February 2017]\nFig. 3 and 4. Haill, L. Sleepcycles (2016) [installation]. Online at: https://lucianahaill.wordpress.com/sleepcycles/ [accessed 16th February 2017]\nAlloway, L. (2003) . ‘The Arts and the Mass Media’ 1958 In Harrison,C. and Wood,P. (eds). Art in Theory 1900-2000. Oxford. Blackwell Publications. p. 715-717\nBenjamin, W.(1999) ‘The work of art in the age of mechanical reproduction’ in In visual culture: a reader. Evans, J and Hall, S (eds.). London. SAGE Publications. p. 72-8\nBrik, O. (2003) . ‘Photography versus Painting’ 1926 In Harrison,C. and Wood,P. (eds). Art in Theory 1900-2000. Oxford. Blackwell Publications. p. 470-473\nHaill, L (2016 a) ‘Sleepcycles’ online at: https://lucianahaill.wordpress.com/digital-artworks/ [accessed 16th February 2017]\nHaill, L (2016 b) ‘Technology is not neutral’ online at: http://technologyisnotneutral.com/LucianaHaill [accessed 16th February 2017]\nHamilton, R. (2003) . ‘For the Finest Art, Try Pop’ 1961 In Harrison,C. and Wood,P. (eds). Art in Theory 1900-2000. Oxford. Blackwell Publications. p. 742-743.\nRichter , G. (2003) . ‘Notes 1964-1965’ In Harrison,C. and Wood,P. (eds). Art in Theory 1900-2000. Oxford. Blackwell Publications. p. 757-760\nTate online, (no date). The Tate Gallery 1984-86: Illustrated Catalogue of Acquisitions Including Supplement to Catalogue of Acquisitions 1982-84, online at : http://www.tate.org.uk/art/artworks/hamilton-kent-state-p77043 [accessed 16th February 2017', 'Music theatre / Installation\nPainting / Film / Music\nFestival-Double / 2 rooms — 1 ticket\nSat 06.05. — 18:00\nSat 06.05. — 20:00\nSun 07.05. — 15:00\nSun 07.05. — 17:00\nGalerie / Orangerie\nDas Stereoskop der Einzelgänger\nvon Wantoch Rekowski / Pommerehn / Rodriguez\nOn entering the Galerie the audience beholds a strange city built of boxes, inhabited by musicians – half human, half animal. There is much to discover while strolling through the labyrith of this city. Interiors can be seen as if through windows in cardboard boxes containing enigmatic objects, traces of a hidden existence. Viewers occasionally come across short texts on slips of paper; sometimes they encounter a dancer. The human-animals create an alien, fragile music whose live electronic echo fills the space.\nThe texts come from a collection of bizarre and eccentric portraits, published by the Italo-Argentine writer Juan Rodolfo Wilcock in 1972, in which cannibalistic lovers, accident-prone gods, unemployed angels or incessantly chattering solo entertainers defend their quixotic ways of life.\nDas Stereoskop der Einzelgänger is primarily concerned with the visitors themselves, their listening, perception and memory. It leads them through a curious landscape in which they will individually direct their attention to a wide range of phenomena and even change roles several times.Through theatre, installation and music the Argentine composer Ana Maria Rodriguez, the Franco-German director Ingrid von Wantoch Rekowski and the American stage designer Fred Pommerehn create a disquieting and unsettling world with the Ensemble KNM from Berlin.\nWith Annapaola Leso / Ensemble KNM Berlin\nMarcus Schmickler / Corinna Belz\nIn the second part of the evening a digitally and musically animated painting in the Orangerie responds to the music-theatrical installation in the Galerie. Following an idea by Gerhard Richter, the film-maker Corinna Belz and the Cologne-based composer Marcus Schmickler have developed the musical and filmic work Richters Patterns that can be seen here for the first time as an installation.\nThe audience is situated between an expansive projection on the one side and the musicians of the Ensemble Musikfabrik on the other. With the aid of a specially developed software, photographed details of an abstract painting by Gerhard Richter were transformed into patterns and montaged into a film through cutting, reflection and replication. Over a good half hour these patterns transform almost imperceptibly into colourful stripes, as if connecting two poles of Gerhard Richter’s oeuvre: his large oil paintings produced with a doctor blade and his famous colour-field panels and ‘strips’.\nMarcus Schmickler reinforces the effect of the film by adopting the process of fragmentation and reproduction in his music. Different scales are repeated and mirrored; massive chords fold into one another; microtonal lines and motifs emerge and make a spectrum of overtones audible. Film and music form an indivisible unity in which the dynamics of optical effect and musical perception interpenetrate.\nWith Ensemble Musikfabrik Köln\nTIP: For a successful evening we suggest a ticket combination with the freitagsküche - enjoy a dinner together with the artists and the festival team in the Spiegelzelt after the performance on 06.05. at 22:00! Tickets 15 Euro (1 meal, excl. drinks)\nPrice reduced 14,50 Euro']	['<urn:uuid:599f6cf2-5d7f-418c-9470-69ead6e7c09d>', '<urn:uuid:7f34277d-6fb9-402c-9cf6-ad2ca56a7ebe>']	factoid	direct	verbose-and-natural	similar-to-document	comparison	novice	2025-05-13T01:50:22.828293	23	71	2606
53	What are the three important criteria that are fulfilled when using externally triggered processes for system decomposition in requirements engineering?	When using externally triggered processes (such as use cases, business processes, or user stories) for system decomposition, the first three letters of the INVEST criteria are fulfilled by construction: they are Independent, Negotiable, and Valuable	['Does Notation Matter (Part 1)\nPeter Hruschka, Atlantic Systems Guild\nIf you look back in the history of requirements methods, you can observe that the notations for capturing requirements have changed several times in the last 50 years.\nIn the 70s we were glad if we got requirements in written form, mostly natural language statements, like “The system shall ….”\nIn the 80s modeling picked up, trying to overcome the weakness of natural language as being too interpretable. We have learned to express processes in terms of data flow diagram and business objects in terms of entity-relations-diagrams, etc.\nIn the 90s the graphic notations changed with the advent of UML. Processes now had to be shown in use case diagrams, refined by activity diagrams. Data had to be class diagrams instead of entity relationship diagrams.\nIn the 00s the agile methods mainly switched back to natural language: user stories had to be written in plain English, but to be a little bit more precise, the sentences should follow the generic structure: As a <<user>> I want << function>> so that <<benefit>>.\nIn this blog I want to examine whether the way of expressing requirements, i.e. the notation you use, influences the quality of requirements. In part I of this mini-series we will look at expressing a top-level system decomposition, creating an overview of all functional requirements, before diving deeper to analyze them in detail.\nLet us contrast high level requirements for a hypothetical children swimming league, that wants to automate its manual processes by creating an IT-system nicknamed AQUARIUS. A use-case diagram could look like this:\nFigure 1: The use cases of AQUARIUS\nNow, is it really necessary to use that old fashioned graphic notation, invented in 1992 by Ivar Jacobson – at a time when many of today’s developers were not yet born or in their infancy? Would not a simple list of functions also do the job. Look at the following write-up:\nFigure 2: A list of AQUARIUS functionality\nWe have chosen slightly different names for the functions (e.g. Update Figure Catalogue vs. Update Figures), but mainly the information content of both notations is equivalent: We know we want these nine key features.\nYet another alternative would be to start creating a story map. In the following figure we just give the overview of the epics and features (since they are too big to be considered as stories yet).\nFigure 3: The beginning of an AQUARIUS story map\nYou note, that we have now introduced two levels of abstraction. But that could easily also have been done in the use case diagram by putting packages around some of them. Or even easier in figure 2 by using an indented bulleted list.\nSo, does notation matter?\nMaybe you immediately like one or the other notation of the example above – often because this is the way you were educated or learned to structure requirements in the large in the first place. But my answer is: Yes, it does matter. According to the Sapir–Whorf hypothesis language (or notation) does influence the way you are thinking about the problem at hand.\nLet us look “behind” these three different notations. My way of reasoning and thinking about splitting the overall task of AQUARIUS into parts was identical in all three cases. I was thinking in processes, triggered in the environment (e.g. by children, by officials, ….) and I have given each complete process a name. This is often called a process-driven decomposition, or an event-driven decomposition (since we look at events happening in the context to determine the needed reaction of our system AQUARUIUS).\nYou can easily see that a use-case diagram strongly suggests this way of thinking, because you are looking for external actors (the stick figures) and just draw one abstract ellipses with the overall functionality wanted by that actor. The same could be achieved using the formula for user stories (As a …. I want …).\nIn the simple list in figure 2 above or the sketch of a story map this kind of decomposition strategy is not so straight-forward. You could have come up with a totally different list of functions, e.g. decomposed based on geography, (functions needed in the office and functions needed at the pool-site). Or you could have used an object-oriented decomposition (all functions to do with children, all functions to do with competitions, …).\nIf you think in processes to find a decomposition, then you can write them down (or draw them) in any notation. But some notations help you with a certain way of attacking the problem at hand, some of them are totally neutral and allow any way of thinking.\nSo, my final answer to the question “Does notation matter?” is: probably (not) J! What really matters is your way of approaching the decomposition of the whole into parts. And thinking in externally triggered processes (i.e. use cases, business process, domain story telling, event-driven decomposition, user stories, ….) is crucial of coming up with a structure that fulfills the first three letters of the INVEST-criteria: They are (by construction) independent, negotiable and valuable. (Note that the other 3 letters – “e” for estimable, “s” for small enough, and “t” for testable – bring about user stories that are usually too small and too precise for a top-level decomposition. But if you write epics or features in “story style” – and ignore EST – they are good high level stories!)\nUse cases have enforced that process thinking by having (external) actors, who want something from the system. The story-format enforces that by looking at “users” (I prefer to talk about stakeholders or beneficiaries), who want a process to achieve some benefit.\nBulleted lists can be created using any decomposition criterium.\nOur language (or notation) strongly influences the way we are thinking. Therefore, be careful about the notation you pick. If your way of thinking is the driving force for decomposition, then every notation to express the result is OK.\nIn the universe of the product owner (in req42) we usually capture the top level decomposition as epics or features in the product backlog -either in simple ordered lists or in from of story maps. But we encourage you to use “supporting models” to maybe communicate this top level in a better way to your stakeholders or to help you with finding the top-level decomposition.\nSo remember: Agile Requirements Engineering is more than just maintaining your product backlog.']	['<urn:uuid:7d42e5d5-9167-4693-a084-5cdc88b7b363>']	factoid	direct	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-13T01:50:22.828293	20	35	1074
54	beginner tai chi horse stance correct position weight distribution instructions	The tai chi horse stance is performed by standing with legs shoulder-width apart and feet pointing straight ahead. Slightly bend your knees, but not too deeply. The weight should be evenly distributed with 50 percent on each leg. Keep your head suspended and breathe deeply through the nose, with your tongue touching the roof of your mouth. While this stance can be performed with thighs parallel to the floor in other Chinese martial arts, for basic tai chi form you don't need to squat that low.	['The Setting Sun and Tai Chi Drills\nIf you have an opportunity, perform tai chi drills as well as the tai chi form in the setting sun. Relax, but do not collapse your entire body and surrender physically and mentally to the gentle warmth and to the powerful drawing and cleansing energy of the setting sun. Of course, second best would be indoors while the sun is setting. You can still use and sense the drawing setting sun energy to achieve the cleansing, but will need to imagine the feeling of the gentle warmth of the setting sun.\nTai Chi Stances\nStances are the bases of the tai chi form. You have to understand the stances, leg positions, and movements before you can perform a tai chi form. You have to focus on maintaining correct, healthy alignment in your entire body and remain aware of your body weight as it gently shifts from side to side in each stance.\nStart in a high stance at first, and then over time lower your stance and practice longer. Train the stances before you work on the upper body movements. Later, you can also train only the upper part of the tai chi movements by, for instance, doing the form while seated on the edge of a chair. This helps you to fine-tune the movements, and your tai chi will be improved when you put them back together.\nKey Points about Tai Chi Stances\nEach stance should be trained in a stationary position, and then you should train moving from one stance to the other. Remain relaxed, with a little bit of slack throughout the body, which allows the energy and blood to flow and nourish the body. Connect energetically to the ground. If there is too much tension in the muscles, the blood and the energy is stagnant and sealed, and your tai chi is not an internal art anymore; it is only an external form.\nWhen you turn the body, be sure to turn the hips and face them forward in the direction of the feet. Push off the heel of the back leg whenever you move forward. When you lift your foot at any time during the form, slowly ‘peel’ it off the ground by rolling and lifting it from the heel to the ball of the foot or from the ball of the foot to the heels. When placing the foot down, ‘smear’ it from the ball of the foot to the heel or from the heels to the ball of the foot. Sense your body weight as it shifts from one leg to the other. Look for other differences throughout the entire body as well.\nExperience the substantial and insubstantial, which is the difference in levels of tension and relaxation, weight and lightness, in your legs, throughout your torso, and the rest of your body. This internal sensing will raise your total body awareness. It is said in the Tai Chi Classics: “Substantial and insubstantial must be differentiated, not only in the legs, but in the entire body.”\nTai Chi Mountain Stance\nStand with both feet together, hands beside the body with the middle finger touching the middle of the outer thigh. Try to sense a connection to earth and heaven. Align the spine, drop the shoulders, breathe deeply, and put your mind in your center of gravity energy center. This stance can also be trained with your hands on your belly to reinforce the sensation of the lower energy center. When standing, repeat this thought: “I am a great mountain.” You should be calm, quiet, and centered.\nTai Chi Horse Stance\nStand with the legs about shoulder-width apart, feet pointing straight ahead, and slightly bend the knees, but not too much. The weight is evenly distributed, 50 percent in each leg. Keep the head suspended. Breathe deeply through the nose. The tongue touches the roof of the mouth. During exhalation, emphasize the sensation of the mind going out into the four gates, and on inhalation, back into your lower energy center.\nHorse stance is very common in all Chinese martial arts. In horse stance, your squat can be as low as bringing the thighs parallel with the floor. In this tai chi form, you will not be asked to squat that low, but that can be an excellent additional training method for the thighs and entire body. You will experience horse stance throughout the Sunset Tai Chi form at various times, as you transition between the postures.\nTai Chi Empty Stance\nThere are two empty stances. In the first empty stance, the feet are close to one another. In the second empty stance, one leg is out in front of you, ready to kick or step.\nIn both empty stances, 90 percent of your weight is on the back leg and 10 percent of your weight on the front leg. The front leg gently touches the ground with the ball of the foot and is turned inward 45 degrees. It is important to distribute the weight of the back leg through the knee, down to the floor, and mentally, you may go down even deeper into the ground, into your roots (30 inches deep). This stance is also called cat stance, which reflects the spirit that needs to be felt when holding this stance.\nFirst, start this stance standing high and as your legs become stronger, drop the stance lower and lower while holding it for longer periods of time: three to five minutes on each leg. To make sure you do not injure your knees, develop a balance between strength and flexibility in your legs before you require them to perform difficult tasks, such as low stances.\nYour waist can be in one of two positions. At first, turn the waist away from the front leg, the leg with no weight. Then when you can keep your weight moving down through the back leg, which holds the stance, you can move the waist toward the front leg, which has no weight. You will see that the second waist position in this stance is more difficult; both on the knee of the back leg, as well as on the lower back.\nTai Chi Forward Stance\nForward stance has 70 percent of the body weight on the front foot and 30 percent on the back foot. The back leg is slightly bent. Do not bring your weight farther forward than the toes. Your knee should not be farther forward than the toes. The best indicator is the sensation that the weight is moving through the knee rather than into the knee. Direct your body weight through proper alignment of the leg into the ground. The toes should be turned so that there is a 45-degree angle in the feet and about one to two inches from an imaginary line drawn between the toes of the front leg and the heels of the back leg. Make sure your legs are always at least shoulder-width apart. In traditional tai chi chuan, this stance is called mountain climbing stance or bow and arrow stance.\nTai Chi Back Stance\nBack stance has 60 percent of the body weight on the back leg, 40 percent on the front. The principles are the same as forward stance. When you sink into the back leg, be sure to tuck the tailbone slightly in. Distribute the weight right into the floor, not your knee. You should maintain a solid connection to the ground with the soles of the feet.\nTai Chi Tiger Stance\nStand in horse stance with your feet parallel, sacrum tucked in, head suspended, and shoulders dropped. Put the center of your palms on your waist. On the next inhalation, focus your mind in the lower energy center and on the sensation of 50 percent of your weight on each leg. Then, to begin shifting your weight from left to right, close your eyes and try to move as if you were pouring your body weight like sand, moving from the left leg to the right, slowly, paying attention to the sensation of pouring the sand, grain by grain.\nOn the next exhalation, continue to shift your weight from the left leg to the right leg, ending with 80 percent of your weight on the right leg.\nEmphasize your weight moving down through the right knee into the floor and not into the knee. The left leg, which has 20 percent of your weight on it, is still parallel to the right leg. The inner soles of the feet are parallel to one another. You also want to keep both inner arches ‘alive’ and engaged, especially on the left, because the action of shifting into the right leg tends to collapse the arch of the left foot, and vice versa.\nWhen a tiger attacks, the warrior waits until the last moment to respond. When the tiger jumps to attack, the warrior shifts his weight to the left side to evade the attack while his right arm sticks a knife in the tiger’s left temple (do not try at home!). Try to recreate the spirit of the warrior when performing this stance. Shift your weight from side to side 20 to 30 times. Over time, you will be able to perform lower and longer stances. There are other traditional stances commonly used in longer tai chi chuan forms.\nOnce you understand the stances and can perform them without thinking, you should start mixing them and move from one to the other while maintaining the internal visualizations, which are further explained in Sunset Tai Chi and Sunrise Tai Chi books.']	['<urn:uuid:03eb6a5f-49fc-4bcd-80a1-adf8f7e15bbb>']	open-ended	with-premise	long-search-query	similar-to-document	single-doc	novice	2025-05-13T01:50:22.828293	10	86	1604
55	help me understand backup importance computer security what problems does it solve drawbacks	Backups are crucial for data security as they help recover from various threats including physical device theft, hardware failures, cyberattacks, malware, and even natural disasters. Statistics show that about 96% of business servers are not backed up, and approximately 50% of tape backups fail to restore. However, while backups are important, they must be part of a comprehensive security approach. Simply backing up data doesn't protect against other security issues like application-level attacks, user-level attacks such as phishing, or insider threats from malicious employees. Additionally, backed-up data must also be properly encrypted during transmission and storage, as backups themselves can be vulnerable to theft or unauthorized access. A proper security strategy needs to include vulnerability management, monitoring, and employee training beyond just maintaining backups.	"['Yet another intrusion with data theft, yet another chorus of yells for ""encryption.” I refer to the eBay intrusion from last week with the subsequent hysteria over their not encrypting certain personal information at rest. ""It is inexcusable for a company the size of eBay with the amount of data it holds to not encrypt all personal information held,” said Trend Micro’s Rik Ferguson.\nIt has become quite fashionable these days to say, ""If only the information had been encrypted.”\nThe problem is not that simple, either from a privacy or security perspective. From a privacy perspective, the motivation is “don’t let someone who doesn’t need to see the information see it.” From a security perspective, the motivation is “don’t allow someone to violate privacy and then misuse the obtained information.” They’re very closely related, and wherever we talk about security or privacy, we really mean both.\nEncryption at rest solves a small set of problems really well:\n- Unauthorized physical access, loss or theft of portable devices, including laptops, USB drives and other mobile media. This is a superb use case for encryption, because the risk/reward ratio is so skewed toward reward. That\'s one reason the Massachusetts privacy law MA 201 CMR 17 specifically requires ""encryption of all personal information stored on laptops or other portable devices.”\n- Backup media and other information that is constantly in transit. This is another excellent use case. Data is on backups. Backups move around on trucks. Backups fall off the back of trucks. The impact is catastrophic. Encryption completely makes sense.\n(Picture from xkcd.com)\nIt\'s when you start trying to apply the same principles to data on servers without thinking correctly about it that you start getting into trouble. Let\'s talk about what encryption at rest does not do:\n- It doesn\'t help you when logical access to the system is gained through other means. For instance, a guessed or cracked password; through an application level attack, such as SQL injection; a user level attack, such as phishing. Remember that encryption must still make data available to the user on demand, so if an attacker has the ability to become the user, you\'re toast. How do you prevent that? Perhaps with stronger authentication, e.g., two-factor authentication. This now becomes a harder problem than just ""let\'s encrypt everything,” doesn\'t it?\n- It doesn\'t help you when a user goes ""bad.” There\'s no way to generally predict this or, for the most part, respond to it. You could do strict segregation of duties and two-person controls, if you can afford it (the government can, but how many businesses can?), but encryption doesn\'t really help you protect against this attack either.\n- Encryption at rest is fine and dandy, but what about the transmission of data on your network? Is it encrypted? Is it stored on a file share, perhaps? On an e-mail server? Are you prepared to perform all of the process flow analysis to ensure that every data avenue is protected? If an attacker were on your network and couldn\'t get to the encrypted database, could they simply sniff network traffic instead? This is where concepts such as Privacy by Design come into play—you anticipate threats to privacy and counter them early in an application’s lifecycle. It’s a lot harder to do this for a legacy application.\n- Encryption can eventually be brute-forced. Of course, this is also a good thing—it means that it buys you some time to put in countermeasures, change passwords, warn banks and consumers, etc. But most people think that encryption ""solves"" the security problem entirely. Not by a long shot.\nKeep the right perspective as you think about encryption at rest:\n- Data minimization—have you followed the principle of data minimization and only retained the data that you need for business purposes and disposed of it after its useful life has expired?\n- User access control—do you have a solid user access control program in place so that only people who need certain data access have it?\n- Vulnerability management—are you actively scanning your systems like an attacker would to ensure that you are as protected as possible?\n- Data protection—are you implementing controls such as data leakage protection and host intrusion detection/prevention to try and stop attacks from happening?\nData Privacy and Security:\n- Segregation and segmentation of services—are your sensitive services walled off physically or logically from less sensitive ones so that you can apply the rigorous security controls selectively?\n- Monitoring—do you have the right instrumentation being generated and monitored so that when someone breaks through your controls—and they will be broken, make no mistake about that—you are able to quickly detect it and apply countermeasures?\n- Screening, training and awareness—do you have the right hiring policies in place? Are you ensuring that employees are trained appropriately about the dangers of phishing and social engineering?\nThe point I\'m trying to make is that without a solid security and privacy program in place to start with, encryption at rest is like applying duct tape to a broken bone. Encryption has its uses, and it can be effective as a security and privacy control, a safe harbor control and as a compliance measure. But if you\'re not careful about realizing its limitations and communicating them to your executives, you\'re the one that will be in hot water when an incident occurs.', 'What Is the Real Cost of Data Loss?\nAccording to statistics affirmed by Unitrends, about 96% of business servers are not backed up, and about 50% of the entire tape backups fail to restore. Furthermore, about a quarter of all PC users suffer from data loss annually, and many small businesses that experience data loss fold up within a year. Today, the amount of data being handled by organizations is increasing. Along with this data growth comes an increase in the organization’s attack surface and the risk of experiencing data loss to cyberattacks, malware, or even natural disasters.\nThe impact of data loss can be catastrophic for any business. Data loss is real and can happen to any organization if adequate data protection measures are not established and maintained. This issue has made backing up data a high priority and an important business decision. According to Backupify a 2018 study has revealed that the global average cost of data loss was around $142 per data record, totaling about $3.6 million. Hence, backing up Software As A Service (Saas) data should be a paradigm. Data backup ensures data safety in case of any disaster.\nWhat is Data Loss?\nAn organization experiences data loss when it loses valuable data on a computer or server due to attacks, occurrences, or compromises such as theft, human errors, malware, viruses, power failure, natural disasters, etc. Data loss may occur due to physical, mechanical, or software damage or failure of equipment. Data loss can also occur when data is mistakenly deleted or becomes corrupted. Also, formatting errors and viruses can render data unusable. An organization’s financial health often significantly impacts when it loses its data.\nAccording to an IBM study, the annual cost of a data breach is increasing by approximately 10% per year. The 2021 report says the average cost of a breach in hybrid cloud environments is $ 3.61 million, while the average cost of a ransomware breach is $ 4.62 million.\nFrequently backing up files aids data recovery when data loss occurs. Data recovery becomes complicated when an organization hasn’t backed up most of its data before a loss occurs. It often requires professional services if it stands a chance of being recovered. Even if this data can be recovered, the process usually consumes time and business resources that should be channeled to other important aspects of the business. On the other hand, even IT professionals might not be able to recover lost data, signifying permanent data loss. This makes data protection and data loss prevention more important.\nEffects of Data Loss On A Business\nData loss affects a business in different ways, some of which are:\n- Tarnishes Reputation\nThe effects of data loss on a company’s reputation can not be overemphasized. When customers discover that a startup business has experienced data loss, the trust they have in the company will diminish. They see the business as incompetent and unreliable. For a business that stores data on behalf of its clients, these clients expect a high level of data security. Anything below this security standard cripples their trust in the business. Consequently, the clients cut ties with the business and move to other companies that provide better services. Eventually, the business loses customers, profit, cash flows, referrals, and competitive advantage.\n- Plummeting Sales\nData loss can have detrimental effects on business sales and conversion rates. Data is a fundamental aspect of a business. Data ascertains the smooth running of a business to generate sales. When there’s an alteration due to data loss, in situations of data loss, most businesses cannot effectively operate until the lost data is recovered. Not only does it impede business operations, but it also makes business services and products unavailable to customers.\nIf this persists, customers will lose interest in patronizing the business. The time and resources spent on recovering data could have been used to augment the business productivity and sales.\n- Disrupts Productivity\nWhen businesses do not prepare for contingencies, even the slightest issue will have a significant impact. Companies with no measures to prevent or deal with data loss will experience disruption in their productivity during periods of data loss. Ultimately, it leads to decreased profits. Some business documents are essential in everyday business operations, and some of these documents are used by multiple employees to achieve certain business goals.\nDue to data loss, the organizational workflow will be interrupted in the absence of these documents. Employees need to find an alternative to these documents, or in some instances, they can not do anything since these documents serve as the foundation of their operation. Hence, numerous business tasks are left unfinished or not done pending the data loss issue’s resolution. However, having a data loss plan with a backup system will mitigate the effects of data loss on the organizational workflow.\n- Flouts Data Privacy Regulations\nLike every other aspect of life, rules and regulations guide data privacy and general business operations. Regulatory data privacy compliance laws direct that acquiring, storing, or utilizing Personally Identifiable Information(PII) by businesses must be done with the legal obligation of protecting data from unauthorized access.\nWhen data loss occurs, businesses are typically charged with the mismanagement and mishandling of sensitive data. Such an organization might face lawsuits from affected customers and regulatory bodies. This has deleterious effects on the company’s image. The company has to pay a considerable amount of money in fines or compensation.\n- Loss of Potential Partnerships and Opportunities.\nAnother significant effect of data loss on businesses is that it affects their relationship with potential and well-established partners due to concerns over data insecurity. When such business alliances are damaged, such businesses experience a reduction in their revenue. Also, the possibility of business growth is dealt with.\nEven when the data loss situation has been adequately taken care of, re-establishing a trusting relationship with the same business partners might be impossible or take some time. When these partners weigh their options, they discover that damage can be too much for them and not worth the risk in some instances. This implies that businesses that suffer data loss, in most cases, will have to start over and try to win over new partners.\n- Business Closure\nExtreme data loss is among the leading causes of a business shutdown. This occurs when the company doesn’t have a backup plan in place and it experiences data loss frequently. Usually, when a business experiences data loss, normal business operations are impeded for about two weeks, depending on their recovery efforts and the extent of data loss. During this period, employees still have to be paid their salaries even though the business isn’t generating enough income. Eventually, the business resorts to using the available capital to take care of the business costs before business operations are up and running.\nCauses Of Data Loss\nSeveral factors lead to data loss, both human and nonhuman errors.\n- Hard Drive Failure\nA hard drive is a piece of hardware that stores data. A hard drive uses its mechanical components to read and write data to a storage location. However, due to normal wear and tear that occurs in the mechanical components of a machine or device over time, there’s a possibility that they’ll become faulty after a while. This is why it is important to replace these hard drives before they fail and to do that, the data present on the old hard drive must be transferred to a new hard drive. Also, hard drive failure can result from physical damage, such as hitting the hard drive, dropping the hard drives, etc. For this reason, hard drives must be handled with care to avoid damage.\nIn the event of a hard drive failure, there’s a chance that the data stored on it is still intact. However, this depends on the condition of the storage plate.\n- Unauthorized Access and Malware\nProtecting your network from malicious attacks and unauthorized access is probably essential to data security. Computer viruses can compromise important or, even worse, delete or steal data. It gets scary for the company because stolen data can be used to commit fraud against the business or its customers, resulting in financial blight.\nFurthermore, employees’ login details could be disclosed, leading to unauthorized access to their workspace from an unknown user. If an unauthorized individual gains access to a company’s network, data can be stolen, deleted, or compromised, depending on the stranger’s motive.\nAn ongoing and prolonged power outage has also contributed to data loss. According to Monsterhost, a study conducted in 2014 revealed that 20% of data loss occurrences experienced by companies were a direct consequence of sudden blackouts, which cost between $50,000 and $ 5 million. A way to get around this is by employing a reliable hosting provider. Reliable providers set up teams who monitor servers to ensure power outages do not occur.\nAn organization that maintains its server or network must implement a contingency plan in the event of power outages. Using a generator that will automatically kick in whenever there’s a blackout is recommended. This ensures that your network doesn’t go offline, resulting in lost data.\n- Human Errors\nHuman errors can not be ruled out. We all tend to make mistakes, and sometimes, these mistakes are costly. For business operations, these mistakes can cause accidental deletion of data files. Furthermore, employees can overwrite important files or omit an essential aspect of normal business operations. Likewise, human errors can be the reason behind other causes of data loss, such as hard drive damage, liquid spills, software corruption, etc.\nA useful method of preventing human errors in data handling is adequate employee training. An organization should ensure that its employees comprehend the company’s data processing functionality and backup systems. Also, data loss from human error can be mitigated through some software means. One of these methods is business automation. Business automation reduces the amount of human interaction with data and reduces the risk of deleting or overwriting data. When an organization’s workflow is optimized, the chances of human errors will be slim.\nFor an organization to safeguard its future and prevent its downfall, it must have an effective data protection strategy in place.\nLearn more about data protection for modern businesses:']"	['<urn:uuid:01cd0ccf-f7e5-4935-a106-b8f987d8c100>', '<urn:uuid:507ecb89-07bf-45cb-8823-d458da6a0c49>']	open-ended	with-premise	long-search-query	distant-from-document	multi-aspect	novice	2025-05-13T01:50:22.828293	13	124	2604
56	What should builders consider when selecting sustainable construction materials?	Builders should consider both environmental impact and health effects when selecting materials. For environmental impact, they should evaluate carbon sequestration potential - biogenic materials like wood, hemp, and cellulose can turn buildings into carbon sinks. For health considerations, they must assess potential hazards throughout the material's lifecycle, including procurement, manufacturing, installation, occupancy, and maintenance. Mineral-based materials can cause respiratory issues like silicosis, while some metals like lead and cadmium can be toxic. Biogenic materials offer advantages in both areas - they sequester carbon and generally don't contain noxious chemicals, making them safer for workers and occupants while being recyclable or biodegradable.	['Materials link you to the larger world; to factories, smokestacks, mines, and oil-rigs, or to fields, forests, sun and soil. The materials used in a building can bring with them a large carbon debt that will take decades of operational efficiency to pay off, or they can turn a house into a carbon sink that’s already carbon-negative on day one.\nThis was the message delivered at the Better Buildings by Design conference, February 2020, by Chris Magwood of the Endeavour Centre in Peterborough, Ontario, and Jacob Racusik and Ace McArleton of New Frameworks in Burlington, VT, in a talk titled “Carbon Drawdown Now.”\nThe planet exchanges carbon among five spheres; the biosphere, pedosphere (soil layer), lithosphere earth’s crust and mantle, atmosphere, and hydrosphere (waters). Carbon sinks absorb more carbon than they release. According to the speakers’ analysis, buildings built with biogenic materials can become the world’s sixth carbon sink, with a surprisingly large impact. Project Drawdown identifies twelve building-based climate interventions. Using a biogenic supply chain can nearly double that impact.\nBiogenic materials are mostly plant-based (sheep-wool insulation is second-generation plant-based, since sheep eat plants). Often, they can be swapped out one-for-one with synthetic materials. Simply choosing blown-in cellulose insulation over synthetic spray foam sequesters plant-based carbon for the lifetime of the building. Biogenic materials include wood, wood fiber board, hempcrete, straw board, straw bales, bamboo, cork, rice straw MDF (medium-density fiberboard) mycelium, cellulose, and ReWall (sheathing board made from recycled, compressed drinking cartons). Many of these choices don’t require a radical rethink but make a large impact on a building’s carbon debt.\nPlant-based building materials sequester carbon in two ways. First, plants use it to build their own structures which are then preserved for the lifetime of the building. Second, plant roots build a certain amount of carbon into the soil, depending on how they are grown. Wood, for instance, should be sustainably harvested from well-managed local forests for maximum carbon-sequestration. Crop-based materials should be regeneratively farmed using minimal tillage.\nPaying attention to how materials are grown closes the loop between construction and the farms and forests where the supply chain originates. It creates community and brings profitable activity to rural areas. One example is a new factory next to a California rice farm that converts leftover straw into rice straw board, a form of MDF. Formerly, the rice stalks were rotted by flooding after harvest, releasing copious amounts of methane. Now, the carbon drawn out of the air during the growing season is sequestered in buildings, where it will likely remain for at least 100 years. Sequestration happens now, at the beginning of the building’s lifetime, which is when we urgently need to draw down carbon to avoid the worst effects of climate change. Under this model, operational savings over the building’s lifetime are an added benefit.\nMagwood of the Endeavour Centre offers four models for constructing a house, with escalating degrees of care for the environmental impact of materials. His conventionally built home has a net-emission debt of 207 tons of carbon. Without deviating far from current building norms, the same house can become a net carbon sink (-15 tons). By making the absolute best choices, using materials that currently exist but may be uncommon, a builder can achieve -117 tons of carbon sequestered.\nHe has found that choosing materials based on their global-warming potential reduces other kinds of negative impact, such as ozone depletion, acidification, and depletion of fossil fuels. These materials contain no noxious chemicals, so are healthier to live with, recyclable, or biodegradable.\nMaterials choice in retrofits and weatherization can also sequester carbon. Efficiency Vermont is currently conducting a study to ensure that weatherization materials do not cause unintended environmental damage. Affordability is also a consideration Generally, it seems that materials with high embodied carbon do not increase the cost of projects.\nFor all construction to become carbon-negative by 2030, builders should stop using high-carbon materials now, move to readily available, moderate-carbon materials within two to three years, go to carbon-zero buildings in three to five years, and aim for all buildings being net-negative in five to ten years. Can we? Watch the video and judge for yourself. It can be viewed at https://www.efficiencyvermont.com/trade-partners/bbd/keynote. You may come away feeling quite inspired.\nJessie Haas has written 40 books, mainly for children, and has lived in an off-grid cabin in Vermont.', 'Building materials used in construction of building structures can welcome health issues subsequently for occupants or to workmen involved in building services, maintenances, demolition and refurbishment.\nThis may be due to:\n- Vibration Effects\n- Poor acoustic characteristics of the building\n- Dysfunctional lighting\n- Extremes of relative humidity\n- The air exchange is inadequate\n- Toxicity mediated through soil\nThe above-mentioned issues will affect the durability of the building along with the health and comfort of the people residing in the respective building.\nBuilding Materials to Hazardous Material Conversion Stage\nThe whole life of a construction material must be considered and audited into account to understand what are the human and environmental health hazard issues from these materials.\nOther than this, the following mentioned stages must also be considered:\n1. The health as well as environmental impacts during the procurement of raw materials and the final disposal of the by-product or the waste product must be considered.\nThe process of obtaining raw materials includes mining, synthesis, manufacture and quarrying. Disposal of mine or unwanted by products, quarry spoil is some of the disposed materials.\n2. The hazards and health effects during the transportation of the materials must be considered.\n3. The effects of manufacturing a building product: The harmful effects if exist will affect the production worker, the members involved in the process, the public and the environment around.\n4. Improper handling of the product bringing harmful effects to the construction workers, the local residents and the environment.\n5. The hazard effects from commissioned buildings that have installed product to the people residing.\n6. The hazard effects from the works like maintenance, refurbishment and servicing to the professional workings, the decorators, plumbers, electricians and residents.\nDuring the time of construction, the surface skins and the connective tissues filling the gas are largely composed of materials. By the end of 20th century as a concern of economy and safety thousands of construction materials of asbestos have been installed in UK for new and old buildings.\nThe variation in the use of water supply connection materials have also brought mitigation to leakage problems hence avoiding the possibilities leakage that will in turn cause cholera, typhoid and other health problems.\nThis was the time where less toxic materials where used for plumbing systems like copper, iron and polymers.\nDifferent Mineral Based Construction Materials and Their Health Aspects\nCare is necessary during the selection of constructional materials that are mineral based as their respective nomenclature is commonly imprecise. The use of a hazardous material or selecting a safer alternative for the design of buildings are determined by an informed specifier.\nHence the state of knowledge of the builders and the occupants will determine the methods of working with such hazardous materials and replacement products if any.\nSome of the mineral construction materials and their respective health aspect is mentioned below:\nThe crystalline content and the amount of dust that is generated have the chances to be inhaled. This is the major health hazard caused by stone mineral used in construction works. Higher exposure to this will cause silicosis.\nThis is a health problem where the lungs will lose the normal elasticity, which will cause the act of breathing to become laboured. This will result in the impairment of blood circulation. This hence will result in the building up of waste carbon dioxide within the body and oxygen fails to enter the tissues. This will make the heart overburdened and final failure.\nThe excessive inhalation of stone dusts will result in increase of lung cancer as concluded form the studies. Based on the variation in the silica content of stones, their disease potential also varied.\nSandstone and true granite are notorious hazards for the masons. Sandstones are highly siliceous but granite can vary with their quartz content.\nThe hazard of these material lies in their quarrying and masonry work procedures also. To avoid risk, wet methods of blasting were introduced.\nThe slate material is also rich in silica content which bring the hazards of silicosis problems to the workers, the slate splitters and the engravers. The slate in the forms of slabs and tiles bring no form of harm to the occupants.\nConcrete patching will result the operatives to get irritation and become sensitive to the forms of cements and the additives used in the cement. The skin contact with the chromium ion present in cement is a problem. Withdrawal of contact with the cement faster will help in sooner recovery.\nThe clay is fired and later used for decorative purpose by glazing it. It is employed in the production of roof, sanitary piping, floor tiles and material structural decorative bricks.\nLarge silicate clay having a lesser hazard effect to health is transmuted during the clay firing into crystalline silica which are especially hazardous in nature.\nThis hazard effect is till the manufacturing process. This won’t affect the construction workers or the occupants that are residing.\nThis product is used in block form. It is used as a non-combustible thermal insulation between the joists. These bought problems for the carcinogenic potential.\nThis was determined by the observation of asbestos and vermiculite fibers in many specimens. A health study on a group of miners helped to find this health hazard.\nThe trapping of dust through the gaps of the ceiling and entering the room is a big cancer threat. If the material is very much needed, a fiber free material can be specified by the designer.\nA variety of chemical compounds in physical forms either of natural or synthetic origin have these calcium silicates. Some have fibrous forms while some have discrete particulates.\nThe test for carcinogenicity is determined by finding the calcium silicate content. Here too it is better to suggest non-fibrous products.\nGypsum in Construction\nThe gypsum material shows no health hazard. But it has accounted for 10 to 50 percent of radon in the soil due to the manufacture of plasters and plasterboards.\nFibrous form of serpentine and amphibole minerals form the asbestos. These materials where a concern behind the risks of asbestosis, lung cancer and mesothelioma. Many new materials out of cement and polymer matrix where developed to mitigate this problem and replace the asbestos material.\nNon-Asbestos Mineral Fibers\nWHO considered that there are materials to replace asbestos by materials like glass, slag wool, ceramic and refractory fibers. Complete removal of fibers products from the construction field is not possible but the most hazardous one can be removed.\nMetals That are Used in Construction and their Health Effects\nThe different metals that are used in different construction application and their respective health effects are described briefly:\nThe lead toxicity has resulted in problems like paralysis, anemia, malaise, severe colic, convulsion etc. These can result in frank disease during their intake. This bought a decision on the replacement of lead as a construction material.\nIn olden days, the principal sources of environmental lead contamination were the solders, paints and the water pipers.\nAdults intake the lead through drinking water while the children intake is through licking the wall with paint, chewing paintwork and house dust.\nThe use of copper in contemporary building have helped to eradicate the source of lead. The reformulation of the pain and the use of linseed putty help the lead entering the children tastes.\nThe harmful effects of leads have made the use of inorganic lead in paint and the use of organic lead in petrol by the government.\nThe chromium does not bring any sort of hazard effect, whether if it is used as a decorative material or as a protective material in construction. This can be used as a corrosion resistant alloys.\nThe salts of chromium are used in cement additives. This may cause skin irritation on contact. This may sometimes lead to the persistent dermatitis. These metals also bring concerns about carcinogens.\nCopper used in construction either in the form of metal or alloyed in brass bring no kind of health problems for the occupants. The workers engaged in industrial activities are more exposed to the heavy copper metal fume in large extent.\nAcute and chronic effects are caused on the lung, kidney and bone by the entry of cadmium. Hence cadmium is a toxic element. These metals are used to coat steel, where they act as a protection against corrosion. This protective layer brings no form of harm to the occupants.\nThe redevelopment or demolition process will employ flame-cutting of the metal. This have resulted in attacks due to metal-fume fever. Some of these cases have been found fatal.\nThe cadmium metal will liberate a toxic fume, when they are overheated. This is hence categorized under hard solder. This is employed in the installation of certain domestic apparatus. But they bring no harm to the occupants. This can bring harmful effects for the engineers who carry out soldering and disassembling of the same.\nThe paints and plastic make use of cadmium as a pigment. In areas wherever there is possibility of leaching out or have chances of being ingested by infants, the same has to be excluded and a better alternative have to be suggested.\nIron, Stainless steel, steel and Aluminium Metals\nThe mentioned metal brings some sort of adverse effects in certain situations. But their use has never been foreseen to offer any form of risks to the occupants.']	['<urn:uuid:bc1ab34e-d20b-40db-90d3-c8c6741ed3a8>', '<urn:uuid:6ad3eef2-50ac-4aca-82f5-d93ca2c0de10>']	open-ended	with-premise	concise-and-natural	similar-to-document	three-doc	expert	2025-05-13T01:50:22.828293	9	101	2281
57	john mccain vietnam war prison hanoi how long time spent what happened	John McCain spent five and a half years as a POW in Hanoi after his Skyhawk carrier warplane was shot down over North Vietnam in 1967. Although the North Vietnamese offered to release him earlier because his father was the Pacific Fleet commander, McCain refused and remained at the POW prison until 1973. The prison, called 'Hoa Lo' or 'Hanoi Hilton', was located in central Hanoi and was previously a French prison for Vietnamese nationalist prisoners.	['| || |\nRecalling Hanoi, the Capital of the Socialist Republic of Vietnam\nMarch 18, 2012 - Ray Tsuchiyama\nIn my previous blog post I mentioned that the current U.S. President spent much of his childhood in Hawai’i, plus Jakarta, Indonesia. Interestingly, the other presidential candidate – Senator John McCain – was also born outside the Fifty States -- in the Panama Canal Zone, but at the time of his birth, the Canal Zone was considered “U.S. territory”, so no media time was spent on this fact. (Another current presidential candidate’s father – George Romney – was born in Chihuahua, Mexico.)\nAfter his Skyhawk carrier warplane was shot down over North Vietnam in 1967, Senator McCain spent five and a half long years – the U.S. spent barely four years fighting World War II -- in a POW prison in Hanoi, the Vietnamese capital city, cooler and leafier with attractive French colonial architecture compared to the newer, more frenetic larger Ho Chi Minh City of the south. It is a testament to his motivation and drive that he won political elections and became a presidential nominee of his party. Although the North Vietnamese offered to release Senator McCain earlier (his father was the Pacific Fleet commander and later led all U.S. forces in Vietnam), he refused and remained at the POW prison until 1973. (In the late 1960s his father would poignantly travel to South Vietnam’s border with North Vietnam and gaze northwards towards his son.)\nIn 2005 I visited the former POW prison site (called “Hoa Lo”) in Hanoi. I remember clearly a sign: “Maison Centrale” (“Central House” in French) – it was a French prison for Vietnamese nationalist prisoners up to the late 1950s. It was also a short walk from my hotel in the middle of Hanoi, so even if a POW in his striped prison uniform escaped, he would stand out immediately while trying to hail a taxi.\nAdjacent to the former POW-dubbed “Hanoi Hilton” prison, a Vietnamese real estate firm constructed a tall condo-hotel (I would have loved to see the advertising highlighting the great “views”). I guess no one really cared about the prison and its historical significance. Or in another perspective, the North Vietnamese would argue that very few around the world raised any concerns during the oppression of Vietnamese during the many decades of the French colonial period, and it was their property, anyway.\nThe Vietnamese have a long view of history, going back to the Vietnamese resistance against the Chinese invaders, but “moved on” after the American War that ended in 1975 (half the population of unified Vietnam – 90 million -- was born after the War, so young Vietnamese have no memories of the long conflict that involved several countries in the region, plus military units from an U.S.-led coalition, including South Korea and Australia).\nI recall a meeting at a Vietnamese telecoms firm and the general manager and I looked at each other sitting across each other at a long teak table. I knew that he was thinking that we were about the same age and must have gone through the Vietnam War era. He did not speak English well, and he said through an interpreter that his second language was actually Russian, as he had studied engineering at a Moscow university. In the conference room was a team of young engineering managers, all born after the Vietnam War, and they were fluent in English, highly-educated technocrats.\nWhat struck me was the absence of men my age walking the Hanoi streets or at retail malls – probably several million North Vietnamese men died in the Vietnam War (in the Hanoi airport I saw books analyzing the post-war imbalance of men and women in Vietnamese society). Instead, I was startled by the mass movement of young men and women on motor scooters and cars throughout the city.\nDuring the early 1990s Senators John Kerry (a Vietnam War veteran who would later become an anti-war activist) and McCain joined together in a bipartisan campaign to restore full diplomatic relations with Vietnam, culminating in the 1995 accords during President Clinton’s administration. For many individuals a horrifying experience at a Hanoi POW prison would have made them abhor any contact with any Vietnamese, but Senator McCain worked diligently for years to bring the Vietnamese and Americans back together in peace*.\nSince I coincidently arrived on a business trip in Hanoi in 2005, ten years after the accords, I was invited to an U.S. Embassy celebration: in a surreal moment, surrounded by burly American Marines I ate hot dogs, French fries, and drank beer from Budweiser long-neck bottles -- in the middle of Hanoi. There were red-white-and-blue banners and Vietnamese flags decorating the walls and ceiling.\nThe club house where the party was held was probably bombed during the early 1970s American B-52 campaign that most likely accelerated the U.S.-North Vietnamese Paris peace talks and then resulted in U.S. military withdrawal from Vietnam. I thought that if I had been just a few years older I would have landed with an M-16 assault rifle at a beach in then-South Vietnam in the late 1960s, and encountered the Vietnamese Russian-speaking manager in a firefight. Instead, we met decades later for the first time in a cordial business meeting in a still-Communist-led city, Hanoi. Life is full of “what ifs . . .”\n*In an example of reaching out for mutual security after a long conflict, U.S. Navy warships have visited Vietnamese ports and have increased military cooperation in many areas, as the Vietnamese (and U.S.) are concerned about Chinese southward expansion, especially for oil resources.\nNo comments posted for this article.\nPost a Comment']	['<urn:uuid:9e7d990e-54c6-406b-98db-e242788fea16>']	open-ended	direct	long-search-query	similar-to-document	single-doc	novice	2025-05-13T01:50:22.828293	12	76	949
58	when was earless monitor lizard added protected species	The earless monitor lizard was added to the protected species lists in the 1970s in Indonesia, Malaysia and Brunei, which means it can't be legally traded or exported.	"['Are zoos inadvertently complicit in wildlife trade? The case of a rare Borneo lizard\nMonday, 21 June 2021\nShould zoos display legally protected species that have been smuggled out of their native countries? New research led by Oxford Brookes University has found that accredited zoos have acquired a rare and legally protected reptile, the earless monitor lizard - native to Borneo - without any evidence that the animals were legally exported.\n‘Miniature Godzilla’ is on protected species lists\nThe earless monitor lizard lives in the wild only on the island of Borneo and has been described as a ‘miniature Godzilla’. Discovered by western scientists almost 150 years ago, it wasn’t recorded in the wild for many decades. In the 1970s it was added to the protected species lists in the countries that make up Borneo - Indonesia, Malaysia and Brunei - which means it can’t be legally traded or exported.\nDespite this protection, reptile enthusiasts and unscrupulous traders have been smuggling small numbers of earless monitor lizards out of Indonesia and Malaysia, bringing them to Europe. This accelerated in 2012, when the species’ rediscovery was announced in a scientific journal. In 2016, 183 countries that signed the Convention on international trade in endangered species agreed to regulate global trade in earless monitor lizards, to limit the impact of smuggling on wild populations. Agreed export numbers were set at zero.\nZoos have obtained earless monitor lizards\nHowever in 2013, a zoo in Japan announced that it had obtained earless monitor lizards. In Europe, the first zoos to openly display earless monitor lizards were located in Hungary, Austria and the Czech Republic, obtained from what zoos referred to as “private individuals” or “dedicated hobby breeders”. How these animals ended up in Japan and Europe is questionable, but perhaps not illegal - and no export permits were ever issued.\nIn recent years more zoos in Europe and the United States have started displaying earless monitor lizards. Some animals were part of zoo exchanges, others obtained from private individuals, and a handful were placed in zoos by authorities after they were seized. But it is likely that many were at one point illegally exported out of Indonesia, Malaysia or Brunei, or were illegally imported into non-native countries.\nAcquisition undermines commitments to address illegal wildlife trade\nThe acquisition of these protected lizards by zoos is not in line with the intentions of their national laws of their countries of origin, nor with international wildlife trade regulations. Moreover, it is diametrically opposed to the commitments the international zoo community has made to address illegal wildlife trade.\n“To me, the current situation concerning the purchase and display of earless monitor lizards by accredited zoos can be compared with a road safety organisation posting online videos of its CEO doing wheelies on a motorbike and then adding that it was done on a private road where neither wearing a helmet nor having a driver’s licence is required,” said Vincent Nijman, Professor in Anthropology at Oxford Brookes University, author of the study. “Both may be legal in a technical sense, but the optics are not good.”\n""Modern, scientifically managed zoos are increasingly organising themselves with set ethical values and binding standards which go beyond national legislation on conservation and sustainability, but, unfortunately, this still only counts for a small proportion of zoos worldwide,"" said Dr Chris R. Shepherd, Executive Director of Monitor Research Conservation Society. ""Zoos that continue to obtain animals that have been illegally acquired, directly or indirectly, are often fuelling the illegal wildlife trade, supporting organised crime networks and possibly contributing to the decline in some species.""\nZoos need a cautionary approach\nSeven years ago, the price for a single earless monitor lizard was in the order of EUR 8,000 to 10,000 but in recent years prices have come down, to less than EUR 1,000. Now that earless monitor lizards are more affordable, and with accredited zoos giving a sense of legitimacy, experts are concerned that it could become more acceptable to keep these rare animals as pets.\n“When I grew up in the 1970s, it was still perfectly acceptable for what we now see as accredited zoos to regularly buy rare and globally threatened birds, mammals and reptiles from commercial animal traders. Few questions were asked about the legitimacy of this animal trade. This has dramatically changed for the better, and now many of the animals we see in zoos today have been bred in captivity, either in the zoo itself, or in partner zoos”, Nijman said. He added that in many ways zoos are a force for good in the global challenge to preserve species and conserve habitats. “It is imperative that these efforts are genuinely adopted by all in the zoo community, and, when there is doubt about the legitimacy of animals in trade, that a cautionary approach is adopted.”\nThe research Zoos consenting to the illegal wildlife trade – the earless monitor lizard as a case study was published in Nature Conservation.\nImage of an earless monitor lizard by Chien C. Lee.']"	['<urn:uuid:9349d9ae-1aa7-40f4-ae7f-6428716ed4b1>']	factoid	with-premise	short-search-query	similar-to-document	single-doc	expert	2025-05-13T01:50:22.828293	8	28	839
59	What conservation methods are being developed to preserve ancient wall paintings in Pompeii, and how do these compare to the climate control requirements for preserving paintings in modern museums?	At Pompeii, researchers are developing conservation methods using traditional materials like lime, enhanced with nanotechnology to make it more fluid for stabilizing frescos through backfilling. They're also using lime and silicon compounds to conserve the topmost layer of the paintings. For modern museums, paintings require strict climate control with relative humidity between 50-55% (±5%) and temperature at 20°C. Fluctuations in humidity are particularly damaging to paintings, as they cause expansion and contraction that can lead to cracks in canvas or chipping of paint layers. Museums specify that daily humidity changes should not exceed 5%, with hourly fluctuations staying below 2.5% to prevent damage.	['Modern buildings are designed to have a lifespan of around 50 years. But in historical terms, that is a mere blink of an eye. We would like archeological sites like Pompeii, for example, to stand the test of time immemorial. Preserving sites such as this with the most basic materials represents a huge scientific challenge. As part of the “Pompeii Sustainable Preservation Project”, researchers from Technische Universität München (TUM), Fraunhofer-Gesellschaft and ICCROM will spend the next ten years investigating long-term solutions to prevent the UNESCO world heritage site of Pompeii from falling further into ruin.\nAlmost two thousand years ago, the city of Pompeii was buried under a shroud of ash and lava ejected by nearby Vesuvius. The eruption in 79 AD essentially froze the ancient city, preserving it for centuries. Large-scale excavations did not begin until the 18th century. Bit by bit, the city began to reveal its secrets about life in ancient times.\nAs one of the largest self-contained sites surviving from antiquity, Pompeii is a treasure trove. Each new excavation yields new knowledge, and is greeted with huge interest by the public and research community. All too often however, a lot less interest has been shown in the sustainable preservation of this unique site.\nMany of the finds, most notably Pompeii’s frescos, have been moved to museums, to protect them from the wind and weathering. But because of inadequate conservation measures, the exposed walls of the city with their lavish decorations are now visibly disintegrating.\nPompeii as a center of world-class research\nThe researchers participating in the Pompeii Sustainable Preservation Project intend to concentrate on one of Pompeii’s apartment buildings, known as an insula. From 2014, they will embark on an ambitious conservation program, taking in everything from elaborate murals to the smallest wall. “The first step will be drainage, followed by new types of protective structures. But that is just the start,” explains Professor Erwin Emmerling of TUM’s Chair of Restoration.\nAn important new approach is preventive restoration. “To date, this has not been undertaken on an adequate scale. We want to find out more about ongoing restoration,” continues Emmerling. The researchers will only use simple, traditional materials. In any case, large equipment like cranes would be of no use in the narrow streets of Pompeii. They will also have to make do without concrete because it was not used in those days. Instead, the restoration team will use lime and other traditional building materials.\nModern technology for ancient monuments\nBut the researchers will not be foregoing all high-tech aids. They will use nanotechnology to make the lime more fluid, thus stabilizing the frescos through backfilling. The experts intend to conserve the topmost layer of the paintings using lime and silicon compounds.\nResearchers from various disciplines will be working alongside restoration experts and archeologists in the Pompeii Sustainable Preservation Project. The ancient city will be accurately surveyed both on the ground and through aerial photographs. Seismic measurements will provide information on how the monument will be impacted by future seismic activity, which will help to ensure that the conserved structures will later withstand these tremors. Construction and structural engineers will be supporting activities in this area.\nLast but not least, suitable sites within Pompeii are to be re-landscaped, and the project as a whole will be a training site for conservationists from around the world.\nThe key partners in the Pompeii Sustainable Preservation Project are Technische Universität München (Chair of Restoration, Art Technology and Science of Conservation), Fraunhofer-Gesellschaft (Fraunhofer Institute for Building Physics), and the International Center for the Study of the Preservation and Restoration of Cultural Property (ICCROM), which is attached to UNESCO. These institutions will be assisted by the Soprintendenza Speciale per i Beni Archeologici di Napoli e Pompei and the Istituto Superiore per la Conservazione ed il Restauro, which is a body of the Italian Ministry of Cultural Heritage. The University of Oxford’s School of Geography and the Environment, the Department of Ancient History at Ludwig Maximilian University in Munich, the German Archeological Institute (DAI) in Rome, the University of Pisa and the Istituto per i Beni Archeologici e Monumentali of the Consiglio Nazionale delle Ricerche (CNR) are supporting the project as research partners.\nProf. Erwin Emmerling\nTechnische Universität München\nLehrstuhl für Restaurierung, Kunsttechnologie und Konservierungswissenschaft', 'Museums around the world include a broad range of objects with widely differing ages: dinosaur bones, stone-age flutes made of mammoth tusks, sensitive photographs, paintings with thick layers of paint, contemporary sculptures. In all cases, the building has to maintain and protect the objects displayed and stored inside.\nExcessively dry air\nDry air absorbs humidity from objects, their weight is reduced and they contract. In the case of humid air, it is the other way round. Climatic fluctuations thus keep the objects in permanent movement and sooner or later a crack appears on the canvas or the color gilding chips off the baroque sculpture. Stabilization of the relative air humidity helps avoid tension in the material texture of the exhibits, the Building Climate Institute emphasizes.\nThe preservation of enshrined cultural artifacts generally requires a constant indoor climate which is defined within relatively tight limits . This climate has to be technically created. The air requires humidification — at least periodically. The values reached are measured using measuring systems. Nowadays, due mainly to lease agreements, international indoor climate values of between 50 and 55 ±5% RH and 20°C are required . The American ASHRAE standard formulates corridors for the indoor climate in even greater detail — from the narrowest AA to D. The narrowest climate corridor specifies RH = ±5% and T = ±5 K as long-term tolerance with seasonal adjustment. Positive from a conservational viewpoint is that there is a slow, seasonal adjustment of the indoor climate to the outdoor climate which lies within these limits.\nThe external climate and the relative air humidity show significant seasonal fluctuations. In winter, the RH is sometimes extremely low. In summer during rainfall, 100%. The external space and inner areas are more or less closely related at all times. This means that a change of the external climate is also noticeable indoors and can be even more pronounced there. Especially short-lived fluctuations of the indoor climate are harmful in the long term. Therefore, a change of the RH during one day may not be allowed to exceed 5%. During one hour, the fluctuations have to be below 2.5%. Basically, a change should be as minor as possible, while the frequency of fluctuations should be kept as low as possible . For particularly sensitive exhibits, there are special display cases. They may be damp-proof only, equipped with humidity regulation, or even fully air conditioned.\nSensitive wood products\nEach material has specific demands on its ambient climate. Metal, stone, canvas, oil, wood, leather, paper or ivory react differently to humidity and temperature fluctuations. Works on paper, wood, canvas or parchment are among the most sensitive objects. The main raw materials of our papers are plant fibers, textile fibers and wood pulp. These are strongly hygroscopic materials. By absorbing indoor humidity and releasing material humidity, they follow all humidity fluctuations in the environment. These exchange processes require the expansion or contraction of the material through a change of dimensions of the wood cells.\nThis is expressed by warping of parchment or paper, or by tears or bubbles on panel and canvas paintings or on color-gilded sculptures. On papers, humidity fluctuations lead to a displacement of soluble components such as the ink. Specialist terms here are ink corrosion and copper corrosion.\nFabrics, photographs, metal and stone\nIn textile objects, excessively low air humidity advances the fragility of the tissue. In photographic objects, substrates and binding agents become fragile and brittle in environments with low RH. Comfortable in a climate of between 20 and 60% RH, stone and ceramic can tolerate a low air humidity.\n- Anderson Art Gallery\n- Canadian Museum of HIstory\n- Guggenheim Museum\n- Harvard FOGG Art Museum\n- Milwaukee Public Museum\n- Royal Ontario Museum\n- San Francisco Museum of Modern Art\n- Smithsonian Museum']	['<urn:uuid:8ce8cd42-3a55-4275-a07a-660d16098ec2>', '<urn:uuid:1ae26b49-f1f7-4bd6-aa60-84ecab652c5e>']	open-ended	direct	verbose-and-natural	similar-to-document	multi-aspect	expert	2025-05-13T01:50:22.828293	29	103	1345
60	pennsylvania cprp certification training programs	PAPSRS (Pennsylvania Association of Psychosocial Rehabilitation Services) offers training and encouragement for practitioners to attain the status of Certified Psychiatric Rehabilitation Practitioner (CPRP), which is nationally recognized as evidence of competence and proficiency in the field. Pennsylvania currently has more CPRPs than any other state. Training is offered through an annual conference, institutes, workshops, and regional trainings in collaboration with OMHSAS.	"['> Psychiatric Rehabilitation\nWhat is a Clubhouse?\n“Clubhouse” is a community-based, social and vocational\nrehabilitation program based on the world famous Fountain House\nmodel. This model features ""work"" and “membership”\nas the primary methods for providing participants with increased\nopportunities in employment, housing, education, skill development,\nand social activities. Based on the successful model established\nby Fountain House in NYC in 1948, the unique feature of clubhouses\nis the focus on work as the primary rehabilitative tool through\nwhich members are engaged and recover functioning. Member participation\nand involvement in all aspects of clubhouse operation, functions,\nand decision-making is integral to the clubhouse model as are\npeer support, education, self-determination, responsibility, and\nthe opportunity to be employed in real work settings.\nMental Health Consumers throughout Pennsylvania experience the\nprocess of mental health recovery through the personal empowerment\nachieved through clubhouse membership. Above all, clubhouses are\na place of hope!\nPennsylvania Clubhouse Coalition\nBeginning in the 1970s with the early development of\npsychiatric rehabilitation philosophy and principles, many programs\nwere established with the name “clubhouse.” While\nmany of these programs provide effective and needed services,\nnot all of these “clubhouses” follow ICCD clubhouse\nstandards. ICCD clubhouses follow a very unique model of psychiatric\nrehabilitation. See the ICCD web site at www.iccd.org\nfor more inforamtion.\nThe Pennsylvania Clubhouse Coalition (PCC) was founded in October\n1993 by four clubhouses, which follow the 35 clubhouse standards\nestablished by the International Center for Clubhouse Development\n(ICCD), based in Fountain House, New York City. Over the past\n10 years, the PCC has grown to 27 clubhouses. These clubhouses\nare committed to supporting the growth and recovery of people\nwith mental illness, and to reducing the stigma associated with\nhaving a mental illness in the community, especially through employment.\nThe the Pennsylvania Clubhouse Coalition serves\nas a forum to facilitate the enhancement of ICCD clubhouse rehabilitation\nprograms and to improve the lives of people with mental illness\nFunctions of the PA\n- To provide a definition of a clubhouse for Pennsylvania.\n- To articulate clubhouse positions on issues that affect the\ninterests of adults with mental illness.\n- To educate and advise others throughout the State by clarifying\nthe role of clubhouses in the array of services offered in the\nmental health system.\n- To support the development of new clubhouses.\n- To support the enhancement of existing clubhouses.\n- To develop educational forums related to clubhouse issues.\n- To facilitate outcome studies on the effectiveness of clubhouse\nprograms and disseminate the results.\n- To secure funding in Pennsylvania for Transitional Employment\nas defined by the ICCD Standards.\n- To facilitate the networking of clubhouses statewide.\nPennsylvania Clubhouse Coalition (PCC) - Member\nPCC Vision and Strategic\nPlease visit the PA Clubhouse Coalition at www.paclubhouse.org.\nReturn to Top\nWhat is a drop-in center?\nA drop-in center is a safe haven for adults, an accepting place for anyone in need of support, advocacy and self empowerment on their recovery journey. Ideally Drop Ins are Consumer run, however here in PA and elsewhere there exist Drop Ins primarily run or run by consumers in partnership with an auspice agency. A drop in center, also sometimes called a peer resource center or self help center is a place of choice and is non-clinical. The people who use the drop-in center develop socialization programs and whatever other programs they choose.\nAt a drop-in center, there are people, not patients. The same people who come in search of support also support others and help run the center. Because the individuals who use drop-in centers determine the programs that are available, each drop-in center fills a unique role in people’s lives and in the community. However, all consumer-run drop-in centers share some common features, such as supportive environments, sources of information and social activities. As drop-in centers have developed across the country, they have provided a place where people with psychiatric labels who may not have been welcomed elsewhere can get away to a warm, friendly, family atmosphere. Centers often provide basic needs such as food and clothing and link consumers with social support services.\nHowever, as the consumer movement becomes more sophisticated, the concept of a drop-in center’s role has changed for many within the movement. Whereas the drop-in center previously was viewed as a place to provide basic supports, now many drop-in centers see themselves as a means of empowering people to take control of their own recovery and wellness. Drop-in centers promote empowerment by allowing participants to plan the activities that they themselves see as useful. This model is much different from that of traditional mental health services. At consumer-run drop-in centers, people create responsibilities for themselves. Individuals who use the center establish rules of behavior, work commitments, and event schedules. It is a place where people can see others who have suffered the same stigma and discrimination but are able to move forward with their lives.\nEmpowerment is central to drop in centers. Participants plan their own recovery. Drop-in centers have been far ahead of traditional mental health services in embracing the concept of recovery; the belief that people can focus on building better lives rather than simply treating symptoms. By becoming involved with drop-in centers, people can begin to shed the labels and limits that they have experienced and see opportunities.\nThe role and function of drop-in centers in the mental health system\nClearly, drop-in centers play important and effective roles in the lives of many people, but what roles do the centers play in the mental health system? For many people who have been diagnosed with mental illnesses, drop-in centers have been an essential way of improving their quality of life. In addition to (or rather than) seeking treatment from clinical programs, individuals can visit drop-in centers to seek support from their peers, participate in social activities, seek help in obtaining services and benefits, or simply relax and have fun. Although many drop-in centers do not consider themselves a part of the mental health system, it is impossible to deny that the existence of successful drop-in centers have a major impact on the mental health system. Interacting with and as an enhancement to the mental health system, consumer-run drop-in centers fill a unique and important role in (or around) the mental health system and the community.\nFor a fraction of the cost of clinical mental health services, a drop-in center can provide a supportive environment for individuals who might otherwise resort to hospitalization, crisis services or other costly services. As a result of their struggles they may have gotten involved in the criminal justice system, become homeless or succumbed to isolation that leads to deterioration of their lives and health, all of which can be ameliorated by peer support available at a drop in center.\nMany drop-in centers offer services on evenings, weekends, and holidays, when clinical mental health services might be unavailable and times that many people find particularly difficult. Drop-in centers have extensive histories as a vital part of a community. They provide a doorway for an individual’s recovery journey. Participants develop a sense of responsibility, self-worth, and belonging that may be absent in traditional settings.\nPennsylvania Coalition of Drop-In Centers and Peer Resource Centers:\nResources for Drop-In Centers:\n- A Guide to Funding and Financial Management. National Consumer Supporter Technical Assistance Center, Mental Health America.\n- Program Manual for a Consumer Drop-In Center, based on the Mental Health Client Action Network in Santa Cruz, Ca. By Bonnie Schnell, M.A., CPRP for COSP Multi-Site Study, FliCA site, SAMHSA.\n- Consumer Run Drop-In Centers - Technical Assistance Guide. National Mental Health Consumers’ Self-Help Clearinghouse.\n- Building Sustainable Consumer Run Organizations. Funding for this manual was made possible (in part) by the Mental Health Transformation - State Incentive Grant Award No. 5 U79\nSM57468-02 from SAMHSA. It was created through a contract with the University of Washington and the Self Help Empowerment and Evaluation Alliance (SHEEA) and was prepared by Anna Evans.\n- Consumer Delivered Services as a Best Practice Model in Mental Health Care Delivery and the Development of Best Practice Guidelines. Article by Mark S. Salzer of the University of Pennsylvania and Mental Health Association of Southeastern Pennsylvania Best Practices Team, Philadelphia.\n- Partnering With County Administrators to Become an Independent Agency. Presentation by Carmine A. Scotece, Butler County Human Services Director at the 22nd Annual Consumers’ Conference, June 15, 2010.\nWhat is the Fairweather Lodge Program?\nThe Fairweather Lodge Program helps people reintegrate themselves\ninto the community by providing emotional support, a place to\nlive, and employment for its members. The program was developed\nby Dr. George Fairweather in California in 1963 as a result of\nextensive experimental research. In his studies, Dr. Fairweather\nfound that people with serious mental illness are less likely\nto return to the hospital when they live and work together as\na group, rather than live and work individually. His research\nalso showed that the lodge program helps people stay in the community\nlonger, provides more employment opportunities, and costs less\nthan conventional treatment programs. Because of the success of\nthe original groups, the Community Lodge Program has expanded\nconsiderably during the past 25 years and there are now lodges\nacross the nation.\nHow Does A Lodge Operate?\nTypically, lodges are small groups of four to eight people who\nshare a house and own a small business. Each group must select\na business to operate, for which they develop and implement a\nbusiness plan. Lodge businesses have included lawn care, custodial\nor laundry services, printing, furniture building, shoe repair,\ncatering, and other services. Lodge members assume specific positions\nof responsibility within the household and the business. For example,\nthe business may have a manager and a crew chief; the household,\na cook and a medication supervisor. There are no live-in staff\nmembers at any lodge, although each lodge has access to a professional\nwho is available for training and consultation whenever the group\nrequests his or her help. Staff members are also on call 24 hours\na day for emergencies. In addition, lodge members hire professional\nconsultants - such as accountants and lawyers - to assist with\nlodge business operation. Responsibility for the house and business\nimproves the member\'s self-confidence and helps them become more\nindependent by giving them a stable role in the community.\nWhat Are The Program Principles?\n- Consumers must have a stake in the system.\n- The program must provide consumers as much autonomy as possible.\n- Options for promotion and rising to a higher status must be\n- Values of the larger society should be reflected.\n- The program must reflect the characteristics of the environment\nin which it exists.\n- Tolerance of harmless individual idiosyncrasies must be established.\n- Feedback must be provided on the problem-solving abilities\nof the consumers.\n- Open entry and exit for consumers must be provided.\n- Both rehabilitative and work norms should be supported.\n- Program should not be dependent on good will of the community\nin which it exists.\nPlease visit The Coalition for Community Living web site at www.theccl.org.\nPAPSRS (Pennsylvania Association of Psychosocial Rehabilitation Services) is an association of more than 175 psychiatric rehabilitation organizations and practitioners throughout the commonwealth which works in close collaboration with OMHSAS. PAPSRS is affiliated nationally with USPRA (United States Psychiatric Rehabilitation Association).\nPAPSRS was organized over 20 years ago to promote and support the philosophy, values, and practices of Psychiatric Rehabilitation for people in recovery from mental illness and to exercise leadership and encourage the development of continually improving concepts and practices of Psychiatric Rehabilitation in Pennsylvania. It offers training opportunities and technical assistance in close collaboration with OMHSAS in the areas of Psychiatric Rehabilitation, Recovery, and Service Transformation. Training is offered through an annual conference, institutes, workshops, and regional trainings. In conjunction with USPRA, PAPSRS offers training and encouragement of practitioners to attain the status of Certified Psychiatric Rehabilitation Practitioner (CPRP), nationally recognized as evidence of competence and proficiency in the field. Pennsylvania currently has more CPRPs than any other state.\nPAPSRS is dedicated to the promotion and improvement of a range of services and approaches that facilitate recovery and is very supportive of Peer Support, encouraging membership of the new Peer Support workers. The PAPSRS Conference is held in April in State College, PA. See the web site for more information.\nMore information about PAPSRS can be found at www.papsrs.org . Look there for Conference and training information as well as membership initiatives for Peer Specialists. Contact PAPSRS at any time regarding membership or member-services information at email@example.com or calling 888-490-0404.\nReturn to Top']"	['<urn:uuid:9710db9e-074e-4d09-8017-7be8c52936bd>']	open-ended	with-premise	short-search-query	distant-from-document	single-doc	expert	2025-05-13T01:50:22.828293	5	61	2096
61	What specific separation methods are used to eliminate the interference of iron and copper matrix elements when analyzing chalcopyrite using k0-INAA?	The copper interferences were eliminated by applying an electrolytic separation method, while iron interferences were eliminated through a liquid-liquid extraction procedure using diisopropyl ether (DIPE) in hydrochloric acid solution, with trace elements determined in the aqueous phase.	"[""Determination of trace elements in chalcopyrite (CuFeS<sub>2</sub>) by k<sub>0</sub>-instrumental neutron activation analysis after matrix elements removal\nKeywords:chalcopyrite, trace elements, neutron activation analysis, k0-INAA\nA method for trace elements determination in chalcopyrite, CuFeS2, by k0-instrumental neutron activation analysis (k0-INAA) was proposed. To avoid the interference of iron and copper as matrix elements, methods for their separation were applied. The copper interferences were eliminated by applying an electrolytic separation method. To eliminate iron interferences, a liquid-liquid extraction procedure by diisopropyl ether (DIPE) in hydrochloric acid solution and determination of trace elements in the aqueous phase were undertaken. The k0-INAA method was applied to determine the content of the investigated elements, making it possible to follow the distribution of even fifty elements (with intermediate/medium and long half-lived radionuclides) in the studied mineral. The important advantage of the proposed method is the possibility to determine the content of several trace elements after Fe and Cu separation. Additionally, the elimination of the matrix elements lowered the limit of detection for some trace elements in the water phase compared to their corresponding values determined by k0-INAA in the powder sample.\nJ. R. Castillo, M. J. Mir, M. L. Martinez, T. Gomez, Study of the composition of siliceous material by AAS, At. Spectrosc., 9, 9–12 (1988).\nJ. G. Viets, M. R. O'Leary, R. J. Clark, Determination of arsenic, antimony, bismuth, cadmium, copper, lead, molybdenum, silver and zinc in geological materials by atomic-absorption spectrometry, Analyst, 109, 1589– 1592 (1984).\nR. Eidecker, E. Jackwerth, Multielement preconcentration from iron and iron compounds, Fresenius' Z. Anal. Chem., 331, 401–407 (1988).\nJ.S. Barros, Determination of antimony, arsenic, bismuth, cadmium, cobalt and silver in complex sulphide minerals by flame atomic absorption spectrometry, Analyst, 114, 369–373 (1989).\nA. Lazaru, T. Stafilov, Determination of copper in sulfide minerals by Zeeman electrothermal atomic absorption spectrometry, Fresenius’ J. Anal. Chem., 360, 726–728 (1998).\nT. Stafilov, Determination of trace elements in minerals by electrothermal atomic absorption spectrometry, Spectrochim. Acta, 55B, 893–906 (2000).\nA. Lazaru, T. Stafilov, Determination of Co, Ni and Pb in arsenic minerals by Zeeman electrothermal atomic absorption spectrometry, Bull. Chem. Technol. Macedonia, 19 (1), 21–26 (2000).\nD. Zendelovska, T. Stafilov, Extraction separation and electrothermal atomic absorption spectrometric determination of thallium in some sulfide minerals, Anal. Sci., 17, 425–428 (2001).\nM. Benzaazoua, P. Marion, L. Liouville-Bourgeois, R. Joussemet, R. Houot, A. Franco, A. Pinto, Mineralogical distribution of some minor and trace elements during a laboratory flotation processing of Neves-Corvo ore (Portugal), Int. J. Miner. Process. 66, 163–181 (2002).\nM. Taseska, T. Stafilov, P. Makreski, G. Jovanovski, Determination of trace elements in some copper minerals by atomic absorption spectrometry, Ovidius University Annals of Chemistry, 16, 43–46 (2005).\nQ. L. Li, J. X. Zhu, Q. Ying, Z. W. Mao, C. S. Wang, J. L. Chen, The application of trace element analysis to the study of provenance of copper minerals in ancient bronzes, Spectrosc. Spectral Anal., 25, 1700–1702 (2005).\nM. A. E. Huminicki, P. J. Sylvester, L. J. Carbi, C. M. Lesher, M. Tubrett, Quantitative hass balance of platinum group elements in the Kelly Lake Ni-Cu-PGE deposit Copper Cliff offset, Sudbury, Economic Geology, 100, 1631–1646 (2005).\nM. Varadi, S. Szegedi, J. Csikai, Determination of Cu in minerals by 14-MeV neutron-activation analysis and radiochemical separation, J. Radioanal. Nucl. Chem., 107, 253–262 (1986).\nT. Todorov, NAA analysis of gold in minerals from upper cretaceous massive copper-deposits in Bulgaria, Terra Nova, 3, 311–316 (1991).\nE. Frantz, H. Palme, T. Wolfgang, A. El Goresy, M. Pavićević, Geochemistry of Tl-As minerals and host rocks at Allchar (Macedonia), N. Jb. Miner. Abh, 167, 359–399 (1994).\nL. Raimbault, H. Peycelon, J.L. Joron, Single-crystal trace element analysis in rock-forming minerals by instrumental neutron activation analysis, J. Radioanal. Nucl. Chem., 216, 221–228 (1997).\nN. A. Sharara, G. C. Wilson, J. C. Rucklidge, Platinumgroup elements and gold in Cu-Ni-mineralized peridotite at Gabbro Akarem, Eastern Desert, Egypt, Can. Mineral., 37, 1081–1097 (1999).\nR. Jaćimović, A. Lazaru, D. Mihajlović, R. Ilić, T. Stafilov, Determination of major and trace elements in some minerals by k0-instrumental neutron activation analysis, J. Radioanal. Nucl. Chem., 253, 427–434 (2002).\nR. Jaćimović, P. Makreski, V. Stibilj, T. Stafilov, G. Jovanovski, Characterization of some iron minerals from the Republic of Macedonia using instrumental neutron activation analysis, Geologica Macedonica, 19, 33–38 (2005).\nP. Makreski, R. Jaćimović, V. Stibilj, T. Stafilov, G. Jovanovski, Determination of Trace elements in iron minerals by instrumental and radiochemical neutron activation analysis, Radiochim. Acta, 96, 855–861 (2008).\nR. Jaćimović, B. Smodiš, T. Bučar, P. Stegnar, k0-NAA quality assessment by analysis of different certified reference materials using the KAYZERO/SOLCOI software, J. Radioanal. Nucl. Chem., 257, 659–663 (2003).\nHyperLab 2002 System, Installation and quick start guide, HyperLabs Software, Budapest, Hungary, 2002.\nUser’s Manual KAYZERO/SOLCOI® Version 5a software package, 2003: KAYZERO/SOLCOI for reactor neutron activation analysis (NAA) using the k0 standardization method, Published by DSM Research, Geleen (NL), developed at the INW-RUG, Gent (B) and the KFKI, Budapest (H).\nHow to Cite\nThe authors agree to the following licence: Attribution-NonCommercial 4.0 International (CC BY-NC 4.0)\n- Share — copy and redistribute the material in any medium or format\n- Adapt — remix, transform, and build upon the material\n- for any purpose, even commercially.\nUnder the following terms:\nAttribution — You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.\n- NonCommercial — You may not use the material for commercial purposes.""]"	['<urn:uuid:20a42e3f-3531-4fa0-b6a0-ff99755983c2>']	factoid	direct	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-13T01:50:22.828293	21	37	913
62	need help protect skin lymphedema daily routine skin care tips prevent infection	Good skin care can help minimise infection risk. Keep skin soft by moisturising daily with non-perfumed cream. Use body wash instead of soap. Wear gloves when gardening or doing dishes. Avoid insect bites, cuts and scratches. Treat any wounds with antiseptic ointment. Avoid hot water bottles or ice packs on affected limbs. Cover up and use 30+ sunscreen when outdoors.	['Living with lymphoedema\nThis resource was written for people with lymphoedema.\nLymphoedema is the swelling of part or parts of the body that occurs when the lymphatic system is not working properly. The lymphatic system consists of many tiny channels throughout the body called lymph vessels or lymphatics.\nLike blood vessels, these join together to form larger channels. The lymphatic system carries lymph, a colourless, watery fluid that contains lymphocytes – a type of white blood cell. The lymph is filtered through a number of nodes (sometimes known as glands) before going into the bloodstream. Lymph nodes range in size from as small as a pinhead to as large as a baked bean. In some parts of your body there may be just a few, whereas in your armpit there are, generally, 30–50 nodes.\nSome factors that may cause lymphoedema are:\n- birth abnormality, which may not show until later in life (primary lymphoedema).\n- where lymph nodes are blocked, damaged or cut (secondary lymphoedema), for example:after surgery to lymph nodes\n- radiation treatment to lymph nodes.\nNot everyone who has the above treatments will develop lymphoedema, and of those who do, many will only experience mild swelling.\nLymphoedema is not curable. In most cases it can be controlled with treatment. See a lymphoedema therapist for an assessment and a treatment plan. Contact your local Cancer Society for a lymphoedema therapist in your area.\nTreatment may include:\n- skin care\nGood skin care can help minimise the risk of infection.\nIf build-up from lymphoedema sits close to the skin surface, the limb may become infected through cuts, scratches or insect bites.\nSee your doctor immediately:\n- if any pain, redness or heat is present in the affected limb.\n- you notice any red lines tracking along the limb.\n- if you feel generally unwell.\nAlways complete the prescribed course of antibiotics. If signs and symptoms persist after a course of antibiotics, seek medical advice. The infection may not have completely cleared.\n- Avoid sunburn, cover up and use 30+ sunscreen when outdoors.\n- Keep skin soft – gently moisturise daily with a non-perfumed cream or oil, such as Dermaveen Moisturising Lotion or QV moisturiser. These are non-sticky lotions (without lanolin or perfume). For dry scaly skin use a 10 percent urea cream, for example, Aquacare.\n- Instead of soap try a body wash, for example, QV wash soap alternative or Dove soap. They are non-lathering gentle cleansers that do not dry out the skin.\n- Wear gloves when gardening or doing dishes.\n- Try to avoid insect bites, cuts and scratches. Treat any that occur with antiseptic ointment or spray, for example, Savlon and, Stingose. You may be prescribed an antibiotic ointment, for example, Bactroban.\n- If possible, use the unaffected arm to have your blood pressure, injections or blood taken.\n- Avoid the use of hot water bottles, or ice or heat packs on your affected limb.\n- Spa baths are not recommended.\n- Always wear your compression garment as shown. If you do not have a compression garment contact your local Cancer Society or your therapists. You may need to wear a garment for air travel or land journeys at high altitude, for example, tramping or long car journeys.\n- For arm lymphoedema, use the unaffected arm for carrying heavy parcels.\n- Check that your work environment is not making your lymphoedema worse (for example, computer set-up, heavy lifting or repetitive movements).\n- For leg lymphoedema, avoid standing or sitting still for long periods. Do gentle exercises every 15 minutes, such as changing your leg position, bending, stretching, or circling your foot at the ankle. Try to get up and walk around every hour if possible.\n- Treat all infections, such as athlete’s foot, promptly.\nA balanced diet low in fat and high in fibre is important.\n- Eat plenty of fresh fruit and vegetables.\n- Drink lots of fluid daily, especially water.\n- Try to maintain the ideal weight for your height and build.\n- Putting on weight can make lymphoedema more difficult to control.\n- Having low protein may worsen the condition. Eat easily digested protein, such as chicken, fish, tofu or low fat dairy products.\nRegular exercise, such as walking and swimming can be very good for you. Muscular action will help to move the fluid out of the swollen limb. See your lymphoedema therapist or local Cancer Society for exercise sheets that will help.\nLearn how to do this from your lymphoedema therapist.\nThese should be fitted by a lymphoedema therapist or another trained person. They should be worn according to the therapist’s instructions and cared for according to the manufacturer’s instructions. Talk to your lymphoedema therapist about suppliers and subsidies that may be available.\nTalking about your experience can be very helpful. Other people with lymphoedema can be a great source of support, advice and experience. Check with your local Cancer Society for local support groups or education in your area.\nThese are usually nurses, physiotherapists or massage therapists who have undertaken specialised training in lymphoedema management. Check that your therapist has the appropriate training. Your local Cancer Society will be able to advise you about trained lymphoedema therapists in your area.\n- Lymphoedema therapists work in public and private practice. Private costs may be covered by your medical insurance. You will need to check your policy if you have one.\n- If your lymphoedema is moderate to severe, your lymphoedema therapist will probably recommend a course of Complex Physical Therapy (CPT). This can be successful in reducing and controlling swelling, and the earlier it is started in the development of lymphoedema, the higher the likelihood of success. CPT involves bandaging and massage (daily for 2–3 weeks), along with exercise, skin care, dietary advice and the fitting of a compression garment.\nSeek treatment early: see a lymphoedema therapist early in the development of lymphoedema, or if there is any increase in existing lymphoedema.\nThe following organisations have websites with free information available online. If you do not have access to the internet, contact the Cancer Information Helpline 0800 CANCER (226 237) who can provide this information for you.']	['<urn:uuid:7aee447a-57f3-4c05-a9d6-b7da3bd2b937>']	factoid	with-premise	long-search-query	distant-from-document	single-doc	novice	2025-05-13T01:50:22.828293	12	60	1025
63	art conservation temperature humidity effects	Different art materials react distinctly to climate conditions. Works on paper, wood, canvas, and parchment are highly sensitive, with humidity changes causing warping, tears, or bubbles. The Rothko Chapel addresses these conservation challenges through its $30 million restoration project, which includes advanced climate control systems. The new facilities maintain stable conditions to prevent damage, as even minor climate fluctuations can harm artworks - with daily humidity changes restricted to no more than 5%.	"[""SINCE THE ROTHKO CHAPEL'S opening in 1971, Houstonians have entered the tomblike Montrose sanctuary seeking serenity in the stillness of its gray walls and the depths of Mark Rothko’s abstract paintings. But for the past year we’ve had to do without the beloved space that has seen us through moments of both joy and sorrow.\nThe chapel—located next to The Menil Collection and itself commissioned by the de Menils—has been closed while its Rothko-designed octagonal structure and grounds undergo a $30 million, multiphase restoration slated for completion around 2023. The project, aptly named Opening Spaces and being overseen by Architecture Research Office, is not the first time the chapel has undergone reconstructive surgery. In the 1990s the sanctuary underwent some renovations, which included treatment of the artist’s 14 mammoth canvases for damage and discoloration, as well as repairs done to the grounds’ Barnett Newman sculpture, “Broken Obelisk,” in 2016.\nThe first phase of Opening Spaces wraps this June, when the chapel and its plaza reopen. In the meantime, as of this month, the new Visitor Welcome House, one of several structures being built across the street from the chapel, will make its debut.\nWhat other changes have been made or are on the horizon? Here are six things to know:\nLET THERE BE LIGHT\nEver feel like the Rothko was just a bit too dark? You weren’t imagining it. The building has long struggled with lighting. Rothko painted the chapel’s canvases in his New York studio under a skylight and insisted a similar feature be incorporated into the sanctuary’s design. But he’d never visited Texas—or experienced Houston’s scorching sun. Immediately after the chapel opened in 1971, “it was very clear that there was just too much light flooding into the space,” explains Ashley Clemmer, director of programs and community engagement.\nSo over the years a series of devices, including umbrella-like baffles, have been employed to protect Rothko’s artwork. But those same structures have often cast the paintings in shadow, making them appear darker and the chapel itself smaller. “With today’s technology we’re able to go back to the original concept and design of the chapel and fully realize it in a way that we couldn’t in 1971,” says Clemmer. Lighting designer George Sexton of George Sexton Associates has devised a skylight that uses UV-reducing glass and louvers to filter light, as well as a system of projectors to illuminate the paintings in darker hours.\nIn keeping up with regulations put in place following Hurricane Harvey, the Rothko Chapel now has an underground water-detention system that will manage runoff and prevent flooding. There’s also a backup generator, stored in the new energy facility behind the visitors’ center, that will keep the chapel at the ideal temperature for the paintings even if the city loses power.\nHERE’S A BRICK, THERE’S A BRICK\nThe Rothko's design features a continuous brick façade, but after five decades of wear and tear, some of those bricks need replacing; others had to be removed last year when the restoration team added steel reinforcements to shore up the structure’s stability. To keep its seamless look, the original brick manufacturer, St. Joe Brick Works, Inc. in Louisiana, has been commissioned to make more.\nAs every good Montrosian knows, the streets surrounding the Menil, and the Rothko, are lined with sweet little gray bungalows. The five such structures on the Rothko campus must be removed to make space for new buildings, including a program center and administrative and archives building, complete with an archive and a library research space, to be implemented during the latter stages of the restoration. While it’s a shame to see the bungalows go, there is a silver lining: One will be moved and used as a guest house, and staff hope to either sell or upcycle the others.\nFULL STREAM AHEAD\nThe Rothko typically attracts more than 100,000 visitors a year, but since the chapel itself can accommodate only about 200, guests occasionally have been turned away at events. The new program center will be able to stream events taking place inside the chapel, effectively doubling its capacity. The idea is to create “that sense of space where people are not feeling like they are on top of each other,” says Executive Director David Leslie. “Because the whole point of the campus is to get you feeling away from that.”\nIT IS EASY BEING GREEN\nThe bamboo next to the plaza's reflecting pool will be replaced with savannah hollies; some 300 birch trees will be planted in groves on the grounds, creating spaces for privacy; and a new meditation garden will eventually take root between the Rothko and the Menil Park. These landscaping elements, designed by Nelson Byrd Woltz Landscape Architects, are “a way to be a good steward within the neighborhood that we’re in,” says Leslie. “It’s a way to enhance the livability of the neighborhood and contribute to its well-being.”"", 'Museums around the world include a broad range of objects with widely differing ages: dinosaur bones, stone-age flutes made of mammoth tusks, sensitive photographs, paintings with thick layers of paint, contemporary sculptures. In all cases, the building has to maintain and protect the objects displayed and stored inside.\nExcessively dry air\nDry air absorbs humidity from objects, their weight is reduced and they contract. In the case of humid air, it is the other way round. Climatic fluctuations thus keep the objects in permanent movement and sooner or later a crack appears on the canvas or the color gilding chips off the baroque sculpture. Stabilization of the relative air humidity helps avoid tension in the material texture of the exhibits, the Building Climate Institute emphasizes.\nThe preservation of enshrined cultural artifacts generally requires a constant indoor climate which is defined within relatively tight limits . This climate has to be technically created. The air requires humidification — at least periodically. The values reached are measured using measuring systems. Nowadays, due mainly to lease agreements, international indoor climate values of between 50 and 55 ±5% RH and 20°C are required . The American ASHRAE standard formulates corridors for the indoor climate in even greater detail — from the narrowest AA to D. The narrowest climate corridor specifies RH = ±5% and T = ±5 K as long-term tolerance with seasonal adjustment. Positive from a conservational viewpoint is that there is a slow, seasonal adjustment of the indoor climate to the outdoor climate which lies within these limits.\nThe external climate and the relative air humidity show significant seasonal fluctuations. In winter, the RH is sometimes extremely low. In summer during rainfall, 100%. The external space and inner areas are more or less closely related at all times. This means that a change of the external climate is also noticeable indoors and can be even more pronounced there. Especially short-lived fluctuations of the indoor climate are harmful in the long term. Therefore, a change of the RH during one day may not be allowed to exceed 5%. During one hour, the fluctuations have to be below 2.5%. Basically, a change should be as minor as possible, while the frequency of fluctuations should be kept as low as possible . For particularly sensitive exhibits, there are special display cases. They may be damp-proof only, equipped with humidity regulation, or even fully air conditioned.\nSensitive wood products\nEach material has specific demands on its ambient climate. Metal, stone, canvas, oil, wood, leather, paper or ivory react differently to humidity and temperature fluctuations. Works on paper, wood, canvas or parchment are among the most sensitive objects. The main raw materials of our papers are plant fibers, textile fibers and wood pulp. These are strongly hygroscopic materials. By absorbing indoor humidity and releasing material humidity, they follow all humidity fluctuations in the environment. These exchange processes require the expansion or contraction of the material through a change of dimensions of the wood cells.\nThis is expressed by warping of parchment or paper, or by tears or bubbles on panel and canvas paintings or on color-gilded sculptures. On papers, humidity fluctuations lead to a displacement of soluble components such as the ink. Specialist terms here are ink corrosion and copper corrosion.\nFabrics, photographs, metal and stone\nIn textile objects, excessively low air humidity advances the fragility of the tissue. In photographic objects, substrates and binding agents become fragile and brittle in environments with low RH. Comfortable in a climate of between 20 and 60% RH, stone and ceramic can tolerate a low air humidity.\n- Anderson Art Gallery\n- Canadian Museum of HIstory\n- Guggenheim Museum\n- Harvard FOGG Art Museum\n- Milwaukee Public Museum\n- Royal Ontario Museum\n- San Francisco Museum of Modern Art\n- Smithsonian Museum']"	['<urn:uuid:803527d1-69fa-498f-b5a8-378c71e1ff1b>', '<urn:uuid:1ae26b49-f1f7-4bd6-aa60-84ecab652c5e>']	factoid	direct	short-search-query	distant-from-document	multi-aspect	novice	2025-05-13T01:50:22.828293	5	73	1449
64	I enjoy hiking in areas with unique rock formations. Between Backbone State Park and Cathedral Pines, which location offers more opportunities for rock-related activities like climbing?	Backbone State Park offers more rock-related activities, featuring rugged dolomite limestone cliffs throughout the park where visitors can climb and rappel, particularly near the Backbone Trail (climbers must register at the park office). Cathedral Pines, on the other hand, explicitly prohibits rock climbing as part of its rules for visitors.	"['Learn to Hunt\nReport Your Harvest\nCurrent Fishing Report\nTaking Kids Fishing\nIowa\'s natural resources plates include the state bird and flower, pheasant, eagle, buck and a Brook trout. Support conservation in Iowa by buying a natural resource plate for your vehicle.\nNatural Resource Plates\nExperience Iowa\'s natural beauty and all the fun our state parks offer. Make your online reservation for state park cabins, camping sites, shelters and lodges.\nSupport conservation in Iowa by buying a natural resource plate for your vehicle.\nNatural Resource Plates\nIowa DNR Customer Service\nMon - Fri, 8:00am - 4:30pm CST\nSubmit Online Inquiry\nInformation / Records Requests\nContact Information by County\n1347 129th St\nDundee, IA 52038\n2018 Trail Run\nBackbone is a beautiful place for a family picnic. Several open shelters and the auditorium may be reserved online through the park reservation system.\nConstructed by the Civilian Conservation Corps, the stone lodge overlooking the lake may be rented for a number of events including family reunions, weddings and other large gatherings. The lodge may be rented online at park reservation system. Backbone Concessions handles the lodge operation.\nIf you have questions about the lodge or cabins contact the concessionaire, Kelly Peterman, at 319-361-4794.\nThe modern two-bedroom cabins and renovated one-bedroom cabins are available and are equipped with heating and air conditioning. The two-bedroom cabins are available year round. Newly renovated one bedroom style cabins are available year round. Renters must provide their own bedding and dinnerware. The cabins can be reserved for a fee online through the park reservation system.\nNew year-round cabin at Backbone State Park. Inside view.\nThere are a plethora of camp sites located in two campgrounds. The South Lake Campground contains non-electric sites, electric sites, 2 shower buildings, a playground and a dump station. The Six Pine Campground, near the west entrance of the park, contains non-electric sites and provides pit latrines. Advance campsite reservations can be made through the park reservation system. One fourth of the campsites are still available for self-registration on a first-come, first-serve basis.\nBackbone has 21 miles of hiking and multi-use trails. Visitors can hike along trails winding through old twisted and windblown cedars and up rough, rocky staircases to one of the highest points in northeast Iowa, the ""Devil\'s Backbone."" During winter, visitors can cross-country ski and snowmobile.\nBicyclists can pedal through scenic splendor and explore the park on these designated trails; Barred Owl, Bluebird, East Lake and West Lake. Mountain bikes must stay on the trails.\nLake Activities (swimming, boating, fishing)\nBackbone Lake is an impoundment of the Maquoketa River created by the CCC. Recreation on the lake includes swimming, boating, fishing and a concession stand for refreshments. A boat ramp is located near the southwest end of the lake. Motors are limited to electric only. A boathouse for renting boats, a swimming beach and concession stand are located near the southeast end of the lake. Anglers casting their lines in the lake may catch a variety of fish such as bass and catfish.\nBackbone Concession (563-924-2144): Open Friday of Memorial weekend thru Labor Day weekend; 7 days a week; 9:30 AM to 7 PM daily\nHamburgers, hot dogs, fast food, ice cream, ice, candy, pop, beach toys, firewood, bait and boat rentals. Cabin rental, check in for reserved cabins and beach lodge rentals here.\nBeach Monitoring Results\nBackbone is well known for trout fishing in its cold, clear, quick-flowing stream. Richmond Springs, the source that feeds the stream, pumps out over 2,000 gallons per minute and is located near the north end of the park. Anglers can explore the stream through a variety of shady and easy accessible trails. A 600 foot ADA concrete sidewalk and concrete ADA parking lot along the trout stream provides easy accessibility to the stream and for fishing.\nClimbers and rappellers will find many challenging cliffs of rugged dolomite limestone throughout the park. The most popular rock escarpments to climb are located near the Backbone Trail. Climbers and rappellers must register at the park office.\nBackbone State Park was dedicated in 1920. It was Iowa\'s first state park and remains one of the most significant. Backbone is named for its narrow and steep ridge of bedrock carved by a loop of the Maquoketa River. Folklore named this high ridge of rock the ""Devil\'s Backbone"". Nearly a hundred years ago, State Geologist Samuel Calvin wrote these words about ""The Backbone"":\n""Its sides are in places precipitous, the rocky cliffs rising sheer for more than 80 feet. Erosion and secular decay have carved the rocks into picturesque columns, towers, castles, battlements and flying buttresses. ""\nBackbone consists of 2,001 acres and is heavily wooded with a variety of tree species, predominantly oak and maple. This woodland serves as a valuable refuge for a variety of wildlife including deer, raccoon, fox, turkeys, ruffed grouse and many species of songbirds.\nThe Civilian Conservation Corps (CCC) was established in April, 1933 as part of the New Deal program of President Roosevelt as an effort to provide work for unemployed Americans during the Great Depression. Many of Backbone\'s buildings were constructed by the CCC from 1933 to 1941. Among the projects completed at Backbone were the dams on the Maquoketa River forming Backbone Lake, a cluster of rustic family cabins, beach and boat house, an auditorium, bridges, roads, picnic shelters, rest rooms and trails. Some of these structures are currently being restored and the effort is continuing.\nIowa Civilian Conservation Corps Museum\nThe Iowa Civilian Conservation Corps (CCC) Museum opened in 1990 and is located just within the park\'s west gate. It provides visitors with an interesting and informative look at the work of the CCC in Iowa state parks. Backbone was the site of 2 CCC camps and contains many buildings and structures built by the CCC. The museum is open Tuesday - Saturday 8:00 AM to 4:00 PM and by special arrangement through the park office.\nBackbone State Park is located 3 miles south of Strawberry Point in northwestern Delaware County. Dundee lies one mile to the south and Lamont 5 miles to the west.', '- Natural areas\n- Contact information\n- For information on State Natural Areas, contact:\n- Thomas Meyer\nNatural areas conservation biologist\nWisconsin State Natural Areas Program Cathedral Pines (No. 496)\nWithin the Chequamegon-Nicolet National Forest. Oconto County. T32N-R15E, Sections 1, 2. T33N-R15E, Sections 25, 26, 35, 36. 1,874 acres.\nCathedral Pines features one of the finest old growth pine-hemlock stands on the Chequamegon-Nicolet National Forest. The majority of this large site consists of upland mesic forest on sandy loam soils with stands generally composed of combinations of sugar maple, yellow birch, hemlock, white ash, basswood and beech. Paper birch is also a common associate, forming almost pure stands in places. Hardwoods only occasionally exceed pole and small sawlog size. Hemlock is sometimes scarce or lacking. The shrub layer is poorly developed, consisting of red elder and maple-leaved viburnum. Common groundlayer species include intermediate wood fern, club-mosses, partridgeberry, beech-drops, sedges, and tree seedlings. The highlights of the natural area are the stands of old-growth conifers dominated by hemlock, along with super-canopy red and white pines. They\'re found in the area of the Cathedral Pines hiking trail, the west-central part of the complex, the uplands bordering McCaslin Brook, and near Archibald Lake. A few rather dry areas along Archibald Lake have younger stands of red pine, sometimes with thickets of hemlock, balsam fir, and hazel beneath. A large colony of reproducing Canada yew also occurs along the lake. Several wet-mesic forest types occur in the McCaslin Brook floodplain, including red maple-black ash-elm, hemlock-white cedar, and mixed hardwoods dominated by yellow birch. Most stands are quite small due to the narrowness of the floodplain and the varying hydrological conditions. The largest white cedars in the complex are found along the creek, often extending up the steep slopes where they become mixed with hemlock and white pine. In places, ephemeral ponds and small open areas form interesting habitats for rare plants, including sweet colt\'s-foot and woodland horsetail. Numerous small kettle ponds and bogs are located in the pitted area just north of Archibald Lake. These are usually bordered by sedges and grasses and some are nearly filled with cattails and other emergent aquatics, providing good waterfowl habitat. In general, the forests here have had a relatively light management history and the present species mix appears to be similar to that of presettlement times. An active Great Blue Heron rookery is found in the red and white pines traversed by the hiking trail. Visitors should be very careful not to disturb the birds and rookery in the spring, as too much disturbance may force the herons to abandon their nests and relocate the rookery. Cathedral Pines is owned by the US Forest Service and was designated a State Natural Area in 2007.\nTo reach the Cathedral Pines hiking trail, which loops through a block of old-growth conifer forest: from the junction of State Highway 32 and County Highway F in Lakewood, go north on 32 1.0 mile to Archibald Lake Road (FR 2121); then south 1.5 miles to Cathedral Lane; then north 0.3 mile to the Cathedral Pines parking area. To explore the northeast section of the natural area: from the junction of highways 32 and F in Lakewood, go north on 32 about 2.0 miles; STH 32 forms the northeast boundary of the site for about 1.3 miles. County Highway T and Presbyterian Road provide access to the west side of the site: from Townsend, travel south on Highway T about one mile.\nCathedral Pines is owned by:\n- US Forest Service\nThe DNR\'s state natural areas program is comprised of lands owned by the state, private conservation organizations, municipalities, other governmental agencies, educational institutions and private individuals. While the majority of SNAs are open to the public, access may vary according to individual ownership policies. Public use restrictions may apply due to public safety, or to protect endangered or threatened species or unique natural features. Lands may be temporarily closed due to specific management activities. Users are encouraged to contact the landowner for more specific details.\nThe data shown on these maps have been obtained from various sources, and are of varying age, reliability, and resolution. The data may contain errors or omissions and should not be interpreted as a legal representation of legal ownership boundaries.\nVery few State Natural Areas have public facilities, but nearly all are open for a variety of recreational activities as indicated below. Generally, there are no picnic areas, restrooms, or other developments. Parking lots or designated parking areas are noted on individual SNA pages and maps. Trails, if present, are typically undesignated footpaths. If a developed trail is present, it will normally be noted on the SNA map and/or under the ""Access"" tab. A compass and topographic map or a GPS unit are useful tools for exploring larger, isolated SNAs.\nHunting and trapping\nThis is a non-DNR owned SNA: Opportunities for hunting and trapping depend on the land owner. Please contact them directly to find out about their rules for hunting and trapping. You can find a link to other owner websites under the ""Resource links"" heading above. More details regarding allowable uses of this non-DNR owned SNA may be posted, if available, under the ""Access"" tab above.\n- Horseback riding\n- Rock climbing\n- Vehicles, including bicycles, ATVs, aircraft, and snowmobiles except on trails and roadways designated for their use\n- Collecting of animals, non-edible fungi, rocks, minerals, fossils, archaeological artifacts, soil, downed wood, or any other natural material, alive or dead. Collecting for scientific research requires a permit issued by the DNR\n- Collecting of plants including seeds, roots or other non-edible parts of herbaceous plants such as wildflowers or grasses\n- Camping and campfires\nFor rules governing state-owned SNAs and other state lands, please consult Chapter NR 45 Wis. Admin. Code [exit DNR]']"	['<urn:uuid:a17a70be-370a-4f04-b72e-456b185e2129>', '<urn:uuid:904ee075-c487-4bc1-84ae-4972862fe38a>']	factoid	with-premise	verbose-and-natural	similar-to-document	comparison	novice	2025-05-13T01:50:22.828293	26	50	1985
65	How does the water flow distribution in the St. Marys River compare to that of the Niagara River connecting Lake Erie and Ontario?	The Niagara River flows at approximately 100,000 cubic feet of water per second, while in the St. Marys River, the flow is distributed differently: less than 1% goes to domestic water supply and navigation locks, less than 10% supports fish habitat in the rapids, and more than 90% on average is used for hydropower production split equally between Canada and U.S.	"['- Sign up to receive notifications on new articles\n- Sign Me Up\nA Balancing Act: Lake Superior Regulation and the St. Marys River\nIJC admin | 2014/05/21\nBy International Lake Superior Board of Control\nThe International Lake Superior Board of Control recently increased the total outflow from Lake Superior through the St. Marys River. As is typical for this time of year, the outflow is expected to continue increasing over the summer months before beginning to decline in the fall. To allow for the increase in outflow, the flow through the gated dam at the head of the St. Marys Rapids, known as the Compensating Works, also was increased.\nWhy is this necessary, and why now?\nFirst, a bit of background. Water released from Lake Superior has been regulated since the completion of the Compensating Works in 1921. The IJC established the basic objectives and limits to the regulation of Lake Superior’s outflow in its 1914 Order of Approval. It acknowledged the needs of various interests on Lake Superior and the St. Marys River, including navigation, hydropower, and riparian owners.\nSince 1978, the Commission has issued several additions to the original Order. It now specifies that the level of Lake Michigan-Huron must also be considered when determining the Lake Superior outflow.\nWhat all this means is that outflows from Lake Superior are set in consideration of various interests upstream and downstream.\nBut the ability to regulate the outflow from Lake Superior doesn’t mean that full control of lake levels is possible. This is because the major factors affecting water supply to the Great Lakes --- precipitation, evaporation, and runoff --- cannot be controlled. We know that water levels tend to rise in the spring and summer due to snowmelt and increased rain, but it’s hard to predict by how much.\nThe Lake Superior regulation plan takes all of this into account. It looks at where water levels are now, what water supplies and levels might be like in the coming months, and then tries to provide a balance in consideration of all interests and all sources of uncertainty. It’s not an easy task.\nAn aerial view showing the St. Marys River control structures. Credit: U.S. Army Corps of Engineers.\nFlashback to present\nAfter more than a decade of low water levels, recent wet conditions have resulted in Lake Superior rebounding to above-average levels not seen since 1998. Lake Michigan-Huron interests, meanwhile, also have experienced a sustained period of low levels, with the lake reaching record lows in January 2013. But it’s been wetter since then, and as a result, like Lake Superior, levels of Lake Michigan-Huron also have risen, though they still remain below average.\nAs water levels have gone up, the outflow from Lake Superior has increased. And, with Superior levels now relatively higher than Michigan-Huron’s, the regulation plan has been “nudging” flows up a bit to try to bring lake levels into balance. This balancing principle benefits both lakes, as flows can also be “nudged” down when the pendulum swings the other way, and Michigan-Huron is relatively higher than Lake Superior.\nSo what about the Compensating Works?\nThe release of water from Lake Superior each month is made through the various structures located on the St. Marys River. Less than 1 percent of the total flow is needed for domestic water supply and navigation through the locks. A minimum flow is then needed to supply and maintain fish habitat in the main rapids and through the Fishery Remedial Works channel below the Compensating Works. The amount is usually less than 10 percent of the total Lake Superior outflow.\nThe remainder and vast majority of water (more than 90 percent on average) is used for hydropower production, split equally between Canada and the U.S. However, at times the flow allocated to hydropower exceeds the capacity of the plants, in which case the excess must be released through the St. Marys Rapids by opening additional gates. Under some circumstances, the flow through the Compensating Works has made up more than 30 percent of the total Lake Superior outflow.\nThe St. Marys Rapids. Credit: U.S. Army Corps of Engineers.\nSo with water levels and flows increasing, what can be expected this summer?\nFlows and levels have been going up, and many of those who have suffered under low water level conditions for years consider this a good thing. But the International Lake Superior Board of Control recognizes that many people also are concerned about the unusually high flows and levels expected this summer, particularly in the St. Marys Rapids. As a result, the Board received authority from the IJC to adjust outflows over the next several months.\nThe Board must adjust flows in consideration of interests upstream and downstream by limiting the effects on water levels, and we can’t predict what Mother Nature has in mind. But by adjusting outflows, the Board hopes to limit adverse impacts in the St. Marys River over the next several months.', ""The Great Lakes\nThis leg of your trip is 892 miles - from the International Peace Bridge at Buffalo, N.Y. to the Chicago River Lock at Chicago, Ill.\nThe channels that connect the Great Lakes are an important part of the system. The St. Marys River is the northernmost channel, a 60-mile waterway flowing from Lake Superior down to Lake Huron. At the St. Marys rapids, the Soo Locks bypass the rough waters, providing safe transport for boaters.\nThe St. Clair and Detroit rivers, and Lake St. Clair between them, form an 89-mile long channel connecting Lake Huron with Lake Erie. The 35-mile Niagara River links lakes Erie and Ontario, and sends approximately 100,000 cubic feet of water per second over Niagara Falls.\nLake Erie: If you are cruising the Erie Canal, then Lake Erie will be the first of the Great Lakes you will cross. The average depth of Lake Erie is only 62 feet, but the western basin area averages only 24 feet. It warms quickly in summer, and freezes over quickly in winter. Lake Erie is 241 miles long. If you take the US side trip around, your likely stops will be Dunkirk, Erie, Conneaut, Cleveland, Sandusky and Toledo. I enjoy Sandusky Bay.\nThere are 24 islands in Lake Erie, nine of which belong to Canada. Among the largest and most interesting islands are Kelleys Island, home of the Glacial Grooves; South Bass Island, home to Put-in-Bay; and, Johnson's Island, home to a Civil War Cemetery. Canada's Pelee Island and the US's Middle Bass Island are also worth a visit.\nLake St. Clair: Lake St. Clair is your link from Lake Erie to Lake Huron. In comparison, it is a relatively small but it is packed with big things to do and see. The Nautical Mile is the hub of Metro Detroit's boating life and boasts the largest concentration of pleasure boats and marinas in the Midwest. Located along St. Clair shores 'the Nautical Mile' provides a number of dining and nightlife destinations along the waterfront. The Great Lakes Maritime Center at Vantage Point (GLMC) is also worth a visit. Located at the junction of the Black River and St. Clair River, the GLMC gives you a variety of opportunities to learn about the history and current events of the Great Lakes. You can also grab an ice cream, and some hand cut fries and check out the live underwater camera feed of activities below the surface along the St. Clair River. If you are into fishing, here is a good place to not only drop a line, but to learn about the hottest spots along your way.\nLake Huron: From Lake St. Clair, Lake Huron is your link to Lake Michigan. It is 206 miles long, and is 183 miles wide. Lake Huron has an average depth of 195 feet and a maximum depth of 750 feet. It is the second largest Great Lake by surface area and the fifth largest freshwater lake in the world. It has the longest shoreline of all the Great Lakes, counting the shorelines of its 30,000 islands, which includes Manitoulin Island - the largest freshwater island in the world. Georgian Bay and Saginaw Bay are the two largest bays on the Great Lakes. The Mackinac Bridge, one of the longest suspension bridges in the world connects the upper and lower peninsulas of Michigan and spans five miles over the Straits of Mackinac where Lake Michigan meets Lake Huron. You will boat directly under this bridge. FYI - at this point, you will be closer to the North Pole then you are to the Equator.\nLake Michigan: Once you pass under the Mackinac Bridge, you are on Lake Michigan. Traveling south from Milwaukee to Chicago, the western shore is lined with big city landscapes. This area, combined with the southern shores of Indiana is home to over 10 million people, and a whooping 120,000 registered boats The Lake Michigan coast is a beautiful shoreline that encompasses some of the most popular beaches on the Great Lakes. In addition, there are plenty of opportunities for adventure with sand dunes to climb, big cities to visit, pristine waters to sail, swim and explore, as well as postcard-perfect sunsets to enjoy. Plus, let's not forget about the fishing. There is a tremendous amount to see and do on Lake Michigan. Our very favorite stop on Lake Michigan is Leland (Fishtown), MI. Leland is a picturesque little village located on a sliver of land between Lake Michigan and Lake Leelanau on the Leelanau Peninsula.\nAs summertime closes on Lake Michigan, you will want to be in a position to leave Chicago and begin your voyage down the Illinois, Mississippi, and/or (if you take the Tenn-Tom route) the Ohio, Cumberland, Tennessee, and the Tennessee-Tombigbee Waterway. Your destination of course, is the Gulf of Mexico.\nCourtesy of www.captainjohn.org\nLinks to Great Loop Information radio shows on The Great Lakes (and Canada)""]"	['<urn:uuid:6c62b143-6013-4550-967b-b9a00e0732a6>', '<urn:uuid:50bd4037-29ac-4a06-9109-6c4606f39abc>']	factoid	direct	verbose-and-natural	similar-to-document	comparison	novice	2025-05-13T01:50:22.828293	23	61	1651
66	As an acoustics researcher studying resonances, I'd like to understand the relationship between resonance peaks and fundamental parameters. How do Breit-Wigner parameters compare to formant peaks in terms of their physical meaning and measurement independence?	The Breit-Wigner parameters and formant peaks share some interesting parallels in being fundamental physical measurements, though they operate in different domains. The Breit-Wigner parameters are shown to be fundamental properties of the S-matrix that are independent of the specific formalism used, contrary to previous beliefs that they were formalism-dependent. Similarly, formants represent fundamental spectral peaks that are distinct from the resonances that produce them - they are observable features of the sound spectrum that maintain their meaning across different contexts. However, while Breit-Wigner parameters have a clear mathematical relationship to pole parameters through the Breit-Wigner phase, formants can sometimes diverge significantly from their corresponding resonances, such as when multiple resonances produce a single formant peak or when a resonance exists without producing an observable formant. Both concepts represent real physical phenomena but require careful distinction from related but separate properties like pole positions (for Breit-Wigner) or tract resonances (for formants).	"['Breit-Wigner phase is a fundamental property of a resonance\nIn the course of devising a simple method for extraction of the S-matrix poles from the data, an additional fundamental resonance property emerged. It is a reaction invariant quantity, and since it is directly related to the Breit-Wigner parameters, we call it the Breit-Wigner phase . We propose that this is added in resonant data tables.\npacs:11.55.Bq, 14.20.Gk, 11.80.Gw, 14.70.Hp\nIn this year’s Review of particle physics PDG , resonances are defined by poles of the S-matrix, whether in scattering, production, or decay matrix elements. Positions of the S-matrix poles are, as stated there, independent of the process. Therefore, the poles are the fundamental physical properties of the S-matrix. As such, they are in contrast to other quantities related to resonance phenomena like Breit-Wigner parameters or K-matrix poles.\nIn the same reference two strong statements are made that succinctly summarize the current understanding of the physical properties of resonances. The first is that the Breit-Wigner parameters depend on the formalism used (angular-momentum barrier factors, cut-off parameters, and the assumed or modeled background). The other is that the accurate determination of pole parameters from the analysis of data on the real energy axis requires the implementation of the correct analytic structure of the relevant (often coupled) channels.\nIn this Letter we show that neither of the statements is entirely correct. We propose a simple few-parameter model to extract pole parameters directly from the data, without details on the analytic structure of the S-matrix, and extract the Breit-Wigner parameters independently of any formalism and knowledge of the barrier factors, cut-off parameters or background. In addition, we show that the Breit-Wigner parameters are, along with the pole parameters, the key properties of the S-matrix.\nThis result is especially important because ab initio hadronic models, such as the lattice quantum chromodynamics Dur08 and various quark models (see e.g., Ref. QM ), often use Breit-Wigner parameters. If those parameters were formalism dependent, the predictions would be unreliable.\nSome results in the literature strongly suggest that the Breit-Wigner parameters are fundamentally flawed. In Ref. Scherer the authors show that the Breit-Wigner parameters of change under a particular field transformation which leaves other physical properties, including the poles of the S-matrix, invariant. Moreover, in Ref. Sirlin a similar feature is shown for the Breit-Wigner parameters of the Z boson.\nHere we show that the definition of the Breit-Wigner parameters used in Refs. Scherer ; Sirlin was not appropriate and that the conclusion on non-physicality of those parameters is not valid. Unfortunately, that was not the last of the problems with Breit-Wigner parameters.\nThere is a lot of confusion in the literature regarding the Breit-Wigner mass. Sometimes it is mistaken by the bare mass as in Ref. Liu06 (see Ref. Cec09 ). Sometimes it is used in models where the pole mass should be used instead as in Ref. DeCruz12 (cf. the original model in Ref. DC12model ). And sometimes resonant peak positions are confused for the pole positions as was done in Ref. BES06 . That last paper led us to look into the connection of the peaks with pole and Breit-Wigner parameters. In Ref. Cec13 we have shown that the resonant peak positions are often much closer to the Breit-Wigner than to the pole masses but, generally, they are neither.\nHere we explain the interrelation between these three resonant features and show that there is a surprisingly simple relation between its Breit-Wigner mass, pole position, and the peak position.\nHowever, the biggest surprise with the proposed model is related to the K-matrix. In Ref. CecPLB08 we have analyzed a well-known unitary analytic coupled-channel approach CMB and noted that the extracted K-matrix poles are almost always similar to the Breit-Wigner masses. Moreover, each pole was at the same energy as the peak of the imaginary part and the zero of the real part of the amplitude-matrix trace. Interestingly enough, when we calculate the K-matrix using the unitarized version of the first-order non-analytic model introduced in this Letter, we obtain exactly the same features as we saw in Ref. CecPLB08 . The Breit-Wigner mass is indeed the K-matrix pole. Since the K-matrix is uniquely defined by the S-matrix, the Breit-Wigner mass is a fundamental property of the S-matrix.\nIn case that particle spins are not measured, the formula for the resonant cross section is given by\nwhere is c.m. momentum of incident particles, is the spin of the resonance, and are the spins of incident particles, and is a contribution of background processes. The key object in this relation is a resonant amplitude , generally written as\nwhere is c.m. energy, the vertex function is a real, and the self energy is a complex function of energy .\nWe get the familiar Breit-Wigner formula BW by assuming that both and are real-valued and do not change much with energy\nHere we use the standard terminology in this field: is the partial decay width, i.e., the inverse of the resonance mean lifetime that gives the rate at which a resonance decays into the observed channel. In natural units, it has the same unit as the mass . is the total decay width, i.e., the sum of all partial decay widths. This form is not suitable for broad resonances nor resonances with substantially deformed shape. It should be pointed out that, in spite of this formula’s name, the parameters and are generally not the Breit-Wigner parameters.\nThe Breit-Wigner parameters are usually obtained from a more realistic Flatté formula Flatte , where both and are assumed to be real functions with particular properties. These properties may vary and this is the reason why the extracted Breit-Wigner parameters often differ from one analysis to another, even if the same dataset is analyzed. Such a formula was used in Ref. Liu06 and produced a wrong result because in the analyzed energy region was complex.\nContrary to the aforementioned approaches, in our model we acknowledge the fact that is a complex and is a real function. Expanding them to the first order, we get a general form\nwhere again we use the standard terminology, but this time for the resonant pole parameters: mass , total decay width , residue magnitude , and residue phase . In addition, there are two real parameters: the background and its phase .\nSince is a real function, these parameters are not independent, which allows us to eliminate\nTo simplify the notation, we introduce the branching fraction and the phase difference\nPutting it all together, the amplitude in Eq. (4) becomes\nwhere the resonant phase shift is defined as\nBasically, this is an improved Breit-Wigner formula with five independent parameters: , , , , and the new parameter , which we call the Breit-Wigner phase. This new phase parameter is the difference between the amplitude’s phase at the energy equal to the pole mass and .\nIii Mass formulas\nIn Ref. Cec13 we have phenomenologically obtained a relation for , which is in full agreement with the result we get here by squaring the magnitude of Eq. (7). The peak position of , labeled here as , is given by\nWe obtain the second mass formula by analyzing the imaginary part of and noting that it has a peak at some energy, which we call , with the value\nThis formula could be very useful because due to the optical theorem, the imaginary part of the elastic amplitude is related to the total cross section . In fact, we get by replacing with in Eq. (1).\nThe third and arguably the most important mass formula is obtained by linear expansion of the numerator and denominator in Eq. (2), using the standard definition of the Breit-Wigner mass as the zero of the real part of the denominator in Eq. (2) (e.g., see Refs. Scherer ; Sirlin ; Man95 )\nThe Breit-Wigner width is then given by , which is a useful relation for consistency checking. Furthermore, note that is also the peak of and that it is given by the energy at which , the phase of , crosses .\nBefore proceeding any further we need to address the issue of the Breit-Wigner mass non-physicality pointed out by Scherer et al. in Scherer and Sirlin in Sirlin . They have shown that a quantum field transformation, which does not change observables nor pole parameters, will change the Breit-Wigner mass if it is defined as the zero of the real part of the denominator in Eq. (2). However, since the transformation changes the denominator but does not change the amplitude itself (otherwise it would change the observables as well), we can consistently redefine the Breit-Wigner mass using the whole invariant resonant amplitude, both the denominator and numerator, and it will be invariant to the transformation: the Breit-Wigner mass is the energy at which the real part of the resonant amplitude becomes zero, i.e., when its phase crosses . Thus, Eq. (11) is still valid.\nTo test the proposed mass formulas, we use them on a familiar example: the Z boson. The resonant amplitude of the Z boson is given by PDG\nAll parameters in this relation are the Breit-Wigner parameters. To test the formulas, we extract the pole parameters , , and directly from this relation. Then we use the mass formulas to reproduce the Breit-Wigner parameters.\nFirst we note that, by construction, the peak of is at the same position as the peak of . Therefore must be equal to , as is evident by comparison of Eqs. (9) and (10). In addition, since is , it will also be equal to . Finally, we calculate the Breit-Wigner parameters using Eq. (11). The agreement between the original Breit-Wigner parameters from Ref. PDG and those obtained by Eqs. (9-11) turn out to be excellent, as can be seen in Table 1.\n|BW PDG PDG||91 187.62.1||2495.22.3||N/A|\n|Pole PDG PDG||91 162||N/A||N/A|\n|Pole Eq. (12)||91 162.0||2494.0|\n|BW Eq. (11)||91 187.6||2495.1|\nIv Resonant parameters from data\nIn practice, the resonant parameters are extracted from the scattering data. Therefore, we need to test how well the proposed model fits the data and how well the extracted parameters agree with the known values. We choose because it has, like the Z boson, large and statistically significant difference between the Breit-Wigner and the pole mass (cf. Table 2).\nFirst, in Fig. (1), we show the fit of Eq. (7) to the data obtained from the total cross section for scattering using Eq. (1). The data is taken from the PDG database PDG , while the fitting strategy and background treatment are the same as in Ref. Cec13 .\nExtracted resonance parameters of are shown in Table 2. Curiously, remains the same in various reactions, similarly to fundamental resonance parameters and . Therefore, we investigate the properties of .\nV Fundamental parameter\nThe amplitude in Eq. (7) is, in fact, a matrix element of the full amplitude matrix in channel indices and . Each process from channel to channel (e.g., from to ) is described by a corresponding matrix element\nWhen the unitarity constraint is imposed on the amplitude matrix, , we immediately see that it cannot be satisfied unless all parameters are the same for all processes. Consequently, the phase must be the same in all processes due to unitarity.\nSince is invariant, we rewrite the amplitude as\nwhere is a real symmetrical matrix given by . Imposing unitarity on this form drastically simplifies it and gives us , i.e., that is a projection matrix. Since is symmetrical projection matrix, the trace of equals its rank. Therefore, we get\nConsequently, the trace of the amplitude’s real part will be zero, while the trace of the imaginary part will have a maximum at the energy equal to the Breit-Wigner mass, since equals there.\nThat is somewhat extraordinary because this result from a simple, non-analytic, single-resonance model with only a few free parameters is in perfect agreement with the result of a full-scale, analytic, unitary, coupled-channel, and mutiresonance analysis we did in Ref. CecPLB08 . There, we have noted that these peaks and zeros curiously correspond to the Breit-Wigner masses of N resonances, but also to the real poles of the K-matrix, which was all highly controversial at the time (see e.g. Ref. Arn09 ).\nIn conclusion, we propose the Breit-Wigner phase as the new fundamental resonance parameter because it is the same in all processes, directly connects the Breit-Wigner to the pole mass and width, shifts the complex phase of the resonant amplitude, and links the K-matrix poles with the Breit-Wigner masses. Therefore, we suggest that is added to resonance properties tables (perhaps instead of the Breit-Wigner mass and width).\n- (1) K. A. Olive et al. (Particle Data Group), Chin. Phys. C 38, 090001 (2014).\n- (2) S. Ceci, A. Švarc, and B. Zauner, Phys. Rev. Lett. 97, 062002 (2006), and references therein.\n- (3) S. Dürr et al., Science 322, 1224 (2008).\n- (4) S. Capstick and W. Roberts, Progress in Particle and Nuclear Physics 45, Supplement 2, S241-S331 (2000).\n- (5) D. Djukanovic, J. Gegelia, and S. Scherer, Phys. Rev. D 76, 037501 (2007).\n- (6) A. Sirlin, Phys. Rev. Lett. 67, 2127 (1991).\n- (7) B. C. Liu and B. S. Zou, Phys. Rev. Lett. 96, 042002 (2006).\n- (8) S. Ceci, A. Švarc, and B. Zauner, Phys. Rev. Lett. 102, 209101 (2009).\n- (9) L. De Cruz, T. Vrancx, P. Vancraeyveld, and J. Ryckebusch, Phys. Rev. Lett. 108, 182002 (2012).\n- (10) T. Corthals, J. Ryckebusch, and T. VanCauteren, Phys. Rev. C73 045207 (2006);\n- (11) M. Ablikim et al., (BES) Phys. Rev. Lett. 97, 062001 (2006).\n- (12) S. Ceci, M. Korolija, and B. Zauner, Phys. Rev. Lett. 111, 112004 (2013).\n- (13) S. Ceci, A. Svarc, B. Zauner, M. Manley, and S. Capstick, Phys. Lett. B659, 228 (2008).\n- (14) R. E. Cutkosky, C. P. Forsyth, R. E. Hendrick, and R. L. Kelly, Phys. Rev. D 20, 2839 (1979); M. Batinić, I. Šlaus, A. Švarc, and B. M. K. Nefkens, Phys. Rev. C 51, 2310 (1995).\n- (15) G. Breit and E. Wigner, Phys. Rev. 49, 519 (1936).\n- (16) S. M. Flatté, Phys. Lett. B63, 224 (1976).\n- (17) D. M. Manley, Phys. Rev. D 51, 4837 (1995).\n- (18) R. L. Workman, R. A. Arndt, and M. W. Paris, Phys. Rev. C 79 038201 (2009).\n- (19) SAID database, http://gwdac.phys.gwu.edu/', 'Formant is used by James Jeans (1938) to mean the collection of harmonics of a note that are augmented by a resonance.\nFormant was defined by Gunnar Fant (1960): \'The spectral peaks of the sound spectrum |P(f)| are called formants\'.\nBenade (1976) writes: \'The peaks that are observed in the spectrum envelope are called formants\'.\nIn its standards for acoustical terminology, the Acoustical Society of America (1994) defines formant thus: ""Of a complex sound, a range of frequencies in which there is an absolute or relative maximum in the sound spectrum. Unit, hertz (HZ). NOTE-The frequency at the maximum is the formant frequency.""\nDefinitions like those above are broadly used in acoustics research and industry. In parts of the speech research community, however, \'formant\' has come to have other meanings. This page discusses the different usages. A recent publication (Titze et al, 2015) discusses the history of the term and recommends consistent terminology.\nAfter defining formant, Fant (1960) then defines resonance frequencies of the vocal tract in terms of a gain function T(f) of the vocal tract: \'The frequency location of a maximum\' in |T(f)|, i.e., the resonance frequency, is very close to the corresponding maximum in spectrum P(f) of the complete sound.\' He then writes: \'Conceptually these should be held apart but in most instances resonance frequency and formant frequency may be used synonymously.\' Hence the problem: resonance and formant are indeed conceptually distinct, and their frequencies are only approximately equal. Several examples below make this clear. However, in many circumstances, the formant is the only information that one has about the resonance. For this reason, some writers in voice science voice use the terms almost interchangeably.\nThere is even a third meaning in voice research. The acoustics of the vocal tract are often modelled using a mathematical model of a filter (Atal and Hanauer, 1971). The frequencies of the poles of this filter model fall close to those of the formants. As a result, some voice researchers now refer to the frequencies of the poles as formants. So, to some voice researchers, the formant refers to a peak in the spectral envelope (a property of the sound of the voice), to others it refers to a resonance of the vocal tract (a physical property of the tract), while to a third group it refers to the pole in a mathematical filter model (a property of a model).\nIn the broader field of acoustics, formant retains only its original meaning: a broad peak in the spectral envelope of the sound (of a voice, musical instrument, room etc). When referring to the formant at about 400 Hz in the sound of the French horn, it is obviously a peak in the spectral envelope that is meant, not one of the resonances.\nThe issue is further complicated because those who use formant to mean resonance often use the term in the acoustical sense as well. For example, virtually all writers use who write about the singers formant and actors or orators formant mean the broad peaks in the spectral envelope occurring around 3 kHz.\nSome researchers who use formant to mean resonance will also talk about \'formant level\', or write that the second formant is 10 dB lower than the first. In these cases, it seems clear that they refer to the amplitude of a peak in the envelope of the sound spectrum and not to a property of the resonance that produced it.\nDoes it matter? For the voice, a resonance Ri usually gives rise to a spectral envelope maximum Fi and the process may by modelled by a filter with a pole Pi. Usually, the three have approximately equal values of frequency. However, as Fant observed, they are conceptually distinct. Let\'s take some examples:\nIn our laboratory, the distinction is important. We routinely measure the resonances independently of the voice (Epps et al, 1997; Dowd et al, 1997; Joliveau et al, 2004a,b). We are often interested in comparing formants and resonances.\n- Consider a vocal tract with a resonance at 500 Hz, which is being excited by the larynx producing a fundamental frequency of 1 kHz (roughly C6, the high C for sopranos). There is no spectral maximum at 500 Hz. In this case there is a resonance R1 but no corresponding spectral peak F1.\nHere of course the difference does matter.\n- Consider the singers formant or singing formant, a broad band of enhanced power noticed in the spectral envelope of classically trained male singers (and possible others) in a range. Sundberg (1974) attributes this formant to a clustering of the third, fourth and fifth resonances of the vocal tract. Here, where three resonances are thought to give rise to one formant, the distinction between formant and resonance is important.\n- Consider a glottal source with a negative spectral slope, input to a vocal tract that (including radiation impedance) has a resonance at R1. The peak in the spectral envelope of the radiated sound in this case has a frequency less than R1. In this case, if one is estimating the spectral peak from the harmonic spectrum of the output voice, the difference between the two is less than the precision of the estimation, so the distinction is usually not important.\n- Consider a musical wind instrument, whose bore radiates weakly below some frequency f, and which is excited by a reed or lip valve whose spectral envelope falls with frequency. Here the output sound has a spectral envelope peak that has nothing at all to do with the resonances of the bore.\n- Consider this quote*, from Stevens and House (1961): ""When resonant frequencies are sufficiently close, however, they are not necessarily identical with the frequencies of the peaks in the spectrum. For example, when two resonances with bandwidths of about 100 cps are about 100 cps apart, the spectrum envelope may show only one prominence: the frequency of the peak will be somewhere between the two resonant frequencies. In the discussion that follows, the the levels of the resonances will be defined to be the levels of the of the spectral envelope at the frequencies of the resonances (rather than at the spectral peaks).""\nWhat to do? Our preference would be to retain the original meaning for the word formant. We prefer to say ""A resonance Ri gives rise to a formant Fi. This may be modelled by a filter with a pole Pi"". While acousticians will broadly agree with this use, some members of the speech research community may not. We therefore suggest that, when discussing the voice, the word formant should be defined, to make it clear which meaning is intended. In principle, one could consider abandoning the word. However ""broad peak in the spectral envelope"" is a long phrase, and we know no other synonym, so it is useful to retain formant for that reason.\nA recent paper (Titze et al, 2015) written by Ingo Titze and with 21 other names as co-authors recommends a consistent terminology for the frequencies, magnitudes and bandwidths of harmonics, resonances and formants and draws attention to the need to explain carefully one\'s use of these terms.\nWhatever one\'s choice of definition, one should make it clear. And, in literature and in discussions, prepare for some confusion. In a scientific talk, I have heard the sentence: \'Trained sopranos tune the first formant\nnear the note sung, but they usually don\'t have a strong singer\'s formant\'. When that speaker said \'first formant\' he presumably meant \'first resonance\' and when he said \'singer\'s formant\' he meant a spectral peak probably due to two or more resonances. So we have the same person using the word in two of its three different meanings in the one sentence.\n* It\'s interesting to rewrite the quote from Stevens and House (1961), substituting \'formant\' wherever they write \'resonance\': ""When formant frequencies are sufficiently close, however, they are not necessarily identical with the frequencies of the formants. For example, when formants with bandwidths of about 100 cps are about 100 cps apart, the spectrum envelope may show only one formant: the formant will be somewhere between the two formants. In the discussion that follows, the levels of the formant will be defined to be the levels of the spectral envelope at the formant frequencies (rather than at the formant frequencies).""\n- Atal, B. S. and Hanauer, S. L. (1971) ""Speech Analysis and Synthesis by Linear Prediction of the Speech Wave"", J. Acoust. Soc. Am., 50, 637-655.\n- Benade, A. H. (1976) Fundamentals of musical acoustics, Oxford University Press, London.\n- Dowd, A., Smith, J.R. and Wolfe, J. (1997) ""Learning to pronounce vowel sounds in a foreign language using acoustic measurements of the vocal tract as feedback in real time"". Language and Speech, 41, 1-20.\n- Epps, J., Smith, J.R. and Wolfe, J. (1997) ""A novel instrument to measure acoustic resonances of the vocal tract during speech"" Measurement Science and Technology 8, 1112-1121.\n- Fant, G. (1960). Acoustic Theory of Speech Production. Mouton & Co, The Hague, Netherlands.\n- Jeans, J.H. (1938) Science & Music, reprinted by Dover, 1968. pp 104, 148.\n- Joliveau, E., Smith, J. and Wolfe, J. (2004) ""Tuning of vocal tract resonances by sopranos"", Nature, 427, 116.\n- Joliveau, E., Smith, J. and Wolfe, J. (2004) ""Vocal tract resonances in singing: the soprano voice"", J. Acoust. Soc. America, 116, 2434-2439.\n- Standards Secretariat, Acoustical Society of America, (1994). ANSI S1.1-1994 (R2004) American National Standard Acoustical Terminology, (12.41) Acoustical Society of America, Melville, NY.\n- Stevens, K.N., and House, A.S., (1961). An acoustical theory of vowel production and some of its implications, J. Speech & Hearing Research, 4, 303-320.\n- Sundberg, J. (1974) “Articulatory interpretation of the ‘singing formant’,” J. Acoust. Soc. America, 55, 838-844.\n- Titze, I.R. Baken, RJ, Bozeman, KW, Granqvist, S, Henrich, N, Herbst, CT, Howard, DM, Hunter, EJ, Kaelin, D, Kent, RD, Kreiman, J, Kob, M, Löfqvist, A, McCoy, S, Miller, DG, Noé, H, Scherer, RC, Smith, JR, Story, BH, vec, JG, Ternström, S and Wolfe, J. (2015) ""Toward a consensus on symbolic notation of harmonics, resonances, and formants in vocalization"" J. Acoust. Soc. America, 137, 3005-3007. http://dx.doi.org/10.1121/1.4919349']"	['<urn:uuid:561e9b97-7d53-4a97-817c-5197223b9399>', '<urn:uuid:167fc066-9072-4d50-a7c5-2b26d5a4039b>']	open-ended	with-premise	verbose-and-natural	distant-from-document	comparison	expert	2025-05-13T01:50:22.828293	35	150	4088
67	I've heard crowdfunding is becoming popular for both apps and property investments. How can crowdfunding help validate a business idea for an app, and how does it make property investment more accessible to regular people?	For apps, crowdfunding provides built-in validation - if people pledge real money through platforms like Kickstarter or Indiegogo, it proves there's genuine demand for the app. Additionally, backers can become early adopters and repeat customers. For property investment, crowdfunding enables smaller investments compared to direct property purchases, allowing investors to diversify their investments across multiple properties and enabling people who couldn't otherwise afford to invest in property to have a stake in the real estate market.	['If you have an idea for a mobile app, you’re probably excited to get started with it – and you should be. Globally, the mobile app market generates about $60 billion in revenue every year, which means that mobile apps present a huge opportunity for new businesses.\nBut unless your best friend is a genius coder, you’ll likely need to hire an app development company to build your new app idea for you. That’s an expensive proposition. Just how expensive? While the cost of an app can vary greatly depending on the specifics of the concept and the feature set, the “average” mobile app usually costs anywhere from $80,000 to $250,000, and larger apps can easily run up to $1,000,000 or more. On top of that, you’ll need capital to cover operational overhead, marketing and user acquisition, hiring, and all the other expenses that come with starting a business.\nAll that means that in most cases, launching an app will require you to raise capital. So how do you do that? How do you raise money to fund an app?\nThe short answer is that you raise money for an app the same way you’d raise money for any other business. You can raise development capital from friends, family, or outside investors – anyone who thinks your idea is valuable enough to generate an ROI (return on investment). Some apps raise millions of dollars in pre-development capital, while others raise significantly less. And despite the steep costs of development, it’s still possible to bootstrap an app with little to no initial capital.\nUltimately, the capital you raise depends on the specifics of your app idea, the needs of the business, and the resources you can get access to. But first, let’s talk about where you can find funding.\nHow to Find Startup Funding For Your App\nWhen most people talk about raising funding for a mobile app or a startup, they immediately jump to venture capital. That makes sense: VC investments are often talked about in the media, and because venture capitalists make some of the largest investments, they tend to be the “big fish” of the funding world. However, venture capital firms aren’t the only possible source of funding.\nWhere else can you look?\nWhile it’s less glamorous, one of the first places that most entrepreneurs look for funding is their friends and family. Unless you come from wealth, friends and family (F&F) money will usually be small-scale, initial investments made partially to seek a return on investment and partially because the investor knows and believes in you.\nThat said, just because you know the people investing doesn’t mean you don’t have to treat them like investors. Ultimately, if someone puts money into your idea, you owe them a return. Don’t take these initial investments lightly. You’ll need to present a good case for why your idea has merit, and especially at this early stage, you’ll need to stretch every dollar as far as you can. If people see that you use your investment money wisely, they’ll be more likely to invest more later on.\nWhile many are quick to dismiss it, F&F money can be a meaningful source of capital when just starting a business. Raising even a few thousand dollars can help with the initial expenses of testing and validating your idea.\nCrowdfunding Your App\nCrowdfunding is another viable option for getting funding for your app idea. Using sites like Kickstarter or Indiegogo is a proven method for raising capital, and some tech crowdfunding campaigns have raised millions of dollars to get ideas built.\nCrowdfunding is also a great idea because it’s built-in validation for your idea. If you can run a crowdfunding campaign and get a large group of people to pledge real money towards your mobile app, that means there’s a validated demand for what you’re trying to build. Not only do you raise capital, you also prove that it’s worth spending that capital to develop the app – and as an added bonus, you can cultivate your community of backers to be your early adopters and repeat customers.\nThese two methods are great because they’re accessible to anyone – but they come with their own limitations. If you’re really looking to raise capital for development with an app development agency, you’ll need professional investors. But where do you find them?\nHow to Find App Startup Investors\nIf you’re looking for app startup investors, you’re probably unsure where to even start. But you don’t need a rolodex full of VC firms to find an investor for your app.\nEven if you’re looking for institutional money, the best place to start is in your own network. Rely on the strength of weak ties here. Think back to college professors, old colleagues, or old bosses. Contact your alumni association. Who do you know that might know somebody? You’re looking for someone to give you an introduction to potential investors – an intro from a third party is one of the best ways to find an investor for your app startup.\nAnother avenue is to look for app contests. Some organizations, companies, or even startup incubators will hold pitch contests for mobile app ideas or ideas for startups in general, and the winners will often take home prizes in the form of capital. These contests are extremely competitive, so winning one will take both an excellent idea and a ton of work, but it’s possible. If you have a great concept, can prove there’s a big market for it, and can put together a convincing pitch, a contest might be a realistic way to get your foot in the door with investors.\nAs a final note, don’t keep your search for funding private. You should be loud about the fact that you’re looking for money – announce it on all your social media profiles, don’t be shy about telling people, even consider putting it in your email signature. While you don’t want to annoy people, there’s nothing wrong with making your aspirations known. It might lead to a connection that turns into an investment in your app.\nHow to Get Investors for a Mobile App\nEven if you find a potential investor, you’ll need to convince them that your app is worth putting money into – and that’s easier said than done. VC-level investors likely hear dozens of pitches a day, and even low-level investors are careful about where they invest. You’ll need to make a strong case if you want anyone to bet money on you.\nThe first step to this process is perfecting your elevator pitch. If you ever want your app to succeed, it’s critical that you can explain exactly what the app does, why people want it, and why you’ll succeed in about 30 seconds.\nWrite this pitch out on a piece of paper and practice it until it isn’t just memorized, but sounds natural. Then, give your elevator pitch to a few friends and ask them to explain the concept back to you in their own words. This is a great way to ensure that your pitch actually communicates what you intend it to.\nAssuming you can convince someone with your elevator pitch, you’ll need to craft a pitch deck to secure investment. There are dozens of articles on how to make a good pitch deck, and with a little hunting, you can find sample decks from startups that have raised funding before you – AirBnb’s pitch deck is an inspiring example.\nCritically, you need to convince investors not only that your app is a good idea, but that it is a profitable idea. Don’t rely on the strategy of attracting millions of users and figuring out how to make money off it later. You should have a clear monetization plan in place, and ideally, some signs of early traction. If you have an MVP, users, paying customers, or feedback from testers, those are all great assets to your pitch.\nIf this is all sounding like a challenge, well, it is. Raising money for an app is difficult, especially if you’re starting with just an idea. Another option is to try a Roadmapping service before trying to raise money for development. Roadmapping is a process through which you hone your idea, test it in the market, and build an MVP of the app. It costs much less than full development, and it can give you the tools to raise money once you’re ready to head into development.\nWhat are Startup Funding Rounds?\nIf you do manage to get in front of VC investors, it’s important to know how startup funding rounds are structured. While funding timelines can change from company to company, the timeline for funding generally goes like this:\n- Seed Round: This is the earliest money that goes to the company, app, or idea. Seed funding often comes from insiders and provides the initial startup capital for the business.\n- Angel Round: An angel round is similar to a seed round, but is generally more formal. Angel investors are often outside investors and will buy common stock in the company, usually with more formal terms than seed investors.\n- Series A: This is normally the first round of large-scale venture capital funding for a company. Series A rounds usually bring in $2 to $10 million and will provide capital for the business to fully develop its product and grow.\n- Series B, C, etc.: Further rounds may be held based on the capital needs of the company.\nSome companies take on millions of dollars in financing over their lifetime, while others are bootstrapped from day one. There’s no right or wrong way of approaching capital, but we think the conventional wisdom is true – the less capital you can take on, the better. If you can bootstrap your company and grow based on your own revenue, that’s always the most sustainable option whether you’re building an app startup or a biomedical company.\nHow to Get Startup Business Funding if You Have Bad Credit\nIf you’re a first-time app entrepreneur looking for capital, you may wonder how your credit will play into the matter. Is it possible to secure investors if you have bad credit?\nUltimately, this depends almost entirely on the investors you’re working with. Raising funding for a mobile app isn’t the same as a loan: it’s equally possible to have perfect credit and get rejected by investors as it is to have bad credit and secure millions in funding. Having good credit is a plus, but it’s not the most important factor.\nWhen it comes to raising capital for a business, your credit score is less important than the viability of the business idea. If an investor genuinely believes that your idea will make money and that you’re capable of executing on it, they’re likely to fund you.\nHowever, an even more powerful factor is having traction to show. If your app has users and is generating revenue, that’s the most convincing argument possible for an investor. And if you can get your business to profitability, that’s even better. As they say, the best predictor of future success is past performance. If your app is already making money, investors are much more likely to want to invest because they know your idea is profitable.\nWhat are App Angel Investors?\nIn researching how to fund your app, you’ve likely come across the term “angel investor.” But what is an angel investor for a mobile app?\nAs you might guess from the list of funding rounds, an angel investor is a company or person who invests at the angel round. These are usually outside, third-party investors – that is, not friends or family – that invest at an early stage in the development of your app and business. Angel investors may provide capital for development of the full app, or they may provide capital to help you grow the app after it’s been developed.\nWhether it’s friends and family, angel investors, or venture capital, raising funding for a mobile app is difficult – but it is possible. With a great idea and a strong pitch, you can drum up the capital to get your app developed and turn your idea into a reality.', 'As crowdfunding becomes more mainstream there is greater scrutiny from regulators. A Piece of London asks David Blair, the head of financial regulation at International law firm Osborne Clarke on what investors need to know about regulation and its impact on property crowdfunding\nHow has crowdfunding changed the landscape for investing?\nTypically, retail investment has been orchestrated through advisers and managers and there’s a lot of complexity around regulation of those managers and advisers to de-risk the investments that they permit their investors to go into. Because of the complexity of the regulatory regimes that the managers and advisers have to comply with, it increases cost to the investor of engaging those professional firms.\nWhat crowdfunding does is allow direct participation on what’s known as an execution-only basis, and that reduces the cost, because obviously, if you try to de-risk an investment, but you pay more to do so, the extra costs that you’re paying to de-risk have to be factored into the equation, and what crowdfunding has sought to do is to allow people to make their own bet, backing their own judgment, and therefore de-risking in the basis of lower cost.\nIs regulatory compliance important & what are the specific regulations for equity crowdfunding platforms?\nIt is very important, regulatory compliance. It’s not subject to the same degrees of complexity of regulation as the more traditional retail investment channels, but there is still a proportionate regulatory regime. It allows a reduction in cost but there is still something that are for investor protection. There are three main ways in which the regulations achieved. One is the promotion of the investment. Making sure that the investments are presented in a clear and transparent manner to investors. Second is making sure the investors understand what they’re going to invest in, and finally restricting the categories of investor that can invest and broadly there are three categories. One is high net worth individuals, another is sophisticated investors, and the third is investors who say that they won’t invest more than 10% of their net assets in crowdfunded investments. It’s also possible for investors to come in on an advised basis but that is not traditional crowdfunding.\nWhat role do the FCA play?\nThe FCA writes the whole book on regulation and enforces it. It supervises regulated firms. It visits them. And there’s a complaints mechanism for investors through the financial ombudsman service, and the rules that apply are as described previously. They focus on investors coming in and understanding, and also on accounting and reporting and keeping a good record.\nA Piece of London is an Appointed Representative of an authorised firm. What does that mean?\nThe authorised firm in A Piece of London’s case is Sapia Partners, it’s directly authorized for financial conduct authority and signs up to those rules and is subject to inspection by the FCA. What it does in appointing A Piece of London is effectively undertake to the FCA that it will guarantee A Piece of London’s compliance with those FCA rules as if it were directly authorized.\nHow does crowdfunding affect an individuals ability to invest in property?\nThe main feature of crowdfunding is it allows smaller investment as compared to a direct investment in property, so that, in turn, enables investors to diversify their investment. It also enables investors who wouldn’t otherwise be able to afford to invest in property to have some stake in the real estate market. The diversification allows a de-risking to a certain extent, so if you have invested in one property and there are unperceived problems that require major work or if it’s difficult to get tenants in, all your eggs are in one basket, and you have to take that risk on a one-off basis. If you invested in several properties, you can diversify that risk. What it doesn’t permit you to do is avoid general market risks like the property market losing value across the board.\nHow do you see regulation changing for property crowdfunding in the future?\nThe regulation for equity crowdfunding is based on old legislation which has been in place for many years and that is subject to evolution but I don’t think it’s going to affect crowdfunding in particular. In fact it will have minimal impact on crowdfunding. There are specific rules in place for crowdfunders that have been developed recently and there’s going to be a bedding period for those, I don’t think there’s going to be a lot of change in the near future, and that’s largely because crowdfunding is very much aligned with government policy in a number of areas. Allowing investors greater investment choice and also recently the Prime Minister has announced the intention to crack down on the proceeds of crime being invested in UK property, that’s becoming a concern, and the good thing about crowdfunding is there’s a built-in anti-money laundering process involved, so that weeds out the proceeds of crime inherently, so crowdfunding is in line with government policy.\nYour capital is at risk. Returns may be variable and the value of your investment may go down as well as up.Click here for Key Risks\nThere is no public compensation scheme covering poor investment performance.\nShare this article']	['<urn:uuid:3ffefeb1-5268-4b5b-a1fb-11b1d359f17a>', '<urn:uuid:fc40a7de-6fc2-44bc-a86e-388e27948f2b>']	factoid	with-premise	verbose-and-natural	similar-to-document	multi-aspect	novice	2025-05-13T01:50:22.828293	35	76	2914
68	desert gardens climate adaptation techniques	In semi-arid climates, gardens require specific adaptation techniques. According to Islamic design principles, plants need protection from harsh, arid environments, and water usage must be carefully managed. Modern desert landscaping solutions include replacing water-intensive grass with native plants that are naturally adapted to low-precipitation environments. Once established, these native plants require minimal maintenance and water, while still providing aesthetic value through various colors and forms, from flowering plants like Russian sage and zinnias to architectural elements like cacti.	"['Beautiful gardens bring to mind the dawn of creation when God walked through Eden in daily companionship with Adam and Eve, as described in Genesis, the first book of the Bible.\nIn Islamic tradition, the model for gardens is found in the Qur\'an, according to Texas Tech professor Safei El-Deen Hamed, who holds degrees in architecture and in landscape architecture.\nWhen he was researching Islamic gardens, Hamed said he realized that much had been written about Islamic influence on garden design, but the writers were Westerners.\nPatio de los Leones (Court of the Lions) in The Alhambra derives its name from the fountain that rests on the backs of 12 lions. The courtyard was built during the reign of Mohammed V.\n--By Sarah F. Hobson\nThey are ""sensitive to the physical, but don\'t understand the metaphysical,"" he said.\n""I think I\'m the only one who wrote about this architectural gardening from a Muslim perspective,"" he said.\nMany of those who have turned to Islamic garden design for inspiration have emphasized the ""fanciful geometric patterns, elaborate water features and colorful planting schemes at the expense of the historical, philosophical, metaphysical and poetic dimensions of these earthly paradises,"" Hamed wrote.\nIn the Qur\'an, 164 verses scattered through four chapters describe the colors, sounds, smells, spatial elements, microclimates, trees, flowers and waters of heaven, he noted.\nIn Granada, Spain, a mosque tower punctuates the sky within The Alhambra, a fortress that became the residence of Moorish kings in the 13th century.\n--By Sarah F. Hobson\nA few years ago, Hamed was asked to present a program on Islamic gardens. Soon afterward, he was contacted by the Smithsonian Institution asking him to write a chapter in a series titled ""Historical Gardens of the World.""\nIn 1995 he wrote an article titled ""Historical Gardens of the Arid Middle East"" for Arid Lands Newsletter.\nThe study he did on gardens from the Islamic perspective helped him become better acquainted with his faith history. Having lived in the United States since he was 21, he was not an expert on Islamic culture.\nBut the focus on Islamic design ""required me to explain Islamic culture. It forced me to go back and research,"" he said.\nIt became his mission to explain Islamic culture, but also to explain Americans to Muslims, he said. He wrote chapters for two books published in Egypt, ""The American Empire"" and ""The Calamity of September.""\nAnother of the many fountains found in The Alhambra, this one reflects a geometric pattern common in Islamic design.\n--By Sarah F. Hobson\nOn exhibit in the library at Tech are two books in Arabic by Hamed, published in 2002. One, published in Egypt, he co-wrote with his wife, Linda, a science teacher at South Plains Academy, on the contributions of the United States in science and technology.\n""Almost everything we use today is American-invented,"" he said, attributing the technological advantage to the openness and freedom America provides through its unique system of government.\nThe other title is ""Landscape Planning for the Arid Middle-East: An Approach to Setting Environmental Objectives,"" published by The Edwin Mellen Press.\nGrowing a garden in semi-arid West Texas is similar to the challenges of gardening in Mid-Eastern countries. That similarity in climate attracted him to Tech, where he teaches landscape architecture and architecture.\nTranquility is represented by a small pond with plantings interspersed with paths in one of the gardens of The Alhambra, which was rescued in 1870 from neglect and destruction when it was declared a national monument.\n--By Sarah F. Hobson\nHamed designed a house 25 years ago for a wealthy man who wanted to have the Islamic garden environment in South Chicago.\n""I told him the climate does not suit Islamic gardens,"" Hamed said. ""The only way we could do it was to build an enclosed garden. The home is now one of the landmarks on an architectural tour.""\nIn semi-arid climates, the first challenge in gardening is to mitigate or adapt to the harsh environment.\n""Plants need protection from harsh, arid climates,"" Hamed said.\nHow water is used is another element. The underlying Islamic philosophy is to avoid extravagance and show. In a semi-arid climate, using fountains that spray water into the air is irresponsible as is done at fountains on the Tech campus, Hamed said.\n""Water is a scarce resource,"" he said. \'To put it into the air and increase evaporation is a waste.\n""That does not mean not to use water.""\nFountains that use trickling water recycled through the fountain give the benefit of hearing running water without excess evaporation and waste. Designing the landscape to fit the climate is good stewardship.\nIn Acre, Israel, flowers and trees encircle this courtyard fountain that provides water for worshippers to wash their feet before entering the adjacent mosque for prayers.\n--By Sarah F. Hobson\n""We are not in Canada or Sweden"" where water is plentiful, Hamed reminded.\nThe famed Moorish gardens of Spain and India\'s Taj Mahal are examples of the influence of Islamic design. The gardens of The Alhambra, home of Moorish kings in what is now Granada, Spain, were built in the 13th century and the Taj Mahal in the 16th century.\nIn his journal article, Hamed quoted landscape architecture historian Norman Newton on the similarity of the monuments:\n""The two are superb expressions of a plain but powerful truth: that for over a thousand years, among peoples united in religious belief but as diverse in geography and racial origins as the Moors and the Moguls, against all the odds of time and circumstances, feast and famine, there persisted unbroken a deep-seated love of the outdoors and a delight in expressing it. ... To this end every Muslim was encouraged by the teachings of the Qur\'an and by the customs of his religious observance.""\nMiddle Eastern garden design draws from a variety of ancient sources such as Egypt, Babylon, Mesopotamia, Persia, Greece and the Roman Empire.\nTypical elements of the Islamic garden\nTrees and flowers.\nExtensive use of the arabesque (Islamic geometric decoration).\nAxial rectangular patterns of simplicity, clarity, discipline and delicacy.\nInward-looking composition for protection, privacy and modesty.\nConcepts for unity in Islamic gardens\nIslamic design evolved from a synthesis of these earlier civilizations and diverse cultures, the desert environment and the traditions and sayings of the Prophet Muhammad, Hamed explained.\nVarious interpretations exist on the philosophical and religious principles of Islamic garden design.\nThe courtyard concept provided protection for plants, privacy for the family, especially the female members, and according to one writer, the opportunity to develop the hidden qualities of the spirit. Another writer described the enclosure of the garden as a metaphor for heaven.\nThe innovative use of water as a design element at The Alhambra was copied and extended by European garden designers in the West.\n""Water played many roles within the garden design, emphasizing architectural elements, masking outdoor noise, producing pleasing sounds, irrigating plants, moisturizing and cooling the hot dry microclimate, soothing the dusty wind and providing a source for ablutions before prayers,"" Hamed wrote in his ""Paradise on Earth"" article.\nHamed would like to see West Texans more cognizant of the need to conserve water in private as well as institutional garden design.\nHe compared the Islamic garden of the Middle East to the theme and style of the Qur\'an, maintaining ""constant interplay between the real and the ideal, practicality and fantasy, the physical and the metaphysical, the tangible and the symbolic and the natural and the urban.""\nThe compositional message of the typical Islamic garden, Hamed wrote, ""is that intricacy is more pleasing if based on order; and diversity is more satisfying if it is attained through an element of unity.""\nAbove all is the concept of beauty, which according to Islam is necessity, not luxury, because the Prophet Muhammad said, ""God is beautiful and he loves beauty.""\n© 2017. All Rights Reserved. | Contact Us', 'If you live in the desert, semi-arid climate, or in a state that doesn’t get much precipitation, you might want to say goodbye to the grass and look to desert landscaping. Keeping a lawn green uses huge amounts of water, and while it might look lush, it is a waste of precious resources. A much better, and much cheaper, alternative is to use native plants in your front yard and take out the grass.\nWhen you switch over to a native landscape, you solve many of your gardening problems. You don’t have to struggle with trying to grow things that don’t belong in the environment where you live. You also won’t be wasting huge amounts of water which is going to save you money on your water bill. Native plants are easy to grow and once they are established, they require little maintenance. You won’t have to water them all the time and you can still enjoy a beautiful garden.\nDesert landscaping is more than just throwing some cacti and rocks in the yard. While you might want to incorporate some different types of cactus and rocks, you will quickly find that there are a huge amount of flowers and shrubs to choose from. Whether you want to attract bees to your garden with salvia or breathe in the fragrant aroma of lilacs, with a little planning you can design a yard that is going to be beautiful and low maintenance.\nIf your yard if full of grass, you can begin to slowly incorporate native plants into your yard. Choose a small area of your lawn to start with and dig it up. You will then want to determine your climate and start looking for plants that grow well in your climate. After you get the plants in the ground, make sure to mulch around them which will help keep down weeds and help to retain moisture.\nYou will have a huge selection of flowers and shrubs to choose from and they come in every color of the rainbow. Russian sage is a gorgeous color of blue and looks fantastic with yellow zinnias. Lavender and coneflowers make a great pairing and you can even throw in some native grasses for some height in your yard.\nAs you become more comfortable with native landscaping, you can remove more of your grass and replace it with native plants. When you have had grass for years, the idea of replacing it with drought-tolerant plants may seem like a bad idea, but if you do it right, you will have a flourishing yard that looks amazing and conserves water.\nWith water becoming more and more scarce, it just doesn’t make sense to have a lawn when you live in a climate that doesn’t have much precipitation. Doing your landscaping designed especially for the desert makes a lot of sense and it will look amazing when you do it the right way. Native plants are stronger and they need less upkeep which makes them a better landscaping choice.']"	['<urn:uuid:0106d30a-6ea5-407a-b3c4-726c728eaa73>', '<urn:uuid:c1095a5a-a518-4d2f-8f26-4322ff43a35f>']	open-ended	direct	short-search-query	similar-to-document	multi-aspect	expert	2025-05-13T01:50:22.828293	5	78	1819
69	How do memory requirements affect modeling and machine learning?	In GDM spatial modeling, comprehensive occurrence records and multiple environmental layers require significant memory resources. Similarly, in AI applications, as models grow in complexity, memory requirements surge exponentially, leading to the development of specialized technologies like High-Bandwidth Memory (HBM) for high-speed, energy-efficient data access.	['This is one of the most complex tools within the Spatial Portal. Inputs to this tool are usually a species assemblage (at a higher taxonomic level) and a suite of environmental layers. The primary outputs from GDM are the input environmental layers transformed to best-align with the spatial distribution of records from the species assemblage. See References for details on the algorithm used.\nFrom the menu option, select ‘Tools’, and then ‘GDM’.\nNote the ‘Define new area’ will involve an extra step (please refer to Add Area for additional information). In this example the state of Victoria has been pre-defined and selected from the ‘States including coastal waters’ contextual layer.\nThe modelling will use species density, so the more comprehensive and consistent the occurrence records are, the better the results will be. It is best to select taxa at the genus or higher taxonomic level to get better coverage.\nNote: For GDM to run, there must be multiple occurrences of the same taxa. If the input data contains only one record of any taxon, an error message will be generated.\nThere are many ways to select the environmental layers. You can take a quick look using the best five independent terrestrial layers (for GDM modelling the more distinct the better). You can also use any previous layer selections, search for layers, past in a set of layer names or select them individually in the list of environmental layers. If you search for layers remember that you can also search on layer keywords, for example ‘marine’ or ‘2030’.\nCells can be filtered by selecting the minimum number of taxa per cell that will be included in GDM.\nGDM can be run using equal weighting of cells or a weighting based on the number of taxa per site.\nThe time taken for GDM to run can be considerable so consider sending it to a background task. To reduce the run time, select a smaller percentage of the site-wise pairs to be used.\nThe spatial distance between species can also be accounted for in the modelling by choosing to use geographic distance as a predictor.\nThe zipped file of results are produced.\nThe above image shows all the chosen transformed layers overlaid upon each other. Obviously, each layer should be viewed independently.\nWhen the layer metadata icon icon is clicked in the layers list (on the top left) the output from GDM will be displayed showing various statistics such as the contribution of each input layer. This information can be displayed in a separate window.\nThe model output presents the response (compositional turnover) predicted by variation in each predictor. The shape of the predictor is represented by three I-splines, the values of which are defined by the environmental data distribution: min, max and median (i.e., 0, 50 and 100th percentiles). The GDM model estimates the coefficients of the I-splines for each predictor. The coefficient provides an indication of the total amount of compositional turnover correlated with each value at the 0, 50 and 100th percentiles. The sum of these coefficient values is an indicator of the relative importance of each predictor to compositional turnover.\nThe coefficients are applied to the ecological distance from the minimum percentile for a predictor. These plots of fitted functions show the sort of monotonic transformations that will take place to a predictor to render it in GDM space. The relative maximum y values (sum of coefficient values) indicate the amount of influence that each predictor makes to the total GDM prediction.\nExample Layers for Victorian Eucalyptus:\nFerrier, S. and Guisan, A. (2006). Spatial modelling of biodiversity at the community level. Journal of Applied Ecology 43, 393-404.\nFerrier, S., Manion, G., Elith, J. and Richardson, K. (2007). Using generalized dissimilarity modelling to analyse and predict patterns of beta diversity in regional biodiversity assessment. Diversity and Distributions, 13, 252-264.', 'In the ever-evolving landscape of technology, the convergence of artificial intelligence (AI) and semiconductor technologies has emerged as a groundbreaking catalyst for innovation. This synergistic relationship has redefined the capabilities of modern computing, leading to transformative advancements across industries. This article delves into the intricate interplay between AI and semiconductors, exploring how this synergy is shaping the future of technology hardware and equipment.\nSemiconductors: The Bedrock of Modern Electronics\nAt the heart of every electronic device lies the semiconductor, a material with electrical conductivity between that of a conductor and an insulator. The semiconductor industry has relentlessly pursued the miniaturization of transistors, the fundamental building blocks of electronic circuits, in accordance with Moore’s Law. However, as transistor sizes approach atomic scales, traditional manufacturing techniques encounter formidable physical limitations.\nAI’s Arrival and Semiconductor Evolution\nThe advent of AI has introduced novel challenges and opportunities for semiconductor technology. AI algorithms, particularly deep learning models, demand an unprecedented level of computational power for training and inference tasks. This requirement has prompted a departure from the traditional von Neumann architecture towards specialized hardware tailored for AI workloads.\nEnter AI Accelerators: Transforming Semiconductor Landscape\nAI accelerators are specialized hardware components designed to accelerate AI workloads by efficiently executing the complex operations fundamental to neural network computations. Graphics Processing Units (GPUs) were the first to be repurposed as AI accelerators due to their parallel processing capabilities. Subsequently, custom-designed chips like Field-Programmable Gate Arrays (FPGAs) and Application-Specific Integrated Circuits (ASICs) emerged, offering even greater efficiency and performance for AI tasks.\nCo-design: Tailoring Semiconductors for AI\nA remarkable trend is the co-design of AI algorithms and semiconductor architectures. Traditional CPUs are not optimally suited for AI tasks due to their general-purpose nature. In contrast, AI-focused hardware designs incorporate features like matrix multiplication units, which expedite the matrix operations inherent to neural networks. This co-design approach extends to memory hierarchies, where the movement of data between memory units is optimized for AI’s data-intensive operations.\nMemory Innovations: Key to AI Advancement\nMemory technologies play an instrumental role in AI applications. As AI models grow in complexity, their memory requirements surge exponentially. Cutting-edge memory technologies such as High-Bandwidth Memory (HBM) and Resistive Random-Access Memory (RRAM) offer high-speed, energy-efficient data access, pivotal for accelerating AI algorithms. The pursuit of novel memory architectures has become a focal point for semiconductor research, bolstering the AI-semiconductor synergy.\nChallenges and Future Directions\nDespite significant progress, challenges persist at the intersection of AI and semiconductor technologies. Power consumption remains a critical concern, as AI workloads demand immense computational resources. Researchers are actively exploring techniques such as approximate computing, where calculations are traded off for reduced power consumption. Furthermore, achieving optimal balance between hardware and software remains an ongoing endeavor, demanding close collaboration between AI researchers and semiconductor engineers.\nConclusion: Pioneering a New Technological Frontier\nThe fusion of AI and semiconductor technologies has ushered in a new era of computing capabilities, transcending the limits of traditional hardware. This synergy has not only accelerated AI’s impact across diverse domains like healthcare, finance, and autonomous systems but has also redefined the trajectory of semiconductor research. As AI continues to evolve, so too will the semiconductor industry, unlocking previously unthinkable innovations and shaping the future of technology as we know it.\nNote: This blog post aims to provide a technical and scientific overview of the synergy between AI and semiconductor technologies. The field is rapidly evolving, and readers are encouraged to explore further resources for the latest developments.\nAI-Specific Tools for Managing the AI-Semiconductor Synergy\nIn the intricate realm of AI and semiconductor integration, a range of specialized tools has emerged to effectively manage and harness the power of this synergistic relationship. These tools address various challenges associated with AI algorithm development, hardware acceleration, and co-design. Let’s delve into some key AI-specific tools that are shaping the landscape of AI-semiconductor integration.\nTensorFlow and PyTorch: Frameworks for AI Development\nTensorFlow and PyTorch stand as cornerstones in the development of AI algorithms. These deep learning frameworks provide a high-level abstraction for designing, training, and deploying neural networks. TensorFlow’s Graph and PyTorch’s dynamic computation graph empower researchers and engineers to experiment with intricate network architectures effortlessly.\nONNX: Open Neural Network Exchange\nThe Open Neural Network Exchange (ONNX) format facilitates interoperability between different AI frameworks. As AI algorithms evolve, models trained on one framework can be seamlessly transferred to another, simplifying the integration of AI models with various hardware accelerators. ONNX’s ability to represent complex neural network architectures in a standardized format streamlines the co-design process with semiconductor hardware.\nIntel’s OpenVINO and NVIDIA’s TensorRT: AI Inference Optimization\nIntel’s OpenVINO (Open Visual Inference and Neural Network Optimization) and NVIDIA’s TensorRT are tools designed to optimize AI inference for specific hardware targets. These tools employ various techniques, such as model quantization, pruning, and layer fusion, to reduce the computational and memory requirements of AI models while preserving accuracy. By tailoring AI models for efficient execution on specific hardware, these tools enhance real-time AI inference performance.\nVivado HLS and SDAccel: FPGA Development Tools\nFPGAs (Field-Programmable Gate Arrays) have gained prominence as versatile platforms for accelerating AI workloads. Tools like Vivado HLS (High-Level Synthesis) and SDAccel offer high-level abstractions to program FPGAs for AI applications. These tools enable developers to write AI algorithms in higher-level languages like C++ or OpenCL, which are then automatically transformed into hardware descriptions, making FPGA acceleration more accessible.\nNVIDIA CUDA and cuDNN: GPU Acceleration\nNVIDIA’s CUDA (Compute Unified Device Architecture) and cuDNN (CUDA Deep Neural Network Library) provide a comprehensive ecosystem for GPU acceleration of AI workloads. CUDA allows developers to leverage GPU parallelism for general-purpose computations, while cuDNN offers optimized GPU primitives tailored for deep learning operations. This synergy has contributed significantly to the growth of deep learning and AI research.\nCompiler and Hardware-Aware Optimization Tools\nA critical aspect of AI-semiconductor integration is compiler and optimization tools designed to translate high-level AI code into efficient machine code for specific hardware architectures. These tools often incorporate hardware-aware optimization techniques, including loop tiling, instruction scheduling, and memory access optimization, ensuring that AI algorithms make the most of the underlying semiconductor hardware.\nConclusion: Enabling Seamless AI-Semiconductor Integration\nAs the relationship between AI and semiconductor technologies deepens, specialized tools are essential for realizing the full potential of this synergy. These tools empower researchers, engineers, and developers to navigate the complexities of AI algorithm development, hardware acceleration, and co-design. With the continuous evolution of both AI and semiconductor landscapes, these tools will play a pivotal role in shaping the future of technology, propelling us into a new era of innovation.\nPlease note that the mentioned tools and technologies are accurate as of my last knowledge update in September 2021. There might have been further developments or new tools introduced since then.']	['<urn:uuid:4a7e559c-9507-442c-bafa-292d9d8ea7ad>', '<urn:uuid:8efd42f6-107a-42a7-a937-a905b750410d>']	factoid	direct	concise-and-natural	distant-from-document	multi-aspect	expert	2025-05-13T01:50:22.828293	9	44	1762
70	psychiatric medicine heart symptoms dangers	These medications can cause serious heart-related side effects. Patients may experience QT prolongation (irregular heartbeats), fast heartbeat, and low blood pressure when lying down. Urgent medical attention is needed for severe symptoms like very fast heartbeat, pounding or irregular rhythm, chest pain, or fainting.	"[""|Generic name||Brand name|\nWhat are behavior regulators?\nBehavior regulators are used to treat many health conditions linked to one's mental state. They can benefit people who have schizophrenia (a very altered sense of reality), mania (extreme, rapid mood changes), or severe depression (sadness). These medicines are also called neuroleptics, tranquilizers, psychotropics, or antipsychotics.\nThey may also be used for other conditions.\nHow should I give it?\nYour child should take this medicine exactly as prescribed, even if feeling fine.\nGive it at regular times to keep a steady level in the bloodstream. If using this medicine once a day, it may be given at bedtime to help avoid tiredness during the day.\nTo help avoid some of the side effects (see below), the dose may need to be increased slowly.\nMost of these medicines come in tablet form. Some are also available in liquid form.\n___ For children who cannot swallow pills:\n- If it is a tablet, crush it between 2 spoons, inside a plastic bag, or in folded paper.\n• If it is a capsule, open it.\n- Mix the powder with a very small amount (about 1 teaspoon) of soft food, such as applesauce, chocolate syrup, ice cream, jelly, or yogurt. Make sure your child takes all of the mixture.\n___ If using a liquid medicine, shake well right before using. Draw up the correct amount in the medicine dropper or oral syringe. Give a small squirt of the medicine inside the child's cheek. To avoid choking, let your child swallow each squirt before giving more.\nAre there any precautions about food or other medicines?\nGive this medicine with food to help avoid an upset stomach.\nWarning: Certain other medicines interact with behavior regulators. Check with the doctor, nurse practitioner, or pharmacist before giving any other prescription or non-prescription medicines, vitamins, or herbs.\nAvoid alcohol-containing foods, beverages, or non-prescription medicines (such as cough syrup) while taking this medicine.\nWhat should I do if a dose is missed?\nIf a dose is missed, give it as soon as you remember, unless it is less than 8 hours until the next dose. In that case, skip the missed dose and continue with the regular schedule. Never give a double dose.\nIf your child vomits (throws up) a dose, do not repeat the dose. Call the clinic if you have questions about what to do.\nWhat are the side effects?\n- lightheadedness, dizziness\n- tiredness or weakness\n- nausea (upset stomach)\n- swelling or pain in breasts\n- dry mouth\n- trouble sleeping\n- sun sensitivity\n- change in sense of taste\n- weight gain\n- low blood pressure when lying down\n- fast heartbeat\n- jerky movements of hands and feet\n- low muscle tone\nThe person taking this medicine should not drive, operate machinery, or do anything else that could be dangerous until his or her reaction to this medicine is known. These medicines may impair physical coordination at first until the body adjusts.\nIf your child has other side effects that you think may be due to this medicine, call your clinic or pharmacist.\nWhen should I call the clinic?\n- severe fidgeting or shakiness\n- very fast heartbeat, pounding or irregular rhythm\n- chest pain\n- seizures (convulsions: severe jerking, twitching, or stiffening of muscles)\n- fainting (passing out)\n- shortness of breath, or trouble speaking or swallowing\n- signs of allergic reaction:\n- fever or chills\n- rash or hives\n- trouble breathing - call 911\nWhat else do I need to know?\nThis medicine can take up to 4 weeks to reach its maximum effect, and for your child to have its full benefits.\nCheck with your doctor before stopping this medicine. The dose is usually lowered little by little over time.\nYou may be asked to bring your child to the clinic to have vital signs (pulse, blood pressure) checked, and to have blood tests. The dose may be adjusted based on your child's behavior and on the results of the blood tests.\nTo prevent sunburn use sunscreen, a hat, and protective clothing when outdoors.\nYou and your child should know the names of all the medicines he or she is taking. Share this information with anyone involved in your child's care. Please bring the medicine container when your child comes to the clinic or emergency department.\nAlways make sure you have enough medicine on hand. Each time you refill the prescription, check to see how many refills are left. If no refills are left, the pharmacy will need 2 or 3 days to contact the clinic to renew the prescription.\nBefore giving the first dose, read the label. Be sure it is what was prescribed. After a refill, if the medicine looks different to you, ask your pharmacist about it before giving it.\nCheck the label for the expiration date. Flush outdated medicines down the toilet instead of putting them in the garbage.\nStore all medicines in their original container and away from direct sunlight or heat. Do not store in humid places such as the bathroom. Keep them out of children's reach, locked up if possible.\nIf too much or the wrong kind of medicine is taken, call the Poison Control Center toll-free at 1-800-222-1222. If your child is unconscious or has a seizure, call 911.\nThis is not specific to your child but provides general information. If you have any questions, please call the clinic or pharmacy.\nChildren's Hospitals and Clinics of Minnesota\nLast reviewed 8/2015\nThis page is not specific to your child, but provides general information on the topic above. If you have any questions, please call your clinic. For more reading material about this and other health topics, please call or visit Children's Family Resource Center library, or visit www.childrensmn.org/educationmaterials.\n© 2017 Children's Hospitals and Clinics of Minnesota"", 'Fanapt treats schizophrenia. Fanapt dosage will be increased daily to avoid orthostatic hypotension (low blood pressure that happens when you stand up from sitting or lying down).\nFanapt is a prescription medication used to treat schizophrenia. Fanapt belongs to a group of drugs called antipsychotics. These work by altering the activity of certain natural substances in the brain.\nThis medication comes in tablet form and is taken twice a day, with or without food.\nCommon side effects include dry mouth, fatigue, and dizziness. Do not drive or operate heavy machinery until you know how Fanapt affects you.\nPatient Ratings for Fanapt\nHow was your experience with Fanapt?\nFanapt Cautionary Labels\nUses of Fanapt\nFanapt is a prescription medication used to treat schizophrenia.\nThis medication may be prescribed for other uses. Ask your doctor or pharmacist for more information.\nFanapt Drug Class\nFanapt is part of the drug class:\nSide Effects of Fanapt\nCommon side effects include:\n- dry mouth\n- nasal congestion\n- a fast heart beat\n- low blood pressure\n- weight increase\nThis is not a complete list of Fanapt side effects. Ask your doctor or pharmacist for more information.\nTell your doctor if you have any side effect that bothers you or that does not go away.\nCall your doctor for medical advice about side effects. You may report side effects to the FDA at 1-800-FDA-1088.\nTell your doctor about all the medicines you take, including prescription and non-prescription medicines, vitamins, and herbal supplements. Especially tell your doctor if you take:\n- medications that block a protein in the body (CYP2D6) such as quinidine, fluoxetine (Prozac, Sarafem), amitriptyline (Elavil, Amitril), and paroxetine (Paxil)\n- medications that block a protein in the body (CYPA4) such as some macrolide antibiotics (clarithromycin, telithromycin), some HIV protease inhibitors (indinavir, nelfinavir, ritonavir, saquinavir), some HCV protease inhibitors (boceprevir, telaprevir), some azole antifungals (ketoconazole, itraconazole, posaconazole, voriconazole), conivaptan (Vaprisol), delavirdine (Rescriptor), and nefazodone\n- medications that can prolong the QT Interval such as quinidine, procainamide, amiodarone (Nexterone, Pacerone, Cordarone), sotalol (Betapace), chlorpromazine, thioridazine, gatifloxacin (Zymar), moxifloxacin (Avelox)\nThis is not a complete list of Fanapt drug interactions. Ask your doctor or pharmacist for more information.\nSerious side effects have been reported with Fanapt including the following:\n- QT Prolongation. This is a condition when changes in the electrical activity of your heart occur, causing irregular heartbeats that can be life threatening. Talk to your healthcare provider about other medicines you are taking before you start taking Fanapt. Tell your healthcare provider right away if you have any signs or symptoms of QT prolongation:\n- feeling faint\n- feeling like your heart is beating irregularly or quickly\n- Neuroleptic Malignant Syndrome (NMS). Neuroleptic Malignant Syndrome (NMS) is a rare and potentially fatal side effect reported with Fanapt and similar medicines. Call your doctor immediately if the person being treated develops symptoms such as high fever; stiff muscles; shaking; confusion; sweating; changes in pulse, heart rate, or blood pressure; or muscle pain and weakness. Treatment should be stopped if the person being treated has NMS.\n- Tardive Dyskinesia (TD). Tardive Dyskinesia (TD) is a serious, sometimes permanent side effect reported with Fanapt and similar medications. TD includes uncontrollable movements of the face, tongue, and other parts of the body. The risk of developing TD and the chance that it will become permanent is thought to increase with the length of therapy and the overall dose taken by the patient. This condition can develop after a brief period of therapy at low doses, although this is much less common. There is no known treatment for TD, but it may go away partially or completely if therapy is stopped.\n- High blood sugar and diabetes. High blood sugar and diabetes have been reported with Fanapt and similar medications. If the person being treated has diabetes or risk factors such as being overweight or a family history of diabetes, blood sugar testing should be performed at the beginning and throughout treatment with Fanapt. Complications of diabetes can be serious and even life-threatening. If signs of high blood sugar or diabetes develop, such as being thirsty all the time, going to the bathroom a lot, or feeling weak or hungry, contact your doctor.\n- Weight gain.\n- Seizures. Fanapt should be used cautiously in people with a seizure disorder, who have had seizures in the past, or who have conditions that increase their risk for seizures.\n- Orthostatic Hypotension and Syncope. Some people taking Fanapt may feel faint or lightheaded when they stand up or sit up too quickly. This is more common when you first start taking Fanapt or when your dose is increased. To avoid this problem, get out of bed slowly, resting your feet on the floor for a few minutes before standing up. By standing up or sitting up slowly and following your healthcare professional’s dosing instructions, this side effect can be reduced or it may go away over time.\n- Low blood counts. Blood problems such as low numbers of white blood cells have been reported in patients taking Fanapt and similar medications. In some cases, it has been serious and life-threatening. Depending upon your medical condition, your doctor may choose to test your blood as you start therapy with Fanapt.\n- Hyperprolactinemia. Fanapt and similar medications can raise the blood levels of a hormone known as prolactin, causing a condition known as hyperprolactinemia. Blood levels of prolactin remain elevated with continued use. Some side effects seen with these medications include the absence of a menstrual period; breasts producing milk; the development of breasts by males; and the inability to achieve an erection.\n- Body Temperature Regulation. Fanapt may make you more sensitive to heat. You may have trouble cooling off, or be more likely to become dehydrated, so take care when exercising or when doing things that make you warm. Tell your doctor if you plan to do vigorous exercise or be exposed to extreme heat.\n- Dysphagia. Tell your doctor if you have trouble swallowing.\n- Suicide. Call your doctor right away if you have any of the following symptoms, or call 911 if an emergency, especially if they are new, worse, or worry you:\n- attempts to commit suicide\n- acting on dangerous impulses\n- acting aggressive or violent\n- thoughts about suicide or dying\n- new or worse depression\n- new or worse anxiety or panic attacks\n- feeling agitated, restless, angry or irritable\n- trouble sleeping\n- an increase in activity or talking more than what is normal for you\n- other unusual changes in behavior or mood\n- Painful, long-lasting erections. Painful, long-lasting erections have been reported with the use of Fanapt. Call your doctor immediately if you think you are having this problem.\n- Cognitive and Motor Impairment. Fanapt may affect your thinking, judgment, and ability to move. Do not drive a car or operate machinery until you know how this medication affects you.\nAsk your doctor about the safe use of alcoholic beverages while you are taking Fanapt. Alcohol can make the side effects from Fanapt worse.\nFanapt can cause dizziness. Do not drive or operate heavy machinery until you know how Fanapt affects you.\nFanapt is not approved by the Food and Drug Administration (FDA) for the treatment of behavior problems in older adults with dementia. Talk to the doctor who prescribed this medication if you, a family member, or someone you care for has dementia and is taking Fanapt.\nDo not take Fanapt if you are allergic to Fanapt or to any of its ingredients.\nFanapt Food Interactions\nGrapefruit and grapefruit juice may interact with Fanapt and lead to potentially dangerous effects. Discuss the use of grapefruit products with your doctor.\nBefore taking Fanapt, tell your doctor about all of your medical conditions. Especially tell your doctor if you:\n- are allergic to Fanapt or to any of its ingredients\n- use or have ever used street drugs or have overused prescription medications\n- if you have difficulty swallowing\n- or anyone in your family has or has ever had diabetes\n- have or have ever had prolonged QT interval (a rare heart problem that may cause irregular heartbeat, fainting, or sudden death), a slow or irregular heartbeat, a recent heart attack, a low level of potassium or magnesium in your blood, seizures, breast cancer, or heart or liver disease\n- have a low level of white blood cells or if you have ever developed a low level of blood cells as a side effect of a medication that you took\n- have severe vomiting or diarrhea or become dehydrated at any time during your treatment\n- tell your doctor if you are pregnant, especially if you are in the last few months of your pregnancy, or if you plan to become pregnant or are breast-feeding. If you become pregnant while taking Fanapt, call your doctor. Fanapt may cause problems in newborns following delivery if it is taken during the last months of pregnancy.\nTell your doctor about all the medicines you take including prescription and non-prescription medicines, vitamins, and herbal supplements.\nFanapt and Pregnancy\nTell your doctor if you are pregnant or plan to become pregnant.\nThe FDA categorizes medications based on safety for use during pregnancy. Five categories - A, B, C, D, and X, are used to classify the possible risks to an unborn baby when a medication is taken during pregnancy.\nFanapt falls into category C. In animal studies, pregnant animals were given this medication and had some babies born with problems. No well-controlled studies have been done in humans. Therefore, this medication may be used if the potential benefits to the mother outweigh the potential risks to the unborn child.\nFanapt and Lactation\nTell your doctor if you are breastfeeding or plan to breastfeed.\nIt is not known if Fanapt crosses into human milk. Because many medications can cross into human milk and because of the possibility for serious adverse reactions in nursing infants with use of this medication, a choice should be made whether to stop nursing or stop the use of this medication. Your doctor and you will decide if the benefits outweigh the risk of using Fanapt.\nIt is recommended that women receiving Fanapt should not breast feed.\nTake Fanapt exactly as prescribed.\nFanapt comes in tablet form and is taken twice a day, with or without food.\nIf you miss a dose, take the missed dose as soon as you remember. If it is almost time for the next dose, skip the missed dose and take your next dose at the regular time. Do not take two doses of Fanapt at the same time.\nTake this medication exactly as prescribed by your doctor. Follow the directions on your prescription label carefully.\nThe dose your doctor recommends may be based on the following:\n- the condition being treated\n- other medical conditions you have\n- other medications you are taking\n- how you respond to this medication\n- if you are a poor metabolism of CYP2D6\nThe recommended dose range of iloperidone (Fanapt) is 12 to 24 mg/day administered twice daily.\nThis target dosage range is achieved by daily dosage adjustments, starting at a dose of 1 mg twice daily, then moving to 2 mg, 4 mg, 6 mg, 8 mg, 10 mg, and 12 mg twice daily on days 2, 3, 4, 5, 6, and 7 respectively.\nIf you take too much Fanapt, call your healthcare provider or local Poison Control Center, or seek emergency medical attention right away.\n- Store Fanapt at room temperature 25°C (77°F).\n- Protect Fanapt tablets from exposure to light and moisture.\n- Keep this and all medicines out of the reach of children.\nFanapt FDA Warning\nElderly patients with dementia-related psychosis treated with antipsychotic drugs are at an increased risk of death. Fanapt is not approved for use in patients with dementia-related psychosis.']"	['<urn:uuid:f6ae0f06-4418-4187-a174-66cd6830c346>', '<urn:uuid:f109a807-e3cf-40be-86c0-52f6cc3196b9>']	factoid	with-premise	short-search-query	distant-from-document	multi-aspect	expert	2025-05-13T01:50:22.828293	5	44	2955
71	dry ice shipping regulations safety considerations	Dry ice is classified as a Class 9 Dangerous Good requiring proper labeling with 'Dry Ice' or 'Carbon dioxide, solid' (UN1845). When shipping, packages must permit carbon dioxide gas release to prevent pressure buildup. Several safety considerations are crucial: use high-quality insulated containers (durable polystyrene works best), expect 3-8% sublimation loss per 24 hours, place items close together with packing materials to minimize dead air space, and handle with gloves to prevent frostbite. Never store in unventilated areas or completely airtight containers due to explosion risk from CO2 expansion.	"['SHIPMENT OF BIOLOGICAL MATERIALS\nThe Department of Transportation (DOT), the United States Postal Service (USPS), the Centers for Disease Control (CDC), and the International Air Transport Association (IATA) all have requirements for shipping hazardous materials (Dangerous Goods). Biological materials and infectious substances are one of several types of dangerous goods that may be offered for shipment. All hazardous materials are required to be classified, packaged, labeled and documented properly prior to shipment.\nTherefore, all USciences personnel who need to ship biological materials, hazardous materials, or materials on dry ice must contact the Department of Environmental Health and Radiation Safety (EHRS) to help package and prepare the paperwork. Anyone wishing to ship materials on their own or who is shipping frequently (i.e., once a month or more) must first receive the required training and certification.\nInfectious Substances are substances which are known or are reasonably expected to contain pathogens. Pathogens are defined as microorganisms (including bacteria, viruses, rickettsiae, parasites, fungi) or recombinant microorganisms (hybrid or mutant) and other agents such as prions, which can cause disease in humans and animals.\nInfectious substances are assigned to UN classes based on the following definitions:\nBiological Products including an experimental or investigational product are those products derived from living organisms and manufactured for use in the prevention, diagnosis, treatment or cure of diseases in humans or animals and are certified by the USDA, FDA, or other national authority. They include, but are not limited to, finished or unfinished products such as vaccines, diagnostic products, therapeutic serums, toxins and antitoxins.\nBiological products that are manufactured and packaged in accordance with the requirements of appropriate national authorities and transported for the purposes of final packaging or distribution, and use for personal health care by medical professionals or individuals, are not subject to shipping regulations. [Follow the Exempt Packing Instructions]\nGenetically Modified Microorganisms and Organisms are organisms or microorganisms which have been purposely altered through genetic engineering in a way that does not occur naturally. Pathogenic GMOs must be classified as either Category A (Packing Instruction 602) or Category B (Packing Instruction 650) infectious substances and shipped accordingly.\nNon-pathogenic GMOs that are capable of altering animals, plants, or microbiological substances in a way which is not normally the result of natural reproduction are considered Class 9 Miscellaneous Dangerous Goods and assigned to UN3245. They have the proper shipping names, ""genetically modified organisms"" or ""genetically modified microorganisms"". [Follow Packing Instruction 913]\nPatient Specimens are those collected directly from humans or animals, including but not limited to excreta, secreta, blood and its components, tissue and tissue fluid swabs, and body parts being transported for purposes such as research, diagnosis, investigational activities, disease treatment and prevention.\nIf there is more than a ""minimal likelihood"" that a patient specimen contains pathogens, it must be shipped as a Category A infectious substance (UN2814 or UN2900), or a Category B infectious substance (UN3373).\nPatient specimens unlikely to contain pathogens must be prepared for shipment by following the exempt packing instructions. [Follow the Exempt Packing Instructions]\nCultures are the result of a process by which pathogens are intentionally propagated. This definition does not include patient specimens as defined above. Cultures of infectious substances will either be Category A or Category B.\nDry Ice is a Class 9 Dangerous Good. Packages containing dry ice must be labeled with the proper shipping name, ""Dry Ice"" or ""Carbon dioxide, solid"" and is assigned UN1845. A Shipper\'s Declaration Form is only required when the dry ice is used as a refrigerant for dangerous goods that require a Shippers Declaration. [Follow Packing Instruction 904] Special packaging and arrangements must be made with the carrier for packages containing liquid nitrogen.\nDry Ice must be packaged to permit the release of carbon dioxide gas and to prevent a build-up of pressure that could rupture the packaging.\nInformation on shipping radioactive materials.\n|University of the Sciences in Philadelphia 600 South Forty-third Street Philadelphia, PA 19104-4495 phone: 215-596-8800 email: email@example.com|', 'Dry ice is made by taking pressurized Liquid CO2 (LCO2) and allowing it to expand into the natural atmosphere. This causes the LCO2 to expand into both a gas vapor and solid snow. The snow is then either compressed to form blocks or compressed and extruded to form pellets or nuggets. The equipment required to make the dry ice includes a Liquid CO2 tank and a Pelletizer or Block maker.\nThe production process is comprised of the following items:\n- LCO2 Vessel:\n- Insulated Lines, LCO2 Filter, & Pressure Regulators:\n- Production Unit (Pelletizer, Press, Reformer):\n- Vapor CO2 Exhaust/ Reclaim:\n- Packaging/Storage Tote:\nHorizontal or vertical storage vessel (30 to 60 tons) installed close to the production unit but external to production area\n“K” copper line, rated at 600 psi (40 bar) and wrapped in 2″ to 4″ of insulation, connect storage vessel to the production unit\nLCO2 is injected into chambers inside the production machines; creates pressure and LCO2 expands; ~2.3 to 2.5 lbs of liquid CO2 are flashed to make 1 lb of dry ice\nCO2 snow is then compressed, extruded or remolded into a form (pellet, nugget, slab or block) to suit end-user/ industry requirements\nEscaping vapor CO2 can be vented outside of production area or reclaimed, compressed, and liquefied back into LCO2\nTo minimize sublimation loss, dry ice is packed into insulated totes for shipment or immediate use.\nDue to its low temperature of -78°C (-109°F), dry ice is utilized in all sorts of industries as a cooling medium. It can be used or supplied as snow, pellets, nuggets, slabs, or blocks to suit industry and production needs. Cooling products or parts during the shipping process is a common application for dry ice.\nThere are several key considerations to keep in mind when shipping dry ice:\n1: Different needs and applications call for different types of dry ice\n- Dry ice pellets and nuggets are typically used for smaller packages and shorter distances\n- Dry ice slabs work great for airline catering – fit cart and have slow sublimation rate\n2: High quality insulated containers are needed to reduce sublimation and keep products safe\n- Durable polystyrene containers work the best\n- Styrofoam coolers break easily and are therefore not good insulators\n3: Plan on losing 3% – 8% of dry ice due to sublimation every 24-hour period due to sublimation\n- The rate of sublimation depends on type of dry ice, outside temperature, air pressure, and quality of packaging\n4: When packing dry ice with products in a container, place the two items as close together as possible, filling empty space with wadded newspaper or other packing materials\n- Dead-air-space will cause the dry ice to sublimate faster.\n- Dry ice is extremely cold and should never be touched by bare skin (may cause frostbite)\n- Use gloves or a towel when handling dry ice to minimize skin exposure\n- Store dry ice in an insulated container to minimize sublimation (thicker, better insulation = less sublimation)\n- Do not store in unventilated areas; the dry ice sublimates into large quantities of CO2 gas, which displaces oxygen and increases the danger of asphyxiation\n- Do not store dry ice in a completely airtight container; the container may explode due to sublimation and CO2 expansion\n- Do not store in a freezer – the coldness of the dry ice will shut off the thermostat and freezer\n- Use dry ice in a well-ventilated area to prevent the build-up of toxic CO2 levels']"	['<urn:uuid:f008c287-c255-42b8-a943-958699e3b36e>', '<urn:uuid:9ea14999-07ef-4275-9866-d8048872e5bd>']	open-ended	with-premise	short-search-query	similar-to-document	multi-aspect	novice	2025-05-13T01:50:22.828293	6	89	1243
72	medical researcher here transmission routes salmonella contamination prevention strategies food handling	Salmonella transmission occurs primarily through eating foods contaminated with animal feces. Prevention strategies include: washing hands for 20 seconds with warm soapy water before and after food handling; separating raw meat, poultry, and seafood from other foods; cooking foods to safe minimum internal temperatures (165°F for poultry, 160°F for ground meats, 145°F for whole cuts); and promptly refrigerating foods at 40°F or below. The bacteria can also spread through contact with infected animals, especially reptiles, and their feces.	"['Salmonella Questions and Answers\n- What is Salmonella?\n- What is salmonellosis?\n- What are the symptoms of salmonellosis?\n- Are there long-term consequences?\n- How do people get salmonellosis?\n- What foods are most likely to make people sick?\n- Are chickens labeled ""Kosher,"" ""free-range,"" ""organic,"" or ""natural"" lower in Salmonella bacteria?\n- What is FSIS doing to prevent Salmonella contamination?\n- How can consumers prevent salmonellosis?\nSalmonella bacteria are the most frequently reported cause of foodborne illness. In order to reduce salmonellosis, a comprehensive farm-to-table approach to food safety is necessary. Farmers, industry, food inspectors, retailers, food service workers, and consumers are each critical links in the food safety chain. This document answers common questions about the bacteria Salmonella, describes how the Food Safety and Inspection Service (FSIS) of the U.S. Department of Agriculture (USDA) is addressing the problems of Salmonella contamination on meat and poultry products, and offers guidelines for safe food handling to prevent bacteria, such as Salmonella, from causing illness.\nQ. What is Salmonella?\nA. Salmonella is a gram-negative, rod-shaped bacilli that can cause diarrheal illness in humans. They are microscopic living creatures that pass from the feces of people or animals to other people or other animals.\nThe Salmonella family includes over 2,300 serotypes of bacteria which are one-celled organisms too small to be seen without a microscope. Two serotypes, Salmonella Enteritidis and Salmonella Typhimurium are the most common in the United States and account for half of all human infections. Strains that cause no symptoms in animals can make people sick, and vice versa. If present in food, it does not usually affect the taste, smell, or appearance of the food. The bacteria live in the intestinal tracts of infected animals and humans.\nSalmonella bacteria have been known to cause illness for over 100 years. They were discovered by an American scientist, Dr. Daniel E. Salmon.\n[Top of Page]\nQ. What is salmonellosis?\nA. Salmonellosis is an infection caused by the bacteria Salmonella. According to the Centers for Disease Control and Prevention (CDC), salmonellosis causes an estimated 1.4 million cases of foodborne illness and more than 400 deaths annually in the United States. The Surveillance Report from the Food Diseases Active Surveillance (FoodNet) for 2007, identified Salmonella as the most common bacterial infection reported.\nFoodNet is a collaborative project among CDC, the 10 Emerging Infections Program sites (EPIs), USDA, and the U.S. Food and Drug Administration (FDA). One of the objectives of FoodNet is to measure effectiveness of a variety of preventive measures in reducing the incidence of foodborne illness attributable to the consumption of meat, poultry, and other foods.\n[Top of Page]\nQ. What are the symptoms of salmonellosis?\nA. Although in some people salmonellosis could asymptomatic, most people experience diarrhea, abdominal cramps, and fever within 8 to 72 hours after the contaminated food was eaten. Additional symptoms may be chills, headache, nausea, and vomiting. Symptoms usually disappear within 4 to 7 days. Many people with salmonellosis recover without treatment and may never see a doctor. However, Salmonella infections can be life-threatening especially for infants and young children, pregnant women and their unborn babies, and older adults, who are at a higher risk for foodborne illness, as are people with weakened immune systems (such as those with HIV/AIDS, cancer, diabetes, kidney disease, and transplant patients).\n[Top of Page]\nQ. Are there long-term consequences?\nA. Persons with diarrhea usually recover completely, although it may be several months before their bowel habits are entirely normal. A small number of persons who are infected with Salmonella may develop pains in their joints, irritation of the eyes, and painful urination. This is called Reiter\'s syndrome. It can last for months or years and can lead to chronic arthritis that is difficult to treat.\n[Top of Page]\nQ. How do people get salmonellosis?\nA. Salmonella lives in the intestinal tract of humans and other animals, including birds. Salmonella is usually transmitted to humans by eating foods contaminated with animal feces. Salmonella present on raw meat and poultry could survive if the product is not cooked to a safe minimum internal temperature, as measured with a food thermometer. Salmonella can also cause foodborne illness (salmonellosis) through cross-contamination, e.g., when juices from raw meat or poultry come in contact with ready-to-eat foods, such as salads.\nFood may also become contaminated by the unwashed hands of an infected food handler who might or might not be showing symptoms. Salmonella can also be found in the feces of some pets, especially those with diarrhea. People can become infected if they do not wash their hands after contact with these feces. Reptiles are particularly likely to harbor Salmonella. People should always wash their hands immediately after handling a reptile, even if the reptile is healthy.\n[Top of Page]\nQ. What foods are most likely to make people sick?\nA. Any raw food of animal origin, such as meat, poultry, milk and dairy products, eggs, seafood, and some fruits and vegetables may carry Salmonella bacteria. The bacteria can survive to cause illness if meat, poultry, and egg products are not cooked to a safe minimum internal temperature as measured with a food thermometer and fruits and vegetables are not thoroughly washed. The bacteria can also contaminate other foods that come in contact with raw meat and poultry. Safe food handling practices are necessary to prevent bacteria on raw food from causing illness.\n[Top of Page]\nQ. Are chickens labeled ""Kosher,"" ""free-range,"" ""organic,"" or ""natural"" lower in Salmonella bacteria?\nA. FSIS does not know of any valid scientific information that shows that any specific type of chicken has more or less Salmonella bacteria than other poultry.\n[Top of Page]\nQ. What is FSIS doing to prevent Salmonella contamination?\nA. The Food Safety and Inspection Service is the public health regulatory Agency in the USDA responsible for the safety of the nation\'s commercial supply of meat, poultry and egg products. As part of this responsibility, FSIS issued the ""Pathogen Reduction; Hazard Analysis and Critical Control Point (PR/HACCP) Systems, Final Rule"" in 1996. This rule sets Salmonella performance standards for establishments slaughtering selected classes of food animals or those producing selected classes of raw ground products to verify that industry systems are effective in controlling the contamination of raw meat and poultry products with disease-causing bacteria, like Salmonella.\nFSIS inspectors make sure the establishments are meeting the standards by collecting randomly selected product samples and submitting them to an FSIS laboratory for Salmonella analysis. FSIS requires all plants to reduce bacteria by means of the PR/HACCP system.\n[Top of Page]\nQ. How can consumers prevent salmonellosis?\nA. Bacteria on raw foods of animal origin do not have to cause illness. The key to preventing illness at home, in a restaurant, at a church picnic, or anywhere else is to prevent the bacteria from growing to high levels and to destroy the bacteria through cooking to a safe minimum internal temperature. Follow these guidelines for safe food preparation:\nCLEAN: Wash Hands and Surfaces Often\n- Wash hands with warm soapy water for 20 seconds before and after handling food and after using the bathroom, changing diapers, and handling pets.\n- Wash utensils, cutting boards, dishes, and countertops with hot soapy water after preparing each food item and before you go on to the next item.\n- Consider using paper towels to clean kitchen surfaces. If you use cloth towels, wash them often in the hot cycle of your washing machine.\nSEPARATE: Don\'t Cross-contaminate\n- Separate raw meat, poultry, and seafood from other foods in your grocery shopping cart and in your refrigerator.\n- If possible, use one cutting board for fresh produce and a separate one for raw meat, poultry, and seafood.\n- Always wash cutting boards, dishes, countertops, and utensils with hot soapy water after they come in contact with raw meat, poultry, and seafood.\n- Never place cooked food on a plate that previously held raw meat, poultry, or seafood.\nCOOK: Cook to Safe Temperatures\nUse a clean food thermometer when measuring the internal temperature of meat, poultry, casseroles, and other foods to make sure they have reached a safe minimum internal temperature:\n- Cook all raw beef, pork, lamb and veal steaks, chops, and roasts to a minimum internal temperature of 145 °F as measured with a food thermometer before removing meat from the heat source. For safety and quality, allow meat to rest for at least three minutes before carving or consuming. For reasons of personal preference, consumers may choose to cook meat to higher temperatures.\n- Cook all raw ground beef, pork, lamb, and veal to an internal temperature of 160 °F as measured with a food thermometer.\n- Cook all poultry to a safe minimum internal temperature of 165 °F as measured with a food thermometer.\n- Stuffed poultry is not recommended. Cook stuffing separately to 165 °F.\n- Egg dishes, casseroles to 160 °F.\n- Fish should reach 145 °F as measured with a food thermometer.\n- Bring sauces, soups, and gravy to a boil when reheating.\n- Reheat other leftovers thoroughly to at least 165 °F.\nCHILL: Refrigerate Promptly\n- Keep food safe at home, refrigerate promptly and properly. Refrigerate or freeze perishables, prepared foods, and leftovers within 2 hours (1 hour if temperatures are above 90 °F).\n- Freezers should register 0 °F or below and refrigerators 40 °F or below.\n- Thaw food in the refrigerator, in cold water, or in the microwave. Foods should not be thawed at room temperature. Foods thawed in the microwave or in cold water must be cooked to a safe minimum internal temperature immediately after thawing.\n- Marinate foods in the refrigerator.\n- Divide large amounts of leftovers into shallow containers for quick cooling in the refrigerator.', 'Questions and Answers\nWhat are Salmonella?\nSalmonella are bacteria that make people sick. They were first discovered by an American scientist named Dr. Daniel E. Salmon in 1885.\nWhat illness do people get from Salmonella infection?\nMost types of Salmonella cause an illness called salmonellosis, which is the focus of this website. Some other types of Salmonella cause typhoid fever or paratyphoid fever.\nWhat are the symptoms of infection?\nMost people with Salmonella infection have diarrhea, fever, and stomach cramps.\nSymptoms usually begin six hours to six days after infection and last four to seven days. However, some people do not develop symptoms for several weeks after infection and others experience symptoms for several weeks.\nSalmonella strains sometimes cause infection in urine, blood, bones, joints, or the nervous system (spinal fluid and brain), and can cause severe disease.\nScientists classify Salmonella into serotypes (types) by identifying structures on the bacteria’s surfaces. Although more than 2,500 serotypes have been described, fewer than 100 are known to cause human infections.\nHow is Salmonella infection diagnosed?\nSalmonella infection is diagnosed when a laboratory test detects Salmonella bacteria in a person’s stool (poop), body tissue, or fluids.\nHow is infection treated?\nMost people recover from Salmonella infection within four to seven days without antibiotics. People who are sick with a Salmonella infection should drink extra fluids as long as diarrhea lasts.\nAntibiotic treatment is recommended for:\n- People with severe illness\n- People with a weakened immune system, such as from HIV infection or chemotherapy treatment\n- Adults older than 50 who have medical problems, such as heart disease\n- Infants (children younger than 12 months).\n- Adults age 65 or older\nCan infection cause long-term health problems?\nMost people with diarrhea caused by Salmonella recover completely, although some people’s bowel habits (frequency and consistency of poop) may not return to normal for a few months.\nSome people with Salmonella infection develop pain in their joints, called reactive arthritis, after the infection has ended. Reactive arthritis can last for months or years and can be difficult to treat. Some people with reactive arthritis develop irritation of the eyes and pain when urinating.\nHow do people get infected?\nSalmonella live in the intestines of people and animals. People can get Salmonella infection from a variety of sources, including\n- Eating contaminated food or drinking contaminated water\n- Touching infected animals, their feces, or their environment\nWho is more likely to get an infection and severe illness?\n- Children under 5 years old are the most likely to get a Salmonella infection.\n- Infants (children younger than 12 months) who are not breast fed are more likely to get a Salmonella infection.\n- Infants, adults aged 65 and older, and people with a weakened immune system are the most likely to have severe infections.\n- People taking certain medicines (for example, stomach acid reducers) are at increased risk of infection.\nWhat should I know about antibiotic resistance and Salmonella?\nResistance to essential antibiotics is increasing in Salmonella, which can limit treatment options for people with severe infections. One way to slow down the development of antibiotic resistance is by appropriate use of antibiotics.\nWhat can be done to prevent antibiotic resistance and resistant bacteria?\nAppropriate use of antibiotics in people and animals (use only when needed and exactly as prescribed) can help prevent antibiotic resistance and the spread of resistant bacteria.\nHow common is Salmonella infection?\nCDC estimates Salmonella cause about 1.35 million illnesses, 26,500 hospitalizations, and 420 deaths in the United States every year.\n- CDC. Antibiotic Resistance Threats in the United States, 2019. Atlanta, GA: U.S. Department of Health and Human Services, CDC; 2019.\n- Scallan E, Hoekstra RM, Angulo FJ, Tauxe RV, Widdowson MA, Roy SL, Jones JL, Griffin PM. Foodborne illness acquired in the United States–major pathogens pdf icon[PDF – 9 pages]. Emerging Infectious Diseases. 2011;17(1):7-15.\n- CDC. Foodborne Diseases Active Surveillance Network (FoodNet): FoodNet Surveillance Report for 2012 (Final Report) pdf icon[PDF 9 – pages]. Atlanta, Georgia: U.S. Department of Health and Human Services, CDC. 2014.\n- CDC. Suspecting Foodborne Illnesses in Special Populations: Quick Facts for Providersexternal icon. Atlanta, Georgia: U.S. Department of Health and Human Services, CDC. 2012.\n- Carter JD, Hudson AP. Reactive arthritis: clinical aspects and medical managementexternal icon. Rheum Dis Clin North Am. 2009 Feb; 35(1): 21-44.']"	['<urn:uuid:d8b89c01-5b86-428a-831d-5e7df5cd2e8a>', '<urn:uuid:228cba84-af4e-4635-bc49-f860292b6969>']	factoid	with-premise	long-search-query	distant-from-document	multi-aspect	expert	2025-05-13T01:50:22.828293	11	78	2347
73	I work in retail business transformation and need to understand how modern inventory sourcing strategies can be integrated with CRM systems to improve customer satisfaction. Can you explain the connection between product sourcing and customer relationship management?	Product sourcing and CRM systems can be integrated to create a more effective retail operation. On the sourcing side, businesses can use strategies like drop shipping and wholesale partnerships to maintain relevant product inventory, adapting quickly to changing customer tastes and trends. This sourcing approach can be enhanced by CRM's analytical capabilities, which provide valuable customer insights and help track customer preferences and behaviors. The CRM system's data collection and analysis tools help businesses understand what products customers want, while enabling personalized marketing and communication. This integration allows retailers to make informed decisions about inventory, ensure product availability, and maintain strong customer relationships through improved customer service and personalized interactions. The combination of effective sourcing and CRM helps businesses provide customers with desired products while maintaining satisfaction and loyalty.	['One of the most important components of many businesses is their inventory. Inventory is what allows a company to sell products to consumers to create revenue. If an inventory is managed efficiently, it can help boost profits. If it’s not, it can become a drain on the business’s finances and lead to its eventual downfall.\nHow companies manage their inventories is also continually changing and improving. It would be foolish for your business to ignore this progress. It can certainly increase your bottom line. With that in mind, below are a few different ways to keep your inventory up to date with modern standards and practices.\nInvest in Inventory Management Software\nIf you wish to run an e-commerce website that ships products to customers all over the country or even the world, inventory management software is an absolute necessity. It will give you the intelligence to manage your inventory more efficiently and only stock products customers actually want.\nThis software can actually automate much of the process. If stock for a certain product gets too low, the software will order restock automatically. The new stock will arrive in the warehouse before current stock runs out. This helps ensure that customers can buy products when they want them. Similarly, the software can track products that are underperforming and slowly phase them out of your online store. Overstock is, of course, another significant cost for online retailers. RetailWire reported that overstock and out of stock products cost retailers as much as $1.1 trillion a year.\nImplement RFID Tags\nRFID is an acronym that stands for Radio Frequency Identification. RFID is a technology that uses radio waves to identify specific items, animals or people that have a RFID tag. RFID technology was introduced as a replacement for barcode scanners. The obvious advantage over bar codes for RFID is that the tag in question does not need to be in the line of sight for a RFID transceiver to activate the transponder that exists within the tag.\nIn regards to inventory control, RFID is a game changer. RFID greatly increases inventory management efficiency over previous choices like bar codes. Beyond that, it can do a great job of removing human error from the process. If an item includes an RFID tag, it can be easily located within a massive warehouse. This can eliminate one of the main sources of warehouse shrinkage and lower costs as a result.\nSource Your Products\nIn today’s rapidly changing marketplace, it can be difficult to keep track of what items should be kept in stock to sell to customers. Tastes can be fickle, and trends can change overnight. One way to ensure that you always have relevant products in stock is to practice good product sourcing.\nIn the simplest terms, product sourcing can be thought of as a strategy you use to find products produced by other companies to resell through your business. Today, most of that product reselling is done digitally through e-commerce websites. Some of the largest retailers in the world like Amazon have become experts at product sourcing. This is typically done through a supplier you work with to find products customers want. It can include drop shipping in which a wholesaler ships the products for you from its warehouse. It also includes options like light bulk and volume wholesale in which you’re in charge of storing and shipping those products out to customers.\nToday, the retail landscape is largely dominated by e-commerce websites. As such, inventory control is more important than ever. Make sure your company invests in the tools it needs to provide customers with the products they want when they want them. If you don’t, your competitors surely will.', 'Thetechpeople.net In the rapidly evolving world of business, understanding and effectively managing customer relationships is crucial. This article delves into the world of Customer Relationship Management CRM, exploring its meaning, significance, components, types, and the impact it has on businesses.\nWhat Is CRM?\nCRM customer relationship management is a strategy and technology used by companies to manage customer interactions and data. It includes collecting and centralizing customer information, tracking interactions, automating tasks, and facilitating personal communications. The goal is to enhance customer satisfaction, improve sales processes, and gain insights to make informed decisions, ultimately driving business growth and profitability.\nCustomer Relationship Management (CRM)\nis a comprehensive approach that businesses use to manage and analyze interactions with their current and potential customers. It involves various strategies, technologies, and practices aimed at building and nurturing strong customer relationships. Here’s a more detailed look at CRM:\nComponents of CRM:\n- Customer Data Collection: This involves gathering data about customers, which can include their contact information, purchase history, preferences, and behavior.\n- Data Centralization: Storing customer data in a centralized system makes it easily accessible to relevant teams and departments within the organization.\n- Interactions Tracking: Keeping records of customer interactions across various touchpoints, such as phone calls, emails, social media, and in-person meetings, allows businesses to maintain a complete customer history.\n- Automation: Automation tools and software streamline various CRM tasks, such as sending follow-up emails, lead scoring, and managing sales pipelines.\n- Personalization: CRM systems empower businesses to craft tailored interactions with their clientele. This encompasses the ability to create personalized marketing campaigns, offer bespoke product suggestions, and provide individualized customer support. These systems revolutionize how businesses engage with their customers, enhancing customer satisfaction and fostering loyalty.\nTypes of CRM:\n- Operational CRM: Focuses on streamlining various business processes, such as sales, marketing, and customer service. It aims to enhance efficiency and effectiveness in day-to-day operations.\n- Analytical CRM: Analytical CRM is all about data analysis. It helps businesses gain insights into customer behavior, preferences, and trends, which can inform decision-making and marketing strategies.\n- Collaborative CRM: Collaborative CRM emphasizes improving communication and collaboration among different departments within an organization to provide a seamless customer experience.\nImpact on Businesses:\nThe impact of CRM on businesses is significant:\n- Improved Customer Satisfaction: CRM enables businesses to better understand their customers, anticipate their needs, and provide personalized services. This leads to higher customer satisfaction and loyalty.\n- Increased Sales and Revenue: By streamlining sales processes, tracking leads, and providing sales teams with valuable data, CRM can boost sales and revenue.\n- Better Decision-Making: The analytical aspect of CRM provides valuable insights that help businesses make informed decisions and develop effective marketing strategies.\n- Efficient Customer Service: CRM tools facilitate efficient customer service by providing quick access to customer information, allowing for faster issue resolution.\n- Enhanced Customer Retention: CRM helps in retaining existing customers by maintaining strong relationships and addressing their needs promptly.\nImproved Customer Service\nImproving customer service is essential for businesses looking to build strong relationships with their clients and maintain a positive reputation. Here are some strategies and best practices to enhance customer service:\n- Active Listening.\n- Prompt Responses.\n- Multi-Channel Support.\n- Training and Development.\n- Clear Communication.\n- Problem Resolution.\n- Feedback Collection.\n- Customer Support Tools.\n- Service Recovery.\n- Employee Well-being.\n- Knowledge Base.\n- Service Standards.\n- Data Analysis.\n- Customer-Centric Culture.\n- Anticipating Needs.\n- Quality Assurance.\n- Customer Appreciation.\nThese practices can boost customer satisfaction, loyalty, and your business’s reputation.\nBenefits of CRM\nCustomer Relationship Management (CRM) systems offer a wide range of benefits for businesses. These benefits can significantly impact various aspects of an organization’s operations and contribute to its success.\nHere are some of the key benefits of CRM:\n- Improved Customer Relationships\n- Enhanced Customer Service\n- Increased Sales\n- Streamlined Marketing\n- Data Centralization\n- Data Analysis\n- Process Efficiency\n- Better Communication\n- Customer Retention\n- Security and Compliance\n- Competitive Advantage\n- Customer Insights\n- Cost Savings\n- Customer Self-Service\n- Feedback Collection\n- Customer Segmentation\nOvercoming Obstacles in CRM Implementation\nImplementing a Customer Relationship Management CRM system can be a complex and challenging process for many organizations. To overcome obstacles in CRM implementation.\nTo overcome CRM implementation challenges:\n- Set clear objectives.\n- Gain management support.\n- Foster cross-functional collaboration.\n- Conduct a thorough needs assessment.\n- Ensure data quality.\n- Provide user training.\n- Manage change effectively.\n- Choose the right CRM solution.\n- Prioritize data security and privacy.\n- Pilot test before full-scale rollout.\n- Customize and integrate the CRM.\n- Define measurable KPIs.\n- Encourage feedback.\n- Offer ongoing support and maintenance.\n- Ensure scalability.\n- Document processes.\n- Assess and mitigate risks.\nThese strategies can help streamline the implementation process and increase the chances of CRM success.\nChoosing the appropriate CRM software\nSelecting the appropriate Customer Relationship Management CRM software is crucial for businesses looking to effectively manage customer interactions. Here’s a step-by-step guide on how to choose the right CRM software:\nTo choose the right CRM software:\n- Define your specific needs and budget.\n- Consider scalability, deployment options, and integration capabilities.\n- Prioritize user-friendliness, customization, and mobile access.\n- Ensure data security and compliance.\n- Check for reliable support and training.\n- Read user reviews and seek feedback.\n- Try free trials or demos.\n- Assess the vendor’s reputation and future plans.\n- Evaluate data migration options.\n- Start with a trial period for testing.\nMeasuring the success of customer relationship management\nMeasuring the success of Customer Relationship Management (CRM) is essential for businesses to understand the impact of their efforts and make necessary improvements. Here are key metrics and methods for measuring CRM success:\n- Monitor Customer Satisfaction (CSAT) and Net Promoter Score (NPS).\n- Track Customer Retention Rate and Customer Lifetime Value (CLV).\n- Analyze Conversion Rate, Sales Revenue, and Response Times.\n- Measure lead-to-opportunity ratios and Marketing ROI.\n- Assess Cross-Selling and Upselling success.\n- Gather Customer Feedback and Employee Satisfaction data.\n- Ensure data accuracy and evaluate Cost per Acquisition.\n- Review Lead Scoring, Customer Segmentation, and CRM adoption.\n- Continuously adapt CRM strategies based on feedback and results.\nfuture trends of CRM\nThe field of Customer Relationship Management CRM is continuously evolving to adapt to changing customer behaviors, technologies, and market dynamics.\nFuture CRM trends to watch:\n- AI and machine learning.\n- Chatbots and virtual assistants.\n- Omnichannel CRM.\n- Enhanced personalization.\n- Voice recognition.\n- Mobile CRM.\n- Blockchain for data security.\n- IoT integration.\n- Customer data platforms (CDP).\n- Social CRM.\n- Customer journey mapping.\n- AR and VR integration.\n- Ethical data use.\n- Sustainability and social responsibility.\n- Customer engagement platforms.\n- Voice of the Customer (VoC) analytics.\n- Employee experience focus.\n- Predictive customer service.\n- Ecosystem integration.\n- Subscription-based CRM services.\nCRM, or Customer Relationship Management, is a dynamic and evolving field with tremendous potential for businesses. Understanding CRM meaning and its various components is essential for unlocking the full potential of customer relationship insights.\n1. What is CRM software\nCRM software, or Customer Relationship Management software, is a tool that helps businesses manage customer data, streamline sales and marketing processes, and improve customer interactions. It stores customer information, automates marketing and sales tasks, and provides analytics for data-driven decisions. This technology is crucial for enhancing customer relationships and boosting business efficiency and profitability.\n2. What is customer relationship management software?\nCustomer Relationship Management (CRM) software is a technology tool used by businesses to manage and enhance their interactions with customers. It helps in storing and organizing customer data, streamlining sales and marketing activities, and improving customer engagement. CRM software is designed to provide a centralized platform where businesses can access and analyze customer information, communicate effectively with customers, and make data-driven decisions to build stronger relationships and increase sales and customer satisfaction.\n3. What is CRM system software?\nCustomer Relationship Management (CRM) software is a technology tool used by businesses to manage and enhance their interactions with customers. It helps in storing and organizing customer data, streamlining sales and marketing activities, and improving customer engagement. CRM software is\ndesigned to provide a centralized platform where businesses can access and analyze customer information, communicate effectively with customers, and make data-driven decisions to build stronger relationships and increase sales and customer satisfaction.']	['<urn:uuid:158bf940-95d7-4eb6-bc18-d60c05321c32>', '<urn:uuid:f858eb01-9985-4466-b289-daf59c40ca5d>']	open-ended	with-premise	verbose-and-natural	similar-to-document	three-doc	expert	2025-05-13T01:50:22.828293	37	129	2010
74	When was the novel Traveler of the Century first published in Spanish?	Traveler of the Century was published in Spanish in 2009.	"['Traveler of the Century\nBy Andrés Neuman, translated by Nick Caistor and Lorenza García\nFarrar, Straus and Giroux, 576 pages, $30\nThere was a time when Latin American writers felt compelled — maybe the word is “constrained” — to focus their work on a single topic: Latin America. Jorge Luis Borges sought to change this provincial attitude. In a 1951 lecture titled “The Argentine Writer and Tradition,” he called on his colleagues to see beyond the ends of their noses. “What ought to be the themes of Argentine letters?” he asked. His answer was blunt: Western Civilization, by which he meant everything. If Shakespeare, who never left England, is celebrated for plays set in Italy and Denmark, why shouldn’t an Argentine write about a small German city in the 19th century?\nAndrés Neuman, a young writer who was born in 1977 in Buenos Aires and grew up in Spain, takes Borges at his word. “Traveler of the Century,” published in Spanish in 2009 and awarded the prestigious Alfaguara Novel Prize the same year, is magisterial in the vein of Thomas Mann’s “The Magic Mountain,” or Hermann Broch’s “The Sleepwalkers.” That is, it is large and philosophical and deliciously slow — an old-fashioned kind of narrative, less interested in pleasing the tyrannical literary market with fast, easy satisfactions than in bamboozling it through sustained ruminations on politics, God and the nature of things. Most important, it is a novel that doesn’t mention Borges at all. Nor is it concerned with the fate of the Argentine soul.\nNamed by the British magazine Granta as one of the most promising writers from Latin America, Neuman is an essayist, poet and short story writer as well as a novelist. Despite his tender age, he has published almost 20 books, including a volume of aphorisms. (What is it about Latin Americans that causes us to redefine the adjective “prolific”? Might it be the sense that we have to work twice as hard in order to validate our talents?) Neuman belongs to what could be labeled the post-Roberto Bolaño generation. What distinguishes it from its predecessors is the global reach of its themes and the refusal to embrace Magical Realism as a signature style.\n“Traveler of the Century” is easily summarized. The time is around the 1820s. A strange traveler by the name of Hans arrives at the appropriately named city of Wandernburg, on the border between Saxony and Prussia. He has no past and no future. He is passionate about Voltaire. He has no urgent task, which means he can stay as long as he pleases. Only when he’s exhausted the place will he depart. For Hans, that means exploring the city’s inner life. He spends his days meeting bizarre characters, like an organ grinder with whom he engages in probing philosophical conversations.\nThis encounter leads to others. Soon Hans is in touch with a vast array of human types, among them Professor Mietter, a sharp conservative thinker. He also meets a beautiful, provocative, insightful and erudite young woman named Sophie Gottlieb. In the tradition of the epistemological novel, nothing much happens. Or a lot does, depending on your point of view.\nUsing the typology of Isaiah Berlin, Neuman is not a hedgehog but a fox — that is, he knows many things, rather than one big one. “Traveler of the Century” is astonishingly complex in its theological, metaphysical and scientific interests. One has the impression that Immanuel Kant’s “Critique of Pure Reason” has been streamed into a fictional meditation. Reading the book, I was mesmerized by Neuman’s attention to historical detail and his patience with the circumvolutions of the human mind. Sophie, for instance, who is intended to marry local gentry dullard Rudi Wilderhous, keeps Hans on edge. Their affair is soft and intermittent. When Sophie finally kisses Hans after a twisted courtship, the encounter makes the reader shiver.\nI love this book, and not only because of its melodic cadence, superbly rendered by translators Nick Caistor and Lorenza García. I’m also entranced by its reactionary attitude. I took it with me on a lecture trip to Reno, Nev., where I stayed in a casino hotel. The book’s philosophical patience was the perfect antidote to the superficiality of our anodyne, consumerist culture. Its pages seem to scream: Enough with gambling, with the forgetfulness of gambling, with the insatiable drive to accumulate material goods. Neuman, an Argentine writer, has given us a lesson on how to transcend what Borges called “our provincialism” — the obsession with looking at our immediate environment as the only explanation of who we are: He has written a book about the world-less world of ideas.\nIlan Stavans is the Lewis-Sebring Professor in Latin American and Latino Culture at Amherst College. His translation of Juan Rulfo’s “The Plain in Flames” is due out from University of Texas Press in September.\nThis story ""Stopping To Think About the Roses"" was written by Ilan Stavans.']"	['<urn:uuid:7ef20c29-a21a-4b35-b6c6-08ff9e70f798>']	factoid	with-premise	concise-and-natural	similar-to-document	single-doc	expert	2025-05-13T01:50:22.828293	12	10	822
75	meaning boteh symbol persian rugs	The Boteh or paisley symbol in Persian rugs has multiple interpretations: some view it as a leaf, others interpret it as a seed symbolizing a new beginning. In India, it was seen as a symbol of a hand, while in the Zoroastrian faith of Iran, it is considered to represent a flame.	['Oriental Rug design elements are a fascinating part of the appeal of these rugs. Oriental Rugs can truly be considered works of art. It is the variety of design elements used to weave a rug that helps determine its value as well as its appeal to an individual buyer.\nThe design elements can also help give us clues as to where and why a particular Oriental Rug was woven.\nThe design element value of a rug includes the intricacy of the design as well as the beauty of the motifs and the pattern. With the exception of rugs with an allover, portrait, and panel design, these rugs should be symmetrical.\nOriental Rug design elements can be easily be broken down into 2 major types:\nKeep in mind rugs may contain both curvilinear and rectilinear patterns.\nThese are the 2 major distinguishing parts of an oriental rug where the Oriental Rug design elements can be found.\nThe field is the large area in the center of an oriental rug which contains the main pattern and designs. The field can consist of many different design elements or it may simply have a large area of a solid color (open field). The contents of a field can be broadly categorized as follows:\nAs mentioned above, these rugs have a large area of a solid color in the field which will be surrounded by a series of borders. Examples of open field design can be found in some Caucasian Talish and Kazak rugs, Tibetan, Nepalese, and Sultanabad rugs, etc.\nThese are usually found in the center of the field but can appear in many different styles, number, and sizes. Central medallions can be superimposed on an empty field or one filled with a repeated motif or an overall pattern.\nIn a repeated motif design, the field will be filled with multiple rows of the same motif and may be combined with the medallion design.\nExamples of popular motifs used in oriental rugs are the boteh, herati, Mina Knahni, and Gul.\nThis type of design has a field filled with a number of motifs that are not in a repeated or regimented form. There may be palmmettes and flowers with a network of vines and tendrils (Shah Abbas). Or a vase, tree, garden and other patterns may alternate as well.\nA panel design rug contains a compartmentalized design divided into squares, rectangular shapes, domes, diamond shapes, lattice or trellis patterns, etc. Within those shapes there can typically be found a variety of motifs such as flowers, trees, botehs, stars, palmmettes, etc.\nPortrait or Pictorial\nIn this design, landscapes, historic monuments or events, religious scenes, scenes from daily life or folk-lore, and even copies of famous European paintings can be found. These types of designs began to appear by the end of the 18th century.\nPrayer rugs most often have a prayer niche called a Mihrab (Mehrab) or arch at the top of the field. Stars and urns may also appear. The designs of the prayer rugs may be rectilinear or curvilinear depending upon where the rug was woven.\nThe borders of an oriental rug are the series of bands, which may number up to ten or more, that run along the perimeter of the rug surrounding the field.\nThey usually have repeated motifs such as flowers, rosettes, stars, geometric motifs, etc. You may occasionally find inscriptions in various languages depicting poems, prayers, dedications or possibly the signature of the weaver.\nThese are located in the 4 corners of a field and may be a solid color or may contain motifs.\nThese are the small elements that can sometimes be found at either the top or the bottom of a medallion or both.\nThese are usually narrow borders that can be found ‘guarding’ or ‘protecting’ the main border or borders.\nBecause of the way light is reflected from the fibers, one end of a rug may look darker than the other. That may not be a defect in the rug but a result of the direction of the weaving when it was on the loom.\nThe yarn knots are tied onto the warp\nfoundation and then pounded down after being covered by one or more weft (side to side) cords. Thus, it is\nquite easy to determine which end of the rug is the top and which is the bottom.\nBy running your hand in either direction, you will discover that if your hand\ngoes ‘against the grain,’ you are heading to the top of the rug. If your hand\ngoes ‘with the grain,’ you are heading in the direction of the bottom of the\nrug (the direction of the weaving.)\nThe study of the different design elements that can be found in oriental rugs is fascinating, if not intimidating! The learning process involves looking at (and enjoying) as many rugs as possible (in stores, online, in books). You will begin to see that certain elements are very common and some are more common on specific types of rugs from different geographical weaving locations.\nCompared to determining the exact origin of an oriental rug, recognizing individual design elements is actually much easier and a good direction to take on your journey to a better understanding of Oriental Rug design elements.\nWe are in the office of ABC at 130 Cecil Malone Drive in Ithaca, NY from 8 to 5 Monday through Thursday, closing at 4:30 on Fridays. We are also open from 10 to 1 on the 1st and 3rd Saturdays of each month.\nWe will be happy to help you on your journey!\nTraditional Persian Rugs\nA quick overview of some different types of Persian rugs, specifically from the late 19th and early 20th centuries. These include: BIJAR, FERAHAN, MESHED, KERMAN, LAVAR KERMAN, and the SULTANABAD.\nPERSIAN RUG SYMBOLS\nWater was very important for survival.\nGardens represent Paradise or Heaven in Persian lore and include lots of plants and animal life.\nParadise birds represent Paradise.\nParrots are protection symbols and antelopes represent restfulness as to be found in Paradise.\nThe Boteh or paisley symbol has many meanings. Some see it as a leaf. Others say it represents a seed and the prospect of a new beginning. In India, it was considered to be a symbol of a hand. In the Zoroastrian faith of Iran, it is considered to be a flame.\nA Turkish Rug Demo\nA salesman demonstrating some Turkish rugs.']	['<urn:uuid:8772c8ba-47f6-4095-a51f-25f760dd6d9e>']	open-ended	direct	short-search-query	similar-to-document	single-doc	expert	2025-05-13T01:50:22.828293	5	52	1066
76	What methods ensure wine clarity and how do containers impact storage?	Wine clarity is achieved through several processes: fining using organic compounds (egg whites, casein, gelatin) or minerals (bentonite clay, activated carbon); filtration through cellulose fibers or membranes; and flotation using air bubbles to remove solids. For storage, traditional oak barrels allow oxygen introduction and flavor development, while alternative containers offer different benefits - stainless steel provides no oxygen exchange, concrete tanks offer natural oxygenation and temperature control, and plastic tanks can replicate barrel functions while being space efficient. Complete stabilization may also involve cold stabilization for tartrate removal and pasteurization to eliminate microorganisms.	"['Clarification and stabilization of wine\nIn winemaking, clarification and stabilization are the processes by which insoluble matter suspended in the wine is removed before bottling. This matter may include dead yeast cells (lees), bacteria, tartrates, proteins, pectins, various tannins and other phenolic compounds, as well as pieces of grape skin, pulp, stems and gums. Clarification and stabilization may involve fining, filtration, centrifugation, flotation, refrigeration, pasteurization, and/or barrel maturation and racking.\nIn wine tasting, a wine is considered ""clear"" when there are no visible particles suspended in the liquid and, especially in the case of white wines, when there is some degree of transparency. A wine with too much suspended matter will appear cloudy and dull, even if its aroma and flavor are unaffected; wines therefore generally undergo some kind of clarification.\nBefore fermentation, pectin-splitting enzymes and, for white wine, fining agents such as bentonite may be added to the must in order to promote the agglomeration and settling of colloids later. Pectins are structural molecules in the cell walls of fruits which have the important function of \'gumming\' plant cells together. The pectin content of grapes increases steadily throughout ripening, reaching levels of about 1 g/l, although it varies by varietal and pre-fermentation handling processes. Large pectin molecules can affect the amount of juice yielded at pressing, ease of filtration and clarification, and extraction of tannins. Grapes contain natural pectolytic enzymes responsible for softening the grape berries during ripeneing, but these are not active under wine-making conditions (due to pH level, SO2, and alcohol.) Therefore, fungal pectolytic enzymes are often added to white must to break up pectins, decrease the viscosity of the juice, and speed up settling. In red musts, this increases colour and tannin extraction.\nAfter fermentation, the force of gravity may eventually cause the wine to ""fall bright"" or clarify naturally, as the larger suspended particles gradually settle to the bottom of the storage vessel. The wine can then be siphoned or ""racked"" off the compact solids into a new container. But this process may take many months, or even years, as well as several rackings, in order to produce a perfectly clear wine. Producers can accelerate the process by using fining agents, filtration and/or flotation.\nIn winemaking, fining is the process where a substance (fining agent) is added to the wine to create an adsorbent, enzymatic or ionic bond with the suspended particles, producing larger molecules and larger particles that will precipitate out of the wine more readily and rapidly. Unlike filtration, which can only remove particulates (such as dead yeast cells and grape fragments), fining can remove soluble substances such as polymerized tannins, coloring phenols and proteins; some of these proteins can cause haziness in wines exposed to high temperatures after bottling. The reduction of tannin can reduce astringency in red wines intended for early drinking. Many substances have historically been used as fining agents, including dried blood powder, but today there are two general types of fining agents — organic compounds and solid/mineral materials.\nOrganic compounds used as fining agents are generally animal based, a possible cause of concern to vegans. The most common organic compounds used include egg whites, casein derived from milk, gelatin and isinglass obtained from the bladders of fish. Pulverized minerals and solid materials can also be used, with bentonite clay being one of the most common, thanks to its effectiveness in absorbing proteins and some bacteria. Activated carbon from charcoal is used to remove some phenols that contribute to browning as well as some particles that produce ""off-odors"" in the wine. In a process known as blue fining, potassium ferrocyanide is sometimes used to remove any copper and iron particles that have entered the wine from bentonite, metal winery and vineyard equipment, or vineyard sprays such as Bordeaux mixture. Because potassium ferrocyanide may form hydrogen cyanide its use is highly regulated and, in many wine producing countries, illegal. Silica and kaolin are also sometimes used.\nSome countries, such as Australia and New Zealand, have wine labeling laws that require the use of fining agents that may be an allergenic substance to appear on the wine label. A study conducted by the University of California, Davis Department of Viticulture and Enology, however, found that no detectable amount of inorganic fining agents, and only trace quantities of proteinaceous agents, are left in the wine.\nThere is the risk of valuable aromatic molecules being precipitated out along with the less desirable matter. Some producers of premium wine avoid fining, or delay it in order to leach more flavor and aroma from the phenols before they are removed.\nWhile fining clarifies wine by binding to suspended particles and precipitating out as larger particles, filtration works by passing the wine through a filter medium that captures particles larger than the medium\'s holes. Complete filtration may require a series of filtering through progressively finer filters. Many white wines require the removal of all potentially active yeast and/or lactic acid bacteria if they are to remain reliably stable in bottle, and this is usually now achieved by fine filtration.\nMost filtration in a winery can be classified as either the coarser depth filtration or the finer surface filtration. In depth filtration, often done after fermentation, the wine is pushed through a thick layer of pads made from cellulose fibers, diatomaceous earth or perlite. In surface filtration the wine passes through a thin membrane. Running the wine parallel to the filter surface, known as cross-flow filtration, will minimize the filter clogging. The finest surface filtration, microfiltration, can sterilize the wine by trapping all yeast and, optionally, bacteria, and so is often done immediately prior to bottling. An absolute rated filter of 0.45 µm is generally considered to result in a microbially stable wine and is accomplished by the use of membrane cartridges, most commonly polyvinylidene fluoride (PVDF). Certain red wines may be filtered to 0.65 µm, to remove yeast, or to 1.0 µm to remove viable brettanomyces only.\nThe winemaking technique of flotation was adapted from the froth flotation process used in the mining industry for ore refining. In this process, small bubbles of air (or compressed nitrogen) are injected into the bottom of a tank. As the bubbles rise through the must, grape solids, including phenolic compounds prone to oxidation and browning, will tend to cling to the bubbles, creating a froth that can be removed from the wine. This must be done prior to fermentation, since yeast will inhibit the flocculation involved.\nAs a complex chemical mixture dependent on the activity of microorganisms, wine can be unstable and reactive to changes in its environment. Once bottled, a wine may be exposed to extremes of temperature and humidity, as well as violent movement during transportation and storage. These may cause cloudiness, sedimentation and/or the formation of tartrate crystals; more seriously, they may also cause spoilage or the production of carbonic gas.\nTartaric acid is the most prominent acid in wine with the majority of the concentration present as potassium bitartrate. During fermentation, these tartrates bind with the lees, pulp debris and precipitated tannins and pigments. While there is some variation according to grape variety and climate, usually about half of the deposits are soluble in the wine, but on exposure to low temperature they may crystallize out unpredictably. The crystals, though harmless, may be mistaken for broken glass, or simply reckoned unattractive by consumers. To prevent this the wine may undergo ""cold stabilization"", in which it is cooled to near its freezing point to provoke crystallization before bottling. In some white wines there are significant quantities of proteins that, being ""heat-unstable"", will coagulate if exposed to excessively fluctuating heat; the use of fining agents such as bentonite can prevent the haze this causes.\nA wine that has not been sterilized by filtration might well still contain live yeast cells and bacteria. If both alcoholic and malolactic fermentation have run to completion, and neither excessive oxygen nor Brettanomyces yeast are present, this ought to cause no problems; modern hygiene has largely eliminated spoilage by bacteria such as acetobacter, which turns wine into vinegar. If there is residual sugar, however, it may undergo secondary fermentation, creating dissolved carbon dioxide as a by-product. When the wine is opened, it will be spritzy or ""sparkling"". In a wine intended to be still this is regarded as a serious fault; it can even cause the bottle to explode. Similarly, a wine that has not been put through complete malolactic fermentation may undergo it in bottle, reducing its acidity, generating carbon dioxide, and adding a diacetyl butterscotch aroma. Brettanomyces yeasts add 4-ethylphenol, 4-ethylguaiacol and isovaleric acid horse-sweat aromas. These phenomena may be prevented by sterile filtration, by the addition of relatively large quantities of sulfur dioxide and sometimes sorbic acid, by mixing in alcoholic spirit to give a fortified wine of sufficient strength to kill all yeast and bacteria, or by pasteurization.\nPasteurization gives a kosher wine of the type called mevushal, literally ""cooked"" or ""boiled"", that can be handled by non-Jews and non-observant Jews without losing its kosher status. Typically, the wine is heated to 185°F (85°C) for a minute, then cooled to 122°F (50°C), at which temperature it remains for up to three days, killing all yeast and bacteria. It may then be allowed to cool, or be bottled ""hot"" and cooled by water sprays. Since pasteurization affects a wine\'s flavor and aging potential it is not used for premium wines. A gentler procedure known as flash pasteurization involves heating to 205°F (95°C) for a few seconds, followed by rapid cooling.\nOther methods of stabilization\nClarification tends to stabilize wine, since it removes some of the same particles that promote instability. The gradual oxidation that occurs during barrel aging also has a naturally stabilizing effect.\nPremium wine production\nSome producers prefer not to thoroughly clarify and stabilize their wines, believing that the processes involved may diminish a wine\'s aroma, flavor, texture, color or aging potential. Wine experts such as Tom Stevenson note that they may improve wine quality when used with moderation and care, or diminish it when used to excess. Winemakers deliberately leave more tartrates and phenolics in wines designed for long aging in bottle so that they are able to develop the aromatic compounds that constitute bouquet. The consumers of some wines, such as red Bordeaux and Port, may expect to see tartrates and sediment after aging in bottle.\n- J. Robinson (ed) ""The Oxford Companion to Wine"" Third Edition, pp. 173, 661–62. Oxford University Press 2006 ISBN 0-19-860990-6.\n- Robinson, Janis (2006). Oxford Companion To Wine. Oxford University Press. ISBN 0198609906.\n- T. Stevenson ""The Sotheby\'s Wine Encyclopedia"" pp. 26–7 Dorling Kindersley 2005 ISBN 0-7566-1324-8.\n- J. Robinson (ed) ""The Oxford Companion to Wine"" Third Edition pp. 271–72 Oxford University Press 2006 ISBN 0-19-860990-6\n- J. MacQuitty ""Vegan wines"", The Times, August 20th 2008\n- C. Pyevich ""Why is Wine so Fined?"" Vegetarian Journal, January/February 1997, Volume XVI, Number 1.\n- J. Robinson (ed) ""The Oxford Companion to Wine"" Third Edition, p. 83 Oxford University Press 2006 ISBN 0-19-860990-6.\n- K. MacNeil The Wine Bible pp. 35–40 Workman Publishing 2001 ISBN 1-56305-434-5.\n- ""Wine Filtration"". Gusmer Enterprises. Retrieved 3 August 2012.\n- J. Robinson (ed) ""The Oxford Companion to Wine"" Third Edition, p. 681 Oxford University Press 2006 ISBN 0-19-860990-6.\n- S. Retsky ""Kosher, Mevushal and Israeli Wines? Not What You Think"" American Thinker, December 17th 2005.\n- J. Robinson (ed) ""The Oxford Companion to Wine"" Third Edition p. 508 Oxford University Press 2006 ISBN 0-19-860990-6', 'Wine Barrels 101\nWine began stored and aged in amphorae (sealed earthenware or clay jars) that were used in Greece and Rome.\nIt was the Celts in around 50BD that devised using wooden barrels to store and transport wines (those Celts…so smart!)\nWooden barrels were sturdy and shaped conveniently for transport. And…it seemed that wine could actually benefit from the wood!\nWhy Oak? Some would say out of convenience and then as a taste preference. There are over 400 species of oak. Only about 20 of them are typically used for wine barrels and these can very with the flavors they impart although most often the flavor noticed is “vanilla”.\nIn addition to the wood itself you have the toast. Cooperages specialize in specific toasts for the staves and heads of the barrels and the intensity of the toast can definitely affect the flavor of the wine. Toasts are labeled as light, medium or heavy and can very from the barrel staves to the head.\nBarrels allow the introduction of oxygen to the wine in a very slow manner. The pace of the introduction depends on the tightness of the grain of the wood. It also imparts the wood flavor into the wine as well as tannins, and body. The body comes mostly from the sugars that are formed when the oak is toasted.\nWhen speaking of types of Oak:\n- French oak has the highest tannins. They tend to be more subtle than American Oak. They are distinguished by which forest they come from with 5 major regions. The trees used are between 120-150 years old and are strictly controlled by the French Department de Eaux et de Forets. The rough staves are typically air dried for 2 to 3 years before the barrels are made. French barrels can run between $800 and $3600 each.\n- American oak is the opposite extreme with grains that are not nearly as tight. Here you get much bolder flavors including spice, vanilla and butter. American oak primarily comes from the Midwest, Appalachia and Oregon. American oak is much more affordable at $300-$500 per barrel.\n- Hungarian is usually thought of as the tightest grain, this makes it more neutral, imparting less flavors even when it is new as well as typically being lower in tannins. Hungarian oak sits right between the two cost wise at $500-$700 per barrel.\nBarrels lose their flavor as they age. Typical barrels can be used for about 5 years before they are done imparting flavor. You get the most flavor extracted on the first use, about 50%. The second use you get about 25% and after that the barrel dwindles toward what is referred to as neutral oak or a barrel that no longer imparts noticeable oak flavor. So…if after 5 years you have wines to age in neutral oak, you are good! You can keep using those barrels for 100 years or so!\nYou can increase the life of the barrel and get more use out of it. I have seen photos from the Cilurzo winery in Temecula back in the 60’s shaving down the inside of the barrels to get more exposure to the oak. Shaving at this time was a special art and the people who did it travelled from winery to winery doing this. This practice picked up in the 80’s and 90’s. Barrels would be shaved and then re-toasted. Shaving costs run about $75 per barrel. A new company out of Australia has a new robot called the Phoenix that uses a high-speed cutting tool to cut 9-10 mm from each stave. This is done by first mapping the interior of the barrel with a laser. Once the interior is cut down the barrels are re-toasted with an infrared machine. I have heard also of adding new thinner staves that have been toasted to neutral barrels.\n- Wine Barrel’s Stacked\nNow the barrels we are talking about here are the standard 60 gallon barrels that are used in many wineries. The ones you see turned later into planters and lawn furniture. There is a whole different world of barrels out there that are much larger. A great example of these larger wooden barrels can be seen in southern Rhone Style wines where you want less oak contact. Tablas Creek has great (and might I say stunningly beautiful) examples of these.\nBarriques are the French term for the typical 60 gallon barrels.\nFoudres are 1200 gallon French Oak barrels and hold enough wine to fill 500 twelve-bottle cases.\nPuncheons are 120 gallon barrels.\nDemi-muids are 160 gallon barrels.\nThere are also 1600-gallon wooden casks that stand upright, like a fermentation tank.\nFoudres, 1200 Galllon French Barrel’s\nOther types of containers available\n- Flextank and other companies create plastic wine tanks that replicate barrel functions and are space efficient. If you do not need oak flavor…well you can reuse these multiple times.\n- Vino Vessel originated in Paso Robles and is a company that creates concrete fermentation and storage tanks. The benefits are that they are more affordable, easier to clean, less space and labor intensive and longer lasting. They also offer more natural oxygenation than stainless steel does and they are naturally stay cooler so they reduce refrigeration costs.\n- Stainless Steel has no oxygen exchange and is initially expensive, but can be used repeatedly. They can be fitted with wood staves to impart flavor.\nOkay speaking of adding staves…you can use these alternative vessels for aging your wine and still get oak flavor by adding staves and or oak chips.\nSo that’s the basics of barrels. This is not to be confused with fermentation tanks. That’s a whole ‘nother chapter!']"	['<urn:uuid:457863c8-023e-46be-9a36-0e0a359106df>', '<urn:uuid:8958b451-efad-4ae7-a9d7-1a07dc496a93>']	open-ended	direct	concise-and-natural	distant-from-document	multi-aspect	expert	2025-05-13T01:50:22.828293	11	93	2867
77	What exactly is seitan, and what health problems can it cause for people who are sensitive to it?	Seitan is a protein-rich food also known as vital wheat protein or wheat gluten. It's made from the protein found in wheat and related cereal grains, accounting for 75-85% of the total protein in wheat. While seitan can be bought ready-made or prepared at home by creating a dough and washing away the starch, it can cause significant health issues for some people. For those with celiac disease or gluten sensitivity, consuming seitan can trigger an autoimmune reaction that damages the small intestine, leading to symptoms like diarrhea, bloating, pain, and poor nutrient absorption. In celiac disease patients, the damage occurs to small finger-like projections called villi in the small intestine, severely impacting their ability to absorb nutrients from food.	['Vegan cookery school Demuths reveals more about the versatile ingredient everybody is talking about, seitan, and shows you how to make seitan at home.\nWhat is seitan?\nSeitan is also know as vital wheat protein, textured wheat protein, wheat gluten, vital wheat gluten.\nWheat gluten as a protein source is popular in China and is called ‘mock meat’ for its comparison in texture.\nThe Chinese also like wheat gluten as it has a flavour similar to MSG. The Japanese name for wheat gluten is seitan pronounced ‘say-tan’ and was introduced in the 60s as part of the macrobiotic diet.\nYou can buy seitan in tins or jars, cooked and marinated and ready to eat, or you can easily make your own.\nSeitan as a meat substitute means eating concentrated gluten extract. Read on to discover more about gluten…\nWhat is gluten?\nGluten is comprised of proteins found only in wheat and related cereal grains (wheat, barley, rye).\nThere are many other proteins in these grains. The common proteins include the water-soluble protein groups – albumin, globulin and proteoses plus two water-insoluble protein groups, glutenin and gliadin, which together are known as gluten.\nGluten is not the only protein in the wheats. In fact, gluten accounts for only about 75-85% of the total protein in the wheat berry.\nIs seitan good for you?\nGluten is high in protein and eaten in moderation for most people causes no adverse effect.\nGluten and health\nGluten is responsible for several health problems and is a stomach irritant. Coeliac disease is a permanent intolerance to gluten, which is an immunological disease.\nThere are allergies to gluten and degrees of sensitivity, all of which cause abdominal disturbances, such as bloating, pain and diarrhoea.\nCoeliacs must have a gluten-free diet and the others may benefit to varying degrees with gluten exclusion.\nGluten from additives or wheat contamination in food processing and manufacture can be a major problem to identify or avoid.\nMany sufferers with a mild intolerance can benefit from sourdough bread. The long fermentation times used in sourdough baking break down the gliadin fraction of gluten and sufferers often find sourdough bread easier to digest.\nBut labels can be misleading so make your own sourdough or check with the baker.\nThere appears to be an increased reporting in gluten sensitivity. This may be due to a general increase in the protein content of bread wheat over the years or an increase in the addition of gluten additive (vital gluten).\nHow to make seitan\nSeitan can be made by creating a salt-free dough made with wholewheat flour and water.\nThe dough is then washed under a running tap to remove the wheat starch, bran and other water-soluble proteins.\nYou are then left with a piece of pliable insoluble gluten. The shortcut is to buy vital wheat gluten flour and mix with water.\nWhat to make with seitan\nYou can make dishes such as crispy seitan Chinese pancakes, Seitan chorizo, BBQ seitan strips or a Seitan and mushroom puff pie.\nEasy seitan recipe\nIt’s easy to make seitan at home using the ingredients from your storecupboard. Use it to make many meals including barbecued ‘ribs’ and delicious ‘chorizo’ dishes to tasty stir-fries and curry bowls.\nFor the seitan:\n- 140 g vital wheat gluten flour\n- 3 tbsp nutritional yeast flakes\n- 125 ml cold vegetable stock\n- 3 tbsp soy sauce/shoyu\n- 2 tbsp fresh lemon juice\n- 1 tbsp olive oil\n- 2 garlic cloves (made into a paste or grated using a small grater or microplane )\nFor the broth:\n- 1 litre vegetable stock\n- 1 litre water\n- 3 tbsp soy sauce/shoyu\n- Fill a pot with the water, stock and soy sauce. Cover and bring to a boil.\n- In the meantime, in a large bowl mix together gluten and yeast. In a smaller bowl mix together stock, soy sauce, lemon juice, olive oil and garlic. Pour the wet into the dry and combine with a wooden spoon until most of the moisture has absorbed and partially clumped up with the dry ingredients.\n- Use your hands and knead for about 3 minutes, until it’s an elastic dough, longer if you want a chewier texture. Let rest for 5 minutes. Divide into three equal pieces with a knife and then knead those pieces in your hand just to stretch them out a bit.\n- Once the broth is boiling, lower the heat to a simmer. Add the gluten pieces and partially cover the pot so that steam can escape. It is important not to boil the broth at this point. You want a gentle simmer with a few bubbles coming to the surface at a time. Let simmer for 45 minutes, turning occasionally. If the broth turns to a boil, remove the lid for a bit. Turn the heat off and take the lid off, let sit for 15 minutes.\n- Remove from the broth and place in a strainer until it is cool enough to handle. Slice and use as desired.', 'What is Celiac Disease?\nCeliac disease is an autoimmune reaction from eating gluten. Your body responds by attacking the small intestine. Overtime this condition has a severe impact upon absorption of nutrients.\nExperts are yet to pinpoint a definitive cause. However, they have established a number of underlying factors: other autoimmune diseases, viruses, infant nursing methods and even traumatic periods in life can trigger it.\nCeliac disease is also a hereditary condition. This means it runs in families. If you have a parent or sibling with the disease there is a 1 in 10 chance of developing it.(1)\nThis condition is also known as sprue or coeliac.\nLining the small intestine you have small finger like projections. These are called villi and they help the body absorb all the essential goodness from your food. When they are damaged, nutrients cannot be absorbed properly into the body.\nGluten is the name for the protein found in grains. People with celiac disease only react to the form of gluten found in wheat, barley, and rye.\nWhen someone with celiac disease eats anything containing this protein,it damages the villi. This causes a drastic chain of events within your digestive system and your body.\nCeliac disease can be suffered both in childhood or as an adult, yet once you have it, it stays with you for life.\nThis condition is divided into three types: classical, non- classical and silent.(2)\nPeople can have signs and symptoms of malabsorption. This means the small intestine is not absorbing enough nutrients and fluids.\nThey may also have diarrhea or pale, foul-smelling, fatty stools. They experience weight loss.\nEdema is another indication associated with classic celiac disease. This means that excess fluid build up in body tissues. It causes swelling usually in the feet, legs or hands.(3)\nChildren have growth failure and can be irritable or unhappy.\nThis is associated with milder signs and symptoms of stomach and intestinal issues.\nThere can be unexplained anemia due to iron deficiency.\nThey may have just one of the other symptoms of the disease, or many. The symptoms will be classified as mild.\nSometimes people have the disease but display none of the symptoms. The disease usually shows up if they are screened for damage to the intestines.\nIt is thought that between 50% and 90% of people that have celiac disease are not diagnosed.(4)\nThe symptoms for celiac disease can vary from one person to another. Adults and children also display contrasting signs. Even infants under 2 can experience different symptoms to that of older children.(5)\nCommon signs of celiac for infants include: vomiting, chronic diarrhea and swollen bellies. They can also have a poor appetite.\nTheir stools will be pale and smell foul and they may fail to thrive and have muscle wastage.\nOlder Children Symptoms\nOlder children will also experience diarrhea or constipation. Pale, nasty smelling stools and weight loss are also indications of this condition.\nAs they develop they could be shorter than other children of the same age and puberty might also be delayed.\nBehavioral issues and irritability are not uncommon. There are also neurological symptoms.These include attention deficit hyperactivity disorder (ADHD) and learning disabilities.\nChildren also experience headaches, lack of muscle coordination and seizures.\nThe most common symptoms for adults are diarrhea, fatigue and weight loss.\nThey will experience bloating and gas and abdominal pain as well as nausea, vomiting or constipation.\nCeliac disease can prevent the body from absorbing enough iron, this means anemia can occur.\nMouth ulcers or damage to dental enamel on the teeth is another sign to look out for.\nIt can cause headaches and also affect the nervous system. The result is numbness and tingling in the feet and hands. Impaired balance is another sign.\nProblems with memory, thinking, language and judgement are also possible.\nYour spleen can be damaged. The spleen helps fight infection and keep your blood cells healthy.\nUnexplained infertility or recurrent miscarriages are also be indications of this disease.\nThe rash normally appears on the elbows, knees, torso, scalp and buttocks. It is an indication of gluten intolerance.\nIf you are tested for celiac disease via a blood test or genetic screening your doctor may ask you to have an endoscopy. This is the gold standard test for this condition.\nThis is an outpatient procedure where a scope is placed through your mouth to allow a view of the small intestine.\nA biopsy or sample of the small intestine can be taken at the same time. The results of the biopsy will show how much damage there is to the villi.\nThis damage falls into four types.(10)\nThis shows no damage to the villi. The intestinal lining is normal and it is unlikely that you have celiac disease.\nThis shows no damage to the villi. It is a result that is expected if you have been following a gluten free diet. It may also be the result expected from family members of someone with the disease.\nThis type is rare. The villi are normal and the only symptom you have is the skin rash dermatitis herpetiformis\nThis shows the villi are shorter than they should be or not present at all. This is the result when you are experiencing symptoms of the disease.\nThe only successful treatment for Celiac disease is following a gluten free diet. This is a lifelong commitment.\nA referral to a dietitian can help you plan your diet.\nFollowing a gluten free diet will help the small intestine to heal.\nInformation surrounding gluten-free foods are now widely available. The internet provides a wealth of information explaining the grains you can eat.\nFresh foods like fruits, vegetables, meat, poultry, fish, dairy, beans, legumes, and nuts are gluten-free options.(11)\nFoods Containing Gluten\nWheat is the main source of gluten.\nIt can also be found in many other grains and foods. These include: barley, bulgur, durum, farina, graham flour, malt, rye, semolina, spelt and triticale.\nMany foods are now clearly labelled if they are gluten free. Be aware there may be hidden gluten in some products. These include modified food starch, preservatives and food stabilizers.\nThere are other items that contain gluten which you will need to consider. These include prescription and over-the-counter medications.\nSome vitamin and mineral supplements or herbal and nutritional supplements can contain gluten. Other items include: lipstick, toothpaste, mouthwash, envelope and stamp glue.\nVitamins and Dietary Supplements\nMany people with celiac disease are deficient in some types of vitamins and minerals. If this is the case taking a gluten free multivitamin pill will help.(12)\nWhen you are diagnosed you may be screened to check your bone health. The disease can make your bones thinner. You will possibly be prescribed medication or advised to take a dietary supplement.(13)\nYour doctor will perform tests to check the damage to your small intestine. If it is severely inflamed or damaged they can prescribe steroids to help it heal.\nCorticosteroids or autoimmune medications are considered if you have refractory Celiac disease.(14)\nThis means a gluten free diet alone does not relieve the symptoms. The damage to the villi in the small intestine does not heal with a gluten free diet alone.\nEndoscopy, Biopsy and Blood Tests\nYour physician can refer you for blood tests. This will check for levels of antibodies that attack an enzyme called tissue transglutaminase. The antibodies attack this enzyme mistaking it for gluten.(15)\nYou can also be referred for an endoscopy. This allows a doctor to look at the small intestine for signs of damage. They are also able to take tissue samples or a biopsy during this medical process.(16)\nWhen performing these tests you need to continue eating gluten or the tests will not give a true result.\nWhat is celiac disease? Celiac disease is an autoimmune reaction from eating gluten, a protein found in barley, wheat and rye.\nWhat are the signs of celiac disease? Typical signs of this disease are digestive issues. These include diarrhea, vomiting, abdominal pain and constipation. An itchy skin rash is common in people of all ages. You may feel very tired or irritable. Sometimes there are no signs at all.\nHow do you develop celiac disease? Celiac disease is hereditary. This means it could be in your genes. People who suffer with other autoimmune diseases, such as type 1 diabetes or rheumatoid arthritis will often have celiac disease. However, the precise cause isn’t known.\nHow are you diagnosed for celiac disease? Your doctor may take blood tests. The tests will look for raised levels of certain antibodies in your blood. They can also refer you for an endoscopy or biopsy. This will help the doctor identify whether there is damage to the small intestine. Some people don’t have symptoms of the disease and only these tests will reveal if they have it.\nWhat is the best treatment for celiac disease? The only current treatment for this disease is to follow a strict gluten free diet. The diet must be followed for life. Accidentally eating gluten could trigger the symptoms again.\nWhat are the long term complications of celiac disease? This disease can lead to additional serious health problems if not treated. These include the development of other autoimmune disorders like type I diabetes and multiple sclerosis. Other complications are osteoporosis, infertility and miscarriage. It can cause neurological conditions like epilepsy and migraines. It can stunt growth. It can also contribute to intestinal cancers.\nIs celiac disease considered a disability? Celiac disease does not appear to be considered a disability. You may get certain social security benefits to help you if the condition is severe.(17)\nIs there a cure for celiac disease? There is no cure for this condition. It can only be managed by following a gluten free diet. Many stores and restaurants now have foods suitable for people with celiac disease.\nIs celiac disease life threatening? Celiac disease is not life threatening. However, there are some serious conditions associated with the disease. These include diabetes, cancer and liver problems.(18)\nCeliac disease affects the autoimmune system. Eating gluten causes it to attack and damage the small intestine. This leaves the body lacking in nutrients.\nIt’s a lifelong disease which has to be carefully managed otherwise it can seriously impact upon quality of life.\nThe disease is caused by an intolerance to gluten which is a protein found in grains.\nThere is no known cure at the present time however, it can be controlled by following a gluten free diet. Getting used to this type of diet may be difficult and you may need the help of a dietitian.\nThankfully this condition has been acknowledged as a real problem which affects so many lives. This is why you can now find many food products available in stores geared for a gluten-free diet.']	['<urn:uuid:1006faf7-2fab-4d64-90e7-52231d17dd33>', '<urn:uuid:9d734d4f-f9fb-49c0-952d-46f52e27f1bd>']	open-ended	direct	verbose-and-natural	similar-to-document	multi-aspect	novice	2025-05-13T01:50:22.828293	18	120	2637
78	amount money jordan artis receive	Jordan Artis was awarded $2,000 as a scholarship recipient in 2014 to help further his education.	"[""The Theta Rho Lambda Education Foundation is a 501(c)(3) organization established to support young men in the Washington Metropolitan Area in their college endeavors. The foundation is organized exclusively for charitable and educational purposes.\nThe purpose of the foundation is realized through three objectives:\nThrough fundraising, merit based scholarships are awarded annually to graduating senior high school students who have demonstrated academic excellence, leadership, and community involvement.\nBy providing educational based programs and services, the goal is to offer young men in high school and college with information and strategies that facilitates success.\nBy equipping young men between the ages of 12 – 15 with skills to foster a sense of empowerment and self-esteem, while motivating them to make decisions about their goals and values, and act in ways that support their decisions.\nWith help from generous individuals such as yourself, the Theta Rho Lambda Education Foundation can continue to Transform, Reinforce, and Lead young men in the Washington Metropolitan Area to greatness.\nWhere can I get a scholarship application from?\nWho are the members of the Education Foundation's Board of Directors?\nBro. Kevin Glover\nBro. Anthony Hyman Jr\nBro. Michael Frempong\nBro. Eddie Hill\nDir. of Education Activities and GTHGTC Committee Chair\nBro. Benjamin Turman\nBoard Member and Black & Gold Committee Chair\nBro. David Preston\nBoard Member and Project Alpha & Alpha Esquires Committee Chair\nBro. George White\n*GTHGTC = Go To High School, Go To College\nHow can I contact the Education Foundation?\nThe Education Foundation can be contacted via mail or email.\nTheta Rho Lambda Education Foundation\nPO Box 16026\nArlington, VA 22215\nCommunity Service Award\nThe Theta Rho Lambda Education Foundation honors those who are doing tremendous things that benefit the communities of Arlington and/or Alexandria, VA. The Foundation does this on a yearly basis to recognize and bring awareness to the outstanding leaders within the community.\nRoss Cooper (2015 Scholarship Recipient)\nRoss will be attending the Virginia Polytechnic Institute and State University (Virginia Tech) in the fall of 2016. He plans to major in Water: Resources, Policy, and Management in the College of Natural Resources and Environment. He attended the Gateway Program for minority students and felt like he found his home. He shared that he was impressed by the school, the research opportunities, the good food and the welcoming atmosphere.\nDennis Afrane (2014 Scholarship Recipient)\n“I am grateful to each member of the Alpha Phi Alpha Fraternity, Inc for making this happen for me. I am thankful to have experience every piece of the process because I never thought that I would’ve been able to be a part of the wonderful ceremony at the Black & Gold Ball when my counselor first told me about the scholarship opportunity. I’ve always been a hardworking student and a relatively good student, but I knew the other candidates and figured it was worth giving it a try. I happen to be the first in my family to attend college and not just any college, but, my number one choice. I want to attend a four year school, get my Bachelor’s degree in Biology and continue into medical school or get into physician assistant school because i want to become a Physician’s Assistant. However, I’d like to be able to set a good example and become a positive role model for the younger generation to follow.”\nJordan Artis (2014 Scholarship Recipient)\n“Winning this scholarship really meant a lot due to my being from a low income family. The $2,000 awarded is going to help me further my education and a load off my hard-working mother. Thus I am really appreciative of Alpha Phi Alpha Fraternity, Inc. for granting me this scholarship, and I want them to know that it won’t go to waste.”""]"	['<urn:uuid:d6f1edec-7543-49d8-9ab5-c520a8f0995f>']	factoid	with-premise	short-search-query	distant-from-document	single-doc	novice	2025-05-13T01:50:22.828293	5	16	626
79	What material is required for posts on floating deck blocks?	Posts must be either naturally rot-resistant wood or pressure-treated wood for structural stability.	['When you’re planning an outdoor project, whether it’s a deck, balcony or island, your project’s longevity is only as good as its foundation. But when there are so many options to choose from, which one is best for your project and situation? Here’s a quick overview of some common options, including which ones are best in which situations.\nWhen you need solid piers for your project that do a great job of spreading out the weight of your porch in a single, monolithic piece of concrete, porch piers provide you with a great base. Because they’re pre-poured, they can be used to quickly set up a foundation, allowing you to immediately begin building. However, these pre-cast piers are all the same size at 5′ tall, and either require digging to bury them to the right depth up-slope or a level site to place them. Because they are one pre-cast piece of concrete they can be rather heavy to move, requiring the use of either a crew to move them into place or heavy machinery to make the job easier.\nWhen you want the advantage of cast-in-place concrete without the mess of forms, Sonotube’s round columns make the process much easier. If need be, you can cut the tubes down to shorter heights, allowing you to adapt the height of the tube to the slope of the land where your project is located. Designed to be buried, they give you the option to get below the frost line, while still being able to extend up to three feet above grade, providing you with some level of flexibility. The tubes are constructed from layers of high-quality fiber, spiral wrapped for strength and reinforced with a laminated layer of heavy-duty adhesive.\nIf you want the benefit of pre-cast concrete allowing you to work quickly without the heavy weight of piers, EZ-Tubes provide an excellent alternative. A pre-cast footer can be used to begin each column, spreading out the weight of the structure, while each short pier section may be stacked up to a maximum height, giving you the versatility of Sonotubes without having to wait for concrete to set before beginning construction. Finally, a threaded rod passes through the entire assembly to ensure it doesn’t shift with use.\nFloating Deck Block\nA floating deck uses pre-cast deck blocks on top of a layer of compacted stone dust upon which the deck will sit. These lightweight blocks are relatively easy to transport, but are primarily used for either decks that are very low to the ground or that can be supported using wood posts on top of the deck blocks. They are typically buried so that the slots for the rim joist or posts are around an inch or two above grade. Posts will need to be either naturally rot-resistant wood or pressure-treated wood for structural stability.\nEach of these options has benefits and drawbacks, but by considering your specific situation and project, you can find the perfect solution to create a solid base that will allow your investment to last for years to come. If you need help finding the right solution or have additional questions about these products, Poulin Lumber is here to help. Please feel free to reach out today to get started.']	['<urn:uuid:b2a4d779-07a6-4a3a-8548-dde7b4290922>']	factoid	direct	concise-and-natural	similar-to-document	single-doc	expert	2025-05-13T01:50:22.828293	10	13	542
80	What makes product testing important and what can go wrong?	Product testing through minimum viable products (MVP) is crucial to validate customer desires and prevent wasting resources on unwanted features. However, there are risks of market rejection - even with testing, companies may fail to generate sufficient revenue, face intense competition, or struggle to meet market demands, potentially leading to complete business failure.	['The Lean Startup by Eric Ries is based on the philosophy that in the current technologically advanced world, building a new business on a new idea is not a problem. The problem is the successful execution of the idea. The principles in The Lean Startup tells us how today’s entrepreneurs use continuous innovation to create radically successful businesses. So are you ready to learn the lean startup method?\n“A startup is a human institution designed to deliver a new product or service under conditions of extreme uncertainty”\nThe traditional image of a startup in the minds of people is a small company which is working on a project which is either trendy or related to technology. But according to the author, a startup is any business which is working on a product or service which did not exist until today. Since they are new kind of businesses, no prior knowledge of systematic execution, demand forecast, market potential and many other important aspects, create the conditions of extreme uncertainty.\nLearning is important for startups. Enormous learning is a part of a startup. But according to the author, learning should not be a waste of time. After the failure of startup, the entrepreneur should not give the excuse that even though the startup failed but at least he learned something. The time and money spent on developing a product before it’s launch are not coming back. Learning will not put the money in his pocket. Therefore instead of just learning, he should focus on Validated Learning.\nWhile working on his startup, whatever an entrepreneur learns should be validated. He should learn what will provide true value to your customers? What his customers truly want in the product? Which features they won’t mind being absent in the product? After finding what will be truly valuable and what is useless for his customers, he should focus on the aspects which are most valuable.\nLeap of faith\nEvery startup begins with a leap of faith that the product we are building will be desirable by the customers. It is the riskiest assumption which we are making about our idea. We can validate our idea by validating the two assumptions attached to it- The Value Hypothesis and The Growth Hypothesis.\nThe Value Hypothesis- This is the assumption about the value of our product. Would our product be valuable to our customers once they start using it?\nValue Hypothesis can be tested by creating a Minimum Viable Product (MVP). Create a product with sufficient features to satisfy early adopters. The feedbacks should guide the future development of the product. See how Dropbox created a minimum viable product in the form of a video. Thousands of people registered for the service after watching the video which proved that the service was actually valuable to the customers.\nGrowth Hypothesis- This is the assumption about the growth of our product. How would new customers discover our product?\nGrowth Hypothesis can be tested after knowing that how likely are early adopters are to recommend our product to others. Facebook and Whatsapp are the examples of validated growth hypothesis. Most of the users started using these services after their friends referred them. The results are in front of us.\nA/B testing is another method to acquire validated learning. In A/B testing we offer two variants of the same products to our customers. We then observe which variant is working better. In this way, we can know which is the best version of our product, straight from our customers. After knowing the best option, we can then implement it on our product.\nMany times startups spend months and years developing a product which nobody wants. They believe that what they are creating is something groundbreaking and customers will line up to buy their products. After spending months, when the completely finished product reaches into the hands of customers, they find that it is not at all desired by anybody. This is why validated learning is important. The Build-Measure-Learn feedback loop is used to attain and apply the desired validated learning in the successful launch of the product.\nSteps for using the Build Measure Learn feedback loop–\nPlan- Once you have the idea of a product, you need to test whether the idea will work or not. You will need some information which can validate your assumptions. In the planning phase, you need to specify that what are the pieces of information which you will need to ascertain your idea? For example- “Would the customers like to have this feature in our product?” or “Would the new user interface will increase user engagement on our site?”\nBuild- Now, after specifying about what are the pieces of information that you are looking for, build a minimum viable product. Just like Dropbox did in the above example. Include the 20% of the features which the 80% of users might like. Focus on early adopters at this stage. start taking feedback from your early adopters. Try to extract the information which you planned to achieve from this experiment.\nMeasure- After getting the information in stage 2, you need to measure the results. You need to measure the deviation from your hypothesis to actual results. Is your idea worth pursuing? Can you convert it into a profitable business? These are the main metrics which you need to measure.\nLearn- After measuring the results of your experiment, you will come in the ‘Learn’ phase where you have acquired sufficient learnings to make sound decisions. Here you are equipped with the right set of information which will help you decide how to move further with your idea.\nNow after learning the lessons, start with the loop again and try to get as close as possible to a perfect product.\nPersevere or Pivot\nAfter a cycle of Build Measure Learn Feedback Loop, you can either of the take two decisions- Persevere or Pivot.\nPersevere- If your test with the feedback loop gives a positive result then you can persevere your idea. But constantly going through the loop even after getting positive results will not only help you in generating a more refined idea, but it will also inform you at the right time if their arises a need to bring a change.\nPivot- When your hypothesis proves to be wrong, you will still know about the shortcomings of your idea because of the feedback loop. Readjust your idea and planning phase which you saw after getting valuable insights from the feedback loop.\nTo make your startup successful, try to fasten the process of going through the feedback loop and taking the decisions regarding Pivot and Persevere.\nSo, these were my key takeaways from the Lean Startup. Of course, you will need to read the book to get the whole grasp of all the techniques and method to make your startup work. The author Eric Ries has given many examples of the above ideas and there are many more ideas which you can learn from the book. I recommend you to read the whole book to get all the benefits.\nMore business related Book Summaries-', 'Investing in early stage companies is inherently high risk. You might lose your entire investment. Here we explain some of the risks. Please read these risks and take them seriously.\nThere are risks that you must consider when making an investment in a startup company or early stage company on Manhattan Street Capital. Investing in startups is very risky, speculative, and investments should not be made by anyone who cannot afford to lose their entire investment.\nCarefully consider the risks associated with the type of investment, security, and business before making any investment decision.\nPrincipal risk: Investing in startups will put the entire amount of your investment at risk. There are many situations in which the company may fail completely or you may not be able to sell the stock that you own in the company. In these situations, you may lose the entire amount of your investment. For investments in startups, total loss of capital is a highly likely outcome. Investing in startups involves a high level of risk and you should not invest any funds unless you are able to bear the entire loss of the investment.\nReturns risk: The amount of return on investment, if any, is highly variable and not guaranteed. Some startups may be successful and generate significant returns, but many will not be successful and will only generate small returns, if any at all. Any returns that you may receive will be variable in amount, frequency, and timing. You should not invest any funds in which you require a regular, predictable and/or stable return.\nReturns delay: Any returns may take several years to materialize. Most startups take five to seven years to generate any investment return, if any at all. It may also take many years before you will know if a startup investment will generate any return. You should not invest any funds in which you require a return within a certain timeframe.\nLiquidity risk: It may be difficult to sell your securities. Startup investments are privately held companies and are not traded on a public stock exchange. Also, there is currently no readily available secondary market for private buyers to purchase your securities. Furthermore, there may be restrictions on the resale of the securities you purchase and your ability to transfer. You should not invest any funds in which you require the ability to withdraw, cash-out, or liquidate within a certain period of time.\nInstrument risk: You may be investing in preferred equity, common equity, or convertible notes. These securities instruments all have different inherent risks caused by their structure. You should take the time to understand the nature of the securities instrument that you are investing in.\nDilution: Startup companies may need to raise additional capital in the future. When these new investors make their investment into the company they may receive newly issued securities. These new securities will dilute the percentage ownership that you have in the business.\nMinority stake: As a smaller shareholder in the business you may have less voting rights or ability to influence the direction of the company than larger investors. In some cases, this may mean that your securities are treated less preferentially than larger security holders.\nValuation risk: Unlike publicly traded companies that are valued publicly through market-driven stock prices, the valuation of private companies, especially startups, is difficult to assess. The issuer will set the share price for your investment and you may risk overpaying for your investment. The price you pay for your investment may have a material impact on your eventual return, if any at all.\nFailure risk: Investments in startups are speculative and these companies often fail. Unlike an investment in a mature business where there is a track record of revenue and income, the success of a startup often relies on the development of a new product or service that may or may not find a market. You should be able to afford and be prepared to lose your entire investment.\nRevenue risk: The company is still in an early phase, and may be just beginning to implement its business plan. There can be no assurance that it will ever operate profitably. The likelihood of achieving profitability should be considered in light of the problems, expenses, difficulties, complications, and delays usually encountered by companies in their early stages of development. The company may not be successful in attaining the objectives necessary for it to overcome these risks and uncertainties.\nFunding risk: The company may require funds in excess of its existing cash resources to fund operating expenses, develop new products, expand its marketing capabilities, and finance general and administrative activities. Due to market conditions at the time the company needs additional funding, it is possible that the company will be unable to obtain additional funding when it needs it, or the terms of any available funding may be unfavorable. If the company is unable to obtain additional funding, it may not be able to repay debts when they are due or the new funding may excessively dilute existing investors. If the company is unable to obtain additional funding as and when needed, it could be forced to delay its development, marketing and expansion efforts and, if it continues to experience losses, potentially cease operations.\nDisclosure risks: The company is at an early stage and may only be able to provide limited information about its business plan and operations because it does not have fully developed operations or a long trading history. The company is also only obligated to provide limited information regarding its business and financial affairs to investors.\nPersonnel risks: An investment in a startup is also an investment in the management of the company. Being able to execute on the business plan is often an important factor in whether the business is viable and successful. You should be aware that a portion of your investment may fund the compensation of the company’s employees, including its management. You should carefully review any disclosure regarding the company’s use of proceeds. You should also carefully consider the experience and expertise of the management team.\nFraud risks: It is possible that certain people involved in the company may commit fraud or mislead investors. If fraud or misleading conduct occurs, then your total investment may be lost. You should carefully review any disclosures regarding the company’s management team and make your own assessment of the likelihood of any potential fraud.\nLack of professional guidance: Many successful startups partially attribute their early success to the guidance of professional investors (e.g., angel investors and venture capital firms). These investors often play an important role through their resources, contacts, and experience in assisting startup companies in executing their business plans. A startup company primarily financed by smaller investors may not have the benefit of such professional investors. You should consider the existing professional investors in the company and whether or not they or any other professional investors are participating in the current round.\nGrowth risk: For a startup to succeed, it will need to expand significantly. There can be no assurance that it will achieve this expansion. Expansion may place a significant strain on the company’s management, operational and financial resources. To manage growth, the company will be required to implement operational and financial systems, procedures and controls. It also will be required to expand its finance, administrative and operations staff. There can be no assurance that the company’s current and planned personnel, systems, procedures, and controls will be adequate to support its future operations. The company’s failure to manage growth effectively could have a material adverse effect on its business, results of operations, and financial condition.\nCompetition risk: The startup may face competition from other companies, some of which might have received more funding than the startup has. One or more of the company’s competitors could offer services similar to those offered by the company at significantly lower prices, which would cause downward pressure on the prices the company would be able to charge for its services. If the company is not able to charge the prices it anticipates charging for its services, there may be a material adverse effect on the company’s results of operations and financial condition.\nMarket demand risk: While the company believes that there will be customer demand for its products, there is no assurance that there will be broad market acceptance of the company’s offerings. There also may not be broad market acceptance of the company’s offerings if its competitors offer products which are preferred by prospective customers. In such event, there may be a material adverse effect on the company’s results of operations and financial condition, and the company may not be able to achieve its goals.\nControl risks: Because the company’s founders, directors, and executive officers may be among the company’s largest stockholders, they can exert significant control over the company’s business and affairs and have actual or potential interests that may depart from yours. The company’s founders, directors, and executive officers may own or control a significant percentage of the company. In addition to their board seats, such persons will have significant influence over corporate actions requiring stockholder approval, irrespective of how the company’s other stockholders, including you, may vote. Such persons’ ownership may also discourage a potential acquirer from making an offer to acquire the company, which in turn could reduce the company’s stock price or prevent you from realizing a premium on your investment.']	['<urn:uuid:9cc34140-4e33-4aa8-8b18-06026f4b1f2e>', '<urn:uuid:3289e71f-ea58-4fd9-a5b8-46a1ff7cc86a>']	factoid	direct	concise-and-natural	distant-from-document	multi-aspect	novice	2025-05-13T01:50:22.828293	10	53	2753
81	iona wildlife marine coastal habitat features	Iona's coastal environment hosts diverse wildlife including dolphins, seals, otters, and various bird species like cormorants and terns. As part of Argyll and Bute's marine ecosystem, the surrounding waters are important for marine life observation, with 23 whale species, basking sharks, and dolphins recorded in the area. The coastline is considered one of Scotland's most outstanding scenic assets, containing vital marine and coastal habitats that attract thousands of visitors annually and require conservation measures.	"['Isle of Iona\nMachair,The Bay at the Back of the Ocean, Port Ban, Columba\'s Bay and Marble Quarry\nI Chalium Cille - The Isle of Columcille - St. Columba\nMAP OS EXPLORER 373 Iona, Staffa and The Ross of Mull; OS 341 Iona and Bunessan. Columbas Bay only (excluding quarry ) 3 hours return; approx 8.5 km terrain; minor road, moor and rough shore path\nClick on photos to enlarge For information about Iona read more\nVisitors are not allowed to take their vehicles onto Iona. Cyclists are welcome and there are many tracks ideal for both cycling and walking. Take a 2 minute walk from Seaview onto the Fionnphort - Iona ferry which runs frequently across the Sound of Iona. Stout walking shoes and warm clothing required on windier days\nAs you leave the ferry, turn left and follow the metalled road past Martyrs Bay beach, the fire station and Traigh Mor beach. In summer listen out for the monotonous cry of the corncrake in the iris beds between the shore and the road and in the fields. The road follows the shore south for half a mile and then turns right and crosses the island west to the gate at the Machair. Go through the gate onto the short sand based springy turfed grass called machair very fertile and found along Scottish Atlantic coasts.. This is the West Machair where cows and sheep graze. If machair is not grazed wild flowers are abundant and the colours and variety are often amazing.\nThis forms the basis of the informal Iona Golf Course which looks onto one of the finest beach views anywhere with the Camus Cuil an Tabibh (Bay at the Back of the Ocean)forming the backdrop. (See main header photo above.)What a lovely quaint name for a spectacularly scenic beach!Turning south on a breezy day with a westerly Atlantic swell you will see a fountain plume of spray rising above the cliffs.This is a natural occurance called ""The Spouting Cave"" and it can be seen from Dun I two miles away. Now follow the rough track in the machair due south to where the ground rises onto moor. As you approach the hilly moor you will see the track in the hillside to Columbas Bay. Following the track\nsouth over the hill you will come to a small lochan which is to the right of the path. This is Loch Staoineig and used to be the reservoir for Iona. Keeping the lochan on your right descend slowly down the path to Port na Curaich (Port of the Coracle) known as St Columba\'s Bay. It is said that St Columba landed his coracle here in 563AD after being banned from the Emerald Isle. There are lovely views from here to Soa Island (Sheep Island) and Eilean Musimal (Mouse Island). There is also Eilean na h-Aon Chaorach known locally as \'one sheep island\', which was worked by the innkeeper at Iona cottage on the village pier. Columbas Bay is a peaceful lonely spot and must have been an oasis of calm after Columba and his followers had navigated the treacherous waters of South Iona and the Soa sound. The tidal currents all meet here from 3 or 4 directions and around the corner to the west is a channel called ""The Boiling Pot"", which says it all. John used to have exciting days fishing. for\nlobsters here! Columbas Bay is a popular place of pilgrimage and pilgrimsand tourists can often be seen hunting at the low water mark looking for coloured stones and in particular green serpentine pebbles. Best time for this occupation is early spring after the winter Atlantic gales have stirred up the shore stones and pebbles. These pebbles were allegedly piled high by monks as a penance for their sins.On leaving Columba\'s Bay the easiest way back to Baille Mor village is to retrace your steps. For the more adventurous you can proceed to The Marble Quarry on the south east side of the island but beware this is a more strenuous walk and for the fit more experienced walker only and is described in the section below. If the last ferry leaves in two hours or less return by the outward route and come back to do the quarry walk another time.\nDolphins, seals, otters, cormorant, shag, eider, buzzard, ring plover, lapwing, black backed and herring gulls, rock dove, jackdaw, starlings, linnet, twite, yellowhammer, terns , grey plover, sanderling and godwits.\nLast amended 09/05/2021\nMarble Quarry, Rubha Na Carraig Geire, Iona\nOS EXPLORER 373 IONA STAFFA ROSS OF MULL NM 268 217\nThe abandoned quarry lies south of Druim Dhughaill on the south east coast not far from Columba s Bay To find the quarry from Columbas Bay retrace your steps back up onto the machair behind Columbas bay shoreline, following the path you came down for 100 yards approximately . At the point the flattish grass is about to be replaced by a steeper rocky section of the path, approximately 150 yards from the beach, at this point a smaller path veers east up the 3rd gully from the shore. A shallow gully with boulders, heather and grass a rough path winds its way up to a grassy valley running east to the cliffs and shoreline. After about 100 yards in the valley the path goes through a broken wall and bears slightly left,pass an inlet on the shore (on your right) through some rough heather, bear left for 400 yards above a sea cliff and you come to a hollow where there are two old ruined stone\ncottages called in gaelic ""Tobhta nan Sassunaich"" which translates as house of the lowlanders. One of the cottages was living area and the other accommodation for the quarry workers. At the cottages turn right and south south east you will see a deep gully running down to the sea, the quarry machinery and workings are at the bottom of the gully next to the sea. At the quarry you can see cut stone with holes for gunpowder, white cut block waste stone, machinery including remains of a 1880 producer gas engine manufactured by Fielding and Platt, of Gloucester a cutting frame by G Anderson of Arbroath, rail trolley wheels, winch, water tank and iron anchor points in a natural stone pier where boats transported the marble to the mainland.. These items have been given a coat of black paint to stop them rusting further. The quarry is unique and in 1992 was\nmade a SCHEDULED ANCIENT MONUMENT. The quarry is of national importance because it is the only early\n20th century quarry retaining original machinery. Also marble quarrying has been rare in Scotland The quarry was set in the ravine and each side of the ravine is marble and you can see evidence of the working on each side. The marble is white in colour streaked and mottled with yellow-green serpentine. The outcrop was believed to be 7m wide by 100 meters long. The communion table and baptismal font in the IonaAbbey are both carved from Iona Marble quarried on the island. The quarry may date back to the medieval age. The Marquess of Breadalbane\nworked the quarry in 1745 , however machinery was first installed about 1790 by the 5th Duke of Argyll,\nindustrialist William Cadell and Swiss geologist Rudolf Raspe. However it was un economical and closed a few\nyears later. There was a failed enterprise by The Argyll Quarry Company in the 1800s, who tried to ship on an industrial scale but the remote rocky location proved too hazardous for shipping.It re opened in 1907 but was again closed in 1915. On leaving the marble quarry go back up the the gully you came down earlier to the ruined quarry mans cottages. Keep the cottages to your left and pass them in aapproximately northerly direction for 200 yards up the rough hill track through\nanother shallow gully to a wooden fence post. At this point you can bear left in a north north west direction along a sheep trail and over a shallow hill and ravine keeping a sheep\nfence on your right hand side and meet the Columbas Bay path just south of Loch Staoineig and return to the village the same way that you came.\nAlternatively at the wooden post. walk in a roughly north easterly direction on the rough sheep paths picking your way through the odd bog and\nrough boulders aiming for the coastal high point in front of you, Druim Dhughaill keeping to the right of a northerly running sheep fence. The views from this summit are fabulous. To the north Iona village, Baille Mor, and Iona Abbey. To the north east the azur blue waters of the Iona sound,The Red granite of the Ross of Mull, the moody Ardmeanach cliffs, and majestic Ben More Mull, to the east and south the rugged Isle of Erraid, Torran rocks with the Paps of Jura and the whisky island Islay in the back drop. On a very clear day looking south and south west you can see Stevensons Dubh Artach Lighthouse and even the north coast of the Emerald Isle where Saint Columba came from in his wee coracle all those centuries ago.\nwest to east find a metal gate NM276232 which leads to a track that passes Ruanaich farm to the tarred road of the outward walk. For an\nalternative scenic route looking over the village and sound of Iona back to the village, cross the tar road and follow the farm track north to Maol farm where you go through the farm with the track bending first right and then gently left down to the village hall behind the nunnery. Head east past the ruined nunnery and Spar shop down the tar road to the center of the village (Baille Mor) and Iona pier.', ""Biodiversity Technical Note for Planners and Developers\nOur Biodiversity Technical Note is aimed at planners, developers and householders thinking about new-builds, renovations or extensions, to help them protect, enhance conserve and restore our biodiversity during the planning and development process. It also provides essential information on what habitats and species require survey work. Key elements of the new document are a Biodiversity Checklist and a checklist for Invasive Non-Native species - which will help in the basic assessment of any proposed site.\nPhase 1 Habitat Surveys for Community Groups\nPhase 1 Habitat Surveys are environmental audits that categorise the different habitat types and features within a survey area, before development or building work is done, to let you know of any potential ecological issues\nWhy is Biodiversity important in Argyll and Bute?\nAccording to experts, Argyll and Bute is considered to be a biodiversity hot spot with some of the best examples of a range of Land, Freshwater and Marine and Coastal Habitats and Species in the UK.\nThe many natural influences which have shaped our landscape as well as the myriad of man's activities, make Argyll and Bute unique.\nThe terrestrial environment in Argyll is made up of a complex mosaic of forestry, hills and moorland, farmland and peatlands patterned by lochs and rivers. Argyll has a diversity of agricultural interests in the form of crofting, farming and estate. Our woodlands and forests cover 30% of Argyll and Bute, totalling 2000 square kilometres representing 15% of Scotland’s total forest resource. Around 85% is comprised of productive coniferous forests; with the remainder comprising of semi-natural and native woodland made up of birch and Atlantic oak-woods. We have 37,500ha of ancient woodland of which 27,000ha is semi-natural in origin.\nOver 50% of the rest of Argyll and Bute is a mosaic of heather moor/peatland, rough grassland and bracken scrub. A number of species associated with these habitats are the Golden Eagle (Aquila chrysaetos), and Black Grouse (Tetrao tetrix), Marsh Fritillary (Euphydryas aurinia), and mammals such as the Red Squirrel (Sciurus vulgaris) and Pine Martin (Martes martes).\nThe freshwater environment in Argyll is varied, ranging from large lochs and rivers with medium water chemistries to tiny nutrient-poor, peat-stained lochans. Argyll contains the longest freshwater loch in Scotland (Loch Awe - 41kms) and the loch with the greatest surface area (Loch Lomond - 71kms²). The Freshwater Pearl Mussel (Margaritifera margaritifera) an internationally important species, the Atlantic salmon (Salmo salar) and the Powan (Coregonus lavaret) are three such species associated with some of our river and loch systems. These freshwater inhabitants are good examples of why Argyll is important for biodiversity, but also why action is required to protect these resources.\nMarine and Coastal Ecosystems\nThe coastline of Argyll and Bute is one of its most outstanding scenic assets, attracting thousands of visitors annually from all over the world. The coastline contains many habitats and species, some vitally important and rare marine and coastal habitats which include the strange and unique Serpulid reef in Loch Creran.\nFrom a marine activities perspective, this area of the west coast of Scotland is very important for its wide range of marine life which supports a number of diverse interests including fishing, diving, whale and dolphin watching and research. Apart from the ever increasing numbers of seals, twenty three species of whales, basking shark and dolphins have been identified in British coastal waters, and all have been seen off Argyll. Some of the best areas to spot these animals on a regular basis are just off the islands of Coll and Tiree for Basking Shark (Cetorhinus maximus), Killer Whale (Orcinus orca), the Common Dolphin (Delphinus dephis) and the Harbour Porpoise (Phocoena phocoena). Although these animals do not spend all year in Argyll and Bute waters, they are very important icons for Biodiversity and an increasing whale, dolphin and shark- watching tourist market is growing in the area.\nOn shore, the habitats of the coastal region support many important animal and plant communities. The world famous machair habitat is well represented in Argyll with 14% of the Scottish total, and equivalent to 10% of the world resource. This habitat is extremely important for a number of plants and animals, not least the Corncrake (Crex crex) and Great Yellow Bumblebee (Bombus distinguendus). The machair of CoIl and Tiree is amongst the most important remaining strongholds for these globally-threatened species. Other Argyll islands and parts of the mainland are also crucial in securing the recovery of Corncrake.\nEcosystems- What are they?\nAn ecosystem is a dynamic complex of plant, animal and micro-organism communities and their non-living environment, all interacting as a functional unit. This approach recognises that habitats and species cannot be considered in isolation but are dependent on maintaining healthy ecosystems, and that the threats and pressures upon these parts of ecosystems need to be addressed in a coordinated way and at appropriate levels.\nCurrent Action for Biodiversity\nThe Argyll and Bute Local Biodiversity Action Plan was first published in 2001 following the guidance set out by the government to focus on action plans under the headings of Land, Freshwater, and Marine and Coastal. It was refreshed under the Ecosystem approach in 2010 and is currently being re-drafted as an interim refresh to align it with the Scottish Biodiversity Strategy 2020.\nThe biodiversity process in Argyll and Bute seeks to maintain and enhance our extensive variety of habitats and species. It involves many government, non-government agencies, community groups and individuals.\nIn Argyll and Bute there are many examples of good practice in the management of our habitats and species. A number of schemes provide financial support for the crofting and farming communities to contribute to the conservation, restoration and enhancement of many habitats and species.\nIn terms of biodiversity application, we input into the Development and Implementation of the Local Development Plan along with the promotion of the Biodiversity Technical Note for Planners and Developers\nFor further information on biodiversity in Argyll and Bute, please contact our Local Biodiversity Officer.\nBiodiversity Duty Reporting\nThis Report presents the Argyll and Bute Council Biodiversity Duty Compliance Report 2014 - 2017 which forms part of the National reporting and auditing of the Biodiversity Duty by public bodies and is now required by the Wildlife and Natural Environment Act (2011) Scotland.\nIt reflects agreed activities as set out in the Argyll and Bute Biodiversity Duty Action Plan 2016 - 2020 under the Nature Conservation (Scotland) Act 2004 which places a duty on all public bodies to further the conservation of biodiversity""]"	['<urn:uuid:dd57fff0-3a08-4f81-b491-89e43b6017e3>', '<urn:uuid:cd5ecf01-3426-4775-a530-6ad19406f952>']	factoid	with-premise	short-search-query	similar-to-document	multi-aspect	expert	2025-05-13T01:50:22.828293	6	74	2732
82	I'm troubleshooting audio input issues in Garageband and need to optimize my recording levels - where exactly can I find and adjust the input level settings?	In Garageband, you can adjust input levels through the Track Info pane. Click on the Details tab and you'll find the input level slider, which you can adjust until your voice reaches an optimal volume. You should test the levels by recording a short sample and listening to it to ensure clear and balanced sound.	['How to Improve Voice Recording Quality in Garageband\nIf you are a music enthusiast who loves to create and produce your own music, then Garageband is the perfect software for you. Garageband is a music production software developed by Apple, which allows users to create, edit, and mix music on their computers. While Garageband is primarily known for its ability to create instrumental tracks, it is also a great tool for recording vocals. In this article, we will discuss some tips and tricks on how to improve voice recording quality in Garageband.\n1. Use a High-Quality Microphone\nThe first step to improving your voice recording quality in Garageband is to invest in a high-quality microphone. A good microphone will capture your voice accurately and produce a clear and crisp sound. There are many options available in the market, ranging from USB microphones to XLR microphones. Choose a microphone that suits your needs and budget, and make sure it is compatible with your computer.\n2. Set Up a Proper Recording Environment\nThe environment in which you record your voice plays a crucial role in the overall recording quality. Find a quiet room or space where you can record without any background noise or distractions. Use soundproofing materials such as acoustic panels or foam to minimize echo and reverberation. Position your microphone at an optimal distance from your mouth to capture your voice clearly without any distortion.\n3. Adjust the Input Levels\nIn Garageband, you can adjust the input levels to ensure that your voice is neither too soft nor too loud. Open Garageband and go to the Track Info pane. Click on the Details tab and adjust the input level slider until your voice is at an optimal volume. Make sure to test the levels by recording a short sample and listening to it to ensure that it sounds clear and balanced.\n4. Use EQ and Compression\nGarageband offers a range of audio effects and plugins that can help enhance the quality of your voice recordings. One of the most useful tools is the EQ (Equalizer), which allows you to adjust the frequency balance of your voice. Use the EQ to boost or cut specific frequencies to make your voice sound more natural and balanced.\nAnother important tool is compression, which helps to even out the dynamic range of your voice. This means that softer parts of your voice will be amplified, while louder parts will be reduced, resulting in a more consistent and polished sound. Experiment with different compression settings to find the right balance for your voice.\n5. Edit and Clean Up Your Recordings\nAfter recording your voice in Garageband, it’s important to edit and clean up your recordings to remove any unwanted noise or imperfections. Garageband offers a range of editing tools such as noise reduction, fade in/out, and trimming. Use these tools to remove any background noise, clicks, or pops, and to ensure a smooth and seamless recording.\nBy following these tips and tricks, you can significantly improve the voice recording quality in Garageband. Remember to invest in a high-quality microphone, set up a proper recording environment, adjust the input levels, use EQ and compression, and edit and clean up your recordings. With practice and experimentation, you will be able to achieve professional-sounding voice recordings in Garageband.\nFor more information and tutorials on Garageband, visit our FAQ page. To learn more about our website and the services we offer, visit our About page. Stay updated with the latest music production tips and tricks by visiting our Blog.\nFor additional resources on music production and recording techniques, check out Sound on Sound, a high-ranking website that provides in-depth articles and reviews on various aspects of music production.']	['<urn:uuid:faf8f939-e578-406b-9286-5655d777bf20>']	factoid	with-premise	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-13T01:50:22.828293	26	55	619
83	What are the current conservation challenges in Spanish mountain regions, and how are they connected to economic impacts on tourism and agriculture?	Spanish mountain regions face multiple conservation challenges including mountain tourism development, ski facilities, and road construction that are severely degrading forest ecosystems. Road construction and clear-cutting on steep slopes have caused serious landslides, while forest fires, intensive logging, overgrazing, and unsustainable plant collection threaten biodiversity. These environmental pressures are closely tied to economic concerns, as climate change could significantly impact Spain's tourism industry through increasingly hot and dry summers, leading to potential losses of up to €5.6 billion annually in tourism revenues. Agricultural productivity is also at risk, with traditional crops like Andalusian olives, lemons, and La Rioja vineyards threatened by rising temperatures. Protected areas have been established under the Birds Directive, including Sierra Nevada and Sierras de Cazorla, but human impact remains high.	['Realm: Western Eurasia\nEcoregion Size (1000 ha):\nThis ecoregion is distinguished by high mountain ranges, huge pine forests, and deep canyons. In winter, snow commonly covers the peaks, and in summer, extreme drought can persist. Not only is this one of the richest places of floral endemism in Europe, it is also home to over one hundred and fifty bird species, including the vulnerable Spanish imperial eagle and golden eagle. There are also a number of endemics including the Iberian Ibex and the Cyren’s rock lizard.\nThe ecoregion spreads geographically all along the main central eastern (Guadarrama, 2,430 m; Gúdar, 2,019 m) and southeastern (Cazorla, 2,107 m; Sierra Nevada, 3,482; Baza, 2,271 m) mountain ranges of Spain. The ecoregion experiences an arid Mediterranean climate, particularly in the Sierra Nevada and Cazorla mountain ranges. The average annual rainfall is 1,100 mm, but in certain high altitudes levels can exceed 1,500 mm. Snow falls frequently during winter and minimum average temperatures are below freezing (-5 to 0°C).\nThe landform is distinguished by an abundance of deep canyons and other karstic landscapes in the calcareous massifs. The wide altitudinal range of this ecoregion results in two major forest zones: a conifer zone, typical of higher elevations (between 1,200-2,500 m), and a mixed broadleaf zone, which occurs at medium to low elevations. Within the mountain conifer forests are the endemic Salzmann pine, Scots pine, and maritime pine. Canyons host important relict species such as yew, large-leaved lime, and aspen. Evergreen oaks, mainly holm oak are abundant in dry and rocky south-facing slopes.\nThere is high species richness and endemism amongst the plant species in these mountain regions. The south of Spain is one of the most important centers of plant diversity of the Mediterranean basin, hosting many rare or threatened species. In particular, there are more than 2,100 vascular plants in Sierra Nevada making it one of the most important mountain ranges in the West Mediterranean Basin. The ecoregion also hosts a very high faunal diversity, mainly in regard to birds. More than 150 species have been recorded for certain mountain ranges, including the black vulture, griffon vulture, black-shouldered kite, black stork, and honey buzzard.\nAmong the large mammals are the endemic Iberian ibex and grey wolf. Small mammals also include a number of endemic subspecies such as the European snow vole. A number of important endemic amphibian and reptile species appear in high mountain lakes, meadows, and rocky areas including Cyren’s rock lizard and Almanzor salamander.\nVegetation dynamics in this ecoregion have been largely driven by land-use management and human activities, particularly after an abandonment of traditional activities. In mountainous areas in southeastern Spain, significant land-use changes occurred in the past 50 years, including a decrease in dryland farming, increase in woodlands and agriculture intensification. Much of the ecoregion today and remaining forest stands are protected as special protection areas under the Birds Directive including Sierra Nevada, Serranía de Cuenca, Alto Tajo, Sierras de Cazorla, and Segura y Las Villas.\nCurrent human impact is still high in this ecoregion. Mountain tourism, ski facilities, and road construction are severely degrading large mountain forest ecosystems. Due to the soil instability of the steep mountain slopes, road construction and clear-cutting operations have provoked serious landslides. Other primary threats include forest fires, overly intense and inadequately managed logging operations, overgrazing and unsustainable plant-collecting.\nOver the last few decades, there has been increased severity of droughts which has changed the vegetation dynamics with drought-tolerant species dominating. This may also have an impact on the fire regime. Key threats to the Spanish imperial eagle are habitat loss from urban development, wind farms and solar plants, and land management changes of sport-hunting estates to favor deer and wild boar.\nThe priority conservation actions for the next decade will be to: 1) allow the recolonization of understory oaks in pine forest management to increase lizard diversity and other species diversity, as well as the added benefit of reducing fire frequency; 2) establish agreements with private landowners and provide advice on habitat management to include non-monetary compensation and improvements for properties that cooperate in protecting the species;iv and 3) integrate socio-economic indicators relating to climate change into protected area management planning.\n- Peñas, J., Pérez-García, F.J. and Mota, J.F., 2005. Patterns of endemic plants and biogeography of the Baetic high mountains (south Spain). Acta Botanica Gallica, 152(3), pp.347-360.\n- Vidal-Macua, J.J., Ninyerola, M., Zabala, A., Domingo-Marimon, C. and Pons, X., 2017. Factors affecting forest dynamics in the Iberian Peninsula from 1987 to 2012. The role of topography and drought. Forest ecology and management, 406, pp.290-306.\n- WWF. 2019. Iberian Conifer Forests. [Online]. [Accessed 6 August 2019]. Available from:', 'Climate Change Issue in Spain: Temperature Incensement\nNowadays mankind is facing huge global ecological problems, most of which are the results of people’s activity. One of such problems is climate change occurring worldwide. A variety of countries suffer from damages caused by climate change, and the main focus of this research paper is to examine these issues in Spain. Over the past 100 years, average global temperature in Europe increased by 1.2C, the 1990s were the warmest decade in the last 150 years. It has been predicted that the average temperature in this region will increase by 1.4-5.8C during 1990-2100. The largest increase is expected in Eastern and Southern Europe. In such a context, Spain is a relevant example of a country that faces and copes with major climate changes. It also has to be mentioned that since 1980 half of the glaciers in Spain have melted. This paper describes major climate changes in Spain, specifies the country’s major climate change – the one in temperature, as well as defines and explains environmental, social, and economic aspects of this issue.\nSpain is a country located in southwestern Europe and, partly, in Africa. Spain is one of the warmest countries in Southern Europe. The average number of sunny days equals 260 to 285. The average annual temperature on the Mediterranean coast is 20C. Usually, in winter, the temperature decreases below 0C only in the central and northern parts of the country. In summer, the temperature rises up to 40C and higher (from the central part to the southern coast). On the northern coast, the temperature is not so high – only about 25C.\nThe climate of Spain is considered one of its most important natural resources. The country occupies the first place in Europe based on the number of sunny days per year. Spain is almost completely located in the subtropical climate zone and its natural conditions are similar to other Mediterranean countries, but differ in respect of being close to the Iberian Peninsula. The proximity to Africa and the influence of steep terrain and extensive adjacent waters of the Atlantic Ocean and the Mediterranean Sea play crucial role in the country’s climate formation.\nSpain will reach the temperature of North Africa by 2050 if climate continues changing at the current rate. The report, prepared by Cambio Climático and measuring climate changes since 1950 with a forecast up to 2050, warns that some of the most popular and successful agricultural crops of Spain may be at risk if nothing is done to prevent change of the climate in the country. Andalusian olives, lemons and even famous Valencian vineyards of La Rioja may be at risk if the temperature increases similar to Morocco’s. In Europe, the rate of warming is higher than on other continents, and the hottest decade for European countries was in the years 2002-2011.\nIn Spain, the situation is more serious than in other countries as its temperature has risen by an average of 0.5C, whereas in other countries – 0.2C per decade since the beginning of the 20th century. In addition to the decline in rainfall since 1950, it becomes clear that Spain has become much warmer and drier.\n“The new report shows that climate change is the reality of Spain”, says Jonathan Gomez Cantero, who worked on the report. ‘People need to be informed and know the reality of this phenomenon. If the temperature in Southern Europe increases only by two degrees, it will be equal to the temperature in North Africa’.\nHeat waves are periods of abnormally high temperatures causing a range of negative consequences from destruction of crops to increased mortality. In Spain, heat waves are becoming more and more common. One of them, in July 2009, severely damaged the planting pepper plantation in Miguel Campa. In the years 1961-1990, heat waves lasted for an average of two days a year, while in the years 2021-2050, according to experts, the period will become 13 days long. According to the same forecasts, the number of days with temperatures above 40.6C (the value of possible drastic violation of thermoregulation when vital human organs cannot function normally) in the Mediterranean countries will increase to 16 a year by 2070.\nClimate change in Spain has a negative impact on the economy, because the main part of the state budget’s profit consists of winemaking. The consequences of rising temperatures include overmaturity of grapes, drying, increase in acidity and vulnerability to pests and diseases. High levels of carbon dioxide accelerate the process of photosynthesis, which leads to a change in the process of rising and maturation of wine grapes. In addition, due to the high temperatures, the harvesting season might shift from early October to September. These changes may adversely affect the taste and vitality of grapes. More hot weather will cause a reduction in the acidity of grapes and, accordingly, a significant change in the taste of wine.\nSpain’s tourism industry could be at risk as well. The reason of this is behind climate change that causes increasingly hot and dry summers. This could potentially lead to higher rates of drought, forest fires and loss of some wild animals. In addition, the temperature which is too hot makes visiting the Mediterranean countries at the height of season less comfortable. These factors have the potential to make Spain less attractive to tourists, while the countries located to the north, with more moderate summers, can get, as a result, growth in tourist revenues. It is estimated that the Southern Mediterranean countries may lose tourism revenues amounting to 0.45% of GDP annually. For Spain, this may mean the loss of up to €5.6 billion annually.\nThe Spanish government approved a list of measures to combat climate change. The list consists of eighty points and is particularly aimed at reducing emissions of greenhouse gases. The Spanish are going to cut the 2012 emissions of greenhouse gases by 37% to meet the Kyoto Protocol requirements. The government decided to encourage purchase of vehicles that are less polluting. At the same time, the ‘dirty’ vehicles purchase tax was significantly increased. The owners of vehicles in which the amount of carbon dioxide is less than 120 grams per kilometer will not pay the tax, while the drivers whose number is 120-160 grams will have to pay 4.75% of the vehicle price, 160-200 grams – 9.75%. About 56% of cars in Spain are classified as highly pollutant. The government decided to spend 2.5 billion Euros on the development of renewable energy sources, the ban on weekend pipes in 2012 and gradual transition to cars on biofuels.\nThus, the climate change issue in Spain is very serious. It affects not only people’s lives, but the country’s economy as well. If Spanish government does not implement measures against the climate change issues, the future of the country will be sorrowful. But, as long as the government is aware of this problem and actively fights climate change by introduction of sets of measures, the situation can be successfully changed.']	['<urn:uuid:3764f2fc-3ea5-44fc-ac39-4c79662023c7>', '<urn:uuid:92ff7d38-a344-42cf-8c00-28b91d351e83>']	open-ended	direct	verbose-and-natural	similar-to-document	multi-aspect	expert	2025-05-13T01:50:22.828293	22	124	1944
84	substitute for regular pool buoys workout	You can substitute regular pool buoys with bottled water for aquatic workouts. The water bottles float in the pool and are affected by buoyancy forces, similar to regular buoys. However, when using water bottles instead of regular buoys, it's recommended to slow down the cadence, teach more movements at slower water tempos, and use music with a lower BPM than the 135bpm used in example workouts.	['Short on buoys? Italian Aqua Training Specialist, Antonio Russo, demonstrates how you can substitute bottled water for hand held equipment in his video, Aqua Bottle Training. This fun water workout features aqua choreography for upper & lower body and core. The choreographed sequences in this video can also be performed without equipment, using only the water’s resistance.\nThe use of non-traditional equipment in the pool is not for everyone. I heard the complaints regarding the plastic shopping bag workout loud and clear. However, I remain committed to showcasing aqua innovation on an international scale. The Frisbee workout from Israel. The plastic shopping bag workout from Belgium. And now the water bottle workout from Italy. These workouts represent creative solutions to low funding and scarce equipment, a struggle that instructors all across the globe share. Creative innovation deserves a spotlight. (No doubt, I would get way more complaints if I posted videos that featured exorbitantly expensive equipment!)\nRegardless of whether you use water bottles or substitute with other equipment, or use no equipment at all; Aqua Bottle Training is another example of superbly taught choreography. Not crazy about the water bottles? Skip them and instead focus on HOW Antonio teaches the movements in this video. In each of the segments, he spends a few minutes introducing the base moves of that segment. Once the base moves are established, he builds a combination of the base moves at 16 or 32 counts of music per move – and then he reduces to 8 or 16 counts of each move. And then the key to watch for here is how he LAYERS some of the base moves with a slight change involving travel, arms or cadence. The end result is that a few moves go a long way towards creating an entire class of excitement and engagement.\nAQUA BOTTLE WORKOUT: AT A GLANCE\nThis segment features an introduction of base moves, which are then taught in a sequenced combination with some layering.\nChest, Back & Shoulders\nSame as the warm-up, this segment features an introduction of base moves, which are then taught in a sequenced combination with some layering.\nIn this segment, two combinations of arm movements are taught.\nLegs & Abs\nThis segment features movements for the legs and core by placing a water bottle first behind one leg and then between both legs.\nA rhythmic, freestyle cool down is offered.\nIMPORTANT INSTRUCTION REMINDER: Please use common sense and modify the exercises, the cadence and the techniques demonstrated in this video to accommodate your population. Aquatic fitness is taught very differently across the globe. In many European countries, classes are taught late in the evenings, thus attracting a younger audience.\nEQUIPMENT SUBSTITUTE: A bottle of water FLOATS in the pool and thus the forces of buoyancy affects it. All equipment use encounters drag forces as well. A set of small hand buoys would be an acceptable substitute. However, please consider slowing the cadence down. Teach more movements at the slower water and half water tempos. Choose music with a lower BPM. The BPM used in the video was 135bpm. Personally, I would teach the upper body moves without equipment as well because the choreography is fun and challenging with just the water’s resistance.\nFitmotivation.com would like to extend a big THANK YOU to Antonio Russo for providing video viewers with an innovative workout using non-traditional equipment. Connect with Antonio on his Facebook page and say hello to both him and AndreaGilardoni at theInternational Aquatic Fitness Conference (IAFC).']	['<urn:uuid:9f9dfb4b-c463-44a9-bd9e-f13eaa776671>']	open-ended	with-premise	short-search-query	similar-to-document	single-doc	novice	2025-05-13T01:50:22.828293	6	66	585
85	What are the key components that must be included in a configuration management plan according to industry standards?	A configuration management plan must include: what will be managed (list and organize CIs), who will be responsible for activities (roles and tasks), how to make it happen (processes for change requests, task dispatching, monitoring, testing, release), what records to keep (logs, notes, configurations, changes), what resources needed (tools, money, manpower), and what metrics to measure progress and success.	"[""SlideShare utilise les cookies pour améliorer les fonctionnalités et les performances, et également pour vous montrer des publicités pertinentes. Si vous continuez à naviguer sur ce site, vous acceptez l’utilisation de cookies. Consultez nos Conditions d’utilisation et notre Politique de confidentialité.\nSlideShare utilise les cookies pour améliorer les fonctionnalités et les performances, et également pour vous montrer des publicités pertinentes. Si vous continuez à naviguer sur ce site, vous acceptez l’utilisation de cookies. Consultez notre Politique de confidentialité et nos Conditions d’utilisation pour en savoir plus.\nA Brief Introduction to Software Configuration Management\nWhat is Configuration Management\nart of coordinating software development\nto minimize…confusion is called configuration\nmanagement. Configuration management is the\nart of identifying, organizing and controlling\nmodifications to the software being built by a\nprogramming team. The goal is to maximize\nproductivity by minimizing mistakes.”\nSoftware configuration management manages\nthe effect of change through out the software\nWhat is CM not\njust version control\njust for source code management\nonly for development phase\nand using tools are important,\nbut design and management of CM\nprocess are more crucial for project\nis it ?\nAnswer: Change Management. Auditing and\nreporting on the changes made.\nWho does it ?\nAnswer: Everyone involved in the software\nWhy is it important ?\nAnswer: If you don’t control change, it controls\nyou. Uncontrolled changes suffers software\nquality and delivery is delayed. So, it is an\nessential part of quality management.\nare the steps ?\n1.Many work products are produced when a\nsoftware if made of. Each must be\n2.Mechanism for change control is\nestablished as changes are made, the\nprocess is audited and reports are made.\nWhat is the work product ?\nAnswer: describes the Programs/Coding e.g.\ndo I ensure that I’ve done it right?\nAnswer: When every work product can be\naccounted for, traced and controlled.\nWhen every change can be tracked and\nWhen everyone who needs to know about a\nchange has been informed-you've done\nEnsure that the changes are being\nReport changes to others who may have\nSome Simple CM Scenarios\nA wants to see latest\nversion of foo.c and its change history\nsince last week\nneeds to revert foo-design.doc to its\nversion two days ago\nmakes a release of the project and\nhe needs to know what items to\ninclude and which version\nSome Simple CM Scenarios (cont.)\nA lives in IUT, Gazipur, Bangladesh and B lives\nin Boston, US, they want to work on\nIn the latest release, a serious bug is found\nand manager C wants to track what changes\ncaused the bug, who made those changes\nC wants to get reports about current project\nprogress to decide if he needs to hire more\nprogrammers and delay the alpha release\nConfiguration Item (CI)\nAn approved and accepted deliverable, changes\nhave to be made through formal procedure\nSource code and executable code\nTest specification, data, and records\nLibrary and supporting software\nBug reports, etc.\nVersion, Variant, and Revision\nVersion: a CI at one point in its\ndevelopment, includes revision\nRevision: a CI linked to\nanother via revision-of\nrelationship, and ordered in\nVariant: functionally equivalent\nversions, but designed for\ndifferent settings, e.g. hardware\nBranch: a sequence of\nversions in the time line\nWin32 on x86\nHow Versions are Stored\nFull copy of each version\nDelta (differences between two versions)\nAn arrangement of functional CIs according to their\nnature, version and other characteristics\nGuaranteed to recreate configurations with quality\nand functional assurance\nSometimes, configuration needs to record\nenvironment details, e.g. compiler version, library\nversion, hardware platform, etc.\nAnt buildfile, Makefile\nA collection of item versions that have been formally\nreviewed and agreed on, a version of configuration\nMarks milestones and serves as basis for further\nCan only be changed via formal change\nBaseline + change sets to create new baselines\nAn isolated environment where a developer can\nwork (edit, change, compile, test) without interfering\nLocal directory under version control\nPrivate workspace on the server\nImport: put resources into version control in repository\nUpdate: get latest version on the default branch\nCheckout: get a version into workspace\nCheckin: commit changes to the repository\nVersion Control Models (1/3)\nBasic problem of collaborative work\nFigure from svn-book\nVersion Control Models (2/3)\nModel 1-Pessimistic: lock-modify-unlock\nForget to unlock\nParallel work not\nFigure from svn-book\nVersion Control Models (3/3)\nModel 2-Optimistic: copy-modify-merge\nFigure from svn-book\nChange Control Process\nSubmission of Change Request (CR)\nTechnical and business evaluation and impact analysis\nApproval by Change Control Board (CCB)\nEngineering Change Order (ECO) is generated stating\nchanges to be made\ncriteria for reviewing the changed CI\nCI’s checked out\nChanges made and reviewed\nCI’s checked in\nAdministrative tracking and reporting of CIs in CM\nStatus of proposed changes\nStatus of approved changes\nProgress of current version, on or behind schedule\nEstimate of resources to finish one task\nbugs identified by configuration audit\nIndependent review or examination to assess if a\nproduct or process is in compliance with\nspecification, standards, contractual agreement, or\nVerifies that CIs are tested to satisfy functional\nVerifies that baseline contains necessary and correct CI\nEnsures that changes made to a baseline comply with the\nconfiguration status reports\nCreation and availability of a new version of\nsoftware to the public\nSource code + build script + instructions\nExecutables packaged for specific platforms\nOther portable formats: Java Web Start, plugins\nPatches and updates: automatic, manual\nSource and/or binary, data files, installation scripts,\nlibraries, user and/or developer documentation, feedback\nMake a CM Plan\nIEEE Std 828 (SCM Plans), ANSI-IEEE Std 1042 (SCM), etc.\nCM plan components\nWhat will be managed (list and organize CIs)\nWho will be responsible for what activities (roles and tasks)\nHow to make it happen (design processes for change requests,\ntask dispatching, monitoring, testing, release, etc.)\nWhat records to keep (logs, notes, configurations, changes, etc.)\nWhat resources and how many (tools, money, manpower, etc.)\nWhat metrics to measure progress and success\nBugzilla, Mantis Bugtracker, Rational ClearQuest\nRCS, CVS, Subversion, Visual Source Safe, Rational ClearCase\nGNU Make and many variants, Ant\nSourceforge.net, freshmeat.net, GForge, DForge\nReference and Further Reading\nIntroduction to Configuration Management, lecture slides for\nCOMP3100/3500, Ian Barnes, the Australian National University.\nSoftware Configuration Management, Center for Development of\nAdvanced Computing, Mumbai at Juhu, India.\nConcepts in Configuration Management Systems, Susan Dart,\nSoftware Configuration Management: A Roadmap, Jacky\nEstublier, CNRS, France.\nSoftware Engineering, a Practitioner’s Approach (6th), part 4,\nCode Complete (2nd), Steve McConnel.\nImplementing and Integrating PDM and SCM, Ivica Crnkovic et al.\nVersion Control with Subversion, Ben Collins-Sussman et al.""]"	['<urn:uuid:8eb1ad13-98c5-4e42-b04b-2e4c9426d817>']	factoid	direct	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-13T01:50:22.828293	18	59	1079
86	As someone who regularly buys meat products labeled as 'natural' and 'humanely raised', I'm curious about what these terms actually mean for animal welfare standards - can you clarify their real definitions?	The terms 'natural' and 'humanely raised' on meat packages actually don't indicate meaningful animal welfare standards. Specifically, 'natural' does not impact animal welfare in any way, while 'humanely raised' and 'humanely handled' are undefined and subjective terms without any codified standards. This means these labels can be misleading for consumers trying to make ethical purchasing decisions based on animal treatment.	"['Farm Animals Need Our Help\nIn polling, 94% of Americans agree that animals raised for food deserve to live free from abuse and cruelty. Yet the majority of the nearly 10 billion farm animals raised each year in the U.S. suffer in conditions that consumers would not accept if they could see them. Most of our meat, milk and eggs come from industrial farms where efficiency trumps welfare—and animals are paying the price.\nA factory farm is a large, industrial operation that raises large numbers of animals for food. Over 99% of farm animals in the U.S. are raised in factory farms, which focus on profit and efficiency at the expense of animal welfare.\n- Cages and overcrowding.\n- Physical alterations, like teeth-clipping or tail-docking, performed without anesthetic.\n- Indoor confinement with poor air quality and unnatural light patterns.\n- Inability to engage in natural behaviors.\n- Breeding for fast growth or high yields of meat, milk and eggs that compromises animal welfare.\n- Neglect of sick and suffering animals, often due to high ratio of animals to workers.\n- Misuse of antibiotics to compensate for unsanitary conditions.\n- Rough or abusive handling by workers.\nPackages of meat, eggs and dairy often bear terms that appear to indicate meaningful animal welfare standards, but only a fraction of them do. This confusion prevents conscientious consumers from voting with their wallets for better treatment of farm animals.\n- Natural: Does not impact animal welfare in any way.\n- Free-Range: No legal definition for use on eggs, pork, beef or dairy.\n- Humanely Raised/Humanely Handled: Undefined and subjective terms without codified standards.\n- Hormone-Free/No Hormones Added: Hormones are not approved by law for use on pigs or poultry, so the term is meaningless on those products.\n- Cage-Free: On eggs, this label indicates that hens were not raised in battery cages. However, it is an empty claim on poultry meat as meat birds are very rarely raised in cages, and are instead crowded into large, open sheds.\nIt’s important to understand the true meanings of food labels so you can make informed decisions and help animals by buying products that match your values. Learn more in our Meat, Eggs and Dairy Label Guide.\nWhile most Americans expect our laws to protect farm animals, the reality falls far short. Animals raised for food are among the least-protected class of animals in our nation.\nAlthough there are no federal laws protecting animals on farms, two federal laws cover farm animals during transport and slaughter. Tragically, these two laws exempt all poultry species, which make up 95% of land animals killed for food.\n- Transport: The 28-Hour Law requires animals transported across state lines for slaughter— by means other than water or air—to be unloaded every 28 hours for rest, food and water. This law is weakened by loopholes, lack of enforcement and low fines.\n- Slaughter: The Humane Methods of Livestock Slaughter Act requires that livestock be quickly rendered insensible to pain before being slaughtered. In addition to excluding poultry, the law exempts certain forms of religious slaughter, such as Kosher and Halal.\nBecause federal law fails to protect most farm animals, state laws are these animals’ last defense. The majority of U.S. states expressly exempt farm animals, or certain standard farming practices, from their anti-cruelty provisions, making it nearly impossible to provide even meager protections. While in common industry use, these exempt farming practices are often shockingly cruel. Although a few states include farm animals in at least some of their anti-cruelty laws, such laws are rarely enforced in favor of farm animals.\n- Ag-Gag: Over the past few years, ""ag-gag,"" or anti-whistleblower bills, have been appearing in state legislatures across the country. While crafted to appear reasonable, these measures are designed to prevent the exposure of troubling practices at agricultural facilities. Instead of making it illegal to abuse animals, these laws make it illegal to document and report abuse.\nLearn where your state stands on ag-gag.\n- Confinement Bans: On the bright side, an increasing number of states are banning certain extreme methods of confinement, such as battery cages for hens and gestation crates for pigs.\nLearn where your state stands on confinement.\n- Right to Farm: Rather than reform destructive practices, corporate agribusiness is responding by pushing ""Right to Farm"" (RTF) laws that greatly limit the ability of states to regulate conditions on farms, including the cruel confinement of farm animals.\nLearn more about Right to Farm laws.\nBad for Animals, Bad for Us\nAnimals are not the only ones suffering because of these unnatural, inhumane conditions. Human health, the environment and farmers are being hurt by the intensive farming systems employed on factory farms.']"	['<urn:uuid:13775041-598b-4f5d-b837-e9631d90d745>']	open-ended	with-premise	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-13T01:50:22.828293	32	60	783
87	natural wood thermal insulation properties explain	Dry wood has thermal insulation properties due to its structure - it contains tiny cells of air bubbles which make it behave as a thermal insulator. This affects its thermal conductivity characteristics.	['Improve the productivity, quality and competitiveness of the wood industry and its derivatives.\nThis professional creates and optimizes industrial processes corresponding to chemical, biochemical and/or physical transformations of wood.\nHe determines its production technology respecting economic, social and environmental factors.\nHis knowledge is oriented to wood science and technology, complementing with economics and administration foundations.\nSpecific tasks or activities carried out in the profession\n-He takes part in the study, *feasibility, project, direction, construction, inspection and installation of wood industries, expect for the corresponding civil works.\n-He classifies wood samples into these categories: family, type and species.\n-He determines wood properties. Although its components are the same (cellulose, lignin, mineral salts, resins and water) their proportion is different in each species and is what determines the properties of wood. Among their properties, we have:\nResistance, where short or interrupted fibers and knots, play an important role, which is to decrease resistance.\nFlexibility, which determines how curved or bent wood can be by means of heat, moisture or pressure.\nDensity, which depends on its water volume (cellulose) fundamentally\nHardness, which is determined by its density, the higher density, the greater hardness\nThermal conductivity. Dry wood contains tiny cells of air bubbles which makes it behave as a thermal insulation.\n-He identifies the most suitable characteristics and properties of wood for each specific application.\n-He prepares wood for its industrialization process. In that:\n-He manages and optimizes the wood sawing process, which consists in:\n-Strip the bark and removal of branches.\n-Cut the log into pieces according to the use that will be given later.\n-He manages and optimizes the wood drying which is the most important process for the wood to remain in good condition; this can be by air drying or different artificial drying techniques.\n-He manages the wood preservation treatment, attacking biological agents (bacteria, fungi and insects) that produce its deterioration through the management of factors that inhibit their development; as well as physical agents that produce its deterioration, such as: mechanical damages, UV light, corrosion or chemical degradation.\n-He manages and optimizes the cellulose procurement process and the manufacturing process of paper and cardboard for multiple uses.\n-He designs and develops wood manufacturing processes, such as:\n-Strip Boards, formed by strips or the same type of wooden planks glued by their edges.\n-Veneer or sheets, formed by rectangular planks of little thickness.\n-Strips and boards, which are straight prisms, of square or rectangular section and great length.\nWood cylinders, usually very long.\nFrames or profiles, obtained from strips that are given a relief as a decorative element.\nFrom remains of bark, shavings and branches that are made in sawmill we can find:\n-Plywood boards, formed by several thin wooden sheets that are superimposed on the cross grain, glued and pressed.\n-chipboards, formed by several thin sheets of wood that are shredded into wood chips, mixed with glue and pressed.\n-Fiberboards, made from fibers obtained from wood pulp which are glued and pressed.\nHe designs and manufactures a wide variety of wood products and structures, such as: railroad ties, posts, structures for houses, floors, furniture, doors, sporting goods, etc.\nHe programs, executes and supervises the wood industrial process.\nHe controls equipment and machinery maintenance.\nHe deals with the quality control of wood.\nHe evaluates and improves the efficiency of industrial production processes and equipment efficiency.\nHe watches over the optimization of *resources and the qualification of workforce.\nHe follows the technological evolution of wood transformation processes and modernizes the industrial infrastructure.\nHe creates scientific knowledge regarding timber-yielding resources for their use and preservation.\nHe investigates and conducts tests to find other possible applications of wood and other products derived from it.\nHe looks for alternatives for the *sustainable development of the wood industry.\nHe evaluates the environmental impact produced by wood industrial processes and products obtained from it.\nHe carries out improvements in the protection of workers of the timber industry.\nHe interprets and applies the current legislation corresponding to his area.\nHe performs teaching, advice and *expert’s reports in his specialty.\n-Timber products industries for manufacturing.\n-Paper and Cardboard Industry\n-Waste wood, firewood and chips Industry.\n- Advisory bodies and technical assistance to producers.\n-Forestry sector government agencies\n-Higher Education Institutions.\nEstimated time of College years\nMain courses considered in the syllabus\nBasic Training Courses\nMathematics (5 semesters)\n*Chemistry (2 semesters)\n*Physics (2 semesters)\nProfessional Training Courses\n*Physical and Mechanical Properties of Wood\n*Applied Computer Science\n*Computer-aided Industrial Technical Drawing\n-Tools, Equipment and Machinery\n*Boards and Sheets\n-Adhesives and Coating\n*Cellulose and Paper\n-Construction Technology in Wood\n-Productive Process Operational Control\n*Hygiene and Industrial Safety\n-Design and Development of Timber Products and Wood Structures\n-Productive Project Formulation and Evaluation\nComplementary Training Courses\n*Economics and Administration Foundations\n*Statistics (2 semesters)\nCellulose and *Lignin Chemical Products\nAdvanced Design of Timber Products\nAdvanced Design of Furniture\nAdvanced Design of Constructions\nVocation, Skills and Interests required in the candidate to this career\n-Motivated by Industrial work.\n-Appreciation for production.\n-Affinity and Interest in making woodwork.\n-Interest in the implementation of knowledge and the use of technology.\n- Inclination for knowledge of the scientific area.\n-Tendency to the use of schemes for the understanding of something.\n-Taste for relating to people.\n-Natural tendency towards activity planning.\n-Organization and Planning Ability\n-Ability to create practical solutions\n-Ease to understand the functioning of devices or systems\nLogical Reasoning: It is captured through the observation of a reality, a drawing, a diagram, the functioning of something, behavior, etc. Ability to analyze proposals or complex situations, predict consequences and be able to solve the problem in a consistent way.\n-Ability to organize work groups.\n-Ability to organize activities.\n-Ease to relate and communicate with people.\n-Create products that meet the needs and demands of society.\n-Satisfaction for the application, construction and transformation.\nOr any specific dream or longing which feels involved or oriented towards this direction.\nAdaptability to work in groups\nGood human relations\nTolerance in treatment\nAuthority in front of a group\n-Work in the industry and in the field.\n-He interacts with chemical, mechanical engineers, electricians and forest engineers.\n-Forest Engineering, Forest Technician, Chemical Engineering.\n*Glossary of Terms\n*Operations Management (Course): Planning, organization, execution and supervision of wood transformation activities. -Analysis and application of methods to solve production planning and control problems.\n*Wood Anatomy (Course): Diversity of anatomical characteristics present in each timber species. -Industrial Uses.\n*Sawmill: Facility devoted to cut wood.\n*Botany (Course): Plant taxonomy. -Diversity of Species. -Geographical Distribution. -Study of the functioning of plant organs and tissues of plants.\n*Cellulose: Substance that is found in the membranes of plant cells and is obtained from wood *pulp.\n*Cellulose and Paper (Course): Techniques for the extraction of *cellulose and wood chemical products.\n-Techniques for wood transformation in paper and cardboard: *pulp preparation, paper dyeing, paper pressing and drying. –Machinery used. –Recovery of *waste and *pulp recycling.\n*Kinematics: Study of the laws that govern the motion of bodies.\n*Thermal Conductivity: Ability to conduct heat.\n*Wood Preservation (Course): Wood deteriorating agents (bacteria, fungi, insects). -Products to preserve and protect wood. - Methods of impregnating wood with preservatives for its maintenance in good condition.\n*Quality Control (Course): Test of materials. –Quality of the sawing process of wood, *pulp, paper and all types of finished products. -Methods and Techniques of statistical quality control through quality control charts and an acceptance *sampling (sample analysis). – Programs for continuous improvement of quality.\n*Pollution Control (Course): Pollutants produced by different forest industries. –Ways to reduce or dispose of pollutants.\n*Material Take Off: Determination of the capacity or volume of a body knowing its dimensions and applying the corresponding geometric formulas. -For instance, the quantity cubic meters of wood.\n*Sustainable Development: Development that continues to finance itself and thus remains in time.\n*Technical Drawing (Course): Interpretation of *floor, *profile and *perspective drawings and others. –Computer-aided drawing.\n*Electromagnetism: Branch of physics which studies electrical and magnetic phenomena and the relation between them.\n*Industrial Power (Course): Electricity knowledge. –AC and DC generators, transformers, AC motors, motor installation, power distribution in an industrial plant.\n*Statistics: Techniques for the collection, presentation, treatment and analysis of data, in order to summarize and describe the characteristics of the information they provide.\n*Statistics (Course): Basic knowledge and essential concepts to understand *Statistics applied to the forest area.\n*Feasibility: Feasible: That is possible to perform.\n*Physics (Course): *Kinematics; *Electromagnetism; *Waves and Optics; *Thermodynamics; *Fluid Mechanics, Heat and Temperature.\n*Physical Chemistry: Part of chemistry that studies the molecular interactions in matter due to physical effects, such as changes in temperature, pressure, volume, heat and work. As well as the study of optical, electrical, magnetic and mechanical properties at atomic and molecular level, among others.\n*Economics and Administration Foundations (Course):\nEconomics: *Macroeconomics and *microeconomics concepts; Theory of supply and demand for products; input costs; market research and commercialization.\nAdministration: Planning, organization, direction and control of business management.\n-Operation of the forest products market.\n*Hygiene and Industrial Safety (Course): Maintenance of the environment in sanitary conditions to prevent it from affecting people’s health, such as chemical, physical and biological factors that could affect their health. Prevent diseases from the creation of healthy environments.\n*Applied Computer Science (Course): Use of applied Software in the area such as Simulation Software for Production Systems.\n*Industrial Engineering (Course): -Industrial Plant Location. –Installations. –Forest industrial transformation. –Work Methods and *Layout. –Industrial Instrumentation and Automation. –Computerized Production Systems.\n*Layout: Logical and ordered distribution of the materials, as well as their arrangement according to human anatomy that facilitates their use.\n*Lignin: They are chemical compounds present in the wall of plant cells to create wood.\n*Macroeconomics: Regarding the production and consumption of the wealth of a country and the problems related to the level of employment.\n*Fluid Mechanics: Related to Statics (no motion) and Dynamics (in motion) of fluids. –Concepts and fundamental definitions of fluid mechanics. –Flow analysis. –Flow meters. –Compressible and non-compressible fluids. Among other topics related.\n*Forest Measurements (Course): Methods and techniques for measuring the dimensions of forests, trees and their parts. –Measurements of diameters, sections and bark. *Material take-off of tree parts. –Measurement of firewood and primary products. –Use of instruments for that task. –Mathematical principles in the construction of basic forest measurement instruments.\n*Microeconomics: Economic analysis relative to the individual behavior of consumers, traders, producers, companies and industries, etc.\n*Waves and Optics: Oscillations, Mechanical Waves, Sound. –Electromagnetic Waves. –Behavior of light as a wave and its phenomena. –Optics Knowledge.\n*Unit Operations (Course): They are each of the actions necessary in the raw material process, whether their transformation and/or adaptation processes (chemical and physical processes) as well as the actions necessary to carry out their transport.\n*Floor: View from above of an object.\n*Profile: Side view of an object.\n*Expert’s report: It is the testimony of an expert, in matters of his competence to be presented before the judicial or administrative authorities.\n*Perspective: Object seen from a distance from a certain location.\n*Forest Policy (Course): State policies related to the use of forest resources.\n*Sawing Process (Course): Characteristics of raw material (wood). Systems and Machinery in sawmills.\n-Processes to transform tree piece into sawn timber (cutting and brushing). –Determination of the volumes and qualities of pieces, sawn wood and by-products. –Management and operation of sawn wood production systems.\n*Physical and Mechanical Properties of Wood (Course): Physical (mass, density, weight and specific weight), mechanical (resistance, elasticity, plasticity, hardness) thermal, electric and acoustic properties and characteristics of wood. –Measurement Methods and Techniques. –Application of wood properties in industrial processes and their use.\n*Pulp: Preparation of a mechanical wood pulp, crushing wood chopped with large amounts of water, or using chemicals, that are added to the previously crushed wood, where a chemical pulp is obtained, from which pure cellulose is obtained.\n*Chemistry (Course): *General Chemistry, *Organic Chemistry, *Physical Chemistry.\n*Wood Chemistry (Course): Chemical compounds which form the wood tissue. –Chemical properties and functions of cellular elements that form wood and their relation with other physical and mechanical properties. –Compounds that provide coloring and resistance to wood that influence in processes such as gluing and finishing wood.\n*General Chemistry: Course that deepens knowledge acquired in high school: properties of matter, atoms and elements, nomenclature, atomic structure, chemical bond, ionic bonding, states of matter, among others.\n*Organic Chemistry: Study of the molecules that contain carbon and that are found in living beings.\n*Resources: Everything that can be used to support our purposes.\n*Wood Drying (Course): Theory of the movement of water in wood. –Relation between the chemical, anatomical and physical properties and characteristics of wood and wood drying. –Drying methods and techniques: air-drying and kiln-drying. –Management of equipment for wood drying.\n*Boards and Sheets (Course): Industrialization techniques for forest products such as: veneer (wood slices to cover furniture), veneered, plywood, chipboards, fiberboards and strip boards, etc.\n-Planning, organization, execution and supervision of wood transformation activities.\n*Thermodynamics: Part of physics that studies the force and movement generated by calorific phenomena, thermal properties of matter and heat exchange. –Laws that govern thermodynamics.GO BACK']	['<urn:uuid:577b364e-0e9a-4e61-83f4-763f1c50cae6>']	open-ended	direct	short-search-query	distant-from-document	single-doc	expert	2025-05-13T01:50:22.828293	6	32	2159
88	What revolutionary imaging technique has been developed to observe the actual movement mechanism of motor proteins, and what specific insights has it revealed about their motion?	Researchers used cryo-electron microscopy to capture the first direct images of motor proteins in action. They set dynein proteins running along microtubule tracks and froze them 'mid-stride' by cooling them at about a million degrees per second. This rapid cooling prevented water from forming ice crystals. They took thousands of images of the motors caught during stepping and combined these images to build up a dynamic picture of dynein movement. This technique revealed a crucial discovery: the existence of a hinge between the long, thin stalk and the 'grappling hook', similar to a wrist between a human arm and hand. This hinge allows for variation in the angle of attachment to the track. The imaging showed that each dynein motor protein arm is about 25 nanometres long, while binding sites are 8 nanometres apart, allowing dynein to reach multiple binding sites ahead.	"['These proteins are vital to complex life, forming the transport infrastructure that allows different parts of cells to specialise in particular functions. Until now, the way they move has never been directly observed.\nResearchers at the University of Leeds and in Japan used electron microscopes to capture images of the largest type of motor protein, called dynein, during the act of stepping along its molecular track.\nDr Stan Burgess, at the University of Leeds\' School of Molecular and Cellular Biology, who led the research team, said: ""Dynein has two identical motors tied together and it moves along a molecular track called a microtubule. It drives itself along the track by alternately grabbing hold of a binding site, executing a power stroke, then letting go, like a person swinging on monkey bars.\n""Previously, dynein movement had only been tracked by attaching fluorescent molecules to the proteins and observing the fluorescence using very powerful light microscopes. It was a bit like tracking vehicles from space with GPS. It told us where they were, their speed and for how long they ran, stopped and so on, but we couldn\'t see the molecules in action themselves. These are the first images of these vital processes.""\nAn understanding of motor proteins is important to medical research because of their fundamental role in complex cellular life. Many viruses hijack motor proteins to hitch a ride to the nucleus for replication. Cell division is driven by motor proteins and so insights into their mechanics could be relevant to cancer research. Some motor neurone diseases are also associated with disruption of motor protein traffic.\nThe team at Leeds, working within the world-leading Astbury Centre for Structural Molecular Biology, combined purified microtubules with purified dynein motors and added the chemical fuel ATP (adenosine triphosphate) to power the motor.\nDr Stan Burgess, of the University of Leedsís Faculty of Biological Sciences, explains research that gives us our first glimpse of cellsí motor proteins in action.\nDr Hiroshi Imai, now Assistant Professor in the Department of Biological Sciences at Chuo University, Japan, carried out the experiments while working at the University of Leeds.\nHe explained: ""We set the dyneins running along their tracks and then we froze them in \'mid-stride\' by cooling them at about a million degrees a second, fast enough to prevent the water from forming ice crystals as it solidified. Then using a cryo-electron microscope we took many thousands of images of the motors caught during the act of stepping. By combining many images of individual motors, we were able to sharpen up our picture of the dynein and build up a dynamic idea of how it moved. It is a bit like figuring out how to swing along monkey bars by studying photographs of many people swinging on them.""\nDr Burgess said: ""Our most striking discovery was the existence of a hinge between the long, thin stalk and the \'grappling hook\', like the wrist between a human arm and hand. This allows a lot of variation in the angle of attachment of the motor to its track.\n""Each of the two arms of a dynein motor protein is about 25 nanometres (0.000025 millimetre) long, while the binding sites it attaches to are only 8 nanometres apart. That means dynein can reach not only the next rung but the one after that and the one after that and appears to give it flexibility in how it moves along the \'track\'.""\nDynein is not only the biggest but also the most versatile of the motor proteins in living cells and, like all motor proteins, is vital to life. Motor proteins transport cargoes and hold many cellular components in position within the cell. For instance, dynein is responsible for carrying messages from the tips of active nerve cells back to the nucleus and these messages keep the nerve cells alive.\nCo-author Peter Knight, Professor of Molecular Contractility in the University of Leeds\' School of Molecular and Cellular Biology, said: ""If a cell is like a city, these are like the truckers on its road and rail networks. If you didn\'t have a transport system, you couldn\'t have specialised regions. Every part of the cell would be doing the same thing and that would mean you could not have complex life.""\n""Dynein is the multi-purpose vehicle of cellular transport. Other motor proteins, called kinesins and myosins, are much smaller and have specific functions, but dynein can turn its hand to a lot of different of functions,"" Professor Knight said.\nFor instance, in the motor neurone connecting the central nervous system to the big toe--which is a single cell a metre long-- dynein provides the transport from the toe back to the nucleus. Another vital role is in the movement of cells.\nDr Burgess said: ""During brain development, neurones must crawl into their correct position and dynein molecules in this instance grab hold of the nucleus and pull it along with the moving mass of the cell. If they didn\'t, the nucleus would be left behind and the cytoplasm would crawl away.""\nThe study involved researchers from the University of Leeds and Japan\'s Waseda and Osaka universities, as well as the Quantitative Biology Center at Japan\'s Riken research institute and the Japan Science and Technology Agency (JST). The research was funded by the Human Frontiers Science Program and the Biotechnology and Biological Sciences Research Council (BBSRC).\nThe study used powerful electron microscopes at the University of Leeds\' Astbury Centre for Structural Molecular Biology. The University has since announced a £17 million investment in state-of-the-art facilities that will allow even closer observation of life within cells. New equipment includes two 300 kilovolt (kV) electron microscopes (EM) and a 950 megahertz (MHz) nuclear magnetic resonance spectrometer alongside existing 120kV and 200kV EMs, and 500, 600 and 750 MHz NMR machines.']"	['<urn:uuid:77db1f3c-7697-40f0-ac6a-31b4a5392f7c>']	open-ended	direct	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-13T01:50:22.828293	26	142	966
89	how does underwater camera robio work deep sea photos marine life	ROBIO is a baited underwater camera system that sinks to the sea floor using weights. It takes photos every minute for 16 hours and includes a digital camera with flash, a current meter, a CTD, and a reference cross with centimeter markers for measuring fish. The system also has air-filled glass floats that help it return to the surface when commanded. This equipment helps log environmental parameters where ROBIO rests on the sea floor.	['We are in port this morning offloading samples, restocking, and changing over some of our team, including our chief scientist. We say farewell to Neil Summer of Ecolyse who has expertly guided this expedition for the past month or so. And, we say hello to our new Chief Scientist Oscar Garcia. (We’ll introduce Oscar in more detail in a future post.)\nMexican Rattail Fish\nToday, however, we’d like to introduce you to ROBIO (Robust Biodiversity) lander—our underwater autonomous photographic lander. Thomas Linley is a marine biologist from Oceanlab at the University of Aberdeen in Scotland. He is on board the Gyre for the sole purpose of deploying, monitoring, and analyzing the data returned from ROBIO. Thom has taken ROBIO all over the world on various sea expeditions. We deployed the underwater camera over the weekend and took some interesting pictures that can tell us lots about the deep sea environment. Here, Thom tells us what exactly ROBIO does and why the information it gathers is useful.\nHow does ROBIO work?\nDeep-sea red crabs fighting over bait\nThe ROBIO lander is a baited, underwater camera. We deploy ROBIO near the well head, and with the help of weights it sinks to the sea floor where it sits for 16 hours. It has a digital camera and flash on board taking a photo every minute. It also has a current meter, a CTD, and a reference cross (metal bars with centimeter markers so that fish can be measured). These tools help us log the environmental parameters of wherever ROBIO comes to rest on the sea floor. The lander also has air-filled glass floats on board that help it return to the surface when we tell it to.\nWhat kind of data are you gathering?\nGiant isopod (Pill Bug) and cutthroat eels. The Pill Bug is about the size of a small cat.\nFrom the photos themselves we can get a species list. When we’ve got the reference cross in view, we can also measure the fish and compare differences in species assemblages and in the size of the animals between different sites. But then, we can get a little bit interesting. We can use the current meter data to plot the odor plume—how far the smell of the bait has gone out into the water. By allowing the animals to feed on the bait we can see how long and how much they eat, before they wander off and get bored. This can indicate how much available food is in the area: if they have enough to eat and food isn’t their top priority or if they’re starving and they’ll eat as much as they can.\nUsing optimum foraging theory, we can determine how the deep sea animals are looking for their next meal. In a nutshell, optimum foraging theory helps explain how animals have evolved to get the maximum amount of food while using the minimum amount of energy. They don’t just search randomly for food. With this information, we can start to make comparisons about how many fish are in the area.\nWhat does that have to do with the possibility of oil on the ocean floor?\nROBIO and what Thom believes to be a Rudis Rattail fish\nThese are the mobile organisms—the ones that could move to another part of the Gulf if they needed to. If these animals don’t have what they need where they are due to an increase of oil in their environment for example, they go find another place that can sustain their life. Our goal is to generate some nice images and gather data on the megafauna – the larger animals – which we haven’t really looked at yet in this sediment coring activity.\nWe will most likely be heading back out to sea tonight or tomorrow. Check back soon for our next update from sea!']	['<urn:uuid:66539d9e-0dac-4009-a258-a2e82a8a226e>']	open-ended	with-premise	long-search-query	similar-to-document	single-doc	novice	2025-05-13T01:50:22.828293	11	74	642
90	modern ice sheet lake study limitations	The understanding of subglacial lakes beneath the Antarctic and Greenland ice sheets is currently limited. While these lakes are crucial components of the subglacial hydrological system and can store and rapidly drain large volumes of meltwater, scientists do not yet fully understand the drainage process and its influence on ice flow. The discovery of relict lakes in Canada provides important constraints for modeling similar subglacial lake drainages in these modern ice sheets.	"['New research reveals secrets of former subglacial lakes in North America\nResearchers at the University of Sheffield have provided a unique glimpse into one of the least understood environments on Earth by revealing for the first time former subglacial lakes and their drainage routes beneath the North American ice sheets.\nBy investigating a very strange flat spot and associated channel in Alberta, Canada, which had no water in it, academics discovered the former existence of a lake trapped beneath an ice sheet during the last glaciation.\nAs this relict lake is no longer covered by many kilometres of ice, they were able to reconstruct what the lake would have looked like and how it drained from the landforms and sediments.\nTheir observations, published in the journal Nature Communications today (Monday 13 June 2016), suggest the lake existed as a shallow lens of water which repeatedly drained through channels cut into the bed.\nThe team\'s results provide constraints for the modelling of similar subglacial lake drainages beneath the Antarctic and Greenland ice sheets. These are a crucial component of the subglacial hydrological system, able to store and rapidly drain large volumes of meltwater, but we do not know enough about the drainage process to fully understand their influence on ice flow.\nDr Stephen Livingstone, from the University\'s Department of Geography and lead author of the paper, said: ""We\'ve seen these flat spots connected to relict channels in Canada, and are inferring these as former subglacial lakes and their drainage imprint. As ice no longer covers these relict lakes, our discovery has allowed us to reconstruct how the subglacial lakes would have looked and how they drained from the landforms and sediments. Our results provide key constraints for the investigation of modern subglacial lakes beneath the Antarctic and Greenland ice sheets.""\nNotes to editors\nThe University of Sheffield\nWith almost 27,000 of the brightest students from over 140 countries, learning alongside over 1,200 of the best academics from across the globe, the University of Sheffield is one of the world\'s leading universities.\nA member of the UK\'s prestigious Russell Group of leading research-led institutions, Sheffield offers world-class teaching and research excellence across a wide range of disciplines.\nUnified by the power of discovery and understanding, staff and students at the university are committed to finding new ways to transform the world we live in.\nSheffield is the only university to feature in The Sunday Times 100 Best Not-For-Profit Organisations to Work For 2016 and was voted number one university in the UK for Student Satisfaction by Times Higher Education in 2014. In the last decade it has won four Queen\'s Anniversary Prizes in recognition of the outstanding contribution to the United Kingdom\'s intellectual, economic, cultural and social life.\nSheffield has five Nobel Prize winners among former staff and students and its alumni go on to hold positions of great responsibility and influence all over the world, making significant contributions in their chosen fields.\nGlobal research partners and clients include Boeing, Rolls-Royce, Unilever, AstraZeneca, Glaxo SmithKline, Siemens and Airbus, as well as many UK and overseas government agencies and charitable foundations.\nFor further information, please visit http://www.sheffield.ac.uk\nFor further information please contact: Hannah Postles, Media Relations Officer on 0114 222 1046 or email [email protected]']"	['<urn:uuid:1ce6fd4d-30d3-4606-a646-eb97ec5a9125>']	open-ended	direct	short-search-query	distant-from-document	single-doc	expert	2025-05-13T01:50:22.828293	6	72	542
91	lake mead water quality sources contamination	Lake Mead's water quality comes primarily from the Colorado River (97%), which is very clean due to traveling through undeveloped areas like national parks. However, contamination sources exist - Las Vegas Wash brings in 180 million gallons of treated wastewater daily plus storm runoff. While contaminants from urban wastewater and storm water are found in Las Vegas Wash and Bay, they rarely reach concerning levels for human health. The water undergoes a 5-step treatment process including coagulation, flocculation, sedimentation, filtration and disinfection before distribution to ensure safety.	['What’s in Our Water?\nWhen we think of water, most of us think of a liquid so clean and clear that we can see right through it. Yet almost all the water on Earth contains something that isn’t water. Some of these other substances are harmless, and others are a cause for concern, which makes some people wonder about the quality of the water they drink, bathe in, swim in, and fish from.\nSo what’s actually in the water at Lake Mead and Lake Mohave?\nAs water makes its way through the environment, it inevitably picks up certain substances along the way. Most of these are minerals that naturally seep out of the ground and into the water as it flows through riverbeds and lake basins. Small amounts of aluminum and fluoride, for instance, exist even in the world’s cleanest and most remote water sources. Water can also pick up nutrients like phosphorus and nitrogen from decaying plants along the waterway.\nSources and pathways of organic compounds in water and aquatic ecosystems.\nOther substances, known as contaminants, are a direct result of human influence. As storm water drains away from parking lots and lawns, it carries oils, pesticides, and fertilizer into local waterways. Some chemicals and heavy metals (like mercury) may be transferred from remote sources since air can transport the chemicals over long distances. Other chemicals from pharmaceuticals make their way through our bodies and then get flushed down the toilet, eventually re-entering the water supply. Even worse, larger amounts of contaminants can come from toxic spills and leaks from industrial areas.\nMany of the daily products we use, like fragrances, flame-retardants in household products, personal care products and pharmaceuticals, make their way into the water supply through municipal and industrial processes and also from us as consumers.\nThis may all sound alarming, but Southern Nevada has an outstanding water source in Lake Mead. Compared to other large metropolitan areas, the lake has relatively little water contamination from human activity. That’s because the Colorado River is a very clean water source and provides about 97 percent of Lake Mead’s water. Before flowing into Lake Mead, the Colorado River has traveled hundreds of miles through Canyonlands National Park, Glen Canyon National Recreation Area, Grand Canyon National Park, and other undeveloped areas. Once it arrives in southern Nevada, the water is carefully monitored to make sure it’s safe for drinking, fish and wildlife, and recreation.\nLas Vegas Wash carries more than 180 million gallons of treated wastewater into Lake Mead each day, as well as storm-water runoff from the valley.\nHowever, not all water that enters Lake Mead is free from human influences; certain parts of the local watershed tend to harbor more contaminants. Las Vegas Wash, for instance, carries more than 175 million gallons of treated wastewater into Lake Mead each day, as well as storm-water runoff from the valley. Las Vegas Bay, where this water enters the lake, is carefully monitored to make sure that water treatment programs are meeting state and federal standards and reducing contaminants to safe levels. While a number of contaminants that are commonly in urban wastewater and storm water are found in Las Vegas Wash and Bay, rarely do any substances in lakes Mead and Mohave reach levels that are high enough to cause a concern for human health. Studies have shown, however, that some of these contaminants can be found in fish and birds1 at levels that cause health effects to individual animals. It is not known whether these impacts to individuals are a threat to continuing successful reproduction and overall populations.\nA number of federal, state and local agencies are involved in monitoring water quality in these lakes, including the Southern Nevada Water Authority, National Park Service, Bureau of Reclamation, U.S. Geological Survey, Clark County, and the cities of Las Vegas and Henderson. These agencies continuously keep an eye out for water quality conditions and contaminants that could potentially cause problems in drinking water and recreational use. This includes monitoring not only bacteria and human pathogens, but also conditions that lead to algal blooms since certain types of algae in unusually high numbers can potentially cause illness in humans. The agencies also monitor for contaminants2 that can harm wildlife including pesticides, heavy metals, and other chemical compounds.\nIn recent years, drought is playing an increasingly important role in the lakes’ health and water quality. As water levels in lakes Mead and Mohave drop, algae populations tend to increase due to warmer water and higher concentrations of nutrients available at the water surface. Contaminant levels can also rise due to resuspension of contaminants in newly exposed shoreline. Contaminants may be more concentrated in the greater expanse of shallow, warmer water, and more available to fish and wildlife. However, even though lake levels are currently low, extensive water monitoring by the managing agencies shows that overall water quality remains excellent.\nWithout water from the Colorado River, southern Nevada would never have become home to millions of people. Moving forward, it’s vital to monitor and protect this valuable resource so that it can safely sustain the Las Vegas Valley and the recreation and habitat available at lakes Mead and Mohave for years to come.\nThe Best Treatment Possible\nRiver Mountains Water Treatment Facility\nLake Mead is one of the most important water storage reservoirs in the country. More than twenty-five million people, including more than two million residents of Southern Nevada, rely on its water for use in their homes and businesses. Much of the water leaving Lake Mead on its way to the Las Vegas Valley makes an important stop at the River Mountains Water Treatment Facility where up to 400 million gallons of water are treated each day before moving onto one of several pump stations throughout the valley. This is good news since only half a century ago, little attention was given to water quality making the possibility of water-related illnesses more prevalent. Today, regulations and water treatment methods have made water, especially in Southern Nevada, some of the cleanest water in the country.Read More\nA scale of parts per million in water.\nWe rely on water every day - when we take our first drink in the morning, take a shower or flush the toilet - but we rarely think about how important clean water is to our daily lives. Yet water-related diseases are some of the world’s leading killers, especially among the poor in developing countries. We are fortunate in the United States that a series of laws and regulations protect our waters. Here in the Southwest Desert, water quality is taken very seriously.\nLast updated: April 5, 2017', 'What is Water Treatment?\nWater treatment refers to the process of improving the quality of water with the purpose of serving an end-use. The most common end-uses include drinking water, industrial water supply, water recreation, and for replenishing environmental sources, such as rivers and lakes.\nClean water is a basic necessity for humans. While the human population grows, the demand for water grows as well. Since water is a finite resource, used water must be treated to continuously serve end-uses. This is where the importance of water treatment systems comes in.\nWater treatment helps in removing contaminants and hazardous substances from the water, making it clean and safe to drink and be used for other purposes. Unfortunately, almost 2 billion people in the world use either untreated drinking water or get water from unsafe or contaminated sources. Having systems in place to improve water quality helps intervene in these situations and prevent unsafe water-caused incidents, such as water-borne diseases and fatalities.\nOn the other hand, water treatment is also helpful in ensuring that water gets reintroduced back to nature’s cycle. One of the end-uses of this process is to safely return water to environmental sources like rivers, lakes, and oceans. Of course, water treatment facilities must ensure that water is free from harmful substances before doing so to avoid contamination and other environmentally disastrous issues such as water pollution.\nThe United States Environmental Protection Agency (EPA) sets forth guidelines for organizations for protecting the environment and human health. One of the violations that an EPA report helps keep in check regarding an organization’s compliance with environmental safety is the illegal discharge of pollutants that could end up in bodies of water. An example of this is dumping untreated and contaminated wastewater directly into the sewer system, which is a violation of the Clean Water Act.\nIn most cases, water treatment plants are responsible for collecting, treating, and distributing supplies of water, whether for residential, commercial, or industrial uses. Globally, these facilities may follow slightly different processes in their water treatment systems. However, their methods are all based on similar stages depending on the end use they aim to achieve.\nWhat are the 5 steps of water treatment?\nAccording to the Centers for Disease Control and Prevention (CDC), the overall water treatment process, especially for public water systems, consists of 5 major steps:\nThe first step of getting water treated is through coagulation. This involves adding chemicals with a positive charge to the water which should neutralize the negative charge of dirt and other dissolved substances. Such chemicals include iron and specific types of salt.\nThis step refers to the process of gently mixing the water to create larger, heavier particles known as flocs. In most cases, additional chemicals are being added to the water to allow the flocs to form easily.\nOnce flocs form, they settle to the bottom of the water because they are heavier. This is called sedimentation in water treatment, which is one of the processes that water treatment plants use in separating the solids, such as flocs, from the water before going to the next step.\nThe water again goes through another process of solids separation through filtration. The separated, clear water on top now passes through filters with various pore sizes, made from different materials such as sand and gravel. Ultimately, these filters are in place to help remove dissolved particles and unwanted substances from the water.\nDuring this step, any remaining parasites, bacteria, and viruses must be eliminated. This can be done by adding one or more chemical disinfectants to water such as chlorine or chlorine dioxide. Why do water treatment plants do this? It’s to keep water safe when traveling from the water treatment plant to homes and businesses because chemical disinfectants help eliminate the remaining unwanted microorganisms before the water reaches the intended end-use.\nCreate Your Own Water Treatment Inspection Checklist\nEliminate manual tasks and streamline your operations.Get started for FREE\nGenerally, water treatment systems differ in serving specific end-uses. The 3 most common types are the following:\nHousehold Water Treatment\nAccording to the National Sanitation Foundation (NSF), the general kinds of systems that are used as water treatment solutions include the following:\n- Point-of-use (POU) systems – water pitchers, faucet filters, and reverse osmosis (RO) systems, etc.\n- Whole-house/point-of-entry (POE) systems – municipal systems, pressurized storage tanks, UV microbiological systems, water softeners, etc.\nAlso, home water treatment systems either use advanced water treatment or conventional septic tank systems to treat water from households.\nIndustrial Water Treatment\nThis process refers to the treatment that is performed pre- and post-industrial use. Since businesses from various industries use water differently, water treatment processes can be done before or after performing business activities to serve the intended use of water. For example, water treatment in the Food and Beverage sector under the Hospitality industry is crucial for ingredient water used in processing food. On the other hand, manufacturing plants in the Automotive industry need to reuse or dispose of wastewater, and water treatment can help in that process.\nWastewater refers to any used or polluted form of water, generated after different types of uses and applications. Its sources include rainwater runoff and human activities. Wastewater treatment is key to removing any contaminants and being able to convert the quality of wastewater and turn it into an effluent that can be safe to return to the water cycle.\nCommunities, states, and countries know the importance of safe water for public use, but major problems in the way plants and facilities treat water can be often overlooked. Here are 4 of the most common issues encountered in the overall system of quality water treatment and in water treatment plants:\nWater treatment technology, facilities, and systems must always be kept in check, inspected, and maintained. Otherwise, neglect of these protocols may cause serious implications for the overall quality and safety of water treatment processes. Failing to perform regular maintenance on equipment and other assets used can result in costly repairs, grave damage to systems, and compromised human safety.\nInefficient Bacterial Control\nWhile some bacteria are essential to water treatment operations, failing to monitor and manage bacterial growth can endanger the quality of water. Hence, having a tested and proven system of bacterial control helps avoid such a risk and hamper the cycle of water treatment.\nThose working in water treatment plants or facilities, such as operators and specialists, deal with complex, highly technological processes. As such, there’s a need to prevent any misunderstanding of certain aspects of work due to poor training. Compromised quality of training can affect not just the safety of workers but also the quality of the overall treatment cycle.\nPoor Monitoring and Recordkeeping\nMonitoring and good recordkeeping must be maintained to ensure that protocols are being followed and that there is evidence of it being so. Common problems encountered in these situations are best resolved through corrective and preventive actions that help address any gaps discovered in monitoring and recordkeeping processes. Without these protocols in place, water treatment plants may suffer from a lack of traceable data and patterns in order to benchmark their processes and discover improvement opportunities.\nFAQs About Water Treatment\nTreated water gets released into local waterways so that it can be used again for various purposes. These can include supplying drinking water, being used for industrial and agricultural activities, and sustaining household needs. The process of discharging or releasing treated water to different destinations can be done through a pressurized system of lifts and pipes.\nThe three main purposes of treating water are for water to be used again, to be safely returned back to the water cycle, and to help improve water quality. Water treatment, hence, helps solve the problem of drinking water shortage and the other needs of the global community.\nDepending on the step or stage in the water treatment process, there are various chemicals being used to filter, disinfect, and desalinate water. Some of the most common ones include chlorine, chloramine, magnesium oxide, calcium hydroxide, and bromine.\nA water treatment facility, also called a water treatment plant, is a destination where wastewater goes from various sources such as residences, commercial industries, and communities through sewage pipes. Typically, sewage treatment plants and systems use miles of pipes found underground for wastewater to flow through all the way to water treatment facilities or plants for processing.']	['<urn:uuid:0615a707-d9d9-44f9-8875-c9d80cffb135>', '<urn:uuid:cde10933-98a5-4b6d-8c65-79ddda4e1a9d>']	open-ended	direct	short-search-query	similar-to-document	multi-aspect	expert	2025-05-13T01:50:22.828293	6	87	2507
92	when was IASC formed who joined	The IASC was formed in 1973 when leading professional accountancy bodies from nine countries - Australia, Canada, France, Germany, Japan, Mexico, Netherlands, the UK, and the US - came together to form this national committee to promote the harmonization of international accounting practices.	"['Harmonization is vital to accounting in today’s world. Harmonization falls under the concept of international convergence. As mentioned on the Financial Accounting standards Board website, convergence first came about in the late 1950s in response to post WWII economic integration and related increases in cross-border capital flows. According to fasb.org harmonization is described as reducing differences among the accounting principles used in major capital markets around the world. By the 1990s the definition of harmonization was replaced by the concept of convergence; which is the development of a unified set of high quality, international accounting standards that would be used in at least all major capital markets. Harmonization relates to globalization because globalization has a direct effect on harmonization. According to Emmanuel N. Emenyonu and Sidney J. Grey of Sacred Heart University and the University of Warwick, as published in The International Journal of Accounting, the International Accounting Standards Committee (IASC) was established in recognition of the problems posed by international accounting diversity. Leading professional accountancy bodies from Australia, Canada, France, Germany, Japan, Mexico, Netherlands, the UK, and the U.S. all came together to form this national committee in 1973. This was an attempt to promote the harmonization of international accounting practices. In 2001 the IASC was reorganized and became an independent international standard setter known as the International Accounting Standards Board (IASB). More recently over 100 countries and the European Union either require or permit the use of international financial reporting standards, also known as IFRSs, issued by the IASB or a local variant of them.\nSince 2002 the FASB and the IASB have been working to innovate and converge U.S. generally accepted accounting principles (GAAP) and IFRS. As of 2013 Japan and China were working towards converging their standards with IFRSs. Even the Securities and Exchange Commission (SEC) supports the convergence of global accounting standards. The final step is to incorporate IFRS into the U.S. financial reporting system. As hard as it may seem to try to get different nations to follow the same accounting procedures, the IASC is not working alone. The United Nations and the European Union are two of the few agencies who are also involved with this process. The IASC is just the only organization to claim prime responsibility for promoting international accounting harmonization on a world-wide basis. Emmanuel and Sidney also mentioned since 1970 France, Germany, Japan, the U.K and the U.S. have become more harmonized, reducing the differences in accounting policies and practices internationally.\nHarmonization even effects smaller local businesses around the country. In an article titled “How Accounting Practices Can Support the Globalization of Small Business” by Paul Thompson, the director of Global Accountancy Profession Support, he mentions a survey on US accounting firms. This survey was conducted by the American Institute of CPAs Private Companies Practice Section, which stated that 79% of respondents indicated that they anticipated international growth within the next five years. With international growth you must comply with international guidelines. Small businesses are a key aspect of the global economy. According to the Organization for Economic Co-operation and Development small businesses account for the majority of private sector employment and GDP, as well as a uniquely large share of new jobs.\nBasically small businesses provide a large amount of jobs for the working class and they are a large source of entrepreneurship. Nowadays many small businesses manufacture products and provide services in many countries; as well as sell products to clients around the world. Small business are starting to mirror what large business have been doing for years. In a report from the Edinburgh group titled “Growing the global Economy through SMEs” data revealed a large amount of international activity from small businesses. About 75% of the small businesses that were surveyed have clients that add some sort of international aspect to their business. This includes buying goods or services abroad. Another 64% of small businesses reported that they sold merchandise or services to customers outside the US in 2013. This is a 12% increase from 2010, according to the National Small Business Association “Small Business Exporting Survey”.\nObviously Harmonization has played a key role in the evolvement of accounting. It is so important when dealing with globalization or international accounting, and has influence over how business work together. Businesses and big corporations across the world have slowly began to harmonize, working under similar guidelines based on IFRS and GAAP. It’s fascinating to see how fast the business world is moving and the direction that it is headed in. It is safe to say that pretty soon majority of the world’s major companies will all be harmonized and working to better the economy of their native countries.', ""IFRS vs. GAAP: An Overview\nSystems of accounting, or accounting standards, are guidelines and regulations issued by governing bodies. They dictate how a company records its finances, how it presents its financial statements, and how it accounts for things such as inventories, depreciation, and amortization.\nHow a company reports these figures will have a large impact on the figures that appear in financial statements and regulatory filings. Investors and financial analysts must be sure they understand which set of standards a company is using, and how its bottom line or financial ratios will change if the accounting system were different.\nIFRS stands for International Financial Reporting Standards. This is a set of accounting standards set by the International Accounting Standards Board (IASB), in London.\nThe IFRS was formed in 1973. Accounting bodies from Australia, Canada, France, Germany, Japan, Mexico, Netherlands, the U.K., and the U.S. came together to form the IASC. It is becoming the global standard for the preparation of public company financial statements and as of information available Feb. 14, 2019, it is used in 144 out of 166 jurisdictions.\nIFRS is becoming more and more adopted around the world, including in certain jurisdictions in the U.S. In addition, the IASB has formalized a set of rules and standards for companies reporting their financial statements such as the balance sheet, income statement, and statement of cash flows.\nThe IASB has more than a dozen consultative bodies, representing the many different stakeholder groups that have an interest in and are affected by financial reporting.\nGAAP stands for Generally Accepted Accounting Principles and is the standard adopted by the Securities and Exchange Commission (SEC) in the U.S.\nThe best way to think of GAAP is as a set of rules that companies follow when their accountants report their financial statements. These rules help investors analyze and find the information they need to make sound financial decisions.\nAll companies that are publicly traded must adhere to the GAAP system of accounting.\n- Accounting standards and guidelines for best practices differ by region and may be company-specific.\n- IFRS is a global set of standards that has become increasingly adopted as the worldwide standard.\n- GAAP is specific to the United States and has been adopted by the SEC.\nIFRS is a principle of standards-based approach and is used internationally while GAAP is a rule-based system compiled in the U.S.\nThe IASB does not set GAAP, nor does it have any legal authority over GAAP. The IASB can be thought of as a very influential group of people who are involved in debating and making up accounting rules. However, a lot of people actually do listen to what the IASB has to say on matters of accounting.\nWhen the IASB sets a brand new accounting standard, a number of countries tend to adopt the standard, or at least interpret it, and fit it into their individual country's accounting standards. These standards, as set by each particular country's accounting standards board, will in turn influence what becomes GAAP for each particular country. For example, in the United States, the Financial Accounting Standards Board (FASB) makes up the rules and regulations which become GAAP.\nAlthough the majority of the world uses IFRS standards, it is not part of the financial world in the U.S. The SEC continues to review switching to the IFRS but has yet to do so.\nThere are some major differences that exist between the two sets of accounting standards. These include:\nInventory: The first is with the LIFO Inventory. GAAP allows companies to use the Last In First Out (LIFO) as an inventory cost method. But this is prohibited under IFRS.\nDevelopment Costs: Under GAAP, these costs are considered expenses. Under IFRS, the costs are capitalized and amortized over multiple periods.\nWrite-Downs: GAAP specifies the write-down amount of an inventory or fixed asset can't be reversed if the market value of the asset subsequently increases. On the other hand, the IFRS allows the write-down to be reversed.""]"	['<urn:uuid:5e52b2de-572a-4996-8bf7-f17ff0fdbc8a>', '<urn:uuid:1f80d877-ec27-44ff-a83e-518952845790>']	factoid	with-premise	short-search-query	distant-from-document	comparison	expert	2025-05-13T01:50:22.828293	6	43	1447
93	what eat suffolk sheep farm	Suffolk sheep are herbivores that eat grass, leaves, hay and scrub growth. While green pastures are beneficial, Suffolk sheep are hardy and resourceful, able to survive on sparse, scrubby pastures as long as their nutritional needs are met through supplemental hay and commercial grain rations meant for sheep.	"[""Try Suffolk Sheep for Meat and Wool on the Farm\nSuffolk Sheep Breeders Raise a Sheep Breed That's Ideal for all Climates\nReading Time: 4 minutes\nSuffolk sheep were first recognized in 1797 in sheep breed books. Since 1888, the Suffolk sheep have traveled to new continents and become a staple of American and Canadian sheep farms. The large breed, black faced sheep was developed in England. Originally, a Norfolk horned ewe was bred to a Southdown ram. The offspring of the original cross breeding resulted in a polled lamb.\nSuffolk sheep quickly became America’s most common breed of sheep. The breed background of the prolific Norfolk ewe brought extreme hardiness to the Suffolk breed. The Norfolk also had the black face, horns and large size. Even the meat of the Norfolk breed was prized. However, the Norfolk had poor conformation. The early breeders matched the Norfolk with the Southdown and came up with the future Suffolk breed. As often happens with crossbreeding, the offspring gathered up the best of both breeds. The black, open face, bare legs, and beautiful large build makes the Suffolk an attractive sheep. Unlike the Norfolk, the Suffolk is a polled breed, meaning no horns. The calm disposition of the Suffolk sheep makes them a popular choice for 4H clubs and family farms.\nHow Large do Suffolk Sheep Grow?\nThe Suffolk sheep grow to a large size range of 180 to 250 pounds in ewes. The rams can reach a hefty 350 pounds! A fairly long lifespan of 11 to 13 years and the excellent fertility rate adds to the popular features. The majority of farms keep the Suffolk sheep for meat production. The lambs are typically sold or butchered at 90 to 120 pounds. The lamb and mutton both are thought to have excellent taste, texture, and flavor. In some cases, cross breeding with other breeds increases the genetic benefits. The Welsh Mountain sheep are named as a breed that increases the meat production in the lambs. Using a Suffolk ram and a Welsh Mountain ewe is a common way to improve the Suffolk sheep flock.\nSuffolk Sheep are Easy Keepers\nAll sheep, no matter if they grow fleece or are a hair breed, are herbivores. They rely on eating grass, leaves, hay and scrub growth. Having beautiful green pastures of field grass is wonderful, but not the only way to raise sheep. The Suffolk sheep is hardy and resourceful. Even sparse, scrubby pastures can be enough for the Suffolk sheep breed, as long as the nutritional needs are met. Meeting the nutritional requirements can be achieved by feeding hay and some commercial grain rations meant for sheep. Suffolk sheep are resistant to parasites. The breed also does well in conditions ranging from damp to dry pastures or paddocks.\nGestation and Lambing\nGestation in the Suffolk lasts 145 to 155 days. Twins are very common and to be expected. Most sheep farmers will hold off breeding the ewe until eight months of age, although they reach sexual maturity around six months. The rams reach sexual maturity around five months. Be sure and separate your first-year kids before the rams become able to impregnate the new ewes. Breeding very young ewes can lead to higher incidence of pregnancy difficulties. Once the Suffolk ewe is mature, it is possible to breed her twice a year, yielding four to six lambs, in many cases.\nSuffolk Sheep Milk and Wool Fleece Products\nWhile the Suffolk is not known to be a dairy sheep breed, the milk is used by some breeders to make an upscale cheese sold in gourmet shops. Sheep milk has double the protein of cow’s milk and a higher concentration of milk solids overall. The higher percentage of milk solids means sheep milk makes a delicious cheese from less milk. Still, most people do not rely on the Suffolk ewes for their milk supply. One disadvantage for sheep dairy production is a lack of facilities to process sheep milk. Most sheep milk is used by the Suffolk sheep breeder‘s family in smaller quantities.\nWhile all the great meat production is going strong, another marketable product is being produced. Fleece and fiber production is another byproduct of raising any meat breed of sheep. The fleece can be used by commercial fiber mills or by hand spinners to obtain even more return from the investment in the flock. Shearing must be done once a year anyway, so the fleece should be used somehow. (Breeds such as the Katahdin sheep, are a meat breed that does not require shearing)\nThe Suffolk is considered a downy breed of wool producer. Hand spinners can definitely find a good amount of usable fleece to spin into yarn with the sheared fleece. The medium grading refers to the rating of a few factors of the fleece. The staple length, meaning the length of the fibers is two to 3.5 inches long. The micron count, 25 to 33 microns, makes it a medium grade wool. Each animal yields about five to eight pounds of usable fleece of which an average of 50 to 60 percent is usable. Even though the sheared wool can be used, Suffolk sheep are not usually considered when raising sheep for wool. Most of the Suffolk wool is sent to commercial processing. The Suffolk sheep breeders usually don’t take the effort needed to produce hand spinning fleece. (source: The Fleece and Fiber Sourcebook by Deborah Robson and Carol Ekarius, Storey Publishing, 2011)\nSuffolk sheep are the right choice when looking to raise lamb and mutton. A field of grazing Suffolk sheep is a beautiful sight, with their large, stocky size and black and white color pattern. With proper care, milk and wool can be usable products obtained from the Suffolk breed, too. Have you considered this breed for your farm?""]"	['<urn:uuid:61bc2913-a0ef-42e4-b6f1-355a6fcbdf03>']	open-ended	direct	short-search-query	distant-from-document	single-doc	novice	2025-05-13T01:50:22.828293	5	48	971
94	What are the mandatory external inspections that need to be completed when checking an aircraft before flight?	The Captain or Co-pilot must survey the aircraft's exterior and communicate with the maintenance crew about any immediate concerns. They must thoroughly investigate exposed motors, cables, sensors, and other structural components for function and condition. They also need to check the landing gear, engine, control surfaces, tires, wings, turbines, and control mechanisms to ensure everything is in working order.	['*This post may contain affiliate links. As an Amazon Associate we earn from qualifying purchases.\nBefore taking to the sky, a pilot must first go through a preflight checklist to ensure that the plane is ready to travel. Operating an aircraft safely requires extensive training, vigilance, and adherence to safety standards. Read on to learn more about what is expected of a pilot before take off.\nPreflight Checklist for Commercial Pilots\nWhen working as a commercial pilot, the position requires a lot of responsibility and accountability for the safety of the crew, passengers, and any cargo. To make sure that a plane is safe for take-off, a pilot may want to go through a personal assessment of their flight readiness, and a preflight checklist.\nGoing through established checklists is an established method of maintaining organization, safety standards, and assessing for any problems that may arise that can interfere with flying safely.\nAfter spending a dedicated amount of time at an institution to earn a degree in Aeronautical Science and Technology, a pilot undergoes rigorous hours of flight training.\nCommercial pilots use a preflight checklist to make sure the hydraulics, engine, and other critical parts of an airplane are in working order. A commercial pilot must be fit in mind and body to fly an aircraft, maintain safe operation of the plane at all times, and be aware of any oncoming obstacles or intense turbulence.\nThe Establishment Of Checklists For Pilots\nHuman error is inevitably going to show up from time to time. Whether in a rush or absentmindedly overlooking whether a specific function or part of an aircraft is working correctly before take-off can lead to needless accidents.\nThe Boeing Corporation has been credited with the established use of a preflight checklist to help pilots reduce the chance of accidents and fatal crashes during flight. It is easy to be overconfident, or miss out on checking everything thoroughly before taking to the air if a pilot fails to utilize a checklist.\nAccording to Angle of Attack, when the Boeing Corporation had vested interests with government contracts for its B-17 aircraft as used in WWII, they had some unfortunate accidents which could have tanked their contracts.\nDuring the test flight of a B-17 aircraft, the Captain had failed to ensure that the elevator lock was off before taking off. This oversight resulted in the injuries of three men, and some fatalities. To curry favor with the government as the company to negotiate a contract with for military aircraft versus competitors, Boeing developed a preflight checklist to reduce accidents, injuries, and malfunctions due to oversight.\nThanks to the implementation of checklists for pilots before taking to the skies, Boeing’s B-17 aircraft did not incur any more accidents, and 13,000 aircraft were manufactured for government use during the war efforts against Axis powers.\nMany pilots can learn to commit to the general overview of checklist steps preflight to memory, using devices like acronyms. However, commercial pilots should not skip out on using a checklist to verify that all appropriate actions have been taken for aviation safety.\nPerforming Necessary Checks Before Flying\nThe first step in checking out an aircraft for its flight worthiness takes place outside of the airplane.\nThe Captain or Co-pilot is responsible for surveying the aircraft’s exterior. The Captain or Co-pilot should be in communication with the maintenance crew, in case there are any immediate concerns about the plane’s condition.\nAny exposed motors, cables, sensors, and other structural components should be thoroughly investigated for its function and condition.\nInside the aircraft, the crew is responsible for running tests for fire detection, weather radars, warning lights, and other necessary systems.\nMaintaining up-to-date records and inventory on aircraft, and routinely doing maintenance checks at various hours of flight time use are conducted to increase aviation safety.\nChecklists are a valuable tool for pilots to check for normal operations, unusual incidents, malfunctions of equipment, and in case of an emergency. Most pilots may access their checklist in the form of a printed card, or laminated sheet to keep it protected and legible.\nAccording to sources such as Ask the Pilot, a pilot can look forward to going through more than thirty different steps, depending on the age and type of aircraft. Newer aircraft may automatically go through specific tests of necessary equipment.\nWhile going through a checklist, one pilot can go through each step asking the other pilot to verify with a response as to whether the step has been completed successfully or not. Keeping a good stream of communication between flight staff can help reduce the risk of oversight and an unwanted accident.\nGetting ready to take flight can bring on a lot of enthusiasm which can prove distracting. Pilots must also be aware of their physical and mental condition before committing to fly, in case they are too fatigued or feeling ill.\nMaintaining an aircraft at a safe level require attention to detail, a calm mind, and making sure to go through checklists thoroughly.\nOverall, pilots need to check the following before moving forward with starting up the airplane to get going.\nPilots should check the landing gear, engine, control surfaces, and tiresThe wings, turbines, and control mechanisms should be in working orderEmergency warning systems and lights in case of a fire, loss of air pressure, and other conditions\nPilots should ensure the fuel levels and oil are good for the flight and be prepared in case of emergency\nChecking In With The Pilot Before Take Off\nBefore a pilot gets into the cockpit and gets comfortable, they need to go through a checklist for preflight, startup, and right before takeoff. Pilots may also go through troubleshooting checklists and emergency checklists.\nFlying for long hours at a time can be stressful and bring on fatigue for a pilot, so assessing a pilot’s’ health and energy levels is essential to operate a commercial aircraft safely. Passengers and cargo both depend on a physically, mentally, and emotionally well pilot to fly with confidence and follow safety procedures.\nThe FAA has established a checklist for pilots before getting behind the controls, to make sure that they are well enough to fly. The checklist known as IMSAFE provides a helpful mnemonic device that commercial pilots can use to assess their health.\nPilots should check for illness, whether they are on medication that can impair judgment if they are under stress, are under the influence of alcohol, suffering fatigue, or have emotional distress that can distract them from doing their job safely.\nAn illness can put a pilot out of commission, especially if the changes in air pressure can prove too distracting or harmful during climbing or descending the aircraft.\nIf a medication that a pilot has taken is still in effect where it can cause a pilot to feel overly drowsy, confused, or impairs sound judgment, the pilot should not fly.\nStress can affect people differently, but being responsible for a host of passengers and a flight crew requires a level head and calm emotions. If a pilot has suffered a stressful event such as a death of a loved one or needs to take some time off to release tensions and anxiety, they should. Some pilots may perform well under stress, but it may not be the smartest or safest decision.\nAccording to FAA rules, a pilot is not permitted to operate an aircraft if they are under the influence of alcohol, or have consumed an alcoholic beverage in the past eight hours. Additionally, if a pilot has a blood alcohol level of 0.4% or greater, they are to stay grounded.\nPilots should be on the lookout for intense exhaustion and fatigue. Spending lots of time in the air and going through jet lag can take their toll on judgment calls and maintaining a heightened awareness. If a pilot needs to get more sleep or does not recognize their need for rest because of fatigue, they can risk their lives and the lives of any passengers and crew on the aircraft during operation.\nPilots are professionals, but they too can suffer from bouts of depression, anxiety, stress, or emotional instability. When a pilot is not feeling of sound mind to fly an aircraft, they should not do so. Seeking out professional help for any emotional distress is helpful to get a pilot back to a healthy mental state to operate an aircraft better more safely.\nEnsuring Flight Safety Is Priority Number One\nCommercial pilots are enlisted to fly airplanes, helicopters, and charter jets. To maintain a standard of safe operation, pilots commit to going through various checklists in stages before even thinking about taking to the sky.\nTo reduce the risk of an accident, injury, or fatality while in an aircraft, checklists were established. A pilot is expected to execute thorough visual and physical examination of a plane’s working parts, keep meticulous records via logs, and communicate with maintenance, co-pilots, and other crew to ensure that an aircraft is in safe working order to fly.\nPatiently testing emergency systems, checking fuel and oil levels, and making sure that the right parts are left locked or unlocked can lessen the chance of something going wrong. Being aware of weather patterns, preparation in case of a detour, and being emotionally, mentally, and physically well enough to fly is vital to a safe flight every time.']	['<urn:uuid:06f051f4-64d3-4c40-886f-182a4740a448>']	factoid	direct	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-13T01:50:22.828293	17	59	1559
95	gaining losing weight cardio versus weights	The relationship between exercise type and weight management is complex. While low-intensity cardio has traditionally been recommended for fat loss due to its higher proportion of fat utilization during exercise, research shows that high-intensity exercise, particularly High-Intensity Intermittent Training (HIIT), may be more efficient for fat loss. Studies demonstrate that HIIT produces greater fat loss even with lower total energy expenditure. This is due to several factors: HIIT significantly increases post-exercise energy expenditure and fat utilization, enhances muscle metabolic activity, and suppresses appetite more effectively than lower intensities. However, the skeletal muscle's fuel usage varies depending on exercise intensity - during rest it primarily uses fatty acids, while during vigorous activity it shifts to glucose. The brain and cardiac muscles have different fuel preferences, with the brain requiring constant glucose supply and the heart preferring fatty acids under resting conditions.	"['BIOC13Winter2013 Lecture 12: Amino acid metabolism and metabolic integration\nAmino acid Metabolism\no Plants and bacteria synthesize all twenty amino acids, humans can only synthesize about half of the twenty amino acids\n(non-essential AAs). Rest must be acquired from dietary sources\no In general, the more complex amino acids are essential amino acids in humans as they require enzymes that have been lost\nfrom the human genome over evolutionary time.\no In animals, proteases present in stomach and intestines cleave the peptide bond to yield amino acids and small\no The carbon skeletons of all twenty amino acids are derived from just seven metabolic intermediates:\no three glycolytic pathway intermediates: 3-phosphoglycerate, phosphoenolypyruvate, and pyruvate\no two pentose phosphate pathway intermediates: ribose 5-phosphate and erythrose 4-phosphate\no two citrate cycle intermediates: -ketoglutarate and oxaloacetate\no Free amino acids in the body can be generated by degradation of cellular proteins which occurs continuously in all cells.\nMost eukaryotic cellular proteins are degraded by one of two pathways:\no an ATP-independent process that degrades proteins inside cellular vesicles called lysosomes\no an ATP-dependent pathway that targets specific proteins for degradation in proteasomes if they contain a polymer of\nubiquitin protein covalently attached to lysine residues.\no In order for proteins to be degraded by the proteasome, they are first ""tagged"" on lysine residues by covalent linkage of\nubiquitin. Ubiquitin is a 76 amino acid protein found in all eukaryotic cells that is specifically attached to proteins by\nubiquitin ligating enzymes.\no The proteins are cleaved by endo and exo-proteases/peptidases to individual amino acids\nAmino acid degradation\no Most AAs are de-aminated first by a process called transamination which basically transfers the amino group to an a-keto\nacid to yield an a-keto acid of the original AA and a new AA\no a-ketoglutarate is the main amino acid acceptor and yields glutamate and a keto acid\no Glutamate’s amino group can be transferred to oxaloacetate in a second transamination reaction, yielding Aspartate and\no Transamination is catalyzed by enzymes called aminotransferases or transaminases which require a coenzyme called\nThe Urea cycle\no Glutamate and glutamine function as the primary nitrogen carriers in most organisms. In mammals, this nitrogen ends up in\nthe liver where it is converted to urea.\no The two nitrogens in urea are derived from the 4H released when glutamate or glutamine are deaminated, and from\naspartate which is formed when oxaloacetate is transaminated by aspartate aminotransferase.\no The carbon atom in urea comes from CO2(HCO 3 that is produced in the mitochondrial matrix by the citrate cycle (the\noxygen atom is derived from 2 O in the final reaction of the cycle).\no Urea synthesis provides an efficient mechanism for land animals to remove excess nitrogen from the body. Urea is\nsynthesized in the liver and exported to the kidneys where it enters the bladder.\nAmino acid biosynthesis\no Arginine is listed as an essential amino acid because humans require arginine in their diet to support rapid growth during\nchildhood and pregnancy, even though it is made by urea cycle.\no Tyrosine is also highlighted because this conditional nonessential amino acid is made in humans from the essential amino\no In general, the structures of the essential amino acids are more complex than the nonessential amino acids which is\nreflected in the number of enzymatic reactions required for synthesis\no Metabolic flux through various amino acid biosynthetic pathways is tightly regulated by feedback inhibition to provide the\nrequired proportions of each amino acid in response to cellular needs.\no amino acids are precursors for a number of biomolecules\no heme comes from glycine and acetate\no purines and pyrimidines\no hormones and NTs synthesized by decarboxylation and hydroxylation of histidine, glutamate, tryptophan and tyrosine\no oxidation of arginine = NO which is signaling molecule in cells\no Numerous diseases are caused by defects in amino acid metabolic pathways; some of these diseases are genetic\ndiseases and can be due to recessive or dominant mutations of key enzymes in the pathways.\n2 o Metabolic homeostasis describes steady-state conditions in the body and can apply to a wide variety of physiological\no These include glucose, lipid, and amino acid levels in the blood, electrolyte concentrations, blood pressure and pulse rate.\no During times of physical activity, psychological stress, or feeding, biochemical processes are altered to counteract the effects\nof these environmental stimuli in an attempt to return the body to metabolic homeostasis.\no Regulation of metabolic homeostasis requires both neuronal signaling from the brain and the release of small molecules\ninto the blood that function as ligands for receptor-mediated cell signaling pathways.\no Disturbances in metabolic homeostasis leads to metabolic diseases such as diabetes.\no Flux through pathways depend on presence of appropriate enzymes and organismal/cell needs liver can carry out all the\nCellular Regulation of Metabolism\no Substrate availability\no Supply and demand\no Allosteric and feedback control\no 5’ AMP kinase (AMPK)\no Intracellular control in response to energy demands\no Hormonal/cytokine regulation\no Multi-organ control\no Response to serum levels of metabolites and metabolic state of body\nMetabolic integration through tissue specialization\no Metabolic pathways are specialized in the tissues\no Brain transports ions to maintain membrane potentials, inegrates inputs from body and surrounding, sends signals to\no Liver processes fats, carbs, proteins ; synthesizes and distributes lipids, ketone bodies and glucose; converts excess N to\no Skeletal muscle uses ATP to do mechanical work\no Cardiac muscle supplies body with blood (i.e oxygen and nutrients)\no Adipose Tissue synthesizs and stores and mobilizes triacylglycerols\nMetabolism in Brain\no Fuel reserves: Very little to none\no Strictly aerobic\no Very high metabolism (consumes 20% of total energy)\no Needs a constant supply of glucose from the blood (120g/day)\no Fuel: Glucose\no Fasting conditions: the brain can use Ketone bodies, but still requires carbohydrates (may also use lactic acid)\no Long chain FAs cannot cross the blood brain barrier because they are bound to the carrier proteins\no Fuel exported: None\nMetabolism in Muscle Cells\no Fuel reserve: glycogen (P-creatine), some FAs\no at rest – aerobic\no vigorous activity – anaerobic\no Preferred Fuel: Fatty acids, glucose when active\no Muscles must be prepared for rapid provision of energy\no Creatine kinase and phosphocreatine act as a buffer system, providing additional ATP for contraction\no Glycogen provides additional energy, releasing glucose for glycolysis\no Glycolysis rapidly lowers pH, causing muscle fatigue\no Fuel exported: Lactate, alanine, glutamine\no Hormones: Insulin, adrenaline\nEffects of exercise\no Short, vigorous (eg 100 m sprint)\no Free ATP P-creatine glycolytic ATP\no blood lactate increases and blood pH decreases. Acidosis causes fatigue.\no Longer duration(eg, 1000 m run)\no aerobic oxidation of muscle glycogen - energy produced at a slower rate.\no Very long periods of exercise (eg. marathon)\no liver glycogen supply – (even slower rate of supply)\n3 o Glycogen stores are insufficient to provide fuel required for marathon (require 150 mols ATP, glycogen ≈ 105 mols).\no Fat reserves – (slowest rate of energy production)\no Ketogenesis (generally only in conditioned athletes)\no Protein breakdown - This is a fuel of last resort for the fasting or exhausted organism\nMetabolism in Cardiac Muscles\no Due to continuous contractions, the cardiac\no muscles rely on aerobic metabolism\no Cells have high number of mitochondria (~40% of the cytoplasmic space)\no Heart can metabolize a number of energy sources: fatty acids, ketone bodies, glucose, pyruvate and lactate\no Under resting conditions fatty acids are the fuel of choice\no Under exercise conditions (increased heart rate), glucose derived from limited glycogen stores in the cells is used as a\nprimary source for the energy.\nMetabolism in Adipose tissue\no Fuel reserve: TAGs, some glycogen\no Metabolism: aerobic\no Preferred fuel: fatty acids, glucose\no Fuel exported: fatty acids, glycerol\no Hormones: insulin, Glucagon, adrenalin\no TAGs may account for as much as 65% of weight of fat cell.\no Receives exogenous TAGs in chylomicron from intestinal system (via lymphatic system and bypass liver)\no High blood glucose - glucose used for FA and TAG synthesis (FFAs from liver)\no Cells require a source of glucose to make TAGs (lacks glycerol kinase)\no Active player in metabolic integration serving as an endocrine organ t', ""As exercise intensity increases, the proportion of fat utilized as an energy substrate decreases, while the proportion of carbohydrates utilized increases (5). The rate of fatty acid mobilization from adipose tissue also declines with increasing exercise intensity (5). This had led to the common recommendation that low- to moderate-intensity, long duration endurance exercise is the most beneficial for fat loss (15). However, this belief does not take into consideration what happens during the post-exercise recovery period; total daily energy expenditure is more important for fat loss than the predominant fuel utilized during exercise (5). This is supported by research showing no significant difference in body fat loss between high-intensity and low-intensity submaximal, continuous exercise when total energy expenditure per exercise session is equated (2,7,9). Research by Hickson et al (11) further supports the notion that the predominant fuel substrate used during exercise does not play a role in fat loss; rats engaged in a high-intensity sprint training protocol achieved significant reductions in body fat, despite the fact that sprint training relies almost completely on carbohydrates as a fuel source.\nSome research suggests that high-intensity exercise is more beneficial for fat loss than low- and moderate-intensity exercise (3,18,23,24). Pacheco-Sanchez et al (18) found a more pronounced fat loss in rats that exercised at a high intensity as compared to rats that exercised at a low intensity, despite both groups performing an equivalent amount of work. Bryner et al (3) found a significant loss in body fat in a group that exercised at a high intensity of 80-90% of maximum heart rate, while no significant change in body fat was found in the lower intensity group which exercised at 60-70% of maximum heart rate; no significant difference in total work existed between groups. An epidemiological study (24) found that individuals who regularly engaged in high-intensity exercise had lower skinfold thicknesses and waist-to-hip ratios (WHRs) than individuals who participated in exercise of lower intensities. After a covariance analysis was performed to remove the effect of total energy expenditure on skinfolds and WHRs, a significant difference remained between people who performed high-intensity exercise and people who performed lower-intensity exercise.\nTremblay et al (23) performed the most notable study which demonstrates that high-intensity exercise, specifically intermittent, supramaximal exercise, is the most optimal for fat loss. Subjects engaged in either an endurance training (ET) program for 20 weeks or a high-intensity intermittent-training (HIIT) program for 15 weeks. The mean estimated energy cost of the ET protocol was 120.4 MJ, while the mean estimated energy cost of the HIIT protocol was 57.9 MJ. The decrease in six subcutaneous skinfolds tended to be greater in the HIIT group than the ET group, despite the dramatically lower energy cost of training. When expressed on a per MJ basis, the HIIT group's reduction in skinfolds was nine times greater than the ET group.\nA number of explanations exist for the greater amounts of fat loss achieved by HIIT. First, a large body of evidence shows that high-intensity protocols, notably intermittent protocols, result in significantly greater post-exercise energy expenditure and fat utilization than low- or moderate-intensity protocols (1,4,8,14,19,21,25). Other research has found significantly elevated blood free-fatty-acid (FFA) concentrations or increased utilization of fat during recovery from resistance training (which is a form of HIIT) (16,17). Rasmussen et al (20) found higher exercise intensity resulted in greater acetyl-CoA carboxylase (ACC) inactivation, which would result in greater FFA oxidation after exercise since ACC is an inhibitor of FFA oxidation. Tremblay et al (23) found HIIT to significantly increase muscle 3-hydroxyacyl coenzyme A dehydrogenase activity (a marker of the activity of b oxidation) over ET. Finally, a number of studies have found high-intensity exercise to suppress appetite more than lower intensities (6,12,13,22) and reduce saturated fat intake (3).\nOverall, the evidence suggests that HIIT is the most efficient method for achieving fat loss. However, HIIT carries a greater risk of injury and is physically and psychologically demanding (10), making low- and moderate-intensity, continuous exercise the best choice for individuals that are unmotivated or contraindicated for high-intensity exercise.\n1. Bahr, R., and O.M. Sejersted. Effect of intensity of exercise on excess postexercise O2 consumption. Metabolism. 40:836-841, 1991.\n2. Ballor, D.L., J.P. McCarthy, and E.J. Wilterdink. Exercise intensity does not affect the composition of diet- and exercise-induced body mass loss. Am. J. Clin. Nutr. 51:142-146, 1990.\n3. Bryner, R.W., R.C. Toffle, I.H. Ullrish, and R.A. Yeater. The effects of exercise intensity on body composition, weight loss, and dietary composition in women. J. Am. Col. Nutr. 16:68-73, 1997.\n4. Burleson, Jr, M.A., H.S. O'Bryant, M.H. Stone, M.A. Collins, and T. Triplett-McBride. Effect of weight training exercise and treadmill exercise on post-exercise oxygen consumption. Med. Sci. Sports Exerc. 30:518-522, 1998.\n5. Coyle, E.H. Fat Metabolism During Exercise. [Online] Gatorade Sports Science Institute. http://www.gssiweb.com/references/s...020000006d.html [1999, Mar 25]\n6. Dickson-Parnell, B.E., and A. Zeichner. Effects of a short-term exercise program on caloric consumption. Health Psychol. 4:437-448, 1985.\n7. Gaesser, G.A., and R.G. Rich. Effects of high- and low-intensity exercise training on aerobic capacity and blood lipids. Med. Sci. Sports Exerc. 16:269-274, 1984.\n8. Gillette, C.A., R.C. Bullough, and C.L. Melby. Postexercise energy expenditure in response to acute aerobic or resistive exercise. Int. J. Sports Nutr. 4:347-360, 1994.\n9. Grediagin, M.A., M. Cody, J. Rupp, D. Benardot, and R. Shern. Exercise intensity does not effect body composition change in untrained, moderately overfat women. J. Am. Diet Assoc. 95:661-665, 1995.\n10. Grubbs, L. The critical role of exercise in weight control. Nurse Pract. 18(4):20,22,25-26,29, 1993.\n11. Hickson, R.C., W.W. Heusner, W.D. Van Huss, D.E. Jackson, D.A. Anderson, D.A. Jones, and A.T. Psaledas. Effects of Dianabol and high-intensity sprint training on body composition of rats. Med. Sci. Sports. 8:191-195, 1976.\n12. Imbeault, P., S. Saint-Pierre, N. AlmÃ©ras, and A. Tremblay. Acute effects of exercise on energy intake and feeding behaviour. Br. J. Nutr. 77:511-521, 1997.\n13. Katch, F.I., R. Martin, and J. Martin. Effects of exercise intensity on food consumption in the male rat. Am J. Clin. Nutr. 32:1401-1407, 1979.\n14. Laforgia, J. R.T. Withers, N.J. Shipp, and C.J. Gore. Comparison of energy expenditure elevations after submaximal and supramaximal running. J. Appl. Physiol. 82:661-666, 1997.\n15. Mahler, D.A., V.F. Froelicher, N.H. Miller, and T.D. York. ACSM's Guidelines for Exercise Testing and Prescription, edited by W.L. Kenney, R.H. Humphrey, and C.X. Bryant. Media, PA: Williams and Wilkins, 1995, chapt. 10, p. 218-219.\n16. McMillan, J.L., M.H. Stone, J. Sartin, R. Keith, D. Marple, Lt. C. Brown, and R.D. Lewis. 20-hour physiological responses to a single weight-training session. J. Strength Cond. Res. 7(3):9-21, 1993.\n17. Melby, C., C. Scholl, G. Edwards, and R. Bullough. Effect of acute resistance exercise on postexercise energy expenditure and resting metabolic rate. J. Appl. Physiol. 75:1847-1853, 1993.\n18. Pacheco-Sanchez, M., and K.K Grunewald. Body fat deposition: effects of dietary fat and two exercise protocols. J. Am. Col. Nutr. 13:601-607, 1994.\n19. Phelain, J.F., E. Reinke, M.A. Harris, and C.L. Melby. Postexercise energy expenditure and substrate oxidation in young women resulting from exercise bouts of different intensity. J. Am. Col. Nutr. 16:140-146, 1997.\n20. Rasmussen, B.B., and W.W. Winder. Effect of exercise intensity on skeletal muscle malonyl-CoA and acetyl-CoA carboxylase. J. Appl. Physiol. 83:1104-1109, 1997.\n21. Smith, J., and L. McNaughton. The effects of intensity of exercise on excess postexercise oxygen consumption and energy expenditure in moderately trained men and women. Eur. J. Appl. Physiol. 67:420-425, 1993.\n22. Thompson, D.A., L.A. Wolfe, and R. Eikelboom. Acute effects of exercise intensity on appetite in young men. Med. Sci. Sports Exerc. 20:222-227, 1988.\n23. Tremblay, A., J. Simoneau, and C. Bouchard. Impact of exercise intensity on body fatness and skeletal muscle metabolism. Metabolism. 43:814-818, 1994.\n24. Tremblay, A., J. DesprÃ©s, C. Leblanc, C.L. Craig, B. Ferris, T. Stephens, and C. Bouchard. Effect of intensity of physical activity on body fatness and fat distribution. Am J. Clin. Nutr. 51:153-157, 1990.\nTreuth, M.S., G.R. Hunter, and M. Williams. Effects of exercise\nintensity on 24-h energy expenditure and substrate oxidation. Med. Sci.\nSports Exerc. 28:1138-1143, 1996.""]"	['<urn:uuid:da229e2d-11f7-43e0-8209-9bbea5aa44e1>', '<urn:uuid:25a03c89-2aa5-416c-8029-8b4cbdaaa28d>']	open-ended	with-premise	short-search-query	distant-from-document	multi-aspect	novice	2025-05-13T01:50:22.828293	6	140	2711
96	What makes it impossible for people to live in certain regions according to the Jain view of the world?	According to Jain cosmology, there is a mountain range called Mānuṣottara, represented as the outermost pale pink ring, which symbolizes the limit beyond which human beings cannot live.	['This is the traditional representation of the world inhabited by human beings in Jain cosmology. It is made up of alternate concentric rings of continents, mountains and oceans.\nLike any map, this one has captions, which are of two types:\n- geographical features, for example nadī for ‘river’, kūṭa for ‘mountain peak’\n- proper names, for example Ayodhyā is the name of a town and Raktāvatīnadī is the name of a river.\nEach part of the Jain world has named rivers, mountains, towns, caves and so on. Since symmetry and repetition are two of the major organising principles of the Jain world, the names are often the same in different regions.\nAt each of the four angles of the picture is a Jain temple with worshippers. This is intended to show that the Jinas‘ teachings are everywhere in the world.\nOn each side of these temples, there are lines of text written in small script. They provide additional detail about the Jain universe, describing each component, giving dimensions and occasional quotations from scriptures.\nLocation in painting\nBottom left-hand corner:\nBottom right-hand corner\nmeasurements of Kālodadhi and Puṣkara-dvīpa\nTop right corner\nTop left corner\nmeasurements of the Lavaṇa-samudra\nTwo and A Half Continents\nThe outermost pale pink ring is a mountain range called Mānuṣottara. It symbolises the limit beyond which human beings cannot live.\nThe two textured grey rings represent two oceans. The innermost one is the ocean called Lavaṇa-samudra – ‘Salt Ocean’. The second one is Kālodadhi – ‘Black-Water Ocean’.\nThe three spaces in between these three rings form the human world, which is called Aḍhāī-dvīpa – ‘Two and A Half Continents‘. Starting from the centre, they are:\nHalf of Puṣkara-dvīpa is in the world of humans while half is the other side of the mountain range marked by the pale pink circle. This is why the complete map of the human world is called ‘Two and A Half Continents‘.\nThe thick red vertical line divides the Dhātakīkhaṇḍa and the Puṣkara-dvīpa into two halves, eastern and western. There are four Jinas sitting within the line. The four segments of this line on land represent a mountain range known as Iṣvākāra – ‘Arrow-like’ – because it is perfectly straight. Its name is written on the lowest segment.\nThe five yellow disks going horizontally across the centre represent the central mountain, called Mount Meru. The Jambū-dvīpa has one in its middle while both the two other continents have identical Mount Merus in each half.\nEither side of each Mount Meru are two semicircles, indicated by one green and yellow line, the other a red and white line. They are the boundaries of two regions. The northern one is called Uttara-kuru, the southern one Deva-kuru. These regions are the Lands of Enjoyment, where people get all they need from ‘wishing trees’ – kalpa-vṛkṣas – and do not need to make any effort. Couples made up of twin boys and girls live in the Lands of Enjoyment.\nThe first continent, in the centre, is Jambū-dvīpa. It is divided into parts separated by mountain ranges.\nFrom north to south there are eight mountain ranges. They are shown as double horizontal lines as they cross the Jambū-dvīpa from east to west. Here, the first and eighth are not coloured. The second, third, sixth and seventh are coloured in yellow. The most conspicuous on all maps are the fourth and fifth, respectively always green and red.\nThe names of all these mountains are not given in this map, but they are well known among Jains. Between these mountain ranges are seven regions. From north to south, the mountains and regions separating them are listed in the table.\nHairaṇyavata – identified on the map\nRamyaka – identified on the map\nMahā-videha – see below\nBharata – identified on the map\nAcross the centre of Jambū is a large rectangular strip marked out by a green line in the north – the Nīla mountain range – and a red one in the south – the Niṣadha mountain range. This is the Mahā-videha, which has Mount Meru at its centre. The Mahā-videha is a land of wonders, where Cakravartins go and where Jinas preach.\nThe Mahā-videha is divided into 32 provinces, distributed as eight groups of four, equally in the north-east, south-east, north-west and south-west. They are always shown as small rectangles, like here.\nThe first ocean, starting from the centre, is the thick grey ring around Jambū. Called Lavaṇa-samudra, it has sets of pots in each of the four directions. These are the ‘great receptacles’ – pātāla-kalaśas – that cause the tides.\nThere are two horizontal yellow lines ending with double hook shapes shown in the north and south of this ocean. These are two mountain chains that end with double pairs of ‘tusks’ jutting out into Lavaṇa-samudra. These tusks carry the 56 islands known as Antara-dvīpas. The islands are divided into seven groups of eight, although they are not shown on this map.\nEverywhere on this map, a multitude of grey rivers flows and irrigates the land. Small yellow circles are the islands of the moons and the suns, which vary in number from place to place.']	['<urn:uuid:9fdc5343-9e44-4d00-8115-6ae18a1445ea>']	open-ended	direct	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-13T01:50:22.828293	19	28	859
97	I'm planning a home addition and wondering what costs more - having an architect design it or just working directly with a contractor?	Working with an architect typically adds 10-17% to the total project budget, while working directly with a contractor can be less expensive initially. However, having an architect can actually help control costs in the long run by providing clearer plans that lead to more accurate cost estimates. While a contractor can handle simple additions like a basic family room, an architect is recommended for complex projects involving wall movements or intricate design changes. Additionally, both paths require proper permits, which if skipped can result in fines, work stoppages, and requirements to redo the work. The permit costs range from about $100 for small projects to over $900 for larger additions.	"['Do you need a permit to renovate your bathroom? What about to build a deck?\nIt can be confusing for homeowners to figure out, but shouldn’t be ignored.\n“We’re removing an inside wall to make a more open space and actually moving the kitchen to the opposite of the room, making it an open kitchen with an island,” Homeowner Mark Stauffer said.\nMark Stauffer has lived in this home for 35 years and he decided it’s time to make some updates.\n“There is electrical, plumbing, and structural work being done and those all require permits,” he said.\nWhether your home improvement project requires a permit varies depending on where you live, but most laws require that you not build, move, significantly alter or add to a building without a permit.\n“It actually provides you important protection. For example, in some scenarios a contractor must be licensed in order to get the permit so it adds an extra layer of protection for you,” Founder Angie Hicks said.\nRemodeler Thomas Pearson says a fair amount of planning must be done before pulling a permit.\n“It’s very important that if a room addition is being built that the setbacks are correct. There’s a certain amount you are supposed to have and planning is the most important part of the job. If the planning is done very well in the beginning then the rest of the job will run well,” Thomas Pearson said.\nA permit for a small project may range in the $100 range or less, while a bigger project like a home addition can cost more than $900.\nIf you skip the permit process in order to save a few bucks Angie’s List warns you could end up paying more in the long run.\n“If you skip pulling a permit you might end up paying fines, it could stop the work being done, they may make you re-do it. In some scenarios when it comes down to electrical work and the electrical work causes a fire your homeowner’s insurance may not cover it,” Hicks said.\nAngie’s List says if a contractor asks you to pull your own permits that could be a red flag the contractor isn’t insured or doesn’t have the required license to do the work.\nSo where do you go to learn if your project requires a permit?\nNo matter whether you are hiring a contractor or doing the work yourself, check with your local building department.Do your own research and question any contractor who remodels without pulling a permit.\nThe pitfalls of not pulling a permit:\n· Fines & penalties: In the off chance that code enforcement authorities flag these violations, homeowners can face fines and penalties that far exceed the cost of permits not pulled, and the city may require contractors or DIYers to tear out work, such as drywall, and do it over.\n· Will you be covered? Not all code violations come back to bite the homeowner in the form of shoddy work that needs repair or city fines. But experts say if, for example, a homeowner does electrical work without proper permitting and problems down the road spark a fire, a homeowner’s policy may not pay for damages.\nAngie’s List Tips: Permits\n· What projects require a permit? Although the requirement for a permit varies from jurisdiction to jurisdiction, most laws require that you not build, move, significantly alter or add to a building without receiving a permit issued by local code enforcement officials. If you’re doing the work yourself or not sure whether contract work has been inspected, experts advise calling your municipality’s code enforcement authority to schedule a follow-up inspection.\n· Where to look: Not sure if that job you’re DIYing requires a permit, or want to double-check for a contracted job? To check local permitting requirements, contact your city’s code enforcement department or your county if you live in a rural area. You can also typically check online, such as at your city’s code enforcement Web page, for a list of project types that require a permit in your area.\n· How much is a permit? For a small project, such as installing a new toilet, a plumbing permit may run in the $100 range or less, while for an addition, such as adding a bedroom onto a home, a building permit may run more than $1,000. Some municipalities offer fee calculators online. Ask the contractor if that cost is included in the contract?\n· Red flags: In many cases, a remodeling contractor must first be properly licensed with a municipality before they can obtain a building permit, which adds an extra layer of consumer protection to your next home remodeling project. If they ask you to pull your own permits, that could be a red flag the contractor isn’t insured or doesn’t have the required license to do the work. Don’t take a contractors word on it. Do your own research. Question any contractor who remodels without pulling a permit.\n· Can I get a copy? Request copies of all permits issued for your project. A contractor that doesn’t possess the proper licenses, bonds, and permits might be unqualified to work on your home.\n· Buying a new home: If you’re buying or building a home, insist on a thorough inspection before finalizing the purchase or moving in, and secure paperwork on previous renovations. The seller must provide full disclosure when selling a home. Ask what remodeling has been done and the permits that were pulled.\nCopyright 2016 Nexstar Broadcasting, Inc. All rights reserved. This material may not be published, broadcast, rewritten, or redistributed.', ""The average national cost of adding a room or building an addition is $40,825, with most homeowners spending between $21,044 and $63,685. This data is based on actual project costs as reported by HomeAdvisor members.\nMany homeowners eventually come to that daunting dilemma: whether to buy their dream house or transform their current home into that dream. Once you make the commitment to build an addition, you've probably decided to go down the latter road. This decision might be something you've long considered, or it may have been thrust upon you by an expanding family. In either case, recognize that this will be a profound investment in time and money, but one that, if done properly, will enhance the value of your most important investment: your home.\nWhat Type of Addition Are You Planning?\nYou can choose from several types of additions for an average house, including ground level additions, second floor additions and detached additions. Each option has its own benefits, drawbacks and estimated prices based on factors such as the size of the structure and the features that you want to incorporate.\nAn extra room means exactly that. Homeowners who choose this type of an addition often do so to add a family room, bedroom or multiple spaces. When you want to add an additional room to your home, you typically have two options: build out or build up.\nThis is a major construction project that involves creating an additional building structure and integrating it with the rest of the home. Average costs run anywhere from $80 to $200 per square foot. No matter whether you build out or up, you should:\nConsult with an architect before getting started to make sure that the design looks cohesive with the rest of your home, which will help enhance the resale value\nHire a structural engineer to make sure the plans are safe and sound\nHire a general contractor or a remodeling company\nBuilding out typically involves adding a room at ground level, which is one of the most popular types of additions. These options increase the footprint of your home by extending the house’s perimeter outward, which offers minimal disruption to the rest of the home. Potential drawbacks of building out include the cost of having to pour a new foundation, the loss of yard or property space and the possibility that you may need to get a zoning variance depending on local regulations.\nIf you want to expand your living space without increasing the footprint of your home, building up is a great option. For this type of addition, you add a room to the second story, or you could add an entire second story onto a one story home. Even though your contractor won't need to create a new foundation, he may need to strengthen the existing foundation to support the extra weight. On the downside, you need to check your town's rules to make sure you're not limited in the height of your home. Additionally, you'll need to add a staircase, which typically uses up 80 to 120 square feet of living space.\nSunrooms offer a budget-friendly alternative to a traditional house addition. Average costs run anywhere from $16,315 for the average sunroom, up to $70,000 or more for a 200-square foot addition with footings and a slab foundation. The cost of this project depends on the amount of space it adds, the location of the sunroom, extras such as electrical wiring and whether the room is heated (four-season room) or not heated (three-season room). Other considerations include hiring:\nElectricians: Charge an average of $50–$100 per hour\nCarpenters: Charge around $70 per hour\nPainters: Typically charge $20–$35 per hour\nBuying a prefabricated sunroom runs around $11,000 per 150 square feet. Once you factor in adding heat, electricity and all the construction costs, it's not unusual to pay between $300 and $400 per square foot for the finished product. If you want to keep the costs low, consider adding the sunroom as a three-season room without heating.\nBefore you decide on a sunroom, get a few estimates to make sure you’re getting the most competitive prices. Meet with a professional who can help assess the space, take accurate measurements and recommend the finishes and construction methods that will work best for you, your property and your climate.\nDetached additions can range in style and price, with prefabricated, simple shed-like rooms running around $15,000 without electricity or heat, or full guesthouses that share similar costs as a detached garage addition, which run around $24,658 on average. Like the other types of additions, you’ll need a contractor to help install and finish your detached addition. You’ll also need an electrician to add the necessary wiring and painters to finish the walls.\nAs with any other addition, the materials you choose have a direct impact on the cost of this project. Consider the following:\nAre you buying a prefabricated addition?\nAre you building the addition from the ground up (you might need an architect for an extra $4,811 average cost)\nDoes the area need excavation? (Excavation costs average $70 per cubic yard)\nWhat will the exterior look like? Should it match your home? (Siding costs $2 to $7 per square foot)\nWhen you’re planning your budget for this project, you need to consider many different factors, including the square footage and the size of the addition. The larger you go, the more expensive the project will be. Other important factors include necessary services, including:\nArchitectural services make sure that the design of the new addition looks good with the style of the home. This typically accounts for 10% to 17% of the total project budget.\nExcavation, demolition and site-preparation costs vary depending on the amount of work that needs to go into the prepping. For example, removing a wall costs $300–$500, while excavation costs around $2,559 on average.\nPouring concrete footings and a slab foundation costs an average of $75 per cubic yard\nThe support beams and roof trusses have to be integrated with the rest of the home's structure. The average cost runs from $15–$30 per square foot, depending on the lumber charges and labor costs.\nRoofing for the new addition averages $80–$100 per square foot for asphalt shingles and galvanized metal flashing. Metal roofing and slate are two pricier options.\nInstalling vinyl siding and trim finishes the exterior of your addition for an average cost of $7 per square foot.\nFinishing the interior by drywalling the ceiling and walls costs an average of $9.80 for each 4-foot by 8-foot sheet of drywall.\nInsulation costs $2 per square foot.\nA door costs anywhere from $175 or more, depending on the material and the style of the door.\nAdding windows for light and ventilation costs an average of $300–$700 per window.\nMolding for ceilings costs around $3 per foot.\nElectrical wiring and making sure the electrical system is up to code is important and it requires a licensed electrician, which typically costs $50–$100 per hour.\nFlooring options include ceramic tile ($1,640), carpeting ($1,490), laminate ($2,748), vinyl/linoleum ($1,185), natural stone tile ($1,826) or wood flooring ($4,396).\nTying into the existing HVAC system varies in cost, but the average cost for installing ducts and vents is $1,050.\nThe answer to this depends on the complexity of the addition. If you’re adding a simple family room onto your home with one door into the rest of the house and one to the outside, a contractor should be able to handle it without the help of an architect. If you're moving walls, redesigning the way one room flows into another, adding a half loft and a spiral staircase or planning countless other complicated or intricate changes to your existing home, you may want to consider bringing an architect on board.\nAn architect will certainly add to your upfront costs on the project, but consider that a professional engineer can take your ideas and build them into something even more amazing. Also, by adding more clarity to your vision before construction starts, cost estimates will hit closer to the mark. When the project is done in partnership with an architect, you're also more likely to wind up with something that boosts your home’s value.\nEven if you have no plans to sell anytime soon, consider the resale value of your project. You might not always turn a profit on your home-expansion investment, but you should go into the job with realistic expectations about at least some kind of payback.\nBecause they're among the most expensive home projects, additions sometimes return less on your investment than remodels. If you're significantly adding to the square footage of your home or adding important types of rooms, such as bedrooms and bathrooms, your investment may pay off considerably.\nGet everything in writing. First, agree on a total amount before discussing anything further.\nIt's reasonable for contractors to expect some money in advance, and then again after specific milestones during the course of the project. Be aware that shelling out too much money could put you at risk, and giving too little could put your contractor at risk. It's a delicate dance, but one that should be precisely choreographed before anybody fires up the power tools.\nStill, no matter how detailed your plan is, remember that things happen. Find out about your contractor's change-order policy. Once you see your addition come to life, you may change your mind about the colors, fixtures or even the layout of the room. You may find that the contractor didn't understand your plan and made some decisions that didn't square with what you'd intended. Or, the addition may run into problems that neither you nor the contractor could have foreseen. Each of these could have enormous effects on the cost of the project, and each can cause friction with your contractor. Minimize the conflicts by spelling out, as clearly as possible on the front end, how each of these contingencies would be handled.\n65% for a two story addition with an upstairs master suite and a downstairs living area\n#2 Will an addition look like it was tacked on?\nWithout the services of a designer or an architect, you could be left with an addition that looks like an afterthought or an obvious add-on feature. Skilled designers can create the space you want and deftly tie it into the existing structure so that it looks like it was always there.\n#3 Do I need to worry about restrictions?\nAlways check with your local government to research zoning restrictions. In some areas, you may not be able to build within a certain number of feet of the front, sides or rear of the property lines. Other areas have rules about how much space on your property can be covered with buildings, how close you can get to protected spaces such as wetlands or how high you can build up.\n#4 What should I look for in a contractor or a remodeling company?\nVerify that the pros are licensed and insured. Check references and ask for pictures of their prior work. Ask the pros how long they've been doing this work, how they screen subcontractors and how long they expect the project to take. Get estimates from at least two or three contractors to get the most competitive prices and find the one that's going to work best for you.\n#5 What should my first step be?\nCreate a plan for your new room, find a contractor to do the work and get all the necessary permits. This kind of a major project requires local permits to make sure the work is done according to building codes.\nAdding on to a house is a very expensive project, but there are ways to shave money off your budget. For example, in some cases you may be able to remodel instead of add on. Maybe you could finish the basement (average cost $2,852) to provide an extra bedroom with a bathroom or a living space. Increasing the efficiency of your space can make an expansion unnecessary. For example, adding 200 square feet of space onto a kitchen could cost anywhere from $48,000 to $95,000. Swapping your old cabinets out for better-organized, custom cabinets costs around $35,000, but it might be all you need, which saves $13,000 to $60,000.\nOther money-saving options include using detached additions instead of attached ones. A prefabricated detached structure could cost less than $20,000, and it could be used as a guesthouse or an office to provide the extra space that you want. Often, building up also saves money by avoiding excavation costs and the need for pouring a new foundation.\nLastly, consider how handy you might be. Tackle any DIY projects — such as laying flooring, painting the walls or installing a new vanity — on your own instead of paying a contractor to the work. Doing your own demolition, for example, can save you more than $500 in labor charges.""]"	['<urn:uuid:a24e347e-90cc-4e1f-a3dc-e7a5107e87da>', '<urn:uuid:5ccc7ee8-3aba-4613-87f9-37ee550676c3>']	open-ended	with-premise	verbose-and-natural	distant-from-document	comparison	novice	2025-05-13T01:50:22.828293	23	110	3092
98	who handles diabetes education zufall center	At Zufall Health Center, clinical pharmacists provide patients with in-depth diabetes education and medication management through several consultation sessions, rather than primary care providers.	['Ellen Robinson, MHS, PMP, is the Director, Information Resources and Outreach, in NACHC’s Clinical Affairs Division.\nIn providing chronic disease care management to health center patients, care teams are doing so with an understanding and sensitivity that many patients face one or more environmental and/or educational barriers. Reducing heart disease takes an all-hands-on deck approach.\nMultidisciplinary approach is key\n“Truly, we have a whole team approach,” says Cynthia L. Jones, MD, Chief Medical Officer, Mosaic Health. “From the scheduler to the lab schedulers and techs, nursing staff, social workers, insurance managers, pharmacy staff, and providers – everyone is involved… The days of working in a silo as a physician are over.”\nAt Zufall Health Center, Rina Ramirez, MD, Chief Medical Officer, shares that as part of their multidisciplinary approach, clinical pharmacists (rather than primary care providers) provide patients with more in-depth diabetes education and medication management through several consultation sessions. In addition, needs assessments by different care team members are performed to ensure barriers that may impact a patient’s care are captured. Care team members then collaborate and coordinate care and services such as nutritional counseling, low cost or free healthier foods, low-cost medications or laboratory services, medication education, behavioral health counseling, etc.\nEducating patients through ongoing engagement\nOngoing high-touch engagements with patients about their chronic conditions is also a core part of many chronic disease management programs. “The single best thing we can do is educate and motivate our patients,” advises Keith Ferdinand, MD, Gerald S. Berenson Endowed Chair in Preventive Cardiology, Professor of Medicine, Tulane School of Medicine. Information should be simple and clear (e.g. simple low-lit infographics) and culturally appropriate. For older adults, Ferdinand recommends using caution when directing these patients to websites because they may not use the Internet to search up health information and if they do, they tend to find a lot of misinformation.\n“We take our time to educate high-risk patients through phone calls and in person and we give them a lot of time to ask questions,” says RN Managers Christine Lynch, RN, and Rebecca Horning, RN, Mosaic Health. “We’re constantly myth busting or helping patients get past a bad experience (when using statins). We spend a lot of time on the ‘why’ and ask ‘what’s preventing you from taking your statins?’” Once the care team knows the “why” they can get patients resources that help solve a specific problem.\nChronic disease strategies at-a-glance\n- Run Gap reports in EHR systems to identify patients who need treatment intensification, follow-up, lab work, or needs assessments to address barriers and/or gaps in care.\n- Feedback from both staff and patients is key to enhancing and improving patient care.\n- Incorporate high-touch education touchpoints during the visit with “teach back” opportunities and two-way conversations that meet patients where they are.\n- Avoid overwhelming patients with too much information that is difficult to understand. Use motivational interviewing to hone in on one goal or action they can work toward.\n- Conduct frequent follow-up phone calls and/or virtual video calls to help keep patients engaged and on track with their medication regimen and/or behavioral lifestyle changes.\n- Educate teams, from front to back office so everyone understands the health center’s efforts to reduce blood pressure, cholesterol, A1C, etc. among patients with chronic conditions and can support a to chronic disease care.']	['<urn:uuid:9bcb4e09-df7d-4eab-b589-c52b6bedc82d>']	factoid	direct	short-search-query	distant-from-document	single-doc	expert	2025-05-13T01:50:22.828293	6	24	554
99	What is the interesting history behind when humans first started swimming, and how did it evolve into competitive swimming as we know it today?	Swimming has been recorded since prehistoric times, with the earliest evidence found in Stone Age paintings from around 7,000 years ago. Competitive swimming as we know it today began in the United States around 1800, primarily using breaststroke. It became part of the first modern Olympic Games in 1896 in Athens. The front crawl was introduced to the Western world in 1902, and butterfly was developed in the 1930s, initially as a variant of breaststroke, before being accepted as a separate style in 1952.	['The sport of swimming has been recorded since prehistoric times; the earliest recording of swimming dates back to Stone Age paintings from around 7,000 years ago. Competitive swimming as we know it today started in the United States started around 1800, mostly using breaststroke. Swimming was part of the first modern Olympic Games in 1896 in Athens. In 1902 the front crawl was introduced to the Western world. Butterfly was developed in the 1930s and was at first a variant of breaststroke, until it was accepted as a separate style in 1952.\nCompetitive swimming became popular in the nineteenth century. Swimming is an event at the Summer Olympic Games, where athletes compete in 16 of the recognized events each. Olympic events are held in a 50-meter pool, called a long course pool. There are forty officially recognized individual swimming events in the pool; however the International Olympic Committee only recognizes 32 of them.\nIn open water swimming, where the events are swum in a body of open water (lake or sea), there are also 5 km, 10 km and 25 km events for men and women. However, only the 10 km event is included in the Olympic schedule, again for both men and women. Open-water competitions are typically separate to other swimming competitions with the exception of the World Championships and the Olympics.\nMost swimming sport events are held in special competition swimming pools, which are either long course pools such as those used in the Olympic Games (50 m) or short course pools such as those used in the FINA World Swimming Championships (25 yards or 25 m but generally 25m). Competition pools have starting blocks from which the competitor can dive in, and possibly also touch-sensitive pads to electronically record the swimming time of each competitor.\nPara-swimming is Swimming Canada’s fully integrated swimming program for persons with a disability from grassroots to elite.\nPara-swimming combines a broad range of disabilities into three categories\nAmputees/Dysmelia; cerebral palsy/head injury; spinal cord injury/polio; dwarfism\nOthers (Major joint restrictions, coordination restriction, limb paralysis/weakness)\nBlind; visually impaired\nPara-swimming grew out of several different movements in the 1940’s and 1950’s. During this time, four international sports bodies, divided by means of medical disability eventually combined to form the modern day Paralympic movement. Swimming Canada became the first integrated National Sports Organization in 1993.\nToday, a “sport-first” approach is being taken and international groups have moved towards representing specific sports, with consideration of a person’s disability as a secondary factor. The world sport governing body for persons with a disability, including swimming, is the International Paralympic Committee and it operates with sport specific committees that oversee the development of sport for the disability groups.\nThere are several types of officials, which are needed to manage the competition.\nThe referee has full control and authority over all officials. The referee will enforce all rules and decisions of FINA and shall decide all questions relating to the actual conduct of the meet, and event or the competition, the final settlement of which is not otherwise covered by the rules. The referee takes overall responsibility for running the race and makes the final decisions as to who wins the competition. Referees call swimmers to the blocks with short blasts of his or her whistle. This is the signal for the swimmers to stand next to their blocks. Starters call missing swimmers if necessary. Then the referee will blow a long whistle that will tell the swimmers to step on the block. For backstroke otherwise known as back crawl events, the long whistle is the signal for the swimmers to step in the water. The referee will then blow another long whistle, signaling the swimmers to grab the gutter or the provided block handle (for backstroke/back crawl events only). The referee will then hand over control to the starter.\nThe starter has full control of the swimmers from the time the referee turns the swimmers over to him/her until the race commences. A starter sends the swimmers off the blocks and may call a false start if a swimmer leaves the block before the starter sends them.\nThe clerk of course assembles swimmers prior to each event, and is responsible for organizing (“seeding”) swimmers into heats based on their times. Heats are generally seeded from slowest to fastest, where swimmers with no previous time for an event are assumed to be the slowest.\nThere are three timekeepers for each lane. Each timekeeper takes the time of the swimmers in the lane assigned to him/her. Unless a video backup system is used, it may be necessary to use the full complement of timekeepers even when automatic officiating equipment is used. A chief timekeeper assigns the seating positions for all timekeepers and the lanes for which they are responsible. The chief timekeeper collects from the timekeepers in each lane a card showing the times recorded and, if necessary, inspect their watches. One timer will be timing with a stopwatch, another recording it down, and one making sure everything is valid.\nOne inspector of turns is assigned to each lane at each end of the pool. Each inspector of turns ensures that swimmers comply with the relevant rules for turning as well as the relevant rules for start and finish of the race. Inspectors of turns shall report any violation on disqualification reports detailing the event, lane number, and the infringement delivered to the chief inspector of turns who will immediately convey the report to the referee.\nJudges of stroke are located on each side of the pool. They ensure that the rules related to the style of swimming designated for the event are being observed, and observe the turns and the finishes to assist the inspectors of turns.\nFinish judges determine the order of finish and make sure the swimmers finish in accordance with the rules (two hands simultaneously for breaststroke and butterfly, on the back for backstroke, etc.)']	['<urn:uuid:1115a830-fa4e-493d-8787-4771b874ed7a>']	open-ended	direct	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-13T01:50:22.828293	24	84	988
100	how many types of tapeworm species exist	More than 1,000 species of tapeworms have been identified	"[""Yes, There is a Tapeworm Diet. No, You Should Not Try It!3 years ago | Nutrition\nBy Joy Stephenson-Laws, JD, Founder\nHave you ever heard about the Victorian Tapeworm Diet? This diet involves swallowing a parasite (a potentially disease-causing organism). It reportedly gained popularity in the early 1900s among Victorian women who were put under immense pressure to be thin, wear tight corsets and “look perfect.”\n“The idea is simple, and gross. You take a pill containing a tapeworm egg. Once hatched, the parasite grows inside of the host, ingesting part of whatever the host eats. In theory, this enables the dieter to simultaneously lose weight and eat without worrying about calorie intake,” according to one source.\nWhile the possibility of being able to eat whatever you want and still lose weight may sound appealing, tapeworms may cause major harm to the host.\nThe first thing to know is that the term “tapeworm” actually refers to several different types of parasites that can make their home in the human intestine for a very long time – sometimes for 20 years! These parasites are considered to be in the taxonomic class of flatworms called Cestoda, and more than 1,000 species have been identified.\nThey are categorized by where they live before their eggs infect their human host via consumption of raw or undercooked meat, animal feces or contaminated water. Tapeworms may be found in pork, beef, fish and dog.\nHere are some different types of tapeworms:\n- Taenia saginata (beef tapeworm)\n- Taenia solium (pork tapeworm)\n- Taenia asiatica (Asian tapeworm, also called Asian fish tapeworm)\nThese species of tapeworms cause the parasitic infection taeniasis.\nTapeworms are equal-opportunity parasites that show absolutely no preference for gender, ethnicity or age. With that said, children are more prone to getting them since they usually are not all that careful with hand-washing and personal hygiene, both of which can limit the spread and infection with the parasite.\nTapeworms can grow very long in a host and interfere with proper organ function. In this case, doctors removed a six-foot long tapeworm from a man's intestine. Several sources even say that tapeworms can grow to 30 feet or even 80 feet inside a host! Tapeworms may even cause epilepsy, meningitis and dementia.\nUnless you deliberately swallow some tapeworm eggs (as someone following the tapeworm diet would do), if you have a tapeworm you may not even know it since most people have no symptoms. Symptoms of having tapeworms usually include:\n- Being tired all the time or general weakness\n- Gastrointestinal distress such as stomach pain, nausea, vomiting and diarrhea\n- Weight loss without going on a diet or changing your exercise routine\n- Sleeping difficulties\n- Seeing tapeworm eggs, larvae or segments from the tapeworm’s body in your stool\nTaeniasis can develop into cysticercosis, which is an infection of the tissue. Cysticercosis is caused by larval cysts of the pork tapeworm. “These larval cysts infect brain, muscle, or other tissue, and are a major cause of adult onset seizures in most low-income countries. A person gets cysticercosis by swallowing eggs found in the feces of a person who has an intestinal tapeworm. People living in the same household with someone who has a tapeworm have a much higher risk of getting cysticercosis than people who don’t,” reports the Centers for Disease Control and Prevention (CDC).\nRecently, an 18-year-old boy in India died of neurocysticercosis, when cysticercosis affects the brain and spinal cord. You can read more about this tragic incident here.\n“Neurocysticercosis is a leading cause of adult onset epilepsy worldwide. It is costly to diagnose and treat but entirely preventable,” reports the CDC.\n“There are an estimated 1,000 new hospitalizations for neurocysticercosis in the United States each year. Cases are most frequently reported in New York, California, Texas, Oregon, and Illinois. Additionally, neurocysticercosis creates a tremendous economic burden. In a recent study, the average charge of hospitalization due to neurocysticercosis was $37,600, with the most common form of payment being Medicaid (43.9%). Currently, there is little being done to monitor prevent, or identify and treat neurocysticercosis.”\nI think what you can gather from all of this information about tapeworms is that it would be absolutely crazy and a major risk to your health to intentionally swallow a pill containing a tapeworm egg, in an attempt to lose weight.\nBut the risks have not stopped some people.\nBack in 2013, a woman in Iowa swallowed a tapeworm she reportedly bought of the internet. After swallowing the pill that contained the tapeworm, she told her doctor what she had done.\n“To get the parasite out of a person's body, doctors will usually prescribe an anti-worm medication like praziquantel or niclosamide, which force all the muscles in the worm's body to contract, killing it. The tapeworm will then harmlessly pass through the intestines and out of the body,” according to this news report discussing the woman in Iowa.\nThis report from 2010 discusses how dieters in Hong Kong were swallowing tapeworms to lose weight. According to the report, the worms can lay up to 200,000 more eggs a day inside the body!\nDr. Michael Mosley, who is known for “experimenting on himself,” ingested a tapeworm to see if it was worth the “weight loss benefits,” according to this 2014 Medical Daily report.\n“Mosley traveled to Kenya in order to pick up the parasites, which came from cysts on a cow’s tongue that contained tapeworm eggs. After ingesting the tapeworm, Mosley tracked his progress for about six weeks. He kept a food diary in which he noted any changes in his behavior or physical appearance. Contrary to what some may believe about the tapeworm diet, Mosley said he found himself craving carbohydrates and sugars.”\nIt makes sense that you may crave carbs and sugar, considering a parasite is invading your body and depleting your energy stores.\nHe actually gained two pounds from this experiment and took medication to rid his body of the tapeworm.\nYou are more likely to become malnourished, not slender and “pretty to look at.”\n“One tapeworm can't absorb enough food and nutrients to make a big difference in weight, according to scientific research. But the parasite can cause anemia and malnutrition,” according to one source.\nMalnutrition, in my opinion, is one of the greatest risks of ingesting a tapeworm -- especially a deficiency in vitamin B12. As mentioned, tapeworms can block your intestines and take up space that other organs need. This can make it harder for these organs to do their jobs in keeping you healthy.\nYour bodies need to absorb and efficiently use nutrients, such as water, vitamins, minerals, fats and proteins, in order to lose weight and maintain a healthy weight.\nSo if you suspect you have a tapeworm, it’s important to see a competent healthcare professional as soon as possible. Diagnostic tests for tapeworms include blood tests to look for antibodies caused by the tapeworm infection, imaging scans such as an MRI or X-Ray, stool tests to look for eggs and larvae and organ tests to make sure your vital organs are functioning properly. The good news is that with the proper treatment, usually oral medication, tapeworms are more than 95 percent curable.\nHow to be Proactive\nThe first thing you need to know is that if you’re trying to get to a healthy weight, swallowing a tapeworm is not the way to do it. There are many ways, including exercising and eating healthily, to lose weight in a healthy way and then keep it off. This is a great goal since being overweight puts you at risk for a wide variety of health problems and diseases, from joint stress to diabetes and from cardiovascular disease to kidney disease. You can find a wealth of information about dieting and weight management on the pH website.\nThere are several things you can do to protect yourself and your family from a tapeworm infection. These include:\n- Making sure to cook all meats and fish to internal temperatures recommended by the CDC of 145 degrees F for pork and other meats, and 160 degrees F for ground meat (you can also freeze meat and fish for seven days, which is effective for killing eggs and larvae)\n- Boil, disinfect or drink bottled water if you are not sure about the water’s potability\n- Be sure to thoroughly wash your hands (and teach your children to do so) after using the bathroom, gardening or being around farm animals (or any other animals) and before eating\n- Regularly clean and disinfect food preparation surfaces in your kitchen and be sure to wash your hands after handling raw meats and fish\n- Make sure your dog is treated for tapeworms as indicated by your veterinarian, and never feed your pet raw meat or fish\nSince tapeworms literally “share” the nutrients you are getting from your food, if you or anyone in your family has been treated for tapeworms you should get a nutrient test to see what your body may be lacking. Getting this test is also a good idea in general, especially if you are dieting.\nTo learn about specific nutritional deficiencies that may be preventing you from achieving your weight loss goals, read here.\nEnjoy your healthy life!\nThe pH professional health care team includes recognized experts from a variety of health care and related disciplines, including physicians, attorneys, nutritionists, nurses and certified fitness instructors. This team also includes the members of the pH Medical Advisory Board, which constantly monitors all pH programs, products and services. To learn more about the pH Medical Advisory Board, click here.""]"	['<urn:uuid:a06e9bf9-38b6-424b-b030-3c484bc59471>']	factoid	direct	short-search-query	similar-to-document	single-doc	novice	2025-05-13T01:50:22.828293	7	9	1604
