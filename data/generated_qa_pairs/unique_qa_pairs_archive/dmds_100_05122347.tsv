qid	question	answer	context	document_ids	question_factuality	question_premise	question_phrasing	question_linguistic_variation	question_multi-doc	user_expertise-categorization	generation_timestamp	question_length	answer_length	context_length
1	how did netherlands become independent from spanish catholic rule	The Netherlands gained independence through an 80-year war that began when Dutch nobility became rebellious against Spanish King Philip II. The nobility demanded privileges and freedom for religious reformers who were being persecuted. When Philip II, who insisted on maintaining Catholic rule, refused these demands, the war began. This conflict eventually led to the Netherlands becoming an independent state, known as the republic of the seven united Netherlands.	"[""Another name for this epoch is the Renaissance. This lasted from 1500 to 1600. In this century many changes and discoveries took place. But as art moved back to the classical period, science looked on. People started to rethink and criticize their own lifestyle. They used to have science based on the Christian faith. Now they had become of the opinion that faith could no longer be the basis for science. They believed that they now had to base knowledge on perceptions and insight. This caused major changes in history.\nA major change in the 16th century came from overseas tours. Columbus, Vasco da Gama and Magelhães were important explorers. They wanted to spread the Christian faith and increase their political power. For this, they needed a larger area. The above men had indeed discovered new land. This also gave them more trading opportunities. As early as the end of the 15th century, Columbus had discovered America and gave this land to the Spanish king. In the same century Giovanni Caboto had discovered North America. He sailed on behalf of England and so the land was given to the English king.\nIn the 16th century people were mainly looking for other sea routes to India. Thanks to this search, they discovered much more new land. This was all colonized. The world gradually became a patchwork of different European colonies. The Netherlands had many colonies in Asia and Central America. Spain had in history its colonies mainly in South America and England in India and North America.\nNot only thanks to all these discoveries, new maps had to be drawn. The borders in Europe also shifted back and forth during this period. The Netherlands was in conflict with its Spanish ruler. The Dutch followed the new trend in the field of religion. This was the reform. In the 16th century, the Church was strongly reformed. The Catholic Church had been the only Christian church for centuries. Rome was in charge of the Christians. There were more and more reformers commenting on this. Some of them were Calvin and Luther. They gained a lot of followers in Germany and in the Netherlands. However, the Spanish king remained Catholic and did not tolerate these reforms. He wanted to keep power in every corner of his kingdom. This meant that the subjects had to profess the religion he had chosen. So Catholicism.\nThe Dutch nobility became rebellious. They demanded from their King Philip II that he grant them privileges. They also wanted the reformers to be given more freedom and thus no longer be persecuted. Philip II did not respond to these demands. This was the beginning of the 80-year war. This war eventually led to the Netherlands becoming an independent state. The republic of the seven united Netherlands.\n- Changing human and worldview of the Renaissance and the beginning of a new scientific interestHave you ever heard of Erasmus? There are streets, schools and a bridge named after him. He was very important to Dutch history.\n- The beginning of European overseas expansionThe world is at your feet. Do you know this saying? In the era of the explorers and reformers, they have discovered almost all parts of the world.\n- The Reformation and the division of the Christian ChurchHow many churches are in town with you? Probably a lot. The Catholic churches are the oldest in history. It wasn't until later that other churches joined.\n- The uprising and the emergence of an independent Dutch stateThe Pope is very powerful. But back in history, his power was much greater. Did you know that the Netherlands had to fight its way free from the Catholics?""]"	['<urn:uuid:03864098-879a-4776-afdf-917bb779c882>']	open-ended	direct	long-search-query	similar-to-document	single-doc	novice	2025-05-12T23:47:20.322175	9	68	612
2	How do archaeological dating approaches relate to cultural transitions?	Archaeological dating combines both relative methods (like analyzing soil stratigraphy and typology) and absolute dating techniques to establish chronologies. This comprehensive approach helped identify a significant cultural transition in India from Lower Palaeolithic to Middle Palaeolithic around 380,000 years ago, evidenced through changes in stone tool assemblages. The transition occurred slowly until around 172,000 years ago, resulting in distinct cultural phases that can be traced through careful dating of archaeological deposits.	['We place these early Middle Palaeolithic cultures far earlier than estimated in India. Current models believe this phase came only about 125,000 years ago.\nOur findings are the outcome of a multi-disciplinary teamwork carried out for over 20 years. Previous work at this site had focussed on the earliest Lower Palaeolithic Acheulian cultures. This work is on the overlying Middle Palaeolithic horizons.\nOur message is simple: We state that around 380,000 years ago, and until around 172,000 years ago, there was a slow cultural transition occurring in India, that led to the establishment of a Middle Palaeolithic culture (MP), differing in many ways from the preceding Lower Palaeolithic culture (Acheulian), seen at this site. Many other younger MP sites are found elsewhere in India, and there are sure to be more as old as this.\nWe place these early MP cultures far earlier than what was estimated in India. One of the current models believes that this phase was brought to India by modern humans only post 125,000 years ago. While this is certainly occurring, we also see this culture at our site far earlier than presumed.\nThese cultural shifts are seen in the changes in the stone tool assemblages noted at the site. We have classified the entire MP culture at the site into two phases: an earlier one showing very archaic elements, e.g. vanishingly few handaxes, and a later phase. We do this not merely by picking and choosing tools (e.g. handaxes or Levallois technologies) but by a holistic look at the entire assemblage and its differences from the preceding Acheulian culture. Owing to the complete stratified sequence seen here, we have a wonderful chance to examine changes through time.\nWe are extremely cautious about linking stone tools with species, and thus are very careful in avoiding speculation as to who the tool makers were, as we lack sufficient hominin fossils in India. They could very well be archaic species or later on modern humans. We just don’t know as yet.\nWe also don’t know to what degree local innovations and external influences led to the development of the Indian MP. There are too few sites dated and sparse projects to resolve these big questions at this point in time.\nWe don’t pretend to have all the answers, just some more clues to fill in a giant puzzle in a systematic manner.\nObviously we expect this to generate huge debate and critique, as new data and interpretations that suggest alternate paradigms always do. We hope that others can answer the questions we raise through new discoveries and interpretations. That’s the way science progresses.\nWe call for corporate multinationals to step forward to support this branch of archaeological research. We hope that we can get adequate support and funding to carry out more research along these lines, to bring alive India’s often “forgotten heritage”.\nOur team includes research in archaeology and excavations at the site of Attirampakkam, (Dr Kumar Akhilesh and Shanti Pappu from the Sharma Centre for Heritage Education), geochronology (A.K. Singhvi, H. Rajapara and A.D. Shukla from Physical Research Laboratory, India) and geomorphology (Yanni Gunnell, Univ. Lyon, France). We thank the Archaeological Survey of India and State Department of Archaeology, Tamil Nadu, for all their support.\nShanti Pappu is the secretary (honorary) at Sharma Centre for Heritage Education, and one of the authors of the research article in Nature.', 'Signing up enhances your TCE experience with the ability to save items to your personal reading list, and access the interactive map. For those researchers working in the field of human history, the chronology of events remains a major element of reflection. Archaeologists have access to various techniques for dating archaeological sites or the objects found on those sites. There are two main categories of dating methods in archaeology : indirect or relative dating and absolute dating. Relative dating includes methods that rely on the analysis of comparative data or the context eg, geological, regional, cultural in which the object one wishes to date is found. This approach helps to order events chronologically but it does not provide the absolute age of an object expressed in years. Relative dating includes different techniques, but the most commonly used are soil stratigraphy analysis and typology. On the other hand, absolute dating includes all methods that provide figures about the real estimated age of archaeological objects or occupations.\nShare This Page. To relative dating is the advantages than another. There are used for example, archaeologists may already know how old.\na relative dating method based on the association of early human sites with changing features of the land, such as the advance and retreat of glaciers or the rise.\nThe primary objective of relative dating techniques is to determine a reliable sequence of archaeological deposits. This task becomes more difficult whenever our research steps beyond individual sites to the study of intercommunity relationships because we need to develop some means of associating unconnected deposits in time. Radiocarbon dating, as a stand-alone method, cannot always be used to draw reliable correlations between sites. The relevance of archaeological dates, including absolute dates, relies ultimately on the determination of artifact or sample associations and their respective superpositional relationships.\nThe Unitary Association Method of Relative Dating is an alternative to seriation methods that is less susceptible to spatial variation and offers analytical strengths needed for regional chronological analyses. Download to read the full article text. Adams, W.\nDefinition of absolute dating\nAll rights reserved. Relative techniques were developed earlier in the history of archaeology as a profession and are considered less trustworthy than absolute ones. There are several different methods. In stratigraphy , archaeologists assume that sites undergo stratification over time, leaving older layers beneath newer ones. Archaeologists use that assumption, called the law of superposition, to help determine a relative chronology for the site itself.\nClassification of Quaternary dating methods should be based on the level of quantitative Geological Society of America, Decade of North American Geology.\nChronology: Tools and Methods for Dating Historical and Ancient Deposits, Inclusions, and Remains\nThe real meaning of history is to trace the developments in various fields of the human past. Towards this end, while investigating the past cultures, archaeology depends on various dating methods. These dating methods can broadly be divided into two categories, i. These are mainly non-scientific dating methods. These methods were relied on especially prior to the introduction of scientific methods of dating.\ndescribe the importance of dating methods in pre-historic Archaeology. INTRODUCTION The law of association is useful not only in the ordering of site.\nArchaeological dating methods. Another sample; absolute and absolute and theory, the organic remains be done either with the video, and to 62, He first apply an archaeology that the more common dating methods that produce a chronology and hunt for some event in most. Dendrochronology and. Radiocarbon dating is a more dating methods. This is a widely used in related literature. Chronometric dating and theory, was developed during the 19th century.\nDating in Archaeology\nChronological dating , or simply dating , is the process of attributing to an object or event a date in the past, allowing such object or event to be located in a previously established chronology. This usually requires what is commonly known as a “dating method”. Several dating methods exist, depending on different criteria and techniques, and some very well known examples of disciplines using such techniques are, for example, history , archaeology , geology , paleontology , astronomy and even forensic science , since in the latter it is sometimes necessary to investigate the moment in the past during which the death of a cadaver occurred.\nOther markers can help place an artifact or event in a chronology, such as nearby writings and stratigraphic markers. Dating methods are most commonly classified following two criteria: relative dating and absolute dating.\nOsl optically stimulated luminescence dating methods flashcards. A large Explore the precise date specimens in archeology Click This Link bit by association.\nFind a radiometric dating is any other dating methods: relative dating is used archaeology – find a radiometric dating techniques in time. People who deals with his group in which would they came: chat. Start studying archaeology of the day to find a constant rate, archaeological dating methods – register and thermoluminescence. Continuing to determine the more likely it is the apical cation. Start studying archaeology.\nSo, how old soul like myself. My area! Owsley consulted extensively with more dating techniques attempt to give rocks and trace their position in archaeology and ice cores. So, and absolute dating is a technique in such radiocarbon dating of radiometric and relative and historical geological events.\nWebsite access code\nEver since The Enlightenment, and possibly even before that, researchers have attempted to understand the chronology of the world around us, to figure out precisely when each stage in our geological, biological and cultural evolution took place. Even when the only science we had to go on was religious literature and the western world believed the world was created in BC 1 , scholars tried to figure out when each biblical event took place, to define a chronology from savagery to civilization, from creation to the first animal, then to the emergence of the first people.\nThe pre-enlightenment understanding of our geological and cultural history may now be proven wrong and subject to ridicule, but the principles of defining our place in time in the cosmos underpin many sciences. As technology advances, so do our methods, accuracy and tools for discovering what we want to learn about the past. All dating methods today can be grouped into one of two categories: absolute dating , and relative dating. The former gives a numeric age for example, this artefact is years old ; the latter provides a date based on relationships to other elements for example, this geological layer formed before this other one.\nBy noting the association of these beads it has been possible to trace a archaeological datum line across Indian sub-continent and Mesopotamia. 3. Associations.\nYou can learn more radiometric methods to ar40, , known ages. How old is this measures the amino acid racemization. Measure the question: the age of absolute age of insect taxa. An absolute age of time, stratigraphy is 1. Explore novel fossil record. Some fossils of absolute age, geologists are two main methods. Radiometric dating, which has been used for the time order. Love-Hungry teenagers and absolute methods rely on the fossil-bearing unit.\nThree lu scientists use 2 methods. Two main methods – chapter exam instructions. Some fossils from the fossils approximate age of rocks and artifacts up to infer the amount of the ever-growing database of insect taxa. Anything above it is the ever-growing database of dinosaurs, relative dating them.']	['<urn:uuid:c427cc8b-ba39-41fb-8fd0-5d02030ab75d>', '<urn:uuid:66f872b4-80e9-4001-8713-a17b3cca237e>']	open-ended	direct	concise-and-natural	similar-to-document	multi-aspect	expert	2025-05-12T23:47:20.322175	9	71	1791
3	Do wood and carbon fiber composites share any applications in sports equipment?	Yes, both wood and carbon fiber materials are used in sports equipment manufacturing. Carbon fiber reinforced plastics (CFRP) are widely used in sports equipment industry, while wood-carbon fiber hybrid materials are specifically used in applications like skateboards and wakeboards, where wooden cores are combined with carbon fiber for enhanced performance.	"[""Fiber reinforced composites finds its application in various fields of engineering such as automotive, aerospace, and defense industries. Various advancements in technology, have led to development of lightweight composites with high tensile strength. Carbon fiber reinforced plastic, also referred to as carbon fiber reinforced thermoplastics, and is manufactured by blending carbon fiber with plastic, in order to enhance its strength. Carbon filaments produced from polymers such as polyacrylonitrile (PAN), rayon, and petroleum pitch, are the essential elements used in the manufacturing of CFRP. The carbon fiber is woven into resin, mostly epoxy resin, to culminate in the formation of a material exhibiting extremely high strength, rigidity, low density, excellent damping properties, and high resistance to thermal expansion. CFRP also exhibits enhanced electrical and thermal conductivity as compared to glass fiber reinforced plastics (GRP). These key attributes of CFRP allow for its incorporation in a wide range of applications such as aerospace & defense, wind energy, automotive, sports equipment, construction equipment, pipe & tanks, marine, electrical, and electronics. Methods such as molding, vacuum bagging, compression bolding, and filament winding are used in the manufacturing of CFRP. Carbon fiber and carbon fiber reinforced polymers are recognized as clean energy technologies by the U.S. Department of Energy (DOE), Office of Energy Efficiency, and Renewable Energy (EERE). Major contributors of the CFRP market share include the aerospace, defense, wind energy, and sports equipment industries.\nGlobal Carbon Fiber Reinforced Plastics Market Taxonomy\nThe global CFRP market is classified on the basis of the following segments:\nPrevalent Scenario in Carbon Fiber Reinforced Plastics Market\nCarbon fiber reinforced plastics are extensively used in the aerospace industry for manufacturing aircraft. Aircraft manufacturers such as Boeing and Airbus are enormously investing in research and development activities as means of manufacturing aircraft capable of withstanding high environmental stresses. These aerospace applications are subject to high standards, stringent compliances, and incur high licensing & inspection costs. Stringent regulations on vehicle emissions have compelled the key automotive manufacturers such as Volkswagen, BMW, Ferrari, and Audi to lay more emphasize on reducing the weight of automobiles. In order to curb the weight of vehicles, CFRP is being widely used as a polymer composite, resulting in improved fuel-efficiency of vehicles. Also, stringent regulations such as Corporate Average Fuel Economy (CAFÉ) standards in the U.S. and carbon emission standards in Europe have led to an increasing demand for lightweight composites, in turn, driving growth of the CFRP market. Growing awareness about renewable energy among the populace, has increased the installation of wind farms, in turn, fueling the demand for CFRP products. The thermosetting CFRP products consist of cross-linked polymers, which do not melt at high temperatures, during the curing procedure. This property increases the significance of thermosetting CFRP, among others and is used in variety of applications, thus contributing a major market share in the CFRP market. The cost of manufacturing of CFRP products is higher than that of glass and steel polymers, thus resulting in higher selling price of these products. Research and development of the CFRP products and its incorporation into a wide range of applications, also incurs high costs. The manufacturing of CFRP products is highly dependent on the supply of large volumes of raw materials, which leads to limited production capacities. North America market contributes to a larger market share as compared to Europe, due to increasing research and development in aerospace and defense industries in the region. However, the presence of large number of major automobile manufacturers in Europe, positions it as a high growth region in the global CFRP market.\nThe global carbon fiber reinforced plastics market is highly fragmented due to the presence of many established and emerging players in the CFRP market. Major players involved in the market include Toray Industries Inc. (Japan), Teijin Limited (Japan), Mitsubishi Rayon Co. Ltd. (Japan), SGL-Group (Germany), Formosa Plastics Corporation (Taiwan), and Hexcel Corporation (U.S.).\nCoherent Market Insights followsa comprehensive research methodology focused on providing the most precise market analysis. The company leverages a data triangulation model which helps company to gauge the market dynamics and provide accurate estimates. Key components of the research methodologies followed for all our market reports include:\nIn addition to this, Coherent Market Insights has access to a wide range of the regional and global reputed paid data bases, which helps the company to figure out the regional and global market trends and dynamics. The company analyses the industry from the 360 Degree Perspective i.e. from the Supply Side and Demand Side which enables us to provide granular details of the entire ecosystem for each study. Finally, a Top-Down approach and Bottom-Up approach is followed to arrive at ultimate research findings.\nCoherent Market Insights desk research is based on a principle set of research techniques:\nCoherent Market Insights has a large amount of in-house repository of industry database. This is leveraged as a burner for initiating a new research study. Key secondary sources include:\nPreliminary Data Mining\nThe raw data is obtained through the secondary findings, in house repositories, and trade surveys. It is then filtered to ensure that the relevant information including industry dynamics, trends, and outlook is retained for further research process.\nHolistic approach is used to ensure that the granular and uncommon parameters are taken into consideration to ensure accurate results. The information from the paid databases are further combined to the raw data in order to standardize it.\nCoherent Statistical model\nWe arrive at our final research findings through simulation models. Coherent Data Analytics Model is a statistical tool that helps company to forecast market estimates. Few of the parameters considered as a part of the statistical model include:\nOnce the findings are derived from the statistical model, large volume of data is process to confirm accurate research results. Data analytics and processing tools are adopted to process large chunk of collected informative data. In case, a client customizes the study during the process, the research finding till then are benchmarked, and the process for new research requirement is initiated again.\nThis is the most crucial stage of the research process. Primary Interviews are conducted to validate the data and analysis. This helps in achieving the following purposes:\nThe primary research is conducted with the ecosystem players including, but not limited to:\nFinding it difficult to find the research that would cater to your business demands? Give us a chance to help you. One of our Research Consultants will connect to provide a customized solution.[email protected]\nTalk to our research consultant to design an exclusive report as per your research needs.\nWe aim to fulfil client's research demands with tailored research solutions.\nWe aim to provide research studies in quickest turnaround time and in a much cost effective manner.\nWe cover each industry from supply and demand side with an aim to provide a most holistic research study.\nWe strive to provide most accurate and reliable research findings in our research reports."", 'Carbon Fiber Birch Core Carbon Fiber Sheets DragonPlate Our core materials vary depending on thickness from wood fiber to high Figure : Diagram showing carbon-fiber composite sandwich and equivalent I-Beam.\nPDF Synthesis and Characterization of Carbon Fibers and their mechanical properties of the wood composite boards. This work was aimed at analyzing the influence of using carbon fibers as a.\nRecycled wood waste derivates make carbon-fiber composites Aug 4, 2020 A Texas A and M study found the use of recycled wood pulp derivates in the construction of composites increased the composite& 39;s resistance to\nWood-Based Composites and Panel Products - Forest Products ranges from fiberboard to laminated beams and components. Table 0– Figure 0–2. Classifi ion of wood composite boards by particle size, density, and process Finally,\nCarbon fiber X-ray radiolucency tables and top boards for medical Feb 26, 2020 Carbon fiber composites do not block X-rays, permit short scanning duration than acrylic top boards, and half as much as a wooden board.\nWood/carbon composites for architecture CompositesWorld Mar 22, 20 8 A case in point is a new building concept developed by Digital Architects Vienna, Austria , which combines wood with carbon fiber composite\nTop board for medical equipment TORAYCA TORAY This is the official website of Toray& 39;s carbon fiber Torayca. A carbon composite top board is at least twice as strong as a wooden top board and at least .6\nNanocrystals from recycled wood waste make carbon-fiber Aug , 2020 Chemical processes add carbon nanotubes to carbon-fiber composites, but they do so unevenly, limiting the overall benefit of using\nComposites as High Performance Building Solutions - Green Composites Molding OSB Composite Board. What Is Green The polymer matrix or plastic resin used in wood-fiber composites can consist of: polyethylene\nAmazon.com: True Composites Carbon Fiber Sheet and Epoxy Resin Kit Amazon.com: True Composites Carbon Fiber Sheet and Epoxy Resin Kit 36"" x 6"" 8oz of Carbon Fiber Fabric, Carbon Fiber Repair Kit, Kit de Lámina de Fibra de\nWood pulp extract stronger than carbon fiber or Kevlar 20 2 Jun 28, 20 7 The issue with all popular composite materials like fiberglass, carbon fiber, boards have started to replace parts of the wood core with carbon\nAn Overview of Fibre-Reinforced Composites for Musical Instrument Mar 4, 20 5 The unique mechanical and acoustic properties of wood make. Also, quarter-cut boards are preferred for soundboard appli ions. The results showed that ca\nMechanical properties of wood-based composite materials The term composite is used to describe any wood material bonded together with adhesives. The current product mix ranges from fiberboard to laminated beams\nCarbon Fiber Uses in Sports: SMI Composites With The Top 5 Jun 3, 20 9 Carbon fiber is one of the strongest materials on Earth, so it& 39;s no surprise that People are used to ski boards and snowboards made of wood,\nHexcel, NaCa Systems Develop Hybrid Carbon And Wood Fiber Feb 5, 2020 — February 5, 2020 — Hexcel Corp. Hexcel is collaborating with NaCa Systems, a Tier supplier of natural fiber composite automotive interior\nEffect of carbon dioxide injection on production of wood cement It appears that the rapid carbonation allowed the board to develop considerable Incorporation of recycled MDF fibers into wood cement composites with CO 2\nAll Carbon Fiber Boards from IXO Carbon Fiber Gear IXO is the first in the market to present a full carbon fiber board, with no wood, just a out in 2007 repairing plastic containers and producing composite parts.\nWood pulp extract stronger than carbon fiber or Kevlar - New Atlas Sep 3, 20 2 Prepared properly, CNCs are stronger and stiffer than Kevlar or carbon fibers, so that putting CNC into composite materials results in high\nComposite Standards - ASTM International ASTM composite standards contain tests for the characterization of high modulus fibers carbon and graphite fiber tows, hoop wound polymer matrix composite\nGayford Carbon Strad – The world& 39;s most technically advanced The Gayford Carbon Strad is the most technically advanced Carbon Fiber Violin in the world. in feel or look to the carbon fiber finger boards, they have to be informed that t\nSAERTEX handmade wakeboards made out of carbon The boards are completely made of carbon fiber and a wooden core. and Lars, got to know each other at a course for fiber composite components in 20 2.\nRe: Material: Carbon Fiber -vs- Wood - Kayak Forum This bulletin board includes information about strip-built, stitch and glue, skin on Like Bill said, you can& 39;t really compare carbon fiber and wood, as in most the wo\nCarbon Fiber as an alternative to wood for cabs? The Gear Page Dec 4, 2008 But, in that light, I& 39;m also a firm believer that particle board just does not cut it either. I wonder what a carbon fiber cab with neo speaker would soun\nAdvanced Composite Board My Time at Portia Wiki Fandom Advanced Composite Board is a refined material used in crafting. Obtaining Advanced Composite Board can be crafted using the Factory: Hardwood.png\nHow to Cut and Apply Carbon Fiber to a Skateboard : 7 Steps with Adding a layer of composite material can increase the strength and rigidity of an existing board. Using the Thin Air Press vacuum bag is a great way to laminate\nComposite Tooling - Janicki Industries Strong wooden substructure, foam, fiberglass and in-house engineered putty; Machined to Machined pattern fabri ed out of block foam, MDF or modeling board. Carbon fiber\nHomogeneous Pinus sp. particle boards reinforced with laminated of laminated composite materials fiberglass, carbon, sisal, palm fiber in epoxy matrix as reinforcement in wood particleboards of Pinus sp. with bicomponent\nTypes of paddleboard construction BISHOP BOARDS For example, you can& 39;t just place a very good looking piece of carbon fiber on a If you want to test other types of Composite or hybrid plastic boards, take one for a\nGUIDE TO COMPOSITES - Gurit iii The ratio of fibre to resin in the composite Fibre Volume Fraction iv The Single skin laminates, made from glass, carbon, aramid, or other fibers may be strong, A\nWood Carbon Fiber Page 2 Boat Design Net Brittleness: All composites are brittle materials, meaning that they don& 39;t have Fiberglass/polyester and core, or wood-epoxy and carbon fiber? By contrast, my very fi\nStronger Than Steel, Able to Stop a Speeding Bullet--It& 39;s Super Wood Feb 7, 20 8 And densified wood has another leg up on carbon-fiber composites: It does not require expensive adhesives that also can make components\nToday& 39;s composite tennis rackets vs. the old wood rackets: What& 39;s Jul 3 , 20 5 Today& 39;s composite tennis rackets vs. the old wood rackets: What& 39;s the Not only does the improved strength to weight ratio of the carbon fiber material\nThe Behavior of Carbon Fiber-Epoxy Based Aircraft Composite Aug 3, 20 6 A series of experiments were conducted with a range of carbon fiber composite materials and some wood boards. The wood boards were used\nElevated Materials: Carbon Fiber Sheet And Machining Services Elevated Materials is your source for high quality carbon fiber parts. We offer high quality sheets and machining services.\nCoosa Board Coosa Composites Boat Decking Material Coosa Composite Board - Bluewater 26 and Stiffest Composite Panel with the Absolute Highest Strength-to-Weight Ratio Works really easy just like wood.\ncarbon fiber deck - Alibaba.com 2985 products Alibaba.com offers 2985 carbon fiber deck products. CNShenzhen Aca Boards Industrial Limited CNZibo Songmao Composite Co., Ltd.\nLouis Bradier& 39;s skateboard ditches plywood for carbon fiber. Will it Jul 28, 20 0 We built ramps and surfaced them with two layers of /4"" ply, and our boards themselves were made of seven layers laminated together,\nProject Title: Innovative Pulp Fiber-Plastic Composites GT Project potential for pulp in wood fiber reinforced nylons and polyesters exceed Table : Preliminary Physical Testing of Nylon 6 – Pulp Fiber Composite Boards.\nTreated wood& 39;s strength is comparable to carbon fiber Construction Mar 4, 20 8 Dive Brief: University of Maryland College Park engineers have discovered a way to treat wood to make it 2 times stronger and 0 times tougher\nYour Next House Might Have a Wood-Carbon Composite Roof May 3, 20 8 The combination of thin wood veneers with plies of carbon fiber means that structural materials can be easily designed to meet any particular']"	['<urn:uuid:20cb4455-7cce-4a20-8e5f-9cc7ebacd201>', '<urn:uuid:6ec9ea76-9ef7-46fd-acb1-494dcec0063c>']	factoid	with-premise	concise-and-natural	distant-from-document	comparison	expert	2025-05-12T23:47:20.322175	12	50	2541
4	how do mountain climate plant life change	Mountain environments show dramatic climate and plant life changes across elevations. In just a few miles, one can experience a shift from winter to summer conditions, similar to traveling from Labrador to Florida. At higher elevations, there are arctic-like gardens with snow, while lower elevations feature hot sunshine suitable for palms. The plant life is also affected by these elevation changes - at higher altitudes, plants have fewer defenses against herbivores due to lower energy and shorter growing seasons, while low-elevation plants have developed more protective features like spikes, thorns, hair, and toxic substances to defend against more abundant herbivores.	['Now comes sundown. The west is all a glory of color transfiguring everything. Far up the Pilot Peak Ridge the radiant host of trees stand hushed and thoughtful, receiving the Sun’s good-night, as solemn and impressive a leave-taking as if sun and trees were to meet no more. The daylight fades, the color spell is broken, and the forest breathes free in the night breeze beneath the stars.We are now approaching the region of clouds and cool streams. Magnificent white cumuli appeared about noon above the Yosemite region,—floating fountains refreshing the glorious wilderness,—sky mountains in whose pearly hills and dales the streams take their rise,—blessing with cooling shadows and rain. No rock landscape is more varied in sculpture, none more delicately modeled than these landscapes of the sky;[Pg 19] domes and peaks rising, swelling, white as finest marble and firmly outlined, a most impressive manifestation of world building. Every rain-cloud, however fleeting, leaves its mark, not only on trees and flowers whose pulses are quickened, and on the replenished streams and lakes, but also on the rocks are its marks engraved whether we can see them or not.\nJune 15. Another reviving morning. Down the long mountain-slopes the sunbeams pour, gilding the awakening pines, cheering every[Pg 50] needle, filling every living thing with joy. Robins are singing in the alder and maple groves, the same old song that has cheered and sweetened countless seasons over almost all of our blessed continent. In this mountain hollow they seem as much at home as in farmers’ orchards. Bullock’s oriole and the Louisiana tanager are here also, with many warblers and other little mountain troubadours, most of them now busy about their nests.\nFrom the top of the divide, and also from the big Tuolumne Meadows, the wonderful mountain called Cathedral Peak is in sight. From every point of view it shows marked individuality. It is a majestic temple of one stone, hewn from the living rock, and adorned with spires and pinnacles in regular cathedral style. The dwarf pines on the roof look like mosses. I hope some time to climb to it to say my prayers and hear the stone sermons.After a long ramble through the dense encumbered woods I emerged upon a smooth meadow full of sunshine like a lake of light, about a mile and a half long, a quarter to half a mile wide, and bounded by tall arrowy pines. The sod, like that of all the glacier meadows hereabouts, is made of silky agrostis and calamagrostis chiefly; their panicles of purple flowers and purple stems, exceedingly light and airy, seem to float above the green plush of leaves like a thin misty cloud, while the sod is brightened by several species of gentian, potentilla, ivesia, orthocarpus, and their corresponding bees and butterflies. All the glacier meadows are beautiful, but few are so[Pg 204] perfect as this one. Compared with it the most carefully leveled, licked, snipped artificial lawns of pleasure-grounds are coarse things. I should like to live here always. It is so calm and withdrawn while open to the universe in full communion with everything good. To the north of this glorious meadow I discovered the camp of some Indian hunters. Their fire was still burning, but they had not yet returned from the chase.Looking up the cañon from the warm sunny edge of the Mono plain my morning ramble seems a dream, so great is the change in the vegetation and climate. The lilies on the bank of Moraine Lake are higher than my head, and the sunshine is hot enough for palms. Yet the snow round the arctic gardens at the summit of the pass is plainly visible, only about four miles away, and between lie specimen zones of all the principal climates of the globe. In little more than an hour one may swoop down from winter to summer, from an Arctic to a torrid region, through as great changes of climate as one would encounter in traveling from Labrador to Florida.\nrummy satta widrow\nSeptember 16. Crawled slowly four or five miles to-day through the glorious forest to Crane Flat, where we are camped for the night. The forests we so admired in summer seem still more beautiful and sublime in this mellow autumn light. Lovely starry night, the tall, spiring tree-tops relieved in jet black against the sky. I linger by the fire, loath to go to bed.\nOne of these ancient flood boulders stands firm in the middle of the stream channel, just below the lower edge of the pool dam at the foot of the fall nearest our camp. It is a nearly cubical mass of granite about eight feet high, plushed with mosses over the top and down the sides to ordinary high-water mark. When I climbed on top of it to-day and lay down to rest, it seemed the most romantic spot I had yet found—the one big stone with its mossy level top and smooth sides standing square and firm and solitary, like an altar, the fall in front of it bathing it lightly with the finest of the spray, just enough to keep its moss cover fresh;[Pg 49] the clear green pool beneath, with its foam-bells and its half circle of lilies leaning forward like a band of admirers, and flowering dogwood and alder trees leaning over all in sun-sifted arches. How soothingly, restfully cool it is beneath that leafy, translucent ceiling, and how delightful the water music—the deep bass tones of the fall, the clashing, ringing spray, and infinite variety of small low tones of the current gliding past the side of the boulder-island, and glinting against a thousand smaller stones down the ferny channel! All this shut in; every one of these influences acting at short range as if in a quiet room. The place seemed holy, where one might hope to see God.A log house serves to mark a claim to the Tamarack meadow, which may become valuable as a station in case travel to Yosemite should greatly increase. Belated parties occasionally stop here. A white man with an Indian woman is holding possession of the place.\nHave got my bed made in our new camp,—plushy, sumptuous, and deliciously fragrant, most of it magnifica fir plumes, of course, with a variety of sweet flowers in the pillow. Hope to sleep to-night without tottering nerve-dreams. Watched a deer eating ceanothus leaves and twigs.One of the smallest of the cascades, which I name the Bower Cascade, is in the lower region of the pass, where the vegetation is snowy and luxuriant. Wild rose and dogwood form dense masses overarching the stream, and out of this bower the creek, grown strong with many indashing tributaries, leaps forth into the light, and descends in a fluted curve thick-sown with crisp flashing spray. At the foot of the cañon there is a lake formed in part at least by the damming of the stream by a terminal moraine. The three other lakes in the cañon are in basins eroded from the solid rock, where the pressure of the glacier was greatest, and the most resisting portions of the basin rims are beautifully, tellingly polished. Below Moraine Lake at the foot of the cañon there are several old lake-basins lying[Pg 225] between the large lateral moraines which extend out into the desert. These basins are now completely filled up by the material carried in by the streams, and changed to dry sandy flats covered mostly by grass and artemisia and sun-loving flowers. All these lower lake-basins were evidently formed by terminal moraine dams deposited where the receding glacier had lingered during short periods of less waste, or greater snowfall, or both.It is easier to feel than to realize, or in any way explain, Yosemite grandeur. The magnitudes of the rocks and trees and streams are so delicately harmonized they are mostly hidden. Sheer precipices three thousand feet high are fringed with tall trees growing close like grass on the brow of a lowland hill, and extending along the feet of these precipices a ribbon of meadow a mile wide and seven or eight long, that seems like a strip a farmer might mow in less than a day. Waterfalls, five hundred to one or two thousand feet high, are so subordinated to the mighty cliffs over which they pour that they seem like wisps of smoke, gentle as floating clouds, though their voices fill the valley and make the rocks tremble. The mountains, too, along the eastern sky, and the domes in front of them, and the succession of smooth rounded waves between, swelling higher, higher, with dark woods in[Pg 133] their hollows, serene in massive exuberant bulk and beauty, tend yet more to hide the grandeur of the Yosemite temple and make it appear as a subdued subordinate feature of the vast harmonious landscape. Thus every attempt to appreciate any one feature is beaten down by the overwhelming influence of all the others. And, as if this were not enough, lo! in the sky arises another mountain range with topography as rugged and substantial-looking as the one beneath it—snowy peaks and domes and shadowy Yosemite valleys—another version of the snowy Sierra, a new creation heralded by a thunder-storm. How fiercely, devoutly wild is Nature in the midst of her beauty-loving tenderness!—painting lilies, watering them, caressing them with gentle hand, going from flower to flower like a gardener while building rock mountains and cloud mountains full of lightning and rain. Gladly we run for shelter beneath an overhanging cliff and examine the reassuring ferns and mosses, gentle love tokens growing in cracks and chinks. Daisies, too, and ivesias, confiding wild children of light, too small to fear. To these one’s heart goes home, and the voices of the storm become gentle. Now the sun breaks forth and fragrant steam arises. The birds are out singing on the edges of the[Pg 134] groves. The west is flaming in gold and purple, ready for the ceremony of the sunset, and back I go to camp with my notes and pictures, the best of them printed in my mind as dreams. A fruitful day, without measured beginning or ending. A terrestrial eternity. A gift of good God.\nJune 14. The pool-basins below the falls and cascades hereabouts, formed by the heavy down-plunging currents, are kept nicely clean and clear of detritus. The heavier parts of the material swept over the falls are heaped up a short distance in front of the basins in the form of a dam, thus tending, together with erosion, to increase their size. Sudden changes, however, are effected during the spring floods, when the snow is melting and the upper tributaries are roaring loud from “bank to brae.” Then boulders that have fallen into the channels, and which the ordinary summer and winter currents were unable to move, are suddenly swept forward as by a mighty besom, hurled over the falls into these pools, and piled up in a new dam together with part of the old one, while some of the smaller boulders are carried further down stream and variously lodged according to size and shape, all seeking rest where the force of the current is less than the resistance they are able to offer. But the greatest changes made in these relations of fall, pool,[Pg 48] and dam are caused, not by the ordinary spring floods, but by extraordinary ones that occur at irregular intervals. The testimony of trees growing on flood boulder deposits shows that a century or more has passed since the last master flood came to awaken everything movable to go swirling and dancing on wonderful journeys. These floods may occur during the summer, when heavy thunder-showers, called “cloud-bursts,” fall on wide, steeply inclined stream basins furrowed by converging channels, which suddenly gather the waters together into the main trunk in booming torrents of enormous transporting power, though short lived.\nHow boundless the day seems as we revel in these storm-beaten sky gardens amid so vast a congregation of onlooking mountains! Strange and admirable it is that the more savage and chilly and storm-chafed the mountains, the finer the glow on their faces and the finer the plants they bear. The myriads of flowers tingeing the mountain-top do not seem to have grown out of the dry, rough gravel of disintegration, but rather they appear as visi[Pg 153]tors, a cloud of witnesses to Nature’s love in what we in our timid ignorance and unbelief call howling desert. The surface of the ground, so dull and forbidding at first sight, besides being rich in plants, shines and sparkles with crystals: mica, hornblende, feldspar, quartz, tourmaline. The radiance in some places is so great as to be fairly dazzling, keen lance rays of every color flashing, sparkling in glorious abundance, joining the plants in their fine, brave beauty-work—every crystal, every flower a window opening into heaven, a mirror reflecting the Creator.', 'The world is getting warmer and warmer — and many organisms native to lower latitudes or elevations are moving higher.\nHowever, novel organisms moving into a new habitat could disturb the ecological balance which has been established over a long period. Plants and herbivores are characterised by long-term co-evolution, shaping both their geographic distribution and the characteristics that they display in their occupied sites.\nAt higher elevations, this is seen in insect herbivores being generally less abundant and plants in turn being less well defended against herbivores, as a result of lower energy and shorter growing seasons. In contrast, low-elevation plant species defend themselves against more abundant and diverse herbivores, whether by means of spikes, thorns or hair, or by toxic substances. Climate change could disturb this ecological organisation.\nGrasshoppers translocated to high elevations\nIn an experiment, researchers from ETH Zurich, the Swiss Federal Institute for Forest, Snow and Landscape Research (WSL) and the University of Neuchâtel investigated what could happen if herbivores — in this case various grasshoppers from middle elevations — settled in alpine meadows at higher elevations and encountered new plant communities there. The study has just been published in the journal Science.\nThe researchers translocated various grasshopper species from medium altitudes (1,400 metres above sea level) to three alpine grassland sites at elevations of 1,800, 2,070 and 2,270 metres above sea level, where the ecologists placed the grasshoppers in cages. The local grasshoppers had previously been removed from the experimental areas. The experiment was carried out in the Anzeindaz region in the Vaud Alps, Switzerland.\nIn their study, the researchers measured things like how the biomass, structure and composition of the alpine plant communities changed under the influence of the herbivorous insects. The researchers also investigated whether some plant species were more susceptible to herbivory, for instance plants with tougher leaves, or those containing more silica or other constituents such as phenols or tannins.\nLowland grasshoppers influence alpine community\nThe ecologists discovered that the grasshoppers’ feeding behaviour had a clear influence on the vegetation structure and composition of the alpine flora. Alpine communities display clear structure in the organisation of the canopy, with plants with tough leaves at the top, and more shade-tolerant plants with softer leaves at the bottom. But this natural organisation was disturbed, because the translocated grasshoppers preferred to feed on taller and tough alpine plants, which exhibited functional characteristics such as leaf structure, nutrient content, chemical defence, or growth form similar to those of their previous, lower-elevation food plants. As a result, the insects reduced the biomass of dominant tough alpine plants, which in turn favoured the growth of small-stature plant species that herbivores avoid. The overall plant diversity thus increased in the short term.\n“Immigrant herbivores consume specific plants in their new location and this changes and reorganises the competitive interaction between those alpine plant species,” says the study’s first author, Patrice Descombes. Global warming, for example, could disrupt the ecological balance because mobile animals, including many herbivorous insects, can expand their habitat to higher elevations more rapidly than sedentary plants. Herbivorous insects from lower altitudes could therefore have an easy time in alpine habitats with resident plants that are insufficiently or not at all prepared to defend themselves against those new herbivores. This could change the current structure and functioning of alpine plant communities as a whole. Climate change would thus have an indirect impact on ecosystems, in addition to the direct consequences of rising temperatures.\nImportant drivers of changed ecosystems\nFor Loïc Pellisier, Professor of Landscape Ecology at ETH Zurich and WSL, this indirect effect of climate change on ecosystems is one of the most important things to emerge from the study: “Climate impact research has largely investigated the direct effects of temperature on ecosystems, but these novel interactions that arise between species moving into new habitats could generate important structural modifications. They are important drivers of changed ecosystems in an increasingly warm climate.”\nWith their results, the researchers also want to improve models that have so far only inadequately integrated such processes. They also hope that this will improve the prognosis of how climate change will influence the functioning of ecosystems and the services they provide.\nMaterials provided by ETH Zurich. Original written by Peter Rüegg. Note: Content may be edited for style and length.']	['<urn:uuid:30106118-c9a9-484a-95a8-13c1a8f5815f>', '<urn:uuid:047039e7-f383-416b-8774-195340dbf6d1>']	open-ended	with-premise	short-search-query	similar-to-document	multi-aspect	novice	2025-05-12T23:47:20.322175	7	100	2874
5	Being interested in traditional masonry and cooking equipment, I'd like to know how the structural requirements differ between a stone pizza oven and a Shokunin Kamado Grill - which needs more complex construction materials?	The stone pizza oven requires more complex construction materials, needing both refactory brick with heat resistant mortar for the inner oven, plus an external stone structure that must be carefully built with chiseled curved stones and a corbelled roof. The Shokunin Kamado Grill, in contrast, simply requires basic components like a fire grate, cooking grates, and a pizza stone for operation.	"['We finished the exterior of a stone clad summer house some time ago. We wanted the stonework of the building to be very tight and to not show any gaps or mortar and so we selected a flat bedded Yorkshire sandstone. The three main windows were designed to let in natural light and to allude to Georgian symmetry. We also built the cabin with a large double doors that could be left open on a summers day.\nThe attention then turned to the interior which had to be wired, fitted, plastered and painted. The result is a relaxed creative office space that can double as a garden living room. The floor is two-inch thick Cornish slate, which lends a vintage look combined with the large local oak beams and window frames. We painted the interior with a shade of London Plane green which is perfect for a garden space.\nWe have finished the tall dry stone wall that separates a large car parking area from a curving terrace garden with a central path. The wall is above 6 foot in places and provides a pleasant screen from the vehicles when sat in the garden. The path leads through two beds on either side and leads to a stone patio seating area that is raised up by the terrace wall and provides striking views down the valley.\nAnother entrance on the other side of the parking bay is created by two curving wall ends that create an artistically symmetrical gateway that leads to a gradually declining stone staircase surrounded by alliums and hellebores.\nOn a sandstone patio we erected a large stone block that supports a beautiful Forest of Dean stone slab which makes a fantastic seating area to sit and look at the view on a sunny day.\nWe have been continuing to work on the area of garden reclaimed from thin air by the large terrace wall and lots of soil infill. We got 20 tonnes of soil from a different quarry in West Yorkshire that we liked the look of. We built a curving boundary dry stone wall that defines a large sloping soil bed that we raked out and have begun planting up with trees and shrubs. In this area we have also created paths lined with sawn sandstone blocks leading to a small sandstone patio with an interesting block stone altar table.\nHere is the wall underway:\nThe wall has opened up a large sloping bed that had quite a bit of top soil brought in from elsewhere to bolster the fertility. The small trees that have been planted towards the wall are a prunus spinosa and a viburnum opulus. We also put in a few different varieties of euphorbia, which makes for a more interesting planting. Everything just needs a lot of watering and some time to grow!\nBelow the wall, the path sweeps round to the sandstone patio and large block table that we have built. The table and patio are on the edge of the terrace but puts the sitter at the height of the sambucus growing on the other side. When it\'s in blossom this is a nice time to sit and reflect.\nThe wall continues and tightly curves to form a large ovular car parking space. This has to be a large substantial wall with large foundations, which is still underway. We have just had another 20 tonnes of stone delivered from West Yorkshire and it looks like quite a pile, but a long and tall wall like this is very hungry for stone so it will all disappear into the wall in due course.\nLast year we began the process of transforming a steep orchard area of apple trees and fruit bushes into a series of stepped terraces. This involved bringing in around 60 tonnes of stone thus far and the tallest of the terrace walls is complete. To flatten the area tonnes and tonnes of soil had to be brought in behind the wall as it went up. Now the area is flattened we have begun planting up the new bed. New fruit bushes have also been planted at the base of the wall.\nHere is the completed wall, holding the tonnes of soil forming the upper terrace. We have also excavated some paths in the earth of the lower bank that will be a network of grass paths once the grass seeds germinate. Smaller walls are planned further down the bank to create a stepped terrace landscape.\nBehind the terrace wall is a planting bed which will have a gravel path running alongside it edged with stone bricks. This will lead to the large slab staircase we already built. We are now working on a large curving wall that partly retains another level of ground that will be a hard standing area.\nBefore Christmas we worked on a rural village garden in idyllic setting with a small stream running through it. It was nice working to the sound of running water. The job involved bringing in 20 tonnes of quarried stone to build one large planter 4 metre in diameter around an olive tree and an adjacent wall with a three cheek ends. The olive was apparently brought in containerised from Spain.\nThe copes (i.e. the top stones) of the circular planter are flat with and at the right height to serve as a seating area. These copers required quite a bit of working in order to get an inner and outer curved edge but it is a nice clean effect overall. The wall itself kept the regional West-Riding style of coping which had to be chiselled to shape.\nBuilding the stone pizza oven\nDuring the summer of this year, we built a stone wood-fired pizza oven. It was entirely of our own design and we wanted it to have a traditional rustic character with a nod to traditional features and yet also feel contemporary in appearance. The external stone structure encapsulates a refectory brick oven, built with heat resistant mortar, to cope with the high heat of the wood fired oven. The stone is cylindrical and it formed such a tight curve that each stone block needed to have it face chiselled to the right curvature as well as having its sides tapered. However, the extra effort was worth it as the circles and curves complement each other, the curve of the arch over the oven mouth and the domed corbelled roof are reflected by the curved shape of the body of the oven. The archway had to be built across the curve of the oven, which took a lot of skill to achieve. The arch is very tight and we managed to find a nice long stone to chisel into a lintel for below the arch. Having two large jumper stones to form the base on each side of the arch added a nice symmetry.\nThe stone was handpicked by us from a Yorkshire quarry and it is an extremely hard sandstone. One of the nice things about using a local natural product like this is the naturally occurring patterns and colour variations that create pleasing character rather than being uniform. We also took a lot of effort to \'grade\' the stone into courses so that the larger stones are toward the bottom and the size of the stones diminish in height further up until we reached the slate-like pieces for the top of the corbel. As well as good practice, this helps the masonry to look right on the eye. The roof curves in on the top of the chimney pipe of the oven and the smoke rises out of the hole in the top. We had to carve a domed stone finial for the top to hold down the top course of stone slates with a hole in the centre to let out the smoke. Finally, we made a thin circular piece of stone to sit on top of the finial to keep out the rain when the oven isn\'t being used, which was more visually pleasing than a metal chimney cowl.\nIt was surprising in the end just how much stone was required for a feature like this. The entire base up to the chimney opening is solid dry stone with the centre filled in with larger stones which are then packed tightly around with the offcut stone chips that chiselling produces. Overall, it is a dense structure but it ought to be around for a long time to come.\nUsing the stone pizza oven\nSince the construction of the oven we have used it to make pizzas several times already during the summer. We first had to light a fire just to \'proof\' the oven. Then on a dry day we tried making pizzas, which it turns out is quite an art form. It does take a while to get the oven up to a high temperature and the type and dryness of the wood is important in this. Once to temperature, however, a large number of pizzas can be produced.\nOn an area of sloping ground where there is a small orchard we are building curving stone walls to form flat terraces. As we build the new retaining wall, we will then infill behind it with tonnes of soil in order to form the new level and turn sloping ground into a flat garden area. Dry stone is the perfect way to do this as it is so free draining, there is no mortar or concrete to stop the drainage of water. In order to hold such a large amount of soil, the wall is very thick and has a considerable backing of large stones.\nSoil is being riddled and brought in slowly via tractor allowing us to build up courses of the retaining wall as soil is filled in behind it which helps to stabilise the wall. We will also have to move some small fruit trees and bushes as the dormant season approaches; often in landscaping there will be some temporary disruption in order to do something new.\nWe have continued making progress on the walled garden, our take on the productive feature of many old estates.\nPart of the design for the stone walled garden includes two stone structures in the corner of the garden. We completed a stone pizza oven earlier in the year and we have also completed the exterior of a stone building that is a garden room or summer house. Once the interior is fitted out, it will be a great space for enjoying the garden in the summer months. The garden room sits on the blueprint of an older lime mortared brick and stone building, however we wanted a dry stone appearance to compliment the surrounding dry stone walls. We opted to use a flat very evenly bedded Yorkshire sandstone which would give the stonework on the building very tight and less rustic in character than a dry stone wall. We also constructed a timber roof frame using local oak and tiled it from large flat pieces of Yorkshire sandstone which we shaped into sandstone roofing tiles. This seemed the most appropriate thing to do rather than simply using slate as sandstone tiles are much more traditional to this area and we wanted to create a new building that, although had some modern features would also completely sit at home within its historical environment.\nA recent repair of a tumbled down section of dry stone walling is a good reminder of how important it is to have a strong structure to a dry stone wall. Aside from sound foundations and correct wall batter, or pitch, a common problem to encounter with fallen sections is that the stones are mostly laid ""length on"" like bricks rather than placed into the wall for greater strength. This means that in the middle of the wall a larger space is left having to be filled in with more stone rubble infill known as hearting or packing. When the wall is mostly hearting through the centre and there are also no longer stones, called \'through\' stones or tuskers, placed right the way through, the wall will not stay up long. This is because there is nothing tying the two outer skins of the wall together and it is mostly relying on the action of gravity from the wall batter.\nBuilding in this way is not good practice and can be called \'trace walling\', however there can also be other reasons. The waller could have only had access to smaller pieces of stone and was making do with the materials to hand or perhaps had limited stone and was making the outer stone go further and using more infill. It may also be that appearance had been prioritised over strength as the longer \'faces\' of the stone can give a more regular masonry appearance. A wall can appear well put together on the surface, but not be strongly built.\nThis means that when a wall comes down and the original has been built in a \'trace walling\' way, in order to strengthen it you can expect to have to bring in quite a bit of extra stone. The original wall will not be a dense structure and once you start turning the stones inwards this means that you will be making the wall more dense, meaning you\'ll ultimately need more stone. Also. if there are few or no \'through\' stones, then you\'ll need to bring these crucial stones in as well. The waller is always on the look out for \'throughs\', which are laid in several alternate bands in the wall and are very important in holding it all together.', 'Making Pizzas in the Shokunin Kamado Grill\nThe Shokunin Kamado Grill is incredibly versatile. Use it to smoke, roast, bake and grill with a flavorful charcoal and wood fire. One of our favorite things to cook in the Shokunin is pizza. Because of the amazing efficiency of the Shokunin’s insulated design, it is easy to maintain a 750°F baking temperature for hours at a time. At this temperature, you can make a perfect pizza in just three minutes.\nThis simple guide to baking pizzas in Kalamazoo’s kamado grill will walk you through the tools, steps and techniques needed for a successful artisan pizza night at home.\nThis two-piece baking deck creates an air gap for more gentle heat.\nTHE TOOLS YOU’LL NEED\nThe most important tool you’ll need is a hollow-core baking deck or pizza stone. The cordierite two-piece deck from PizzaCraft is ideal for balancing the heat and preventing the bottom of the pizza from cooking too quickly. Make sure your pizza stone is no more than 16 inches in diameter.\nIf your pizza stone is solid, without an air gap, you can use an aluminum pizza screen between the pizza and the stone to slow down the cooking.\nA perforated pizza peel, like the one included in Kalamazoo’s Pizza Master’s Essentials Kit (PMEK), is very helpful in transferring the assembled pizza into the grill. A wooden pizza peel, or even a thin cutting board can also be used. The PMEK also includes a pair of dough boxes that are helpful when resting the dough prior to shaping the crust.\nOnce the pizza has cooked, you can lift it out of the grill with a large grill turner or spatula, or you can use a pizza peel.\nPizza cooking with a pizza screen on top of the stone.\nA chimney starter gets the charcoal started quickly with no chemicals.\nSETTING UP THE GRILL\nConfigure your grill with the fire grate placed in the highest of the three positions. Because of the tapered interior shape of the Shokunin, you’ll want to slide each part of the two-piece adjustable fire grate to the outside (far left and far right) of the grill. Pile a little hardwood lump charcoal in each of the four corners of the grill.\nOpen all four vents (two supply vents in the base of the grill and two exhaust vents in the lid) to the wide-open positions.\nStarting the Fire\nFill the chimney starter with more lump charcoal. We typically use a paper grocery sack to start the chimney, but you can also use paraffin fire starters. To use paper, loosely wad it up and put it inside the bottom of the chimney starter. Place the chimney starter in the center of the fire grate, then use the plumber’s torch to light the paper on fire. Leave the grill lid open and the cooking grates flipped up out of the way while the charcoal starts, about 15 minutes.\nOnce the fire has travelled all the way up the chimney and the coals at the top are burning, it is time to distribute them in the grill. Use long, protective gloves to pour the burning coals out of the chimney starter and onto the unlit charcoal that was positioned earlier. You want to keep all of the charcoal positioned toward the corners of the fire grate so that the heat envelopes the pizza and reflects down from the inner curvature of the lid.\nOnce the charcoal is distributed, you can add wood chunks or small wood splits on top of the charcoal. The wood will boost the heat and add subtle wood flavor to the pizza. (Unlike a wood-fired pizza oven, where the fire is next to the pizza and the smoke travels out the chimney, the fire in the Shokunin is below the pizza so the flavor is noticeable.)\nNow you can lower the cooking grates into position and place the pizza stone in the center of the cooking grate.\nClose the lid and preheat the grill to 750°F, about an hour of preheating time.\nCOOKING THE PIZZA\nAssemble your pizza on the countertop, then transfer to the pizza stone using a pizza peel (see tips that follow). Close the lid and start a three-minute timer. The pizza will cook evenly from all sides and does not need to be rotated in the Shokunin. With a hollow-core pizza stone, the pizza will cook untouched for three minutes.\nWith a solid stone, check the pizza after one minute. If the crust has “set” and the pizza is easily moved, gently lift it off the stone and slide a pizza screen into position. Close the lid and continue cooking for the remaining two minutes.\nRemove the pizza when done and let rest for a minute before slicing.\nPIZZA MAKING TIPS\nBecause we are cooking pizzas quickly at a high temperature, use a pizza dough made in whole or in part with Tipo ‘00 flour. This is the flour used in traditional Neapolitan pizzas. Our Artisan Fire Pizza Dough recipe is perfect for cooking in the Shokunin.\nPizza dough needs to relax before stretching, and ideally needs to come up to room temperature. We recommend keeping dough balls in the dough box at room temperature for three to four hours before making pizza. A seven to ten ounce dough ball size is good for working with a 14-inch diameter pizza stone.\nWhen forming the pizza, be gentle with the dough. You want to avoid “bruising” it and creating areas that can’t form air pockets inside as the crust bakes. We form our pizzas by hand rather than using a rolling pin. The dough can be formed to a flat disc. There is no need to form it with a raised crust around the outside. The heat of the grill will do that for you.\nThe first two minutes of this pizza making video includes tips for stretching the dough and getting the assembled pizza onto the pizza peel.\nOur Favorite Pizza Recipes\nThese recipes are all written for the Artisan Fire Pizza Oven, but are easily cooked in the Shokunin following the directions above. Browse the full collection of pizza recipes in the recipes section of our website. Below are some of our favorites:']"	['<urn:uuid:cecee591-71a3-4bca-911e-e5e833ab83d8>', '<urn:uuid:f3fbe984-562f-471b-8a09-c5cfc016b6f0>']	factoid	with-premise	verbose-and-natural	distant-from-document	comparison	expert	2025-05-12T23:47:20.322175	34	61	3325
6	Did Thomas Dodd and Robert La Follette Jr both serve in World War 1?	Neither of them served in World War I. Thomas Dodd's military service is not mentioned in the documents, while Robert La Follette Jr. was kept out of military service during World War I due to illness.	"['Thomas Joseph Dodd was a United States Senator and Representative from Connecticut, He is the father of former U.S. Senator Christopher Dodd and Thomas J. Dodd, Jr., who served as the United States Ambassador to Uruguay from 1993 to 1997 and to Costa Rica from 1997 to 2001.\nDodd was born in Norwich, New London County, to Abigail Margaret (née O\'Sullivan) and Thomas Joseph Dodd, a building contractor; all four of his grandparents were immigrants from Ireland. His paternal grandparents were farmers in the Housatonic river valley with large commercial tobacco leaf farms located near Kent and New Milford. He graduated from Saint Anselm College\'s preparatory school, run by Benedictine monks in Goffstown, New Hampshire, in 1926. He graduated from Providence College in 1930 with a degree in philosophy, and from Yale Law School in 1933. In 1934, Dodd married Grace Murphy of Westerly, Rhode Island. They had six children.\nHe served as a special agent for the Federal Bureau of Investigation in 1933 and 1934, the highlight of his career there being his participation in an unsuccessful attempt to capture John Dillinger at Little Bohemia Lodge. He was then Connecticut director of the National Youth Administration from 1935 to 1938. He was assistant to five successive United States Attorneys General (Homer Cummings, Frank Murphy, Robert Jackson, Francis Biddle and Tom Clark) from 1938 to 1945.\nAs a special agent for the Attorney General, Dodd was basically a trial-level federal prosecutor. He worked primarily on criminal and civil liberties cases, including the prosecution of the Ku Klux Klan in the 1930s. In 1942, he was sent to Hartford to prosecute a major spy ring case in which five men (Anastasy Vonsyatsky, Wilhelm Kunze, and others) were accused of violating the Espionage Act of 1917 by conspiring to gather and deliver US Army, Navy, and defense information to Germany or Japan. Four of the five pleaded guilty; Dodd tried and won the conviction of the fifth man, Reverend Kurt Emil Bruno Molzahn.\nDodd became vice chairman of the Board of Review and later executive trial counsel for the Office of the United States Chief of Counsel for the Prosecution of Axis Criminality at Nuremberg, Germany, in 1945 and 1946. He practiced law privately in Hartford, Connecticut, from 1947 to 1953.\nBoth Supreme Court Justice Robert H. Jackson, chief prosecutor for the U.S., and Dodd insisted upon a fair and legal trial to prosecute the Nazi war criminals. Dodd accepted Jackson\'s offer to join him in Germany. Dodd expected the position to last only several months, but he wound up spending 15 months there. Dodd suggested Heidelberg as the location for the International Military Tribunal, since it had survived the war almost completely unscathed, but Nuremberg was eventually chosen. In October 1945, Jackson named Dodd to his senior Trial Board for the Nuremberg Trials, and later in 1946, named him Executive Trial Counsel, putting him in the number-two position at the trials. In the summer of 1946, Jackson appointed Dodd as the acting Chief of Counsel while he returned to DC. Dodd finally returned to the U.S. in October 1946. He described the delegation as ""an autopsy on history\'s most horrible catalogue of human crime.""\nDodd cross-examined defendants Wilhelm Keitel, Alfred Rosenberg, Hans Frank, Walther Funk, Baldur von Schirach, Fritz Sauckel and Arthur Seyss-Inquart. In addition to cross-examining, Dodd drafted indictments against the defendants, showed films of concentration camps, provided evidence of slave labor programs, and presented evidence of economic preparations by the Nazis for an aggressive war.\nDodd showed through his evidence that Erich Koch, the Reichkommissioner for the Ukraine and defendant Hans Frank, the Governor-General of Poland were responsible for the plan to deport one million Poles for slave labor. Dodd also showed evidence that defendant Walther Funk turned the Reichsbank into a depository for gold teeth and other valuables seized from the concentration camp victims. Dodd showed a motion picture of the vaults in Frankfurt where Allied troops found cases of these valuables, containing dentures, earrings, silverware and candelabra. Dodd showed many gruesome items of evidence, such as a shrunken, stuffed and preserved human head of one of the concentration camp victims that had been used as a paperweight by the commandant of Buchenwald Concentration Camp.\nFinal pleas were made on August 31, 1946, and the Tribunal announced its judgment in September 1946. Dodd assisted the Allied prosecuting team of convicting all but three of the defendants. All but one of the defendants had claimed innocence, including Hermann Göring, whom Dodd had charged with ordering Reinhard Heydrich to set the Holocaust in motion. In addition to prosecuting the individual defendants, Dodd demanded in his summation to the Tribunal that all six of the indicted Nazi organizations be convicted of crimes against humanity, on the same grounds of the crimes against humanity ascribed to the individual defendants. These six organizations are the Leadership Corps, the Reich cabinet, the Gestapo, The Storm Troops (SA), the Armed Forces, and the Elite Guard (SS). Dodd said that these organizations should not escape liability on the grounds that they were too large, part of a political party, etc.\nDodd was given several awards in recognition of his work at the Nuremberg trials. Jackson awarded him the Medal of Freedom in July 1946 and President Harry Truman awarded him the Certificate of Merit, which Jackson personally delivered to him in Hartford in the fall of 1946. Dodd also received the Czechoslovak Order of the White Lion. In 1949, the Polish government had intended to award Dodd with a badge of honor called the Officer\'s Cross of the Order of Polonia Restituta, but Dodd rejected the medal due to his commitment to human rights and views that the Polish government was imposing a tyranny like that imposed by the Nazis, and accepting an honor from the President of Poland would be like accepting one from the Nazis.\nDodd was elected as a Democrat to the House of Representatives in 1952, and served two terms. He lost a Senate election in 1956 to Prescott S. Bush, but was elected in 1958 to Connecticut\'s other Senate seat and then re-elected in 1964.\nBefore becoming a U.S. senator, Dodd was hired to lobby for Guatemala in the United States for $50,000 a year by dictator Carlos Castillo Armas. According to the North American Congress on Latin America, Dodd ""had perhaps the coziest relationship with the Castillo Armas government."" After a short trip to Guatemala in 1955, Dodd urged the House of Representatives to increase aid to the Central American country. Dodd\'s amendment passed, and Guatemala received $15 million of US aid in 1956. Dodd was unapologetic when criticized for his lobbying efforts on behalf of the Guatemalan dictatorship. When a Republican organizer challenged Dodd on his lobbying, Dodd stated ""I am a practicing attorney and I am proud of the fact that the anti-communist government of Guatemala has asked me to handle its legal affairs in the US. Of course, I will not represent the government of Guatemala or any other private client if I am elected to the Senate.""\nIn 1961, Dodd visited the Congo to investigate the civil war caused by the secession of the province of Katanga. In addition to his work in the Congo Senator Dodd opened what became nearly three years of intermittent hearings. The results of the three-committee staff monitoring reports of television content in 1954, 1961, and 1964 showed incidents of violence. Senator Dodd and Estes Kefauver are the two men responsible for informing the public of the effects of violence on juveniles.\nIn the fall of 1965, Dodd tried to get Martin Luther King, Jr. arrested for violating the Logan Act. As chairman of the Senate Subcommittee on Juvenile Delinquency, Dodd worked to restrict the purchase of mail order handguns, and later shotguns and rifles. These efforts culminated in the Gun Control Act of 1968, which Dodd introduced, including certain registration requirements.\nDodd played an instrumental role in the prohibition of LSD in the United States, presiding over subcommittee hearings purportedly investigating the drug\'s effects on youth. Notably, Harvard psychologist and LSD proponent Timothy Leary was called to testify. Despite that Leary urged lawmakers to enact a strictly regulated framework where LSD would remain legal, Dodd and his colleagues drafted a ban which was later adopted. This event was one episode in the prelude towards an all-out ""War on Drugs"" in the 1970s.\nIn 1967 Dodd became the first Senator censured by the US Senate since Joseph McCarthy in 1954, and was one of only six people censured by the Senate in the 20th century. The resulting censure was a condemnation and finding that he had converted campaign funds to his personal accounts and spent the money. Beyond the Senate Ethics Committee\'s formal disciplinary action, other sources (such as investigative journalist Drew Pearson and Jack Anderson\'s Congress in Crisis) suggest Dodd\'s corruption was far broader in scope, and there were accusations of alcoholism. In response to these accusations, Dodd filed a lawsuit against Pearson claiming that Pearson had illegally interfered with his private property. Although the district court granted a partial judgment to Dodd, the appellate court ruled in favor of Pearson because Dodd\'s property had not been physically abused.\nIn 1970, the Democrats endorsed for his seat Joseph Duffey, who won the nomination in the primary. Dodd then entered the race as an independent, taking just under a quarter of the vote, in a three-way race which he and Duffey lost to Republican Lowell Weicker. Dodd finished third, with 266,500 votes–far exceeding Weicker\'s 86,600-vote margin over Duffey. Months after his defeat, Dodd died from a heart attack at his home.', '|Robert M. La Follette Jr.|\n|United States Senator\nSeptember 30, 1925 – January 3, 1947\n|Preceded by||Robert M. La Follette Sr.|\n|Succeeded by||Joseph McCarthy|\n|Born||Robert Marion La Follette Jr.\nFebruary 6, 1895\nMadison, Wisconsin, United States\n|Died||February 24, 1953\nWashington, D.C., United States\nWisconsin Progressive Party\n|Spouse(s)||Rachel Wilson Young|\nRobert Marion ""Young Bob"" La Follette Jr. (February 6, 1895 – February 24, 1953) was a U.S. senator from Wisconsin from 1925 to 1947. As an outspoken son of Representative, Senator, and Wisconsin Governor Robert M. La Follette Sr., co-founder of the Progressive Party and ally of the Farmer-Labor Party in adjacent Minnesota, La Follette kept the Progressive Party alive in the US Senate until his defeat by Joe McCarthy in 1946.\nLa Follette was born in Madison, Wisconsin, the son of Robert M. La Follette Sr. and Belle Case La Follette. He attended the University of Wisconsin–Madison from 1913 to 1917 but he did not graduate because of illness. (He received the honorary degree of LL.D. from the University of Wisconsin in 1938.) The same illness kept him out the military during World War I. La Follette served as his father\'s private secretary between 1919 and 1925. He married Rachel Wilson Young in 1930; they had two children, Joseph Oden La Follette and Bronson Cutting La Follette. La Follette had two siblings, Philip La Follette and Fola La Follette.\nLa Follette was elected as a Republican to the United States Senate on September 29, 1925, to fill the vacancy caused by the death of his father. ""Young Bob,"" as he was called, was a champion of organized labor. He gained national prominence between 1936 and 1940 as chairman of a special Senate investigating committee, commonly called the La Follette Civil Liberties Committee, that exposed the surveillance, physical intimidation, and other techniques used by large employers to prevent workers from organizing.\nHe was chairman of the Committee on Manufactures in the 71st and 72nd Congresses. He supported President Franklin D. Roosevelt and most New Deal legislation until the passage of the 1938 naval expansion bill.\nHe was re-elected as a Republican in 1928. With his brother Philip, he formed the Wisconsin Progressive Party in 1934, and for a time the party was dominant in Wisconsin. He was reelected with the Progressive Party in 1934 and 1940.\nThe Wisconsin Progressive Party dissolved, and La Follette returned to the Republican Party in 1946. La Follette was one of the Senate\'s leading isolationists and helped found the America First Committee in 1940. He helped to draft and win passage of the Legislative Reorganization Act of 1946 that modernized the legislative process in Congress.\nLa Follette was an unsuccessful candidate for reelection as a Republican in 1946. He ran an isolationist campaign against the United Nations and was critical of Soviet dictator Joseph Stalin but ended up narrowly losing to Joseph McCarthy in the Republican primary, 207,935 votes to 202,557. While La Follette initially started with a large lead in the polls, that lead gradually dwindled, and on the primary election day, the results of the final county to report polls tipped the scales in McCarthy\'s favor. La Follette sent a one-word telegram saying ""Congratulations"" to McCarthy.\nLa Follette made several decisions that hurt his primary campaign. Disbanding the Progressive Party and seeking election on the Republican ticket that same year cost him the support of many progressive supporters that belonged to the former, while the more conservative Republicans were also suspicious of La Follette, as he had previously run against them. Being initially confident of victory, he further hurt his chances by staying on in Washington to draft and win passage of the Legislative Reorganization Act of 1946 rather than returning to Wisconsin to campaign for re-election.\nLa Follette faced an aggressive campaign by McCarthy and failed to refute the latter\'s charges, several of which were false. McCarthy attacked La Follette for not enlisting during the war, although La Follette had been 46 when Pearl Harbor was bombed and would have been too old to be accepted. McCarthy played up his own wartime service, using his wartime nickname, ""Tail-Gunner Joe,"" and the slogan ""Congress needs a tail-gunner"". McCarthy also claimed La Follette had made huge profits from investments while he had been away fighting for his country; the suggestion that La Follette had been guilty of war profiteering was deeply damaging. (In fact, McCarthy had invested in the stock market himself during the war, netting a profit of $42,000 in 1943. La Follette\'s investments consisted of partial interest in a radio station, which earned him a profit of $47,000 over two years.)\nArnold Beichman later stated that McCarthy ""was elected to his first term in the Senate with support from the Communist-controlled United Electrical, Radio and Machine Workers, CIO"", which preferred McCarthy to the anti-communist Robert M. La Follette. This charge, however, has never been proved.\nIn a February 8, 1947, Collier\'s Weekly article, La Follette reported infiltration of Communists onto Congressional committee staffs. The Venona project materials revealed that four agents of Soviet intelligence had served on La Follette\'s Civil Liberties Subcommittee, including the chief counsel, John Abt.\nOn February 24, 1953, La Follette was found dead of a self-inflicted gunshot wound in Washington, D.C. On September 9, 1953, John Lautner testified before McCarthy\'s Permanent Subcommittee on Investigations, revealing the existence of Communists that had served on La Follette\'s subcommittee. Some historians believe that La Follette killed himself out of fear of being exposed by McCarthy; others believe he succumbed to anxiety and depression that had plagued him for much of his life.\nLa Follette was interred at Forest Hill Cemetery in Madison, Wisconsin, and was survived by his sons, Bronson La Follette, who served as Wisconsin\'s attorney general 1965–69 and 1975–87, and the late Joseph Oden LaFollette who spent his career working at IBM.\nThe death of former Senator Robert M. La Follette Jr., who killed himself at his home in Washington yesterday, is not expected to have any considerable impact on the Wisconsin political situation, even though many of his followers in the old Progressive movement never abandoned hope that he would someday attempt a political comeback.\n|Wikimedia Commons has media related to Robert M. La Follette, Jr..|\n|United States Senate|\nRobert M. La Follette Sr.\n|U.S. Senator (Class 1) from Wisconsin\nServed alongside: Irvine Lenroot, John J. Blaine, F. Ryan Duffy, Alexander Wiley\n|69th||Senate: R. La Follette Sr. • I. Lenroot • R. La Follette Jr.||House: E. Browne • J. Frear • E. Voigt • F. Lampert • H. Cooper • J. Nelson • J. Beck • V. Berger • J. Schafer • G. Schneider • H. Peavey|\n|70th||Senate: R. La Follette Jr. • J. Blaine||House: E. Browne • J. Frear • F. Lampert • H. Cooper • J. Nelson • J. Beck • V. Berger • J. Schafer • G. Schneider • H. Peavey • C. Kading|\n|71st||Senate: R. La Follette Jr. • J. Blaine||House: E. Browne • J. Frear • F. Lampert • H. Cooper • J. Nelson • J. Schafer • G. Schneider • H. Peavey • C. Kading • W. Stafford • M. Hull|\n|72nd||Senate: R. La Follette Jr. • J. Blaine||House: J. Frear • J. Nelson • J. Schafer • G. Schneider • H. Peavey • C. Kading • W. Stafford • M. Reilly • G. Withrow • G. Boileau • T. Amile|\n|73rd||Senate: R. La Follette Jr. • R. Duffy||House: J. Frear • H. Peavey • M. Reilly • G. Withrow • G. Boileau • G. Blanchard • C. Henney • R. Cannon • T. O\'Malley • J. Hughes|\n|74th||Senate: R. La Follette Jr. • R. Duffy||House: M. Reilly • G. Withrow • G. Boileau • R. Cannon • T. O\'Malley • T. Amlie • H. Sauthoff • G. Schneider • M. Hull • B. Gehrmann|\n|75th||Senate: R. La Follette Jr. • R. Duffy||House: M. Reilly • G. Withrow • G. Boileau • R. Cannon • T. O\'Malley • T. Amlie • H. Sauthoff • G. Schneider • M. Hull • B. Gehrmann|\n|76th||Senate: R. La Follette Jr. • A. Wiley||House: M. Hull • B. Gehrmann • S. Bolles • C. Hawks Jr. • H. Griswold • J. Schafer • L. Thill • F. Keefe • R. Murray • J. Johns|\n|77th||Senate: R. La Follette Jr. • A. Wiley||House: M. Hull • B. Gehrmann • L. Thill • F. Keefe • R. Murray • J. Johns • H. Sauthoff • W. Stevenson • T. Wasielewski • L. Smith|\n|78th||Senate: R. La Follette Jr. • A. Wiley||House: M. Hull • F. Keefe • R. Murray • H. Sauthoff • W. Stevenson • T. Wasielewski • L. Smith • H. McMurray • L. Dilweg • A. O\'Konski|\n|79th||Senate: R. La Follette Jr. • A. Wiley||House: M. Hull • F. Keefe • R. Murray • W. Stevenson • T. Wasielewski • L. Smith • A. O\'Konski • R. Henry • A. Biemiller • J. Byrnes|']"	['<urn:uuid:0b2111ca-7991-475a-a216-7bb7ae637ecb>', '<urn:uuid:49b3fd78-7da5-4778-b4de-af0d5fb16122>']	open-ended	direct	concise-and-natural	similar-to-document	comparison	novice	2025-05-12T23:47:20.322175	14	36	3098
7	adhd therapy control effectiveness measurement methods	Current ADHD treatment evaluation relies primarily on behavioral symptoms improvement, requiring at least six behavioral symptoms for diagnosis. However, researchers suggest that treatment effectiveness should also consider neurocognitive outcomes like inhibitory control. Studies show that while neurofeedback's effectiveness can be measured through improved reading comprehension and attention metrics, methylphenidate's effectiveness should be evaluated through both behavioral symptoms and neurocognitive functioning, as higher doses may improve behavioral symptoms without enhancing inhibitory control.	"['Jeff La Marca, Ph.D., assistant professor of special education, has completed a study funded through a Seton Hall University Research Council Grant titled ""Evaluation of Artifact-Controlled Electroencephalographic (EEG) Training: A Pilot Study."" The study provided further research into the use of EEG training, otherwise known as Neurofeedback, as a potentially useful non-medicinal method to improve focus and concentration for individuals diagnosed with ADD/ADHD. Specifically, Neurofeedback is used to train individuals to control their own brainwaves. In this study, La Marca evaluated how movements of the eyes and facial muscles (termed artifacts) affected the ability to accurately read brainwaves. Through potential future grant-funded research, La Marca aims to examine if Neurofeedback is a viable non-medicinal option to improve academic performance in students with attention deficits.\nNeurofeedback is a form of biofeedback, based on the principles of operant conditioning using EEG data, which trains individuals to control their own brainwaves. Although used to treat ADD since 1976, it has never been regulated to act in place of medications such as Ritalin. As such, its effectiveness has not been sufficiently confirmed. La Marca views his research of Neurofeedback as a potentially significant break-through in the safe treatment of ADD/ADHD, which may be used in schools.\nEssentially, individuals with ADD/ADHD experience an overabundance of theta brainwaves during many daily activities.. Theta is a frequency (4 to 8 Hz or cycles per second) that the brain usually produces when entering a light state of sleep. The ability to pay attention is optimum when a faster brainwave frequency, low beta brainwaves (15 to 18 Hz) are present. Neurofeedback has the ability to train the brain to reduce theta brainwaves and increase low beta when practiced during an extended period. This may help students with attention deficits to do better in school.\nLa Marca began his research in California, evaluating a group of fourth grade students during 40 half-hour sessions in which they played brainwave-activated video games while being monitored with electrode receivers. A car racing game was one of many different options where the students\' opportunity to win was based on their ability to decrease their theta and increase their low beta brainwaves in order to compete against the computer and move the game forward. La Marca\'s findings found that Neurofeedback improved the group\'s reading comprehension, fluency, and speed at the conclusion of the training.\nThe next phase of La Marca\'s research sought to explore how the removal of artifacts, such as muscle and eye movements, would serve to improve the accuracy of the results. Fourteen New Jersey college students were selected for participation based on previous diagnoses of ADHD or for meeting inclusionary criteria suggesting an attention deficit. Those meeting inclusionary criteria were randomly assigned to either an artifact-corrected group or non-artifact corrected group. Participants and Seton Hall graduate research assistants were blinded to the purpose of the study and were told that the research was designed to measure changes in attention. Only La Marca knew which participants were assigned to each group. As anticipated, students who were trained with extraneous signaling due to muscle and eye movements were more successful in controlling their brainwaves and showed significant improvements in attention as measured by computer assessments.\nLa Marca has collaborated with colleagues in the fields of psychology to produce his research, yet is unique among them as an educator with a focus on neurological conditioning. He is now in the process of disseminating the findings of his research via journal publications and conference presentations and is pursuing grant funding that would allow him to replicate it on a larger scale. His future work could have implications for academic achievement, assessment, and intervention in schools. He states, ""We would have the potential to go into schools and help children to learn better without the use of medication.""\nLa Marca, J. P. (2018). Historical overview of attention deficit-hyperactivity disorder and neurofeedback: Implications for academic achievement, assessment, and intervention in schools. Contemporary School Psychology, 22(1), 1-17. doi:10.1007/s40688-017-0155-9\nLa Marca, J. P., & O\'Connor, R. E. (2016). Neurofeedback as an intervention to improve reading achievement in students with attention deficit hyperactivity disorder, inattentive subtype. NeuroRegulation, 3(2), 55-77. doi:10.15540/nr.3.2.55\nLa Marca, J. P., Cruz, D., Cacciaguerra, F., Guerra, A. T., Fandino, J., & Fresco, J. J. (2017, September). Artifact-controlled neurofeedback: A pilot study. Poster presented at the 2017 Conference of the International Society for Neurofeedback & Research. Mashantucket, Connecticut.\nLa Marca, J. P. (2018, April). Neurofeedback in schools: An examination of the role of automatic artifact removal during training. Paper to be presented at the 2018 Annual Meeting of the American Educational Research Association, New York, New York.\nLa Marca, J. P. (2018, February-a). Neurofeedback as a strategy to improve academic achievement with ADHD students. Paper presented at the 2018 Annual Convention of the National Association of School Psychologists, Chicago, Illinois.\nLa Marca, J. P., Cruz, D., Cacciaguerra, F., Guerra, A. T., Fandino, J., & Fresco, J. J. (2018, February). Neurofeedback and automatic artifact removal: Considerations for effective training procedures. Poster presented at the 2018 Annual Convention of the National Association of School Psychologists. Chicago, Illinois.\nLa Marca, J. P. (2018, February-b). Neurofeedback as an intervention for ADHD in public schools. Paper presented at the 55th Annual (2018) International Conference of the Learning Disabilities Association of America, Atlanta, Georgia.', 'ADHD meds not necessarily more effective in higher doses\nWhen children with ADHD don’t respond well to methylphenidate, doctors often increase the dose. Now a new review shows that increasing the dose may not always be the best option, as it may have no effect on some of the functional impairments associated with ADHD.\nAttention-deficit/hyperactivity disorder (ADHD) is the most common childhood-onset psychiatric disorder, characterised by symptoms such as inattention, hyperactivity and impulsivity. Worldwide, around 5% of children and adolescents suffer from ADHD.\nDiagnosis of ADHD requires that a patient exhibit at least six behavioural symptoms; treatment is normally judged on how well these behavioural symptoms are improved. However, children with ADHD can also be characterised by looking at functional impairments such as neurocognitive functioning, including inhibitory control — a measure of how they keep their impulsiveness under control.\nMethylphenidate (MPH, sold under the trade name of Ritalin) has been commonly used as a first line medication to treat children with ADHD since the 1990s — but while it is generally effective and well tolerated, around 30% of children taking MPH don’t respond to standard doses, often leading doctors to consider increasing the dose. Furthermore, MPH carries the risk of side effects, including growth retardation and difficulty in gaining weight, which may become more significant at increased dose and with long-term use.\nTo understand and distil the effects of the drug on children with ADHD, Karen Vertessen and colleagues at the Vrije Universiteit Amsterdam undertook a review of all the scientific literature to dose effects of MPH on inhibitory control in children and adolescents. They identified 18 studies, comprising in total 606 subjects with ADHD, and classified the MPH doses reported as low, medium or high.\nThe researchers found that a medium dose of MPH had the strongest beneficial effects on inhibitory control. Increasing the dose past medium had some effect on behavioural factors, but not on inhibitory control. The outcome was presented at the 32nd ECNP (European College of Neuropsychopharmacology) Congress, held in Copenhagen in early September.\n“Scientifically, this is an interesting result,” Vertessen said. “Generally, high doses of MPH does not help the child or adolescent keep their inhibitions under better control, although an increased dose, in general, does have a greater effect on the core behavioural symptoms of ADHD.\n“Even though inhibitory control is just one aspect of impulsivity, we suggest that medically we need to be cautious about just increasing the dose when a child does not instantly respond to the drugs. Children are more vulnerable than adults in these cases, especially since they will be just beginning to receive treatment, and so many treatment variables will still need to be established. If clinicians decide to start therapy with MPH, they need to keep a close eye on the patient and objectively evaluate every dose, to make sure that the higher dose is actually having an effect.\n“Current ADHD evaluation only uses behavioural outcomes, whereas we suggest adding neurocognitive outcomes to this evaluation, given that these outcomes are important for, among others, academic functioning. In other words, checking for whether or not MPH is dealing with inhibitory control might allow us to see if increasing the dose makes sense. To see to what extent these findings might have a clinical impact, we are currently investigating the other most relevant neurocognitive factors related to ADHD.\nThe team of doctors used stereotactic ablative body radiotherapy to treat a patient with a...\nResearchers at the University of Adelaide are working with international partners to train...\nOne in three of us is walking around with untreated tooth decay, while one in four has...']"	['<urn:uuid:5ccff674-1faf-4da1-ad66-e3d77abbc23c>', '<urn:uuid:6bc0cd93-2907-4552-b309-27d51f865cdf>']	factoid	with-premise	short-search-query	distant-from-document	multi-aspect	expert	2025-05-12T23:47:20.322175	6	71	1482
8	imaging methods hospital availability cost comparison	SPECT is the most widely available and least expensive imaging method, with the most extensive validation. PET and CMR demonstrate higher diagnostic accuracy than SPECT, but their availability is more limited. For hospitals, CT and MRI have become the primary imaging methods, with MRI being more expensive than CT but offering advantages in soft tissue imaging, though poorer for bone visualization.	"['Swipe om te navigeren naar een ander artikel\nNoninvasive imaging in the evaluation of a wide variety of cardiovascular diseases has gained an increasing role in the diagnostic strategy in current cardiology practice [1–4]. This holds in particular for patients with myocardial ischaemia due to coronary artery disease (CAD) [5–7]. Of the present imaging modalities, single-photon emission computed tomography (SPECT), positron emission tomography (PET) and cardiac magnetic resonance (CMR) have attained a major position when it comes to myocardial perfusion imaging [8–12].\nIn the May 2012 issue of the Journal of the American College of Cardiology (JACC), Jaarsma et al.  from Maastricht University Medical Center evaluated the diagnostic accuracy of SPECT, PET and CMR for the diagnosis of obstructive CAD. Studies published between 1990 and 2010 identified by PubMed search and citation tracking were examined. A study was included if a perfusion imaging modality was used as a diagnostic test for the detection of obstructive CAD and coronary angiography as the reference standard (50 % diameter luminal stenosis).\nOut of a total of 3635 studies, 166 articles (including 17,901 patients) met the inclusion criteria: 114 SPECT, 37 CMR, and 15 PET studies. There were insufficient publications on perfusion echocardiography and computed tomography to include these modalities in the study. Patient-based analysis per imaging modality demonstrated pooled sensitivities of 88 % for SPECT, 84 % for PET , and 89 % for CMR; pooled specificities were 61 %, 81 %, and 76 %, respectively.\nThe authors concluded that SPECT, PET, and CMR all yielded high sensitivities, whereas a broad range of specificities were observed. CMR and especially PET showed a significantly higher diagnostic accuracy than SPECT. However, SPECT is more widely available, less expensive, and most extensively validated. In addition, the use of attenuation programs improved the specificity of SPECT. CMR may provide a valid alternative without ionising radiation to the nuclear imaging methods. The authors suggested that referring physicians should consider these findings in the context of local expertise and internal logistics.\nThe authors should be complimented for performing this impressive research. It is the first meta-analysis that has directly compared the three most commonly used techniques for myocardial perfusion imaging, i.e. SPECT, PET, and CMR. The present study emphasises that, from a clinical perspective, each of the studied imaging modalities is in principle suited for detection of abnormalities in myocardial perfusion imaging . As always, selective use is mostly dependent on the institutional availability of the imaging device(s), familiarity with the technique, and the individual expert knowledge of the treating physician .\nThis article is distributed under the terms of the Creative Commons Attribution License which permits any use, distribution, and reproduction in any medium, provided the original author(s) and the source are credited.\nGroenink M, Lohuis TA, Tijssen JG, et al. Survival and complication free survival in Marfan’s syndrome: implications of current guidelines. Heart. 1999;82:499–504. PubMed\nvan der Wall EE, Heidendal GA, den Hollander W, Westera G, Roos JP. Metabolic myocardial imaging with 123I-labeled heptadecanoic acid in patients with angina pectoris. Eur J Nucl Med. 1981;6:391–6. PubMed\nde Roos A, Doornbos J, van der Wall EE, van Voorthuisen AE. MR imaging of acute myocardial infarction: value of Gd-DTPA. AJR Am J Roentgenol. 1988;150:531–4. PubMed\nMatheijssen NA, Louwerenburg HW, van Rugge FP, et al. Comparison of ultrafast dipyridamole magnetic resonance imaging with dipyridamole SestaMIBI SPECT for detection of perfusion abnormalities in patients with one-vessel coronary artery disease: assessment by quantitative model fitting. Magn Reson Med. 1996;35:221–8. PubMedCrossRef\nJaarsma C, Leiner T, Bekkers SC, et al. Diagnostic performance of noninvasive myocardial perfusion imaging using single-photon emission computed tomography, cardiac magnetic resonance, and positron emission tomography Imaging for the detection of obstructive coronary artery disease: a meta-analysis. J Am Coll Cardiol. 2012;59:1719–28. PubMedCrossRef\n- Myocardial perfusion imaging in coronary artery disease: SPECT, PET or CMR?\nE. E. van der Wall\n- Bohn Stafleu van Loghum', 'A basic problem in imaging with x-rays (or other penetrating radiation) is that a two-dimensional image is obtained of a three-dimensional object. This means that structures can overlap in the final image, even though they are completely separate in the object. This is particularly troublesome in medical diagnosis where there are many anatomic structures that can interfere with what the physician is trying to see. During the 1930\'s, this problem was attacked by moving the x-ray source and detector in a coordinated motion during image formation. From the geometry of this motion, a single plane within the patient remains in focus, while structures outside this plane become blurred. This is analogous to a camera being focused on an object at 5 feet, while objects at a distance of 1 and 50 feet are blurry. These related techniques based on motion blurring are now collectively called classical tomography. The word tomography means ""a picture of a plane.""\nIn spite of being well developed for more than 50 years, classical tomography is rarely used. This is because it has a significant limitation: the interfering objects are not removed from the image, only blurred. The resulting image quality is usually too poor to be of practical use. The long sought solution was a system that could create an image representing a 2D slice through a 3D object with no interference from other structures in the 3D object.\nThis problem was solved in the early 1970s with the introduction of a technique called computed tomography (CT). CT revolutionized the medical x-ray field with its unprecedented ability to visualize the anatomic structure of the body. Figure 25-13 shows a typical medical CT image. Computed tomography was originally introduced to the marketplace under the names Computed Axial Tomography and CAT scanner. These terms are now frowned upon in the medical field, although you hear them used frequently by the general public.\nFigure 25-14 illustrates a simple geometry for acquiring a CT slice through the center of the head. A narrow pencil beam of x-rays is passed from the x-ray source to the x-ray detector. This means that the measured value at the detector is related to the total amount of material placed anywhere\nalong the beam\'s path. Materials such as bone and teeth block more of the x-rays, resulting in a lower signal compared to soft tissue and fat. As shown in the illustration, the source and detector assemblies are translated to acquire a view (CT jargon) at this particular angle. While this figure shows only a single view being acquired, a complete CT scan requires 300 to 1000 views taken at rotational increments of about 0.3° to 1.0°. This is accomplished by mounting the x-ray source and detector on a rotating gantry that surrounds the patient. A key feature of CT data acquisition is that x-rays pass only through the slice of the body being examined. This is unlike classical tomography where x-rays are passing through structures that you try to suppress in the final image. Computed tomography doesn\'t allow information from irrelevant locations to even enter the acquired data.\nSeveral preprocessing steps are usually needed before the image reconstruction can take place. For instance, the logarithm must be taken of each x-ray measurement. This is because x-rays decrease in intensity exponentially as they pass through material. Taking the logarithm provides a signal that is linearly related to the characteristics of the material being measured. Other preprocessing steps are used to compensate for the use of polychromatic (more than one energy) x-rays, and multielement detectors (as opposed to the single element shown in Fig. 25-14). While these are a key step in the overall technique, they are not related to the reconstruction algorithms and we won\'t discuss them further.\nFigure 25-15 illustrates the relationship between the measured views and the corresponding image. Each sample acquired in a CT system is equal to the sum of the image values along a ray pointing to that sample. For example, view 1 is found by adding all the pixels in each row. Likewise, view 3 is found by adding all the pixels in each column. The other views, such as view 2, sum the pixels along rays that are at an angle.\nThere are four main approaches to calculating the slice image given the set of its views. These are called CT reconstruction algorithms. The first method is totally impractical, but provides a better understanding of the problem. It is based on solving many simultaneous linear equations. One equation can be written for each measurement. That is, a particular sample in a particular profile is the sum of a particular group of pixels in the image. To calculate unknown variables (i.e., the image pixel values), there must be independent equations, and therefore N2 measurements. Most CT scanners acquire about 50% more samples than rigidly required by this analysis. For example, to reconstruct a 512×512 image, a system might take 700 views with 600 samples in each view. By making the problem overdetermined in this manner, the final image has reduced noise and artifacts. The problem with this first method of CT reconstruction is computation time. Solving several hundred thousand simultaneous linear equations is an daunting task.\nThe second method of CT reconstruction uses iterative techniques to calculate the final image in small steps. There are several variations of this method: the Algebraic Reconstruction Technique (ART), Simultaneous Iterative Reconstruction Technique (SIRT), and Iterative Least Squares Technique (ILST). The difference between these methods is how the successive corrections are made: ray-by-ray, pixel-by-pixel, or simultaneously correcting the entire data set, respectively. As an example of these techniques, we will look at ART.\nTo start the ART algorithm, all the pixels in the image array are set to some arbitrary value. An iterative procedure is then used to gradually change the image array to correspond to the profiles. An iteration cycle consists of looping through each of the measured data points. For each measured value, the following question is asked: how can the pixel values in the array be changed to make them consistent with this particular measurement? In other words, the measured sample is compared with the\nsum of the image pixels along the ray pointing to the sample. If the ray sum is lower than the measured sample, all the pixels along the ray are increased in value. Likewise, if the ray sum is higher than the measured sample, all of the pixel values along the ray are decreased. After the first complete iteration cycle, there will still be an error between the ray sums and the measured values. This is because the changes made for any one measurement disrupts all the previous corrections made. The idea is that the errors become smaller with repeated iterations until the image converges to the proper solution.\nIterative techniques are generally slow, but they are useful when better algorithms are not available. In fact, ART was used in the first commercial medical CT scanner released in 1972, the EMI Mark I. We will revisit iterative techniques in the next chapter on neural networks. Development of the third and forth methods have almost entirely replaced iterative techniques in commercial CT products.\nThe last two reconstruction algorithms are based on formal mathematical solutions to the problem. These are elegant examples of DSP. The third method is called filtered backprojection. It is a modification of an older\ntechnique, called backprojection or simple backprojection. Figure 25-16 shows that simple backprojection is a common sense approach, but very unsophisticated. An individual sample is backprojected by setting all the image pixels along the ray pointing to the sample to the same value. In less technical terms, a backprojection is formed by smearing each view back through the image in the direction it was originally acquired. The final backprojected image is then taken as the sum of all the backprojected views.\nWhile backprojection is conceptually simple, it does not correctly solve the problem. As shown in (b), a backprojected image is very blurry. A single point in the true image is reconstructed as a circular region that decreases in intensity away from the center. In more formal terms, the point spread function of backprojection is circularly symmetric, and decreases as the reciprocal of its radius.\nFiltered backprojection is a technique to correct the blurring encountered in simple backprojection. As illustrated in Fig. 25-17, each view is filtered before the backprojection to counteract the blurring PSF. That is, each of the one-dimensional views is convolved with a one-dimensional filter kernel to create a set of filtered views. These filtered views are then backprojected to provide the reconstructed image, a close approximation to the ""correct"" image. In fact, the image produced by filtered backprojection is identical\nto the ""correct"" image when there are an infinite number of views and an infinite number of points per view.\nThe filter kernel used in this technique will be discussed shortly. For now, notice how the profiles have been changed by the filter. The image in this example is a uniform white circle surrounded by a black background (a pillbox). Each of the acquired views has a flat background with a rounded region representing the white circle. Filtering changes the views in two significant ways. First, the top of the pulse is made flat, resulting in the final backprojection creating a uniform signal level within the circle. Second, negative spikes have been introduced at the sides of the pulse. When backprojected, these negative regions counteract the blur.\nThe fourth method is called Fourier reconstruction. In the spatial domain, CT reconstruction involves the relationship between a two-dimensional image and its set of one-dimensional views. By taking the two-dimensional Fourier transform of the image and the one-dimensional Fourier transform of each of its views, the problem can be examined in the frequency domain. As it turns out, the relationship between an image and its views is far simpler in the frequency domain than in the spatial domain. The frequency domain analysis of this problem is a milestone in CT technology called the Fourier slice theorem.\nFigure 25-18 shows how the problem looks in both the spatial and the frequency domains. In the spatial domain, each view is found by integrating the image along rays at a particular angle. In the frequency domain, the image spectrum is represented in this illustration by a two-dimensional grid. The spectrum of each view (a one-dimensional signal) is represented by a dark line superimposed on the grid. As shown by the positioning of the lines on the grid, the Fourier slice theorem states that the spectrum of a view is identical to the values along a line (slice) through the image spectrum. For instance, the spectrum of view 1 is the same as the center column of the image spectrum, and the spectrum of view 3 is the same as the center row of the image spectrum. Notice that the spectrum of each view is positioned on the grid at the same angle that the view was originally acquired. All these frequency spectra include the negative frequencies and are displayed with zero frequency at the center.\nFourier reconstruction of a CT image requires three steps. First, the one-dimensional FFT is taken of each view. Second, these view spectra are used to calculate the two-dimensional frequency spectrum of the image, as outlined by the Fourier slice theorem. Since the view spectra are arranged radially, and the correct image spectrum is arranged rectangularly, an interpolation routine is needed to make the conversion. Third, the inverse FFT is taken of the image spectrum to obtain the reconstructed image.\nThis ""radial to rectangular"" conversion is also the key for understanding filtered backprojection. The radial arrangement is the spectrum of the backprojected image, while the rectangular grid is the spectrum of the correct image. If we compare one small region of the radial spectrum with the corresponding region of the rectangular grid, we find that the sample values are identical. However, they have a different sample density. The correct spectrum has uniformly spaced points throughout, as shown by the even spacing of the rectangular grid. In comparison, the backprojected spectrum has a higher sample density near the center because of its radial arrangement. In other words, the spokes of a wheel are closer together near the hub. This issue does not affect Fourier reconstruction because the interpolation is from the values of the nearest neighbors, not their density.\nThe filter in filtered backprojection cancels this unequal sample density. In particular, the frequency response of the filter must be the inverse of the sample density. Since the backprojected spectrum has a density of 1/f, the appropriate filter has a frequency response of . This frequency response is shown in Fig. 25-19a. The filter kernel is then found by taking the inverse Fourier transform, as shown in (b). Mathematically, the filter kernel is given by:\nBefore leaving the topic of computed tomography, it should be mentioned that there are several similar imaging techniques in the medical field. All use extensive amounts of DSP. Positron emission tomography (PET) involves injecting the patient with a mildly radioactive compound that emits positrons. Immediately after emission, the positron annihilates with an electron, creating two gamma rays that exit the body in exactly opposite directions. Radiation detectors placed around the patient look for these back-to-back gamma rays, identifying the location of the line that the gamma rays traveled along. Since the point where the gamma rays were created must be somewhere along this line, a reconstruction algorithm similar to computed tomography can be used. This results in an image that looks similar to CT, except that brightness is related to the amount of the radioactive material present at each location. A unique advantage of PET is that the radioactive compounds can be attached to various substances used by the body in some manner, such as glucose. The reconstructed image is then related to the concentration of this biological substance. This allows the imaging of the body\'s physiology rather than simple anatomy. For example, images can be produced showing which portions of the human brain are involved in various mental tasks.\nA more direct competitor to computed tomography is magnetic resonance imaging (MRI), which is now found in most major hospitals. This technique was originally developed under the name nuclear magnetic resonance (NMR). The name change was for public relations when local governments protested the use of anything nuclear in their communities. It was often an impossible task to educate the public that the term nuclear simply referred to the fact that all atoms contain a nucleus. An MRI scan is conducted by placing the patient in the center of a powerful magnet. Radio waves in conjunction with the magnetic field cause selected nuclei in the body to resonate, resulting in the emission of secondary radio waves. These secondary radio waves are digitized and form the data set used in the MRI reconstruction algorithms. The result is a set of images that appear very similar to computed tomography. The advantages of MRI are numerous: good soft tissue discrimination, flexible slice selection, and not using potentially dangerous x-ray radiation. On the negative side, MRI is a more expensive technique than CT, and poor for imaging bones and other hard tissues. CT and MRI will be the mainstays of medical imaging for many years to come.']"	['<urn:uuid:ae38052a-8b1c-4a37-87de-0e42ede3c700>', '<urn:uuid:55e7a106-59d6-494d-9cd0-6d6531ea82b3>']	factoid	with-premise	short-search-query	distant-from-document	multi-aspect	expert	2025-05-12T23:47:20.322175	6	61	3202
9	help small business minimize downtime costs steps avoid financial losses disaster recovery plan	To minimize downtime costs and avoid financial losses, small businesses should take several key steps. First, establish a clear disaster recovery plan that identifies critical system components and documents recovery processes. Second, eliminate single points of failure by increasing redundancy and ensuring data is replicated to multiple failover nodes. Third, maintain open communication channels during outages and be transparent with customers about problems. For SMBs specifically, it's crucial to determine the financial impact of potential outages by calculating how much money would be lost when revenue streams are interrupted. The total cost of implementing a recovery strategy should never exceed the potential losses it aims to prevent. Testing the recovery plan frequently is also essential to identify gaps and achieve plan maturity.	"[""In this blog postWhat Does Business Downtime Mean?What Does Business Downtime Mean?Common Causes of DowntimeCommon Causes of DowntimeSoftware Bugs and GlitchesSoftware Bugs and GlitchesHardware FailureHardware FailureNetworking ErrorsNetworking ErrorsMisconfigurationMisconfigurationPower Outages and External FactorsPower Outages and External FactorsMigration ErrorsMigration ErrorsHuman ErrorHuman ErrorCalculating Downtime CostCalculating Downtime CostWhat’s the Average Cost of Downtime?What’s the Average Cost of Downtime?Minimize Downtime CostsMinimize Downtime CostsPut a Disaster Recovery Plan in PlacePut a Disaster Recovery Plan in PlaceOpen Communication ChannelsOpen Communication ChannelsAddress Single Points of FailureAddress Single Points of FailureBe Honest with Your CustomersBe Honest with Your CustomersFinal ThoughtsFinal ThoughtsSign up to Lightstep todaySign up to Lightstep today\nDowntime can have a crippling impact on your business, even if you manage to restore services quickly. Many organizations underestimate the true cost of downtime because it can be difficult to comprehend the wide-ranging effects. Outages can cause lost revenue, reputational damage, employee productivity, and regulatory penalties, creating spiraling costs for every minute you’re offline.\nIn this article, you’ll learn to calculate the true cost of downtime to help understand the long-term impacts of an outage. You’ll also look at some techniques for mitigating the effects of downtime and accelerating service recovery. These can help you cut costs and restore user confidence.\nWhat Does Business Downtime Mean?\nDowntime occurs whenever a business is unable to operate its core functions. In the context of technology companies, downtime is usually the result of a software bug, configuration error, or hardware failure that prevents customers or employees, from accessing your services.\nDowntime affects businesses differently depending on their industry and operating model:\nAn e-commerce company loses sales if customers can’t complete an online checkout. Manufacturing firms stop producing if their inventory management system is unavailable. Logistics firms are unable to complete deliveries if packages can’t be scanned in and out of warehouses. Any one of these scenarios can accrue huge costs for the organization after the briefest of outages. The loss of critical systems often leads to a backlog of pending work that could take days or weeks to resolve.\nCommon Causes of Downtime\nDowntime can stem from many types of issues. The following are some of the most common situations that organizations are likely to face.\nSoftware Bugs and Glitches\nBugs leading to software crashes are a top cause of downtime. Cloudflare encountered this in July 2019 when a deployment introduced a long-running regular expression that caused massive CPU exhaustiona long-running regular expression that caused massive CPU exhaustion. Users couldn’t access websites deployed behind a Cloudflare proxy as there was no spare capacity.\n“Research has shown that as much as 80% of system unavailability is caused by incorrectly applied change. This includes changes made at unauthorized times or without approved change tickets, and can also include approved changes that are not properly executed” (Network WorldNetwork World).\nPhysical hardware failure can still cause system downtime risks, usually for businesses self-hosting their applications. This is less of an issue for companies using public cloud providers with highly available compute architectures.\nNetwork disruption between services can render individual components inaccessible or take the system offline entirely. Even services hosted in major public clouds aren’t immune: the outage experienced by AWS in December 2021 is an example of an incident where internal networking issuesinternal networking issues had a knock-on impact on customer workloads.\nMisconfiguration can occur in several forms, from simple incorrect config values that create unexpected behavior, to sub-optimal auto-scaling that ends up making congestion worse.\nPower Outages and External Factors\nExternal disasters such as power outages, floods, and fires are constant threats. Although data centers should be adequately protected from this kind of weakness, there’s always a lingering vulnerability. For example, some customers faced unrecoverable data lossunrecoverable data loss when OVHcloud’s Strasbourg data center burned down in 2021.\nMigrations and upgrades are common causes of problems. Unforeseen incompatibilities and deployment errors can cause failures in production, even if the system functioned correctly in staging environments. This was the case during TSB’s disastrous transition to a new platform in 2018TSB’s disastrous transition to a new platform in 2018, which saw customers locked out of their bank accounts for up to two weeks.\nHuman error remains a frequent cause of downtime, usually seen in conjunction with one of the other factors on this list. Simple mistakes can cause networking outages, power failures, and software misconfigurations. Facebook’s October 2021 outage began when an engineer unintentionally disabled networkingunintentionally disabled networking between the company’s data centers and the internet.\nCalculating Downtime Cost\nDowntime always has a cost, irrespective of the outage’s root cause. The duration of the downtime and the cost incurred per minute you’re offline are the two variables that most affect the financial impact of an outage.\nThe following formula is the simplest for calculating the cost of a period of downtime:\nCost of Outage = (Minutes of Downtime x Cost per Minute)\nThe cost per minute will be unique to your organization. The most basic way of computing this value is using the revenue that your online services would generate in a typical minute. For example, if you normally make $10,000 in sales per day, you’re making about $6.90 per minute ($1,000 / (24 hours x 60 minutes)). Consequently, an outage of only 30 minutes has an associated cost of over $200:\nCost of Outage ($207) = (30 x 6.90)\nIn reality, this formula is too basic for all but the smallest organizations. You also need to account for recovery costs, any reputational damage, and the supplies that are still being consumed during the downtime period. After all, you’ve still got to pay your staffing costs, business rates, and utility bills, even if your organization’s unable to be productive.\nA more accurate formula could look like this:\nCost of Outage = (Minutes of Downtime x (Average Sales per Minute + Average Costs per Minute + Contingency for Lost Business Due to Reputational Damage)) + Recovery Cost\nCalculating the lost business contingency value can be the hardest part of the formula. You can usually produce a good ballpark figure by looking at the number of clients you acquire in a typical time period, averaging the extra value they bring to your business, and estimating how many would-be leads have been lost due to the outage.\nThere are methods that can make this formula even more accurate, if you’re prepared to deal with extra complexity. As an example, you could multiply the duration of downtime by a logarithmic coefficientlogarithmic coefficient to recognize that longer outages are usually more likely to impact customer acquisitions.\nWhat’s the Average Cost of Downtime?\nThe cost of downtime varies wildly between industries and individual organizations. It depends on the number of people who’ll be impacted, how instrumental the affected service is to your portfolio, and how quickly you recover.\nGartner estimates that major network outages normally incur costs to the tune of $5,600/minute for organizations operating at an enterprise scalemajor network outages normally incur costs to the tune of $5,600/minute for organizations operating at an enterprise scale. Delta Air Lines calculated the cost of its five-hour IT meltdowncalculated the cost of its five-hour IT meltdown in 2016 at $150 million, illustrating how expensive a relatively short event can prove.\nAt the other end of the spectrum, a report by IDC for Carbonite found outages cost smaller businesses between $137 and $427 a minuteoutages cost smaller businesses between $137 and $427 a minute.\nThe effect on these firms can be particularly acute. The lost revenue and potential regulatory fines create cash flow pressures that can cast doubt on long-term viability. Bringing in money is often the primary objective of these firms, and running out of operating fundsrunning out of operating funds is one of the most common reasons for failure.\nMinimize Downtime Costs\nWith unplanned downtime incurring such devastating costs, what can you do to cut your expenses should disaster strike? Although downtime can’t be avoided entirely, acknowledging its existence and planning can help lessen its effects.\nPut a Disaster Recovery Plan in Place\nEstablishing a clear disaster recovery planclear disaster recovery plan should be your first step. This plan needs to identify critical components of your system, establish recovery time objectives, and document the processes to follow in the event of an outage.\nYou should store this document centrally inside your organization’s knowledge hub or operations manual so everyone can access it when the pager pings. It needs to be easily accessible so anyone can quickly retrieve it regardless of the situation that’s being faced.\nOpen Communication Channels\nIt’s also important to facilitate clear communication between members of your restoration team. Primary and backup communication channels should be available, so you’re not dependent on a single platform. Inaccurate tracking and relaying of key discoveries will hinder your recovery effort and lead to delays that raise your costs.\nAddress Single Points of Failure\nAnother way to mitigate damage is to redesign your system to eliminate single points of failureeliminate single points of failure. You can increase redundancy by distributing components across different cloud providers and ensuring data is replicated to multiple failover nodes.\nIf all your application servers connect to a single database instance, you face catastrophic server downtime if that machine fails. Deploying database replicas behind a load balancer would prevent downtime by automatically routing traffic to one of the healthy instances. Writing post mortems after incidents and outages help your organization identify action items to prevent issues from reoccurring, reducing future outages.\nBe Honest with Your Customers\nDisaster recovery tends to prompt an all-out recovery effort inside the affected organization. This can overshadow the need to communicate regularly with customers. In many recent outages, such as Atlassian’s incident in April 2022, users were kept in the dark about the true severity of the problems.\nAdmitting an outage can be painful, but failing to inform users promptly creates a greater risk of the company's reputation damage. Providing regular status updates with precise information about the recovery effort can help maintain confidence in your solution, curbing the long-term cost of downtime.\nDowntime will always be costly. Service outages jeopardize your platform’s perceived reliability and your company’s sales opportunities, and they are devastating to users. The ability to accurately forecast the true cost of downtime is important to establish meaningful service-level agreements (SLAs) and identify optimal outage mitigation strategies.\nIn this article, you’ve seen how to calculate the cost of downtime using a simple formula. You’ve also learned some ways to reduce downtime costs, such as eliminating single points of failure and implementing a disaster recovery plan.\nTo rapidly respond to downtime, you need timely alerts for when a new outage begins. LightstepLightstep is a cloud-native reliability platform that provides a monitoring, observability, and incident response solution for systems at any scale."", ""What you will learn in this tip: This technical tip outlines the essentials of disaster recovery and business continuity...\nplanning for small- to medium-sized businesses (SMBs). Learn about SMB disaster recovery best practices and what to include in the disaster recovery planning process.\nIt is possible for IT managers at SMBs to feel that they can easily recover from an outage because they have smaller IT environments and employ smart IT people. Conversely, there are instances where managers don’t know how to build a disaster recovery strategy. In either case, this often leads to no disaster recovery planning at all. If an SMB intends to build a DR plan, they need to follow the essentials for disaster recovery planning.\nThe most important—and difficult—step in disaster recovery planning is to understand how an unplanned outage would affect an organization. This step is a referred to a business impact analysis (BIA). Without the ability to determine impact of an unplanned outage in a meaningful way, it becomes very difficult to determine the type of disaster recovery strategy is needed.\nAn “unplanned outage” refers to any unforeseen event that interrupts normal business activity for a period of amount of time, such as an IT systems failure, fire, power outage or a natural disaster. Depending on the nature of the interruption, this can cause an organization to lose revenue, have problems with customer satisfaction, lose opportunities or possibly go out of business.\nThat impact is determined by identifying the most critical business activities or functions, and then predicting what would happen if those processes stopped. This is where many inexperienced planners make a mistake: They are tempted skip a few steps and go to solution mode.\nDR planners should not assume there is a workaround or contingency available in case a highly critical function goes offline.\nThe intention is to set a recovery time objective (or RTO, which refers to how long can a process be down) and a recovery point objective (meaning how much data can be lost) for critical functions and IT infrastructure.\nBusinesses must determine:\n- A financial value for a critical function, based on how much money is lost when the revenue stream is interrupted. An organization’s accountant can usually help with this process\n- How critical each function is for the organization, based on how a function affects the revenue stream using a rating system (for example, one to five) where one is the most critical and five the least critical\n- How long a business function can be interrupted before it starts affecting revenue stream\n- How much client or business transaction information can be lost or recreated without seriously affecting the business\n- The IT infrastructure and systems upon which the business functions depend\nThe next step is the risk assessment which complements the impact analysis. The impact of an outage and the anticipated risk that may exist will indicate the need to develop a recovery strategy.\nAssessing risk is another area where planners can get bogged down. Do not attempt to calculate risk on the chance it could happen, or try to calculate annualized loss expectancy (which are both complex tasks). Keep it simple and be realistic about the kinds of risks your organization could face, including specific threats tied to an organization’s geographic location. A risk exists for an organization if there’s nothing in place to maintain or quickly recover a critical function.\nOn the other hand, if a system identified as critical is found to have adequate redundancies and protection, you can move on to the next systems and applications.\nDeveloping a recovery strategy\nOnce critical functions and the supporting IT infrastructure have been identified, and the impact of an outage is quantified using a dollar value or rating, a recovery strategy can be developed to help prevent or mitigate losses.\nThis is also when we need to start considering any existing contingencies or redundancies already in place. For example, if a critical application is hosted by a service provider and under a service-level agreement, it is probably safe to say that little to no recovery strategy is required for that application. However, a recovery strategy is required for applications which support critical functions that lack provisions to keep those applications operational.\nA specific recovery strategy is determined by an organization’s anticipated financial losses if critical functions are unavailable, as well as the time needed to recover necessary applications.\nAn application with a recovery time objective of within five days may do just fine with a tape backup process, but an application that needs to be up within an eight-hour business day might require remote data replication and/or standby IT systems at a recovery site. Outsourcing disaster recovery is also a viable strategy: Companies that cannot afford the cost of developing their own recovery strategy may consider paying for DR availability services or a DR-as-a-Service subscription.\nThe key is to always remember that the total cost of a recovery strategy should never exceed the losses it is designed to prevent.\nDocumenting the recovery plan\nThe next step is to document the recovery strategy and procedure, which forms the foundation for a disaster recovery plan. Keep it simple: Smaller businesses should not attempt to develop an enterprise-class DR plan. Very detailed disaster recovery plans take time to develop and are hard to maintain. At a high level, the disaster recovery plan should outline the priorities for system recovery, the recovery time objective, recovery procedures, as well as the location of data backups and the contacts for key recovery personnel.\nTesting the plan frequently will help identify what elements are missing and need to be added, instead of discovering problems with the plan during a disaster event. Every time a recovery procedure is tested, gaps and improvements are identified and this is how plan maturity is eventually achieved.\nAbout this author:\nPierre Dorion is the data center practice director and a senior consultant with Long View Systems Inc. in Phoenix, Ariz., specializing in the areas of business continuity and DR planning services and corporate data protection.\nDownload a free small business disaster recovery template and guide\nTake our quiz on disaster recovery basics\nRead about the results of Symantec's SMB disaster recovery survey""]"	['<urn:uuid:feb7f029-b23f-48d1-aa73-c16723f06129>', '<urn:uuid:4dbaf5ae-a7f3-40ca-a404-c8700e4f4784>']	open-ended	with-premise	long-search-query	similar-to-document	three-doc	novice	2025-05-12T23:47:20.322175	13	122	2824
10	What is an AutoCAD Attribute object and its main purpose?	An AutoCAD Attribute object is meta-data that describes the characteristics of AutoCAD objects, particularly Block objects. It contains text that characterizes some AutoCAD block object through the AttributeReference class. These attributes are essential for daily working activities such as tagging entities, creating drawing labels and annotations, notations for particular objects, and viewport setting adjustments.	"['In my previous article I discussed AutoCAD Block objects and other related objects related to the AutoCAD Block class. In that article I also briefly introduced Block atrributes. Now, in this article, I mainly focus on the AutoCAD Attribute class.\nI am using the pyautocad module for this article, but I can also use communication modules such as pythoncom, and win32com.\nWhat is an AutoCAD Attribute object?\nThe AutoCAD Attribute object is basically a meta-data that describes the characteristics of an AutoCAD object. For example, it can describe the characteristics of AutoCAD Block objects.AttributeReference is the object class containing text that characterizes some AutoCAD block object.\nAs I have already explained in one of my previous articles covering AutoCAD Block objects the AutoCAD Block is an element of the BlockCollection class. To use AutoCAD Block object I have to create an instance of a specific block in my drawing. The resulting object is a BlockReference instance.\nSimilarly, an AutoCAD AttributeRefrence object is an instance of the Attribute class.\nIn daily working activities such as e.g. tagging entities, creating drawing labels and annotations, notations for a particular object, viewport setting adjustments, etc. I will need attributed AutoCAD Block objects.\nTherefore, understanding the various AutoCAD Attribute related commands is of great importance.\nAutoCAD Attribute object properties\nIn this section I will discuss some of the important properties of Attribute objects. Besides that, I would like to point out that all the properties that are apply to Attribute objects apply to AttributeReference objects too.\nI have used the same example for this practice as I have already used in my previous AutoCAD Block article. I recommend that you check out that blog post for comprehensive understanding of the AutoCAD Block class.\nfrom pickle import TRUE from pyautocad import Autocad, APoint, aDouble acad = Autocad(create_if_not_exists=True) ip = APoint(0, 0, 0) b1 = acad.doc.Blocks.Add(ip, ""Attributed_Block_1"") pl = b1.AddPolyline(aDouble(0, 0, 0, 10000, 0, 0, 10000, 5000, 0, 0, 5000, 0, 0, 0, 0)) l = b1.AddLine(APoint(0, 250, 0), APoint(10000, 250, 0)) l = b1.AddLine(APoint(5000, 250, 0), APoint(5000, 0, 0)) #0, 1, 2, 3, 4, 5, 6 .... 10 a1 = b1.AddAttribute(50, 0, ""DATE"", aDouble(200, 100, 0), ""DATE"", ""Date: 17/07/2022"") a2 = b1.AddAttribute(50, 0, ""DWG"", aDouble(5200, 100, 0), ""DWG"", ""Drawing Name: Drawing 1"") a2.MTextAttribute=True br = acad.model.InsertBlock(APoint(50, 50, 0), ""Attributed_Block_1"", 1, 1, 1, 0) print(""Does the Block contain any Attributes: "", end="""") print(br.HasAttributes)\nNow, I can see that a reference to the AutoCAD Attributed Block has been created in my document.\nBelow I demonstrate the properties of the Attribute object and the AttributeRefrence object that I created.\n#General Properties print(""Attribute alignment: "", end="""") print(a1.Alignment) print(""Layer of attribute: "" + a1.Layer) print(""Is the direction of text backward? "" + str(a1.Backward)) print(""Is the attribute reference constant ? "" + str(a1.Constant)) print(""Entity transparency value: "", end="""") print(a1.EntityTransparency) print(""Field length of the attribute: "", end="""") print(a1.FieldLength) print(""Text height: "", end="""") print(a1.Height) print(""Attribute insertion point: "", end="""") print(a1.InsertionPoint) print(""Is attribute reference invisible: "" + str(a1.Invisible)) print(""Can the attribute or attribute reference be moved relative to geometry in the block ? "" + str(a1.LockPosition)) print(""Object name: "" + a1.ObjectName) print(""Oblique angle of the object: "", end="""") print(a1.ObliqueAngle) print(""Is the attribute preset? "" + str(a1.Preset)) # apreset attribute sets the attribute to its default, or preset, value when the user inserts the block. print(""Rotation of object: "", end="""") print(a1.Rotation) print(""Scale factor for the object: "", end="""") print(a1.ScaleFactor) print(""Style name of the attribute object: "" + a1.StyleName) print(""Is the attribute set for verification: "" + str(a1.Verify)) O/p: Attribute alignment: 0 Layer of attribute: 0 Is the direction of text backward? False Is the attribute reference constant ? False Entity transparency value: ByLayer Field length of the attribute: 0 Text height: 50.0 Attribute insertion point: (200.0, 100.0, 0.0) Is attribute reference invisible: False Can the attribute or attribute reference be moved relative to geometry in the block ? False Object name: AcDbAttributeDefinition Oblique angle of the object: 0.0 Is the attribute preset? False Rotation of object: 0.0 Scale factor for the object: 1.0 Style name of the attribute object: Standard Is the attribute set for verification: False\nSimilarly, there are some other properties that define the attribute name, attribute content, and type of text. And so on. See the code and program output below.\n# multiline text / text properties if(a2.MTextAttribute==True): print(""Attribute content: "" + a2.MTextAttributeContent) print(""Boundary width of multiline text: "", end="""") print(a2.MTextBoundaryWidth) print(""Multiline text direction: "", end="""") print(a2.MTextDrawingDirection) print(""Prompt string of an attribute: "" + a1.PromptString) print(""Tag string of the attribute: "" + a1.TagString) print(""Text string of the attribute: "" + a1.TextString) print(""Alignment point of the text: "", end="""") print(a1.TextAlignmentPoint) print(""Attribute text generation flag: "", end="""") print(a1.TextGenerationFlag) O/p: Attribute content: Drawing Name: Drawing 1 Boundary width of multiline text: 0.0 Multiline text direction: 5 Prompt string of an attribute: DATE Tag string of the attribute: DATE Text string of the attribute: Date: 17/07/2022 Alignment point of the text: (0.0, 0.0, 0.0) Attribute text generation flag: 0\nAs I show in above code there is a property for multiline text that returns the value of text direction. It has five possible return values in the form of integers. Those options are as follows:\n- acBottomToTop: 1\n- acByStyle: 2\n- acLeftToRight: 3\n- acRightToLeft: 4\n- acTopToBottom: 5\nMethods of the AutoCAD Attribute class\nSome methods of the Attribute and AttributeReference class are similar to other methods of other AutoCAD object classes. I list some of the important methods below:\nI demonstrated the use of the AutoCAD Attribute, AttributeReference, and AttriburtedBlock classes. Obviously, the most important thing is implementing this information in our day-to-day life to automatize repetitive and costly tasks in an effort to increase productivity. Considering the same, feel free to use our contact form to book a session with me for any kind of technical guidance. Besides that, leave any feedback, doubts or questions in the comment section below.\nReferences to related content\nI have already established a rather comprehensive documentation on pyautocad, AutoCAD, pythoncom, and pywin32. Please see a list of some related content below:\n- Link: Python for AutoCAD pyautocad module\n- Link: add() method in pyautocad\n- Link: Solved call was rejected by callee in pythoncom\n- Link: Tree data structure for AutoCAD objects using Python\n- Link: Extending the objects in AutoCAD using pyautocad in Python\n- Link: Using Python lists and dictionaries to work with AutoCAD objects with pyautocad\n- Link: Hatching objects on AutoCAD template using pywin32 in Python\n- Link: Raster image object in AutoCAD with pyautocad in Python\n- Link: Working with 3D mesh object in AutoCAD using pyautocad in Python\n- Link: Creating adouble constructor using pywin32 in Python\n- Link: Creating apoint method using pywin32 in Python\n- Link: Python integration with AutoCAD using pywin32 and win32com\n- Link: Deleting objects in a AutoCAD template with pyautocad and pywin32 in Python\n- Link: Mirror object on a 2D plane with pyautocad in Python\n- Link: Working with texts in Autocad using pyautocad in Python\n- Link: Polar arrays in AutoCAD using pyautocad in Python\n- Link: Rectangular arrays in AutoCAD using pyautocad in Python\n- Link: Operations with AutoCAD objects using pyautocad in Python\n- Link: Solid objects in AutoCAD using pyautocad in Python\n- Link: Working with helices in AutoCAD using pyautocad in Python\n- Link: Drawing splines in AutoCAD with pyautocad in Python\n- Link: Polylines in pyautocad for drawing AutoCAD polygons in Python\n- Link: Drawing ellipse arcs in AutoCAD using pyautocad in Python\n- Link: Drawing arcs in AutoCAD using pyautocad in Python\n- Link: Near simultaneous factory design and process optimization with Promodel AutoCAD edition\n- Link: Python for AutoCAD pyautocad module\n- Link: Region object in AutoCAD with Python\n- Link: AutoCAD Application object class in Python\nCivil engineer interested in automation in core subjects such as civil, mechanical and electrical, using IT skills comprising cloud computing, devops, programming languages and databases along with the technical skills gained while working as a civil engineer since past 3 years.']"	['<urn:uuid:4a51f912-2488-4bd2-8734-b547c8483265>']	open-ended	direct	concise-and-natural	similar-to-document	single-doc	expert	2025-05-12T23:47:20.322175	10	54	1332
11	what pattern is avoided in plutarch lives	In Plutarch's Lives, the hemiepies pattern (-uu-uu-) occurs naturally 2.5% of the time but is avoided at the end, occurring only 0.8% finally.	"[""The first systematic study of these I can find reference to is by A.W. de Groot, who has an entire book of tables, Handbook of Greek Prose Rhythm (our library has a German edition, but I will have to delve into the oft-pillaged Cutter stacks to find it). By comparing frequencies of metrical patterns within a sentence to their frequency at the end you can see which patterns were preferred for the end of a line. It also turns out certain patterns were scrupulously avoided. For example, a hemiepies (-uu-uu-, a fundamental unit of Epic meter) occurs naturally in Plutarch's Lives 2.5% of the time, but only 0.8% finally. Other obviously Epic metrical patterns are avoided some authors, though Plutarch makes no special efforts to control the oft-avoided adonic end, -uu--.\nCertain clausulae are common, regardless of author or genre: -u-- is very popular, and in the Moralia Plutarch uses it a whopping 29.1% of the time:\nὥστε καθίσας περὶ τὸν νεὼν τὰ μὲν αὐτὸς ἠρξάμην ζητεῖν, τὰ δ’ ἐκείνους ἐρωτᾶν [-u--], ὑπὸ τοῦ τόπου καὶ τῶν λόγων αὐτῶν ἀνεμνήσθην ἃ πάλαι ποτὲ καθ’ ὃν καιρὸν ἐπεδήμει Νέρων ἠκούσαμεν Ἀμμωνίου καί τινων ἄλλων διεξιόντων [-u--], ἐνταῦθα τῆς αὐτῆς ἀπορίας ὁμοίως ἐμπεσούσης [-u--].\nThe E at Delphi, 385B\n-u-- is also used by Xenophon, Lysias, Isocrates, Demosthenes (this is the only clausula he obviously favors), Plato, Aristotle and sometimes Lucian (sometimes he avoids it).\nOther common clausulae:\n- -u--- : Isocrates, Isaeus, Plato (in some works; avoided in the Laws), Plutarch\n- -u--u- : (Cicero's double cretic again) Aeschines, Aristotle, Lysias, Lucian; avoided by Isocrates\n- ----u- : Lysias, Isaeus, Aeschines, Plato, Aristotle, Lucian; avoided by Plutarch\n- -uu-u- : Lysias, Isocrates, Xenophon, Aeschines, Plato, Lucian\nThucydides is fairly restrained, obviously preferring only -uu--- and avoiding -u-u- (a shape favored, on the other hand, by Xenophon).\nHere's a selection of Xenophon's Cyropaedia (1.2.1 - 1.2.2) with some clausula noted:\nΠατρὸς μὲν δὴ ὁ Κῦρος λέγεται γενέσθαι Καμβύσου Περσῶν βασιλέως [uuu-]· ὁ δὲ Καμβύσης οὗτος τοῦ Περσειδῶν γένους ἦν [-u--]· οἱ δὲ Περσεῖδαι ἀπὸ Περσέως κλήιζονται· μητρὸς δὲ ὁμολογεῖται Μανδάνης γενέσθαι [-u--]· ἡ δὲ Μανδάνη αὕτη Ἀστυάγους ἦν θυγάτηρ τοῦ Μήδων γενομένου βασιλέως [uuu-]. φῦναι δὲ ὁ Κῦρος λέγεται καὶ ἄιδεται ἔτι καὶ νῦν ὑπὸ τῶν βαρβάρων εἶδος μὲν κάλλιστος, ψυχὴν δὲ φιλανθρωπότατος καὶ φιλομαθέστατος καὶ φιλοτιμότατος, ὥστε πάντα μὲν πόνον ἀνατλῆναι, πάντα δὲ κίνδυνον ὑπομεῖναι τοῦ ἐπαινεῖσθαι ἕνεκα. φύσιν μὲν δὴ τῆς μορφῆς καὶ τῆς ψυχῆς τοιαύτην ἔχων διαμνημονεύεται [-u-u-]· ἐπαιδεύθη γε μὴν ἐν Περσῶν νόμοις· οὗτοι δὲ δοκοῦσιν οἱ νόμοι ἄρχεσθαι τοῦ κοινοῦ ἀγαθοῦ ἐπιμελούμενοι οὐκ ἔνθενπερ ἐν ταῖς πλείσταις πόλεσιν ἄρχονται. αἱ μὲν γὰρ πλεῖσται πόλεις ἀφεῖσαι παιδεύειν ὅπως τις ἐθέλει τοὺς ἑαυτοῦ παῖδας, καὶ αὐτοὺς τοὺς πρεσβυτέρους ὅπως ἐθέλουσι διάγειν, ἔπειτα προστάττουσιν αὐτοῖς μὴ κλέπτειν μηδὲ ἁρπάζειν, μὴ βίαι εἰς οἰκίαν παριέναι [uuu-], μὴ παίειν ὃν μὴ δίκαιον [-u--], μὴ μοιχεύειν, μὴ ἀπειθεῖν ἄρχοντι, καὶ τἆλλα τὰ τοιαῦτα ὡσαύτως· ἢν δέ τις τούτων τι παραβαίνηι, ζημίαν αὐτοῖς ἐπέθεσαν [uuu-].\nUntil now I've been telling people on Textkit asking about Greek pronunciation that vowel quantities probably didn't matter to appreciate prose. I guess I'll have to stop saying that.\nI've grabbed the data for this post from W.H. Shewring's Prose-rhythm and the Comparative Method, CQ v.25 no.1 pp. 12-22. He has a lot more on the Greek authors, as well as all the Latin authors I've skipped here. And F.H. Sandbach's Rhythm and Authenticity in Plutarch's Moralia, CQ v.33 no.3/4 pp.194-203. I still have to track down de Groot.""]"	['<urn:uuid:213035e5-9e50-4bfb-9afa-9858f99c5b6b>']	factoid	direct	short-search-query	similar-to-document	single-doc	expert	2025-05-12T23:47:20.322175	7	23	580
12	link physical exercise breast tumor prevention	Research demonstrates that women who exercise at moderate-to-vigorous levels for more than three hours per week have a 30% to 40% lower risk of breast cancer. This reduction in risk applies to all women, regardless of their family history or risk level of breast cancer. While lifelong activity is important, engaging in physical activity at any age may help lower breast cancer risk.	['Getting help from the family doctor may be a better way for overweight, middle-aged women to increase their physical activity, rather than trying to go it alone, according to a trial led by researchers at the University of Pittsburgh School of Medicine and funded by the National Institutes of Health (NIH). Obesity and physical inactivity are significant risk factors for cardiovascular disease in middle-aged women.\nThe results, available online in the February issue of the Journal of General Internal Medicine, show that obese, middle-aged women who participated in an exercise program based at their primary care doctor’s office were more likely to continue to exercise over several months compared with those who were self-guided.\n“Women who participated in programs in their doctor’s office had a structured environment allowing them to focus on their lifestyle habits like eating and exercising, and make changes,” said Molly Conroy, M.D., M.P.H., associate professor of medicine, epidemiology, and clinical and translational science at Pitt.\nThe Healthy Bodies Healthy Hearts investigators enrolled 99 inactive, overweight women ages 45 through 65 at three UPMC primary care offices at UPMC Montefiore, UPMC Shadyside and Magee-Womens Hospital of UPMC. The women were randomly separated into two groups: one in which they participated in 12 weekly sessions at their primary care physician’s office consisting of 30 minutes of discussion and 30 minutes of moderate-intensity exercise; and a self-guided group that received a manual for independent use.\nAfter three months, assessments showed that the women in the interventionist-led group had significantly higher levels of physical activity, such as walking at a moderate pace, with improvements equal to about 90 minutes per week, compared to the self-guided women who improved by only about 30 minutes per week.\nAfter a year, both groups reduced their level of activity. The self-guided participants returned to pre-intervention activity levels; however, the interventionist-led women were still more active than they had been before participation by about 60 minutes of exercise per week.\n“These outcomes imply that primary care-based interventions can be very beneficial to keep sedentary women motivated for several months. Many indicated their confidence was higher and that they felt more comfortable exercising with support. Follow-up sessions could help women over the long-term,” said Dr. Conroy. “Future efforts should focus on finding the best way to sustain that activity, using resources available in the primary care setting.”\nCo-authors of the study include Kathleen L. Sward, Ph.D., M.P.H., of Heartchange; Kathleen Spadaro, Ph.D., of Chatham University; and Dana Tudorascu, Ph.D., Irna Karpov, M.S., Bobby L. Jones, Ph.D., Andrea M. Kriska, Ph.D., and Wishwa N. Kapoor, M.D., M.P.H., all of Pitt.\nThe study was sponsored by NIH National Heart, Lung and Blood Institute grant K23 HL 085405.\nLowering cancer risk with exercise\nIt is important to remember that there is no proven way to completely prevent cancer, but there may be steps you can take to lower your risk. Research shows that physical activity may lower the risk of the following cancers:\nColon cancer. According to the National Cancer Institute, people who exercise regularly have a 40% to 50% lower risk of colon cancer, compared with those who don’t exercise regularly. There is some evidence that suggests people who maintain active lifestyles throughout their lives have the lowest risk of colon cancer.\nBreast cancer. Research shows that women who exercise at moderate-to-vigorous levels for more than three hours per week have a 30% to 40% lower risk of breast cancer. This result held true for all women, regardless of their family history or risk level of breast cancer.\nMost studies show that the higher the level of activity, the lower the risk, although it is not clear whether there is a specific level of activity that must be met. Although activity throughout a person’s life is important, activity at any age may help lower breast cancer risk.\nUterine cancer. Some research has found a 38% to 46% reduced risk of this type of cancer in active women. Exercise can help lower obesity and decrease estrogen levels, both of which are factors that may be related to uterine cancer development.\nLung cancer. Studies show that people who are regularly active are less likely to develop lung cancer. However, it isn’t clear why this link exists, although one reason may be that people who exercise are less likely to use tobacco.\nHow physical activity can lower cancer risk\nBeing physically active can help you avoid the following factors that contribute to the development of cancer.\nObesity. Being obese (substantially or extremely overweight) is defined as having a body mass index (BMI; the ratio of a person’s weight and height) of 30 or higher. Obesity increases a person’s risk of developing and dying from certain types of cancer, including postmenopausal breast cancer, colorectal cancer, uterine cancer, kidney cancer, pancreatic cancer, gallbladder cancer, thyroid cancer, and esophageal cancer. Other cancers that may be linked to obesity include prostate cancer, liver cancer, ovarian cancer, cervical cancer, multiple myeloma, and non-Hodgkin lymphoma.\nSeveral studies have shown that regular aerobic exercise combined with a low-calorie diet can help people lose weight and keep it off. Even when a person doesn’t eat less, aerobic exercise results in small amounts of weight loss and lowers intra-abdominal fat (the dangerous fat that forms deep in the center part of the body and is linked with a higher risk of several diseases). Talk with your doctor about an exercise and eating plan that is appropriate for your medical history and goals.\nAbout the University of Pittsburgh Schools of the Health Sciences\nThe University of Pittsburgh Schools of the Health Sciences include the schools of Medicine, Nursing, Dental Medicine, Pharmacy, Health and Rehabilitation Sciences and the Graduate School of Public Health. The schools serve as the academic partner to the UPMC (University of Pittsburgh Medical Center). Together, their combined mission is to train tomorrow’s health care specialists and biomedical scientists, engage in groundbreaking research that will advance understanding of the causes and treatments of disease and participate in the delivery of outstanding patient care. Since 1998, Pitt and its affiliated university faculty have ranked among the top 10 educational institutions in grant support from the National Institutes of Health.\nUniversity of Pittsburgh Schools of the Health Sciences\nJournal of General Internal Medicine']	['<urn:uuid:433f3edc-328e-460b-b00e-1d9e77e46a01>']	open-ended	direct	short-search-query	distant-from-document	single-doc	expert	2025-05-12T23:47:20.322175	6	63	1042
13	Which body areas can artificial tissue replacements help with?	The artificial tissue replacements can help with eyes through synthetic retinas for treating retinal degeneration, and with limbs through synthetic skin coverings for prosthetics.	"['The World’s First Soft Tissue Synthetic Retina\nResearchers have created the world’s first artificial retina using soft synthetic tissue, which they say could be used to develop a new generation of less-invasive bionic eye implants in the future.\nMade from a combination of water-based hydrogel droplets and light-sensitive proteins, the synthetic retina is designed to mimic the functionality of its biological counterpart while existing in harmony with the tissue that makes up the rest of the inner eye.\n“The human eye is incredibly sensitive, which is why foreign bodies like metal retinal implants can be so damaging, leading to inflammation and/or scarring,” says chemical biologist Vanessa Restrepo-Schild from the University of Oxford in the UK.\n“But a biological synthetic implant is soft and water based, so much more friendly to the eye environment.”\nThe retina is a membrane positioned at the back of the eye, where millions of light-sensitive cells called photoreceptors register photons (or light particles) channelled through the pupil, which sits at the front of the eye.\nWhen photons hit the membrane, the photoreceptors convert the light into electrical signals that travel via the nervous system to the brain, which interprets the signals, ultimately helping us to picture the world around us.\nAt least, that’s what they do if your eyes are healthy. Gene mutations can lead to retinal degeneration, such as conditions like retinitis pigmentosa, where the photoreceptor cells die off, meaning they can’t convert the light into signals our brain can understand.\nThis is where the team’s artificial retina comes in.\nRestrepo-Schild’s team developed their synthetic substitute by creating a 4 x 4 array of aqueous droplets containing bacteriorhodopsin – a light-sensitive protein found in single-celled microorganisms called archaea.\nActing like a grid of 16 pixels, these hydrogel cells mimic a very basic, very low-resolution retina. Lab tests show the device is capable of registering simple, blocky, grey-scale images based on light patterns shone onto the array. Nothing like a real retina, but it’s a start.\n“The synthetic material can generate electrical signals, which stimulate the neurons at the back of our eye just like the original retina,” says Restrepo-Schild.\nIt’s not the first synthetic retina we’ve seen – researchers have been studying the concept for decades, figuring out ways to design bionic eyes that respond to light in the absence of healthy photoreceptor cells.\nBut despite the success of previous artificial retinas, Restrepo-Schild suggests a soft, water-based array like her prototype would be less likely to have an adverse reaction when implanted in the eye than mechanical devices incorporating rigid, unyielding materials.\n“I have taken the principles behind vital bodily functions, e.g. our sense of hearing, touch, and the ability to detect light, and replicated them in a laboratory environment with natural, synthetic components,” she says.\n“I hope my research is the first step in a journey towards building technology that is soft and biodegradable instead of hard and wasteful.”\nThe researchers acknowledge their prototype – which has not yet been tested in living tissue – is just a proof of concept for now, but are working towards developing it into bionic implant..\nThe team is also investigating how to make the device register colours – not just detect light in black and white – and eventually hope to test the synthetic implant in animal studies. If all goes well, clinical trials involving human subjects could be on the cards.\nIn light of the amount of research that still needs to be done, it will be years before a soft implant like this can treat actual patients faced with retinal degeneration, but with retinitis pigmentosa estimated to affect one in 4,000 people worldwide, any advances in this area are good news.\nThe research is published in Scientific Reports.', 'N22A-T018 TITLE: Enhanced Sensory Perception via Advanced Synthetic Skins\nOUSD (R&E) MODERNIZATION PRIORITY: Artificial Intelligence (AI)/Machine Learning (ML);Autonomy;Microelectronics\nTECHNOLOGY AREA(S): Electronics;Materials / Processes;Sensors\nOBJECTIVE: Develop an innovative, wide-area synthetic skin that utilizes advances in machine perception to enhance the sensory capabilities of the device or system to which the skin is applied and for enhanced investigative capabilities in low-visibility, undersea environments.\nDESCRIPTION: A key characteristic of a high-performing synthetic sensory skin is the ability to remain fully operational when stretched, deformed, or used in undersea operations conducted in harsh environments. There are technical risks associated with the implementation of synthetic skins with human-like sensory capability such as manufacturability, resiliency, sensors, and data processing. This STTR topic seeks to develop innovative, wide-area, synthetic sensory skin technologies that address these risks. Solutions should provide high-functioning synthetic sensory skin that augments operations in low-access, low-visibility environments as well as in missions requiring teleoperations of critical systems.\nPHASE I: Conduct a proof-of-concept study, culminating in a design package and a demonstrable simulation and/or laboratory experiment, that proves the feasibility of achieving the desired synthetic sensory skin requirements. Produce a detailed report summarizing simulation and/or testing results, a presentation of the initial design, and plans for prototyping the synthetic skin in Phase II.\nPHASE II: Finalize design details through Preliminary and Critical Design Reviews, provide a manufacturability analysis, and develop and demonstrate the prototype synthetic skin in a relevant environment.\nPHASE III DUAL USE APPLICATIONS: Support the Navy in transitioning the technology to a program of record for operational use. Potential medical applications include telemedicine, where it could enable a medical clinician to replicate the physical contact they have when they evaluate a patient in person, and as a covering for prosthetic limbs. Another commercial application includes using it to enable robots to work more safely around humans.\nKEYWORDS: artificial intelligence; perception; underwater; robotics; synthetic skin; bio-inspired; materials; microelectronics; sensors\n** TOPIC NOTICE **\nThe Navy Topic above is an ""unofficial"" copy from the overall DoD 22.A STTR BAA. Please see the official DoD Topic website at rt.cto.mil/rtl-small-business-resources/sbir-sttr/ for any updates.\nThe DoD issued its 22.A STTR BAA pre-release on December 1, 2021, which opens to receive proposals on January 12, 2022, and closes February 10, 2022 (12:00pm est).\nDirect Contact with Topic Authors: During the pre-release period (December 1, 2021 thru January 11, 2022) proposing firms have an opportunity to directly contact the Technical Point of Contact (TPOC) to ask technical questions about the specific BAA topic. Once DoD begins accepting proposals on January 12, 2022 no further direct contact between proposers and topic authors is allowed unless the Topic Author is responding to a question submitted during the Pre-release period.\nSITIS Q&A System: After the pre-release period, proposers may submit written questions through SITIS (SBIR/STTR Interactive Topic Information System) at www.dodsbirsttr.mil/topics-app/, login and follow instructions. In SITIS, the questioner and respondent remain anonymous but all questions and answers are posted for general viewing.\nTopics Search Engine: Visit the DoD Topic Search Tool at www.dodsbirsttr.mil/topics-app/ to find topics by keyword across all DoD Components participating in this BAA.']"	['<urn:uuid:8a6594c7-18d7-4fdc-b674-4ec4b3fca0cd>', '<urn:uuid:6e913be4-1eb7-41b7-b311-87efb3c43e38>']	factoid	direct	concise-and-natural	distant-from-document	comparison	novice	2025-05-12T23:47:20.322175	9	24	1137
14	signs found wood powder dust holes insect infestation furniture antiques	Signs of an infestation include 'frass' - a powdery sawdust-like substance typically found along the edges of fresh holes or settled on adjacent surfaces, sharp circular exit holes on the surface, and alive or dead insects on or close to the piece.	['What do antique frames, ethnographic items, and furniture all have in common? They are made of wood and can become good places for shelter and food sources for insects. The most common culprit for wood infestation is the powderpost beetle.\nSigns of an Infestation\nSearch atop and beneath wooden objects for “frass” – a powdery substance left by burrowing pests. Powderpost beetles bore in wood to lay eggs and - when they hatch – the grubs develop to pupae and then when mature the beetles bore out, leaving exit holes, a crisp hole with a delicate layer of frass along the perimeter.\nExit Holes - Sharp circular holes on the surface\nFrass - a powdery sawdust like substance which is typically along the edges of fresh holes or settled on an adjacent surface nearby.\nInsects - alive or dead on or close to the piece.\nBecause many antiques have historic bore marks from previous infestations, the presence of holes and frass doesn’t necessarily indicate an active infestation. When bore holes and frass are evident, it should be noted that the any movement of the piece may have dislodged historic frass causing it to become visible.\nThe piece should be carefully monitored for potential insect activity and the structural stability of the piece be reviewed. Typically, infestations are most evident on the unfinished sections of a piece of furniture, or frame, commonly the back panels, and undersides of a piece. The damage evident on the exterior of a piece isn’t necessarily the most concerning issue, since the infestation can significantly compromise the interior of the wood support, as well weakening of joints, and even sections of the surface can even potentially detach if the support beneath has been severely compromised.\nWhat to do\nIf you find signs of active insects, immediately quarantine the infested piece from other objects by wrapping and sealing it in a plastic bag. If the infestation is localized within an antique frame, and the painting and its stretcher is not affected, the painting should be removed from the frame and the frame bagged. The painting should also be isolated and monitored as a precautionary measure.\nThere are a number of options to address an active infestation. Each has advantages and disadvantages depending on the piece that is exposed, and the needs of the owner.\nFumigation - Consult a specialist about options and approaches that will not affect the finish. Oftentimes this is the most expedient and cost-effective approach.\nAnoxic Treatment - The artifact is placed in a special air tight bag, and the oxygen is depleted from bag. This approach is preferred and the most passive, while not exposing the piece to chemicals.\nThe treatment takes time to allow to deplete oxygen and takes the most time of the listed options. It is also difficult to treat large pieces, since they need to be contained with an airtight seal.\nNitrogen/Argon Gas-Oxygen is replaced with Nitrogen/Argon Gas either in sealed bag, or controlled chamber. The introduction of gas reduces the time required for treatment and does not leave a residue on the surface. It is more costly than the other options.\nFreeze/Thaw - The piece is carefully wrapped, frozen and then thawed. As a proactive measure, the cycle is sometimes repeated. This treatment is expedient and does not require exposure to chemicals.\nSize might become a limitation. There is also the concern that the freezing and thawing could cause expansion and contraction of the piece leading to potential splits, delamination, etc.\nAfter treatment, and the infestation is addressed, the piece should be cleaned to remove old insect accretions and deposits. Compromised areas should be consolidated and stabilized, to ensure no further loss of the wood support, or finished surface.\nThere are many variables to consider when addressing an infestation. Some approaches may be detrimental to select mediums, or to components of a piece.\nA conservator can help determine the extent of the damage, the best approach as well as stabilize the damage after the infestation is eradicated.']	['<urn:uuid:e4c897ef-5b43-49ce-85b8-8f742ca78de9>']	factoid	direct	long-search-query	distant-from-document	single-doc	expert	2025-05-12T23:47:20.322175	10	42	669
15	remote work network protection measures comparison cloud office environments	The shift from traditional office working to remote working introduces increased security risks, particularly in how networks are accessed and protected across different environments. For cloud environments, this requires implementing end-to-end encryption, secure HTTP access with SSL encryption, and role-based access controls (RBACs) to regulate employee access to sensitive data. In the traditional office-to-remote transition, organizations need to establish clear BYOD policies, implement VPNs with multi-factor authentication for secure access, and provide employee training on identifying phishing attempts and maintaining strong passwords. Both environments require protection against DDoS attacks through multi-layered security controls including web application firewalls, intrusion protection systems, and load balancers.	"['With the ever-increasing rise in cyberattacks across the globe, cybersecurity has now become a serious concern for businesses of all sizes. Cisco\'s latest survey, ""Big Security in a Small Business World: 10 myth busters for SMB security"" says that small to midsize businesses (SMBs) face the same challenges as big companies. SMBs tend to be easy launch pads for cybercriminals, for they do not have the resources and infrastructure similar to corporates. They often have lesser security layers compared with larger companies. The impact of a cyberattack can turn to be devastating for SMBs as a majority of their operations could be stunted by the attack.\nWith the COVID 19 pandemic affecting businesses across the globe, SMBs are one among the most impacted business segment. The rapid shift of their operations from workspaces to homes without adequate infrastructure and resources have exposed them more to cyber-attacks. Managing and securing their networks has now become a top priority of most of the SMBs.\nSMBs run on limited resources and they might not have the budget to implement expensive and complex security measures. Thus, the task of ensuring cybersecurity tends to be on the shoulders of an individual or a small network management team. However, it is high time that the SMBs implement basic mitigation plans right from the employee level, like providing appropriate training, and regularly updating software products used across the organization. Small businesses should treat cybersecurity among their top three business priorities. Here we are putting out a checklist, which could be used as general guidelines to ensure cyber-safety for small and mid-sized organizations.\nIt is important that organizations, big or small should follow the best practices to ensure cyber security. The following checklist will help them thwart attackers from accessing their company’s network and mitigate their cyber-attack exposure.\nThe shift from traditional office working to remote working poses more risks to SMBs. Use of personal devices and Wi-Fi are now integral part of routine working. It is essential to maintain an optimal balance between the risk and prevalence of personal devices and remote working. A clear Bring Your Own Device (BYOD) policy should be in place to ensure best security practices and maintain a high level of security on every device that access company network or resources.\nEmployees should be trained about the need of updating their devices, identifying phishing attempts and scams. They should be aware of the procedures for flagging concerns. Likewise, it is important to educate them about the necessity of strong passwords and use of password management tools. Employees should be encouraged to enable two-factor authentication or multi-factor authentication for every possible device or service.\nA VPN can help SMBs to limit network access to their employees, partners and other authorized people. Setting up a VPN for business enables employees to securely access resources on their business network while working remotely or travelling. It also ensures that your sensitive business data is well protected and prevents data snooping even if the employees use public Wi-Fi. A VPN, with an embedded multi-factor authentication setup would be an ideal choice to provide an additional layer of security for businesses.\nCybersecurity experts recommend firewall as an essential for SMBs. It guards their devices and networks from the threats spread across the internet. While traditional firewalls help to control traffic on the basis of port and protocol information, modern firewalls have better screening and reporting abilities and are sometimes capable of automatically responding to security threats to isolate and clear-out affected systems.\nEmbedding cybersecurity policies in an organization’s business culture is relevant at this point in time. A cybersecurity policy describes the technology and information assets that a company, its employees and authorized users should protect and it identifies the potential threats to such assets. The policy should describe the privileges, limitations and responsibilities of each user. It should also inform the penalties for the violation of the cybersecurity policy. A well-documented cybersecurity policy with a proper plan, schedule and checklist can ensure that the processes are implemented on time. It will also empower staff of their responsibilities.\nReviewing user access rights minimizes the risk of compromising sensitive data. This is relevant to safeguard the data from former employees, contractors or temporary staff. Absence of proper access restriction can result in unauthorized information access or disclosure, malicious attacks against resources, data leakage or installation of malicious code. An appropriate user access review will minimize the number of possible routes to critical data. Access should be restricted to only those who require it and should be revoked once their role changes.\nSometimes, even after taking adequate precautions, there are still chances of a successful attack on your network. Ransomware attacks have now become a commonplace problem for businesses and could sometimes cost a fortune get the data back. To deal with a possible attack, regular backups should be done and stored at offline locations. This can save a lot of headache recovering from an attack. Also, in general, data backups are themselves a good practice even beyond a cyber or ransomware attack.\nStudies shows that the cause of one in three breaches in SMBs is unpatched vulnerabilities. Organizations should proactively identify and test the flaws and deploy corresponding patches. This can serve as the first step to defend cyber-attacks. You need to identify your high risk exposures and patch the applications based on its relevance to the business. Any system that cannot be mended should be isolated from other patched systems. Make sure that the software on every device in your organization is up-to-date so that it is insulated against the latest vulnerabilities. Appropriate server maintenance is another major aspect to be checked on. Attacks like distributed denial-of-service (DDoS) can even result in the complete shutdown of your vital servers.\nWith the increasing frequency of cyber-attacks on businesses, SMBs should have a proper multi-layered security strategy to counter cyber-attacks. In most cases SMBs are prone to attacks because they do not have comprehensive security strategy. Having a proper strategy at place and creating adequate employee awareness should be a top agenda.\nThe internet is like a double-edge sword. It makes work easier, accessible, and convenient. At the same time, however, it poses threats to your business’ privacy and security.… 07 September 2020\nTechnology has changed the way today’s businesses operate. Organizations of all sizes need to continuously evolve and embrace technologies that can secure them from data …18 June 2020', 'There are two sides to every coin, and nowhere is that more evident than on your cloud server. The exact same attributes that make cloud storage servers so cost-effective and convenient also make them much more difficult to secure.\nIn the cloud, maintenance and upgrade management falls entirely to your cloud hosting provider. On one hand, this frees up internal resources, meaning less time (and money) is spent on routine maintenance. On the other hand, you don’t have control over server configurations and upgrades, which could spell trouble where your business security is concerned.\nSimilarly, the same virtualization technology that allows you to rapidly deploy new cloud servers also puts you at risk for data breaches and other cybercriminal events. In cloud computing, physical servers are split into virtual machines, which means other organizations could theoretically access the data stored on them—especially if your provider is lax with security controls.\nThese issues highlight just how diligently business IT support teams must work to secure cloud storage servers and databases. Beating hackers at their own game requires robust, thorough security strategies like those described below.\nEnd-to-end data encryption\nImplementing encryption solutions is one of the most crucial moves you can make to protect your data from leaks and ransomware attacks. Most cloud storage services automatically encrypt data while in transit; however, once that data is saved to your cloud server, there’s no guarantee that it’s secure. And even if a third-party cloud storage service does encrypt the data stored on its servers, the company ultimately holds the key to that information, not you. In other words, if that third party is compromised, your data could go down with it.\nThese facts make a good case for implementing some kind of encryption method before you store data in the cloud, but regardless of whether you use a cloud storage service or have a separate cloud environment, protecting your data with encryption software offers security against brute-force attacks, data leaks and ransomware. Your business IT support provider should be able to help you design an encryption technique for your cloud storage solutions—for instance, at MyITpros, we offer whole-disk encryption for our cloud services.\nSecure data transfers\nKeep in mind that data is not only at risk when it’s sitting on cloud storage servers, it’s also vulnerable when in transit (i.e. while being uploaded, downloaded or moved on your server). Although most cloud service providers encrypt data transfers as a rule, this is not always a given.\nTo ensure data is protected while on the move, make certain that transfers go through secure HTTP access and are encrypted using SSL. Your business IT support provider should be able to help you obtain an SSL certificate and configure your cloud service to use it. You may also want to install HTTPS Everywhere on all devices that connect to your cloud.\nLocal data backups\nThe cloud often lulls business owners into a false sense of security where data integrity is concerned. After all, if one of the main cloud benefits is that your data is backed up automatically, there’s no need to save it locally, right?\nNot necessarily. Hackers know that many businesses don’t save data locally, and they exploit this to their advantage when they launch ransomware attacks. Without local backups, you might feel pressure to surrender large sums of money to get your data back.\nHowever, the FBI recommends that you don’t pay ransoms. Not only is there no guarantee that hackers will play fair and return your data (these are criminals, after all), paying up could brand you as an easy target and make you more likely to be hacked in the future. Backing up your data locally will give you the confidence you need to refute a ransomer’s fee.\nDistributed denial-of-service protections\nYou may already be familiar with distributed denial-of-service (DDoS) attacks in which a hacker drowns your server, website or application with multiple requests for data, essentially rendering it useless. Cybercriminals have been launching denial-of-service attacks for at least 20 years, but today’s access to bots and IoT devices makes it even easier for hackers to coordinate the attacks through multiple systems, hence the term “distributed.”\nYou can fight back by building multi-layered protections into your networks and systems. Using web application firewalls, intrusion protection systems (IPS), load balancers and other tools, you’ll be able to better detect and prevent DDoS attacks and handle high-volume requests that might otherwise paralyze your network. A good managed service provider will be intimately familiar with these controls and able to add them to your infrastructure and servers.\nHackers are constantly at work, which means your IT support provider must be, too. To keep your company’s data, applications, websites and networks secure, you’ll need to stay one step ahead of cybercriminals.\nEssentially, this boils down to identifying system weaknesses before they cost you. You may want to engage your business IT support team in performing a vulnerability assessment, which will involve your provider testing your cloud storage networks to locate weaknesses that may allow hackers in and then developing a plan to address these. Performing these assessments regularly keeps your networks like a shark: always swimming.\nAn unfortunate truth about security threats is that they don’t necessarily come from outside a business. Internal team members with access to sensitive data on the cloud can wreak havoc in their own right, whether they take the form of disgruntled employees stealing confidential data for malicious purposes or negligent personnel accidentally exposing information housed in the cloud.\nRole-based access controls (RBACs) help you regulate the access given to various employees, allowing you to designate which servers and files individual users can open, edit or copy. Administrators can assign roles and privileges to users based on need, authority and the employee’s position within the company. Implementing these controls may also be required to stay compliant with statutory and regulatory requirements for your industry.\nSo what if there are two sides to the cloud computing coin? With the right cloud security controls, the odds will be in your favor every time!']"	['<urn:uuid:01c0be0e-1ba9-4d6d-8669-8dbd98f504b1>', '<urn:uuid:7485cb1f-5a98-4332-a04e-ffa03d3c8686>']	open-ended	direct	long-search-query	distant-from-document	multi-aspect	expert	2025-05-12T23:47:20.322175	9	103	2082
16	How are child workers helped when found in factories?	When child workers are identified, they are immediately removed from the factory. The suppliers must pay them minimum wage until they reach legal working age, provide health screening, transportation funds, and accommodation to return them home. If the child wants to study, suppliers must pay for vocational training until they reach legal working age, after which they can be re-employed.	"[""To be certain, women are among the most vulnerable to abusive labour practices. We do not condone any underage, forced, or bonded labour—nor other forms of abuse toward workers, especially women—and work closely with suppliers to make sure these are absent from our supply chain.\nWe expect suppliers to give special consideration to the rights of women and all those who are especially vulnerable, including home, agency, temporary, and migrant workers. We are using a gender lens—focusing on women—in our sustainability strategy to ensure that all of our goals can help improve the lives of the women who work in our supply chain.\nWe require that our suppliers do not engage in, support, or tolerate discrimination in employment, including recruitment, hiring, training, working conditions, job assignments, compensation, promotions, discipline, termination, and retirement, on the basis of gender, age, religion, marital status, race, caste, social background, diseases, disability, pregnancy, ethnic and national origin, nationality, membership in worker organizations including unions, political affiliation, sexual orientation, or any other personal characteristics. If we find any of these situations in production units supplying C&A, we educate our suppliers on how to avoid and eliminate discrimination. Repeat issues with a supplier will result in termination.\nThis important aspect of our business will evolve over time to support the UN Sustainable Development Goal of Gender Equality, and increase the proactive nature of our commitment to gender equality beyond auditing.\nIndia is competitive in the global apparel market thanks in large part to those who produce hand-embroidered items. Yet these workers—who often work at home—have received little support to date, with their situation declining due to market pressure. We allow this conditionally if suppliers follow C&A Guidelines for the Use of Home Workers, which is adapted from the Ethical Trading Initiative guidelines.\nThrough a two-year pilot, GoodWeave seeks a new sourcing system that will increase supply chain visibility and improve conditions for homeworkers. The pilot is in collaboration with C&A and three of our suppliers in India, with funding from C&A Foundation. It will test and refine GoodWeave’s system: mapping the supply chain, conducting inspection and monitoring, improving workplace conditions, and offering child protection and education programming.\nWe expect our suppliers to treat workers with dignity and respect. We do not tolerate abuse, harassment, the threat of abuse, or any forms of intimidation. We expect suppliers to have clear policies and procedures and we require disciplinary actions to be fair and consistent. Incidences of harsh treatment will result in termination of a production unit and discipline of the supplier. In 2015, we did not detect cases of physical or sexual abuse through the course of our factory audits.\nIn our new Code of Conduct, we raised the requirement on the minimum age of workers in our supply chain to follow the recommendations in the ETI base code and to meet our expectations. Workers must be at least 16 years old. We do not allow underage workers to be present in any supplier production area, even if not working. If young workers—defined as 16 to 18 years old—are hired, suppliers must comply with all relevant legal requirements, including work hour restrictions, hazardous work restrictions, and health checks.\nIn addition, we proactively partner with C&A Foundation on important projects with non-governmental organizations like GoodWeave. This programme seeks a new sourcing system that will increase supply chain visibility and improve conditions for homeworkers, while eradicating child labour.\nIf child labour is identified in our supply chain, the child is removed from the factory immediately. In 2015, we identified eight cases of underage workers in the supply chain which were effectively remediated, supporting the underage worker until legal employment age.\nTo remediate these situations, suppliers are required to pay minimum wage until she/he reaches the legal minimum age. To discourage the underage person from seeking a job elsewhere, monthly payments are disbursed until he/she reaches a legal age.\nWe also require that suppliers provide families with compensation for health screening, transportation funds, and accommodation for a child’s relatives to return him/her to the home. If the child is willing to attend lessons, suppliers must pay the vocational fees until the child meets the legal minimum working age. At this point, the individual should be given the opportunity to be re-employed.\nTo foster this process we partner with local non-governmental organizations like the Centre for Child-Rights and Corporate Social Responsibility (CCR CSR) in China and Southeast Asia, Sheva in Bangladesh, and Çagdas Yasami Destekleme Dernegi (The Association for the Support of Contemporary Living) in Turkey to ensure that the underage worker is supported and tracked through the process of remediation.\nWorkers must be entitled to freedom of employment and movement. Work must be voluntary, and all forms of bonded, indentured, or prison labour are prohibited. In our Code of Conduct forced or bonded labour is a zero tolerance issue. Suppliers and labour brokers must not restrict the freedom of employment of workers by:\nIt is also important that workers are free to refuse performing certain tasks that are hazardous—without fear of disciplinary action, discrimination, or termination of employment.\nDuring working hours, suppliers must allow workers to have free access to toilets, water, and breaks without any disadvantage, disciplinary action, discrimination, or termination of employment. In addition, suppliers must allow workers to leave the production unit either at the end of their shift or under extenuating circumstances, such as personal or family emergencies or illness, without fear of disciplinary action, discrimination, or termination of employment. If any form of bonded, indentured, or prison labour is identified in our supply chain, we terminate the relationship with the production unit immediately and the supplier will be disciplined. In 2015, we had zero cases of forced labor detected in the audits of our global factory base.\nSumangali is a form of bonded labour practised in parts of India that violates international labour standards and the human rights of women. Women are given three-year contracts, often in unacceptable working and living conditions, with the promise of a bulk payment that will cover their dowry to get married. However, their wages are often held back, if they receive them at all, and they are not allowed to leave or return to their homes.\nWe first became aware of this illegal system in 2007. Since then, we have been working to eradicate it from our supply network, and we regularly inspect our direct suppliers—with an emphasis on spinning mills—to ensure the bonded labour practices and curfew have been discontinued.\nAbolishing Sumangali will be possible only through collective action by brands, suppliers, non-governmental organizations, policymakers, and communities. We have joined the Tamil Nadu Multi-Stakeholder Initiative’s Nalam Programme. Nalam is a year-long peer learning program created by Ethical Trading Initiative to educate young female workers about their rights and responsibilities in the mill sector. So far, four of our mill suppliers from Tamil Nadu have signed up for the training programme. An additional two are in the process of joining. In 2016, we will increase collaboration with stakeholders to further address this issue.\nTo support the eradication of Sumangali, the C&A Foundation has been working for several years to address the root causes of the issue, beginning with a three-year project run by child rights organization Terres des Hommes. The program aims to rehabilitate girls and women and provide education. To date, around 10,000 girls and women have been released from Sumangali contracts and are enjoying education. Now, C&A Foundation is expanding this approach with a €770,000 grant to reach 25,000 girls and young women, providing schooling, vocational training, and work placement.\nC&A Foundation is also working to prevent vulnerable girls and young women from entering the system in the first place. In 2015, C&A Foundation made a €2.4 million grant to The Freedom Fund, the world’s first private donor fund dedicated to ending modern slavery. The initiative brings strategic focus and reinforces industry collaboration to curb demand for bonded labour. It aims to mobilize at least 240 communities in Tamil Nadu to promote education and training, along with care to rehabilitate survivors.\nOur approach to refugees is exemplified in how we have supported the Syrian refugees in Turkey. As of this report, Turkey is the world’s largest recipient of refugees, hosting as many as two million displaced Syrians. C&A Europe applauds the generous open door policy of the Republic of Turkey. At the same time, we are well aware that the situation of Syrian refugees in Turkey is extremely difficult, and assisting them requires more than providing life-saving aid. We’ve been actively working with Ethical Trading Initiative, Fair Labor Association, and other brands to ask the government of Turkey for a process that would enable refugees to receive legal permission to work. Without it, refugees are more vulnerable to abuse and exploitation. We welcome the government’s decision to finalize the work permit regulation that went into force in January 2016, and will continue to educate our suppliers and their factories to protect the human rights of Syrian refugees.\nIn 2015, we identified two cases of illegal Syrian migrants working in our suppliers' factories in Turkey. This situation involved six workers in two factories. To remediate the situation we worked with our suppliers to identify the root cause and develop a corrective action plan to prevent future incidents. In these two cases, all of the workers were 18 or older. We have not experienced any Syrian refugee children in our supply chain.\nThroughout 2016, we will also conduct unannounced audits in the southern part of Turkey close to the Syrian border. We will develop concrete steps to support production units, such as by raising awareness about the new employment regulations for Syrian refugees and their implementation. We will support our approach by collaborating with other brands and stakeholders to avoid human rights abuses of refugees.\nIn Brazil, Instituto C&A is helping improve the lives of Bolivian and Paraguayan migrants working in apparel factories. Because these workers don’t always know their legal rights, they can end up working in irregular conditions.\nTogether with non-governmental organization partners Missão Paz and Pastoral Immigrant Support Centre, Instituto C&A is helping immigrant workers obtain the documents they need to work and live legally, and understand their rights in the workplace. Financial support and help with strategic planning are also provided.\nIn 2015, a non-profit centre that supports immigrants, Centro de Apoio e Pastoral do Migrante, helped 2,500 immigrants register as residents and made 950 visits to factories and immigrant homes to provide advice on social welfare and labour conditions issues, in addition to legal counselling in some 400 cases. Additionally, C&A Brazil has become a founding member of InPACTO, the National Institute for the Eradication of Slave Labour. As one of the main supporters, we’re shaping the initiative’s direction and providing important funding.""]"	['<urn:uuid:293e3bc2-3e9f-444c-bea7-ac2be3b6c5f5>']	open-ended	direct	concise-and-natural	similar-to-document	single-doc	novice	2025-05-12T23:47:20.322175	9	60	1797
17	nasa space program history current challenges moon landing debris	In 1961, NASA focused on landing humans on the Moon as a Cold War objective, requiring massive funding and technological development to beat the Soviets. Currently, NASA faces different operational challenges, particularly managing the growing threat of space debris, with about 19,000 pieces larger than a softball being tracked to protect operational satellites and the International Space Station, while scientists worry about potential chain reactions of collisions making parts of space unusable.	"['NASA was well placed to exploit the new administration’s willingness to expand the space program. Its long-term planning was impressive for its detail, in particular\nThis report was excerpted in the New York Times on 12 January 1961, and is sometimes wrongly dated as such.\nbecause George Low’s committee had costed the accelerated plan – concluding that it would require $7 billion to land a man on the Moon by the end of the decade. In January 1961 Low briefed Keith Glennan on the forthcoming hearings for NASA’s budget, but Glennan expected to be replaced by the new administration and so was in a weak position.\nOn Johnson becoming Kennedy’s Vice President, Robert S. Kerr took over from him the chairmanship of the Senate Committee on Aeronautical and Space Sciences. After consulting Kerr, Johnson recommended James E. Webb to succeed Glennan as NASA administrator, and Webb took over on 14 February. Whereas Glennan was a scientific administrator with a conservative outlook, Webb was a political operator. He had served as Director of the Bureau of the Budget between 1946 and 1949 and Undersecretary of State from then until 1952 in the Truman administration. He had been a director of Kerr’s oil and uranium conglomerate, Kerr-McGee Oil Industries, and simultaneously a director of the McDonnell Aircraft Company.\nWebb immediately set out to obtain the funding that was earlier denied for Apollo and the Saturn launch vehicle. When the Bureau of Budget refused, Webb wrote to Kennedy in early March that Eisenhower had “emasculated the 10-Year Plan before it was one year old’’, and if the funding were not made available it would “guarantee that the Russians will, for the next five to ten years, beat us to every exploratory space flight’’. To ram home the message in terms that Kennedy would appreciate, Webb said, “We have already felt the effects of the fact that they were the first to place a satellite into orbit, have intercepted the Moon, photographed the back side of the Moon, and have sent a large spacecraft to Venus. They can now orbit seven and a half ton vehicles about the Earth, compared to our two and a half tons, and they have successfully recovered animals from flights of as much as 24 hours. Their present position is one from which further substantial accomplishments can be expected, and our best information points to a steadily increasing pace of successful effort on a realistic timetable.’’\nOn 23 March Kennedy met with Lyndon Johnson, Jerome Wiesner, David Bell of the Bureau of Budget and Edward C. Welsh, a former aide to Johnson who was now serving as Executive Director of the National Aeronautics and Space Council, of which Johnson was chairman. Kennedy agreed to increase funding for the Saturn launch vehicle, but said he would need to deliberate further on the Apollo spacecraft – he would decide in the autumn, he said.\nJust when NASA began to think that it might beat the Soviets to a manned space flight, on 12 April 1961 Yuri Alexseyevich Gagarin made a single orbit and landed safely. Webb told Congress, in budget hearings then underway, that NASA could certainly work faster if its funding was increased.\nThe next evening Kennedy met at the White House with Jerome Wiesner, David Bell, James Webb, Hugh Dryden, Theodore Sorensen, who was a friend and advisor, and Hugh Sidey, a journalist for Life magazine who was one of Kennedy’s friends, and put to them the question, “at what point we can overtake the Russians’’. NASA opened with a space station to be assembled in Earth orbit to serve as a jumping off point for a future mission to the Moon. But, it pointed out, if the Soviets were on the same plan they would likely remain in the lead for some considerable time. Kennedy\nwanted to minimise this period, either by accelerating or by short circuiting the plan. Dryden said a ‘crash’ program might land a man on the Moon ahead of the Soviets, but it might cost as much as $40 billion. ‘‘The cost! That’s what gets me,’’ Kennedy mused. ‘‘When we know more, I can decide if it’s worth it or not. If somebody can just tell me how to catch up.’’ As the meeting broke up, Sorensen remained behind to discuss what had been said, and upon emerging told the others, ‘‘We’re going to the Moon!’’\nOn 19 April Kennedy summoned Johnson and told him he had decided to issue a momentous challenge. The next day, Kennedy sent a memo to Johnson seeking ‘‘an overall survey of where we stand in space’’. Specifically:\n1. Do we have a chance of beating the Soviets by putting a laboratory in space, or by a trip around the moon, or by a rocket to land on the moon, or by a rocket to go to the moon and back with a man. Is there any other space program which promises dramatic results in which we could win?\n2. How much additional would it cost?\n3. Are we working 24 hours a day on existing programs. If not, why not? If not, will you make recommendations to me as to how work can be speeded up.\n4. In building large boosters should we put [our] emphasis on nuclear, chemical or liquid fuel, or a combination of these three?\n5. Are we making maximum effort? Are we achieving necessary results?\nOn 21 April Kennedy told reporters that his administration was considering the options and cost of space, and said, ‘‘If we can get to the Moon before the Russians, we should.’’\nJohnson consulted NASA first, which said there was little chance of beating the Russians to a space station; it might be possible to beat them to lunar orbit; the best bet was a lunar landing. This matched Johnson’s thinking. NASA suggested 1967 as a target date because it was expected that the Soviets would attempt to make a lunar landing then in order to mark the 50th anniversary of the Bolshevik Revolution. As a result of the additional analysis by Low, the costing had been increased from the $7 billion estimate for a landing in 1969 to $22 billion; but a landing in 1967 would be $34 billion. Next, Johnson consulted the Pentagon, and the Air Force agreed that a manned lunar landing would be appropriate – even although the Air Force would not be allowed to perform it. Finally, Johnson consulted three businessmen whose judgement he trusted: Frank Stanton of the Columbia Broadcasting System; Donald Cook of the American Electric Power Service Corporation; and George Brown of Brown and Root, which was a construction company in Texas. The fact that none of them was involved in the aerospace industry that would be called upon to build the hardware for the program was a point in their favour, since it meant they were unbiased. At the National Aeronautics and Space Council on 24 April, Johnson, as Wiesner later described it, ‘‘went around the room saying, ‘We’ve got a terribly important decision to make. Shall we put a man on the Moon?’ And everybody said ‘yes’. And he said ‘Thank you’.’’\nThe scientific community was represented in the White House by Wiesner. The majority of space scientists were interested in particles and fields, and because this\nChairman of the Space Council to be in charge of making an overall survey of where we stand in apace.\n1. Do we have a chance of beating the Soviets by putting a laboratory in space, or by a trip around the moon, pr by a rocket to land on the moon, or by a rocket to go to the moon and back with a man. Is there any other space program which promises dramatic results in which we could win?\n2. How much additional would it cost?\n3. Are we working 24 hours a day on existing programs. If not, why not? If not, will you make reconmenda – tions to me as to how work can be speeded up.\nД. In building large boosters should we put out\nemphasis on nuclear, chemical or liquid fuel, or a confcination of these three?\n5. Are we making maximum effort? Are we achieving necessary results?\nI have asked Jim Webb, Dr. Wiesner, Secretary McNamara\n/в/ John F. Kennedy\nThe historic memo to Lyndon B. Johnson which led John F. Kennedy to challenge his nation to land a man on the Moon before the decade was out.\nresearch did not require a human presence, money spent on sending men into space was by definition wasted. But Kennedy wanted “dramatic results” and the scientists were unable to offer this. To be fair, Kennedy invited Wiesner to suggest a terrestrial challenge that would serve the purpose, “… something with an overseas impact, like desalination or feeding the hungry”. However, Wiesner could see that the Moon was\nshaping up to be the challenge, and advised the President “never to refer publicly to the Moon landing as a scientific enterprise”.\nOn 28 April Johnson submitted the National Aeronautics and Space Council’s recommendation:\nLargely due to their concerted efforts and their earlier emphasis upon the development of large rocket engines, the Soviets are ahead of the United States in world prestige attained through impressive technological accomplishments in space. The US has greater resources than the USSR, etc. The country should be realistic and recognize that other nations, regardless of their appreciation of our idealistic values, will tend to align themselves with a country which they believe will be the world leader. The US can, if it will firm up its objectives and employ its resources, have a reasonable chance of attaining world leadership in space. If we don’t make a strong effort now, the time will soon be reached when the margin of control over space and other men’s minds through space accomplishment will have swung so far on the Russian side that we will not be able to catch up. Even in those areas in which the Soviets already have the capability to be first and are likely to improve upon such capability, the United States should make aggressive efforts, as the technological gains as well as the international rewards are essential steps in gaining leadership. Manned exploration of the Moon, for example, is not only an achievement with great national propaganda value, but is essential as an objective, whether or not we are first in its accomplishment – and we may be able to be first.\nKennedy was receptive to Johnson’s recommendation, but he postponed a formal decision until after the first manned Mercury mission, which came on Friday, 5 May 1961 when Al Shepard rode a Redstone missile on a suborbital arc.\nOver the weekend, Johnson met James Webb and Secretary of Defense Robert S. McNamara to draw up a formal recommendation to Kennedy’s memo of 20 April. Recommendations for our National Space Program: Changes, Policies and Goals, jointly authored by Webb and McNamara, said, “It is man, not merely machines, in space that captures the imagination of the world. All large-scale projects require the mobilization of resources on a national scale. They require the development and successful application of the most advanced technologies. Dramatic achievements in space, therefore, symbolize the technological power and organizing capacity of a nation. It is for reasons such as these that major achievements in space contribute to\nIn a speech to Congress on 25 May 1961 John F. Kennedy challenged his nation to land a man on the Moon before the decade was out.\nnational prestige.” They wrote, “even though the scientific, commercial or military value of [such an] undertaking may by ordinary standards be marginal or economically unjustified”, it nevertheless generated “national prestige”, which had value in its own right. Furthermore, “The non-military, non-commercial, nonscientific but ‘civilian’ projects such as lunar and planetary exploration are, in this sense, part of the battle along the fluid front of the Cold War.’’ This echoed Kennedy’s criticism of Eisenhower: whereas Eisenhower had been conscious of the cost and dismissive of national prestige, to Kennedy national prestige was the issue and the cost was secondary.\nOn 25 May Kennedy gave a speech to a joint session of Congress on the theme of Urgent National Needs. In view of recent space achievements by the Soviets, he proclaimed, ‘‘Now it is time to take longer strides, time for a great new American enterprise, time for this nation to take a clearly leading role in space achievement, which in many ways may hold the key to our future on Earth.’’ Having outlined the political background, he laid down the gauntlet. ‘‘I believe that this nation should commit itself to achieving the goal, before this decade is out, of landing a man on the Moon, and returning him, safely, to the Earth.’’ He had opted for a lunar landing precisely because it posed a great technical challenge. By literally ‘shooting for the Moon’, he was betting that America would not only catch up with the Soviet Union in space, but forge ahead. Having concluded that space was the arena of superpower politics, he was challenging his rival, Nikita Khrushchev, for world leadership. He had imposed the deadline to ensure that reaching the Moon was perceived as a race. He was also well aware of the magnitude of the task. ‘‘No single space project in this\nperiod will be more impressive to mankind, or more important for the long-range exploration of space; and none will be so difficult or expensive to accomplish.” The sending of a man to the Moon was to be the modern form of the ancient practice of ‘single combat’, whereby opposing armies lined up and each dispatched a single warrior to decide the issue. To indicate that it was a matter of national honour, he added, ‘‘In a very real sense, it will not be one man going to the Moon; if we make this judgment affirmatively it will be an entire nation, for all of us must work to put him there.’’ And in order to emphasise what was at stake, he warned, ‘‘If we are to go only halfway, or reduce our sights in the face of difficulty, in my judgment it would be better not to go at all.’’\nFor Kennedy the Moon was a symbol and, in terms of what he wished to achieve it was an excellent symbol. He had the impression that the applause in Congress was ‘‘something less than enthusiastic”, as he told Sorensen immediately after giving the speech. But Johnson had read the mood well: there was only minor opposition in the House of Representatives, and the debate in the Senate lasted less than an hour – only five of the 96 senators spoke, and the floor was dominated by Robert Kerr, who was Johnson’s man. NASA’s budget was doubled without a formal vote being taken.', 'Right now, there are more than 300,000 pieces of debris larger than a centimeter in diameter orbiting Earth.\nThey range from tiny shards of metal to deactivated, decades-old satellites. Most are shrapnel from discarded rocket stages that have exploded after use, or satellites that have collided. Colloquially, all this debris is usually called ""space junk.""\nTogether, the Department of Defense and NASA track the orbits of the 19,000 or so pieces of junk that are larger than a softball, alerting satellite operators when any satellite — including the International Space Station — is in danger, so they can move it.\nBut doing so takes time and resources. What\'s more, the cloud of debris has been steadily growing over time, and some scientists worry that if we\'re not careful, we could trigger a chain reaction: More space junk raises the chance of collisions, which in turn can lead to even more debris, until the sheer volume of space junk makes parts of space unusable.\n""Space is a finite resource — just like the atmosphere, and the water, and the Earth,"" says William Schonberg, an aerospace engineer who designs spacecraft to minimize damage from orbital debris. ""We need to be careful about how we use it.""\nWhy space junk is a problem\nEven small pieces of debris in orbit around Earth can cause a surprising amount of damage because of a basic reason: speed.\n""All the objects in Earth\'s orbit naturally have a high velocity,"" says Holger Krag, head of the European Space Agency\'s Space Debris Office. (If they weren\'t traveling that fast, they\'d simply drop to Earth.) In low Earth orbit, this speed is around 16,000 miles per hour. ""Even a centimeter-long screw can generate the energy of an exploding hand grenade.""\nAs a result, collisions have to be avoided at all costs. Using ground-based radar and other instruments, the Department of Defense and NASA keep track of about 19,000 pieces of debris larger than five centimeters — the ones big enough to cause significant damage.\n""We do an assessment for every operational satellite, looking typically three days into the future, and if we think that some other object is going to come close to hitting it, we notify the owner-operator,"" Nicholas L. Johnson, then-chief scientist at NASA’s Orbital Debris Program, told me in 2012. About once a week or so, satellites are moved to prevent a collision.\nBecause there\'s crew on board, the International Space Station is treated with extreme delicacy and is moved if there\'s more than a 1 in 100,000 chance something will collide with it. In a few cases, warning hasn\'t come in time, and astronauts have had to quickly take shelter in the capsules that serve as the station\'s lifeboats.\nEven with these preventative measures, though, debris are a long-term issue for space operations as a whole. One problem is that a steady stream of even tinier, sand grain-sized particles can gradually erode the surface of all spacecraft in orbit.\nAnd there\'s a bigger concern for heavily-trafficked orbits — such as low Earth orbit and geosynchronous orbits (often used for communication satellites, so they can stay fixed over one location on Earth). As these orbits fill with debris, they become more and more expensive to use. ""Every collision avoidance maneuver means loss of mission time,"" Krag says. ""And you have to use manpower and fuel to carry them out.""\nAll debris eventually falls back to Earth given enough time — and objects in lower orbits fall much faster, over the course of a few years, because traces of atmosphere drag on them and slow them down. But those in higher orbits might take decades or even centuries. And if we\'re not careful, some orbits could become so clogged with junk that they\'re impossible to use.\nWhere all the space junk came from\nA few different factors have contributed to the steady accumulation of orbital debris ever since we started using space in the 1950s.\nOne is the fact that for decades, the rockets we used to lift spacecraft into orbit were only designed with the first few minutes of flight in mind. ""We didn\'t think at all about how the object might behave after years or decades,"" Krag says.\nAs a result, rocket components were commonly left in orbit with tiny amounts of extra fuel and built-up pressure inside. When an object in orbit leaves the shadow of the Earth and is hit by sunlight, its temperature can swing by hundreds of degrees. This has led many rocket stages to explode, sending thousands of shards of metal cascading in orbit.\nIn the 80s, scientists recognized the problem, and now, rockets are designed so that they can be fully emptied after use. These intact rockets, along with deactivated satellites, make up a minority of the pieces of debris in orbit.\nBut two recent events generated another 5,000 pieces of tracked debris, generating about a quarter of the total.\nIn 2007, China intentionally destroyed one of its weather satellites in orbit as part of a military test, generating about 3,000 pieces of debris. Even worse, it was done in a higher orbit than other anti-satellite tests previously conducted by the US and Russia, so the debris will take much longer to come down. Other countries criticized the test, but the damage was done.\nThen, in 2009, two satellites — a deactivated Russian military satellite and an active US communications satellite — accidentally collided, creating a shower of another 2,000 or so pieces of debris.\nWhat\'s going to happen to space junk in the future\nThe 2009 event was especially alarming because it may be a sign of things to come: if space gets too crowded with debris, it could trigger a positive feedback loop, in which collisions beget debris, which beget collisions.\nSome scientists, in fact, believe this scenario (called the Kessler syndrome) is already happening, just slowly. Unlike in the movie Gravity, the chain reaction would accelerate slowly, over the course of decades: right now it\'s estimated that one collision will occur every five years, and if things get worse, the rate could increase to one collision annually within 50 to 100 years.\nStill, there\'s disagreement over whether this is happening yet — and spacefaring nations are generally being more careful nowadays. Rockets are drained of fuel and pressure after use, and satellite operators are now required to move their satellites down to a lower altitude after use, so they\'ll fall back to Earth more quickly, or take them up to an unused ""graveyard"" orbit.\nStill, there\'s tons of debris already in orbit. If we did enter a scenario in which debris accumulated uncontrollably, people have drawn up some ideas for cleaning up our orbits: crafts that would use nets or harpoons to grab derelict satellites to bring them down, for instance, or a spacecraft that would grab debris, throw it down to Earth, and use the resulting momentum to move on to the next object.\nAt the moment, though, these ideas are purely hypothetical, and all of them would be extremely expensive. If we want to continue relying on Earth\'s orbit for communication, navigating, and all other sorts of useful technologies, we need to be more careful with it going forward.\nFurther reading: How NASA steers the International Space Station around space junk']"	['<urn:uuid:e3713883-bf2b-4ee7-ae9c-696e8a02be23>', '<urn:uuid:af09ffe4-73dd-4917-b8ac-4c2ad6170415>']	factoid	with-premise	long-search-query	distant-from-document	multi-aspect	novice	2025-05-12T23:47:20.322175	9	72	3696
18	what percentage adults get anxiety life	According to estimates, between 5 and 7% of the general population are affected by anxiety disorders. Up to 29% of people will experience an anxiety disorder at least once during their lifetime. The disorders affect both men and women across the world, though the burden of the disease is greater in women than in men.	['Anxiety is a normal response to stress, worry or threat – but when it is very severe, long-lasting, or out of proportion to the circumstances, it becomes known as an anxiety disorder.\nThere are several different types of anxiety disorder: for example, generalised anxiety disorder, social anxiety disorder, panic disorder and obsessive–compulsive disorder. By affecting a person’s mood, thoughts and behaviour, an anxiety disorder can make it difficult to cope with daily life at home, at work or school, and when socialising.\nThe cause of anxiety disorders it not known. However, certain alterations in brain functions have been shown to be implicated in various anxiety disorders. In addition, social conditions and stresses may contribute to the risk of developing an anxiety disorder.\nAlthough they vary between individuals, typical symptoms of anxiety disorders include fear, inner tension, irritability and poor concentration, and physical signs such as dry mouth, dizziness, tense muscles, sweating and palpitations – all of which interfere with daily life. A person may suffer from more than one anxiety disorder at the same time, and sometimes alongside other mood disorders such as depression (so-called ‘co-morbidity’). The co-occurrence of anxiety and depression is very common.\nGeneralised anxiety disorder (GAD) involves a non-specific anxiety that something undesirable could happen. Excessive and uncontrollable worry, anxiety and tension are typical symptoms, together with physical symptoms such as dry mouth, clammy hands, sweating or dizziness.\n¨ Social anxiety disorder (SAD) causes people to fear or avoid social situations. The person fears that he or she will act in a way that will be humiliating or embarrassing.\n¨ Panic disorder is typified by sudden panic attacks associated with marked fear or nervousness. Panic disorder can also include physical symptoms such as sweating, pain, headache, nausea, a pounding heart or a dry mouth.\n¨ Obsessive–compulsive disorder (OCD) causes repetitive, obtrusive and unwanted thoughts, which result in unreasonable fears (obsessions) associated with cleanliness, body secretions or health, for example. In response to these fears, patients may also carry out special rituals (compulsions), including persistent washing, cleaning, bathing, constant checking and rechecking, or maintaining a rigid diet.\nIt has been estimated that anxiety disorders affect between 5 and 7% of the general population, and that up to 29% of people will suffer from an anxiety disorder at least once during their lifetime.1 In 2004, over 28 million people worldwide had obsessive–compulsive disorder, and over 30 million experienced panic disorder.2\nAnxiety disorders affect both men and women across the world, but the burden of the disease is greater in women than in men.3\nSeeking diagnosis and care\nMany treatments are available to effectively manage anxiety disorders, and personal support from family and friends is valuable at all stages.\nDuring a medical appointment, a doctor will diagnose anxiety disorders by asking questions about symptoms, daily life and family history. There may also be a physical examination to exclude other conditions. If an anxiety disorder is confirmed, treatment options will then be considered, including medications, counselling, social support, exercise, relaxation and self-help techniques.\nIn all cases, it is important that professional advice is sought.\n1. Baldwin, D.S. and Hirschfeld, R. M. A. (2005). Fast Facts: Depression, 2nd edn. Health Press, Oxford, UK.\n2. World Health Organization (2004). Prevalence for Selected Causes in WHO Regions, 2004. http://www.who.int/healthinfo/global_burden_disease/PREV6%202004.xls. Accessed 16/09/11.\n3. World Health Organization (2004). The Global Burden of Disease. 2004 Update. www.who.int/healthinfo/global_burden_disease/2004_report_update/en/index.html. Accessed 16/09/11.']	['<urn:uuid:6f94984e-151a-4808-a33e-f7d8caf3ebdf>']	open-ended	with-premise	short-search-query	distant-from-document	single-doc	novice	2025-05-12T23:47:20.322175	6	55	562
19	who leads vision therapy rehabilitation service	The Vision Therapy and Rehabilitation Service (VTR) is under the direction of Marc Taub, OD, MS, FAAO, FCOVD, who serves as Chief of Service.	['The Vision Therapy and Rehabilitation Service (VTR) provides care to patients of all ages under the direction of Marc Taub, OD, MS, FAAO, FCOVD, Chief of Service.\nPatients are referred to the care of doctors in this service both from within The Eye Center and from other doctors throughout the Mid-South region.\nThe VTR service specializes in the care of patients experiencing visual deficits secondary to learning and physical disability, acquired brain injury or neurological insult and low vision secondary to ocular disease.\nWho can benefit from a vision therapy or vision rehabilitation evaluation?\nMany eye diseases and injuries may cause decreased vision. (www.lighthouse.org) Among the most common conditions encountered include macular degeneration, (www.ahaf.org) glaucoma, (www.glaucoma.org) and diabetic retinopathy (www.aoa.org/diabetic-retinopathy.xml.) Genetic diseases such as Leber’s Hereditary Amaurosis, albinism and retinitis pigmentosa may affect vision at an early age.\nAcquired brain injury (CVA or trauma) can alter not only a patient’s sight, but the ability to process the information. (https://noravisionrehab.org/)\nChildren and young adults may suffer from a binocular vision, accommodative, visual processing or ocular motor dysfunction that may affect academics. (www.childrensvision.com)\nAn evaluation in the VTR service will determine the need for optometric vision rehabilitation, which is an individualized treatment regimen aimed at the remediation of visual, perceptual and motor disorders. Treatment provided in this service often consists of multi-sensory and neuro-behavioral therapy for disorders not managed solely by eyeglasses or contact lenses. State-of-the-art instrumentation and computerized technology allow patients of all ages to improve their vision for optimum performance not only in the classroom or on the sports field but also in performing the everyday activities of daily living.\nDoctors at TEC are specifically trained to provide the highest level of diagnosis and treatment for these conditions. In fact, a majority of doctors in this service area are certified Fellows of the College of Optometrists in Vision Development. (www.COVD.org)\nSeveral types of diagnostic examinations are performed in the VTR Service. The following descriptions will allow for a better understanding about the type of recommended exam.\nBASIC VISION SKILLS\nThis group of tests will help the doctors in the VTR service determine how clearly patients are seeing, how well their eyes focus, how well their eye muscles work together and the quality of depth perception. This type of exam is recommended when experiencing eye discomfort, reading and/or learning problems that may be linked to vision. Many people are surprised to learn that problems with vision can affect so many daily activities. This can be particularly troublesome for children in school, adults whose job requires a significant amount of near work, athletes whose good performance depends upon the quality of their vision and those who have experienced a brain injury.\nVisual Perceptual/Developmental Exam\nHOW EYES WORK TO UNDERSTAND WHAT THEY SEE\nThis group of tests is designed to provide detailed information about the way the eyes are developing or have developed and how visual information is gathered and processed. Doctors in the VTR service check the ability to understand, store and manipulate material presented through the visual system alone and in conjunction with other senses (i.e. speech, hearing, touch). Doctors also measure the recognition of symbols and letters and the patient’s ability to draw, write and manipulate printed material. This type of exam is typically recommended when a child or teen is not doing well in school or an adult is experiencing vision difficulty following a problem like a stroke or other accident. At least 80% of all that is learned or experienced comes through our visual system, so problems with perception can be extremely disabling.\nStrabismus and Amblyopia Exam\nUNDERSTANDING EYES THAT FAIL TO WORK TOGETHER\nThis exam is designed to specifically address the needs of patients with eye turns and “lazy eye.” This group of tests, like the sensorimotor exam (basic vision skills), checks how clearly patients are seeing, how well their eyes focus, how well their eye muscles work together and the quality of depth perception. In addition, this exam also helps the doctor detect the reason for eye turns and vision loss. Amblyopia, or “lazy eye” as it is often called, is one of the leading causes of preventable vision loss in the U.S. Strabismus, or “eye turn,” is found both in children and in those who have experienced a brain injury. Detection and aggressive treatment can restore vision and eye alignment and positively affect daily activities.\nLow Vision Exam\nMAXIMIZING THE REMAINING VISION\nWhen other medical or surgical treatment cannot provide any further improvement or when medical or surgical treatment must be delayed, a low vision examination is recommended. The low vision examination is an in depth evaluation of the person’s functional use of the remaining vision. The purpose of this evaluation is to prescribe optical and non-optical aids to maximize use of the patient’s residual vision. Optical aids vary in type from magnifiers and telescopes for seeing at distance and near, to closed circuit televisions that can magnify print up to 100 times, enabling the person to read again. Non-optical aids include items such as talking watches, books on tape, colored filters to reduce glare and other devices aimed at improving activities of daily living. Coupled with the wide variety in types of optical and non-optical aids and extent of vision impairments, it is necessary to perform a special low vision examination to analyze what the best residual vision is and what specific type of aids will best help the person meet their visual needs.\nVision Therapy/Orthoptics is an individually prescribed (often medically necessary) course of techniques designed to strengthen basic vision skills, correct muscle problems (like eye turn) and treat “lazy eye”. Specific activities stimulate the eyes and brain to improve a patient’s ability to control his or her visual system. This therapy may be conducted along with surgical treatment and or spectacle lenses.\nPleoptics involves the use of light to stimulate the eyes and brain. Various techniques are used along with Vision Therapy/Orthoptic procedures to increase treatment results.\nPerceptual Therapy involves the use of special activities to help an individual compensate for problems that affect learning. Activities improve a person’s ability to gather and process information received from the eyes. Often this therapy is conducted along with remedial activities at home and school.\nSports Vision Enhancement\nSports Vision Enhancement can be achieved through the use of Vision Therapy in the individual with an otherwise “normal” visual system. Vision therapy has been demonstrated to be effective in improving visual skills for maximum performance in baseball, tennis and even golf.\nVisual Rehabilitation Services\nVisual Rehabilitation Services are often provided in addition to Vision Therapy for individuals suffering from problems related to stroke and other forms of accidental head trauma.\nDuring a visit to the Vision Therapy and Rehabilitation service, an in-depth report will be prepared. This report will explain any problems with the patient’s visual system and make recommendations for treatment. In some cases, the use of eye glasses, prism lenses, Vision Therapy, optical/non-optical aids for low vision and/or specialized vision devices (including computer software) may be prescribed.\nAt times, referral may be necessary to another specialist, such as an educational psychologist, occupational therapist, neurologist or reading specialist for further evaluation or even treatment (such as surgery). The doctors in the Vision Therapy and Rehabilitation service will work closely with your referring doctor(s) to ensure that patients receive the best possible care.\nKnow what to expect during your visit:\nFor more information about what a vision therapy appointment might look like, parents and children can read and see pictures about a visit to Vision Therapy at The Eye Center in our social stories:\nMy Vision Therapy Visit to The Eye Center (PDF)']	['<urn:uuid:924f6607-9ec4-42fc-a748-f043e7a5fd15>']	factoid	direct	short-search-query	similar-to-document	single-doc	novice	2025-05-12T23:47:20.322175	6	24	1277
20	How does CCAS audit code sponsors?	CCAS conducts an onsite audit in the first year, followed by desk top audits in the second and third years. The audits are conducted by auditing specialists for CTSI, and code sponsors must provide comprehensive details of audits they've undertaken with their members throughout the year.	['The Consumer Code for Home Builders is an approved Code of Practice, recognised by the Chartered Trading Standard Institute’s Consumer Codes Approval Scheme. We caught up with Sue Steward, Head of Client and Commissioning at CTSI, to find out more about CCAS and their role in helping strengthen consumer protection.\nWhen was the Consumer Codes Approval Scheme set up and what is its main purpose?\nCTSI CCAS was officially launched in April 2013. CTSI (then TSI) was invited by the government to create a successor to the Office of Fair Trading-run Consumer Codes Approval Scheme (CCAS) as part of the Consumer Landscape Review.\nThe main purpose of the scheme is to improve customer service standards by approving and promoting codes of practice through code sponsors. Code sponsors have to pass a rigorous set of core criteria to become a sponsor, which incorporates a robust assessment to validate the quality of each code of practice. Once successfully completed, the code of practice is approved by the Chartered Trading Standards Institute (CTSI).\nIn addition, the CCAS scheme aims to raise industry standards. Further details are available here: https://www.tradingstandards.uk/media/documents/commercial/consumer-codes-documents/ctsi-code-guide-booklet-2018.pdf\nWhy are Codes of practice valuable?\nConsumer codes are valuable to all of us because they encourage a higher standard of consumer protection and in turn, can increase business standards. Organisations with a consumer code share similar aims to CCAS. They play an essential role in protecting consumers by ensuring businesses adhere to a strict code of practice, which then helps provide customer service standards higher than standard consumer law.\nA Code of Practice means businesses have strict guidance to adhere to, and can demonstrate their commitment to customer service, giving them an edge over other organisations without those standards in place.\nWhat in your view are the most important aspects of good customer service? What do you principally look for in a Consumer Code?\nWhen looking at a consumer code we have core criteria to compare the code against. This is a rigorous set of standards the code of practice must meet, in order for the organisation to become a code sponsor.\nThere are a number of critical elements we look for, including:\n- Clear contract, terms and conditions\n- Ensuring the product or service is protected throughout the whole purchasing journey\n- Access to a clear complaints procedure if needed\nHow robust is the CCAS annual audit?\nAudits commence with an onsite audit in the first year, followed desk top audits in the second and third years. The audits follow a robust process and are undertaken for CTSI by auditing specialists.\nThe Code Sponsors are required to provide comprehensive details of audits they have undertaken throughout the year with their members ensuring the code of practice is being adhered to. All code sponsors audits are displayed on the code sponsor’s dedicated page on the website.\nHow confident can consumers feel in a CCAS-approved Code?\nConsumers can look out for the CTSI approved code logo when searching for a trader and be confident that any approved business they choose has a proven commitment to honest business and higher customer standards. This gives them peace of mind over other business that are not approved.\nYou recently celebrated five years of Alternative Dispute Resolution. What in your view are the key benefits of ADR for consumers?\nAlternative Dispute Resolution is a fast, efficient and often less stressful way of seeking redress when compared to going to court. Key benefits include:\n- The process is relatively informal and easy to follow\n- ADR is often free and therefore more accessible for consumers\n- ADR usually results in a faster conclusion than going to court\n- It is mandatory in many sectors\n- The process is confidential and impartial\nWhat impact do you think COVID-19 will have on consumer protection?\nCovid-19 has heightened the need for consumer protection. More people are, working from home, isolated and potentially vulnerable to untrustworthy businesses and services. This makes consumer protection more important and much more of a focus than ever before.\nWhat developments would you like to see in consumer protection in the future?\nCCAS provides facilitated self-regulation, which aims to bolster consumer protection and improve customer service standards. We would like to see CCAS grow and for more organisations to join in our commitment to increasing consumer protection. The scheme not only benefits consumers, but also helps support businesses throughout the whole purchasing journey too.']	['<urn:uuid:ab181899-10d6-4da6-9f28-6d0a789ee8f0>']	factoid	with-premise	concise-and-natural	similar-to-document	single-doc	expert	2025-05-12T23:47:20.322175	6	46	736
21	When designing structural components made of plastic materials, what percentage of their ultimate strength should be used as the maximum continuous operating stress?	Structural components are commonly designed for maximum continuous operating stresses equal to 25% of their ultimate strength at a specific temperature. This guideline is meant to compensate for the viscoelastic behavior of plastics that result in creep.	"['Plastics are increasingly being used to replace other materials like bronze, stainless steel, aluminum and ceramics. The most popular reasons for switching to plastics include:\nWith the many plastic materials available today, selecting the best one can be an intimidating proposition. Here are guidelines to assist those less familiar with these plastics.\nDetermine whether the component is a:\nDetermining the primary function of the finished component will direct you to a group of materials. For example, crystalline materials (i.e., nylon, acetal) outperform amorphous materials (i.e., polysulfone,Duratron® PEI or polycarbonate) in bearing and wear applications. Within the material groups, you can further reduce your choices by knowing what additives are best suited to your application.\nWear properties are enhanced by MoS2, graphite, carbon fiber and polymeric lubricants (i.e., PTFE, waxes).\nStructural properties are enhanced by glass fiber and carbon fiber.\nOnce you have determined the nature of the application (B&W or Structural), you can further reduce your material choices by determining the application\'s mechanical property requirements. For bearing and wear applications, the first consideration is wear performance expressed in PV and""k"" -factor. Calculate the PV (pressure (psi) x velocity (fpm)) required. Using Figure 1, select materials whose limiting PV\'s are above the PV you have calculated for the application. Further selection can be made by noting the ""k"" wear factor of your material choices. In general the lower the ""k"" factor, the longer the wear life of the material.\nStructural components are commonly designed for maximum continuous operating stresses equal to 25% of their ultimate strength at a specific temperature. This guideline is meant to compensate for the viscoelastic behavior of plastics that result in creep. Isometric stress-time curves are provided here to help you characterize a material\'s strength behavior as a function of time at both room temperature (Figure 2) and at 300°F (Figure 3).\nConsider the thermal requirements of your application using both typical and extreme conditions.\nA material\'s heat resistance is characterized by both its heat deflection temperature (HDT) and continuous service temperature. HDT is an indication of a material\'s softening temperature and is generally accepted as a maximum temperature limit for moderately to highly stressed, unconstrained components. Continuous service temperature is generally reported as the temperature above which significant, permanent physical property degradation occurs after long term exposure. This guideline is not to be confused with continuous operation or use temperatures reported by regulatory agencies such as Underwriters Laboratories UL.\nThe melting point of crystalline materials and glass transition temperature of amorphous materials are the short-term temperature extremes to which form stability is maintained. For most engineering plastic materials, using them at or above these temperatures should be avoided.\nConsider chemicals to which the material will be exposed during use and cleaning.\nMitsubishi Chemical Advanced Materials provides chemical compatibility information as a guideline in this brochure although it can be difficult to predict since concentration, temperature, time and stress each have a role in defining suitability for use. Nylon, acetal and Ertalyte® PET-P are generally suitable for industrial environments. Crystalline high performance materials such as Fluorosint® filled PTFE, Techtron® PPS and Ketron™ PEEK are more suitable for aggressive chemical environments (See Figure 5). We strongly recommend that you test under end-use conditions. Specific chemical resistance can be found on the property comparison chart.\nBefore proceeding to steps 5-7 it may be appropriate to consider additional material characteristics including:\nMaterials with higher tensile elongation, Izod impact and tensile impact strengths are generally tougher and less notch sensitive for shock loading applications (See Table 1).\n|Mechanical Property Comparisons|\n|Nylatron® NSM Nylon||11,000||14,000||475,000||20||0.5||0.25|\n|Acetron® GP Acetal||9,500||15,000||400,000||30||1.0||0.2|\n|Mitsubishi Chemical Advanced Materials PPSU||11,000||13,400||345,000||30||2.5||0.37|\n|Duratron® U1000 PEI||16,500||22,000||500,000||80||0.5||0.25|\n|Duratron® U2300 PEI||17,000||32,000||900,000||3||1.0||0.18|\n|40% GF Ryton* PPS||13,000||24,000||1,000,000||2||1.0||0.02|\n|Ketron® 1000 PEEK||16,000||20,000||600,000||20||1.0||0.10|\n|Ketron GF30 PEEK||18,000||26,000||1,000,000||3||1.4||0.10|\n|Duratron® T4203 PAI||18,000||30,000||600,000||5||2.0||0.33|\n|Duratron® T4301 PAI||12,000||24,000||1,000,000||3||0.8||0.28|\n|Duratron® T5530 PAI||14,000||27,000||900,000||3||0.7||0.30|\nEngineering plastics can expand and contract with temperature changes 10 to 15 times more than many metals including steel. The coefficient of linear thermal expansion (CLTE) is used to estimate the expansion rate for engineering plastic materials. CLTE is reported both as a function of temperature and as an average value. Figure 6 shows how many different engineering plastics react to increased temperature.\nModulus of elasticity and water absorption also contribute to the dimensional stability of a material. Be sure to consider the effects of humidity and steam.\nAgencies such as the Food and Drug Administration (FDA), U.S. Department of Agriculture (USDA), Underwriters Laboratory (UL), 3A-Diary Association and American Bureau of Shipping (ABS) commonly approve or set specific guidelines for material usage within their industrial segments.\nSelect the most cost-effective shape for your part.\nMitsubishi Chemical Advanced Materials offers designers the broadest size and configuration availability. Be sure to investigate all of the shape possibilities — you can reduce your fabrication costs by obtaining the most economical shape.\nConsider Mitsubishi Chemical Advanced Materials\' many processing alternatives.\nRod, plate, strip, profiles,\ntubular bar, bushing stock\n|Large stock shapes|\nNear net shapes\nRod, plate, tubular bar, near,\n|Small Shapes in advanced|\nRod, disc, plate, tubular bar\n|Small shapes in advanced|\nRod, disc, plate, tubular bar\nNote: From process to process, many material choices remain the same. However, there are physical property differences based upon the processing technique used to make the shape.\nDetermine the machinability of your material options.\nMachinability can also be a material selection criterion. All products of Mitsubishi Chemical Advanced Materials in this site are stress relieved to enhance machinability. In general, glass and carbon reinforced grades are considerably more abrasive on tooling and are more notch sensitive during machining than unfilled grades. Reinforced grades are commonly more stable during machining.\nBecause of their extreme hardness, imidized materials (i.e., Duratron® PAI, Duratron® PI and Duratron® PBI) can be challenging to fabricate. Carbide and polycrystalline diamond tools should be used during machining of these materials. To aid you in assessing machinability, a relative rating for each material can be found on the property comparison charts.\nMake sure you receive what you specify.\nThe properties listed in this site are for products of Mitsubishi Chemical Advanced Materials only. Be sure you are not purchasing an inferior product. Request product certifications when you order.\nAll material have inherent limitations that must be considered when designing parts. To make limitations clear, each material profiled in this site has an Engineering Notes section dedicated to identifying these attributes.\nWe hope our candor about material strengths and weaknesses simplifies your selection process. For additional information, please contact Mitsubishi Chemical Advanced Materials\' Technical Services Department.']"	['<urn:uuid:b5493d5a-5ffd-4552-a86d-89c8bbfb5138>']	factoid	direct	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-12T23:47:20.322175	23	37	1074
22	beginner tea brewing methods simple equipment water types effect taste explain filtering versus direct steeping	There are two main brewing approaches - direct steeping with leaves in water, and filtered brewing which separates leaves from liquid using a filter. The filtered method allows more control over brewing time and multiple steeps, revealing different tea flavors with each infusion. For equipment, glass or clean ceramic/porcelain vessels are recommended over plastic or metal which can negatively affect flavor. Regarding water, tap water often contains chemicals that suppress tea's fragrance and character, while distilled water lacks important minerals and dissolved oxygen, resulting in flat taste. Spring water is optimal as it contains beneficial minerals that enhance flavor. When filtering, avoid metal filters touching the tea during brewing as this can influence the taste negatively.	['Method 2: The ‘Filter tea’ method\nThis method is where things get interesting. We begin using separate brewing and drinking vessels, and separate the leaves from the liquor using a filter of some sort.\nWe now have options to experiment with brewing times and tea strength, have more variables to play with and can also get more steeps from the tea.\nThe benefit of multiple steeps (aside from the fact that you get more tea!) is that you can start to really appreciate the different layers and depths of your tea.\nThe first infusion is often very light and fragrant. The second and third steeps tend to be more full and obvious, and the subsequent steepings reveal the deeper, less obvious notes of the tea.\nSome teas give up their best flavour and aroma quickly, and it’s all over within 3-4 steeps, and some can seem like they go on forever, revealing layer after layer as you steep long in to the night.\nTea lingo: Teas that last longer are generally referred to as ‘patient’.\nThe road to mastery begins here\nThis method puts the tools in your hands to begin exploring the wonderful, mysterious world of high end tea for yourself.\nThis is the proving ground that raises you up from nervous novice to ‘gong fu tea’ pro.\nThe best part?\nIt’s really easy to do, you don’t need to purchase expensive equipment, and when you do it right the quality of tea you can brew is genuinely high quality.\nI use this method when I am working or moving around. For example: I will have a bowl on my desk to drink from, and use a glass flask to brew the tea easily, as I move around the office or home.\nAnother common use case is when travelling. Often, you don’t have space to bring your entire gongfu set up, so levelling down using simple ‘filter tea’ principles is ideal.\nWhy ‘Filter Tea’?\nI call this method ‘filter tea’, because that’s the extra factor we bring in to level us up from Method 1: Leaves in method.\nThe concept of ‘filter tea’ is very broad, and simply means that we will filter the tea between brewing and drinking.\nThe classic ‘English Teapot’ (often referred to as ‘Western brewing’) fits into this method, as does a glass teapot or flask with a metal filter built in, a french press (commonly used for coffee) or even a strainer ball inside your cup (although I don’t like this method as you are brewing with metal in your tea).\nIf you do use a french press, try to use a new one, not one that has been used for coffee. Coffee has a particularly lingering presence, and tea is particularly absorbent and easily affected by other aromas. You will lose the lighter, more subtle notes of Living Leaf Tea if you are brewing in a ‘coffee flavoured’ pot.\nDon’t brew in plastic or metal\nI prefer to work with glass or clean ceramic / porcelain for this method. Avoid using plastic or metal as it will influence the flavour and energy of the tea negatively.\nYou will notice that all the pictures above (which were found online) have some element of metal touching the tea while brewing, with the exception of the french press, in which the metal part can be raised above the water while the tea is brewing.\nFor this reason, I prefer to use a glass flask with a smaller filter, like this:\nThe metal filter on these flasks is raised above the water when brewing, and can be easily removed from the flask when adding hot water.\nThe double-walled glass is great for preserving heat and they are also very clean and easy to use.\nI use it almost every day, especially when travelling or working.\nThese flasks are my number one recommendation for brewing Filter Tea, and you can purchase one directly from us if you like:\nThe Steps: How to brew ‘Filter Tea’\nFor this method you will need:\n- Loose leaf tea (all Living Leaf Teas work well with this method)\n- Hot water\n- A vessel to brew the tea in (See above)\n- A filter (usually attached to the brewing vessel)\n- A bowl or cup(s) to drink the tea from\nImportant note: make sure the cup(s) you intend to drink the tea from are larger than the vessel you choose to brew the tea in!\nYou need to be able to completely empty the brewing vessel after each infusion. If you can not, the remaining water will continue to brew the tea, and it will become stewed.\nBrewing this way takes about as much time as it does to prepare a filter coffee (maybe slightly faster), but less messy and you get multiple brews!\nThe steps are as follows:\nStep 1: Add leaves to your brewing vessel\nAdd tea leaves to your brewing vessel (teapot, glass flask, french press etc).\nA rough guide is about the same amount as you would find in a tea bag, but you may want to add more depending on the size of your pot (if you would usually add two tea bags to a large teapot for example, use the equivalent amount of dry leaves).\nStep 2: Add hot water and brew\nPour hot water into the brewing vessel and allow the tea to ‘brew’.\nYou may wait anything from 5 to 60 seconds, depending on how much dry leaf you used, how strong you like your tea, how hot the water is etc. Start with 10-15 seconds and see how the tea comes out.\nThis is going to be the fun part that you experiment with over time.\n(Note: in the picture my metal filter is above the water while brewing. Brewing with metal inside the water tends to influence the flavour of the tea negatively.)\nStep 3: Pour (filter) the tea\nPour the tea through the filter into your drinking cup(s).\nStep 4: Enjoy your tea & brew again\nYour tea is ready as soon as it is cool enough to drink. You may enjoy smelling the fragrance of the tea in the cup at this stage, and you can also try smelling the wet leaves and steam coming from the brewing cup. An enjoyable fragrance is one hallmark of a high quality tea.\nThe wet leaves (pictured) can be brewed multiple times, depending on how much leaf you used and how long each of your brews are. At least 3-4 brews is a general guideline for this method.\nRefining your Filter Tea Game\nBONUS STEP 1: Wash and ‘wake up’ your tea before brewing\nIf you’re ready to start working on your tea game, you can add add an extra step between steps 1 and 2.\nAfter you have added your leaves, but before you brew the tea, you can add some hot water (less than the amount of a full brew) give the tea a quick ‘swirl’ and then discard the water (using the filter, so the tea leaves stay in the pot!).\nThis extra step has the effect of cleaning the leaves, ‘waking them up’ (getting them ready to be brewed) and releasing some of the fragrance for you to enjoy.\nI personally find it very ‘hard’ to brew without this step. Once you begin brewing with a wash pour, you will find it makes a nicer first infusion.\n(Note: You have just taken your first step on the path to brewing ‘Kung Fu tea’ like a pro!)\nBONUS STEP 2: Pre-heat your cup and brewing vessel\nPreserving the heat is one of the most important aspects of brewing high quality tea (as we will learn about in ‘Method 3: Gong Fu Tea’ next). So for super bonus points, pre-heat everything by pouring hot water through your vessels before adding the dry leaf.\nAdd the hot water to the brewing vessel (including pouring it through the filter), then pour it out into your cup. Now add the dry leaf to the empty, but warm, brewing vessel.\nWait just a few seconds… and now smell the dry, warm leaf in the brewing vessel. Doesn’t that smell wonderful?\nNow go ahead with your wash pour or first infusion.\nThis method is super simple, and my ‘most used’ method as I go about my day (ie. I am not sat down at my gongfu tea table). It is also very flexible. As long as the principles of ‘Brewing vessel -> Filter -> Drinking cup’ are held to, you can experiment freely with what you use for each of the vessels and filter.\nTea can be infused this way 2-3 times at a minimum, and up to 5-6 or more depending how long you are brewing for, how much leaf you used and the temperature of the water.', 'In today’s post, we’re going to look closely at some of the most commonly encountered problems and questions tea drinkers have when attempting to brew green tea.\nIf you’ve ever wondered how long to wait between infusions or what to do when you don’t have a variable temperature control electric kettle, you will find the following FAQ immensely helpful.\nQ1. I use a stovetop kettle and thermometer for my teas. Am I supposed to let the water boil first for my green tea? I just don’t have the time to wait that long for it to cool down.\nWe always recommend that you boil the water first, letting it cool down to 180° F (82°C) before pouring it over your green tea. Of course, the drawback is that you’ll need to wait a moment, but fortunately, there are ways to cool your water down more quickly.\nWhat’s the solution?\nFor one, take care to ensure that your teaware is made of glass or porcelain, materials that allow heat to escape faster (unlike stoneware, which holds on to the heat). While it may be tempting to put your gaiwan or Yixing teapot to good use, these are not ideal for brewing green tea. Instead, we would recommend investing in something like a glass teapot.\nWhen you’re ready to brew your tea but you’re pressed for time, a technique to cool your water down is to set aside two cups, bowls, or servers, and then transfer the water in and out of each until it reaches the desired temperature.\nQ2. How long are you supposed to brew your green tea? I seem to get mixed messages about this from different sources, some claiming 30 seconds, 1 minute, or even as long as 3 minutes. Can you clarify this?\nHow long you brew your tea depends on the leaf to water ratio, the type of green tea, and your personal preference. Steeping longer, for example, will always result in a stronger flavor, but for some green tea, it will also introduce bitterness.\nFor your first infusion, we recommend a water temperature around 80–85°C (175–185°F) and an infusion time around 1–2 minutes. The goal is to bring out complexity and nuance while minimizing astringency and bitterness, and much of this depends on the type of tea you’re steeping. For hardier green teas (such as Anji Bai Cha), a steeping time closer to 2 minutes will do the trick, but for more delicate green teas (like Dragonwell), any time longer than 1 minute could result in bitterness.\nIt is important to remember that things change a little when it comes to subsequent steeps though.\nWith your second steep, we usually advise shortening the infusion time since the tea leaves are already saturated and opened, unlike the initial infusion (opened leaves will release more flavor into the water more quickly); but with the third steep, you’ll want to do the opposite and increase your infusion time, in some cases even as long as 3 minutes. Because green teas are usually only steeped 2 or 3 times, the 3rd infusion will demand the most patience for extracting any remaining flavor after the first 2 steeps.\nIt’s important to keep in mind, however, that this only applies to green teas. Oolongs and pu’erhs, for instance, can be steeped around a dozen times (with high-quality pu’erhs even known to withstand more than twenty infusions).\nQ3. I try to measure out my tea, but what is a good tea to water ratio? I’ve seen places suggest 4g of tea to 6oz, 8oz, and even 12oz of water.\nIt’s important to know how much volume your mugs, teapots, and gaiwans can hold; otherwise, you may be using too much or too little water, both of which can adversely affect the overall taste.\nWhen working with your usual quantities, such as 6–8oz of water, we can make the following recommendation:\n- 2g–3g tea leaves: 6–8oz water\nIf you wish to use more or less water, however, things can begin to get a little tricky. Much of this boils down to trial and error. For instance, you might discover that you can double your total number of infusions with 2g of tea and just 3oz of water, but then that also requires more frequent infusions. Aim to find your balance between convenience, cost, and desire.\nUltimately, the best outcome with your green tea depends on the water to leaf ratio, temperature, infusion time, and water quality. Any amount of tea can be prepared with an appropriate adjustment to the guidelines above. These are tried-and-true ratios that guarantee the best taste for your tea and the most bang for your tea leaves.\nQ4. I know that you can resteep your teas, but sometimes my second steeping doesn’t taste quite right. How long can you let your used leaves sit around? How long can you wait between infusions?\nTo get the most out of your tea, then, you will want to take care not to wait too long between infusions. In a perfect world, you would re-infuse your tea leaves within 5–10 minutes of your previous infusion (like what you find during a Gong Fu Tea Ceremony), but at a minimum, we recommend waiting no longer than 90 minutes between infusions, assuming the leaves are not soaking in water and you’ve completely emptied your teapot or gaiwan.\nWhile there can be some flexibility, depending on your taste preferences, for both health reasons and optimal tasting quality, we certainly wouldn’t recommend using wet leaves that are more than a few hours old.\nQ5. I’ve heard that you should leave some water to cover your leaves between infusions. Is this true? What purpose does this serve? Wouldn’t this make your tea too concentrated?\nThe reason for letting your leaves soak in some water between infusions is to even out the tea flavor over several steepings. To do that, you need only a little bit of water leftover, just enough that it nearly covers the remaining leaves. If you use too much or too little water, you defeat the purpose of this technique.\nIf you decide to try this method out, however, you will want to take care not to wait too long between infusions. Around 5-10 minutes can be fine (although pushing it), but we cannot recommend letting your leaves steep in a little bit of water any longer than that. If you wait as much as an hour, for example, you’ve created a recipe for terrible tasting tea, introducing astringency, bitterness, and worse to your cup.\nQ6. I see on your website and packaging that you recommend we use filtered water and spring water. What’s wrong with distilled water or tap water? Can I still use these?\nIn many cases, tap water can be laden with too many chemicals that can suppress the fragrance and character of the tea. For example, in some places, there is a very real concern that heavy metals such as lead, nickel, or copper have reached concentrations in the water that are unsafe for long-term consumption. Besides these concerns, there’s also the chlorination and fluoridation treatments used to clean tap water, treatments that sometimes result in a funny taste. While you may get used to this taste, unable to notice it anymore, the very presence of these chemicals still prevents your tea from releasing an optimal amount of flavorful and aromatic compounds into the water, risking an underwhelming cup of tea (and in some cases, even tea that tastes sour, metallic, or salty). This means that even at low concentrations, these chemicals decrease the quality of your cup.\nWhen it comes to distilled water, there’s a different set of issues. This type of water lacks dissolved oxygen and other important minerals that can enhance flavor, such as magnesium, zinc, and potassium. The oxygen is what gives your water a liveliness while the minerals impart a taste. Distilled water, in contrast, is flat and bland, and these same qualities carry over to the tea you make with it, resulting in a flat and bland cup.\nPer our experience, spring water guarantees the best results. Of course, you’ll need to experiment a little to discover which brand is best for your tea. Since each brand has a different combination of minerals in the water, each will affect the outcome of your cup a little differently.\nWe hope you’ve enjoyed this Green Tea FAQ, and if you have any other questions, please feel free to post them below!']	['<urn:uuid:7fdbe3be-8368-406e-acd4-fe2c30c43a30>', '<urn:uuid:dcfa97ed-7471-42ff-afb7-228d4843e86b>']	open-ended	with-premise	long-search-query	distant-from-document	multi-aspect	novice	2025-05-12T23:47:20.322175	15	116	2887
23	Which hiking gear considerations change between summer hiking and snowshoeing?	Summer hiking and snowshoeing require different gear considerations. For summer hiking, the focus is on sun protection (hat, sunscreen, sunglasses) and staying hydrated with plenty of water, especially during afternoon hikes when temperatures are highest. For snowshoeing, the emphasis is on specialized footwear - waterproof boots with proper insulation, non-compressible uppers for secure binding attachment, and rigid soles for energy transfer. While both activities benefit from layered clothing, snowshoeing requires specific attention to boot fit to accommodate thicker socks while maintaining circulation.	['Snowshoes come in different types for the terrain and your boots and other gear should match your specific snowshoe model. For challenging terrain, rigid and sturdy boots work well. Crescent Moon foam snowshoes work great for almost all terrain and are the perfect low-impact snowshoes.\nTypes of Shoes to Wear Snowshoeing\nYou can have the option of different types of shoes to wear while snowshoeing.\nSnowshoes and Winter Boots:\nIf you are only an occasional snowshoer and you tend to travel on groomed terrain then a simple pair of winter boots can suffice. If you would wear those boots in the snow anyway then there is a good chance the boots can be worn with snowshoes. Regular winter boots may be stiff, heavy, and don’t breathe well. If you are going to be going out for a long walk then these may not be the best solution.\nSnowshoes and Hiking Boots:\nHiking boots can be the best option for snowshoeing, as long as they are insulated and warm. Hiking boots can keep your feet dry despite the snow and give you good ankle support. They help your feet breathe and the design creates a comfortable and natural stride.\nSnowshoes and Alpinism Boots:\nFor large expeditions or where the terrain is rough or icy, some may want to wear mountaineering boots. These boots can offer you good protection against humidity and cold but may not be the most comfortable option.\nKey Considerations for Shoes to Wear Snowshoeing\nA good winter boot will keep your feet dry and warm and will prevent you from unnecessarily expending energy and strength. A good and secure fit means your feet stay put within the boots. The sturdy upper part will allow you to attach the snowshoes without compressing your shoes or putting any pressure on your feet. A stiff sole will allow for optimal transfer of energy and properly bind the snowshoes to your boot.\nSnowshoe Boot Warmth:\nIn the winter, you need to stay warm. Boots help you stay warm with a combination of a liner and insulation. The material traps heat to your body and keeps the cold out. In order to save weight, manufacturers use synthetic materials. On some models, you may find that there is a reflective liner in order to further increase the warmth. Your blood needs to circulate in order for your feet to stay warm so there should be sufficient room in your boot.\nSnowshoe Boot Waterproofing:\nBoots for snowshoeing need to be waterproof. The sole usually acts as a bottom layer and the material on the top repels water. Many boots have a combination of both synthetic material and leather in order to help with breathability. The tongue of the shoe is important for keeping water out. If moisture does get into your shoe then your feet will be cold, depending on the liner. A liner from sheepskin or felt will continue to insulate even when wet.\nSnowshoe Boot Comfort and Fit:\nThe proper fit is not only important to the comfort of the shoe but also to provide protection for your toes and ankles. Boots should cover and secure the ankle. The deeper the snow, the higher the shaft needs to be in order to keep out snow. Full height to the knee is overkill since the purpose is to prevent you from sinking too deep into the powder. If your feet move around in the shoe too much then you will tire out faster while snowshoeing. You need enough room in your shoe to have thicker socks and to maintain circulation.\nSnowshoe Boot Stiffness and Stability:\nA non-compressible and sturdy upper is needed so you can fit your snowshoe bindings securely and tightly and prevent your shoes from shifting. A soft toe box becomes squished by binding straps, which can cut off your circulation.\nSnowshoe Boot Traction:\nThe traction will depend on your equipment. A rigid and thick sole helps transfer energy better. Winter boots usually have a sole similar to a snow tire with a large surface area, sticky rubber, and deep lugs.\nSnowshoe Boot Extras:\nWhile extras aren’t necessary, they can be nice to have. Manufacturers can make it easy to get in and out of boots with a quick lace system. Insoles may be removable to help dry out shoes. On some models, you can find ways to attach gaiters and features that help with snowshoes, such as toecaps. Crescent moon booties add another layer of protection against cold, snow and wetness.', 'If you’ve been hiking before, you know that the right time, temperature, and weather system can make all the difference on your trip.\nThe best time to go hiking is during the Summer, Fall, and Spring seasons. In general, the best times of the day to hike are at 6:00 am to 9:00 am and 2:00 pm to 7:00 pm. Midday hikes may be best during winter since this will be the warmest time of the day.\nLet’s dig in a bit deeper to get a better understanding of what you should be considering when looking for the perfect time to go hiking.\nHiking in the Morning\nMorning hikes are the most popular and go hand-in-hand with the majority of people’s work schedules. Here are some pros and cons of taking a morning hike:\nPros of Hiking in the Morning\n- The trails will be less crowded.\n- You are likely to catch a beautiful sunrise if you begin your hike early enough.\n- The temperatures will be cooler if you’re hiking in the warmer months.\n- You will have plenty of energy for your day as well as some time to relax after your hike.\n- Morning hikes are the best for ensuring a good night’s sleep.\n- Hiking in the morning is safer. If you have an injury or emergency, it’s more likely that someone will find you on the trail throughout the day.\nCons of Hiking in the Morning\n- You will need to get up earlier than you’re used to.\n- Be prepared for higher humidity and dew on the ground (especially if hiking during Spring or Fall).\n- It may be quite cold, especially during early Spring, late Fall, and Winter.\n- If you’re hiking before work, you’ll need to make sure you make it back in time to begin.\nHiking at Sunrise\nSome of the most beautiful hikes happen during sunrise, especially when you can catch a glimpse of the sun as it comes over mountains, creating some amazing colours on the ground. You can make sure that you catch this beautiful moment by looking up the sunrise time for your hike.\nTry to time out your hike so you arrive at an area with a scenic view right at the time that the sun rises. Since most hikers won’t be on the trail this early in the morning, you may have the opportunity to watch it in peace and quiet.\nHow to Prepare for a Morning Hike\nIf you’re taking a morning hike, make sure that you:\n- Wear layers and be prepared for the weather to change.\n- Lay your hiking clothes and gear out the night before to make sure you can leave as early as possible.\n- Drink water and eat a light snack before your hike.\n- Pack an extra pair of socks in case your feet get wet or sweaty from morning dew.\n- Keep an eye on the sunrise time and note how that changes the weather or temperature.\nHiking in the Afternoon\nHiking in the afternoon is very common, especially on weekends. Some people like to hike before work or after they get off of work in the mid to late afternoon, while others prefer doing it during lunchtime.\nHere are some pros and cons of taking a late morning hike:\nPros of Hiking in the Afternoon\n- You don’t have to wake up early and can usually be more flexible with your time.\n- It tends to be the most agreeable time to plan a group hike. It’s also a great time to hike with a family or small children who may be sleeping in the morning or evening.\n- You are likely to have many other people on the trail with you, which can be fun for people and dog watching.\n- It will be the warmest and brightest time to hike in winter.\n- It’s the safest time to hike since you’re likely to run into more people on the trail.\nCons of Hiking in the Afternoon\n- You may not catch a sunrise or sunset if those are important factors for your hike.\n- In summer, early fall, and late spring, the temperature will climb quickly.\n- The trails will likely have more people on them throughout the day, so if you prefer hiking alone, it may be too busy.\nHow to Prepare for an Afternoon Hike\nHere are some tips on preparing for your afternoon hike:\n- Wear layers so that you can easily take them off if the sun starts shining too brightly or put them back on as it begins getting colder.\n- Make sure you have a hat, sunscreen, and sunglasses.\n- Pack a small snack that will give you some energy but not make you feel bloated or tired on your hike. Some examples include fruit with peanut butter on crackers, an apple with cheese sticks, grapes, granola bars, etc.\n- Since this will be the hottest time of the day in the warmer months, make sure to bring plenty of water with you. If you can carry it, bring twice the amount of water that you plan on drinking.\n- Keep an eye on the time as well as your pacing if you’re trying to avoid night hiking.\nHiking at Night\nOne of the most unique experiences you can have on a hike is to take it at night. If you’re not used to hiking in the dark, this may be quite scary or intimidating for some people, but if done with caution and preparation, these hikes are very rewarding and serene.\nPros of Hiking at Night\n- You’ll see things differently than you do during the day.\n- If you’re hiking in an area with no light pollution, it can be extremely beautiful at night, especially if there are stars outside.\n- You may catch a gorgeous full moon\n- You’ll have the whole trail to yourself, which some people find very relaxing.\n- You may be able to catch a sunset depending on your timing.\nCons of Hiking at Night\n- It will be dark on your way home, so you will have to be careful since it will be more dangerous.\n- If it’s cold outside, the temperature will drop even more at night, so you’ll need to make sure that you’re prepared for extreme temperatures.\n- You need to be very familiar with the trail and surrounding area.\n- If you are injured or have an emergency on the trail, it’s unlikely anyone will be coming along the trail to find you until the morning.\n- You may miss some beautiful views since it’s dark outside.\n- Depending on the terrain, there may be certain animals that are more active at night, so be careful.\nHow to Prepare for a Night Hike\n- Make sure to bring a headlamp or flashlight with you and make sure that it is charged or has fresh batteries.\n- It’s always good to hike with another person, but it is especially important at night since you never know what could happen.\n- Wear clothing with reflective materials so that if someone does come driving down the trail, you’ll be easy to see.\n- Make sure to wear warm enough clothes when hiking during the colder months. The temperature can exponentially drop, especially if you’re rapidly changing your altitude.\n- Be aware of the sunset time and make sure to start your hike within that time frame.\n- Make sure you don’t get lost in the dark by bringing a map and compass.\n- It will be very difficult to navigate at night with no light, so if you don’t have a headlamp, ensure that your phone is fully charged before going out.\nHiking at Sunset\nEven though it’s more dangerous to hike during the evening or night, there is something so special about watching the sun go down and seeing all of the colours at sunset. If you want to try this out for yourself, make sure that you’re aware of how long it takes to get back from your hike before heading out.\nYou will also want to make sure to look up the time of sunset in the area and align your hike by finding a scenic view as the sunsets. It’s best to make sure that your scenic view is close to the end of your hike, so you can make it back home or to your transportation before it becomes completely dark.\nHiking in the Spring\nHiking in the Spring provides the best of both worlds. You get to experience the changing of seasons with different types of flowers, trees, and critters. The weather is also very forgiving since it’s not too hot or cold outside.\nIn Spring, the weather can be volatile. It can suddenly rain or snow during the day, so you’ll want to make sure you have waterproof or resistant clothing.\nThe temperature can also fluctuate, so dressing in layers is a great idea to make sure that you can regulate your body temperature.\nHiking in the Summer\nSummer hiking is great for people who don’t mind high temperatures because there are so many beautiful places to hike. It’s also an ideal time for campers to hike since it’s warm enough for them to comfortably spend the night.\nSummer tends to be an extremely busy time of the year for most hiking trails. If you want to avoid the busy season, try going on a hike early in the morning or later at night when it’s cooler outside and there are fewer people out.\nThe light also lasts longer in the summertime, giving you a bigger window of time to hike before it gets too dark.\nAs long as you make sure to stay hydrated and protect yourself from excessive sunlight, summer is one of the most flexible and enjoyable seasons for hiking.\nIf it’s getting too warm, find trails that are mostly shaded or that lead to bodies of water that you are allowed to access. This will make a huge difference and ensure that you don’t become fatigued on the trail.\nHiking in the Fall/Autumn\nThe leaves are changing colours and everything is starting to become dormant for winter, which makes hiking during fall an amazing experience! You’ll be able to see a variety of trees with different types of foliage while also being a bit more stable than in springtime, but you can still expect some rain as well as quickly changing temperatures.\nMany hikers prefer to head out in the mornings and afternoons during the autumn because the temperatures are best. Going out on a bright and sunny day is ideal in the fall since it won’t be as hot as it is in the summer.\nHiking in the Winter\nWinter hiking is unique in that you can see the beautiful snow-covered landscapes. Although it might seem like a good idea to go out on the trails after fresh powder falls, you should wait until there are at least four inches of packed snow before going hiking, as only then will your footprints not damage any vegetation around.\nIt will also be more stable for you to walk on, making it safer. The best time to go hiking in the winter is late morning and afternoon so that you can maximize the heat from the sun. The days will be shorter, so you’ll have to pay attention to the sunrise and sunset times.\nJust like summer, you’ll want to dress in layers so that you can keep yourself warm while also protecting your skin from the elements. It’s important not to forget a hat and gloves since these exposed areas can get cold without proper protection.\nWhat Is the Best Weather to Hike In?\nGo on a cloudy day if you’re afraid of getting sunburned or overheated; clouds provide shade and can make for comfortable hiking conditions. If it’s cold, try wearing layers so that you can take them off once you start heating up during your hike and put the extra clothes back on.\nWindy and breezy days are also great for hiking since the wind can cool you down and keep your body temperature regulated. Just make sure that the wind won’t become too stormy, especially if you’re hiking in an area where there are unprotected ledges and it’s important to keep your footing secure.\nSunny, cool days are also perfect for hiking since there is enough warmth to keep you comfortable but not too much where it could become overwhelming or dehydrating.\nDon’t be afraid to hike on rainy or snowy days, as long as you are in areas where there aren’t slippery, uneven rocks. If you want to take on more rugged terrain, you can purchase shoes or boots that are made for hiking in the rain or snow.\nThere is no “bad” weather to hike in, just different challenges that you’ll have to face while being outdoors. If it’s a bit colder or windier than normal then be sure to dress accordingly and protect yourself from the elements.\nGo out and enjoy nature if you can safely manage it year-round! There is so much to learn and explore from each season, time of day, and different weather conditions. If you experiment, you’ll find the hiking time that is just right for you.\nLooking for more hiking guides and essential advice ahead of your next trip? We’ve got you covered.']	['<urn:uuid:600d0dee-27d5-4e4a-a3eb-9c04768fb39e>', '<urn:uuid:3a6ce548-d026-4009-9c72-9a2b58b4c038>']	open-ended	with-premise	concise-and-natural	similar-to-document	comparison	expert	2025-05-12T23:47:20.322175	10	82	2999
24	locate mac address firestick steps	To find the MAC address on a Firestick: First, connect to WiFi and press the Home button on the controller. Go to Settings, then My Fire TV, followed by About. Select Network, and the MAC Address will be displayed on the right side of the screen along with other network information like IP Address, Gateway, Subnet Mask, and DNS Address.	['When a device is linked to a local network, its MAC (Media Access Control) address, a distinctive identifier allocated to each network card, makes it simple to recognize the device. Even with Firestick, the MAC address is frequently written on the device’s bottom. The network card on your device has a special address called a media access control address (MAC address). It functions somewhat similarly to a postal address, except that a network distributes internet traffic to your device instead of your mailbox receiving mail. If you cannot physically locate the MAC address on your Firestick, you can use the settings to do so. Reading this post, you may learn how to locate the MAC Address on a Firestick. Consequently, let’s begin:\nRead Also: How to Install SoundCloud on Firestick\nHow to Find MAC Address on Firestick\n1. Join a WiFi network using your Firestick.\n2. Press the Home button on your Firestick controller to access the home screen.\n3. Navigate to the Settings button.\n4. From the Settings menu, choose My Fire TV.\n5. Click the About link next to that.\n6. Select the Network option by moving the cursor down.\n7. Along with the IP Address, Gateway, Subnet Mask, and DNS Address, the MAC Address is displayed on the right side of the screen.\nUsing Router Admin Panel:\n1. Open a browser or connect your PC to the router using WiFi or LAN. The address of the router’s administrative panel.\n2. Enter your Username and Password in the corresponding boxes to log in.\n3. Select the Connected Devices option after logging in.\n4. The list of linked devices will be given to you. Select a name for your Firestick.\n5. You may find your MAC address underneath your Fire TV.\nWhat is a MAC address?\nThe network card on your device has a special address called a media access control address (MAC address). It functions somewhat similarly to a postal address, except that a network distributes internet traffic to your device as opposed to your mailbox receiving mail.\nIs Wi-Fi address the same as MAC address?\nSelect Network. Toggle to Wi-Fi. Select “Advanced” from the menu. Your wireless MAC address is known as the Wi-Fi address.\nWhat is MAC address and IP address?\nA device is identified by its physical address, also known as its media access control, or MAC, address, to other devices connected to the same local network. The gadget is uniquely identified internationally by its internet address or IP address. Both addresses are required for a network packet to reach its destination.\nDoes MAC address change with WIFI?\nFirst, unlike IPs, which might vary based on location and are used to identify network devices globally, MAC addresses are static and only used in local networks. Additionally, unlike IP addresses provided by the network administrator or ISP (internet service provider), MAC addresses are assigned by the hardware manufacturer.\nIs MAC address permanent?\nThe MAC address is indeed permanent. All network adapters are given MAC addresses at the time of manufacture, and each networking device’s MAC address is distinct.\nCan I delete my MAC address?\nChoose MAC ACL under Configuration > Security > Basic. The screen for MAC authentication basics appears. Select the check boxes next to the MAC addresses that you want to delete in the Selected Wireless Clients list. Press the Delete key.']	['<urn:uuid:60d796e7-5c3d-4688-9438-39adc60df134>']	open-ended	direct	short-search-query	similar-to-document	single-doc	expert	2025-05-12T23:47:20.322175	5	60	558
25	inactive dehydrated yeast cells preservation market segments applications	Dehydrated yeast cells are preserved in a nonliving condition through controlled drying conditions in large vats. In the market, these are segmented into different products including fresh yeast, dry yeast, and instant yeast, with applications across various sectors such as food & beverages (including alcoholic beverages, non-alcoholic beverages, bakery products) and animal feed.	"['There is a miracle in my refrigerator.\nI\'m not referring to the leftovers from the delicious lamb curry that my wife, Linda, prepared last night for supper. I\'m referring to something even more spectacular.\nCan you guess what it is?\nHere\'s a clue — bakers and pastry-makers routinely experience this miracle. Give up?\nIt\'s a packet of dry yeast.\nBefore you say, ""No way, Steve,"" consider the marvel in this package. Inside is a tan-colored, granular substance, which is comprised of yeast cells that have been dried and coated with an inert material.\nThe cells show no signs of life. No metabolism. No reproduction. No growth. For all practical purposes, the yeast is dead.\nBut the cells aren\'t really dead. They are waiting in a state of suspended animation for a little water to rouse them from their sleep, much like the prince\'s kiss did for Sleeping Beauty.\nAdd warm water and in about the time it takes to hard-boil an Easter egg, the yeast cells will be growing, metabolizing and dividing — oblivious to their deep slumber.\nIn short, the yeast cells have undergone the wonder of resurrection.\nThe yeast cells were originally grown in large vats and then dried under controlled conditions. The cells went from an active living state to a dry nonliving condition, and finally in our kitchens they are revived with water.\nBiologists call this phenomenon in which an organism can be dried and then rehydrated anhydrobiosis.\nAnhydrobiosis is an adaption that evolved in organisms that live in environments where moisture availability is sporadic. A variety of microscopic animals, such as rotifers, nematodes and tardigrades, as well as fungi such as yeast, and even a few plants such as rusty woodsia (Woodsia ilvensis) are capable of resurrection.\nIf you\'ve hiked around Quarry Park & Nature Preserve in Waite Park, you may have seen rusty woodsia. This fern grows in the cracks and crevices on the rocky outcrops.\nWhen there is adequate rain, rusty woodsia looks like an ordinary fern with expanded green fronds. However, during dry periods, the fronds curl up and turn brown and the plant looks dead. A subsequent rain will kiss it back to life.\nYeast and rusty woodsia are able to resurrect because they evolved a clever mechanism to protect their cells as they dry. Unlike humans and most other organisms, the cells of anhydrobiotic organisms produce a special sugar called trehalose that acts a little like a referee to prevent irreversible chemical reactions between the dried cell components. Without trehalose, a cell can\'t be revived when it is rehydrated.\nThe practical implications of anhydrobiosis are enormous. For example, if we can figure out how to load trehalose into blood cells, the blood could be dried down and would have a long shelf life without the need for continuous donations.\nAll of this talk about yeast, bread and lamb curry is making me hungry. I think I\'ll go check out what new miracle Linda has waiting for me in the refrigerator.\nThis is the opinion of Stephen G. Saupe, a professor in the biology department of the College of St. Benedict and St. John\'s University and director of the CSB/SJU Bailey Herbarium and Melancon Greenhouse. He can be reached at firstname.lastname@example.org.', 'Global Yeast Market\nThe global Yeast Market was valued at USD 3.04 billion in 2016 and is projected to reach USD 6.44 billion by 2025, growing at a CAGR of 8.7% from 2017 to 2025.\nYeast is one of the most widely used micro-organisms for manufacturing food & beverages. It is used in the process of fermentation and imparts a better texture, taste, and aroma to the food products. This product has witnessed growing demand courtesy an increase in the consumption of functional bakery foods and alcoholic beverages.\n1. Market Drivers\n1.1 Growing demand functional bakery products\n1.2 Growing demand from the alcohol industry\n1.3 Growing demand for bioethanol as a fuel\n1.4 Increasing awareness about the importance of yeast as compared to its alternative Monosodium Glutamate (MSG)\n2. Market Restraints\n2.1 Scarcity of raw materials\n2.2 Stringent food safety standards and regulations\nThe global Yeast Market is segmented on the basis of Product, Type, Application and Region\n1. Global Yeast Market, by Product:\n1.1 Fresh Yeast\n1.2 Dry Yeast\n1.3 Instant Yeast\n2. Global Yeast Market, by Type:\n2.1 Baker’s Yeast\n2.2 Wine Yeast\n2.3 Brewer’s Yeast\n2.4 Bioethanol Yeast\n2.5 Feed Yeast\n3. Global Yeast Market, by Application:\n3.1 Food & Beverages\n3.1.1 Alcoholic Beverages\n3.1.2 Non-alcoholic beverages\n3.1.3 Bakery Products\n3.2 Animal Feed\n4. Global Yeast Market, by Region:\n4.1 North America (U.S., Canada, Mexico)\n4.2 Europe (Germany, UK, France, Rest of Europe)\n4.3 Asia Pacific (China, India, Japan, Rest of Asia Pacific)\n4.4 Latin America (Brazil, Argentina, Rest of Latin America)\n4.5 Middle East & Africa\nThe major players in the market are as follows:\n1. AB Mauri Food\n2. AB Vista\n4. Chr. Hansen\n7. Archer Daniels Midland Company\n8. Kerry Group PLC\n10. Nutreco N.V.\n11. Synergy Flavors\n12. Oriental Yeast Co., Ltd\n13. Koninklijke DSM N.V.\n14. Angelyeast Co., Ltd.\n15. Associated British Foods PLC\nThese major players have adopted various organic as well as inorganic growth strategies such as mergers & acquisitions, new product launches, expansions, agreements, joint ventures, partnerships, and others to strengthen their position in this market.\nRESEARCH METHODOLOGY OF VERIFIED MARKET INTELLIGENCE:\nResearch study on the Yeast Market was performed in five phases which include Secondary research, Primary research, subject matter expert advice, quality check and final review.\nThe market data was analyzed and forecasted using market statistical and coherent models. Also market shares and key trends were taken into consideration while making the report. Apart from this, other data models include Vendor Positioning Grid, Market Time Line Analysis, Market Overview and Guide, Company Positioning Grid, Company Market Share Analysis, Standards of Measurement, Top to Bottom Analysis and Vendor Share Analysis.\nTo know more about the Research Methodology of Verified Market Intelligence and other aspects of the research study, kindly get in touch with our sales team.\nVerified Market Research has been providing Research Reports, with up to date information, and in-depth analysis, for several years now, to individuals and companies alike that are looking for accurate Research Data. It has large database which includes the latest content from renowned authors and publications worldwide. It also provides customized Data and Reports according to the need of the client.']"	['<urn:uuid:f1191bdc-4408-48ab-801d-176ccbd0314d>', '<urn:uuid:edda0c5e-c719-489a-87ec-9a545fb117cc>']	factoid	direct	long-search-query	distant-from-document	multi-aspect	expert	2025-05-12T23:47:20.322175	8	53	1069
26	ways stop spreading harmful plants before they grow	Prevention is the first line of defense against weeds. Key preventative measures include: planting high-quality weed-free crops or grass seed, promoting strong competition from desirable plants, keeping weeds from going to seed, using proper mulching (50-100mm depth), regular lawn mowing, and maintaining healthy grass through proper fertilization. These methods help prevent new weed infestations from occurring.	['A major component of the Undesirable Plant Management Plan is the requirement to provide Douglas County Property Owners with technical assistance in determining methods to control or eliminate their weed problems. Staff continues to insure County-owned properties are under treatment for weeds, as well as working with other public entities to assist them in their weed control problems.\nPrevention, eradication, and control are three general weed management strategies. Be a good neighbor and control your noxious weeds.\nPrevention is the first line of defense to keep weeds from growing in an area. Planting high quality, weed-free crops or grass seed is the basis for good land management. Plant competition is an effective way to prevent the invasion of noxious weeds and proper management of perennial grasses will inhibit the establishment of weeds. The most important preventative measure is to keep weeds from going to seed so that new infestations are prevented. Second, eradication is the removal of weeds from an area so they will not reoccur unless reintroduced.\nEradication is not usually possible on large areas but should be used for areas of 10 to 100 feet in diameter. The area must be replanted or another weed infestation will occur.\nThird, control measures reduce weed populations to an acceptable level and should be the objective in all weed management plans.\nThere are four types of control measures:\n- Cultural methods, like prevention, promote the growth of desirable plants. Fertilization, irrigation, and planting high-quality desirable plants, allows plants to outcompete noxious weeds. Mechanical controls are the oldest control methods.\n- Mechanical measures involve disrupting weed growth by mowing, pulling, hoeing and burning. Biological controls involve the introduction of host-specific predators from the weed’s native country and the use of animals such as sheep and goats to reduce the vegetative growth of weeds. In Douglas County, the brown-legged leafy spurge flea beetle, aphthona lacertosa, has been introduced on an experimental basis to control leafy spurge.\n- Biological controls should only be done under the direction of the Douglas County Weed Inspector and work only 30% of the time after a 3 – 5 year establishment period. Chemical control methods use herbicides to kill weeds.\n- Herbicides are most effective when used in conjunction with other management techniques. Always read and follow label instructions with applying herbicides. A good weed management system integrates two or more of these methods into a plan of operation.\nOf special concern in Douglas County is diffuse knapweed. Diffuse knapweed is native to degraded non-cropland and seashores from the Mediterranean. It thrives in the semi-arid west and can’t tolerate flooding or shade. Diffuse knapweed has been reported to contain chemicals that can suppress competitive plant growth. Environmental disturbances encourage its invasion. The key to management is to prevent it from going to seed. A\nsingle knapweed plant can produce 500 – 1500 seeds! Seeds are disbursed by the wind, as the plant dries, it breaks off and becomes a tumbleweed, allowing seeds to be disbursed over large areas. The dried stalks can lodge under vehicles, which spreads the seeds even further. Diffuse knapweed invades overgrazed pastures, forms dense stands and may be toxic to horses. Herbicides should be used in the spring or fall, and then the pasture area should be allowed to recuperate by not grazing for a season or longer as needed. If grasses do not return it should be re-seeded so grasses can compete with any surviving knapweed plants.\nBecome a better neighbor\n- Learn to identify the noxious weed species that are invading the area where you live and work\n- Report the location of all known and suspected noxious weeds to local managers so they can be dealt with quickly.\n- Understand the negative impact that weeds have on the environment.\n- Manage noxious weeds on your property by developing a weed management control plan to implement over time. Share your concerns about noxious weeds with your neighbors.\n- Minimize ground-disturbing activities on your land and always re-plant with desirable plants.\n- Use integrated weed management techniques for the effective and safe management of noxious weeds.', 'Generally, the term “weed” is used to describe any plant that is unwanted and grows or spreads aggressively. The term “exotic weed” describes an invasive unwanted non-native plant. Terms such as invasive weed or noxious weed are used somewhat interchangeably to refer to weeds that infest large areas or cause economic and ecological damage to an area. The term “noxious” weed has legal ramifications in some states that maintain official lists of noxious weeds.\nSo, what is considered a weed in one area may not be a weed in another! For example, the owner of Lawn Green has a stunningly beautiful “kikuyu” lawn at his home, however, for someone else this “kikuyu” could be a living nightmare that is overtaking his garden.\nPut simply, a weed is an unwanted plant.\nWeeds can be grouped into several broad categories.\n- Grasses (for example, kikuyu, couch, buffalo, St. Augustine)\n- Grassy weeds (for example, paspalum, wintergrass, summergrass, crabgrass)\n- Sedges (for example, nutgrass, mullimbimby couch)\n- Broadleaf weeds (for example, bindii, clover, dandelions, oxalis, buttercup, thistle).\nThere are many practices the home gardener can adopt to keep on top of the continuous battle with weeds. These practises can be split into three groups:\n- Physical weed control – physically removing weeds from around the home garden and lawn may be the only way to remove some weeds species (for example, removing couch or bermudagrass from mondo grass; or wandering dew from garden beds or lawns), however, this may be a very time consuming. It may be the only way to remove some weed species that existing or current herbicides have little or no effect on. Also, the weeds may not be safely accessible with a herbicide spray because they are growing in amongst other desirable plant species. When physically removing weeds it is important to remove all plant parts including the roots, any stolons (above ground runners), rhizomes (underground runners), bulbs and vegetative pieces, as some weed species are capable of regrowing from any of these plant parts if they are left behind. Removing weeds before they flower and set seed will help reduce the build up of future weed populations.\n- Cultural weed control – adopting various cultural practices around the home garden is probably the best long term weapon the home gardener has in the fight against weed invasion. A healthy and vigorously growing lawn is a big suppressant of weed growth, because it acts as a barrier to and shades out emerging weed seedlings.The following cultural practices include:\n1. regular lawn mowing (weekly during the warmer months and every seven to fourteen days during the cooler months depending on the day/night temperatures in your region).\n2. frequent mowing encourages the grass to spread out and thicken (good lateral growth), thereby, suppressing weed emergence and reducing the chance of tall growing weeds to set seed.\n3. mowing the lawn at the correct height for the species grown. If the lawn is cut too high it will not spread and thicken and if it is cut too short it will scalp the lawn resulting in a less vigorous growing habit and therefore reduce its ability to compete with weeds.\n4. regular fertilising to encourage a healthy, vigorous lawn.\n5. garden mulching (to a depth of 50-100 millimeters) and planting out with ground cover plants are very effective ways of suppressing weed growth\n- Chemical weed control – Herbicides are the common alternative to hand weeding for controlling weeds in the home garden. A herbicide is a chemical that kills weeds or suppresses weed growth.The chemicals in herbicides are referred to as active constituents. The active constituent is named on a herbicide package or container directly under the trade name and is measured in grams/Litre (g/L). It is not uncommon for a herbicide to contain more than one active constituent and by referring to the active constituents listed on the package rather than the trade name you can compare products by what they contain and their concentrations.\nHerbicides can be split into two groups, selective and non-selective. Selective herbicides control the weeds listed on their label but will not damage the crop that they are registered for use in e.g. the active constituents MCPA, dicamba and halosulfuron methyl are registered for use in turf. Non-selective herbicides control the weeds listed on their label but can damage or kill other plant life that they come into contact with e.g. the active constituent glyphosate.\nThe information in Table 1. sets out the range of active constituents registered for use in the home garden and some of the many trade names under which these active constituents can be found.\nHerbicides have different modes of action depending on whether the herbicide is a contact herbicide, a systemic herbicide or a residual herbicide.\nA contact herbicide (e.g. active constituents bromoxynil, sodium chloride and pine oil) only kills the plant part that it comes into contact with, so good coverage of the whole surface area of the weed is essential for good weed control. The disadvantage of herbicides with this mode of action is that the under ground part of some weeds, particularly those that have under ground storage bulbs e.g. onion weed, can remain unaffected by the spray and regrow soon after spraying.\nA systemic herbicide (e.g. active constituents MCPA ,dicamba and glyphosate) once sprayed onto the target weed is translocated through the plants vascular system, killing the above ground foliage and the roots. For best results the target weeds should not be undergoing any type of stress e.g. from waterlogged soil, dry soil, frost damage or extreme heat, as this will hinder the translocation of the herbicide. Good spray coverage will improve the efficacy of systemic herbicides.\nA residual herbicide (e.g. active constituents imazine) is applied to bare soil and then incorporated into the soil soon after application, either by rainfall or with the irrigation sprinkler. Residual herbicides reside in the soil for several months and controls any plant that germinates in the treated soil band, either before it reaches the soil surface or very soon after. The length of time the herbicide remains active in the soil depends on the rate of application, the susceptibility of the emerging weed to the herbicide, the rate of breakdown from heat and microbial activity and how quickly the herbicide is leached through the soil. Residual herbicides are very useful for controling weeds growing in paths, driveways and pavers. However, care must be taken, as any desirable plant thats roots come into contact with the herbicide may be damaged or killed.\nWeeds in garden beds may be spot sprayed with a herbicide if great care is taken not to spray any desirable plants. If the herbicide does make contact with a desirable plant it should be washed off immediately with water to reduce possible damage. The active constituents glyphosate and pine oil can be used for spot spraying in garden beds as they don’t leave a residue in the soil.\nThere are a few precautions that should be taken when applying herbicides in garden beds.\n- It may be necessary to adjust your spray nozzle to produce large droplets rather than a fine mist spray, as large droplets are heavier and are therefore less likely to drift onto desireable plants.\n- Keeping the spray nozzle as close to the target weed as possible will also reduce the chance of drift. A small paintbrush may be a safer alternative for herbicide application than a sprayer when applying to weeds in very close proximity to desirable plants. Care must be taken not to flick the paintbrush.\n- Never apply herbicides with a sprayer when wind is strong enough to cause a drift hazard.\nHerbicides are a very efficient way of controlling weeds in the home garden lawn. For maximum affect on the weeds and greatest safety to the lawn, the active constituent in the herbicide needs to be active on the weed species present and safe to use on the lawn species in question. All of this information is displayed on the herbicide label.\nThe majority of broadleaf weeds in the lawn can be controlled with a range of selective herbicides. However there are fewer selective herbicide options available for the control of grass weeds and sedges in the lawn. Summer grass, barnyard grass and paspalum can be controlled with selective herbicides containing the active constituent DSMA, while nut grass and mullimbimby couch can be controlled with selective herbicides containing the active constituent DSMA, or halosulfuron methyl.\nIt should be noted that selective lawn herbicides may damage soft new lawn growth that occurs after fertilising or top dressing. Herbicides can be safely applied after this new growth matures. This takes about four weeks.\nPaths, pavers and driveways\nWeeds growing through cracks in paths, pavers and driveways can become a real nuisance. To overcome the repetitive task of hand weeding or spraying with a contact or systemic herbicide a residual herbicide can be applied. Residual herbicides when applied to bare dirt, pavers and cracks in paths and driveways can remain active in the soil for up to 12 months, making hand weeding of these sprayed areas a non-event instead of a monthly one.\nWhen using residual herbicides, there are a few important rules that need to be followed, to ensure maximum weed control and minimum damage to the surrounding desirable plants.\n1. Before application, any existing weeds must be removed so that a bare surface is left to spray. After application the herbicide needs to be watered in, either by rain or with the sprinkler, to move the chemical into the soil band where weed seeds germinate. Weed seeds that germinate below the chemical band will not be controlled.\n2. Residual herbicides should not be applied to areas where desirable plants/lawn are growing, or will be planted within the next 12 months.\n3. While spraying the herbicide do not allow it to drift onto desirable plants.\n4. Residual herbicides should not be applied to areas that directly drain onto lawn or garden beds.\nIt is important to use all of these practices together and not rely on just one to achieve optimum results in weed control.']	['<urn:uuid:27c610df-ffde-4194-9882-335cb91ad7f2>', '<urn:uuid:915b6f37-5195-4435-8c8b-fddcff675089>']	factoid	direct	long-search-query	distant-from-document	three-doc	novice	2025-05-12T23:47:20.322175	8	56	2377
27	I'm researching global heritage conservation strategies and would like to understand how the nomination process for UNESCO World Heritage status works, particularly in relation to the Colonies of Benevolence's application. What are the key requirements and timeline?	The Colonies of Benevolence pursued UNESCO World Heritage status through a transnational, serial nomination, including sites at Frederiksoord, Willemsoord, Wilhelminaoord, Boschoord, Veenhuizen, Ommerschans, Wortel and Merkplas, with a decision expected in 2020. According to UNESCO's requirements, sites must meet at least one of ten selection criteria to be included on the World Heritage List. These criteria range from representing human creative genius to exhibiting important human values in architecture or landscape design. Sites must demonstrate 'outstanding universal value' to be considered. For comparison, other successful World Heritage sites include diverse locations from Easter Island's moai statues to the Taj Mahal, each meeting specific criteria that prove their exceptional significance to human history or natural phenomena.	['The Company of Benevolence focuses on the preservation of the work started by Johannes van den Bosch 200 years ago. A visionary idealist, Johannes believed in a socially engineerable society. His ideas stem from the European Age of Enlightenment. After Napoleon’s French troops had withdrawn from our country, Johannes van den Bosch wanted to end the impoverishment of the urban population in particular. Offering housing, work, education and care within agrarian colonies to be founded in Drenthe was at the core of his solution.\nAs an organisation, the Company of Benevolence now strives to preserve the material heritage and ideology of this historic event and to develop this for generations yet to come, so it may be a continual source of inspiration and an example in the field of housing, work, education, and care – the major pillars of those days.\nThe Company of Benevolence strives to:\n- tell the unique story, together with its partners in the area, also for the generations yet to come.\n- provide space for social and sustainable entrepreneurship, while preserving the cultural heritage.\n- develop Frederiksoord to become an Experimental Garden of Benevolence; a place which provides inspiration for living together and caring for each other, and for healthy, self-reliant, and sustainable living.\nIn addition, the foundation acts as the manager of grounds and property, consisting of about 1,300 hectares of land and 65 buildings, 30 of which are listed buildings.\nThe mission for achieving this objective is: from forgetting to telling, from preserving to developing.\nGeneral Johannes van den Bosch is the founder of the Company of Benevolence. Not only Minister of State, confidant of King William I, Member of the Second Chamber of the Dutch Parliament and governor general of the Dutch East Indies, but also a visionary idealist who believed in a socially engineerable society.\nJohannes van den Bosch founded the Company of Benevolence in 1818. At a rapid speed, the first hundreds of colony cottages are built and needy families arrive in this first agrarian colony. Schools are founded and facilities such as a soup kitchen and a spinning mill, in fact everything that is necessary for achieving self-reliance, are set up. Going to church is obligatory, as is school attendance and membership of the ‘sickness fund’. During the period from 1818 to 1921, this probably concerns around 80,000 people in these colonies in Drenthe, with an estimated number of one million descendants today.\nThese events have left their traces to this very day. This wonderful material legacy consisting of monumental buildings, characteristic landscape structures and moulded nature offers a unique insight into the area as it was designed by general Johannes van den Bosch.\nInspired by the ideas of Johannes van den Bosch, various initiatives have been launched that give a new meaning to these historical sites. An influential history worth telling, which will be propagated again by visitors.\nBy means of transnational, serial nomination, the colonies of Frederiksoord, Willemsoord, Wilhelminaoord, Boschoord, Veenhuizen, Ommerschans, Wortel and Merkplas have been put forward to UNESCO in Paris for nomination for World Heritage. UNESCO will decide on the matter in 2020.\nPay a visit to the free Colonies of Benevolence in Frederiksoord and its surroundings and learn all about the unique story. Experience the past today on foot or by bike.\nA new visitor centre will be opened in the House of Benevolence in Frederiksoord in May 2019. Here you can take a trip back in time to the days when the first colonists arrived in Frederiksoord.\nThere are excellent facilities for having dinner and staying the night in the surrounding area. Check all the options on www.weldadigoord.nl\nColony cottage of the future\nIn order to restore a part of the landscape, the concept of the ‘Colony Cottage of the Future’ was developed. Sixty-two historic houses, built in accordance with the standards of the future, will soon restore the historic image in the colonies around Frederiksoord. Under the name of ‘Colonies of Benevolence’, the Company of Benevolence is well on its way to acquire the status of UNESCO World Heritage Site in 2020. Much work has been done and is still done to restore several characteristic landscape elements. Once the colony cottages are placed back, the story will be complete again.\nInterested in living in a colony? You can rent a cottage for a trial period.', 'Achieving World Heritage status is a great honour and one that has been bestowed on many natural and architectural sites around the world. From Easter Island to Stonehenge, the Taj Mahal to the Acropolis, many UNESCO World Heritage sites are instantly recognisable.\nBeing listed as a World Heritage site isn’t just a matter of status, however, it also helps to protect the area or building from being harmed in any way by new developments or environmental factors. In July, 21 new places received the prestigious accolade. The list included the Lake District in the UK, caves and ice age art at Swabian Jura in Germany and Los Alerces National Park in Argentina.\nIn this article we will talk you through five of the most iconic World Heritage sites across the globe and exactly what it takes to be included in the list.\nWhat does it take to become a UNESCO World Heritage site?\nAccording to the UNESCO World Heritage Centre website: “To be included on the World Heritage List, sites must be of outstanding universal value and meet at least one out of ten selection criteria:\n- To represent a masterpiece of human creative genius\n- To exhibit an important interchange of human values, over a span of time or within a cultural area of the world, on developments in architecture or technology, monumental arts, town-planning or landscape design\n- To bear a unique or at least exceptional testimony to a cultural tradition or to a civilisation which is living or which has disappeared\n- To be an outstanding example of a type of building, architectural or technological ensemble or landscape which illustrates significant stage(s) in human history\n- To be an outstanding example of a traditional human settlement, land-use, or sea-use which is representative of a culture (or cultures), or human interaction with the environment especially when it has become vulnerable under the impact of irreversible change\n- To be directly or tangibly associated with events or living traditions, with ideas, or beliefs, with artistic and literary works of outstanding universal significance\n- To contain superlative natural phenomena or areas of exceptional natural beauty and aesthetic importance\n- To be outstanding examples representing major stages of Earth’s history, including the record of life, significant ongoing geological processes in the development of landforms, or significant geomorphic or physiographic features\n- To be outstanding examples representing significant ongoing ecological and biological processes in the evolution and development of terrestrial, fresh water, coastal and marine ecosystems and communities of plants and animals\n- To contain the most important and significant natural habitats for in-situ conservation of biological diversity, including those containing threatened species of outstanding universal value from the point of view of science or conservation.\nAs a result of UNESCO’s criteria, World Heritage sites include natural wonders such as Mount Fuji and Yellowstone National Park, as well as architectural marvels including Chichen Itza in Mexico and the Great Wall of China.\nEaster Island, Chile\nPerhaps one of the most iconic World Heritage sites is Easter Island. This remote Chilean island is famous for its 887 monumental statues, called moai. Found along the coast, often in formation, the moai were created by the island’s earliest inhabitants. The first humans on the island of Rapa Nui (the Polynesian name for Easter Island) are believed to have arrived in approximately 300-400 A.D.\nThe tall statues stand at an average height of 13 feet and weigh 13 tonnes. They were carved out of tuff – the light, porous rock formed by volcanic ash – and placed on top of ceremonial stones called ahus. It is believed that the statues represent the ancestors of the people of Rapa Nui, however it is not known how the heavy moai were transported across the island.\nToday, the island welcomes visitors who wish to see this historical marvel for themselves. The island is accessible on a cruise via Hanga Roa, the main town, harbour and capital of Easter Island. Hanga Roa is home to around 3,300 people, amounting to 87 per cent of the island’s population.\nBetween exploring the statues, be sure to stop at one of the island’s swimming beaches. Although most of the coastline of Rapa Nui National Park is rocky due to the volcanic terrain, Ovahe Beach and Anakena Beach are white coral sand beaches with crystal clear water. Visitors can also discover the island on horseback, visit The Anthropological Museum and see the only moais facing the ocean at Ahu Akivi.\nJarryd and Alesha of NOMADasaurus told us about their experience at Rapa Nui: “Easter Island is one of the world’s most isolated destinations, and the iconic moai statues make it one of the best and most unique World Heritage sites.\n“Mystery still shrouds the fascinating heads, and it’s unknown how the ancient Rapa Nui people managed to transport the stones across the island. The highlights come from driving around Easter Island, marvelling at the wonderful statues, and visiting the volcanic craters and quarry. If visiting for one day we recommend joining a tour with a local guide to get the most information from your trip.”\nGreat Barrier Reef, Australia\nSpanning 133,000 square miles, the Great Barrier Reef is the largest coral reef system in the world. The reef can be found off the coast of Queensland, Australia, and achieved World Heritage status in 1981. It’s considered by UNESCO to be a “globally outstanding and significant entity” and welcomes visitors from all over the world.\nSadly, the reef has fallen victim to what is known as ‘bleaching’. When corals are stressed by changes in conditions such as temperature, light or nutrients, they expel the symbiotic algae living in their tissues, causing them to turn completely white. Warmer water temperatures are believed to be the cause of this in the Great Barrier Reef.\nThe Australian Marine Conservation Society (AMCS) has a long history of fighting to protect the reef. Ingrid Neilson, communications manager at AMCS said: “The Great Barrier Reef represents about 10% of all the world’s coral reefs. It is one of the seven natural wonders of the world. Spanning 2,300km along the Queensland coast, the Great Barrier Reef’s 3,000 coral reef systems contain a huge diversity of marine plants and animals such as sea turtles, reef fish, sharks, hard and soft corals and migrating whales.\n“AMCS has a long, proud history of fighting for the Great Barrier Reef. We led an Australia-wide community campaign to prevent coral mining and oil drilling on the reef in the 1960s. We played a critical role in establishing the Great Barrier Reef Marine Park (1974) and World Heritage Area (1982).”\nAlthough greater protection of the reef has been achieved, there’s still plenty of work to, according to Ingrid: “We are currently working to stop the industrialisation of the coastline, particularly one of the largest coal mines on Earth which is planned for Queensland. We are working hard to convince the Australian Government to heed the will of Australians who want a rapid switch to renewable energy away from coal and gas, which creates carbon pollution and drives global ocean warming and bleaching. A rapid transition to clean renewable energy is in the best interest of the reef, its communities and future generations”\nWhen asked why people should visit the reef, Ingrid said: “Because despite two years of unprecedented coral bleaching, the Great Barrier Reef is still one of the most beautiful places on Earth. Half of the reef’s corals have died in the last two years, but there are still many beautiful places to visit.\n“We must keep supporting our sustainable industries like reef tourism which sustains coastal communities and charges our economies. The tourism industries are the eyes and ears on the water along the reef. They need our support because their livelihoods, along with the marine life of the Great Barrier Reef, are too previous to lose.”\nTaj Mahal, India\nBuilt by Mughal emperor Shah Jahan in memory of his late wife, the Taj Mahal is considered to be a masterpiece of the world’s heritage. The ivory-white marble building, on the bank of the Yamuna River in Agra, is universally recognised, famous for its intricate detail and symmetry.\nShah Jahan was a member of the Mughal dynasty that ruled much of India from the 16 to 18th century. In 1628, after the death of his father, King Jahangir, and a power struggle with his brothers, Shah Jahan crowned himself emperor of Agra. His wife, Mumtaz Mahal, was said to be the most cherished of his three queens. In 1631, Mumtaz Mahal died after giving birth to their 14th child. Grief stricken, Shah Jahan commissioned the building of a huge mausoleum to house her tomb. It is said that 20,000 workers and 1,000 elephants were brought in to build the Taj Mahal.\nThe innovative design and planning of the Taj Mahal is what captures the attention of many. UNESCO states: “The Taj Mahal represents the finest architectural and artistic movement through perfect harmony an excellent craftsmanship in a whole range of Indo-Islamic sepulchral architecture. It is a masterpiece of architectural style in conception, treatment and execution and has unique aesthetic qualities in balance, symmetry and harmonious blending of various elements.”\nCanadian Rocky Mountains National Parks\nIcy blue lakes, glaciers and mountain peaks all come to mind when we think of Canada’s Rocky Mountains. The national parks of Banff, Jasper, Kootenay and Yoho, along with the provincial parks of Mount Robson, Mount Assiniboine and Hamber, have all been granted World Heritage status.\nUnlike the American Rockies, the Canadian Rockies are formed of layers of sedimentary rock such as limestone and shale, making them appear much more jagged and dramatic. The highest peak in the Canadian Rockies is Mount Robson, towering 3,954m over the landscape.\nUNESCO describes the parks on its website: “The seven parks of the Canadian Rockies form a striking mountain landscape. With rugged mountain peaks, icefields and glaciers, alpine meadows, lakes, waterfalls, extensive karst cave systems and deeply incised canyons, the Canadian Rocky Mountain Parks possess exceptional natural beauty, attracting millions of visitors annually.”\nSavi and Vid of Bruised Passports told us why they think the Canadian Rockies are so special:\n“Having travelled to more than 80 countries on this beautiful planet, if we had to choose one place that we feel is the most beautiful when it comes to natural beauty, it’d have to be the Canadian Rocky Mountain Parks. We could not believe how gorgeous the entire area is and the variety that is offers to tourists.\n“Lakes, waterfalls, mountain peaks, alpine meadows and stunning wildlife – there’s pretty much nothing nature-related that you won’t find in this area. What’s more, the glaciers, ice fields and the karst caves provide stunning insights into the evolution of our beautiful planet, making this naturally rich area an important World Heritage site.”\nWhen asked to choose the highlights of their trip to the Canadian Rockies, Savi and Vid said:\n“There were far too many to mention but if we had to pick the top three those would have to be driving the Icefields parkway, enjoying a sunset at Lake Moraine and photographing the Sunwapta waterfalls in Jasper National Park.”\nCologne Cathedral, Germany\nAs a striking example of Gothic architecture, it’s little wonder why Cologne Cathedral was granted World Heritage status in 1996. The imposing building is the largest Gothic church in Northern Europe and Germany’s most visited landmark, welcoming around 20,000 visitors each day. Visitors can admire Cologne Cathedral from a Rhine river cruise. At the site itself, there are 533 stone steps leading up to a viewing platform in the structure with spectacular views over the city.\nBuilding began in 1248 and the cathedral was not completed until 1880. Today, the cathedral represents seven centuries of craftsmanship, towering over Cologne. UNESCO states that the cathedral “bears witness to the strength and endurance of European Christianity”, adding: “no other cathedral is so perfectly conceived, so uniformly and uncompromisingly executed in all its parts.”\nAcross the world there are 1,073 World Heritage sites, from natural wonders to architectural marvels. By taking a world cruise you can tick off plenty of sites on your travel bucket list, including some of the most iconic sites on Earth. How many World Heritage sites have you visited? We’d love to hear about your experiences!']	['<urn:uuid:88b69a1c-3606-47a4-8175-46444dfb6cbd>', '<urn:uuid:b2a0ba6a-79ef-45aa-aea6-2345043ca1b4>']	open-ended	with-premise	verbose-and-natural	distant-from-document	three-doc	expert	2025-05-12T23:47:20.322175	37	115	2776
28	What makes nanobubbles so interesting to scientists, and how does their stability compare to the distribution patterns of electric vehicle charging stations?	Nanobubbles are interesting because they defy theoretical expectations - they survive despite surface tension that should make them collapse, and can even withstand shock waves of over 60 atmospheres. Similarly to how nanobubbles show unexpected stability patterns, EV charging stations show distinct distribution patterns, with Level 2 chargers (which make up 80% of public chargers) being 2.24 times more likely to appear in areas with above-median household income.	['Focus: The Little Bubbles that Could\nAn air bubble will live peacefully on the side of your glass of water for a long time, but shrink that bubble to the nanoscale, and the overwhelming force of surface tension should prevent it from ever forming. Yet researchers have been observing them for several years, thanks to recent advances in imaging technology. The puzzle of nanobubbles has deepened with the 18 May Physical Review Letters, in which a team reports that nanobubbles can withstand shock waves exerting wide swings in pressure, a sign of what they call superstability. Aside from any impact on solving the riddle, the results suggest that tiny bubbles could be useful pieces of nanotechnology, perhaps serving to protect delicate machinery in future biochemical devices.\nSurface tension, the force that makes water bead up on a freshly waxed car hood, also keeps a submerged air bubble as round as possible. Surface tension pushes in on the bubble, and the smaller the bubble, the higher the air pressure inside the bubble must be to keep it from collapsing. For a 100-nanometer-diameter bubble, the pressure should theoretically be at least five times that of the atmosphere, easily high enough to force the gas to dissolve into the surrounding liquid. Blip, the bubble should disappear. But it doesn’t.\nIn 2000 Japanese researchers discovered these surprisingly small bubbles on a silicon surface covered with water . They were using the new imaging technology called “tapping mode” atomic force microscopy (AFM), where a tiny lever vibrates up and down to tap the sample. In these and many other experiments, nanobubbles behave differently than ordinary bubbles, says Andrea Prosperetti, of Johns Hopkins University in Baltimore. Researchers still don’t agree on how nanobubbles survive, although they have proposed several different theories.\nDetlef Lohse of the University of Twente in the Netherlands and his colleagues decided to check the bubbles’ ultimate stability by subjecting them to severe stress. They created nanobubbles in a drop of water on a silicon wafer coated with a hydrophobic material and imaged it with AFM for the “before” picture. Next they submerged the wafer in a water bath and blasted it with a powerful, 6-microsecond-long shock wave produced by the same kind of generator that can destroy kidney stones. Each pulse included positive and negative pressures over 60 atmospheres. This level of abuse would ordinarily create a drastic inflation of bubbles, in a process called cavitation, but the “after” image of the nanobubbles showed them to be unaffected. Based on the bubbles surprising survival, the team dubbed them “superstable.”\nThis stability could be useful, says team member Bram Borkent of the University of Twente. Chemical analysis devices now under development will need to move fluid through nano-channels cut into solids, but pushing the fluid through such tiny spaces is hard. “If you can create these bubbles on purpose then you can cover a nanochannel with bubbles,” which might reduce the friction, says Borkent. Other researchers envision using nanobubbles as computer memory structures or to remove blood clots. “Wherever surface effects are important,â€ Borkent says, â€œnanobubbles may play an important role.”\nProsperetti sees the new work as part of a larger story. “It is another tantalizing example of the surprises that lie in the gray area of nano–the not-so-small to be quantum, but not-so-large to be fully macroscopic.”\n- N. Ishida, T. Inoue, M. Miyahara, and K. Higashitani, “Nano Bubbles on a Hydrophobic Surface in Water Observed by Tapping-Mode Atomic Force Microscopy,” Langmuir 16, 6377 (2000)', 'As electric vehicles (EVs) roll onto the roads in large volumes across the U.S, there has been a corresponding demand for more robust charging infrastructure. Despite the appealing environmental and economic benefits of EVs, the convenience of charging stations heavily influences adoption. And there begins the problem. While electric vehicle use is growing rapidly in well-to-do, predominantly White communities, minority neighborhoods have largely been left behind to date.\nThe U.S. government has emphasized the importance of equity when planning infrastructure investments in bills like the Build Back Better plan, and has incentivized a large portion of EV infrastructure funding in programs like NEVI and policies that seek to ensure EV charging infrastructure is deployed equitably.\nBut how well are these policies performing?\nTaking a granular approach to assess the current state of EV infrastructure\nIn an effort to understand the current state of equity in charger deployment, identify gaps that may exist, and add to the body of knowledge surrounding EV infrastructure deployment – we decided to leverage our vast data core, analytical expertise, and powerful software platform to conduct an analysis of Public EV Level 2 chargers in Columbus, Ohio.\nIn the sections below, we explore where access to EV chargers is most prevalent based on variables like population density, various socio-demographic statistics, and with different definitions of what constitutes a charging gap.\nEV Charging Infrastructure Basics\nFor EVs to achieve broad adoption and utilization, drivers need easy access to charging infrastructure. While many EV owners charge at home, people with longer commutes or irregular driving habits are unlikely to see themselves in EV ownership without excellent access to public charging stations.\nThere are three levels of charging equipment, determined by charging speed.\n- Level 1 (L1) – less than 2% of public EV chargers in the U.S. are L1.\n- Level 2 (L2) – the most common type of public EV chargers, accounting for more than 80% of public EV chargers in the U.S.\n- Level 3 (L3) – more than 15% of public EV chargers in the U.S. are L3.\nDue to the overwhelming preference for and majority of public charging stations being Level 2, we focused our analysis on L2 chargers.\nThe Landscape of EV Charging Infrastructure in Columbus\nAt first glance, you see that Columbus has Level 2 EV chargers spread across the city. A high concentration of chargers are located in the downtown area. So during our study, we took population density into consideration when drawing any conclusions regarding charger placement.\nRacial Factors and public EV Charger Locations\nCloser inspection of the distribution of public chargers in Columbus reveals disparities when comparing majority White areas to majority non-White areas. This is in line with other recent studies on public EV charging distribution. For example, Axios did an analysis of 35 U.S. cities and found that majority-White census tracts are 1.4 times as likely to have a charger.\nGiven UrbanFootprint’s unique ability to aggregate data across all census resolutions, we looked a level of granularity deeper, analyzing census block groups in Columbus using our Analyst application. It revealed that the EV charging locations in our study area are even more heavily skewed towards majority-White areas than what Axios had found in other cities around the country.\nIn Columbus, majority-White block groups are 2 times more likely to have a charger, and 2.3 times more likely to have at least three chargers.\nBut we knew there were likely other factors that may be more strongly correlated with the prevalence of charging stations than race and ethnicity.\nRelationship between EV Charger Presence and Educational Level\nOur study found an even stronger correlation between high education levels and the presence of EV chargers. It was immediately apparent from looking at the map that the median US educational attainment level (36% with at least a bachelor’s degree) was a tipping point for whether a block group would likely contain an L2 charger.\nTo be specific, around 80% of L2 chargers in our study were located in block groups with above the US median for bachelor’s degree attainment – and those block groups were 3.55 times as likely to contain a charger than those below the median.\nThe really shocking piece of this statistic is that these same block groups accounted for only 51% of population and only 40% of area.\nMedian Income and its Impact on EV Charger Distribution\nMedian income also appears to play a significant role in charger presence. Within our study area, block groups with chargers had median incomes 1.1 times higher than those without. Moreover, block groups with average incomes above the US median for household income ($68,703) were 2.24 times as likely to have a charger.\nThis finding supports the argument that historically, charger placement has favored higher income areas, and raises concerns for how access to EV infrastructure will lead to income-based disparities in future EV usage.\nEquitable Access to EV Chargers\nThe end goal of public EV charging infrastructure is to serve the public. That is, having enough chargers in a given block group to satisfy demand. We wanted to get an overall picture of who is being “served” versus “unserved” in Columbus. We chose 4 L2 chargers as a threshold for which to consider a block group “served.”\nWhen we looked at the data through this lens, all three ‘metrics’ (education level, median income, and racial composition) showed equity-related differences.\nConclusions and Recommendations\nOverall, our findings indicate that education level and median income are the most closely related metrics to the distribution of EV chargers in Columbus, Ohio. While racial factors are not quite as strong, there is still a trend for chargers to be more present in predominantly White block groups – in line with studies of other major cities across the country.\nAdditionally, the results were progressively more compelling as we peeled back all of the layers of data. For example, when limiting the analysis to the areas of the city with the highest population density, and increasing the threshold of what counts as a charging gap, the trends are magnified significantly.\nPolicymakers, local governments, utilities, and private companies should consider these findings when incentivizing, funding, planning, and placing future EV infrastructure. By focusing on ensuring equitable access to chargers, they can support the wider adoption of EVs. This includes prioritizing charger installation in diverse neighborhoods and areas with lower educational attainment and income levels.\nBy leveraging the right data at the intersections of climate, community, and the built environment, we can surface the actionable insights that will ensure a more equitable distribution of EV chargers – that will ultimately contribute significantly to higher EV adoption rates, pushing us closer towards a more resilient, sustainable, and inclusive future. Resilience Insights, when paired with our comprehensive Analyst application for data visualization, provide answers to many complex questions related to Infrastructure & Mobility for any location in the United States. Contact us if you want to learn more!']	['<urn:uuid:6b9db2ec-1103-4b20-b071-b2d484e55929>', '<urn:uuid:5fbf5a0f-b48f-437c-a774-25770944f520>']	factoid	direct	verbose-and-natural	similar-to-document	multi-aspect	novice	2025-05-12T23:47:20.322175	22	68	1740
29	As a dairy farmer considering modernization, how do tie-stall and free-stall systems compare in terms of cow comfort and milking efficiency?	Tie-stall and free-stall systems have distinct characteristics affecting cow comfort and milking efficiency. In tie-stalls, each cow has a separate stall allowing individual attention during feeding, grooming and milking. However, free-stall systems, which are more popular for herds of 50 or more, allow animals to walk around freely, lie down when they like, eat and be milked when they choose. Free-stall barns equipped with milking robots can milk each cow 3.2 times per day, leading to better milk production by allowing milking when the cows want. Free-stall systems also require much less bedding since it tends to stay in the stalls. Additionally, free-stall barns lend themselves to better ventilation, can use sand bedding, and generally result in happier animals which leads to better milk production.	"['From tie-stall to freestall\nThe Overvest’s newly built freestall barn was open for around 1,000 visitors on Sat., May 6. The barn was occupied by January 2017. Vogel photo\nby Kalynn Sawyer Helmer\nAgriNews Staff Writer\nL’ORIGINAL – Overdale Farms held an open house on Sat., May 6, from 10 a.m. to 4 p.m. The farm was displaying their new 136 ft. by 222 ft. freestall barn and the many features inside to up production and keep their dairy cows comfortable. Morgan Overvest estimated a continuous stream of approximately 1,000 guests made their way through the barn to check out the features and support their friends.\nOvervest said the farm, “wanted to give everyone a chance to come see [the barn] without feeling like they are taking up so much time.” The Overvests moved into the newly built barn on Jan. 11, and are expected to be at capacity by late July. The barn has room for 120 dairy cows and suggested loads for two milking robots is 110.\nThe new barn sports two Lely Astronaut A-4 milking robots and a Lely Juno 150 feed pusher. Despite the well-known benefits of milking robots for freeing up a farmer’s time and allowing more flexibility in farm ownership, there are also a number of benefits to the cows themselves.\nIn terms of animal welfare and comfort, freestall barns allow the animals to walk around freely, lie down when they like, eat and be milked when they choose. This leads to happier animals which leads to better milk production said Dundas Agri Systems General Manager Levi Dejong. Freestall barns also lend themselves to ventilation and sand bedding all making the animals more comfortable.\n“The milking robots are made for cow comfort,” said Dejong. The robots can milk each cow 3.2 times per day. This helps the animals produce more milk and become more efficient producers of milk since they can be milked when they want. The robots also can lower costs in the long run. Hiring on one farm hand to do one of the milkings a day, for seven days a week, every day of the year can add up costs. Dejong was adamant to explain that the robots in no way suggest a lazy farmer, but one who understands that the robots can unleash the full genetic potential of their animals.\nThe milking robots can even identify which cows are producing more milk and those that are not. It then combines with the feeding technology to reward the higher producers and modify the food for lower producers. Ensuring the lower producers do not get overfed.\nWhile the new technology is a good perk, Overvest explained that it wasn’t necessary for her to come back to the farm. Overvest was working for Holstein Canada and spent her time visiting farms. With each farm she would visit, Overvest would feel a longing to be back on her own family farm. As the only sibling interested in taking over, the thought was always in the back of her mind. This was until it became time for the Overvests to build. There needed to be a decision made of whether to downsize or grow, and Overvest’s parents, Gary and Linda, were looking to free up some of their time as they get closer to retirement.\nThis does not mean Gary and Linda Overvest will be quitting anytime soon, however. Morgan Overvest explained that since coming back in November, the family has been focused on farm operation and the new barn. Talk of business is on the back burner at least for a short while. Overvest said it will be a slow transition since her parents still feel young enough to be active on the farm. Overvest recalled her parents joking that they will retire to 40-hour weeks with her return.\nOverall, Overvest could not say for sure whether the trend of women taking over farms and positions in agriculture is relatively new or is more noticeable to her now that she is in a position of future ownership. However, she did say the robotic milkers do help to make running a milking operation single-handedly, less intimidating. With many of her female friends doing similar transitions, Overvest said it is nice to feel as though there is a supportive community of women farmers.', ""This action might not be possible to undo. Are you sure you want to continue?\nREV 06:05 Good dairy housing is important for quality milk production. A well-designed barn provides a clean, comfortable home for the herd and a pleasant, efficient workplace for the operator. Plan carefully for the storage and handling of milk, feed, bedding and manure, as these account for most of your labor. Also remember that a dairy building must satisfy a number of regulations; investigate these before construction begins. Make sure you have a plentiful, dependable supply of good water, made available 24 h a day A lactating cow will drink 135 L (30 gal) a day. The ideal water temperature is about 5-10°C. Supply pipes buried deep in the ground will help keep the water cool in summer and prevent freezing in winter. Use automatic heating if the waterer is located where it might freeze. Provide 0.1 m2 (1 sq ft) of watering tank surface for every 50 head. A large, mechanized operation also needs dependable electrical power plus a standby system. SITE SELECTION Choose a high, relatively level, well-drained site that will allow future building expansion. Build the floors above ground level to keep out runoff water. Where possible, pick a site that allows good snow and wind control. You may have to add windbreaks and snow-and wind-control fences. Locate the milkhouse and/or milk parlor on the north or east side of the barn to reduce the summer heat load. Locate yards where they are exposed to winter sunlight; those facing south or southeast thaw and dry faster, so are easier to manage. The barn should be served by a good all-weather driveway, or border on a high, well-drained service yard with a good gravel base. Consider a circular driveway if milk is shipped in bulk. The truck driver should not have to open or close gates or back up to load. Build the barn close to pasture lanes and where it gives easy access to the house and other work areas. Remember, if you raise your own replacement stock, you'll have twice as many animals and will need calf barns, maternity areas, dry cow housing, and storage for bedding, feed and manure. Based on the number of milking cows, you can estimate the additional animals you'll need for replacements as follows: - Heifer calves (0-3 months) 12% - Bull calves (0-3 months, if housed) 12% - Heifers (3-10 months) 20% - Heifers (10 months-2 years) 35% - Heifers (2 years to freshening) 0-20% - Dry cows 12% HOUSING SYSTEMS Barns must protect cows from wind, moisture and extreme temperatures. Whether you choose warm or cold housing, or loose tie-stall or free-stall management depends on the size of your operation, availability of bedding, climate, existing facilities, the degree of mechanization and personal preferences. Warm housing is kept no cooler than 4°C (40°F) in winter. It must be well-insulated to retain animal heat. Ventilation (either fan-powered or automated natural ventilation) removes excess moisture in the winter and excess heat in the summer. Cold housing in winter is only slightly warmer than outdoors. Natural ventilation removes moisture and keeps the barn temperature about 5-10°C above that outside. Insulation under the roof reduces condensation in winter and heat buildup in summer. Cold barns cost less than warm barns but their watering systems must be protected against freezing. The three basic housing systems are tie-stall, free-stall and loose. Tie-stalls are the most common in Canada. Each cow has a separate stall that permits individual\nThe Canada Plan Service prepares detailed plans showing how to construct modern farm buildings, livestock housing systems, storages and equipment for Canadian Agriculture. To obtain another copy of this leaflet, contact your local provincial agricultural engineer or extension advisor.\nattention during feeding, grooming and milking. Additional pens are provided for calves, young stock and for freshening cows. Tie-stall barns are generally 9.6-11.4 m (132-138 ft) wide with a ceiling height of 2.4 m (8 ft) or more. Stall dimensions are shown in Table 1. Free-stalls are the most popular for 50 or more head. The resting area is divided into individual stalls without ties, and the paved alleys are cleaned by scraping. You need much less bedding because it tends to stay in the stalls. Barns with a feeder down the center and one row of stalls down each side should be 12-13.2 m (40-44 ft) wide. Two rows of stalls on each side can be used for larger herds. The minimum ceiling height is 2.7 m (9 ft). Stall dimensions are shown in Table 2 and alley widths in Table 3.\nLoose housing uses a deep-bedded resting area plus separate feeding, holding and milking areas. Bedding requirements are very high, so it is seldom used now except where bedding is inexpensive and abundant. Barns should provide 6 m² (60 sq ft) per head for milking cows and 4 m² (40 sq ft) for dry cows and heifers. A ceiling at least 3 m (10 ft) high permits manure pack buildup and cleaning. Allow a minimum of 6 m² (60 sq ft) per head in paved exercise yards for milking cows, dry cows and heifers. If unpaved, provide 30 m² (300 sq ft) per head for milking cows and 20 m² (200 sq ft) for dry cows and heifers. Unpaved yards are not suitable for heavy traffic areas or where annual precipitation exceeds 50 cm (20 in.). THE MILKING CENTER This must be a sanitary, efficient place to milkcows and handle, cool and hold milk. It demands the greatest investment, the most time and labor, and the strictest sanitation. Since sanitation regulations vary by region, contact local health or dairy officials before construction begins. The milkhouse must meet strict sanitary requirements. It is attached to, but partitioned off from, the barn and the milking parlor. Here milk is cooled and held for pickup and equipment is cleaned and stored. If milk must be carried, locate the milkhouse to minimize the walking distance to the milking area. Make sure you can move the bulktank in and out, by installing double doors or removable panels that extend to the floor. The milking parlor is used for regular milking. It reduces labor by bringing the cows to the operator, generally standing them on a platform 750-900 mm (30-36 in.) high. Layout will depend upon required capacity, personal preferences, economics and design. Parlors can be as simple as a few stanchion milking stalls beside the milkhouse, with the milk carried out by hand, to something as complex as a rotary system with automated equipment and transfer systems. Herringbone or side-opening stalls in two rows are the most common. Cows wait to be milked in the holding area. This may be part of the regular animal traffic area or a separate space used only for this purpose. It should be surfaced with rough-textured pavement, and provide 1.1-1.7 m² (12-18 sq ft) per cow. If the holding area slopes, make sure it rises toward the milking parlor entrances. Design the holding area so cows can enter the parlor easily and without sharp turns. MATERNITY, HOSPITAL, SERVICE AND CALF PEN AREA\nTABLE 1 DIMENSIONS FOR TIE STALLS\nStall platform length with Animal size Stall width trainer*___ kg (lb) mm (in.) mm (in.) 400 (880) 1000 (40) 1450 (58) 500 (1100) 1100 (44) 1500 (60) 600 (1320) 1200 (48) 1600 (64) 700 (1540) 1300 (52) 1700 (68) 800 (1760) 1400 (56) 1800 (72) * Make stalls 100 mm (4 in.) shorter if used without trainers.\nTABLE 2 DIMENSIONS FOR FREE STALLS_____________ Stall length including curb mm (in.) 1200 (48) 1400 (56) 1650 (66) 2100 (84) 2250 (90) 2250 190) 2250 (90) _____________\nAnimal size kg (lb) 100 (220) 200 (440) 300 (660) 400 (880) 500 (1100) 600 (1320) 700 (1540) and over\nStall width mm (in.) 700 (28) 800 (32) 900 (36) 1000 (40) 1100 (44) 1200 148) 1200 (48)\nTABLE 3 LITTER ALLEY WIDTHS BETWEEN FREESTALL CURBS _ Slotted floors or automatic alley scraper___ m (ft) 2.1 (7) 2.1 17) 2.4 (8)\nStalls per row Up to 5 6 to 16 17 to 36\nSolid floors tractor scraper m (ft) 2.1 (7) 2.4 (8) 3.0 (10)\nMost operators prefer this area in a building (or section of a building) where they can control the environment. Often you can convert part of the stable in an existing barn. The area must be dry, draft-free, well lighted, insulated and ventilated. Provide one 3 x 3 m (10 x 10 ft) maternity pen, or one maternity tie-stall without gutter, for every 20 to 25\ncows (in loose housing, add a treatment tie-stall for every 20 to 25 cows). You'll also need an isolation pen for every 40 animals; it should have minimum dimensions of 3 x 3 m (10 x 10 ft), be separate from the main livestock area and have a stanchion or tie-stall in one corner. Calves up to 3 months old should have individual stalls with 600 x 1500 mm (2 x 5 ft) minimum dimensions. Calves 3 to 10 months old should each have 2.2 m2 (24 sq ft) of pen with bedding or 1.5 m2 (16 sq ft) with slotted floors. Alternatively, they may be housed in free stalls. See Table 2 for stall sizes. AREAS FOR YOUNG STOCK AND DRY COWS Keep this stock separate from the milking herd. Most operators use loose housing to save work. It is best to separate the large and small heifers. If you can't, leave liberal amounts of feeding space so that smaller animals will not be crowded out. Heifers 10 to 24 months old should each have 3.2 m2 (35 sq ft) with bedding or 2 m2 (22 sq ft) with slotted floors.\ndiagonally from the top of the throat board) should be 850 mm (34 in.). For cows and heifers, leave at least 3.3 m (11 ft) from bunk to wall or fence, 3.6 m (12 ft) from feed bunk to free-stall heel curb, and 4.8 m (16 ft) from feed bunk to parallel feed bunk. Use Table 5 to plan storage for bedding. TABLE 4 MANURE STORAGE REQUIRED PER ANIMAL /DAY Solid manure Liquid storage Manure manure (including Class of produced storage bedding) animal L (cu ft) L (cu ft) L (cu ft) Dairy calves 5.4 (0.19) 5.4 (0.19) (0-3 months) Dairy calves 7.1 (0.25) 9.9 (0.35) (3-6 months) Dairy heifers 14.2 (0.50) 19.8 (0.70) 17.0 (0.60) (6-15 months) Dairy heifers 21.2 (0.75) 31.1 (1.1) 22.6 (0.80) (15-24 months) Dairy cows 45.3 (1.6) 62.3 (2.2) 450 kg (1200 lb) Open-pen housing 56.6 (2.0) Free-stall housing 67.9 (2.4) 48.1 (1 .7) Tie-stall housing 50.9 (1 .8)\nMANURE MANAGEMENT The most common way to remove manure from a tiestall barn is with a mechanical gutter cleaner. The manure is either moved directly into a spreader for field spreading, or stacked outside on a paved slab that has low curbs or earth banks to confine runoff. Free-stall barns with solid alley floors are scraped to a collection point. The manure can then be moved to storage by gutter cleaner, pump or gravity pipe. With slotted floors, manure is tramped down into a concrete gutter. Provide enough room for storage and handling (Table 4), as well as good access to the storage for removing and transporting manure to the field. Locate the storage so prevailing winds carry odors away from the house.\nTABLE 5 BEDDING REQUIRED PER ANIMAL PER DAY Manure pack loose housing kg (lb) 4.5 (10) 2.2 (5)\nFEEDING AND BEDDING Plan feed storage for each milking cow based on 13.6 kg (30 lb) of hay per day if no silage is fed, or 40.8 kg (90 lb) of silage if no hay is fed. If you feed silage and hay in combination, substitute at the ratio of three units of silage to one of hay, by weight. Concentrate storage should allow for 3-7 kg (6-15 lb) per cow per day, or one unit by weight per three of milk produced. Provide about 50% additional storage for the rest of the herd. Allow 700 mm (28 in.) of feed bunk per animal if the cows are fed on a timetable. If they are self-fed and feed is available at all times, you can reduce feeder space to as little as 300 mm (12 in.) per milking cow and 200 mm (8 in.) for each dry cow and heifer. Feed bunks should be 750 mm (30 in.) wide if animals feed from one side and 1500 mm (60 in.) wide if they feed from both sides. The maximum height at the throat should be 550 mm (22 in.) and the maximum reach (measured\nTie-stall Class of housing animal kg (lb) Milk cows 3.6 (8) Dry cows and 1.8 (4) heifers Calves 1.4 (3) 0-0.5 (0-1) 1.4 (3) (3-10 months) _ * Some operators use sand instead of bedding materials but not with liquid manure.\n*Free-stall loose housing kg (lb) 0-0.9 (0-21 0-0.9 (0-2)\nCONSTRUCTION MATERIALS The general trend is toward single-story, light woodframe dairy buildings. Select materials for sanitation, durability, strength, fire-resistance and thermal insulation. Building and maintenance costs are largely determined by the construction materials. Concrete is good\nfor footings, floors, ramps and steps because it costs little to maintain, is workable before it sets, is durable, and (above all) is sanitary. Generally, wood framing is used for walls, partitions and roofs because it is readily available, is easily cut, and practically all building panels can be attached directly. Good insulation is necessary for proper ventilation in enclosed buildings. Durable weatherproof materials are recommended for exterior surfaces. Interior surfaces exposed to high humidity like that in a milkhouse must be waterproof and easily cleaned. Windows lose heat and often get dirty and wet from condensation. Many new dairy barns have few or no windows unless local regulations require them. HEATING AND VENTILATION Fans are generally used to exhaust stale air from a barn. They must be selected to provide air flow rates that range from the winter minimum to the summer maximum (Table 7). Inlet location and design are more important than fan location. A good inlet allows enough fresh air to enter\nthe barn and encourages it to mix well throughout the room, without drafts on the animals. In a well-insulated barn housing the milking herd, you'll need little or no heat other than that produced by the animals until the outside temperature falls below -20°C (-4°F). Calf and maternity areas will require supplementary heat. Heat the milkhouse and milk parlor to keep them dry and above freezing. The parlor must also be ventilated to remove excess heat produced during milking. TABLE 6 TEMPERATURE AND HUMIDITY REQUIREMENTS Recommended Recommended inside temperature inside relative humidity\nClass of_______________°C (°F)______________(%)____ animal Min. Max. Min. Max. Cows -7 (20) 24 (75) 25 75 Calves 10 (50) 27 (80) 25 75 Calves over 6 weeks -18 ( 0) 27 (80) (if draft free)_______________________________________\nTABLE 7 VENTILATION REQUIREMENTS L/s (cfm) per animal Step 2 Step 3 moisture temperature control control 9.4 (20) 47 (100)\nStep 1 Type of livestock Dairy cows 450 kg cow (1000 lb) Type of housing Conventional fall to spring stabling ventilation by windows during summer Year-round insulated windowless housing or barn with non-opening windows Insulated free-stall barn without windows ventilation by doors during summer Continuous in wellinsulated building Continuous in wellinsulated building Batch housing in wellinsulated building Batch housing in wellinsulated building continuous 9.4 (20)\nTotal ventilation required 65.8 (140)\n450 kg cow (1000 lb)\n450 kg cow (1000 lb)\nDairy calves 50 kg av wt. (110 lb) 63 kg av wt. (139 lb) 45 kg (100 lb) 135 kg (300 lb)\n3.3 (7) 4.7 (10) 2.4 (5) 5.6 (12)\n3.3 (7) 4.7 (10) 2.4 (51 5.6 (12)\n17 (36) 23.5 (50) 19 (40) 47 (10_0)\n23.6 (50) 32.9 (70) 23.8 (50) 58.2 (134)\n* Stea 3 (temperature control) should be in two or three stages when possible.\nThis action might not be possible to undo. Are you sure you want to continue?\nWe've moved you to where you read on your other device.\nGet the full title to continue reading from where you left off, or restart the preview.""]"	['<urn:uuid:33c57ae1-d73c-4203-b8bb-945cbee12414>', '<urn:uuid:d7ad04d9-2171-4a7f-9adf-3dc55cce087b>']	open-ended	with-premise	concise-and-natural	similar-to-document	comparison	expert	2025-05-12T23:47:20.322175	21	125	3415
30	what special defense mechanisms do hoopoe birds use against predators in nest	Hoopoes have several defense mechanisms to protect their nests. The female and nestlings produce a foul-smelling liquid from their uropygial gland that smells like rotting meat, which they rub into their plumage to deter predators and parasites. Additionally, from six days old, nestlings can direct streams of feces at intruders and will hiss at them and strike with their bill or wing.	"[""In 2008, the Eurasian hoopoe, or duchifat (דוכיפת) in Hebrew, was chosen as Israel’s National Bird. This distinctive bird is also found in the mythologies of Egypt, Greece, Arabia, Persia, and other ancient cultures.\nI've been fortunate to visit Israel twice. To this day, I've never forgotten the sounds of sunrise by the Sea of Galilee. The chorus of birds was astonishing. I took along a small tape recorder to capture the sounds of the country and highly recommend that to anyone planning a visit.\nThe city of Jerusalem itself is home to over 300 bird species. Experts estimate that during the migration season as many as 500 million birds pass through Israel. For some species, almost the entire global population moves through this region.\n(Photos taken on the Sea of Galilee, are mine)\nA Hoopoe Provokes the Wrath of a King\n“I will punish him most severely,” bellows an infuriated King Solomon about a hoopoe in Chapter 27 of the Qu’ran (Koran),“or will kill him, unless he brings me a convincing excuse!”\nDespite, or perhaps because of, this legend, the hoopoe has enjoyed a rather lofty status throughout history. Not only was a hoopoe Solomon’s special messenger according to the Qu’ran but was also called the wisest bird in the world by the Persian poet Attar of Nishapur in his epic poem, The Conference of the Birds.\n(Above: The Conference of the Birds, miniature from a manuscript of the Mantiq al-Tayr (The Language of the Birds) of Farid al-Din Attar, ca. 1600, Safavid, Iran)\nIsrael Makes Eurasian Hoopoe the National Bird\nA Distinctive Species\nAlong with a crown of feathers, the bird's long, thin, tapering black bill with light yellowish-tan base makes the species highly distinctive. A strengthened musculature of the head allows the bill to be opened when probing the soil. The hoopoe has broad, rounded wings capable of strong flight. Due to the wings half closing at the end of each beat or short sequence of beats, hoopoes have a characteristic undulating flight like a giant butterfly.\nThe call is typically a three-syllable oop-oop-oop, which may have given rise to the name. Another explanation is a derivation of the French name for the bird, huppée, which means crested.\n(Above: Located at the junction of three continents, Israel is crossed by migrating birds on a scale unparalleled anywhere. Around 500 million birds cross Israel's narrow airspace twice every year during their migrations. Photo: מינוזיג [CC BY-SA (https://creativecommons.org/licenses/by-sa/4.0)])\nThe Eurasian hoopoe's range is widespread across Europe, Asia, North Africa, Sub-Saharan Africa and Madagascar. As early as the 18th Century, it was recorded in Britain.\nMost European and northern Asian hoopoes migrate to the tropics in winter. By contrast, the African populations of this bird are sedentary all year. The species has been a vagrant in Alaska where it was recorded in the Yukon Delta in 1975.\nHoopoes have been known to breed north of their European range and in southern England during warm, dry summers that provide plenty of grasshoppers and similar insects. As early as the 1980s, Northern European populations were reported to be in decline, possibly due to climate changes.\nHow They Behave\nThe hoopoe has two basic habitat requirements: bare or sparsely vegetated ground where it can forage and vertical surfaces with cavities for nesting. These requirements are found in a wide range of ecosystems. As a result, hoopoes inhabit a variety of habitats including grasslands, heath, wooded steppes, savannas, forests, and glades.\nIn some regions, they move seasonally in response to rain. Hoopoes have been seen at high altitudes during migration across the Himalayas. One was recorded at about 21,000 ft. by the first Mount Everest expedition in 1953.\nIn what was long thought to be a defensive posture, the birds sunbathe by spreading out their wings and tails low against the ground while tilting their heads up. They also enjoy dust and sand baths.\nWhat Does a Hoopoe Eat?\nThe bird is a solitary forager that eats mostly insects, small reptiles, frogs, plant matter, seeds, and berries. Its common foraging style is to stride over relatively open ground and periodically pause to probe the ground with its entire bill.\nHoopoes will also feed on surface insects, probe piles of leaves, and even use the bill as a lever to move large stones and flake off tree bark. Their common diet includes crickets, locusts, beetles, earwigs, cicadas, bugs, and ants. Larger prey is beaten against the ground or a rock to kill it and remove any indigestible body parts.\nThe Eurasian hoopoe's diet includes many pest species such as the pupae of the Oak processionary moth, a damaging forest pest. For this reason, the species is afforded protection under the law in many countries.\nThe genus is monogamous, although the pair bond apparently only lasts for a single season. They are territorial. The male calls frequently to advertise his ownership of the territory. Chases and fights between rival males and females are common and sometimes brutal. Birds will try to stab rivals with their bills, resulting in occasional blinding.The nest is in a hole in a tree or wall. The female alone is responsible for incubating the eggs. Clutch size varies with location. Northern Hemisphere birds lay more eggs than those in the Southern Hemisphere, and birds at higher latitudes have larger clutches than those closer to the Equator. In central and northern Europe and Asia, clutch size is around twelve; it's around four in the tropics and seven in the subtropics. The eggs are pale blue to milky white when laid but quickly discolor in the increasingly dirty nest.\nStinking to Survive\nHoopoes employ well-developed anti-predator defenses in the nest. The uropygial gland of the incubating and brooding female along with her nestlings is quickly modified to produce a foul-smelling liquid that discolors the eggs. These secretions smell like rotting meat. They're rubbed into the plumage to help deter predators and parasites and possibly act as an antibacterial agent. The secretions stop just before the young birds leave the nest. From the age of six days, nestlings can also direct streams of feces at intruders and will hiss at them and strike with their bill or wing.\nThese distinctive birds have made a cultural impact over much of their range. Considered sacred in Ancient Egypt, they were depicted on the walls of tombs and temples.\n(Above: Birds in an acacia tree, Egyptian wall painting, ca. 1991–1802 BC, from tomb of Khnumhotep III, Beni Hasan Cemetery, Egypt)\nHoopoes were thought of as thieves across much of Europe and as harbingers of war in Scandinavia. In Estonian tradition, they are strongly connected with death and the underworld. Their song is believed to foreshadow the death of people or livestock.The hoopoe appears on the logo of the University of Johannesburg and is the official mascot of its sports teams. The municipalities of Armstedt and Brechten, Germany, display a hoopoe in their coat of arms.\nThe Eurasian hoopoe is the type of bird that looks like it should be rare, but isn't. An interesting and popular bird with a big reputation, it wears its crown well.""]"	['<urn:uuid:9dc65096-f629-4127-be4b-93da449c2d54>']	open-ended	direct	long-search-query	similar-to-document	single-doc	novice	2025-05-12T23:47:20.322175	12	62	1188
31	How many people have trouble reading due to dyslexia?	Dyslexia affects 5 to 15% of the population, specifically affecting the ability of otherwise intelligent people to read.	['Regulation and Integration of the Body\nphysician suspects meningitis and performs a lumbar tap. Using\nyour knowledge of neuroanatomy, explain into which space and\nat what level of the vertebral column the needle will be inserted to\nperform this test. Which ﬂuid is being obtained and why?\nFive-year-old Amy wakes her parents up at 3 ±M crying and\ncomplaining of a sore neck, severe headache, and feeling sick to\nher stomach. She has a temperature of 40°C (104°F) and hides\nher eyes, saying that the lights are too bright. Te emergency\nRelated Clinical Terms\nA complex developmental neurological disorder, typically\nappearing in the ﬁrst three years of life, characterized by\ndiﬃculty in communicating, forming relationships with others,\nand responding appropriately to the environment. A wide\nvariety of mutations in functionally related genes can give rise to\nautism and its related disorders. Occurs in about two per 1000\npeople, and early behavioral intervention is beneﬁcial.\no-me) A procedure in which a tract in\nthe spinal cord is severed surgically; usually done to relieve\nA learning disability in 5 to 15% of the population that\nspeciﬁcally aﬀects the ability of otherwise intelligent people\nto read. Tis deﬁcit in visual symbol and language processing\nis thought to result from errors arising in one hemisphere.\nSeveral genes that predispose children to dyslexia have been\nidentiﬁed, but dyslexia can also be acquired by brain injury or\ndisease) Any disease or disorder of the brain.\nsleep) A condition in\nwhich aﬀected individuals sleep as much as 15 hours daily.\ncondition involving the formation of a small brain, as evidenced\nby reduced skull size; most microcephalic children are mentally\nInﬂammation of the spinal cord.\nrecording) X ray of the spinal cord a²er\ninjection of a contrast medium.\ntumult) Sudden contraction of a muscle or muscle part, usually\ninvolving muscles of the limbs. ³yoclonal jerks can occur in\nnormal individuals as they are falling asleep; others may be due\nto diseases of the reticular formation or cerebellum.\nsēs) A less debilitating class of mental illness;\nexamples include severe anxiety (panic attacks), phobias\n(irrational fears), and obsessive-compulsive behaviors (e.g.,\nwashing one’s hands every few minutes). However, the aﬀected\nindividual retains contact with reality.\nsēs) A class of severe mental illness in which\naﬀected individuals lose touch with reality and exhibit bizarre\nbehaviors; the legal word for psychotic behavior is insanity.\nPsychoses include schizophrenia (skit-so-fre\ndisorder, and some forms of depression.\nAT T H E C L I N I C\nMargaret Bryans, a 39-year-old\nfemale, was a passenger on the bus\nthat crashed on Route 91. When\nparamedics arrived on the scene, she\nwas unconscious, with cuts on her arms, face, and scalp. She\nregained consciousness en route to the hospital and appeared\nagitated and combative. Paramedics observed that she had a right\nhemiparesis (muscle weakness), with a near complete paresis of\nher right upper extremity and a partial paresis of the right lower\nextremity. A head CT scan revealed an acute subdural hematoma\nand an extensive subarachnoid hemorrhage. Doctors noted that\nshe was able to follow commands from medical personnel. With\ndifﬁculty, she could speak haltingly, using only simple words.\nSurgery to remove large clots from the subarachnoid space was\nperformed immediately. Two weeks after the surgery, she showed\nsigniﬁcant improvement in her speech and motor function.\nThe adult brain can be broken down into four functional\nregions (see Table 12.1). Based on the observed signs in this\ncase, which of these four brain regions is involved? What\nevidence did you use to determine this?\nWhich side of the brain is involved in Mrs. Bryans’s injury? What\nevidence did you use to determine this?\nWhat speciﬁc parts of the region of the brain you identiﬁed in\nquestion 1 are being affected by the injury to cause the muscle\nweakness and language problems?\nWhat are the three membranes that make up the meninges?\nDescribe their positions relative to the brain.\nRelative to the meninges, describe the location of the bleeding\nrevealed on the CT scan.\n(Answers in Appendix H)\nCentral Nervous System']	['<urn:uuid:5cd465dc-a730-4894-93f7-0c5a54b6b489>']	factoid	direct	concise-and-natural	distant-from-document	single-doc	novice	2025-05-12T23:47:20.322175	9	18	673
32	What portion of yearly home sales happen in summer months?	May, June, July and August account for 40% of the total number of homes sold throughout the year.	['As the weather gets warmer, millions of Americans are gearing up to buy a new home. We’re entering peak real estate season, as May, June, July and August account for 40% of the total number of homes sold throughout the year.\nBut, if you want to be a savvy consumer, you’ll start your search for a new home closer to Thanksgiving than to Memorial Day.\nHouse hunting in the winter has several advantages, such as decreased competition for properties and the chance to properly assess a home’s heating system. Plus, you might even find a seller so overcome by eggnog and holiday cheer that they offer you an amazing deal. (We’re scientifically happier over the holidays, after all.)\nBut there’s an even bigger and simpler reason to consider waiting until the weather cools before you buy a home: It’s cheaper.\nThe latest research from real estate website Zillow shows that those who buy at the peak of the market (April and May) can expect to pay a premium of $1,500 on average. Houses listed in December, on the other hand, sell for $3,100 less than average.\nUnsurprisingly, the big guns of the housing industry recognize this trend. Lawrence Yun, chief economist for the National Association of Realtors, points out, “Year after year, closings in January tend to show a dip in prices, suggesting that buyers who made offers in November and December got the best deals.” As an example, Yun says, “In the summer of 2014, median home prices climbed past $220,000, only to drop below $200,000 in January of 2015.”\nAnother compelling case study comes out of Dallas, where it’s been shown that prices vary by as much as 12% depending on the season: Houses are more expensive in the summer and cheaper in the winter.\nThat means if you’re looking to buy a $200,000 home in Dallas, you could save $24,000 off the purchase price if you delay your purchase until the winter. If you took that $24,000 and invested it in a low-cost index fund that returned 7% a year for the next 30 years, you’d have an extra $182,000 in your pocket as you sent in your final mortgage payment. That’s a solid chunk of change simply for doing your house shopping against the grain.\nOf course, the main reason for the cheaper prices is the law of supply and demand. There are more houses available in the spring, but there are a lot more buyers, too — many of whom don’t want to uproot their kids halfway through the school year. And doing your search when there’s more available inventory increases the odds that you find a house that ends up being a perfect fit.\nBut, that doesn’t mean you can’t find something great in the winter. It will just take a little more effort. Silvana Tenreyro and L. Rachel Ngai, professors at the London School of Economics, pointed out as much in a recent paper on housing prices. Searching in the winter, according to the authors, is “a bit like searching for bargains in a leftovers’ sale. You might see low prices, but you are less likely to find your combination of size, color, and style. Only if you search a lot will you get the lucky draw.”\nSo, if you have ample amounts of patience and perseverance, you should be able to find a home that makes you happy, even when looking during the winter – and you could get it on sale to boot.\nAnother advantage of shopping in the winter is illuminated by a well-documented phenomenon called the “too much choice effect” (also referred to as the Paradox of Choice). This is when “an overabundance of options eventually leads to negative consequences, such as a diminished motivation to choose any option or a decreased satisfaction with the finally chosen alternative.”\nHaving too many options – even when it comes to minor choices, like what to have for lunch or what to watch on Netflix – can leave us feeling overwhelmed or making rushed decisions. And in the end we’re more likely to regret our choice as we reflect on all the other options and wonder, “What if?”\nAs Trent puts it, “Some choice is better than no choice, but there quickly comes a point where more choices are actually a negative rather than a positive.” If you focus your efforts on a diligent home search during the off-season, you might mitigate the effects of the too much choice effect, because there aren’t as many options on the market.\nShopping in the winter could also help you avoid falling into the hedonic adaptation trap. This refers to the mechanism by which people rapidly get used to changes and revert back to a base level of happiness. As Sonja Lyubomirsky, a psychology professor at the University of California Riverside, told the New York Times, “We buy a new house, we get accustomed to it… and we stop getting pleasure from it.”\nIn essence, even if you do find your dream home in the spring bonanza, it won’t make you happy for very long. We think the extra square footage and walk-in closet will make us happy, but in the long run, they won’t. So instead of holding out for a dream home – or worse, overspending for one — you’re better off being realistic about what you need, and finding something within your budget. And it’ll be easier to find something affordable outside of the peak real estate season.\nIn the end, though, only you know which tradeoffs make sense for your family. No one should rush into a major purchase just because they’re trying to take advantage of a small seasonal discount. It’s important to do thorough research and to see a lot of places, if only to get a better feel for the market, as this is a purchase you might be living with (and in) for 30 years or more.\nIt could be worth the extra thousand bucks or more to get a house in the spring if you’re certain it’s the perfect fit. I know I’m grateful my family picked the one house in my neighborhood with a driveway suitable for playing basketball, as I ended up spending countless hours practicing on our hoop and ultimately ended up earning a living playing the sport.\nIf you’re reading The Simple Dollar, you’re probably up for a financial challenge. Making your own laundry detergent, buying secondhand clothes, and starting a side hustle all take determination and outside-the-box thinking. If you apply that same attitude to house hunting, you’re likely to realize that searching for a home in the winter can make a lot of sense, even if it means bucking conventional wisdom.']	['<urn:uuid:dfc4e381-94d3-411b-a108-90c05eda9801>']	factoid	with-premise	concise-and-natural	distant-from-document	single-doc	expert	2025-05-12T23:47:20.322175	10	18	1121
33	What is the standard seam allowance for slipcover patterns?	The standard seam allowance for slipcover patterns is 1/2-inch. After tracing the seams with tailor's chalk, you draw another line 1/2-inch to the right from the chalk line, which becomes your cutting line and reflects your seam allowance.	['How to Make Slipcover Patterns\nYou can go to the store and buy a slipcover pattern that loosely conforms to the dimensions of your piece of furniture, but making your own pattern allows you to get your slipcover’s curves, contours, width, and length just right. Muslin is a terrific fabric for slipcover planning:\nBuy more muslin than you think you’ll need, even as much as one-third more.\nTake off the chair’s cushion.\nStarting with the outside back of your chair, measure the width and length.\nIf you want the slipcover to go all the way to the floor, measure to the floor.\nAdd 4 inches to your width and length measurements and cut your muslin piece.\nThis extra amount allows adequate muslin to create your seam allowance.\nPin it to the back of the chair with straight pins.\nWith tailor’s chalk, carefully follow the seams that are already on your armchair, tracing lines with your chalk right on your pinned muslin.\nMake sure your lines are straight; use your ruler or L-square if that helps you.\nRemove the muslin and using your fabric marker and ruler, draw another line a 1/2-inch to the right from the chalk line that you traced in Step 5.\nThis mark is the cutting line and reflects your 1/2-inch seam allowance.\nWith your scissors, cut the muslin piece out using the second line you drew in Step 6.\nWith your fabric marker, write on the back: Back, Cut 1.\nMeasure your chair’s side.\nFollow the same instructions in Steps 1 through 7. Add 4 inches to each measurement, measure and pin the muslin to the chair, chalk around the seams to get the shape, add your 1/2-inch seam allowance in fabric marker, and cut out your piece. This piece is your side pattern; mark it Side, Cut 2, reversing one. To get a mirrored pair of sidepieces, you must flip the pattern over when you cut the second piece unless your pattern piece is truly rectilinear.\nFor the inside seat area, measure from the bottom of the seatback up and over the top of the chair, to the back area (where you made your first pattern), and be sure to add 4 inches to each measurement.\nChalk a line on the top where the fabric bends to meet the chair back pattern.\nPin, chalk, remove your muslin, add a 1/2-inch seam allowance line around your chalk marks using your fabric marker, label it Seatback, Cut 1, and cut out your pattern.\nFor the inside armrest area, you have to go over the top to meet your side pattern, and make sure to chalk a line at the bend.\nPin, chalk, remove, add your 1/2-inch seam allowance line, cut out your pattern, and label it Inside arm rest, Cut 2, reversing one.\nCreate your seat pattern.\nStart at the crease where the seat meets the seatback and go down to the floor in front of the chair. Repeat the steps as previously to create your muslin pattern and label it Seat, Cut 1.\nCreate a pattern for the front of the armrests.\nRepeat all the previous steps to create your muslin pattern, and label it Front armrest, Cut 2, reversing one.\nYou also need to cover your seat cushion.\nThis cushion cover looks like a tube, and it’s easy to make. To make the first pattern:\nMeasure the cushion’s width and the circumference and add a 1/2-inch to each measurement. Create your pattern in muslin and label it Cushion top, Cut 1.\nMeasure the cushion’s front and back. If your cushion is square, these measurements are equal. Add a 1/2-inch to each measurement. Create your pattern and label it Cushion sides, Cut 2.\nPin the muslin pieces together working right on the armchair.\nA 1/2-inch in from the cut edge of the muslin fabric is where the pieces need to join. Use straight pins, or safety pins, the latter for more hold.\nAfter you pin your muslin, remove the muslin and, using a baste stitch, start sewing your pieces together, making sure to check the slipcover as you sew every few seams to make sure the fit is correct.\nHem the bottom.\nFor your cushion, sew the two ends of the long piece of muslin into a tube.\nStarting at the corner, pin in one rectangular piece of muslin into the open area, or the tube’s mouth, and stitch it in using a 1/2-inch seam allowance.\nStitch only one long seam on the other side so you can insert your cushion to check for the fit.']	['<urn:uuid:4b3a11fc-eb42-4986-9a10-afb1754f492a>']	open-ended	direct	concise-and-natural	similar-to-document	single-doc	expert	2025-05-12T23:47:20.322175	9	38	760
34	positive changes market competition brought to medical services	Markets have brought several beneficial changes to healthcare including new payment models, telemedicine, a shift from inpatient to outpatient care, and narrow networks which allows for lower prices.	['This is the last part of the Fundamentals of U.S. Health Policy series! And it’s a super interesting one. Michael Chernew, Ph.D., wrote about the role of market forces in U.S. health care. Since this is squarely in my area of focus, I have a lot of thoughts. Thus, this week I’ll stick to summarizing Dr. Chernew’s article, and then next week I’ll provide some commentary.\nForewarning, I’m following the paper’s logic flow, which, to my brain, is a little meandering, so it’s easy to lose one’s place, but I’ll clarify as much as I can now and then attempt to provide additional insight next week.\nRemember how Total Healthcare Spending = Price x Quantity? (Well, actually, it’s the sum of the price x quantity of all the different services being provided in our healthcare system.) Dr. Chernew is basically using that equation when he starts out by saying that our challenge is to reduce the quantity of low-value services provided and to lower prices.\nAnd then the big question . . .\nWhat role should markets play in doing that?\nHe finally gets to the answer at the end, which is that markets and government should both be used to complement each other. Markets can be leveraged inasmuch as they will help, and this should be paired with the government regulations needed to help them work as well as they can.\nI won’t list his specific recommendations quite yet about how we could do that because first I need to review what he says in the rest of the article about markets and how they work.\nFirst, he says that markets are the “foundation of our economy,” and they promote efficient production and cost-reducing innovation. He doesn’t exactly give the step-by-step explanation of how they do that, but you can gather it from his next several paragraphs. Markets create competition, which is when consumers (in this case, patients) have “the ability and incentives . . . to seek low-price, high-quality providers. . . .” And because of that competitive pressure to win consumers, the players in a market are forced to innovate in ways that make production more efficient.\nGreat, so a good healthcare market will help patients choose low-price, high-quality providers. Unfortunately, healthcare markets are more imperfect than other markets. Want a big piece of evidence for this? Look at the extent of unwarranted price variations that exist in healthcare. It’s way more than in other markets.\nBut why is the healthcare market so bad?\n“Competition in health care fails for several fundamental reasons. First, patients often lack the information needed to assess both their care needs and the quality of their care. Second, illness and health care needs are inherently difficult to predict, exposing people to financial risks that they must insure against. This risk gives rise to an insurance system that shields patients from the price of care, dampening their incentive to use care judiciously and to seek care from providers offering high-quality care at affordable prices. The information problem, amplified by insurance, reduces the ability and incentives for patients to seek low-price, high-quality providers and impedes well-functioning markets. This problem has been magnified lately by consolidation of health care providers.”\nSo, basically, it’s difficult for patients to really know what care they need, they have a hard time assessing quality of care, they’re shielded from prices because of insurance, and consolidation has limited their options. The result of all that is they have neither the ability nor the incentives to choose low-price, high-quality providers.\nThis, by the way, sounds almost exactly like what I’ve written (or linked to) a thousand times before, which is that patients need to start making value-sensitive decisions, and to do that they need (1) multiple options, (2) the ability to identify the value of each option, and (3) the incentive to choose the highest-value option.\nRegarding consolidation, he gives some interesting data, which show that only 51% of markets have 3 or more hospital systems.\nBased on all of that, many would conclude that we should abandon markets altogether in healthcare. But he says, “The weaknesses associated with market-based health care systems are severe, but that does not mean the market should be abandoned.”\nAnd then he proceeds to give a few examples of beneficial things that have come from markets already, such as new payment models, telemedicine, a shift from inpatient to outpatient care, and narrow networks (which allows for lower prices).\nThose, however, end up being overshadowed by the list of ways we’ve tried and failed to bolster market function by providing patients with better information about quality and prices and by changing insurance benefit designs.\nThe summary of this section of the paper is that giving patients better information about quality and prices have had very little success because . . .\n- Patients rarely use price- and quality-transparency tools\n- These sorts of decisions are complex\n- Patients fear disrupting their relationships with their physicians\nChanging benefit designs to get patients to directly pay for more of their care (e.g., implementing high deductibles) has had a larger effect on utilization, but it hasn’t significantly impacted the market because . . .\n- What tends to happen is higher-value and lower-value care both decrease\n- Not enough patients end up getting steered toward higher-value providers to actually impact market prices.\nHe provides his explanation for all these failures: “The core problem is that for markets to work, patients must face the economic consequences of their choices, but labor-market concerns dampen employers’ enthusiasm for adopting plans that impose such consequences.”\nIn the realm of getting patients to choose higher-value insurance plans, there’s been a little bit of headway with insurance exchanges, although there are many drawbacks to those, too . . .\n- Beneficiaries make poor plan choices\n- Insurance exchanges induce more price sensitivity, which leads people to choose lower-premium plans that impose greater financial risk on them, which they often cannot bear\nAnd, to make things worse, many of the downsides of insurance exchanges can worsen inequity.\nDr. Chernew is not exactly giving a glowing review of market-based reform attempts, is he? His comments are all accurate though.\nNext, though, he says that “in evaluating their merits, we need to compare them with other systems, such as government-run models.” And government-run models have their own set of limitations.\nLuckily, we are not facing an either-or decision. The important question is how government and markets can complement one another. “We do not need to abandon markets–we can make them better.”\nFinally, getting to his recommendations about how to use markets and government to complement each other, he says we could work to increase the effectiveness of transparency initiatives, limit provider consolidation, and impose gentle regulations to prevent the most severe market failures (like limits on surprise billing and instituting price caps on the most excessive prices).\nDr. Chernew’s conclusion is that, “If we fail to improve market functioning, stronger government involvement will most likely be needed.” Agreed.\nNext week, I’ll give my thoughts on all this!']	['<urn:uuid:c49e0bc8-39fc-4713-be9c-670e4394c2ad>']	factoid	direct	long-search-query	distant-from-document	single-doc	novice	2025-05-12T23:47:20.322175	8	28	1179
35	mental health signs physical effects anxiety	Anxiety and stress can manifest both mentally and physically. Mental symptoms include lack of motivation, irritability, anger, and difficulty concentrating. Physical symptoms include increased heart rate, rising blood pressure, muscle tension, upset stomach, lack of sexual desire, and changes in appetite. If left unchecked, chronic stress can lead to more serious health problems like heart disease, high blood pressure, gastrointestinal problems, heart attacks, and strokes. Children and teens may be particularly vulnerable, showing additional signs like changes in behavior, social withdrawal, and difficulty sleeping.	"['Fear, uncertainty, angst and anxiety are certain to escalate with children and teenagers who tend to lean towards anxiety in the first place. The outbreak of the highly contagious coronavirus (COVID-19) and the media coverage regarding this disease affects our children greatly whether they are articulating their feelings or not. We can help our kids with anxiety cope with the outbreak COVID-19.\nAfter the “Yes! We are out of school for another two weeks!” passes, and their lives are suddenly changed from what they know to be true, kids’ anxiety can surface internally. Our kids are witnessing the sheer panic among adults with the lack of toilet paper, hand sanitizer, rubbing alcohol, and medical masks. They witness what many kids have said to me, “This might be the end of the earth.”\nChildren and teens may have a particularly hard time making sense of what’s happening in such a scenario, given their pending brain maturation, their lack of experience, and their inherent suggestibility and vulnerability. Seemingly endless news cycles may feel overwhelming, confusing and scary to a child or teen. Children typically possess lesser abilities to decipher and understand from the news, the extent of risk that a disease outbreak poses to them or to their loved ones and friends. This can create a sense of panic amongst children. This may be more challenging when a child/teen is already suffering from an anxiety disorder or predisposed to feeling more anxious in unusual or new situations.\nHow a child responds to news of the coronavirus may depend on several factors, such as:\n- age of the child,\n- language/comprehension abilities and developmental level of the child,\n- presence, severity and type of anxiety disorder(s) or other psychiatric conditions,\n- prior history of trauma or serious illness of loved ones or self,\n- occurrence of other recent stressors or major life events (such as parental divorce, death of loved ones, major move, change of school), etc. Therefore, a parent’s response would need to be tailored to the individual situation and context surrounding their child/teen.\nListed below are some tips for communication with a child or teenager who is feeling anxious regarding the coronavirus.\nKids observe our behaviors to determine their own feelings. When we appear to be panicking and freaking out, they quickly determine there is reason to be frightened.\nThe most important and impactful form of communication to your child/teen is your own behavior. Children typically tend to be perceptive and sensitive to the behavior of others in their surroundings. If you and other adults in the home are acting and behaving calmly, you are sending a clear message to your child/teen that there is no need to panic or worry. If you are acting a fool by constantly watching for updates on television or social media, over discussing the pandemic, or running to the nearest store for toilet paper, just know they are feeding off of your behaviors. Monitor your own feelings and behaviors. Take time to enjoy extra time with your kids by playing a board game, going on a walk, or sitting outside and talking.\nChildren sense their parents’ anxiety even when parents are not voicing or expressing their anxiety related thoughts or fears. Carving a few minutes for yourself for mindful breathing pauses during the day may help you model calm for your child/teen.\nSignificant changes to daily routines or schedules are stressful for children and convey to the child that you are very concerned or there is a crisis. As soon as the school districts called a hiatus on school, our kids’ lives changed suddenly and dramatically. Make new schedules and adhere to them as much as possible. Be creative and use the millions of websites where you can gain “homework” or ideas for your kids to continue learning and reading. Consistency is key. With school closed, kids tend to miss the structure and routine and rarely know what to do with their new spare time that proves to be educational or healthy learning. Devices are overly used and serve as babysitters. Kids even get tired of the devices, believe it or not.\nSitting around idle or on a device without a plan for the day is likely to escalate anxiety, especially for teens already suffering from anxiety. On the other hand, if your child/teen happens to suffer from Obsessive Compulsive Disorder (OCD) related to maladaptive perfectionism and has a need for excessive structuring, adding more structure would not apply to your child/teen. In this case, you would need to work with your child’s therapist/psychiatrist to determine the best strategy to navigate this situation, taking into account the unique circumstances of your child.\nListen to your child/teen’s feelings, worries, fears and questions about coronavirus. Children may receive their news about coronavirus from friends, neighbors, parents, internet, TV, home or elsewhere. They may worry that the worst may happen to them and/or their friends and loved ones. Ask questions in a non-judgmental and empathetic manner. Show your child/teen that you are present and interested in hearing their thoughts and feelings. This will make it easier for your child/teen to approach you with their thoughts and feelings in future as well. You can find more information on Active Listening at CDC (Centers for Disease Control and Prevention)’s ‘Essentials for Parenting Toddlers and Preschoolers’ here: https://www.cdc.gov/parents/essentials/overview.html\nAcknowledge your child’s feelings. Let your child know you hear what they are saying. Discounting their fears only teaches them to stop talking to you. Be careful not to dismiss, invalidate, make fun of or reject their feelings. You may also inform your child that it is common to feel this way; many other people (including children) experience similar feelings. Many people have shared with me that they worry when validating their child’s feelings, it increases the feeling. Validating someone’s feelings does not mean you agree with the beliefs underlying those feelings, but, it means you acknowledge the presence of those feelings and that you understand that such feelings are a part of the human experience. Validating is very powerful as it helps the person feel understood. This is especially important for children as they rely on and check with parents/teachers to make sense of their emotional experiences, particularly experiences or situations that are new or unusual for them. Validation can help the child feel calmer and enhance the child’s ability to process their emotions. Frequent invalidation of a child/teen can lead them to be confused about or doubt their own feelings as they grow up and may contribute to low self-esteem or sense of self, besides potentially affecting or even rupturing your relationship with them in the long-term.\nHelp Sit with Anxiety:\nEncourage your child to practice sitting with and experiencing the anxiety, rather than doing something to relieve it or distract from it. Sitting with the anxiety is challenging at first because we are not taught to do this. Teach your child to sit with the feelings – feel them – and ride the wave of these feelings with breathing techniques, listening to a mindfulness app, and to verbalize their feelings and not avoiding them. This can prove to be challenging and unpleasant until the child learns to feel the feelings, verbalize the feelings, and allow the feelings to pass with the best techniques that work for them. Normalizing the experience of anxiety allows the child/teen to work through it.\nSuggestions for Mindfulness/Meditation/Coping Skills\n- Small kids/Breathe-think—do-with-sesame: https://itunes.apple.com/us/app/breathe-think-do-with-sesame/id721853597?mt=8&at=1l3v7C7\n- Tweens and teens/Calm: https://itunes.apple.com/us/app/calm-meditation-to-relax-focus-sleep-better/id571800810?mt=8&at=1l3v7C7\n- Kids and teens: Dreamy Kids: https://itunes.apple.com/us/app/dreamykid-meditation-app-just-for-kids/id1161307071?mt=8&at=1l3v7C7\n- Kids and Teens: Headspace: https://itunes.apple.com/us/app/headspace-guided-meditation-and-mindfulness/id493145008?mt=8&at=1l3v7C\nKnow the Facts and Direct towards Facts:\nYour child/teen is hearing about the novel coronavirus from several sources! Do not shy away from approaching or discussing it. Be proactive in talking to your child/teen about facts regarding the coronavirus. For this, you will need to equip yourself with and read about the facts around coronavirus first. Ensure that you are getting your facts from reliable sources, such as the CDC: https://www.cdc.gov/coronavirus/2019-ncov/faq.html.\nFor an older child/teen, point them in the direction of scientifically authentic and reliable sources of news information about coronavirus. Inform your older child/teen that every new story may not be complete or show the big picture. This is an excellent way to spend time with your teenager! Educate yourself as well as your older child/teen on distinguishing reliable and scientific sources of information about coronavirus from non-reliable ones. Inform your child/teen about the facts that you know about coronavirus, in a developmentally suitable way (in terms and amounts that they can grasp at their age and comprehension level).\nChildren may have heard news about deaths from coronavirus. For older children who are more likely to understand the concept of death and its finality, you can educate them that most people do not die from this disease, rather, most get better. Regardless of the age of your child, if your child asks specific questions about deaths from coronavirus, do not avoid those; ask them what they think and know, and explain facts to your child in a simple way that is digestible for their age and developmental level, and is situationally appropriate. Ask them further about their concerns. Let your child/teen know that you are available if they want to talk further or have any questions.\nLimit Excessive Reassurance:\nChildren or teens, who are feeling anxious or suffering from anxiety disorders, may repeatedly ask their parents for words or gestures of reassurance. Excessive reassurance may be in the form of repeated requests for gestures of comfort, repeated questions to verify safety of self and others, repeated requests for checking or repeating or asking you to repeat facts of the situation to reassure self, etcetera. While you may have an urge to provide such reassurance and such reassurance may give you the impression that it is helping at that moment, excessive reassurance actually serves to reinforce and increase anxiety in the long term. Therefore, it is advisable to limit excessive reassurance. Also, aim to provide a high ratio of positive to constructive feedback for your child/teen when they engage in appropriate behavior. Parents who are suffering from anxiety disorders, may find it particularly challenging to limit such reassurance and may benefit from professional help for themselves to address these challenges.\nLimit and Monitor News/Media Exposure:\nMost children and adolescents in the US (and in large parts of the world) watch hours of TV and other media daily. Limiting and monitoring the exposure of your child/teen to news cycles can be one step towards helping them regulate their anxiety. The younger the child, the greater their need for limiting exposure to news. For older children too, parental monitoring and guidance to help navigate the confusing and often scary news about coronavirus, is needed.\nConsult, Collaborate with Healthcare Professionals:\nIf your child/teen is suffering from an anxiety disorder or other psychiatric condition, talk to your pediatrician and arrange for a consultation with a mental health professional, if you haven’t done so already. Most treatments for anxiety in children and teens should involve psychotherapy. There are various modalities of psychotherapy that can be beneficial for anxiety; Cognitive Behavioral Therapy (CBT) is one form of psychotherapy that has substantial evidence of benefit for treatment of anxiety in children and adolescents. If your child/teen already is under the care of a mental health professional, work closely with that professional to help your child navigate this unusual time.\nIt is important during this time to take care of your own mental health as well. I recently blogged about Overcoming Worry however if you are feeling stuck and need to talk, I would love to meet you! Email or call anytime to schedule an in-person or virtual session. (817) 701-5438 | firstname.lastname@example.org\nCRT, CCDC, CACC | Counselor & Life Coach\nEmpowering individuals, families and communities to grow and heal through advanced approaches in Creative Arts Therapy, setting the standard for treatment, practice and training within the field.', ""How Does Stress Affect The Body: Symptoms And Solutions\nUpdated August 27, 2020\nMedically Reviewed By: Lori Jones, LMHC\nAre you exhausted all the time? Do you have a lot of muscle tension and pain? Is your head or stomach bothering you? It could be stress. There is a long list of symptoms that falls under the question, “How does stress affect the body?” And, learning how to identify the symptoms can help you find the right solution.\nStress levels have been on the rise in Americans over recent years. It’s impacting people of all ages and spans a wide range of worries and concerns.\nThe Impact Of Chronic Stress\nEveryday stress can have a negative impact on multiple areas of your life. However, when the stressful situation passes, you may find that things return to normal even if you didn’t do anything to address your stress. This isn’t the healthiest way to get through stress, but it happens this way for some people.\nHowever, if you’re experiencing chronic stress, it’s not going to just go away. It may not be tied to a specific situation in your life. Instead, it might be the result of poor habits or not knowing how to deal with past trauma. It will not just go away if left untreated.\nThe Effect Of Stress On The Body\nStress can wreak havoc on your body if it’s left unchecked. Not only does occasional stress show up in your body, but chronic stress can also have long-term negative consequences for your physical health. When you are feeling stressed, you may experience:\n- Increased heart rate\n- Rising blood pressure\n- Muscle tension\n- Upset stomach\n- Lack of sexual desire\n- Change in appetite\nAnd these are just a few of the symptoms that you may experience. If you suffer from chronic stress, the symptoms above can start to turn into more serious health consequences.\nChronic stress can lead to health problems such as heart disease, high blood pressure, gastrointestinal problems, heart attack, and strokes, among others. These are clear indicators that allowing chronic stress to continue in your life can be detrimental to your physical health and well-being.\nHow Stress Affects Mental Health\nStress also impacts your mental health and wellness. It can lead to you experiencing many different negatives and difficult emotions such as sadness, anger, frustration, and fear.\nSome of the mental health symptoms that you may notice in your life from stress include:\n- Lack of motivation\n- Irritability and anger\n- Lack of concentration and focus\nThese are serious symptoms that should not be taken lightly. If you experience chronic stress, you may begin to think that these symptoms are just a normal part of life. But, they’re not. All of these symptoms can grow into more serious problems if you don’t work on addressing them.\nHow Stress Affects Behavior\nStress can also impact your behavior. If you look at the symptoms listed above under physical and mental health, it can be easier to understand how stress changes your behavior. If you’re living under constant overwhelm and anxiety and experiencing things like frequent headaches or stomach aches, it can be easy to lose your temper with your loved ones, for example. Here are some of the other behavioral changes that you may experience in your life as a result of stress:\n- Angry outbursts\n- Eating too much or not enough\n- Substance use or abuse\n- Social withdrawal\nThese behaviors can have a negative spiral effect on your life. For example, as your withdrawal from friends and family because of stress, you may find that you struggle even more to cope with stress in your life. This can lead to additional problems which keep you away from a social activity even more. This is why it’s important to learn to recognize and healthily address your stress.\nStress Management Tips To Overcome Chronic Stress\nThankfully there are many things that you can do to address your chronic stress and learn to overcome it. This doesn’t mean that you’ll never experience stress again. Instead, it means that when you do go through stressful situations, you’ll have tips and strategies that you can use to relieve stress and handle it healthily.\nSome of the stress management solutions you may benefit from include:\nLearn to identify your stress triggers\nWhen you start to feel stressed, it can be helpful to take time to identify where the feelings are coming from. This allows you to begin investigating what you can do to make to address it.\nWhile there will be some things causing you to stress that you can’t do anything about, there will be some things that you can address. For example, if a family member’s behavior is causing you to feel stressed, you probably aren’t going to be able to control how they are behaving. But you may be able to establish boundaries in your life that stop the other person’s behavior from having as large of a negative consequence on you.\nThere will be some things that you find are short term stressors. But there also might be habits that you identify that are causing you unnecessary stress. When you learn where the stress is coming from, you can start to take your first steps to address or removing it.\nPractice Deep Breathing\nWhen you’re starting to feel the stress and tension build up within your body, deep breathing can help to break up some of the physical symptoms that you’re experiencing. For example, you may notice that you start to breathe faster as your frustration grows. This can cause your heart to race, as well. And, as your heart beats faster, your blood pressure rises. These physical symptoms can continue to build and even lead to things like full-blown panic attacks.\nDeep breathing can help to stop your physical symptoms from progressing. As you start taking slow, deep breaths in and out, you may notice that it feels like your blood pressure is lowering, and your heart rate is returning to normal.\nYou may also find that deep breathing can help you to slow your thoughts. Your mind will be forced to temporarily shift from your stress and worry to the breathing technique that you’re using. This can help you to regain mental clarity and look for solutions to the stressful situation or problem that you’re facing.\nThere are multiple types of breathing techniques that you can use, so practice a few of them to find what works best for you. It can also help to practice them when you’re not under stress, so when you find your stress starting to build, you will know how to put the breathing exercise to use without too much thought.\nNot getting enough sleep can make it even harder to deal with stress. You may find that you struggle to be patient with others, and you cannot think clearly to look for solutions. If you’re having problems falling asleep or staying asleep due to stress, it’s an important symptom to address.\nMany different things may help improve sleep troubles. A few that you could try include:\n- Keeping a strict sleep schedule\n- Cutting out caffeine\n- Not exercising too close to bedtime.\n- Sleeping in a dark, cool room\n- Using white noise\nHowever, if you’re continuing to struggle, don’t be afraid to talk with your doctor to explore additional options.\nGet More Physical Activity\nPhysical activity and exercise can help you release tension that has built up from chronic stress. It also releases chemicals in your brain that work to boost your mood. But these chemicals also act as natural pain killers, which can help reduce some of the physical symptoms you’re experiencing.\nThere are other ways that physical activity and exercise can help with stress. You may find that you sleep better when you exercise. And, you may experience a boost in your self-esteem as well.\nThe Anxiety and Depression Association of America shares that you may start to experience these positive mental boosts after just five minutes of physical activity. So, if you’re feeling stressed, you don’t need to feel like you have to get in a full workout. Simply getting moving for a few minutes can start to help.\nTalk To Someone\nHaving a trusted person to turn to for support can help when you’re going through stressful situations or experiencing chronic stress. This could be a friend or family member. It could also be a support group. For example, if you’re under stress as a result of losing a loved one, you may benefit from connecting in a group for others experiencing grief from losing someone.\nIf you don’t have anyone to turn to or could use additional support in handling your stress, a licensed therapist is an effective option to consider. Not only can they listen as you talk through the stress in your life, but they also have education on how to help you overcome it. A therapist, like those at BetterHelp, can assist you in finding stress-relieving strategies that work for your specific situation.\nPrevious ArticleHow Stress Can Lead To Emotional Breakdowns And What You Can Do To Avoid It\nNext ArticleAre You Under Too Much Stress? Symptoms, Treatment And Tips\nLearn MoreWhat Is Online Therapy? About Online Counseling\nAbuse ADHD Adolescence Alzheimer's Ambition Anger Anxiety Attachment Attraction Behavior Bipolar Body Dysmorphic Disorder Body Language Bullying Careers Chat Childhood Counseling Dating Defense Mechanisms Dementia Depression Domestic Violence Eating Disorders Family Friendship General Grief Guilt Happiness How To Huntington's Disease Impulse Control Disorder Intimacy Loneliness Love Marriage Medication Memory Menopause MidLife Crisis Mindfulness Monogamy Morality Motivation Neuroticism Optimism Panic Attacks Paranoia Parenting Personality Personality Disorders Persuasion Pessimism Pheromones Phobias Pornography Procrastination Psychiatry Psychologists Psychopathy Psychosis Psychotherapy PTSD Punishment Rejection Relationships Resilience Schizophrenia Self Esteem Sleep Sociopathy Stage Fright Stereotypes Stress Success Stories Synesthesia Teamwork Teenagers Temperament Tests Therapy Time Management Trauma Visualization Willpower Wisdom Worry\nFeeling Overwhelmed? Learn These Stress Management Strategies How To Stop Stressing: 7 Tips To Find Balance And Relax How Stress Can Lead To Emotional Breakdowns And What You Can Do To Avoid It Are You Under Too Much Stress? Symptoms, Treatment And Tips 7 Tips On How To Handle Stressful Situations Stress Management That Works: How To Be Less Stressed""]"	['<urn:uuid:96071681-3e76-4d11-9cc1-5eac8bd91593>', '<urn:uuid:1fe21db8-8096-462d-a9b3-85cbac331785>']	open-ended	with-premise	short-search-query	distant-from-document	multi-aspect	novice	2025-05-12T23:47:20.322175	6	84	3704
36	Why do certain types of antibiotics make us more vulnerable to C. diff?	Certain broad-spectrum antibiotics (particularly cefoperazone, clindamycin and vancomycin) kill off beneficial gut bacteria, specifically from the Lachnospiraceae and Ruminococcaceae families, that normally convert primary bile acids into secondary bile acids. These secondary bile acids inhibit C. diff growth, so when they are absent due to antibiotic treatment, C. diff is able to grow rapidly in the large intestine.	"['New research from North Carolina State University and the University of Michigan finds that bile acids which are altered by bacteria normally living in the large intestine inhibit the growth of Clostridium difficile, or C. diff. C. diff is a harmful bacterium that can cause painful and sometimes fatal infections. The work sheds light on the ways in which some commonly used antibiotics can promote C. diff infections by killing off the bile acid-altering microbes.\nC. diff exists in the environment as a dormant spore. To colonize the gut, C. diff. spores need to germinate and become growing bacteria that produce toxins and damage the large intestine. Researchers know that the use of certain antibiotics lead to a higher risk of C. diff infections, particularly among hospital patients. Casey Theriot, an assistant professor of infectious disease at NC State, wanted to know exactly how C. diff spores were interacting with the microbiota, or natural bacterial environment, within the gut.\n""We know that within a healthy gut environment, the growth of C. diff is inhibited,"" Theriot says. ""But we wanted to learn more about the mechanisms behind that inhibitory effect.""\nBile acids are made from cholesterol and aid in the digestion and absorption of fats. They also control lipoprotein, glucose, drug and energy metabolism. Primary bile acids are made in the liver and travel through the intestinal tract. In the large intestine, bacteria convert these to secondary bile acids, of which Theriot found many have an inhibitory effect on C. diff growth.\nTheriot started the project while a research investigator at the University of Michigan with infectious diseases physician Vincent Young and undergraduate researcher Alison Bowman. The researchers looked at the intestinal contents of mice before and after treatment with many different antibiotics. They identified 26 different primary and secondary bile acids and defined the concentrations of those acids before and after treatment. Then they added C. diff spores to the contents in order to find out how the bacterium may germinate and grow in an actual gut environment.\nInterestingly, they found that the primary bile acids in the small intestine allowed spores to germinate, or begin to grow, regardless of the antibiotic treatment.\nBut when the spores reached the large intestine, where normal gut bacteria generate secondary bile acids, the researchers found that those secondary bile acids stopped the C. diff from growing. When those bacteria -- and the secondary bile acids -- were not present following antibiotic treatment, the C. diff was able to quickly grow.\n""These findings are a first step in understanding how the gut microbiota regulates bile acids throughout the intestine,"" says Theriot. ""Hopefully they will aid the development of future therapies for C. difficile infection and other metabolically relevant disorders such as obesity and diabetes.""\nThe researchers\' findings appear in mSphere. The research was funded by the National Institutes of Health (grant K01GM109236).\nNote to editors: an abstract of the paper follows.\n\'Antibiotic induced alterations of the gut microbiota alter secondary bile acid production and allow for C. difficile spore germination and outgrowth in the large intestine\'\nAuthors: Casey M. Theriot, NC State University; Vincent B. Young, Alison A. Bowman, University of Michigan\nPublished: Jan. 6, 2016 in mSphere\nIt is hypothesized that the depletion of microbial members responsible for converting primary bile acids into secondary bile acids reduces resistance to C. difficile colonization. To date, inhibition of C. difficile growth by secondary bile acids has only been shown in vitro. Using targeted bile acid metabolomics, we sought to define the physiologically relevant concentrations of primary and secondary bile acids present in the murine small and large intestinal tract and how these impact C. difficile dynamics. We treated mice with a variety of antibiotics to create distinct microbial and metabolic (bile acids) environments, and directly tested their ability to support or inhibit C. difficile spore germination and outgrowth ex vivo. Susceptibility to C. difficile in the large intestine was observed only after specific broad-spectrum antibiotic treatment (cefoperazone, clindamycin and vancomycin) and was accompanied by a significant loss of secondary bile acids (DCA, LCA, UDCA, HDCA, and ωMCA). These changes were correlated to the loss of specific microbiota community members, the Lachnospiraceae and Ruminococcaceae families. Additionally, physiological concentrations of secondary bile acids present during C. difficile resistance were able to inhibit spore germination and outgrowth in vitro. Interestingly, we observed that C. difficile spore germination and outgrowth was supported constantly in murine small intestinal content regardless of antibiotic perturbation, suggesting that targeting growth of C. difficile will prove most important for future therapeutics and antibiotic related changes are organ-specific. Understanding how the gut microbiota regulates bile acids throughout the intestine will aid the development of future therapies for C. difficile infection and other metabolically relevant disorders such as obesity and diabetes.']"	['<urn:uuid:4d7676b1-193c-4619-bddd-c27569872d07>']	open-ended	with-premise	concise-and-natural	distant-from-document	single-doc	expert	2025-05-12T23:47:20.322175	13	58	795
37	vietnam singapore double tax main strategy	The main strategy for avoiding double taxation is the foreign tax credit (FTC) program. The FTC is a decrease in foreign taxes paid on a dollar-for-dollar basis.	['Vietnam and Singapore DTAA\nIn today’s dynamic and expanding economy, taxation serves as a vital mechanism for governments to generate revenue. As businesses increasingly engage in cross-border transactions and activities to foster growth and global reach, they may encounter the challenge of double taxation – a situation where the same income is subject to taxation in both the home country and the foreign country.\nTo address this issue and promote seamless business operations between Singapore and Vietnam, the governments of both countries have proactively negotiated and established the Double Taxation Avoidance Agreement (DTAA).\nThrough this guide, we would briefly discuss the Vietnam-Singapore DTAA and its related aspects.\nOverview of the Vietnam and Singapore double taxation avoidance agreement\nThe Vietnam and Singapore Double taxation avoidance agreement is an accord ratified between the governments of Vietnam and Singapore that aims at eliminating double taxation and fiscal evasion of income taxes. The Vietnam and Singapore DTAA lays out the regulations and procedures for taxing various forms of income received by citizens as well as corporations incorporated in Singapore and Vietnam.\nThe Vietnam and Singapore double taxation avoidance agreement was entered into force on 9 September 1994 and took effect on 1 January 1993. The second protocol pertaining to Vietnam and Singapore was signed on 12th September 2012 and entered into force on 11 January 2013. Citizens of one or both of the contractual nations of Singapore and Vietnam would be subject to the provisions of this treaty.\nAvoiding double taxes under the Vietnam-Singapore DTAA\nThe primary motive behind signing the DTAA between Vietnam and Singapore is eliminating double taxes on income generated in either of the two nations. The main strategy for avoiding double taxation is the foreign tax credit (FTC) program. The FTC is a decrease in foreign taxes paid on a dollar-for-dollar basis.\nAccording to the DTAA requirements, dividends, royalties, and interest are subject to income tax in the state where the beneficiary resides as well as withholding tax in the state where the business receiving the dividends resides. Taxpayers may utilize the foreign tax credit to lessen their tax obligation and benefit from the DTAA’s decreased withholding taxes on dividends, interest, and royalties.\nTaxes included by the DTAA between Vietnam and Singapore\nIncome taxes assessed on behalf of a contractual nation, its political subdivisions, or regional bodies are covered by the Vietnam-Singapore DTAA regardless of how they are collected. All taxes levied on the overall amount of revenue or specific components of earnings, such as taxes on gains from the sale of personal or real property, shall be considered income taxes.\nThe current taxes that the agreement will cover are:\nA. In Singapore\n- Income tax\nB. In Vietnam\n- Personal income tax\n- Foreign contractor tax\n- Foreign petroleum sub-contractor tax\n- Profit remittance tax\n- Profit tax\nAny taxes that are levied on top of, or instead of, the current taxes that are the same or significantly comparable are likewise covered by the DTAA.\nTax residency as per the Vietnam and Singapore DTAA\nAs per the Vietnam and Singapore DTAA, an individual who is a “resident of a Contracting State” is one who, as per the legislation of that particular country, is subject to paying taxes there because of their domicile, location of residence, business, or any other comparable criteria.\nIndividuals tax residency\nIf a person resides in both contractual nations, the following criteria must be used for assessing his status:\n- The person will be regarded as a resident of the nation in which the individual has a permanent abode.\n- In case the person has a permanent resident in both jurisdictions, then the person will be regarded as a resident of the jurisdiction where his personal and professional ties are closest.\n- The person is a resident of the jurisdiction where they have a habitual habitation if the aforementioned criteria are difficult to be met.\n- The tax officials of the two states are required to resolve the issue by mutual agreement, regardless of whether the person resides habitually in one of the two nations or neither.\nTax residency for legal organizations\n- If a business is a resident of more than one state, it ought to be regarded as a resident of the one where its location of effective management is located.\n- If it is impossible to identify the location of effective management, the issue will be resolved by consensus between the tax officials of both nations.\nPermanent establishment as per the Vietnam-Singapore DTAA\nAs per the Vietnam-Singapore DTAA, permanent establishment usually means an established location for a company where the corporation conducts all or part of its commercial activities. “Permanent establishment” refers to various structures, including a center of management, a branch location, a factory, and a workshop.\nTaxes are required to pay on earnings as per the Vietnam and Singapore DTAA\n|Kinds of Income\n|Where is it taxable?\n|Revenue generated from immovable property\n|Taxable in the jurisdiction in which the property is located.\n|Could be subject to taxation in both the state where the beneficiary resides and the state where the royalties are generated.\n|Could be subject to taxation in both the state where the beneficiary resides and the state where the dividends are generated.\n|Could be subject to taxation in both the state where the beneficiary resides and the state where the interests are generated.\n|Taxable in the jurisdiction in which the seller resides.\n|Liable for taxes in the state in which a business is managed and overseen\nRevenue generated from immovable propertyA resident of one contractual jurisdiction (Singapore) who receives income from real estate located in another contractual jurisdiction (Vietnam) can be covered by taxation in that other jurisdiction (Vietnam).\nRoyaltiesRoyalties that are generated from one contractual country (Singapore) and distributed to another contractual country (Vietnam) will be liable for taxation in the other country (Vietnam). But, these royalties can be taxable in the nation in which they originate (Singapore) and by its rules, although if the beneficiary of the royalties is a resident of the other nation (Vietnam), the tax thus imposed must not be higher than:\n- 5% of all gross royalties obtained as compensation for the application of any patents, the right to utilize patents, or for access to scientific information.\n- 15% of the royalties’ total value in all other circumstances.\nDividendsA corporation that is a resident of one contractual nation (Singapore) that pays dividends to a resident of another contractual nation (Vietnam) might be subject to taxation in that other jurisdiction (Vietnam). However, these dividends could also be taxed under the regulations of the nation where the dividend-paying firm resides, if the receiver is the beneficial owner of the dividends; in such case, the tax applied should not surpass:\n- 5% of the dividends’ total value if the beneficial proprietor has provided over US$10 million or over fifty percent of the dividend-paying organization’s capital, either directly or indirectly.\n- 7% of the dividend’s aggregate value if the beneficial owner paid from twenty-five percent to fifty percent of the dividend-paying business’s capital, either directly or indirectly.\n- In all other situations, 12.5% of the dividends’ aggregate value.\nInterestsInterest that is generated in one jurisdiction (Singapore) and given to a citizen of another jurisdiction (Vietnam) can be liable for taxation in that other jurisdiction (Vietnam). Nevertheless, such interest can be further taxed in the jurisdiction where it originates (Singapore) and by the legislation of that State; but, if the recipient is the interest’s beneficial owner, the tax thus levied must not surpass 10% of the interest’s total value.\nCapital gainsGains from the sale of all assets are typically only subject to taxation in the state where the seller resides. There are a few exceptions, though:\n- Gains from the sale of real estate located in Vietnam that belong to a resident of Singapore are subject to taxation in Vietnam as well.\n- Gains from the selling of movable assets that is a component of a PE’s commercial assets are also subject to taxation in the jurisdiction where the PE is located.\nCompany profitsThe profits of a corporation are solely taxable in the state where it has its legal residence unless the corporation has a Permanent Establishment (PE) in a different nation and conducts business there.\nThe Vietnam-Singapore DTAA plays a crucial role in fostering economic cooperation and trade between the two nations. In addition to that, Vietnam and Singapore’s double taxation avoidance agreement also provides a favorable environment for enterprises and individuals to participate in overseas operations without experiencing unnecessary tax liabilities by eliminating double taxation and giving clarity on tax duties.\nOur team of seasoned specialists at Odint Consulting is dedicated to offering you the best caliber of support and direction and is well-versed in the complexity of the Vietnam-Singapore DTAA. We are available to answer any questions you may have regarding this bilateral tax treaty, regardless of whether you are a startup, an established firm, or an individual. We can assist you in navigating the tax environment in Singapore and Vietnam and ensure you take advantage of the possible benefits due to our in-depth understanding of the DTAA’s provisions.\nThe Vietnam and Singapore double taxation avoidance agreement is an accord ratified between the governments of Vietnam and Singapore that aims at eliminating double taxation and fiscal evasion with regard to income taxes.\nThe Vietnam and Singapore double taxation avoidance agreement was entered into force on 9 September 1994 and took effect on 1 January 1993.\nThe DTAA is crucial because it avoids the chance that income may be taxed twice—once in Singapore and once in Vietnam—reducing the tax obligation for cross-border taxpayers. It gives tax liabilities stability and predictability, encouraging international trade, investment, and economic cooperation.\nThe foreign tax credit (FTC) program is the primary method for preventing double taxation. The FTC is a decrease in the amount of foreign taxes paid on a dollar-for-dollar basis.\nThe DTAA covers a number of different sources of income, including dividends, immovable property revenue, business earnings, interest, royalties, and capital gains.\nYes, the DTAA has provisions for information sharing between Singapore’s and Vietnam’s tax authorities in order to stop tax evasion and other financial abuse. This encourages transparency and improves both nations’ capacity to combat tax-related offenses.']	['<urn:uuid:82b5553b-4af9-48f8-9edd-47d179234032>']	factoid	with-premise	short-search-query	similar-to-document	single-doc	expert	2025-05-12T23:47:20.322175	6	27	1709
38	What specialized equipment does the NOAA ship Pisces have for detecting and identifying fish species in the water?	The Pisces is equipped with one of six multi-beam acoustic instruments in the world (NOAA owns five of them). This system uses SONAR with a split beam into quadrants, located on the center board beneath the ship. The benefit of this multi-beam instrument is that each beam can be set to different frequencies (kHz), enabling detection of more features and different species of fish.	['NOAA Teacher at Sea\nAboard the NOAA ship Pisces\nJune 16 – June 29, 2012\nMission: SEAMAP Caribbean Reef Fish Survey\nGeographical area of cruise: St. Croix, U.S. Virgin Islands\nDate: June 22, 2012\nWeather Data from the Bridge:\nAir Temperature: 28.6°C (83.5°F)\nWind Speed: 9 knots (10.5 mph), Beaufort scale: 3\nWind Direction: from SE\nRelative Humidity: 77%\nBarometric Pressure: 1,014.80 mb\nSurface Water Temperature: 28.1°C (82.6°F)\nScience and Technology Log\nAnother aspect (much more technical) of the scientific research conducted on this cruise is the collection of acoustic data. This field is continually evolving as the detection resolution improves allowing scientists to more precisely identify fish. This has been used with more success in fisheries farther north because the schools of fish are more likely to be monospecific (a single species). However, the technique still needs improvement in warmer waters where the fish assemblages tend to be multi-specific (having a much greater variety of fish).\nThis field of study is called Hydroacoustics (hydro- means water, and acoustics refers to sound). It is the science of how sound moves through water. Leonardo da Vinci noticed how sound travels through water in 1490. He noticed that, “If you cause your ship to stop and place the head of a long tube in the water and place the outer extremity to your ear, you will hear ships at a great distance from you.” (Urick, Robert J. Principles of Underwater Sound, 3rd Edition. New York. McGraw-Hill, 1983.) World War I helped promote innovation in the field, especially with the need for anti-submarine detection devices (Wood, A. B., From the Board of Invention and Research to the Royal Naval Scientific Service, Journal of the Royal Naval Scientific Service Vol 20, No 4, pp 1-100 (185-284)).\nHydroacoustic instruments utilize SOund Navigation and Ranging, more commonly referred to as SONAR. The ship Pisces is equipped with a system located on the center board; this is a flat structure that can be raised/lowered through the water column beneath the center of the ship.\nThe system used is a sonar beam that is split into quadrants. This instrument is used to assist in determining fish abundance and distribution. The premise is relatively simple: an echo sounder transmits a pulse of energy waves (sound), when the pulse strikes an object, it is reflected (bounced) back to the transducer. The echo sounder is then processed and sent to a video display. This is the same general process behind the recreationally available fishfinder.\n- A short burst of energy is focused into a narrow beam. When this beam encounters an object such as a fish, a school of fish, plankton, or other object, some of the energy bounces back up through the water to the transducer. It is the detection of these reflections that allow scientists to determine location, size, and abundance of fish. These reflections show up on our video monitor. These measurements are combined with groundtruthed data (for example, fish collected in the field, camera images).\nOne of the difficulties in data interpretation is that often, the signals that appear on the computer monitor have false readings. This is a result of the sound wave bouncing multiple times. It travels to the bottom from the transducer, strikes an object, returns to the ship, bounces off the ship back toward the bottom, strikes another object, and is detected yet again.\nThe Pisces is actually home to one of six multi-beam acoustic instruments in the world. Of the six in existence, NOAA has five of them. The benefit of running a multi-beam instrument is that each beam can be set to measure a different frequency (kHz), thus enabling detection of many more features (different species of fish, etc.)\nLast night the crew of the Pisces carried out a task that they don’t normally perform. The Pisces was created for fisheries research projects – it focuses on collecting fish samples either by bandit reel, longline, or trawling. This particular operation was to deploy the anchor for a buoy that will be attached at a later date. When the buoy is ready to be attached, another vessel will bring it out to the site and divers will go down to the anchor to make the final attachment.\nThe anchor consists of a huge rebar-reinforced concrete block with a very long chain that has marker floats attached at the end. Logistically, this took some planning; the A-frame had to be raised and the anchor lifted with the Gilson winch with a 1″ spectra line (has an enormous tensile strength). The gate to the ship’s ramp was lowered and the A-frame (or as the deck hands call it, the “Tuna Tower”) repositioned so the anchor was hanging over the water. The rope holding the anchor, chain, and float was cut through, and the anchor plunged to the ocean bottom. Again, the crew made the operation go smoothly and demonstrated their ability to complete unexpectedly assigned tasks.\nToday was a slow fishing day – no fish at all. Without any fish to “work up” (collect samples from), the day goes more slowly and we have more down time. With the extra time, I had a chance to interview Kevin Rademacher, the Chief Scientist on the cruise.\nLU: What is your official job title and what are your job duties?\nKR: I’m a Research Fisheries Biologist. I work for the Reef Fish Unit at the NOAA Fisheries Lab in Pascagoula, MS. I am the Senior Tape Reader/Reviewer, in charge of the readers that analyze the video data we collect from Reef Fish Surveys. I also help plan, organize, and run the surveys. Additionally, I participate in trawl surveys and anything else the lab needs done.\nLU: When did you first become interested in the ocean and marine sciences?\nKR: I guess that would have been when I was really young. There is a photo from the Panama City, Florida newspaper, two weeks after I was born with my parents pulling me in a homemade wagon along the beach! I knew in junior high school that I wanted to be a cross between Jacques Cousteau and Marlin Perkins of Mutual of Omaha’s Wild Kingdom.\nLU: It’s such a broad field; how did you narrow your focus down to what you’re currently doing?\nKR: I got lucky and kind of fell into reading underwater videos at the initial stages of the project and fell in love with being the proverbial “fly on the wall”! It has allowed me to see the fish in their natural habitat, different color phases, behavior, etc.\nLU: If you were to go into another area of ocean research, what would it be?\nKR: Marine Mammal Studies. After college I trained dolphins and sea lions and put on shows with them for a local Oceanarium on the Mississippi Gulf Coast.\nLU: What is the biggest challenge in your job?\nKR: Communicating with people and writing papers.\nLU: What do you think is the biggest issue of contention in your field?\nKR: The impression that commercial fishermen have regarding the work we do to regulate the fisheries they work in.\nLU: What are some effects of climate change that you’ve witnessed during your career in fisheries research?\nKR: The decline of coral reefs and overfishing of some species.\nLU: In what areas of marine science do you foresee a lot of career paths and job opportunities?\nKR: Ecosystem management and data modelers. There has also been a decline in taxonomists over the past few decades.\nLU: How would you explain your work to a layperson?\nKR: I use underwater cameras to help assess populations of reef fish, especially snappers and groupers. The data collected is used to manage those fisheries.\nLU: If a high school student wanted to go into your field of study/marine science in general, what kinds of courses would you recommend they take?\nKR: Math, Biology, Chemistry, and any other science courses available.\nLU: Do you recommend students interested in your field pursue original research as high school students or undergraduates? If so, what kind?\nKR: Most definitely! Whatever they are interested in would be beneficial.\nWell, only two more days left with the scientists before we pull into San Juan, Puerto Rico. We have 17 more daytime sites to sample and then this survey will be over. The scientific crew will be flying home on the 25th, and once home, their work will really begin. Back in the lab, they will be analyzing the data and reviewing the video. Some of them will be going back out on other cruises. Kevin Rademacher will be going out on another reef fish survey in the eastern Gulf of Mexico. It is currently delayed because of the potential formation of tropical storm Debby. Joey Salisbury has a couple more; he will be going on a longline cruise and then another reef fish survey, both of which will be in the Gulf of Mexico. Arian Frappier will be heading off to begin a masters program in marine systems and coastal studies at Texas A&M Corpus Christi.\nAfter a day’s shore leave in San Juan, I’ll continue on to Mayport on the Pisces. During this time, I’ll focus on the crew members and their jobs. The cruise will definitely take on a different feel at this point, but it will give me an opportunity to explore other ocean related careers.']	['<urn:uuid:e7556c60-ecbc-4e11-9af6-7de59f29dd02>']	factoid	direct	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-12T23:47:20.322175	18	64	1564
39	how long fireproof clothing protects driver flames	The protection time of fireproof clothing is determined by its TPP (Thermal Protective Performance) rating. The TPP rating divided by 2 equals the number of seconds until a second-degree burn occurs. For example, with a TPP rating of 35, it takes 17.5 seconds until a second-degree burn occurs in a flashover situation. Multiple layers increase TPP rating but make suits bulkier. Fire-retardant underwear can be worn beneath the suit to increase protection without moving to a heavier suit.	['Nobody wants to be on fire—prep for the worst!\nIt happens in an instant. One second you’re holding your line, fighting for position. The next, and often times without warning, a mechanical failure or a wreck of almost any degree turns from bad to worse as fire erupts, turning your race car into a flaming ball of metal. Are you and your race car prepared for such a catastrophe? No one is immune from the possibility of fire, and it’s something every racer, and their cars should be prepared for before it happens.\nThe No. 22 car of Jeremy Spoonmore (pictured above) erupted into flames after a catastrophic engine failure ignited two gallons of oil from the wet-sump lubrication system. The cockpit was completely engulfed in flames, causing damage to the window net, seat, Spoonmore’s firesuit, gloves, shoes, helmet, and seatbelts. We were also told his impressive goatee was significantly shorter after the fire. Spoonmore recalls the events of that day.\n“There was more fire than I would have ever thought there would have been,” explains Spoonmore. “The engine seized and I heard a pop. When it did, a rod came out of the block and the oil ignited on the headers. When I turned the wheel down I saw the flames. The fire started coming into the cockpit and got very close to my face so I closed my eyes so it didn’t burn them.”\nAt this point, Spoonmore should have been able to come to a stop and get out of the car, but bad turned worse. Another car slid in the oil left on the track, knocking Jeremy into the wall. “The power steering broke when the car hit the wall, igniting more fluid,” Spoonmore adds. “And that just made the fire worse. I already had the window net down and was about to undo my belts. Luckily they were still on.”\nIn the end, Spoonmore walked away with burns about as severe as a bad sunburn and a shortened goatee, but some racers aren’t that lucky. “I never even thought about fire in the race car,” explains Spoonmore. “I hope it will never happen again, but I learned the hard way.”\nSurviving a fire in a race car is a game of time. If a fire erupts, you want to give yourself enough time to safely stop the car and get out. If the fire happens as a result of a wreck and you are unconscious, you want to be protected for enough time that the safety crew can get there and remove you from the car. Racers never want to be reminded of the dangers of racing, but not preparing for the worst is silly when you think how easy it is to be prepared.\nEmerging from a fire like Spoonmore’s unscathed is as much about preparation as it is about luck. Racing is inherently dangerous, and taking the proper precautions greatly diminished the risk of injury, and it starts with what you wear.\nWe all know wearing the proper firesuit, fire retardant underwear, head sock, gloves, and shoes can be uncomfortable, especially in the heat of the summer, but the healing process from third degree burns is far worse.\nFiresuits come with an SFI rating. This rating gives you an idea of how protective it will be in a fire. Your firesuit is designed to protect you, but you have to take care of your firesuit properly for it to do its job when needed. So many times you see racers jump out of the car, dive under the car, and start turning wrenches. While the ability to drive and wrench on a race car is admirable, it can be foolish if you don’t remove your firesuit. Dirt, solvents, fuels, and oils can turn a piece of fire retardant clothing into an oily flammable rag—probably the last thing you want to be wearing if there ever was a fire.\nThe moral of the story is don’t ever work on the car in your firesuit. While it’s easier than changing, and takes less time, the extra five minutes could save your life the next time you go on track. The same also goes for shoes and gloves.\nMost racers don’t realize that cleaning your firesuit the wrong way could reduce its fire resistant characteristics. We went to G-Force Racing Gear for a little more info on cleaning your safety gear.\nWhen in doubt, mild soap and water will work with most any product. As for racing suits, wash in cold water and hang to dry. Some manufacturers recommend dry cleaning, but to be sure of the chemicals used, you should wash at home. With helmets, a damp cloth and mild soap used to blot the inside of the liner will help remove any built up residue. Belts are susceptible to sunlight and water will speed up the aging process. Be sure to remove or cover belts when washing the inside of a racing vehicle.\nPrepping Your Car\nBeyond protective clothing, preparing the car for the worst is hugely important. The driver’s compartment should be as sealed as possibly with tape that won’t burn. There are aluminum tapes that are specifically designed for sealing areas of the car that could possibly be exposed to fire and high heat. Even the smallest holes can let fluids and fire into the cockpit.\nOnce the driver’s compartment is sealed, a fire extinguisher or fire system should be in place, in working order, and the activation mechanism should be in an easy place for the driver to operate if needed. Also, the system does no good if the safety pin is still in place. Be sure to remove it before each trip out on track.\nLastly, have an exit strategy and practice it. Having all of the safety equipment means nothing if you can’t get out of your car. Especially with how popular full-containments seats and head-and-neck restraints have become, getting out of a race car, let alone a burning one, can be very difficult with obstacles on you and in the way.\nA fire can induce panic; hey, it’s a natural reaction if you’re on fire. But practicing getting out on a regular basis can make a scary moment a little less frightening if you know exactly how to do it. Have a crewmember time your evacuation from the car. Practice a few times and break out the stopwatch again. We bet you’ll be surprised at how much you can improve in just a few tries.\nSFI and Thermal Protection Performance\nIf you’ve ever worn any kind of protecting equipment, chances are you’ve seen the SFI tags on them. Besides the fact that in-date SFI-rated equipment is required, it also allows you to pick the right equipment for what you are doing.\nWhich SFI Rating Should I Choose?\nSafety manufacturers who advertise in Circle Track produce products that carry SFI ratings. A typical rating looks like this: SFI 3.2A/5 where 3.2A is the foundation’s standard for firesuits and 5 is the rating. The higher that rating number, the better the protection. In this example, the number 5 is the most important number you will see, especially if the manufacturer doesn’t release TPP numbers. Most sanctioning bodies and tracks will require you to have a firesuit with a minimum SFI-rating in order to compete. However, that does not mean that you should buy only their minimum.\nWhat Do All Those Ratings Mean?\nThe quality of any fire-retardant material can be determined by looking closely at two measuring factors: LOI, which stands for Limiting Oxygen Index, and TPP or Thermal Protective Performance. LOI is the most commonly used measurement for flame retardancy and refers to the amount of oxygen needed in the atmosphere to support combustion. If a fiber or fabric has an LOI of 25, that means that at least 25 percent oxygen needs to be present for the fabric to burn. Consequently, a higher rating equals more fire protection. You won’t often see LOI in race suit literature, but it’s an important factor in good fire protection.\nTPP on the other hand refers to the garment’s ability to provide thermal protection when exposed to both direct flame and radiant heat while taking into account the length of time before a person is subject to second-degree burns. While that’s a mouthful, TPP is the second most important number you need to know when firesuit shopping. The TPP rating is derived from a mathematical calculation performed with the results of a sophisticated test procedure that utilizes two different heat sources, sensors, and the fabric to be tested. The TPP rating is divided in half to determine the number of seconds until the human tissue reaches a second-degree burn. For example, if a particular fabric has a TPP rating of 35, it takes 17.5 seconds until a second-degree burn occurs in a flashover situation.\nThe only way to increase a TPP rating is through adding multiple layers. However, as you increase layers, suits get bulkier—and bulk doesn’t equal comfort. Your goal in selecting a firesuit should be the balance of comfort with maximum protection.\nA great way to increase the TPP without jumping up to a three-layer drag racing suit is to wear fire-retardant underwear beneath your suit. If you’re budget doesn’t allow for FR underwear, even a cotton sweatshirt adds some protection.\nOK, now here’s a great question to ask yourself. How fast can the safety crew at your local track get you out of a burning car? If they can do it in 3 seconds, go ahead and buy that $99 single-layer special and drop me a note telling me your home track because I want to race there.']	['<urn:uuid:65fdd6ce-6028-4451-bf75-c850645975e4>']	open-ended	direct	short-search-query	distant-from-document	single-doc	novice	2025-05-12T23:47:20.322175	7	78	1619
40	beneficial ownership transparency vs foreign trust disclosure	Beneficial ownership transparency, advocated by GFI, requires disclosing the real person who profits from or controls a company to prevent criminal actors from hiding behind anonymous shell companies. In contrast, India's foreign trust disclosure requirements specifically mandate tax residents to report their involvement in trusts created under foreign laws where they are trustee, beneficiary or settlor, as part of their global asset disclosure obligations. While both aim for financial transparency, beneficial ownership focuses on company control, while trust disclosure targets personal financial interests in foreign structures.	['Providing research, advocacy and policy solutions on anti-corruption is a key part of GFI’s work. Not only does corruption generate illicit financial flows, it also promotes other illicit activities that negatively impact governance, economic development, and security. Tax evasion, natural resource crime and other transnational crimes can all be facilitated by corruption.\nAddressing corruption is complex because it requires effective engagement with stakeholders including governments, civil society groups, international organizations, and the private sector. GFI’s work on anti-corruption includes convening diverse stakeholder groups, advocating for beneficial ownership transparency, improving trade integrity, providing legal/regulatory technical assistance to governments, and conducting research on anti-corruption best practices.\nImpact of Corruption\nIn 2020-2021 GFI has undertaken a large anti-corruption research project for the U.S. State Department analyzing corruption trends across Latin American and Caribbean countries. The project began with hundreds of stakeholder interviews to understand the mechanics of corruption in different country contexts, tracing how money and value moves through political systems and economies. The project then analyzed legal and regulatory tools to address corruption and whether they have been effective. The project will conclude with recommendations to address current gaps and more effectively curtail corruption.\nBeneficial Ownership Transparency and Anti-Corruption\nBeneficial ownership transparency is a key tool in the fight against corruption and other financial crimes. Disclosing the real person, or “beneficial owner”, who profits from or controls a company makes it harder for criminal actors to hide behind anonymous shell companies. Beneficial ownership transparency is important for public and private sectors alike. As an anti-corruption tool, it allows greater transparency over public procurement and contracts. As a law enforcement tool, knowing who is controlling companies prevents bad actors from maintaining plausible deniability and operating with impunity. And for all people and companies, knowing with whom you are doing business enables good actors to make informed decisions about a deal or transaction, making it easier to manage potential risk.\nGFI worked, as a key member of the FACT Coalition, to advocate for beneficial ownership legislation in the U.S. In December, 2020, after ten years of work, the Corporate Transparency Act was passed and will help eliminate anonymous shell companies in the United States. This was, by far, the most significant anti-money laundering legislation passed since the Patriot Act in 2001.\nBy working with lawmakers, private companies, media outlets and civil society organizations, GFI advocates for increased beneficial ownership transparency. This work extends outside the U.S. as well, with GFI working in Colombia and Kenya to advance beneficial ownership legislation. In the fall of 2020 Colombia introduced a bill to increase transparency and create a central registry of company ownership.\nTrade Integrity and Anti-Corruption\nIn Uganda, GFI works with partners to advocate for anti-corruption and financial transparency reform in the mining sector. In 2019, GFI and partner ACODE provided comments on Uganda’s draft mining and mineral bill, which would update the 2003 mining law. GFI addressed fair and transparent procurement, contracting and licensing processes, beneficial ownership standards, corporate board governance of Uganda’s state-owned enterprises, and management of risks of politically exposed persons in the mining sector. These changes would fight corruption and improve transparency in the mining sector in order to reduce illicit financial flows.\nUN CONVENTION AGAINST CORRUPTION (UNCAC) COALITION\nGlobal Financial Integrity is part of the UNCAC Coalition, which consists of over 300 civil society organizations in over 100 countries committed to promoting the ratification, implementation and monitoring of the UN Convention Against Corruption.', 'INTERNATIONAL TAX COMPLIANCE REGULATIONS IN (PART 10): India\nBy Ashishkumar Bairagra, M L BHUWANIA AND CO LLP\nIn dia is known for its strict international tax compliance applicable to residents as well as non-residents who are liable to file their tax returns in India. Landmark judgements include the case of Vodafone (on indirect purchase), Asia Satellite (on satellite charges), Formula One (on permanent establishment [PE]), Morgan Stanley (on dependent agent PE) and the most recent case of Master Card (on service PE).\nAs per the (Indian) Income-Tax Act 1961 (ITA) a tax resident in India is liable to tax on their global income and also liable to disclose their global assets in their annual tax return. A tax non-resident is liable to tax on income received or deemed to be received in India or income deemed to accrue or arise in India and, as one can imagine, it is the deeming fiction which has created most of the controversy. In addition, India has also introduced regulations for “Place of Effective Management” and “Equalisation Levy” to keep pace with the BEPS Action plan.\nMain Types of Business and Taxes for Each Entity\nFor Individuals / Hindu Undivided Family Association of Persons / Body of Individuals:\nIndia also has various other forms of taxes like dividend distribution tax, capital gains tax, and minimum alternate tax, and a wide-ranging withholding tax regime, along with various doubletax avoidance agreements (DTAA).\nTypes of Trusts and Their Taxability\nThe ITA does not have specific charging sections for trusts; hence taxability of the various forms of trusts has been determined through judicial rulings over the past decades. Taxability of a few common forms of trusts is briefly discussed as follows:\n1. Charitable/Public Trust incomes and donations are not taxed if stringent conditions of utilising the donations towards the objective of the trusts are fulfilled.\n2. Private Trust settlor is taxed if the trust is revocable.\n3. Discretionary Private Trust the trustee is taxed as the representative since beneficiaries or their shares are unknown or undetermined.\n4. Specific Private Trust beneficiaries are taxed since share of each beneficiary is known, but the tax can be paid by/recovered from the trustee.\n5. Foreign Trust if the income of the trust is liable to tax in India, then it is taxable in India.\n6. Foreign Trust if the settlor or trustee or beneficiary is tax resident in India, then the person is liable to tax in India. It may be noted that beneficiaries are liable only on any distribution by the trust.\n7. Foundations similar principles as applicable to trusts are followed.\nA trust is taxed at the maximum marginal rate of 30% + surcharge + cess if the trustee is liable to tax on behalf of the trust. If the income is taxed in the hands of the beneficiary or settlor, then the tax rate applicable to the beneficiary or settlor is applicable.\nTax Compliance Requirements for Owners of Foreign Assets\nTax residents in India are liable to disclose their global income and global assets, whether held directly or if they hold a beneficial interest, held at any time of the year in their annual tax return with details for each of the following:\n1. Foreign Depository Accounts held;\n2. Foreign Custodial Accounts held;\n3. Foreign Equity and Debt Interest held in any entity;\n4. Foreign Cash Value Insurance Contract or Annuity Contract held;\n5. Financial Interest in any Entity held;\n6. Immovable Property held;\n7. Any other Capital Asset held;\n8. Account(s) in which they have signing authority held which has not been included above;\n9. Trusts, created under the laws of a country outside India, in which they are a trustee, beneficiary or settlor;\n10. Any other income derived from any source outside India which is not included above or in other parts of the tax return.\nTax Compliance Requirements for Estate and Wealth Planning Matters\nTraditionally in India, a testamentary will has been the preferred route for estate and wealth planning since it is the most optimum route for tax purposes. In recent times, due to various litigations amongst legal heirs and claimants, family trusts are starting to become popular. There are also rumours that just like some of the developed economies, India may soon introduce “inheritance tax” and hence high net-worth individuals (HNI’s) are scrambling to form trusts and plan their inheritance.\nIt is important to note that apart from income tax, there could be implications of stamp duty, state/local regulations requiring permissions/approvals, valuation norms, and other hindrances in estate and wealth planning matters which involve real estate or immovable assets. In recent years, FATCA has been a major concern while evaluating such planning situations, especially if one of the beneficiaries is covered by FATCA regulations. Similarly, while planning for foreign assets, adequate precaution should be considered if one of the beneficiaries is a tax resident of India.\nTax authorities will request detailed documentation for assets/gifts received as part of an estate/wealth from an individual, including for establishing the relationship. In most cases, the cost of the original holder is considered to be the cost of the new holder and the period of holding is considered to start from the date when the asset was acquired by the original holder; hence it is important to preserve the primary acquisition document of the original holder to claim maximum relief/deduction at the time of sale of the inherited asset.\nTax Compliance Requirement on Sale of Real Estate\nIf a non-resident sells real estate in India, there are myriad regulations and compliances which they will need to fulfil. The most important one is the withholding tax obligation on buyers to deduct and deposit 20% + applicable surcharge + cess on the entire sale consideration with the tax authorities on behalf of the seller. These withholding tax regulations do not allow the buyer to consider the actual capital gain (if any) earned by the seller. The only option is for either of them to file an application to the tax authorities to determine the actual capital gain earned by the seller, derive the actual amount of tax payable by the seller on the sale of the real estate, and issue a certificate enabling the buyer to deduct the specific amount as withholding tax. This process is time consuming and requires planning in advance, which is rarely possible in such situations. In cases where the capital gain is significantly lower than the sale consideration, the non-resident must wait to file the tax return for that year to be eligible to obtain a refund of the tax withheld by the buyer.\nIn a recent case, we assisted a GGI member firm to assess whether their client (an international soccer coach) has become a tax resident in India or not, and the detailed tax implication on his global incomes if he was classified as a tax resident. The discussions also revolved around tax credit mechanisms available to him through the DTAAs between India and source countries.\nIn several other cases, we have assisted non-residents to obtain the certificate from tax authorities determining their capital gains tax liability on sale of real estate and several HNI tax residents with disclosure of their foreign assets.\nAshishkumar BairagraGGI member firm\nM L BHUWANIA AND CO LLP, Chartered Accountants\nAdvisory, Auditing and Accounting, Corporate Finance, Fiduciary and Estate Planning, Tax\nT: +91 22 6117 49 49\nM L BHUWANIA AND CO LLP is a firm dedicated to offering professional services by employing the industry’s brightest minds. They offer collaborative audit, consulting, financial advisory, risk management, and tax services to clients. The firm’s diversified client profile across industries has helped it to improve its ability to advise clients on the dynamic and challenging environments in which they do business.\nAshishkumar Bairagra has been in practice and a Partner of the firm since 2001. He handles international taxation matters, internal audits, management audits, and consulting assignments. His areas of specialisation include international taxation, transfer pricing, valuation, due diligence, cross border business structuring, and business consulting. Ashishkumar is the Global Vice Chairman of GGI’s International Taxation Practice Group (ITPG)\nPublished: Working Together to Optimise International Tax Compliance, No. 2, Spring 2020 l Photo: Sapsiwai - stock.adobe.com']	['<urn:uuid:b745902a-f227-4bcc-843e-01737211cf8f>', '<urn:uuid:4592393c-8501-4de7-9259-f6f0aeed8baa>']	open-ended	with-premise	short-search-query	similar-to-document	comparison	expert	2025-05-12T23:47:20.322175	7	86	1939
41	sustainable innovation research centers basf covestro compare environmental approach	Both companies demonstrate commitment to environmental sustainability through different approaches. Covestro developed the Triturn® system that reduces fossil raw materials by up to 20% in polyol production by reusing CO2. BASF created the Ecoefficient House (CasaE) project in São Paulo, which uses innovative construction materials to reduce energy consumption by up to 70% and features solutions to reduce water consumption and CO2 emissions. The project received LEED-NC Gold certification for sustainable building.	"['Joint development of Covestro and Tekmar Group\nMore sustainable solution for cable protection system in offshore industries\n- New polyurethane elastomer system using CO2 Technology, now called Triturn®\n- Covestro wins UTECH Europe Polyurethane Award 2021\nThe growing offshore wind farm market requires a sustainable value chain capable of delivering robust and long lasting subsea infrastructure whilst reducing the industries environmental impact. To achieve this, the offshore industry is urgently seeking for renewable materials matching their high performance requirements from the supply chain.\nCovestro and Tekmar Group have embraced this challenge and are collaborating to develop more sustainable subsea products by leveraging each other’s expertise in their respective fields.\nCovestro Elastomers develops cast elastomer systems to provide solutions for the offshore energy market. Tekmar is a leading producer of polyurethane based cable protection systems for the global offshore energy markets.\nA key component of the cable protection system is the bend restrictor, which along with the rest of the system, is designed to protect cables in the ocean for decades. So, why not propose an alternative polyurethane elastomer system for more sustainable casting of these products? One of the major challenges is the reconciliation of sustainability and technical performance, without any compromise on quality. To solve this, Covestro has developed a new polyurethane elastomer system based on its CO2 Technology, now called Triturn®, which positively contributes to reducing the products´ carbon footprint.\nThe new system for bend restrictors from Covestro, which was recently honored with the UTECH Europe Award 2021 in the CASE category (CASE stands for coatings, adhesives, sealants and elastomers), allows to reuse CO2 as a valuable material source in polyol production and to reduce up to 20 percent of the fossil raw materials which is normally used for the polyol. The new system also makes significant technical gains by being easier to process and improving non-aging properties in salt water. Tekmar is using the new PU system to manufacture sample products at its facility in the North East of England and is currently conducting a range of tests on the products.\nMarc Bell, Managing Director at Tekmar Energy, says: ""Tekmar is committed to developing more sustainable solutions for the offshore energy markets. Working with Covestro enables us to explore alternative solutions which we can share with our customers to support their transition to cleaner energy and net-zero emission targets.""\nThrough a long-term collaboration, Covestro and Tekmar are proactively shaping the subsea protection industry by introducing an alternative and more sustainable solution to move the offshore industry forward.\nWith 2020 sales of EUR 10.7 billion, Covestro is among the world’s leading polymer companies. Business activities are focused on the manufacture of high-tech polymer materials and the development of innovative, sustainable solutions for products used in many areas of daily life. In doing so, Covestro is fully committed to the circular economy. The main industries served are the automotive and transportation industries, construction, furniture and wood processing, as well as electrical, electronics, and household appliances industries. Other sectors include sports and leisure, cosmetics, health and the chemical industry itself. At the end of 2020, Covestro has 33 production sites worldwide and employs approximately 16,500 people (calculated as full-time equivalents).\nThis news release may contain forward-looking statements based on current assumptions and forecasts made by Covestro AG. Various known and unknown risks, uncertainties and other factors could lead to material differences between the actual future results, financial situation, development or performance of the company and the estimates given here. These factors include those discussed in Covestro’s public reports which are available at www.covestro.com. The company assumes no liability whatsoever to update these forward-looking statements or to conform them to future events or developments.', 'The chemistry of the future\nBASF has two global laboratories in Brazil and research groups focusing mainly on agribusiness and construction\nOperating in Brazil for over 100 years, BASF is one of the world’s leading chemical companies in terms of innovation. Brazil, accounting for about 60% of South American business, participates in the global ecosystem of the group’s research and development (R&D), which is headquartered in Ludwigshafen am Rhein, Germany. The Brazilian unit houses two world-class laboratories and is known for its innovative activities related to agriculture, such as soybean and sugarcane crops, and the paint industry, specializing in paint for the walls of buildings. One of the most recent technologies developed by the Brazilian researchers is the Cultivance soybean, the first genetically modified variety developed completely in Brazil. The result of a 10-year partnership with the Brazilian Agricultural Research Corporation (Embrapa), it was introduced on the market in June 2016 and has already been approved for use in the European Union and almost 20 other countries.\n“The Cultivance soybean was the first variety in the field of plant biotechnology approved commercially throughout BASF. This product launch reveals the importance of Brazil in the global context of the group’s innovation activities,” says technology and innovation manager Rony Akio Sato. According to Sato, the Cultivance Protection System is ideal for use in integrated management of invasive species in the fields. “It combines genetically modified soybean cultivars that have competitive genetic potential with the use of broad-spectrum herbicides to control grasses and weeds with broad leaves ,” explains Daniela Contri, manager of innovation and strategy for Latin America.\n|São Paulo, SP|\n|Nº of employees|\n|4,200 in Brazil|\n|Soybean seeds, sugarcane seedlings, paint for buildings, pesticides, drug ingredients and ingredients for plastics|\nAnother technology developed in Brazil is the AgMusa system, for sugarcane crops. It is a technological system designed to renew high-yield sugarcane fields by planting healthy sugarcane seedlings produced in nurseries using varieties obtained from companies and institutions specialized in genetic improvement. The seedlings are subjected to treatment that ensures improved vigor, in addition to the homogeneous genetic identity needed for formation of nurseries. The system allows more rapid introduction of a new cultivar in the fields. In the conventional method for multiplication and development of nurseries, the producer works on a new variety for six years before it can be used commercially. With the AgMusa system, this time is cut in half. “This technology facilitates the rapid expansion of new sugarcane varieties with greater production potential,” says Daniela Contri.\nIn the construction sector, one of BASF’s principal regional innovations is Suvinil Família Protegida antibacterial paint, which reduces microorganisms on walls by up to 99% for a period of two years. BASF acquired control of Suvinil in 1969 and incorporated its R&D activities. The product has the seal of approval of the Brazilian Health Surveillance Agency (Anvisa) The company also developed an acrylic paint for the Suvinil line that is used on external surfaces. It is manufactured with special resins that reduce the accumulation of dirt on walls and protect against the wind, and another high-concentration, high-yield paint named Max Rendimento. “In order to show clients its innovations for the housing market, BASF built in São Paulo its first energy-efficient house in a tropical climate — there are nine more units around the world in cities where the weather is cold or temperate,” says corporate innovation manager Nina Traut.\nDubbed the Ecoefficient House, or CasaE, this project incorporates solutions to reduce water and power consumption and curb CO2 emissions. The 400-square-meter building exhibits 36 products developed by BASF worldwide and solutions from 29 partner companies, half of which are Brazilian (Gerdau, Tigre, Deca, Tecmar, etc.). Its porous flooring is built with permeable concrete or high-permeability polyurethane compounds that allow water to pass through it, in addition to cold pigments applied in paints that help regulate the ambient temperature. “Thanks to the use of differentiated construction materials, CasaE can use up to 70% less energy,” says Sato. The project received LEED-NC Gold (Leadership in Energy and Environmental Design) certification granted to new sustainable buildings by the Green Building Council, an organization present in more than 90 countries whose purpose is to promote sustainable construction.\nR&D activities in Brazil began in the 1950s with the installation of the first application development laboratories, whose purpose was to transfer technology. Today BASF has 4,200 employees in Brazil, distributed among the central office in São Paulo and nine factories. The company does not disclose figures on the number of employees involved in R&D in Brazil, or the amount of money invested in this area. It does state that the profile of the R&D team is diverse and includes agronomists, chemists, biologists, chemical engineers and pharmacists. More than 80% have undergraduate degrees, with 11% holding master’s degrees and 3% with PhDs. Three of every 10 researchers are women. The company also reports that it interacts annually with about 60 to 80 Brazilian research institutions in its search for innovations. In addition to Embrapa, BASF has partnerships with the São Paulo State University (Unesp) , the University of Campinas (Unicamp) and the State University of Maringá (UEM).\nLocated in upstate São Paulo, the Guaratinguetá factory is BASF’s largest chemical complex in South America. It produces 1,500 different products and houses one of the group’s two global research centers in Brazil, the Global Environment and Food Safety Laboratory (GENCS). “At GENCS we conduct studies to evaluate pesticide residues in food, in addition to the environmental studies required by Brazilian and international regulatory authorities for registering new products and extending the use of existing ones,” says Sato. He explains that these studies begin in the field, where scientists simulate the use of pesticides recommended for each specific crop of interest (coffee, corn, vegetables, etc.). Afterwards, the researchers collect samples of the crops and send them for analysis in the laboratory. During this stage, the samples are processed and analyzed using purification and quantification techniques. “Based on the results of the residue studies and on the toxicological data, we verify food safety, thereby ensuring that BASF innovations for agriculture comply with regulatory and sustainability requirements. Since 2001, GENCS has been recognized by the National Institute of Metrology, Quality and Technology (Inmetro) for good laboratory practices that ensure the trackability and reliability of studies conducted there.\nThe other world-class laboratory in Brazil is the Agricultural Experimental Station in Santo Antônio de Posse, in the Campinas region. Founded 35 years ago, it occupies 110 hectares and is the company’s largest physical research space anywhere in the world. The station accounts for 45% of research done in Brazil. Established with the goal of decentralizing agricultural studies that initially were done only in Germany, the research center is the only one of its kind south of the equator. There BASF develops pesticides for soybeans, sugarcane, corn, coffee, rice, beans and other crops. It also tests biological treatments against weeds, diseases and pests that attack crops. The station belongs to the Crop Protection Unit responsible for developing the Cultivance Production System and AgMusa.\nBASF’s research structure in Brazil also includes the Nutrition and Health Applications Center, the only one of its type that BASF has in South America. Located in Jacareí, São Paulo State, it features a pharmaceutical laboratory that specializes in preparing solid pharmaceutical forms, and a test kitchen known as Newtrition for developing food technologies and prototypes, focusing on breads, cookies and cakes.\nBASF’s innovation division has more than 70 R&D centers worldwide and 10,000 researchers, or 10% of its total staff. In 2015, the multinational’s research lines included about 3,000 projects and received €1.95 billion in investments. This figure corresponds to about 3% of its worldwide sales of €70 billion — of this total, €10 billion come from product innovations. With a portfolio of 8,000 families of products that engender 60,000 applications, the company manufactures everything from chemicals, plastics and agricultural pesticides to drug ingredients and paint for buildings. The company does not focus on consumer products for retail sale— such as the old BASF cassette tapes, one of the company’s most visible products in Brazil — but rather inputs, formulations, ingredients, raw materials and intermediate products for many different manufacturing industries.\nAmong the innovations developed at BASF’s research centers in other countries is the indigo blue pigment that gives jeans their blue color and is used by the textile industry, as well as polystyrene and the inputs used to manufacture plastic toys, such as Legos. “At BASF we constantly strive for innovation ,” says Sato. Proof of this, he says , is that the company files an average of 1,300 patent applications annually. “For the last five years we have been leaders in the Patent Asset Index, a worldwide index created by the principal chemical companies — Bayer, Dow, Du Pont, Evonik and BASF — to measure the value of patents in terms of technological competitiveness and impact on business and the market,” he says.']"	['<urn:uuid:d17637cd-443d-449e-a70a-f8828b502964>', '<urn:uuid:c2f8c008-44ec-492d-baaf-03c781af1dba>']	open-ended	with-premise	long-search-query	distant-from-document	comparison	novice	2025-05-12T23:47:20.322175	9	72	2106
42	Basic doubt: what's the difference between root and stem?	A root is the primary unit carrying the main semantic content, while a stem is the combination of roots and derivational affixes, serving as the base structure over which inflections apply.	"['Morphology is the branch of linguistics that studies patterns of word formation within and across languages, and attempts to formulate rules that model the knowledge of the speakers of those languages.\nWords, word forms and lexemes\nThere are several difficulties in arriving at a consistent use of the term ""word"" in relation to other categories of linguistic description, and several criteria (prosodical, morphological, syntactical) have been suggested for the identification of words in a language. One of the main difficulties concerns the use of the term ""word"" both as a class and as any of its elements. The forms ""love"", ""loves"", ""loving"" and ""loved"", for instance, may be considered to be different ""words"" of English or different forms (variants) of the same ""word"", depending on the case.\nIn order to avoid ambiguities, linguists differentiate between two senses of ""word"". The first sense, the one in which ""love"", ""loves"", ""loving"" and ""loved"" are different ""words"", is usually called a word form. Word forms are therefore ""the physically definable units which one encounters in a stretch of writing (bounded by spaces) or speech (where identification is more difficult, but where there may be phonological clues to identify boundaries, such as a pause, or juncture features)"" (Crystal, 2008, p. 522).\nThe second sense, the one in which ""love"", ""loves"", ""loving"" and ""loved"" are ""the same word"", is normally called a lexeme. The lexeme is an abstract underlying unit that corresponds to a set of different word forms reputed to be part of the same word class.\nDifferent word forms are said to be part of the same lexeme if they share the same fundamental morphological identity. This means that word forms are analysed into smaller units, called morphemes, which are the smallest linguistic units that have semantic meaning.\nMorphemes can be classified according to several different criteria. The most frequent ones are syntactic and semantic. From the syntactic perspective, morphemes can be:\n- free morpheme, if they can stand alone (such as ""table"", ""happy""); or\n- bound morpheme, if they cannot stand alone (such as ""un-"", ""-ism"" and ""-rupt-"").\nFrom the semantic point of view, there are again two main different types of morphemes:\n- root - the primary unit of a word unit, which carries the most significant aspects of semantic content; and\n- affix - a morpheme attached to the root to modify its meaning (such as ""-s"" in ""tables"", or ""un-"" in ""undo"").\nWord forms may have one (“fire”, “man”, “dish”, “washer”) or several roots (“fireman”, ""dishwasher""), and zero (""happy"") or more (""unhappy"", ""unhappiness"") affixes.\nAffixes are divided into several categories, depending on their position and their role with reference to the root. The most important positional categories are:\n- prefix (PFX) - Appears at the front of the root (such as ""un-"" in ""undo"", or ""re-"" in ""rewrite"")\n- suffix (SFX) - Appears at the back of the root (such ""-s"" in ""tables"", or ""-er"" in ""writer"")\n- infix (IFX) - Appears within the root (very rare in English, such as ""-ma-"" in ""sophistimacated"")\n- circumfix (CCX) - Appears at the front and at the back of the root (very rare in English, such as ""a-"" + ""-ed"" in ""ascattered"")\nAs for their roles, there are two main different types of affixes:\n- inflectional affix - assign grammatical properties (such as number, gender, tense, person) to the root in order to form the different word forms of the same lexeme (""-s"" in ""tables"", ""-ed"" in ""loved"")\n- derivational affix - form a new lexeme by modifying the meaning (and sometimes the category) of the root (""un-"" in ""unhappy"", ""-ness"" in ""happiness"").\nThe combination of roots and derivational affixes is usually called stem (or inflectional root). The stem is therefore the longest common denominator among all word forms belonging to the same lexeme. It defines the basic structure over which inflections apply. For instance:\nMorphological categories often coincide, but they correspond to different levels of morphological analysis. In non-inflectional (invariant) lexemes (such as English adjectives and adverbs), for instance, the stem is equal to the word form (""happily"" = word form = stem). In non-derivational (primitive) lexemes, the stem is equal to the root (""here"" = stem = root). In any case, especially in inflectional and derivational lexemes, these categories are clearly differentiated. The Spanish lexeme corresponding to the forms of the adjective ""desanimado"" (= discouraged), for instance, has the following morphological items:\n- word forms = desanimado, desanimada, desanimados, desanimadas\n- stem = desanimad-\n- inflectional affixes = -o, -a, -os, -as\n- derivational affixes = des-, -ad-\n- root = anim-\nIn case of overlapping, these categories are used from the least comprehensive (""root"") to the most comprehensive (""word form""). Thus;\n- ""friend"" (word form = stem = root) is classified as root;\n- ""unfriendly"" (word form = stem) is classified as stem; and\n- ""clothes"" (word form > stem) is classified as word form.\nIn some languages, a given inflection may assume different forms. The feature ALT must be used for alternative forms.\nIn English, for instance, the word \'volcano\' may have two different plural forms:\nIn case of more than one possible alternative form, the features ALT1, ALT2 and ALT3 must be used instead of ALT.\nFor instance, in Arabic the word \'elephant\' has three plural forms, as indicated below:\nIn the UNLarium, we recognize six main morphological categories:\n|lexeme||word forms||root||derivational affixes||inflectional affixes||stem|\n|6||love, loves, loving, loved||lov-||-e,-s, -ing, -ed||lov-|\n|7||desanimado, desanimada, desanimados, desanimadas||anim-||des-, -ad-||-o, -a, -s||desanimad-|\n|8||unbreakableness||break||un-, -able, -ness||unbreakableness|\n|9||fireman, firemen||fire, man||fireman|\n|10||part of speech, parts of speech||part, of, speech||-s||part of speech|']"	['<urn:uuid:bb45bf24-abb9-47e6-bb6c-ed87eda6634a>']	factoid	with-premise	concise-and-natural	similar-to-document	single-doc	novice	2025-05-12T23:47:20.322175	9	31	926
43	main reasons russians engage collective urban activism comparison economic political issues	Urban issues are the most common reason for collective activism among Russians, mobilizing people even more than economic and socio-political problems or questions about the political regime. Specifically, protests against infrastructure projects (24%), against densely populated buildings (23%), and construction in recreational areas (21%) were the most frequent types of urban conflicts, accounting for two-thirds of analyzed cases.	"['What is the opposite of an activist\nBy Anna Zhelnina (Institute of Sociology of the Russian Academy of Sciences, St. Petersburg)\nThe myth of Russians\' political passivity is surprisingly long-lived, despite ample evidence to the contrary, both nationally and locally. The article deals with local activism in the big cities of Russia. This type of activism receives less attention in the national media, but it is precisely the attempts of city dwellers to shape their lives together on site and in the renovation, redesign or redevelopment of urban areas that are central to the sustainability of civil society Play a role in demanding that their interests be safeguarded. By participating in local initiatives, city dwellers acquire new skills; in addition, they create new political identities and social connections.\nProtests often have an urban character\nUrban social movements occupy a strange place in political science and sociology. They are popular as a research project, but scientists do not always take their urban character into account. Sometimes they consider local protests to be insufficiently ""political"" or too minor. At the same time, the fact that these movements and initiatives arise from the everyday life of city dwellers: inside or because of urban spaces that are literally not far from one\'s own home and city centers, has a considerable influence on the mobilization potential, on their composition as well as on the character of them social and political consequences.\nStudies on urban social movements in different national and cultural contexts regularly provide evidence that city dwellers learn to use instruments of citizen participation, especially in the format of specific local initiatives, and to build activist networks that remain active after the end of the respective conflict; they also develop new political identities and contexts of meaning. In the context of authoritarian regimes, where political participation carries a number of risks, local activism may be the only acceptable format in which citizens can make their demands. City dwellers can perceive local conflicts as being forced upon them because the mobilization often results from questions that are embedded in everyday life and that evoke strong emotional reactions. Finally, the civil society skills and contacts that are gained in the course of urban conflicts can be transferred to other policy areas and thus form the basis for civil society infrastructures.\nUrban conflict occupies a prominent place among the movements and protests in Russia. According to calculations by political scientist Andrei Semyonov, urban issues are the most common reason why Russians are collectively active. They mobilize even more than economic and socio-political problems or questions of the political regime. The team of the research project ""Mechanisms of the reconciliation of interests in processes of urban space development"" (http://urbanconflictsrussia.ru/) has identified over 8,000 conflicts in connection with urban space development on the basis of a specially created collection of media publications from the years 2012 to 2016. Among these conflicts, protests by the urban population against infrastructure projects (24%), against densely populated buildings (23%) and the construction of recreational areas (21%) were particularly frequent, which together account for two thirds of the cases we analyzed.\nIn most of the cases of disagreement and protests, the conflicts concerned areas associated with everyday urban life and part of the urban population\'s environment (residential and recreational areas, and places for trade and services). What is special about many of these social movements is that they attract people who have no experience of civil society resistance, who appear for the first time as actors in the political field and who set up new networks of activists and create a new repertoire of instruments for political debate.\nFormal and informal civil society infrastructures\nCivic participation, which also includes collective action on the occasion of urban development measures, not only requires motivation on the part of the citizens, but also a certain infrastructure, namely rules, resources and platforms for interaction, with the help of which the actors can try to achieve their goals. The infrastructures through which the urban population is involved in negotiation and decision-making processes can be described as civil society infrastructures.\nAccording to Russian legislation, the citizens of the country have a whole range of formal, legally anchored instruments of participation at their disposal, which can be described as formal civil society infrastructure. These include elections, participation in voluntary organizations, municipal self-administration, self-organization and cooperation between homeowners, participatory budgeting, etc. Recent studies on civil society show that the formal structures are supplemented or even supplemented by informal networks and relationship structures of civil society self-organization - i.e. by informal civil society infrastructure be completely replaced. This includes informal associations, networks of friends and acquaintances, which nonetheless concentrate on the creation and preservation of a certain common good. An important element of the informal infrastructure are the citizens themselves - activists and those who support them - who have a certain view of their place in city administration and a vision of their rights and opportunities to influence their surroundings .\nThe formal and the informal civil society infrastructure are not opposed to each other, but rather represent a mutual prerequisite for their respective functioning. Thus, Russian legislation provides for the possibility of so-called territorial social self-government (Russian: territorialnye obschtschestvennyje objedinenija, TOS), which have a fairly wide range of decision-making powers at local level. However, these formal legal provisions do not work with full force and do not allow all powers and possibilities inherent in them to be realized unless they are underpinned by informal connections in the urban population. Because they are embedded in a political context that is characterized by a lack of social trust and distrust of the authorities. In addition, a formally anchored and compulsory element in urban development measures such as the public hearing is often only held in order to ""tick off"" it, namely without the residents being fully informed.\nHowever, even such formalistic stages can be filled with meaning by mobilizing the urban population and their activity. This allows activists to prepare and turn a formal process such as a public hearing on a controversial project into an important public action that attracts media attention and creates the emotions necessary to mobilize and retain new followers . This also applies if decisions of the public hearing should only have the character of recommendations.\nAnother example of a more harmonious, mutual enrichment and underpinning of the formal and informal infrastructure of citizen participation is the strongly developing instrument of participatory budgeting. This form of citizen participation has been formally anchored in many countries on the initiative of grassroots movements. In Russia, especially in St. Petersburg, urban activists who have experience in formulating demands or implementing urban projects are recruited to develop and anchor the ideas behind participatory budgeting.\nDifferences between cities\nA large part of the formal instruments for civic participation in Russia is regulated by legislation at the federal level, for example the urban development and housing codes that apply in all regions of the country. In every city, however, unique configurations of actors and platforms emerge on which cooperation for urban development develops. Each city has its own configuration of informal relationships and civil society infrastructures, which can have a significant impact on the way city policies are pursued and conflicts in the city are resolved.\nAs part of the research project ""Mechanisms for the reconciliation of interests in processes of urban space development"", the situation in six Russian cities with over a million inhabitants was analyzed, namely in Moscow, St. Petersburg, Kazan, Nizhny Novgorod, Samara and Novosibirsk, in addition to the statistical recording of urban conflicts. An in-depth analysis of media reports and interviews with those who were involved in urban conflicts (both with activists and with representatives of the administration and of urban development companies) have allowed us to identify the specific outline of the urban in each of the six cities to recognize political arena.\nOne of the interesting features of the transformation processes in each of the cities is related to the respective initiators: inside controversial projects. In Moscow, for example, in 23 of the 44 cases we analyzed, the projects that led to the protests were promoted by bureaucrats. At the same time, most of the conflicts examined in St. Petersburg revolved around corporate projects (27 out of 44). In Moscow, the proximity of the central budget and the decision-making centers had an impact on the dimensions of the projects and the aggressiveness with which the initiators proceeded. In this case we can speak of the well-known phenomenon that entrepreneurial structures grow together with the authorities. This configuration of strong actors who drive a project forward makes the work of activists very difficult or even completely blocks any attempts by the population to influence the course of events in any way. Experienced Moscow activists often mentioned this constellation in the interviews, emphasizing that corruption and informal agreements by the Moscow bureaucrats greatly reduce the activists\' chances of success. Interestingly, this topic was raised less often in St. Petersburg, as there representatives of the administration appeared less frequently as the main initiators of controversial projects. Of course, we cannot rule out an informal interest on the part of bureaucrats in projects there.\nThe difference between the entanglement of bureaucrats in urban transformation projects in Moscow and in St. Petersburg creates an important context for attempts by activists to influence the course of events. In Moscow it is much more difficult to oppose the representatives of the bureaucracy: According to our data, the majority of the projects initiated or supported by bureaucrats are being implemented unchanged. Our interlocutors also said that it is easier in Moscow with builders who enter into a dialogue with local activists and MPs than with representatives of the city authorities, who are practically deaf in the opinion of the local population. In comparison, projects in St. Petersburg that were pushed forward by bureaucrats have been abandoned or heavily modified in several cases due to demands from citizens.\nConsequences of mobilization\nIn addition to the myth of the passivity of the Russians, there is also the notion that protests in Russia are pointless and ineffective. However, our data show that local protests can produce results, namely abandoning or at least significantly modifying a controversial project (in around half of the cases). In 30 percent of the cases analyzed, the announced project, which had caused public displeasure, was implemented unchanged, and in a further 13 percent of the cases minor changes were made. At the same time, projects were completely abandoned in 29 percent of the cases and significantly changed in 16 percent of the cases (e.g. relocated to another location, changed in the planned height, etc.).\nThis is also where the difference between the different urban contexts can be seen. If we compare Moscow and St. Petersburg, on the other hand, we can see that the urban protests in St. Petersburg have achieved something more often than those in the capital. In Petersburg half of the projects were abandoned, another third was modified. In Moscow, the situation is reversed: Almost half of the projects here were implemented unchanged. One of the possible explanations lies in the amount of resources, including financial ones, that are used in refurbishment or development projects. Also relevant here is the fact that the officials in Moscow have strong levers of power and that actors at the federal level are also involved in the transformation projects in the capital.\nBut the characteristics of civil society actors should not be ignored either. Our analysis shows that the peculiarities of the civil society infrastructure are also important. An interesting peculiarity of the protests in St. Petersburg was that they were often joined by a broad coalition of actors during the period we examined: representatives of various social organizations and activist networks come together to form the protesters to support a concrete dispute, to bring them together with influential MPs who are involved in these networks, and to point the direction of action. In Moscow, residents are more likely to act independently or, at best, seek the help of committed activists among the local MPs.\nOne can assume that there is a special history of the defense of the urban structure in St. Peterburg, which has created the basis for a lively and committed civil society infrastructure. This includes long, extensive protests against the demolition of historic buildings and new buildings in the city center, but also the connections between people and public resources that beginning activists can use, for example groups and pages in social networks. In the cases we examined in St. Petersburg - the struggle against the development of Malinovka Park, against the demolition of substation No. 11 (»Blokadnaya podanziya«), The conflict over the Westtangente (a toll motorway) - the most important activists knew each other before the protests, which accelerated the mobilization and facilitated cooperation. In addition, experienced activists and experts challenge controversial urban development projects without the participation of the ""ordinary"" local population, especially in the area of preserving the historical heritage.\nIn Nizhny Novgorod, the presence of a dense network of activists and experts who stand up for the preservation of the historical heritage in the city enables them to react quickly to emerging threats to the historical building fabric. However, in Nizhny Novgorod, the protection of historical buildings from demolition - unlike the much sensational ecological problems - does not always meet with the same understanding and support from the ""ordinary"" population; without this support, even the work of such active, committed civil society networks will be made more difficult. Discourses, ideas, values and other elements of worldview are also a necessary instrument for civic participation. In contrast to St. Petersburg, where there is widespread awareness of the value of historical heritage, activists in Nizhny Novgorod have emphasized in talks, that the residents of their city see historical buildings more as ""clutter"" than as values.\nAll of these characteristics - the existence of activist networks, public platforms for the exchange of news and experiences, the course of certain values and ideas in urban discourse - are of fundamental importance for the success of urban social movements. However, they are also a potential result of local initiatives. Whenever there is a mobilization, even if the protesters do not achieve their immediate goals, that changes a lot: those involved get to know each other, meet experienced activists and sympathetic politicians and find out which approaches are more or less effective .It is also important that in the course of mobilization new values, ideas and social and political identities can be developed.\nThrough these effects of participating in a joint approach, even unsuccessful actions can lay the foundation for a more effective approach in the future. Activists usually emphasize the importance of those defining moments that mark a turning point for them. For example, our interlocutors in Moscow said that an example of such a turning point was the active and successful fight against the dismantling of the Shukhov Tower in 2014. He had shown the authorities and construction companies that an attack on objects of historical heritage can turn into a protracted and resource-guzzling struggle with the citizens.\nIf one looks at the development of urban activism in the cities of Russia, one can see a gradual increase in civil society infrastructure: experience and knowledge in the ranks of activists, activist networks and social organizations have increased. Values and discourses have emerged that are essential for citizens to participate in urban politics. In addition, a protest activity in the city has an influence on the behavior of the authorities, who then start planning urban development, taking into account the potential for resistance based on previous experience. Sometimes formal and informal civil society infrastructures ""meet"" and complement each other in a conflict-free way. More often, however, the people in the city have to do a lot of work and fight for their rights in order to be heard.\nThe contribution is based on materials from the research project ""Mechanisms for the reconciliation of interests in urban space development processes"" (http://urbanconflictsrussia.ru/).\nTranslation from Russian: Hartmut Schröder\n- There are enough jobs for everyone\n- What is the meaning of love life\n- What\'s the hardest part about growing up\n- How many countries did Britain create\n- Social anxiety makes you flat\n- What are the types of internet advertising\n- How does King Solomon relate to Freemasonry?\n- Where was Louis XVI. Executed\n- Mustangs were native to North America\n- How smart is Ray Kurzweil\n- How many women use breast implants\n- Can I drink coffee after I have eaten eggs\n- Why are good workers hated?\n- Can I start my career in badminton?\n- Aryans are an actual ethnic group\n- How do I choose GIA certified diamonds\n- How much should minorities fear Donald Trump?\n- What are the disadvantages of AAC blocks\n- Who saved most of the Jews during World War II\n- Can people change how\n- Hebrew is the oldest language on earth\n- The Swiss are very patriotic\n- What words rhyme with block\n- Who buys diamonds in rock form']"	['<urn:uuid:5022aa61-2fd4-4bce-a2e9-ea26ecc5b49a>']	factoid	with-premise	long-search-query	similar-to-document	single-doc	expert	2025-05-12T23:47:20.322175	11	58	2859
44	Working on city infrastructure projects, I need to understand both risk management and digital transformation aspects. What are the key societal changes affecting infrastructure asset management, and how do they relate to model risk control in digital systems?	Three major societal changes are impacting infrastructure asset management: digital change driving real-time coordination, resources change enabling smart logistics, and city change causing competition for urban space. Regarding model risk control, organizations need to manage both individual model risks and aggregate risks from model interactions. This requires monitoring tools with targeted reports for decision-makers, and independent risk monitoring teams to prevent asymmetric incentives from compromising model validation.	['Engineering & Systems\n‘Connect for Continuous Care’\nEngineering Asset Management (EAM) is dedicated to the development and application of engineering and managerial solutions to make physical assets as part of (public) infrastructures safe, effective, efficient and environmentally-friendly. EAM is all of the activities and processes used to ensure that new and existing assets provide balanced performance levels, for a specified time frame, accounting for the entire life-cycle phases: Design, Build, Maintain, Operate and Demolish (DBMOD cycle), see Fig. 1. Thus, it promotes a very multi-disciplinary thinking connecting engineering, economics, organisations etc., to create added value for asset users, owners, managers, service contractors and other stakeholders.\nEAM requires taking into consideration the value of these assets, including ecological and social benefits and costs. This requires a dynamic approach integrating engineering assets technology, asset information systems and operational processes. Within this approach, it is essential to balance the (varying) user demands and available financial resources with the supply of effective and efficient engineering assets service levels. To manage these levels, proper tooling, systems and methods are required to analyse, plan & control and forecast accurate service level states of the engineering assets.\nSpecifically, within the civil construction industry, EAM recently emerged as an important field of research due to the shift from ‘one-time control of new green-field’ build projects towards ‘continuous care of quality of service levels of existing gray-field’ infrastructures, including renovations, re-builts and or modifications. Moreover, this ‘service’ change, drives the following important developments\n- effective and efficient interventions and renovations are needed to ensure that existing infrastructures keep on providing adequate service levels with a minimum of service interruptions;\n- actual service information and predictions are expected by the rapid development of intelligent monitoring and data analysis capabilities;\n- long-term and integrated performance based contracts are common where payments are related to service requirements;\n- optimal distribution and allocation of resources (money, equipment and people) within the total service supply chain (owner, provider, operator, government and or (safety) regulator).\nAll of this requires a continuous cooperation within the supply chain of service provision between asset owners and engineering services contractors over the entire asset life-cycle phases. It is also of importance that the asset performances (‘supply’) are optimally balanced between the user requirements (‘demand’) and the resources c.q. budgets (‘finance’) that are available, see Fig.1. Moreover, asset managers and service contractors realize that they are operating within a challenging and changing environment where the three major societal changes or drivers: i.e., ‘digital’, ‘resources’ and ‘city’, will have a profound impact on different assets as part of infrastructures over the coming decade and will even inter-connect different infrastructures more and more.\nFirst, the digital change is driving transport processes towards more real-time co-ordination of supply and demand with completely new types of asset management practices. Second, the resources change drives towards smart logistics both for providing engineering services and for staff. Third, the city change is driving all major infrastructures competing for space with existing and new spatial uses in the urban environment. All of this leads to connectivity and interface challenges where integral planning should solve these. Last but not least, because of this fast changing world, the future infrastructure systems and their engineering assets should be responsive to these changes for which a connective EAM approach is necessary.\nEAM themes and scientific questions\nThere is a wide variety of scientific questions related to the developments as described above. For reasons of focus, the EAM themes are predominantly related to the engineering asset supply domain, with potentially links to the user or finance domain (see Fig. 1). Moreover, these themes are primarily dealing with quantitative information and or operational process topics. Hence, the three following EAM themes below with associated scientific questions provide a starting point both for research and education (see for more details section 1 and 2).\n- Integral Asset Planning (IAP)\nHow can engineering asset systems be planned in an integral manner with the following dimensions: i.e., 1. Spatial (multi-scale: system, network, object, element, component, material level); 2. Time (multi-scale: weeks, months, years, decades and life-cycle phase: design, build, maintain, demolishment); 3. Measurement (financial performance, physical capabilities, contract goal, safety requirements); 4. Organization (user, owner, provider) 5. Risk (estimate, measure)? Which type (or combination) of modelling technique (Monte Carlo simulation, Dynamic Programming, (semi-) Markov processes, Bayesian networks, decision, Game theory, Real Options, hybrid System Dynamics, Adaptive Pathways, Serious Gaming etc.) is appropriate for the type of scale of the planning model to be developed? Which management and planning strategies including control measures can be proposed to asset managers by using these models? How can we derive a dynamic response functions for infrastructure systems? How can we integrate price uncertainties, successive multiple intervention strategies and managerial flexibility into a next generation of LCC optimisation models for public infrastructures?\n- Asset Service Logistics (ASL)\nWhat type of algorithms or techniques are required for asset service logistical support systems that powers: 1. sustainable energy (support) infrastructure 2. city service hubs? For which spatial or time level within the entire supply chain, what type of modelling is most suitable? In which part of the supply chain the uncertainties have to be taking into account by probabilistic scheduling and where can we plan with deterministic values? Which type of automated control techniques are required for the development of virtual scheduling and control assistants? What is the role of expert judgement in asset service logistics and can it be automated within a virtual maintenance assistant? How can a Reversed Logistics service market model for local city-mining enhance the efficiency within the asset re-cycling supply chain? What is the impact of the introduction of vested contracts for asset service levels? How to improve associative contracting to is to optimize the performance goals of each partner within the asset service supply chain?\n- Asset Information Systems (AIS)\nLooking to all latest data and ICT developments, which possible technologies (e.g. AI, augmented reality, robots) can improve engineering asset management and how should these be adapted to the infrastructure and or the building domain? How can these developments be evaluated? How does the asset management office of the future look like and what is the role of virtual assistants for design, engineering and maintenance in this? How can innovative insights, techniques, virtual support systems and forms of collaboration be used and operationalised? How can structural health monitoring be improved following a data-science approach? What type and which level of asset information is needed for ‘local city-mining’ of recycled materials and what does it mean for existing Building Information Models (BIM)? How can heterogenous information management in scattered enterprise asset management software tooling, including BIM 5D, be optimized? How can we utilise user generated asset information? What can be the role for Serious Gaming, Expert Judgement and virtual maintenance assistants to control engineering assets with long-life spans? Can we improve system safety and system validation by digital-infra-twin models and virtual training concepts for engineering assets, operating software and stakeholder processes (eg. safety officer, tunnel operator, service contractor)? How can actual asset information from ‘outside’, gathered by users and inspectors be linked between asset management offices and what type of techniques should be used for these so-called ‘data-to-xx’ concepts?', 'A look at how guidelines from regulated industries can help shape your ML strategy.\nBy Ben Lorica, Harish Doddi, David Talby.\nAs companies use machine learning (ML) and AI technologies across a broader suite of products and services, it’s clear that new tools, best practices, and new organizational structures will be needed. In recent posts, we described requisite foundational technologies needed to sustain machine learning practices within organizations, and specialized tools for model development, model governance, and model operations/testing/monitoring.\nWhat cultural and organizational changes will be needed to accommodate the rise of machine and learning and AI? In this post, we’ll address this question through the lens of one highly regulated industry: financial services. Financial services firms have a rich tradition of being early adopters of many new technologies, and AI is no exception:\nFigure 1. Stage of adoption of AI technologies (by industry). Image by Ben Lorica.\nAlongside health care, another heavily regulated sector, financial services companies have historically had to build in explainability and transparency to some of their algorithms (e.g., credit scores). In our experience, many of the most popular conference talks on model explainability and interpretability are those given by speakers from finance.\nFigure 2. AI projects in financial services and health care. Image by Ben Lorica.\nAfter the 2008 financial crisis, the Federal Reserve issued a new set of guidelines governing models—SR 11-7: Guidance on Model Risk Management. The goal of SR 11-7 was to broaden a set of earlier guidelines which focused mainly on model validation. While there aren’t any surprising things in SR 11-7, it pulls together important considerations that arise once an organization starts using models to power important products and services. In the remainder of this post, we’ll list the key areas and recommendations covered in SR 11-7, and explain how they are relevant to recent developments in machine learning. (Note that the emphasis of SR 11-7 is on risk management.)\nSources of model risk\nWe should clarify that SR 11-7 also covers models that aren’t necessarily based on machine learning: “quantitative method, system, or approach that applies statistical, economic, financial, or mathematical theories, techniques, and assumptions to process input data into quantitative estimates.” With this in mind, there are many potential sources of model risk, SR 11-7 highlighted incorrect or inappropriate use of models, and fundamental errors. Machine learning developers are beginning to look at an even broader set of risk factors. In earlier posts, we listed things ML engineers and data scientists may have to manage, such as bias, privacy, security (including attacks aimed against models), explainability, and safety and reliability.\nFigure 3. Model risk management. Image by Ben Lorica and Harish Doddi.\nModel development and implementation\nThe authors of SR 11-7 emphasize the importance of having a clear statement of purpose so models are aligned with their intended use. This is consistent with something ML developers have long known: models built and trained for a specific application are seldom (off-the-shelf) usable in other settings. Regulators behind SR 11-7 also emphasize the importance of data—specifically data quality, relevance, and documentation. While models garner the most press coverage, the reality is that data remains the main bottleneck in most ML projects. With these important considerations in mind, research organizations and startups are building tools focused on data quality, governance, and lineage. Developers are also building tools that enable model reproducibility, collaboration, and partial automation.\nSR 11-7 has some specific organizational suggestions for how to approach model validation. The fundamental principle it advances is that organizations need to enable critical analysis by competent teams that are able to identify the limitations of proposed models. First, model validation teams should be comprised of people who weren’t responsible for the development of a model. This is similar to recommendations made in a recent report released by The Future of Privacy Forum and Immuta (their report is specifically focused on ML). Second, given the tendency to showcase and reward the work of model builders overthose of model validators, appropriate authority, incentives, and compensation policies should be in place to reward teams that perform model validation. In particular, SR 11-7 introduces the notion of “effective challenge”:\nStaff conducting validation work should have explicit authority to challenge developers and users, and to elevate their findings, including issues and deficiencies. … Effective challenge depends on a combination of incentives, competence, and influence.\nFinally, SR 11-7 recommends that there be processes in place to select and validate models developed by third-parties. Given the rise of SaaS and the proliferation of open source research prototypes, this is an issue that is very relevant to organizations that use machine learning.\nOnce a model is deployed to production, SR 11-7 authors emphasize the importance of having monitoring tools and targeted reports aimed at decision-makers. This is in line with our recent recommendation that ML operations teams provide dashboards with custom views for all principals (operations, ML engineers, data scientists, and business owners). They also cite another important reason to setup independentrisk monitoring teams: the authors point out that in some instances, the incentive to challenge specific models might be asymmetric. Depending on the reward structure within an organization, some parties might be less likely to challenge models that help elevate their own specific key performance indicators (KPIs).\nGovernance, policies, controls\nSR 11-7 highlights the importance of maintaining a model catalog that contains complete information for all models, including those currently deployed, recently retired, and under development. The authors also emphasize that documentation should be detailed enough so that “parties unfamiliar with a model can understand how the model operates, its limitations, and its key assumptions.” These are relevant to ML, and the early tools and open source projects for ML lifecycle development and model governance will need to be supplemented with tools that facilitate the creation of adequate documentation.\nThis section of SR 11-7 also has specific recommendations on roles that might be useful for organizations that are beginning to use more ML in products and services:\n- Model owners make sure that models are properly developed, implemented, and used. In the ML world, these are data scientists, machine learning engineers, or other specialists.\n- Risk-control staff take care of risk measurement, limits, monitoring, and independent validation. In the ML context, this would be a separate team of domain experts, data scientists, and ML engineers.\n- Compliance staff ensure there are specific processes in place for model owners and risk-control staff.\n- External regulators are responsible for making sure these measures are being properly followed across all the business units.\nThere have been many examples of seemingly well-prepared financial institutions caught off-guard by rogue units or rogue traders who weren’t properly accounted for in risk models. To that end, SR 11-7 recommends that financial institutions consider risk from individualmodels as well as aggregaterisks that stem from model interactions and dependencies. Many ML teams have not started to think of tools and processes for managing risks stemming from the simultaneous deployment of multiple models, but it’s clear that many applications will require this sort of planning and thinking. Creators of emerging applications that depend on many different data sources, pipelines, and models (e.g., autonomous vehicles, smart buildings, and smart cities) will need to manage risks in the aggregate. New digital-native companies (in media, e-commerce, finance, etc.) that rely very heavily on data and machine learning also need systems to monitor many machine learning models individually and in aggregate.\nHealth care and other industries\nWhile we focused this post in guidelines written specifically for financial institutions, companies in every industry will need to develop tools and processes for model risk management. Many companies are already affected by existing (GDPR) and forthcoming (CCPA) privacy regulations. And, as mentioned, ML teams are beginning to build tools to help detect bias, protect privacy, protect against attacks aimed at models, and ensure model safety and reliability.\nHealth care is another highly regulated industry that AI is rapidly changing. Earlier this year, the U.S. FDA took a big step forward by publishing a Proposed Regulatory Framework for Modifications to AI/ML Based Software as a Medical Device. The document starts by stating that “the traditional paradigm of medical device regulation was not designed for adaptive AI/ML technologies, which have the potential to adapt and optimize device performance in real time to continuously improve health care for patients.”\nThe document goes on to propose a framework for risk management and best practices for evolving such ML/AI based systems. As a first step, the authors list modifications that impact users and thus need to be managed:\n- modifications to analytical performance (i.e., model re-training)\n- changes to the software’s inputs\n- changes to its intended use.\nThe FDA proposes a total product lifecycle approach that requires different regulatory approvals. For the initial system, a premarket assurance of safety and effectiveness is required. For real-time performance, monitoring is required—along with logging, tracking, and other processes supporting a culture of quality—but not regulatory approval of every change.\nThis regulatory framework is new and was published in order to receive comments from the public before a full implementation. It still lacks requirements for localized measurement of safety and effectiveness, as well as for the evaluation and elimination of bias. However, it’s an important first step for developing a fast-growing AI industry for health care and biotech with a clear regulatory framework, and we recommend that practitioners stay educated on it as it evolves.\nEvery important new wave of technologies brings benefits and challenges. Managing risks in machine learning is something organizations will increasingly need to grapple with. SR 11-7 from the Federal Reserve contains many recommendations and guidelines that map well over to the needs of companies that are integrating machine learning into products and services.\n[A version of this post appears on the O’Reilly Radar.]\n- “Managing risk in machine learning”\n- “What are model governance and model operations?”\n- “Becoming a machine learning company means investing in foundational technologies”\n- “The quest for high-quality data”\n- Andrew Burt and Steven Touw on how companies can manage models they cannot fully explain.\n- David Talby: “Lessons learned turning machine learning models into real products and services”\n- Ira Cohen: “Applying machine learning for insights into machine learning algorithms”\n- “You created a machine learning application. Now make sure it’s secure”\n- Jike Chong on “Applications of data science and machine learning in financial services”\n- Gary Kazantsev on how “Data science makes an impact on Wall Street”']	['<urn:uuid:6bf91c60-aa57-4de1-a694-9e0d27d51484>', '<urn:uuid:587ec635-5e80-45f6-919d-6ee4e2741bb1>']	factoid	with-premise	verbose-and-natural	distant-from-document	multi-aspect	expert	2025-05-12T23:47:20.322175	38	67	2945
45	benefits social media healthcare marketing risks hipaa compliance	Social media in healthcare marketing offers benefits like informing and attracting new patients, building credibility, and enhancing online reputation, with 75% of people using at least one platform. However, it poses HIPAA compliance risks as healthcare providers cannot reveal any patient health information that could be connected to individuals, including 18 specific identifiers like locations smaller than a state or dates other than years.	['Social media is a powerful communication tool, as demonstrated by its ability to influence, educate, and inform prospective customers across a variety of industries. From consumer products and real estate to political campaigns, technology, and beyond, social media has become an integral tactic in any marketer’s toolbox.\nWhat about medical marketing? Medical and dental practices use social media to inform patients and attract new ones, reinforce their brand, boost web presence, build credibility, and enhance online reputation.\nIf you’re skeptical about how social media can support your healthcare practice’s marketing strategy, here are some powerful statistics to consider.\n9 social media statistics for healthcare practices\n- More than 75 percent of people use at least one social media platform.\nThe verdict is in: Social media isn’t going anywhere. According to Statista, nearly 80 percent of Americans use at least one social media platform. Facebook and Twitter have now been around for more than 15 years and have become part of our daily lives. Add in massively frequented outlets like YouTube and Instagram, and practices have a variety of channels to connect with patients in meaningful and engaging ways.\n- Facebook is the most widely used social media platform.\nAs a market leader, Facebook draws nearly two-thirds of all U.S. adults. While checking their feed for the latest on family and friends, users often spend time engaging with the more-than 200 million small businesses that use Facebook. A report published by Datareportal says Facebook users spend nearly 20 hours per month on the platform, providing healthcare practices with numerous opportunities to inform, educate, and connect with both current and prospective patients.\n(source: Pew Research)\n- Nearly three-quarters of marketers feel social media has been effective for their business.\nIf your practice is working with a limited marketing budget, it’s critical to know which of your marketing tactics are the most effective. One of the many benefits of social media marketing over traditional channels is the ability to track your campaigns’ results and progress — this offers greater insight into your social media return on investment.\nPractices using social media can track the number of users reached with each post, their level of engagement (clicks, “likes”), how many people visited their website or booked an appointment as a result, and much more. While data review takes a bit of time, Buffer’s 2019 State of Social Media Report reaffirms that most marketers are pleased with the performance of their social media marketing efforts.\n- Eighty percent of social media time is spent on a mobile platform.\nThis highlights the importance of creating mobile-friendly social media content. That means making your posts that short, sweet and to the point. Smartphone and tablet users also enjoy dynamic content like video — short videos can be among the most successful communication on mobile devices.\nFinally, since the goal of most social media posts is to convert readers and followers into patients via your website, this reaffirms the need for a website that is either mobile-optimized or mobile-responsive. That’s the only way to ensure a clear, satisfying experience for patients who visit your site via their mobile device.\n- Ninety percent of Instagram users follow a business.\nIf your practice is not participating on Instagram, you risk losing prospective patients to the social media-savvy practice down the road. While you may think of Instagram as a newer platform, it’s been around for more than a decade, and is drawing more businesses using the channel as part of an integrated marketing strategy.\nIn the popular PatientPop social media 101 webinar, 8 of 10 live attendees told us they already use Instagram at their practice — second only to Facebook. Think of Instagram almost like a rotating billboard, with people spending a lot more time “driving” their mobile devices than cars these days. Within your Instagram account, you can feature physicians, facilities, services you offer, and any visually appealing content that won’t play as well on other channels.\nIf your specialty lends itself to visual storytelling — aesthetics, plastic surgery, dermatology, weight loss — then Instagram is a must. Its light tone and quick video snippets make it easy to engage with your followers, and can help prospective patients get to know your brand and services in an interactive way.\n- Adults 18 and older watch an average of 4.9 hours of YouTube videos each week.\nThat’s more than 41 minutes a day, of what people too often perceive as time-wasting videos of silly animals, pranks, and stunts. But with a staggering variety of videos, YouTube can be a source of education. Why not bring meaningful information to your prospective patients? Healthcare practices that use YouTube connect with followers, patients, and prospective patients on a more personal level.\nCommon healthcare practice uses for YouTube videos include:\n- “meet the provider”-style videos\n- office and facility tours\n- “day in the life” physician or provider stories\n- patient stories or testimonials\n- educational videos or vlogs that answer patients’ most frequently asked questions\nFor providers who offer unique or highly specialized services, YouTube can be a powerful tool to introduce your practice to patients who may not otherwise make their way to your website.\n- More than 70 percent of consumers who have a positive brand experience on social media are likely to recommend that brand to friends and family.\nYou know the old mantra “Experience is everything?” It translates well to the world of social media. Healthcare practices that engage with social media followers, respond to questions and feedback promptly, and offer a positive patient experience are introducing themselves to a much broader audience than most are used to.\nTake that opportunity to show off your patient-focused approach for all to see. Treat social media comments, questions, direct messages, reviews, and feedback just as you would when speaking with a patient in person or on the phone. This increases your chances of scoring a personal recommendation, and helps continually improve your online reputation.\n(Source: Forbes, via Oberlo)\n- The number of daily active Stories users on Instagram and Facebook hit 500 million in 2019.\nJust when healthcare practices figured out the social media basics, the Stories format has taken over and users can’t get enough. Stories has played an integral role on Instagram for more than a decade — now, on Facebook, the format is growing 15 times faster than news-feed sharing.\nHealthcare practices can use the fast-moving Stories option to give followers a quick look within the practice, feature patients (with permission, of course!) or providers, or highlight new services or equipment. When it comes to Facebook or Instagram Stories, creativity is the name of the game. But remember that Stories disappear after 24 hours unless you add them to your highlights reel, on Instagram and Facebook.\n- At least 30 percent of consumers use social media to communicate with a company.\nThe rise of direct messaging on social media has created yet another avenue for patients and prospective patients to connect with your healthcare practice. Don’t ignore them.\nCheck your messages regularly and respond promptly, just as you would after receiving a voicemail or patient portal message. As with the tips in number 7, this level of connection can help you improve the patient experience and maintain a positive online reputation.\n(source: Drift, via Oberlo)\nSince most experts assume the use of social media as a business communications channel will increase, you may find your practice receiving more patient inquiries with time. Consider delegating the responsibility of monitoring and responding to comments to a practice staff member with a great track record for delivering exceptional customer service and prompt response times.', 'Social media is as important for healthcare marketing as it is for any other industry. Healthcare organizations need to connect with their audience, and to do that, they have to be where their audience is. Marketing teams and individual healthcare providers are using social media to share important updates, news and personalizing photos and stories, and that’s good. It’s also risky because of a little thing called HIPAA.\nAnyone working in healthcare has heard that word a lot, connected to the general idea of keeping patient information private. But there are some specific details you might not know about that could trip you up as you share photos and stories online. Here, we highlight a few pitfalls to look out for.\nBefore we get started, here are a couple of acronyms you might use all the time without knowing what they stand for:\nHIPAA: The Health Insurance Portability and Accountability Act. It’s a lengthy and complex law, but the upshot for you is that you can’t reveal any past, present or potential health information that can be connected to the patient. One twist is that, since the act was passed in 1996, it doesn’t include any specific regulations for social media. That means you need to be especially careful, because enforcement of the law is largely open to interpretation.\nPHI: Protected health information. This is… protected information related to a patient’s health. If it includes any identifiers, mentioning it online could result in a privacy breach. HIPAA helpfully provides a list of 18 identifiers that are off limits, and while some seem pretty obvious, others might surprise you. It’s good to give it a glance.\nOne important thing to remember is that your healthcare organization almost certainly has a HIPAA compliance officer on site or on contract. If there is any possibility that something you post might reveal PHI, check with your compliance officer first.\nPotential PHI Pitfalls\nNo one doesn’t like a happy ending, and healthcare offers some of the happiest — high-risk pregnancies that result in adorable triplets, lengthy illnesses that end in miraculous recoveries or even just funny goings-on in the clinic that gave everyone a chuckle. Such stories are great Facebook fodder — and a minefield of PHI. The more details you include, the more compelling your post is, and the more likely you are to provide information that could connect that touching story to the patient who may or may not want it told.\nRemember that list of identifiers? You might feel confident that you’ve protected patient privacy because you didn’t include a name or a photo. But that list also includes any location smaller than a state or any date other than a year. And on top of that, information from your own profile could combine with seemingly innocuous patient information to reveal their identity — your location, the facility where you work, the date of your post. If any weirdly dedicated Internet sleuth could use the information to identify the patient, you’re on the hook for failing to protect patient privacy. So as compelling and Facebook-ready as that story might be, you might have to just sigh and keep the story in your heart. If you have any questions, feel free to ask your compliance officer.\nThink you’ve avoided any possible HIPAA violation by not including your patient in the photo? Take another look, paying careful attention to the background. Does that selfie also capture the status board in the patient’s room or the nurses’ station? When you took a picture of your lunch for the ‘gram, is it sitting on top of a patient file with the name visible? (Do you even need to post your lunch on social media? I mean, really?) Does that happy photo of a successful care team also include a patient in the distance you hadn’t noticed when you were getting everyone together? Those are all potential violations.\nEven if you’ve gotten a written release from the patient to use their image on social media, never post anything without doing a thorough scan of the background to look for any unintentional photobombs. Any questions can be directed to… you know.\nDon’t do it. You might want to. You might have had a great experience treating an individual. Their treatment might have been lengthy, and you had time to get to know each other, and now you feel like friends.\nYou might be friends, but you’re care provider and patient first. Online and in the real world, there are issues of ethics and professionalism. In terms of HIPAA, the more you interact with this patient on social media, the more likely it is that PHI is going to slip out during the course of conversation.\nYou probably don’t even need to bother asking Compliance about this one. Just don’t do it.\nFacebook, Twitter, Instagram and, increasingly, TikTok are a great way to inform your audience and just let them know who you are as an organization. Storytelling is a great way to make connections. HIPAA doesn’t mean you have to stop doing it, and PHI doesn’t need to be a dark cloud looming over your head every time you write a Twitter post. Just be informed, be careful and be respectful. And look over any group photo to see if anyone has bad hair or is making a weird face — just because you look good, that doesn’t make it Instagram-worthy.']	['<urn:uuid:d384ea22-1c21-41bc-9bba-17274b6da38f>', '<urn:uuid:b862f203-daad-425c-bafe-90511544deda>']	factoid	direct	long-search-query	similar-to-document	multi-aspect	expert	2025-05-12T23:47:20.322175	8	64	2177
46	urban beekeeping success survival vs countryside hives	Urban beekeeping actually shows higher success rates compared to rural beekeeping in several ways. Urban bees have a higher winter survival rate than rural bees and produce more honey in their first year. This is partly because urban bees have access to more diverse plants and are less exposed to harmful pesticides commonly used in rural agricultural areas. Additionally, urban bees can thrive by accessing a variety of pollinator plants across neighborhoods, being able to fly up to 5 miles to find nectar and pollen sources. However, they do require consistent access to diverse plant habitats from March to October to sustain their hives.	['If you want someone to show up and care about something or someone, ask a nurse. If you want someone who has time and will go the extra mile for a something or someone, ask a retired nurse.\nTerry Dettweiler contacted me last year about doing a special project for her University of New Mexico neighborhood to support bees. She noticed that her neighborhood beekeeper no longer brought her the requisite annual jar of honey. When asking the beekeeper about this loss, her friend said she had hung up her beekeeping veil and could no longer keep the beehive alive. She noted a dreary lack of pollinator plants in the neighborhood. Bees need a smorgasbord of habitat all 3 seasons—from March to October. They can fly up to 5 miles to pursue their banquet of nectar and pollen. If it is a food desert, they will not be able to sustain their hives.\nTerry, a master gardener, became concerned after this conversation. She loved plants. She loved honey. And so, it made sense that she loved bees!\nSoon Terry and her daughter, Eva, embarked on a COVID year project to raise the money from the city and her local neighbors, as “seed money” for her pollinator plant corridors. Terry’s goal was to inspire neighbors with free plants to create oases of pollinator habitat and begin to learn about bees and native plants of the high desert southwest. Eva, who works for the Quivira Coalition, wrote a bang up grant that we pitched to city leaders for funding.\nI was stirred to excitement as I remembered our Burque Bee City resolution that we passed in 2016 through the city council. Unanimously, I might add.\nOne of the defining goals is:\nWhereas communities have the opportunity to support bees and other pollinators on both public and private land through reduced and pesticide free zones: working in collaboration with city officials to manage and increase healthy habitat for pollinators—including but not limited to roadsides, medians, open spaces and parks. (CITY OF ALBUQUERQUE, 22nd city council, Burque Bee City Resolution)\nThe good news is that Terry raised so much money from neighborhood, her City Councilors, Ike Benton and Pat Davis, and Commissioner Adrian Barboa, that she has money leftover for another project in 2022! She was able to work with the Santa Ana Pueblo nursery to purchase plants at wholesale prices!\nAnd so we commenced with the pollinator plant giveaway on September 25 and 26, 2021, shortly after Fall Equinox. Enthusiasm abounded amongst the neighbors. They worked hard as an association to organize, set up and show up the days of the giveaway. Both days dawned with the usual blue skies and Autumnal sunshine bathing the city. People showed up with dogs, partners, families and children, armed with wagons, bags and buckets. They hauled away armloads and boxes of coral penstemon, sages, grasses, chocolate flowers, echinacea, gaillardia, flowering bushes and more… Teachers came eager to bring plants back for their schools and students. 500-700 plants went out the door each day.\nThe buzz was out! Terry had tables laden with materials for how to water your plants and nurture them til it is well rooted. There were loads of resources for native plants, xeric landscapes, and backyard wildlife refuges. Think Like a Bee was there to answer any questions alongside master naturalists and gardeners.\nCommissioner Barboa came and joined in the celebratory atmosphere, excited about how this project met so many of her own urban agriculture goals—connecting neighbors, populating our landscape with native plants, feeding bees, connecting Indigenous communities.\nYou can also have your own neighborhood pollinator plant beautification and habitat project! We can help you do it. Terry now has a template for how it’s done and she’s willing to share.\nNeighborhoods, let’s feed the bees in 2022! Remember. People love free stuff.', 'When you think of beekeeping you may think of the rural countryside, forests, or homesteads. You may even be interested in beekeeping, but think it is not possible because you live in an urban area. However, that is not true! Urban beekeeping is a rising trend, and with urban beekeeping kits readily available, it’s never been easier to raise bees, no matter where you live.\nWhat is Urban Beekeeping?\nUrban beekeeping is basically what it sounds like – the practice of keeping and raising bees in an urban area. It is sometimes also called backyard beekeeping, or hobby beekeeping. Beekeeping in a highly populated city may not sound feasible, but urban bees actually have a higher winter survival rate than rural bees. In addition, urban bees produce more honey than rural bees in their first year.\nBenefits of Urban Beekeeping\nJust as bees are essential for pollination on farms and agricultural areas, urban areas also depend on bees in order to grow local produce. In an effort to grow more fruits and vegetables locally, many cities have started to utilize rooftop gardens.\nNew York City’s Fashion Institute of Technology’s building – an iconic building in a densely populated city, features a lush, green rooftop garden, as well as beehives housing colonies of Italian bees. FIT’s rooftop bees have become so popular that they have even installed a camera so curious bee watchers can view the bees online.\nRooftop gardening would not be possible without bees there to take on the important task of pollination. With a growing interest in sustainability, urban beekeeping kits are now popping up everywhere.\nIn addition, urban beekeeping makes it possible for locals to enjoy fresh, local honey made in their very own city. Urban bees likely have access to much more diverse plants than rural bees. With many farms resorting to using pesticides on their crops, rural bees unfortunately tend to be exposed to those harmful chemicals. Since pesticides aren’t usually used in urban areas, it isn’t a problem for urban bees.\nUrban beekeeping isn’t just good for people, it’s beneficial to bees too. With colony collapse disorder taking a huge toll on the bee population, urban beekeeping is a great way to help bees survive, and help our ecosystem overall.\nHow to Start Urban Beekeeping\nIf you would like to start urban beekeeping, there are a few things to consider. First, you must check if your city has any rules or regulations regarding beekeeping. You can do this by checking your city’s zoning ordinances. This information should be available online on your city’s government website. Some cities have regulations on the size of your lot, the numbers of hives you may keep, and the type of bees you raise.\nNext you must determine the best spot for your urban beekeeping kit. In an urban setting, location is the main challenge of beekeeping. It is best to be creative and keep an open mind when searching for an area to start your beehive. Choosing a spot that is easily accessible will aid in doing hive inspections later on. Rooftops are popular areas for urban beekeeping kits to be kept. So if you have access to you rooftop, that may be a good option for you.\nTypes of Urban Beekeeping Kits\nNow you need to decide what type of beehive you would like to use. The 3 most common types are the Langstroth hive, the Warre hive, and the Top Bar hive.\nLangstroth hives are rectangular boxes containing 8 – 10 frames for the bees to build comb on. As your bee colony grows you stack more boxes onto the hive. The Warre hive looks and similar to the Langstroth hive, but it is smaller. It also does not use frames like the Langstroth, but instead it uses top bars.\nThe last type of beehive to consider for your urban beekeeping kit is the Top Bar hive. Top bar hives consist of a long, rectangular box with bars laying on the top. The bees build comb on these bars.\nMost urban beekeeping kits will feature a Langstroth hive. Langstroth hives are the most commonly used type of beehive today. Therefore, they have the most supplies and information available to new beekeepers. For this reason I would suggest a Langstroth hive for your urban beekeeping kit.\nBest Urban Beekeeping Kits\nMann Lake Basic Beekeeping Starter Kit\nThe Mann Lake Basic Beekeeping Starter Kit is the perfect starter kit for urban beekeepers. It is constructed well and has a simple, easy to use design. The best thing about this kit is that it comes assembled and painted. That alone saves so much time.\nThis kit includes 1 box and 10 assembled frames with foundation. You start your bee colony in this box and add more boxes as your colony grows. Another good thing about this kit is that it includes several beekeeping supplies such as a veil, gloves, and hive tool.\nA con of this beekeeping kit is that it costs a little more than some other beehives, but I think the price is worth it because it is fully assembled and made in the USA. I’d gladly pay a little extra to save the time and effort of putting together and painting a beehive myself. It also only has one box, so be prepared to buy more boxes when your colony expands.\nHoover Hives Natural Bees Wax Coated 10 Frame Bee Hive\nThis beehive from Hoover hives is a great option because it comes with 3 boxes – 1 medium and 2 deep. The measurements of the medium box is 16-1/4″ x 19-7/8″ x 6-5/8″, while the deep boxes measure 16-1/4″ x 19-7/8″ x 9-5/8″. The boxes are made of high quality pine and have dovetail joints.\nEach box holds 10 frames, so this kit comes with 30 frames, total. Each frame has food grade plastic foundation which is coated with real beeswax. The wax coating ensures quick acceptance by the bees. Other things included are a wax coated solid bottom board, metal telescoping top cover, inner cover, plastic queen excluder, and entrance reducer.\nDovetail joints make assembly quick and easy, and the nails are even included. The boxes are made of high quality fir, which is both strong and attractive. Furthermore, the boxes are all coated with beeswax, which offers great protection to the wood. Because of this, this beehive does not need to be painted.\nA benefit of this hive is that it included 3 boxes for an affordable price. I also like that both the foundation and the boxes are coated in beeswax. A con is that if you would prefer to paint your hive, the paint will not stick to the wax. For that reason, I would recommend this hive to someone that does not want to paint their beehive.\nHoney Keeper Beehive 20 Frame Complete Box Kit\nThis Honey Keeper Beehive comes with 2 boxes and 20 frames to fill them. There are 2 different frame sizes- 10 deep and 10 medium. Other things included with this beehive kit are a metal telescoping roof, solid bottom board, entrance reducer, inner cover, and queen excluder.\nThis beehive kit is a great price for 2 boxes and 20 frames. The wood is premium fir and the pieces have dove tail joints which ensure a tight, secure fit. I like how affordable this hive kit is, and that it comes with 2 boxes instead of 1. That is a really great value!\nA con of this kit is that it is not assembled, so you’ll have to spend some time putting it together. Most people spend about 2 hours setting up the hive. It is recommended to use wood glue when assembling the beehive.\nThe wood is untreated, so you should also plan to paint it. Paint protects the wood from the elements so the hive lasts longer. Paint only the outside of the hive and allow ample time for off-gassing.\nTips for Urban Beekeeping\n- Before you get started, research bees. Knowing more about how and why bees do things will go a long way with urban beekeeping. Luckily there is an abundance of information out there on different species of bees. Books and websites, such as this one are a great resource for urban beekeeping.\n- Make sure your bees have shade. With many urban beekeepers placing their hives on their rooftops it is important to note that bees need shade. Place your bees in a shady area near a water source. If your rooftop is very windy you also need to strap your hive down to ensure it isn’t knocked over.\n- Plant flowers. While bees can travel up to 5 miles in search of flowers and nectar, it is helpful to bees if you plant flowers yourself. Choose varieties that will bloom throughout the year. Click here to see a list of flowers bees love.\n- Use one size box for brood and honey. In a Langstroth hive bee boxes come in 3 different sizes. Beekeepers often use deep boxes for brood and medium boxes for honey. It can be helpful for beginner urban beekeepers to instead use medium boxes for both brood and honey. Medium boxes are lighter and may be easier to manage than deep boxes.\n- Inspect your hive every 7 – 10 days. Regular inspections are important because you don’t want your colony to run out of space. You should also look for healthy eggs, larva, and the queen. Because bees are so interesting you may be tempted to check on your bees multiple times a day. Please resist the urge to do so because checking on them too much will cause the bees unnecessary stress.\nSummary – Beekeeping is For Everyone\nIf you live in an urban area and would like to try beekeeping, don’t fret! Beekeeping is entirely possible in an urban environment. It is very beneficial to both bees and people, helping to create a healthy ecosystem.\nBefore getting an urban beekeeping kit you should first look up local zoning ordinances. Then, determine the ideal spot for your hive and the best beehive for you. You will soon find that urban beekeeping is an enjoyable hobby with many rewards.\nOriginally posted on July 10th, 2019 and updated on March 13th, 2020.']	['<urn:uuid:54aed1e3-c7e4-4e27-afa2-07e94d7aaaa0>', '<urn:uuid:d0215a21-0d39-4398-a7f4-8e1a9352edc5>']	open-ended	with-premise	short-search-query	distant-from-document	multi-aspect	novice	2025-05-12T23:47:20.322175	7	104	2357
47	open plan office partition effects daylight transmission workplace stress management	Partitions in open plan offices have significant dual effects: They can reduce daylight transmission by up to 50% at 15 feet from windows when using 72-inch partitions compared to 48-inch ones, impacting potential energy savings. However, when made of planted or natural materials like timber boards, partitions can serve a positive role in workplace stress management by blocking visual distractions and dampening sound, which helps address the issue of workplace interruptions that take an average of 23 minutes to recover from.	['How can we design the mindful office? What would a mindful office look and feel like?\nAn introduction to mindfulness\nWe live and work in a world full of distracting pollution.\nWith increased digital connectivity through access to emails, social media, the web’s encyclopedic repository of information and all the other distractions that are commonplace in office environments – other people’s conversations, phones ringing, machines whirring and bleeping and the sound of passing traffic – we are increasingly finding it impossible to focus on the task at hand.\nProfessor Gloria Mark, who researches “interruption”, conducted a study of information workers in high-tech companies. She found that the people they observed over 3.5 days switched activities every three minutes and five seconds on average (half of these switches were caused by self-interruptions). In the study she found that relevant interruptions can be beneficial and provided they are short and fairly automatic they won’t cause too much disruption, however if they require a switch in cognitive functioning they can make it difficult to regain focus.\nFrom what she observed, 82% of interrupted work was resumed on the same day. However it took the workers an average of 23 minutes and 15 seconds to return to what they were doing. Surprisingly, those who were interrupted worked faster without any significant difference in the number of errors in the work. However these interruptions have more serious implications as they increase stress levels.\nExcessive or prolonged stress can lead to illness, physical and emotional exhaustion and depression. It can affect the behaviours and factors that increase the risk of heart disease (high blood pressure, cholesterol levels, smoking, physical inactivity and overeating). In fact the World Health Organization believe that the stress related illnesses of heart disease and depression are projected to become the prime causes of illness by 2020.\nConsidering 90% of a typical business’ operating costs are related to staff (salaries and benefits) as opposed to 10% on the physical environment. It is worth considering how the office environment can be designed to help workers focus on the task at hand and reduce the risk of increasing prolonged stress levels which in the long term will affect both the individuals’ health, their ability to work and the companies’ costs.\nBig businesses like Goldman Sachs, Barclays, Google and JP Morgan are now investing in Mindfulness programmes for their staff to address these issues . Mindfulness techniques are also being trialed in schools to help improve students’ performance and experience.\nMindfulness is a technique rooted in Eastern meditation that helps increase awareness of the present moment through regular connection with one’s senses. It has more recently become a tried and tested technique in psychology to reduce stress and anxiety related mental health issues and in other medical professions to address physical disorders.\nMindfulness in the workplace\nSo how do we create working environments that encourage mindfulness and help employees stay focused on the task at hand? Biophilic design offers opportunities to encourage sensory awareness required for mindful states by appealing to a range of senses:\nThrough increasing the amount of natural light & creating views out to nature it’s possible for employees to have greater awareness of the present moment whether that is the time of day or year. Partitions can help in open plan offices, not only do they block visual distraction but if planted or natural material partitions (i.e. timber boards) are used they can also dampen sound and have positive effects on health and wellbeing1.\nIntroducing plants can improve air quality2 and increase oxygen level, but also emits a subtle scent by putting pot plants & green planted walls. Other natural aromas can be introduced to help.\nRange of natural surface textures e.g. Timber furniture grain provides haptic stimulation. Interface’s Human Nature and Urban Retreat collections of flooring mimic the varying textures in natural environments and the undulating surface to walk across.\nSound masking can be introduced where it is impossible to block out extraneous noise as a method of stress reduction. Recorded sounds like water flowing can effectively mask disruptive noises like passing traffic3 or others’ conversations. In the Heath Design studio we use a service called Focus@will, or listen to Julian Treasure’s “Study” app. Sound insulation – wall panels made from natural materials like wool felt4 – or green walls can absorb excessive sound whilst introducing biophilic natural elements and textures.\nThermoception is the sense by which we perceive temperature, which can be influenced by the feeling of air moving across the skin. Thus, optimizing ventilation and thermal control5 to ensure workers can control the temperature and air flow according to their needs (i.e. windows and vents that can be opened when needed and accessible localised thermostats).\nWith this in mind, the slick shiny surfaces used in minimalist office interiors of the past which were meant to reflect and encourage efficiency actually prove to be less efficient. This is because a lack of sensory stimulation in the workspace can lead us to seek or be susceptible to distractions and to interrupt our work flow.\nHave you been distracted in the course of reading this article? Could your surroundings need to become more “mindful”? What is your most powerful mindful space?\n1Biophilia: Does Visual Contact with Nature Impact on Health and Well-Being\n2Nasa Report (1989) Interior Landscape Plants for Air Pollution Abatement\n3Galbrun & T. T. Ali (2012) Perceptual assessment of water sounds for road traffic noise masking\n4Oldham, D.J., Egan, C.A. & Cookson, R.D. (2011) Sustainable acoustic absorbers from the biomass. Applied Acoustics. 72: 350-363.\n5World Health Organisation (2010) Guidelines for Indoor Air Quality', 'Daylighting Resources - Energy Issues\nIf a workplace is well lit by daylight, then electric lighting can be dimmed or switched off, creating a reduction in lighting electricity bills. In some buildings, windows may increase heating bills in the winter because they are poor thermal insulators. Windows may also increase air conditioning bills in the summer if direct sunlight is allowed to enter the buildings.\nEnergy cost savings in practice are highly dependent on the behavior and cultural values of occupants—if occupants are provided with opaque aluminum blinds and leave them closed all the time to ensure privacy, then no lighting energy savings are possible. If occupants value daylight and the view out, or are motivated to minimize energy costs, substantial savings are possible.\nTypical cost of lighting energy\nElectricity for lighting typically costs 60 cents per square foot per year, or approximately $60 per year per employee (assuming a typical lighting energy density of 1.5 watts per square foot (W/ft2), office occupancy from 08:00 to 18:00, 100 square feet per employee, 12 cents per kWh electricity cost, and that 0.35 watts of air conditioning are required to remove one Watt of lighting heat).\nSixty dollars per employee is a very low sum compared to the cost of hiring, training, paying, managing and retaining that employee, and so the primary goal in the use of daylight should be to improve employees’ working environment and to cause them no undue annoyance or discomfort. Unsuccessful energy-saving schemes focus only on the cost savings to the company, whereas successful schemes focus on creating pride in the workplace, improved morale and an awareness of shared responsibilities and benefits.\nEnergy-saving potential of various lighting control systems\nThe energy saved by any lighting control system varies very widely depending on the size and layout of the office, the size of the windows, and any partitioning systems used. All energy savings are quoted relative to a baseline of the lights being switched on all the time.\n- Single-occupant or small shared offices\nA simple light switch is an effective energy-saving device because it allows occupants to easily switch their lights on when required, or to leave them switched off if daylight is providing sufficient light (Hunt, 1979). Light switches are appropriate when occupants are controlling only their own lights, or those of a small group of co-workers. Switches should be positioned close to the light fixtures in order to maximize usage (California Energy Commission, 2003). Lighting energy savings of around 30% are typical for small offices, but vary widely depending on the size and type of windows, and the motivation and preferences of the occupant(s) (Newsham, 1994).\nAutomatic systems that switch off or dim the lights in response to daylight are highly effective in single daylit offices. Reinhart (2002) found that energy savings of 50% were possible in conjunction with a manually-operated blind system, and that savings could reach 70% if the blind were optimally controlled either by occupants or by an automatic system.\n- Large open-plan offices\nIn open plan offices it is difficult to provide light switches close to the fixtures, unless local task lighting is used, or unless an expensive, addressable control system is installed. Occupants of shared space are often reluctant to use light switches for fear of creating conflict with their co-workers (Moore et al., 2003).\nA system that automatically controls the lights in the response to the amount of daylight is the most effective way of saving energy in open-plan spaces. Systems that progressively dim the lights are preferred to those that switch them off, because the operation of the automatic system is less noticeable to occupants. Occupants should always be provided with a simple means of overriding the automatic system, otherwise complaints may lead to the system being decommissioned.\nLighting energy savings for automatic systems vary widely depending on the size and type of windows; Reinhart (2002) showed that a typical 30’ deep office with dimming controls could save approximately 40% of lighting energy in conjunction with manually-controlled window blinds. Switching systems are not effective at distances of more than 10-15’ from windows.\n- Large partitioned offices\nPartitions dramatically reduce the transmission of daylight into an office, and the resulting energy savings, compared with open-plan offices. Reinhart (2002) showed that 72” partitions halved daylight levels in an office 15’ from the windows, compared with 48” partitions. Therefore automatic dimming or switching systems will only achieve significant energy savings in the first row of offices with high partitions.\nSkylights are a particularly effective source of daylight because they admit light from the brightest part of the sky (the zenith), but seldom cause glare because they are above the typical visual field of occupants. Skylights are complementary to windows, since windows illuminate the perimeter of a space, whereas skylights can illuminate its center.\nThe use of skylights can reduce the electric lighting requirement of an entire space during daylight hours to almost zero, but they must be designed to shade the space from direct sunlight (Heschong-Mahone Group, 1998).\nStrategies for maximizing energy savings\n- Light-colored walls and furnishings increase the amount of daylight in a space and improve visual comfort by reducing contrast. The areas around the windows are especially important.\n- Removing clutter from the window sill and the floor around the window, and using a light colored carpet or rug will significantly improve the transmission of daylight into the space.\n- Light switches should be clearly labeled to show which light fixtures they control. This will reduce people’s uncertainty and make them more likely to turn lights off, or switch on only the lights they require.\n- A simple “light shelf” made of a light-colored material, approximately 18” deep and placed horizontally about 2-3’ below the top of the window will brighten the upper walls and ceiling around the window, reducing contrast and improving visual comfort. This will make occupants less likely to switch their lights on.\nback to top']	['<urn:uuid:ac075f53-145b-4995-b82f-7cd50d18593e>', '<urn:uuid:eb3882d9-d2fb-499c-a74c-e384884e6b05>']	factoid	direct	long-search-query	similar-to-document	multi-aspect	expert	2025-05-12T23:47:20.322175	10	81	1923
48	As a cardiovascular surgeon, which nonabsorbable sutures can I use?	All types of nonabsorbable sutures can be used for cardiovascular procedures, including nylon (natural monofilament), polypropylene/Prolene (synthetic monofilament), silk (braided natural), and polyester/Ethibond (braided synthetic).	['Sutures are used by your doctor to close wounds to your skin or other tissues. When your doctor sutures a wound, they’ll use a needle attached to a length of “thread” to stitch the wound shut.\nThere are a variety of available materials that can be used for suturing. Your doctor will choose a material that’s appropriate for the wound or procedure.\nThe different types of sutures can be classified in many ways.\nFirst, suture material can be classified as either absorbable or nonabsorbable.\nAbsorbable sutures don’t require your doctor to remove them. This is because enzymes found in the tissues of your body naturally digest them.\nNonabsorbable sutures will need to be removed by your doctor at a later date or in some cases left in permanently.\nSecond, the suture material can be classified according to the actual structure of the material. Monofilament sutures consist of a single thread. This allows the suture to more easily pass through tissues. Braided sutures consist of several small threads braided together. This can lead to better security, but at the cost of increased potential for infection.\nThird, sutures can be classified as either being made from natural or synthetic material. However, since all suture material is sterilized, this distinction is not particularly useful.\nTypes of absorbable sutures\n- Gut. This natural monofilament suture is used for repairing internal soft tissue wounds or lacerations. Gut shouldn’t be used for cardiovascular or neurological procedures. The body has the strongest reaction to this suture and will often scar over. It’s not commonly used outside of gynecological surgery.\n- Polydioxanone (PDS). This synthetic monofilament suture can be used for many types of soft tissue wound repair (such as abdominal closures) as well as for pediatric cardiac procedures.\n- Poliglecaprone (MONOCRYL). This synthetic monofilament suture is used for general use in soft tissue repair. This material shouldn’t be used for cardiovascular or neurological procedures. This suture is most commonly used to close skin in an invisible manner.\n- Polyglactin (Vicryl). This synthetic braided suture is good for repairing hand or facial lacerations. It shouldn’t be used for cardiovascular or neurological procedures.\nTypes of nonabsorbable sutures\nSome examples of nonabsorbable sutures can be found below. These types of sutures can all be used generally for soft tissue repair, including for both cardiovascular and neurological procedures.\n- Nylon. A natural monofilament suture.\n- Polypropylene (Prolene). A synthetic monofilament suture.\n- Silk. A braided natural suture.\n- Polyester (Ethibond). A braided synthetic suture.\nYou’ll often see sutures and stitches referred to interchangeably. It’s important to note that “suture” is the name for the actual medical device used to repair the wound. The stitching is the technique used by your doctor to close the wound.\nSuture material is graded according to the diameter of the suture strand. The grading system uses the letter “O” preceded by a number to indicate material diameter. The higher the number, the smaller the diameter of the suture strand.\nSuture material is also attached to a needle. The needle can have many different features. It can be of various sizes and also have a cutting or noncutting edge. Larger needles can close more tissue with each stitch while smaller needles are more likely to reduce scarring.\nJust like there are many different types of sutures, there are many different suture techniques. Some of them are:\nThis technique involves a series of stitches that use a single strand of suture material. This type of suture can be placed rapidly and is also strong, since tension is distributed evenly throughout the continuous suture strand.\nThis suture technique uses several strands of suture material to close the wound. After a stitch is made, the material is cut and tied off. This technique leads to a securely closed wound. If one of the stitches breaks, the remainder of the stitches will still hold the wound together.\nThis type of suture is placed under the layers of tissue below (deep) to the skin. They may either be continuous or interrupted. This stitch is often used to close fascial layers.\nThis type of suture is applied so that the suture knot is found inside (that is, under or within the area that is to be closed off). This type of suture is typically not removed and is useful when large sutures are used deeper in the body.\nThis is a type of continuous suture that is placed around an area and tightened much like the drawstring on a bag. For example, this type of suture would be used in your intestines in order to secure an intestinal stapling device.\nThese sutures are placed in your dermis, the layer of tissue that lies below the upper layer of your skin. Short stitches are placed in a line that is parallel to your wound. The stitches are then anchored at either end of the wound.\nWhen your sutures are removed will depend on where they are on your body. According to American Family Physician, some general guidelines are as follows:\n- scalp: 7 to 10 days\n- face: 3 to 5 days\n- chest or trunk: 10 to 14 days\n- arms: 7 to 10 days\n- legs: 10 to 14 days\n- hands or feet: 10 to 14 days\n- palms of hands or soles of feet: 14 to 21 days\nTo remove your sutures, your doctor will first sterilize the area. They’ll pick up one end of your suture and cut it, trying to stay as close to your skin as possible. Then, they’ll gently pull out the suture strand.\nYou may have heard the word “sutures” in reference to a bone or bones. This is because the area where the bones of your skull meet is called a suture. Your skull has many of them. They allow the skull to increase in size throughout development and then fuse together when growth is complete. This is not related to the sutures that a physician or surgeon may place to close a wound.\nSutures are used by your doctor to stitch shut wounds or lacerations. There are many different types of suture materials available. Additionally, there are many suture techniques that can be used. Your doctor will choose both the correct suture material and technique to use for your condition. Talk to your doctor about any concerns you have about sutures before your procedure.']	['<urn:uuid:5a6b770a-a7cb-4bbf-8236-ee5893c0c8d7>']	open-ended	with-premise	concise-and-natural	similar-to-document	single-doc	expert	2025-05-12T23:47:20.322175	10	25	1061
49	What documents are needed for events vs treatment plants?	For events, promoters need to provide garbage collection arrangements to NSWMA, while waste treatment facilities must submit extensive documentation including waste descriptions, treatment procedures, site plans, transportation details, data recording methods, and closure cost estimates.	"[""Editors' Forum | Solid waste permits soon needed for event approval\nIf the management and board at the National Solid Waste Management Authority (NSWMA) have their way, party promoters will soon need to secure a solid waste permit before they can host events in Jamaica.\nIn a move geared at holding promoters accountable for the collection, containment and disposal of garbage after staging events, the NSWMA will be seeking to have recommended regulations passed into law.\nNSWMA Legal Director Gail Mitchell says the agency intends to correct and monitor the ongoing process.\n“We have fines in relation to littering and different forms of littering in public places, and it has now gone far beyond what the parent act provides for,” Mitchell said at a Gleaner Editors’ Forum last week. “You think of persons in an apartment and they just litter everywhere; think of people in entertainment, you keep a dance over by Palisadoes and you have one whole heap of garbage. It’s not going to work. We are going to ensure that you take responsibility for that.”\nShe continued: “The regulations are now going to provide for an application to the NSWMA, in terms of permit and licensing, and to monitor you after the fact, so you are going to need to take responsibility for whatever garbage you would have generated and pick it up or make provisions.”\nThe Gleaner understands that the regulations are now at the Office of the Chief Parliamentary Counsel.\nNSWMA Chairman Dennis Chung said that the recommended fines are meant to ensure persons take greater responsibility for keeping the country clean.\n“What we have recommended from the board level is significant,” Chung said.\nAudley Gordon, executive director at NSWMA, acknowledged that enforcement of the law is key to changing behaviour.\n“Let me caution that it must go hand in hand with the boots on the ground because you can have the regulations, but if you do not have the capacity to enforce it, it stays on the paper where it is written,” he said.\nAccording to the NSWMA, promoters would need to visit the agency and make arrangements for garbage collection or state how the garbage would be collected and disposal of.\n“We just want to ensure that the garbage or solid waste would have been containerised and disposed of, so they can ask the NSWMA to do it, but the onus is now going to be on the promoter or whoever is putting on that entertainment activity to say to the authority, ‘This is how I am going to dispose of my garbage’,” Mitchell pointed out.\nGordon, however, stressed that the NSWMA would not be seeking to approve or deny permits in the event application process.\n“We would not be infringing on the police’s jurisdiction. They will decide if they want to permit a dance or a show. That’s not our business. We not going to infringe on the parish council, who have their other considerations to make; that’s there prerogative to make,” the NSWMA executive director said. “We are saying, to the extent that you get permission to keep this show, we want to ensure that the place nuh nasty up.”\nThe NSWMA cited the mounds of garbage left by revellers at a carnival event this year as a point of reference.\n“If you notice the last carnival, there was a mess uptown after the carnival. However, that is not to say that there weren’t arrangements in place. There were arrangements in place with a private hauler, but what we concluded was that the arrangement was not adequate in terms of the amount of people. The volume of garbage was out of this world,” Gordon said.\n“We want to make that now backed by the regulation that we must have a say so that an event like carnival, we can anticipate by experience the amount of people, how much garbage will be generated, how many people we should have there picking up, how many bags we should have placed at strategic points, and how many trucks we should have come in the aftermath of the carnival. Regulation would give us not just a seat around the table, but a hand on the control,” he explained."", 'The requirement for a permit in order to operate a waste treatment facility (recovery or disposal) aims at preventing or reducing as much as possible the negative effects of waste production on man and on the environment.\nReducing the harmful effects of waste must be carried out:\n- where possible, by waste recovery, i.e. through reuse, recycling or any other ecologically appropriate method allowing the waste to be reintroduced into the economic system in the form of secondary raw materials after treatment;\n- failing this, through the disposal of the final waste in an ecologically and economically suitable manner, i.e. by dumping or, as a last resort, incinerating said waste.\nA specific waste permit application for operating a waste treatment facility must be submitted to the Waste Division (Division des déchets) of the Environment Agency (Administration de l’environnement).\nWho is concerned\nA waste treatment permit application must be submitted for:\n- the setting up or operating of a plant or site to be used in a professional capacity for at least one of the waste treatment processes listed in appendices I (disposal activities) and II (recovery activities) of the law on the management of waste;\n- any substantial change, i.e. the transfer, expansion or conversion of plants or sites used for these activities.\nThe permit may be required for establishments or businesses carrying out one of the following activities:\n- waste disposal, in particular:\n- land or maritime burial;\n- incineration (without energy recovery);\n- biological or physico-chemical treatment leading to the disposal of certain compounds, etc.;\n- activities leading to the possibility of waste recovery, in particular:\n- recycling or recovery of materials;\n- regeneration of substances (solvents, acids, bases, oils, etc.);\n- energy recovery;\n- agricultural spreading of organic waste, etc.\nAs of certain thresholds or depending on the activity, waste recovery or disposal facilities are classified according to the nomenclature of classified establishments.\nIt is the case for landfills, incineration plants or waste treatment facilities using physical, chemical, biological or thermal methods.\nIn these cases, waste permit applications are combined with applications for an operating permit for classified establishments.\nEstablishments that are not subject to an operating permit for classified establishments or that fall under class 4 of the nomenclature of classified establishments must register with the Environment Agency.\nIt is thus advisable to check whether the facility concerned is classified in the nomenclature.\nHow to proceed\nIf the facility is listed in the nomenclature of classified establishments, the waste permit application is submitted together with the application for an operating permit for classified establishments and the applicant must gather the documents relating to it.\nThe following documents regarding the waste permit in particular must be added:\n- a precise description and origin of the waste to be accepted, stored and/or treated, with their European Waste Codes (EWC or CED2 in French);\n- clear and precise names of the waste treatment operations to be used for each fraction of waste concerned (on the basis of the disposal and recovery codes provided in appendices I and II of the law of 21 March 2012 on the management of waste);\n- a detailed description of the procedures, machinery and/or equipment used for the treatment of waste;\n- a plan of the site, including the place of storage of the waste in question;\n- contact details and permit numbers of the transportation / trading companies of the waste resulting from the treatment carried out;\n- a presentation of the methods used to record data relating to the waste treated;\n- an estimate of the cost of closing the site and, where applicable, of the management of the site following its closure.\nRequesting or renewing a waste permit\nIf the facility is subject to an operating permit for calssified establishments, it is sufficient to add a copy of the waste permit application to the application for an operating permit for classified establishments.\nThe operating permit for classified establishment has the same legal status as a waste permit.\nWhere the establishment in question does not require a classified establishment operating permit or when the permit reaches expiry, the waste permit application or the renewal application may be sent directly to the Environment Agency.\nOperating a waste treatment facility\nEstablishments or businesses with a waste treatment permit are required to:\n- draw up acceptance criteria approved by an approved organisation for the waste intended to be accepted;\n- conclude an acceptance agreement with the producer or holder of waste prior to acceptance thereof;\n- have control procedures for accepted waste approved by an approved organisation;\n- prepare internal regulations and send said regulations to the competent supervisory authorities;\n- keep a journal relating to the management of the site and have it certified at least once a week by the person in charge of the site;\n- provide the Waste Division of the Environment Agency with an annual report containing the information stipulated in the permit order before 31 March of the year following the period under review;\n- have diplomas and/or certificates providing proof of the practical experience of staff;\n- prepare a manual with all the different work procedures;\n- set up a financial guarantee or any equivalent means to cover the estimated cost of the closure of the site and its subsequent management;\n- have a site acceptance report drawn up by an approved entity within one year following notification of the permit order;\n- notify the Environment Agency of the cessation of activities covered by the order as soon as possible and at least 6 months in advance according to the standard administrative procedure;\n- designate a contact person in charge of environmental issues and a replacement person and provide the Environment Agency with the names of said persons on the day that the site becomes operational at the latest.\nDepending on the type of facility and activity planned, other specific permits might be required:\nForms / Online services\nRapport annuel – traitement / élimination / valorisation de déchets\nWho to contact']"	['<urn:uuid:f8d321ef-d6e4-4f88-8af6-dd24d7719fd0>', '<urn:uuid:fa3b0e0b-d2a7-4a1c-87d8-d0f92fa020c5>']	factoid	direct	concise-and-natural	distant-from-document	comparison	novice	2025-05-12T23:47:20.322175	9	35	1705
50	I keep hearing about AI in banking but don't really get it - what are some actual ways banks are using artificial intelligence to catch criminals and prevent fraud?	Banks are using AI and machine learning particularly in financial crime risk management, specifically for anti-fraud, anti-money laundering (AML) and cybersecurity applications. They use AI for client screening using external risk factors and have alert prioritization frameworks for sanctions screening and transaction monitoring to better manage and detect financial crime signals.	['Background and key dimensions of pandemic impact\nAfter the 2008 recession, financial institutions (FIs) & central banks have been continuously building resilience against market shocks to avoid resorting to public funded bail outs. Capital & liquidity buffers have been maintained at a healthy level through the past decade, that can now be used to mitigate the financial crisis triggered by the current pandemic.\nMoreover, in responding to the pandemic, global regulators have come out with similar responses, by encouraging FIs to support customers in surviving this crisis and gradually land on their feet. To this purpose, many non-critical regulatory deadlines have been postponed in order to reduce the operational burden to some extent. In brief, the guidance has been:\n- An increased focus on protecting consumers and market integrity in the short term, and remaining vigilant against financial crime\n- Continuation of liquidity injection into the markets to avoid any ripple effect resulting into a systemic breakdown\nThe present crisis has an impact on various dimensions of business operations. These repercussions fall under four main buckets – Financial, Operational, Customer and Regulatory – that can ultimately lead to business disruption (see Figure 1).\nCRO / CCO response to pandemic impact to date\nThe impact of COVID-19 has dealt a dual blow creating supply chain disruption and demand-side slowdown. The chief risk & compliance officer (CRO/CCO) division plays a key role in the mitigation of rapidly emerging risks and to lead recovery efforts into the new beginning. Two primary focus areas are driving these efforts: client centricity and operational resilience.\nMoreover, the risk & compliance leadership is using pandemic impact (e.g. changed working practices), as a strong driver to accelerate their digital adoption roadmap. The upcoming two quarters will prove critical in determining the future course of the financial organization and industry.\nOperational resilience and customer centricity will become the overarching theme for CROs to deliver confidence and continuity of services\nIndicative regulatory focus\nWe are witnessing a two-way push across the regulatory spectrum, with the focus increasing in some areas and easing out in others. Broad categories across global regulators include:\nOutcomes map in the New Beginning\nWith the rapid evolution of financial ecosystems, the risk and compliance function is also constantly growing in coverage as the result of newer risk types into the governance, risk and compliance (GRC) spectrum. The pandemic has accelerated this change, and encouraged CROs to reassess & reimagine their core capabilities and the corresponding expansion possibilities in delivering incremental value, positioning CROs/CCOs as potent catalysts in optimizing risk-return profiles\nFurthermore, there is also an active focus on proactively developing transformational capabilities toward delivering a competitive advantage for the organization. The segregation of outcomes across core, adjacent and transformational themes can be seen in Figure 2.\nRole of emerging AI and ML technologies to re-imagine use cases\nIn a recent survey report conducted by TCS and Chartis1 across 166 relevant risk business & technology leaders, covering retail and commercial banks, capital markets institutions, and insurance and wealth management firms, we discussed the maturity of AI in their institutions, and the potential for further uplifting these capabilities to deliver specific outcomes. The next few sections list some of our key findings.\nIn enterprise resource management (ERM) the use of artificial intelligence (AI) techniques is focused on non-regulated use cases, such as the generation of early warning signs, and the analysis of what-if scenarios instead of regulatory reporting projects. A representative of a large universal bank proposed leveraging AI capabilities to construct a varied and expansive stress and scenarios library. The bank could then scan tens of thousands of benchmark results, and millions of market data points, to pinpoint potential areas of concern.\nIn regulatory reporting, AI has been used in managing and validating data, validating results against predetermined criteria and monitoring overall compliance. Representatives from several large banks explained that they are now running elaborate data management and validation programs using strong machine learning (ML) and related analytical frameworks.\nIn financial crime risk management (FCRM), respondents see the greatest benefits in anti-fraud, anti-money laundering (AML) and cybersecurity applications, with KYC an area of growing interest. Client screening using external risk factors and alert prioritization frameworks for sanctions screening and transaction monitoring are providing greater resiliency in the management of financial crime signals.\nIn operational risk, quantifying has traditionally been extremely challenging. Standard statistical models have struggled with the relative paucity of data and lack of deep statistical processes. However, in our discussions with banks and other FIs, three key trends stood out:\n- Widespread digitalization has effectively solved the data paucity problem\n- External and internal networks can now be monitored in much greater detail\n- There are broad uses for AI in non-financial and operational risk management contexts, although one quarter of respondents are not engaged.\nCROs’ evolving influence in a client-centric ecosystem to deliver growth and transformation\nCROs are gradually moving toward a user journey-driven operational model that’s focused upon client centricity. Initiatives like improvement of customer data view, including hardships and dispute analytics, enable insights for a more informed and empathetic decision making by the frontline. This model also requires reimagination of business services and processes to improve throughput and risk management efficiency.\nMoreover, in the time of crisis, strengthening workforce availability and effectiveness in forbearance, and restructuring cases and guidance on alternate products is imperative to expand operational capacity and ensure business continuity. CROs are looking at strengthening risk & compliance capabilities to deliver insights and value-added services, like ratings and hedging advisory for SME clients, and defensive measures like improving customer data protection against cyber-attacks and financial crime, to create competitive advantage in the marketplace.\nThese factors, coupled with an expanding profile of a CRO, necessitate a larger ecosystem to mitigate the expanding risk profile of financial institutions. Figure 3 shows different enablers participating together in a conducive ecosystem:\nHorizon for CRO initiatives (6 to 8 quarters)\nWe are witnessing a sudden surge in risk clusters and their interplay, which has never been observed before in recent history. While we have had pandemics in the past, the potential impact of a pandemic has increased exponentially, due to the sheer size of today’s global banking system, and an ever increasing reliance on the infrastructure to conduct day-to-day transactions. In such an environment, prioritizing remediation initiatives is proving very challenging for CROs. Figure 4 visually represents this horizon of prioritized initiatives.\nFigure 4: Prioritized focus horizon view\nIn summary, the pandemic presents unique challenges and opportunities for the FIs in adapting to a new normal of delivering business continuity in a remote operation’s dominant setup. Risk & compliance organizations have so far responded well, in delivering client centricity and operational resilience, wherein FIs are going above and beyond their traditional mandates, with value-added services for customers while continuously adopting newer design patterns. Capability uplifts in areas like conduct risk mitigation, reputational risk management & early warnings for shifting left, are emerging as priorities, with a customer centric use journey approach, to deliver client protection and enablement.\n1“The State of AI in Risk Management: Developing an AI roadmap for risk and compliance in the finance industry,” 2019, https://www.tcs.com/content/dam/tcs/pdf/Industries/Banking%20and%20Financial%20Services/State-of-AI-in-Risk-Management.pdf']	['<urn:uuid:3c36c37a-42c8-4ac2-b9a5-8554afc9b127>']	factoid	with-premise	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-12T23:47:20.322175	29	51	1193
51	networking events professional dos donts resume	At networking events, professionals should bring business cards, dress appropriately, set goals, be concise, and follow up on connections. However, they should not distribute paper copies of their resume, as this is more appropriate for job fairs. The focus should be on meeting people and forging real connections rather than appearing overly eager to land a job.	"['Professional networking might sound intimidating to recent college graduates or people who have never tried it before. In reality, networking simply means making connections and forming relationships with other professionals in your field. Many graduates view professional networking as the gateway to obtaining job offers. While networking and knowing the right people often provides access to career opportunities, there is more to be gained from successful networking than just finding a job. Through networking, professionals share a wealth of knowledge, resources, and connections.\nNetworking simply means making connections and forming relationships with other professionals in your field.\nProfessionals network online through popular sites such as LinkedIn, and in person at conferences, events, and meetings. More than just taking down names and phone numbers, or adding distant colleagues on a website, professional networking should retain a personalized element. Forming positive, personal associations with other public health professionals creates an environment that encourages collaboration, mutual assistance, and respect. In a field focused on improving the health of society as a whole, it is beneficial for individuals to maintain professional and personal relationships with their peers.\nDifferent Types of Professional Networks in Public Health\nSome researchers argue that three types of professional networks exist: operational, personal, and strategic. Each adheres to its own unique purpose, function, and makeup. Operational networks, which typically consist of internal contacts within an organization, exist to enhance a group\'s functionality and efficiency. Personal networks, which consist of contacts from external locations, exist for professional and personal development as well as to provide access to useful contacts. Strategic networks comprised of internal and external connections look to facing future challenges, determining priorities, and building industry support.\nEach strategy poses its own advantages and disadvantages, including internal blind spots and bias, questions of accessibility, and exclusiveness. Public health professionals benefit from forming networking associations of all three types, but strategic networks prove the most important in the field as a whole, encouraging professionals to collaborate for larger, common goals concerning the promotion of human health.\nNetworking Events in Public Health\nAlthough networking often occurs online, the importance of public health networking events cannot be understated. In-person networking provides an immediate connection and, depending on the context, may prove more memorable for both parties. Networking opportunities occur in convention centers, workplaces, and even in public. Make time to attend relevant lectures and seminars, visit job fairs, and attend social events.\nAdding a personal touch to your professional connections will help you stand out and be remembered.\nNetworking in person might seem like a contrived or hollow process, but this doesn\'t have to be the case. A stereotypical networking method, such as handing out business cards or contact information, goes along well with a chat about your current work experience, future goals, or personal motivations. Adding a personal touch to your professional connections will help you stand out and be remembered.\nElevator Pitches in Public Health\nOne useful tool for professional networkers to keep in their back pocket is the classic elevator pitch: a concise, brief summary of who you are, what you offer, and what you’re seeking. It should last no more than approximately 30 seconds, which is the length of an average elevator ride. Apart from avoiding a clunky sales pitch format, few hard and fast rules exist for elevator pitches. You should craft yours according to your own needs. Aspiring public health professionals might consider sharing their motivations for choosing to pursue work in this particular field. For additional ideas, use online guides and suggestions.\nSocial Networking Sites for Public Health Professionals\nLinkedIn is the most popular and widely known professional social networking site. However, public health professionals have additional online networking options, such as BranchOut and Gadball. Online social networking provides several advantages over traditional methods, namely increasing the size of your potential networking pool. You can access people from global locations without leaving your desk, although online communication often lacks the personal touch of face-to-face networking. LinkedIn and other business networking sites frequently require paid membership to access certain features, which limits your networking ability if you choose to remain on a free plan.\nIt takes time and experience to develop networking abilities. Even long-time professionals must continue to hone their methods as they learn what to say and how to act in their efforts to make meaningful connections with others.\nListen and Ask Questions\nDont Go it Alone\nNetworking Event ""Do\'s"" for Public Health Professionals\n- Set Goals: Before you attend a networking event, consider what you want to accomplish and set goals accordingly. Maybe you want to hold five in-depth conversations that end with an exchange of contact information. Maybe you want to meet a specific person in attendance. Wherever you go, go with a goal in mind.\n- Dress Appropriately: You don\'t have to dress the same way for every event you attend. Consider the event’s context. A social mixer might not require the same attire as a business conference. When in doubt, business casual is usually appropriate.\n- Bring Business Cards: While networking events stand apart from job fairs or vendor exhibitions, you should still bring business cards with relevant information and contact details. At the end of a conversation with someone, offer them your card and ask if they would like to stay in touch.\n- Be Concise: At heavily attended networking events, everyone arrives with the hope of making as many significant professional connections as possible. Keeping this in mind, try to avoid unintentionally holding others hostage with a long-winded discussion. Keep your conversations and anecdotes concise, and allow conversation partners to move on if they wish.\n- Follow Up on Connections: You’ve spent the evening conversing, shaking hands, and getting to know others in your field. Now you can head home and let the networking magic kick in, right? Not quite. Following up on conversations with a timely email, LinkedIn connection request, or phone call in the week following the event is vital to meaningful networking.\nNetworking Event ""Don\'ts"" for Public Health Professionals\n- Distribute Paper Copies of Your Resume: Although the population at networking events might look similar to what you would see at a job fair, the two come with entirely different social rules. Keep your resume at home when you attend networking events. Focus on meeting people and forging real connections rather than appearing overly eager to land a job.\n- Use a Shotgun Approach: When attending a networking event, focus on the quality, not quantity, of connections. One surefire way to alienate other professionals in the room is by making a sales pitch to everyone within earshot or passing out business cards like candy.\n- Interrupt or Talk Over Others: Successful networkers listen and speak. Interruptions are rude in any context. Remember that networking means making real connections, not getting the last word. Give others your attention, and they will return the favor.\n- Be Intimidated: No matter what professional hats we wear in the workplace or how much name recognition we possess, at the end of the day, we’re all human. Don’t be afraid to approach others at a networking event. Even notable public health professionals benefit from conversations with others.\n- Neglect to Follow Up on Connections: Following up on connections after a networking event ensures your best chance of developing and maintaining the professional relationship. Take the initiative, and don’t assume others will reach out first. Waiting too long, or forgetting entirely, to follow up on a connection makes it difficult to reconnect in the future.']"	['<urn:uuid:1e196372-d753-4b58-8bd7-58fe8fa637c1>']	factoid	with-premise	short-search-query	similar-to-document	single-doc	expert	2025-05-12T23:47:20.322175	6	57	1253
52	What irrigation solutions exist for both natural and synthetic turf fields?	For natural turf, in-ground irrigation systems with retractable sprinkler heads provide comprehensive coverage, such as the Goulds Water Technology system installed at the Travis Roy Foundation's fields that ensures constant pressure and monitoring. These systems typically require at least 21 heads within playing boundaries for a regulation football field. For synthetic turf, specialized irrigation solutions include eight-head systems throwing water from sidelines to overlap between hash marks, primarily for cleansing purposes. Additionally, traveling aboveground sprinkler systems with wheel-mounted water guns and twin heads can be used for rapid rinsing and cooling of synthetic surfaces. Both types of fields require different maintenance approaches - natural turf needs careful moisture management for plant growth, while synthetic turf irrigation focuses on cleaning and temperature control.	"['Water irrigation solutions provided to the Travis Roy Foundation’s Wiffle Ball Park\nGreen fields and efficient sprinkler systems might not sound like a typical component in supporting spinal cord injury research and awareness, but for the Travis Roy Foundation, this was an important part of aiding its overall mission.\nThe Travis Roy Foundation hosts an annual Wiffle ball tournament in Essex, Vermont, to raise money for spinal cord injury research. For the three fields in this one-of-a-kind facility, the foundation needed a smart irrigation and pump control system to keep the fields green and lush. Goulds Water Technology (GWT) was selected to provide an efficient system to maintain the fields all season and has been delivering optimal performance since the installation.\nThe Wiffle ball park is comprised of three fields, each a to-scale replica of famous baseball parks including Wrigley Field, Fenway Park and the Field of Dreams. Little Wrigley, as it is affectionately named, features ivy and a chalk-style scoreboard. Little Fenway is complete with its very own green monster and mini CITGO sign in left field. Little Field of Dreams is meticulously surrounded by cornstalks.\n“We host the tournament entirely on all three fields, and that’s a lot of ground to maintain and keep green,” said Pat O’Connor, Tournament Director. “I have been responsible for the fields for the past 17 years. It was very labor-intensive since I had to drag hoses around the field to properly water everything.”\nIn order to reduce the time spent on maintenance, O’Connor consulted with local well drilling, irrigation and lawn maintenance dealers and contractors to find a solution that was good for the field and enabled O’Connor to dedicate more time to other areas of the foundation.\nSpafford & Sons Water Wells in Jericho, Vermont, was selected to help lead the installation of the new sprinkler system and pump monitoring. The Spafford team installed a GWT Aquavar SOLO 2 constant pressure system with a NEMA 3R enclosure and a 1.5HP 18GPM GS 4” submersible pump.\n“We needed a system that would produce 70 psi to run water cannons as well as be on a pedestal outside,” said Jeff Williams, Vice President, Spafford & Sons Water Wells. “GWT provided the best system options. The fact that the irrigation contractor was also familiar with GWT really helped solidify our choice.”\nThe GS 4” submersible pump features stainless steel construction for convenient serviceability and industry leading hydraulic performance, which is needed to reach all three fields, and allows for convenient serviceability so Williams and his team can address potential issues easily.\n“By coupling the GS pump with the Aquavar SOLO 2, we are able to help ensure constant pressure control and monitoring to optimize performance of the entire system,” said Chris Preston, Residential Water Product Manager, Xylem AWS. “This system solution efficiently provides water that the fields need and helps maintain their high quality.”\nIn its 16-year history, the Travis Roy Foundation has raised more than $4.6 million for spinal cord injury research and grants. With the new GWT pump system, the Wiffle ball park is in top shape all season, not just when the area receives sufficient rainfall. This allows the Travis Roy Foundation to focus on increasing participation in tournaments and advocacy for spinal cord injury research.', 'At the mercy of available water reserves, groundskeepers must strive for peak irrigation efficiency.\nRainfall was already lagging 30 inches behind the 12-month norm when drought conditions spiraled out of control last July in Mesquite, Texas. For two solid weeks, high temperatures topped 105 degrees, baking the city\'s clay-based recreational sports fields as if they were in some giant meteorological kiln. Fractured soil and patches of brown turf characterized many fields - the usable ones. And in a cruel bit of irony, updates to the in-ground irrigation system at one of Mesquite\'s multipurpose venues had bared so much soil to the blazing sun that cracks on that field measured a full 12 inches wide and three feet deep, exposing the system\'s brand-new wiring strung 18 inches below the playing surface and rendering the renovated tract useless for the entire baseball and football seasons.\nLeagues were shuffled among satisfactory game sites, and seasons shortened. Some associations took to filling cracks themselves to keep fields playable. Practicing on game fields was strictly prohibited. ""Everyone had to make sacrifices,"" says Mesquite park services superintendent Travis Sales. ""That\'s the only way we were able to work around it.""\nThe biggest sacrifice took the form of water. With local lake levels depleted by as much as 17 feet, Sales had to scale back his irrigation regimen from three days per week to one weekly watering. Mandated restrictions coupled with evening playing schedules further dictated that watering take place only between midnight and 6 a.m. Fields fortunate enough to receive water did so only within their playing boundaries.\nFar from ideal, such compromises were at least possible thanks to the automated in-ground irrigation system already in place on Mesquite park grounds. Forty-seven of 100 citywide irrigation stations, including those covering all athletic fields, are controlled by computer from Mesquite Park Services Division headquarters. Water waste is further curtailed by flow meters that detect leaky pipes and damaged sprinkler heads, then automatically shut down the affected station in favor of the next one in the irrigation sequence. ""All in all, we made it through pretty well, but we are still far from being out of the drought,"" Sales says. ""There are going to have to be permanent changes made to the way we water.""\nThough severe, the situation in Mesquite is not isolated. Climate patterns - even population surges - are foretelling future strain on our nation\'s natural resources. And ask any groundskeeper or agronomist: The single most important ingredient in successfully growing sports turf is water. ""In certain parts of the country, such as the semi-arid West, you either have water or you don\'t have grass,"" says Iowa State University horticulture professor David Minner, who teaches a three-credit course focused solely on irrigation. ""In other areas that receive fairly high rainfall, we use supplemental water there, too, because we\'re not only growing grass, we\'re growing it on cue. We\'re forcing it to grow. And because we don\'t tolerate brown grass during the playing season, we need supplemental irrigation systems.""\nGiven the ever-increasing demand for recreational green space, not to mention the lofty expectations of today\'s end users, the pressure is on groundskeepers everywhere to deliver lush playing surfaces while ensuring that their irrigation practices meet peak efficiency. Says David Zoldoske, director of the Center for Irrigation Technology at California State University, Fresno, ""I think large parks and athletic fields are going to come under increasing scrutiny to minimize the total amount of applied water in a given area.""\n""School districts are already under increased pressure,"" says Mike Tarantino. As grounds and operations superintendent of the Poway (Calif.) Unified School District near San Diego, Tarantino oversees 35 separate playing sites. ""My elementary school, middle school and high school fields are used seven days a week, probably 365 days a year,"" he says. ""All my fields are open to any community group that wants to use them - from Little League to Pop Warner to soccer, rugby, lacrosse and field hockey organizations.""\nLike most of his colleagues in California and throughout the Southwest, all of Tarantino\'s natural-grass fields - game and practice - feature in-ground irrigation. The investment in such technology becomes spottier as one travels east into more intemperate climates. ""In the Midwest, some high school athletic directors and coaches, the decision-makers, don\'t think irrigation is important. They think it\'s a luxury,"" says Lynda Wightman, senior sales manager for irrigation manufacturer Hunter Industries and a member of the National Interscholastic Athletic Administrators Association\'s sports turf committee. ""My job is to try to teach them about efficient irrigation - what they need to do to have an irrigation system and how they need to maintain it so that their fields are safe. It\'s not just about aesthetics; it\'s about safety.""\nEnsuring irrigation efficiency starts with a working knowledge of hydraulics, Wightman says. That means knowing where water is going to come from, at what pressure, through what type of equipment and layout, and under what kind of control. Sufficient pressure is needed to activate retractable sprinkler heads, the size of which can be specified based on available water pressure. The heads must be spaced so that the water they throw - typically anywhere from 30 to 90 feet, depending on available pressure and system design - at least reaches the next closest heads in the layout for complete, overlapping irrigation. This so-called ""head-to-head coverage"" means that a regulation-size football field will feature at least 21 retractable heads within its playing boundaries, and perhaps another 30 or more out of bounds. Heads should be no larger than two to three inches in diameter, capped in hard rubber and positioned so that the rubber cap is level with the finished grade when retracted. Ideally, heads on fields that receive regular top-dressing treatments are specified with swing joints, allowing them to be trenched out and manually raised every five to eight years as the soil profile steadily accumulates additional layers.\nDue to pressure limitations, sports fields are typically irrigated in valve-controlled zones, with only a fraction of the sprinkler heads active at any given time. The addition of a booster pump can increase pressure and allow for the activation of a greater number of heads and even the simultaneous irrigation of more than one field. Care must be taken, however, to ensure that water traveling to the area doesn\'t exceed the accepted industry speed limit for PVC pipe of five feet per second. If too much water is forced through too small a pipe, pressure actually drops due to frictional losses caused by agitated water contacting more of the pipe\'s inner surface area. Too much pressure can also cause water hammer - the backlash exhibited by high-speed water flow once it hits an obstacle in its path, such as a ""T"" intersection or a 90-degree elbow within the design layout.\nEfficient irrigation design also requires forethought. Experts recommend roughing in additional pipe for future expansion of in-ground systems to include adjacent fields, as well as specifying a sufficient number of quick couplers on any given field for manual watering, in the event of in-ground system failure.\nUnderground leaks and heads knocked out of alignment or damaged by mowers are among the biggest contributors to an established system\'s inefficiency. A tilted sprinkler head will spray the water at an improper trajectory, or perhaps even straight into the air, and a head whose rotary arc (adjustable from 45 to 360 degrees in some models) has come out of alignment may be watering bleachers instead of turf. In addition, all heads should pop high enough above the grass blades to avoid having their spraying distance inhibited by the turf itself. Wightman recommends semiannual or even monthly inspections of empty fields with the system on to ensure water is not being wasted. ""Site inspections are cheap insurance policies,"" she says. Still, no system is perfect. Says Tarantino, the current president of the Sports Turf Managers Association\'s Southern California chapter, ""If you get a system that operates at 75 to 80 percent efficiency, you\'re blessed.""\nGrant Trenbeath, head groundskeeper for Major League Baseball\'s desert-based Arizona Diamondbacks, recently tweaked the irrigation system at Chase Field to allow high-speed rotors to water much of the facility\'s skinned areas. ""To alleviate some of the man-hours we were pouring into the watering of our infield dirt, I put in a system that allows me to turn on one manual valve and run it while I\'m hand-watering at the same time,"" Trenbeath says. ""I can be done watering my infield and darn near flooding it in 15 minutes, as opposed to it taking three people up to 45 minutes.""\nNowhere on a baseball field are true hops more critical than on the infield dirt, and proper moisture levels are what keep this mostly clay surface soft - but not too soft. It\'s commonly accepted that if a player\'s spikes sink in, but no deeper than the sole of the shoe, the infield dirt exhibits adequate moisture. The challenge becomes maintaining such conditions throughout the course of one game day. That\'s why a fifth-inning drag is useful not only for smoothing out impressions in the dirt, but for reintroducing to the playing surface moisture left in lower soil levels from the pregame water application. ""A lot of college fields are hosting weekend doubleheaders, with only 20 or 25 minutes in between games,"" says Trenbeath. ""A system like this is a great tool to put down a greater volume of water in a short period of time to improve the playability of the field.""\nThe synthetic-turf explosion, meanwhile, is widely viewed as a direct response to sports administrators\' ongoing concerns over the cost of maintaining natural grass. But irrigation experts caution that even today\'s advanced synthetics aren\'t maintenance-free. Rare is the synthetic football field specified today without in-ground irrigation, typically designed as eight heads throwing water far enough from outside opposite sidelines to overlap between the hash marks. Uniform coverage isn\'t essential, since the goal here has nothing to do with nurturing plant growth. ""Typically, the first reaction is to not irrigate synthetic turf,"" says Brad Waters, a representative of irrigation manufacturer Rain Bird, who sees the benefit of synthetic-turf irrigation not so much in commonly cited heat and static reduction, but in basic cleansing. ""Kids spit, they bleed, they do other things on synthetic turf that aren\'t clean. Now you can get a synthetic-turf football field clean without having to pop a lot of heads out there.""\nTraveling aboveground sprinkler systems, which consist of a wheel-mounted water gun pulled by its hose across the field toward a hose reel, offer another means by which to irrigate synthetic turf. While some aboveground units are used exclusively on natural grass (their reels automatically turned either by water filling and discharging out of a bellows or by water driving a turbine), others are designed solely for the rapid rinsing and cooling of synthetic turf. These units offer speedier, engine-driven reels and twin sprinkler heads (since water pressure isn\'t compromised by propulsion). Because the unit can traverse the length of a football field in a fraction of the time it takes natural-grass irrigation units to do so, the twin heads pointed toward opposite sidelines ensure more uniform coverage. Says Brian Behrends, sales manager at irrigation manufacturer Kifco, which introduced a synthetic-turf irrigation model last summer, ""You can take it out at halftime and pull it through real quick, so by the time the players come back out the field has been cooled down.""\nET data, which can also be gathered by contacting nearby universities or local meteorologists, is especially useful to those in charge of far-flung fields that can\'t be visually inspected on a daily basis. Moreover, the day-to-day monitoring of ET becomes increasingly critical in regions of the country (such as the Midwest) where weather conditions may vary widely within a 48-hour window, but less so in states such as California, where more consistent seasonal conditions are a given. ""Once I get into summer,"" says Tarantino, who sees an average of nine inches of rain per year, mostly during the winter months, ""I know what I\'m going to get.""\nGroundskeepers able to walk their fields can still fall back on visual inspection to determine the turf\'s level of thirst. Footprinting - the inability of grass blades to rebound when stepped on - is an indication of incipient wilt, or a lack of turgidity within the plant. The grass may also exhibit a blue-green hue at this stage of stress. ""It really doesn\'t hurt the grass,"" says ISU\'s Minner. ""In fact, it makes roots grow."" Adds Brad Waters, area specification manager for irrigation manufacturer Rain Bird, which will stage its sixth Intelligent Use of Water Summit this month in Madrid, Spain, ""The deeper the roots, the less frequent your irrigation, typically, because deep roots can get available soil moisture easier than extremely shallow ones.""\nIrrigation isn\'t the only horticultural practice influencing root development, however. Mowing turf at low heights, while fostering denser turf growth to meet today\'s performance demands, actually retards deep root development. Thus, fields mowed at three-quarters of an inch will require more frequent irrigation than those mowed at two inches.\nMinner recommends that turf managers master the art of recognizing when their fields reach a point of manageable stress, then put down just enough water to coax continued root growth. Turf on sand-based fields will begin to show signs of stress again in about three days, while it may take a soil-based field seven or more days to wilt. ""Going through this cycle of what we call deep and infrequent watering allows the field to dry out,"" Minner says. ""The drying period is good, because when it dries and wilts you know that there is sufficient oxygen in the root system. If you\'re watering so you never see any wilt at all, then you are probably over-watering. You probably have a lack or reduced amount of oxygen in the root zone.""\nIt\'s even useful for those with irrigation systems featuring computerized controls to learn to visually recognize their turf\'s point of incipient wilt, according to Minner. ""These systems can be so automated that the tendency is to turn them on, walk away and let that little electronic box think for you,"" he says. ""I usually train people to turn the automated part off, learn what their grass needs are, then come back and use the automated part for times they\'re away.""\nThe future of sports field irrigation may be no easier to forecast than average yearly rainfall totals, but one thing remains readily apparent: Grounds maintenance personnel need to take a closer look at their watering practices. By the time 2006 was declared the hottest year on record in the United States, British scientists had already predicted that 2007 would be the warmest ever worldwide. If available water again becomes scarce, sports field administrators can expect to see a trickle-down effect that starts with residential watering restrictions. ""Turf is a threatened species,"" says Fresno State\'s Zoldoske. ""I\'m not saying that anybody\'s ever going to talk about banning sports fields, but I think they\'re going to look a lot closer at how much water is being allocated to grow turf, and there are going to be ever-increasing pressures to do more with less.""\nThose in Mesquite are already feeling the heat. Upon learning of the climatic challenges this summer may bring, Sales admits that his heart skipped a beat. ""Right now, we\'re at a point where there\'s very limited water to feed our system,"" he says. ""We\'re doing everything we can as far as having the most state-of-the-art equipment, keeping it in good running shape, having the sensors to detect leaks and shut the systems off immediately so that we don\'t waste water. The problem is we don\'t have the water available to have those systems do what they\'re supposed to do. That\'s scary.""']"	['<urn:uuid:6953e7a8-8e67-405c-9724-a21f39097881>', '<urn:uuid:f05f5e66-ec0d-4b4d-b09f-b9da72e5914e>']	open-ended	with-premise	concise-and-natural	similar-to-document	multi-aspect	expert	2025-05-12T23:47:20.322175	11	122	3195
53	spicy italian noodle dish name meaning	Pasta all'arrabbiata means 'angry macaroni' in translation, referring to the spicy heat in the dish from peperoncino (dried crushed red chiles).	['PASTA ALL’ARRABBIATA…translated it means ANGRY MACARONI. A descriptive term referring to the spicy heat in the dish from the PEPERONCINO, or dried crushed red chiles that are used all over the world including many regions of Italy. The dish is said to have originated in Rome and often it’s catalogued in La Cucina Romana (Roman cuisine) but Southern Italy has so many instances of chile-infused oil , or lard based , or tomato based sauces for pasta that it’s really a tough call. What is generally thought of as the right pasta to serve with Arrabbiata sauce is PENNE, or PENNETTA. Perfect when some of the tomato and chile flecks get caught inside of the penne. I also love it with spaghetti…as illustrated in this ridiculous poor quality grainy Selfie.. Don’t be bullied. Penne is the most popular pasta used for a reason, it’s just a great match. But Spaghetti and any other pasta you like works too. Shh..just don’t say that in Italy. LOL. In the town of Marigliano outside of Naples in Campania the beginning of July is given over to a Sagra, or a Celebration in honor of PENNETTA ALL’ARRABBIATA. Imagine? A feast celebrating a dish of tomatoes, olive oil, garlic, hot peppers and penne? This year’s announcement for the Sagra. Music, Drink and Pennetta All’Arabbiata. I think I like the sound of this. The sauce for Arrabbiata, like SO many of Italy’s pasta sauces is a simple affair. Olive Oil, Chiles, either Fresh or dried, garlic (some use onion), Italian Tomatoes, basil or not..Salt, and Penne. Really. That’s it. From what my amateur research has gathered, recipes calling themselves “true” Roman recipes all use fresh chopped chiles. Southern Italian recipes and Italianamerican recipes use Peperoncino, the same pepper, but dried. While they may be the same vegetable they do have different tastes. One imparts a fragrant fresh taste with it’s heat and the other gives a deep earthy flavor and heat. One day I will try this dish with fresh chiles, for now I use the dried. While it’s a very quick dish to make the best way to get maximum chile flavor and heat is to slowly “fry” it in the Olive Oil rather than add it to the simmering sauce or only when ready to eat. For dinner for 4-5 here’s how I do it.\nTIME: 1 hour or less SERVES: 4-5\n1/2 cup good quality Olive Oil or Extra Virgin, preferably Italian\n1 TBS. PEPERONCINO (crushed dried red hot pepper flakes), plus more for serving\n2 sliced cloves of Garlic, or 1 small onion finely diced\n2 28 oz cans SAN MARZANO DOP TOMATOES (or Italian Plums) crushed with your hands\n1 pound Penne (I use imported ITalian Pasta )\n4 Basil leaves\nIn a large pan or heavy pot heat the olive oil to medium. Add the peperoncino and let this sizzle and pop on medium heat for a good 4 minutes. This releases the oils in the dried peppers and helps to carry all of it’s flavor through the sauce. Add 1/2 tsp of Kosher Salt. Add the garlic and (tricky here) saute’ until you just bring the slices to where they begin to get golden color than add the Tomatoes. Blend well and bring to a boil, then back down to a simmer. Allow the sauce to thicken, this will take some time, maybe 1/2 hour. Then taste for seasoning. If the sauce is thick enough (not watery) add the basil leaves and stir. If it needs more time, keep it on low simmer until you get a thicker sauce. Arrabbiata’s beauty is that it’s not “supposed” to be scorching…unless you want it to be. At this point you can add more peperoncino to taste. I find when feeding the family, less is more. I’ll add more on my dish when I sit down anyway to get it to my heat threshold. While the sauce is cooking , during the last 10 minutes, make a pound of Penne or Spaghettti till just al dente. Drain and add to the sauce and let it cook in the sauce for only 3 minutes. Tear in the Basil leaves…mix, taste for seasoning, then serve.\nDress the pasta with some Grated Pecorino Romano, a drizzle of Olive Oil, and more Peperoncino. GET ANGRY!!! ARRABBIATA!!!!! A grating of Pecorino or Parmigiano if you like! I like.\nHere’s a variation…PASTA ALL’ARRABIATA con SPINACI SALTATI. Saute’ some fresh spinach with garlic and olive oil. Serve on top of the Sauced Pasta. Then mix it all in after you’ve taken a nice pic for Instagram, Snapchat or Facebook…ok Twitter and Pinterest too. Here’s a tip regarding Italian tomato sauces from South to North…only a handful are more complex requiring a sizable list of ingredients. The vast majority are but a handful of ingredients. What makes people NOT angry with this Arrabbiata is that you control your anger..an anger management of sorts LOL. The amount of peperoncino heat is up to you but it needs to be more than just a pinch since it’s not just Sugo di Pomodoro or Marinara, but a wake up call for the taste buds..feel the burn!!! Happy Cooking!!']	['<urn:uuid:bc61f175-915f-4399-b277-2a7e5e4e7385>']	factoid	with-premise	short-search-query	distant-from-document	single-doc	expert	2025-05-12T23:47:20.322175	6	21	865
54	How does the bacterial strain from the 1971 hospital blood specimen differ from other strains in terms of its surface molecules and ability to form bacterial communities?	P. aeruginosa ATCC 27853 lacks genes that encode the B-band O-antigen of LPS and has distinctive SNPs in genes for cellular adhesion proteins like type IV pili and flagella biosynthesis. It showed enhanced biofilm formation capability on solid agar surface compared to Pseudomonas aeruginosa PAO1.	"[""Comparative genome and transcriptome analysis reveals distinctive surface characteristics and unique physiological potentials of Pseudomonas aeruginosa ATCC 27853\nKAUST DepartmentComputational Bioscience Research Center (CBRC)\nMetadataShow full item record\nAbstractPseudomonas aeruginosa ATCC 27853 was isolated from a hospital blood specimen in 1971 and has been widely used as a model strain to survey antibiotics susceptibilities, biofilm development, and metabolic activities of Pseudomonas spp.. Although four draft genomes of P. aeruginosa ATCC 27853 have been sequenced, the complete genome of this strain is still lacking, hindering a comprehensive understanding of its physiology and functional genome.Here we sequenced and assembled the complete genome of P. aeruginosa ATCC 27853 using the Pacific Biosciences SMRT (PacBio) technology and Illumina sequencing platform. We found that accessory genes of ATCC 27853 including prophages and genomic islands (GIs) mainly contribute to the difference between P. aeruginosa ATCC 27853 and other P. aeruginosa strains. Seven prophages were identified within the genome of P. aeruginosa ATCC 27853. Of the predicted 25 GIs, three contain genes that encode monoxoygenases, dioxygenases and hydrolases that could be involved in the metabolism of aromatic compounds. Surveying virulence-related genes revealed that a series of genes that encode the B-band O-antigen of LPS are lacking in ATCC 27853. Distinctive SNPs in genes of cellular adhesion proteins such as type IV pili and flagella biosynthesis were also observed in this strain. Colony morphology analysis confirmed an enhanced biofilm formation capability of ATCC 27853 on solid agar surface compared to Pseudomonas aeruginosa PAO1. We then performed transcriptome analysis of ATCC 27853 and PAO1 using RNA-seq and compared the expression of orthologous genes to understand the functional genome and the genomic details underlying the distinctive colony morphogenesis. These analyses revealed an increased expression of genes involved in cellular adhesion and biofilm maturation such as type IV pili, exopolysaccharide and electron transport chain components in ATCC 27853 compared with PAO1. In addition, distinctive expression profiles of the virulence genes lecA, lasB, quorum sensing regulators LasI/R, and the type I, III and VI secretion systems were observed in the two strains.The complete genome sequence of P. aeruginosa ATCC 27853 reveals the comprehensive genetic background of the strain, and provides genetic basis for several interesting findings about the functions of surface associated proteins, prophages, and genomic islands. Comparative transcriptome analysis of P. aeruginosa ATCC 27853 and PAO1 revealed several classes of differentially expressed genes in the two strains, underlying the genetic and molecular details of several known and yet to be explored morphological and physiological potentials of P. aeruginosa ATCC 27853.\nCitationCao H, Lai Y, Bougouffa S, Xu Z, Yan A (2017) Comparative genome and transcriptome analysis reveals distinctive surface characteristics and unique physiological potentials of Pseudomonas aeruginosa ATCC 27853. BMC Genomics 18. Available: http://dx.doi.org/10.1186/s12864-017-3842-z.\nSponsorsThis work was supported by the Hong Kong University Grants Council General Research Fund (HKU17142316) and Seed Funding for Basic Research Scheme of The University of Hong Kong (201411159065) to Dr. Aixin Yan and the postdoctoral fellowship from The University of Hong Kong to Dr. Huiluo Cao. We thank the Centre for Genomic Sciences at the University of Hong Kong for the sequencing and bioinformatics analysis assistance of the project. We thank Prof. Christopher Rensing (Fujian Agriculture & Forestry University) for proof-reading our manuscript.\nExcept where otherwise noted, this item's license is described as This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver (http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.\n- Genomic analyses of multidrug resistant Pseudomonas aeruginosa PA1 resequenced by single-molecule real-time sequencing.\n- Authors: Li G, Shen M, Le S, Tan Y, Li M, Zhao X, Shen W, Yang Y, Wang J, Zhu H, Li S, Rao X, Hu F, Lu S\n- Issue date: 2016 Dec\n- Genomic analysis and temperature-dependent transcriptome profiles of the rhizosphere originating strain Pseudomonas aeruginosa M18.\n- Authors: Wu DQ, Ye J, Ou HY, Wei X, Huang X, He YW, Xu Y\n- Issue date: 2011 Aug 31\n- Transcriptomic Analyses Elucidate Adaptive Differences of Closely Related Strains of Pseudomonas aeruginosa in Fuel.\n- Authors: Gunasekera TS, Bowen LL, Zhou CE, Howard-Byerly SC, Foley WS, Striebich RC, Dugan LC, Ruiz ON\n- Issue date: 2017 May 15\n- Within-Host Evolution of the Dutch High-Prevalent Pseudomonas aeruginosa Clone ST406 during Chronic Colonization of a Patient with Cystic Fibrosis.\n- Authors: van Mansfeld R, de Been M, Paganelli F, Yang L, Bonten M, Willems R\n- Issue date: 2016\n- Newly introduced genomic prophage islands are critical determinants of in vivo competitiveness in the Liverpool Epidemic Strain of Pseudomonas aeruginosa.\n- Authors: Winstanley C, Langille MG, Fothergill JL, Kukavica-Ibrulj I, Paradis-Bleau C, Sanschagrin F, Thomson NR, Winsor GL, Quail MA, Lennard N, Bignell A, Clarke L, Seeger K, Saunders D, Harris D, Parkhill J, Hancock RE, Brinkman FS, Levesque RC\n- Issue date: 2009 Jan""]"	['<urn:uuid:eb318abe-f580-46d5-a0e3-8db5f04b04bc>']	factoid	direct	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-12T23:47:20.322175	27	45	850
55	As someone looking to understand basic electrical concepts, what's the key difference between the piezoelectric effect used in laboratory studies versus practical applications like shoe-mounted generators?	In laboratory studies, scientists examine the piezoelectric effect using pure crystals under high pressure conditions to achieve maximum electrical response. In practical applications like shoe-mounted generators, simpler ceramic piezoelectric elements are used with voltage multiplier circuits to convert mechanical pressure from walking into usable DC electricity.	"['Feb. 4, 2008 A discovery by scientists at the Carnegie Institution has opened the door to a new generation of piezoelectric materials that can convert mechanical strain into electricity and vice versa, potentially cutting costs and boosting performance in myriad applications ranging from medical diagnostics to green energy technologies.\nHigh-performance piezoelectric materials used today, such as those in probes for medical ultrasound, are specially grown crystals of mixed composition known as ""solid solutions,"" making them difficult to study and expensive to manufacture. But in the January 31 Nature a research team* led by Ronald Cohen and Russell Hemley of the Carnegie Institution\'s Geophysical Laboratory report that at high pressure pure crystals of lead titanate show the same transitions seen in more complex materials. Moreover, theory predicts that lead titanate under pressure has the largest piezoelectric response of any material known. This suggests the exciting possibility of low-cost but extremely high-performance piezoelectrics.\n""The most useful piezoelectric materials have a critical range of compositions called the morphotopic phase boundary, where the crystal structure changes and the piezoelectric properties are maximal,"" says Muhtar Ahart, a co-author of the study. ""These are usually complex, engineered, solid solutions. But we showed that a pure compound can display a morphotopic phase boundary under pressure.""\nFor the study, the researchers placed powdered crystals of lead titanate in a device called a diamond anvil cell, which can generate pressures exceeding those at the center of the Earth. They monitored the changes in crystal structure with pressure using high-energy X-ray beams of the Advanced Photon Source at Argonne National Laboratory in Illinois. Using this data and calculations based on first-principle theoretical computations, the researchers were able to determine the piezoelectric properties of the pure crystals at different pressures.\n""It turns out that complex microstructures or compositions are not necessary to obtain strong piezoelectricity,"" says Ahart.\nThe use of piezoelectrics has boomed in recent years and is rapidly expanding. Their ability to convert mechanical energy to electric energy and vice versa has made them invaluable for acoustic transducers for sonar and medical ultrasound, and for tiny, high-precision pumps and motors for medical and other applications. High-performance piezoelectrics have also opened up new possibilities for ""energy harvesting,"" using ambient motion and vibration to generate electricity where batteries or other power sources are impractical or unavailable.\n""This is a field in which theory, experiment, and material development work side-by-side,"" says Ronald Cohen, a staff scientist at the Carnegie Institution and a co-author of the study. ""Delineating the underlying physics of piezoelectric materials will make it easier to develop new materials and improve existing ones. We\'re now poised on the edge of hugely expanded applications of these technologies.""\nThis work was sponsored by the Office of Naval Research. Support was also received from the Carnegie/Department of Energy Alliance Center (CDAC). High-pressure X-ray diffraction at the HPCAT facility of Advanced Photon Source was supported by DOE-BES, DOE-NNSA (CDAC), and the W. M. Keck Foundation. Use of the Advanced Photon Source was supported by the US Department of Energy, Office of Science, Office of Basic Energy Sciences.\nAuthors: Muhtar Ahart, Maddury Somayazulu, R. E. Cohen, P. Ganesh, Przemyslaw Dera, Ho-kwang Mao, Russell J. Hemley, Yang Ren, Peter Liermann, and Zhigang Wu.\nOther social bookmarking and sharing tools:\nNote: Materials may be edited for content and length. For further information, please contact the source cited above.\nNote: If no author is given, the source is cited instead.', ""Hello Instructables !\nIn this Instructables we will generate electricity from piezoelectric element by using the phenomenon\nof PIEZOELECTRIC EFFECT\nPiezoelectric Effect is the ability of certain materials to generate an electric charge in response to applied mechanical stress .The piezoelectric crystals exhibit the piezoelectric effect. This piezoelectric effect having two properties. First one is the direct piezoelectric effect which means that material has ability to convert mechanical strain into electrical charge. Second one is the converse effect, in which the applied electrical potential converted into mechanical strain energy. In this project we are using direct piezoelectric effect to generate electricity\nStep 1: Concept\nPIEZO ELECRIC TRANSDUCER\nA piezoelectric plate is a device that uses the piezoelectric effect to measure pressure, acceleration, strain or force by converting them to an electrical charge. Piezoelectricity is the electricity generated by piezo element by effect called the piezoelectric effect.It is the ability of certain materials to generate an AC (alternating current) voltage when subjected to mechanical stress or vibration, or to vibrate when subjected to an AC voltage, or both. The most common piezoelectric material is quartz. Certain ceramics, Rochelle salts, and various other solids also exhibit this effect. When a sound wave strikes one or both sides of the plates, the plates vibrate. The crystal picks up this vibration, which it translates into a weak AC voltage. Therefore, an AC voltage arises between the two metal plates, with a waveform similar to that of the sound waves. Conversely, if an AC signal is applied to the plates, it causes the crystal to vibrate in sync with the signal voltage. As a result, the metal plates also vibrates and produce an acoustic disturbance.\nIn our project we used Villard Cased to convert AC supply to DC and amplify the voltage.We chose Villard cascade because it rectify and amplify the input from the source simultaneously by using diodes and capacitor.\nA voltage multiplier is an electrical circuit that converts AC electrical power from a lower voltage to a higher DC voltage, typically using a network of capacitors and diodes.Voltage multipliers can be used to generate a few volts for electronic appliances, to millions of volts for purposes such as high-energy physics experiments and lightning safety testing. The most common type of voltage multiplier is the half-wave series multiplier, also called the Villard cascade.\nStep 2: Components Required\n- Piezoelectric elements\n- Hookup wire\n- PVC sheet\n- Foam Push ups\n- Soldering Iron\n- Drem tool\nStep 3: Construction\n1.Mark the feet size on PVC sheet and cut it accordingly\n2.Place piezo elements on the pvc sheet and mark it to make holes\n3.Make holes into the PVC according to the marking\n4.Stick the piezo elements in the sandwiching manner with hot glue\nAVOID CONTACT OF PIEZO ELEMENTS EACH OTHER\nIn the project we used piezoelectric transducer of ceramic type. Piezo transducer generate AC voltage when we apply pressure on piezoelectric transducer. As AC voltage cannot sum up each other, we have to convert AC voltage to DC voltage. We are converting AC to DC because AC voltage cannot sum up but DC voltage can sum up in series. But in process of converting AC to DC we may loose some energy. If we use full wave reflection bridge to convert AC to DC. We get approx. 80% of energy generated by transducer. (Here we are getting nearly 20% of energy loss). If we connect each piezoelectric transducer with each full wave rectifier bridge and connect them in series we may loose large amount of energy than released from transducer, then we may not get appreciable output.\nBy a long research on this concept, we found a solution, that is Villard cascade which is also called as voltage multiplier.\nHere by applying pressure on the piezoelectric transducer, it generates the AC output. That AC output is connected to Villard cascade (voltage multiplier). By connecting the voltage multiplier the output will in DC with some voltage boosting. By using voltage multiplier we reduced rectifier bridge and voltage booster.\nIn the project I connected each piezoelectric transducer with each voltage multiplier. For this project I used 6 piezoelectric transducer .So,we got 6 DC outputs. To increase the output I connected the DC outputs in series. By connecting in series, I sums up the 6 DC outputs of voltage multiplier as circuit given in the pictures.\nI fixed 6 piezoelectric transducers to a flexible plastic material in a sandwiching manner ,so that piezoelectric elements are bend easily. Soldered all piezoelectric elements individually to connect to voltage multiplier.I fixed some foam material to make force to concentrate at the center of the piezo transducer and not to damage the piezoelectric element.\nIt can be place in shoes.\nYES! IT'S DONE!\nFollow up to get more interesting Instructables.\nStep 7: Testing\nDON'T FORGET TO SUBSCRIBE""]"	['<urn:uuid:cd15d4f2-9356-42cf-89e3-33637904289a>', '<urn:uuid:13ee009b-f60a-4e79-a6ae-110dd9a544ef>']	factoid	with-premise	verbose-and-natural	similar-to-document	comparison	novice	2025-05-12T23:47:20.322175	26	46	1377
56	What is the prevalence of overactive bladder in Western populations?	Overactive bladder affects about 17 percent of the Western population, and it is believed to be under-reported. This translates to well over 50 million people in the United States. The condition becomes more prevalent with age and can sometimes force elderly individuals into nursing homes.	"[""Channeling research success\nBy Steven Powell, firstname.lastname@example.org, 803-777-1923\nAaron Provence’s doctoral research in the South Carolina College of Pharmacy might be focused on a very specific disorder, overactive bladder, but he hopes that the insight he’s gaining as a research scientist might have even wider medical impact.\nDon’t take that the wrong way. The malady he's studying right now might not be life-threatening, but it's a serious problem, and he knows it.\n“The statistics say that it affects about 17 percent of the Western population,” Provence says. “And they say it’s under-reported as well.” That works out to well over 50 million people in the United States dealing with overactive bladder, a condition that can make life very difficult every day. It becomes more prevalent with age and is sometimes the reason an elderly individual is forced to move into a nursing home.\nIn the search for a drug that might alleviate overactive bladder, Provence is studying a medication, retigabine, that is approved in the U.S. for a different use altogether: as an anticonvulsive. One of its side effects is to cause retention of urine, so Provence, working in SCCP professor Georgi Petkov’s lab, has been researching its effects on a very fundamental cog in the bio-machinery of a bladder: the ion channel.\nAn ion channel is a collection of several proteins that fit together to form what is essentially a tiny tube that floats in a cell’s membrane, the barrier between the cell’s contents and the rest of the world. One end of the tube is inside the cell and the other faces outward.\nDepending on what's going on nearby, the protein building blocks that make up the ion channel can be made to snap into different conformations, and they do so in such a way that either opens or closes the tube. When it’s open, ions, such as as potassium, sodium or calcium, rapidly flow through it. When it’s closed, nothing flows.\nIn humans, cells build a wide range of ion channels — dozens of subtypes — that are tailored to very specific cellular needs. A cell can use ion channels to regulate what goes in and out of the cell and also to send signals to other cells.\nPetkov and Provence have shown that a particular subtype of ion channel, Kv7, is an important part of bladder function and activity. The drug retigabine makes the Kv7 ion channel more susceptible to opening, and Provence is determining how many and in what pattern the cells in bladder tissue produce the Kv7 ion channels that go into their membranes.\n“We want to know how the expression pattern is different from other tissue systems,” Provence says. “That way we can gear the drug discovery efforts to make a more specific therapeutic drug, so that you can target the bladder with minimum collateral effects elsewhere.”\nThe National Institutes of Health like what they’ve seen of his work so far. He earned a three-year F31 NIH fellowship that started last year, and he credits the process of applying for a SPARC grant from the Office of the Vice President for Research as integral to that success.\n“The first time I applied for the SPARC fellowship I got rejected,” Provence says. “That was actually a good experience because it gave me an opportunity to get feedback from reviewers at the university and work on improving my strategy and the proposal. That laid a solid foundation for my application to the NIH the following year.”\nAfter he finishes at Carolina, Provence is planning a postdoctoral experience where he can continue his research of ion channels, but likely with a different focus. Putting ion channels at the center of his studies has given him a broad array of opportunities in pharmaceutical research.\n“Studying ion channels as drug targets transcends the urinary bladder,” Provence says. “The science can be applied to other conditions, like seizures, hypertension, cerebral vasospasm. It’s a good foundation for where I want to go.”\nShare this Story! Let friends in your social network know what you are reading about""]"	['<urn:uuid:577a428e-f904-4256-8aa1-c22592b18ab0>']	open-ended	direct	concise-and-natural	similar-to-document	single-doc	expert	2025-05-12T23:47:20.322175	10	45	677
57	What is the total solar power generation capacity of the combined solar systems installed in Colville Lake for their power plant?	The finished generating system has a total of 132.5 kW AC solar generation capacity, consisting of an 82.5 kW AC solar system added alongside an existing phase-1 50kW solar system which had been installed in 2014.	['Colville Lake is a small, remote community in the Northwest Territories (NWT) of Canada, north of the Arctic Circle – not the first place one might think of for solar power. As Klaus Dohring writes, the climate in Colville Lake is typical of the far north with challenging winters, but sun-rich summers. This article originally appeared in The Circle 03.15.\nThe only overland connection to Colville Lake – a community of about 160, mostly Dene First Nation residents – is the seasonal winter ice road, open about six weeks each year. We travelled to Colville Lake in June 2015 to install what we believe is the most advanced renewable energy project in the north to date. At that time of year, it doesn’t get dark at all. The sun intensity all summer is remarkable, and the sun hours are plentiful.\nElectrical power in Colville Lake has been provided by diesel generators in a stand-alone micro-grid. It is one of the most expensive diesel generation communities in the Northwest Territories which is why it was chosen for a new power plant concept combining solar power with large scale battery storage and new diesel generators. The goal is to supply the community exclusively with solar power and eliminate diesel generation during the summer. Surplus solar energy will be directed into the batteries, with the battery bank alternating between generation and consumption day and night.\nIn winter, when the sun rarely shines, the community will continue to be supplied with diesel-powered generators although the operators are hoping to reduce generation time with the new power plant by up to 50 per cent. Shutting down diesel generation for extended periods benefits the community through noise reduction and emissions elimination, cost avoidance, autonomy from total dependence on diesel and greatly improved quality of life. Maintenance requirements are being reduced, and the diesel generator lifespan will be extended, thus reducing operating and replacement costs. In shoulder months solar power can still reduce the need for diesel generation.\nTo achieve this, we added an 82.5 kW AC solar system, alongside an existing phase-1 50kW solar system which had been installed in 2014. The finished generating system will have a total of 132.5 kW AC solar generation capacity, and over 200 kWhs of battery storage capacity. Monitoring systems allow for remote internet-based monitoring and recording of solar generation data. Our solar system is ground-mounted, using local ballast to avoid disturbing the permafrost because it “floats” on the ground above the permafrost.\nMaterials were prepared, premachined and pre-assembled in Ontario over the winter, packaged and crated up in custom-made crates for protection during transportation. The winter ice roads are rough and very challenging so sturdy crating is important to avoid transport damage. We safely delivered over 15 tons of solar materials into Colville Lake via winter ice road in February/ March 2015, without any transport damage.\nOn June 1st we were greeted by a still-frozen lake, snow , frost, and a few very sunny days which brought out a bountiful crop of mosquitoes. Due to the preparation work in our shop over the winter, the on-site work was mainly assembly of pre-machined parts, allowing us to install this project in less than 10 working days. This project was the largest solar installation in NWT in 2015, and to the best of our knowledge the Colville Lake solar system is the largest solar system anywhere north of the Arctic Circle. It is interesting to note that the International Space Station is also powered by an 82 kW solar system, in continuous operation for roughly 12 years.\nOur solar system is fixed-angle and maintenance free. Whenever sunshine reaches a module the photovoltaic effect kicks in, and free electrons are generated to provide free and clean electricity to the micro-grid. There are no moving parts and – other than the slow and limited solar cell degradation – no wear and tear. The solar cells are warranted to generate at least 80 per cent of rated output after 25 years. Solar generation is directly linked with sunshine availability. It will still occur with scattered and diffuse light and low light conditions, but to a lesser degree.\nSolar cells become more efficient at lower ambient temperatures, so the low air temperatures in the North actually benefit solar generation. Dry air has less water vapour, and allows for more sun energy to penetrate the atmosphere to reach the solar cells. With about 1/3 of the inbound solar energy being absorbed in the atmosphere before reaching the ground, the dryer air in the North allows for noticeably more sun energy to reach the surface. Data for northern communities shows excellent solar energy availability in the summer months. We are monitoring solar systems in NWT, and can compare the data to similar size solar systems in southern Canada. While the solar harvest in NWT in winter is very low to zero, the best solar months in NWT greatly outperform the best solar months in the south. The seasonality in the North is more pronounced, which is what the weather data has been telling us all along. We hope the power plant concept of a combination solar generation/battery bank will be embraced by many other remote communities to reduce and eliminate diesel generation as much as possible. The perfectly quiet and clean, emission- and noise-free operation of a solar system with or without battery storage, offers such an improvement in quality of life for the community, and affords them independence and autonomy, to the degree that sunshine is available and clean energy can be stored. The winter diesel supply truck or barge may not make it, but the sun will always rise with the seasons to provide free and clean energy.\nKLAUS DOHRING is president of Green Sun Rising, a Canadian company that develops and supplies solar systems to generate clean electricity and heat.']	['<urn:uuid:d49b29dd-3820-4b99-9016-973eace7546b>']	factoid	direct	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-12T23:47:20.322175	21	36	976
58	veena ancient history musical features and its relationship with raga tala system	The veena is India's most ancient stringed instrument, mentioned in Vedic literature. It was originally used in vedic rites where priests chanted while the wife played the veena. In terms of musical features, the veena can produce all gamakas (graces) of Indian music and is particularly renowned for Tanam playing. Its relationship with the raga-tala system is based on the fundamentals of Indian classical music, which dates back over 3,000 years. The raga aspect is expressed through melody patterns, while the tala provides rhythmic structure. During performances, these elements combine in two sections: the alap (unaccompanied melodic exploration) and the gat (rhythmic section with fixed beat cycles).	"['The veena is the most ancient stringed instrument of India. It is one of the three principal musical instruments mentioned in the Vedic literature, the other two being the venu (flute) and Mridangam. Veena is considered to be a divine instrument and in Hindu mythology, Gods and Goddesses are often depicted as playing on the veena and enjoying its sweet melodies. The great acharya, Sankara Bhagavadpada describes Devi Meenakshi as Veena venu mridanga vadyarasikam in Meenakshi Pancharatnam. The descriptions of the Divine Mother by the eminent poet Kalidasa are often as playing veena (Manikya veenamupalalayantim in Syamala Dandakam, Veena sankrantahastam in Navaratna malika stotram etc).\nVeena is known from time immemorial, although the descriptions in the vedic literature tend to suggest veena of a different design than the present day ones. Also, vedic literature describes several different forms of veena. A careful examination of the description of vedic rites drives us to the conclusion that the origin of Indian music lay in certain rites where the priest and the performer chant some gathas alternately while the wife (Yajamani) plays on the veena. Mention of veena can often be found in various brahmanas and sutras. For example, Aitreya Brahmana describes two different types of veena, the daivi and manushi veenas. Similarly, Naradi Siksha mentions about the daravi and gatra veenas. It is interesting to note that veenas with various numbers of strings, starting with the ekatantri (single string) veena to one with one hundred strings are mentioned in vedic texts.\nThe great epics, Ramayana and Mahabharata also speak of veena. In Ramayana we find mention of the Vipanchi veena with nine strings. Veena is referred to as laya and tantri in some places of the epic. Valmiki after composing the Ramayana declares “this historical poem, which is pleasant to sing and adapted to the three measurements of time, is contained within the seven notes and can be sung to the veena”. In fact, the princess Lava and Kusa are said to have used the Ekatantri veena in the Ramayana Gana in Lord Rama’s court.\nThe sanskrit treatises on music describe veena in great detail. Bharata in his Natyasastra talks of the chitra veena as having seven strings and vipanchi veena as having nine strings (saptatrantri bhavechchitra vipanchi navatantrika). Bharata also makes mention of the veenas, kachchapi, ghosaka etc. Narada in Sangita Makaranda mentions a variety of veenas like kachchapi, kubjika, chitra, parivadini, jaya, ghosavati, jyeshta, nakuli, mahati, vaishnavi, brahmi, raudri, ravani, sarasvati, kinnari, saurandri, ghosaka etc. Sarangadeva mentions two main types of veena, the sruti and swara. He also describes elaborately the construction and playing of different kinds of veena. Pandit Ramamatya in the third chapter of his treatise, Swaramelakalanidhi, describes the construction of veenas and divides veenas into three main heads, the sudhdha mela veena, madhya mela veena and achyuta rajendra mela veena.\nThe word veena nowadays has come to mean the Sarasvati veena, the most important instrument of the Carnatic music sphere. Veena produces all the gamakas or graces of Indian Music. Both the Lakshya and Lakshana forms of music are possible in veena playing. The epitome of veena playing is the Tanam, and veena has few equals in this particular forte. Listening to tanam playing on veena is a unique experience. Further, the presence of frets enables the production of music of highest purity, even in high-speed brigas, which can be achieved by sincere and dedicated practice.\nFor centuries over, veena is considered as a divine instrument and playing veena is considered to be a yoga. Yagjavalkya Maharishi observed that:\nVeena vadana tatvagjah Srutijaati Visarathah |\nTalagjascha$prayatnena mokshamargam sa gachchati ||\n(In short, it means, salvation or liberation can be attained effortlessly by playing veena).\nMaharishi has chosen the word “aprayatnena” (effortlessly) since the usual yogas prescribed by the Vedas for liberation require a lot of mental and physical efforts. Sarangadeva has beautifully elaborated the divinity of Veena as:\nDarsana sparsane chasya bhoga svargapavargade |\nPunito viprahatyadi patakaih patitam janam ||\nDanda sambhuruma tantri kakubhah kamalapatih |\nIndra patrika brahma tumbam nabhih sarasvati ||\nDorako vasukirjiva sudhamsuh sarika ravih |\nSarvadevamayi tasmad veeneyam sarvamangala ||\n(That is, by seeing and touching the veena, one attains the sacred religion and liberation. It purifies the sinner, who is been guilty of killing a Brahmin. The danda, made of wood or Bamboo, is Siva, the string is Devi Uma, the shoulder is Vishnu, the bridge is Lakshmi, the gourd is Brahma, the navel is Sarasvati, the connecting wires are vasuki, the jiva is the moon and the pegs are the sun. The veena thus represents nearly all the Gods and Goddesses, and is, therefore, capable of bestowing all kinds of divine blessings, benediction, and auspiciousness).\nThe music world has always kept the highest regard for the veena music. Sri Muthuswami Dikshitar was a veena player par excellence; hence the sangatis and phrases in his songs are coloured with gamakas characteristic of Indian music. He proudly stamps his signature as “Vainika Gayaka Guruguha” in the Bhairavi song Balagopala. He addresses Raja Matangi, a form of Divine Mother depicted as playing veena, as Veena gana dasagamakakriye in his immortal song Meenakshi me mudam. Saint Tyagaraja observes in the song Mokshamu Galata that people know not the secret of Lord Siva deriving immeasurable pleasure from the music of veena. It may further be noted that the first part of the charanam of this song describes implicitly the vocal music and the second part talks of veena music. It perhaps testifies the intimate association of veena music with vocal music. At this juncture, it may well be noted that the renowned musicologist, Prof. Sambamoorthy suggested that singing along with veena improves the quality of the voice.\nIn conclusion, veena playing is an yoga by itself, which can bestow happiness both in mundane as well as supramundane lives. Rishis of the yore to musicians of the day have engrossed themselves in the divine music of veena and have looked upon the veena practice as means to an end.', 'The classical tradition in Indian music dates back over 3,000 years to the Vedas, the earliest Hindu spiritual texts. The Sama Veda speaks of ""Nada Bramha,"" the concept that ""music is the language of God."" Based on the fundamentals of Raga (melody) and Tala (rhythm) the music has developed continuously through ancient and medieval times into a system capable of expressing the finest shades and degrees of color and emotion. Indian classical music utilizes the same 12 note scale as is used in the West, except that the notes are used in just (pure) intonation rather than the equal temperament developed in Europe. The existence of ""microtones"" between the standard notes is also recognized.\nA raga is formed from a series of ascending and descending notes selected from a given music scale. Within this skeleton, the musician brings out the melody that gives a particular raga its character and mood: joy, sadness, romance, or a combination of these and other basic emotions.\nIn a classical performance, the raga is presented in two sections. In the first part, called alap , the musician plays unaccompanied and presents the notes contained within the raga, proceeding until all the notes and their interrelationship are explored. This allows the character of the notes and the raga to be shown in a framework free of a fixed rhythmic structure.\nThe second section, gat, is marked by the entrance of the accompanying table player. From this point the raga is presented within a rhythmic cycle, having a specified number of beats, called the tala. The most common cycles contain 16, 10, 7, or 6 beats, subdivided into blocks of 2,3, or 4 beats. The music takes the form of theme and variation with the tabla maintaining a fixed pattern while the instrumentalist solos, and improvising in turn when the instrumentalist returns to the initial theme. The interplay or musical exchange between the instrumentalist and the accompanying tabla player revolves around showing the sam, the downbeat of the cycle. The speed and energy of the exchange increases throughout the composition building to a climax at the end of the piece.\nThe sarod evolved into a classical instrument about 150 years ago, an expression of the combination of the classical, court-based tradition of the Moghul Empire with instruments derived from the folk-based traditions of Central Asia. The body of the sarod is carved from a single piece of teak covered with a skin head. The steel fingerboard is fretless, permitting the use of the slides, ornaments, and microtones characteristic of Indian music. The brass bell at the end of the instrument acts as a resonator. The sarod has 25 strings, 18 of which are sympathetic. Four main playing strings produce the same note range as a viola. Three rhythm strings are tuned to the tonic note.\nThe tabla is the classical drum of North India, used to accompany classical vocal or instrumental music since its development in the 18th century. It consists of two small hand drums, the right hand drum is made of rosewood, the larger left hand drum of copper or brass. Both are covered with heads made of multiple layers of goatskin. The black circle of paste and iron filings in the center permits the drum to be tuned precisely to a particular note. The drums, played separately and together, are capable of a wide variety of specific sounds or syllables which are combined into characteristic patterns and compositions.\nThe tanpura, usually played in the background during a classical concert, provides the tonic drone essential to classical Indian music.']"	['<urn:uuid:300b879a-2393-42e2-96a3-3fdfdb747f5d>', '<urn:uuid:0961e6b6-dc62-4234-8edc-a877ce05c14c>']	factoid	with-premise	long-search-query	similar-to-document	multi-aspect	expert	2025-05-12T23:47:20.322175	12	107	1596
59	I'm curious about how soldiers support each other during battles. Could you share any touching moments where troops showed care for their wounded commanders during combat?	During the Battle of Coruña, there was a moving display of soldiers' care for their wounded commander, Sir John Moore. After he was severely wounded, soldiers carried him in a blanket, and when offered the alternative of a spring wagon, they suggested that the blanket would be better as they could keep in step and carry him more gently. These Highland soldiers carried their commander to his quarters in Coruña, weeping as they went, showing their deep emotional attachment to their leader. They were careful to accommodate his wishes, frequently turning so he could observe the battlefield and listen to the combat sounds as they retreated.	['Henry Craik, ed. English Prose. 1916. Vol. V. Nineteenth Century\nThe Battle of Coruña\nBy Robert Southey (17741843)\nFrom The History of the Peninsular War\nTHE PREPARATIONS for embarking were completed on the morning of the 16th, and the General gave notice that he intended, if the French did not move, to begin embarking the reserve at four in the afternoon. This was about mid-day. He mounted his horse, and set off to visit the outposts: before he had proceeded far, a messenger came to tell him that the enemys line were getting under arms; and a deserter, arriving at the same moment, confirmed the intelligence. He spurred forward. Their light troops were pouring rapidly down the hill on the right wing of the British, and the advanced picquet were already beginning to fire. Lord William Bentincks brigade, consisting of the 4th, 42nd, and 50th regiments, maintained this post. It was a bad position, and yet, if the troops gave way on that point, the ruin of the army was inevitable. The Guards were in their rear. General Paget was ordered to advance with the reserve, and support Lord William. The enemy opened a cannonade with eleven heavy guns, advantageously placed on the hills. Two strong columns, one advancing from a wood, the other skirting its edge, directed their march towards the right wing. A third column approached the centre: a fourth advanced slowly upon the left, a fifth remained half way down the hill, in the same direction. Both in number and weight of guns they had a decided superiority; and they fired with such effect from the commanding situation which they had chosen, that the balls in their bounding reached the British reserve, and occasioned some loss there.\nSir David Baird had his arm shattered with a grape-shot as he was leading on his division. The two lines of infantry advanced against each other: they were separated by stone walls and hedges which intersected the ground; but as they closed, it was perceived that the French line extended beyond the right flank of the British and a body of the enemy was observed moving up the valley to turn it. Marshal Soults intention was to force the right of the British, and thus to interpose between Coruña and the army, and cut it off from the place of embarkation. Failing in this attempt, he was now endeavouring to outflank it. Half of the 4th regiment was therefore ordered to fall back, forming an obtuse angle with the other half. This manuvre was excellently performed, and they commenced a heavy flanking fire. Sir John Moore called out to them that this was exactly what he wanted to be done, and rode on to the 50th, commanded by Majors Napier and Stanhope. They got over an enclosure in their front, charged the enemy most gallantly, and drove them out of the village of Elvina; but Major Napier, advancing too far in the pursuit, received several wounds, and was made prisoner, and Major Stanhope was killed.\nThe General now proceeded to the 42nd. Highlanders, said he, remember Egypt! They rushed on, and drove the French before them, till they were stopped by a wall: Sir John accompanied them in this charge. He now sent Captain Hardinge to order up a battalion of Guards to the left flank of the 42nd. The officer commanding the light infantry conceived, at this, that they were to be relieved by the Guards, because their ammunition was nearly expended, and he began to fall back. The General, discovering the mistake, said to them, My brave 42nd, join your comrades: ammunition is coming, and you have your bayonets! Upon this, they instantly moved forward. Captain Hardinge returned, and pointed out to the General where the Guards were advancing. The enemy kept up a hot fire, and their artillery played incessantly on the spot where they were standing. A cannon-shot struck Sir John, and carried away his left shoulder and part of the collar-bone, leaving the arm hanging by the flesh. He fell from his horse on his back, his countenance did not change, neither did he betray the least sensation of pain. Captain Hardinge, who dismounted, and took him by the hand, observed him anxiously watching the 42nd, which was warmly engaged, and told him they were advancing; and upon that intelligence his countenance brightened. Colonel Graham, who now came up to assist him, seeing the composure of his features, began to hope that he was not wounded, till he saw the dreadful laceration. From the size of the wound, it was in vain to make any attempt at stopping the blood; and Sir John consented to be removed in a blanket to the rear. In raising him up, his sword, hanging on the wounded side, touched his arm, and became entangled between his legs. Captain Hardinge, observing his composure, began to hope that the wound might not be mortal, and said to him, he trusted he might be spared to the army, and recover. Moore turned his head, and looking steadfastly at the wound for a few seconds, replied, No, Hardinge, I feel that to be impossible.\nAs the soldiers were carrying him slowly along, he made them frequently turn round, that he might see the field of battle, and listen to the firing; and he was well pleased when the sound grew fainter. A spring waggon came up, bearing Colonel Wynch, who was wounded: the Colonel asked who was in the blanket, and being told it was Sir John Moore, wished him to be placed on the waggon. Sir John asked one of the Highlanders whether he thought the waggon or the blanket was best? and the man said the blanket would not shake him so much, as he and the other soldiers would keep the step, and carry him easy. So they proceeded with him to his quarters at Coruña, weeping as they went.']	['<urn:uuid:109fcf24-176a-49f2-a646-2b2e269f6229>']	open-ended	with-premise	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-12T23:47:20.322175	26	106	990
60	how top down proteomics identify proteins sequence	In top-down proteomics, the protein sample is first fractionated before being introduced into the mass spectrometer. One or more charge states of a single intact protein are isolated in the gas phase. To identify the protein, fragmentation of the intact protein is performed on the isolated ion using tandem MS (through methods like electron capture dissociation or infrared multiphoton dissociation) to determine the amino acid sequence.	['Mass spectrometry is a powerful tool with much promise in global proteomic studies. abundance pairs directly. For both FT- and TOF-based mass analyzers, a mass-calibration transformation is usually applied in order to ultimately obtain a set of and abundance pairs. The purpose of this article is usually to provide an overview of mass-spectrometry data, in particular how and abundance values are generated, and to spotlight areas that deserve attention from the statistical community after the and abundance pairs are generated. Although recent research has focused on improving mass-spectrometry technologies, insufficient attention has been given to proper statistical methods for optimally preprocessing and analyzing the acquired data. Thus, herein we aim to (1) provide an introduction to the resulting data and the multiple analytical actions that are required to obtain abundance and pairs for each detectable molecule and (2) discuss places where statistical methods can play an important role in improving the quality of inferences derived from the data. We begin in Section 2 with a description of bottomCup versus topCdown proteomics and explain why the proteomics community makes samples more complicated by digestion of a protein to multiple peptides, that is, smaller chains of amino acids. In Section 3, we discuss data acquisition and the analytical preprocessing that is required to obtain buy Valrubicin and abundance pairs from the data obtained from a mass analyzer. We have chosen to provide examples from the FT-based technology with which we are the most familiar; however, the general analytical preprocessing actions described herein apply to other mass analyzers. For a more thorough discussion of TOF-based technology, see the 2003 special edition on proteomics in domain name, the next step is data reduction via peak detection, which is discussed buy Valrubicin in Section 4. Section 5 introduces alignment, and Section 6 provides a discussion on how peptides and proteins are identified. Section 7 discusses important statistical considerations for experimental design buy Valrubicin and analysis. 2.?BOTTOMCUP VERSUS TOPCDOWN PROTEOMICS Proteomics in the broad sense implies the identification and quantification of proteins and peptides present in a tissue or cell at a single point in time or under a set of conditions. Top down (protein level) and bottom up (peptide level) are 2 techniques that have been broadly utilized for this task (Physique 1). In a topCdown approach, accurate mass and high-resolution mass spectrometers are required. When using a topCdown approach, the protein sample is fractionated prior to introduction into the mass spectrometer and one or more of the charge says of a single intact protein are isolated in the gas phase (Kelleher, 2004). In order to identify the corresponding protein, fragmentation of the intact protein is subsequently performed around CD244 the isolated ion by tandem MS (e.g. using electron capture dissociation or infrared multiphoton dissociation) in order to determine the amino acid sequence. Although some exceptions exist, this methodology only works well on abundant proteins and on proteins with molecular weights less than 30 kDa (Han focused solely on TOF data. Herein, we primarily focus on FT-ICR and FT-orbitrap technology, which has the advantage of extremely high resolving power, mass-measurement accuracy, precision, and wide dynamic range. buy Valrubicin 3.1. Obtaining frequency and abundance pairs An FT-ICR steps the rotational frequency of ions as they orbit in the magnetic field of a superconducting magnet. Ions are introduced into an ICR cell and are subsequently excited. Ions of comparable orbit together as a packet and induce an electrical current that is detected by.']	['<urn:uuid:717a890d-ff43-4cb6-ae3f-ca17d86907e3>']	open-ended	direct	short-search-query	similar-to-document	single-doc	expert	2025-05-12T23:47:20.322175	7	66	576
61	How long did the first solo trek across Antarctica take?	Colin O'Brady became the first person to traverse Antarctica without assistance, completing the 930-mile journey in 54 days.	['When tourists think of travelling, one place that doesn’t make their list that often is Antarctica. The seventh continent is the most forgotten one, and rightfully so, because temperatures can dip to extreme lows, ice and snow cover every place, and there is no human life other than scientists and tourists, so you have to bring everything with you. But that doesn’t mean that Antarctica doesn’t have some amazing views and beautiful things to look at and let’s not forget the penguins on the massive ice shelf, which are cute birds that people only get to see in zoos.\nAntarctica is the last frontier for most travellers and there are plenty of opportunities to travel there on one of the cruises and tours that exist. As this list will show, people go there for fun, for sport and for science, but everyone who goes will agree that Antarctica, while barren, is very beautiful. Sure, it can be dark at times, as the South Pole doesn’t get much sunlight during the winter months, but that only makes it the best place on Earth to look at the stars. And when it’s summer and a little warmer, chances are you can travel around the ice shelf and see some amazing sights. So take a look at these stunning photos from Antarctica and perhaps consider your next trip way down south.\nThis photo is a cool sunset photo over Halley Research Station, which is located on the Brunt Ice Shelf in Antarctica. The station is controlled by the British Antarctic Survey and was established in 1956. According to the British Antarctic Survey, this station led the discovery of the ozone hole in 1985. As this photo shows, one of the main modes of transportation is by dog sled, as it is located on an ice shelf, which in 2017 and 2018, left the base unmanned over worry about cracks in the ice shelf.\nThis man stands beside a massive iceberg in Antarctica, which gives you a good impression of just how big the icebergs can be. But the real question is, how can this man stand beside an iceberg, which is generally in the water. That’s because, according to Cool Antarctica, these icebergs float around the Southern Ocean and are carried into the sea-ice of Antarctica, and when the temperature drops, they are basically frozen in place until the spring when the ice finally breaks up.\nThis photo shows the Aurora Australis over the Halley 6 Base in Antarctica, which according to the Australian Government, is light emitted when the upper atmosphere is hit by energetic charged particles. It’s the Antarctic equivalent of the Northern Lights and can take on many different colors, depending on the type of charge in the atmosphere. This green version really makes the blue and red of the Halley 6 Base pop out in this nighttime photo, giving the snow a green hue as well.\nWhen someone asks you to take a canoe trip, this isn’t probably what you have in mind. During the spring and summer months on Antarctica, the water can be warm enough that it melts the ice around the main ice shelf and allows tourist to row right up close. And it also allows them to row right up to icebergs, giant chunks of ice that are made entirely of fresh water and float around in the ocean. At least with these icebergs, there is no chance your canoe is going to sink if you get a little to close, but they are amazing to look at close up, especially when canoeing.\nAnother amazing image of Antarctica at night shows of everything the Milky Way Galaxy has to offer. It makes for an amazing and breathtaking view when sitting in one of the coldest places on Earth. Due to Antarctica’s position on the globe, there are times in Antarctica where night lasts for the entire day. According to Oceanwide Expeditions, this happens during the Winter solstice, and of course, the opposite happens during the summer, when Antarctica is completely light for 24 hours.\nTwo scientists set up flares on Antarctica to help guide their way. Due to the fact that there is no natural light source or a man-made one, it is possible to get lost on the ice shelf if you don’t know your way and wander off. In fact, people have got stranded on Antarctica for multiple reasons and had to be rescued. According to the Smithsonian, the largest reason for people to get stranded is due to blizzards, which can be made worse by the extreme cold. So stay close to shelter and keep a light on if you dare walk away from camp.\nAurora isn’t the only cool phenomena you can see in the school when you travel to Antarctica, as a Solar Halo is another common occurrence and frequently seen by those who travel way down south. According to Cool Antarctica, solar halos happen as a result of scattering of light by ice particles suspended in the air. If any place is going to be able to suspend ice particles in the air, it’s the cold temperatures of the Antarctic. These solar halos generally happen in the winter, when the temperature makes it happen more often.\nThese clouds over Antarctica make look pretty with their orange hue, but they are actually responsible for the destruction of the atmospheric ozone, according to Cool Antarctica. What happens is, they create conditions that release chlorine which reacts with and destroys ozone throughout the Antarctic winter. They are maintained by the polar vortex that isolates the weather in the region from the rest of the world. It means it stays longer and has a lot longer to affect the trapped ozone. So, this is one case where something beautiful in Antarctica, can be very harmful.\nThis photo is on the coast of Antarctica and is more than likely during the spring or summer months when the water isn’t frozen solid from cold temperatures. Remember that the Southern Hemisphere, the seasons are opposite those in the United States, so spring is actually in November and December, while summer happens in January and February. During the summer, according to Wildland Adventures, the temperature can reach 50 degrees Fahrenheit, and there is also 24 hours of daylight, which can make for some amazing looking photos from the Antarctic coast.\nThis swimmer isn’t swimming next to a large jellyfish, but rather, is swimming under Antarctica. According to National Geographic, those tendrils you see in this photo are not there to snatch up any drifting swimmers, but rather, are ice-covered brine. This photo is taken near the French scientific base on the Adélie Coast of East Antarctica and shows an entirely different world below the ice, where sea life, such as penguins and seals can thrive in the icy cold waters under the South Pole.\nThis photo shows a man making a solo trek across Antarctica. It’s actually an endurance race that takes over a month to complete and requires, as this photo shows, for the person to take everything with them in sleds. According to USA Today, Colin O’Brady became the first person to traverse Antarctica without assistance. It took him 54 days and it was over 930 miles from start to finish, which he finished just after Christmas in 2018, starting back in November. At least he picked the spring and summer months, which gave warmer temperatures.\nA familiar sight for anyone travelling to Antarctica will be penguins. They are probably the main reason most people want to go to the South Pole, in order to see these birds there. According to Global, there are 17 species of penguins in the world but only seven of them are found on Antarctica, which include the Adelie penguins, which are pictured here, the Emperor penguin, which is the largest, the chinstrap, Gentoo, King, Macaroni and Rockhopper. With thousands of penguins on Antarctica, it will be hard to not stumble upon one of them.\nThis photo is from a facility that is part of SALSA Antarctica, which stands for Subglacial Antarctic Lakes Scientific Access. According to SALSA, we actually know more about Mars than we do about Antarctica, so they set up scientific posts to study the ice, what is below it, and everything about Antarctica. They have made discoveries, such as the thought that over 379 lakes exist beneath the ice sheet. Camps, such as these, will be home to over 50 scientists in the coming year.\nThis photo looks stunning for it being a frozen ice sheet, but Antarctica does have some of the bluest water in the world, except it may be just a tad bit cold to go swimming in. According to Live Science, the water is so cold it can freeze fish blood, but fish don’t freeze because they have a natural antifreeze in their system. The water can be as cold as 28.8 degrees Fahrenheit, but that hasn’t stopped humans from jumping in, even without much protection on.\nThese penguins are waiting for their new visitors to stop on by as the cruise ships get closer to the Antarctic shore. It won’t be hard for anyone heading to Antarctica to spot penguins, as according to USA Today, the penguin population in Antarctica is over 12 million. Someone has actually counted the penguins to keep track of their population numbers and to see if they are declining in numbers. Unfortunately, they are declining, so photos like this one might not be around forever if the penguin population doesn’t increase.\nCruise ships bring tourists as close as they want to Antarctica, leaving off the coast of Argentina and taking 10 nights or more to cruise around the ice shelf. According to Oceanwide Expeditions, they offer multiple types of cruises that take people around the ice continent or even land them on it. But they can be prices trips, ranging from $4,000 to $6,000, depending on the person and what kind of accommodations they are after. It for sure will be an experience they soon won’t forget\nTo bring supplies to Antarctica for researchers, they are often flown in on some pretty big planes. The Hercules plane, which has four engines, can land on the thick ice and take off. With plenty of ice shelf to land on, there is plenty of space for the planes to come in. According to the National Science Foundation, the Hercules airplanes are the backbone of the United States transportation within Antarctica and come with ski-equipped landing gear. They are operated by the U.S. Air National Guard.\nWell hello, penguin! This person got to get up close and personal with the penguins, something very few people get to do outside of zoos. With over 12 million of them in Antarctica, it’s no surprise that scientists and tourists are able to walk up to them and get as close a view of the flightless birds as possible. This penguin is the Emperor penguin, which according to the Australian Government, is the largest of the penguin species and can weight up to 40 kilograms and they live to be more than 40 years old.\nThis photo shows a group of penguins most likely during their migration, as they look to mate, and they head back to the water to feed. According to the Independent, emperor penguins begin their march when Antarctica is almost entirely sunlight. This lets the sea-ice break-up, meaning the journey back to the ocean waters is a lot shorter. They can make a crossing over nearly 60 to 100 miles of sea ice to their breeding spot where the female lays a single egg. It’s an amazing sight to see in their environment.\nThe Antarctic Ice Marathon was started by the Polar Running Adventures to allow marathon runners to compete on all seven continents on Earth. By doing so, it is said that the runners complete the grand slam of marathon running, doing so on every possible continent. The race first started in January 2006, and has gone on every single year since then. It has included a men’s and women’s marathon, plus a men’s 100K and women’s 100k four other times. Petr Vabroušek won both the marathon and 100K in 2013, while Richard Donovan from Ireland has won the 100K three times.\nWhat a way to spend your Christmas holidays, on the ice shelf of Antarctica with some penguins around you. These two ladies are sending a Christmas message back to everyone in what would be the summer in Antarctica, as December is the start of the warm months there. According to the Weather Network, the highest temperature ever recorded at the South Pole was 9.9-degree Fahrenheit, while at the edges, it was 59 degrees. So, for these two during Christmas, it would just feel like a mild day if the temperatures reached that.\nYou only get these kinds of photos from Antarctica because there is zero light pollution from any human-made light sources. So every star in the night sky can be seen from Antarctica without much interference. According to Nature.com, Antarctica is deemed perfect for stargazing for this very reason, as the calm air part makes it the best place on Earth for astronomy. It’s why scientists want to build a telescope there because there is little interference from human-made or natural interference.\nThis photo is of the Amundsen-Scott South Pole Station, which is a United States scientific research station at the South Pole. It is located on the high plateau of Antarctica at an elevation of 9,301 feet above sea level. It is as close as you can get to the South Pole, and gets some amazing views from the bottom of the world. According to researchers on the station, they experience one very long day and one very long night, which lasts six months each.\nEven when on Antarctica, there is some time to have some fun and make snow angels in the snow. These two are taking in as much fun as they can in a place on few drew of going to. According to Global News, about 5,000 people each year visited in the early 1990s, but it has drastically increased, as in 2018, over 46,000 people visited the continent, with 14,000 of them coming from the United States. It’s the last vacation on most people’s bucket list, so it only makes sense that it’s growing.\nIf you want to do Antarctica, but don’t want to step out of the warm cabin, you can hop on one of the many luxury cruises that tour Antarctica. According to Global News, over 100 companies have contracts to take tours to Antarctica, but it is being regulated by the International Association of Antarctica Tour Operators, who monitors how many people actually visit and regulates the number of people. It’s the last all-natural place on Earth, and they are trying to keep it that way.']	['<urn:uuid:a0e70de6-c2e1-4f88-ba3e-025cbfc334f0>']	factoid	direct	concise-and-natural	similar-to-document	single-doc	novice	2025-05-12T23:47:20.322175	10	18	2489
62	trade opportunities middle east healthcare sector pharmaceutical restrictions	The healthcare and pharmaceutical sectors present significant opportunities in the Arab region, driven by demographic factors and lifestyle-related conditions. The region faces a notable shortage of healthcare professionals, creating opportunities for healthcare provision and training. The pharmaceutical sector is particularly promising given the focus on improving healthcare following the global pandemic. However, strict pharmaceutical regulations exist in these countries. In Qatar, for example, many common medications require prescriptions, and some are completely banned. Controlled substances require special permissions through the Department of Pharmacology and Drugs Control, with detailed documentation including medical reports and prescriptions not older than six months. Healthcare professionals must be consulted regarding medicine contents, and quantities are typically restricted to 30-day supplies.	['Please click on the below link for the full interview:\nIrish exports to Arab States up 10% – opportunities for Irish businesses grow despite pandemic\nAs Brexit deal or no deal looms and Irish economy contracts, Arab Irish Chamber of Commerce highlights strong opportunities for Irish businesses in Arab region\nIrish exports to the Arab World increased 10% in the first nine months of 2020 compared to the same period last year, according to the Arab Irish Chamber of Commerce (AICC) with notable increases in exports of Irish goods and services to Qatar, Jordan, Saudi Arabia, Egypt, the UAE and Algeria.\nThe latest figures show that despite the ongoing global health pandemic, the Irish export market to the Arab World remained robust, experiencing overall growth from January to September 2020. Ireland has exported a total of almost €1.9 billion in goods alone to the Arab states from Q1 to Q3 this year, compared with €1.73 billion for 2019.\nWith the end of the Brexit transition fast approaching and the prospect of a trade deal in flux, Irish SMEs are looking to expand their reach when it comes to export partners. The countries of the Arab region represent a growing market for Irish businesses, and Ahmad Younis, CEO of the Arab Irish Chamber of Commerce says, “Many Irish companies are looking to reduce their dependence on the UK market so we forecast that Irish exports to the region will increase even further. While the impact of Brexit is instilling a sense of trepidation in many business owners in Ireland, now is the time to focus on the bigger picture and explore opportunities elsewhere, and the reality is they don’t have to look too far to successfully diversify their export markets.”\nThe Arab region is worth €5.18 billion1, to Ireland’s export market, including goods and services, with figures expected to more than double within the next 13 years to reach almost €12 billion by 2032.\nAhmad R. Younis, Secretary-General & C.E.O., Arab-Irish Chamber of Commerce\nCountries of greatest opportunity\nThe region of 21 states between the Middle East and North Africa (MENA) has a growing population of more than 420 million people, representing 5.5% of the world’s population and accounting for 3.1% of the world’s economy. The population of the region is growing rapidly and is forecast to exceed 500 million, 6% of the global population, by 2028.\nLast year, the AICC commissioned a report by EY-DKM that highlighted 11 member countries that are considered to represent the greatest potential for Irish business: Algeria, Bahrain, Egypt, Iraq, Jordan, Kuwait, Morocco, Oman, Qatar, Saudi Arabia and the United Arab Emirates (UAE). These countries represent approximately 4.4% of the world’s population and 2.8% of the world economy.\nWith a population of 33.7 million, Saudi Arabia is the largest importer of Irish goods among the AICC member countries. 0.88% of Saudi Arabia’s merchandise imports are from Ireland and food imports are important; Ornua (formerly Bord Bainne) recognises Saudi Arabia as the fifth largest dairy importer in the world and operates a cheese factory in Riyadh. While exports to Saudi Arabia have had a slight decrease of 7% compared with last year, they still hold the highest value with a significant €466.6 million worth of Irish goods exported in the first three quarters of 2020.\nThe UAE, which is home to an estimated 10,000 Irish expats and with a population of 9.6 million, imported €411 million3 worth of Irish goods last year. It is one of the most dynamic and diversified economies in the Arab region with significant growth potential for Irish businesses. There has been a further 22% increase in exports to the UAE from Ireland this year, from €324.3 million (Q1-Q3 2019) to €395.1 million (Q1-Q3 2020).\nTwo other major importers of Irish dairy are Algeria and Egypt. Egypt is the world’s 11th largest dairy importer and with an estimated dairy self-sufficiency of approximately 70-75% it represents an excellent market for Irish dairy produce. Irish exports to Egypt grew by 18% in 2020, from €159.3 million (Q1-Q3 2019) to €187.3 million (Q1-Q3 2020), with dairy and seafood comprising the main export categories over the last year.\nAlgeria, with a population of 41 million, is the third largest whole milk powder importer in the world. Total Irish exports to Algeria grew this year by 41% from €64.8 million (Q1-Q3 2019) to €91 million (Q1-Q3 2020), largely attributable to the agri-food sector. This, coupled with the fact there are plans for a new Algerian embassy in Ireland, means there will be strengthened business relations and more opportunity.\nOther notable increases for 2020 lie in exports to Qatar and Jordan, with an increase in exports of a staggering 88% to Qatar for the first three quarters of 2020 compared to 2019 (growing from €56 million to €105.3 million), and an increase of 45% in exports to Jordan for the same period (from €64.5 million to €93.5 million).\nMajor growth categories\nFive categories of Irish goods account for almost 80% of Irish merchandise exports to the region namely soft drink concentrates, baby formula, pharmaceuticals, computers and dairy.\nThe Arab region represents huge potential for the Irish food and agri-food sector. On average, countries in the Gulf Co-operation Council, i.e. the United Arab Emirates, Saudi Arabia, Qatar, Oman, Kuwait and Bahrain import about 90% of their food produce, with Qatar, for example, importing almost all of its foodstuff.\nThe main destination for Irish food exports in the Middle East is Saudi Arabia, and while most of these are in the dairy category, there is huge potential for other food categories. The UAE imports a widespread range of food products, with a focus on consumer goods, including beverages, poultry, seafood, and confectionery. The trade possibilities with Kuwait, Qatar and Jordan, markets that may not be on the radar for many Irish SMEs, are enormous, according to Mr Younis. “Qatar and Jordan are definitely ones to watch and I urge Ireland’s CEOs to explore markets that they may never have previously considered as I believe that these are the ones that present the best opportunities for business growth beyond the domestic market right now.”\nWhat makes the Arab World an attractive prospect?\nThe countries of the Arab world import many of the products and services that Irish companies can supply competitively; they have considerable resources to fund their imports; their rising populations cause demand to grow year after year—and they are relatively close to Ireland in terms of accessibility.\n“Demand for imports is high, and, coupled with multiple large-scale investment and infrastructure plans that are already in train, it’s a ready-made market for Irish SMEs,” explains Mr Younis. “Direct links between Ireland and the region have improved significantly, creating stronger links between the two markets. Irish businesses with a high-quality product or service that are willing to put in the effort to cultivate new opportunities are on a path to success in the Arab world. Ireland is a small nation, but we already have a very positive image in the region. Despite this year’s difficulties, I see huge potential for trade from Ireland to the east and the timing has probably never been better.”\nTwo Irish organisations that have spent a lot of time on the ground in the Arab States are Bord Bia and Enterprise Ireland, both of which actively promote brand Ireland and help Irish companies launch in these markets.\n“There are great supports for Irish SMEs looking to make a start and explore new opportunities in the Arab region so a lack of market knowledge should never be a reason not to explore the multiple prospects that exist.”\nTaking the first step\nWith traditional business activities such as conferences and exhibitions on pause for the next few months, Mr Younis advises that companies are not deterred and instead make use of all available resources.\n“There is a lot of help and advice available locally to business-owners looking to expand their international exporting potential. Make use of this time and the expertise that’s available by speaking to organisations like Bord Bia and the AICC. Enterprise Ireland also has specialist teams across the region to specifically support Irish firms in getting established and provides advice on the different business models that operate out there. Do your research and avoid wasting time, money and effort surging ahead with a business model that is not right for you – or the market,” advises Mr Younis.\nOpportunities for growth\n- Food sector: Rapidly growing populations along with constrained and relatively underdeveloped agriculture creates an ongoing opportunity in the food sector and, in particular, dairy and meat. Several markets in the region have recently reopened to Irish meat, which is pertinent given the disruptions likely to be caused by Brexit. As the Arab region is a net food importer, and in light of the supply chain issues highlighted by the Covid-19 crisis, security of food supply will be an important issue for the region going forward.\n- Pharma and medical: Driven by demographic factors, the incidence of lifestyle-related conditions and the move towards improving the healthcare sector, of particular relevance now in light of the global pandemic.\n- Healthcare: There is a significant shortage of local healthcare professionals creating opportunities to directly provide healthcare or provide healthcare training,\n- Agricultural advice and training are expected to be growth areas as countries look to improve their food security and production capacity.\n- Construction: With ambitious plans across the region for large volumes of investment across economic and social infrastructure, there is a wide range of opportunities in construction and development services (urban planners, QS, architects, engineers and construction companies).\n- Education: Policies aimed at improving education together with a shortage of local teachers generates opportunities to directly provide education or teacher training services, particularly in the Gulf States\n- Renewables: Policies aimed at increasing the share of renewables in the local energy markets point to opportunities for Irish businesses with knowledge, experience and capabilities in the development and operation of renewables infrastructure.\n- Infrastructure: There is a move to privatise significant elements of state-owned enterprises in many of the Gulf Countries, which could lead to opportunities for Irish infrastructure firms in areas such as transport, logistics, energy and water.\n- Aviation: Aviation-related services will provide significant opportunities for Irish businesses operating in this sector, particularly in the UAE.\n- Tourism: Many of the AICC ‘s member countries view tourism as a means of diversifying their economies and generating employment, which opens doors for those who can offer technical and marketing advice in addition to operating facilities.', 'Having medicines in your travel bag is second nature to most people, but if you’re not careful, those medicines to relieve a cough or treat painful gastric ulcers can land you in jail.\nThe general rules is that if you are under medication and if you are carrying certain prescribed medicines you must have doctor’s prescription in original and the medicines should be carried along with its original packing and literature so that custom authorities can easily identify them.\nSome medicines, which are over-the-counter in other countries, are also considered controlled items in Qatar as they produce effects that contravene local laws.\n- Many common cold and cough remedies, which you might assume to be harmless, must be accompanied by a prescription.\n- Some sleeping tablets, painkillers, anti-depressants and hormone replacement therapy drugs are banned here.\n- Some controlled drugs include alfentanil, amphetamine, codeine, fentanyl, ketamine, methadone, methyphenidate and morphine.\nGuidelines for carrying medicines containing drugs or psychotropic substance\nAfter the recent incidents involving Indian nationals being held at Doha airport for carrying medicines without prescription, Indian Embassy in Qatar has re-published a circular from Qatar’s Supreme Council of Health addressed to all embassies (originally published in November 2014).\nThe circular contains the procedures and regulations to be followed while carrying medicines containing either drugs or psychotropic substance by patients coming to Qatar or departing from here for their personal use.\nHere are the main extracts from the circular :\n1. It is prohibited to carry medicines and substances which are banned internationally and locally.\n2. It s prohibited to carry medicines mentioned in the list (a) and list (b) of Law (9) issued in the year 1987, regarding anti-drugs and dangerous psychotropic substances. Likewise the items registered at schedule No. (3) of the same law (Link to the list is given below).\n3. In order to carry such medicines, an application is to be given to the Department of Pharmacology and Drugs Control in the Supreme Council of Health.\nProcedure for special permission\n4. Permission would be granted to carry the medicines by the patients coming to State of Qatar for their personal use as per the following guidelines :\na) To attach detailed medical report attested by the hospital treated the patient. Medical report should not be older than six months. The report must contain the following:\n- Personal Details of the patient\n- Medical diagnosis\n- Treatment and duration\n- Medical Prescriptions\n- Scientific name of the medicines, Form and scheduled doses.\nb) Or to attach the medical prescription in the name of the patient, attested by the same hospital and the prescription should not be older than six months.\nThe prescription must have the following:\n- Diagnosis of the disease\n- Scientific name of the medicines, Form and scheduled doses.\n- How to use and duration of treatment\n- Seal of the hospital\nc) To pledge that only patient will use the medicine and will use on his responsibility.\nd) To attach a copy of the ID card of the patient\n5. Approval can be granted to carry medicines of 30-days maximum period or for the duration of the stay if the patient in Qatar, whatever is less, subject to validity of the medicines.\nThe patient has to keep in mind the following:\n- In case the medicine exhausts, the patient has to contact the specialist physician licensed to practice in a hospital (in Qatar), to check whether he needs to continue the same medicine.\n- In case the physician confirms that the patient needs to continue the same treatment, a specific medical file has to be opened in that hospital and the appropriate medicine would be prescribed through a medical prescription attested by the same hospital. The medicine would be provided from the local pharmacy for the required period. The patient will continue to do follow ups with the same hospital for his continuos treatment if his medical condition warrants so.\n- In case the medicine or its alternative is not available in the local market, the hospital treating the patient can secure this medicine through one of the drugs distributors after obtaining approval from the Department of Pharmacology and Drugs Control in the Supreme Council of Health.\n6. If the medicine is in form of injection, the approval can be obtained under the supervision of any local hospital in the name of the patient. The medicine would be registered in the file of the hospital meant for personal use as per the followed procedure for such medicines.\n7. Excess medicine can be destroyed through the Department of Pharmacology and Drugs Control in the Supreme Council of the Health.\nWhile departing from Qatar\n8. Departing patients from Qatar would be treated as par with one coming to Qatar according to the above mentioned paragraphs No (1), No (2), No (3) and no (4). Quantity of the medicine would be allowed for 30 days only.\n9. In case, the medicine is not carried by the patient but was carried by one of his relatives (like parents, children, brothers or spouse), a copy of his ID would be taken. In case the medicine was carried by the representative of the patient, the written consent of the patient for carrying medicines has to be attached. A copy of his ID would be taken.\nSpecial procedure for diplomats / government officials\n10. In case the medicines contain drugs or psychotropic substance are to be carried by the diplomats or government officials (only) coming to State of Qatar for the patients working with the diplomatic mission. The procedures would be as following :\na) The Missions has to send an application to the Department of Pharmacology and Drugs Control in the Supreme Council of Health, mentioning the name of head of the Mission or name of the custodian of the drugs. If not so, the accompanying physician would be the custodian of the medicine.\nThe application should be attached with the following :\n- Details of the desired medicines certified by the concerned authority in the country of Mission, including the scientific name of the drug and psychotropic substance, form, concentration, size and quantity. Medicines containing drug and psychotropic substance have to be borough through aerial transportation only.\n- To pledge that the medicine would be used by the members of the Mission/delegation only on their responsibility and it would not be sold or it would not be utilised for any other purpose. To pledge that the excess medicines would be carried back. To pledge to provide details of medicine utilization, reasons for utilization, excess medicine and destroyed ones before departure of the delegation to the Department of Drugs and Pharmacology Control in the Supreme Council of Health,\n11. Once application is approved, permission would be granted for carrying the medicine.\nPlease note that the detailed application process as above is only required for medicines containing either drugs or psychotropic substance.\nHowever, only health care professional can advise you about the contents of a medicine. So please check with your doctor about the contents of your medicine.\nAlso make sure not to carry them in large quantities. Medicines for common conditions such as diabetes, hypertension (High Blood Pressure) etc are usually allowed for 1-3 months for residents. However make sure to carry the medical reports, prescriptions and original packing.\nFor travellers to other GCC countries, the guidelines are almost similar. However list of banned medicines may not be the same. For UAE, you can find the list of banned medicines here.']	['<urn:uuid:33779245-db61-4070-a6df-eeab57441e72>', '<urn:uuid:03569d6d-2d09-4ece-b91c-fea157da7366>']	open-ended	direct	long-search-query	distant-from-document	multi-aspect	expert	2025-05-12T23:47:20.322175	8	115	3012
63	What caused Stonewall Jackson's death at Chancellorsville?	During the Battle of Chancellorsville, on the evening of May 2, Stonewall Jackson was accidentally shot by his own men while on a scouting mission. Specifically, a teenage sergeant ordered shots at what they thought was a lost Union soldier in the woods, leading to several hundred musket balls being fired. Jackson was hit twice in the left arm during this friendly fire incident. He ultimately died on May 10, not from the wounds directly, but from pneumonia that developed during his recovery.	"['The locomotive ground to a halt at a little depot amidst a drenching downpour. An eager figure scanned the cars for two passengers who meant more to him than anyone else on earth.\nThe legendary ""Stonewall"" Jackson, renowned as the quintessential grim warrior, revealed his gentler nature on April 20, 1863, at Guinea Station, 12 miles south of Fredericksburg as he greeted his beloved wife and saw his infant daughter for the first time. The blissful family repaired to a nearby house and passed the next nine days enjoying the only domestic contentment they would ever share. In less than three weeks, at a small frame building near Guinea, Jackson would be dead.\nThe campaign that resulted in Jackson\'s demise, paradoxically remembered as ""Lee\'s greatest victory,"" emerged from the backwash of the Battle of Fredericksburg. That Federal debacle and subsequent political intrigue at army headquarters prompted a change of command in the Army of the Potomac. Major General Joseph Hooker, a 48-year-old Massachusetts native endowed with high courage and low morals, replaced Burnside in January. Within weeks, Hooker\'s able administrative skills restored the health and morale of his troops, whom he proudly proclaimed ""the finest army on the planet.""\nThe new commander crafted a brilliant plan for the spring that he expected would at least compel General Robert E. Lee to abandon his Fredericksburg entrenchments, and, possibly, prove fatal to the Army of Northern Virginia. First, Hooker would detach his cavalry, 10,000 strong, on a flying raid toward Richmond to sever Lee\'s communications with the Confederate capital. Then, he would send most of his infantry 40 miles upstream to cross the Rappahannock and Rapidan Rivers beyond the Confederate defenses, and sweep east against Lee\'s left flank. The rest of ""Fighting Joe\'s"" army would cross the river at Fredericksburg and menace the Confederate front as the second blade of a great pincers. ""My plans are perfect,"" boasted Hooker ""and when I start to carry them out may God have mercy on General Lee, for I will have none.""\nThe condition of the Confederate army lent credence to Hooker\'s confidence. In February, Lee detached his stalwart lieutenant, James Longstreet, with two strong divisions to gather food and supplies in southeastern Virginia. The gray commander cherished the offensive, but could not hope to move north without Longstreet. In the meantime, Lee\'s 60,000 veterans at Fredericksburg would guard their long river line against 130,000 well-equipped Yankees.\nHooker began the campaign on April 27 and within three days some 40,000 Federals had splashed through the upriver fords, their presence detected by Confederate cavalry. On April 29, a sizable Union force led by Major General John Sedgwick\'s Sixth Corps erected pontoon bridges below Fredericksburg and also moved to Lee\'s side of the river.\nWith both wings of the enemy across the Rappahannock, Lee faced a serious dilemma. Conventional military wisdom dictated that the understrength Army of Northern Virginia retreat south and escape Hooker\'s trap. Lee opted instead to meet the Federal challenge head-on. Correctly deducing that Hooker\'s primary threat lay to the west, ""Marse Robert"" assigned 10,000 troops under Major General Jubal A. Early to man the old Fredericksburg entrenchments. The balance of the army would turn west toward the tangled Wilderness to confront Hooker\'s flanking column.\nBy mid afternoon of April 30, that column, now containing 50,000 men and 108 artillery pieces, rendezvoused at the most important road junction in the Wilderness. A large brick tavern named Chancellorsville dominated this intersection of the Orange Turnpike with the Orange Plank, Ely\'s Ford, and River roads. ""This is splendid,"" exulted one of Hooker\'s corps commanders, ""Hurrah for Old Joe.""\nThe Federals had encountered virtually no opposition to this point. Moreover, they could now press eastward, break clear of the Wilderness, and uncover Banks Ford downstream, thus significantly shortening the distance between their two wings. Hooker, however, decided to halt at Chancellorsville and await the arrival of additional Union troops. This fateful decision disheartened the Federal officers on the scene who recognized the urgency of maintaining the momentum they had thus far sustained.\n""Stonewall"" Jackson, gladly seizing the initiative that Hooker needlessly surrendered, left the Fredericksburg lines at 3:00 a.m., on May I and arrived at Zoan Church five hours later. There he found two divisions of Confederate infantry, Major General Richard H. Anderson\'s and Major General Lafayette McLaws\', fortifying a prominent ridge covering the Turnpike and Plank Road. Although his corps had not yet appeared, Jackson ordered Anderson and McLaws to drop their shovels, pick up their rifles, and advance to the attack.\nJackson\'s audacity dictated the shape of the Battle of Chancellorsville. When Hooker at last authorized an eastward movement late in the morning of May 1, his troops on the Turnpike and Plank Road ran flush against ""Stonewall\'s"", outgunned but aggressive brigades. Union front-line commanders had not expected this kind of resistance. They sent anxious messages to Hooker, who quickly ordered his generals to fall back to the Wilderness and assume a defensive posture. The Federal columns on the River Road marched almost to Bank\'s Ford without seeing a Rebel. They returned to Chancellorsville fuming, fully realizing the opportunity that had slipped through their fingers.\nLate in the day, as the blue infantry threw up entrenchments encircling Hooker\'s Chancellorsville headquarters, Major General Darius N. Couch approached his superior. As the army\'s senior corps commander, Couch had advocated an offensive strategy and shared his comrades\' disappointment with ""Fighting Joe\'s"" judgment. ""It is all right, Couch,"" Hooker reassured him, ""I have got Lee just where I want him; he must fight me on my own ground.""\nCouch could barely believe his ears. ""To hear from his own lip that the advantages gained by the successful marches of his lieutenants were to culminate in fighting a defensive battle in that nest of thickets was too much, and I retired from his presence with the belief that my commanding general was a whipped man.""\nHooker\'s confidence had faded to caution, but whether he was ""whipped"" depended upon Lee and Jackson. Those two officers reined up along the Plank Road at its intersection with a byway call the Furnace Road on the evening of May 1. Transforming discarded Federal cracker boxes into camp stools, the generals examined their options.\nConfederate scouts verified the Federals\' strong positions extending from the Rappahannock River, around Chancellorsville, to the high, open ground at Hazel Grove. This was the bad news. The Southern army could not afford a costly frontal attack against prepared fortifications.\nThen, about midnight, Lee\'s cavalry chief, ""Jeb"" Stuart, galloped up to the little campfire. The flamboyant Virginian carried thrilling intelligence. The Union right flank was ""in the air"" -- that is, resting on no natural or artificial obstacle! From that moment on, the generals thought of nothing but how to gain access to Hooker\'s vulnerable flank. Jackson consulted with staff officers familiar with the area, dispatched his topographical engineer to explore the roads to the west, and tried to snatch a few hours rest at the chilly bivouac.\nBefore dawn, Lee and Jackson studied a hastily drawn map and decided to undertake one of the biggest gambles in American military history. Jackson\'s corps, about 30,000 troops, would follow a series of country roads and woods paths to reach the Union right. Lee, with the remaining 14,000 infantry, would occupy a position more than three miles long and divert Hooker\'s attention during Jackson\'s dangerous trek. Once in position, ""Stonewall"" would smash the Federals with his full strength while Lee cooperated as best he could. The Army of Northern Virginia would thus be fractured into three pieces, counting Early\'s contingent at Fredericksburg, any one of which might be subject to rout or annihilation if the Yankees resumed the offensive. To learn more about the role of McLaws\' men on May 2 see a folder for McLaws\' Trail.\nJackson led his column past the bivouac early on the morning of May 2. He conferred briefly with Lee, then trotted down the Furnace Road with the fire of battle kindled in his eyes. After about one mile, as the Confederates traversed a small clearing, Union scouts perched in treetops at Hazel Grove spotted the marchers. The Federals lobbed artillery shells at Jackson\'s men and notified Hooker of the enemy movement.\n""Fighting Joe"" correctly identified Jackson\'s maneuver as an effort to reach his right flank. He advised the area commander, Major General Oliver 0. Howard, to be on the lookout for an attack from the west. As the morning progressed, however, the Union chief grew to believe that Lee was actually withdrawing - the course of events Hooker most preferred. Worries about his right disappeared. Instead, he ordered his Third Corps to harass the tail end of Lee\'s ""retreating"" army.\nColorful Major General Daniel E. Sickles commanded the Third Corps. He probed cautiously from Hazel Grove toward a local iron manufactory called Catharine Furnace. In mid-afternoon the Federals overwhelmed Jackson\'s rearguard beyond the furnace along the cut of an unfinished railroad, capturing nearly an entire Georgia regiment. The action at Catharine Furnace, however, eventually attracted some 20,000 Bluecoats onto the scene thus effectively isolating Howard\'s Eleventh Corps on the right with no nearby support.\nMeanwhile the bulk of Jackson\'s column snaked its way along uncharted trails barely wide enough to accommodate four men abreast. ""Stonewall"" contributed to Hooker\'s faith in a Confederate retreat by twice turning away from the Union line - first at Catharine Furnace, then again at the Brock Road. After making the desired impression, Jackson ducked under the Wilderness canopy and continued his march toward Howard\'s insensible soldiers.\nActing upon a personal reconnaissance recommended by cavalry general Fitzhugh Lee, Jackson kept his column northbound on the Brock Road to the Orange Turnpike where the Confederates would at last be beyond the Union right. The exhausting march, which altogether traversed more, than 12 miles, ended about 3 p.m. when ""Old Jack\'s"" warriors began deploying into battle lines astride the Turnpike. Jackson, however, did not authorize an attack for some two hours, providing 11 of his 15 brigades time to take position in the silent forest. The awe-inspiring Confederate front measured nearly two miles across.\nAlthough individual Northern officers and men warned of Jackson\'s approach, Eleventh Corps headquarters dismissed the reports as frightened exaggerations from alarmists or cowards. Hooker\'s shortage of cavalry hampered the Federals\'s ability to penetrate the Wilderness and uncover the Confederate presence with certainty. Only two small regiments and half a New York battery faced west in the direction of Jackson\'s corps.\nSuddenly, a bugle rang out in the afternoon shadows. Bugles everywhere echoed the notes up and down the line. As waves of sweat-soaked soldiers rolled forward, the high defiance of the Rebel Yell pierced the gloomy woods. Jackson\'s Corps erupted from the trees and sent the astonished Unionists reeling. ""Along the road it was pandemonium,"" recalled a Massachusetts soldier, ""and on the side of the road it was chaos.""\nMost of Howard\'s men fought bravely, drawing three additional battle lines across Jackson\'s path. But the overmatched Federals occupied an untenable position. The screaming gray legions overwhelmed each Union stand and eventually drove the Eleventh Corps completely from the field.\nSunset and the inevitable intermingling of ""Stonewall\'s"" brigades compelled Jackson to call a reluctant halt to the advance about 7:15. He summoned Major General A.P. Hill\'s division to the front and, typically, determined to renew his attack despite the darkness. Jackson hoped to maneuver between Hooker and his escape routes across the rivers and then, with Lee\'s help, grind the Army of the Potomac into oblivion.\nWhile Hill brought his brigades forward, Jackson rode ahead of his men to reconnoiter. When he attempted to return, a North Carolina regiment mistook his small party for Union cavalry. Two volleys burst forth in the blackness and Jackson tottered in his saddle, suffering from three wounds. Shortly thereafter a Federal shell struck Hill, incapacitating him, and direction of the corps devolved upon Stuart. The cavalryman wisely canceled ""Stonewall\'s"" plans for a night attack. See text for Wounding of Stonewall Jackson Trail.\nDespite his misfortune on May 2, Hooker still held the advantage at Chancellorsville. He received reinforcements during the night and the Third Corps moved back from Catharine Furnace to reoccupy Hazel Grove. Sickles\' troops thus divided the Confederates into separate wings controlled by Stuart and Lee. Hooker, if he chose, could defeat each fraction of his out manned enemy in detail.\nThe Confederate commanders understood the need to connect their divisions, and Stuart prepared an all-out assault against Hazel Grove at dawn. Hooker made it easy for him. As the Southerners approached the far crest of Hazel Grove they witnessed Sickles\' men retiring in an orderly fashion. ""Fighting Joe"" had directed that his troops surrender the key ground and fall back to Fairview, an elevated clearing closer to Chancellorsville.\nStuart immediately exploited the opportunity by placing 31 cannon on Hazel Grove. Combined with artillery located west along the Turnpike, the gunners at Hazel Grove pounded Fairview with a spectacular bombardment. The Federals responded with 34 pieces of their own and soon the Wilderness trembled with a discordant symphony of iron. See folder for Hazel Grove to Fairview walking trail.\nThe bloodiest fighting of the battle occurred between 6:30 and 9:30 a.m. on May 3. Stuart launched brigade after brigade against entrenched Union lines on both sides of the Turnpike. Troops lost their way in the tangled underbrush and the woods caught fire, confronting the wounded with a horrible fate.\nThe see-saw fighting began to favor the Southerners as, one by one, Union artillery pieces dropped out of the contest. Hooker failed to resupply his cannoneers with ammunition or shift sufficient infantry reserves to critical areas. A Confederate projectile abetted this mental paralysis when it struck a pillar at Chancellorsville, throwing the Union commander violently to the ground. The impact stunned Hooker, physically removing him from a battle in which he had not materially been engaged for nearly 48 hours. Before relinquishing partial authority to Couch, Hooker instructed the army to assume a prepared position in the rear, protecting the bridgehead across the Rappahannock.\nStuart pressed forward first to Fairview and then against the remaining Union units at Chancellorsville. Lee\'s wing advanced simultaneously from the south and east. The Bluecoats receded at last and thousands of powder-smeared Confederates poured into the clearing, illuminated by flames from the burning Chancellorsville mansion.\nLee emerged from the smoke and elicited a long, unbroken cheer from the gray multitudes who recognized him as the architect of their improbable victory. A Confederate staff officer, watching the unbridled expression of so much admiration, reverence, and love, thought that, ""it must have been from such a scene that men in ancient times rose to the dignity of gods.""\nThe Southern commander wasted little time on reflection. He prepared to pursue Hooker and seal the success achieved since dawn. A courier bearing news from Fredericksburg shattered Lee\'s plans. Sedgwick had driven Early\'s contingent from Marye\'s Heights and now threatened the Confederate rear. This changed everything. Lee assigned Stuart to watch Hooker\'s host and sent McLaws eastward to deal with the Sixth Corps menace. See a folder for a driving tour of 2nd Fredericksburg & Salem Church.\nSedgwick, slowed by Wilcox\'s single Alabama brigade retreating stubbornly from Fredericksburg, came to grips with the Confederates four miles west of town at Salem Church. The Federals swept into the churchyard but a powerful counterattack drove them back and ended the day\'s combat. The next day Lee shoved Sedgwick across the Rappahannock at Banks Ford and once again focused on the main Union army in the Wilderness.\nHooker, however, had seen enough. Despite the objections of most of his corps commanders, he ordered a withdrawal across the river. The Federals conducted their retreat under cover of darkness and arrived back in Stafford County on May 6. Ironically, this decision may have been Hooker\'s most serious blunder of the campaign. Lee\'s impending assault on May 6 might have failed and completely reversed the outcome of the battle.\nConfederate leadership during the Chancellorsville Campaign may represent the finest generalship of the Civil War, but the luster of ""Lee\'s greatest victory"" tarnishes upon examination of the battle\'s tangible results. In truth, the Army of the Potomac had not been so thoroughly defeated - some 40,000 Federals had done no fighting whatsoever. Although Hooker suffered more than 17,000 casualties, those losses accounted for only 13% of his total strength. Lee\'s 13,000 casualties amounted to 22% of his army, men difficult to replace. Of course, Jackson\'s death on May 10 created a vacancy that could never be filled. Finally, Lee\'s triumph at Chancellorsville imbued him with the belief that his army was invincible. He convinced the Richmond government to endorse his proposed offensive into Pennsylvania. Within six weeks, the Army of Northern Virginia confidently embarked on a journey northward to keep an appointment with destiny at a place called Gettysburg.\nThe text for this section was written by A. Wilson Green, former staff historian for Fredericksburg and Spotsylvania National Military Park. It is derived from a National Park Service training booklet.', 'The performance of several officers at the Battle of Chancellorsville is put under scrutiny by a batch of distinguished historians in this, the third volume in a meritorious series of essays on military campaigns of the Civil War edited by Gary W. Gallagher of Pennsylvania State University.\nThis pivotal battle in early May 1863 - remembered as a remarkable triumph for Gen. Robert E. Lee and for the fatal wounding of Lt. Gen. Thomas J. ""Stonewall"" Jackson - is also the subject of two current books: Ernest B. Furgurson\'s ""Chancellorsville, 1863: The Souls of The Brave"" (Knopf, 405 pages, $25) published in 1992, and Stephen Sears\' ""Chancellorsville"" (480 pages, $29.95), due out in August from Houghton Mifflin.\nThis collection of essays makes a fine and informative supplement to these two extensive studies, and can also be profitably enjoyed without reference to other treatments given the battle in which Lee audaciously divided his Army of Northern Virginia in the face of superior forces and the battle during which Union Maj. Gen. Joseph Hooker mysteriously lost his will to fight.\nWhile Lee and Hooker are not principal subjects of analysis here, the officer corps of the Army of the Potomac and the circumstances leading up to Jackson\'s death are related in detail. Hooker, in a few months while encamped in Stafford north of the Rappahannock River, ""had worked a dramatic transformation"" in rebuilding an army dispirited by Ambrose Burnside\'s disastrous Mud March in January. John J. Hennessy notes that Hooker deserved to be confident as he, at the end of April, marched upstream and across the Rappahannock and set up his headquarters at the crossroads home of the Chancellor family.\nOn the evening of May 2, after he had led a dramatic flank attack on the Union army, Jackson was in one of two scouting parties that ventured down a wooded road and in front of Confederate troops. Down the line, relates Robert K. Krick, ""a tangled skein of tactical developments led a teen-age sergeant to order a shot against a lost Yankee in the woods. ... The spark inevitably flared into fire by nearby lines. The firing spread northward, instinctive and unreasoning. It eventually results in the discharge of several hundred musket balls and rifled bullets eastward from the front of the 18th North Carolina toward the backs of friendly skirmishers - and through A.P. Hill\'s and Thomas J. Jackson\'s parties in the intervening ground."" One officer was killed outright. Jackson, who was farthest away from the unidentified Confederate soldiers firing, was hit twice in the left arm. He died May 10 of pneumonia.\nIn a separate essay, James I. Robertson Jr. of Virginia Tech reports on the medical service at Chancellorsville of both armies. By 1863 strides in sanitation and the organization of field hospitals had been made, although treatment was still crude.\nThe positioning and movement opposite Fredericksburg and at Salem Church of Maj. Gen. Jubal Early, who was on the right wing of Lee\'s army, was criticized after the war by one of Early\'s fellow officers, a debate that Early, although deeply offended, didn\'t enter. Early had the approbation of Lee, and that was good enough for him.\nWhether or not Confederate Col. Emory F. Best abandoned his men of the 23rd Georgia regiment may never be determined with certainty, but he was, nonetheless, convicted of cowardice and dismissed from the army. After the war Best was a lawyer for the federal government and died in Washington in 1912.\nOn the other side of the battleline, the May 2-3 defense of Chancellor House by Maj. Gen. Winfield S. Hancock\'s division is acclaimed for giving Hooker time to withdraw his army across the Rappahannock. Hancock was given the appellation ""the superb"" by George B. McClellan the year before at Williamsburg; at Chancellorsville he earned it.\nThe components of Brig. Gen. George Stoneman\'s corps of cavalry moved to the far right of Hooker\'s army and deep into Confederate Virginia with the mission of cutting off rail support for Lee. Mounted troops under Col. Hugh Judson Kilpatrick and Lt. Col. Hasbrouck Davis got to the outskirts of Richmond. But because the cavalry was absent from Chancellorsville, Hooker blamed Stoneman for the loss of the battle. The effect of the Union cavalry has long been debated, but A. Wilson Greene, executive director of Pamplin Park Civil War Site near Petersburg, argues in his essay that ""Stoneman\'s raid compares quite well with virtually every other cavalry operation during the first three years of the war - even those remembered as brilliant successes.""\nIn the final essay, ""Children of Chancellorsville,"" James Marten of Marquette University writes engagingly of accounts of two young people caught up in the battle - the reminiscences (published in 1921) of 14-year-old Sue Chancellor, who took refuge in the basement of her home, and a 1865 account of the heroism of a Union drummer boy by the name of Robert.\nAll in all, Gallagher\'s ""Chancellorsville"" is another fine addition to anyone\'s Civil War library and reading list.\nThe Battle and its Aftermath\nEdited by Gary W. Gallagher\nUniversity of North Carolina Press\nIllustrations. 263 pages. $29.95']"	['<urn:uuid:b43c7b5a-8fc4-463c-9233-a748d3a28798>', '<urn:uuid:1d6cca1d-5fe5-4158-8371-4ede486e0f3e>']	open-ended	direct	concise-and-natural	similar-to-document	three-doc	novice	2025-05-12T23:47:20.322175	7	83	3706
64	analyzing religious hypocrisy examples whitewashed tombs metaphor explain meaning significance	The whitewashed tombs metaphor was used to describe religious hypocrites who outwardly appear beautiful and righteous to others, but inside are full of dead people's bones and all uncleanness. This metaphor illustrated how these religious leaders maintained an appearance of righteousness on the outside while being full of hypocrisy and lawlessness within. Like tombs that are painted white but contain death inside, they presented a false exterior that masked their true corrupt nature.	['English Standard Version (ESV)\nSeven Woes to the Scribes and Pharisees\n23 Then Jesus said to the crowds and to his disciples, 2 “The scribes and the Pharisees sit on Moses’ seat, 3 so do and observe whatever they tell you, but not the works they do. For they preach, but do not practice. 4 They tie up heavy burdens, hard to bear,[a] and lay them on people’s shoulders, but they themselves are not willing to move them with their finger. 5 They do all their deeds to be seen by others. For they make their phylacteries broad and their fringes long, 6 and they love the place of honor at feasts and the best seats in the synagogues 7 andgreetings in the marketplaces and being called rabbi[b] by others. 8 But you are not to be called rabbi, for you have one teacher, and you are all brothers.[c] 9 And call no man your father on earth, for you have one Father, who is in heaven. 10 Neither be called instructors, for you have one instructor, the Christ. 11 The greatest among you shall be your servant. 12 Whoever exalts himself will be humbled, and whoever humbles himself will be exalted.\n13 “But woe to you, scribes and Pharisees, hypocrites! For you shut the kingdom of heaven in people’s faces. For you neither enter yourselves nor allow those who would enter to go in.[d]15 Woe to you, scribes and Pharisees, hypocrites! For you travel across sea and land to make a single proselyte, and when he becomes a proselyte, you make him twice as much a child ofhell[e] as yourselves.\n16 “Woe to you, blind guides, who say, ‘If anyone swears by the temple, it is nothing, but if anyone swears by the gold of the temple, he is bound by his oath.’ 17 You blind fools! For which is greater, the gold or the temple that has made the gold sacred? 18 And you say, ‘If anyone swears by the altar, it is nothing, but if anyone swears by the gift that is on the altar, he is bound by his oath.’ 19 You blind men! For which is greater, the gift or the altar that makes the gift sacred? 20 So whoever swears by the altar swears by it and by everything on it. 21 And whoever swears by the temple swears by it and by him who dwells in it. 22 And whoever swears byheaven swears by the throne of God and by him who sits upon it.\n23 “Woe to you, scribes and Pharisees, hypocrites! For you tithe mint and dill and cumin, and have neglected the weightier matters of the law: justice and mercy and faithfulness. These you ought to have done, without neglecting the others. 24 You blind guides, straining out a gnat and swallowing a camel!\n25 “Woe to you, scribes and Pharisees, hypocrites! For you clean the outside of the cup and the plate, but inside they are full of greed and self-indulgence. 26 You blind Pharisee! First clean the inside of the cup and the plate, that the outside also may be clean.\n27 “Woe to you, scribes and Pharisees, hypocrites! For you are like whitewashed tombs, which outwardly appear beautiful, but within are full of dead people’s bones and all uncleanness. 28 So you also outwardly appear righteous to others, but within you are full of hypocrisy and lawlessness.\n29 “Woe to you, scribes and Pharisees, hypocrites! For you build the tombs of the prophets and decorate the monuments of the righteous, 30 saying, ‘If we had lived in the days of our fathers, we would not have taken part with them in shedding the blood of the prophets.’ 31 Thus you witness against yourselves that you are sons of those who murdered the prophets. 32 Fill up, then, the measure of your fathers. 33 You serpents, you brood of vipers, how are you to escape being sentenced to hell? 34 Therefore I send you prophets and wise men and scribes, some of whom you will kill and crucify, and some you will flog in your synagogues and persecute from town to town, 35 so that on you may come all the righteous blood shed on earth, from the blood of righteous Abel to the blood of Zechariah the son of Barachiah,[f] whom you murdered betweenthe sanctuary and the altar. 36 Truly, I say to you, all these things will come upon this generation.\nLament over Jerusalem\n37 “O Jerusalem, Jerusalem, the city that kills the prophets and stones those who are sent to it! How often would I have gathered your children together as a hen gathers her brood under her wings, and you were not willing! 38 See, your house is left to you desolate. 39 For I tell you, you will not see me again, until you say, ‘Blessed is he who comes in the name of the Lord.’”\nEnglish Standard Version (ESV)\nJesus Foretells Destruction of the Temple\n24 Jesus left the temple and was going away, when his disciples came to point out to him the buildings of the temple. 2 But he answered them, “You see all these, do you not? Truly, I say to you, there will not be left here one stone upon another that will not be thrown down.”\nSigns of the End of the Age\n3 As he sat on the Mount of Olives, the disciples came to him privately, saying, “Tell us, when will these things be, and what will be the sign of your coming and of the end of the age?” 4 And Jesus answered them, “See that no one leads you astray. 5 For many will come in my name, saying, ‘I am the Christ,’ and they will lead many astray. 6 And you will hear of wars and rumors of wars. See that you are not alarmed, for this must take place, but the end is not yet. 7 Fornation will rise against nation, and kingdom against kingdom, and there will be famines and earthquakes in various places. 8 All these are but the beginning of the birth pains.\n9 “Then they will deliver you up to tribulation and put you to death, and you will be hated by all nations for my name’s sake. 10 And then many will fall away[a] and betray one another and hate one another. 11 And many false prophets will arise and lead many astray. 12 And because lawlessness will be increased, the love of many will grow cold. 13 But the one who endures to the end will be saved. 14 And this gospel of the kingdom will be proclaimed throughout the whole world as a testimony to all nations, and then the end will come.\nThe Abomination of Desolation\n15 “So when you see the abomination of desolation spoken of by the prophet Daniel, standing inthe holy place (let the reader understand), 16 then let those who are in Judea flee to the mountains. 17 Let the one who is on the housetop not go down to take what is in his house,18 and let the one who is in the field not turn back to take his cloak. 19 And alas for women who are pregnant and for those who are nursing infants in those days! 20 Pray that your flight may not be in winter or on a Sabbath. 21 For then there will be great tribulation, such as has not been from the beginning of the world until now, no, and never will be. 22 And if those days had not been cut short, no human being would be saved. But for the sake of the elect those days will be cut short. 23 Then if anyone says to you, ‘Look, here is the Christ!’ or ‘There he is!’ do not believe it. 24 For false christs and false prophets will arise and perform great signs and wonders, so as to lead astray, if possible, even the elect. 25 See, I have told you beforehand. 26 So, if they say to you, ‘Look, he is in the wilderness,’ do not go out. If they say, ‘Look, he is in the inner rooms,’ do not believe it. 27 For as the lightning comes from the east and shines as far as the west, so will be the coming of the Son of Man. 28 Wherever the corpse is, there the vultures will gather.\nThe Coming of the Son of Man\n29 “Immediately after the tribulation of those days the sun will be darkened, and the moon will not give its light, and the stars will fall from heaven, and the powers of the heavens will be shaken. 30 Then will appear in heaven the sign of the Son of Man, and then all the tribes of the earth will mourn, and they will see the Son of Man coming on the clouds of heaven with power and great glory. 31 And he will send out his angels with a loud trumpet call, and they will gatherhis elect from the four winds, from one end of heaven to the other.\nThe Lesson of the Fig Tree\n32 “From the fig tree learn its lesson: as soon as its branch becomes tender and puts out its leaves, you know that summer is near. 33 So also, when you see all these things, you know that he is near, at the very gates. 34 Truly, I say to you, this generation will not pass away until all these things take place. 35 Heaven and earth will pass away, but my words will not pass away.\nNo One Knows That Day and Hour\n36 “But concerning that day and hour no one knows, not even the angels of heaven, nor the Son,[b] but the Father only. 37 For as were the days of Noah, so will be the coming of the Son of Man.38 For as in those days before the flood they were eating and drinking, marrying and giving in marriage, until the day when Noah entered the ark, 39 and they were unaware until the flood came and swept them all away, so will be the coming of the Son of Man. 40 Then two men will be in the field; one will be taken and one left. 41 Two women will be grinding at the mill; one will be taken and one left. 42 Therefore, stay awake, for you do not know on what day your Lord is coming. 43 But know this, that if the master of the house had known in what part of the nightthe thief was coming, he would have stayed awake and would not have let his house be broken into. 44 Therefore you also must be ready, for the Son of Man is coming at an hour you do not expect.\n45 “Who then is the faithful and wise servant,[c] whom his master has set over his household, to give them their food at the proper time? 46 Blessed is that servant whom his master will find so doing when he comes. 47 Truly, I say to you, he will set him over all his possessions. 48 But if that wicked servant says to himself, ‘My master is delayed,’ 49 and begins to beat his fellow servants[d] and eats and drinks with drunkards, 50 the master of that servant will come on a day when he does not expect him and at an hour he does not know 51 and will cut him in pieces and put him with the hypocrites. In that place there will be weeping and gnashing of teeth.']	['<urn:uuid:c9e2606b-0fed-4214-b91f-558fb257cc4e>']	open-ended	with-premise	long-search-query	similar-to-document	single-doc	expert	2025-05-12T23:47:20.322175	10	73	1943
65	standards verification differ united states japan meat labels	In the United States, the USDA does not perform on-farm audits to verify animal welfare claims and relies solely on producer-supplied information, allowing producers to set their own definitions. In contrast, for Japanese organic certification (JAS), operations must undergo mandatory inspections to the JAS organic standards, with CCOF inspectors verifying compliance to JAS standards for certification.	['Washington, DC—As families across the country begin planning their Thanksgiving feasts, consumers interested in purchasing higher-welfare or sustainably raised turkeys will be confronted with a slew of misleading labels sanctioned by the USDA.\nAccording to a new report by the Animal Welfare Institute (AWI), “Label Confusion 2.0: How the USDA Allows Producers to Use ‘Humane’ and ‘Sustainable’ Claims on Meat Packages and Deceive Consumers,” the USDA continues to allow producers to deceive consumers by making animal welfare and environmental claims on meat and poultry packaging without sufficient supporting evidence.\nThe report analyzes a selection of the agency’s label approval files from 2014 to 2018 in response to Freedom of Information Act requests submitted by AWI. It reveals how the USDA’s label approval process continues to fail consumers, five years after AWI compiled a similar report documenting widespread abuse of the system.\n“The system is easily manipulated by producers who want to make higher-welfare claims on their packages and charge a premium without improving the treatment of animals raised under their care,” said Erin Thompson, staff attorney for AWI’s farm animal program. “Because of the USDA’s lack of oversight, consumers are often thwarted in their attempts to use labels to guide their food-buying decisions.”\nFor the current report, AWI evaluated government label approvals for a total of 23 claims on 19 meat and poultry products. These claims include “socially raised,” “humanely raised,” “free raised,” and “sustainably farmed.” Although the USDA requires producers to define animal raising claims on their packaging, the report found that the agency’s lack of enforcement means that producers can continue to use definitions that are often irrelevant or too vague to inform consumers. Moreover, the USDA regularly approves claims without sufficient verification that producers actually meet these definitions. In response to AWI’s FOIA request, the USDA was unable to provide substantiation for half (12) of the claims. As a result, all 12 received an “F” grade under AWI’s scoring tool.\nTwo turkey product lines covered in the report, Diestel Turkey Ranch Organic Turkey Products and Empire Kosher Natural Ground White Turkey, received “D” grades.\nFor instance, the USDA approved a ”humanely raised” claim for Empire Kosher, a turkey producer headquartered in Mifflintown, Pa., based on an affidavit containing only two sentences pertaining to the claim. Seven other producer claims reviewed by AWI had a similarly vague affidavit. Other producers used third-party certifications to bolster their claims, even though certificates appeared to be expired at the time of application or the certifying entity didn’t list the producer as certified on its website.\nOther report highlights:\n- The current label approval process harms farmers who make accurate claims. Producers who make animal welfare and/or environmental claims but do not adhere to higher standards and are not independently certified are able to avoid the cost of both certification and better production, yet still reap the benefits of the claim by selling products at a premium price (or undercutting the price of products produced at higher standards).\n- While the USDA has the authority to deny false or misleading labels under the Federal Meat Inspection Act and the Poultry Products Inspection Act, the department does not perform on-farm audits to assess whether or not producers comply with the claims they wish to place on their labels. Rather, the USDA relies solely on information supplied by producers to determine whether claims related to humane animal treatment and sustainable agricultural practices are accurate and appropriate for use on a meat label. Most producers refuse to make their standards available to the public.\nAccording to a 2018 AWI national consumer survey, a large majority of consumers who frequently purchase meat or poultry products believe that producers should not be allowed to set their own definitions for claims about how farm animals are raised and that farms should be inspected to verify such claims.\nIn 2014, AWI petitioned the USDA to amend its labeling regulations to require third-party certification of animal welfare and environmental stewardship claims to improve transparency and consistency. After waiting more than four years, AWI sued the USDA in 2018 for failing to respond to this petition. In February of this year, the USDA declined the petition in part because of producers’ conflicting definitions of animal-raising claims. AWI finds this decision troubling, as it is the department’s duty to promote consistent definitions to avoid misleading labels.\nTo help consumers avoid contributing to animal suffering, AWI publishes “A Consumer’s Guide to Food Labels and Animal Welfare.” A recently updated version of the guide divides claims about how farm animals are raised into “best choices,” (such as Certified Animal Welfare Approved by AGW and Certified Grassfed by AGW), “next best choices,” “potentially good choices,” and “beware of these labels.”\nVague, subjective animal raising claims, such as “natural,” “thoughtfully raised,” and “ethically raised,” are meaningless when it comes to animal welfare in large part because there are no regulatory standards or third-party certification programs to validate these labels. AWI urges consumers to be wary of these marketing tactics.\nMargie Fishman, (202) 446-2128, [email protected]', 'Exporting To and From Japan\nIf you would like to export organic products to Japan, CCOF can help. On September 26, 2013, the USDA National Organic Program (NOP) and the Japan Ministry of Agriculture, Food and Fisheries (MAFF) signed a historic organic standards equivalency arrangement, going in to effect January 1, 2014. This has eased the process for organic exports and eliminated differences in organic standards between the two nations.\nAdditionally, in 2013, MAFF also created new opportunities for the use of Japan’s organic seal, called the “JAS seal.”\nUnder the terms of this agreement:\n- Products from the United States that are certified to NOP standards will be recognized as equivalent to the Japanese Agricultural Standards (JAS) and may be shipped to Japan. Each shipment must be accompanied by a TM-11 certifier-issued import certificate.\n- Livestock and alcohol products are not covered under this agreement.\n- Product from Japan that is certified to the JAS Organic Program may be shipped to the United States and marketed as organic. Each shipment will require a Certificate of Inspection from the Japanese certifier.\n- Products shipped from the United States and sold as organic in Japan are required to display the JAS seal. The seal may be applied in Japan by a JAS-certified importer or applied by U.S. companies through a consignment contract with a JAS-certified importer.\n- Use of the USDA organic seal is voluntary as long as the products meet USDA labeling requirements. The accredited certifier must also be identified on the label.\nYou need to enroll in the Global Market Access (GMA) program for Japan export if you do any of the following:\n- Want to maximize market opportunities and ensure your products will be accepted by most foreign markets and buyers\n- Export CCOF certified organic products to Japan from the United States\n- Design labels for products that will be sold in Japan\n- Sell CCOF certified organic products to any buyer who requires international verification certification\nLearn more about the CCOF Global Market Access program.\nAdditional equivalency arrangement information:\nLabeling Requirements and Use of the JAS Seal\nAll products shipped to Japan under the U.S.-MAFF Organic Equivalency Arrangement must meet the JAS labeling requirements. Send all labels to CCOF for approval prior to printing. To learn more, read MAFF’s JAS labeling requirements.\nU.S. Exporters can meet the JAS labeling requirements in three ways.\n- Exporters who have a JAS Seal Consignment Contract with a JAS-certified importer may apply the JAS seal directly to their products. This allows for pre-printed labels for bulk or retail products and more effective recognition of organic status within Japan. CCOF can help you navigate the consignment contract and provide required reporting under the JAS system. Note, the JAS seal is unique to each JAS certifier.\n- Exporters who do not have a JAS Seal Consignment Contract with a JAS-certified importer cannot apply the JAS seal to their products prior to export. A JAS-certified importer must import the product, and that importer must apply the seal to the product prior to sale within Japan.\n- Exporters can obtain direct JAS certification through a JAS-accredited certifier. With direct JAS certification, the exporter can apply the JAS seal directly to their product prior to shipping without a Consignment Contract. CCOF has observed that this option is time consuming and costly but will allow the ability to use only one seal version on all products.\nJAS Seal Consignment Contract\nU.S. exporters can sign a JAS Seal Consignment Contract with a JAS-certified importer to apply the JAS seal to USDA NOP-certified organic products in the United States. Under this system, the U.S. exporter must identify a responsible employee, undergo some minor training, and maintain records of the number of seals applied to products and the number of JAS-labeled products shipped to Japan.\nWith enrollment in the GMA Japan export program, we will guide you through the Consignment Contract process and facilitate maintenance of the required records through the exporting process. CCOF has analyzed the process and provides a variety of tools and processes based on MAFF’s instructions. See below.\nConsignment Contract Process\n- Contact your JAS-certified importer in Japan and sign the JAS Seal Consignment Contract. Send a copy of the signed contract to CCOF.\n- Complete the training for attaching JAS seals and send the signed documents to your importer for their records. Send a copy to CCOF.\n- Your importer will send their JAS seal for you to use on your products.\n- Each JAS seal is specific to the name of the importer’s certifier, so you must be careful to apply the correct seal if you have multiple contracts.\n- You are only allowed to apply the JAS seal on products destined to the specific importer you have subcontracted with.\n- Submit the new labels for international sales to CCOF.\n- Apply the JAS seal to the products that your importer has requested.\n- Use the Report of Attached JAS Seals to document how many seals were attached for each shipment. Send this document to CCOF with your TM-11 request.\n- Send your shipment to your importer along with a TM-11 document for export to Japan and the report of attached JAS seals. CCOF will keep copies of these documents for your recordkeeping requirement.\nConsignment Contract Process Graphic\nApplying the JAS Seal through Direct JAS Certification\nGetting certified to the JAS standard allows you as a U.S. exporter to directly apply the JAS seal before exporting your product to Japan. CCOF offers a program to help facilitate your JAS certification with our partner certifier in Japan, Japan Certification Services (JCS). With the JAS certification program, CCOF will:\n- Facilitate completion of the initial application for JAS certification and send to JCS for processing\n- Once the application is accepted, a CCOF inspector will inspect your operation to the JAS organic standards.\n- Facilitate ongoing paperwork completion and annual inspections to the JAS organic standards\nInformation for U.S. Operations Shipping Products to Japan\nIn order to export your product to Japan, you will need to be enrolled in CCOF’s Global Market Access program for MAFF/USDA compliance. Once your product is in the program with a status of compliant, you can sell your goods to Japan, following all labeling requirements.\nYou are required to send an export certificate, also referred to as a certificate of import, with each shipment of product bound for Japan, stating specific details about the shipment. You must enroll in the GMA Japan export program to request an export certificate. For additional information on exporting, check out our exporter guidance information page.\nImporting Product from Japan\nWould you like to import Japanese organic product or ingredients? Japanese organic products sold in the United States must meet the following requirements:\n- Products must be either produced within Japan or have had final processing or packaging occur within Japan.\n- Products must meet USDA NOP labeling requirements.\n- Products must travel with an import certificate that has been completed by a MAFF-accredited certifying agent.']	['<urn:uuid:089e8c35-f061-4012-98f2-a0a57c18ccb3>', '<urn:uuid:05230764-fd44-49ff-9ef1-3381516af5f5>']	factoid	direct	long-search-query	distant-from-document	comparison	novice	2025-05-12T23:47:20.322175	8	56	2010
66	maintenance planner vs investment fund manager skills	Maintenance planners and investment fund managers share some core skills but have distinct requirements. Both need strong analytical thinking and computer literacy. Maintenance planners need plant operations understanding, planning techniques knowledge, and interpersonal skills for stakeholder management. Investment fund managers require more extensive financial expertise, including economics, accounting, and market analysis. They also need skills in portfolio management, risk analysis, and regulatory compliance. While maintenance planners focus on plant efficiency and resource utilization, investment managers focus on maximizing investment returns and managing client relationships.	"['RS Component’s Richard Jeffers pinpoints the skills needed for effective planning and maintenance, supporting Maintenance, Repair and Operations (MRO)\nEffective maintenance planning and scheduling is probably the single most important area to get right in an effective maintenance organisation. Yet it is consistently dismissed as an add-on function that can be removed in times of budget constraint and often assigned to the person who is no longer able to work on the tools, without any consideration to their capability in the role. Getting the right capability in the planning and scheduling role will transform a poor maintenance function from being trapped in a reactive cycle into one where work, corrective or preventive, is executed effectively.\nA plan without a schedule is simply a wish list\nPlanning is the process of deciding what tasks should be completed, their priorities, an estimate of duration and how the task should be conducted. Scheduling, on the other hand, is the process of deciding when and who should be assigned the task and ensuring that all the available resources, assets, labour and spares are available to complete it.\nThe primary purpose of the maintenance planner is to ensure maximum utilisation of available maintenance resources to execute the agreed Planned Preventive Maintenance (PPM) schedules and corrective works at the lowest total cost with minimum plant downtime.\nCommon pitfalls in effective maintenance planning and scheduling\n- Allowing all work to be done reactively. Except in the event of a critical plant breakdown, even corrective work is better done when it is scheduled. Responding immediately to all requests means you will never increase maintenance maturity.\n- Choosing the wrong person as planner. The person in the role of maintenance planner has often been assigned to it as they are unable to fulfil the requirements of another role, not because they have the skill to be a planner. A planner should ideally:\n- Have a good understanding of the requirements of the maintenance work itself\n- Have a good understanding of planning and scheduling techniques\n- Have good interpersonal skills to help manage diverse stakeholders\n- The ability to work with the operators – and value their opinions\n- High levels of computer literacy\n- The ability to work with complex data\n- Not training the planner. It is unlikely that the planner will have the full range of knowledge, skills and experience required to be successful. Reliance upon on-the-job training by experience will be costly in terms of low labour utilisation of the technician pool.\n- Spending time at a desk not on the plant. An effective planner will see his desk as a necessary evil, but will spend the time on the plant, building their understanding of the tasks, the skills of the team, the spares requirements, the time tasks really take and the effectiveness of the planned work to mitigate the impact of failure.\n- Not effectively scheduling. So often, the PPM schedule is just a job list to be executed if the opportunity arises. Without bringing together the plant, resources, spares and making an individual accountable for completion, success will happen by chance, not by design.\n- Not having any KPIs. The planner should be tracking the maintenance backlog, labour utilisation and PPM completion rate as a minimum. Without these bases measures there is no way to see whether they are adding value.\n- Not seeing operations as the customer. Too often you see conflict between operations and maintenance, with maintenance forgetting that they are there to provide a service of high uptime to the user.\n- No, or unclear, maintenance workflows. Unless there is a common understanding of how tasks are created, validated, planned, scheduled and executed, and what meetings are in place to run the workflow, the chances of success are low.\nMaintenance planning and scheduling should be the first area of focus on any maintenance maturity improvement programme. Far too frequently, it becomes one of the last areas addressed while the site discusses how to break out of the reactive cycle.', 'Summary Report for:\n11-9199.03 - Investment Fund Managers\nPlan, direct, or coordinate investment strategy or operations for a large pool of liquid assets supplied by institutional investors or individual investors.\nSample of reported job titles: Assistant Vice President, Investment Analysis; Equity Analyst; Fixed Income Portfolio Manager; Investment Analyst; Lead Portfolio Manager; Portfolio Manager; Senior Investment Analyst; Senior Portfolio Manager; Vice President and Portfolio Manager; Vice President, Fixed Income\nTasks | Tools & Technology | Knowledge | Skills | Abilities | Work Activities | Detailed Work Activities | Work Context | Job Zone | Education | Credentials | Interests | Work Styles | Work Values | Wages & Employment | Job Openings\n- Manage investment funds to maximize return on client investments.\n- Select specific investments or investment mixes for purchase by an investment fund.\n- Monitor financial or operational performance of individual investments to ensure portfolios meet risk goals.\n- Select or direct the execution of trades.\n- Develop or implement fund investment policies or strategies.\n- Perform or evaluate research, such as detailed company or industry analyses, to inform financial forecasting, decision making, or valuation.\n- Present investment information, such as product risks, fees, or fund performance statistics.\n- Develop, implement, or monitor security valuation policies.\n- Meet with investors to determine investment goals or to discuss investment strategies.\n- Attend investment briefings or consult financial media to stay abreast of relevant investment markets.\n- Prepare for and respond to regulatory inquiries.\n- Evaluate the potential of new product developments or market opportunities, according to factors such as business plans, technologies, or market potential.\n- Hire or evaluate staff.\n- Monitor regulatory or tax law changes to ensure fund compliance or to capitalize on development opportunities.\n- Develop or direct development of offering documents or marketing materials.\n- Analyze acquisitions to ensure conformance with strategic goals or regulatory requirements.\n- Verify regulatory compliance of transaction reporting.\n- Review offering documents or marketing materials to ensure regulatory compliance.\n- Identify group or individual target investors for a specific fund.\n- Direct activities of accounting or operations departments.\nTools & Technology\nTools used in this occupation:\n- Desktop computers\n- Notebook computers — Laptop computers\n- Personal computers\n- Special purpose telephones — Multiline telephone systems\n- Teleconference equipment — Teleconferencing equipment\n- Videoconferencing systems — Videoconferencing equipment\nTechnology used in this occupation:\n- Accounting software — Financial accounting software\n- Analytical or scientific software — Risk analysis software; SAS software ; Statistical analysis software\n- Computer aided design CAD software — Autodesk AutoCAD Blue Sky\n- Data base user interface and query software — Microsoft Access ; Structured query language SQL\n- Document management software — ReadSoft software\n- Electronic mail software — Microsoft Outlook\n- Enterprise resource planning ERP software — Oracle Hyperion software ; SAP software\n- Financial analysis software — Portfolio analysis software; SunGard Financial Systems AddVantage\n- Graphics or photo imaging software — Microsoft Visio\n- Internet browser software — Web browser software\n- Map creation software — Microsoft MapPoint\n- Office suite software — Microsoft Office software\n- Presentation software — Microsoft PowerPoint\n- Project management software — Microsoft Project\n- Spreadsheet software — Microsoft Excel\n- Word processing software — Microsoft Word\nHot Technology — a technology requirement frequently included in employer job postings.\n- Economics and Accounting — Knowledge of economic and accounting principles and practices, the financial markets, banking and the analysis and reporting of financial data.\n- English Language — Knowledge of the structure and content of the English language including the meaning and spelling of words, rules of composition, and grammar.\n- Mathematics — Knowledge of arithmetic, algebra, geometry, calculus, statistics, and their applications.\n- Customer and Personal Service — Knowledge of principles and processes for providing customer and personal services. This includes customer needs assessment, meeting quality standards for services, and evaluation of customer satisfaction.\n- Administration and Management — Knowledge of business and management principles involved in strategic planning, resource allocation, human resources modeling, leadership technique, production methods, and coordination of people and resources.\n- Law and Government — Knowledge of laws, legal codes, court procedures, precedents, government regulations, executive orders, agency rules, and the democratic political process.\n- Computers and Electronics — Knowledge of circuit boards, processors, chips, electronic equipment, and computer hardware and software, including applications and programming.\n- Sales and Marketing — Knowledge of principles and methods for showing, promoting, and selling products or services. This includes marketing strategy and tactics, product demonstration, sales techniques, and sales control systems.\n- Active Listening — Giving full attention to what other people are saying, taking time to understand the points being made, asking questions as appropriate, and not interrupting at inappropriate times.\n- Critical Thinking — Using logic and reasoning to identify the strengths and weaknesses of alternative solutions, conclusions or approaches to problems.\n- Reading Comprehension — Understanding written sentences and paragraphs in work related documents.\n- Judgment and Decision Making — Considering the relative costs and benefits of potential actions to choose the most appropriate one.\n- Speaking — Talking to others to convey information effectively.\n- Active Learning — Understanding the implications of new information for both current and future problem-solving and decision-making.\n- Complex Problem Solving — Identifying complex problems and reviewing related information to develop and evaluate options and implement solutions.\n- Writing — Communicating effectively in writing as appropriate for the needs of the audience.\n- Monitoring — Monitoring/Assessing performance of yourself, other individuals, or organizations to make improvements or take corrective action.\n- Mathematics — Using mathematics to solve problems.\n- Systems Analysis — Determining how a system should work and how changes in conditions, operations, and the environment will affect outcomes.\n- Systems Evaluation — Identifying measures or indicators of system performance and the actions needed to improve or correct performance, relative to the goals of the system.\n- Time Management — Managing one\'s own time and the time of others.\n- Coordination — Adjusting actions in relation to others\' actions.\n- Persuasion — Persuading others to change their minds or behavior.\n- Instructing — Teaching others how to do something.\n- Negotiation — Bringing others together and trying to reconcile differences.\n- Social Perceptiveness — Being aware of others\' reactions and understanding why they react as they do.\n- Deductive Reasoning — The ability to apply general rules to specific problems to produce answers that make sense.\n- Oral Comprehension — The ability to listen to and understand information and ideas presented through spoken words and sentences.\n- Oral Expression — The ability to communicate information and ideas in speaking so others will understand.\n- Written Comprehension — The ability to read and understand information and ideas presented in writing.\n- Inductive Reasoning — The ability to combine pieces of information to form general rules or conclusions (includes finding a relationship among seemingly unrelated events).\n- Information Ordering — The ability to arrange things or actions in a certain order or pattern according to a specific rule or set of rules (e.g., patterns of numbers, letters, words, pictures, mathematical operations).\n- Mathematical Reasoning — The ability to choose the right mathematical methods or formulas to solve a problem.\n- Problem Sensitivity — The ability to tell when something is wrong or is likely to go wrong. It does not involve solving the problem, only recognizing there is a problem.\n- Speech Clarity — The ability to speak clearly so others can understand you.\n- Written Expression — The ability to communicate information and ideas in writing so others will understand.\n- Near Vision — The ability to see details at close range (within a few feet of the observer).\n- Number Facility — The ability to add, subtract, multiply, or divide quickly and correctly.\n- Speech Recognition — The ability to identify and understand the speech of another person.\n- Category Flexibility — The ability to generate or use different sets of rules for combining or grouping things in different ways.\n- Flexibility of Closure — The ability to identify or detect a known pattern (a figure, object, word, or sound) that is hidden in other distracting material.\n- Fluency of Ideas — The ability to come up with a number of ideas about a topic (the number of ideas is important, not their quality, correctness, or creativity).\n- Originality — The ability to come up with unusual or clever ideas about a given topic or situation, or to develop creative ways to solve a problem.\n- Selective Attention — The ability to concentrate on a task over a period of time without being distracted.\n- Perceptual Speed — The ability to quickly and accurately compare similarities and differences among sets of letters, numbers, objects, pictures, or patterns. The things to be compared may be presented at the same time or one after the other. This ability also includes comparing a presented object with a remembered object.\n- Getting Information — Observing, receiving, and otherwise obtaining information from all relevant sources.\n- Analyzing Data or Information — Identifying the underlying principles, reasons, or facts of information by breaking down information or data into separate parts.\n- Making Decisions and Solving Problems — Analyzing information and evaluating results to choose the best solution and solve problems.\n- Interacting With Computers — Using computers and computer systems (including hardware and software) to program, write software, set up functions, enter data, or process information.\n- Processing Information — Compiling, coding, categorizing, calculating, tabulating, auditing, or verifying information or data.\n- Identifying Objects, Actions, and Events — Identifying information by categorizing, estimating, recognizing differences or similarities, and detecting changes in circumstances or events.\n- Communicating with Supervisors, Peers, or Subordinates — Providing information to supervisors, co-workers, and subordinates by telephone, in written form, e-mail, or in person.\n- Communicating with Persons Outside Organization — Communicating with people outside the organization, representing the organization to customers, the public, government, and other external sources. This information can be exchanged in person, in writing, or by telephone or e-mail.\n- Organizing, Planning, and Prioritizing Work — Developing specific goals and plans to prioritize, organize, and accomplish your work.\n- Updating and Using Relevant Knowledge — Keeping up-to-date technically and applying new knowledge to your job.\n- Estimating the Quantifiable Characteristics of Products, Events, or Information — Estimating sizes, distances, and quantities; or determining time, costs, resources, or materials needed to perform a work activity.\n- Establishing and Maintaining Interpersonal Relationships — Developing constructive and cooperative working relationships with others, and maintaining them over time.\n- Interpreting the Meaning of Information for Others — Translating or explaining what information means and how it can be used.\n- Thinking Creatively — Developing, designing, or creating new applications, ideas, relationships, systems, or products, including artistic contributions.\n- Judging the Qualities of Things, Services, or People — Assessing the value, importance, or quality of things or people.\n- Developing Objectives and Strategies — Establishing long-range objectives and specifying the strategies and actions to achieve them.\n- Evaluating Information to Determine Compliance with Standards — Using relevant information and individual judgment to determine whether events or processes comply with laws, regulations, or standards.\n- Documenting/Recording Information — Entering, transcribing, recording, storing, or maintaining information in written or electronic/magnetic form.\n- Developing and Building Teams — Encouraging and building mutual trust, respect, and cooperation among team members.\n- Selling or Influencing Others — Convincing others to buy merchandise/goods or to otherwise change their minds or actions.\n- Training and Teaching Others — Identifying the educational needs of others, developing formal educational or training programs or classes, and teaching or instructing others.\n- Coaching and Developing Others — Identifying the developmental needs of others and coaching, mentoring, or otherwise helping others to improve their knowledge or skills.\nDetailed Work Activities\n- Direct financial operations.\n- Direct organizational operations, projects, or services.\n- Monitor external affairs or events affecting business operations.\n- Monitor organizational procedures to ensure proper functioning.\n- Develop organizational policies or programs.\n- Implement organizational process or policy changes.\n- Approve expenditures.\n- Examine marketing materials to ensure compliance with policies or regulations.\n- Determine operational compliance with regulations or standards.\n- Advise others on business or operational matters.\n- Analyze forecasting data to improve business decisions.\n- Evaluate employee performance.\n- Maintain knowledge of current developments in area of expertise.\n- Develop promotional materials.\n- Coordinate with external parties to exchange information.\n- Hire personnel.\n- Direct sales, marketing, or customer service activities.\n- Communicate organizational information to customers or other stakeholders.\n- Examine financial records to ensure compliance with policies or regulations.\n- Electronic Mail — 100% responded “Every day.”\n- Telephone — 92% responded “Every day.”\n- Duration of Typical Work Week — 87% responded “More than 40 hours.”\n- Face-to-Face Discussions — 83% responded “Every day.”\n- Spend Time Sitting — 75% responded “Continually or almost continually.”\n- Indoors, Environmentally Controlled — 87% responded “Every day.”\n- Level of Competition — 61% responded “Extremely competitive.”\n- Freedom to Make Decisions — 63% responded “A lot of freedom.”\n- Structured versus Unstructured Work — 59% responded “A lot of freedom.”\n- Frequency of Decision Making — 66% responded “Every day.”\n- Impact of Decisions on Co-workers or Company Results — 47% responded “Important results.”\n- Contact With Others — 51% responded “Constant contact with others.”\n- Importance of Being Exact or Accurate — 44% responded “Extremely important.”\n- Time Pressure — 40% responded “Every day.”\n- Work With Work Group or Team — 47% responded “Extremely important.”\n- Consequence of Error — 32% responded “Extremely serious.”\n- Responsibility for Outcomes and Results — 40% responded “Very high responsibility.”\n- Coordinate or Lead Others — 32% responded “Very important.”\n- Letters and Memos — 41% responded “Once a week or more but not every day.”\n- Deal With External Customers — 29% responded “Extremely important.”\n|Title||Job Zone Five: Extensive Preparation Needed|\n|Education||Most of these occupations require graduate school. For example, they may require a master\'s degree, and some require a Ph.D., M.D., or J.D. (law degree).|\n|Related Experience||Extensive skill, knowledge, and experience are needed for these occupations. Many require more than five years of experience. For example, surgeons must complete four years of college and an additional five to seven years of specialized medical training to be able to do their job.|\n|Job Training||Employees may need some on-the-job training, but most of these occupations assume that the person will already have the required skills, knowledge, work-related experience, and/or training.|\n|Job Zone Examples||These occupations often involve coordinating, training, supervising, or managing the activities of others to accomplish goals. Very advanced communication and organizational skills are required. Examples include librarians, lawyers, astronomers, biologists, clergy, surgeons, and veterinarians.|\n|SVP Range||(8.0 and above)|\nPercentage of Respondents\n|Education Level Required|\nInterest code: EC\n- Enterprising — Enterprising occupations frequently involve starting up and carrying out projects. These occupations can involve leading people and making many decisions. Sometimes they require risk taking and often deal with business.\n- Conventional — Conventional occupations frequently involve following set procedures and routines. These occupations can include working with data and details more than with ideas. Usually there is a clear line of authority to follow.\n- Integrity — Job requires being honest and ethical.\n- Analytical Thinking — Job requires analyzing information and using logic to address work-related issues and problems.\n- Stress Tolerance — Job requires accepting criticism and dealing calmly and effectively with high stress situations.\n- Achievement/Effort — Job requires establishing and maintaining personally challenging achievement goals and exerting effort toward mastering tasks.\n- Dependability — Job requires being reliable, responsible, and dependable, and fulfilling obligations.\n- Persistence — Job requires persistence in the face of obstacles.\n- Initiative — Job requires a willingness to take on responsibilities and challenges.\n- Attention to Detail — Job requires being careful about detail and thorough in completing work tasks.\n- Cooperation — Job requires being pleasant with others on the job and displaying a good-natured, cooperative attitude.\n- Self Control — Job requires maintaining composure, keeping emotions in check, controlling anger, and avoiding aggressive behavior, even in very difficult situations.\n- Leadership — Job requires a willingness to lead, take charge, and offer opinions and direction.\n- Adaptability/Flexibility — Job requires being open to change (positive or negative) and to considerable variety in the workplace.\n- Independence — Job requires developing one\'s own ways of doing things, guiding oneself with little or no supervision, and depending on oneself to get things done.\n- Innovation — Job requires creativity and alternative thinking to develop new ideas for and answers to work-related problems.\n- Social Orientation — Job requires preferring to work with others rather than alone, and being personally connected with others on the job.\n- Concern for Others — Job requires being sensitive to others\' needs and feelings and being understanding and helpful on the job.\n- Achievement — Occupations that satisfy this work value are results oriented and allow employees to use their strongest abilities, giving them a feeling of accomplishment. Corresponding needs are Ability Utilization and Achievement.\n- Recognition — Occupations that satisfy this work value offer advancement, potential for leadership, and are often considered prestigious. Corresponding needs are Advancement, Authority, Recognition and Social Status.\n- Working Conditions — Occupations that satisfy this work value offer job security and good working conditions. Corresponding needs are Activity, Compensation, Independence, Security, Variety and Working Conditions.\nWages & Employment Trends\nMedian wages data collected from Managers, All Other.\nEmployment data collected from Managers, All Other.\nIndustry data collected from Managers, All Other.\n|Median wages (2015)||$50.41 hourly, $104,850 annual|\n|Employment (2014)||986,000 employees|\n|Projected growth (2014-2024)||Slower than average (2% to 4%)|\n|Projected job openings (2014-2024)||255,400|\n|Top industries (2014)|\nSource: Bureau of Labor Statistics 2015 wage data and 2014-2024 employment projections . ""Projected growth"" represents the estimated change in total employment over the projections period (2014-2024). ""Projected job openings"" represent openings due to growth and replacement.']"	['<urn:uuid:8f2fa964-3b92-48bd-b361-1a4eb54e07fc>', '<urn:uuid:17f66bea-d135-43c3-bd78-161b6b356c2a>']	open-ended	with-premise	short-search-query	similar-to-document	comparison	expert	2025-05-12T23:47:20.322175	7	84	3665
67	cash flow reports frequency and main problems	Companies typically produce financial reports including cash flows on a weekly, monthly and quarterly basis. Cash flow problems are a major concern, as insufficient cash flow management is responsible for up to 82% of small business failures.	['Create one or more reports that return data from your tables. Typically, you’ll use SUMIFS, SUMPRODUCT, INDEX-MATCH, AGGREGATE, SUM, and/or array formulas to return this data. Most Board members have widely diverse backgrounds and very little time. I would say you need to be concise but include of course the KPI’s relevent to your business. A line by line P&L will contain too much detail – but key lines compared to your budget, and/or forecast will be necessary – Month, quarter and YTD. A comparison with prior year actuals can also be of interest.\nMaintaining an efficient, productive work environment, and ensuring that you can identify any employee discrepancies or issues is critical to being proactive about business growth. Now we will take a look at some financial statements examples to get a clearer picture of what can be tracked in weekly intervals. Generally, costs should not be looked upon purely on the base of black and white. If sales and marketing cause cost increment, maybe they also deliver high volumes of revenue so the balance is healthy, and not negative. An indicator over 1 means that the company is making a profit above all expenses while a coefficient below 1 will indicate that the company is losing money.\nMost companies produce weekly, monthly and quarterly financial reports, which include information such as profit and loss statements, a balance sheet, accounts payable, accounts receivable and a statement of cash flows. A financial report is an informational document about the financial health of a company or organization, which includes a balance sheet, an income statement and a statement of cash flows. Financial reports are often reviewed and analyzed by business managers, boards of directors, investors, financial analysts and government agencies. Reports must be prepared and disseminated in a timely manner, and they must be accurate and clear. Although creating a financial report may seem daunting, the accounting required is not all that difficult. Here are five key financial reports that can give business owners valuable perspective on the growth and development of their businesses.\nMonthly Management Accounts Template\nWhen you make sure to all is for the same objective of the documents. You can also include the name of reports like ABC organization and strategy report.\nIf you move with your perspective and discuss all objectives, reports management works best. Also analysis with some of the necessary recommendations and supporting statistics or projects. It enables event organizers to adequately plan for an event by showing the cost of each item and the expenses incurred or expected to be incurred.\n(The ratio can be calculated by dividing the period-ending balance of accounts receivable by revenue for that period, then multiplying the result by the number of days in the period). Looking at that ratio over several periods can indicate whether receivables are piling up faster than sales or faster than the company’s ability to collect. You can also compare that ratio to Accounts Payable Days (calculated by dividing the period-ending balance of accounts payable by the period’s cost of goods sold, multiplied by the number of days in the period). AP Days indicates how long it’s taking the business to pay suppliers, so like AR Days, it has a major influence on the company’s cash situation. Like other financial ratios, both AR Days and AP Days can vary widely by industry.\nUsually, it keeps the track of mandatory information of thirty days. As well as the version of Microsoft word and specifically Microsoft Excel. Learn about the eight core bookkeeping jobs, from data entry to bank rec, reporting and tax prep.\nThis is measured by dividing your business’s net income by your shareholder’s equity. These KPIs are particularly helpful to benchmark your company against other businesses. It doesn’t include revenue earned from investments or the effects of taxes. To manage financial performance in comparison to a set target, you can also use a modern KPI scorecard. That way, you will not only monitor your performance but see where you stand against your goals and objectives. In the overview, we can see that scatter plots and bubble plots will work best in depicting the relationship of the data while the column chart or histogram in the distribution of data.\nWho Creates Financial Reports?\nThis KPI is a crucial measurement of production efficiency within your organization. Costs may include the price of labor and materials but exclude distribution and rent expenses. If customers are unsatisfied, it can also cause damages from outside of your team that can, consequently, influence the financial performance as well. If you see that most costs come from administrational activities, you should consider automating tasks as much as possible. By utilizing self service analytics tools, each professional in your team will be equipped to explore and generate insights on their own, without burdening other departments and saving countless working hours. The quick ratio/acid test report example is worth tracking – by measuring these particular metrics, you’ll be able to understand whether your business is scalable, and if not – which measures you need to take to foster growth.\nFor example, you can schedule your financial statement report on a daily, weekly, monthly, or yearly basis and send it to the selected recipients automatically. Moreover, you can share your dashboard or select certain viewers that have access only to the filters you have assigned. Finally, an embedded option will enable you to customize your dashboards and reports within your own application and white label based on your branding requirements. You can learn more about this point in our article where we explain in detail about the usage and benefits of professional embedded BI tools. No matter if you’re a small business or large enterprise, you need to clearly define your goals and what are you trying to achieve with the report. This can help both internal and external stakeholders who are not familiarized with your company or the financial data.\nYou can just do cash flow, starting from your business’ last busy season through the end of the next, graphics are better than numbers. If you have questions beyond that, drill down into your business’ drivers, that is, what makes your money. First of all, the company should define what they needs to make a following of the business. There are many Key Performance Indicators and the board should define wich are appropiate to their business. The left hand side of the one pager was a rear view mirror and the right was a windshield. I presented this one pager to an executive committee of the board and it gave them enough insight to oversee the company and evaluate executive management.\nStandard Monthly Financial Reports\nTo write a financial report, format a balance sheet that lists assets, liabilities, and equity. Combine the totals for each category and include the final total at the bottom of the sheet. Next, create an income statement page to list revenue, cost of goods sold, operating expenses, and retained earnings, then sum those categories. Lastly, create a cash flows statement page to compile operating, investing, and financing activities and include a sum at the bottom. Financial reporting is compliance-oriented and is used for external purposes.\n- This section also often includes details about the company’s tax situation, pension plans, and stock options.\n- The set of reports are normally available by the 5th business day of the month.\n- The first three reports – collectively known as financial statements — are critical to seeing the big picture of your business, Hamilton notes.\n- Taken together, these reports tell you what your business is worth, how profitable it is, and if it has enough money coming in to keep trading.\n- Also analysis with some of the necessary recommendations and supporting statistics or projects.\nIt should include much more than just your financial statements. Statement of Cash Flows – This financial statement blends information from both the income statement and the balance sheet to give a picture of how cash is going into and out of a business. For a business owner, the “cash flow from operations” line is one of the most important across all financial statements. It shows over the period listed the net difference of cash that came in and cash that went out on an operating level. “In my experience working with companies in banking and consulting, I find that most business owners typically struggle to get a strong handle on their cash flow,” Hamilton says. You want to be focused on growing the business.” Looking regularly at cash flow from operations gives better perspective on the health of the business, allowing owners to concentrate on how to improve results.\nUnless your board requests monthly financials, stick with high level figures that are meaningful to them. If they approved the budget they need to know how you are running compared to the target. The monthly management report is the report that shows your company’s financial and operational performance on a month to month basis.\nTips For Designing Monthly Financial Reports\nThis is to the purpose of your monthly management report to recheck your strategy. The best report contains all data with your management team have to make decisions. to see the performance or financial status with a specific group. Whereas the index tool is about to illustrate by charts or graphs for reports.\nYou may not have all of these reports each month, depending on what applies to the selected department. Michael R. Lewis is a retired corporate executive, entrepreneur, and investment advisor in Texas. He has over 40 years of experience in business and finance, including as a Vice President for Blue Cross Blue Shield of Texas. He has a BBA in Industrial Management from the University of Texas at Austin. Gross Profit is the earnings after direct costs of production are deducted from Revenues. A low gross profit typically means a competitive market so prices are not easily raised and manufacturing costs are not easily reduced.\nThe essence of a monthly financial report should include relevant data that is easy to read and to comprehend. A board portal system by Diligent puts financial reports at board directors’ fingertips at any time of day or night. Back in the day, month end reports consisted of a income statement, balance sheet, and maybe a cash flow statement. These are the three statements that made up your financial statements for month end reporting. As technology advanced and people got smarter about tracking trends, analysis, and operations today, the month end report includes much more. In this week’s blog, I answer the question, what should your month end reports contain?. AR Days vs. AP Days – Accounts Receivable Days is the number of days until a company gets paid for its goods or services.\nAccess your Strategic Pricing Model Execution Plan in SCFO Lab. The step-by-step plan to set your prices to maximize profits. Browse the Business Exchange to find information, resources and peer reviews to help you select the right solution for your business. By signing up, you will receive emails from Proformative regarding Proformative programs, events, community news and activity.', 'Inadequate cash flow can cripple a small business. In fact, research shows that the insufficient management of cash flow can be pinned on as much as 82 percent of small business and start-up failure.\nIf you run a small business and are experiencing problems with cash flow, take a look at the advice of Fred Parrish.\nParrish is founder and chief executive officer of The Profit Experts and creator of The Profit Beacon, a new app that provides predictive analytics to help businesses make timely and smart decisions. Parrish is also author of “The Profit Mentality”.\nHow to Avoid Cash Flow Problems\nParrish, aka “America’s Small Business CFO”, provided Small Business Trends the following tips on avoiding cash flow problems at your small business.\nDo Appropriate Planning, Constantly\nAccording to Parrish, the real key to avoiding a cash flow crisis is to do the appropriate planning on a constant basis.\n“To accomplish this, you as the business owner/manager must look at the profit and loss (P&L) and any other non-operational items (or circumstances) that specifically affect cash flow,” Parrish advises.\nTake the Appropriate Steps to Manage Profit and Loss\nSmall business owners must take the appropriate steps to manage P&L. This includes, says Parrish, being “realistic about upcoming revenue opportunities and the timing of when they will be realized.”\nPart of a solid profit and loss management strategy should include performing an analysis of all costs (direct and indirect) and how they are driven by revenue or other activity in the business.\nAccording to Parrish, the “appropriate staffing level for the different stages of the company should also be determined” to help small businesses manage profit and loss adequately and help prevent running into cash flow problems.\nA monthly forecast for at least one year should also be developed says Parrish, “starting with the line items in accounting reports.”\nCreate a Forecast for Future Cash Streams\nParrish also advises small business owners to create a forecast of future cash stream, “preferably weekly.”\n“Developing an understanding about when revenues can be collected” is part of a comprehensive and effective cash flow, he says.\nThink About the Timing of All Operational Cash Payments\nAre you always aware of the timing cash disbursements will be made? It is wise for small business owners to, as Parrish says, “determine the timing of all operational cash disbursements.\nOther disbursements should also be identified, such as owner distributions, principal payments on debt and capital expenditures.\nParrish advises small business owners to subtract the disbursements from the receipts to determine cash balances for each future period.\n“Update the information as conditions change in the business or the market that will influence the outcomes to maintain a realistic view of the future,” he told Small Business Trends.\nCarry out a Comparative Analysis\nAccording to Parrish, small businesses must do a comparative analysis (compare the actual results to the forecast) to determine where the company is not performing as expected, in order to gain a better understanding about what actions should be taken to ensure an optimal outcome.\nParrish warns that: “No forecast is perfect and you can always come back to adjust any items that look to be incorrect. This will not be as painful as it sounds. Start with what information you have and refine the process over time.”\nFocus on Proactive Planning\nThe veteran CFO and author also told Small Business Trends that proactive planning is the key to avoiding a cash flow crisis and the symptoms or warning signs.\nAccording to Parrish, small businesses can avert running into a cash flow crisis by proactive planning and avoiding the following:\nCash Discounts Being Missed\nThe returns on cash discounts far exceed most returns on any other use of cash.\nVendors Being Stretched Beyond Normal Payment Terms\nParrish warns small business owners: “If this situation is allowed to persist for too long it will irreparably damage these relationships and could impede the business from acquiring the necessary items to operate.”\nLate Fees Being Incurred on Lease Payments or Trade Accounts\n“In a similar way as cash discounts, the effect of these penalties can far exceed the normal costs of traditional financing arrangements,” says Parrish.\nAge of Your Accounts Receivables Increasing or Increased Difficulty in Collecting Accounts\nUnfortunately, most managers do not attempt to manage A/R with more than a passing thought until there is a problem with cash or a question arises regarding the validity of the recorded balances, Parrish says.\n“You must have a sustained effort to manage A/R in place at all times. Uncover any issues that impair the ability to collect all amounts billed and develop a plan for working through each to a successful conclusion,” says Parrish.\nHe says this plan should include:\n- Billing promptly and as often as possible.\n- Collecting all payments as and when due.\n- Eliminating all barriers to payment at the outset.\n- Providing all documentation necessary to facilitate payment at the beginning of the process.\n- Aggressively following up on overdue invoices.\n- Not working only the old accounts. (If you focus only on the older accounts, you ensure that you will always have older accounts. Working the more current accounts allows you to collect them before they become old.)\n- Staying on top of the situation.\nParrish advises all small business owners ask themselves:\n“Who would you pay first — a vendor who is sending invoices on a consistent schedule with full supporting documentation who is very diligent in contacting you to determine the status of a timely payment, or a company that sends invoices from time to time with little explanation and no follow up?”\nIncrease Scrutiny of Operating Expenses\nThere are numerous reasons why a business owner will incur debt. Most are perfectly valid. However, there are times when business owners will take on debt in the hope that it will buy enough time to repair a damaged business or to prop up an inability to gain revenue traction in a particular market.\nTo avoid this, Parrish advises:\n“Increase scrutiny of operating expenses, liquidation of under-performing assets or outdated inventory, and carry out an unbiased evaluation of staffing requirements”.\nAvoid Filing Delays in Deposits of Payroll or Other Taxes\nParrish says filing delays in deposits of payroll and other taxes should be avoided at all costs.\n“The penalties can be severe,” he sats. “Once this path is taken, it’s a dangerous slippery slope.”\nAre you a small business owner who has successfully overcome cash flow problems? Is so, share your experiences of running into, avoiding and overcoming issues related to small business cash flow.\nCash Flow Photo via Shutterstock']	['<urn:uuid:a5a014e0-bf59-4edb-ab0c-d8179dea67fb>', '<urn:uuid:fd2f78c6-5899-4a61-abf6-858459fe2a31>']	factoid	with-premise	short-search-query	distant-from-document	multi-aspect	novice	2025-05-12T23:47:20.322175	7	37	2963
68	How do both military combat training and vertical farming address the challenge of resource efficiency, and what benefits do they offer compared to traditional approaches?	Both systems emphasize resource efficiency compared to traditional methods. Military combatives training has evolved from basic two-hour judo sessions to comprehensive programs that efficiently train soldiers in multiple combat scenarios using limited space and resources. Similarly, vertical farming has moved away from conventional agriculture's extensive land use, reducing water consumption by reusing resources through nutrient and water flow systems. The benefits are significant in both cases. Military combatives produces more effective fighters while using fewer training resources, as evidenced by their success in competitions. Vertical farming achieves higher yields per area while using 90% less water than traditional farming, and can operate year-round independent of external conditions. Both approaches also offer location flexibility - combatives can be taught in converted facilities, while vertical farms can be set up in various locations from urban centers to rural areas.	['Army Combatives turns soldiers into fighters on the battlefield and in the cage.\nWhen Tim Kennedy found out he’d be making his Octagon debut against jiu-jitsu ace Roger Gracie, he asked himself who was best suited to help him get ready. Without question, his longtime coaches Greg Jackson and Mike Winkeljohn would train and corner him at UFC 162, giving him advice for which they’re so renowned. His friend Nick Palmisciano from Ranger Up and his wife would be providing moral support. But who would guide him when he wasn’t in Albuquerque, NM, getting in rounds? Who should help him at home in Austin, TX, when he began the slog toward peak fight condition?\nShould he choose a striking guru so that he could KO the Brazilian before they hit the mat? Should he fly in a Division-I wrestler so his sprawl might be invincible? Should he just call Steven Seagal? Many of his eventual picks were what you’d expect, but he also chose one you might not—Army combatives instructor Kristopher Perkins, who’d never before been a part of a UFC fight camp.\nJust about everyone knows Kennedy is a soldier first and foremost—an Army Ranger, Green Beret, and sniper. As an MMA fighter, he’s aligned himself closely with Jackson and Winkeljohn’s squad. Perhaps that’s why Perkins was surprised to get an invitation from Kennedy, although it made sense once his friend and colleague explained the decision.\n“In Army combatives, our soldiers’ hand-to-hand incidents were happening inside small rooms,” says Perkins. “This requires the soldier to know how to take someone down where a wall is involved in the scenario. This is why our wall takedowns have advanced. We have been evaluating and training this portion of the fight for a long time. It naturally crosses into MMA takedowns against the cage, and Tim wanted to utilize that idea.”\nPerkins is an expert in the hand-to-hand combat taught in modern combatives, which was founded in 2001 by Army sergeant Matt Larsen. The combatives school Larsen founded at Fort Benning, Ga., swapped old-school Judo and karate techniques for modern arts that include jiu-jitsu, wrestling, Muay Thai and boxing. It provided a blueprint for stripping away ineffective fighting tools for ones who work in the field.\nPerkins teaches takedowns, but they’re not the variety done by guys sporting mohawks and Hayabusa shorts. When his soldiers put an opponent on the ground, they’re often in fatigues, a Kevlar vest, and a helmet. They might have an M-4 assault rifle slung over their shoulder. And they’re fighting for their lives.\nWhen not drilling in close-quarters combat, Perkins’ students are training in the cage at a huge facility in Fort Hood, TX. For the past three years, his combatives team has won the All-Army Combatives Tournament, which combines submission wrestling, Pancrase-style fighting, and MMA.\n“If you teach a guy how to be an MMA fighter, even if he’s just mediocre, he’s going to destroy people in combat,” says Perkins. “He’s mentally tougher, he’s physically fit, and if it goes to a hand-to-hand fight, he’s just so advanced.”\nGraduates of the combatives school carry accolades far from mediocre. Kennedy won the Combatives Tournament three times and is a Silver Star recipient. Army Ranger Colton Smith won The Ultimate Fighter 16. Watching opponents try in vain to escape Smith’s takedowns on the reality show, it’s easy to see why Kennedy requested Perkins to acclimate himself to the type of pressure that Gracie could bring.\n“I attribute quite a bit of my success in MMA to the Army combatives program,” Smith says.\nIf you watched UFC 162, you know Kennedy didn’t exactly dominate the grappling savant in his native territory. But he certainly wasn’t chaff in the tank, and he defended takedowns while landing his own and scoring points on the mat. It was far from a barnburner, but it did get him his first UFC win.\nKennedy and Smith, of course, are finished products. Years before the soldiers ever got their hands raised in the Octagon, however, they had to triumph over their own nervous systems. As soldiers, they trained for the field by turning fear into action, so that when a threat came around the corner, they would never be unprepared.\nWhile Perkins might be a good guy to know when you’re looking to stay upright or ground someone, his main job is to bridge the gap between those responses.\nBack in the day, the Army’s idea of hand-to-hand combat instruction was a two-hour block where you tossed a buddy over your back with a judo throw. As Perkins remembers, “That was it. God go with you.”\nWhile serving as a drill sergeant at Oklahoma’s Fort Sill, Perkins found combatives. A former wrestler who once tried to walk on to Oklahoma State University’s team, he understood the necessity of practical ground fighting. By 2006, he was working out in a cage that the program called “The Laboratory.”\nThen, he went to Iraq, where he ran into “a lot of bad situations.”\n“I found that I started reacting just like I did in the cage,” Perkins says. “When you get blown up by an IED, it feels like when you almost get knocked out. You know if this guy hits you one more time, the next thing you’re going to see is the fight doc. So you start reacting. I have to achieve the clinch, I have to fight back, I have to continue.”\nHe tried to take that mindset home when he was enlisted in 2007 to run a combatives training program at Fort Hood. The Army invested $3 million in converting an old basketball court into a modern facility with MMA equipment and a “kill room” for scenario training. The program was divided into four levels that started with basic fighting techniques and expanded to tactical applications, which address how to subdue opponents or get back to a gun.\n“If we became an MMA gym, the Army was only going to keep us around about 18 months,” says Perkins, who became a government services employee when he retired from active duty in 2010. “We still have to keep pushing the tactical training, and that’s how the place stays in business.”\nSoldiers in levels three and four train to become certified instructors, but they get an added twist: a fight every Friday. They also fight in full gear and practice clearing the kill room.\n“When they get into the cage for their first sparring, the guys are tagging them up,” Perkins says. “They keep backing up, they keep getting tagged. But if they close the gap or counterpunch, they start learning that the way to make this stop is to fight back. Then we notice that they become very mentally resilient, and also physically resistant.”\nPerkins might take students on a five-mile run and interrupt them midway to fight. He says his goal is not only to physically prepare soldiers for the rigors of combat, but hone their instincts so they make the right choices under duress.\n“Let’s say you’re driving down the street, and someone starts shooting at you from the stores on the side of the street,” he says. “The only way to survive that is to turn and fight into it. You don’t have a lot of time to think, ‘I have option A, run and get shot at.’ You’re going to do what’s instinctual. That’s why we train and train.”\nThere’s apparently another side effect of that preparation. It turns soldiers into great MMA fighters.\n“I used to take guys to pro/am fights in a casino,” says Perkins. “We’d end up taking six guys in a night and just crush everybody. It got to the point where we’d have to travel out of state because people were like, ‘It’s not fair to fight you guys. You train all the time.’”\nWith soldiers still deploying to Afghanistan and hot spots around the world, combatives remain an essential part of the military’s training. Domestically, however, the program is fighting a more insidious battle. Budget cutbacks, which came earlier this year as the result of the government’s sequester, have eliminated much of the funding for competitions such as the All-Army Combatives Tournament. That’s prompted Perkins to take his team on the civilian circuit.\n“We still have to convince the Army that fighting is something that soldiers should be doing,” says the coach, who’s contract with the government expires this month.\nCommand Sergeant Major Dan O’Brien, the senior enlisted advisor for combatives at Fort Hood, says the program isn’t being pulled any time soon. But with fewer resources to go around, soldiers won’t be able to test their skills against the best of the best when it requires the military to ship them to competitions.\n“When money is tight in the military, then it’s up to an installation to conduct tournaments,” he says. “There are other priorities in the military right now, which makes it hard to send everybody to one central location. I personally feel that the program is only as good as the people who support it, and as a senior leader, I support the program. Combatives runs very strong in my unit. But I can’t speak for all the other units across the Army.”\nLike Kennedy, Smith considers himself a soldier first and fighter second. It still irks him to hear other fighters talk about going to war in the cage. Having seen what war actually looks like, he makes a point to pay his respects to the people he considers to be the purest warriors, because no MMA camp will ever truly compare to preparing for battle.\n“The intestinal fortitude you get in the combatives program—it’s for possible life-or-death situations,” he says. “I’m sorry, but the cage, it’s not life or death. Obviously, people can pass away, but chances are, worst-case scenario is that you’re going to be single-legging Herb Dean in the cage. What we do in the cage is easy. What soldiers do overseas, that’s hard.”\nComments are closed.', 'Agricultural systems around the world need to adapt to the rapidly changing environmental, demographic, and socioeconomic landscapes, and new alternative practices, such as vertical agriculture, may offer new opportunities to accelerate such adaptation.\nNext Gen Farming Without Soil and 90% Less Water | GRATEFUL\nWhat is vertical farming and why is it important\nModern agricultural systems encompass an estimated 1.5 billion hectares of the world’s surface area. With a growing population and resource needs, the availability of arable land is shrinking rapidly.\nSince the agricultural revolution, conventional agriculture has focused on practices requiring considerable quantities of space, water, fertilizer, and pesticides. The past 50 years have seen an accelerating rate of increase in these requirements as modern food production aims to increase productivity in the hopes of addressing growing food insecurity.\nLooking into the future, yield production is forecasted to decrease due to widespread environmental and socioeconomic changes that will generate unpredictable consequences on food systems.\nIn response, many strategies have been developed as alternatives to conventional agricultural practices. These strategies have focused on key principles and their combination to be effective: require less space, less water, and increase yield per unit of area. Moreover, due to the negative effects of agrichemicals, modern practices have also aimed to use significantly less to avoid potentially adverse effects for humans and animals.\nOne such alternative is the development of vertical agriculture, also referred to as vertical farming. As the name implies, vertical agriculture relies on expanding production vertically and not horizontally. Vertical agriculture is a multilayer indoor plant production system that allows for precise control of growth factors, such as light, temperature, humidity, carbon dioxide concentration, water, and nutrients.\nThis allows for the growing and production of crops year-round, completely independent of solar light and other external conditions. Indeed, vertical agriculture makes use of key concepts within ecology and physiology to optimize growing and fertilization within controlled conditions. For instance, elements of photobiology, thermomorphogenesis, hydroponics, and genetic breeding, are all used commonly across systems of vertical agriculture.\nBenefits, challenges, and disadvantages moving from horizontal to vertical farming\nAs a result of tight control over crop breeding, growing, and harvesting, vertical farming provides several benefits relative to conventional methods of ‘horizontal’ food production. This was the topic of a literature review by Kalantari et al. published in 2016 in the Journal of Landscape Ecology.\nFrom a systems perspective, the enclosed design prevents pests and diseases from entering by the adoption of a high level of hygiene, continuous monitoring, and non-chemical disinfection, providing security from crops. Moreover, recent technology has also allowed for automated control over environmental conditions by using sensors and imaging techniques in combination with crop simulation models and artificial intelligence, limiting the need for physical labor.\nVertical farming also allows for flexible organization, with designs ranging from large vertical walls covered with crops to large hangars or re-used shipping containers that can be transported. Consequently, vertical agricultural systems, can comprise many varying sizes and be located within many different areas from the middle of highly urbanized cities to more suburban or rural areas.\nMoreover, the verticality element of this system also provides nutrient and water flow, helping to reuse costly resources. The reduction in space also means there is a significant increase in yield per area, holding extensive potential for a future world of urbanization.\nFrom an economic perspective, vertical farming also provides for more jobs in localized areas and is community-focused by addressing the needs of immediate areas, which in turn can provide food at a lower price. Finally, the optionality of location for vertical systems also allows producers to reduce transport costs, as consumers may access them within urban areas, or transport can be minimized to nearby areas.\nHowever, despite the design, environmental, and economic advantages, vertical farming also incorporates several issues that remain a challenge to its broader implementation as a system.\nVertical farming has a high energy requirement and needs extensive investment costs to implement and develop successfully. Moreover, indoor issues relating to excessive UV, heat, and ozone-induced plant damage may have unpredictable repercussions for plant growth.\nAdditionally, vertical systems are difficult to adapt to a larger scale. They are costly to build and maintain and have yet to demonstrate the ability to provide food for larger areas than community-scale populations. This would make it difficult to implement in areas at higher risk of food insecurity, such as developing agricultural nations.\nThe lack of empirical research on a broader scale has meant that vertical farming has yet to develop past the concept stage on community levels, as persistent issues make it difficult to break through to a larger scale.\nImage Credit: YEINISM/Shutterstock.com\nGrowing skywards - the implications of vertical farming in a rapidly populating and changing world\nAmong the development of alternative agricultural practices, vertical agriculture provides a promising solution for many of the challenges facing current agricultural policies. However, for vertical systems to be integrated on a larger scale requires further technological progress and economic investment.\nNevertheless, gradually implementing more verticality, or combining it with other practices aiming for more sustainable practices may be promising. For instance, the combination of verticality with other practices such as intercropping may be particularly beneficial for developing more sustainable food systems.\nIncorporating technological progress into vertical systems also holds promise, with automated sensors and machinery able to operate near-independently. Progress in gene editing and plant genome modifications will also allow for faster, bigger, and healthier crops, allowing vertical agriculture to produce more over time.\nThroughout agricultural history, farming systems have typically spread over large spans of land, yet the reduction in arable land, as well as the increase in demand to house growing populations, means that such strategies need to be reconsidered, and vertical agriculture may play a role looking into the future.\nContinue Reading: Benefits of Vertical Agriculture and Hydroponics\n- Beacham, A. M., Vickers, L. H., & Monaghan, J. M. (2019). Vertical farming: a summary of approaches to growing skywards. The Journal of Horticultural Science and Biotechnology, 94(3), 277–283. doi: 10.1080/14620316.2019.1574214\n- Chaudhry A. R. and Mishra V. P.,(2019) A Comparative Analysis of Vertical Agriculture Systems in Residential Apartments, Advances in Science and Engineering Technology International Conferences (ASET), 2019, pp. 1-5, doi: 10.1109/ICASET.2019.8714358\n- Sarkar, A., & Majumder, M. (2015). Opportunities and Challenges in Sustainability of Vertical Eco-Farming: A Review. Journal of Advanced Agricultural Technologies, 2(2). doi: 10.12720/joaat.2.2.98-105\n- SharathKumar, M., Heuvelink, E., & Marcelis, L. F. (2020). Vertical Farming: Moving from Genetic to Environmental Modification. Trends in Plant Science, 25(8), 724–727. doi: 10.1016/j.tplants.2020.05.012']	['<urn:uuid:b7b45ec0-6afa-48f4-bce6-5c7c591a9f7a>', '<urn:uuid:3566e03d-b8ac-4d36-b13c-9d56f4d7ba0e>']	open-ended	direct	verbose-and-natural	similar-to-document	multi-aspect	novice	2025-05-12T23:47:20.322175	25	137	2755
69	3d printer iss what can it make	The Manufacturing Device (ManD) on the International Space Station can produce components, entire experiments, and tools on demand. It is installed in an Express Rack locker location and is capable of producing parts using a wide variety of thermopolymers including engineered plastics.	['- Press Release\n- Jan 27, 2023\nNASA Space Station On-Orbit Status 12 August, 2021 – Cygnus Cargo Spacecraft Arrives\nThe Northrop Grumman Cygnus spacecraft’s hatch was opened this afternoon after successful rendezvous and berthing operations.\nAt 6:07 a.m. EDT, NASA astronaut Megan McArthur used the International Space Station’s robotic Canadarm2 to grapple the Northrop Grumman Cygnus spacecraft as ESA (European Space Agency) astronaut Thomas Pesquet monitored Cygnus systems during its approach. Cygnus was then bolted into place on the International Space Station’s Earth-facing port of the Unity module at 9:42 a.m. EDT. Cygnus will remain at the space station for about three months until the spacecraft departs in November.\nThe spacecraft’s arrival brings more than 8,200 pounds of research and supplies to space station. Highlights of cargo aboard Cygnus include research studying 3D printing using simulated lunar regolith, seeking to utilize microgravity to develop new means to treat a degenerative muscle condition on Earth, investigating new tactics to control heat during operations in space and during the intense heating of reentry, and testing a technology to remove carbon dioxide from spacecraft atmospheres with applications to future NASA exploration missions.\nThese are just a sample of the hundreds of investigations currently being conducted aboard the orbiting laboratory in the areas of biology and biotechnology, physical sciences, and Earth and space science. Advances in these areas will help keep astronauts healthy during long-duration space travel and demonstrate technologies for future human and robotic exploration missions as part of NASA’s Moon and Mars exploration approach, including lunar missions through NASA’s Artemis program.\nNASA has continued to assess any integrated impacts to the space station from the inadvertent firing of thrusters on the newly arrived Russian Nauka module. Routine operations have continued uninterrupted since the event, with the space station prepared for the arrival of multiple spacecraft. Consistent with NASA policies, an investigation team is being formed to review the activity. NASA’s team will begin with identifying team members and defining the scope of the investigation. The team will focus on analyzing available data, cooperating with our Russian colleagues for any information they require for their assessment, and coordinating with the other international partners.\nOn-Orbit Status Report\nESA-Education Payload Operations (EPO) Microbes Video: The crew recorded video, which will be used to educate children about Microbes on the ISS and will feature Paxi, ESA’s mascot for young children. The activities related to EPO Generic Videos are intended to encourage and strengthen the teaching of science curriculum, and stimulate the curiosity of students to motivate them towards further study of Science, Technology, Engineering and Mathematics (STEM) subjects.\nManufacturing Device (ManD): The crew removed the printed objects, cleaned the extruder print nozzle, photographed, and stowed the pair of printed objects. The Manufacturing Device enables the production of components on the ISS for both NASA and commercial objectives. Parts, entire experiments, and tools can be created on demand utilizing the ManD printer that is installed into an Express Rack locker location. ManD is capable of producing parts out of a wide variety of thermopolymers including engineered plastics.\nMochii: The crew continued troubleshooting efforts to recover the Mochii hardware using several different methods to boot from an external SD card containing the Operating Software. Mochii is a miniature scanning electron microscope (SEM) with spectroscopy to conduct real-time, on-site imaging and compositional measurements of particles on the International Space Station (ISS). Such particles can cause vehicle and equipment malfunctions and threaten crew health, but currently, samples must be returned to Earth for analysis, leaving crew and vehicle at risk. Mochii also provides a powerful new analysis platform to support novel microgravity science and engineering.\nCygnus Capture/Berthing: The NG-16 Cygnus cargo spacecraft was captured today at 05:09 CT (224/10:09 GMT). The Cygnus spacecraft was then berthed to the Node1 Nadir Port and bolted into place. The crew performed leak checks, outfitted the vestibule, and ingressed into the Cygnus vehicle.\nExtravehicluar Activity (EVA) Preparation: In preparation for the iROSA 4A preparation EVA currently scheduled for August 24th, the crew performed a visual review of the EVA using the Dynamic Onboard Ubiquitous Graphic (DOUG) software. This session allows the crew to view the step-by-step sequence of a specific EVA. The crew also performed the initial configuration of tools required for the EVA.\nAirlock Intermodule Ventilation (IMV) Cleaning: The crew completed the Airlock IMV cleaning today. The purpose of this cleaning is to remove any foreign object or debris (FOD) from the IMV inlet flow straightener and silencers located in the Airlock. Following the cleaning, the crew used the Velocicalc tool to measure the air flow through the IMV.\nCompleted Task List Activities:\nSSC-UDON SP BPW-RVW\nOBT-CYG VEH OPS-CBT\nToday’s Ground Activities:\nAll activities are complete unless otherwise noted.\nSSRMS Cygnus Install\nSystem Configurations for Cygnus Berthing and configuring back to nominal after berthing.\nLook Ahead Plan\nFriday, August 13 (GMT 225)\nCardinal-Muscle sample Insert (NASA)\nCell Gravisensing Sample preparation (JAXA)\nMochii Application connect (NASA)\nRing Shear Drop hardware setup (NASA)\nStandard Measures Post Sleep Questionnaire (NASA)\nCygnus Cargo Operations\nEMU Loop Scrub\nCygnus Emer OBT\nSaturday, August 14 (GMT 226)\nCardinal Muscle media exchange (NASA)\nCell Gravisensing Fixation operations (JAXA)\nMochii hardware Activation 1 (NASA)\nNanoRacks-MainFrame Alpha-install (NASA)\nSunday, August 15 (GMT 227)\nCardinal Muscle Microscopy(NASA)\nCell Gravisensing Observations (JAXA)\nToday’s Planned Activities:\nAll activities are complete unless otherwise noted.\nCell Gravisensing-1 Experiment Familiarization\nPublic Affairs Office (PAO) Downlink Message\nExtravehicular Activity (EVA) Tool Configuring\nPortable Onboard Computers (POC) Dynamic Onboard Ubiquitous Graphics (DOUG) Software Review\nPrivate Psychological Conference (PPC)\nPublic Affairs Office (PAO) Social Media Event\nCygnus/Node 1 Leak Check Preperation\nA/L Adapter Plate (JCAP) and NanoRacks Kaber Plate (STEP) Gather\nFood Acceptability Survey\nHealth Maintenance System (HMS) ISS Food Intake Tracker (ISS FIT)\nPhoto TV High Definition (HD) Cygnus Video Setup\nCygnus/Node 1 Vestibule Leak Check\nNode 1 Nadir to Cygnus Vestibule Outfitting, Part 1\nTemperature and Humidity Control (THC) Intermodule Ventilation (IMV) Flow Measurement Survey\nNode 1 Nadir to Cygnus Vestibule Outfitting Part 2\nCommon Berthing Mechanism (CBM) Controller Panel Assembly (CPA) Rotation and Closeout']	['<urn:uuid:d98159af-476b-4db2-bc49-1e0bd1551338>']	open-ended	with-premise	short-search-query	distant-from-document	single-doc	novice	2025-05-12T23:47:20.322175	7	42	1007
70	I'm curious about how aerial reconnaissance has changed over time - what are the key differences between how Penniman did photo reconnaissance in Tomcats versus how the P-8A Poseidon handles surveillance missions today?	There have been major technological advances in aerial reconnaissance. In the past, when Penniman flew Tomcats, photo reconnaissance involved using three types of cameras (infrared, black and white, and color). After completing a mission, the films had to be physically brought back to the ship, downloaded and developed, which could take hours for intelligence specialists to review. In contrast, today's P-8A Poseidon represents a dramatic technological leap, comparable to the difference between 1960s black and white TV and modern television. It has advanced computing power that can process all available information on one platform and communicate it in real-time to warfare commanders anywhere in the world. Additionally, unmanned aerial surveillance vehicles like the Triton can now provide 24-hour overhead presence and communicate with users via satellite in real time.	['RANCHO SANTA FE — For some, serving their country is a four-year enlistment, and for others, it remains an integral part of their lives. The latter example is a perfect profile for Rear Adm. Russell S. Penniman.\nIn 1979, Penniman graduated from the United States Naval Academy, and in 1981, earned his wings as a designated naval aviator.\nA decorated aviator who was released from active duty in 1994, he joined the reserves for various staff duties, which at times pulled him back into active duty once again. Throughout this period, the fluidity of being in the reserves to active duty, and back to the reserves, has proven to be as robust as when he was a naval aviator.\nA resident of Rancho Santa Fe since the early 1990s, Penniman, 56, thinks back to his training days when he became a pilot. Although he admits it’s hard to walk in the shoes of the young men and women doing it now, Penniman said with much certainty the aircraft have become better over the years.\n“Everything I flew in the training command has been retired. We have new generations of aircraft for both our propeller aircraft and for our jet trainers,” said Penniman, Reserve Deputy Commander and former Maritime Operations Director. “In my time, there were two jet trainers that you flew — the T2 Buckeye and the A4 Skyhawk; and, now there is a single trainer.”\nAnother progressive change has been unmanned aerial surveillance vehicles. The Navy’s Triton can offer 24-hour or more overhead presence for visual observation and detection methods.\n“When I was flying Tomcats, one of my missions was photo reconnaissance,” he said. Typically there were three cameras: infrared, black and white, and color.\nOnce he completed his visual observation mission, Penniman brought the cameras back on the ship; the films were downloaded and then developed. From start to finish, it could take hours for their intelligence specialists to view the films.\nNow, these unmanned aerial surveillance vehicles communicate with the users via satellite in real time.\nWhile Penniman has great memories being a naval aviator, he equally has a litany of fond memories in the reserves, especially when returning back to active duty.\nIn January 2003, he was mobilized to support Operation Iraqi Freedom and was stationed at the Prince Sultan Air Base in Saudi Arabia for major combat operations.\n“I was the night director of combat plans, helping to lead the planning for that operation up to execution,” he said. “And it was probably one of the most challenging experiences, quite frankly, in my life.”\nPresently, he is assigned to the U.S. Pacific Fleet, alternatively serving as reserve deputy commander, deputy commander and chief of staff.\nPenniman explained that following 9/11, there was a shift with the naval reserves. Now, it’s very much integrated with the active duty force.\n“You can usually walk up to any active duty staff and there will be multiple reserves doing active duty work and you can’t tell the difference from one or the other,” he said. Penniman continued, “Since Enduring Freedom in Afghanistan and Iraqi Freedom started, the reserves have mobilized over 71,000. We mobilized 55,000 folks but we covered 71,000 mobilizations with a preponderance of those being in Iraq and Afghanistan and we’ve lost 48 folks along the way.”\nAlthough Penniman is a clear example of reserve integration, he’s quick to point out that he is not unique among the reserve force. The reserves have enabled the navy to perform at these levels through this integration.\nLike most military families, Penniman thanks his wife, Carol, for making it all possible. He calls her the “glue” that keeps everything together at home when he is mobilized and may be gone for a few months.', 'Reasserting Sub-Maritime Domain Dominance\nFrom Armor & Mobility, March/April 2018 Issue\nRear Admiral William\nW. “Trey” Wheeler III\nPatrol and Reconnaissance Group (CPRG),\nA native of Cross City, Florida, Wheeler graduated with a Bachelor of Science degree in Oceanography from the United States Naval Academy in 1988, and was awarded a Master’s Degree in National Security Strategy from the National War College in Washington D.C. during 2008. As a career Naval Flight Officer, Wheeler has served a tour with the War Eagles of Patrol Squadron (VP) 16, and as an instructor with the Pro’s Nest of VP-30. He served as the officer-in-charge of the Maritime Patrol and Reconnaissance Weapons Tactics Unit at the Pelicans of VP-45, and was the commanding officer of the Red Lancers of VP-10, and the commander of the Patrol and Reconnaissance Wing ELEVEN. While serving in the joint environment, Wheeler was the commander of the Provincial Reconstruction Team at the Forward Operating Base Sharana in Paktika Province in Afghanistan. Likewise, he served as the Deputy Brigade Commander for Interagency and Joint Operations at Task Force YUKON, 4th Brigade Combat Team (Airborne) with the 25th Infantry Division at Forward Operating Base Salerno in Afghanistan. Prior to reporting for his current assignment, Wheeler was the Deputy Commander at the Combined Joint Task Force – Horn of Africa in Djibouti, Africa.\nBy Denver Beaulieu-Hains, PMA 290 Public Affairs\n“Today, we are seeing a renewed interest in airborne anti-submarine warfare and in the underwater domain,” says Rear Adm. William “Trey” Wheeler III, the U.S. Navy’s commander of Patrol and Reconnaissance Group and Patrol and Reconnaissance Group Pacific. “Imagine in the early 60’s, black and white television compared to what we have today, that’s the technology jump we’re seeing between the capabilities of the legacy P-3C Orion (P-3C) and its successor, the P-8A Poseidon (P-8A).“\nThe Maritime Patrol and Reconnaissance Force (MPRF) led by Rear Adm. Wheeler, consists of 12 active component patrol squadrons, two reserve component patrol squadrons, and a fleet replacement training squadron. During 2012, the MPRF began its transition from legacy platforms to a new family of systems, including the P-8A Poseidon multi-mission aircraft, the MQ-4C Triton Unmanned Aerial System, and a Tactical Mobile ground support system.\nWheeler says it is technology, communication and teaming that makes this an exciting time for operators and stakeholders in the Maritime Patrol and Reconnaissance community. Today, the P-8A Poseidon brings speed to the fleet, the power of secure networks, and twice as much acoustic capability.\nA&M: Tell us about the P-8.\nRear Adm. Wheeler: The P-8A was designed and built to replace the P-3C Orion, which I believe has been in the fleet since 1962, and has been doing great work for us for a long time. The Navy really invested in the P-8A to do that traditional role of anti-submarine warfare. So, it’s built to accomplish that mission and it’s doing a tremendous job.\nA&M: How is it different than the P-3? What new capabilities does it bring to the fight?\nRear Adm. Wheeler: Obviously, the most striking difference is its two engines, jet propulsion, as compared to the four-engine propeller-driven P-3 Orion. As I mentioned, the P-3 has been flying since the early 60’s. You can imagine the technology that has changed since then. Really, what the P-8 brings is that new technology. It takes an airframe that is very dependable in the Boeing 737 and combines it with some of the great sensors our industry partners have developed over the years combined with great computing power.\nA&M: How is this helping the Navy in its modernization efforts, and meeting the operational goals of the Navy right now?\nRear Adm. Wheeler: What the P-8A really brings is that culmination of technology. If you imagine in the early 60’s black and white television compared to what we have today. Well, that’s the technology jump that we’re seeing, between a P-3C and a P-8A. The computing power alone, and being able to take all the information that’s available to that crew and bring it into one platform, process it and then have the ability to communicate that out to the warfare commanders, both on the carrier [carrier strike group], or at a fleet operations center or really just about anywhere around the world…where it’s needed…to get that information to the right decision makers. It’s a tremendous technology and a leap for the warfighter.\nA&M: How do you think the crew is enjoying it? Do you think they really like flying the P-8A?\nRear Adm. Wheeler: They absolutely love the P-8A. For us old-timers, we grew up on that P-3, and it was a long mission, but it was a worthwhile mission. I think the difference today is that crew is still doing that long mission, but it’s a little smoother flying. They typically fly at a little higher altitude and, when they get back, they aren’t completely worn out. That level of improved comfort actually helps you on station when you are looking for a submarine. You stay fresh longer, and the technology on that plane fits what they grew up doing. They actually love it!\nA&M: Can you explain how the P-8A operates in the Family of Systems?\nRear Adm. Wheeler: The Family of Systems really refers to the Maritime Patrol Reconnaissance Force that we are looking to build. It takes the P-8A Poseidon, couples it with the MQ-4C Triton, and then we have a ground node, if you will, in our Tactical Mobile.\nWhat we are able to do is to look at the complementary missions that these two airframes bring and then merge the information from them both and get it to the right folks to act on it. From a P-8A standpoint, it’s taking advantage of a manned platform, which can get to a location quickly, deliver weapons if needed, and return; couple that with a Triton, which is a high-level, persistent intelligence, surveillance, and reconnaissance type platform and you have an unbeatable team. We take advantage of the best of both and use that ground node to help translate that information and pass it around. It is a nice, strong family.\nA&M: Where are we now as far as development and delivery?\nRear Adm. Wheeler: So, we started the transition around 2012. The first P-8A deployment was in December of 2013. Since then, we’ve been working from one squadron to another. We’re a little over halfway. For the east coast, those squadrons that reside in Jacksonville (Fla.), they are complete. They are P-8A pure. Whidbey Island has completed their second squadron transition, and they’re well on the way to their third. It’s been a great thing to watch both from a leadership perspective, and as an operator … looking at what the airplane brings; it has tremendous, tremendous capability.\nA&M: What do you expect to see in the future?\nRear Adm. Wheeler: I think our imagination is our only limit on what these planes will be able to do. The P-8A itself, one of the advantages we have is simply capacity. There is room on the plane, in the internal infrastructure, for growth, which is how it was designed for future development. I think our anti-submarine warfare role, which is really the core of the maritime patrol and reconnaissance community is here to stay. We are the only community that does long-range Airborne ASW. That mission is here to stay and we look forward to flying the P-8A for a long time.\nA&M: Why the interest from the international community?\nRear Adm. Wheeler: Our foreign military sales and cooperative partners, currently the UK and Norway, and partner Australia provide tremendous leverage for us as a collective. When the partners come in, not only do we get closer from a commonality standpoint, but it allows us to leverage each other’s buying capital. By leveraging our partners, we can buy, produce, and procure things quicker, maybe than we could by ourselves. It’s tremendous leverage for us all. And, it’s great to have great allies.\nFrom a teaming standpoint, the maritime patrol and reconnaissance force has really enjoyed a great team from the folks here at Pax River, PMA 290, as well as our resource sponsors up at the Pentagon. It’s a great, great team, great communications, and again the industry partners involved in both the P-8A and MQ-4C have been crucial. There are absolutely no complaints from where I sit.\nAs for the P-8A, the computing power alone, being able to take all the information that’s available to that crew, bring it onto one platform, process it, then have the ability to communicate that out to the warfare commanders, both on the carrier strike group or at a fleet operations center, or really just about anywhere in the world that it’s needed to the right decision maker, tremendous technology, and again, a leap for the warfighter.']	['<urn:uuid:cbcbd3fa-71e0-485a-a7fd-d49ac5b9c510>', '<urn:uuid:f0e398ec-c62a-4b5c-9a10-6673989c875d>']	open-ended	with-premise	verbose-and-natural	similar-to-document	comparison	novice	2025-05-12T23:47:20.322175	33	129	2102
71	celestial navigation training prerequisites for yachtmaster offshore license experience hours at sea required	The prerequisites for the celestial navigation course include having a Yachtmaster Offshore license or equivalent, and 3000 nautical miles at sea with some night experience and a good command of a sail boat. Additionally, candidates need a VHF license and Medical Test, and preferably STCW95.	['Course Objective: Prepare sailors to skipper a vessel in all oceans anywhere in the world by day and by night and be able to navigate only by means of celestial navigation\nPre Course Experience: Yachtmaster Offshore license or equivalent\nAssume Knowledge: 3000NM at sea with some night experienceand a good command of a sail boat. VHF license. Medical Test and preferably STCW95\nDuration: 6 days theory, 6 days at sea\nWhat will I learn?\n- History of astronomy and celestial navigation\n- Principle of astronomy\n- Circle of position\n- Spherical trigonometry\n- Sight taking\n- How to read an almanac\n- Sight reduction techniques (Sumner and St Hilaire)\n- Latitude by Polaris\n- Noon sighting and Sun Run Sun\n- Understanding time\n- Star identification and sight planning\n- Passage planning with sights\nThis is a course for anyone serious about sailing. Celestial navigation is an important skill and is still taught today even though GPS have become so convenient and affordable. Even though the GPS system (and other similar services) are reliable, we are still at the mercy of solar flares which can disrupt permanently any satellites (as it nearly happen, by 1 week in 2012 according to NASA) and/or lightning strikes which will disable any electronic equipment on board.\nAt the beginning of this course, we will take a trip back in time and start our journey of the stars with the first greek astronomers. We will pay respect to Eratosthenes and Aristarchus for their brilliant intuition and mathematical genius in discovering that our planet is a sphere and not at the center of the universe, more than 2000 years before Galileo and Copernicus. We will explore the first methods for finding a position using stars and how celestial objects locations in the celestial sphere were recorded in almanacs. On the way to modern times, we will salute Sumner and St Hilaire for giving us, back in the mid 19th century, the 2 main methods used for sight reductions today.\nFor those of you who have not done any spherical trigonometry since high school, don’t worry, we go back to the basics and re-explain the sine and cosine laws for planes and spheres (high school 10th grade). These laws are used throughout the course and it is important to understand how they are useful to calculate the length in degrees between 2 points or to calculate an angle (to compute an azimuth for instance or a longitude).\nOur school has several sextants for students, from simple Mak 3 sextants to the very powerful and precise Astra III and Tamaya They will be used for noon/sun sighting during the day and star altitude observation at night.\nWe will then explain how to read an almanac to extract the Geographic Position of the observed celestial object, do all our fine tuning by including all the necessary corrections like dip, altitude, sextant errors …\nFrom the almanac readings we will have a correct GP of celestial objects which will then be used with either pure trigonometry or using sight reduction techniques (a semi-graphical method) to obtain our position. Et voila !\nBefore finishing, we will look at “time” and awe at its complexity. We will learn about Aphelion, Perihelion, Analemma, Equinox, Solstices, the path of the Earth around the sun, the difference between apparent solar time (used by ancient Greeks with their gnomon), mean solar time (used by you and me with a watch) and sidereal time (used by astronomers). And you will finally understand why we constantly need to adjust our watches because a day is not really 24 hours !\nWith this certificate, you can charter a boat anywhere in the world and skipper a boat day and night up anywhere you want. So buy a sextant, practice and take it with you on your boat!\nIt’s recommended that you contact us to book your course.\nCall +639 959 655 287 (please, remember the time difference with the Philippines: UTC/GMT +8 hours) to inquire or book or use our contact form.\nYachtmaster Ocean Course price:\nYou can pay by cash or Paypal. All our prices are fixed.\nOur course package includes: boat rental and instructive materials, instructor’s fee, warm lunch made from fresh local ingredients (when on the boat). Our package does not include the Eco Tourism Development fee and has to be paid in cash. This ticket costs P200 and is valid for 10 days.\nNote: All our courses have to be paid in Philipino Pesos. The prices in Euros are informative.']	['<urn:uuid:e8138d33-7ede-41ff-a013-03358239bd3a>']	factoid	with-premise	long-search-query	similar-to-document	single-doc	expert	2025-05-12T23:47:20.322175	13	45	755
72	How did Brew win the Melbourne Cup in 2000?	Brew won the 2000 Melbourne Cup carrying 49.5 kilos, defeating Yippyio and Second Coming. He qualified for the Cup by winning The Dalgety on Derby Day, just three days before the race. It was his last win.	"['Definitions for Brewbru\nThis page provides all possible meanings and translations of the word Brew\nRandom House Webster\'s College Dictionary\nto make (beer, ale, etc.) by steeping, boiling, and fermenting malt and hops.\nto prepare (tea, coffee, etc.) by boiling, steeping, or the like.\nto contrive, plan, or bring about:\nto brew mischief.\n(v.i.)to make beer or ale.\nto boil, steep, soak, or cook.\n(n.)a quantity brewed in a single process.\na brewed beverage.\nany concoction, esp. a liquid produced by a mixture of unusual ingredients:\na witches\' brew.\nInformal. beer or ale.\nCategory: Common Vocabulary, Viniculture/Winemaking, Informal\nOrigin of brew:\nbef. 900; ME; OE brēowan\ndrink made by steeping and boiling and fermenting rather than distilling\nprepare by brewing\n""people have been brewing beer for thousands of years""\nsit or let sit in boiling water so as to extract the flavor\n""the tea is brewing""\nKernerman English Learner\'s Dictionary\nto make beer\n***to brew beer\nto begin to develop\nThere\'s trouble brewing.\nThe mixture formed by brewing; that which is brewed; a brewage.\nA cup of tea.\nThe act of making a cup of tea.\nTo prepare (usually a beverage) by steeping and mingling; to concoct.\nTo foment or prepare, as by brewing; to contrive; to plot; to hatch.\nTo attend to the business, or go through the processes, of brewing or making beer.\nTo be in a state of preparation; to be mixing, forming, or gathering.\nTo boil or seethe; to cook.\nOrigin: brewen, from breowan, from brewwanan, from bʰreuh₁- (compare Welsh berw ‘boiling’, Latin fervere, Albanian brumë, Russian ‘current’, Sanskrit ‘motion of water’ ).\nto boil or seethe; to cook\nto prepare, as beer or other liquor, from malt and hops, or from other materials, by steeping, boiling, and fermentation\nto prepare by steeping and mingling; to concoct\nto foment or prepare, as by brewing; to contrive; to plot; to concoct; to hatch; as, to brew mischief\nto attend to the business, or go through the processes, of brewing or making beer\nto be in a state of preparation; to be mixing, forming, or gathering; as, a storm brews in the west\nthe mixture formed by brewing; that which is brewed\nBrew is a small, plain bay Thoroughbred gelding who won the 2000 Melbourne Cup for trainer Mike Moroney and jockey Kerrin McEvoy. Brew carried the lightweight of 49.5 kilos, and defeated the veteran Yippyio and the stablemate Second Coming. After finishing second to Yippyio in the Moonee Valley Cup, Brew qualified for the Melbourne Cup by winning The Dalgety on Derby Day, three days before the Cup. Brew was a son of the Sir Tristram and the champion New Zealand racemare and Japan Cup winner Horlicks, but, unfortunately for such a well-bred horse, was gelded before showing his best form. The Melbourne Cup was Brew\'s last win. Brew is now at Living Legends, the International Home of Rest for Champion Horses located in Woodlands Historic Park, Greenvale, Victoria, Australia.\nTranslations for Brew\nKernerman English Multilingual Dictionary\nto make (beer, ale etc)\nHe brews beer at home.\n- يخمّـر البيره، يَنْقَعArabic\n- варя бираBulgarian\n- produzirPortuguese (BR)\n- brygge; fremstilleDanish\n- παρασκευάζω (π.χ. μπίρα)Greek\n- elaborar bebidas fermentadasSpanish\n- به عمل آوردنFarsi\n- panna oluttaFinnish\n- לְבָשֵל בִּירָהHebrew\n- मद्य बनानाHindi\n- variti pivoCroatian\n- főz (italt)Hungarian\n- fare, preparareItalian\n- daryti (alų)Lithuanian\n- brūvēt (alu)Latvian\n- membuat birMalay\n- به عمل آوردنPersian\n- عمل کی راوړلPashto\n- a fabrica (bere)Romanian\n- ต้ม (เหล้า)Thai\n- bira yapmakTurkish\n- 釀造(啤酒等)Chinese (Trad.)\n- بئیر بناناUrdu\n- chế, ủ (rượu, bia)Vietnamese\n- 酿造（啤酒等）Chinese (Simp.)\nGet even more translations for Brew »\nFind a translation for the Brew definition in other languages:\nSelect another language:']"	['<urn:uuid:6cffc59a-6985-4211-8045-85a894110cbb>']	open-ended	direct	concise-and-natural	similar-to-document	single-doc	expert	2025-05-12T23:47:20.322175	9	37	614
73	which english cities allowed married women run own businesses medieval times	A small number of English urban centers allowed married women to register as independent business operators, including Exeter, Hastings, London, Lincoln, Winchelsea, and Worcester. However, none of these cities has produced lists of women who registered as such, and historical examples of women taking advantage of this option are extremely rare.	['Posted by Sara M. Butler; 8 February 2019.\nWhen reading over an anonymous reviewer’s comments on a manuscript I was writing on the subject of women’s legal disability in medieval England, I was genuinely surprised by one of the recommendations. He (or she) asked me to insert a reminder to my audience that, when it comes to the law, not all married women experienced the strictures of coverture. The legal designation of femme sole (“woman alone”) made some women an exception to the rule.\nFor those who are not English legal historians, allow me to explain. Inspired by scripture (Mark 10:8, “and the two will become one flesh”), for much of England’s history the law understood marriage as creating a unity of person. Once married, a wife’s legal personality merged into her husband’s: the couple became one person at law, represented in the person of the husband. The term “coverture” derives from the legal description of that unification process: a wife was deemed “covered” (protected) by her husband, thus coverte de baron – the use of the term “baron” in this instance was, of course, a recognition of the “natural” hierarchy that existed between husband and wife.\nThis fictionalized unity of person was not just a legal construct; it had real life implications. The wedding ceremony transformed an active, independent woman, who shared the same legal standing as a man, into a dependent at law. Accordingly, without her husband’s express permission, she could not make purchases, enter into contracts or leases, or initiate a lawsuit, even if she had participated in these activities in her own right prior to marriage. As I have written elsewhere, because coverture was not yet the finely honed tool it became in the early modern era, it did not quite result in a married woman’s civil death. Yet, coverture was a formidable obstacle, incapacitating a married woman from performing many of the necessary activities of daily life without rigorous accommodations by merchants and retailers, who had no choice but to conduct financial transactions with married women on a daily basis.\nThis is where the legal designation of femme sole comes in. Recognizing that some men might wish to have their wives continue the thriving businesses they had founded or inherited prior to marriage, some English cities permitted a wife to register as femme sole. As such, a married woman might behave as if she was single for the purposes of conducting business. The benefits of this arrangement were twofold. The designation not only freed a woman from the constraints of coverture so that she could run a business, it protected her husband’s business interests. The White Book (Liber Albus), a customal of sorts for the city of London, clarifies that the latter was in fact the chief concern behind the status’s design, so that when it comes to a wife who trades alone,\nif the husband and wife are impleaded, in such case, the wife shall plead as a single woman in a Court of Record, and shall have her law and other advantages by way of plea just as a single woman. And if she is condemned, she shall be committed to prison until she shall have made satisfaction; and neither the husband nor his goods shall in such case be charged or impleaded.\nTo return to my initial statement: the anonymous reviewer’s request to include mention of femmes soles took me by surprise largely because so few women fell into this category in the Middle Ages that referencing femme sole in a general overview of women’s legal rights seemed senseless, perhaps even misleading. To my mind, femme sole is much like the medieval hermaphrodite: the laws have a lot to say on the issue because its very existence disrupts traditional gender norms, and thus requires exceptions ingeniously applied so as not to undermine the gender hierarchy. Yet, the attention given to the subject is largely academic and disproportionate to any reality. Actual historical examples of hermaphrodites (or femmes soles, for that matter) are few and far between.\nThe status of femme sole was an English phenomenon, a necessary byproduct of coverture, also an exclusively English experience. Yet, even within England, the designation was available in only a small number of urban environments, among others: Exeter, Hastings, London, Lincoln, Winchelsea, and Worcester, and none of those few urban centers has produced lists of women who registered as such. Historical arguments about the femme sole rest principally on municipal legislation and less than a handful of cases drawn from manuscript notations. A chamberlain’s account from York covering the years 1453-54 notes that Robert Horman, a tailor, paid 3 s. 4 d. for his wife to “follow the trade of the cardmaker by herself.” In 1457, a London silkwoman named Agnes wife of John Gower appeared before the mayor and aldermen to ask to be permitted to act as “sole merchant.” There are also a select few court cases centering on a woman’s status as femme sole; however, in each of these instances the female defendant rejected the plaintiff’s characterization of her as a femme sole (perhaps, preferring to use coverture as a shield to guard her assets). We do not have any cases of a femme sole suing a debtor in her own right. In all likelihood, this is because she knew well that her chances of being successful in a lawsuit increased exponentially if she had a man at her side.\nThe inability of historians to uncover a plethora of concrete examples of married women registering as femme sole is striking in large part because of the historiography. Dating as far back as Alice Clark’s Working Life of Women in the Seventeenth Century, published in 1920, the femme sole has played a pivotal role in historical interpretations of women’s place in premodern society. Essentially, the legal fiction levelled the economic playing field for women, diminishing the real power of coverture by erasing its impact on daily life. It offered the potential for women to hold a “rough equality” with men. Without actual examples of married femmes soles, a positive assessment of women’s independence in the medieval marketplace is less credible.\nThe real question, of course, is: have medievalists even noticed that the femme sole was largely a mythical figure? There are only two dedicated studies of the medieval femme sole and their arguments run in opposite directions. Brian Gastle, writing in 2004, sees that “by the end of the fourteenth century, femme sole wives had become almost commonplace.” As proof, Gastle seems to include every instance in which a wife acts outside her husband’s control. This methodology, of course, is inherently flawed: wives frequently had to conduct business in the absence of their husbands, but as Cordelia Beattie has written, doing so was not an example of women acting as if they were single; rather, it was an early version of the “law of necessaries.”\nWriting just one year later, Marjorie McIntosh, underscores the rarity of solid examples of medieval femmes soles, leading her to conclude that the “status was of limited importance in economic and legal terms.” Indeed, she argues that the designation “was not seen as desirable by working women” (a statement that might have shocked poor Alice Clark!). McIntosh observes that some women may have represented themselves as femme sole in their business transactions, but they chose not to register as such because being a femme coverte provided greater “legal maneuverability.” A male plaintiff was much less hesitant to sue her if he knew that he might have to take on her husband in court. More important still, coverture provided the ultimate “legal dodge.” The responsibility fell to the creditor to ensure that a married woman had her husband’s permission before entering into any agreement with her. Thus, if she was in fact a femme coverte, any contracts she entered into independently were not legally binding.\nStudy of the few disputes revolving around a woman’s supposed femme sole status in the late medieval court of Chancery can contribute a number of insights to these debates.\nFirst, they make it clear that femme sole is the term favored by historians; “sole merchant,” or some variant of it, was the actual descriptor applied in both London custom (uxor quæ sola mercandizat), and Chancery petitions (always, sole merchaunt). What’s in a name? Femme sole is the flipside of femme coverte: thus, the term itself subtly invokes coverture even while speaking to a woman’s independent state. Femme sole also highlights the performative nature of marital status, a somewhat subversive proposition. If it is acceptable for a wife to act as a single woman for business purposes, when else might she pretend to be single? Is the mantel of coverture something that can be removed so effortlessly? The use of “sole merchant” evades these debates entirely. The term is devoid of gender: theoretically, it might apply equally to a man as to a woman. Thus, unlike femme sole, it is not a reminder that a married woman is doing something extraordinary.\nSecond, Chancery petitions add another dimension to the undesirability of the status. Femme sole status provided unscrupulous creditors an opportunity to sue married women independently for their husbands’ debts. The petition of Joan, wife of John Kirton, lays out the usual scenario. Her husband was purportedly indebted to Thomas Bailly for the sum of five marks for nonpayment. In the hopes of inspiring eventual repayment, Thomas had Joan’s husband imprisoned. John then charged Joan and other “friends” to negotiate with Thomas on his behalf, hoping to be awarded “longer days of payment” (i.e. more time to repay the debt). He also endeavored to gain Thomas’s permission to “go at large,” on the premise that he has a better chance of repayment if John is working than sitting in prison. Thomas’s agreement led to John being released from prison. But, of course, John did not keep his promises. As a result, Thomas decided to adopt what he hoped might be a more fruitful tactic: he had Joan arrested and thrown in prison, claiming that the debt was in fact hers as sole merchant. Joan’s petition to the chancellor, penned while she was in prison, makes clear that “she never undertoke to pay nor ever bought or sold with the same Thomas” and yet because of his “great might” she expected to be condemned, “against all right and good conscience.” She begged the chancellor for a corpus cum causa directed to the sheriffs of London to have her case removed into Chancery for consideration. Of course, as is typical of all medieval Chancery cases, the court’s verdict has not survived so we don’t actually know what happened to Joan in the end.\nAt times, zealous creditors waited until the husband was out of town before initiating litigation. Henry Shepper, a parish clerk in London, had just departed for Rome on pilgrimage when Richard Wyld, described as citizen and salter of London, sued an action of debt for 44s in the sheriffs’ court of London against Henry’s wife, Margery. Richard claimed that Margery was sole merchant, while Margery insisted that she had always been “covert baron under her said husband.” Elizabeth Broun’s husband, John, was away “beyond the sea” in the employ of the Duke of Burgundy when Thomas Brighton, a London fuller, took out a plaint against her for her husband’s debts of 34s and 4d. The first suit failed: the court declared that she was “covert baron” and thus Thomas would have to wait until her husband returned before he could proceed with his lawsuit. Astutely, in his next plaint he alleged that she had borrowed the money from him as sole merchant, and Elizabeth was certain that she would soon face conviction and a prison sentence.\nThird, the petition of John Fynkell, knight, raises questions about the process of discerning whether a married woman was in fact femme sole. John tells the chancellor that his beef lay with Joan Horne, a recent widow, once married to William Horne, knight and alderman of London. During her husband’s lifetime, John had contracted to sell £61 worth of silks to Joan, believing that she was sole merchant, as he describes it, “that she after the custom of London might in her own name buy and sell and that all contract and bond by her and in her sole name made should not withstanding her coverture be good and effectual in the law to all her creditors.” The proof of her status, as John implies, was the fact that she had her own seal (in reality, not an indication of femme sole status). Eventually she failed to pay him for the silks; both she and her husband refused to acknowledge the debt, and so he then turned to the city, only to discover that “no manner of record could be showed to prove her after the custom of London to be sole merchant.” Since her husband died, he had renewed his attempts to have her pay her debts, without much success, leaving John to turn to the chancellor as a last ditch attempt at repayment.\nFinally, the petitions challenge popular knowledge of femme sole status. Anne Davell’s statement to the chancellor is pertinent here. Facing prison for an 18s debt to singlewoman Christian Baxter, that she argues her husband, a debtor in Ludgate prison, entered into, Anne makes it clear that her activities reflect what “many other poor women done,” that she “never was sole merchant nor knew what the term meant until this time that necessity teaches her but was ever continually covert baron.” Anne’s statement may have been a coy masquerade, hoping to sweet talk her way out of being punished for failing to settle a debt. It may also have been a frank admission.\nFar from the economic freedom that historians once envisioned, these cases instead suggest that femme sole status was a) a legal dodge for women hoping to avoid responsibility for repaying debts; and b) a weapon for devious creditors eager to compel their debtors’ wives to cough up the money they could not squeeze from their husbands. Was there more to the story? The feminist in me can only cling to the hope that there was.\nFeature Image: “The Moneylender and his Wife,” Quentin Massys (1456). Public Domain via Wikimedia Commons.\n Sara M. Butler, “Discourse on the Nature of Coverture in the Later Medieval Courtroom,” in Married Women and the Law: Coverture in England and the Common Law World, ed. Tim Stretton and K.J.Kesselring (Montreal: McGill-Queen’s University Press, 2013), 24-44.\n H.T. Riley, ed., Munimenta Gildhallae Londoniensis; Liber Albus, Liber Custumarum et Liber Horn, 3 vols (London: Longman, Green, Longman and Roberts, 1862), vol. III, 38.\n P.J.P. Goldberg, ed., Women in England, c. 1275-1525 (Manchester, 1995), 189.\n CLRO, journal 6, f. 182 28 October 1457, as cited in Marjorie K. McIntosh, “The Benefits and Drawbacks of Femme Sole Status in England, 1300-1630,” Journal of British Studies 44 (2005), 417.\n I have discussed this in Sara M. Butler, “Medieval Singlewomen in Law and Practice,” in The Place of the Social Margins, ed. Andrew Spicer and Jane Stevens Crawshaw (New York and London: Routledge, 2017), 59-78.\n Brian W. Gastle, “‘As if she were single’: Working Wives and the Late Medieval English Femme Sole,” in The Middle Ages at Work: Practicing Labor in Late Medieval England, ed. Kellie Robertson and Michael Uebel (New York: Palgrave Macmillan, 2004), 52.\n Cordelia Beattie, “Married Women, Contracts and Coverture in Late Medieval England,” in Married Women and the Law in Premodern Northwest Europe, ed. Beattie and Matthew Frank Stevens (Woodbridge: Boydell, 2013), 133-54.\n McIntosh, 425.\n McIntosh, 412.\n McIntosh, 427.\n McIntosh 412.\n Riley, vol. I, 204.\n The National Archives (TNA) C 1/64/607 (1475-80, or 1483-85): Kirton v. Sheriffs of London.\n TNA C 1/73/119 (1386-1486), Shepper v. Wylde.\n TNA C 1/64/434 (1475-80, or 1483-85), Broun v. The Sheriffs of London.\n TNA C 1/201/32 (1493-1500), Fynkell v. Horne.\n TNA C 1/80/12 (1486), Davell v. The Mayor and Sheriffs of London.']	['<urn:uuid:fb30fb23-ab95-4309-8eaf-083efab2f630>']	factoid	with-premise	long-search-query	distant-from-document	single-doc	novice	2025-05-12T23:47:20.322175	11	51	2666
74	what are best techniques prevent water damage underground part house	Basement waterproofing is the technique to prevent water seepage into underground rooms of structures. Two efficient methods exist: 1) A drainage control apparatus with vertical and horizontal legs, featuring embossments and spacer lips that maintain gaps between walls, allowing water drainage through channels into a drainpipe. 2) A sump system with a rectangular geometry, containing apertures to exchange groundwater while blocking debris, and including a pump stand with notches for debris collection.	"['A building, which has a basement, has a great chance to face the problem of seepage of water or penetration of water through the wall of the basement especially at the time of heavy precipitation. This water from seepage stay at the floor line of a basement and if not controlled this condition can cause severe damage to the interior wall of the basement and the contents of the basement. This type of water seepage can get into the basement through the crack of the foundation walls and can develop over time if not it handled properly.\nPorous building materials, such as concrete block, are capable of percolation and seepage of water through the building material itself and into the interior portion of the structure. Another source of moisture arises from capillary action and water vapor.\nFacts and Ways of Water Intrusion into the Basement :\nWater can enter a basement in several ways. The conventional basement consists of three elements. Such as\n- A foundation wall.\n- A footer on which the wall rests.\n- A floor slab.\nUnderground water and Groundwater is the main source of water which will enter a basement.\nIf the water table rises above the level of the basement floor water can enter the basement through the side wall.\nSo what is the solution to this problem?????????????? The answer is basement waterproofing. Below we have discussed briefly the basement waterproofing, methods, which methods are efficient etc.\nWhat is Basement Waterproofing?\nBasement waterproofing means the technique and the materials to prevent seepage of water into the basement or the penetration of water into the basement of a house or structure. This waterproofing is for an underground room of a structure.\nMethod of Basement Waterproofing\nThere have many ways of solving the problem of seepage of water but all the way is not truly efficient because of cost and difficulty of installation.\nSome Method and the fact about those methods :\n- Trying to seal the crack after the formation of a crack of a foundation wall. It can be done at inside or outside. It is not only costly but also ineffective.\n- Moisture resistant flashings or coatings can be a solution but Moisture-resistant flashings or coatings tend to fracture and tear due to building expansion, settling, and careless installation.\n- By setting a plywood board against the foundation wall before the pouring of concrete slab water can be drained from the interior of the basement. Then the board is removed while the concrete is still ""green\' and not completely set. But this procedure has some disadvantages:\n- it causes damage to the edge of the concrete floor;\n- it results in additional labor costs,\n- it may cause the concrete floor to shift.\nSo an efficient method is highly desirable for waterproofing solution. Two methods, which are considered as efficient, are described below.\nEfficient Methods of Basement Waterproofing\nApparatus: Drainage Control Apparatus\nPart of the Apparatus: Vertical leg, Horizontal leg, Embossments, Longitudinal spacer slip, Drainpipe.\nMethodology: A drainage control apparatus has been used in this method. A vertical leg of this apparatus has been set up to the vertical side wall of the basement and a horizontal leg has been set up to the top of the foundation footing. The vertical leg consists of an embossment at the bottom end of the vertical leg. The vertical leg also consists of a longitudinal spacer lip at the upper end of the vertical leg. Both the embossment and the spacer lip touch vertical side wall of the basement to maintain a gap between the vertical leg and the vertical side wall. The horizontal leg consists of channels to flow water into a drain pipe. For the corner of the basement, the apparatus is named as corner drainage control apparatus but the setting of the apparatus is same. After that concrete is poured to fulfill the slab and then the vertical portion of the apparatus has been cut off to level the apparatus with slab end. This invention is quite easy to install and it is also advantageous because it can drain water from the interior of the basement.\nA sump system in geometry is rectangular. It has two side elements with apertures to exchange the groundwater while blocking debris. In another side element, an adjustable inlet had been provided to connect other elements of a basement waterproofing system to the sump liner. After that in the sump liner, a base configured can be used to provide a built-in stand for the sump pump. The pump stand contains a lip including notches to allow the fallen of debris and collection in a trough around the periphery of the base. The base further provides an underside cavity which accommodates an obstruction in the floor of the sum hole. A removable lid used to facilitate the access of the interior of the sump liner and also contains a breakaway feature to accommodate discharge piping. The sump liner can be oriented into the sump hole to protect the basement foundation from the adverse effect of erosion.\n- Andras, S. Basement sump system, and method. U.S. Patent 8973324B2 filed January 24, 2013, and issued March 10, 2015.\n- Geske, D. R. Apparatus, and method for waterproofing basements. U.S. Patent 4869032A filed September 25, 1987, and issued September 26, 1989.\n- Read, R. R. Basement Waterproofing. U.S. Patent 5845456A filed December 14, 1990, and issued December 8, 1998.\n- DiFiore, D. Basement waterproofing system. U.S. Patent 4136500A filed March 30, 1978, and issued January 30, 1979.']"	['<urn:uuid:b796d0aa-4d4c-4824-bbc9-61b51569a097>']	open-ended	with-premise	long-search-query	distant-from-document	single-doc	expert	2025-05-12T23:47:20.322175	10	72	924
75	I've seen some old churches that have these covered walkways around a square space, with walls on one side and columns on the other. What are these areas called and what were they used for?	These covered walkways are called cloisters. In Christian monasteries, they typically served as a connecting passage between the church and domestic quarters. A cloister is characterized by having a wall on one side and columns on the other, arranged around a square space.	"['Glossary of Architectural Terms\nSee below for an explanation of fine art\nterminology used in Architecture history\nA - B\n- C - D - E - F\n- G - H-J - K - L\n- M - N - O - P-Q\n- R - S - T - U-V\nTransfiguration Church (17th century)\nKizhi Pogost, Lake Onega, Karelia.\nUNESCO list of World Heritage sites.\nAmazing wooden architecture!!\nA modern example of sand architecture\n(2002). Victoria, Australia.\nNationale Nederlanden Building,\nPrague (1992-97). Deconstructivist design\nby Frank Gehry.\nuppermost part or division of the capital of a column, usually shaped\nlike a parallelepiped; the architrave rests on it.\ncollection of buildings, such as a church, cloisters, and guest rooms,\nthat compose a monastery complex ruled by an abbot.\nstructure supporting the lateral thrust of an arch or vault; see vault\npedestal or figure placed at the three angles of a pediment.\nopening, such as door or window, framed by columns, with a pediment; see\nClassic Greek architecture.\nAEG Turbine Factory\nIconic example of early modernist architecture designed by Peter\nBehrens (1868-1940), who was also noted for his pupils Waler Gropius,\nLe Corbusier and Mies van der Rohe.\nstyle of Greek architecture found in the 6th century BCE; sometimes called\ndivision of space at the sides of a church, parallel to the nave and separated\nfrom it by piers or arcades.\nrecess, niche, or reception hall in ancient Parthian building or mosque.\narchitectural form created by two horseshoe arches paired at the sides\nof a central column.\nAkropolis (or acropolis)\nfortified citadel in Greek cities. ""The Acropolis"" usually refers\nto the one in Athens.\nrectangular panel that frames an arch, usually horseshoe-shaped.\nin antiquity, a raised structure composed of a wooden plank or stone on\nwhich sacrifices were offered. In Christian religion, the altar is used\nfor the celebration of the Mass; initially made of wood, altars were later\nmade of stone, marble, or other materials.\nin Christian church architecture, the picture or decorated screen behind\nthe altar. It may consist of a single painting or an elaborate group of\nreading desk or pulpit in early Christian church, usually of stone. Normally\nthere were two, facing each other on each side of the choir.\ncontinuation of the aisles of the choir around the apse, sometimes giving\naccess to smaller chapels; see church.\nAmorino (pl. amorini)\nsmall Putto; usually winged.\narena surrounded by tiered seats. Used from the 1st century BCE throughout\nthe Roman world for public spectacles.\nvaulted roof over a ring-shaped (annular) space, between two concentric\nwalls; see vault construction.\nupright architectural ornament found in Classical buildings, where it\ndecorated the ends of a roof ridge.\nuppermost point of a triangular or conical form.\nsemicircular or polygonal end of a church; usually the end of the chancel,\nat the east end.\na series of arches, often supporting a wall, with their columns or piers.\nA blind arcade is an arcade set against a wall without openings in the\nusually curved architectural member spanning an opening and serving as\nsupport. According to the shape of the curve, arches are identified by\na variety of names, including round arches, pointed or ogee arches, trefoil,\nlancet, basket-handle, or Tudor arches, or horseshoe arches, typical of\nArab architecture. A rampant arch is an arch in which one abutment is\nhigher than the other. Hanging arches are tall blind arches, often reaching\n1 science or art of building. 2 the structure or style of what is built.\nSee also: Greatest Architects (1400\nthe lowest division of an entablature; a horizontal beam supported by\nmoulding or cornice, bare or decorated, that follows the contour of an\narch, whether on the outside face (lintel) or on the inside (intrados).\nArt Nouveau architecture\nDecorative design movement centred on Europe, led by Victor Horta (1861-1947)\nin Belgium, Antoni Gaudi\n(1852-1926) in Spain and Hector\nGuimard (1867-1942) in France.\nsquared, even-faced block of stone.\nfigures of men used to support an entablature. The female equivalent is\n1 forecourt of Roman house leading to various rooms. 2 court in front\nof Early Christian and Romanesque churches.\nin classical architecture, the part of a building above the main order\non a facade. This area can often become a separate storey of the building.\nsquare column of Greek architectural order, or pilasters applied to upper\nstory of building.\nterracotta or majolica glazed tiles in bright colours, used for floors\nand both interior and exterior wall dressings. Of Arabic origin, their\nuse spread in Spain beginning in the 13th century.\nsmall pillar or column supporting rail.\nseries of balusters, usually edging terrace or balcony.\na part of a church or a separate building near a church in which baptismal\nrites are performed.\nfrom the Arabic Persian bahhana (a fortified gallery), a defensive structure\nin front of a gate, such as a tower, an outer defensive work, a reinforced\narea on the\ninternal part of a wall, most of all in medieval and Renaissance fortresses.\na covered storage space attached to a farm house; the word is used for\nthe bodies forming the wings of Palladian villas, which usually function\nas service areas.\nIn Italy: mostly religious building design, exemplified by the Roman designs\nof Bernini (1598-1680)\nand his rival, Francesco\nmedieval church in which the nave is taller than the aisles; early churches\nhad an apse at one end. It was based on the Roman assembly hall, or the\ndesign of colonnaded halls in private houses. The most famous example\nis St Peter\'s Basilica\nin Rome, the second largest church in the world.\nBauhaus Design School\nAvant-garde school of architecture and crafts in Weimar, founded by Walter\nthe space formed, usually within a church where the limits are indicated\nby Orders, vaults, etc, rather than by walls. On an external wall a bay\nmay be indicated by buttresses.\nhorizontal structural member, usually made of wood, bearing a load.\ncombination of Neo-Baroque and Neo-Renaissance architecture that symbolized\nthe Belle Epoque. The leading American exponents were Richard\nMorris Hunt (1827-95) and Cass\nBenedictine, or stepped, choir\nchoir flanked by rectangular areas of decreasing size.\ncruciform basilican plan with a nave and two aisles, projecting transept,\nchoir, and flat-ended side chapels.\nornamentation formed by short cylindrical or rectangular blocks placed\nat regular intervals in hollow moldings.\nLike The Palace of Versailles in France, Blenheim - designed by Sir\nJohn Vanbrugh (1664-1726)\n- was a symbol of the Baroque style in England.\nA form of postmodernist 20th-Century\narchitecture, marked by bulging curves.\nornamental projection, of wood or stone, placed at the join of vaulting,\nribs, etc; see vault construction.\na formal grove of trees, containing at least five of the same species,\nused in formal French gardens, such as those at the Palace of Versailles\n(see below), designed by Andre le Notre.\nBow window (also bay window)\na window forming a recess in a room while also projecting beyond the exterior\nwall, in so doing increasing the amount of light.\nprojection that functions as a support; may also be decorative.\nIconic neoclassical building in Berlin designed and built by Carl\nGotthard Langhans (1732-1808) during the period 1789-94. His pioneering\nneoclassicism was further popularized by Karl\nFriedrich Schinkel (1781-1841).\nshutter to block sunlight.\nreinforced, projecting wall, usually on the exterior of a building, supporting\nit at a point of stress. A flying buttress transmits the thrust of a vault\nto an outer support; see vault construction.\nconvex rope-like molding found in Norman architecture. Sometimes also\nrefers to similar decoration in goldsmiths\' work.\nfreestanding bell tower of church.\nsuspended or projected miniature roof over an altar, seat, statue, or\na beam supported or fixed at one end carrying a load at the other.\narchitectural element that crowns a vertical support element (column,\npilaster, or pier) and is thus located beneath a horizontal lintel, entablature,\nor arcade. It is composed of a lower part (echinus), often decorated,\nand a simpler upper part (abacus). The basic types of capitals are the\nDoric, composed of a square abacus resting on a circular echinus; Ionic,\nwith a generally ornate echinus ending in spiral volutes and a somewhat\nflat abacus; Corinthian, a bell-shaped cone decorated by flowers and leaves;\nTuscan, similar to the Doric, with wider and lower echinus; and composite,\nmade up of Ionic elements (volutes) and Corinthian (leaves). There are\nalso crocket, or hooked, capitals, Gothic capitals decorated with stylized\ndecoration of a building with battlements and turrets, like a castle;\nthe result may be described as castellated.\nseat or throne made of wood, marble, or ivory, often decorated with inlays\nand bas-relief, located behind the altar at the end of the apse and used\nby the bishop during religious functions. Its presence creates a cathedral.\nfrom the presence of the bishop\'s throne, or cathedra; the principal church\nof a diocese, the church where a bishop officiates. The most famous cathedrals\nare probably the Gothic\ncathedrals of Northern France. These include: Chartres\nCathedral (1194-1250); Notre-Dame\nCathedral Paris (1163-1345); as well as those at Reims and Amiens.\nIn Germany, the most famous is Cologne\nCathedral (1248-1880); in Italy, Florence Cathedral (1296-1436) and\nthose at Milan and Siena; as well as Burgos and Santiago de Compostela\na compartment, most especially one of the four triangular divisions of\na sepulchral monument.\nthe temporary wooden structure built to support an arch or vault during\ncapital whose square angles are cut obliquely.\neast end of church containing the altar.\na small room used for worship. A chapel can be isolated or included within\na larger architectural complex. In most cases numerous chapels, each with\nan altar, are arranged along the length of a nave or aisle or around the\nthe large room in a convent, monastery, or cathedral in which the chapter\nmeets (the canons or members of the religious order); in monasteries and\nconvents it usually faces a large cloister.\nthe far end of a church, beyond the transept and including the choir,\napse, and ambulatory. It can have a variety of plans and in Gothic architecture\noften includes radiating chapels.\n1 zigzag molding in Norman architecture. 2 pattern of V shapes.\nChicago School of Architecture\nleading group of pioneer skyscraper architects, led by William\nLe Baron Jenney (1832-1907). Please see also: Second\nChicago School of Architecture (c.1940-75) led by Mies\nvan der Rohe.\nterm taken from ancient Greek drama (chorus); in a Christian church it\nis the area reserved for cantors and the clergy, usually composed of wooden\nstalls often carved or inlaid with a reading stand for the choristers.\nToday the term indicates the area included between the transept and the\napse or the zone of the church located behind the main altar. According\nto its shape it can be ambulatory, stepped or Benedictine, or triconch.\n1 vaulted canopy over an altar. 2 vessel for holding consecrated host.\nDrum-shaped structure, often pierced with windows, and supporting a dome.\nin British usage, an open area at a street junction or intersection or\na group of buildings arranged around such a space, which may then serve\nas a public garden.\nClassic Greek architecture\napogee of Greek architectural design, much imitated in later architecture.\nupper story of nave of chruch, pierced with windows; see vault construction.\ncovered walk around a space, usually square, with a wall on one side and\ncolumns on the other. In Christian monasteries it often links the church\nand domestic quarters.\n1 Ornamental sunken panel recessed into ceiling or vault, which may then\nbe described as coffered. 2 chest for valuable objects.\nrow of columns supporting entablature.\nvertical architectural element with support function, usually cylindrical\nand composed of a base, shaft, and capital. The lower third of a column\nis often thicker (entasis) and then tapers slightly upward. Columns can\nbe arranged in groups or can be free-standing. They can also be engaged,\nmeaning set into a wall.\nComposite order: see orders of architecture.\nConcha (or conch)\nthe domed roof of a semicircular apse.\nmixture of sand, stone, and cement used as a building material, especially\nin the 20th century.\n1 architectural term for scrolled bracket. 2 in furniture, a side table\nwith marble top.\nprojection on a wall, bearing a weight.\nseries of corbels built one above the other.\nCorinthian order: see orders of architecture.\n1 upper member of an entablature. 2 ornamental molding finishing the part\nto which it is attached, (eg) at the junction of a wall and ceiling.\nthe principal section or block of a large building, such as a palace or\nmansion, containing the entrance and main rooms.\nCosmati work, Cosmatesque\na type of inlaid marble mosaic practised by Roman marble workers in the\n12th and 13th centuries, so-named from the mistaken belief that all the\ncity\'s leading marble workers came from the same family.\narchitectural term for elements used in pairs, as in coupled columns.\ntwo pilasters standing on the same pedestal.\nconcave molding, especially between the ceiling and cornice of a room.\nthe formation of battlements, in which the openings are known as crenelles.\nin British usage, a group of buildings arranged along a curving street\nline of ornament finishing a roof or wall.\nin Gothic architecture, a carved decoration, usually leaf-shaped, projecting\nfrom the sides of pinnacles or gables.\nthe space in a church where nave, chancel, and transepts meet. Bay or\nother area of a church defined by the crossing of the main nave and the\ntransept. According to how the two bodies intersect, the crossing can\nbe isolated, in which the nave and transept are the same height and the\nsquare bay is defined by four equal and opposing arches, or suppressed,\nin which the bay is defined by lower and narrower arches that clearly\nseparate the crossing from the transept, from the nave and from the choir.\nchurch plan, common in Armenia.\ncross-shaped; used especially of a church that has transepts.\nunderground area composed of one or more chambers located beneath the\npresbytery in a church. The crypt originated in the apostolic tombs made\nin Roman basilicas during the age of Constantine; beginning in the 7th\ncentury it assumed the function of housing the relics of the martyr saint\nto whom the church was dedicated. An annular crypt is surrounded by a\nsemicircular ambulatory that follows the shape of the apse above; if other\naisles and rooms are located off the crypt it is called a hall crypt.\nBeginning in the 10th-11th centuries the crypt took the shape of a nave\nand was enlarged, almost becoming a second, underground, church. Another\nname for the crypt is lower church.\ndomed vault roof.\nouter wall of castle joining towers and gate-house. Also refers to a wall\nthat divides space without bearing weight.\nbase of a capital associated with early medieval architecture; shaped\nlike a cube but with rounded edges and corners. See Cushion capital.\nsquare capital with rounded corners, found chiefly in Romanesque and early\nmedieval buildings; see vault construction.\npoint at which two arcs meet in Gothic arch or tracery.']"	['<urn:uuid:18d67e57-32cf-4867-96a5-b8c75eee0c3e>']	open-ended	with-premise	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-12T23:47:20.322175	35	43	2497
76	How does the volcanic landscape contribute to tourism activities in both Mauritius and Reunion islands?	In Mauritius, tourists can visit the dormant Trou aux Cerfs volcano, which is 300 meters wide and 650 meters high, offering views of Port Louis and coastal resorts. In Reunion, the volcanic landscapes are more prominently featured in tourism, with hiking trails through plains and volcanoes being considered among the best attractions, particularly at Volcano and Mafate Cirque, which are part of the French national natural park.	['The island nation of Mauritius (officially the Republic of Mauritius) is located in the Indian Ocean, off the southeast coast of Africa. Mauritius was a British colony, taken from France during the Napoleonic Wars in 1810, until gaining independence in 1968. While English is the only official language, French and Mauritian Creole are more commonly spoken. A wide variety of ethnicities (Indian, African, Chinese, and French to name a few) are found on the island as no indigenous peoples lived on Mauritius prior to European discovery. Thus the population of Port Louis is now largely made up of descendants of laborers from India and African slaves. Many Mauritians are of mixed ethnic descent as a result of the longstanding diversity of the island.\nThough geographically considered a part of Africa, the island nation of Mauritius has close relations with a variety of regions. Its closest ties are with India and South Africa (its largest trading partner), however. Mauritius is one of the most affluent countries in Africa, and is considered to be an upper middle income economy relying on tourism, textiles, sugar, and financial services. New technologies have introduced new sectors, however, and foreign investment is increasing. Construction booms in the 1990s and 2000s have dramatically changed Port Louis’ skyline. Port Louis’ skyscrapers are the tallest buildings on the island, and are quite unusual for a small African island.\n- Mauritius is becoming a top luxury tourism destination with a wide variety of natural and man-made attractions, a sub-tropical climate, attractive beaches, and an exciting multi-ethnic culture. Mauritius has one of the highest rates of returning tourists in the world and is home to many attractive and well-run hotels. In January 2012 the island won the World’s Best Beach award at the World Travel Awards. Clearly the island has a lot to offer.\nA wide variety of recreational activities are available on the island, but make sure to use anti-mosquito protection at all times when outside. On land one can partake in golf, tennis, sky diving, hunting, mountain biking, horse riding, as well as a variety of other exciting activities. As the island is surrounded with coral reefs, water sports are popular in the area’s shallow and calm waters. Deep-sea fishing, surfing, windsurfing, water-skiing, yachting, and even submarine rides are fun options. The national sport of Mauritius is horseracing, though Mauritians compete in a variety of local sports such as swimming, sailing, basketball, martial arts, and weightlifting.\nIn addition to being a haven for beach lovers, Port Louis is a snacker’s paradise. Food stalls all over town offer fantastic mixed-cuisine morsels, but the Central Market and the various bus stations are particularly popular spots. As a result of Port Louis’ cosmopolitan culture, the city celebrates a colourful variety of festivals and holidays, including Christian, Catholic, Buddhist, Confucian, Hindu, and Muslim traditions.\n- Getting around\n- Port Louis is the busiest and most congested city in Mauritius, with only one major road leading in and out of the city. If you are planning on spending your time on the island within Port Louis, it is not advised that you hire a car as the traffic can be stressful. If you are planning on travelling outside the city, however, many of the larger car rental companies are available and offer affordable options.\nThe city of Port Louis is only around 8km in diameter, with many of the attractions and amenities in close proximity to one another. This means Port Louis could be quite walk-able. If you choose not to walk or want a wider travelling range, however, you have a few additional good options. The most common form of public transportation on Mauritius is the bus—there are no railways on the island. The buses are economical and are manned by a driver and a conductor who walk around collecting fares and issuing tickets. Simply board and tell the conductor where you want to go to find out the fare amount. Most conductors are very helpful for giving local directions.\nTaxis are another great way to visit the island, but make sure not to patronise unlicensed taxis. Although they may offer cheaper rates, robbers have been known to use this trick to lure and attack tourists.\nMauritius is a volcanic island, considered fairly young by geological standards. For a unique experience, consider a day trip to the volcano Trou aux Cerfs to learn more about the island’s ancient past. A “dead” volcano which hasn’t been active in millions of years, Trou aux Cerfs is located in the centre of Mauritius in the middle of the city Curepipe. This area is most easily reached via car, and there is ample parking surrounding the crater where one can park to explore by foot.\nThe crater of Trou aux Cerfs is around 300 metres wide and 650 metres high, and is today covered with silt, water, and vegetation. One can view a great deal of the island from the top of the volcano—including Port Louis and some of the coastal resorts. One can even climb down into the crater to the water, but the trail can be slippery so use caution and good judgement. Also in the town of Curepipe one can visit a lovely botanical gardens and enjoy a delicious dinner at one of the town’s famous restaurants.\n- Beyond Mauritius\n- Mauritius is a volcanic island, considered fairly young by geological standards. For a unique experience, consider a day trip to the volcano Trou aux Cerfs to learn more about the island’s ancient past. A “dead” volcano which hasn’t been active in millions of years, Trou aux Cerfs is located in the centre of Mauritius in the middle of the city Curepipe. This area is most easily reached via car, and there is ample parking surrounding the crater where one can park to explore by foot.\n- Local activities\n- Deep Sea Fishing – Mauritius\nLove fishing? Consider a deep sea fishing excursion off the West coast of Mauritius. Boats usually accommodate up to 5 people, and one can choose between half or full day trips (full day trips typically include both breakfast and lunch). Depending on the time of year, one can expect to find blue and black marlin, multiple types of sharks, yellow tuna, bonito, or barracuda.\nSSR Botanical Gardens\nMore than just for eco tourists, the SSR Botanical Gardens of Mauritius is a 60-acre garden boasting 500 different species of plants (of which 80 are types of palms). Founded in 1770, this is the oldest botanical garden in the Southern Hemisphere. Along with the beautiful plant varieties, the SSR Botanical Gardens also are home to deer and tortoises known for delighting visiting children.\nL’Aventure du Sucre\nFor a fun and educational history lesson, visit L’Aventure du Sucre—an interactive and ultramodern 5000sq metre exhibition on sugarcane. Situated at the heart of an ancient sugarmill, this exhibit also offers great souvenir shopping and tastings of special unrefined sugars and local rum. An authentic Mauritian cuisine restaurant is on site.\n- Local cuisine and drinks\n- The cuisine of Mauritius is a unique blend of Indian, African, Chinese and European influences. Make sure to sample some of the favourite local snacks: gateaux piments (chilli cakes), samosas (vegetable or meat puffs), octopus curry in bread, or rougaille (a variation on the French ragout). The street stalls with the longest lines are most often the tastiest, and local rum is the preferred alcoholic drink.\n- Where you are docked\n- An emerging hub for cruise ships, Port Louis Harbour is visited by over 25 cruise ships each year, carrying over 21,000 passengers. The newly opened Christian Decotter Cruise Terminal is the first in the Indian Ocean capable of accommodating the largest ships in the world. Security at the terminal is high, and access bridges allow passengers and vehicles to easily travel into town.\n- Regional weather\n- Mauritius experiences a micro-climate as do most tropical islands, it could well be raining where you are, yet just a mile away the sky is cloudless and calm. Summer extends from November to April, even the winter which appears from May to October is warm and tropical.', 'Reunion is an overseas territory of France in Africa, located on Indian Ocean, on the eastern side of Madagascar Island. Reunion is known by many to be quite an enchanting destination worthy a visit, thanks to its appealing volcanic landscapes and tropical climate. Its beautiful mountain scenery and sandy beaches are also reasons why you must consider paying Reunion a visit one of these days. The island has its capital in Saint Denis city and all the lovely beaches are located in Saint- Gilles city. Saint- Leu city is well renowned as a surfing city and Saint Pierre is yet another very important city in Reunion as well as Saint Benoit and Etang Sale towns. Other destinations in Reunion worthy a visit are Cilaos, Mafate, Salazie and Piton de la Fournaise.\nA notable celebration in Reunion is anniversary of slave trade abolition which locals celebrate during La Fete Cafre festival. Due to the areas history with slavery, gestures such as calling a local ‘slave’ can have serious repercussions and you need to beware of this. Present day’s population in Reunion is quite varied as the ethnic communications have their unique traditions.\nDespite having close ties with France, Reunion is nonetheless not a designated Schengen area and that has its own rules when it comes to visas and immigration. Hiking trails are perhaps the best things in Reunion and the island has a surprising landscape. The plains, volcano and cirques have been named as the French national natural park. For an awesome hiking experience, it is advisable that you go to Volcano and Mafate Cirque but you can get better guidance from local tour guides.\nGuided island tours in Reunion are also offered by some airline and helicopter companies. Reunion is a great destination to explore thanks to its lovely mountainous scenery which offers a great place for outdoor activities. The beautiful surroundings of Reunion are also great as you can walk around and visit the local villages. Forest walks are also organized by locals as there is a land reforested just next to a local church where you will find numerous waterfalls, picnic spots and pools. Notre Dame Des Neiges is a sacred architecture in Reunion and regarded as a jewel of the place. A spectacular sight at the island is Salazie that you will definitely want to visit and get to see its greenery surroundings and beautiful surroundings that are ideal for picnics.\nThe official language in Reunion is French and only few people will understand English. For English travelers, Reunion is a great place to share your culture as you share their local food and drinks. Being a Eurozone, they use euro as their trading currency. There are numerous shops and supermarkets where you can enjoy a shopping expedition but most of them do not open on Sunday. Traditional items are largely available in these shops including clothing, spices, and run, books on volcano eruptions as well as DVDs and local music. While the island is fairly safe, it is advisable that you travel in a way that thieves don’t find you attractive.']	['<urn:uuid:3670e405-bf2b-4b7e-ab4b-31e754874880>', '<urn:uuid:9710f541-f6af-42ce-8528-3278a804fc45>']	factoid	direct	verbose-and-natural	similar-to-document	comparison	expert	2025-05-12T23:47:20.322175	15	67	1873
77	effectiveness benefits playing multiple different sports during childhood development	Playing multiple different sports during childhood offers significant benefits. Each sport helps develop different muscles and different ways to focus. By trying various sports, children learn diverse skills and have a greater chance of discovering one they truly love. This variety also helps prevent burnout and overuse injuries. Additionally, participating in different sports, especially team sports, teaches fundamental life skills like teamwork, respect, hard work and dedication that can be used throughout life.	"[""House rules of NBA great: Try a lot of sports\nBy Greg Bach\nWhen it came to sports, the rules were simple for former NBA great Kiki VanDeWeghe growing up.\n“My dad was a pediatrician and also a sports medicine doctor and when I was young his one rule was that we had to try different sports,” says VanDeWeghe, who scored nearly 16,000 points during a 13-year NBA career and is the NBA’s Vice President of Basketball Operations. “We had to learn the fundamentals and skills of all the sports and then when we got to be teenagers he said pick one that you really love and apply yourself and be as good as you can possibly be in that sport. And I think that’s a pretty good model for everybody.”\nIs it ever.\nBurnout and overuse injuries never had a chance to sabotage VanDeWeghe’s youth like they have so many other youngsters these days.\nInstead, he played, enjoyed – and reaped the benefits – from trying a multitude of sports.\n“We want kids to participate in athletics and we want them to try all different sports,” he says. “You learn different things from different sports and you develop different muscles and different ways to focus.”\nSo, the more sports kids are exposed to the more diverse skills they’ll develop.\nAnd the greater chance they’ll discover a sport they truly love and will crave playing for years to come.\n“That’s the beauty of sports, especially team sports, is not necessarily playing one in particular; but it’s learning the fundamentals of that particular sport so you can enjoy it the rest of your life,” VanDeWeghe says. “Whether it’s basketball or any other sport, it teaches you teamwork, respect, hard work and dedication – all things you can use throughout your life.”\nMany other lessons are also learned which prove incredibly valuable while transitioning into adulthood.\n“The real lesson in sports – and it comes from my dad – is to learn how to fail,” VanDeWeghe says. “It’s learning how to fail and then coming back from failure. Whatever sport you’re participating in – it can be swimming, it can be water polo, diving, basketball, baseball, it doesn’t matter – you learn about having a bad day. And what happens? You work harder, get better and come back and do it again.”\nCREATING CONFIDENT SHOOTERS\nVanDeWeghe averaged more than 19 points a game during his illustrious NBA career. So when it comes to shooting and helping kids become more efficient and confident at it he’s a great source of insight because he was a real headache for opposing players to defend.\n“A coach told me once to practice the shot that you know you can make and that you will get in the game and develop confidence with that one shot,” he says. “Then you have something to go to in the game, and I thought that was a great learning lesson.”\nBut it all starts with creating that positive vibe where kids feel good about what they’re hearing from you and are enjoying their time with you.\n“If kids are feeling good about what they are doing and they feel that their coaches believe in them and are encouraging them and are rooting for them to succeed they tend to do better,” VanDeWeghe says. “And even on the bad days they realize that ‘hey, somebody believes in me so I’m going to get out there and work and try harder and I’m going to succeed next time.’ It’s all about positive reinforcement.”\nCoaches have lots to cover with their teams, and teaching and modeling good sportsmanship should always be one of the top priorities.\n“Great sportsmanship and what we like to call respect for the game is a huge part of learning lessons in sports and should always be part of sports,” VanDeWeghe says. “It’s an old statement – it’s not if you win or lose but how you play the game – and that starts in practice with having respect for others, showing up on time, working hard, making your teammates better and always having a positive attitude. All those things translate to success.”\nAnd no coach was more successful – or respected – than the Wizard of Westwood.\n“You know there was a great coach at UCLA by the name of John Wooden who never talked about winning or losing and never mentioned it in a pre-game or post-game speech,” VanDeWeghe says. “What he talked about was doing your best, playing your hardest, making your teammates better, and practicing the little things that are going to make you successful. And those are the types of things you want to impart to young players.”\nJamie Clarke has climbed the tallest mountain on every continent and worked with elite athletes on the mental side of the game. Use his insights to elevate your leadership skills and take your young athletes on a journey they'll never forget\n3-time Olympian Allison Baver overcame gruesome injuries throughout her career to excel on the world stage. Use her insight to help young athletes overcome fears lurking in their minds\nTeam USA’s Kendall Coyne cherished her childhood where her parents didn’t pressure and push. The result? Her love for hockey flourished, and is as strong as ever these days\nCurt Tomasevicz, Olympic champion in the four-man bobsled and former football player at Nebraska, on helping young athletes conquer fears, stay focused, and perform at their best when the pressure rises""]"	['<urn:uuid:ff302fce-a047-4642-85f8-309305557bfd>']	open-ended	direct	long-search-query	distant-from-document	single-doc	expert	2025-05-12T23:47:20.322175	9	73	914
78	monofilament vs fluorocarbon fishing line stretch	Monofilament has a wider range of stretch compared to fluorocarbon. Fluorocarbon is much stiffer than monofilament line, and has less stretch. This difference in stretch can be important - for example, when using spinnerbaits, fishing with monofilament feels like using a big rubber band compared to fluorocarbon.	['Bass fishing without a leader can be a great way to catch some large bass. There are some important things you should know about this type of fishing, including the types of line you should use.\nOne of the most popular lines for bass fishing is fluorocarbon. This line provides the perfect balance of strength, low stretch, and line sensitivity. Fluorocarbon line is also abrasion resistant. It’s the perfect line for finesse rigs and slow rolling magnum-sized spinnerbaits.\nDespite its benefits, there are also disadvantages to using a fluorocarbon fishing line. First, it’s much harder to see than monofilament line. Second, it’s more expensive. Third, the abrasion resistance isn’t as good. The abrasion resistance is the ability of a line to resist damage from friction.\nAnother disadvantage is the amount of stretch. Compared to monofilament line, fluorocarbon is much stiffer. That can be a plus or a minus depending on how you intend to use it.\nAside from its stiffness, fluorocarbon is also abrasion resistant. So if you plan to fish in a harsh environment, this is probably one of the best options.\nAlthough fluorocarbon fishing line is tough, it does have some knot issues. In order to prevent line damage, wet the knots before tying them.\nSingle-strand wire is the oldest form of fishing wire. Although it has its flaws, it is still the preferred choice of most experienced anglers. It has several advantages that other wires do not.\nThe first and simplest advantage of using single-strand wire is that it doesn’t get tangled in your hook during casting. Unlike other forms of wire, it is also very easy to work with and has a very low tendency to break. Another advantage of the wire is that it is available in a variety of colors and sizes.\nWire can be used for many different fishing situations. For example, there are various types of wire leaders that are sold. Some of these are made of fluorocarbon, which is a material that is less visible in water, as well as strong. However, they can be expensive.\nOther wire materials include braided and monofilament. Braided wire is tougher than monofilament and is more expensive. To tie braided wire, you’ll need quality wire snips.\nSwivels can make a big difference in the way your lure performs in the water. They also provide you with a break-off point.\nSwivels come in several different sizes. For general saltwater use, a swivel rated between #1 and 2/0 should be used. The larger the swivel, the heavier the weight that it can support. Using a heavy swivel can allow you to cast bigger and heavier lures.\nSome fishermen find swivels to be a nuisance. They get jammed in rod guides. This can cause lost fish. Another concern is that a swivel can spook a finicky fish.\nSnap swivels are another option for those who do not like swivels. These are also used to connect the hook to the line. However, snap swivels are not recommended for tournaments or casting. A snap swivel can add “stuff” to the line and spook a fish.\nIf you are not sure whether you need a swivel, you should ask an experienced angler for advice. When fishing in rough waters, swivels are a must.\nMonofilament is the most common material used for bass fishing leaders. It’s easy to work with, has a wide range of stretch, and is relatively inexpensive. However, it’s also susceptible to abrasion damage, and it’s not designed to float.\nBraided wire is a more expensive option. While it’s tougher and more abrasion resistant, it’s not as strong or transparent as monofilament. Plus, braided fishing lines can be easily snagged in water.\nFluorocarbon is another material that is popular for bass fishing leaders. This material is made of carbon molecules and resists sunlight and harsh chemicals. The refractive index of fluorocarbon is almost the same as that of water.\nAlthough both materials are great for bass fishing, there are some major advantages and disadvantages. When choosing a leader for your line, consider how clear the water is and what kinds of fish you’ll be targeting.\nFor example, if you’re going to be casting a jerkbait into a hole, you need a leader that’s heavy enough to prevent bites. Also, you’ll need one that’s durable enough to withstand sharp teeth.', 'Choosing the right fishing line\nFew aspects of bass fishing have changed more rapidly, or more dramatically, in recent years than the development of new fishing lines. Now, anglers are faced not only with choosing which strength of line the need but also which type of line.\n“Each type of line we use today, braid, fluorocarbon or monofilament, has both advantages and disadvantages,” explained veteran tournament pro Terry Scroggins, who’s been climbing the line-learning curve since he began fishing braids more than a decade ago. “For example, fluorocarbon is nearly invisible underwater and has less stretch than monofilament, and braid has a very thin diameter and extra strength, but virtually no stretch.\n“I believe every bass fisherman has to look at his own style of fishing and the conditions he’s actually facing, and then choose a line that best meets those conditions. The chances are, if you fish very often with several different techniques, you’re going to use all three types of lines.”\nScroggins uses all three, on occasion he combines braid with either a monofilament or fluorocarbon leader to suit the technique he’s using. Here’s how he rigs his rods for a variety of different lures and presentations:\nTopwaters – “Being from Florida, I have always fished a lot of prop baits like a Devils Horse and Boy Howdy, and for these types of lures I prefer 40 pound braid with a four to five foot leader of 15 pound monofilament.\n“Monofilament floats, and with prop baits we often use a very slow presentation during which the lure may sit motionless on the surface for 15 or 20 seconds, so a floating line gives the lures better action. The stretch in the mono also acts as a type of shock absorber for the non-stretching braid.”\nLipless Crankbaits – “I prefer 40 pound braid with a four- to five-foot leader of 15 to 17-pound fluorocarbon. “That’s because I frequently use these lures over hydrilla or milfoil, and many strikes come when you rip the bait out of that vegetation. The fluorocarbon has very little stretch and recovers quickly, while the braid helps cut through the grass.\n“I use the same combination when I’m yo-yoing these lures. Strikes come as the bait is falling, and the braid gives you instant hook-setting; you almost never lose a bass this way.”\nDeep Crankbaiting – “Here I use 10-pound monofilament. It’s strong enough to handle big bass, and the small line diameter allows the lure to reach maximum depth. It has just enough stretch to let the fish engulf the lure for a good hook-set, too.\n“Remember, we used monofilament for years before braids and fluorocarbons were developed, and we caught a lot of bass with it. There are still applications where I think mono out-performs these other lines. Some pros will use fluorocarbon line for deep cranking, but I like mono.”\nFlipping – “When I’m flipping, I use the ‘¾-ounce rule’. If I’m using a ¾-ounce or lighter sinker, it generally means the cover I’m fishing is not very thick nor is it very deep, so I’ll normally use 20-pound or heavier fluorocarbon for its strength and lack of stretch.\n“If I’m fishing slightly deeper and heavier cover, I’ll use 40-pound braid without a leader. Even in the clear water of a lake like Amistad, I’ll use braid because the fish are deeper in submerged timber and I need the strength of braid to get them out.”\nSpinnerbaits – “Depending on the type of cover, I’ll use 14- to 20-pound fluorocarbon. Because I’m in tight contact with the lure, I don’t think there’s a need for braid, although a number of pros do choose it when spinnerbaiting over vegetation. I prefer fluorocarbon because it’s more sensitive and I can feel the blades better.\n“We used to think monofilament was perfect for spinnerbaits, but once you get accustomed to fluorocarbon, using these lures with mono feels like fishing with a big rubber band.”\nShaky Head – “I use six-pound fluorocarbon exclusively with this technique, because I’m not trying for a big bass, but rather, for numbers of fish that are usually in deeper water. I don’t like mono because it has too much stretch.”\nShallow Crankbaits – “When I’m target fishing crankbaits in water six feet or less, I prefer 12- to 15-pound monofilament. It has better castability because it is usually more limp than fluorocarbon, and the visibility of monofilament is not really an issue because I’m usually fishing stained water.”\nSpoons – “My normal choice here is 40-pound braid with a four- to six-foot leader of 14- to 16-pound fluorocarbon. This allows me to make long casts, and because bass nearly always hit this lure while it falls, the braid/fluorocarbon combination gives good hook-sets because of the lack of stretch.”\nCasting Jigs – “With a football-style jig I work on the bottom, I prefer 12- or 14-pound fluorocarbon because of the lack of stretch and visibility, and if I’m working particularly heavy cover, I’ll use 20-pound fluorocarbon. If I’m swimming a jig, however, I’ll use braid without a leader because I’m usually working the lure shallower and want direct contact with it.”\nCarolina Rigs – “I nearly always choose 40-pound braid with a 14- to 17-pound monofilament leader. Mono floats better than fluorocarbon, and in this presentation, it should help my lure as it swims near the bottom.\n“You don’t really lose any sensitivity with mono here, because all your feel comes from your sinker. Most bites on a Carolina rig are nothing more than a ‘heavy’ feeling, and when you learn that bite, it doesn’t mater whether you’re using a monofilament or fluorocarbon leader.\n“The only real advantage I see with a fluorocarbon leader in this case is that it’s invisible. You need a shock absorber in your line system, and because fluorocarbon has such little stretch, you may realize you have to change to a lighter rod for Carolina rigging. To me, that’s a disadvantage, so my choice is monofilament.”\n“When I’m fishing my 10-inch Big Show worms, I use 16-pound fluorocarbon. Again, the advantages are low stretch and near invisibility underwater.”\nWhile most pros have chosen 65-pound braid as their standard, Scroggins feels 40 pound braid is more suitable for his fishing style. The advantage of the smaller size is that it casts easier since he can spool more of it on his reels. Even with 50-pound braid, Scroggins can practically empty a spool on a long cast, which translates into far less cranking power when a bass hits far away\n“I believe the real keys to choosing lines are analyzing both the situations you’re fishing, and then trying different lines and line sizes. Eventually, you’ll settle on some that work best for you, and they may not necessarily be the same choices I use. Each line has distinct characteristics that may or may not be an advantage in your own personal fishing style\n“The best part is that today we all have far more options to choose from than we did just a few years ago.”\n©2015 Bass Edge, Inc. All Rights Reserved.']	['<urn:uuid:6be48702-ff61-4298-a3ab-5e49d9850b1d>', '<urn:uuid:b11cd001-9a17-477f-b5cb-20cae24a4aef>']	factoid	direct	short-search-query	similar-to-document	comparison	novice	2025-05-12T23:47:20.322175	6	47	1905
79	how do trees help environment benefits	Trees provide indirect benefits including soil stabilization and prevention of erosion, windbreaks, sound barriers and air purification. They are also valued for products like pulpwood, paper, cork, rubber, gums, tannin, pharmaceuticals, fruits, nuts and syrups.	"['Values People have always been impressed by trees, by their massiveness and majesty, by the sound of wind in their branches, and by their visual beauty. Legend and folklore suggest attitudes of awe and reverence: YEWS, symbols of eternity; BIRCHES, holy trees; LARCHES, guardians against enchantment.\nTreesTrees are single-stemmed, perennial, woody plants taller than 3 m and exceeding 8 cm in diameter at breast height; shrubs are multistemmed and smaller. These definitions are somewhat arbitrary, since many species (eg, willow, alder, cherry, maple) can grow as trees or shrubs, depending on the environment. Counting the 30-odd shrubs that assume tree form under favourable conditions, there are about 140 native Canadian trees. The largest and oldest grow in the Pacific temperate rain FOREST. Douglas fir is an imposing example and, although it does not reach the size of redwoods or the age of bristlecone pines, specimens 90 m tall, 5 m in basal diameter and older than 1000 years have been reported. Canada\'s tallest reported tree (95 m) is a Stika spruce, the ""Carmanah Giant"" in the Carmanah Valley on the west coast of Vancouver Island. Canada\'s tallest Douglas fir, 94.3 m in height and 8.07 m in circumference, stands near Coquitlam, BC.\nPeople have always been impressed by trees, by their massiveness and majesty, by the sound of wind in their branches, and by their visual beauty. Legend and folklore suggest attitudes of awe and reverence: YEWS, symbols of eternity; BIRCHES, holy trees; LARCHES, guardians against enchantment. The Greeks gave trees spirits (dryads), attributing religious significance to them, as did the druids, who conferred on forest groves and oak woods a sacred, precommercial value now, unfortunately, lost.\nToday, trees are valued for their products: pulpwood, sawtimber, poles, plywood, particle board, paper, cork, rubber, gums, tannin, pharmaceuticals, fruits, nuts and syrups. Indirect benefits include soil stabilization and prevention of EROSION, windbreaks, sound barriers and air purification.\nApart from a few large, single-stemmed FERNS, trees are classified as gymnosperms and angiosperms. Gymnosperms (CONIFERS), with scalelike or needlelike leaves, appear first in the FOSSIL record (Carboniferous period, 353-300 million years ago) and, by early Mesozoic times (Triassic, 250-205.7 million years ago), dominated Earth\'s vegetation. Later in the Mesozoic, during the Cretaceous period (144.2-65 million years ago), broadleaf angiosperms evolved to become the more important group, perhaps profiting from their close relationships with INSECT pollinators and with larger animals which spread their fruits. Angiosperms also developed the ability to reproduce vegetatively by sprouting, an advantage which is shared by few conifers.\nConifers tend to concentrate growth in a central trunk from which many small branches are offset, producing a conical crown. They are usually evergreen, an adaptation fitting them for difficult environments by allowing internal recycling of nutrients from old to new foliage. Broadleaf trees tend to have rounded crowns because side branches grow just as well as main stems, which may fork repeatedly. They are typically deciduous, and grow on more fertile soils and in more moderate climates. There are numerous exceptions: some conifers (eg, larches, CYPRESSES, dawn redwood) are deciduous; some pines have relatively hard wood; some broadleaf trees (eg, POPLARS) have soft wood; others are evergreen, especially in subtropical and tropical climates. The only native Canadian broadleaf evergreen is the red-barked arbutus of southwestern BC.\nTree roots perform both anchoring and absorbing functions. Like the tops, they are distinctive according to species and environment. They may penetrate deeply (taproots of PINE) or spread horizontally just below the surface (platelike system of SPRUCE). Buttress roots, thickened vertically, characterize wet sites, particularly in the tropics, although they are sometimes seen on ELM. Adventitious roots, sprouting from the lower trunk (as on spruce and poplar), are a response to burial by accumulations of peat, silt on river floodplains, or windblown sand.\nIn climates that vary seasonally, the ""growth ring"" is a characteristic anatomical feature of trees. Regenerative, meristematic cells (cambium and cork cambium) sheathe the living trunk, branches and roots just under the bark, annually forming layers of phloem and corky cells to the outside (bark) and xylem cells to the inside (wood). Both bark and wood thicken with age. Products of photosynthesis and various other biochemicals are transported by phloem; water is transported chiefly by active xylem in sapwood surrounding older, darker, nonfunctional heartwood.\nThe water-conducting efficiency of xylem cells is a function of their size, controlled by growth regulators released from the tree\'s growing tips. When shoot growth begins in spring, cambium produces large-diameter cells. Later, in summer, as growth slows and stops, wood-cell diameters decrease. Therefore, a cross-section of trunk, root or branch shows concentric ""growth rings"" outlined by the contrast between the small, dense, latewood cells of one year and larger, lighter earlywood cells of the next. An uncritical count of a tree\'s growth rings may overestimate its true age, since extra flushes of growth in a year can be triggered by weather changes or defoliation, forming false annual rings.\nRing size reflects growing conditions. Where precipitation is the limiting factor, sensitive trees record wet and dry years in wide and narrow rings. Where heat is limiting, ring sizes mirror sequences of warm and cold summers.\nTrees were eliminated by ice-age GLACIERS which covered most of Canada. Deglaciation began about 18 000 years ago, allowing the migration of plants to newly exposed soils. Species with small, winged seeds travelled fastest and farthest, and the boreal zone was filled by spruce, pine, larch, FIR, poplar and birch. Trees that migrated more slowly or were less stress tolerant came later, and they now characterize more favourable environments: southern BC, with numerous conifers; and southern Ontario, with an even greater variety of broadleaf deciduous trees.\nAltitudinal and latitudinal distributions are in part related to wood anatomy: small-diameter xylem cells of boreal species (spruce, fir, ASPEN, ALDER, WILLOW, birch) are less prone to freezing damage than larger cells of ""ring porous"" southern hardwoods (OAK, hickory, WALNUT).\nEach wide-ranging tree species includes locally adapted varieties. Although they seem similar, white spruces from the territories, Newfoundland and southern Manitoba are genetically different and respond differently when planted together. Successful planting is best accomplished, therefore, by using seed from trees native to the area. This variation within species means that the preservation of native trees, as well as that of other plants and animals, in all their genetic diversity, requires the protection of many large, widely distributed, natural areas as ecological preserves.\nSee also individual tree entries.']"	['<urn:uuid:d0dcabe5-b955-4906-a2ff-bab89be208dc>']	factoid	direct	short-search-query	distant-from-document	single-doc	novice	2025-05-12T23:47:20.322175	6	35	1070
80	I need help understanding cleanup methods - what's the main difference between absorbing and containing a chemical spill? Which one should be done first?	Containment should always be done first as it is the first line of response regardless of spill size. Containment involves preventing the spill from spreading by confining it to a small space, often using dike spill socks or creating dams of absorbent material in the spill's path. This is particularly crucial to prevent chemicals from reaching water sources like ponds, streams, or storm sewers. Absorption, on the other hand, is the process of soaking up the spilled liquid using materials like sand, clay, pet litter, paper towels, or specialized absorbent materials. After containing the spill's spread, absorption is used to clean up the confined liquid. The absorbed materials must then be properly disposed of, typically in garbage bags for small spills or drums for larger amounts. Both processes require appropriate personal protective equipment and should be part of a facility's standard spill response protocol.	"['When the flood waters subside, carefully evaluate the pesticide storage area. If this area was underwater, damaged containers and spilled product could result in a potentially hazardous situation. Deal with it the same way as any spill.\nYour personal safety and that of anyone helping you should be the first consideration. Of course, appropriate personal safety equipment should be used, such as heavy-duty rubber gloves, rubber boots, a chemical resistant apron, and eye protection. A respirator may be necessary for some chemicals. If you know the product or products damaged, use the personal protection as required on those labels. When in doubt, use the personal protection equipment suggested. Then follow these standard guidelines for handling spills:\n- Control the Spill: Stop the spill as quickly as possible by restoring the container to its upright position, closing a leaking valve or hose, or putting a secondary container in place to catch the leaking solution. Bags that are broken or soaked through need to be carefully placed in a secondary container, such as a drum or heavy plastic bags.\n- Contain the Spread: When the leak has been stopped, contain the spread of the spill by creating dams of absorbent material in the path of the spilled liquid. It may be most important to first divert a spill away from a nearby pond, stream, or storm sewer before attempting to stop the spill or leak. This is a judgment call that only you can make.\n- Call Your Supplier: Get advice quickly from your agricultural chemical supplier or the manufacturer on cleanup of specific chemicals. They also can provide you with special safety advice and other information.\n- Begin Cleanup Promptly: As soon as the situation has been stabilized, begin cleaning it up. Quick response to a spill is not only required in many states, but will prevent the chemical from leaching or washing away in a rainstorm. If possible, stand upwind or use a fan for ventilation.\n- Use Absorbent Materials: On pavement or concrete, use absorbent materials to capture the spilled liquids. They then can be shoveled or swept into disposal containers. Non-chlorinated pet litter is an excellent, inexpensive absorbent material to keep on hand for such purposes. Large spills may require commercially available pillows of highly absorbent materials.\n- Properly Dispose of the Damaged Containers or Absorbent Materials: If a container is damaged but the contents are not contaminated, transfer the chemical to another clean container. If the product label cannot be transferred to the new container, then you must write the following information on the container:\n- Common or chemical name\n- Percentage of active ingredients\n- EPA registration number\n- Signal word (""Caution,"" ""Warning"" or ""Danger"")\n- Use classification (General or Restricted Use)\nIf there is standing water in your pesticide storage facility, assume it is hazardous until you can check all pesticide containers for leaks or breakage. Do not allow any skin contact with this water. If there is no evidence of pesticide leakage into the water, it can be safely pumped out. However, if pesticides have mixed with this water, the water will have to be pumped to a storage tank for land application. Note: In order to use the water for a land application, it can only be applied to an area (or cover crop) that is on the product label of the pesticide in question. If the water could contain multiple pesticides, you may need to dispose of it as hazardous waste. It depends largely on the amount of water flooding the building (and the amount of chemical that was released). If a land application can be used, it must be at or below label rates, so the amount of product spillage will have to be estimated. The water should be filtered before it enters the spray tank to avoid damaging pumps or clogging nozzles with grit or other debris.Particularly with herbicides, check the product label for any ""plant back"" restrictions regarding planting different crops for the next season.\nBe sure to wear your personal protection equipment during all cleanup operations. If possible, have someone remain nearby checking on you regularly in case you are injured or overcome during cleanup.\nYou may need to obtain further information or assistance before cleaning up the pesticide storage area. In addition to your retail dealer and the manufacturers, the following is a list of numbers where information may be obtained:\nFor More Information\nFor more information on disaster preparedness and recovery visit the NC Disaster Information Center.\nPublication date: June 11, 2014\nRevised: Sept. 2, 2019\nN.C. Cooperative Extension prohibits discrimination and harassment regardless of age, color, disability, family and marital status, gender identity, national origin, political beliefs, race, religion, sex (including pregnancy), sexual orientation and veteran status.', 'Spill Response: When To Absorb and When To Contain\nWhat is a spill?\nSpills always happen in most industrial facilities.\nA spill is defined by Occupational Health and Safety magazine as when an overflow of “high levels of toxic or potentially harmful ingredients or substances that could injure workers,” if the flow is exposed.\nWhat is essential is preventing and containing — and reacting effectively to the spills when it happens. This means having the right tools and knowledge to clear up the mess. What are the tools to manage the spill effectively, and are they updated to the latest modern gadgets? Are these chemical spill contingency plans current?\nReview your relevant government guidelines and protocols to check whether anything has changed. For example, Australia has its national plan that clearly states what actions companies need to take in a marine oil spill or industrial oil spill. Prevention is another area that will reduce the impact of the spill. Your company must install educational visuals that constantly explain the effects of spills. Are there high levels of toxic or potentially harmful chemicals that will cause a fire or explosion or dangerously impact indoor oxygen levels in the facility? The facility must arm people with the necessary information to evacuate everyone to safe ground.\nWhat is Spill Response?\nWhether it is in an industrial facility or transportation of hazardous materials, the potential for spill happens all the time. While data shows that oil spills have lowered worldwide, it is still important to ensure that management trains staff in responding to spills. Besides the regulatory requirement that all employees are trained to handle chemical spills, the management must also observe the strict safety regulations. There are two parts to spill response: absorbing and containing spills. Below is an outline of 7 easy steps to spill response:\n7 Easy Steps To Spill Response\nWhile steps to contain any spill response action plan are the same, the first thing is to assess the spill’s size if the spill involves 50 gallons or more of a liquid. That qualifies as a major spill.\nIt is essential to set up a spill response team. These are the seven easy steps to manoeuvre the movement to spill response.\n- Isolate the area; install warning cones around the incident area; a 25-foot radius is recommended.\n- Evacuate the workers from the workspace determined by the size and type of spill.\n- Call the police or fire department if the content of the spill is considered dangerous according to safety rules.\n- Wear appropriate safety gear such as gloves, eye goggles, mask, and a PPE gown.\n- Use any absorbent materials that help absorb and block the spills from spreading.\n- Sweep and wipe any debris caused by the spill and dispose of it properly.\n- Most workplaces require a report document to the authorities.\nUsage of Spill Kit\nA spill kit is a well-organised set of designed equipment to clean up dangerous substances.\nSpill kits come in duffle bags, wheelie bins, and even trailers. The custom contents of a spill kit include\n- Waste disposal bags\n- PPE wear (personal protective equipment)\n- Absorbents for soaking up the spill\n- A containment boom for preventing further spread of the spill\n- Dispersants (in some cases)\nThe goal of a spill kit is to contain the spill in a short time and clean it up effectively.\nHowever, even with the spill kit, management must ensure that workers are aware of workplace safety knowledge. Everyone must see the importance of working safely in the environment and be prepared.\nSpill Response Procedures: When to Absorb and When to Contain Spills?\nTo respond to this question as to when you should absorb or contain spills, it is important to first note that every workplace should have a standard protocol for containing spills. When a spill occurs, report to your supervisor or manager -no matter how small the situation. The team should be permitted to obtain a material safety data sheet for each chemical and proper procedures to follow up their encounter. Here are some suggested ways to consider whether you should absorb or contain spills:\n- Risk assessment: The first part of the absorbing procedure of spill is to assess the risk by identifying the chemical and choosing the necessary gear to prevent injuries. Consider the situation and specify the Personal Protective Gear required when responding to a spill\n- Control and Containment of Spills\nOnce the case has been addressed, take steps to keep the spill from contaminating the rest of the area. Containing is the first line of response no matter how large or small the problem is. Control the spread of the problem by confining the size to a small space by using absorbent material or neutraliser. Spread the fabric around the perimeter of the spills. Ensure the spill stays in one area and does not flow into a floor drain or other places. Use a dike spill sock to block the spread.\nIf the spill is fast spreading, absorbing the overflow becomes critical. The worksite must have a supply of materials for absorbing the spill—items of absorbent materials, paper towels, and an elaborate kit with special cleaning equipment and personal protective gear. Handy absorbent materials include sand, clay, or even pet litter.\n- Minimise the risk: Block access to spilled material with caution tape to prevent others from coming in contact with it.\nLast step after Containing: Clean up and decontaminate\nClean up the spill and any related damages. Gather the materials used to contain the spill and dispose of them in the specified ways. The garbage black plastic bags will keep a small spill, and drums or pails hold the more significant spill.\nAt the same time, larger spills may require plastic pails or drums. Dispose of any materials used to clean the spill, e.g. brooms. Clean the surface with the right cleaner for spill materials. Use another absorbent material to rinse the floor. Then make sure to have a clean bath to rinse off any chemicals from your skin and dispose of the clothing if necessary.\nYour company needs to have a good safety plan for the right time to absorb and contain a spill. They need to obtain a suitable spill usage kit. The spill plan includes prevention and clear guidance on how and when to handle evacuation. In addition, management must ensure details about proper containment, clean-up, and disposal of spilled material are clearly explained to all workers. That way, workers know how to decontaminate the surfaces where the spill is located. By developing a thorough plan to ensure that the spill is fully absorbed and contained, you are minimising the potential dangers posed by chemical spills.\nEmergency spill response call-outs: Ecospill can help\nEcospill knows that spill events can happen at any time. Ecospill has an after-hours call-out service to supply help at any time, day or night. They have a spill response trailer that they can utilise at a moment’s notice, should you need it, to help protect you, your facility, and the environment.']"	['<urn:uuid:229a1674-df79-4ff0-8e6d-7215f39b8a81>', '<urn:uuid:d7649c94-2bb8-4a47-9e60-c6025918b784>']	open-ended	with-premise	verbose-and-natural	distant-from-document	comparison	novice	2025-05-12T23:47:20.322175	24	144	1974
81	data protection social media security measures steps	Data protection on social media requires several key measures. From social media, businesses must ensure personal data is handled lawfully, implement privacy notices, and advise users to share personal information privately rather than publicly. Additionally, comprehensive security steps include implementing two-factor authentication, regularly updating software and hardware, encrypting customer data, using strong anti-virus software, and running regular vulnerability scans to identify potential cybersecurity vulnerabilities.	['All businesses today need to be concerned with data protection. Nevertheless, with so many different communication platforms, it can almost seem impossible to know where to begin.\nSocial media is an excellent tool in terms of finding out what your consumers want from you and what they think about your products and services. Did you know that 72 percent of companies use data from social media to help them make business decisions? This is a significant number, and if you fall into this category, you need to make sure you use social media responsibly and are on top of your social media data privacy.\nAs we use social media as a direct communication channel between consumers and businesses, it is vital to ensure social media platforms are secure and that you handle any personal data in a responsible and lawful manner.\nKeeping that in mind, in this guide, we will tell you everything you should know about social media and data protection.\nManaging your interactions online in accordance with data protection laws\nWe use social media to post public messages. This can sometimes mean that personal data is exchanged via social media. It is vital to understand that when data is posted on social media, the person using the social media network is the owner of this information. It is certainly not owned by your brand, nor is it owned by any agency that acts on behalf of your business.\nEvery social media platform, be it LinkedIn or Facebook, has its own set of guidelines, as well as in-depth privacy notices. Every social media advertiser and user must comply with this.\nNevertheless, brands must go one step further and establish their own privacy notice. This should indicate how you are going to use personal data in line with the General Data Protection Regulation (GDPR), as well as any other laws or rules that have been implemented.\nData protection when running competitions on social media\nThere is no denying that competitions have become a highly effective method of marketing and advertising on social media. This is a great way of building brand awareness and increasing engagement. Plus, you will create user-generated content as well.\nAfter all, whenever someone enters your competition, they will share your post and advertise your brand to all of their followers. It is likely that some of their own followers will do the same thing, and so it has a powerful snowball effect.\nIf you are going to run a competition on the likes of Facebook or Twitter, it is critical to make sure that you put together some of your own terms and conditions that should explain how to enter the competition, how the competition works, and how data is going to be collected and used.\nWhat to do if a user sends you personal information publicly over social media\nNot only do you need to put together a social media policy for your brand but you need to make a dedicated effort to ensure that this social media policy is being implemented effectively.\nIf someone wishes to share their personal data with your brand, you are advised to send them a message and suggest that they delete this public information and instead send you the data via private message.\nYou can have a boilerplate message ready for situations like this. For instance, your message could state: “We care about our customers’ security, and we advise that you send us any personal details privately for your own safety.’\nUsers on social media may not be aware of what could happen if they were to share personal data via a public domain in this way. So, it is vital to make sure you moderate your platform and provide advice for users where necessary.\nHandling B2C vs B2B data\nIt is vital to understand that the GDPR only applies to personal data that relates to an individual. This is not a regulation that is applicable to company information.\nHowever, there can be a few blurry areas, which you do need to keep in mind. For example, the contact details of an individual or individuals working for a specific organization or business fall into the definition of personal data. This means you are not allowed to share the name of an employee, or their phone number, email address, or social media account.\nThe only exception to this is when there is a generic email address that a number of different staff members use and monitor. For example, email addresses that begin with “[email protected]” or “[email protected]” will fall into this category.\nIf the individual’s information comes under the GDPR’s definition of personal data, you do need to continue to act in accordance with all of the GDPR rules and regulations.\nSome of the different pieces of information in the B2B sphere that is not deemed personal information, and therefore do not relate to GDPR, include the number of people that currently work for the business, financial figures, or a postal address for the enterprise itself.\nHow does GDPR impact linking your social network channels?\nWe’re sure that you probably link your social network channels to your website or your email, and so it is vital to make sure you are doing this in a responsible manner.\nThe good news is that there is nothing that restricts you from linking your social media channels via your email or website under the General Data Protection Regulations. This is a great way of integrating your marketing efforts and reaching more people online.\nHowever, you will need to ensure that there is a part of your data privacy notice that explains how you will utilize any of the contact data you collate on social media.\nCompanies also need to make certain that they create and implement a social media policy internally. This policy is designed to make sure that people working for your company know how they should use and respond to any data that has been sourced via social media.\nManage custom audiences on social media while also adhering to GDPR\nNext, we need to understand how to use custom audiences on social media. A custom audience refers to a list of consumer contacts that fall within a specific area of your audience.\nFor instance, you may decide that you are going to create a custom audience list that is made up entirely of social media accounts that engage with your business regularly. The list may contain all of the people who have engaged with your brand “x” number of times on Twitter, for example.\nTo create a list of this nature, you must share consumer information so that the platform can match it with their database. Typically, an email for the customer will be required. In some cases, you may need their phone number from their mobile SIM plan.\nAn important part of this process involves data scrambling or “hashing” – this means making sure that the data is obscure but still unique. This ensures that matching can be a success while also keeping the data protected from threat actors.\nOnce the information is matched, this gives you the ability to target customers on your list with specific adverts that are going to be more likely to appeal to them when they are using the social media platform in question.\nIt can be highly effective to create a custom audience. This is particularly the case if you segment the list before it is uploaded.\nIn this situation, it is imperative to make it clear and evident within your privacy notice that the personal data you hold about your consumers is going to be used for the purpose of finding them and contacting them via social media. Of course, they should also have the option of being able to opt-out of this if they wish to do so.\nIn fact, Facebook has implemented a Custom Audiences Permission Tool, which means that marketers will need to confirm the correct consent has been obtained under General Data Protection Regulations. You won’t be able to upload personal data to create your custom audience without doing this.\nIf you have a data privacy notice that you have already developed, yet it does not include a statement regarding the data you already hold and how you will use this to find consumers on social media, you must amend your data privacy notice as quickly as you are able to so you can show that this is the case.\nYou should choose language that is easy to understand. Clearly explain how this data is going to be shared with social network platforms. Also, make sure that you state that this is going to be done on a legal basis of consent.\nAnother option that a lot of businesses like to follow when it comes to the use of data is the creation of “lookalikes.” As the name indicates, this involves incorporating individuals that have characteristics like your customers in the initial upload. This is used to expand your audience at a quick pace, and it is proven to be highly effective.\nShould you decide to use this approach, you are not going to need to get consent from your customers because you are not going to get targeting that individual consumer specifically. Rather, you are going to be targeting individuals that are like that person.\nWhat about retargeting adverts on social media?\nNow, let’s move on to the area of advertisement retargeting on social media, which will provide you with the ability to show adverts to people who have already been on your website before.\nIf you go down this route, a pixel will be placed onto your website, which visitors are unable to see. Basically, in the user’s browser, a unique cookie will be placed. This means that you can easily identify whether or not a person has visited your website before.\nWe are sure that you will have seen a cookie pop-up when landing on a website previously, and this is the sort of thing that cookies are used for.\nHowever, do make sure that consent is sought when it comes to using these sorts of cookies. This is required as per the Privacy and Electronic Communications Regulations. It is imperative that you ensure the consent you receive for the use of retargeting cookies meets the standard of content that the GDPR states.\nGeneral cybersecurity measures your business will need to adhere to\nOne thing that all companies need to take very seriously today is cybersecurity. If you turn on the news on TV or do a quick search online, you will see that there seems to be news about a big data breach every week, if not every day.\nIf your company ends up suffering a breach due to weak social media security, you could find yourself with monumental reputational damage and massive fines to pay.\nAt a very basic level, you should be doing the following:\n- Make sure that all client or customer personal data is encrypted and stored in a secure manner.\n- Any CRM solution or software you use that involves personal information needs to have multi-factor authentication. This means that it is not only password protected but another layer of security is implemented as well.\n- Put in measures to ensure that you have a secure network. Examples include firewalls, network segregation, encryption, and much more.\n- Make sure that every single device that is connected to the Internet has strong anti-virus software in place.\nIf cybersecurity is not an area that you have any sort of experience in, it certainly makes sense to look for a personal cybersecurity company that can do a test to figure out what vulnerabilities you currently have so that you can put steps in place to rectify them.\nClosing words on data protection and social media\nAs you can see, there is a lot that needs to be considered when it comes to protecting your business on social media. However, this is not something you can afford to overlook. It is your responsibility to make sure all data is handled correctly.', 'Data security is an increasingly important issue for businesses of all sizes. With ever-evolving cyber threats, it is essential that businesses take proactive steps to secure their data and protect against malicious activity. Fortunately, there are a variety of measures that can be taken to ensure the safety of your business’s data and systems. From implementing a comprehensive security policy to utilizing secure cloud storage solutions, there are many practical steps businesses can take to help protect their data.\nIn this article, we’ll provide an overview of 6 practical steps to secure your business and protect your data. By following these steps, you can ensure that your data is not only secure but also easily accessible when needed.\n#1: Develop a comprehensive security policy\nA security policy will help your business identify what data is critical and how that data is being used. This will help you prioritize which security measures are most important, such as securing remote access or creating a robust incident response plan. A comprehensive security policy should include a strategy for managing data risk and include a schedule for testing your security posture. It is also important to have a plan for responding to an incident and identifying who is responsible for managing these risks. Once you have a comprehensive security policy in place, it is important to follow it rigorously.\nYou can also buy services that help store your data and protects your documents. For example, a company such as the docshop prides itself in being e waste recycling company that is easy, confidential, and professional. Something like this can help you prevent organizational complacency and ensure everything is safe without having to do it all yourself.\n#2: Implement two-factor authentication\nTwo-factor authentication, also known as tokenization, is essential for securing remote access to sensitive systems and data. Client devices are often one of the weakest links in a security architecture. When these devices are stolen or confiscated, it can have devastating consequences for an organization.\nThis can lead to sensitive information being accessed, deleted or altered. To prevent this, it is important to implement two-factor authentication on the devices that employees use to access sensitive systems.\nTwo-factor authentication can be implemented in a number of ways. It is possible, for example, to link an app to a security system. This way, if an employee with the right device tries to access an app that has been previously verified, the employee will be required to enter a code sent to their mobile device.\n#3: Regularly Update Software and Hardware\nIt is important to regularly update software and hardware to help prevent cybersecurity vulnerabilities. New software and hardware releases often contain security vulnerabilities that hackers exploit to infiltrate systems. It is also important to update critical software and hardware, such as operating systems, as new versions are released.\nNew versions frequently include security patches that can help prevent vulnerabilities from being exploited. It is also important to follow best practices when updating software and hardware. For example, updating software on a scheduled basis will ensure that you do not experience any outages.\nIt is also important to update hardware when it is due. This helps ensure you do not experience any downtime. It is also important to regularly back up data. This helps ensure that you have a copy of your data in the event that your device or software is compromised. It is important to back up data using an external hard drive or cloud storage solution. It is also important to select a reliable backup solution.\n#4: Secure Mobile Devices and Remote Access\nAs data breaches and cyberattacks become more frequent and sophisticated, it is increasingly important to protect remote access. Remote access is often leveraged to access data that is stored on different systems, such as cloud storage or legacy systems. It can also be used to support interactive workflows that require employee collaboration.\nRemote access solutions can be categorized into public and private solutions. Public remote access solutions, such as Team Viewer, are accessible by anyone with an internet connection. This may not be ideal, given the risk of data theft or unauthorized access.\nPrivate remote access solutions, on the other hand, are accessible only by authorized individuals or organizations. Some private remote access solutions, like Mango Networks’ RemoteAccess VPN, offer hybrid cloud access options that utilize both private and public cloud storage.\n#5: Restrict access to sensitive data\nIt is important to restrict access to sensitive data. This helps ensure that only authorized individuals have access to this data. This can be accomplished through the use of access control lists (ACLs), role-based access control (RBAC), or access management solutions. It is also important to audit ACLs and access management solutions on a regular basis to ensure they are working as intended.\nAccess control lists can be leveraged to help manage data risk. They can be used to ensure that data with a high level of risk is accessed by authorized individuals only. These can also be used to help manage access to data that is shared across your organization. It is also important to monitor access to data using monitoring solutions. These can be used to help identify when a member of an organization has accessed sensitive data that should not have been accessed.\n#6: Run regular vulnerability scans\nVulnerability scans are essential for identifying potential cybersecurity vulnerabilities within your organization. It is important to select a reliable and trustworthy vulnerability solution. It is also important to select a solution that is supported by your organization’s preferred vulnerability solution. It is also important to select a solution that is supported by your organization’s preferred vulnerability solution.\nVulnerability scanning helps identify potential issues within your infrastructure, such as unpatched servers, outdated software, and weak passwords. It is also important to regularly run vulnerability scans to help identify new issues and ensure your infrastructure is being kept as up-to-date as possible.\nIt is also important to leverage penetration testing solutions when doing this work. Penetration testing will help identify any potential issues around data security. It is also important to leverage penetration testing solutions when doing this work. Penetration testing will help identify any potential issues around data security. It is also important to leverage automated threat feeds when doing this work. These will help provide real-time information on potential cyber threats.']	['<urn:uuid:e0394603-45d1-4adb-b528-b96b05e1f665>', '<urn:uuid:6f7551cf-cf84-499e-bdb0-95ff7903a771>']	open-ended	direct	short-search-query	similar-to-document	multi-aspect	novice	2025-05-12T23:47:20.322175	7	64	3077
82	I'm preparing applications for both med school and scholarships - what's the best timing strategy for submission materials?	For both medical school and scholarships, starting early is crucial. For medical school letters of intent, you should write them about a month after your interview, particularly if waitlisted. For scholarships, you need to begin gathering materials months ahead of deadlines since you'll need recommendation letters, transcripts, essays and personal statements. In both cases, you should carefully review all submission guidelines and deadlines, ensure materials are error-free by having others proofread them, and maintain professionalism in all communications. Neither process should be rushed - quality is just as important as quantity of applications submitted.	"['Well, what’s a letter of intent for medical school?\nYou’ve completed prerequisite courses, thoughtfully chosen extracurricular activities, earned a high GPA and stellar MCAT scores, completed first and second round medical school applications, and even attended a few interviews.\nNow, there’s nothing left to do but wait. Or is there?\n- After interviewing or even after being waitlisted, there are additional steps you can take to strengthen your chances of acceptance (and to keep from feeling helpless as you play the waiting game).\nOne of the most persuasive additional steps you can take is writing a letter of intent to your first-choice school.\nIn this guide, we’ll explain what to include in a letter of intent and how to structure it, in addition to providing Do’s and Don’ts and answering frequently asked questions.\nWhat is a medical school letter of intent?\nA letter of intent informs a medical school that it is your top choice and that you will accept admission there if offered.\n- This is not be confused with the “other” LOI, the letter of interest.\n- There are, however, some similarities between the two.\n- Both the letter of intent and the letter of interest convey your interest in a school, what you would contribute to that school, and why you’re a great fit based on factors like culture, academic environment, curriculum, etc.\nThe main difference is in the name: A letter of interest simply verifies that you’re still interested, while a letter of intent confirms your intention to enroll if admitted.\nWhen should I write a medical school letter of intent?\nWrite a medical school letter of intent about a month after you have interviewed with a school if you have not yet been admitted or have been waitlisted.\n- Don’t write a letter of intent to a school that has not invited you to an interview or has not shown continued interest in admitting you.\n- Also, there’s no need to write a letter of intent to a school that has accepted you.\nIf you’ve already been invited to an interview but the interview hasn’t taken place yet, wait.\nIt can seem disingenuous to tell a school that they’re your top choice before you’ve had a chance to sit down with an interviewer.\nBefore writing a letter of intent, review the school’s previous communications with you, as well as their website and applicant portal.\n- Does the school encourage updates and ongoing communication?\n- Do they offer additional instructions to deferred or waitlisted candidates?\nIf you’re unsure, try reaching out to other medical school students or anyone you may know at the school.\n- In most cases, it’s safe to write the letter unless the school directly states that they do not want ongoing communication from applicants.\nIf the school expresses that they do not want letters of intent and you send one anyway, it can hurt your chances by demonstrating that you do not follow directions.\nHow many schools should I send my letter of intent to?\nOne. Only one school can be your top choice, so this is the school that should receive your letter of intent.\nAlthough a letter of intent is not a legally binding document, it is unethical to send a letter of intent to a school and not enroll there if accepted.\nA letter of intent is a promise that a school is your first choice.\n- This means you shouldn’t send a letter of intent unless you are certain that you would accept an offer of admission from that school—and that you would be thrilled to do so.\nIf you don’t want to limit your options, send letters of interest to several schools instead.\nWhat should I include in a medical school letter of intent?\nA medical school letter of intent should include:\n- A clear statement that the school is your top choice and you will matriculate there if admitted\n- An explanation of why the school is your top choice\n- Several reasons why you are a good fit for the school/an explanation of what you would contribute\n- Any additional achievements or updates since your interview (e.g. additional community service hours and their impact, anything you’ve done to strengthen areas of weakness, etc.)\nYour letter of intent should not be longer than a page, so make a list of the most important information you’d like to include before you start writing.\nThen, communicate your interest and fit as clearly and succinctly as possible.\nA letter that rambles or is too long may be more annoying than appreciated.\nHow should I structure my letter of intent?\nThe letter of intent should be structured like most traditional formal letters:\n- Address the letter to the dean or director of admissions.\nIf you aren’t sure who this person is, do your research.\nEven if you think you know who this person is, double check to ensure that your spelling and titles are accurate.\nFeel free to add a memorable interviewer that you clicked with to the email as well. Use the formal greeting “Dear” rather than “Hello,” and definitely don’t use “Hi.”\n- Paragraph 1: Introduce yourself and state your purpose for writing the letter.\nState your name and the date of your interview. Briefly say how much you enjoyed the interview.\nThen, get right to the point: Explain that your purpose is to reiterate that the school is your top choice.\nYou can even say something as blunt as, “If accepted, I will definitely attend [School].”\nAlso mention that your letter will explain why you’re a good fit for the school and, if applicable, update the school on new accomplishments that may not be included in your file.\n- Paragraph 2: Explain what you love about the school.\nGive specific reasons that you’ve fallen in love with this particular medical school: collaborations with major area hospitals, opportunities for dual degree programs, unique research opportunities or student clinics, and information about the school that excited you during your interview.\nMake sure the reasons you mention are specific to this school, not something that any medical school could offer.\n- Paragraph 3: Mention why you’re a great fit.\nIf you can find a way to mesh this part into your second paragraph, that’s fine too.\nJust be sure that you explain not only why you love the school, but also why you would be a great fit.\nPerhaps the mission or vision particularly resonates with you based on your personal experiences, or the curriculum complements your learning style and personality well.\nBriefly highlight a few reasons that you’re a unique and excellent candidate who has a lot to contribute to the school.\nMake it clear that you will be actively involved on campus and plan to be an asset to the school.\n- Paragraph 4: Update the school\n…on any new developments, such as accomplishments at your job or somewhere you volunteer, a research publication, a leadership experience, an effort to improve upon any weaknesses, etc.\nYou can also discuss future plans that may interest the school.\nIf you have a particularly noteworthy new accomplishment and you want to be sure the school sees it, you may want to mention this in your second paragraph instead.\n- Conclusion: Briefly restate your intent to attend the school…\n…if admitted, as well as your belief that you are a great fit. Say that you look forward to the rest of the application process or that you hope to see them in the fall.\n- Close the letter. Use a formal closing like “Best wishes” or “Sincerely,” followed by your name.\nDO’s and DON’TS\nFollow these steps to write the best letter of intent.\nAs with most rules in writing, don’t break them unless you’re supremely confident in your alternative strategy.\n- Double check your letter for spelling and grammar.\nIt’s best to have someone else proofread your letter as well.\nMake sure that you haven’t forgotten any attachments and that you’ve used appropriately formal language throughout the letter.\n- Show personality.\nWhile being appropriately formal, don’t be afraid to show a bit of your personality and use your genuine voice.\nA heartfelt, persuasive letter can go a long way in helping you get accepted to your dream school.\n- Use specific details.\nSpecific details concerning what you love about the school make your letter more convincing.\nThese details indicate that your interest is genuine and that you’ve spent time researching the school and envisioning yourself on campus.\n- Show enthusiasm.\nUse a passionate, enthusiastic tone when writing about the school. Think of it almost like a love letter, but don’t overdo it or exaggerate.\nAllow your authentic excitement about the school to shine through.\n- Mention other acceptances.\nIt’s fine to mention that you’ve been accepted to other schools by saying, “Although I’ve been accepted to other medical schools, your school remains my top choice and I will attend if accepted.”\nThis shows that your letter doesn’t represent a desperate plea for acceptance to any medical school, but a genuine desire to attend this medical school in particular.\n- Save your letter as a PDF.\nThis prevents any changes to formatting. After saving your letter as a PDF, attach it an email or upload to the school’s application portal.\nMost medical schools specify which approach they prefer.\n- Spend too much time restating information already in your application.\nAlthough you do want to explain why you’re a good fit and a strong candidate, you don’t want to spend too much time rehashing information the school already knows.\nA quick recap of your highlights is sufficient, then focus on specific reasons you and the school complement one another.\n- Sound too arrogant.\nDon’t make it sound like you’re overconfident that you will eventually be accepted, and don’t imply that the school would be wrong not to accept you.\nUnderstand that the school has plenty of qualified applicants, and simply explain why you think you’re a good fit. State that you’re honored to be considered by the school and would be delighted to attend.\n- Send multiple letters of intent.\nWe’ve mentioned this already, but it can’t be emphasized enough. Don’t send multiple letters of intent in a bid to get acceptance letters.\nOnly write a letter of intent to your first choice—this is an exclusive commitment.\n- Write more than a page.\nYou want to include several specific details about the school and why you love it, but try to limit your letter to one page.\nIt’s possible that the admissions director will only skim letters of intent as it is. Make a list of essential information to include, then keep your letter brief.\nFAQs: Letter of Intent for Medical School\nQ: Do medical schools appreciate letters of intent?\nA: Yes. Unless the medical school has specifically stated otherwise, letters of intent are appreciated and can be a factor in your acceptance to a school.\nMedical schools want a high yield rate, meaning they want to accept students who will eagerly attend.\nIt can certainly help to share with a medical school that you are sure to enroll if admitted.\nQ: Should I send a follow-up letter of intent?\nA: It’s acceptable to send an additional letter of intent (to the same school) about a month after sending your first letter.\nThis is only the case if your situation has remained the same: You are still waitlisted or waiting to hear back, and you have not yet been rejected or accepted.\nAlthough many students fear they will come off as too aggressive or potentially obnoxious, demonstrating clear enthusiasm and a desire to attend the medical school can only help you (unless the medical school has stated it does not want additional communication from applicants).\nQ: What if I’m not sure which school is my first choice?\nA: If you’re undecided and don’t have a clear top choice, avoid writing a letter of intent.\nIf you write a letter of intent, you’re ethically obligated to attend that school if they accept you.\nThis means that if you’re not 100 percent committed to one school, you want to keep your options open. Instead of writing a letter of intent, write a letter of interest to several schools that have caught your eye.\nQ: What if there’s no new information to add to my file?\nA: It’s okay if you don’t have any updates.\nTry to pursue additional opportunities and experiences after applying to medical school, and rack your brain for anything new that might make you a more attractive candidate.\nBut ultimately, if there’s nothing of interest to add, just skip that part of the letter.\nFocus on making the other portions of your letter—like the reasons you’re excited about the school and what you’d contribute if admitted—excellent.\nAfter all, there are letters of update for applicants with new information.\nThe true purpose of the letter of intent is to emphasize that a school is your first choice and you’re committed to attending if admitted.\nFinal Thoughts: Medical School Letter of Intent\nWriting a medical school letter of intent is a great way to tell a medical school that they are your clear first choice, which can increase your chances of acceptance.\nKey information to remember includes:\n- Only write a letter of intent to ONE school (your first choice).\n- Write the letter of intent about a month after being interviewed, particularly if you’ve been waitlisted.\n- Clearly state that you will attend the school if given the opportunity.\n- Include what you love about the school, why you’re a good fit/what you offer, and any new information that could influence the admission decision.\n- Use your authentic voice, but be sure to keep it formal.\n- Limit your letter to one page.\n- Don’t send a letter of intent to a school that has given specific directions not to do so. Also follow directions concerning how the school would like the letter delivered (via email or via their applicant portal).\nAs always, don’t forget to proofread, and ideally, have others review your letter of intent as well.\nBe heartfelt and convincing, highlighting a true passion for your first-choice school.\nAfter all, a persuasive letter of intent can propel you off the waitlist and into the medical school of your dreams.', ""Scholarship Application Process\nBefore you can apply for scholarships you must first put together a list of scholarships you're interested in. Then you must organize them according to application deadline, prioritizing those with the earliest deadlines. The next and final step is to sit down and actually go through the application process for each scholarship. The more scholarships you apply for the greater your chance of receiving a scholarship award. However, don't hurry yourself. The quality of each application you submit is just as important as the number of applications submitted. The tips below will help you maximize the effectiveness of the scholarship application process.\nStart early.A scholarship application requires more information than just a name, citizen status, and birthdate. You'll be required to provide more than just basic contact information. Most scholarship applications require letters of recommendation from teachers or employers, academic transcripts, cover letters, resumes, essays, and multi-page personal statements. And nearly every scholarship has an application submission deadline. To ensure you meet application deadlines, start gathering everything you need, begin brainstorming for personal statements, and request letters of recommendations months ahead of time. Don't begin writing your personal statement or essay the night before the submission deadline. A key to obtaining scholarship awards is starting the application process long before the submission deadline.\nDon't loose focus of the detail.Applying to several scholarships is the best strategy for maximizing your chances of receiving a scholarship award, but be careful. When students are applying to several scholarships, it's not uncommon for them to mix up the details of their scholarship applications. Make sure you know the specific requirements for each scholarship for which you apply. Overlooking critical detail, or neglecting just a few requirements, can disqualify you from a scholarship award. Read the directions for each scholarship carefully. If you have any questions, don't hesitate to reach out to the scholarship provider via email or a phone call. Believe it or not, scholarship providers are eager to answer your questions and assist you.\nBe OriginalImagine that you're asked to review a thousand scholarship applications and to determine which applicant should receive a scholarship award. After reviewing all one thousand scholarship applications, you're about ready to keel over from exhaustion and boredom. All one thousand applications re really good. All the applications included the requisite number of personal statements, letters of recommendation and essays. They all followed the application guidelines perfectly. But they were all pretty much carbon copies of one another. None of the applicants stood out from one another as original or unique.\nWhen preparing your scholarship application, it's important you follow all application rules and submission guidelines. This does not however mean you shouldn't be orginal. Remember, scholarship judges are people just like you and me. The last thing they want to do is review one thousand scholarship applications that are essentially the same. As you prepare your scholarship application, include information and exhibits that will help set you apart as interesting, unique and especially deserving.\nPay attention to presentation.Pay attention to the presentation of your scholarship applications. Sometimes, presentation is just as important as content. If you've written a great essay, and meet all the scholarship requirements, but submit an application that is sloppy, you could jeopordize your chances of receiving the scholarship award. All things being equal, the student who submits a neat and professional looking application is going to have an advantage over other applicants. Even if it's not required, you should type your responses to essay questions. If you must fill out the application itself by hand, use your very best pennmanship. Never submit an application with with smudges, white out or other blemishes.\nHave someone else review your application for errors.Whether you're applying for one or a hundred scholarship awards, it's easy to make mistakes on a scholarship application. However, the likelihood of making errors will increase, if you're applying for several scholarships. Before submitting your application(s) have good friend, maybe your parent, review your application(s) for errors. A second pair of eyes will often spot errors that you missed.\nHave someone review your essay.Just as critical as the application itself, is the application essay. With respect to flow of thought, clarity and grammar, your essay should be flawless. We recommend having your teacher read your essay and provide feedback. If your teacher isn't available, find a school counselor, qualified adult or even a friend who can review your essay for you. A second pair of eyes will be able to identify issues with incohesiveness and grammar that you are not. Ask your reviewer to make sure your essay adequately addresses and proves your thesis. Also, ask them if they like your essay or have any other feedback. Don't forget, the scholarship judges are people just like your teacher, parent and friend. If the person you have review your essay finds it compelling, the judges probably will too.\nFollow all application submission rules.You've written the perfect essay. You've completed the application. Now it's time to submit your application. When submitting your scholarship application, follow submission instructions precisely. Neglecting to do so could cost you your scholarship. Most scholarship committees have very specific application submission guidelines. It's important you follow these guidelines. Some applications can be e-mailed. Others must be submitted via U.S. Mail in a plain white envelope with a stamp. If you're not familiar with the submission guidelines for a scholarship, find out. Call or write the scholarship provider, if necessary. Not following submission guidelines can automatically disqualify you for consideration.\nAlways be professional and courteous when addressing members of scholarship committees. Many people are impressed by professionalism, and even if you're not awarded a particular scholarship, committee members could recommend you to other organizations offering scholarships.""]"	['<urn:uuid:0ef5810b-5cdd-40d5-857a-d13f0a346852>', '<urn:uuid:5a91d2da-6ccc-4f0b-b1b9-9a9e6fd7a411>']	open-ended	with-premise	concise-and-natural	distant-from-document	three-doc	expert	2025-05-12T23:47:20.322175	18	94	3344
83	What are the common hand tremors that people experience day to day, and how do they differ from the tremors caused by alcohol withdrawal?	Regular hand tremors that most people experience are typically mild and especially noticeable when holding hands straight out in front of the body. These tremors can occur without any underlying condition and may happen during voluntary movement (action tremor) or when muscles are relaxed (resting tremor). In contrast, tremors during alcohol withdrawal are more severe and progress differently. Alcohol withdrawal tremors begin 6-12 hours after the last drink, intensify over the next 24-48 hours, and are accompanied by other symptoms like sweating and anxiety. While regular tremors usually don't significantly impact daily activities, alcohol withdrawal tremors can be severe enough to require medical attention, especially if they develop into delirium tremens, which can be life-threatening.	['What Does a Hand Tremor Mean?\nA tremor in the hand can occur without a cause of an underlying condition. Shaky hands are not always a sign of a life-threatening symptom, but it can have an impact on daily activities. Most people have a slight tremor in the hands, and it may be especially noticeable when holding the hands straight out in front of the body. Tremors can range in severity, and several conditions can cause more noticeable shaking.\nWhat is a tremor? A tremor is an involuntary, rhythmic muscle contraction that causes shaking. Tremors are most common in the hands, but they can also occur in the arms, head, vocal cords, torso, and legs. Tremors can be intermittent, happening every so often, or constant. Sometimes tremors develop on their own, and other times they signal an underlying health issue. Shaky hands may lead to difficulty writing, driving, or other everyday tasks. A resting tremor occurs when the muscles are relaxed, such as when the hands are resting on the lap. Anaction tremor happens when the muscles are contracted because of voluntary movement.\nWhat causes shaky hands? In some cases, the cause is unknown, but tremors often result from neurological conditions, movement disorders, or other health problems.\nSome neurological conditions that can cause shaky hands include:\nMultiple sclerosis (MS): A tremor often develops when the disease damages areas in the pathways of the central nervous system that control movement.\nStroke: An ischemic stroke occurs when a blood clot blocks an artery, preventing blood from reaching the brain. This can cause lasting damage to neurological pathways and lead to tremors.\nTraumatic brain injury: Physical injury to the brain can also damage nerves that play a role in coordinating movement. Hand tremors may occur when an injury affects certain nerves.\nParkinson’s disease: More than 25 percent of people with Parkinson’s disease have a related action tremor, as well as a more common resting tremor in one or both hands. Tremors usually begin on one side of the body, and they may spread to the other side. Shaking may become more pronounced during periods of stress or strong emotion.\nMovement disorders that can cause hand tremors:\nPsychiatric conditions, such as depression or post-traumatic stress disorder\nInherited degenerative disorders, such as hereditary ataxia or fragile X syndrome\nAlcohol abuse or withdrawal\nHyperthyroidism, or an overactive thyroid\nLiver or kidney failure\nAnxiety or panic\nCertain drugs can also cause hand tremors, such as:\nSome asthma medicines, amphetamines, caffeine, or corticosteroids\nMedicines used to treat certain psychiatric and neurological disorders\nWays to try to stop your hands from shaking:\nIf an underlying condition is responsible for the tremor, it will usually get better with treatment. If a tremor is a side effect, it will often go away when medication is switched.\nThe following may also help:\nLifestyle changes: Limiting or avoiding substances that can cause tremors, such as caffeine and amphetamines, can reduce or eliminate a person’s shaking.\nPhysical therapy: This can improve muscle control, functioning, and strength while enhancing coordination and balance. An occupational therapist can help people living with tremors to continue to engage in daily activities.\nPsychological techniques: If anxiety or panic is responsible for a tremor, a person may benefit from practicing relaxation techniques, such as breathing exercises.\nWhen to seek treatment If you have noticed a new or increased tremor in your hands, make an appointment.\nSource: Medical News Today', 'What Causes Alcohol Withdrawal?\nEvery year more than one and a half million people in the United States either enter alcoholism treatment or are admitted to a general hospital because of medical consequences resulting from alcohol dependence . These patients, as well as a substantial number of other people who stop drinking without seeking professional treatment, experience the effects of alcohol withdrawal.\nHeavy drinkers who suddenly decrease their alcohol consumption or abstain completely may experience the effects of alcohol withdrawal. Signs and symptoms of AW can include, among others, mild to moderate tremors, irritability, anxiety, or agitation. The most severe manifestations of withdrawal include delirium tremens, hallucinations, and seizures. These manifestations result from alcohol-induced imbalances in the brain chemistry that cause excessive neuronal activity if the alcohol is withheld.\nManaging the effects of alcohol withdrawal includes a thorough assessment of the severity of the patient’s symptoms and of any complicating conditions, as well as treatment of the withdrawal symptoms with pharmacological and nonpharmacological approaches. Treatment can occur in both inpatient treatment and outpatient settings. Recognition and treatment of withdrawal can represent a first step in the patient’s recovery process.\nGet Your Life Back\nFind Hope & Recovery. Get Safe Comfortable Detox, Addiction Rehab & Mental Health Dual Diagnosis High-Quality Care at the We Level Up Treatment Centers Network.Hotline (877) 378-4154\nTimeline of the Effects of Alcohol Withdrawal\nThe effects of alcohol withdrawal timeline start as early as two hours after drinking, peaking in severity approximately two to three days after the last drink. Alcohol withdrawal symptoms can last for up to a year after quitting, although this tends to be limited to temptation and relapse. The variety of symptoms changes, depending on the amount of time since someone last consumed an alcoholic drink.\n6 to12 Hours After Quitting Alcohol\nDuring the first six to twelve hours of the alcohol withdrawal timeline, symptoms begin setting in roughly at hour six. That is the reason why many alcoholics have to start drinking the moment they wake up. Since the symptoms are so severe, many wrongly assume that the 6-12 hours stage is the most dangerous, but that is the 24-48 hours phase in reality.\nSymptoms include, but are not limited to:\n- Alcohol is an addictive drug or substance. So naturally, when a person suffering from alcohol use disorder does not have it, they crave it. Unfortunately, cravings are terrible at this stage since the person knows that drinking would relieve all the unpleasant effects of alcohol withdrawal.\n- Throughout the initial stage of the alcohol withdrawal timeline, an individual’s mind and body are all out of whack. A person will feel sick, uncomfortable, hurt, and various other bothersome symptoms that can increase a person’s anxiety. For those who already experience high anxiety, these feelings will be doubled.\n- Extreme Sweating\n- The body begins to overheat when alcohol is no longer in the system. Sweating is the body’s attempt to protect and cool down the organs. Sweating through your bedsheets is expected, so keeping a high fluid level is so important to the doctors who are monitoring the process.\n- It is usually caused by loss of body fluid and dehydration.\n- Alcohol does change the way a person sleeps; skipping the initial phases of sleep and dropping straight to REM helps someone fall asleep, but it doesn’t produce healthy sleep. In this stage of the alcohol withdrawal, the mind may want to sleep but be incapable, either from restlessness or other symptoms.\n- Extreme drinking changes the intestine walls and the amount of stomach acid the body produces. As a result, nausea is quite common during this stage of the alcohol withdrawal.\n- When the brain starts to function on overdrive without the alcohol’s depressant effects to counteract this hyperactivity, the brain has trouble working normally, causing malfunctions in nerve cell activity, leading to tremors and shakes.\n12 to 24 Hours After Stopping Drinking\nIn Stage 12-24 hours of the alcohol withdrawal, the person may see a continuation of the previous symptoms in addition to some new symptoms. This trend may continue with each following stage.\n- Dehydration really sets in at this stage of the alcohol withdrawal timeline due to trips to the bathroom and sweating. The advantage of an inpatient detox program is the capability to have medical professionals monitor the levels of care and make sure the person has enough fluids.\n- Low blood sugar combined with extra dopamine release often results to hallucinations. Although these can be very disorienting or upsetting, hallucinations are not life-threatening.\n- As the body experiences all these uncomfortable symptoms, the last thing on someone’s mind is food. A loss of appetite should not be surprising for someone dealing with nausea.\nGet Help. Get Better. Get Your Life Back.\nSearching for Accredited Drug & Alcohol Rehab Centers Near You? Or Mental Health Support?\nEven if you have failed previously, relapsed, or are in a difficult crisis, we stand ready to support you. Our trusted behavioral health specialists will not give up on you. Call us when you feel ready or want someone to speak to about therapy alternatives to change your life. Even if we cannot assist you, we will lead you wherever you can get support. There is no obligation. Call our hotline today.FREE Addiction Hotline – Call 24/7\n24 to 48 Hours Post Drinking\nAs mentioned above, this is the most dangerous and crucial part of the alcohol withdrawal timeline. At this phase, the alcoholic’s body is in full panic mode and can have some severe reactions to the absence of alcohol in the system.\n- At this point of the alcohol withdrawal timeline, mood swings are not unusual. The person is anxious uncomfortable, and their body and brain feel like they are going haywire. Any patience or discipline they might have had initially had already faded, if not completely diminished.\n- Low Blood Sugar Levels\n- Alcohol use disorder usually leads to alcoholic liver cirrhosis and alcoholic hepatitis. When the liver does stop functioning, it fails to release glucose into the bloodstream. Hypoglycemia is a typical effect of alcohol withdrawal at this stage, This leads o exhaustion and weakness.\n- Grand Mal Seizures\n- Approximately four out of a hundred individuals will experience grand mal seizures in a day or two after quitting. The effects of alcohol withdrawal , particularly, seizures arise from sleep, water, and nutrient deprivation. For some, these seizures can be a warning sign of a much more alarming and dangerous effects of alcohol withdrawal known as Delirium Tremens.\n- Delirium Tremens\n- The possibly deadly effects of alcohol withdrawals, Delirium Tremens, is a sudden case of extreme confusion followed by sweats, shivering, seizures, overheating, hallucinations, and in some instances, death. During this period of the alcohol withdrawal, the body is experiencing a biochemical decline where the brain is malfunctioning and firing off incorrect signals.\n48 to 168 Hours Post Drink\nAt this stage of the alcohol withdrawal timeline, most physical symptoms have softened if not completely disappeared. Most of these are replaced by mental distress and feelings of anxiety, depression, confusion, restlessness, anger, and others. Now, in recovery, the client will learn to express and manage these feelings as well as coping ways to combat relapse.\nPAWS (Post-Acute Withdrawal Syndrome) refers to the long-term side effect of alcohol abuse, potentially challenging and affecting a person’s life. Symptoms might continue years after withdrawal and initial detox. That is why it is highly recommended to continue treatment after the initial seven-day detox.\nThese symptoms include:\n- Anxiety & Depression\n- Mood swings\n- Low levels of energy\n- Inability to focus\n- Lack of sex drive\n- Chronic pain\nThese symptoms are mainly psychological and have been known to continue for months or years after alcohol cessation. They tend to ‘come and go’ in waves or episodes, and can be triggered by specific circumstances, memories, smells, or people.\nCommon Effects of Alcohol Withdrawal\nIf you’ve been regularly drinking excessively and you stop drinking suddenly, you may experience one or more effects of alcohol withdrawal. Depending on your past alcohol use, these symptoms can range from mild and uncomfortable to severe and potentially life-threatening.\nThough symptoms typically begin within eight hours after your last drink, you may not experience any until several days later. These symptoms tend to spike around 24 to 72 hours after your last drink, though milder ones may persist for much longer in some people .\nCommon symptoms include:\n- Feeling anxious or nervous\n- Feeling irritable\n- Feeling depressed\n- Feeling wiped out and tired\n- Mood swings\n- Not being able to think clearly\n- Having nightmares\n- Dilated pupils\n- Difficulty sleeping\n- Nausea and/or vomiting\n- Appetite loss\n- Faster heart rate\n- Pale skin\nFirst-class Facilities & Amenities\nWorld-class High-Quality Addiction & Mental Health Rehabilitation TreatmentRehab Centers Tour\nRenowned Addiction Centers. Serene Private Facilities. Inpatient rehab programs vary.Addiction Helpline (877) 378-4154\nProven recovery success experience, backed by a Team w/ History of:\n- 15+ Years Experience\n- 100s of 5-Star Reviews\n- 10K+ Recovery Successes\n- Low Patient to Therapist Ratio\n- Onsite Medical Detox Center\n- Comprehensive Dual-Diagnosis Treatment\n- Complimentary Family & Alumni Programs\n- Coaching, Recovery & Personal Development Events\nSevere Effects of Alcohol Withdrawal\nOne of the most severe effects of alcohol withdrawal is called delirium tremens, or “the DTs.” About 3% to 5% of people who withdraw from heavy drinking experience delirium tremens. This condition can become fatal if it’s left untreated, so if you or a loved one show any symptoms of the DTs, seek emergency treatment because symptoms can get worse.\nSymptoms of delirium tremens include:\n- Extreme agitation\n- Extreme confusion\n- Hallucinations (feeling, seeing, or hearing things that aren’t there)\n- High blood pressure\nHospitals and detox centers have experienced staff who are familiar with these symptoms and have the tools to provide appropriate treatment.\nCan Alcohol Withdrawal Be Fatal?\nSevere effects of alcohol withdrawal can actually lead to death during the addiction recovery process. This can happen in a number of different ways, most commonly among alcoholics attempting recovery without medical supervision.\nAsk any recovering alcoholic and they may tell you that the detox process often made them feel as if they were dying. Of course, we do know that withdrawal itself is not a cause of death. However, there are two notably concerning effects of alcohol withdrawal that are linked to the occasional death of recovering alcoholics.\nSeizures: Those who have been drinking heavily for several years are more likely to experience seizures during the detox and withdrawal process. This can lead to choking, aspiration, or physical injury due to uncontrollable convulsions.\nDelirium Tremens: Otherwise known as “DTs,” this serious condition presents a number of dangerous symptoms of withdrawal, such as confusion, disorientation, hyperactivity, seizures, heart attack, and stroke.\nDiagnosing Alcohol Withdrawal\nYour doctor will review your medical history, ask about your symptoms, and conduct a physical exam. Some signs your doctor will look for include:\n- Hand tremors\n- An irregular heart rate\nYour doctor may also perform a toxicology screen, which tests how much alcohol is in your body.\nThe Clinical Institute Withdrawal Assessment of Alcohol (CIWA-Ar) is a series of questions used to measure AWS. Healthcare professionals may use this test to diagnose AWS. It can also be used to determine the severity of your symptoms. The scale measures the following 10 symptoms:\n- Auditory disturbances\n- Clouding of sensorium, or the inability to think clearly\n- Nausea and vomiting\n- Paroxysmal sweats, or sudden, uncontrollable sweating\n- Tactile disturbances\n- Visual disturbances\nIt’s important to note that the Clinical Assessment mentioned above may be unreliable because it is subjective in nature. According to a 2017 study , the use of the Objective Alcohol Withdrawal Scale (OAWS) was more useful for treatment because it can be used as a framework and tailored to individual cases.\nQuestions a medical professional may ask include:\n- Who am I?\n- What day is this?\n- Does it feel like there is a band around your head?\n- Do you feel sick to your stomach?\n- Do you feel bugs crawling under your skin?\nWorld-class, Accredited, 5-Star Reviewed, Effective Addiction & Mental Health Programs. Complete Behavioral Health Inpatient Rehab, Detox plus Co-occuring Disorders Therapy.CALL (877) 378-4154\nEnd the Addiction Pain. End the Emotional Rollercoaster. Get Your Life Back. Start Drug, Alcohol & Dual Diagnosis Mental Health Treatment Now. Get Free No-obligation Guidance by Substance Abuse Specialists Who Understand Addiction & Mental Health Recovery & Know How to Help.\nAlcohol Withdrawal Treatment\nDetox is often considered the first stage of treatment. It will help you navigate the complicated process of alcohol withdrawal, but it doesn’t address patterns of thought and behavior that contribute to alcohol use. Various treatment approaches and settings can help provide the ongoing support necessary to maintain long-term sobriety after you complete detox.\nCravings are very common during detox and can be challenging to overcome. This often leads to relapse. Constant medical care provided during inpatient treatment helps prevent relapse. Clinicians can provide necessary medication and medical expertise to lessen cravings and the effects of alcohol withdrawals.\nMedication-Assisted Treatments (MAT) for alcohol use disorder and mental health disorder are commonly used in conjunction with one another. This includes the use of medications and other medical procedures. During your rehab, the staff from your treatment facility will help you identify what caused your addiction and teach you skills that will help you change your behavior patterns and challenge the negative thoughts that led to your addiction. Sometimes, the pressures and problems in your life lead you to rely on substances to help you forget about them momentarily.\nIntegrated Mental Health Care\nAlcohol affects mental health, so people may use it to self-medicate undiagnosed disorders. Rehab centers typically provide mental health screenings, diagnoses, and integrated treatment for co-occurring disorders. In addition, holistic and therapeutic approaches are often used to treat recovering addicts with these conditions.\nCognitive Behavioral Therapy (CBT) and Dialectical Behavioral Therapy (DBT) can improve addicts’ behavior. CBT targets negative and maladaptive thought patterns as it promotes positive emotions and beliefs, while DBT helps clients address conflicting impulses so they can make healthy choices. Both therapies treat substance abuse and mental health disorders. Therapy also empowers clients to identify, avoid and mitigate cues that trigger drug cravings.\nIndividual and Group Counseling\nAddiction and mental health counseling occur in both individual and group settings. One-on-one treatment sessions may address unresolved trauma, unconscious conflicts, and specific struggles, while group sessions often involve training in life skills, stress management, conflict resolution, and social connections. Group counseling also gives clients the chance to share their thoughts and experiences to develop social support, which is essential for lasting recovery\nPlease, do not try to detox on your own because the detox process can be painful and difficult without medical assistance. If you or someone you know regularly exceeds these recommended daily limits or is experiencing effects of alcohol withdrawal, it is important to intervene early. We Level Up NJ has addiction specialists that are standing by to help.\nStart a New Life\nBegin with a free call to an addiction & behavioral health treatment advisor. Learn more about our dual-diagnosis programs. The We Level Up treatment center network delivers recovery programs that vary by each treatment facility. Call to learn more.\n- Personalized Care\n- Caring Accountable Staff\n- World-class Amenities\n- Licensed & Accredited\n- Renowned w/ 100s 5-Star Reviews\nWe’ll Call You']	['<urn:uuid:7579e0ac-b7d4-4de2-8efc-f17640a8b73a>', '<urn:uuid:603455ca-cac3-4017-89bc-35378543d951>']	open-ended	direct	verbose-and-natural	similar-to-document	multi-aspect	novice	2025-05-12T23:47:20.322175	24	115	3160
84	As a blade enthusiast, where are Japan's finest cooking knives made?	Sakai forged blades dominate the professional cooking knife market with 90% market share. They are renowned for their exceptional sharpness, achieved through superior smithing and grinding skills. Their history dates back to the 16th century, beginning with tobacco knives. The Tokugawa Shogunate recognized their quality by granting Sakai the 'Gokuin' certificate seal and exclusive selling rights.	['The character form has a left and a right side, which both, in the tortoise plastron and bone characters, were used with the meaning of the present complete character, of ‘army,’ or ‘master, instructor.’ The first form of 師 appearing in the tortoise plastron and bone characters is the left part of the character resembling the form of a big piece of meat fried on a skewer. It depicts the piece of meat the departing army uses to worship the ancestors when going to war praying for victory in war; by this time it alone had the meaning ‘army.’ The army always carried this meat around with it. The right part is the form of a knife with a blood stopper and a handle. Apart from the meaning ‘army,’ 師 was also used with the meaning of the person that has the authority to cut this meat. From the background that after retirement from active service these persons often were in charge of youth education, it also was used with the meaning ‘teacher.’\nIn contrast to ceremonies in Buddhism, the custom of offering meat afterwards was continued in Confucianism. In the realm of Confucianism, i.e. China, Korea, Taiwan, Vietnam, and Japan, when worshipping the previous sages and teachers of ancient China as, for example, in the 釈奠 ‘Sekiten, (Shakuten, Sakuten): Big Ceremony of Confucius Worship’ this is an important element of the ritual. In Japan, for example, meat also is at the center of the worship rituals for Confucius at the ‘Yushima Seido: Yushima Confucius Shrine’ in Tokyo.\nBesides, the character form of 帥 ‘Sui: general, leader’ may well seem to resemble 師, if, however, one has a look at the tortoise plastron and bone characters, the left part depicts the doors of a board enshrining deities, and the right part 巾 shows a cloth. It is of a completely different lineage.\nTakefu Knife Village is a brand created in 1982 by local curter artisans in Takefu, the biggest cutlery producing district that proudly maintains over seven hundred years of history.\nIn 1983 with the collaboration of Kazuo Kawasaki, a design director who was born and raised locally, Takefu launched its new series of kitchen knives, ARTUS.\nWhile using the traditional method to create the blade part and by utilizing a unique design to unify from the tip of the blade to the handle, it achieved a simple yet innovative, hygienic and highly aesthetic product.\nATRUS is made by “fire casting”, a traditional craftsman’s striking technique, which uses a three-layer structure with steel forged by hand that is inserted between stainless steel. It is this technique that enables the knife to be sharp and resistant to rust.\nATRUS was born from a great trinity: the seven policies based on the Takefu’s commitment to create wonderful hand-made products; its traditional cutlery making method; and outstanding design by Kazuo Kawasaki. Its excellence is evident as even more than 20 years after its initial introduction it is still sold without any modifications.\nOku-Izumi Tama-steel handicraft is one of the industrial arts of the town of Oku-Izumi, in Shimane Prefecture, which became prosperous in iron production.\nIron production began in the Muromachi period. Oku-Izumi is the site of the legend of the slaying of the Yamatano serpent recorded in the ‘Kojiki’. It is said that Kusanagi’s sword appeared from the serpent’s tail, and was an excellent source of steel.\nUntil the mid-Meiji period, Oku-Izumi supplied 70 percent of Japan’s iron . But as iron production became more prevalent with greater demand and easier production methods, the Tama-steel technique died out in the fourth decade of the Showa period. Only the ‘Nippo sword Tatara’ crafted by Toriue Iron Factory survived in Japan. Tama-steel and Wa-steel are manufactured using a traditional technique of refinement, using ‘Tatara’, which is made from iron sand. This Tama-steel has such good adhesion that a steel can be wrought that is strong enough to make beautiful swords.\nTama steel is still made by hand and the artisans are working on new forms of iron handiworks; they maintain the tradition and the knowledge of the manufacturing process.\nShinshu forged blade is a handicraft in Shinshu-Shinano-machi, Nagano Pref. It was designated as a Traditional Craft Product by Minister of International Trade and Industry in 1982. Forging skills were introduced into this area during the warring state period in the latter half of the 16th Century, when swordsmiths came to this area and repaired weapons. The local people saw their work and learned the skills. Their forged weapons were used in many battles throughout the warring state period, and the swordsmiths made improvement in their techniques. Extremely soft steel is used as the base whereas high purity carbon steel is used for the blade, the combination of which produces appropriate hardness and persistent strength. The technique has been handed down for 450 years and is still producing excellent blades, which are wide, durable, and cuts clearly.\nSakai forged blades has the share of 90% in the market for cooking knives used by professional cooks. The No.1 standard of sharpness and traditional forging technique has increased their reputation. The history dates back the 16th century, when guns and tobacco were introduced into Japan from Portugal. In the late 16th century, Sakai’s “tobacco knives” to shred tobacco were known nationwide. The Tokugawa Shogunate granted Sakai a certificate seal called “Gokuin” to guarantee their quality and also the exclusive selling right, by which the reputation of Sakai forged blades spread all over the country. These knives are characterized by their distinctive sharpness that is only possible through the excellent smithing and grinding skills. The sharp blade edge produced by well trained skills represents the master’s pride.\nEchizen forged blades, one of the traditional handicrafts of Echizen City,\nFukui Pref., has its own distinctive sharpness produced through 700 years of\nits history, where craftsmen have competed in refining their skills. The\nhistory dates back to the Nanbokucho period (1336−1392), when a swordsmith\nfrom Kyoto came to this area. This swordsmith, Chiyotsuru Kuniyasu visited\nFuchu (present Takeo City, Fukui Pref.) in search of a suitable place for\nsword-making. He also made grain sickles for the local farmers and this\nevolved into forging in the area. Since then Takeo is a big producing area\nof edged farming tools, which were spread throughout the country by peddlers\nunique to Hokuriku region. Using aged-old Japanese forging skills before\nbeing finished by hand, kitchen knives, sickles and trimmers are now\nproduced. Echizen forged blades were awarded the nationally recognized\nTraditional Craft Product in 1980, as daily commodities combined with\naccomplished skills and artistic sensitivity.']	['<urn:uuid:d759fa86-02f8-4503-93a9-7f5cde1582db>']	open-ended	with-premise	concise-and-natural	distant-from-document	single-doc	expert	2025-05-12T23:47:20.322175	11	56	1101
85	advantages direct push water sampling over wells	Direct-push water sampling is an economical method for obtaining discrete groundwater samples without the expense of permanent monitoring well installation. It can also better define conditions in thin multiple aquifers than monitoring wells, since monitoring wells with screened intervals can intersect and allow for intercommunication of multiple aquifers.	"[""Active Standard ASTM D6001 | Developed by Subcommittee: D18.21\nBook of Standards Volume: 04.09\nHistorical (view previous versions of standard)\nSignificance and Use\n5.1 Direct-push water sampling is an economical method for obtaining discrete groundwater samples without the expense of permanent monitoring well installation (1-6).4 This guide can be used to profile potential groundwater contamination with depth by performing repetitive sampling events. Direct-push water sampling is often used in expedited site characterization (Practice D6235). Soils to be sampled must be permeable to allow filling of the sampler in a relatively short time. The zone to be sampled can be isolated by matching well screen length to obtain discrete samples of thin aquifers. Use of these sampling techniques will result in more detailed characterization of sites containing multiple aquifers. By inserting a protected sampling screen in direct contact with soil and with watertight risers, initial well development (Guide D5521) and purging of wells (Guide D6452) may not be required for the first sampling event. Discrete water sampling, combined with knowledge of location and thickness of target aquifers, may better define conditions in thin multiple aquifers than monitoring wells with screened intervals that can intersect and allow for intercommunication of multiple aquifers (4,6,7,9,13). Direct-push sampling performed without knowledge of the location and thickness of target aquifers can result in sampling of the wrong aquifer or penetration through confining beds.\n5.2 For sites that allow surface push of the sampling device, discrete water sampling is often performed in conjunction with the cone penetration test (Test Method D6067) (4-9), which is often used for stratigraphic mapping of aquifers, and to delineate high-permeability zones. In such cases, direct-push water sampling is normally performed close to cone holes. In complex alluvial environments, thin aquifers may vary in continuity such that water sampling devices may not intersect the same layer at equivalent depths as companion cone penetrometer holes.\n5.3 Water sampling chambers may be sealed to maintain in situ pressures and to allow for pressure measurements and permeability testing (6,9,12). Sealing of samples under pressure may reduce the possible volatilization of some organic compounds. Field comparisons may be used to evaluate any systematic errors in sampling equipments and methods. Comparison studies may include the need for pressurizing samples, or the use of vacuum to extract fluids more rapidly from low hydraulic conductivity soils (18.104.22.168).\n5.4 Degradation of water samples during handling and transport can be reduced if discrete water sampling events with protected screen samplers are combined with real time field analysis of potential contaminants. In limited studies, researchers have found that the combination of discrete protected screen sampling with onsite field analytical testing provide accurate data of aquifer water quality conditions at the time of testing (4,6). Direct-push water sampling with exposed screen sampling devices, which may require development or purging, are considered as screening tools depending on precautions that are taken during testing.\n5.5 A well screen may be pushed into undisturbed soils at the base of a drill hole and backfilled to make permanent installed monitoring wells. Procedures to complete direct-push wells as permanent installations are given in Practice D6725 and Guide D6724.\n5.6 In difficult driving conditions, penetrating to the required depth to ensure sealing of the sampler well screen may not be possible. If the well screen cannot be inserted into the soil with an adequate seal, the water-sampling event would require sealing in accordance with Practice D5092 to isolate the required aquifer. Selection of the appropriate equipment and methods to reach required depth at the site of concern should be made in consultation with experienced operators or manufacturers. If there is no information as to the subsurface conditions, initial explorations consisting of penetration-resistance tests, such as Test Method D6067, or actual direct-push testing trials can be performed to select the appropriate testing system.\n5.6.1 Typical penetration depths for a specific equipment configuration depend on many variables. Some of the variables are the driving system, the diameter of the sampler and riser pipes, and the resistance of the materials.\n5.6.2 Certain subsurface conditions may prevent sampler insertion. Penetration is not possible in hard rock and usually not possible in softer rocks such as claystones and shales. Coarse particles such as gravels, cobbles, and boulders may be difficult to penetrate or cause damage to the sampler or riser pipes. Cemented soil zones may be difficult to penetrate depending on the strength and thickness of the layers. If layers are present that prevent direct-push from the surface, the rotary or percussion drilling methods (Guide D6286) can be employed to advance a boring through impeding layers to reach testing zones.\n5.6.3 Driving systems are generally selected based on required testing depths and the materials to be penetrated. For systems using primarily static reaction force to insert the sampler, depth will be limited by the reaction weight of the equipment and penetration resistance of the material. The ability to pull back the rod string is also a consideration. Impact or percussion soil probing has an advantage of reducing the reaction weight required for penetration. Penetration capability in clays may be increased by reducing rod friction by enlarging tips or friction reducers. However, over reaming of the hole may increase the possibility of rod buckling and may allow for communication of differing groundwater tables. Hand-held equipment is generally used on very shallow investigations, typically less than 5-m depth, but depths on the order of 10 m have been reached in very soft lacustrine clays. Intermediate size driving systems, such as small truck-mounted hydraulic-powered push and impact drivers, typically work within depth ranges from 5 to 30 m. Heavy static-push cone penetrometer vehicles, such as 20-ton trucks, typically work within depth ranges from 15 to 45 m, and also reach depth ranges on the order of 102 m in soft ground conditions. Drilling methods (Guide D6286) using drilling and incremental sampling are frequently used in all depth ranges and can be used to reach depths on the order of 103 m.\n5.7 Combining multiple-sampling events in a single-sample chamber without decontamination (Practices D5088) is generally unacceptable. In this application, purging of the chamber should be performed to ensure isolation of the sampling event. Purging should be performed by removing several volumes of fluid until new chemical properties have been stabilized or elements are flushed with fluid of known chemistry. Purging requirements may depend upon the materials used in the sampler and the sampler design (Guide D6634).\n1.1 This guide covers a review of methods for sampling groundwater at discrete points or in increments by insertion of sampling devices by static force or impact without drilling and removal of cuttings. By directly pushing the sampler, the soil is displaced and helps to form an annular seal above the sampling zone. Direct-push water sampling can be one time, or multiple sampling events. Methods for obtaining water samples for water quality analysis and detection of contaminants are presented.\n1.2 Direct-push methods of water sampling are used for groundwater quality studies. Water quality may vary at different depths below the surface depending on geohydrologic conditions. Incremental sampling or sampling at discrete depths is used to determine the distribution of contaminants and to more completely characterize geohydrologic environments. These investigations are frequently required in characterization of hazardous and toxic waste sites.\n1.3 Direct-push methods can provide accurate information on the distribution of water quality if provisions are made to ensure that cross-contamination or linkage between water bearing strata are not made. Discrete point sampling with a sealed (protected) screen sampler, combined with on-site analysis of water samples, can provide the most accurate depiction of water quality conditions at the time of sampling. Direct-push water sampling with exposed-screen sampling devices may be useful and are considered as screening tools depending on precautions taken during testing. Exposed screen samplers may require development or purging depending on sampling and quality assurance plans. Results from direct-push investigations can be used to guide placement of permanent groundwater monitoring wells and direct remediation efforts. Multiple sampling events can be performed to depict conditions over time. Use of double tube tooling, where the outer push tube seals the hole, prevents the sampling tools from coming in contact with the formation, except at the sampling point.\n1.4 Field test methods described in this guide include installation of temporary well points, and insertion of water samplers using a variety of insertion methods. Insertion methods include: (1) soil probing using combinations of impact, percussion, or vibratory driving with or without additions of smooth static force; (2) smooth static force from the surface using hydraulic cone penetrometer (Guide D6067) or drilling equipment (Guide D6286), and incremental drilling combined with direct-push water sampling events. Under typical incremental drilling operations, samplers are advanced with assistance of drilling equipment by smooth hydraulic push, or mechanical impacts from hammers or other vibratory equipment. Direct-push water sampling maybe combined with other sampling methods (Guide D6169) in drilled holes. Methods for borehole abandonment by grouting are also addressed.\n1.5 Direct-push water sampling is limited to soils that can be penetrated with available equipment. In strong soils damage may result during insertion of the sampler from rod bending or assembly buckling. Penetration may be limited, or damage to samplers or rods can occur in certain ground conditions, some of which are discussed in 5.6. Information in this procedure is limited to sampling of saturated soils in perched or saturated groundwater conditions. Some soil formations do not yield water in a timely fashion for direct-push sampling. In the case of unyielding formations direct-push soil sampling can be performed (Guide D6282).\n1.6 This guide does not address installation of permanent water sampling systems such as those presented in Practice D5092. Direct-push monitoring wells for long term monitoring are addressed in Guide D6724 and Practice D6725.\n1.8 This guide does not purport to address all aspects of exploration and site safety. It is the responsibility of the user of this guide to establish appropriate safety and health practices and determine the applicability of regulatory limitations before its use.\n1.9 This guide offers an organized collection of information or a series of options and does not recommend a specific course of action. This document cannot replace education or experience and should be used in conjunction with professional judgment. Not all aspects of this guide may be applicable in all circumstances. This ASTM standard is not intended to represent or replace the standard of care by which the adequacy of a given professional service must be judged, nor should this document be applied without consideration of a project's many unique aspects. The word “Standard” in the title of this document means only that the document has been approved through the ASTM consensus process.\n2. Referenced Documents (purchase separately) The documents listed below are referenced within the subject standard but are not provided as part of the standard.\nD653 Terminology Relating to Soil, Rock, and Contained Fluids\nD2488 Practice for Description and Identification of Soils (Visual-Manual Procedure)\nD4448 Guide for Sampling Ground-Water Monitoring Wells\nD4750 Test Method for Determining Subsurface Liquid Levels in a Borehole or Monitoring Well (Observation Well)\nD5088 Practice for Decontamination of Field Equipment Used at Waste Sites\nD5092 Practice for Design and Installation of Ground Water Monitoring Wells\nD5254 Practice for Minimum Set of Data Elements to Identify a Ground-Water Site\nD5314 Guide for Soil Gas Monitoring in the Vadose Zone\nD5434 Guide for Field Logging of Subsurface Explorations of Soil and Rock\nD5474 Guide for Selection of Data Elements for Groundwater Investigations\nD5521 Guide for Development of Ground-Water Monitoring Wells in Granular Aquifers\nD5730 Guide for Site Characterization for Environmental Purposes With Emphasis on Soil, Rock, the Vadose Zone and Ground Water\nD5778 Test Method for Electronic Friction Cone and Piezocone Penetration Testing of Soils\nD5903 Guide for Planning and Preparing for a Groundwater Sampling Event\nD6067 Practice for Using the Electronic Piezocone Penetrometer Tests for Environmental Site Characterization\nD6089 Guide for Documenting a Ground-Water Sampling Event\nD6235 Practice for Expedited Site Characterization of Vadose Zone and Groundwater Contamination at Hazardous Waste Contaminated Sites\nD6452 Guide for Purging Methods for Wells Used for Ground-Water Quality Investigations\nD6517 Guide for Field Preservation of Groundwater Samples\nD6564 Guide for Field Filtration of Ground-Water Samples\nD6634 Guide for the Selection of Purging and Sampling Devices for Ground-Water Monitoring Wells\nD6724 Guide for Installation of Direct Push Groundwater Monitoring Wells\nD6725 Practice for Direct Push Installation of Prepacked Screen Monitoring Wells in Unconsolidated Aquifers\nD6771 Practice for Low-Flow Purging and Sampling for Wells and Devices Used for Ground-Water Quality Investigations\nD6911 Guide for Packaging and Shipping Environmental Samples for Laboratory Analysis\nICS Number Code 13.060.10 (Water of natural resources)""]"	['<urn:uuid:830f3c97-2865-4db6-bfb1-b2ff70aac8ff>']	factoid	with-premise	short-search-query	similar-to-document	single-doc	expert	2025-05-12T23:47:20.322175	7	48	2103
86	safety required gear emergency hiking radio compass map unplanned situations	For safety in emergency situations while hiking, essential gear includes both communication tools and navigation equipment. A radio can be used to call for help when no other communications are available, even by unlicensed operators in life-threatening emergencies. Additionally, carrying a detailed map appropriate for your area and a compass (preferably liquid-filled with 0-360 degree markings) are crucial navigation tools. The map and compass should be supplemented with other essentials like extra food, clothing, and an emergency shelter for unplanned situations.	"['So imagine this scenario: You need help because life safety is at stake and you have no phone service, but your dad’s radio is sitting in the corner, gathering dust. Can you use it?\nThe FCC amateur radio Technician exam has a question regarding this – “When may an amateur station use any means of radio communications at its disposal for essential communications in connection with immediate safety of human life and protection of property?” The General exam asks a very similar question – “When normal communications systems are not available, what means may an amateur station use to provide essential communications when there is an immediate threat to the safety of human life or the protection of property?”\nThis stuff never happens in real life, you say. But it does! Three members of O.M.E.G.A. deployed to support the National MS Society’s Bike MS-150 the weekend of June 25, 2011. The MS-150 is a grueling 150 mile charity bicycle ride along the hills of the Colorado Front Range. The 2011 ride starts and ends in Denver with an overnight in Fort Collins. Radio communications is used to tie together 3500 riders with the event organizers, police, medical services and support crews across 75 miles of challenging road.\nSaturday evening around 6 PM we were relaxing on the Colorado State University lawn with one of the other radio operators when a call came in on the radio. It was a rather strange call as the woman asked for the county sheriff. We let that go a couple of times, then WØJEN answered. It was very clear that the caller had just enough radio savvy to use push-to-talk.\nThe woman on the radio passed the microphone to a man who sounded like a young adult. He relayed that they were in a cabin with no phone service, waiting for a party of six hikers to return. The hikers departed in the morning for a four hour hike and were now more than four hours overdue. The callers decided to try and use the radio in the cabin to call for help, thinking that this was a frequency monitored by the sheriff.\nOur job now was to relay a message to the sheriff to get search and rescue out to look for overdue hikers. The first thing that we needed to do was gather information about where the hikers were supposed to have been hiking and where they were supposed to return to. We were given a forest road address. Working under the assumption that the 70cm band call could not have originated very far, we used smart phones to check the vicinity of Fort Collins for the location. That failed. More research revealed that the location was actually west of Loveland, southwest of Fort Collins, still in Larimer County.\nWe got a hold of the Fort Collins Police Department and had them route us over to Larimer County Sheriff. Then it was a game of getting questions from the sheriff’s dispatcher and gathering the answers from the reporting party. We identified their location, got names (thus identifying who the radio station belonged to) and the trail that the hikers were supposed to be on.\nThe sheriff’s office put out a call to Larimer County Search and Rescue. We continued to function as a communications bridge between the reporting party and the sheriff, fielding questions and providing additional information. Then the reporting party announced that six hikers walked in through the door. It was almost 7 PM. They were five hours overdue, but everyone was okay and we cancelled the request for help.\nIt was very clear from the very beginning that the calling party was not a licensed radio operator. While it is true that the FCC mandates that all use of amateur frequencies must be by licensed operators, it is equally important to stress that at times of emergency, extreme measures may come into play. This was one such time.\nWe don’t know what led to the hiking party’s five hour delay in getting back. It could really have been anything and this is an important point to make when addressing general preparedness. Was the hiking party prepared to be out in the wilderness? That could be debated since they ended up being so delayed. We know that cell phone service was not available in the area, but quite clearly radio communications was an option, in this case an option that was not fully exercised.\nWere the family and friends left behind ready to deal with an emergency? Perhaps a little more so than the hikers. They had a radio and the sense to use it to call for help. They did not try to go out looking for the missing hikers, which could have made the situation worse. It can be argued that they didn’t fully understand the radio’s capabilities or who monitors the frequency, but they got lucky and stumbled across someone who was listening and was able to help.\nAnd the group of tired radio operators taking the call? We learned some lessons, too. Have a spare battery. After ten hours on the radio, batteries die. It was a good thing that multiple radios were present. Carry a pen and paper. That makes taking notes a lot easier. And most importantly, weird calls on the radio can be important. Don’t ignore them.\nThere is another question on the General test that asks, “When is an amateur station prevented from using any means at its disposal to assist another station in distress?” Do you know the answer? It’s very simple. Never. If there is potential danger to human life or welfare and no other form of communications is available, it is okay to break the rules and use a radio without a license to call for help.\nWe’re happy that we were available to take the call and it should go without saying that neither the sheriff, nor Larimer County Search and Rescue are upset to have received a false alarm. In this business a false alarm is infinitely preferable to trying to haul a mangled body down the side of a mountain.\nNever be afraid to call for help. It may save a life.', 'Backpacking ten essentials: the first ten items in this list are the selections of essential backpacking gear which The Mountaineers refer to as The Ten Essentials and promote as critical and essential items which belong in your pack as insurance against the unexpected. Although you may not use all the backpacking ten essentials every day, they can be life savers in an emergency.\nAlso, if you shop with prudence, these essential gear items can be lightweight, as well.\nAs a supplement to the ten essentials, I have added four additional backpacking essential gear items which are pretty important to our health and welfare in the wilds, as well as suggest some small, lightweight, purchase options for many of the ""essentials"".\nThe most important essential , however, is not on the list--""Common Sense"". Having the right gear is one thing, knowing how and when to use it is quite another. Most often, it\'s not a person\'s equipment that saves their bacon. It\'s their experience, know-how, and good judgment.\nConversely, it is generally inexperience and lack of good judgment that gets people into trouble. Not only must we have the proper equipment -- including the ten essentials plus four -- and know how to use them, but we must also cultivate knowledge and wisdom related to the backcountry activities that we engage in--thru self-study, courses, and leveraging off the experiences of others.\nAlways carry a detailed map of the area you will be visiting. If alpine scrambling or otherwise navigating cross-country consider the 7.5 minute USGS maps--they reveal considerable detail. For traveling on trails, the 15 minute series Green Trails is a good choice, among others. The point is to carry a map appropriate for the area you will be in and the activity you will be undertaking--and know how to use it !\nCarry a compass, at all times, in the backcountry--and know how to use it ! Some features to look for:\n0 to 360 degrees, preferably, in 2 degree increments;\nliquid filled, which protects the magnetic needle and its jeweled bearing and minimizes fluctuation;\na base plate--3"" to 4"", in length-- which can be used as a straight-edge for taking map bearings and determining distances on maps;\nan adjustable declination to account for the difference between Magnetic North and True North. The compass responds to Magnetic North, whereas, maps are based upon True North. Therefore, the compass needs to be adjusted to compensate. An adjustable declination feature lets you turn a small screw to ""permanently"" adjust declination to match the geographic area you will be in, so that you don\'t need to calculate your bearing each time.\na fold-out mirror for sightings. The mirror allows for more accurate readings because you can position the mirror such that the mirror and the distant objective are both visible at the same time.\na clinometer is useful for measuring vertical angles and, thus, measures slope steepness. This feature is helpful in determining avalanche potentials, and for determining position on a map.\nThe following compasses are lightweight and would be the minimum you would want to carry. They probably would suffice as an emergency gear item while backpacking entirely on trails.\nSuunto A10; weighs 1 oz, 0 to 360 degrees in 2 degree increments; liquid-filled with straight-edge.\nSilva Polaris; (same weight and features as Suunto A10).\nFor serious backcountry travel where map and compass will be used for navigation, the following compasses are recommended:\nSuunto MC-2G Navigator; weighs 2.6 oz, has all the features itemized above, plus luminous bezel and markings.\nSilva Ranger; weighs 3 oz, (same features as Suunto MC-2G, only without the luminous bezel).\n3. Flashlight / Headlamp:\nFlashlights and/or Headlamps are important even on day trips. You never know when you might need to spend the night or make that last mile or so after sunset. Here\'s some features to look for:\nlights which are water resistant--they function reliably in all weather. Look for rubberized bulb housing and battery compartments, or at least adequate rubber gaskets.\nlights which come with extra bulbs stored inside their housing.\nlights which have rotating head or body as the on/off mechanism. Avoid lights with on/off switches which can accidentally be turned-on as it is jostled about in your pack.\nlights which come with or will accept bright beam bulbs such as xenon, krypton, or halogen. Also, always carry several spare bulbs--they are light.\nIt\'s a good idea to carry a small lightweight hand-held light in addition to a headlamp. In the hand held light use a regular bulb which requires less battery juice than the bright-beam bulbs. Use this light for simple around the camp chores, to conserve batteries. In the headlamp, use a halogen (or other bright-beam bulb) and use this light when you are path finding or otherwise require a bright beam.\nSuggestions for a small, lightweight, high-quality hand held light:\nPhoton Micro Light; (the one I use), weighs 7 grams, (click the link to read the review and/or purchase one).\nMini-Maglite AA; (2 AA batteries) weighs 4 oz., twist top on/off, comes with extra bulb.\nPrinceton Tec LED; 4 AAA batteries, weighs 2.5 oz, 3 LED bulbs.\nSuggestions for a small, lightweight, high-quality headlamp:\nPetzl Zipka; (3 AAA batteries) weighs 2.2 oz, built-in retractable head strap. Strong beam from 3 LED bulbs.\nBlack Diamond ION; (1 6 volt battery - included) weighs 1.1 oz, uses 2 LED bulbs.\n4. Extra Food:\nWhenever you go out, even for a day trip, bring extra food in case you are delayed by emergencies, foul weather, or just get lost. The mountaineers suggest a one-day supply. At the very least, bring one good meal more than what you need. The food should require little or no cooking. If your extra food will require cooking, make sure you also carry extra fuel for your stove.\n5. Extra Clothing:\nIn addition to the basic layers you would normally take on an outing, bring extra clothing which would get you through an unplanned bivouac through the worst conditions you might come up against. Extra clothing means a little extra beyond what you would normally carry, just in case of emergencies.\nSuggestions for the basic kinds of clothing that you should be carrying on ""ALL"" hikes can be found HERE!! For Day Hikes only, click HERE!!\nIn addition to the extra clothes, carry an emergency shelter such as a waterproofed tube tent or mylar Space Bag (or blanket). The Space Bag only weighs about 2.5 ounces but will completely encase you and keep you warm and dry. Another option is a VBL (vapor barrier liner ) like the Western Mountaineering ""Hot-Sac"" VBL. The VBL can be used on a regular basis to add warmth to your sleeping bag as well as serve as an emergency shelter. It\'s a little heavier than the Space bag -- 6.5 ounces.\n[ Bill Fusfield\'s Comments on Extra Clothes ]\nYour eyes can experience damage from the intensity of mountain skies, ultraviolet rays, and light reflecting off of snow. As elevation increases so does the intensity of ultraviolet rays. Adequate eye protection is a must!\nBolle\' makes a lightweight pair of glasses with a virtually indestructible polycarbonate lens. They are optically correct and have emerald green lens for true color. They are rated 100 % UV protection. Cost is about US $40.00.\nFor traveling on snow, get a pair of glacier glasses with side shields which reduce reflective light reaching the eyes. Good, quality glacier glasses typically cost in the $50 to $150 range. Nikon makes some nice ones with polycarbonate lens. They are very lightweight, cost is about $110.\nThere are many other brands of sunglasses and glacier glasses which are less expensive and provide adequate protection. Shop around, but be careful. Try to stay with reputable brand names. Your eyes will know damage, long before you feel discomfort.\nJust a bit of trivia for you. When Reinhold Messner climbed Everest solo, he abandoned his pack for the last leg of the descent. He did, however, make sure he took along TWO pairs of sunglasses. Makes sense - you won\'t get home if you\'re blind.\n7. First-Aid Kit:\nCarry first-aid supplies for minor injuries. In particular, carry plenty of adhesive band-aids and sterilized bandages, because they can\'t be easily improvised in the woods. What to carry ? A good book to reference is ""Mountaineering First Aid"" 3rd edition, by Lentz, Macdonald, and Carline, published by The Mountaineers.\nThis booklet was used as a text when I took the Mountaineers\' MOFA (Mountaineering Oriented First Aid) course. I use it now to refresh my memory. It is easy reading, small ( 5 1/4 x 8 1/2 inches ), brief ( 95 pages ) and inexpensive ( $8.95 ). It identifies what items to carry, as well as what to do in emergency situations.\nOnce you are familiar with the supplies you need, you can purchase a kit or make your own. If you purchase one, you\'ll most likely need to add to it ( items like CPR mask, rubber gloves, etc. ) since most commercially prepared kits are inadequate.\nAlso, If you spend any time in the backcountry, it would be a good idea to enroll in a mountaineering first aid course.\n(NOTE: Within the ""Weight-Saving Tips"" page at this site, are many improvisations which can be used in emergency situations--""in lieu of packing the kitchen sink"").\n8. Pocket Knife & Tools:\nYour basic backpacking tool kit. A good example of a single piece of gear which has multiple uses. For example, a Wenger ""Master"" Swiss Army Knife has a locking blade; ""slip-joint"" pliers/wire crimper/wire cutters; springless self-sharpening scissors; wood saw; nail file/cleaner; corkscrew; awl/reamer; can opener; cap lifter; tweezers; and toothpick--all at a weight of about 6 ounces. Swiss-Army knives are available with more and less features.\nAt a minimum, knives are useful for first aid, food preparation, cutting moleskin strips, cutting rope and making repairs. However, scrutinize your needs before you go out and buy a honker like the Victorinox Swiss Champ which has many tools you probably don\'t need and weighs 1/2 pound ! If you don\'t actually use a feature, then you probably don\'t need to be carrying it around.\nA very good source for backpacking knives & tools is TLB\'s own\nBACKPACKING KNIVES & TOOLS STORE - HERE !\n9. Waterproof Matches:\nCarry matches which have been waterproofed or wind and waterproofed, or else carry extra strike-anywhere matches--along with something to strike them on-- in a waterproof container. Keep these matches separate from your regular match or butane lighter supply. Keep them available for emergency situations.\nThere are many commercially prepared waterproof/windproof matches available on the market, e.g., ""Hurricane"" and ""Cyclone"" brands of wind & waterproof matches and Coghlan\'s waterproof safety matches.\nFire starters are useful for quickly starting a fire, especially in emergency situations. They are also useful for igniting wet wood. There are several commercial fire starters available: magnesium blocks w/striking flint; chemically-treated fire sticks, etc.\nIn addition, numerous home-made fire starters work just fine: plumber\'s candles (wax); compressed balls of dryer lint mixed with or covered with melted paraffin; small strips of waxed cardboard (from old produce boxes); small flammable containers--individual egg-carton cups filled with mixtures of wood shavings, wax, & lint; etc.\n11. Water / Filter / Bottles:\nCarry plenty of fresh water. If you are familiar with the area in which you are traveling, and can be sure that water sources are available, carry enough water to get you there.\nIf you aren\'t bringing your water from home or a public source, treat the water you draw from the backcountry, regardless of the source. These days, everything is suspect.\nUse water filter, purifier, chemical tablets, or boiling to treat the water before consuming.\nFor transporting inside your pack, use lightweight water bottles, such as Nalgene 16 oz and 32 oz lexan polycarbonate or high-density polyethylene wide-mouth bottles. Some folks use other containers such as old plastic pop bottles. That\'s okay too. Be careful they don\'t crack and/or leak, though.\nFor emergencies: when you\'re lost, someone else is lost, or you\'re hurt and need help, etc.\nCaution: Metal whistles, with a pea, can be a problem in the mountains. Your ""pea"" can freeze up, and what happens when you put your lips on frozen metal ?\nA better choice would be a pealess plastic whistle like the Fox 40. It is ultra-light and very shrill. Cost about $6.00. REI sells em.\n13. Insect clothing or repellents:\nI don\'t know about you, but summer really ""bugs"" me. Three ways to deal with the biting flies, mosquitoes, knats, etc. are to (1) let them eat you (2) use repellents or (3) wear clothing. Since the first option doesn\'t cut it, there are numerous commercial repellents on the market. Most of them are DEET based. REI Jungle Juice works okay but the stuff gets everything oily. There are many good creams but they need to be reapplied more frequently. There are extended duration DEET products which do not soak into the skin as fast and provide up to 12 hours of protection--such as 3M Ultrathon (now only available as ""Hourguard 12"" thru Amway).\nI\'ve found, recently, that the bugs seem to be getting immune to the juice, so I\'ve been wearing an ultra-lightweight bug-netting jacket and pants. This has been successful, except when I bend over and expose my lower back where the jacket rides up. If you go this way, make sure the garments are very baggy. Many bugs have long stingers that easily penetrate tight fitting netting.\n14. Sunburn preventatives:\nRemember, the higher the elevation, the greater the intensity of the sun. Although each of us has a different capacity -- a.k.a. different pigmentation -- for withstanding the sun\'s onslaught, the message is the same--the penalty for underestimating your need for protection is severe.\nIn sunny conditions, wear light-colored clothing and cover exposed skin, at least, with SPF rated sunscreen appropriate for you, at least 15. Wear coverings over the neck and ears. OR (Outdoor Research) and other manufacturers make baseball-style caps with skirts which cover the neck and ears. Carry an SPF-rated lip-balm, as well, and reapply frequently.']"	['<urn:uuid:666de201-1e44-4492-9c2d-1d245531be2b>', '<urn:uuid:80034a97-d0bf-4af1-8eed-0e0d10503fab>']	factoid	direct	long-search-query	distant-from-document	three-doc	novice	2025-05-12T23:47:20.322175	10	81	3398
87	Who originally owned the villa at Boscotrecase?	According to an inscription from the villa, the owner was Agrippa Postumus, who was the son of Augustus' daughter Julia and Marcus Vipsanius Agrippa.	"['- Identification and Creation\n- Object Number\n- Wall Painting Fragment from the Villa at Boscotrecase\n- Work Type\n- 10 BCE-1 BCE\n- Creation Place: Ancient & Byzantine World, Europe, Campania\n- Roman Imperial period, Early\nLevel 3, Room 3700, Ancient Mediterranean and Near Eastern Art, Roman Art\nView this object\'s location on our interactive map\n- Physical Descriptions\n- Pigment on plaster\n- Fresco painting\n- H. 47.5 x W. 75.8 cm (18 11/16 x 29 13/16 in.)\nwith frame: H. 48.2 x W. 83 x D. 9.7 cm (19 x 32 11/16 x 3 13/16 in.)\n- Albert Gallatin, New York, (by 1921) gift; to the Fogg Art Museum, 1921.\n- Acquisition and Rights\n- Credit Line\n- Harvard Art Museums/Arthur M. Sackler Museum, Gift of Albert Gallatin\n- Accession Year\n- Object Number\n- Asian and Mediterranean Art\n- The Harvard Art Museums encourage the use of images found on this website for personal, noncommercial use, including educational and scholarly purposes. To request a higher resolution file of this image, please submit an online request.\n- This wall painting fragment comes from the so-called \'Mythological Room\' of the villa at Boscotrecase (room 19) where it would have decorated the top register of red-paneled walls. Preserved here is the upper golden register, framed by two narrow white bands in which appears a decorative fleur-de-lis in red pigment. The lower portion of the fragment preserves remains of the bright red panel that would have occupied the lower portion of the wall. Two vignettes appear in the gold register. On the left, in a square panel is a figure. She wears a blue headdress and red draped garment. In profile, the figure kneels on a green cushion with her arms raised at her waist (1). On the right, two birds stand in a puddle of water: one bends to drink while the second stands upright.\nThe details of both vignettes are only partially preserved because the secco paint has worn.\n1. Compare to figures in the Black Room from the Boscotrecase Villa in the Metropolitan Museum of Art, 20.192.2.\n- This fragment is a fine example of what is commonly called the Pompeian Third Style, popular during Augustus\' reign (r. 27 BCE-14 CE) in the late first century BCE and early first century CE. An inscription from the villa suggests the owner was Agrippa Postumus (b.12 BCE-d. 14 CE), the son of Augustus\' daughter Julia and her husband Marcus Vipsanius Agrippa, the close advisor of the Emperor Augustus. Significant renovations occurred at the site following 12 BCE, suggesting a date for the paintings during the final decade of the first century BCE. The elegant and refined quality of this and other paintings at the villa provide some of the best examples of paintings, particularly outside of Rome, and certainly of the so-called Third Style. The Egyptianizing themes were favored by Augustus and other Roman elite during the years of the early Empire, following the victory over Cleopatra.\nThe villa was partly excavated from 1903-1905 and subsequently published in 1922, by the Italian archaeologist Matteo della Corte (1). Other panels were divided between collections of the Metropolitan Museum of Art and the Museo Archeologico Nazionale di Napoli. A reconstructed panel combining the upper frieze from the west all with the primary, red register from the east wall of room 19 in the Metropolitan Museum of Art offers a model for this fragment\'s original wall context (2, 3).\n1. M. Della Corte, ""Scavi eseguiti da privati nel territorio di Pompei,"" Notizie degli Scavi 19, 1922, pp. 459ff.\n2. P. von Blanckenhagen and C. Alexander, The Augustan Villa at Boscotrecase, (Mainz: Verlag Philipp von Zabern, 1990), pl. 38.\n3. Compare to the Metropolitan Museum of Art inv. 20.192.13, M. L. Anderson, ""The Imperial Villa at Boscotrecase,"" The Metropolitan Museum of Art Bulletin, 45.3 (1987): p. 51, fig. 55.\n- Exhibition History\n32Q: 3700 Roman, Harvard Art Museums, Cambridge, 06/13/2017\n- Subjects and Contexts\nRoman Domestic Art\n- Related Articles\n- Related Works\nThis record has been reviewed by the curatorial staff but may be incomplete. Our records are frequently revised and enhanced. For more information please contact the Division of Asian and Mediterranean Art at firstname.lastname@example.org']"	['<urn:uuid:28a8b568-b85b-4686-8df8-30076791ab5f>']	factoid	direct	concise-and-natural	similar-to-document	single-doc	novice	2025-05-12T23:47:20.322175	7	24	704
88	I'm studying medieval art and would love to know: what's the connection between wall paintings in ancient times and how they took care of old tiles in churches - is there any link between how they were made and how they needed to be looked after?	Both frescoes and medieval tiles required careful handling of moisture and specific techniques in their creation and preservation. Minoan frescoes were created by painting on wet lime plaster (buon fresco), where the paint was absorbed and fixed by the plaster. For medieval tiles, moisture control remains crucial in their preservation, requiring stable humidity levels around 50% relative humidity and good air flow to prevent excessive moisture accumulation. Both art forms are particularly vulnerable to damage - frescoes are inherently fragile, while medieval tiles can be damaged by fluctuating temperature and humidity levels, requiring careful cleaning techniques and minimal intervention.	['Frescoes are the source of some of the most striking imagery handed down to us from the Minoan civilization of Bronze Age Crete (2000-1500 BCE). Further, without written records, they are often the only source, along with decorated pottery, of just how the world appeared to the Minoans and give us tantalizing glimpses of their beliefs, cultural practices and aesthetic tastes.\nInherent problems with frescoes are their fragility, incompleteness and artistic anonymity. In addition, in archaeological sites they are often found removed from their original settings, making them extremely difficult to date. Perhaps, restoration has at times been over-imaginative but nevertheless, the overwhelming impression given by this art form is the Minoan’s sheer joy in fluid, naturalistic and graceful forms represented in an impressionistic manner. There are also many surviving fresco fragments dating from the second phase palaces of 1550 to 1450 BCE, when the Mycenaeans began to take over the Minoan sites. However, as these are stylistically very similar to earlier Minoan frescoes, they are discussed as one in the following remarks.\nAs a technique, true fresco painting (buon fresco) is the painting of colour pigments on wet lime plaster without a binding agent and when the paint is absorbed by the plaster it is fixed and protected from fading. That the Minoans employed such a technique in their buildings is evidenced by string impressions in the plaster and by the depth of the paint employed. Fresco secco, which is the application of paint, in particular for details, onto a dry plaster was also used throughout the palaces as was the use of low relief in the plaster to give a shallow three dimensional effect. Colours employed were black (carbonaceous shale), red (haematite), white (hydrate of lime), yellow (ochre), blue (silicate of copper), and green (blue and yellow mixed). There are no surviving examples of shading effects in Minoan frescoes, although interestingly, sometimes the colour of the background changes whilst the foreground subjects remain unchanged. Although the Egyptians did not use true fresco, some of the colour conventions of their architectural painting were adopted by the Minoans. Male skin is usually red, female is white, and for metals: gold is yellow, silver is blue and bronze is red.\nThe first examples of fresco in Crete are limited to simple monochrome walls, most often red but sometimes also black. With improvements in the quality of plaster and pigments, the advent of monumental Minoan architecture and possibly through influence from Egypt and the Near East, the technique was employed to decorate the walls (either in their entirety, above windows and doors or below the dado), ceilings, wooden beams and sometimes floors of the palace complexes, depicting first abstract shapes and geometric designs and then later, all manner of subjects ranging in size from miniature to larger than life size.\nAs in earlier seal and ring engravings, popular scenes for frescoes - and perhaps indicative of the role of the palaces in Minoan society - were of rituals, processions, festivals, ceremonies and bull sports. Celebrated examples include two seated priestesses on either side of a shrine, a grove of olive trees with dancers and audience, two boxers, young men in a procession carrying rhytons, and a scene of both male and female figures in various stages of bull leaping - grasping the horns or somersaulting over the back of the animal. On occasion, fresco was also used to imitate architectural features, for example, veined alabaster slabs painted on the lower portions of walls.\nNatural subjects included flowers such as lilies, irises, crocuses, roses, and also plants such as ivy and reeds. Indeed, the Minoans were one of the earliest cultures to paint natural landscapes without any humans present in the scene; such was their admiration of nature.\nAnimals were also commonly portrayed, most often in their natural habitat, for example, monkeys, birds, cats, goats, deer, sea urchins, dolphins and fish. Although Minoan frescoes were often framed with decorative borders of geometric designs (spirals, diagonals, rosettes, and ‘maze’ patterns), the principal fresco itself, on occasion, went beyond conventional boundaries such as corners and covered several walls, surrounding the viewer.\nOther objects which received the fresco treatment include the celebrated limestone sarcophagus from Hagia Triada, a rare example of a fresco surviving complete. Within decorated frames, different sides of the coffin show two goddesses, each in a chariot, one drawn by goats and the other by griffins, a scene of a bull sacrifice and a funeral scene.\nThe Minoan style in frescoes was influential both with contemporary cultures such as in the Cyclades (e.g. Akrotiri on Thera, Phylakopi on Melos and Hagia Irini on Keos) and with later cultures, especially the Mycenaean, albeit with slightly different subject matter such as shields and other martial paraphernalia and perhaps with a lesser importance given to naturalism. Indeed, as far afield as Tel el Dab’a in Egypt, frescoes have been discovered which are notable for their similarity in style to the Minoan.', 'Circa 11th to 13th century\nOn this page you will find guidance on conserving and caring for medieval tiles.\nA Brief History\nThe proliferation and expansion of medieval tile making runs concurrently with the great age of ecclesiastical building in France and England, the first flowering of tile making began at the middle of the twelfth century to the mid thirteenth century; it is likely that tile makers travelled from Europe to England. In the early period only the wealthiest of ecclesiastical houses or Royal patronage were engaged in commissioning tiles.\nSome of the finest early two colour inlaid tiles, dating from around 1260 were made for Henry IIIs Westminster Abbey Chapter House and the Kings Palace at Clarendon, the British Museum also holds some fine tiles found at Chertsey Abbey in Surrey also dating from the early period. Byland, Rievaulx and Fountains Abbeys in Yorkshire all held, some still in situ, intricately cut mosaic or geometric style tile pavements dating from the end of the twelfth century.\nFrom the mid thirteenth century until the dissolution of the monasteries tile making became more widespread. Tile makers were quite often itinerant, building kilns near the religious establishments they supplied, but they also established permanent kilns in many places including Bawsey in North Norfolk and Coventry in Warwickshire. Wealthy merchants became patrons of the industry using tiles for their increasingly comfortable dwellings.\nIt is commonly thought that the Black Death and the Dissolution combined to see the end of tile making in Britain as there is little evidence for further decorative tile making after the mid sixteenth century, however significant numbers of medieval tiles remain in small churches, chapels and dwellings dating from later sixteenth and seventeenth centuries which have their origins in the removal of fabric from the monasteries.\nPractical guidance on simple conservation issues.\nThe information on these pages is for guidance only we do not accept responsibility as a result of any person carrying out any works according to the advice contained in this web site. Always follow Health and Safety measures described on products, tools and materials. Jackfield Conservation Studio is not responsible for the work which you do, the responsibility is yours and yours alone!\nConservation of medieval tiles should be in the hands of an experienced conservator, it is unfortunately all too easy to inadvertently damage these precious items.\nMedieval tile collections should be assessed annually to ensure that the condition is stable. Look for;\n- Damage as a result of fluctuating temperature and humidity levels\n- Excessive surface dirt or grit and infestations from birds, animals and biological growth\n- Fractured or loose tiles\n- Breakdown of mortar\n- Most medieval tiles will have defects due to manufacturing techniques, restoration is not applicable.\nHumidity and temperature levels should remain stable; they must be in a suitable equilibrium. An ideal storage environment would be;\nTemperature Range 19 degrees Cent + -1 degree.\nHumidity Range 50% +-2% relative humidity\nChurches or chapels, for example, require a good air flow to prevent humidity levels from rising too high. Tiles which are wholly unprotected must be covered during the winter months to avoid the freeze thaw cycle.\nMedieval tiles should only be cleaned very rarely using the utmost care. If excessive amounts of dust and grit form on the surface as a result of the location then it should be gently brushed and collected using soft squirrel hair brushes. Brushing by hand is preferable to vacuum cleaning as loose fragments are more easily collected if the surface is friable.\nA small amount of clay dust will be lost from the surface of the tile at every brushing which is why cleaning should be infrequent. Dry brushing in this fashion should be all that is required, coatings of any kind are not desirable, covering or carpets are not recommended as they will prevent absorbed moisture in the atmosphere from evaporating. Droppings from bats or birds should be removed as soon as possible, dabbing using de ionised water with a soft cloth will suffice.\nIf loose tiles require re setting the advice of a conservator should be sought.\nGood maintenance relies on positive action to maintain an ambient environment suitable for medieval tiles. Regular annual inspection which includes recording the condition of the pavements or individual tiles is essential; from that annual inspection it can be determined if the tiles or pavement require any treatment in the form of cleaning or mortar repair or if they are best left untouched. An annual inspection is best carried out by an experience conservator.']	['<urn:uuid:3d98e494-8a6f-4677-9f1d-b43b224c86eb>', '<urn:uuid:1885221d-a5d4-4d87-bbc5-d3a2a9c667cf>']	factoid	with-premise	verbose-and-natural	distant-from-document	multi-aspect	novice	2025-05-12T23:47:20.322175	46	99	1585
89	What's the connection between Canadian drug patents and water contamination?	In Canada, patented medicines are subject to price review by the Patented Medicine Prices Review Board, with patents lasting 20 years from filing. These regulated pharmaceutical products later appear as contaminants in waterways - studies show that medications from municipal wastewater enter the St. Lawrence River, where some patented drugs like anti-inflammatory medications and antibiotics have been found to cause toxic effects in aquatic organisms, including reduced phagocytosis in freshwater mussels.	['Marketing Innovative Drugs in Canada\nCanada is seeing a surge in small to mid-size pharmaceutical companies marketing directly in Canada. Canada’s public payer system and broad access to healthcare make it an attractive market, as does its proximity to the U.S. border.\nWhile companies are exploring the “Great White North”, it is important not to be caught out in the cold on some market basics. Key factors for marketing a new drug in Canada are data protection, patent protection and enforcement, and drug pricing. Innovators should understand each of these factors well before launch to protect their investment.\nRegulatory Approval: Notice of Compliance\nThe usual gateway to the Canadian market is a Notice of Compliance (NOC): the marketing authorization for new human or animal pharmaceuticals, and for human biologics. An NOC is issued by Health Canada following an acceptable drug submission; e.g., an innovator’s new drug submission (NDS) or a generic’s abbreviated version (ANDS).\nOnce approved, new chemical entities or biologics may benefit from data protection. Data protection applies where the first NOC for an “innovative drug” is granted on or after June 17, 2006.\nAn “innovative drug” is a drug that contains a medicinal ingredient not previously approved in a drug by the Canadian Minister of Health and that is not a variation of a previously approved medicinal ingredient such as a salt, ester, enantiomer, solvate or polymorph.\nThe data protection term comprises: a 6-year data protection period and a further 2-year period of market exclusivity (2½ where certain pediatric studies are timely conducted), from the date of the first NOC. During the 6-year period, a subsequent entry manufacturer cannot file a drug submission making a direct or indirect comparison to the innovative drug (e.g., an ANDS), and Health Canada cannot grant an NOC for the subsequent entry product until the period of market exclusivity expires.\nThe data term cannot be extended, and supplementary terms cannot be obtained based upon supplemental drug submissions or drug submissions filed for a new product where the new product comprises a combination of previously approved medicinal ingredients. It is only where one of the medicinal ingredients in a combination is an innovative drug that data protection would apply.\nData protection may be lost where an innovator stops marketing.\nData protection is independent of patent protection.\nData protection should be automatic for an innovative drug. Nonetheless, innovators should request data protection at the time of filing their NDS.\nPatent Procurement and Enforcement\nPatent procurement is generally procedurally less complex in Canada than many other G-7 countries, and typically less expensive. However, it can take a long time to obtain a patent, unless managed correctly. This can often be accomplished using expedited procedures.\nCanada has no patent term extension or restoration, nor supplementary protection certificates. The term is a fixed 20-year term from the filing date for patents issuing on applications filed on or after October 1, 1989.\nA patentee (or its licensee) can enforce a patent against a non-licensed third party “infringer” in court. A patent infringement trial can take two years or more from commencement to conclusion. During that time, it is unlikely that the patentee will be able to obtain a court order preventing the infringer from selling its product.\nFor pharmaceutical and biologic products, there is another option for patent enforcement under the Patented Medicines (Notice of Compliance) Regulations (“NOC Regulations”). The NOC Regulations link regulatory approval for a subsequent entry product to an innovator’s patent status in situations where the subsequent entrant is comparing or relying upon the innovator’s submission to enable it to file a reduced data package (e.g., an ANDS).\nUnder the NOC Regulations, a subsequent entrant cannot obtain a NOC until it has addressed all patents listed on the Patent Register as of the date the subsequent entry submission is filed. For each listed patent, the subsequent entrant must either accept that its NOC will not grant until the patent expires, or notify the innovator that the patent is not a bar, because, for example, it does not infringe or the patent is invalid.\nPatent listing is the innovator’s responsibility. An innovator must submit the appropriate forms together with its related drug submissions, or within 30 days after patent grant. These deadlines are inextensible; late listing is not possible. Patents are only eligible for listing if they have a filing date before the related drug submission, and if they claim the approved medicinal ingredient, formulation, dosage form or use.\nIf the innovator receives notice from the subsequent entrant, it will have 45 days to commence a court proceeding for review of the merits of the subsequent entrant’s allegations. Where a court proceeding is commenced, Health Canada cannot grant the subsequent entrant a NOC for a period of up to 24 months. If the innovator is successful, the subsequent entrant will not be able to obtain a NOC until patent expiry. If unsuccessful, then a NOC can grant immediately, assuming that safety and efficacy has been established.\nProceedings under the NOC Regulations do not finally decide issues of infringement or validity, but only whether the allegations of the subsequent entrant are justified. A patentee that is not successful under the NOC Regulations may therefore go to court to enforce the patent in an infringement action, or an unsuccessful subsequent entrant may go to court to have the patent invalidated.\nThe price a patentee or its licensee can charge for its drug may depend on whether the drug is patent protected.\nThe Patented Medicine Prices Review Board (PMPRB) is responsible for reviewing and determining whether a price of a patented medicine is excessive based upon a number of factors, including the price at which the drug or similar drugs have been sold domestically or in foreign markets.\nThe PMPRB expects patentees to file a notice of intention to sell a patented medicine in advance of any sales. However, the patentee or its licensee must make its first reporting to the PMPRB within seven days after (a) the first offer for sale of the medicine in Canada or (b) issuance of the first NOC, whichever is earlier. There are also subsequent, periodic reporting obligations.\nIf the patented invention pertains to a medicine, then the jurisdiction of the PMPRB is engaged. This nexus is very broad, and encompasses non-commercial formulations, dosage forms, uses, processes and intermediates, for example.\nThe jurisdiction of the PMPRB is engaged when a patent grants. However, if there are sales of the drug prior to patent grant and after the patent application becomes public, then the PMPRB will take jurisdiction over these sales.\nIf the PMPRB finds that the price of a medicine is excessive, it can order the patentee or its licensee to lower the cost of the drug, pay compensation to the government and/or to lower the price of another drug to offset excessive revenues.\nThere is an obvious interplay between data protection, patent procurement and enforcement and drug pricing. Central to each of these issues is when a patent application and drug submission are filed, and when a patent grants and approval is obtained. Coordination is key, so ask questions early and be ready!\nDaphne Lainson is a partner in the Ottawa office of Smart & Biggar/Fetherstonhaugh. She has been assisting clients with securing patent protection for their innovations for over a decade. Her work specializes in the fields of chemical and biotechnology inventions, including pharmaceuticals, biologics, consumer products, agrochemicals, specialty chemicals, industrial chemical processes, and oil, gas and petrochemicals. Specifically, she is able to advise clients in the pharmaceutical sector on matters involving issues of pharmaceutical regulatory law, including providing strategic advice during patent prosecution and following patent grant for both pharmaceuticals and biologics. Daphne can be contacted on +1 613 232 2486 or by email at firstname.lastname@example.org', 'Information identified as archived on the Web is for reference, research or recordkeeping purposes. It has not been altered or updated after the date of archiving. Web pages that are archived on the Web are not subject to the Government of Canada Web Standards. As per the Communications Policy of the Government of Canada, you can request alternate formats on the Contact Us page.\nDrug cocktail in the St. Lawrence River offers no relief to aquatic organisms\nThe research findings of Environment Canada scientists reveal that medications contained in municipal wastewater discharges are present in the waters of the St. Lawrence River. Some of these medicines could pose a threat to aquatic biota.\nAt water quality monitoring stations along the St. Lawrence River, 17 pharmaceutical, and personal care products (PPCPs), and other substances were detected among the 30-odd contaminants analyzed in 2006. Where do these products come from? Old medications flushed down toilets and medications ingested and eliminated by the human body are the main sources. Thus, wastewater discharged into the St. Lawrence River contains traces of medications which, ironically, you thought were safely stored in your medicine cabinet: analgesics, anti-inflammatory drugs, contraceptives, and so on.\n|Coprostanol||By-product of cholesterol||39|\n|Coprostanol-3-ol||By-product of cholesterol||85|\n|Coprostanol-3-one||By-product of cholesterol||51|\n|4-ter-octylphenol||Surfactant degradation product||97|\nSource: Rondeau, 2008.\n|Yamaska River||1 to 20||2 to 79|\n|Detroit River||64 to 141||94 to 207|\nThe Yamaska River has lower concentrations of ibuprofen and naproxen than the Detroit River.\nSource: Hale et al., 2003.\nConcentrations of PPCPs and other substances measured in the St. Lawrence River and tributaries in 2006\nSource: Rondeau, 2008.\nDo these medications threaten the health of aquatic organisms?\nMost of these substances are considered toxic, but their measured concentrations are generally too low to be acutely toxic to aquatic organisms. However, longer-term effects could occur. Moreover, some substances that are considered non-toxic or not highly toxic, such as caffeine, may cause oxidative damage in the tissues of some aquatic organisms such as mussels and fish. When these organisms absorb caffeine, through the process of biotransformation metabolites are released that are even more toxic than the initial substance.\nThe effects of anti-inflammatory drugs on mussels exposed to them in the laboratory or municipal wastewater have not been demonstrated to date. However, scientists have recently observed that naproxen and ibuprofen produce toxic effects at concentrations ten times lower or less than the values measured in municipal effluents (Blaise et al., 2006). Other medications, such as novobiocin and morphine, respectively used as an antibiotic and an analgesic, cause reduced phagocytosis in freshwater mussels (Elliptio complanata) in the St. Lawrence River (Gagné et al., 2006). Other research findings show that estrogens present in the St. Lawrence River affect the reproductive system of male spottail shiners (Notropis hudsonius), a fish of the minnow family (Cyprinidae), which serves as prey for many freshwater predatory fish (Aravindakshan et al., 2004). Similar results have been observed among E. complanata musselsexposed to water from the St. Lawrence River.\nDid You Know? Up to 66% of male mussels living near the Montréal municipal outfall had become females, whereas the proportion was only 41% upstream from the point of discharge, which is the normal rate of frequency for females of this species (Gagné et al., 2004).\n“Canadian water quality guidelines are intended to provide protection of freshwater and marine life from anthropogenic stressors such as chemical inputs […].” Among other things, these guidelines identify the lowest concentrations of a substance that produce effects on organisms. There are no recommendations yet for several emerging or newly detected substances. However, regulations are being developed governing environmental risks related to pharmaceutical and personal care products contemplated by the Food and Drug Act.\nTo Know More\nAravindakshan, J., V. Paquet, M. Gregory, J. Dufresne, M. Fournier, D.J. Marcogliese, and D.G. Cyr. 2004. Consequences of xenoestrogen exposure on male reproductive function in spottail shiners (Notropis hudsonius). Toxicological Sciences 78: 156–165.\nBlaise, C., F. Gagné, P. Eullaffroy, and J.-F. Férard. 2006. Ecotoxicity of selected pharmaceuticals of urban origin discharged to the St. Lawrence River (Quebec, Canada): A review. Brazilian Journal of Aquatic Science and Technology 10(2): 29–51.\nGagné, F., C. Blaise, M. Fournier, and P.D. Hansen. 2006. Effects of selected pharmaceutical products on phagocytic activity in Elliptio complanata mussels. Comparative Biochemistry and Physiology, Part C 143(2): 179–186.\nGagné, F., C. Blaise, and J. Hellou. 2004. Endocrine disruption and health effects of caged mussels, Elliptio complanata, placed downstream from a primary-treated municipal effluent plume for one year.Comparative Biochemistry and Physiology, Part C, 138: 33–44.\nHale, R.C., M. Alaee, J.B. Manchester-Neesvig, H.M. Stapleton, and M.G. Ikonomoun. 2003. Polybrominated diphenyl ether flame retardants in the North American environment. Environment International 29: 771–779.\nRondeau, B. 2008. Monitoring and Surveillance of Water Quality – Quebec, Water Science and Technology Branch, Environment Canada. Personal communication.\n- Date Modified:']	['<urn:uuid:67057e17-d4a2-470f-ad8e-3bbacdd72397>', '<urn:uuid:12611ba8-9bd4-473d-a3ff-f843a45b61b7>']	factoid	with-premise	concise-and-natural	distant-from-document	multi-aspect	expert	2025-05-12T23:47:20.322175	10	71	2092
90	When did people start making heatmaps for the first time?	Heatmaps have been used since the late 1800s, when Toussaint Loua used a shading map to visualize social demographic changes across Paris. Computer heatmapping technology was first trademarked in the early 1990s by software designer Cormac Kinney, who created a tool to graphically display real-time financial market information.	"[""Website heatmaps are a powerful way to understand what your users do on your website—where they click, how far they scroll, what they engage with, and more.\nEvery website is different, so it’s important to find the heatmap tools that best suit your business needs.\nClick maps and scroll maps are the most popular types of heatmaps, but there are many other types.\nUX designers, marketers, analysts, and product teams can all benefit from utilizing heatmaps.\nWhat is a heatmap?\nHeatmaps are a method of representing data graphically where values are depicted by color, making it easy to visualize complex data and understand it at a glance. Heatmaps can be created by hand, though modern heatmaps are generally created using specialized heatmapping software.\nHeatmaps have been used in some form, since the late 1800s, when Toussaint Loua used a shading map to visualize social demographic changes across Paris.\nComputer heatmapping technology was first trademarked in the early 1990s by software designer Cormac Kinney, who created a tool to graphically display real-time financial market information.\nA variety of color schemes can be used when creating heatmaps, including grayscale and rainbow. Rainbow-schemed maps are often preferred, though, since humans can perceive more shades of color than they can of gray (though there are drawbacks).\nGenerally speaking, warmer colors—reds and oranges—represent “more used” or “more popular” sections, while cooler colors—blues and purples—represent less frequently used sections of your map.\nEach heatmap works differently, though. For example, click maps typically use different shades of one color: the darker the color the more that area is clicked.\nWhat does a heatmap show?\nHeatmaps are visual representations of user reactions on various pages on your website, providing visual context for easy analysis. They help you gather visitor behavior insights, which you can then use to customize your website to better meet visitors’ expectations—improving conversion funnels, increasing conversion rates, reducing bounce rates, or boosting sales, among other goals.\nIn other words, heatmaps are an easy way to contextualize aggregate user trends for any given web page.\nOften, they're are used to reveal clicks and taps on a web page, where each page element on the page is color-coded according to how popular it is. The most-clicked or tapped elements might be bright red, while the less-clicked elements fade toward cooler colors.\nWhen used on websites, heatmaps help identify user behavior that helps you optimize your site. For example, website heatmaps let you easily see high-level user behavior: if nobody is tapping one of your most important page elements, then that suggests you might want a new design to increase engagement.\nFurther, different types of heatmaps can help you understand different elements of your website. For example, a click map reveals the most-clicked elements on your website, while a scroll map depicts how far users scroll down on a given page. There are also error click maps, dead click maps, and more.\nWe’ll talk more about different types in a later section.\nHow does a heatmap work?\nHow a heatmap is created depends on the type. There are multiple types, but they can generally be bucketed into two categories: interaction and attention heatmaps.\nInteraction heatmaps measure different types of engagements and use tracking codes to record interactions between a user and a website, like clicks, scrolls, mouse movements, and more.\nAttention heatmaps are more complex, and monitor how users look at your website content by monitoring or predicting their eye movements.\nTypes of website heatmaps\nThere are many different types of heatmaps that offer different insights. It's usually best practice to combine multiple types of heatmaps to get the truest picture of user behavior.\nClick maps are one of the most popular types of website heatmaps, and show you where users clicked on your page, offering insights into how people use your website or a page of your website. With click maps, you can see which elements on your site are most or least clicked, which can reveal where there are navigational issues.\nClick maps can also help you improve website ROI by placing and monitoring effective CTA buttons; helping you identify and remove areas that are causing user friction and increasing bounce rates; showing which areas of your site are most popular; and monitoring conversion rates for new and returning visitors.\nThere are a few things to watch out for when using click maps, though. Improper analysis can occur from accidental multiple login usage, frustrated clicks that can skew data analysis, and miscellaneous issues caused by browser/device incompatibilities, among other shortcomings.\nLike with any heatmap, visitor click maps need to be paired with other data—data points from product analytics tools, user analytics, Google Analytics, UX surveys, or elsewhere—to get a full picture of why users are behaving the way they are.\nIn the same way that click maps represent where users click, scroll maps are a visual representation of visitors’ scrolling behavior on a web page. Scroll maps tell you:\nHow many visitors scrolled through a page to the bottom\nHow many visitors scrolled through a page but stopped short of the bottom\nHow many visitors abandoned a page\nWhat percentage of users scrolled to certain depths on a web page (for example, 34% of visitors scrolled 50% of the way down a page, 13% of visitors scrolled all the way to the bottom, etc.)\nUnderstanding how far the average visitor scrolls before navigating away can help you determine the ideal length of web pages. It can also help you decide where to put content on a page.\nIf, for example, you find that only 25% of visitors scroll below the fold (below where your screen cuts off the rest of the page) on a page, you know that you need to put the most important content at the very top of the page.\nScroll maps can also help you understand if your web page has a false floor (or false bottom), where visitors believe they’ve reached the bottom of a page but actually have not.\nWhen using scroll maps, always look at metrics for both desktop, tablet, and mobile devices.\nAll in all, using and analyzing scroll maps can show if important content is being ignored and help you understand how a page should be redesigned to maximize its impact.\nRather than tracking mouse clicks, mouse-tracking maps track general mouse movement.\nThey help spot frustrated users by showing where people are hovering, hesitating, or thrashing their cursor on a web page.\nResearch shows an association between where users are looking and where their mouse cursor is, which is what makes mouse-tracking heat maps informative.\nMouse-tracking also helps you identify hover patterns that show areas of visitor friction or frustration, optimize complex web pages with dynamic elements, and estimate the relevance of search results by the volume of clicks.\nThough there’s a relationship between where users look and their cursor location, the two are not identical, and can sometimes lead to faulty insights.\nEye-tracking website heatmaps\nEye-tracking uses a sensor technology that tracks the movements of users’ eyes when they are using a web page. This type of technology can monitor eye movement, blinking, and pupil dilation to analyze where on a page a user’s attention is focused.\nThis type of data gives you insights into how well a web page’s design is working to help you create a more user-friendly layout. Eye-tracking heat maps can reveal information about a visitor’s gaze pattern, which enables you to put a web page’s most important elements in the most-looked at locations on the page.\nEye-tracking maps typically provide extremely accurate data by showing exactly what users are looking at on your web page. They can be validated through comparison with mouse-tracking data.\nHowever, eye-tracking tools are expensive, usually resulting in data based on a small user sample. Additionally, some users are aware and wary of eye tracking, and use camera covers to avoid being surveyed.\nError click heatmaps\nThough the user may or may not realize they’ve triggered an error, you can use error clicks to specifically investigate console errors or uncaught exceptions. Then, you can use your Digital Experience Intelligence tool to view all sessions that contain the same error and determine how to resolve the issue.\nEncountering errors or site glitches can be highly frustrating for your users. Error-click maps let you quickly uncover and fix bugs—drastically enhancing user experience.\nRage Click™ heatmaps\nRage Clicks are used to identify areas of friction or frustration by showing areas where users rapidly click (or tap) an element on your site. Rage Clicks might occur when users mistake a static element for a button and expect something to happen, or when a button isn’t functioning properly and triggers an error.\nRage click maps show all the areas that users click in frustration. (After all, wouldn’t you want to know if the most highly Rage-Clicked element on your website is the “confirm purchase” button?)\nSometimes it’s difficult to predict where users will become frustrated, which is why using your Digital Experience Intelligence solution to monitor rage clicks can be so helpful.\nLearn where your users are Rage Clicking\nFullStory's specializes in Rage Click heatmaps to help businesses understand where their users are getting frustrated and falling out of the funnel. With FullStory, those problems can be solved.\nWith Rage Click maps, you can reproduce and fix unexpected bugs to identify and correct CTA confusion to increase conversions, and increase ROI by reducing product friction.\nWatch out for false positives in your Rage Click analysis, which can occur if a user is rapidly clicking through a multi-page app, for instance.\nIt’s always best practice to pair your Rage Click analysis with watching session replays.\nDead click heatmaps\nSometimes, users mistake un-clickable elements on a website or app as a button, and tap it expecting something to happen—resulting in a dead click. Dead clicks reveal which non-functioning elements on your site or app are being mistaken for buttons, so that you can figure out how to reduce user confusion and frustration.\nThey can also help understand behavioral trends over time to identify new opportunities, and proactively weed out user confusion to optimize conversions.\nThis type of heatmap uses artificial intelligence (AI) to generate visual representations of user attention data created by software algorithms. So rather than showing what users actually are paying attention to on your website, companies like EyeQuant and Attention Insight specialize AI-generated heatmaps show what users are likely to pay attention to on your website.\nTypically, AI-generated heatmaps predict future user behavior by imitating the first three to five seconds of users’ attention on a website to identify which elements are looked at most and least.\nBy predicting where users will look when they first navigate to a website, AI-generated heatmaps can help you understand where to place critical elements and improve future pages and sites. Additionally, they have up to 95% accuracy and are more affordable than eye-tracking technology.\nHowever, AI-generated maps typically aren’t effective on websites with low traffic or engagement, as there are fewer actions to predict and learn from.\nWhy should you use a website heatmap?\nWebsite heatmaps help you track visitor behavior visually so you can make your improve your site around your goals. They highlight which site areas people are engaging with, which areas are working, which aren’t, and which areas your users are avoiding.\nThese insights help you make data-driven changes — you're acting on data, not just guessing.\nAt many organizations, website heatmaps are part of larger conversion rate optimization (CRO) efforts, since they’re mainly used to improve conversion rates.\nWebsite heatmaps can help you determine if:\nThere is important content on a page that visitors aren’t getting to\nUsers are having trouble finding or seeing certain CTAs\nUsers are experiencing issues based on device type or browser\nNon-clickable elements are creating distractions that harm conversion (as shown in the video below)\nFurther reading: How to use session replay for conversion rate optimization\nHow do I create a website heatmap?\nThere are many tools available online. Before choosing your heatmapping tool, you’ll want to compare the tools available. You’ll need to have an idea of which page(s) on your website you want to analyze, and what type of map will surface the data you need.\nYou’ll also want to look for a tool provides the most types of heatmaps. You don’t solely want scroll maps or click maps—ideally, you have as many of the map types listed above. This way, you can combine the insights from each to make the most well-informed decisions for your site.\nSome heatmapping tools that are available:\nWho can benefit from using heatmaps?\nBecause of the variety of data that you can glean and analyze with, heatmapping software can benefit many different teams in an organization. Here’s an overview of how different departments can gain from heatmaps:\nFor UX designers\nUser experience (UX) designers are often responsible for testing on their site or app, and heatmaps can supplement their testing methods.\nFor example, UX designers can use them for usability testing to understand whether their content inspires users to take action, identify patterns of behavior, and determine whether your CTAs are well-placed.\nHeatmaps can also be used to strengthen the insights from A/B experiments, and can be applied both to your control and the variable you’re testing. If your variable doesn’t perform as well as you expected, you’ll know why. With one of these tools in your back pocket, even “failed” tests can provide valuable learnings.\nAny digital marketer knows that the competition for customers’ attention is greater than ever, and traffic acquisition cost (TAC) is increasing. Unsurprisingly, it’s critical to get as much value from your site traffic as possible.\nUsing heatmaps, marketers can understand which parts of a page or an advertisement people’s eyes gravitate toward, and which parts tend to be ignored. This knowledge allows you to place the most important element—like a special offer or a CTA button—on the most-seen part of a page.\nFor digital analysts\nFor analysts, they can provide the critical yet often-missing data that turns analysis into actionable insights and business outcomes. Using heatmaps let you combine qualitative and quantitative data in ways that add depth and context to analyses.\nWhere other methods may only allow you to count clicks on a button, heatmapping tools can help you understand what happened before, after, and in between those clicks—critical information for understanding your user’s behavior.\nWhat’s more, heatmaps are highly visual by nature, allowing digital analysts to see and understand complex data sets at a glance before digging in deeper.\nThe pros and cons of heatmaps\nLike with any type of website analytics, there are benefits and drawbacks of using heatmaps to measure user behavior. Here are a few.\nPros of heatmaps:\nSee and understand large quantities of data at-a-glance in a highly visual format\nIdentify areas where users might be ignoring or overlooking the action you want them to take and implement a solution\nGain a clearer understanding of user behavior over time and identify useful patterns\nLearn from pages on your site to build more effective pages in the future\nFind out what areas of your site users are naturally drawn to and put your most important content there\nCons of heatmaps:\nVariations in device sizes and browsers can sometimes make heatmap data unreliable\nHeatmaps often don’t work well with dynamic applications where the page changes, and most websites today are dynamic\nCertain types of heatmaps, like eye-trackers, can be cost-prohibitive\nSome types of heatmaps, like AI-generated heatmaps, need large volumes of traffic to analyze in order to create accurate predictions\nThe last problem with heatmaps is they should always be paired with other data, as any one heatmap will not provide a holistic view of why users behave the way they are.\nDive into heatmaps with FullStory\nHeatmaps are a critical tool in your digital experience toolbox. Alongside scroll maps, error click, dead click, and Rage Click™️ maps, FullStory lets you analyze user funnels, conversion rates, watch session replays, and more.\nWith FullStory's Digital Experience Intelligence platform, you can combine quantitative and qualitative data for 360º understanding of your website—letting you perfect your digital experience.""]"	['<urn:uuid:af2fa448-7a37-49b1-b6dd-c697018ac18e>']	factoid	with-premise	concise-and-natural	distant-from-document	single-doc	novice	2025-05-12T23:47:20.322175	10	48	2698
91	I'm curious about artists who work with clay - do Debra Fritts and Richard Marquis use similar techniques?	No, Debra Fritts and Richard Marquis use quite different techniques in their work. Debra Fritts hand builds her sculptures using thick coils of clay, firing them three to five times to achieve desired colors using oxides, slips, underglazes, and glazes. She approaches color on clay as a painter. In contrast, Richard Marquis works with blown glass, particularly using the Italian glass-making technique called murrine. He was one of the first foreign artists allowed into Northern Italy's glass blowing foundries in 1967 and became a pioneer in using this technique with nontraditional aesthetics.	"['Highlights from R & Company’s Ambitious Design Exhibition ‘OBJECTS: USA 2020’\nAt the tail end of the 1960s, the Museum of Contemporary Craft (currently Museum of Art and Design) director Paul J. Smith and dealer Lee Nordness decided to portray what R & Company co-founder Evan Snyderman today calls “an investigation that cemented dozens of craft artists’ careers.” The duo embarked on a three-year cross-country journey from Ohio to Nebraska in quest of “a movement happening with minimal outlet outside of art galleries,” according to Snyderman. “OBJECTS: USA“ opened at the Smithsonian American Art Museum in 1969, including works by 253 artists with the backdrop of the Vietnam War, Nixon administration, and Civil Rights Movement. The exhibition traveled to 22 national museums and 11 more in Europe—its splash reached beyond the art circles, as even far as the “Today Show.” Snyderman, who is among the organizers of R & Company’s upcoming exhibition dedicated to this groundbreaking survey, tells Interior Design that “OBJECTS: USA” introduced “a uniquely American genre of artists firsthand making the work as opposed to the European tradition of a separation between artist and fabricator.”\n“OBJECTS: USA 2020“ features 100 artists sharply divided between those from the original exhibition and contemporary names whose practices stem from the craft tradition. Snyderman was joined by design curators Glenn Adamson and James Zemaitis, the gallery’s director of museum relations. for the selection of the historical works and, again, Adamson and Object & Thing founder Abby Bangser for contemporary pieces. After a decade of discussions and nearly three years of planning, the team found the solution to present a contemporary portrait of craft in a biennial-like approach. “Over five decades ago, Smith and Nordness took their survey as a diversity challenge,” says Snyderman. The original show had more women artists than any comparable survey at the time, in addition to a remarkable—still underwhelming—number of artists of color for its time. A tumultuous sociopolitical landscape today makes “OBJECTS USA:2020” an incredibly timely look at the craft movement in art, as notions of inclusion, sustainability, and labor profoundly resonate with an urgency of self-expression.\nRead Interior Design’s picks from R & Company’s “OBJECTS: USA 2020” exhibition, which will remain open through July, 2021 at 64 White Street in Manhattan.\nJoyce Lin, Skinned Table, 2020\nThe youngest name in the show’s contemporary section, Lin is a multidisciplinary artist beyond the principles of art and design. That she studied furniture at the Rhode Island School of Design and geology at Brown University at the same time is reflected in her “skinned” furnitures, in which Lin dissects found objects’ layers with surgical precision. A simple razor blade is the artist’s tool to peel off the table’s veneer to reveal what Snyderman calls “the underbelly of an object between old and new.” She piles the furniture’s layers on brass pegs, similar to those used by museums for exhibiting ancient specimens.\nMichele Oka Doner, Tattooed Dolls, 1968\nOka Doner, on the other hand, was the youngest artist participating in the original show with her porcelain glazed dolls—and similarly she majored both in science and design while studying at the University of Michigan. The eerily anatomical patterns over the dolls’ firm skins stem from iron oxidation, as well as the artist’s painting of motifs that resemble a body’s inner organs. The two dolls in the show comes from Doner’s loft studio in Soho, created a few decades after the initial versions which were also adopted by protestors during the U.S. government’s use of napalm.\nRichard Marquis, American Acid Capsule with Knit Case, 1969-70\nAnother politically-charged piece from the original checklist is Marquis’s physically minuscule yet ideologically hefty blown glass pill dressed in American flag patterns. Marquis was one of the first foreign artists allowed into Northern Italy’s glass blowing foundries in 1967. After studying with Ron Nagle at the University of California in Berkley, Marquis became a pioneer of murrine, the Italian glass-making technique using a cane, in nontraditional aesthetics, with the influence of the time’s social dynamics. Snyderman, who studied under Marquis at age 16 at the Haystack Mountain School of Crafts, notes that the work’s resonance with the current political climate made it an early pick for the new show. Three in total, the work’s one edition sits in the Metropolitan Museum of Art’s collection.\nMarilyn Pappas, Flight Suit, 1972\nLess conventional in material, Pappas’s colorful collage over a U.S. airfare flight suit was another piercing statement on the Vietnam War. The formal attire provides a blank canvas for mixed-media abstraction with colorful geometric forms that challenge the uniform’s political significance. While the edition included in the original exhibition later joined the Museum of Art and Design’s collection, this show’s curators loaned a 1972 version from the artist’s own Massachusetts studio. Following her participation in “OBJECTS: USA,” Pappas instantly became a sought-after figure and extensively exhibited her work across galleries; however, her work has remained out of the radar in recent decades. This edition, for example, has not been exhibited in over four decades.\nJohn Souter, Soft Rock series, 2020\nColor also leads contemporary artist John Souter’s predominantly ceramic mixed-media sculptures in whimsical and alien forms. The Philadelphia-based artist playfully twists notions of texture, materiality, and dimension in a style which Snyderman compares to Nagle’s. “I’ve been following Souter over the years as one of the surrealist artists making work with copper and flocking along with ceramic,” he says. The artist’s seemingly soft surfaces trick the eye, while the sculptures push limits of imagination with their extraterrestrial forms.\nJB Blunk, Stool #7, 1973\nHumor is subdued in sculptor JB Blunk’s wooden stool. An elegantly-curated solo exhibition at Kasmin Gallery last fall had cemented the Californian artist’s posthumous presence on the east coast, supported by his most extensive catalog to date that featured an essay by Adamson. Blunk worked in jewelry, ceramic, and even architecture, but his most striking work arguably came in wood, embodied in the medium’s organic smoothness and demure manifestation of narrative. Similar to Marquis in Italy, Blunk was one of the first American apprentices to study in Japan with master potters. Back in the U.S., he built his own studio in western California where he committed to a life of making, including wooden furniture. “Tension,” says Snyderman “is almost tangible in Blunk’s work.” The kinetic energy in his furniture is best experienced through their utilitarian character, such as this minimalist redwood stool which he accentuated with a sharp bullet-like growth poking from the underneath of the seat.\nAdejoke Tugbiyele, Destiny’s Child, 2019\nMaterials’ potentials beyond their physical limits is traceable in Tugbiyele’s grass broom, church stick, black paint, and resin sculpture. Suspended 3-feet off the floor, the poetically-orchestrated biomorphic work contains the energy of its performative possibilities. The Brooklyn-based artist uses organic labor-related materials, occasionally those used in broom-making, to juxtapose mysteriously sensual works on the body and sexuality. When not activated with performances, the pieces stand in for the absent body yet speaks for the artist’s statement on togetherness as well as longing.\nTiff Massey, Yo Mama’s Earring, 2020\nA recent recipient of United States Artists Fellowship, the Detroit-based artist and metalsmith Tiff Massey beats brass to capture the influence of hip hop culture and the identity politics inseparable from the music genre. Her wearable or non-utilitarian jewelry pieces assume visual and performative cues from the everyday but they subvert connotations on race, class, and gender through Massey’s intricate hammering of the material. This blown-up size brass sculpture of an earring replicates an iconic accessory of hip hop in a scale associated with high art and raises questions about value and access assigned to culture.\nJun Kaneko, Sanbon Ashi, c. 1970\nCorporeality is evident in Omaha-based artist Kun Kaneko’s colorful ceramic sculpture adorned with geometric shapes in pastel hues. The Japanese American artist’s sculpture relies on the looker’s eyes to define its content: either an extremely contorted body, or a abstract bent form, the work is playful and inviting. Mostly known for his densely-colored larger than life ceramic busts, Kaneko has exhibited his clay or ceramic work in public spaces, as well as designing sets for opera. Snyderman considers Kaneko’s work “a cross pollination of cultures,” in which different references of form and pattern blend in with ceramic’s radiant impact.\nTanya Aguiñiga, Vestigial 2, 2019\nMexican artist Tanya Aguiñiga’s practice weaves communities together through yarn and spirit. The L.A.-based artist’s MAD exhibition Craft & Care in 2018, for example, had included massive-scale woven sculptures, as well as a community project she had initiated at the Tijuana border with art-making and story-telling in its core. Aguiñiga’s sculptural practice, which ranges from furniture to abstract wall-hung or floor pieces, is a testimony of weaving’s meticulous and meditative nature. “Vestigial #2” combines cotton rope, sisal, self-drying terra cotta clay, mylar, and gold leaf into a dreamcatcher-like form which elegantly drapes in an airy lightness of woven forms. Both ghostly and present, the work is reminiscent of rivers, brain cells, or a blanket, balancing intimacy with collective use.', 'Muse Gallery will be hosting a joint Pop Up Show @ Muse Gallery Hilton Head- February 15-28, 2018, featuring wall hanging and free standing sculptural work by artists Debra Fritts, Signe Stuart, Sue Cavanaugh and Char Norman. Cavanaugh and Norman will be in attendance for the show to meet and discuss the work. Opening Reception will be held on Friday February 16th from 5-8 pm and a Private Brunch with the artists will be held on Saturday February 17th from 11-1 pm. We hope you can join us!\n""I am interested in gathering: assembling, collecting, hoarding . . . and the process of taking needle to cloth and creating folds. The stitching has grown out of the ancient art of patterning cloth for kimono, and most names reference the original stitches, even though I’ve transformed those stitches over time. The “Ori-Kume” series combines ori-nui, stitches done on the fold with mokume running stitches. “Ori-maki-kume” describes a combination of mokume running stitches and ori-maki-nui stitches, an original hybrid stitch that creates a density I’ve grown to love...Cloth challenges notions of traditional art. At the same time, fabric is universally accessible and comforting. I’m particularly attracted to dichotomies, to yin/yang, attraction/repulsion, black/white, and the vastness of the gray area in between. All my work begins with a drawing, a plan. But the surprises that develop along the way delight and challenge me. These surprises inform future works.""\nCavanaugh works by hand with cloth, cord, dye, paint and occasionally wood and wire. She does this by hand and without assistants. Her work has been seen in national and international exhibits at the Columbus Museum of Art, Oceanside Museum of Art, Springfield Museum of Art (Ohio), Ross Museum of Art, Johnson-Humrickhouse Museum of Art, Ohio Craft Museum and Zanesville Museum of Art. Awards include Best of Show, Shibori Cut Loose exhibit, Textile Center, Minneapolis; Ruth Lantz Fiber Award; Janet Long Memorial Award for Excellence in Fiber; Ohio Arts Council Professional Award; and the Lynn Goodwin Borgman Award for Surface Design.\nIn 2012 she was selected by the Greater Columbus Arts Council and the Free State of Saxony for an artist residency in Dresden, Germany. She worked in a studio at Geh8 Kunstraum und Ateliers for 80 days culminating in a two-person exhibit with Rotterdam painter Marielle Buitendijk.\nCavanaugh\'s work is in collections of the Hilton Columbus Downtown and the Ohio Arts Council and private collections in Ohio, New Mexico, California, New York, Chattanooga, and West Seattle. She is represented by Muse Gallery, Columbus, Ohio, and gráficas gallery, Nantucket, Massachusetts. She lives in downtown Columbus, Ohio, and has a studio in the 400 West Rich artist community.\nABIQUIU, NEW MEXICO\n""As a child, I had dirt under my fingernails and spent hours playing in the mud. Today I continue to allow the earth to feed me information for my art. Working intuitively from pounds of wet red clay, forms appear and stories develop. I may be questioning an occurrence or celebrating a relationship or just being aware of the precious environment. The search continues until I reach the core: the spiritual level of the sculpture. Then the work can speak. At the present, I am exploring new territory in Abiquiu, New Mexico while embracing my southern heritage. Often symbols are used in the work such as the color red or three dots to honor my mother or the raven as a symbol for my new life in the west. I am “touching ground”, getting to the basics, listening and learning. Each sculpture is hand built, using thick coils, and fired three to five times depending on the color and surface I am trying to achieve. I approach the color on the clay as a painter. My palette is a combination of oxides, slips, underglazes, and glazes. The form of the piece informs the type of surface treatment.""\nDebra Fritts considers herself a narrative artist allowing her work to tell stories of daily life and events. Her works are influenced by her time in New Mexico exploring the west while embracing her southern heritage.\n“I hand build each sculpture, primarily using thick coils, and fire three to five times depending on the color and surface I am trying to achieve. I approach color on clay as a painter. My palette is a combination of oxides, slips, underglazes, and glazes. The form of the piece informs how I should approach the surface.”\nDebra has been published in books such as: Artists Homes and Studios, Ashley Rooney, Schiffer Publishing. Contemporary Ceramics, E. Cooper, Ceramic Figures, Lark Books, and 500 Figures, Leslie Ferrin, Lark Books. Museum Collections include: Fuller Museum, Brockton, Massachusetts and Georgia Southern University, Saunders Georgia Artist Museum. Professional and Teaching Experience includes Director of Art Center West, Roswell, Georgia 1995-2011, Beatrice Wood Center, workshop, Ojai, California, and Surface National Clay Conference, San Diego, California.\n""The work I am engaged in stems from a deep-rooted connection to natural objects and environmental issues while examining the relationship between man and nature. Reverential attitudes and nurturing acts contrast with the destruction of nature. The pod forms I use are both a type of shroud for natural relics and a womb or cradle for rebirth. This dichotomy of ideas is further expressed by the mending of natural objects through the violent act of stitching and fastening parts together. I find it fascinating and somewhat meditative to achieve a whole through the slow and gradual building up of small elements. Weaving is based on this principle and my drawing technique mirrors this idea as I layer graphite and colored pencil to create the image. Even the fibers in my handmade paper echo the idea of small units building to become a whole. Manipulation of materials and the use of traditional techniques in surprising or nontraditional ways are challenging and engage me in problem solving. The engineering necessary to create a three-dimensional piece on a loom intended for two-dimensional processes and the use of soft materials to form substantial objects is of particular interest. As I continue to explore natural relics as icons, votives, or objects of reverence, I hope to engage the viewer in a way of seeing that may lead to a respect and appreciation for the environment. Future plans call for returning my sculptures to the location from where the natural object was taken. In this way I give back and let the elements take their natural course in the cycle of life.""\nChar Norman is an accomplished fiber artist specializing in papermaking and fiber sculpture. She received a Master of Fine Art from Claremont Graduate University and a Bachelor of Art from Scripps College. She has lectured and exhibited extensively both nationally and internationally. She has developed and conducted workshops for all ages, worked as a consultant to area schools and community arts organizations, held the positions of Associate Provost and Dean of Faculty at Columbus College of Art & Design and has recently returned to the studio as a full time professional artist.\nSANTE FE, NEW MEXICO\n""Observations and questions about mysteries of the universe, life and consciousness are sources of visual ideas for my paintings and constructions. Making these works is an ongoing process of experimentation and negotiation between ideas and materials. I want my artworks to resonate with viewers and move them toward seeing this is that: everything as a consequence of endless shape-shifting, combining and recombining.""\nSigne Stuart\'s professional history spans over fifty years, beginning in the early 1960\'s. Her approach to art making relies on experimentation with painting materials and forms, often breaking from the standard rectangle and concepts of framing. Stuart has lived and worked in diverse regions of the United States: East Coast, Pacific Northwest, Northern Plains, and Southwest: residing now in Santa Fe, New Mexico.\nSince 1972, Signe Stuart has had 18 solo museum exhibitions including those at the Sheldon Art Museum, Lincoln, NE; North Dakota Museum of Art, Grand Forks, ND; American Swedish Institute, Minneapolis, MN; South Dakota Art Museum, Brookings, SD and the Roswell Museum and Art Center, Roswell, NM. Her work has also been included in many museum group exhibitions, among them the Joslyn Art Museum, Omaha, NE; the New Mexico Museum of Art, Santa Fe, NM; Burchfield Penny Art Center, Buffalo, NY and the Minneapolis Institute of Arts, Minneapolis, MN.\nPublic Collections include: American Swedish Institute, Minneapolis, MN, Benton Museum of Art, Storrs, CT, Blanden Art Museum, Fort Dodge, IA, Boise Art Museum, Boise, ID, Cedar Rapids Puiblic Library, Cedar Rapids, IA, Dahl Art Center, Rapid City, SD, Grinnell College, Grinnell, IA, Joslyn Art Museum, Omaha, NE, Miami Airport, Miami, FL, New Mexico Museum of Art, Santa Fe, NM, New Mexico State Capitol Art Foundation, Santa Fe, NM, North Dakota Museum of Art, Grand Forks, ND, Plains Art Museum, Fargo, ND, Roswell Museum and Art Center, Roswell, NM, Salt Lake City Public Library, Salt Lake City, UT, Schnitzer Museum of Art, Eugene, OR, Sheldon Museum of Art, Lincoln, NE, Sioux Falls Airport, Sioux Falls, SD, South Dakota Art Museum, Brookings, SD, Southwest Minnnesota State University Museum, Marshall, MN, Tacoma Art Museum, Tacoma, WA, University of New Mexico Museum of Art, Albuquerque, NM, Utah Museum of Fine Arts, Salt Lake City, UT, Washington Pavilion, Sioux Falls, SD.']"	['<urn:uuid:5dc08c87-a499-4ad4-b31e-d633916dd518>', '<urn:uuid:79879c71-b902-48bd-9dda-7db479d5cc9f>']	open-ended	with-premise	concise-and-natural	similar-to-document	comparison	novice	2025-05-12T23:47:20.322175	18	92	3040
92	How do online tools compare to Adobe software for resizing?	Online tools are more convenient and often free, but Adobe software (Photoshop and Lightroom) provides better quality results for image resizing. While online tools offer basic resizing functionality through simple web interfaces, Adobe products provide professional-grade tools with features like constrain proportions to prevent distortion and precise pixel control. However, Adobe software requires licenses and installation, unlike readily accessible online options.	['Today, in the world of digital photography, a large part of the job is being able to manage your images online.\nFor professional photographers, it all starts with shooting images at the best resolution possible, downloading them and then editing them.\nIf you would like to properly understand all this, part of the process is to learn about resizing your pictures. Often, you will need a manageable image size to upload to digital platforms which will only accept certain image sizes. Resizing images is also necessary to be able to send via email.\nSo whether it’s a Gif, Jpeg or RAW file, at some point you will need to use a photo resizer.\nSo, how would you go about changing the size of your image?\nIn this article, you will nifty way for resizing your pictures, using a photo resizer to change resolution, file compression and how different image format types.\nResizing Your Pictures Using Paint\nIf you are working on a Windows PC, you probably have Paint which is an image editing programme. Besides being able to crop and convert images into different formats, one of the most effective tools in paint is using the photo resizer which is really easy to use. To do this, follow these simple steps:\n- Right-click on your image and click edit.\n- Open with Paint and then click ‘resize’ which will open a menu.\n- Choose your new dimensions in the image size reducer.\nWhen resizing images to a particular percentage, try and work this out first which will prevent your image from distortion. If you are resizing your pictures in terms of pixels, simply enter the size you want and to prevent distortion, all you have to do is tick the box to that says it will ‘maintain aspect ratio’.\nAlways make sure that you save the file when resizing your pictures.\nUse the Photo Resizer in Adobe’s Photoshop or Lightroom\nIf resizing images without losing quality is important to you, then using Photoshop, Lightroom and Bridge – all of which are Adobe products, is the way to go!\nResizing Images in Photoshop\nResizing your images in Photoshop is pretty easy with these simple steps:\n- Open the image in Photoshop and select the image menu.\n- Next, select, ‘image size’.\n- Type in the width and height of the number of pixels you want your image to be.\n- Check the ‘constrain proportions’ box to prevent image distortion.\n- Click on the file and then ‘Save as’.\nResizing your pictures in Photoshop is so easy and nothing to be afraid of!\nUsing Lightroom’s Image Size Reducer\nUsing Lightroom is one of the easiest methods for resizing images without losing quality, just follow these easy steps:\n- Open your image.\n- Select ‘File’ and then select ‘Export’.\n- In the export tab, you will see destination, filename and format.\n- Use this image size reducer to choose the desired size of your image.\n- Like with Paint, type in both height and width.\n- Use 72 pixels per inch (PPI) as a rule of thumb for digital images.\nUsing an Online Photo Resizer\nIf you don’t have licenced software like Adobe’s photo editing software on your computer you could always use a free, online image size reducer. To find them, simply use Google and enter keywords like ‘photo resizer’ or ‘tools for resizing image’ – you are bound to get a good result.\nThese steps are very similar to what you would find in the programmes already mentioned here. Simply select the number of pixels you want by height and width, choose a format (Jpeg, PDF, Tiff etc) and click OK.\nDon’t forget to always choose a file destination when resizing images so that you can easily find it again!\nReducing the File Size\nDon’t let this confuse you, because, in a way, it’s really the same thing! By resizing your pictures with a photo resizer, you are automatically reducing your file size. However, it is also possible to convert your image into a specific file size too, if that is what you want!\nUsing photo resizer software will allow you to adjust the file size without changing the dimensions. So while dimensions are critical, there are also ways to convert the file size. However, if resizing images without losing quality is important to you, then this should not be your chosen method because reducing the file size could sacrifice quality.\nRegardless of the programme, you are using, whether that is Lightroom, Paint, Photoshop or Gimp, you can adjust the quality of your image through the image menu. In order to decrease quality, simply reduce the percentage quality, and as always, don’t forget to save your changes.\nDon’t forget that reducing quality is the price you will pay for creating a smaller file size. Alternatively, there is another way to reduce a file size without affecting the quality or dimensions of your image – compression!\nTake note that different file formats also affect the size of the file. For instance, Jpegs are not the same size bitmaps or png images.\nAnother example would be to compare a PDF file to a Word document. The PDF is much larger than a word document! Note that when it comes to PDF’s, it is quite easy to find a free online converter, but rare to find a compressor.\nCompress Files to Reduce File Size\nCompressing images is a sure way to maintain the overall image quality of an image, without reducing the dimensions. Whether you are resizing it or not, you can adjust the file by simply compressing it.\nCompressing Images on a Mac\nApple products are really ideal for compressing images, here are a few simple steps:\n- Right-click on the image or folder in question\n- Click “compress\n- You will see the new compressed file, or folder appear next to the original\nThe compressed folder will have the image in the same resolution and dimensions and not be compromised by any loss of quality.\nCompressing Images in Windows\nCompressing images in Windows is not too different from a Mac. To compress a file in Microsoft Office, simply select the image you want to work on, go to ‘Image Format Tools’ and then ‘compress images.’\nNext, follow these easy steps:\nAnd if you are looking to save on disk space or convert a PDF document to Word, there are further compression tools available that you can download.\nCompressing Files Online\nWhen it comes to the easiest, fastest and most convenient way to compress a photograph, it is definitely online. Simply search ‘image compression’ and you will be amazed at the results.\nRemember that when you compress an image, the main idea is to lose absolutely no data. Generally, image compression is quite simple, all you have to do is upload your photographs, choose the compression level, confirm the action and you’re all set.\nOnce that has happened the website you have used will give you a compressed folder or file, which is easily downloadable to your computer.\nThe two main advantages to having compressed images is that you can send them in an email and also have them take up less space on your hard disk! While each technique has its own pros and cons, it is a very simple way to make sure that your photos have the same dimensions and quality.\nWhy not try a few until you find one that works for you?\nFinally, if you are a digital photographer, then it is safe to say that these days you are also an online picture editor! If you are working with RAW, png or video files, there are many things you can do to make your archiving and editing more manageable.\nYou could ask around, search the internet or you could find a private photography tutor who is specialised in post-production. On websites like Superprof, there are hundreds of private photography tutors located all over South Africa. You could search by location and have someone teach you in your own home, at your time and pace, or you could even opt for online lessons which are equally effective.\nIt doesn’t matter how amazing your photography is, if you don’t have the necessary post-production skills for downloading, archiving, editing and correcting your images, you are only halfway qualified!\nIt all depends on how serious you are about your photography, but if you are going to be taking a lot of pictures, or want to go somewhere with your photography, consider investing in good photo editing software like Photoshop or Lightroom. But remember, professional tools like these are only as good as the knowledge you have to operate them.\nOnce you invest in learning as much as you can about post-production as possible, you will be astounded at the rewards that come with it. Not only will your images look polished and professional, but you will have a system and like anything you want to take seriously in life, systems are necessary. Good luck!\nConsider reading our other related articles below:\nThe platform that connects private tutors and students', 'How to Resize and Make Images Larger without Losing Quality\nHave you ever tried resizing a image to make it larger? This usually results in loss of quality where the enlarged image looks blurry and unprofessional. Recently one of our users asked us if it was possible to resize a small image and make it larger without losing quality. In this article, we will show you how to resize images to make them larger without losing quality.\nWhy Images Lose Quality When Enlarged?\nBitmap is the most commonly used image format on the web. All your JPEG and PNG files are Bitmap image files. A bitmap image is made up of thousands of pixels. If you zoom in you can actually see those pixels as squares.\nEach of these pixels is mapped to a fixed location on the image, hence the name Bitmap.\nMost image editing software shrink or enlarge these pixels to resize an image. This is why when you resize an image to a smaller size there is no visible quality loss. Mainly because those pixels become even less visible.\nOn the other hand when you resize an image to make it large, these enlarged pixels become more visible which makes the image look blurry and pixelated. Like this:\nWhat’s The Solution?\nThe solution is to compensate for each enlarged pixel, so that it matches the properties of its nearest pixel. This method is called Fractal Interpolation or simply Fractals. It produces a much better result when an image is enlarged using this technique.\nHere is how to use this method in most common image editing software.\nMethod 1: Using Perfect Resize with Adobe Photoshop\nPerfect Resize is a software that allows you to resize your images smartly. It is available as a standalone software as well as a plugin for Adobe Photoshop.\nThe regular version costs $50 and the premium version which contains plugin for Adobe photoshop costs $150. Both versions are also available for a free 30 day trial. If you resize images on a regular basis, then we recommend you to go for Perfect Resize. It is expensive, but it is the best way to enlarge images.\nNote: we are not affiliated with Perfect Resize in any way. We’re just really happy users of the product.\nAfter installing the software, open the image file you want to resize in Photoshop. Simply go to File » Automate and select Perfect Resize.\nThis will open the image in Perfect Size application. You can choose a preset from the left hand menu or enter your own size in Document Size.\nAfter entering the document size, you need to go to File » Apply to save your changes and apply them to the file in Photoshop.\nNow you can export this file by saving it as a web image.\nThat’s all, your resized image will look much better now than the normal resize.\nMethod 2: Using Free Software Gimp\nGimp is a free alternative to Adobe Photoshop. It can also be used to enlarge images with minimum quality loss. However, we should warn you that the result will not be as good as Perfect Resize.\nHere is how to make small images larger in Gimp without losing quality.\nOpen the image you want to resize in Gimp. Simply go to Image » Scale Image. Enter your desired dimensions. Under the Quality section choose Sinc (Lanczos3) as Interpolation method and click on the Scale Image button.\nThat’s all, you can now export this image for the web. Here is an example for you to compare. The image on the left was resized using bicubic resampling in Photoshop. Image on the right was resized using Sinc (Lanczos3) as interpolation method. You will notice that there is very little difference in both images.\nMethod 3: Enlarge Images Using Irfanview\nIrfanview is a compact photo editing program. It is only available for Windows based operating systems. Irfanview provides a smarter way to resize images and make them larger.\nSimply open your image in Irfanview and go to Image » Resize/Resample.\nThis will bring up image resize popup window. First you need to enter your desired image size in the Set Image Size. After that you need to select resmaple under the Size method. From the filter drop down menu choose Lanczos (slowest). Lastly, check the box next to ‘Apply Sharpen After Resample’.\nIrfanview will now resize the image, which you can then save to your computer.\nAs you would notice that free tools don’t do a very good job when resizing an image to make it larger. However, by adjusting sharpness and image contrast you can enlarge images and minimize the quality loss in the process.']	['<urn:uuid:2c31bb96-c7b5-434e-acad-2dd6e4644087>', '<urn:uuid:3f96bbb8-96a8-4fc2-ae74-4476ae0da696>']	open-ended	direct	concise-and-natural	similar-to-document	comparison	novice	2025-05-12T23:47:20.322175	10	61	2301
93	What makes the Portuguese Francesinha sandwich special in terms of its ingredients, and how does its meat content compare to healthier meat alternatives available today?	The Francesinha is a unique Portuguese sandwich that combines multiple meats (sausage, roast meat or ham) topped with melted cheese and a special tomato-based sauce containing beer. What makes it distinctive is the sauce, which varies between establishments but typically includes tomato paste, spices, and alcohol (beer, Port wine, whiskey, or wine). While traditionally made with red meat like beef and pork, which are high in fat and have a less favorable omega-6:3 ratio, it can be adapted for vegetarians using healthier alternatives like smoked tofu, seitan steaks, or sturdy vegetables like eggplant and Portobello mushrooms. For health-conscious individuals, white meat options like chicken or turkey could be substituted, as these have lower fat content while maintaining good protein levels and providing important nutrients like selenium and B vitamins.	['There are few things in the Western diet that go together as well as fat and salt. To push diners ever forward to taste Nirvana one only has to lock down the holy trinity: Meat (or meat substitute), cheese and potatoes.\nPortugal’s Francesinha, which translates as “small Frenchie,” achieves this in spades.\nIt is neither French in origin nor is it small. It’s actually a massive melt of a sandwich with sausage, roast meat or ham in the centre topped with melted cheese and a special tomato sauce – ‘special’ means It’s got beer in it. When served, the heavy sandwich is typically partnered with french fries to help soak up the sauce.\nBut while one could conceivable achieve the same culinary delight by simply pouring spaghetti sauce and Super Bock on a cheeseburger, there’s a little more to the Francesinha than that.\nFrancesinha is a very special dish. Here’s why\nThe Francesinha is a relatively new dish to Portugal. Sources site its invention in the 1950s when immigrants were moving through a post-war Europe to find work. One immigrant, Daniel da Silva had travelled through France and was so taken with that country’s traditional croque monsieur (grilled ham and cheese), that he created an elaborate Portuguese version.\nDa Silva debuted the sandwich at the Ria do Bonjardim restaurant in Porto and soon it spread throughout the country. Each new adaptation of the recipe saw a variation on the sauce preparation and ingredients as well as what kind of meat goes inside.\nThe franchesinha Sauce\nWhat makes a Francesinha special from one eating establishment to the next is the sauce. Every restaurant that serves the specialty will use their own “house ingredient.” What that is can be anything from pepper sauce to soy to saffron.\nTomato paste along with the usual onion, garlic, salt and pepper spices makes the base of the sauce. But from there you can add bay leaves, parsley, Worcestershire sauce, hot chilli, etc. (you see how creative this dish can be.)\nOne thing consistent through most sauce recipes is alcohol. Beer is mandatory for authentic Francesinha but from there it can expand to include Port wine (makes sense eh?), whiskey, white wine or red wine. (Don’t worry we’ll post the full recipe below).\nThe meat at the centre of the sandwich is usually sliced ham, to pork belly to beef. Sausage is often used, with linguine being a favourite choice. For vegetarians, these meats can be substituted with beefy seitan steaks, smoked tofu, non-meat ham or meat-substitute sausage.\nAlso, heavy vegetables like eggplant and Portobello mushrooms work well too. Any of these ingredients are typically skillet cooked to seal in flavour and to help them maintain their firmness before they go swimming in that amazing Fancesinha sauce.\nBut before you embark on a cooking adventure, why not have someone make it for you who actually knows what they are doing. We took a tour around the birthplace of the Francesinho, Porto, and found the following restaurants to offer excellent dishes. For those of you venturing further south to Lisbon, we’ve listed restaurants there as well.\nWhere to find the best Francesinhas in Porto\nRestaurante Capa Negra II\nCapa Negra ll is a low-key establishment that prides itself on thirty years of experience crafting the perfect Francesinhas. Their version of the Porto tradition is made of steak, sausage and ham with a special house sausage thrown in the mix.\nThe sauce is special, and of course, secret. Prices are low and you can either call to make reservations or use their charming “retro” website (2009).\nRua Campo Alegre, 191 4150-177 Porto\nTelephone: +351 226078380\nAfonso Restaurant carries on the tradition of the late Café Luso and follows the recipe to a “T.” The late Anthony Bourdain chose Afonso Restaurant to show the world what a Francesinha is and how it should be eaten. “Good lord look at that thing,” Bourdain quipped. “Meat, cheese and fat. It’s the immortal combination.” https://www.youtube.com/watch?v=Yv2ldNVsj94\nRua da Torrinha, 219 Porto, Portugal 4050-612\nTelephone: +351 22 200 0395\nFrancesinha o mercadinho\nIf the restaurant is named after the dish you are searching for, chances are you’ve come to the right place. Francesinhas o Mercadinho boasts a cozy atmosphere and a house tradition of using twice the amount of cheese as other versions of this Porto classic.\nRua do Campo Alegre 1577 Loja 18, Porto 4150-182, Portugal\nTelephone: +351 22 610 9006\nLado B Cafe\nTo find a Vegetarian Francesinha check out Lado B Cafe. They are centrally located near the concert hall and offer dining in a casual, stylish atmosphere.\nThey pride themselves on making a Francesinha with meat substitute that is so good, no one can tell that it’s not meat. The sandwich would be totally vegan were it not for the cheese.\nRua de Passos Manuel 190 192 Frente ao Coliseu do Porto, Porto 4000-382, Portugal\nTelephone +351 22 201 4269\nFinding Francesinhas further to the south in Lisbon\nWith the popularity of this dish it’s hard to imagine that it would remain solely in the Porto area. True, it has drifted down to Lisbon and now that city holds several top-notch establishments serving Porto’s pride and joy.\nAt Dom Tacho you can enjoy two Portuguese traditions, watching the footy match on the television and tucking into a Francesinha. The staff have a reputation for being quite nice, but then that’s the way of Portugal isn’t it? And, although it’s a small restaurant they will always make room for your friends to sit down and join in.\nRua David de Sousa 19 A 1000-105 Lisbon, Portugal\nTelephone +351 21 603 6166\nGreat service coupled with a family francesinha recipe set the bar in Lisbon at the Lucimar. It’s a neighbourhood restaurant and off the tourist beaten path. Many visitors love the restaurant’s atmosphere and warm vibe.\nR. Francisco Tomás da Costa, 28 1600-093 Lisbon, Portugal\nTelephone +351 21 797 4689\nFor the best vegetarian Francesinha in Lisbon check out Restaurant Marco. This place taps the cosmopolitan and elegant vibe of Lisbon and they pride themselves on the best “Porto Style” francesinha.\nSeveral diners boasted about how much they love the veggie version of this classic.\nLargo de Santos 14 D, Lisbon 1200-808, Portugal\nTelephone +351 21 395 0966\nThe Francesinha recipe – here’s how to make it\nNow say you can’t make the trek to Porto or Lisbon but still want to taste this glorious tradition. While there are thousands of different riffs on this recipe, we’ve narrowed it down to a few key basics. From this foundation, you can customise your recipe to suit your taste.\nIngredients for sandwiches to serve two people:\n* Note: meat listed below can be substituted with vegetarian options and sturdy vegetables like eggplant and portobello mushrooms\n4 sausages (smoked, spicy, whatever you prefer)\n2 rump steaks\n4 slices bread (thick sliced white works best)\n10 slices flamengo cheese anything from cheddar to flamengo\n4 slices ham\nSalt and pepper\nFor the sauce:\n4 cloves of garlic\nHalf stick of butter\n2 Tbs olive oil\n2 bay leaves\n4 slices of bacon (or use extra olive oil if going veggie)\n½ cup tomato sauce\n1 cup meat, chicken or vegetable stock\n1 pint of beer of your choosing\n¼ cup port\n⅔ cup white wine\n¼ cup whiskey\nSalt and pepper\n¼ cup all-purpose flour\nIt’s kind of like preparing spaghetti sauce, so go ahead and get going on this part first as the sandwich ingredients (meat and bread) won’t take as long.\nChop and sauté the onions and garlic along with the bay leaves, bacon, olive oil, butter, salt and pepper. Once lightly browned, add the tomato sauce and bring to a boil.\nReduce boil and add the stock and alcohol and simmer for half an hour. You will stir in the flour to thicken everything 5 minutes before serving. Use a mixer/blender on the sauce just before serving.\nToast the bread. Cut the sausages lengthwise and season any meats as necessary. Then skillet cook all the meats (not too well-done, but cooked through). Build your sandwich with the meats (or veggie versions) in the middle and place the cheese on top. Pour on the Francesinha sauce and top with fried egg if you’d like.', 'Meat Guide: Health Benefits, Concerns and Profile of Different Meat Cuts\n“There are a lot of reasons to eat meat, but there are more reasons not to eat meat.”\nPork: One of the most popular meat types is pork. It’s cheap in comparison to other meat and quite versatile when it comes to it’s uses. It can be cooked in a million different ways and it can be used to make ham, bacon, jamon, prosciutto, salami, sausages and hot dogs. As far as it’s nutritional value, it is a good source of protein, B1 vitamin, selenium and zinc. However, it contains high amounts of fat, and a high omega 6:3 ratio, which doesn’t make it a top choice.\nBeef: There are many different cuts of beef, with different fat content. It has higher nutritional value than pork (better omega 6:3 ratio, similar protein content, high iron content). However, it is more expensive in comparison to pork.\nChicken: Chicken makes the top 3 in the list of the most popular meat. It is classified as poultry, while the previous 2 are defined as red meat. It has a much lower fat content, similar protein and decent vitamin content. It is also a very good source of gelatin when making soups and broth with chicken bones. It is quite versatile when it come to it’s culinary use, as it can be cooked in any way you can imagine or it can be used to make burgers or ham. It is quite cheap to buy and provides a decent source of necessary vitamins and minerals, particularly selenium, potassium, phosphorus and B vitamins.\nLamb and Mutton: They are quite similar kinds of meat, lamb is from sheep less than a year old and mutton is from adult sheep. Lamb chops is the most popular cut but there are many more. They graze on pasture thus they have a very low omega 6:3 ratio when compared to other meat. It is quite expensive to buy and not so easy to find in some places. Lamb contains high amounts of Zinc, Selenium and B Vitamins.\nTurkey: Turkey is another type of white meat such as chicken. Roasted turkey is probably the most popular form of cooking it and appears mainly during Christmas. It’s nutrition profile is quite similar to that of chicken.\nVenison: The meat that come from deer. It is possibly the most nutrient-dense form of meat but also very expensive. It is considered read meat such as beef and pork but it’s low-fat content makes it’s nutrition profile similar to chicken but packed with more vitamins and minerals than most meat. It has and excellent omega 6:3 ratio because deer mostly live in the wild.\nBison: Very lean form of red meat. As most wild meat, bison has a low omega 6:3 ratio, unless it is grain-fed. Low calorie choice, high nutritional value.\nRabbit: Very nutrient-dense, low calorie form of meat. It is mainly found in Europe but also in the US and China. It’s got one the best omega 6:3 ratios. Not as high protein content.\nDuck: Mainly used in Chinese gastronomy, duck has a similar nutritional profile with lower fat. However, it is mostly served with high fat and sodium sauces in the Asian cuisine.\nOther things to consider:\nGrain-fed vs Grass-fed:\nThe nutritional value of meat is not only impacted by the type of cut. The same cut can have a quite better omega 6:3 ratio when the animal is grown outdoor and is grass-fed. A human diet should have a ratio as close to 1:1 of omega 6:3, however nowadays it can go up to 25:1. Thus, the type of meat we consume should be carefully selected.\nAnimal welfare can have a significant impact on the nutrition profile of meat and should be taken in account for ethical reason as well.\nThe environmental impact of meat production:\nLivestock is one of the most harmful activities for the environment nowadays. Animals release high amounts of substances like methane that pollute the atmosphere, and excessive manure that contains antibiotics, bacteria, pesticides, and heavy metals. When manure is decomposed it releases more methane, ammonia and carbon dioxide into the atmosphere which further contributes to climate change.\nForests like the Amazon that are extremely important for our planet’s wellbeing are being destroyed and millions of acres replaced with monoculture crop fields dedicated to feeding livestock. Converting natural habitats to agricultural fields releases carbon pollution, contributing to climate change. Fertilizers are used to treat the crop fields in much higher amounts that the plants can absorb, thus polluting the waterways.\n1. Sustainable Feed Sourcing\na. Raise all meat on feed from suppliers verifiably implementing practices to prevent agricultural run-off pollution, soil erosion, and native ecosystem clearance across their supply chain.\nb. Enrollment in nutrient optimization plan to prevent excess fertilizer application\nc. Implementation of cover crops and conservation tillage to protect soil health and reduce run-off\nd. Policy against clearing native ecosystems\ne. Incorporation and support of diverse crop rotation to improve soil health\n2. Responsible Manure Management\na. Provide centralized processing facilities to process manure generated\nb. Policy against placement of new or expansion of CAFOs in watersheds already classified as “impaired” from nutrient pollution\n3. Greenhouse Gas Emissions Reductions\na. Time-bound goals to reduce emissions across supply chain\nb. Require meat suppliers to reduce emissions from direct and contract suppliers as well as feed production\nOriginally published at https://www.nutritionjourneys.com on November 26, 2022.']	['<urn:uuid:d118872a-b5c1-4216-8369-c605a8c995b5>', '<urn:uuid:522663c0-3085-4385-ac57-aa6a0ccb6477>']	open-ended	direct	verbose-and-natural	distant-from-document	multi-aspect	novice	2025-05-12T23:47:20.322175	25	129	2291
94	Can you compare how Boyle's law applies differently in a laboratory setting with constant temperature versus in transportation applications like vehicle tires?	In a laboratory setting, Boyle's law demonstrates that at constant temperature, gas pressure increases as volume decreases, as shown by Boyle's original experiment with the J-shaped glass tube and mercury. In transportation applications like vehicle tires, the same principle applies but with practical implications - the gas in tires is compressed into a smaller volume to increase pressure, making this a real-world application of the inverse relationship between pressure and volume while maintaining constant temperature.	"['There are 3 experimental gas laws used to describe the way in which gases behave. If these laws are combined with Avogadro’s principle the ideal gas equation is formed. This is an example of an energy balance equation.\nSome conditions will need to be known such as standard ambient temperature and pressure.\nIf 2 gases are mixed together Dalton’s law can be used to calculate the pressure of each of the gases.\n- What are the 3 experimental gas laws?\n- What is Avogadro’s principle?\n- State the ideal gas equation?\n- What are the values for the standard ambient temperature and pressure?\n- What is Dalton’s Law and how can it be used to calculate the partial pressure of a gas in a mixture?\nBoyle\'s law states for a fixed mass of gas at constant temperature, the pressure is inversely proportional to the volume.\nCharles law states for a fixed mass of gas at contstant pressure, the volume is directly proportional to the temperature.\nPressure law states for a fixed mass of gas at constant volume, the pressure is direstly proportional to the temperature.\nAvogadro\'s principle states that the volume of a gas is proportional to the number of moles at a constant temperature and pressure.\nStandard ambient temperature and pressure is 298.15K and 100kPa.\nDalton\'s law states for a mixture of gases the total pressure is directly proportional to the sum of the partial pressures exterted by each gas.\nKinetic Theory of Gases\nGas molecules in a container are always moving. Therefore they have kinetic energy. This is related using the kinetic theory equation and uses the root mean square speed of the gas molecules.\nHowever using this equation requires some assumptions to be made.\nThe distribution of speeds and energies is related using the Maxwell-Boltzmann Distribution.\nKinetic theory can be proved using effusion.\n- State the kinetic theory equation?\n- What is the root mean square speed?\n- State the 3 assumptions for kinetic theory?\n- Draw the Maxwell-Boltzmann Distribution Curve and what is shown by the integral of the curve?\nThe root mean square speed is statistical value based on the idea that gas molecules have a continous range of speeds. The root mean square speed takes an average of these speeds.\nThere are 3 main assumptions for kinetic theory:\n- Gas molecules move in a random, ceaseless, constant motion.\n- They undergo no interactions, except brief elastic collisions.\n- The size of the particle is negligible when compared to the distance over which it moves between collisions.\nThe Maxwell-Boltzmann distribution shows the relation between the energy of a molecule and the number of molecules with that energy in a container. The integral of the curve therefore gives the total number of molecules.\nIntermolecular Forces and the Joule-Thompson Effec\nIn reality intermolecular forces act in between molecules of gases. This would change the pressure and volume of a gas. This can be shown using the Van der Waals equation. Changes to the pressure and volume are denoted by the letters “a” and “b” respectively.\nWhen a gas liquidises the Joule-Thompson effect occurs. This states that the energy needed to oppose attractive forces in between molecules is taken away from the kinetic energy. As a result different types of forces can cause different things to happen when a gas expands.\n- State the Van der Waals equation and what do the constants “a” and “b” mean?\n- When a gas liquefies, if attractive forces dominate does the gas cool or heat on expansion?\n- When a gas liquefies, if repulsive forces dominate does the gas cool or heat on expansion?\nIn the Van der Waals equation ""a"" takes into account the attractive interactions in between the molecules and ""b"" is a measure of the size of the gas molecules.\nWhen a gas liquefies...\n- If attractive force dominate, the gas cools on expansion.\n- If repulsive forces dominate, the gas heats on expansion.\nTypes of Systems, Boundaries and Work, Energy and\nThere are 3 types of system. These are open, closed and isolated.\nWork, energy and heat are all related.\nThere are 2 types of boundaries - Diathermic and Adiabatic. The temperature changes in different ways changes depending on what reaction is happening.\n- What is an open, closed and isolated system?\n- When is work done?\n- What is energy?\n- What is heat and what is it caused by?\n- What is a diathermic boundary and what temperature changes occur when exothermic and endothermic reactions take place in this system?\n- What is an adiabatic boundary and what temperature changes occur when an exothermic reaction takes place in this system?\n- An open system can exchange energy and matter with its surroundings.\n- An closed system can exchange energy but not matter with its surroundings.\n- An isolated system cannot exchange energy or matter with its surrounding.\nWork is done when an object is moved against an opposing force. If the force isn\'t opposing but helps the object move, the energy of the system decreases.\nEnergy is the capacity to do work.\nHeat is a form of energy which is caused by molecular vibrations.\nDiathermic boundaries allow the transfer of heat energy.\n- Exothermic reactions-------temperature remains the same.\n- Endothermic reactions-------temperature remains the same.\nAdiabatic boundaries don\'t allow the transfer of heat energy.\n- Exothermic reactions-------temperature increases.\nHeat Transfer, Zeroth\'s Law, Internal Energy, 1st\nHeat can be transferred between 2 objects. If they are not at the same temperature heat energy will be transferred between the 2 objects until they are at thermal equilibrium.\nZeroth\'s can be used to relate the temperature/thermal equilibrium between 3 objects- A, B and C.\nThe first law of thermodynamics can be used to describe the internal energy of a system.\nInternal energy for a system can change.\n- State Zeroth’s Law.\n- What is meant by the term internal energy and what type of function is it, what does this mean?\n- State the 1st law of thermodynamics.\n- Most changes in internal energy are small. Write 2 equations the difference between small and large changes in internal energy of a system?\nZeroth\'s law states that if object A is in thermal equilibrium with B and object B is in thermal equilibrium with C, then object A is in thermal equilibrium with C.\nThe internal energy of a system is the total energy a system has. It is a state function which means it doesn\'t matter which route is taken from the start to the end point, the change in internal energy is still the same.\nThe first law of thermodynamics states that the internal energy of a system remains constant and can be increased by doing work on the system or by heating it.\nThis can also be re-written as the work needed to change an adiabatic system from one state to another remains the same.\nExpanding Gases and Heat Transactions\nWhen a gas expands work is done by the gas and its internal energy decreases.\nGases can expand in different conditions.\n- Free expansion – No opposing force, therefore no work is done.\n- Expansion at constant pressure.\n- Reversible expansion results in small changes in internal energy. Therefore there is no motion.\n- Isothermal reversible expansions.\n- Write an equation for work done?\n- How is this equation related to the work done by an expanding gas? (Show using an integral)\n- What is the work done by an expanding gas at constant pressure?\n- What is the work done by a gas expanding isothermally and reversibly?\n- If the work done by a gas is zero what can be said about the internal energy and the heat energy?\nEquation for Work Done\nIntergral for Work Done by an Expanding Gas\nWork done by an expanding gas at constant pressure\nWork done by a gas expanding isothermally and reversibly\nIf the work done is zero the internal energy is equal to the heat energy.\nHeat Capacities and Enthalpies\nHeat capacity is the change in internal energy with temperature at a constant volume. The molar heat capacity is the heat capacity per mole of a substance. It is different for different types of gases\nFor a solid/liquid to gas reaction the change in volume is very large. This can change the equation defining enthalpy. The enthalpy of a system increases as a system heats up. This can be related using the heat capacity at constant pressure. For larger changes in temperature the heat capacity at constant pressure changes.\n- What is the definition of heat capacity? Is it an extensive or intensive property?\n- Are molar heat capacity values extensive or intensive properties?\n- What is the molar heat capacity for monoatomic gases?\n- What is the molar heat capacity for diatomic and linear triatomic gases?\n- What is the definition of enthalpy?\n- Write an integral defining the change in enthalpy as a system is heated up.\n- How does the heat capacity at constant pressure vary at high temperature?\n- Write equations showing the heat change at constant volume and at constant pressure.\nHeat capacity is the change in internal energy with temperature at a constant volume. It is an extensive property which means it depends on how much of something you have. Molar heat capacities are examples of intensive properties. This value varies for different gases:\n- For monoatomic gases it\'s 3R/2.\n- For diatomic and linear triatomic gases it\'s 5R/2.\nEnthalpy can be defined using an equation.\nEnthalpy increases as a system is heated up. This can be related to the heat capacity at constant pressure using an intergral.\nFor large changes in temperature the heat capacity at constant pressure varies as shown in the equation.\nThe heat energy constant pressure and at constant volume can be calculated as shown below.\nEnthalpy values are different for different reactions. As they are state functions they can be added together.\nHess’s law can be used to calculate the enthalpy change for a reaction at standard conditions.\nSometimes reactions don’t happen at 298K. This results in a new change in enthalpy value, therefore we need to use Kirchhoff’s Laws. Remember to write chemical equations.\nAre enthalpy changes for endothermic reactions negative or positive?\nAre enthalpy changes for exothermic reactions negative or positive?\nState Hess’s Law.\nState Kirchhoff’s Law and all components.\nEnthalpy changes for exothermic reactions are negative and for endothermic reactions they are positive.\nHess\'s law states that the standard enthalpy change of an overall reaction is the sum of the standard enthalpies of the individual reactions into which a reaction may be divided into.\nKirchhoff\'s laws can be used to calculate enthalpy changes at different temperatures.\nSome More Equations?????', '⚠️ Report an Issue\nBoyle\'s Law Calculator\nBoyle’s law explains the behavior of gases. It gives us the relationship that exists among the physical forces such as volume, pressure, and temperature.\nThis law is introduced in 1662 by Robert Boyle, an Anglo-Irish physicist, and chemist. Hence, it is named after him. This law is also called as Mariotte\'s law or Boyle–Mariotte law.\nBoyle’s law defines the relationship between the pressure of a gas and the volume of the container it is stored in.\nBoyle’s is defined as, ""within a closed system when temperature and quantity of gas stored are constant, a given mass of ideal gas exerts a pressure that is inversely proportional to the volume that the gas occupies.""\nThis law can be mathematically represented as:\nWhere K is a constant,\nP is the pressure of the gas,\nV is the volume of the container,\nP1 and V1 are the initial pressure and volume of the gas,\nP2 and V2 are the final pressure and volume of the gas.\nStating it in simple terms:Boyle’s law states that at a constant temperature, the pressure of a gas increases as the volume of the container it is stored in decreases.\nWhen a gas is heated, the volume of the gas increases; when the volume of the gas is decreased or compressed, its temperature increases; the temperature of the gas decreases when it is allowed to expand.\nDiscoveryBoyle was trying some experiments on the properties of vacuum and air, using a vacuum pump. It was during these experiments when he was using a J-shaped glass tube which had little air at its tip. When he tried to alter the weight of air using mercury, he noticed that the air space which was at the tip of the glass tube curve became smaller. Thus, deepening this observation. Finally, he discovered that when pressure on a gas increases, the volume of the gas shrinks.\nIn modern day to day life, there are many applications where we use Boyle’s law in a variety of fields:\n- Transportation – Boyles law is used in the operation of steam engines, diesel engines, vehicle tires.\n- Medicine – The basic need, the syringe, uses the principle of Boyles law.\n- Cosmetics – In aerosols such as a perfume bottle or a deodorant spray where gas is stored under high pressures.\n- Food Industry – In storage of aerated drinks such as soda in cans.\nFun Facts about Boyle’s law\nDo you know!!! There are plenty of examples of Boyle’s law in the things that we do daily.\nFor example, breathing! Yes, the way we breathe or take the air into our lungs is a clear picture of Boyle’s law. Want to know how?\n- When we breathe in air, we are drawing the air into lungs and contracting the respiratory muscle and thus increasing the volume of the chest which again decreases the pressure in our chest.\n- Similarly, when we breathe out, that is during exhalation, the respiratory muscles contract and decreasing the size of our chest. Thus reducing the volume of the lungs and increasing the pressure inside them. When we say that pressure inside the lungs is high, it is even higher than outside atmospheric pressure and thus we can move the air out from our lungs using exhalation.\nAnother example where we are applying Boyle’s law is in “Scuba Diving”. The techniques which scuba divers use to ascend descend and breathe under waters holds as good examples of applications of Boyle’s law.\n- Ascent: When a diver ascends, he will have to release the excess of air from his buoyancy control device (BCD). This is because, during the process of ascend, the pressure of water surrounding him decreases, and the air in his BCD expands. If he does not release excess air from BCD, he will lose control over his buoyancy because of the air expansion.\n- Descent: Inversely when a diver descends, the pressure of water surrounding him increases, and the air in his ears gets compressed. He will have to equalize thus created pressure in his ears to avoid ear pain which can lead to an ear injury called ear barotrauma.\nBesides, the above the rules to have safe diving are derived from Boyle’s law calculations. Some of them are hereunder:\n- Breath should not be held underwater – In scuba, when a diver holds his breath underwater during ascending to an area having lesser water pressure, his lungs will expand trapping the air according to Boyle\'s Law. This phenomenon can lead to an injury to the diver\'s lungs causing pulmonary barotrauma.\n- Ascend Slowly – During Scuba, diver\'s body underwater tends to absorb nitrogen gas in compressed form. When he ascends to a depth which has lesser water pressure, nitrogen gas absorbed by him expands. Hence a diver has to ascend slow enough so that his body gets time to eliminate the expanding nitrogen gas. If not, it leads to the formation of tiny bubbles in his tissues and blood and causes decompression sickness.\nThus the discovery of Boyle’s law leads a path to great inventions which are now intertwined to the survival of human life.\nHow to use CalculatorHut’s Boyle’s Law calculator?\nBoyle’s law is widely used in many physics calculations. As the numerical value of pressure and volume most times contains decimal values or may be in different units, CalculatorHut’s Boyle’s law calculator becomes very handy for you!\nAll that you need to do is enter the values of known variables in the right hand and left-hand side of Boyle’s law equation. On clicking ‘Calculate’, CalculatorHut’s Boyle’s law calculator gives you instantaneous results. It’s super cool and easy.\nIf you are looking for one stop solution for online calculators for free, CalcualtorHut is your ultimate resource! Besides, you can always carry CalculatorHut wide range of calculators in your hand. All that you need to do is download the CalculatorHut app and experience its diversified range of easy to use handy calculators ranging from math calculators, scientific calculators, vehicle calculators, health calculators, and other calculators. Happy calculating!!!!']"	['<urn:uuid:9dfc5e43-88cd-4327-8a84-e77efecee437>', '<urn:uuid:2fb968d4-620b-4079-a05b-58dd35e740e8>']	factoid	direct	verbose-and-natural	similar-to-document	comparison	expert	2025-05-12T23:47:20.322175	22	75	2802
95	maneuver shorad system development timeline cost contract details general dynamics	The M-SHORAD system was developed in record time, taking just 19 months from requirement generation in February 2018 to first platform delivery for testing. This rapid development was in response to a 2016 urgent call from U.S. Army Europe. General Dynamics Land Systems, as the lead integrator, received a $1.2 billion contract to build and deliver the system in October 2020.	['WASHINGTON — The primary platoon of the U.S. Military’s Maneuver-Quick-Vary Air Protection System arrived in Europe 5 months in the past, and the primary unit to obtain the Stryker-based programs have now put them by means of their paces forward of live-fire occasions and greater workout routines down the highway, Lt. Col. Abraham Osborn, the top of fifth Battalion, 4th Air Protection Artillery Regiment, instructed Protection Information in an Oct. 4 assertion.\nThe M-SHORAD is a Stryker A1 fight vehicle-based system that features a mission tools package deal designed by Leonardo DRS. That package deal consists of Raytheon’s Stinger car missile launcher.\nBasic Dynamics Land Programs is the lead integrator and obtained a $1.2 billion contract to construct and ship the system in October 2020.\nThe system was quickly developed in file time. The service obtained the requirement to construct the system in February 2018. It took simply 19 months from the time the service generated the requirement to the primary supply of a platform for testing, answering an pressing name in 2016 from U.S. Military Europe to fill the short-range air protection functionality hole.\nFor the reason that tools arrived April 19, “we have now targeted totally on driver’s coaching and crew coaching for the platoon,” Osborn mentioned.\nThe Stryker “will increase our maneuverability over various terrain, [but] it requires a better diploma of coaching and communication between the driving force and car commander to function safely,” he added.\nWhereas the M-SHORADs have been unable to take part in a significant train (the programs arrived too late to hitch the annual train Defender Europe in 2021, the biggest army drill on the continent), Osborn anticipates participation in Defender Europe 22.\nArising “this week,” Osborn mentioned on Oct. 4, the unit is conducting a Stinger missile live-fire demonstration in northern Germany.\n“That is the primary ever live-fire of the M-SHORAD system in Europe, nonetheless that is only a demonstration and never a full certification of crews,” Osborn famous.\nThe M-SHORAD will take part in Saber Strike within the second quarter of fiscal 2022 the place it can assist the 2nd Cavalry Regiment.\nThe unit can be within the planning levels of a full platoon gunnery certification with the M-SHORAD within the third quarter of FY22.\nWhereas it’s too early to offer soldier suggestions from the unit utilizing the programs in Europe, in accordance with Osborn, Maj. Gen. Brian Gibson mentioned what he’s listening to is troopers “need them sooner they usually need extra of them.” Gibson is in command of the Military’s air and missile protection modernization efforts.\nThe Military is planning a larger-scale operational take a look at of the M-SHORAD within the third quarter of FY23, Maj. Gen. Robert Rasch, this system government officer for Military missiles and house, instructed Protection Information in a current interview. However earlier than that occurs, the Military should subject the remainder of the battalion within the 2022 timeframe after which give members time to arrange for the operational take a look at, he mentioned.\nThat point would come with growing doctrine, ways, strategies and process in addition to letting the take a look at neighborhood evaluation the system throughout the context of combating and defending the maneuver power, Rasch mentioned. The Military carried out an early operational evaluation final yr, he added.\n“This occasion shall be extra like: Can the unit with this technique do the general mission set, which is to guard the maneuver power and maneuver with the maneuver power that it’s designed to do?” Rasch mentioned. “So we’ll simply take some time to guarantee that we give that unit the time behind the wheel of that system and get the boldness earlier than we go into that take a look at exercise.”\nThe Military will subject 144 programs to 4 battalions starting this yr, adopted by an everlasting functionality for added battalions.\nFuture variants of the system will embody different kinetic interceptors and a directed-energy functionality that won’t solely defend in opposition to unmanned plane programs and manned plane but additionally rockets, artillery and mortars.\nJen Judson is the land warfare reporter for Protection Information. She has coated protection within the Washington space for 10 years. She was beforehand a reporter at Politico and Inside Protection. She gained the Nationwide Press Membership’s greatest analytical reporting award in 2014 and was named the Protection Media Awards’ greatest younger protection journalist in 2018.']	['<urn:uuid:64c64eb8-0547-469c-92c2-c6fe680d5a37>']	open-ended	direct	long-search-query	similar-to-document	single-doc	expert	2025-05-12T23:47:20.322175	10	61	732
96	how chrome web browser runs cloud computer systems costs benefits	Serverless Chrome enables running headless Chrome on cloud services like AWS Lambda, allowing for web-scraping, testing, and pre-rendering tasks. The system takes care of bundling Chrome binaries and ensures Chrome runs during function execution, supporting common operations like taking screenshots and printing PDFs. In terms of costs and benefits, the serverless model means you only pay for the actual milliseconds of usage rather than hours, resulting in significant cost savings. The system also handles all server management, maintenance, and scaling automatically, allowing developers to focus solely on writing code rather than managing infrastructure.	"['Serverless Chrome contains everything you need to get started running headless Chrome on AWS Lambda (possibly Azure and GCP Functions soon).\nThe aim of this project is to provide the scaffolding for using Headless Chrome during a serverless function invocation. Serverless Chrome takes care of building and bundling the Chrome binaries and making sure Chrome is running when your serverless function executes. In addition, this project also provides a few example services for common patterns (e.g. taking a screenshot of a page, printing to PDF, some scraping, etc.)\nWhy? Because it\'s neat. It also opens up interesting possibilities for using the Chrome DevTools Protocol (and tools like Chromeless or Puppeteer) in serverless architectures and doing testing/CI, web-scraping, pre-rendering, etc.\n- Quick Start\n- The Project\n- Documentation & Resources\n- Articles & Tutorials\n- Projects & Companies using serverless-chrome\n- Change log\n- Prior Art\n""Bla bla bla! I just want to start coding!"" No problem:\nUsing AWS Lambda, the quickest way to get started is with the Serverless-framework CLI.\nserverless globally (\nnpm install -g serverless) and then:\nserverless create -u https://github.com/adieuadieu/serverless-chrome/tree/master/examples/serverless-framework/aws\nThen, you must configure your AWS credentials either by defining\nAWS_SECRET_ACCESS_KEY environmental variables, or\nusing an AWS profile. You can read more about this on the\nServerless Credentials Guide.\nIn short, either:\nexport AWS_ACCESS_KEY_ID=<your-key-here> export AWS_SECRET_ACCESS_KEY=<your-secret-key-here>\nThen, to deploy the service and all of its functions:\nnpm run deploy\nFurther details are available in the Serverless Lambda example.\nThis project contains:\n- @serverless-chrome/lambda NPM package\nA standalone module for AWS Lambda which bundles and launches Headless Chrome with support for local development. For use with—but not limited to—tools like Apex, Claudia.js, SAM Local, or Serverless.\n- serverless-plugin-chrome NPM package\nA plugin for Serverless-framework services which takes care of everything for you. You just write the code to drive Chrome.\n- Example functions\n- Serverless-framework AWS Lambda Node.js functions\n- Serverless-framework AWS Lambda Node.js functions using\n- Build Automation &\nBuild and release tooling shell scripts and Dockerfile for automating the build/release of headless Chrome for serverless environments (AWS Lambda).\nA collection of example functions for different providers and frameworks.\n- Print to PDF\n- Capture Screenshot\n- Page-load Request Logger\nDocumentation & Resources\nBuilding Headless Chrome/Chromium\n- Automated, regularly prebuilt binaries can be found on the\n- adieuadieu/headless-chromium-for-aws-lambda Docker image\n- Documentation on building your own binaries\n- Medium article on how to do build from scratch. This was the origin of this project.\nnpm test. Each package also contains it\'s own integration tests\nwhich can be run with\nnpm run test:integration.\nArticles & Tutorials\nA collection of articles and tutorials written by others on using serverless-chrome\n- AWS DevOps Blog — UI Testing at Scale with AWS Lambda\n- Running puppeteer and headless chrome on AWS lambda with Serverless\n- Will it blend? Or how to run Google Chrome in AWS Lambda\n- Running Selenium and Headless Chrome on AWS Lambda\n- AWS Lambda上のheadless chromeをPythonで動かす\n- AWS Lambda上でpuppeteerを動かして、スクレイピングする\n- serverless-chrome で日本語を表示できるようにする\nCan\'t get Selenium / ChromeDriver to workMake sure that the versions of serverless-chrome, chromedriver, and Selenium are compatible. More details in [#133](https://github.com/adieuadieu/serverless-chrome/issues/133#issuecomment-382743975).\n- Support for Google Cloud Functions\n- Example for Apex\n- Example for Claudia.js\n- DOM manipulation and scraping example handler\n- Support for Azure Functions\n- Headless Firefox\nProjects & Companies using serverless-chrome\nTell us about your project on the Wiki!\nSee the CHANGELOG\nOMG. Yes. Plz, halp meeee.\nThis project was inspired in various ways by the following projects:', 'What is serverless computing? The idea is growing in popularity, but the term honestly sounds like an oxymoron. How does it work, and why should you consider it for your IT organization?\nWell, the name is a false promise–there are actually servers involved with serverless computing. They just aren’t managed by the organization. A serverless computing model means your cloud provider takes care of adding, removing, and/or adjusting your server resources based upon demand. You end up with a more accurate bill for your usage because it’s based literally on milliseconds, not hours. There are a couple of ideas behind this: One is to avoid prepaying for resources that might be unused, resulting in huge savings for your organization. The second is taking the burden of server management off of the developer’s hands, leaving them free to simply write code.\nThis sounds like something out of the future, but the truth is, the future is now. The big cloud providers (Amazon, Microsoft and Google) all offer serverless computing services, but Amazon’s Lambda is perhaps the most well-known. According to their website, “Lambda runs your code on high-availability compute infrastructure and performs all the administration of the compute resources, including server and operating system maintenance, capacity provisioning and automatic scaling, code and security patch deployment, and code monitoring and logging. All you need to do is supply the code.” This saves the developer time and effort in rewriting code to fit a specific infrastructure requirement, meaning applications can deploy faster and more accurately.\nServerless building blocks\nThe code that’s uploaded to AWS or Azure is known as a function. A function is an individual action or piece of logic. This tiny code unit is particularly useful for running jobs like these:\n- Scheduled, repeatable tasks\n- Web request processing\n- Processing queue messages\nThe entire function from beginning to end usually takes only milliseconds. It is these functions that form the building blocks of serverless architectures.\nWhere do containers fit in?\nContainers are the latest “hot thing,” but is it possible that serverless computing will render containers obselete? As Michael Churchman of Rancher explains, probably not. “Serverless computing of the type represented by AWS Lambda can be an extremely valuable resource, … but it is far from being an all-around substitute for deploying and managing your own containers. Serverless computing is really designed to work with containers, rather than replacing them.”\nWhat are some cases where containers might be a better fit? If your application is larger and more complex than AWS or Azure can handle, a container-based system can be as large and complex as you need. If you’re also looking for full control over the containers and the system on which they run, container-based deployment can do that. However, because serverless computing is run by a third party, you have no say in how it is run. For security and policy processes, serverless computing may not be a good fit. If you do decide to try your hand at serverless computing, a best practice is to start with new applications, rather than rewriting old ones to fit the model.\nServerless computing is a new developer-friendly offering that holds a lot of potential for cost savings and software deployment efficiency. It is not, however, a replacement for all infrastructure architectures, including containers or on-premise deployment. Again, as with all things IT, whether you use serverless computing or not depends on what your application and organizational needs are. If you want to work in a serverless environment, you will need to prepare for some changes.']"	['<urn:uuid:5f1e0bae-c49a-4390-ac16-1e6f0f77b154>', '<urn:uuid:8e8c4e5f-acef-4f2c-9a91-218de5e81c98>']	open-ended	direct	long-search-query	distant-from-document	multi-aspect	novice	2025-05-12T23:47:20.322175	10	93	1172
97	What are the emerging opportunities for workers in industrial automation, and what safety protocols need to be implemented to protect employees working alongside robots?	Regarding opportunities, automation is creating new roles where humans work alongside robots. For example, subway train drivers have evolved into route optimizers, and miners now control equipment electronically rather than working at the coal face. Companies like Universal Robots are developing 'cobots' that can be programmed by workers with no engineering background in just 87 minutes, giving employees more control over their daily activities. Regarding safety protocols, comprehensive risk assessments are mandatory before robot systems become operational and after any changes to equipment, policies, or procedures. Common hazards include slip, trip, and fall risks, contact with moving parts, dropped components, and potential pinning by robot arms. While OSHA has no specific robot standard, they refer to consensus standards like ANSI/RIA R15.06 for safety requirements. Employers must implement effective safety systems based on all tasks conducted by the robot, including non-routine operations like programming, maintenance, and setup, which is when most accidents occur.	"['More than 90 million workers across Europe (about 40% of the total workforce) will have to develop significant new skills within their current roles in the next ten years, as automation puts 51 million jobs at risk, warns a report released in June by analyst firm McKinsey.\nAnd almost all of today\'s European workers will face some degree of change as their jobs evolve because of technology. But although the statistics seemingly feed into a common fear of robots taking over our jobs, quick conclusions needn\'t be drawn: the research also shows that employment growth in other sectors will largely compensate for overall job loss.\nSo much, in fact, that Europe might find itself short of up to six million workers by 2030. As new opportunities emerge in fields like technology, for example, McKinsey anticipates that finding sufficient workers with the required skills to fill the jobs that are being created on the continent will be challenging.\nThis is especially the case in megacities like London and Paris, where employment opportunities will be concentrated, but with too few residents qualified to fill them. The report found that in such areas of dynamic growth, less than 60% of new jobs will be taken up by a suitable worker.\nIn other words, up-skilling and re-training the workforce will jump to the top of the to-do list for business leaders in the years to come. The trend has only been further accelerated by the COVID-19 crisis: McKinsey\'s report suggests the jobs most at risk from automation are also those that the pandemic has made more vulnerable.\nCustomer service and sales, food services and building occupations are the three groups that are most likely to be displaced both because of automation and, now, because of the health crisis.\nIt will be critical to make sure that these workers are learning the skills that will let them move on to high-growth opportunities. Susan Lund, an author of the McKinsey report, told ZDNet: ""Today, our report shows that job changes in Europe are typically someone going from one declining occupation, like a retail cashier, to another declining one.\n""What is critical is that people in occupations that are declining because of automation look to acquire the sort of skills that are in demand in growing occupations,"" said Lund. ""There are indeed so-called \'adjacencies\' that can help career progression.""\nSo, where can we expect to find those ""growing occupations""? Generally speaking, and in continuation of a long-standing trend, manufacturing and agriculture are losing weight in favor of services. More specifically, McKinsey analysts predict that human health and social work will see the strongest growth, followed by professional, scientific and technical services, as well as education.\nLund argued that this is good news: jobs will be shifting away from dull routine work and towards more interesting problem-solving and interpersonal interactions. In fact, were she to give tips to a 15 year-old today about the most important skills to take up at school and university, she would advise in favor of STEM subjects; but not only.\n""There are also some other key skills that humans can do really well – far better than machines – and which will be the source material for jobs for years to come,"" said Lund. ""In particular, social and emotional skill and higher cognitive skills have a lot of future promise. That means an ability to work well with others, to coach, teach, and manage, but also strong problem-solving skills and critical thinking.""\nDemand for socio-emotional skills will grow by up to a third, said the report, as human workers focus on roles that machines can\'t fulfill, which require interaction, care-giving, teaching and training, as well as managing others.\nIt\'s not only about future workers, though. Many employees are currently working in jobs that will change because of automation: McKinsey\'s analysts predicted that about 22% of workforce activities across the EU could be automated by 2030.\nTo succeed alongside robots in new types of work, employees will need skills that they don\'t currently have. The concept of ""lifelong learning"" will gather pace, therefore, as workers acquire new knowledge throughout their careers. It will be largely up to employers to initiate programs to re-train their staff and ensure success in a more automated workplace.\nEqually, some new opportunities might emerge to enable a smoother transition for workers. Robotics company Universal Robots, for example, is already deploying ""cobots"" (or collaborative robots) to businesses, which are designed to simplify the use of automation for human employees.\nThe company has developed online courses, which it claims enable workers with no engineering background to program a ""cobot"" in only 87 minutes. The method, according to Universal Robots, reverses the idea that automation is taking jobs away from humans, and instead gives tools to employees to better control their day-to-day activities.\nLund, for her part, is confident that the workforce will easily acquire the new skills that it will need – in part, because it already has. ""Work skills have been evolving over the past years for many professions,"" she says. ""With the advent of digital technologies, this has accelerated.""\n""In Europe, subway train drivers have switched to becoming route optimizers, as trains have become automated,"" she continued. ""Miners in many places no longer head to the coal face – machines do the digging – but instead control the equipment electronically. And so on. Humans and robots are increasingly working side by side.""\nRather than taking over our jobs, therefore, it would seem that robots are coming to the workplace as our next-generation co-workers.', '- This editorial is filed under:\n- Automotive Component\n- Consumer Goods/Appliances\n- Life Sciences Pharma Biomed Medical Devices\n- Rubber & Plastics\n- Off-Road/Heavy Equipment\n- Robot Manufacturing\n- Building Products/Materials\n- Fabricated Metals\n- Printing & Publishing\n- Arc Welding\n- Wood Products\nAre You at Risk of OSHA Citations for Robot Safety?\nConversion Technology Posted 03/12/2019\nRobots have been a part of the industrial landscape for decades. As the world of industrial automation progresses, the number of employees and robots working in close quarters with each other continues to grow. With the increase in automation and the use of mobile and industrial robots, regulations are being updated to address the potential hazards posed by the changes in equipment and routine and non-routine tasks around robots in the workplace. The Occupational Safety and Health Administration (OSHA) is training their inspectors to be aware of these regulatory changes and become familiar with industrial robot use. Not being aware of your facility’s requirements or of the changes in robot regulations could cost you.\nRecently, CTI attended the annual International Robotics Safety Conference, hosted by the Robotics Industries Association (RIA). At the conference, we spoke with representatives from OSHA, who explained the plans and actions put in place to train inspectors to better identify the hazards around industrial robots, as well as a plan to work on updating regulations to better protect employees from these identified hazards.\nRobots are machines, and as such must be safeguarded in ways like those presented for any hazardous remotely controlled machine. As with any other machine, there are countless hazards that could be present in and around a robot system. These hazards could vary depending on the design of the robot cell, placement inside the facility, level of interaction with employees, program or software being run, or end effector being used. Some common hazards are slip, trip, and fall inside the cell, contact with moving parts, dropped parts or end effectors, being pinned by the robot arm, etc. These hazards could be magnified while in Teach mode, unless mechanical and engineering safeguards are in place. The most effective way of identifying hazards is by conducting a comprehensive risk assessment before the system is operational, and after all parts, guards, and work practices are in place.\nARE THERE ANY REGULATIONS FOR ROBOTS?\nWhile there is currently no OSHA standard specifically covering industrial robots, there are several consensus standards, that OSHA refers to, covering safeguarding performance criteria, risk assessment methodologies, and general safety requirements. Consensus standards are voluntary standards developed through the cooperation of multiple parties, typically governing agencies and industry groups, who have an interest in participating in the development and/or use of the standards. OSHA commonly refers to consensus standards when there is no specific regulation covering the topic (e.g. NFPA standards on combustible dust). OSHA is very aware that they do not know everything about every subject for every industry. RIA and the American National Standards Institute (ANSI) have put together the current robot safety standards and have partnered with the National Institute for Occupational Safety and Health (NIOSH) to further promote and update regulations on the topics related to robot safety.\nIf OSHA were to arrive at your facility and inspect a robot or robot system, the first thing the inspector would ask for is a copy of the last risk assessment conducted on the system. If a risk assessment has not been conducted on the system, they could push for a willful violation, as the risk assessment is required by law. Despite no standard in 29 CFR 1910 governing industrial robots, violations and citations can and have been issued on robot system. The primary regulations to be cited for violations with a robot system are Lockout/Tagout and the Control of Hazardous Energy (1910.147), Machine Safeguarding (1910.212), and the General Duty Clause (Section 5(a)(1)). OSHA does also regularly contact original equipment manufacturers (OEMs) and robot system integrators to determine the level of safety provided at installation of the equipment as compared to the hazards present at the time of the inspection or injury. As is the way of industrial safety, the employer is the party with the legal responsibility to recognize and mitigate hazards in the workplace.\nHOW DOES OSHA SEE ROBOT SAFETY?\nOSHA’s view on robot safety is that if the employer is meeting the requirements of the consensus standards, specifically ANSI/RIA R15.06 – Safety Requirements for Robots and Robot Systems, then there will not be any issues. However, one of the primary findings from inspections is that, while machine safeguarding and the control of hazardous energy are typically front of mind for employers, comprehensive risk assessments are not being conducted or revised after the installation of new equipment. A risk assessment is required by R15.06 and specified further in ANSI/RIA B11.0 – Safety of Machinery – General Requirements and Risk Assessment. Some facilities have them done by the robot integrators and installers, but fail to conduct them after changes to equipment, policies or procedures, or tooling and layout specifications.\nMany robot accidents and violations do not usually occur during normal operation and practices. These incidents typically occur during non-routine operating conditions (e.g. programming, maintenance, setup, part/tool changes, and while in Teach mode). It is imperative to select an effective safety system for your robots that is based on all jobs and tasks conducted by the robot and within the robot system. This can be done through safety controls, limiting boundaries, safeguards, etc. Through a comprehensive risk assessment all tasks and corresponding hazards can be identified, hazard ratings applied, and corrective actions can be determined and prioritized.\nHOW TO ENSURE COMPLIANCE\nCTI has years of experience conducting both qualitative and quantitative risk assessments on robots and robot systems. CTI is also a member of the R15.06 rule making committee and is in contact with OSHA representative on how the updating of rules and regulations impact employers and industry sectors. Contact CTI for more information on risk assessments and how to ensure your facility’s industrial robots and robot systems are in compliance with all governing standards and regulations.']"	['<urn:uuid:9faf4377-d39f-41ae-b247-383c0e549a07>', '<urn:uuid:19933ddd-652b-4e96-a35c-746807e8197e>']	open-ended	direct	verbose-and-natural	distant-from-document	multi-aspect	expert	2025-05-12T23:47:20.322175	24	152	1939
98	How is a snow squall different from other types of snowstorms in terms of duration and impact?	Snow squalls are shorter in duration than other snowstorms, typically lasting anywhere from 30 to 60 minutes, and usually produce less snow accumulation. However, they are highly dangerous due to the rapid rate of snowfall accumulation, and can produce high winds, severely limited visibility, and even thundersnow.	['During the winter, have you ever experienced a sudden drop in temperatures with gusty winds and white-out conditions? And then an hour later, the conditions are calm? You may have been caught in a very localized, small-scale weather phenomenon called a snow squall! Much like the localized warnings for thunderstorms and tornadoes, the National Weather Service provides warnings for these brief, intense winter storms.\nLet’s take a look at what creates snow squalls, why they are dangerous, and how you can stay safe.\nWhat Is a Snow Squall?\nA snow squall is a fierce snowstorm producing high winds that moves rapidly. Blowing snow severely limits visibility and the localized and speedy onset of squalls makes them difficult to forecast, enhancing their danger. That is why the NWS issues “short-fused” warnings “focused on distinct areas,” much in the way they warn of tornadoes and other severe storms. While a snow squall can occur anywhere that experiences snow, they are most common in the Great Lakes region due to the lake effect on local conditions.\nDifference Between Snow Squalls and Other Snowstorms\nSqualls are shorter in duration and therefore usually produce less snow accumulation than other snowstorms. However, the intensity of squalls makes them highly dangerous due to the rate of snowfall accumulation, as squalls generally last anywhere from 30 to 60 minutes. In addition to strong wind and snow, a snow squall can even produce thundersnow.\nHow Does a Snow Squall Form?\nIn the winter, when cold air suddenly moves over areas with warmer surface temperatures — such as a lake effect snow event — this can create the specific mix of conditions that can initiate a snow squall. However, the isolation of these fronts means that there does not need to be any other active winter storm occurring in the area. A squall’s strong low-level convergence at the cold front can create high-velocity upward motion, which can allow for heavy snowfall, strong winds, and potentially thunder and lightning.\nWhen Does It Occur?\nBecause they’re made when an Arctic cold front interacts with warmer air, snow squalls often happen in early and late winter, when local temperatures are still relatively high. However, warmer days at any point throughout the winter can experience snow squalls, which corresponds to their prevalence near the Great Lakes.\nDangers of Snow Squalls\nDrivers face the most pressing dangers from a snow squall. Given that larger snowstorms can last from hours to days at a time and are often more predictable in advance, drivers have the opportunity to prepare or avoid the roads altogether. Squalls, however, develop and move much more quickly. The gusty winds and intense snow can completely eliminate visibility. Additionally, the rapid accumulation of snow on the roads creates slick surfaces that drivers are less prepared for.\nThe combination of slippery roads and limited visibility creates imminent danger, which is why the NWS provides localized warnings and is working to further educate the public on snow squall risks.\n4 Tips To Stay Safe\nHere are a few actions you can take to make sure you are prepared in the case of a snow squall.\n- Monitor the Weather\nBefore driving, and especially before longer road travel, monitor your home weather station to watch for signs of a snow squall, such as sudden drops in temperature or rapid increases in wind speeds or shifting winds that could potentially create white-out conditions on the roads. While they can be unpredictable, it’s always recommended to be extra cautious and avoid driving on dangerous winter roads, if possible.\n- Avoid Highways\nWhile it is best to avoid driving altogether in a snow squall, if you must drive, it is best to avoid highways for the duration of the storm. The higher speeds and increased traffic create the potential for dangerous or even deadly pileups.\n- Slow Down and Turn On Lights\nSlow down immediately. Because conditions deteriorate so rapidly in a squall, if you suspect one might occur or receive a warning of one, slow down immediately. As with sleet and other dangerous driving conditions, it is best to err on the side of caution and take any potential storm seriously. Turning on your lights will help other drivers see your vehicle in a snow squall’s limited visibility.\n- Carry a Car Emergency Kit\nIn case you need to pull off the highway and wait out a snow squall, it is a great idea to have a car emergency kit. Essentials like water, snacks, and a blanket could make all the difference while you’re waiting for the storm to pass.\nMonitor Weather Conditions\nSnow squalls are brief and intense winter storms that can create whiteout conditions and slick roads in what feels like an instant. While they are particularly dangerous for drivers due to their unpredictability, refreshing your winter weather awarenessand knowing the signs and risks can better prepare you this winter. A personal weather station will help keep you up to date on conditions before venturing out. It is also a great idea to keep a portable weather sensor in your vehicle so you can tune in to changing conditions like cold fronts with gusty winds. AcuRite weather tools can help you avoid the dangers of snow squalls before they happen.']	['<urn:uuid:17e26764-568a-490a-ab04-6da98bc8df90>']	factoid	direct	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-12T23:47:20.322175	17	47	874
99	I'm planning to store some grain in my new metal tank over winter - what should I do to prevent moisture from building up at the top of the tank?	To prevent moisture migration in grain tanks, you should use aeration by forcing low volumes of air (1/10 to 1/4 cubic foot of air per minute per bushel) through the tank contents. Install aeration fans to draw cold air down through the grain, which discharges warm, moist air outside and prevents condensation on the top surface. Operate fans whenever relative humidity is below 60% and the warmest grain is 10°F warmer than outside air. Avoid running fans during fog, rain, or high humidity. In late fall and winter, operate fans during daylight hours when humidity is near or below 60%. Aim to maintain grain temperature around 50°F.	['- Holding High-Moisture Sorghum ahead of the Dryer\n- Electrocution from Grain Augers\nCompared to other grains, grain sorghum has unique characteristics that must be understood before successfully harvesting, drying and storing it. With some modifications, you can use existing equipment for both sorghum and other grains.\nGrain sorghum plants mature when the moisture in the grain drops to about 30 percent; however, the seed are usually too soft for harvesting when moisture content exceeds 25 percent. Attempts to harvest above 25 percent moisture will usually produce either unthreshed heads or cracked grain. The optimum harvest moisture, about 20 percent, minimizes harvest losses and drying expense.\nBecause field drying is difficult and leads to excessive field losses from birds, wildlife and lodging, harvest early and dry your sorghum mechanically to maintain quality and minimize harvest losses.\nYou can harvest sorghum using row crop or sickle bar headers. Raise the header high enough to harvest only the grain heads with a minimum of leaves and stalks.\nNarrow row spacing helps to discourage lodging due to adjacent plants supporting broken stalks. Consequently, a 30-inch row is usually easier to harvest than a 40-inch row.\nCombine header losses are usually less at a speed of 2.5 to 3 miles per hour; however, this speed may exceed the capacity of the combine rack and shoe if the stand is dense. In this case, you might want to take a partial swath to prevent overloading and still maintain field speed.\nSet combine reel bat speed 15 to 25 percent faster than ground speed to minimize losses. Set the reel height high enough to avoid catching under and throwing the grain heads on the ground. You may need wide reel bats if plant height varies greatly.\nSet your combine cylinder and concave to separate the seed from the head without over-threshing. The cylinder speed for sorghum should be less than that for wheat. Some combine manufacturers recommend removing concave bars. Concave clearance should be about 1/2 inch in front and about 3/16 inch at the rear. Clearance for rotors in rotary combines is usually greater. See your combine instruction manual for details about adjustments.\nGrain sorghum stalks contain more moisture and are smaller than most corn stalks. As a result, grain sorghum stalks are more likely to be chopped up and carried to the grain tank. Pieces of stalk returned to the cylinder in the tailings will be further ground into fines. The chaffer extension can be closed to prevent this material from entering the tailings conveyor. Sorghum stems often catch and choke the straw walkers, which may cause inconvenience and lost time. Some manufacturers make straw walker covers with smaller holes that stop stems while allowing the grain to drop through.\nInspect sieves often during operation to check for matting or clogging. Set the upper sieve 1/2 to 2/3 open with the lower sieve 1/3 to 1/2 open.\nHolding High-Moisture Sorghum ahead of the Dryer\nBe extremely cautious when holding high-moisture grain sorghum ahead of the dryer. Remove all high-moisture grain before refilling.\nSince high-moisture sorghum packs tighter than high-moisture corn, air circulation is inhibited and heating problems may result. If the sorghum is near 25 percent moisture and grain temperature is 80 to 90 degrees Fahrenheit (°F), begin drying the grain within four hours. These conditions may cause heat, molding and sprouting. Aeration in wet holding bins at the rate of ½ cubic foot per minute (cfm) per bushel can be beneficial if nighttime temperatures drop 10° to 20° F below daytime averages. However, if the temperature does not drop, little benefit will result other than a slight amount of evaporative cooling.\nSorghum has more trash mixed in the grain after combining than any other common crop. If harvested prior to frost, pieces of green stems and foliage often mix in with the grain. This foreign matter is difficult to remove before drying. Trash in the dryer can be a fire hazard and offers resistance to air movement. Inspect dryers to make sure all parts unload properly, and do not run dryers unattended for long periods of time. Trash pulled into the dryer air intake often causes fires. Trash in the dryer air intake is carried through the flame and deposited, still glowing, in the plenum chamber and possibly in the grain. You may prevent this from happening by keeping the ground clean near the dryer air intake. The intake may also be shielded with a wire screen that keeps the trash out. The screen should not be finer than ¼ inch mesh or air movement may be restricted. Trash may also blow under the bin drying floors and sift through perforated floors, creating a fire hazard.\nTrash is usually removed from the grain by sifting through a screen or sieve. The seed fall through while trash remains. Most rotary drum cleaners are designed to retain the seed and drop the fines. Removing fines often overloads the take-away conveyors when you clean sorghum. With rotary screens, the grain falls through and trash is retained, requiring a means to catch the portion that would normally be the fines in a normal cleaning operation.\nDryers do not force air through grain sorghum as easily as through corn because the smaller grains leave less space for air movement. The kernels are small, the moisture content is usually high and the resistance to air flow is extremely high. As a result, grain sorghum dries only about 2/3 to ¾ as fast as corn under the same drying conditions.\nFigure 1 shows the pressure drop per foot of grain depth for various airflow rates for both grain sorghum and corn. This pressure drop is a measure of how difficult it is to move air through grain. The higher the pressure drop for a given airflow rate, the more resistance the grain offers to airflow. Notice that the pressure drop per foot of depth of grain for corn at 10 cfm/sf is 0.07 inches water column; for the same airflow rate (10 cfm/sf) the pressure drop per foot depth for grain sorghum is 0.18 inches water column. This is approximately 2½ times the amount indicated for corn.\nThe resistance to airflow through grain sorghum is about 2½ times greater than that for corn, which means more static pressure is needed (from the fan) to dry sorghum than to dry corn. In practice, you can use the same fan; however, sorghum will dry more slowly than corn.\nIf you have in-bin corn drying equipment, you must decrease the grain depths to handle grain sorghum. Unfortunately, in-bin corn drying equipment is not adequately designed to handle corn on many Southeastern farms. Ideally, any method used for drying shelled corn should also work for sorghum; however, if equipment can?t handle corn, it can?t handle grain sorghum either. Check airflow capacities and fan sizes before you commit to drying your crop. Remember, the drying time for sorghum and corn should be the same if the capacity or volume of grain is reduced 25 to 40 percent.\nLimit the drying temperature to 110°F if grain sorghum is to be used for seed. If used for feed grain, you can dry sorghum at 140°F or less for batch-in-bin systems using air flows of 10 to 25 cubic feet of air per minute per bushel (cfm/bu). Batch or continuous flow dryers using air flows of 100 to 200 cfm/bu can successfully dry sorghum at temperatures up to 200°F. Avoid drying sorghum in deep layers since the top layers may mold. Sorghum that is to be held in storage for 12 months should be dried below 12 percent moisture.\nSorghum placed into dry storage should be cleaned and spread mechanically to distribute the dust and fines as well as any remaining trash. Aeration in storage is essential for safe storage, and the aeration rate should be a minimum of 1/10 cfm/bu. Airflow through sorghum will be less than through corn or soybeans because of greater airflow resistance. Airflow for aeration is not as critical as airflow for drying. Since air does not flow as well through sorghum, check the grain more often when you aerate.\nGrain stored in metal tanks can spoil in storage even if the grain was originally dried to the recommended level. Spoilage may be caused by moisture migration, fine material, and insects and molds, all of which are directly affected by moisture.\nGrain harvested in the summer or fall and placed in storage produces air currents within the tank that produce moisture condensation. This process can occur within a completely enclosed and sealed tank and is caused by temperature differences within the grain. As the outside air temperature decreases, the bin walls cool and, as a result, cool the grain layer near the walls and roof. Air next to the walls cools, becomes dense and settles. As this occurs, the central bin air becomes light and rises. As this warm moist air continues to rise, it comes in contact with the cold roof and condenses. This condition (called “moisture migration”) creates a wet zone in the top of the tank (Figure 2). Mold and insects thrive in these warm, moist areas.\nMoisture migration can be prevented in grain tanks by forcing low volumes of air (1/10 to 1/4 cubic foot of air per minute per bushel of contents) through the tank contents. This process, called aeration, produces uniform temperatures throughout the mass.\nInstall aeration fans to draw the cold air down through the grain, reversing the natural trend of the warm air to rise. Drawing the cold air down discharges the warm, moist air to the outside and prevents condensation on the top surface of the grain.\nBegin fan operation as soon as grain is placed in storage and operate it whenever the relative humidity is below 60 percent and the warmest grain is 10°F warmer than the outside air. Do not operate fans when fog, rain and high humidity exist. In late fall and winter, use the fans during daylight hours when the humidity is near or below 60 percent. A grain temperature of 50°F is generally satisfactory. Grain stored for more than one year should be cooled below 50°F if possible to provide better insect and mold control.\nYou can use high-volume drying fans operating two to three hours several times a week when the relative humidity is near or below 60 percent to aerate grain. Air forced upward through grain in high volumes usually does not cause moisture to accumulate in the top layers. Do not use heat when aerating -- the objective is to cool the grain.\nRegular inspection of grain tank contents is a must for successful management. Inspect the grain for moisture, insects and spoilage at least every 30 days.\nElectrocution from Grain Augers\nMany Georgia farmers use grain augers that are 40 to 60 feet long to place grain in metal bins from the top. Many accidents occur when these long augers are being moved from one bin to another without lowering the upper end. Generally, two people hold the auger while moving it. If the upper end touches an overhead power line, both people can be electrocuted. To avoid possible electrocution, consider installing underground electrical service or work with your local utility to move electrical wires that are dangerously close to metal grain bins.\nStatus and Revision History\nPublished with Minor Revisions on May 17, 2012\nPublished with Minor Revisions on Jul 10, 2017']	['<urn:uuid:bd323ee0-2bea-45c4-989c-f815ae3cb138>']	open-ended	with-premise	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-12T23:47:20.322175	30	107	1908
100	Which is older: Krav Maga or Hereville comics?	Krav Maga is older. It was founded by Imrich Lichtenfeld in the 1930s when he developed techniques to defend against fascist gangs, while the Hereville comics were published in 2010 with the first book 'How Mirka Got Her Sword'.	['What does it take to be a hero? In comics, physical daring and superpowers are typically needed. Spiderman broke new ground in the 1960s when teen Peter Parker realized that “with great power there must also come great responsibility.” Parker had to learn how to be an adult as well as a superhero. Now, I am happy to say, we have some great graphic novels recasting this lesson in purely human terms, with young women learning what it takes to be heroic adults. These are enormously entertaining reads, too.\nIn separate, fast-paced and fun series, a 10th grader and an eleven-year-old discover that a sharp blade, however skillfully wielded or magical, is not the solution to their problems. While trouncing trolls—and, later, bouncing meteors—these young heroes learn more about themselves and their own, everyday lives. That is the knowledge they need to rescue others and themselves. Meanwhile, we have a blast watching their fantastic adventures!\nAliera Carstairs does not fit in at her New York City high school. In Foiled (2010) and its sequel Curses! Foiled Again (2013), we see how important the sport of fencing is to her. Through hours of hard practice, she may have the chance to compete nationally. If only the practice fencing foil her mother bought at a garage sale were not an enchanted one, revealing that Aliera is the destined Defender of Faerie. If only the handsomest guy in school, her lab partner Avery, were not really a troll. When things and people are not as they seem, what’s a 10th grader to do? What rules should be broken … what promises kept? Aliera’s cousin Caroline, wheel-chair bound with rheumatoid arthritis, is a major character in both books, helping Aliera with strategy.\nWriter Jane Yolen and illustrator Mike Cavallaro are a dynamic duo in these books, creating plot, characters, and setting with a seamless mesh of words and images. Yolen plays with language as nimbly as one would expect from this acclaimed, veteran author, known as the “Hans Christian Andersen” of the United States. From witty remarks about “Every verbal thrust … parried,” chapter titles aptly named after fencing moves, and high school banter ranging from monosyllables to casual references to Shrek, Harry Potter, and The Wizard of Oz, not one note rings false. And the pacing is great. One example of how this writing team expertly blends words and pictures is a page in Curses! featuring trolls. After troll silhouettes atop the page tell Aliera that they intend to swat her flat, a mid-page series of five close-ups has each troll individually add: “Flat as a hat.” “Flat as a flounder.” “Flat as a board.” “Flat as a pancake.” “What’s a pancake?” At the bottom of the page, as the trolls march off with prisoner Aliera, an explanation of pancakes follows, with Aliera thinking she is pretty lucky the trolls are this easily distracted.\nThis variety of panel sizes, shapes, and perspectives is just one instance of Mike Cavallaro’s versatility and flair. The books’ action is also kept brisk with full page and double page spreads, and with pages where the absence of all words heightens tension and suspense. There is smart use of color to distinguish between the everyday world and Fairie, and to show Aliera’s growing ability to see the Fairie creatures infiltrating New York City. Sometimes Cavallero also uses different drawing styles to indicate velocity as creatures zoom, a magical storm rages, or Aliera charges into battle. I can see why Foiled was acclaimed as a YALSA Great Graphic Novel, A Texas Maverick Graphic Novel, and an Amelia Bloomer Recommended Title. I expect Curses! Foiled Again may win awards, too. I wonder if this second book contains the same clue that the first one did—a t-shirt Aliera wears there displays a quotation that became the next title. I think that careful readers may be able to spot and figure out the title of Aliera, Avery, and Caroline’s third, yet-to-be-written adventure.\nAuthor/illustrator Barry Deutsch identifies his hero and her adventures in his books’ titles: Hereville: How Mirka Got Her Sword (2010) and its sequel, Hereville: How Mirka Met a Meteorite (2012). Deutsch also humorously tells readers a bit about Mirka’s everyday world with an additional line atop each book’s cover. “Yet Another Troll-Fighting Eleven-Year-Old Orthodox Jewish Girl” proclaims the first, while the sequel announces that Mirka is now “Boldly Going Where No Eleven-Year-Old Orthodox Jewish Girl Has Gone Before.” Hereville, as we soon see, represents those rare Jewish communities—such as those in Monsey, New York, and Lakewood Township, New Jersey—where strict religious observance governs all aspects of life. Such Chasidic Jews choose to live apart from the rest of society. Deutsch’s sensitive, even-handed, and wonderfully entertaining depiction of Chasidic Mirka’s first adventure won the 2011 Sydney Taylor Book Award for older readers. It was nominated for the Eisner, Harvey, and Nebula awards, too.\nMirka is a bit of a rebel, hiding forbidden books about monsters under her bed and unhappy about having to learn the “womanly” skill of knitting. How will she balance her genuine faith, the demands of a large family, and school rules and routines with her desire to “slay dragons”? When Mirka meets an unknown creature that she only thinks is a monster, she asks herself, “Am I hero or NOT?” Rising to that supposed challenge, Mirka gets her magical sword. Yet, to defeat a troll, Mirka finds that sharp thinking and life lessons are much better weapons. You may be as surprised as that troll to see what actually proves to be his undoing! Throughout this book and its sequel, author Deutsch does a fine job capturing the verbal give-and-take of brothers and sisters, the jeers of school bullies, the gentle sarcasm of no-nonsense parents, and the harsher jibes of supernatural creatures. Whenever Mirka and her companions in typical Chasidic fashion use a Yiddish word or expression as part of their speech, these words are asterisked. A brief translation appears at the bottom of the page.\nDeutsch’s illustrations sparkle with wit and variety. An amazed Mirka is shown in a two-part panel shaped like an exclamation mark! She is looking off to her right, at an elongated panel containing a tall old mansion. That panel’s top extends upward and inward, to form the peaked roof of the narrow house. Many times, characters’ heads or feet overlap into nearby panels, enhancing the intense emotional connection between scenes. Mirka’s braids whip across panels as she is fighting that first “monster,” and double-page spreads without any panel enclosures capture the furious energy and activity of Mirka’s encounter with the troll. When her younger brother Zindel worriedly follows Mirka, we see him peering around a panel and then pacing around an entire page. Sometimes panels overlap or proliferate to suggest actions occurring in rapid succession. In this book where the difference between day and night becomes an important plot element, Deutsch uses different colors for each. Mirka’s dawn triumph is revealed in a combination of soft daytime orange and fading nighttime blue.\nIn Mirka Meets a Meteorite, green enters Deutsch’s palette, as both Earth and then Mirka are threatened by the space rock that, due to her latest dealings with the troll, has crashed to Earth. Mirka’s amazing race to reach a powerful, helpful witch before this crash occurs is shown in vivid detail, with her large, running figure overlaying many small thought panels. We then see close-ups of Mirka’s anguished face as she struggles to find strength, interspersed with close-ups of other body parts as she tries to rise from her knees or raise a foot just one more time. We turn the page right after seeing Mirka collapse only to see a wordless, double-page spread of the large blue meterorite just above the treetops! The next two pages keep us in further suspense, with images of blinding light, glimpses of a dazed Mirka, and the only words her bewildered, “What happened?” The fantastic answer to this question fuels the rest of the plot.\nIn this charming novel, a frustrated, very hungry Mirka comes to realize the importance of family togetherness and family history. Being the very best Mirka she can be turns out to be more important than any test of strength or knowledge And her stepsister Rochel’s sharp wit turns out to be a more effective weapon than Mirka’s sword. You will have to read this fantasy novel to its very end, though, to find out which everyday skill Mirka uses to cushion her own crash landing on Earth. I do not want to spoil that laugh-filled surprise.', 'Krav Maga – Techniques, Kicks, Self-Defense, etc.\nKrav Maga is an eclectic martial arts style from Israel focused on winning in “real life” combat situations. It uses strikes, kicks, grappling and many other self-defense techniques. Krav Maga was developed to finish a fight as quickly as possible and therefore all attacks are aimed at the most vulnerable parts of the body (i.e. groin). This martial art is utilized by the Israeli Defense Forces. A number of the elite Israeli military units also use the martial arts system known as KAPAP.\nThis Krav Maga wiki provides students with instructions and videos for a wide variety of Krav Maga techniques, terms, etc.\nWiki – Best Krav Maga Books\nMain Elements of Krav Maga\n- Krav Maga Techniques – This section provides detailed instructions and videos for many Krav Maga techniques (i.e. kicks, strikes, self-defenses, escapes, ground fighting, etc.).\n- Krav Maga Weapon Defenses – Various Krav Maga self-defense techniques versus guns, knives, clubs, etc,\n- Krav Maga Belt Levels – This sections looks at the belt colors and requirements for various Krav Maga belt levels.\nHistory of Krav Maga\nKrav Maga is an Israeli martial arts and was founded by Imrich Lichtenfeld.\nAccording to the International Krav Maga Federation, “Imrich (“Imi”) Sde-Or (Lichtenfeld) was born on May 26, 1910, to a Hungarian Jewish family in Budapest in the Austro-Hungarian Empire. He grew up in Bratislava, Slovakia’s capital, with a father who provided him quite an unusual childhood. Samuel Lichtenfeld, his father, was a chief inspector on the Bratislava police force and a former circus acrobat.\nWith his father’s encouragement, Imi engaged in a wide range of sports, such as swimming, boxing, wrestling and gymnastics. He trained at a Gymnasium owned by his father, who taught self-defense. Imi excelled in wrestling both as contestant an as trainer, Also winning several awards in these fields.\nIn the mid thirties, Fascist and anti-Semitic groups appeared in Bratislava, threatening to harm the city’s Jewish community there. Imi led a group of former boxers and wrestlers to defend his Jewish neighborhood against the fascist gangs. This group attempted to block the anti-Semitic gangs from entering the Jewish quarter. Encountering as many “street fights” as he did, Imi quickly realized that sport had little in common with real combat and began developing a system of techniques for practical self-defense in life threatening situations.\nIn 1940 Imi fled the Nazi occupation of his homeland, and boarded the last immigrant ship that succeeded in escaping the Nazis’ clutches. He boarded the vessel “Pencho”, which shipwrecked on the Greek Dodecanese Islands, and arrived to Palestine in 1942.\nAt his arrival, Israel’s early leaders recognized Imi’s fighting abilities and in 1944 he began training fighters in his areas of expertise: physical fitness, swimming, wrestling, use of the knife, and defenses against knife attacks. During this period, Imi trained several elite units of the Hagana and Palmach (striking force of the Hagana and forerunner of the special units of the IDF), including the Pal-Yam, as well as groups of police officers. After the establishment of Israel in 1948 and the formation of the IDF he became Chief Instructor for Physical Fitness and Krav Maga at the IDF School of Combat Fitness. Imi served in the IDF for about 20 years, during which time he developed and refined his unique method for self-defense and hand-to-hand combat.”\nKrav Maga Organizations\nBefore he died, Imi Lichtenfeld delegated his closest students to expand his art and start teaching Krav Maga in different countries. This led to the creation of multiple Krav Maga federations. The following are some of the largest and/or best known Krav Maga organizations:\n- Krav Maga Worldwide (formerly Krav Maga Association of America), founded by Darren Levine in 1983\n- Israeli Krav Magen Association (K.A.M.I) founded by Eli Avikzar in 1989\n- European Federation of Krav Maga (FEKM), founded by Richard Douieb in 1997\n- International Krav Maga Federation (IKMF), founded in 1996\n- South America Federation of Krav Maga, founded by Kobi Lichtenstein\n- Krav Maga Global (KMG), founded by Eyal Yanilov in 2010\nVariety of Krav Maga Self-Defense Techniques\nKrav Maga – Knife Training (with Marine Corps)\nImage provided by Wikimedia Commons\n- Krav Maga organizational information provided by Guillaume Chan, Krav Maga Guild, http://kravmagaguild.com, Added – 05/28/17\n- International Krav Maga Federation, About Us, http://www.kravmaga.co.il/showitem.asp?itemid=About%20us, Added – 7/4/13']	['<urn:uuid:b14fc78c-5876-47d6-a528-718575c74fea>', '<urn:uuid:321dbefe-d4b8-4188-8c8b-01208a1dae8c>']	factoid	direct	concise-and-natural	distant-from-document	comparison	novice	2025-05-12T23:47:20.322175	8	39	2157
