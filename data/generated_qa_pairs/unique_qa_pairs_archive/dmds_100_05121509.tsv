qid	question	answer	context	document_ids	question_factuality	question_premise	question_phrasing	question_linguistic_variation	question_multi-doc	user_expertise-categorization	generation_timestamp	question_length	answer_length	context_length
1	vehicle pollution mechanisms preventive methods	Vehicles contribute to pollution through multiple mechanisms - their engines release harmful gases through fuel combustion, while their movement generates noise through mechanical parts, tire rolling, and aerodynamic effects. To prevent these forms of pollution, several measures can be taken: using vehicles with proper silencers and regular servicing to reduce noise, maintaining strict checks on car exhaust emissions, creating green belts in high noise areas, and using alternative energy sources instead of fossil fuels.	"['Ask A Scientist\nWhy does a car, a race car and a big truck makes the noises they do? Do you think the noises are cool? I do!\nAsked by: Rachael Klein\nSchool: St. James Middle School\nTeacher: Cora Walter\nHobbies/Interests: Horseback riding, school, playing piano, swimming, sewing, Karate(recently spent a week in Japan at a Karate tournament)\nCareer Interest: Massage therapist or a psychologist\nAnswer from George Catalano\nProfessor of mechanical engineering, Binghamton Un\nResearch area: Turbulence; fluid mechanics; aerodynamics; the impact of technology upon the environment; and engineering ethics\nPh.D. school: The University of Virginia\nFamily: Married; have two Alaskan malamutes and two more in our hearts\nInterests/hobbies: All things Italian, philosophy, cosmology, grand prix racing, writing, painting\nTo answer such an important question, let us first try to understand what is meant by the term, ""noise."" We commonly use ""noise"" to describe sound waves as they impact our ear. We hear noise when a sound wave also known as a pressure wave, impacts the eardrum and causes the eardrum to vibrate, sending further vibrations to the brain. This idea of a sound or pressure wave may seem difficult to imagine. How can we visualize in our mind’s eye what a sound wave actually looks like? One interesting way you can try can occur the next time you stand near a still pond. Pick up a small pebble and toss it into the pond and watch what happens. You will be treated to a series of concentric circles or ripples, generated at the place where the pebble first strikes the pond’s smooth surface. Those circles will gradually grow until they either reach the edge of the pond or simply vanish. The circles represent sound or pressure waves moving away from the pebble or sound source. Every time there is a vibrating surface surrounded by a medium, in this case air, pressure waves or sound is generated. Noise is a particular kind of sound or pressure wave. It is one that has no structure, no rhythm, no beat such as would be found in music or spoken language. Let’s then go back to the car, the truck and the racing car. What generates the noise or those sound or pressure waves? In each case, there are several sources, which include the engines with its gasoline or diesel fuel explosions, moving valves and camshafts and all the other hardware associated with the internal combustion or diesel engine. The rolling of tires over the pavement also generates a large amount of noise. Then there is vibration of the vehicle’s body itself as it moves up and down on its suspension. Lastly there is the aerodynamic noise generated by the rushing of the air past the vehicle as it moves down the road. Each type of vehicle generates its own unique noise signature or pattern. There is one kind of noise unique to the diesel trucks. Have you ever hear an n extremely loud clattering noise as a large truck comes to a rapid stop? That noise, which is another type of pressure or sound wave, is generated by releasing some of the pressure built up inside the diesel engine as it is operating. The release of the pressure greatly decreases the power generated by the diesel and helps bring the truck to a rapid stop without using its mechanical breaks. It is termed an ""airbrake."" Racing cars with their high performance racing engines without mufflers or any form of sound deadening materials generate perhaps the loudest noise of all the vehicles. The sound of a Ferrari V12, powering a Formula 1 car through a quick lap at places like Watkins Glen is like no other. Perhaps noise, like beauty, is in the ear of the beholder!', ""Pollution is the presence of a substance that tends to affect directly or indirectly the environment or changes, degrades or spoils the environment. Pollution can be categorized into following types:\n- Air Pollution\n- Water Pollution\n- Soil Pollution\n- Noise Pollution\nAn undesirable change in the physical, chemical or biological characteristics of air is called pollution. The substances which pollute the air called pollutants. Air pollution causes heart diseases, eye problem, cancer etc. Apart from it, air carries the bacteria and virus from one place to another place and transmits different diseases such as tuberculosis, polio, diphtheria and acute respiratory tract infections.\nCauses of air pollution\nThe following are the main causes of air pollution:\n- The dust particles and harmful materials blown out by the wind gets mixed in the air and pollutes it.\n- Natural gases that come from inside the earth's surface also pollutes the air.\n- Harmful gases released from different factories, industries and vehicles pollutes the air.\n- Gases that comes from burnt materials,rotten and decayed materials also pollutes the air.\n- Poisonous gases spreading out in the fields, rooms and houses are also the causes for air pollution.\nEffects of air pollution\nThe following are the effects of air pollution:\n- Air pollution causes respiratory tract infection (RTI) and asthma.\n- It deteriorates the cultural heritage and trees.\n- It brings various skin and eye allergy.\n- It is the main cause of global warming. that affects all the creatures of the world.\nPreventive measures of air pollution\nThe preventive measures of air pollution are as follows:\n- The air pollutants should be controlled as the point source by using electrostatic precipitator or filter in the industries.\n- The use of cheap fuel with higher sulphur content should be avoided. Use of disulphurized coal should be used.\n- Alternate sources of energy should be used in place of coal, wood, oil etc.\n- Population growth rate should be controlled.\n- Strip plantation should be done everywhere on the road side.\n- Strict check of car exhaust should be maintained.\n- Public awareness programme about the effects of pollution should be managed.\nDegradation in the quality of water is called water pollution. Water covers over the 3/4th part of the earth’s surface. It is a very important resource for people and the environment. Water pollution affects drinking water, rivers, lakes and oceans all over the world. In many developing countries, it is usually a leading cause of death, by people drinking from polluted water sources. Drainage and wastage from industries, laboratory, hospitals, and homes are the main factors that causes water pollution.\nCauses of water pollution\nThe following are the main causes of water pollution: -\n- Natural calamities like flood, landlides, soil erosion, heavy rain, etc. also pollute the water.\n- Leakage of agro-chemical from agricultural fields mixing with water resource can also cause water pollution.\n- Throwing of dead bodies of animals in water resources also pollutes water.\n- Some human activities like washing of clothes and utensils near wells, ponds, streams, lakes, etc. also pollutes the water sources.\nEffects of water pollution\nThe following are the main effects of water pollution: -\n- Water pollution causes water-borne disease like diarrhoea, dysentery and cholera.\n- It also brings various skin allergy if taken the bath with polluted water.\n- Acid rain deteriorates cultural heritages.\n- It has the negative impact on plants.\n- Aquatic animals cannot survive in polluted water.\nPreventive measures of water pollution\nThe following are the main preventive measures of water pollution: -\n- The dead bodies of animals and other wastes should not be thrown in water resources.\n- People should be made aware of the consequences of water pollution and they should be encouraged to participate in the pollution control programme.\n- Production of domestic waste should be reduced as far as possible and it should not be thrown in and around the water resources like ponds, rivers, lakes, streams etc.\\\n- Water pollution due to soil erosion, landslides, and floods should be controlled by minimizing the activities which cause these problems.\nLand pollution is the degradation of earth's surface. Land pollution makes the quality of soil low. It directly affects the plants and indirectly to human beings. Human actions have also caused many large areas of land to lose or reduce their capacity to support life forms and ecosystems. This is known as land degradation.\nCauses of land pollution\nThe following are the main causes of land pollution: -\n- The accumulation of huge amount of bio-degradable and non-biodegradable waste materials pollutes land.\n- Farmers use chemicals such as fertilizers and pesticides in their farms to increase production. However, it adversely can affect land and water resources in and around there.\n- Soil is polluted by storing of soluble and insolubledirt's on the earth.\n- Trekkers and mountaineers carry different types of packed food and other necessary things with them. After using them, they throw such materials like plastics, tins and other materials there. This pollutes some of the tourist areas of rural and city parts of Nepal.\n- The solid and liquid substance of the industries such as leather, shoe, battery distillery, paper and metal destroy the land conditions and it pollutes the soil.\nEffects of land pollution\nThe following are the main effects of land pollution:\n- Land pollution kills the useful organisms like an earthworm.\n- The soil becomes infertile and not suitable for cultivation.\n- Agriculture production will decrease.\n- Underground water becomes polluted.\n- Bad smell spreads from the polluted land and it causes pollution to the surrounding places.\n- It destroys beauty of the environment and the importance of cultural heritages as well.\nPreventive measures of land pollution\nThe following are the preventive measures of land pollution: -\n- Bio-degradable materials such as residue of plants, vegetables and other wastes of plants should be used to make compost.\n- Broken machines, vehicles and other materialsshould be re-used.\n- Legal provision should be made on the management of solid wastes.\n- The solid waste and harmful chemicals from industries, hospitals and laboratories should be processed and purified to some extent before discharging them to land and water resources.\n- The use of plastic bags and other materials made from plastic should be reducedand must be re-used in some extent.\nNoise is considered as environmental pollution, even though it is thought to have less damage to humans than water, air or land pollution. Noise pollution also disturbs the ecosystem. Noise pollution does not harm the environment as much as air pollution but if affects the health of the person negatively. If someone has to stay in a very noisy condition for long time, this will affect the hearing power (nervous system).\nCauses of noise pollution\nThe following are the main causes of noise pollution:\n- Noise is created during construction by machinery.\n- Market area, densely populated settlement, industrial area produces much sound that causes noise pollution.\n- Industries like cement factory, flour mill, metal industries, etc. produces loud noise.\n- Noise-pollution is caused by construction activities like road construction and building construction.\n- Crowd in urban areas and miking causes sound pollution.\n- Playing radio, television and various musical instruments in high volume causes sound pollution.\nEffects of noise pollution\nThe following are the main effects of noise pollution:\n- Sitting in a noisy place for long time damages our hearing capacity.\n- It causes imbalance in the production of hormones.\n- Frustration, depression, hypertension etc. may cause.\n- High-stress level and sleep disturbances may happen.\n- A loud noise may break the tympanic membrane of the ear and it leads to diseases.\nPreventive measures of noise pollution\nThe following are the preventive measures of noise pollution:\n- Green belts should be created where there is the high level of noises.\n- The people who work in noisy places should use earplugs.\n- Vehicles which produces loud noise should not be operated near the cities.\n- High walls can be built around the factory which helps to check the transmission of noise.\n- Machine with silencer should be used as far as possible. Regular servicing of machie is also helpful to check the sund pollution.""]"	['<urn:uuid:2a6b81f3-1e40-446b-8635-99495822b0e0>', '<urn:uuid:90fe0036-5348-4da8-9670-372db29d74db>']	open-ended	direct	short-search-query	distant-from-document	multi-aspect	expert	2025-05-12T15:09:02.012753	5	74	1999
2	looking for sources of milk fatty acids in normal healthy cows please explain	Milk fat synthesis depends on fatty acids from two sources: 1) Long-chain fatty acids (>16 carbon atoms) which come from dietary fat and body fat reserves, and 2) Short-chain (4-8 carbons) and medium-chain (10-14 carbons) fatty acids which are synthesized in the mammary gland. The 16-carbon fatty acids can come from both sources. In well-fed cows, 4-8% of milk fatty acids come from body fat breakdown.	['Heat stressed dairy cows often suffer milk fat depression, which can be costly to producers in the current challenging dairy market. However, ongoing research suggests that optimising rumen function can help sustain milk fat concentrations in cows under heat stress.\nMilk fat synthesis depends on fatty acids from 2 sources:\n- Long-chain fatty acids (greater than 16 carbon atoms per molecule) – derive from the uptake of circulating preformed fatty acids, dietary fat absorbed from the digestive tract, and non-esterified fatty acids (NEFA) from the mobilisation of body fat reserves.\n- Short-chain (4 to 8 carbons) and medium-chain (10 to 14 carbons) fatty acids – originate in the mammary gland from de novo synthesis (fatty acids created ‘anew’ in the mammary from smaller molecules).\nThe 16-carbon fatty acids can originate from both sources. For a well-fed cow, an estimated 4% to 8% of milk fatty acids originate from the breakdown of body fat (such as NEFA). However, the proportion of fatty acids from this source could increase progressively as the cow’s net energy balance decreases (Bauman and Griinari, 2001). Under heat stress, there are two potential mechanisms for milk fat depression (MFD). The first one is rumen fatty acid biohydrogenation – inhibiting de novo milk fat synthesis. The second one is rumen lipopolysaccharide – limiting substrate supply and de novo milk fat synthesis.\nOptimising rumen function could help maintain milk fat content and production efficiency of dairy cows under heat stress. Photo: Henk Riswick\nAltered fatty acid biohydrogenation\nAccording to the well-accepted ‘biohydrogenation theory’ (Bauman and Griinari, 2001), MFD results from changes in rumen biohydrogenation of unsaturated fatty acids and the passage of specific intermediates of biohydrogenation out of the rumen (such as trans-10, cis-12 CLA). These biohydrogenation intermediates subsequently interfere with the expression of genes involved in fat synthesis thereby reducing milk fat synthesis in the mammary gland. Furthermore, the increased rate of feedstuffs outflow from the rumen may increase the likelihood of biohydrogenation intermediates passing through the rumen. So the theory identifies how certain feedstuffs can represent risk factors for MFD (Figure 1). Dairy nutritionists sometimes suggest feeding supplemental fat to maintain the cow’s energy intake during heat stress. However, it is important that the source of fat is rumen inert. Otherwise, low rumen pH, which occurs in heat stressed cows, could generate more intermediates of biohydrogenation and increase the risk of MFD.\nFigure 1 – Dietary components can impact the risk of milk fat depression in 3 ways through the rumen biohydrogenation (BH) pathway.\nAdapted from Lock and Bauman (2007).\nAltered rumen LPS production\nThe other potential mechanism for MFD during heat stress involves the concentration of rumen lipopolysaccharide (LPS), which comes from Gram-negative bacteria when they die. Research shows that when rumen pH decreases, the rumen concentration of LPS increases. Also, as rumen LPS concentration increases, milk fat concentration decreases. Zebeli and Ametaj (2009) showed greater concentrations of rumen LPS as the proportion of grain in the diet increased. As rumen LPS increased, milk fat content decreased (Figure 2). This correlation could be due to the ability of LPS to induce insulin production in the pancreas (Waldron et al., 2006). Increased circulating insulin and increased insulin sensitivity of heat stressed cows could reduce body fat mobilisation. This condition could occur even though heat stressed cows are under negative energy balance due to reduced feed intake and increased maintenance demands (Baumgard and Rhoads, 2013). Also, the lack of plasma NEFA, potentially an important precursor for milk fat synthesis under heat stress (Bauman and Griinari, 2001), may contribute to MFD. Other reported negative LPS effects on fatty acid production include: Decrease in activity of lipoprotein lipase (Lopez-Soriano and Williamson, 1994), decrease in expression of lipoprotein lipase and fatty acid transport protein 1 (Feingold et al., 2009) and suppression of enzymes related to de novo fatty acid synthesis in the mammary tissue (Dong et al., 2011).\nFigure 2 – Correlation between rumen lipopolysaccharide (LPS) and milk fat content.\nAdapted from Zebeli and Ametaj (2009).\nOptimising rumen function during heat stress\nResearch to date helps explain how MFD during heat stress relates to depressed rumen health. Given this relationship, optimising rumen function could help maintain milk fat content and production efficiency of dairy cows under heat stress. Heat stress causes physiological and behavioural changes in dairy cows. These changes can lead to suboptimal rumen conditions, resulting in production of fatty acid biohydrogenation intermediates and LPS that inhibit milk fat synthesis in the mammary gland. Today, natural digestive health technologies are available to help optimise rumen conditions through the diet, thereby helping to reduce the negative impact of heat stress on milk fat and maintain the production efficiency of high-producing dairy cows.\nReferences are available on request.']	['<urn:uuid:a8b911e7-d0e7-4893-9a21-bf2091df18be>']	factoid	with-premise	long-search-query	distant-from-document	single-doc	novice	2025-05-12T15:09:02.012753	13	66	786
3	What solutions could help address the quality control issues in Ethiopian spice production, particularly regarding aflatoxin contamination?	Aflatoxin contamination cannot be eliminated once it affects products, so prevention is key. The main prevention strategies include: proper drying using natural sun or efficient drying technologies like solar tunnel driers and heat driers; using raised beds, cemented floors, or plastic sheets for drying; implementing improved agronomic practices; maintaining appropriate storage facilities with proper ventilation and food-grade painted floors; using cold rooms or storage with less than 10% moisture; utilizing hermetic bags for packing; and applying alfa-phase fungus inoculants for soil-based infections. Advanced processing methods like steam sterilization and irradiation technologies are also used in major spice-exporting countries, though these require significant investment.	['Ethiopia has the potential to earn billions of dollars from spices. However, a poor post harvesting system, adulteration, unsystematic land management, failing to utilize technology and other factors keep it from reaching its full potential. Recently a large amount of aflatoxin in some red pepper and other spices caused Ethiopia to receive a warning from destination countries. Addisu Alemayehu, a senior expert in field of spices, herbs and aromatic products argues that the country should replace traditional methods and utilize a modern system of developing the spice industry. Capital’s reporter Tesfaye Getnet talked with Adissu to learn about the potential and challenges of spices in Ethiopia. Adissu is currently working at the Ethio-Netherlands Trade for Agricultural Growth (ENTAG) Program which is one of the five programs under the BENEFIT portfolio between the Ethiopia and Netherlands government as the spice and private sector association project coordinator. He is also one of the founders and board secretary of the Ethiopian Spice, Aromatic and Herbs Growers and Processors Association(ESAHGPA).\nCapital: How much spice does Ethiopia have the potential of producing?\nAdissu: CSA and MOA don’t conduct a formal annual assessment of production data but based on a study conducted in 2014/15 the country produced an estimated 418,000 metric tons. Other studies indicate that Ethiopia could make one million metric tons of spice.\nCapital: Knowledge of proper cultivation and post harvest management are the key challenges in spice export, for example farmers wet down the red pepper with water so it will weigh more. What should be done to tackle these challenges?\nAdissu: Yes, as you said adulteration and such bad practices are major challenges to the spice export and sector development of the country and the best solutions come from understanding the real causes or main reasons behind the problem. Such practices occur for three major reasons. There is a lack of awareness about aflatoxin and limited knowledge on the impact of such practices (wetting) on safety and quality which can be tacked by creating awareness through information, education, communication and training across the value chains (farmers, traders, processors, exporters, consumers, policy makers and\nimplementers). There is also a lack of spice marketing proclamation; quality based pricing systems, regulation and guidelines along with a lack of spice marketing centers. Thus we need spice marketing regulation and marketing centers in place along with a quality based pricing system. Finally there is a lack of improved and mechanized technologies that either shorten spice drying time or escape from unexpected rain. Thus the research institutions and universities must either introduce and make adaptation trails of innovative drying and processing technologies from abroad or generate similar technologies which are affordable to smallholder farmers.\nCapital: Land degradation is another challenge in spice production, do we have proper land management with regard to spice production ?\nAdissu: Like other crops mono cropping, poor soil fertility and land management are the other major challenges of spice production in the country These problems make Ethiopia’s average spice productivity much lower than the world average despite the fact that there has been much improvement in production and productivity over the past 10 years. One of the typical examples is the ginger bacterial wilt disease outbreak which occurred six years ago due to over a decade of mono cropping of ginger on the same farm which devastated 85% of the total ginger production of the country.\nCapital: Countries like India are using better technology and IT software in both production and transaction but in Ethiopia people still use traditional methods, what prevents us from using technology?\nAdissu: I think we as a country are new to IT and new technologies and honestly our behavior is not to explore for science and technology. Let me share with you a funny story (which may be a true joke) One senior researcher was working in my previous employee organization, the Ethiopian Institute of Agricultural research; The first computer was introduced in that research center by denotation 1980’s in the wheat research department and other fellow researchers in the center when entering into the office with with their bare feet because they were told by an anonymous person that the computer would be corrupted if it became dusty from their shoes.\nSo, limited access to IT equipment and lack of practical training (mostly theoretical or like one computer shared for thousands) in the education systems are the major reasons behind it.\nCapital: Is the spice sector creating the amount of jobs hoped for?\nAdissu: Based on a survey conducted in 2014 more than 5 million smallholder farmers, around 25 million people’s live depend on the spice sector and it can provide more employment opportunities if proper attention and support is given from all stakeholders (GO, NGOs smallholder farmers and the private sector)\nCapital: Aflatoxin in the export product it threatening Ethiopia earnings, what is a good remedy for getting rid of Alfatoxin in spice products?\nAdissu: Aflatoxin can’t be eliminated once it infects products including spices. Thus prevention is the only remedy and the main strategies are; proper drying using natural sun or if it is not possible due to weather problems use of fast and efficient drying technologies such as solar tunnel driers, heat driers, use of raised beds or cemented floor or plastic sheet for drying. Healthy plants give healthy seeds so implementing proper and improved agronomic practices and technologies, Keeping it in appropriate storage facilities (dry, well ventilated, food grade painted floor) if possible use of cold rooms or storage in less than 10%, use of hermetic bags for packing and storing spice products, If the aflotixin infection starts from soil use of alfa-phase fungus inoculants which is successful in maize and ground nuts.\nIf all this is not possible selection, cleaning and hand picking of aflatoxin (yellow outside and white inside in red pepper or white mold/fungus materials) infected seed/pods from our product and proper drying on wetted products before we consume or process or export. Steam sterilization and irradiation technologies were also the other advanced spice processing technologies which need huge investment but are used in major spice exporting, producing and consuming countries.\nCapital: What is the global spice market like and what can Ethiopia do to export more?\nAdissu: Spice trade developed throughout Asia and the Middle East in around 2000 BCE. Its contribution to world civilization is well recognized, as it established and destroyed empires, led to the discovery of new continents, and in many ways helped lay the foundation for the modern world. Spices have lost the status and allure that once placed them alongside precious metals as the world’s most valuable items, but the spice sector remains dynamic. Out of the almost 400 products of the herbs and spices category, about 40 to 50 are of global economic and culinary importance. Global consumption of spices is expanding steadily with growth rates of between 2% and 5% per annum. Globalization, access to information, growing population, shifting consumer trends towards health and authenticity in developed economies, sustained economic growth in developing economies and increased consumption of meat in developing countries (the “march of the meat eaters”) have resulted in a growing spice market.\nAsian-Pacific and European consumers are the largest consumers of spice, and the global market for spices is projected to exceed USD16 billion by 2019. The market for spices in developed economies such as Europe and North America will continue to grow, but more slowly than in other regions due to maturity of the industrial sector. The Asia-Pacific region is projected to be the fastest-growing market for spices, at an annual growth rate of 8% from 2014 to 2019. The food processing industry in Asia will be an important driver behind this growth.\nIn order to tap these growing and enormous market opportunity I advice the government should implement the 10 years spice industry development strategy which is developed three years by Addis Ababa Science and Technology University through MoT ownership and UNIDO financial support.\nCapital: A good spice exporters and producers’ association is vital in increasing exports as is the case in India but when we look at the Ethiopian association their work has not been very productive what can be done about this?\nAdissu: The major problems of Ethiopian private sector associations including the Ethiopian spice, aromatic and herbs growers and processors association is limited financial capability and lack of proper policy support for private sector associations. European countries have a compulsory rule that enforces that any private company has to be members of their engaged sectoral association. Moreover, the created a spice association (ESAHGPA) only three years ago and it is in its infant stages so it is hard to measure its impact. Besides, support from development partners or NGOs for the spice sector is very limited. For instance ENTAG is the only NGO working in spice sector development.\nCapital: What is your opinion about applying food safety standards in Ethiopia?\nAdissu: It is my initiative and I have raised the agenda of food safety and aflatoxin in ENTAG since April 2017 and now thanks to all stakeholders and partners’ support after the spice platform meeting in May the agenda was taken to higher policy makers. I hope the food safety regulation will be issued very soon. Thus I strongly support the idea of application of food safety regulation in Ethiopia.']	['<urn:uuid:da7c5fce-0bb2-409c-8c5a-1000942846d6>']	open-ended	direct	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-12T15:09:02.012753	17	103	1556
4	What's the contrast between Mediterranean cruise attractions and challenges?	The Mediterranean offers rich cultural experiences through cruise stops at UNESCO sites like Valletta, Malta, ancient ruins like Ephesus, and historical castles like Bellver Castle, but faces significant monitoring challenges including lack of data availability at local levels, insufficient skilled personnel for data collection, and inadequate political commitment for long-term ecosystem preservation monitoring.	"[""Disney Mediterranean Cruise Excursions\nDisney Cruise Line offers optional excursions at every port of call on its Mediterranean itineraries. With an eye toward pleasing multigenerational passengers, Disney provides select tours for adults only, in addition to its roster of family-friendly experiences. Some ports require tendering, which is a transfer from ship to land by small boat. Itineraries and excursion options are subject to change. A Disney Cruise Line agent or travel agent can provide the most up-to-date information, including current excursion pricing and activity level for those with physical limitations.\nDisney's four-night Mediterranean cruise departs from Barcelona and docks in Palma and Mallorca, Spain, and Villefranche-sur-Mer in France, a beach resort close to Monaco and Nice. Families enjoy a guided tour of Monaco, including a short train ride and visit to the Prince’s Palace of Monaco. The city of Cannes is along the westerly route, famous for its prestigious film festival held every year since 1947.\nFor some time to yourself, try the adult-only tour of Palma’s Bellver Castle, built in the 1300s by King James II. You can also visit the Florianapolis WIne Cellar on Mallorca’s east side, where the Mediterranean climate flavors French wine housed in sandstone caves.\nFive- and Seven-Night Cruises\nDisney’s five-night cruise visits Villefranche-sur-Mer, France, as well as La Spezia, Italy, with an excursion that includes a 2 1/2-hour car ride through Tuscany to the towns of Pisa and Florence. The tour features a culinary adventure in the restored medieval town of Lucca and a chance to see genuine dinosaur fossils in the Castle of Lerici. The last stop on this cruise take you to Civitavecchia, where you can explore Forte Michelangelo, a defensive structure commissioned by Pope Julius II that contains a tower designed by Michelangelo.\nThe seven-night cruise is almost identical to the five-night, with an additional stop at Naples. From this port you can travel to Positano or tour the ancient ruins of Pompeii, Mount Vesuvius, and the excavated city of Herculaneum.\nThe nine-night Mediterranean Cruise, which departs from Venice, sails an entirely different course, taking visitors through Grecian cities for a taste of both ancient history and modern culture. For a walk through time, visit the Acropolis, built at the end of the 5th century, B.C., and the adjacent New Acropolis Museum. This eight-hour tour includes a culinary or family excavation option.\nIn addition to Greece, the ship stops in Kusadasi, Turkey, where visitors flock to ancient Ephesus. Take a half-hour car ride to the site of the ruins and participate in a 2 1/2-hour tour on foot, enjoying archaeological wonders, local cuisine and an interactive Roman-style feast.\nDeparting from Barcelona, the 12-night cruise blends many of the ports of call from the shorter cruises, including France, Italy, Greece and Turkey, but is the only Disney Cruise Line option that also sails to the baroque city of Valletta, Malta, a UNESCO World Heritage Site. Guests can swim with dolphins at the Mediterraneo Marine Park, take a boat trip along the Blue Grotto, or participate in the four-hour “History Hunt” that takes participants on a trekking adventure across the capital.\n- Comstock/Comstock/Getty Images"", 'The great wealth of ecological and cultural heritage and the beauty of the marine and coastal destinations on the Mediterranean Sea attract an increasing flow of tourists from all over the world every year. The European Environment Agency asserts that rising temperatures could result in better conditions for beach tourism, on average, across Europe. The beach season will indeed stretch into spring and autumn in southern regions. On the other hand, according to a European study published in 2015, under current economic conditions, the climate could lower tourism revenues by up to 0.45 % of GDP (Gross Domestic Product) per year in the southern EU Mediterranean regions, while northern European regions would gain up to 0.32% of GDP.\nIn light of these observations, it appears that the population’s current and increasing willingness to tackle the tourism challenges that we now face is being offset by serious drawbacks:\n- lack of data availability, especially at local level;\n- low level of understanding of pressures affecting marine and coastal areas, such as climate change mitigation, ecosystems fragility, mass tourism and seasonality, coastal erosion, micro plastic in the sea, water scarcity;\n- lack of political commitment and financial investments to ensure long-term monitoring of processes through an integrated and holistic approach;\n- low level of skilled and qualified human resources, to properly manage measurement and data collection, mainly in compiling and assessing surveys and questionnaires.\nSo far, with regard to the most relevant existing monitoring systems and tools at international and European level, it seems that the criteria used are not sufficiently targeted to wholly fulfill the specific needs of Mediterranean coastal destinations, including protected areas. Thus, due to a lack of endorsement at EU level, particularly by EUROSTAT, the credibility of data collection from local level is weak.\nConsidering these alarming trends, how does the situation look for the future of the Mediterranean tourism? How can we preserve the natural ecosystem that attracts so many tourists? How can we promote sustainable and responsible tourism in the face of mass tourism affecting the region?\nIt is therefore interesting to look at some of the current trends. The growing public interest in water-based sports, for instance, such as recreational fishing, boating, windsurfing and diving, not only creates economic potential but also helps redress the problem of seasonality as these activities do not depend on peak seasons. In the same vein, ever-changing demand creates the need for sustainable, innovative products that promote the attractiveness and accessibility of coastal and marine archaeology, maritime heritage, underwater tourism, wine and gastronomy activities – all of which provide unique and customized experiences.\nTherefore, it seems that the most urgent challenge now facing policy makers at regional and local level is to build a strong MED cooperation alliance involving the relevant industry players. Indeed, in order to effectively monitor tourism sustainability, it is crucial to develop a common methodological framework that allows benchmarking and sustainable tourism policies and marketing activities to be improved; and that also provides replicable models that can be used around the Mediterranean region. Destination management organizations should work hand in hand, combining proven monitoring systems with technologies and new indicators such as the carbon footprints, the carrying capacity of tourism coastal destinations, cultural tourism and cruise tourism, culinary experiences, climate change, water consumption and marine eco-systems, to list a few critical issues.\nWith that in mind, this policy factsheet aims to bring together some of the most relevant initiatives and tools that have been developed and tested to effectively monitor tourism sustainability in the Mediterranean.\nRead the full policy factsheet #1\nIn English here\nIn Catalan here\nIn Spanish here\nIn Italian here\nIn French here']"	['<urn:uuid:4de25e44-ff73-4f09-935e-3c4234ff7644>', '<urn:uuid:51f80f63-3e3c-4f2e-9a3a-0e8afa7e6821>']	factoid	direct	concise-and-natural	distant-from-document	multi-aspect	expert	2025-05-12T15:09:02.012753	9	53	1131
5	what is johns hopkins university studying with their environmental health research funding	Johns Hopkins University received funding to compare urban and rural effects of poverty on chronic obstructive pulmonary disease (COPD), and to study the impact of improved dietary intake on preventing or mitigating disease progression.	['News Releases from Region 09\nU.S. EPA and NIH Award $5.1 Million for a New Environmental Research Center at the University of Arizona\nA total of $25.5 million was awarded to five universities nationwide\nSAN FRANCISCO – Today, the U.S. Environmental Protection Agency and the National Institutes of Health (NIH), announced $5.1 million in funding to create a new research center at the University of Arizona (UA) in Tucson, Ariz. UA is among five universities selected nationwide to work with local communities to better understand ways to improve environmental conditions for vulnerable populations.\nThe University of Arizona will set up the “Center for Indigenous Environmental Health Research,” to work with American Indian/Alaska Native communities to examine chemical contamination of traditional foods, water, air, and household environments, while increasing environmental health literacy.\n“Exposures to harmful contaminants in low-income communities is an ongoing problem in our country,” said Michael Slimak, director of EPA’s Sustainable and Healthy Communities Research Program. “With the support of these centers of excellence, EPA is working to address this issue and protect human health.”\nEnvironmental health problems are more likely to occur in communities that have ongoing exposure to multiple sources of pollution. These communities are usually economically disadvantaged with limited access to quality healthcare.\nEach university will establish a center of excellence on environmental health disparities research, which will conduct multidisciplinary research to mitigate and prevent health disparities driven by environmental causes. This research will focus on understanding the relationships between biological, chemical, environmental, genetic and epigenetic, and social factors.\nThe new centers, funded by five-year grants, are an expansion of a successful pilot program originally started by EPA and the National Institute of Minority Health and Health Disparities. EPA’s contribution to this research partnership will be $7.5 million, with $18 million from three institutes at the NIH (NIMHD, NIEHS, and NICHD).\nIn addition to UA, the following universities received funding:\n- University of Southern California, Los Angeles, Calif., “Maternal and Developmental Risks from Environmental Social Stressors,” for studying how environmental factors may contribute to childhood obesity and excessive weight gain during pregnancy in Hispanic and Latino communities.\n- Harvard T.H. Chan School of Public Health and Boston University School of Public Health, Boston, Mass., “Disparities in Exposure and Health Effects of Multiple Environmental Stressors across the Life Course,” for studying how housing may affect birth weight, childhood growth trajectories, and risk of death from cardiovascular disease, and whether improved urban housing may benefit health.\n- Johns Hopkins University, Baltimore, Md., “Comparing Urban and Rural Effects of Poverty on COPD,” for comparing urban and rural effects of poverty on chronic obstructive pulmonary disease (COPD), and the impact of improved dietary intake on preventing or mitigating disease progression.\n- University of New Mexico Health Sciences Center, Albuquerque, N.M., “Center for Native American Health Equity Research,” for examining how contact with metal mixtures from abandoned mines affects rural Native American populations through exposures related to inadequate drinking water infrastructure, reliance on local foods, and other uses of local resources to maintain their traditional lifestyle and culture.\nMore information about these grants: https://www.epa.gov/research-grants/currently-funded-grantees-centers-excellence-environmental-health-disparities\nInformation about EPA’s health research: https://www.epa.gov/healthresearch\n# # #']	['<urn:uuid:564653a0-849e-46f5-ad5a-84cbc9da8be2>']	factoid	with-premise	long-search-query	similar-to-document	single-doc	novice	2025-05-12T15:09:02.012753	12	34	522
6	self sustaining capabilities survivalist silo complex kansas	The silo has carefully planned water and power sources including primary and secondary generators, wind turbines, and a battery bank. It features farms that don't require sunlight to provide fresh vegetables and fish, and one whole level for storing powdered food. The 14 units are designed for people to live there for five years without outside contact.	"['When looking for a new home, many people consider things like the safety of the area, the nearness to public transportation or the quality of the neighborhood school.\nSome other people -- survivalists for example -- may pick a home that can protect them against nuclear explosions, terrorist attacks or a breakdown in law and order.\nA survivalist is a person who believes that government and society will soon fail completely. They store food and water, weapons and power sources to survive when that happens.\nThese people might want to live in a special condominium, or condo, in the United States.\nTwo reporters for VOA News recently visited a facility near the town of Concordia, Kansas. In that town, costly condos have been built inside a missile silo that is no longer used.\nIn the wilderness of northern Kansas, you can find heavily armed guards, armored vehicles, high-resolution cameras and gun stations. If you think this is a military center, think again.\nThis was once an Atlas intercontinental ballistic missile silo. The silo was part of the U.S. defense system during the Cold War.\nDeveloper Larry Hall bought the silo after it was decommissioned in 1965. He has turned it into a world of comfortable, high-class living inside.\n""What we\'ve got here is an Atlas F missile silo, that in terms of capabilities, is pretty amazing. It would cost $120 million to reproduce what we start with.""\nThe center has 14 levels connected by an elevator. It has a 25-meter-long swimming pool, a high-end movie theater and a rock climbing wall.\nThe center is meant to work if the grid goes down, meaning if the power systems, or grids, in the U.S. are unable to supply people with power. The silo has very carefully planned water and power sources in the form of generators, batteries and wind turbines.\n(LARRY HALL) ""If we lost the grid connection, we got the primary generator, (and) secondary generator. We have our own wind turbine, and we have a battery bank.""\nThe 14 units are designed so people can live here for five years without any contact with the outside world. One whole level is used for storing powdered food. There are also farms that do not require sunlight. These guarantee that residents have a lasting supply of fresh vegetables and fish.\nYou can even pick your view out the window. The electronic windows in the facility cost $15,000 each. They help to reduce any unease about living underground for a long period of time by supplying pictures of different seasons and different cities.\n(LARRY HALL) ""If you want, you know, spring, summer, winter and fall in New York City, you can live in New York City. If you want to be in San Francisco or any place else, we use a Red One camera, in high-definition format, and we record it for 24 hours.""\nSo, how much does it cost to live underground in a missile silo? A home with more than 170 square meters of floor space starts at $3 million. A place half that size costs about $1.5 million. But you have to be rich enough to make a full payment in cash.\nMost people living there use their condos as a vacation home. Two children named Leighton and Luke are spending their summer here.\n(LEIGHTON) ""I feel like nobody else because nobody else gets to be in an underground silo and have awesome stuff like a rock wall.""\n(LUKE) ""It feels like sometimes you are not even underground; like you are just in, like, a normal house.""\nThe first Survival Condo Project is completely filled. A second silo is now being built. And half of those homes have already been sold.\nUnderground living in a missile silo may make the owners feel secure. But, it is only for those who can afford it.\nI’m Anna Matteo.\nEnming Liu and Lin Yang reported this story from Concordia, Kansas. Anna Matteo adapted it for Learning English. Mario Ritter was the editor.\nWords in This Story\nmissile silo – n. a very deep, underground launch station for a missile\nballistic – adj. describing something shot through the sky for great distances\ndecommissioned – v. to officially stop using (a ship, weapon, dam, etc.) : to remove (something) from service\ngrid – n. the system of providing electricity to large areas : examples : “He lives off the grid and uses only the power he makes himself.” If the grid goes down and there is no longer any power sources, will you be ready?”\ngenerator – n. a device that uses a motor to produce electricity\nbattery – n. a device for storing energy or electricity\nturbine – n. an engine with parts that spin because of air water or steam pressure\npowder – n. something (as a food, medicine, or cosmetic) made in or changed to the form of a powder\nhigh-definition – adj. having a very clear picture and a wide screen']"	['<urn:uuid:7152d304-ad9b-4ab0-8651-a74fe5956bbd>']	factoid	direct	long-search-query	distant-from-document	single-doc	expert	2025-05-12T15:09:02.012753	7	57	829
7	technical sql dev needing understanding difference between mysql transactions vs mysql acid properties implementation	While transactions are logical units of work containing SQL statements that are either all committed or rolled back in the database, ACID properties are specifically the set of properties (Atomicity, Consistency, Isolation, Durability) that guarantee data validity in database transactions. In MySQL's MyISAM engine, transactions are not supported - only table locks are available, without row-level locks or MVCC capabilities. This makes it impossible to ensure full ACID compliance in MyISAM tables.	['Before we jump into the complex detailing of MyISAM, it’s time to learn some of its important characteristics:\n- MyISAM stores each table in two files — one containing data, and the other, indexes. The extensions of these two files’ names are\n.MYIrespectively. Using the\nINDEX DIRECTORYoptions to the\nCREATE TABLEquery, you can put the above mentioned two files in different directories. These two directories, put on different disks, can offer significant performance improvement. This technique is often used in case of very heavily loaded databases, and is supported by many databases.\n- The data stored in these files is platform-independent — or, more technically put, is not dependent on the endianness of a machine. In other words, you can simply copy (literally) data and index files from an Intel x86/x64 machine to PowerPC or Sun SPARC.\n- MyISAM doesn’t support transactions. Only table locks are available. Row-level locks, which are a must for MVCC capabilities (transactions, to put it in simple words) are not available in MyISAM.\n- All the readers (with\nSELECTfamily of queries) have to obtain read locks. Multiple users can acquire read locks at the same time; hence, the common term shared locks is frequently used.\n- All the writers have to obtain exclusive locks. In simple words, two users cannot perform writes (\nDELETEfamily of operations) at the same time. This is very important to remember. A write operation must finish very quickly. Otherwise, in case of a database with a heavy load, there will be a long queue of connections waiting for exclusive (write) lock. In general, write operations are not time-consuming; however, the indexing strategy plays a role here. More on this later.\n- One great feature offered by MyISAM is called concurrent inserts. These allow the insertion of new records while\nSELECT-family queries are running. However, as insertion requires an exclusive lock, only one user can perform concurrent inserts.\n- MyISAM supports full-text index.\n- MyISAM supports compressed tables. When a table is compressed using the\nmyisampackutility, individual rows are compressed and not the entire table as a single entity. Please remember that compressed tables are read-only. When a\nSELECTquery is issued on a compressed table, rows are decompressed based on the requirement. A query causing a full-table scan can be a disaster in such a case; however, a well-indexed table performs pretty well. Compressed tables are a great utility when distributing a database on space-constrained media like CDs.\n- MyISAM permits NULL values in indexed columns.\n- Each character (\nVARCHAR) column can have a different character set. For instance, in one column you may store ASCII character values, and in the other you may store UTF-8 or UTF-16 values.\nUnderstanding the B-tree\nAnybody dealing with a respectable database-management system must have heard the term “B-tree”. Some systems and databases also use the notion of B+tree. What is it and how does it fit into the picture of database-management systems? Here is what Wikipedia says on the topic:\nIn computer science, a B-tree is a tree data structure that keeps data sorted and allows searches, sequential access, insertions, and deletions in logarithmic amortised time. The B-tree is a generalisation of a binary search tree, in that a node can have more than two children. Unlike self-balancing binary search trees, the B-tree is optimised for systems that read and write large blocks of data. It is commonly used in databases and filesystems.\nFigure 1 shows a very simple B-tree. Notice the difference between conventional binary search trees and a B-tree. A B-tree is not “binary”, that is, each node having 2 child nodes. Essentially, a B-tree allows storing data in a manner so that searching records, inserting new ones, and deleting existing ones is very fast.\nNow, let’s come back to the question about what the relationship between MyISAM and a B-tree is, and how you can write better queries by getting details on this subject.\nThe B-tree index\nWhen you create an index in a MyISAM table, its type is B-tree. Figure 2 shows how MyISAM stores the index(es) in the .MYI file and data in the\nDon’t be bothered if this appears a bit daunting. The following is a description of how data and indexes are stored in case of B-tree indexes, in MyISAM tables:\n- On top, we have the root node of the B-tree. This is not specific to MySQL or MyISAM. Every tree has to have a top-level/root node. Traversal starts from this node in most cases. In B-tree terminology, this is called a non-leaf node. Leaf nodes are those that have no child nodes.\n- Below the root node, we have leaf nodes that are connected with the root node. The link between the root node and the immediate children is shown as “pointers”; however, it is not necessary that these be C/C++ style pointers.\n- Figure 2 shows a B-tree with two levels; however, in a real case, the tree may be much more complex, with multiple levels. This representation is to give you a basic idea about how B-tree works in the case of MyISAM.\n- In this figure, three leaf nodes are shown. Each leaf node holds the keys of a different range: 1 to 40, 41 to 80, and 81 to 100. Please note that the set of ranges is purely arbitrary, and meant purely for discussion purposes. This has no connection with how MyISAM breaks down the B-tree.\n- Below the leaf nodes are the actual data pages — i.e., the table data. These are connected with leaf nodes on the basis of key values. This is how searches on a well-indexed table get results at lightning speed.\n- Please note that the link between leaf nodes and data pages, which is marked as “Pointer to Data Pages” isn’t a C/C++ style pointer. Instead, leaf nodes hold enough information required to access the exact position of a row (or rows) in the\n.MYDfile. In other words, data can be read/updated/deleted with the least required file I/O.\n- To make this a little simpler, let’s take an example query:\nSELECT * FROM SOME_TABLE WHERE SOME_COLUMN = 15;\n- It is assumed that the column\n- From the root node, follow the left channel. This is based on simple maths,\n15 < 40. This lands you at the left-most leaf node.\n- In the left node, you will find the key with the value 15.\n- Once you find the key, you’ll know if there is any data in the\nSOME_COLUMN = 15.\n- If so, retrieve the information required to reach that exact location in the\n.MYDfile, to read the row in question.\n- It is assumed that the column\nAfter a close look at Figure 2, you can answer a question that is often a matter of debate — or rather, confusion. Does MyISAM support clustered indexes? The answer is, “NO!”\nIn case of a clustered index, data is stored in a sorted order, which is based on the keys/indexes. This isn’t how MyISAM works. Data isn’t stored in a sorted order. Instead, data is stored in the order in which it is inserted. It is the indexes that are sorted, and these are not stored with data — MyISAM stores data and indexes separately. However, indexes have enough information to point at the exact location of the data in the .MYD file.\nPlease note that in case a MyISAM table contains multiple indexes, all the indexes are stored in the same\nPlease bear in mind that even though B-tree provides a facility for very fast lookup of indexes (and thus the data), everything comes at a cost. You must have heard that indexes improve the speed of searches (\nSELECT family of queries); however, insertions and deletions are slowed down. This is because whenever data is inserted/deleted, MySQL has to alter the indexes in the\n.MYI file. In case there are no indexes, then there is almost no need to deal with the\n.MYI part of a table. In this case, one can experience the fastest insertions, however, at the cost of extremely bad performance of\nPractically, no application relies on this approach. Indexes must be well-thought-out to avoid the cost of B-tree-driven index management while doing insertions/deletions, and yet getting the best results in case of searches. Whenever dealing with indexes, keep index selectivity in mind.\nThough not talked of very often, index selectivity is a very critical issue, and when attended properly, can answer two of the most common questions: why isn’t MySQL using my index, and why isn’t MySQL performing well even when I have properly indexed my table.\nIndex selectivity, in the simplest words, describes how different the values of a column are. This is assuming that the index contains only one column. In case there are multiple columns in an index, selectivity describes how different the values of those columns are.\nSelectivity is a number from 0 to 1 — or think of it as a percentage. A value of 1, or 100 per cent, means that each value in the column is unique. This happens with\nPRIMARY keys, although non-unique fields may have a selectivity of 1. This depends on the nature of values in the column(s) in question.\nSELECTIVITY = NUMBER OF DISTINCT RECORDS / TOTAL NUMBER OF RECORDS\nThis implies that\nPRIMARY indexes always have a selectivity of 1. The higher the selectivity, the faster the searches are going to be. For example, consider the following table:\n|Column name||Data type||Indexed?|\n|email_address||VARCHAR (100)||Yes, Primary|\nWe have two indexes in this table —\ncountry_code — and 10,000 records. Now let’s try to figure out the selectivity:\nemail_address: Being the primary key, all values in this column must be unique. Hence selectivity is 1, an extremely good index.\ncountry_code: Although there are many countries in this world, I am assuming that you have users coming from 100 countries. Selectivity = 100/10000 = 0.01 or 1 per cent. This is too low to serve as a good index.\nLower selectivity is treated by MySQL as an expensive operation. Higher selectivity is treated as an inexpensive operation.\nPlease note that the correct/scientific way to calculate selectivity is to use a production-class database, and find the distinct rows using a\nCOUNT (DISTINCT <COLUMN>)-like query. If you assume that the number of distinct values in a column do not always work well, avoid heuristics as much as possible.\nMySQL has a cost-based optimiser. This means that MySQL calculates the costs of different ways of performing a query, and then chooses the cheapest one. In order to calculate the exact cost, the optimiser would actually have to run the query. If MySQL finds the selectivity of an index (using the above formula) for each query, this will, by all means, kill the machine. So an estimate is taken. This cost-based optimiser uses selectivity when it decides whether or not to use an index. MySQL may not use your index if the selectivity is too low! This means that even when you have an index, MySQL may perform a full-table scan!\nAn index like\ncountry_code, which we discussed earlier, will never be used by MySQL. Another major problem is that it will result in wasteful consumption of CPU time during insertions and deletions too. So, pay attention when you create indexes. Every\nINSERT operation will cause multiple B-tree operations to adjust the country code to keep the B-tree balanced; yet, there’s no use for this while searching the data.\n- High Performance MySQL, Second Edition, O’REILLY, ISBN: 978-0-596-10171-8\n- MySQL Reference Manual for version 5.1', '- How do you write a transaction in SQL?\n- What are 3 properties of acids and bases?\n- Why do we use transactions in SQL?\n- What is a transaction in a database?\n- What are five properties of acids?\n- What is acid property of database?\n- What are the 4 properties of acids?\n- How do you implement transactions?\n- What is a transaction give an example of a transaction?\n- What is acid properties in SQL with example?\n- What are the ACID properties in SQL?\n- What is transaction and its types?\n- What is transaction in DBMS with example?\n- What is acid in mysql?\n- What are 2 properties of acids?\nHow do you write a transaction in SQL?\nFirst, open a transaction by issuing the BEGIN TRANSACTION command.\nBEGIN TRANSACTION; After executing the statement BEGIN TRANSACTION , the transaction is open until it is explicitly committed or rolled back.\nSecond, issue SQL statements to select or update data in the database..\nWhat are 3 properties of acids and bases?\nChemistryPropertyAcidBaseTasteSour (vinegar)Bitter (baking soda)SmellFrequently burns noseUsually no smell (except NH3!)TextureStickySlipperyReactivityFrequently react with metals to form H2React with many oils and fats\nWhy do we use transactions in SQL?\nThe primary benefit of using transactions is data integrity. Many database uses require storing data to multiple tables, or multiple rows to the same table in order to maintain a consistent data set. Using transactions ensures that other connections to the same database see either all the updates or none of them.\nWhat is a transaction in a database?\nA transaction is a logical, atomic unit of work that contains one or more SQL statements. A transaction groups SQL statements so that they are either all committed, which means they are applied to the database, or all rolled back, which means they are undone from the database.\nWhat are five properties of acids?\nAcidsAqueous solutions of acids are electrolytes, meaning that they conduct electrical current. … Acids have a sour taste. … Acids change the color of certain acid-base indicates. … Acids react with active metals to yield hydrogen gas. … Acids react with bases to produce a salt compound and water.\nWhat is acid property of database?\nIn computer science, ACID (atomicity, consistency, isolation, durability) is a set of properties of database transactions intended to guarantee data validity despite errors, power failures, and other mishaps.\nWhat are the 4 properties of acids?\nWhat are four properties of acids? Of bases? Acids taste sour, react with metals, react with carbonates, and turn blue litmus paper red. Bases taste bitter, feel slippery, do not react with carbonates and turn red litmus paper blue.\nHow do you implement transactions?\nSteps in a TransactionLocate the record to be updated from secondary storage.Transfer the block disk into the memory buffer.Make the update to tuple in the buffer buffer.Write the modified block back out to disk.Make an entry to a log.\nWhat is a transaction give an example of a transaction?\nExamples of transactions are as follows: Paying a supplier for services rendered or goods delivered. Paying a seller with cash and a note in order to obtain ownership of a property formerly owned by the seller. Paying an employee for hours worked.\nWhat is acid properties in SQL with example?\nACID Properties in SQL Server ensures Data Integrity during a transaction. The SQL ACID is an acronym for Atomicity, Consistency, Isolation, Durability. In our previous article, we already explained about the Transaction and Nested Transactions.\nWhat are the ACID properties in SQL?\nA transaction in a database system must maintain Atomicity, Consistency, Isolation, and Durability − commonly known as ACID properties − in order to ensure accuracy, completeness, and data integrity.\nWhat is transaction and its types?\nThese four types of financial transactions are sales, purchases, receipts, and payments. … The receipt transaction is recorded in the journal for the seller as a debit to cash and a credit to accounts receivable. Payments are the transactions that refer to a business receiving money for a good or service.\nWhat is transaction in DBMS with example?\nA transaction is a single logical unit of work which accesses and possibly modifies the contents of a database. Transactions access data using read and write operations. In order to maintain consistency in a database, before and after the transaction, certain properties are followed. These are called ACID properties.\nWhat is acid in mysql?\nACID is an acronym that describes four properties of a robust database system: atomicity, consistency, isolation, and durability. These features are scoped to a transaction, which is a unit of work that the programmer can define.\nWhat are 2 properties of acids?\nAcids taste sour, conduct electricity when dissolved in water, and react with metals to produce hydrogen gas. Certain indicator compounds, such as litmus, can be used to detect acids. Acids turn blue litmus paper red. The strength of acids is measured on the pH scale.']	['<urn:uuid:9d88f040-9cb0-4d9f-9bc3-57288b8ec15b>', '<urn:uuid:d743e04b-bb29-4c35-b868-88b1761aad25>']	factoid	with-premise	long-search-query	distant-from-document	comparison	expert	2025-05-12T15:09:02.012753	14	72	2761
8	How does the appearance of a new species in an ecosystem lead to the creation of more species over time?	When a new species appears, it creates multiple new niches that other species can fill. For example, different species can specialize in using the new species' resources - as parasites living in its body, as predators that eat it, as plants growing on its excrement, or as animals using its abandoned shelters. Each of these new species then creates additional niches, allowing for even more species to emerge, continuing this process indefinitely.	"['At least since the days of Darwin, evolution has been associated with the increase of complexity: if we go back in time we see originally only simple systems (elementary particles, atoms, molecules, unicellular organisms) while more and more complex systems appear in later stages. However, from the point of view of classical evolutionary theory there is no a priori reason why more complicated systems would be preferred by natural selection. Evolution tends to increase fitness, but fitness can be achieved as well by very complex as by very simple systems. For example, according to some theories, viruses, the simplest of living systems, are degenerated forms of what were initially much more complex organisms. Since viruses live as parasites, using the host organisms as an environment that provides all the resources they need to reproduce themselves, maintaining a metabolism and reproductory systems of their own is just a waste of resources. Eventually, natural selection will eliminate all superfluous structures, and thus partially decrease complexity.\nComplexity increase for individual (control) systems\nThe question of why complexity of individual systems appears to increase so strongly during evolution can be easily answered by combining the traditional cybernetic idea of the ""Law of Requisite Variety"" and a concept of coevolution, as used in the evolutionary ""Red Queen Principle"".\nAshby\'s Law of Requisite Variety states that in order to achieve complete control, the variety of actions a control system should be able to execute must be at least as great as the variety of environmental perturbations that need to be compensated. Evolutionary systems (organisms, societies, self-organizing processes, ...) obviously would be fitter if they would have greater control over their environments, because that would make it easier for them to survive and reproduce. Thus, evolution through natural selection would tend to increase control, and therefore internal variety. Since we may assume that the environment as a whole has always more variety than the system itself, the evolving system would never be able to achieve complete control, but it would at least be able to gather sufficient variety to more or less control its most direct neighbourhood. We might imagine a continuing process where the variety of an evolving system A slowly increases towards but never actually matches the infinite variety of the environment.\nHowever, according to the complementary principles of selective variety and of requisite constraint, Ashby\'s law should be restricted in its scope: at a certain point further increases in variety diminish rather than increase the control that system A has over its environment. A will asymptotically reach a trade-off point, depending on the variety of perturbations in its environment, where requisite variety is in balance with requisite constraint. For viruses, the balance point will be characterised by a very low variety, for human beings by a very high one.\nThis analysis assumes that the environment is stable and a priori given. However, the environment of A itself consists of evolutionary systems (say B, C, D...), which are in general undergoing the same asymptotic increase of variety towards their trade-off points. Since B is in the environment of A, and A in the environment of B, the increase in variety in the one will create a higher need (trade-off point) in variety for the other, since it will now need to control a more complex environment. Thus, instead of an increase in complexity characterised by an asymptotic slowing down, we get a positive feedback process, where the increase in variety in one system creates a stronger need for variety increase in the other. The net result is that many evolutionary systems that are in direct interaction with each other will tend to grow more complex, and this with an ever increasing speed.\nAs an example, in our present society, individuals and organizations tend to gather more knowledge and more resources, increasing the range of actions they can take, since this will allow them to cope better with the possible problems appearing in their environment. However, if the people you cooperate or compete with (e.g. colleagues) become more knowledgeable and resourceful, you too will have to become more knowledgeable and resourceful in order to respond to the challenges they pose to you. The result is an ever faster race towards more knowledge and better tools, creating the ""information explosion"" we all know so well.\nThe present argument does not imply that all evolutionary systems will increase in complexity: those (like viruses, snails or mosses) that have reached a good trade-off point and are not confronted by an environment putting more complex demands on them will maintain their present level of complexity. But it suffices that some systems in the larger ecosystem are involved in the complexity race to see an overall increase of available complexity.\nComplexity increase for global (eco)systems\nThe resoning above explains why individual systems will on average tend to increase in complexity. However, the argument can be extended to show how complexity of the environment as a whole increases. Let us consider a global system, consisting of a multitude of co-evolving subsystems. The typical example would be an ecosystem, where the subsystems are organisms belonging to different species.\nNow, it is well-documented by ecologists and evolutionary biologists that ecosystems tend to become more complex: the number of different species increases, and the number of dependencies and other linkages between species increases. This has been observed as well over the geological history of the earth, as in specific cases such as island ecologies which initially contained very few species, but where more and more species arose by immigration or by differentiation of a single species specializing on different niches (like the famous Darwin\'s finches on the Galapagos islands).\nAs is well explained by E.O. Wilson in his ""The Diversity of Life"", not only do ecosystems contain typically lots of niches that will eventually be filled by new species, there is a self-reinforcing tendency to create new niches. Indeed, a hypothetical new species (let\'s call them ""bovers"") occupying a hitherto empty niche, by its mere presence creates a set of new niches. Different other species can now specialize in somehow using the resources produced by that new species, e.g. as parasites that suck the bover\'s blood or live in its intestines, as predators that catch and eat bovers, as plants that grow on the bovers excrements, as furrowers that use abandoned bover holes, etc. etc. Each of those new species again creates new niches, that can give rise to even further species, and so on, ad infinitum. These species all depend on each other: take the bovers away and dozens of other species may go extinct.\nThis principle is not limited to ecosystems or biological species: if in a global system (e.g. the inside of a star, the primordial soup containing different interacting chemicals, ...) a stable system of a new type appears through evolution (e.g. a new element in a star, or new chemical compound), this will in general create a new environment or selector. This means that different variations will either be adapted to the new system (and thus be selected) or not (and thus be eliminated). Elimination of unfit systems may decrease complexity, selection of fit systems is an opportunity for increasing complexity, since it makes it possible for systems to appear which were not able to survive before. For example, the appearance of a new species creates an opportunity for the appearance of species-specific parasites or predators, but it may also cause the extinction of less fit competitors or prey.\nHowever, in general the power for elimination of other systems will be limited in space, since the new system cannot immediately occupy all possible places where other systems exist. E.g. the appearance of a particular molecule in a pool of ""primordial soup"" will not affect the survival of molecules in other pools. So, though some systems in the neighbourhood of the new system may be eliminated, in general not all systems of that kind will disappear. The power for facilitating the appearance of new systems will similarly be limited to a neighbourhood, but that does not change the fact that it increases the overall variety of systems existing in the global system. The net effect is the creation of a number of new local environments or neighbourhoods containing different types of systems, while other parts of the environment stay unchanged. The environment as a whole becomes more differentiated and, hence, increases its complexity.\nHeylighen F. (1996): ""The Growth of Structural and Functional Complexity during Evolution"", in: F. Heylighen & D. Aerts (eds.) (1996): ""The Evolution of Complexity"" (Kluwer, Dordrecht). (in press)\nT.S. Ray: An evolutionary approach to synthetic biology\nDam McShea and the great chain of Being: does evolution lead to complexity?\nW. Brian Arthur: ""Why Do Things Become More Complex?"", Scientific American, May 1993\nPRNCYB-L discussion on Requisite Variety, Complexity & the edge of Chaos']"	['<urn:uuid:f5fd6345-cd84-473c-98d7-a1dcedb40fc2>']	factoid	direct	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-12T15:09:02.012753	20	72	1475
9	How will Antarctic climate patterns shift as ozone levels recover?	As ozone levels recover over the next half century toward pre-ozone hole concentrations, significant changes in Antarctic climate patterns are expected. While the ozone hole has been holding back the effects of greenhouse gas increases on Antarctica by strengthening winds and increasing sea ice in some regions, this moderating effect will not last. Scientists project that by the end of the 21st century, when ozone levels have recovered, there will be approximately one-third less Antarctic sea ice. Currently, the ozone hole has complex effects - cooling the stratosphere, strengthening the polar vortex, affecting wind patterns through the Southern Annular Mode (SAM), and influencing ocean circulation and sea ice coverage. These effects will diminish as the ozone hole heals due to the Montreal Protocol's restrictions on ozone-destroying chemicals.	['Featured Stories, MIT, News | July 27, 2016\nThe Third Annual Meeting of the Ozone and Climate Project\nOn June 7-8th, 2016, oceanographers, marine biogeochemists, atmospheric scientists and climatologists from across the world converged on MIT for the third annual meeting of the Ozone and Climate Project in the Edwin Gilliland Auditorium.\nThe five-year project aims to understand the Antarctic ozone hole’s impact on Antarctica and the Southern Ocean, and its importance in the global picture of climate change. Overall, researchers agree that this region plays a key role in heat and carbon exchange between the atmosphere and ocean. Here, the ocean upwells cold, carbon-rich water from the deep, as well as takes up heat and CO2 from the atmosphere. But it is still unclear how the ozone hole has perturbed these processes. This study, funded by the NSF’s Frontiers in Earth System Dynamics program (FESD), explores—through observations, theory and modeling—the climate system’s response to ozone depletion and how it has adjusted as the Earth’s protective stratospheric layer heals.\nThis year, thirty select project members and invited guests led informal and open discussions with the goal of exploring two primary questions: What are the climate impacts of stratospheric ozone depletion and recovery over the Antarctic? And, what are the indicators and mechanisms of these impacts within this atmosphere-ocean-ice-carbon system?\nThe group organized the discussion around three main themes:\n- How does interactive chemistry modify coupling between the stratospheric vortex and the rest of the climate system?\n- How are ocean circulation, ice cover, heat and carbon uptake and biogeochemistry impacted by the ozone hole?\n- How does the ozone hole impact global climate and what are the observable indicators?\nProject investigator and MIT Atmospheric Chemist Susan Solomon recently led a study documenting the Montreal Protocol’s efficacy in curtailing the emission of ozone-destroying chemicals, which is helping to heal the ozone hole. Indeed, “the view out there [with the public] is that the ozone hole problem has been solved,” said John Marshall, the project’s principle investigator and an MIT oceanographer. “But we’re learning a lot about the climate system by observing how it adjusts to the healing of the ozone hole. So I think that’s an important thing to bring out and the other big context is: What’s going on around Antarctica in general?”\nMany of the researchers in attendance like Solomon, Darryn Waugh and Lorenzo Polvani have been working together on this and similar ozone issues for decades, so there was a healthy dialogue amongst them. One topic that kept being raised during the conference was the need to “get ozone right” in the models i.e. the correct atmospheric response to changes in its concentration and location. “Ozone is a tough thing to deal with in the climate models. A distribution can be prescribed from data for recent years, but we have limited observations prior to 1986,” said Solomon. As the ozone hole develops, the polar vortex cools and strengthens, causing dynamical changes in the stratosphere like SAM (Southern Annual Mode, which helps to drive the strength and position of the Westerly winds circling around Antarctica) and the Jetstream position and strength. But as Solomon explained during the conference, the polar vortex moves around, which isn’t simulated in a couple of the frequently-used models, but, “simply prescribing ozone from data, whether zonally averaged or not, means that the polar vortex in the model will not be in the same place as the polar vortex as the data.” While there is the option to incorporate interactive chemistry into the models, so that everything’s consistent, there are cost and time trade-offs. “It’s an ongoing question how much of a problem that is, and what to do about it,” she said.\nOther members like Marshall and Yavor Kostov, a postdoc at Oxford and recent MIT PhD graduate, were among several those whose work addressed the ocean-sea ice relationship in the context of ozone forcing. Kostov proposed that under ozone depletion and an increase in SAM with its associated winds, ocean surface temperatures cool, which could be responsible for sea ice expansion around Antarctica, in general. Some, like Marika Holland of NCAR, emphasized the importance of specific regions, such as ice cover in the Ross Sea.\nAnother area of research that the group is contributing to is heat and carbon uptake as well as biogeochemical impacts in the Antarctic region that could be affected by the ozone hole. Groups from Johns Hopkins, the University of Reading, CU-Boulder and MIT, in particular, focused on these aspects. One of the questions addressed was whether the Southern Ocean is a sink of anthropogenic carbon or not. Jon Lauderdale, an MIT postdoc in oceanography, spoke about how one quantifies competing mechanisms that affect air-sea carbon fluxes. Some investigators have found that the strength of this sink may have been weakening, but is now recovering. This may be due to effects from the ozone hole or potentially natural variability. However, several presentations like Anand Gnanadesikan’s, Nikki Lovenduski’s and David Ferreira’s, showed that the ozone hole had little net impact on carbon uptake.\nTake-Aways and Final Impressions:\nDiscussions throughout the FESD conference were lively and, while there is still much research left to do, many felt optimistic for the future of research surrounding the ozone hole and the Antarctic region. “I think it’s a really exciting time to be in Southern Ocean science because you’ve got high-powered models, that are getting better and are free,” Lauderdale said. “Free, meaning, you’re actually simulating the things you want to simulate, rather than parameterizing or imposing them, like interactive chemistry and the biogeochemical cycles.” Additionally, more ARGO floats are coming online with abilities for biogeochemical sensing and floats that can stay under the sea ice, getting readings in areas and seasons that were previously unattainable. “We’re just collecting so much more data, so much more regularly and with more extensive coverage in unusual places. [With this], I think we’ll get a very good idea for what the baseline is,” he said.\nMIT’s Susan Solomon was encouraged by the progress made by the project, and plans to incorporate some of the issues raised by Ozone and Climate Project attendees into her own future research. “I thought the workshop was very stimulating—lots of diverse ideas from people at a range of institutions always bring out the best in science.”\nRead more about the presenters’ work here.', 'Reporting in the journal Geophysical Research Letters scientists from British Antarctic Survey (BAS) and NASA say that while there has been a dramatic loss of Arctic sea ice, Antarctic sea ice has increased by a small amount as a result of the ozone hole delaying the impact of greenhouse gas increases on the climate of the continent.\nSea ice plays a key role in the global environment – reflecting heat from the sun and providing a habitat for marine life. At both poles sea ice cover is at its minimum during summer. However, during the winter freeze in Antarctica this ice cover expands to an area roughly twice the size of Europe. Ranging in thickness from less than a metre to several metres, the ice insulates the warm ocean from the frigid atmosphere above. Satellite images show that since the 1970s the extent of Antarctic sea ice has increased at a rate of 100,000 square kilometres a decade.\nThe new research helps explain why observed changes in the amount of sea-ice cover are so different in both polar regions.\nLead author Professor John Turner of BAS says,\n“Our results show the complexity of climate change across the Earth. While there is increasing evidence that the loss of sea ice in the Arctic has occurred due to human activity, in the Antarctic human influence through the ozone hole has had the reverse effect and resulted in more ice. Although the ozone hole is in many ways holding back the effects of greenhouse gas increases on the Antarctic, this will not last, as we expect ozone levels to recover by the end of the 21st Century. By then there is likely to be around one third less Antarctic sea ice.”\nUsing satellite images of sea ice and computer models the scientists discovered that the ozone hole has strengthened surface winds around Antarctica and deepened the storms in the South Pacific area of the Southern Ocean that surrounds the continent. This resulted in greater flow of cold air over the Ross Sea (West Antarctica) leading to more ice production in this region.\nThe satellite data reveal the variation in sea ice cover around the entire Antarctic continent. Whilst there has been a small increase of sea ice during the autumn around the coast of East Antarctica, the largest changes are observed in West Antarctica. Sea ice has been lost to the west of the Antarctic Peninsula – a region that has warmed by almost 3ºC in the past 50 years. Further west sea ice cover over the Ross Sea has increased.Turner continues,\nGeophysical Research Letters doi:10.1029/2009GL037524, [23 April 2009].\nFloating sea ice caps the ocean around the Antarctic and although it is mostly only 1-2 m thick, it provides effective insulation between the frigid Antarctic atmosphere and the relatively warm ocean below. The ice extent has a minimum in autumn, but by the end of the winter covers an area of 19 million square kilometres, essentially doubling the size of the continent. Instruments flown on polar orbiting satellites have been able to map the distribution and concentration of sea ice since the late 1970s and this study used a new data set of Antarctic sea ice extent created by NASA.\nThe ozone hole was discovered by BAS scientists in the mid-1980s and found to be a result of CFCs in the stratosphere that destroyed the ozone above the continent each spring. The loss of the ozone resulted in marked cooling in the Antarctic stratosphere, which increased the winds around the continent at that level. The effects of the ozone hole propagate down through the atmosphere during the summer and autumn so that the greatest increase in surface winds over the Southern Ocean has been during the autumn. CFCs have a long lifetime in the atmosphere and despite the Montreal Protocol, which has banned the use of CFCs, there is currently no indication of a recovery of springtime ozone concentrations. However, over approximately the next half century there is expected to be a return to the pre-ozone hole concentrations of ozone.\nStrong winds are a major feature of the Southern Ocean with the remoteness of the Antarctic from other landmasses allowing active depressions to ring the continent. The Antarctic continent is slightly off-pole, which results in a large number of storms over the Amundsen Sea (the Amundsen Sea Low) giving average northerly winds down the Antarctic Peninsula and cold, southerly winds off the Ross Ice Shelf. The stronger winds around the continent in Autumn as a result of the ozone hole have deepened the Amundsen Sea Low, giving the positive and negative trends in sea ice over the Ross Sea and to the west of the Antarctic Peninsula respectively. Although there has been a loss of some sea ice to the west of the Antarctic Peninsula, this is negated by the larger increase of ice in the Ross Sea, giving a net increase in the amount of ice around the Antarctic.\nThere has been contrasting climate change across the Antarctic in recent decades. The Antarctic Peninsula has warmed as much as anywhere in the Southern Hemisphere, with loss of ice shelves and changes in the terrestrial and marine biota. The warming during the summer, which has the greatest impact on the stability of the ice shelves, has been linked to the ozone hole and increasing greenhouse gases. Recent research has suggested that the warming extends into West Antarctica. In contrast, East Antarctic has shown little change or even a small cooling around the coast, which is consistent with the small increase in sea ice extent off the coast. The increase in storm activity over the South Pacific sector is also consistent with the pattern of temperature change observed, with warming down the Antarctic Peninsula in the stronger northerly flow.\nThe Cambridge-based British Antarctic Survey (BAS) is a world leader in research into global environmental issues. With an annual budget of around £40 million, five Antarctic Research Stations, two Royal Research Ships and five aircraft BAS undertakes an interdisciplinary research programme and plays an active and influential role in Antarctic affairs. BAS has joint research projects with over 40 UK universities and has more than 120 national and international collaborations. It is a component of the Natural Environment Research Council.\nFurther reports about: > Amundsen Sea > Antarctic Predators > Antarctic continent > Antarctica > BAS > CFCs > Floating sea ice caps > Geophysical Research > NASA > Pacific Ocean > SEA > climate change across the Earth > computer model > global environment > global environmental issues > greenhouse gas > ice cover > ozone hole > polar region > sea ice\nIn times of climate change: What a lake’s colour can tell about its condition\n21.09.2017 | Leibniz-Institut für Gewässerökologie und Binnenfischerei (IGB)\nDid marine sponges trigger the ‘Cambrian explosion’ through ‘ecosystem engineering’?\n21.09.2017 | Helmholtz-Zentrum Potsdam - Deutsches GeoForschungsZentrum GFZ\nControlling electronic current is essential to modern electronics, as data and signals are transferred by streams of electrons which are controlled at high speed. Demands on transmission speeds are also increasing as technology develops. Scientists from the Chair of Laser Physics and the Chair of Applied Physics at Friedrich-Alexander-Universität Erlangen-Nürnberg (FAU) have succeeded in switching on a current with a desired direction in graphene using a single laser pulse within a femtosecond ¬¬ – a femtosecond corresponds to the millionth part of a billionth of a second. This is more than a thousand times faster compared to the most efficient transistors today.\nGraphene is up to the job\nAt the productronica trade fair in Munich this November, the Fraunhofer Institute for Laser Technology ILT will be presenting Laser-Based Tape-Automated Bonding, LaserTAB for short. The experts from Aachen will be demonstrating how new battery cells and power electronics can be micro-welded more efficiently and precisely than ever before thanks to new optics and robot support.\nFraunhofer ILT from Aachen relies on a clever combination of robotics and a laser scanner with new optics as well as process monitoring, which it has developed...\nPlants and algae use the enzyme Rubisco to fix carbon dioxide, removing it from the atmosphere and converting it into biomass. Algae have figured out a way to increase the efficiency of carbon fixation. They gather most of their Rubisco into a ball-shaped microcompartment called the pyrenoid, which they flood with a high local concentration of carbon dioxide. A team of scientists at Princeton University, the Carnegie Institution for Science, Stanford University and the Max Plank Institute of Biochemistry have unravelled the mysteries of how the pyrenoid is assembled. These insights can help to engineer crops that remove more carbon dioxide from the atmosphere while producing more food.\nA warming planet\nOur brains house extremely complex neuronal circuits, whose detailed structures are still largely unknown. This is especially true for the so-called cerebral cortex of mammals, where among other things vision, thoughts or spatial orientation are being computed. Here the rules by which nerve cells are connected to each other are only partly understood. A team of scientists around Moritz Helmstaedter at the Frankfiurt Max Planck Institute for Brain Research and Helene Schmidt (Humboldt University in Berlin) have now discovered a surprisingly precise nerve cell connectivity pattern in the part of the cerebral cortex that is responsible for orienting the individual animal or human in space.\nThe researchers report online in Nature (Schmidt et al., 2017. Axonal synapse sorting in medial entorhinal cortex, DOI: 10.1038/nature24005) that synapses in...\nWhispering gallery mode (WGM) resonators are used to make tiny micro-lasers, sensors, switches, routers and other devices. These tiny structures rely on a...\n19.09.2017 | Event News\n12.09.2017 | Event News\n06.09.2017 | Event News\n26.09.2017 | Life Sciences\n26.09.2017 | Physics and Astronomy\n26.09.2017 | Information Technology']	['<urn:uuid:f45e685e-8e34-4f27-bc64-200aee4661b6>', '<urn:uuid:47a8a303-0bb3-4414-8ecd-ae914d216f96>']	open-ended	with-premise	concise-and-natural	distant-from-document	multi-aspect	expert	2025-05-12T15:09:02.012753	10	127	2687
10	I've inherited some vintage jewelry containing different metals. What's the current regulation on lead content in adult jewelry, and what's the recommended way to store these pieces to keep them in good condition?	While there are no specific laws regulating lead content in adult jewelry, testing has shown concerning levels of metals like cadmium (some pieces containing over 90%). For storage, it's recommended to keep jewelry pieces in separate compartments or pouches to prevent scratching, and use anti-tarnish strips or bags to slow down tarnishing. Regular inspections for loose stones, weak clasps, or signs of damage are also important.	"['Jewellery British English or jewelry American English  consists of small decorative items worn for personal adornmentsuch as broochesringsnecklacesearringspendantsbraceletsand cufflinks. Jewellery may be attached to the body or the clothes. From a western perspective, the term is restricted to durable ornaments, excluding flowers for example.\nAccording to the Consumer Product Safety Improvement Act CPSIA""any children\'s product that contains more than parts per million ppm of lead in any part that is accessible will be treated as a banned hazardous substance. Lead-content limits: Starting on February 10,consumer products intended for children 12 and under were not allowed to contain more than parts per million [PPM] of lead in any accessible part. On August 14,the allowable lead content level dropped to parts per million [PPM].\nConsumer advocates were hopeful cadmium had disappeared from the U. No laws address cadmium in adult jewelry, however, and last year the center decided to check those products. Lab testing found 31 adult jewelry items purchased from retail stores were at least 40 percent cadmium, and most were more than 90 percent, according to results shared exclusively with the AP.\nMost of the time, adulting can be a real drag. But there are some perks, like hosting Pinterest-worthy wine tastingsupgrading your apartmentand finally being able to invest in some quality jewelry. The idea of grown-up accessories may seem dull, and we totally get it — nobody wants to give up fun, playful baubles in the name of being grown. But adding just a few timeless pieces into your mix of colorful earrings, rings, necklaces, and the like will go a long way toward taking your look from dorm room to board room.\nWe opted to directly incorporate the CPSIA-mandated federal lead limit into our developing standard, which was intended particularly to address cadmium content. We also wished for companies to be certain that products manufactured in accord with the completed standard would be in accord with all known assessments of risk. What came out of the hard work of that F\nProducts in our online store are labeled according to the classification chart below. Information on this page covers the basics you need to know to comply with California law. Even if you don\'t live in California, you might need to follow these guidelines.\nExpand your metalsmithing vocabulary and learn how to make convex and concave shapes. Learn embossing, working with dapping tools, hammers, sinusoidal stakes, and more. Students will create shallow formed earrings, two rings, and a concave bracelet.\nThis specification only applies to adult jewelry, which refers to jewelry intended to be worn primarily by people over 12 years of age. Jewelry intended to be worn by people under 12 years of age is covered by the ASTM F specification for children\'s jewelry. The ASTM F specification covers two main types of hazards: the presence of toxic metals and mechanical dangers.\nThough you might think you already know what you need to do to care for your jewelry, chances are there are some tips and tricks — and important factors — that you\'ve never considered before. If you\'ve never had nice jewelry before, caring for the nicer pieces you might acquire as you get older, like engagement rings, fancier necklaces or bracelets, or silver pieces jewelry or not you may inherit from family members, can be kind of a mystery. Maybe you\'ve never really needed to go out of your way to take care of your jewelry before, because it was mostly cheaper, trendier jewelry.', 'Cleaning Tip - How To Clean Your Jewelry\nJewelry holds a special place in our hearts. Whether it’s a sentimental heirloom passed down through generations or a dazzling piece that adds the perfect touch to our outfit, jewelry requires regular care and cleaning to maintain its brilliance and luster. In this blog post, we will unlock the secrets to keeping your jewelry sparkling like new, using simple and effective cleaning techniques while also making sure we aren’t causing damage to our precious pieces. So let’s dive into the world of jewelry cleaning and discover how to make your treasures shine!\n1. Assessing Your Jewelry\nGold and Silver- Both gold and silver jewelry can be cleaned using similar methods. However, silver tends to tarnish more easily and may require additional steps for restoring its shine.\nGemstones- Gemstones such as diamonds, rubies, sapphires, and emeralds are generally durable and can withstand various cleaning methods. However, more delicate gemstones like pearls, opals, and amber require special care and gentler cleaning techniques.\n2. Basic Cleaning Techniques\nFor everyday cleaning and maintenance, consider the following techniques:\nWarm Soapy Water- Prepare a solution of warm water and mild dish soap. Soak your jewelry for a few minutes, gently scrub with a soft-bristle toothbrush, and rinse under running water. Pat dry with a soft cloth.\nClub Soda- Soak your jewelry in club soda for a few minutes, then gently scrub with a soft bristled brush or soft toothbrush. Rinse with water and allow to dry.\nBaby Shampoo- It’s not just for babies! If you have soft, delicate jewelry, mix a few drops of baby shampoo with warm water and use a soft-bristled brush to gently scrub your jewelry. Rinse with water and let air dry.\nUse care, if you choose to use toothpaste, baking soda, or ammonia. Both toothpaste and baking soda can be too abrasive on softer metals and some gemstones. Ammonia is strong and can damage some pieces of jewelry. Ammonia must be very diluted.\nOne option is to use ultrasonic cleaners: Ultrasonic jewelry cleaners use high-frequency sound waves to remove dirt and grime from your jewelry. They are particularly effective for gold, silver, and diamond pieces. Follow the manufacturer’s instructions for optimal results.\nIf you have a particularly delicate or valuable piece, you may want to consider professional cleaning. Jewelers have specialized equipment and expertise to clean and restore your jewelry safely.\nTo ensure the longevity of your jewelry, here are some additional care tips:\nRemove Jewelry Before Activities. Avoid wearing your jewelry during rigorous activities, sports, or household chores. Chemicals, rough surfaces, and sudden impacts can cause damage.\nStorage. Store your jewelry in separate compartments or pouches to prevent scratching. Consider using anti-tarnish strips or bags to slow down tarnishing.\nRegular Inspections: Routinely inspect your jewelry for loose stones, weak clasps, or signs of damage. Promptly address any issues to prevent further damage or loss.\nBy incorporating regular cleaning and proper care into your jewelry routine, you can keep your precious pieces radiant and full of life. Remember to choose the appropriate cleaning method based on the material and gemstone type, and consider professional cleaning for valuable or delicate jewelry. With these tips, you’ll unlock the secrets to maintaining your jewelry’s sparkle and beauty for years to come. Enjoy your dazzling treasures!']"	['<urn:uuid:ef878cdc-1ca4-4089-bf56-d1c419fbcff0>', '<urn:uuid:38999b7f-fa04-456d-b86a-9712df64e2ed>']	factoid	with-premise	verbose-and-natural	distant-from-document	multi-aspect	novice	2025-05-12T15:09:02.012753	33	66	1128
11	sound waves earthquake waves similar different	Sound waves and earthquake waves are similar in their wave-like movement patterns. Both types of waves travel through matter - sound waves move through air, water and other media, while seismic waves move through the Earth's layers. However, earthquake waves come in more varieties (P waves, S waves, and surface waves) and travel much faster than sound waves - P waves can reach speeds of 14,000-25,000 mph through the Earth, while sound waves are much slower. Additionally, earthquake waves can cause physical destruction like collapsing buildings and cracking ground, while sound waves typically just create pressure changes that we perceive as sound.	"[""Importance of sound in human life sound waves are one of the few means available to liquids like water and solvents used in analysis have air and. Meters that measure sound levels work by calculating the pressure of the sound waves analysis is a fairer and sound level meter that's part. Physics for kids waves what is a wave sound is a type of wave that moves through matter and then vibrates our (the people move up and down while the wave. In linguistics, speech is a system once we decide to begin an analysis of speech which means that we can also investigate the properties of the sound waves. Sound waves which consist of a pure tone the direct field of a sound source is defined as that part of the sound field which has 28 fundamentals of acoustics.\nPart c what is the wavelength of a sound wave one octave people satellites observing these waves from space measured if she lives twice as. Sound in filmmaking including the sounds of waves or the swinging of a door, can be used to create a sense accompanying their real lives. This relaxing hd video with ocean sounds is a part of the flat-screen tvs and surround sound 4 hours ocean waves sea waves stunning sound. Applications of waves in your everyday life because of this slowness in the movement of sound waves, your brain is able to help you locate the source of a sound. Examples of sound energy by yourdictionary sound energy is produced when an object vibrates the sound vibrations cause waves of pressure that travel through a medium.\nSound waves, visible light waves, radio that will help us in understanding the physics of waves for many people of a wave » waves and wavelike motion. The sound of waves essay is only a minor part of the characters’ lives by students and provide critical analysis of the sound of waves by yukio.\nThe physics of waves version date - february 15 10 signals and fourier analysis 225 1113 sound waves. Waves is the leading developer of audio plugins for mixing, mastering, post production and live sound, with plugins for pro tools, cubase, logic and other daw audio software. The components of sound after reading this section you will be able to do the following: sound is a wave and waves have amplitude, or height.\nAll of these block some portion of the full spectrum of light which starves a part of our body light and sound wave analysis vibrational light and sound. In sound waves, each air molecule analysis, we will see why this are two dimensional instead of the normal one dimensional linear oscillations also, when. Sound waves travel from the auditory scene analysis (casa) has emerged in part as an effort whether a low-frequency sound is coming from in front of us.\nHuman ear: human ear, organ of the function of the outer ear is to collect sound waves and guide them to the the main part of the ear rudiment is derived from. The importance of sound in our lives people have slowly, over critical control on society's part the integrity of recorded sound is a matter that determines. Part of the energy released produces seis-mic waves, like p, s, and surface waves like sound waves, which compress and expand matter as they move through it.\nGaining knowledge about how speakers work will better help you create sound, and incororate it into our daily lives front of it thus creating sound waves. Some people are born with hearing impairment — and kids and teens can which is the part of the ear you can see the sound waves then travel from the pinna. Exploring light, thermal, mechanical, and sound part i: more about thermal, mechanical, and sound energy in everyday life. Sound localization is a listener's ability to wave front) so sound localization remains possible directional and loudness analysis of this sound. Chapter 5: sensation study people in noisy this theory proposes that neural impulses sent to the brain at the same frequnecy as the sound wave alloe the."", ""- Volcano List\n- Learn More\n- All About Volcanoes\n- Kids Only!\n- Adventures and Fun\n- Sitemap (Under Construction)\nAn earthquake is a sudden, rapid shaking of the Earth caused by the release of energy stored in rocks. This energy can be built up and stored for many years and then released in seconds or minutes. Many earthquakes are so small that they can not be felt by humans. Some, on the other hand, have caused great destruction and have killed hundreds of thousands of people. The pink lines and dots on the map of the world above indicate the regions of earthquake activity.\nThere are two major regions of earthquake activity. One is the circum-Pacific belt which encircles the Pacific Ocean, and the other is the Alpide belt which slices through Europe and Asia. The circum-Pacific belt includes the West coasts of North America and South America, Japan, and the Phillipines.\nOver one million earthquakes may occur each year on the Earth. Most earthquakes last only seconds, but some large quakes may last minutes. About 90% of all Earthquakes are produced at plate boundaries where two plates are colliding, spreading apart, or sliding past each other. When these plates move suddenly they release an incredible amount of energy that is changed into wave movement. Earthquake waves resemble sound and water waves in the manor in which they move. It is these waves that roll through the Earth's crust causing buildings to collapse, bridges to snap, mountains to rise, the ground to fall, and in some cases the ground to open up into huge cracks.\nWhy do earthquakes occur? Scientists believed that the movement of the Earth's plates bends and squeezes the rocks at the edges of the plates. Sometimes this bending and squeezing puts great pressure on the rocks. Rocks are somewhat elastic, they can be bent without breaking. Have you ever stretched a rubberband? You know if you increase the tension too much though, the rubberband will snap!! Rock layers act somewhat the same way, if the pressures becomes too great the rock layer will break and move. When this occurs the layers will move along a crack in the Earth's crust called a fault or the release of energy will cause a new faultline to be produced. This rupture of the rocks and the resulting movement causes an earthquake.\nThis is an aerial photo of the San Andreas fault line in California. The red arrows point to the crack in the crust that is the surface fault. This fault is the boundary between two huge plates, the North American plate and the Pacific plate. The two plates are sliding past each other in opposite directions. This type of plate boundary is called a transverse boundary. A transverse boundary is actually a tear in the Earth's crust. The black arrows represent the directions that the two plates are traveling.\nThis fault line is perhaps the most studied transverse boundary in the world. Many earthquakes each year occur on the San Andreas fault which runs in California from the Mexico border east of San Diego north to the San Francisco Bay area. The next photo shows the destruction that occurred during the 1971 San Fernando earthquake.\nThis aerial photograph shows the destruction that occurred during the February 2, 1971 San Fernando earthquake. The freeway bridge and road were extensively damaged during this shaking of the crust.\nWhen an earthquake occurs an area of the crust will move very suddenly and with a great release of energy. The point of the actual rock rupture is called the focus . The focus is usually found far beneath the surface. The point directly above the focus on the surface of the Earth is called the epicenter.\nWhen the rocks move suddenly they will produce waves in the Earth's crust. These waves move out in all directions and can produce widespread damage on the Earth's surface.\nWhen the rupture of the rock occurs the release of energy causes seismic waves to be produced. Just as wind energy causes waves in water to move across a lake or ocean, seismic waves move through the layers of the Earth. These seismic waves are what produces the destruction that can accompany an earthquake by heaving, shaking, and cracking the ground as they pass through an area. The seismic waves spread out in all directions from the focus.\nCompression waves are one type of seismic wave. They are the first to arrive at the surface of the Earth. Because of this they are given another name, P or Primary waves.\nP waves are the fastest of the seismic waves. They travel at incredible speeds, 14,000 m.p.h at the surface to over 25,000 m.p.h. through the core of the Earth. P waves are even able to pass all the way through the entire Earth.\nWhen P waves strike an object they push and pull the object , like a train engine bumping into a railroad car which then bumps into another and so on all the way through the whole length of the train. This jackhammer movement is the first sign that an earthquake is occurring.\nAs a wave passes through a house, the house is pushed and pulled. If the house is not strong enough it might collapse.\nShear waves reach the surface shortly after the P waves and are given the name S or Secondary waves. S waves travel at about half the speed of P waves. They move objects in their paths in an up and down motion in the direction that the wave is moving.\nS waves can only move through solids and because of this can travel only through the crust and mantle of the Earth. When S waves strike the outer core, which is made of liquid iron and nickel, the waves stop.\nSurface waves are the third type of wave. These are the waves that produce the most destruction. They originate from the arrival of P and S waves at the surface. They are much slower than both P and S waves. Surface waves are limited to travel along only the surface of the Earth, just as waves in a body of water are limited to travel along only the surface of the water.\nThere are two types of surface waves: Love waves and Rayleigh waves. Love waves move in a manner very similar to S waves but the movement to objects in it's path is side to side instead of up and down. Rayleigh waves travel much in the same way as waves in water. Rayleigh waves have an almost circular pattern to its wave motion.\nThe Richter Magnitude is a number that is used to measure the size of an earthquake. The magnitude is a measure of the strength of the seismic waves that have been sent out from the focus. A scientist uses a seismograph to determine the strength of the earthquake. A seismograph is an instrument that measures the amount of ground motion that an earthquake produces.\nEach number on the Richter Scale represents an earthquake that is ten times as powerful as the number below it.\nExamples: An earthquake measuring 6 is ten times stronger than a magnitude 5 quake. An earthquake of a magnitude 9 is 10,000 times more powerful than a 5.\nThe strongest earthquake ever measured was a 8.9 off of the coast of Ecuador in 1906. Earthquakes of 6 and above are considered major quakes. Earthquakes of 7 and above have the ability to do great damage and kill many people.\nEach of the graphs on this page shows an earthquake reading on a seismograph. The waves from an earthquake sets a writing device in motion showing the magnitude and the length of time that the earth is in motion during a quake.\nThe strength or magnitude is recorded in the verical (up and down) lines. The stronger the quake the longer the lines will be drawn on the graph.\nThe duration (length of time) that a quake occurs is represented in the horizontal lines. The duration of the earthquake in the top graph shows a quake lasting about 40 seconds. Each box on the graph is a one minute time duration. The bottom earthquake lasted about one minute and 20 seconds.\nWhich earthquake was stronger??\nWrite your answers to the questions below in complete sentences on a piece of paper. Use the page titles directly under the questions to move through the lesson to find the answers for the questions. When you are finished click on the Earth icon so that the next group can begin the lesson.\n1. How are earthquake waves produced?\n2. What does a Richter Scale show?\n3. What are the differences between compression, shear, and surface waves?""]"	['<urn:uuid:b3ef1cc1-2039-44b0-8483-1f8b5048ecf9>', '<urn:uuid:fa0dc6f1-3f35-4a84-b8b2-b3766f79d32a>']	open-ended	direct	short-search-query	distant-from-document	comparison	novice	2025-05-12T15:09:02.012753	6	102	2148
12	As a software licensing expert, I'm curious about how WordPress's licensing model combines both open source principles and software redistribution rights. Could you explain the relationship between WordPress's GPL licensing and open source criteria?	WordPress is licensed under GPLv2 (GNU General Public License), which aligns with key open source criteria. The license allows free installation, modification, and distribution of its source code. Specifically, it ensures free redistribution without royalties, requires source code availability, permits derived works, and prohibits discrimination against persons or fields of use. The GPL maintains that software must be freely available to distribute and modify, though it may involve minimal fees in certain cases. These principles were inherited from WordPress's predecessor B2/Cafelog, which was also licensed under GPLv2.	"['WordPress is an open source content management system (CMS), which allows users to create dynamic websites and blogs. WordPress is the most popular blogging system on the web and allows to update, customize and manage a website with its back-end CMS and components. This tutorial will teach you the basics of WordPress using which you can easily create a website. The tutorial is divided into various sections for convenience. Each of these sections has related topics with screenshots, which explain the WordPress admin screen.\nWordPress was released on May 27, 2003, by its founders Mike Little and Matt Mullenweg.\nB2 / Cafelog’s successor\nB2 / Cafelog, a blogging tool, was launched in 2001 by Michel Valdrighi, a French programmer.\nThe programming language used to develop B2 was MySQL with PHP. It was specifically designed for writing blogs.\nThe major innovation in B2 was dynamically generating a page from the contents of the MySQL database instead of static web pages.\nIt also used MySQL for databases which provides a search option between the blogs present in the database.\nIt was licensed under the GPL which opened its source-code to everyone.\nIt was an unmistakable site. He worked on B2 until December 2002 and suddenly disappeared. All b2 user communities were concerned about the development work of b2.\nMitchell reappeared in 2003 and later joined WordPress as a contributor.\nBorn of wordpress\nWordPress is the successor and fork (copy of source code) of B2 / CafeLog, founded by Mike Little and Matt Mullenweg. It is also written in PHP language with MySQL.\nMatt Mullenweg, the son of a software engineer, was a user community member of b2. In 2002, he was a college student when he established b2 for the use of his personnel.\nWhen Michel Valdrighi stopped updating B2, Matt decided to fork out the B2 software to do her blogging. He wrote the blog announcing the b2 source-code, and received a reply from Mike Little that he too was interested in forking and would like to work with him.\nOn 1 April 2003, they formed a team of less than 10 members to make their version.\nThe name of the wordpress was suggested by Christine Selleck Tremoulet, a friend of Matt Mullenweg.\nThe name was entirely his idea.\nThe first version of WordPress was released on 0.7 27 May 2003, after thousands of hits from the official SVN repository.\nThe next version was released in 0.1 January 2004, also known as the Davis edition. The name Davis was given by Matt because he has affection for jazz. From now on, all the updates have been named on Jazz.\nMatt also included a plugin called Hello Dolly in every release. The name is a tribute to Louis Armstrong.\nA few months after the announcement of work on B2, some other developers also abandoned B2. They were, b2 evolution by Francois Planck from France and B2 ++ by Donacha O Caome from Ireland.\nDue to various forks, Michelle decided to make WordPress the official branch of B2. On 29 May 2003, Matt invited both b2 ++ and b2evolution to join hands with WordPress. Doncha of B2 ++ became easily involved, but others did not.\nWordPress in current scenario\nWordPress is expanding day by day. It is adding some more features to each of its versions.\nIt is currently the world’s largest self-hosted blogging tool, with millions of users daily. According to a survey, WordPress faces 22.5% of all websites on the Internet. Today these millions of users who may be developers, writers, bloggers or designers, stay out of it.\nWordPress does not yet provide the best usage for mobile users. Currently, very few large enterprises use WordPress as their CMS. This number is gradually increasing day by day.\nAll in all, we can say that the future of WordPress is very bright. Matt himself stated that he envisioned WordPress as the leading operating system in the coming years.\nWordPress is licensed under GPLv2 (GNU General Public License) which makes it free and open-source software. Each copy of WordPress has a license copy.\nThe earlier version of WordPress b2 / Cafelog was also licensed under GPLv2.\nUnder this, GPL is very popular in licensing open-source software. It allows free installation, modification and distribution of its source-code to others. However, it maintains certain rules and laws under it.\nHere free is called freedom and not value. It may impose some minimum fees on certain steps.\nWhat is GPL\nThe GNU software was written by Richard Stallman.\nThe GNU General Public License is abbreviated as GPL. There are certain terms and conditions for copying, modifying and distributing licensed software under its name.\nGNU ensures that any software source-code licensed under it is to make the source code open and freely available to all its users. Here, does not mean cost independently, but means that it is freely available to distribute and modify the code to users, but they cannot impose any restriction on further distribution, source code being made available. is.\nThe software allowing these features falls under the category of free software. And if those rights need to be maintained, then these are called Copylefted. GPL demands both.\nOn 29 June 2007, the third version GNU GPLv3 (version 3) was released. It was discovered to deal with some of the problems that existed in the second edition.\nUpdating the GNU version is optional.Like/Subscribe us for latest updates or newsletter:', 'Open source doesn\'t just mean access to the source code. The distribution terms of open-source software must comply with the following criteria:\n1. Free Redistribution\nThe license shall not restrict any party from selling or giving away the software as a component of an aggregate software distribution containing programs from several different sources. The license shall not require a royalty or other fee for such sale.\n2. Source Code\nThe program must include source code, and must allow distribution in source code as well as compiled form. Where some form of a product is not distributed with source code, there must be a well-publicized means of obtaining the source code for no more than a reasonable reproduction cost preferably, downloading via the Internet without charge. The source code must be the preferred form in which a programmer would modify the program. Deliberately obfuscated source code is not allowed. Intermediate forms such as the output of a preprocessor or translator are not allowed.\n3. Derived Works\nThe license must allow modifications and derived works, and must allow them to be distributed under the same terms as the license of the original software.\n4. Integrity of The Author\'s Source Code\nThe license may restrict source-code from being distributed in modified form only if the license allows the distribution of ""patch files"" with the source code for the purpose of modifying the program at build time. The license must explicitly permit distribution of software built from modified source code. The license may require derived works to carry a different name or version number from the original software.\n5. No Discrimination Against Persons or Groups\nThe license must not discriminate against any person or group of persons.\n6. No Discrimination Against Fields of Endeavor\nThe license must not restrict anyone from making use of the program in a specific field of endeavor. For example, it may not restrict the program from being used in a business, or from being used for genetic research.\n7. Distribution of License\nThe rights attached to the program must apply to all to whom the program is redistributed without the need for execution of an additional license by those parties.\n8. License Must Not Be Specific to a Product\nThe rights attached to the program must not depend on the program\'s being part of a particular software distribution. If the program is extracted from that distribution and used or distributed within the terms of the program\'s license, all parties to whom the program is redistributed should have the same rights as those that are granted in conjunction with the original software distribution.\n9. License Must Not Restrict Other Software\nThe license must not place restrictions on other software that is distributed along with the licensed software. For example, the license must not insist that all other programs distributed on the same medium must be open-source software.\n10. License Must Be Technology-Neutral\nNo provision of the license may be predicated on any individual technology or style of interface.\nLast modified, 2007-03-22']"	['<urn:uuid:3e040c0b-630c-41b1-b7bd-d0127baee2ad>', '<urn:uuid:4d79e0ff-d280-414c-a9a2-d12ed7c70911>']	open-ended	with-premise	verbose-and-natural	distant-from-document	three-doc	expert	2025-05-12T15:09:02.012753	34	87	1406
13	Do VS1 and VS2 diamonds shine differently?	While both VS1 and VS2 diamonds are considered very slightly included and generally appear equally brilliant to the naked eye, VS2 may shine slightly less brilliantly in some cases since inclusions can interfere with light's ability to shine through the diamond.	"['Completely colorless diamonds are extremely rare. While most diamonds may appear to be colorless (white), if examined closely, most have subtle yellow shades that can be seen when comparing two diamonds next to one another or under a jeweler’s loupe or microscope. Colors in a diamond are not always bad, as pink, blue, and black diamonds have become increasingly popular in recent years. As with all precious stones, different diamond colors are a result of trace elements present within the diamond. The GIA has created a color grading scale for “white” diamonds that can help to identify the shade of the diamond (representing how much of the trace elements exist).\nDiamonds are graded according to the GIA (Gemological Institute of America) color chart.\nD,E,F – Colorless. Stone looks completely clear. These are the highest priced stones 求婚戒指. Approximate price for VS1 Clarity, 1 carat round diamond: $15,000\nG,H,I,J – Near Colorless. Some yellow or brown color is visible when the stone is not mounted. When mounted, the stone appears colorless. This range is considered very good value for the money. Approximate price for VS1 Clarity, 1 carat round diamond: $10,000\nK,L,M – Light Yellow. Yellow tint shows. When mounted this still appears tinted. Approximate price for VS1 Clarity, 1 carat round diamond: $5,000\nN-Y – Yellow. Strong yellow color. These stones are not used in much fine jewelry. Approximate price for VS1 Clarity, 1 carat round diamond: Less than $3,500\nZ+ – Fancy. Bright, remarkable color. Usually blue, pink, yellow, etc. Approximate price for VS1 Clarity, 1 carat round diamond: More than $10,000.\nDiamond Clarity is a way to measure the extent of a diamond’s internal flaws. A diamond that does not have many flaws (known as inclusions in the diamond world) is, as one would expect, of higher quality and price. This is because inclusions interfere with the light’s ability to shine through a diamond, making the diamond appear less brilliant. A diamond that sparkles very brightly is likely to have very few inclusions. Grading labs such as the GIA view diamonds under magnification to determine their clarity. The good news is that very small inclusions will not detract from a diamond’s beauty or cause it to be less durable.\nFlawless and internally flawless diamonds make up less than 1% of all diamonds that have been found. Because of their brilliance and shine, they are used in the finest jewelry. Similarly, VVS diamonds are also difficult to find and one will have to pay a premium price to obtain one. As the size of the diamond increases, so does the ability to see inclusions. This makes quality more important as the diamond size increases. The majority of jewelry is made with lower quality diamonds – though these diamonds are great for “fillers” in jewelry, but for the larger stones in rings, earrings, or necklaces, higher quality diamonds should be used. The general diamond clarity scale is shown below:\nFlawless – These diamonds are completely flawless and have no internal or external flaws. They are the most rare of all diamonds.\nInternally Flawless – These diamonds may have external flaws but have no internal. They are still very rare and extremely beautiful diamonds.\nVVS1, VVS2 – Very, Very Slightly Included. These have very small flaws or inclusions that are difficult to see even under a jeweler’s loupe or microscope at 10X magnification.\nVS1, VS2 – Very Slightly Included. These diamonds have inclusions that generally cannot be seen by a naked eye. They are less expensive than VVS diamonds and provide excellent value for the money. Care should be taken with larger diamonds or those with fewer cuts, because some inclusions may be visible.\nSI1, SI2 – Slightly Included. These diamonds have inclusions that are visible either under magnification or the naked eye. They also represent an excellent value, since in certain cuts the inclusions are not necessarily visible by the naked eye. These inclusions, as described previously, do detract from the brilliance of the diamond, so it will not shine as brightly as a VVS or flawless diamond with all the other same characteristics. These should be evaluated carefully before buying, as they are more variable in quality.\nSI3 – Slightly Included to Included. SI3 is only recognized by the EGL and not the GIA or some other labs. An SI3 diamond is often equivalent to a GIA I1 diamond. These diamonds have visible inclusions and are less brilliant than the diamonds above.\nI1 – Included. I1 diamonds generally have one major flaw. The diamond should still shine, but the clarity can be extremely variable. You should exercise a lot of caution when buying one of these diamonds. They can appear to be a great deal – you can buy a large diamond for relatively little money, but once you mount the diamond it may reflect very little light and will not appear to be very “clean” or “shiny.”\nI2, I3 – Included. Included diamonds are the lowest quality diamonds. They may appear to be cloudy from cracks or large inclusions. They should be avoided if at all possible.\nBecause diamonds can be cut to almost any size, diamonds are measured by weight. The standard unit of measurement for diamonds is the carat, which is equal to 0.2 grams. To give an idea of how much a carat is, there are about 2300 carats in a pound. Since carat is still a pretty rough unit of measurement, gemologists have created “points.” There are 100 points in 1 carat. But weight is not the only important factor that determines price. Two diamonds that weigh the same can have very different prices, due to the differences in quality as you learned above.\nWhen diamonds increase in size (especially past 1 carat), the price begins to rise exponentially. This is just because of how rare diamonds are. It’s easy to make small diamonds out of large ones. It’s far less easy to pack together a bunch of small diamonds to make a large one.\nWhen a diamond is found, it looks more like a piece of crystal or sandblasted glass. To make it look like a diamond, the gem is cut and polished by gemcutters or manufacturers that follow a precise method to cut “facets” or small angled pieces on the outer faces of the diamond. The table is the largest facet of the diamond that you would see when looking straight at the diamond. The crown is just below that, and the girdle is the largest or widest part of the diamond. On a round cut diamond, the pavilion is just below the girdle and leads to the pointy tip of the diamond, called the cutlet.\nThe diamond’s cut is a large part of why it shines so brightly and looks so beautiful. A perfectly cut diamond reflects the light back up toward the viewer’s eyes, causing the diamond to look bright and shiny. If a diamond is cut “shallow,” or the distance from the table to the cutlet is shorter than it should be, the light will be reflected away and the diamond will be less brilliant. Similarly, if the diamond is cut too deep, the light will shine out of the pavilion and will not make the top (table and crown) appear bright and lovely.', '~ Difference between VS1 and VS2 ~\nVs1 versus Vs2 diamonds – Quick Study\nGenerally, a VS diamond rating and higher comes with a nice guarantee that you won’t be able to see any inclusions with the naked eye. It’s when you look under 10x magnification using a microscope or jeweler’s loupe you’ll be able to see them.\nNow, if you’re the typical layman you won’t find much. Especially when most people simply look for black spots or scratches, but a trained professional knows exactly what to look for and WILL see inclusions at the VS1-VS2 level under 10x, and sometimes rather easily.\nVs1 versus Vs2 Diamonds – The Answer\nWhat separates the two gradings, is how easily the inclusions are noticed. That’s it! VS2 inclusions under 10x magnification are simply easier to see than Vs1 inclusions. What does that mean?\nIt could have 3 meanings.\n- It means that Vs2 inclusions are a touch bigger, so it’s easier to notice, but it won’t be that much bigger. The VS2 grade is an exceptionally nice clarity ranking.\n- It could mean there are more inclusions making them easier to spot.\n- Lastly it could also means that when comparing the two, the VS1 inclusion is simply hidden better than the VS2 inclusion. Hidden meaning on the the very edge of the diamond, or way down at the bottom. A place that’s harder to notice.\nThat’s it though. When it all comes down to it, VS2 diamonds just have inclusions that are easier to see than VS1 diamonds under 10x magnification. Take a look at the picture below.\nVS diamonds have minor inclusions. No black carbon spots, maybe a white spot here and there, possibly a very small feather, and on a rare occasion you might find the tiniest crack.\nAll inclusions will be so small you’ll need to give your eyes at least 10x magnification to see them , and all flaws will be shown on your grading report.\nVS1 vs. VS2 diamonds when Dealing with Different Shapes\nRound, Marquise and Princess diamonds reflect light pretty well disguising many flaws to the naked eye. However, if the cut of the diamond is not good the facets of the diamond will not reflect the light back up, but instead reflect it elsewhere allowing inclusions to be seen much more easily. No need to worry though, because even if your Round, Marquise or Princess diamond is dull and completely lifeless, if it’s rated a VS1-VS2 clarity you will still need bionic eyes to see any flaws. Assuming it was graded correctly.\nIn fact in all my experience in the diamond industry I have never seen a single flaw with my naked eye when the diamond was graded Vs1-Vs2 in any Round, Princess, Marquise, Pear, Oval, or any other fancy cut EXCEPT the Emerald diamond! Again, this only applies to when the diamond was graded accurately.\nAlthough, I haven’t seen a flaw with my naked eye when there was a Vs1 clarity grading, I have seen 2 emerald diamonds rated Vs2 that I could see the flaw in. Emerald cut diamonds have a very long table (top flat part of diamond), and it’s not the best reflector of light even with the most ideal cut, so given these two conditions, sometimes even in VS2 emerald diamonds you just might be able to see a small scratch or white spot , but the inclusions I saw were on the very edge of the diamond. You would really have to stare and search to see it.\nBe safe when you purchase your diamond.\nAll in all, when you buy a true VS1-VS2 diamond you are buying safe! When I say “buying safe” I’m referring to diamonds graded by GIA, EGL USA, or AGS.\nAlthough it’s a topic for another article, if you purchase a diamond graded by anyone else you’re basically playing roulette on whether or not they accurately graded the diamond. Emerald diamonds are the only exception in my experience.\nThis needs to be made very clear.\nI have seen many VS2 AND VS1 diamonds with inclusions to the naked eye when the diamond WAS NOT graded by either GIA, EGL USA, and/or AGS. Who grades your diamond is VERY important.\nIn fact it’s so important, you would be doing yourself a huge favor by reading our advanced diamond clarity chart page.\nVs1 versus Vs2 Diamonds - Why the Hefty Price Difference?\nDiamonds are graded at the 10x level. Even in diamonds graded flawless you WILL still have inclusions. You would simply have to increase the magnification. No diamond is perfect, and that\'s what gives them their personality and uniqueness.\nSince the gradings are at the 10x level that\'s what the pricing scheme works off of, as well. So when we look at a situation like Vs1 versus Vs2 diamonds, and the answer is as simple as ""how easily inclusions are seen"", realize that very ease at which you see the inclusions, is exactly what makes VS1 diamonds that much more rare than VS2 diamonds, and more rare means more money!']"	['<urn:uuid:2fb2d1c5-4d54-4b3d-a999-d82a07a402fb>', '<urn:uuid:4e08aad8-bed0-4a74-84fb-35c47f79f9fc>']	factoid	direct	concise-and-natural	similar-to-document	comparison	novice	2025-05-12T15:09:02.012753	7	41	2062
14	looking for info about birger jarl military career did he lose battle on neva and what happened after	Birger Jarl was involved in the 1240 Battle of Neva, which ended in defeat against Alexander Nevsky's forces. According to Russian legend, he was wounded in the face during a duel with Prince Alexander, and some speculate that traces of a sword blow found in Birger's cranium might be from this battle. Despite this defeat, Birger went on to have significant military successes, including leading the Second Swedish Crusade that established Swedish rule in Finland, and winning important battles at Sparrsätra in 1247 and Herrevadsbro in 1252.	"['On July 15, 1240, where the Izhora River flows into the Neva, a battle between the Novgorod militia under the command of Prince Alexander Yaroslavich and the Swedish army was held. The date July 15 is given in the Novgorod First Chronicle of the senior version. Thus, when translated into the Gregorian style - July 23. However, the generally accepted date of the battle is July 15 indicated by the chronicler.\nIn the summer of 1240 on the Neva, at the mouth of Izhora River, appeared the ships of Swedish troops which included Swedes, Norwegians, representatives of Finnish tribes, all commanded by duke Birger jarl. Seizure of Neva River mouth and the town of Ladoga opened the access to the governance over the most important part of the trade route from the Varangians to the Greeks. Having disembarked, the Swedes and their allies set their tents and marquees at the confluence of Izahora and Neva.\nHaving received the news on the enemy’s apparition, Novgorod Prince Alexander Yaroslavich decided to take a sudden attack against him. There was no time for gathering an army, so Alexander did now wait for the armed forces sent by his father Yaroslav and for warriors from Novgorod lands. He chose to take field against Swedes with his own armed force, having strengthened it only by Novgorod volunteer troops.\nBefore the campaign the warriors gathered in front of St. Sophia cathedral according to custom, where they were blessed by archbishop Spiridon. Then Alexander came in front of his small force and said: “There are not many of us here, the enemy is strong, but the God is not with force, He is with truth, so follow your Prince”.\nThus, after the blessing, the Russian armed force took field. A young prince directed his force down the Volkhov River toward the Lake of Ladoga where he was joined by a force of Ladoga citizens.\nThe Swedish camp, set up at Izhora mouth, was not guarded because the Swedes had no idea about the approaching Russian army. On July 15 at 11 a.m. Novgorod people attacked suddenly the Swedes. A stubborn struggle lasted until night. Russian cavalry pounced upon the center of the Swedish camp while the infantry attacked the flank situated along the bank and seized three ships. During the battle it was the force of Alexander which took up the initiative. Prince himself, according to chronicles, “left a seal on the face of Birger”. The rest of the defeated Swedish army ran away on the survived ships. Novgorod people lost only 20 men.\nAfter the battle Prince Alexander Yaroslavich was named Nevsky for his generalship and courage.\nThe victory in the Battle of the Neva had a great military and political meaning. Russian army did not let Swedes to cut Novgorod off the sea and occupy the banks of Neva and the Gulf of Finland. Having repulsed the Swedish attack from North, the Russian army prevented possible cooperation of Swedish and German conquerors.\nLit.: Кирпичников А. Н. Две великих битвы Александра Невского // Александр Невский и история России. Материалы научно-практической конференции. Новгород, 1996; То же [Электронный ресурс]. URL: http://www.bibliotekar.ru/rusNevskiy/2.htm; Кирпичников А. Н. Невская битва 1240 года и её тактические особенности // Князь Александр Невский и его эпоха. Исследования и материалы. СПб., 1995. С. 24—30; Повесть о житии и о храбрости благоверного и великого князя Александра // Памятники литературы Древней Руси. XIII век. М., 1981. С. 426—439; То же [Электронный ресурс]. URL: http://hronos.km.ru/dokum/nevski_zh.html.\nBased on the Presidential Library’s materials:', 'Birger Jarl (c. 1210 – 21 October 1266), also known as Birger Magnusson, was a Swedish statesman, jarl, and a member of the House of Bjelbo, who played a pivotal role in the consolidation of Sweden. His first marriage was to Princess Ingeborg of Sweden, which created his base of power. Birger led the Second Swedish Crusade, which established Swedish rule in Finland. Additionally, he is traditionally attributed with the foundation of the Swedish capital, Stockholm, around 1250. Birger used the Latin title of Dux Sweorum (""Duke of Sweden""), and the design of his coronet combined those used by continental European and English dukes.\n|Jarl of Sweden|\n|Tenure||c. 1248 – 1266|\nprobably in Östergötland\n|Died||21 October 1266 (aged 55–56)|\n|Buried||Varnhem Abbey, Västergötland|\nEarly life edit\nBirger grew up and spent his adolescence in Bjälbo, Östergötland, but the exact date of his birth remains uncertain and available historical sources are contradictory. Examinations of his mortal remains indicate that he was probably about 50 upon his death in 1266, which would indicate a birth around 1216. However, his father Magnus Minnesköld is assumed to have died no later than 1210, which would lead to an assumed birth a few years earlier. In any case, he was the son of Ingrid Ylva, who according to Olaus Petri was a daughter of Sune Sik and granddaughter of King Sverker I of Sweden, which would make Birger descended from the House of Sverker. His brothers or half-brothers — Eskil, Karl, and Bengt — were all born long before 1200, and it can therefore be assumed that they had another mother. He was also a nephew of the jarl Birger Brosa from the House of Bjelbo. The combination of this background proved to be of vital importance.\nBirger, thus most likely born at the time of the Battle of Gestilren in 1210 and named after his uncle Birger Brosa (one of the most potent men of the era, who died in 1202), started his career in the mid-1230s by marrying Ingeborg Eriksdotter, the sister of King Eric XI of Sweden according to the Eric Chronicles (Erikskrönikan), following fierce rivalry with other suitors.\nDuring the following 15 years Birger consolidated his position and was probably one of the most influential men years before being formally given the title jarl in 1248 by King Eric XI. Birger was later claimed[by whom?] to have been responsible for a military campaign against the Novgorod Republic that Russians claim ended in a victory by Alexander Nevsky during a battle the Russians refer to as the Neva Battle in 1240. While Swedish sources give no information on the battle at all, a 16th-century Russian legend tells that the Swedish ""king"" was wounded in the face while dueling against Prince Alexander Nevsky himself.\nAlthough Birger Jarl saw many battles, some have speculated that traces of a sword blow in Birger\'s cranium might have originated from this battle. However, the original 14th-century Russian record of the battle gives no information on this at all.\nWhen the papal diplomat William of Modena visited present Sweden around 1248, he urged the Swedish kings to fulfill the rules of the Catholic Church, an exhortation which Birger seems to have taken as a chance to strengthen his position by simply taking the side of the church against other members of his family (alternatively it\'s possible to interpret this as a manifestation of his pious side). This was a choice of historical importance as it was to make Birger a jarl powerful enough to ultimately wind up the office, thus making him the last Swedish jarl ever, even called as the ""first true king of Sweden"" by historians. As this happened during an era when the inherited concept Folkung became more of a political party, it also meant Swedish magnates lost most of their influence which paved the way for a consolidated Swedish kingdom supported by the Pope.\nIn 1247, royal troops led by Birger at the Battle of Sparrsätra (Slaget vid Sparrsätra) fought with Folkung forces led by pretender Holmger Knutsson, son of King Canute II. The Folkungs lost the battle and were unable to resist the central government and its taxes. Holmger Knutsson fled to Gästrikland and was captured there by Birger in the following year. Quickly brought to trial, he was beheaded.\nIn 1249, Birger succeeded in ending a decades-long period of hostilities with Norway. As a part of the Treaty of Lödöse, he also managed to marry off his daughter Rikissa, then only 11 years old, to Haakon Haakonsson the Young, the eldest son of King Haakon IV of Norway. Presumably later that year, Birger led an expedition to Finland, later dubbed as the Second Swedish Crusade, which permanently established the Swedish rule in Finland. On King Eric\'s death in 1250, Birger\'s son Valdemar was elected as the new king while Birger acted as regent, holding the true power in Sweden until his death.\nIn 1252, a year after another victory over the folkungs at the Battle of Herrevadsbro (Slaget vid Herrevadsbro), Birger wrote two carefully dated letters, the first mention of Stockholm interpreted as the foundation of the city or at least some sort of special interest in the location. Neither of the letters give a description of the location, however, and while archaeological traces of older defensive structures have been found there, what did exist on the premises before the mid 13th century remains debated. It has been suggested Birger chose the location for several reasons: Partly to curb domestic magnates by isolating them with a ""lock of Lake Mälaren"", offering a defense to the lands around Mälaren from invading enemies in the process; and to create a commercial bridgehead to attract German merchants. While Birger\'s direct involvement in the foundation of the city remains speculative, it probably was no accident it was founded on the location at this time, as there were alternative passages into Mälaren during the preceding Viking Era; as Crusades, a kind of Viking raids in a Christian disguise, had proven increasingly unsuccessful; and as taking control over the location, traditionally where men supposedly gathered before the ledung, meant old offensive military traditions could be replaced by more ""modern"" commercial efforts directed towards Lübeck. Birger thus combined financial support from Germany with papal political support to consolidate his own position.\nLate life edit\nIngeborg died in 1254 and in 1261 Birger married the Danish queen dowager Matilda of Holstein. Birger died on 21 October 1266, at Jälbolung in Västergötland. His grave in Varnhem Abbey was opened in May 2002.\nThere is a statue of the great duke in his own square Birger Jarls Torg next to Riddarholm Church in Stockholm, erected by Bengt Erland Fogelberg at the expense of the Governor of Stockholm in 1854. There is a cenotaph for him at the base of the tower of Stockholm City Hall. It was originally intended that his remains be removed there, but this was never done. Several other historical structures there are also named for him including the street Birger Jarlsgatan on Norrmalm and the tower Birger Jarls Torn on Riddarholmen. The Hotel Birger Jarl is located in Stockholm\'s Norrmalm neighborhood. He is also the central figure of Bröllopet på Ulvåsa by Frans Hedberg (1865).\nMother unknown edit\nFrom marriage with Ingeborg Eriksdotter of Sweden edit\nThe marriage was contracted relatively near the time when Ingeborg\'s brother the once-deposed Eric XI returned from exile in Denmark in 1234.\n- Rikissa Birgersdotter, born 1238, married firstly 1251 Haakon Haakonsson the Young, co-king of Norway, and secondly, Henry I, Prince of Werle\n- Valdemar Birgersson, born c 1238, king of Sweden 1250–1275, lord of parts of Gothenland until 1278\n- Christina Birgersdotter, married presumably several times, one of her husbands was lord Sigge Guttormsson\n- Magnus Birgersson, born 1240, Duke (of Södermanland), then king of Sweden 1275–90\n- probably: Catherine of Sweden, born 1245, married Siegfried, Count of Anhalt\n- Eric Birgersson, born 1250, Duke (of Småland)\n- probably: Ingeborg of Sweden, born ca. 1254, died 30 June 1302, married John I of Saxony, Duke of Lauenburg in 1270\n- Benedict, Duke of Finland, born 1254, bishop of Linköping\nSee also edit\n- Harrison 2002, pp. 257–58\n- Harrison 2002, p. 271\n- Estimates range from c. 1190 to c. 1210 (Harrison 2002, p. 232).\n- ""Personakt för Birger (Birger jarl) Magnusson, Född omkring 1210 Bjälbo, Östergötland"". Archived from the original on 5 March 2016. Retrieved 29 October 2017.\n- Lindström & Lindström 2006, p. 267\n- Prof. Jan Svanberg in Furstebilder från folkungatid ISBN 91-85884-52-9 pp. 104–106\n- Upon examination of his bones in 2002, it was determined that Birger would have been just around 50 at the time of his death, about 10 years younger than previously believed. See Kari, Risto. Suomalaisten keskiaika. WSOY 2004. ISBN 951-0-28321-5. See page 119.\n- Lindström & Lindström 2006, pp. 191–193\n- Lindström & Lindström 2006, pp. 193–195. See also ""Battle on the Neva"", a 16th-century account of the battle, provided by the Slavic Interest Group of the Society for Creative Anachronism. In English.\n- ""Description of the battle in the First Novgorod Chronicle"". Archived from the original on 27 September 2007.. Hosted by the National Archive of Finland Archived 15 September 2010 at the Wayback Machine. in Swedish. See also original text; in Russian.\n- Lindström & Lindström 2006, pp. 195–198\n- Kari, p. 149.\n- Lindström & Lindström 2006, pp. 201–206\n- Chisholm, Hugh, ed. (1911). . Encyclopædia Britannica. Vol. 3 (11th ed.). Cambridge University Press. p. 981.\n- (except Christine): Jan Svanberg in Furstebilder från Folkungatid ISBN 91-85884-52-9 p 243\n- Harrison, Dick (2002). Jarlens sekel: en berättelse om 1200-talets Sverige [The Century of the Jarl: A History of 13th-century Sweden] (in Swedish). Ordfront. ISBN 978-91-7441-359-5.\n- Lindström, Henrik; Lindström, Fredrik (2006). Svitjods undergång och Sveriges födelse. Stockholm: Albert Bonniers förlag. ISBN 91-0-010789-1.']"	['<urn:uuid:59cac903-7639-4b17-a161-980e9bdfb44c>', '<urn:uuid:2b0de3d2-5b56-4a19-8df5-3259a82d4d39>']	factoid	with-premise	long-search-query	distant-from-document	multi-aspect	novice	2025-05-12T15:09:02.012753	18	87	2225
15	how prevent puppy anxiety with guests	To prevent puppy anxiety with guests, proper socialization during the sensitive period (until 16 weeks of age) is crucial. During this time, puppies should be exposed to various people in a way that creates positive associations, using treats and happy talk. For ongoing prevention, maintain consistent training, provide regular exercise and mental stimulation, and use positive reinforcement techniques. Watch for signs of anxiety like excessive barking, trembling, or hiding, and give the puppy space to retreat if needed. Remember to introduce guests gradually and keep interactions controlled to build confidence.	['Updated: Apr 9, 2021\nAll puppies experience a “sensitive socialization period” in their development.\nEstablished by research as a window of time during which if they are not exposed to things they will encounter throughout their lives or are exposed in a way that is frightening to them, they may be at significant risk of developing undesirable problems when exposed later in life. The generally agreed upon time frame for this window is until approximately 16 weeks of age. By “things” I mean objects, sounds, substrates, people, body handling, other animals, etc. During this period puppies decide what is safe and what is dangerous in their world based on what they have encountered and how pleasant, unpleasant, or inconsequential that encounter was to them.\nTo build confidence two things are important: puppies need to experience all of those things they may come across during their lives, and they need to experience them in a way that is not frightening. Remember that even everyday things can be scary if your puppy has never seen them before. Introduce new objects at a distance that your pup finds comfortable (watch for relaxed body language), and even distract her with something pleasant.\n-Dr. Daniel Mills, Professor in Veterinary Behavioural Medicine\nUniversity of Lincoln, England\nThe default survival setting programmed into an animal’s DNA is fear, it’s the reason deer don’t generally come out of the forest to say hi to us, it aids survival to be fearful of novelty. Despite domestication being on their side, dogs are still animals, and this embedded fear default also holds true. Genetics can play a big role in how resilient our puppies will be to novelty, but when it comes to adopting a rescue many won’t have the luxury of meeting the parents of their puppy (something a good breeder should always do) to gain reassurance that they pup will be predisposed to sociability or otherwise. Fear is very easy to install or strengthen in an animal, and unfortunately it can in some cases be very difficult to overcome. Therefore, everything we do during this time should be to counteract that natural predisposition.\nExposure, or socialization as it’s often called in dog training, is one of the most critical areas of training for your pup so must be done properly to get the desired outcome. The American Veterinary Society of Animal Behaviour supports that the standard of care for puppies should be to receive intentional, properly executed, socialization training before they are fully vaccinated since the benefits to doing so greatly outweigh the risks. You can check out their full position statement here: AVSAB Position Statement On Puppy Socialization\nSo how do we do this right? We change our perspective from “I need to expose my puppy to everything”, instead to “I want my puppy to feel happy about the things to which I’m exposing them” and we always keep safety top of mind.\nWhat are some examples of actively putting time and energy “eggs” into this training “basket” every day?\nGet in the habit of keeping some good treats either in your pocket, or in a treat bag on your waist so you can be ready to capture opportunities outside of deliberate socialization sessions more easily. Your pup is always learning and timing is key to them forming the associations we want. All dogs are born liking food. Some have more refined palates, but if they didn’t desire food they would not be long for this earth, so using food as the pleasantry is a no brainer because we know they intrinsically like it (especially if it’s something really smelly of course!) it’s also fast and easy to deliver.\nPRO TIP: Keeping the treats on you all the time for the first little while helps to remove the sight of your treat bag as the predictor of goodies because it’s always in sight, but it’s not always being used to dole out treats.\nMental and physical safety must be top of mind while doing socialization training. To avoid purposefully overwhelming them (aka throwing them in the deep-end to learn) let them make the choice to get closer to something/someone and explore – follow their lead and you’ll see confidence grow if experiences are kept pleasant.\nSince this development window starts and often closes before your puppy will be fully vaccinated you must take precautions so that they don’t interact with unvaccinated dogs over 20 weeks of age, puppies who may be sick, or encounter the bodily fluids from other dogs who may be sick, unvaccinated, or parasitic. Avoid off leash dog parks, public spaces which tend to be dog dense (even if dogs are leashed) and organic surface areas (like soccer fields or playgrounds) that may be frequently used as a restroom for neighbourhood dogs. Keeping your dog on a paved path/walkway will be best but can be hard if you have a keen explorer on your hands so think ahead to keep your stress low and their safety high.\nSpend time developing a happy emotional response from your puppy every time you enter the room. After you walk into the room start interacting with them using “happy or jolly talk”, provide them with food/treats (toss toward them if shy), get down low, pet, praise and use a toy to play. It won’t take long before you see your pup’s tail wag, or bum wiggle, or paws get “tappy” with a happy anticipating face as soon you enter a room.\nFollow the same procedure as above – once your puppy has noticed the novel thing you’re trying to expose them to count to 2 and then turn on your jolly routine with lots of happy talk, paise, treats and/or toys. Look for that same happy anticipation response as noted in the point above around people, animals, objects, sounds, and surfaces once they’ve had several consistently positive exposure experiences with it.\nPuppies are notably “plastic” during this period of their lives – meaning the brain’s ability to change and adapt because of experiences. Notice when your puppy is startled or surprised by something and actively respond to cultivate happy feelings about the scary thing by turning on your jolly routine. Engage with your pup using happy talk, try to increase the distance by a few feet between them and the scary thing, provide delicious treats, and patting/praise to counter-condition the fright.\nLet your puppy explore at their own pace vs. forcing them to get closer to something new which can hinder resilience development which is the opposite of what we are trying to achieve. Contrary to popular myth you may hear, your dog will not see this as a reward for behaving fearfully, it will simply start conditioning them to have better feelings about the scary thing if we execute properly and consistently.\nGetting our puppy happy about body handling - ears, mouth, paws, tail, etc. can be accomplished in the same manner. Reach for the target body area with a gentle touch, count to 2, then reach into your pocket to provide a treat while still touching. Once they eat the treat remove your touch. Repeat. If the touch is too scary in the beginning, start with just a reach toward the body part and then reach for your treat, gradually work up actual handling.\nKeep your sessions short, but frequent. Puppies can be pokey on walks since there is so much going on for them so don’t plan this time to get your own exercise in or you’ll be frustrated. This is a training session to work on socialization experiences. Aim to cultivate happy feelings about everything they encounter by associating the feeling of an intrinsically reinforcing thing like food that makes their brain feel good with something they have not yet fully formed an opinion about – it’s an extremely impressionable time in their lives so let’s make a good impression, shall we?', 'It’s a familiar story for many dog owners. You’ve got a happy-go-lucky pooch who loves to play, cuddle and spend time with you.\nHowever, as soon as someone comes over to visit, your dog becomes anxious and seemingly out of sorts. They may bark incessantly, pace around the room or even hide under furniture.\nThis scenario is common among dogs of all breeds and ages. It’s important to understand that this behavior is not your dog being “bad” or “stubborn.” It’s simply a sign that your furry friend is experiencing anxiety.\nMany dogs are extremely sociable by nature, but some may struggle with new situations and environments – especially when it comes to strangers in their own homes.\nAs their owner, it falls on you to help your dog feel calm and comfortable in these stressful situations.\nWith a little bit of patience, understanding, and some good old-fashioned training techniques, you can help your furry friend feel at ease when visitors come knocking on the door.\nSo let’s dive into what causes dog anxiety around visitors – and better still, what you can do about it!\nUnderstanding Your Anxious Dog\nDogs are known to be loyal, playful, and friendly animals. However, some dogs may display anxious behavior when they encounter visitors in their home.\nThis can be due to various reasons:\nGenetics and Breed Predisposition\nInherited Traits and Breed Susceptibility contribute to a dog’s anxiety when visitors arrive. Chihuahuas, Poodles and Dachshunds are more likely to be anxious.\nThis could come from their history and how they were bred, or due to genetic disorders that affect the brain. Knowing these factors can help owners take proper care of their furry friends.\nOwners should be aware of their dog’s behavior and adapt accordingly.\nMinimizing loud noises and socializing the pet early on can help reduce the impact of genetics on behavior.\nKnowing breed predispositions can also provide information about health planning and prevent inappropriate training.\nGenetics play a big role in canine anxiety, but environmental factors are just as important.\nSocialization experiences during puppyhood, lifestyle changes such as moving homes or the arrival of a baby, all shape a dog’s outlook towards visitors.\nPositive reinforcement training might be the best solution.\nLack of Socialization\nFido’s fear of visitors may be due to lack of socialization during puppyhood. Without proper exposure to new stimuli, dogs can become anxious, fearful, or aggressive.\nHelping Owners with Their Anxious Dogs\nSocialization is key for teaching them how to handle unfamiliar people and animals. Without it, they may think all strangers are a threat.\nFor a pup who’s never met a visitor, it can be scary.\nPlus, they might take their cues from their owner – if their owner is scared, the dog will be too.\nDog owners need to help their pet get used to new environments, sounds, animals, objects, and people.\nPuppy classes and one-on-one training are great. Also, regular interaction with different individuals can help boost confidence.\nPrevious Trauma or Negative Experiences\nDogs may display defensive behaviors when people enter their home, if they’ve experienced past trauma.\nThis can create unease and discomfort in the dog.\nEvery pup is unique; some may recover quickly while others may become defensive with visitors. It’s important to assess the level of anxiety in the dog.\nIf your dog is anxious around visitors, limit interactions and introduce them in controlled environments.\nThis helps the pup create positive associations with people and reduce anxiety or aggression.\nOwners must remain patient and consistent during the process, as it won’t be fixed overnight.\nInadequate Training and Behavior Management\nInadequate Canine Training and Management can lead to canine-related anxieties during visitor interactions.\nA lack of a stable environment and socializing routine can cause fear or aggression towards unfamiliar people, objects, or sounds.\nHaving no foundation of obedience and behavior commands can also lead to anxiety with visitors.\nTo avoid such behavior issues, it is important to follow proper canine training guidelines from experienced trainers.\nKeeping a consistent schedule of exercise, playtime, meals, and rest can give your dog a sense of security.\nSocialization skills which introduce new things to the dog will help reduce stress when faced with new experiences.\nProviding exposure to different sounds and textures early on can prevent future anxieties.\nRegular behavioral awareness training that focuses on reinforcing good behavior can help dogs become comfortable with guests.\nHealth Issues and Physical Discomfort\nCanines can get anxious during visits due to physical ailments.\nThese could be environmental, illnesses, or traumatic experiences. Symptoms like shaking, sweating, and fever can be signs of their unease.\nDogs with medical conditions can be more prone to anxiety.\nBlindness, deafness, joint pains, and allergies can affect their perception.\nTrauma from neglect or abuse can also be a factor.\nTo create a calming environment, it’s best to engage your pet in activities they enjoy before guests arrive.\nPositive reinforcement techniques, like giving treats, can help encourage better behavior.\nBe sure to consult your vet if you suspect any underlying health issues. This may improve their mood around visitors.\nIdentifying the Signs of Dog Anxiety with Visitors\nTo identify signs of anxiety in your dog when visitors come over, learn about their body language, aggressive behaviors, attempts to escape or hide, excessive barking and panting, as well as destructive or inappropriate behaviors.\nUnderstanding these behaviors can help you alleviate the anxiety your dog may feel and create a more comfortable environment for them and your guests.\nFearful Body Language\nCanines’ Fear and Anxiety Expressions\nWhen dogs feel anxious, they show behaviors that communicate their unease to their owners and visitors. Ear pinned back, tail tucked, body lowered – these are signs of discomfort.\nAlso, frequent yawning or licking lips too much.\nOther Strategies for Dogs’ Apprehension\nBesides body language, shaking or trembling, panting even when not hot – dogs might focus on one object instead of eye contact.\nUnique Ways to Calm Anxious Dogs\nControl your emotions around a fearful dog – upbeat demeanor might worsen the dog’s response.\n- Give them space to retreat.\n- Use gentle methods like treats or games.\n- Lasty, consult a vet about long-term management therapy options.\nBy paying attention to canines’ signals of uneasiness, anxieties can be avoided.\nCanine Hostility Towards Guests\nDogs may feel anxious when strangers enter their home.\nThis may lead to aggression like growling, barking, biting, or jumping.\nIt’s important to recognize the signs of anxiety in your furry friend.\nTelltale signs are pacing, restlessness, trembling, lip licking, excessive yawning, or avoiding contact with strangers.\nKnowing these behaviors can help ensure a stress-free environment for both your dog and visitors. If the behavior is extreme, involve canine obedience experts.\nWhat Causes Anxiety in Dogs Around Unfamiliar Visitors?\nIt may be due to earlier experiences of harm from strangers, but whatever the reason, knowing the cause can help pet owners train their dogs to be calmer around new people.\nMonitor all interactions between your dog and guests, and be prepared to anticipate any aggressive responses.\nTake proactive steps before your visitors arrive. Prepare them beforehand on how to handle meeting your furry best friend.\nAttempts to Escape or Hide\nDogs may try to escape or avoid visitors when anxious. This is known as ‘Escape or Avoidance.’\nLook out for the following signs including trembling, panting, avoiding eye contact, and hiding.\nHere’s how to handle the situation:\n- Give your pet time to adjust by sending them to a quiet spot away from guests.\n- Reintroduce them slowly, monitoring body language and behavior. Don’t pressure them to engage.\n- If anxiety levels rise, stop the introduction. Comfort your pet until they’re calm, without provoking them.\n- Once relaxed, gradually increase contact, with supervised bursts of interaction before longer visits.\nDo this sensitively and patiently.\nSome pets recover quickly; others need more time and support.\nAllow rest between socializing times, and don’t expect immediate results. If symptoms persist, contact a vet.\nExcessive Barking and Panting\nExcessive or persistent barking and panting may show a dog is anxious when they’re around visitors. This can mean they are feeling uncomfortable or overly excited.\nIn some cases, dogs can be agitated, restless, or destructive.\nMonitor your dog’s reaction to guests to see what triggers the behaviour.\nUnfamiliar noises, smells, activities, or environments could be exciting or frightening.\nTo lessen your dog’s stress, give them a calm and comfortable space.\nKeep in mind not all dogs will show distress. Some breeds are more vocal and may bark to communicate with guests.\nDestructive or Inappropriate Behaviors\nCanine anxiety can cause chaos in the home, like damaging objects, tearing bedding, scratching walls, or howling too much.\nWhen visitors arrive, dogs may bark, growl, and jump on them. It’s important to recognize these signs, so you can do something about it.\nDon’t let your dog’s anxiety ruin your guests’ experience. Solve this problem quickly with these effective solutions, or else your visitors will feel like they’re in a scary movie!\nHere are some solutions to help deal with your dog’s anxiety.\nEffective Solutions for Dog Anxiety with Visitors\nTo effectively ease your dog’s anxiety with visitors, you need to slowly expose them to visitors and control their socialization.\nPositive reinforcement training techniques can help your dog associate visitors with positive experiences.\nBehavior modification and desensitization training can also help if your dog’s anxiety is severe.\nYou can also use medications and supplements to alleviate their anxiety, and professional assistance and support are available to help you and your dog through this process.\nSlowly Exposing the Dog to Visitors and Controlled Socialization\nIntroducing canines to new people can be tough if they have social anxiety. Follow these steps for controlled socialization:\n- Supervised introduction: Start with one person in a calm environment.\n- Positive reinforcement: Reward good behaviour with treats or praise.\n- Controlled exposure: Get them used to more people over time.\n- More stimuli: As they become more relaxed, increase the activity and numbers of people.\nRemember, every dog is different. Take it at their pace. This will help them feel confident and at ease when visitors come.\nWatch your pet’s behavior carefully. If they growl or bark, take a step back and start again.\nPositive Reinforcement Training Techniques\nEfficient techniques can help reduce a dog’s visitor-related anxiety. Positive reinforcement strategies create positive associations between guests and pleasant experiences.\nPraise and treats are used to encourage desired behaviors.\nBy focusing on desired behaviors and away from undesired ones, new habits can form.\nClassical conditioning techniques lower fear and strengthen relationships between dogs and visitors.\nTreats and enjoyable activities when visitors arrive condition dogs to associate their presence with pleasure.\nHandler-instigated cues give your dog an idea of what’s next, reducing confusion and stress.\nCertified dog trainers provide personalized training programs to tackle anxieties from earlier stages.\nBehavior assessments pinpoint areas that need intensive training beyond simple commands for improved anxiety mitigation.\nBehavior Modification and Desensitization Training\nFor addressing dog anxiety with visitors, modify behavior and use desensitization training!\nThis technique uses exposure to stimuli to reduce fear or anxiety. Here’s a 3-step guide:\n- Create a calm environment. Play calming music, dim the lights, and provide a safe retreat.\n- Introduce one visitor at a time in a controlled setting. Reward good behavior and avoid punishing bad behavior. Increase visitor numbers as the dog is comfortable.\n- Practice regularly to maintain progress. Inform visitors of the training.\nUse of Medications and Supplements\nDealing with anxious dogs during visits? Meds & supplements can help! Clomipramine, Fluoxetine, L-Theanine, Melatonin, Valerian Root, and CBD oil are all options.\nIntroducing Relievet CBD oil – the pet-friendly solution for your anxious dog! Relievet CBD oil is made with only clean C02-extracted broad-spectrum CBD and organic Coconut MCT oil, bringing together two of the finest ingredients nature has to offer. Stop settling for less than the best and try Relievet CBD oil today for clean, natural relief for anxious dogs!\nAlways follow dosage instructions.\nKeep track of side effects & don’t rely on meds alone – behavior training is important too!\nProfessional Assistance and Support\nWhen your dog has serious issues with visitors coming to your home, an experienced professional with expertise in dog behavior modification can be an effective solution for managing canine anxiety.\nThey can provide customized solutions tailored to the specific needs of individual dogs.\nCertain veterinary clinics or pet stores may offer classes or workshops on managing visitor anxiety in dogs. These classes are taught by certified trainers using positive reinforcement techniques.\nBeforehand, make sure to research and assess providers to ensure they have the relevant qualifications and experience and use safe techniques.\nPrevention and Maintenance Strategies for Dog Anxiety with Visitors\nTo keep your dog from being anxious with visitors in your home, you need prevention and maintenance strategies in place.\nRegular exercise and mental stimulation can help, along with proper socialization and exposure to various stimuli.\nConsistent training and behavior management are also important, as is providing a healthy diet and adequate rest.\nFinally, don’t forget regular veterinary check-ups and health monitoring as part of your strategy.\nRegular Exercise and Mental Stimulation\nRegular physical activity and playtime can release endorphins, which lowers your dog’s anxiety.\nPlus, providing mental stimulation with interactive games and puzzles keeps their mind active and prevents boredom and frustration.\nYou can do this by teaching new tricks, obedience training, regular sniffing sessions, or playing hide-and-seek with treats spread around the house.\nProper Socialization and Exposure to Various Stimuli\nSocializing and exposing dogs to diverse stimuli is essential to avoiding and managing anxiety when visitors come.\nIntroducing dogs to different people, sounds, and settings in a good way can help them gain assurance and adaptability.\nTake it in steps, offering positive reinforcement for good behavior.\nHaving your dog socialize with kids, seniors, and other animals often can help manage their stress too.\nRemember, socialization has to match the pup’s age and should be done in a safe environment with someone watching.\nConsistent Training and Behavior Management\nEffectively training and controlling Canine behavior is vital for managing a dog anxious with visitors.\nHere are some tips on how to maintain a calm pup when company comes around!\n- Consistency. Make sure your commands, rewards, and training sessions stay the same. No changes.\n- Praise and reward good behavior when guests are present. Be sure to do it promptly and consistently.\n- Stay relaxed and assertive while training. Dogs can sense their owner’s emotions. Anxious or nervous vibes could make them act the same.\n- Correct training can help with unwanted behavior, while encouraging positive interactions with visitors. Every dog is different, so if help is needed, seek professional advice.\n- Feeding and resting your dog is a great way to make a good impression with your guests. A full belly and nap will keep them from barking and scaring away visitors.\nHealthy Diet and Adequate Rest\nFor your pup to manage their anxiety during visitors’ arrival, a balanced and nourishing diet is a must.\nPick food that is nutritious and supports a healthy body and mind. This will give them the energy to be calmer.\nPlus, good-quality protein, carbs, fats, minerals like calcium, magnesium and iron, all help improve their health, reduce stress levels and enhance immunity.\nSleeping for at least 8 hours per day helps balance hormones and reduces those that cause anxiety.\nCreate a tailored-feeding schedule for your pup as erratic eating patterns can aggravate anxiety symptoms.\nWhen it comes to your dog’s anxiety around visitors, understanding their needs and providing the right support is vital.\nTake into account factors like genetics, socialization, past traumas, training, and health.\nSlowly expose your furry friend to visitors, use positive reinforcement, consider behavior modification techniques, and consult a professional if necessary.\nRemember, patience and consistency are what your dog needs most.\nYour little trooper can overcome their anxiety and enjoy calm stress-free with guests your guests, it just might take a little time.\nFrequently Asked Questions\n1. How can I help my dog feel more comfortable around visitors?\nThere are several ways to help your dog feel more comfortable around visitors, including gradual desensitization and counterconditioning, providing a safe and quiet space for your dog to retreat to, and creating positive associations with visitors through treats and toys.\n2. What should I do if my dog exhibits aggressive behavior towards visitors?\nIf your dog exhibits aggressive behavior towards visitors, it is important to consult with a professional dog trainer or behaviorist. They can help identify the underlying cause of your dog’s behavior and provide guidance on how to manage and modify it.\n3. Can medication help a dog anxious with visitors?\nIn some cases, medication may be prescribed by a veterinarian to help relieve your dog’s anxiety with visitors. However, medication should always be used in conjunction with behavior modification techniques and under the guidance of a professional.\n4. How can I prevent my dog from becoming anxious with visitors in the future?\nTo prevent your dog from becoming anxious with visitors in the future, it is important to provide them with plenty of positive socialization experiences from a young age, continue to expose them to new people and environments, and reinforce calm and confident behavior around visitors.\n5. Should I allow visitors to interact with my dog even if they are anxious?\nIf your dog is anxious around visitors, it is important to prioritize their comfort and well-being. It may be best to limit interactions with visitors or provide clear guidelines for how visitors should interact with your dog.\nAll information in this article is for educational purposes only and is not meant to replace your veterinarian’s advice.\nTransforming anxious pups with her wealth of hands-on practical experience, and qualified in the following disciplines: Holistic Healing, Canine Anxiety & Therapy, Zoopharmacognosy, and CBD Oil for Animals\nFounder of Anxious Canine and proud member of the Complementary Medical Association.']	['<urn:uuid:8f9d988d-4c54-4623-9c7d-c4812fa780a4>', '<urn:uuid:49131cdd-5896-4d36-9186-df3ad8794437>']	open-ended	direct	short-search-query	similar-to-document	three-doc	novice	2025-05-12T15:09:02.012753	6	90	4304
16	What are the main characteristics of the Sudbury Basin structure?	The Sudbury Basin structure is located in Greater Sudbury at the erosional boundary between the Archean Superior province and early Proterozoic continental margin deposits. It consists of the Sudbury Igneous Complex, which is a differentiated sequence of intrusive volcanic rocks including norite, gabbro and granophyre, overlain by breccias and metasedimentary rocks. The sublayer consists of basic to ultrabasic inclusions of varying size.	"['University of Michigan experts are available to comment. In Detroit, it was an intensity II-III, while in Chicago it was an intensity V. 1895: A major earthquake originated in Charleston, Missouri. - Hough. Source: http://www.fema.gov/earthquake/earthquake-hazard-maps. An historical record of earthquakes with epicenters in Michigan is shown on Table 1.  The quartz biotite gabbro is medium- to coarse-grained, the Climax quartz monzonite is medium-grained. The rigid nature of the bedrock that runs throughout the Midwest allows seismic waves to travel across the region. :3 Late-stage dikes and sills of diabase, quartz-feldspar fine-grained instrusive rocks (aplite) and quartz-feldspar-mica coarse-grained intrusive rocks (pegmatite) are common. :2 These Huronian and Snowy Pass sedimentary rocks are similar, each having 2,450- to 2,100-million-year-old epicratonic rifts succeeded by a 2,100- to 1,800-million-year-old passive sedimentary margins. It was felt in Grand Rapids as an intensity V. 1935: An earthquake registering 6.1 on the magnitude scale originated in Timiskaming Quebec. In: T. Mikumo, K. Aki, M. Ohnaka, L.J. :1890 The sublayer consists of a mass of basic to ultrabasic inclusions of varying size and frequency of occurrence. Jump to Navigation Significant Earthquakes - 2015. The ground shakes in Detroit from those quakes was felt as a V. Additional notable out-of-state earthquakes felt in Michigan: There have been several earthquakes that have impacted Michigan since 2000. :9, In the northern Black Hills of southwest South Dakota the 2,600- to 2,560-million-year-old Precambrian crystalline core, the Blue Draw Metagabbro, is a 1 km (0.62 mi) thick layered sill. 1980: An earthquake registering 5.2 on the magnitude scale originated in northeast Kentucky, where it was an intensity VII. :8 Lithologies of the rocks are usually gneissose and migmatitic. The geologic record of pre-1811 earthquakes also reveals that the New Madrid seismic zone has repeatedly produced sequences of major earthquakes, including several of magnitude 7 to 8, over the past 4,500 years. Noida, like most of the National Capital Region, is a high-damage risk earthquake zone, also known as earthquake zone 4 or seismic zone 4. The closest fault zone to Michigan are the New Madrid and Wabash Seismic Zones. :1890[note 1] The structure consists of the Sudbury Igneous Complex, a differentiated sequence of intrusive volcanic rocks – norite, gabbro and Updated 2 Dec 2020 06:37 GMT - There were no significant earthquakes in or near Michigan during the past 30 days. Greece and Turkey are both situated in one of the world\'s most active earthquake zones. Most of Michigan ranks in the lowest seismic zone category and is 36 th in the U.S. for earthquake hazards according to the USGS. :8, The Sudbury Basin structure is located in Greater Sudbury:1891 at the erosional boundary between the Archean Superior province and the overlying sequence of early Proterozoic continental margin deposits. , In the eastern Sudbury area the rock is highly crystalline hornblendic gneiss, which apparently dips at a rather low angle toward the southeast. Seismic hazard is the hazard associated with potential earthquakes in a particular area, and a seismic hazard map shows the relative hazards in different areas. The zone, colored red on the map, is called the New Madrid Seismic Zone. In general, greater shaking is expected in regions closer to active faults. This map and table shows where Minnesota\'s earthquakes have occurred. :409 Shear zone boundaries are subparallel and strike N60°W; the foliation in mylonite within the GLTZ strikes N70°W and dips S75°W. When stress that has accumulated over time eventually exceeds the rock’s strength, rupture occurs, generally along a plane of weakness called a fault. It was felt as an intensity II-IV at various locations in and around Detroit. :2 Radiometric dating shows that the Wyoming province\'s Blue Draw Metagabbro was undergoing rifting at 2,480 million years ago, the same time the emplacement of the 250 km (160 mi) long belt of mafic layered intrusions in the Sudbury region. Learn more about the causes and effects of earthquakes … The … This program can be used to obtain the earthquake ground motion parameters needed to design structures for specific geographic locations in accordance with the latest building code reference documents.  The Algoman Mountains had been built and then eroded into sediments that covered the area. Causes of Earthquakes. There are 43 earthquake incidents in Michigan on record since 1931. May 2015 in The Pub. Although you can’t control the seismic hazard in the community where you live or work, you can influence the most important factor in saving lives and reducing losses from an earthquake: the adoption and enforcement of up-to-date building codes. Questions? This region has a low to moderate level of seismicity when compared to the more active seismic zones to the east, along the Ottawa River and in Quebec. The swarm of earthquakes began on September 30 in the Brawley seismic zone. Algoman orogeny added landmass to the Superior province by volcanic activity and continental collision along a boundary that stretches from present-day South Dakota, U.S., into the Lake Huron region near Sudbury, Ontario, Canada. :9, By 2,100 million years ago, the Wyoming craton is thought to have completely separated from the southern Superior province, this is consistent with the occurrence of a 2,076- to 2,067-million-year-old hotspot centered just south of the Superior province and east of the MRV. :145 This is when the Wyoming province is hypothesized to have drifted away from the Superior province. Designated earthquake, hurricane or other emergency shelters. 2015-12-30 07:39:29 UTC 52.4 km.  The growth of the Superior province greenstone-granitic terranes ended with the suturing of the Minnesota River Valley gneiss terrane to the basaltic Wawa subprovince. 2.0+ 3.0+ 4.0+ 5.0+ [smaller] [bigger] Today | Yesterday | Past month | All time. The Holland, Michigan tsunami started at 4:10 AM, just 2 minutes after the earthquake occured. Wisconsin, Upper Peninsula of Michigan and Minnesota, ""SHRIMP study of zircons from Early Archean rocks in the Minnesota River Valley: Implications for the tectonic history of the Superior Province"", ""Development of 3-D seismic exploration technology for deep nickel-copper deposits—A case history from the Sudbury basin, Canada"", ""Title Elastic Moduli, Thermal Expansion, and Inferred Permeability of Climax Quartz Monzonite and Sudbury Gabbro to 500°C and 55 MPa"", ""Notes on a part of the Huronian Series in the Neighbourhood of Sudbury (Canada)"", ""2480 Ma mafic magmatism in the northern Black Hills, South Dakota: a new link connecting the Wyoming and Superior cratons"", Geological Guidebook to the Paleoproterozoic East Bull Lake Intrusive Suite Plutons at East Bull Lake, Agnew Lake and River Valley, Ontario, ""Seismic history of Minnesota and its geological significance"", Circular 14 Seismic Disturbances in Michigan, https://en.wikipedia.org/w/index.php?title=Great_Lakes_tectonic_zone&oldid=991048580, Articles with dead external links from January 2020, Articles with permanently dead external links, Creative Commons Attribution-ShareAlike License, This page was last edited on 28 November 2020, at 00:08. The state averages 1 earthquakes per year. :9 In southcentral Wyoming province there is a 2,170 ± 8-million-year-old quartz diorite dike of Wind River Range.  Similar intrusions farther east along the GLTZ show later dates, reinforcing the theorized closure from west to east.  Fragmentation of this Archean supercontinent began around 2,450 million years ago under a hotspot near Sudbury and was completed by around 2,100 million years ago. The 2,125- to 2,090-million-year-old mafic magmatic events affecting the Superior and Wyoming cratons show the hotspot having moved 500 km (310 mi) west from Sudbury, and the two provinces have rifted so that they are separated by 100 km (60 mi). There is broad agreement in the scientific community that a continuing concern exists for a major destructive earthquake in the New Madrid seismic zone. The 2,170-million-year-old intrusive events that affected the Superior and the Wyoming cratons indicate that the plume had moved 330 km (210 mi) west, centered in the opening between the Superior province and the rifting Wyoming province. It is a 1,400 km (870 mi) long paleosuture that separates the more than 3,000-million-year-old Archean gneissic terrane to the south – Minnesota River Valley subprovince – from the 2,700-million-year-old Late Archean greenstone-granite terrane to the north – Wawa Subprovince of the Superior province. Even though Michigan is categorized as having a very low hazard risk for earthquakes, the state does experience earthquakes. USGS Earthquake Hazards Program, responsible for monitoring, reporting, and researching earthquakes and earthquake hazards . :165, The Northern and Southern complexes of the Upper Peninsula are highly migmatized and intensely foliated, with the intensity of foliation increasing toward margins. 11 Northwestern its first loss of the season with a 29-20 victory Saturday.The Wildcats (5-1, 5-1) were coming off a 17-7 victory over Wisconsin that put them in contention for a spot in the College Football Playoff. Title. Not only was this one of the biggest earthquakes in Michigan’s history, but it came less than two months after a larger earthquake occurred less than 30 miles away. of Examples: Monday, today, last week, Mar 26, 3/26/04. granophyre – overlain by breccias and metasedimenary rocks. It doesn\'t seem to work when the url is typed into Google. The USGS and its partners monitor and report earthquakes, assess earthquake impacts and hazards, and perform research into the causes and … 2015-12-30 01:48:57 UTC 7.0 km. Migrated composite section of COCORP north-south seismic-reflection profiles, Minnesota S4 3. Kalamazoo - It was the first earthquake in Michigan in years with a rating of 4.2; Grand Rapids - Lying on sofa, felt weak tremor lasting 4 seconds. :8 These Late Archean rocks form a roughly north–south belt lying south of Marquette extending to the Michigan-Wisconsin border. A magnitude 4.9 struck near Resolute, Nunavut Sunday night at a depth of 10 kilometres, according to the U.S. Geological Survey. Earthquakes in Virginia commonly occur on blind faults that do not reach earth’s surface. We have a seismic zone that produces earthquake clusters. Earthquake News Today. Ruff and P.K.P. Department of Geological Sciences, Unir~ersity of Michigan, Ann Arbor, MI 48109, USA (Received June 14, 1991; revised version accepted March 2, 1992) ABSTRACT Ruff, L.J., 1992. Filter by magnitude: all. An episode of hotspot gabbro magmatism occurred 2,480 million years ago at the eastern edge of the Wyoming craton,:1 south of current-day Sudbury. :8 The western part of the Southern Complex shows intricate phases of folding and foliation. This assessment is based on decades of research on New Madrid earthquakes and related phenomena by d… Some people often use the term “seismic zone” to talk about an area with an increased risk of seismic activity, while others prefer to talk about “seismic hazard zones” when discussing areas where seismic activity is more … H :2 Intrusion of the 2,475- to 2,445-million-year-old Matachewan-Hearst Mafic Dike Swarm and the 2,490- to 2,475-million-year-old East Bull Lake suite of layered mafic intrusive rocks are interpreted as indicating early Paleoproterozoic, mantle-hotspot driven rifting centered near Sudbury, Ontario, during the onset of Kenorland breakup. Were no significant earthquakes in or near Michigan during the past 30 days a regular Google search box not. The sudden release of accumulated stress within the Earth ’ s surface the only state with a earthquake! Earthquake hazard of Wind River Range hazards according to the University of Michigan ranks the... Rattled windows in downtown Detroit on April 19, 2018 \'\' is the earthquake... April 18th observations along a rifted belt Dakota and continued eastward 2,700 million years ago continued. Offers low earthquake frequency and severity risks registering 5.2 on the magnitude scale originated Olney! Breaking on a fault, which is the next major tectonic event in the area affected by the earthquake..., greater shaking is expected in regions closer to active faults that exist are 43 earthquake incidents in Michigan categorized. Carolina, where it was felt as far away as Cleveland, Ohio ;,! Mar 26, 3/26/04 ( line of tectonic transport ) in the U.S. geological Survey s. Ii-Iii in southern Michigan the subduction zone consumes the oceanic crust connected to the Michigan-Wisconsin.. An active dextral strike-slip zone south of Marquette, passing under the large Marquette anticline tectonic... Is the most powerful predictor of damage from an earthquake registering 5.2 on the magnitude scale originated South-Central... 2 Dec 2020 06:37 GMT - there were no significant earthquakes in Minnesota,,. Regular Google search box ( not felt ) to Level X ( Extreme. ) northeast,... Is medium-grained an earthquake registering 5.2 on the magnitude scale originated in the of... Original url used showed the entire article as a 4.2 earthquake in was... First was probably during formation of the Kenorland supercontinent began 2,450 million years ago and Sudbury... Narrow zones where rock masses move in relation to one another earthquakes rocked the River. Rift margins form elongate, domal or circular bodies that are several kilometers michigan earthquake zone since... And past earthquakes in or near Michigan during the past 30 days into... 8-Million-Year-Old quartz diorite dike of Wind River michigan earthquake zone the scale runs from Level I not. Rotating away, with the Algoman Mountains had been built and then into... As the tsunami hit Holland around 7:00 AM, and the other 2,600 million years ago and was by! Is interpreted to have happened obliquely at an angle, [ 15 ] with at least six in New. Mikumo, michigan earthquake zone Aki, M. Ohnaka, L.J result of rocks breaking on fault! ]:2 These layered mafic intrusions are of Similar thickness and identical age, and occur along single... The world \'s most active earthquake zones a magnitude 7.3 and was intensity X,! Look up most recent and michigan earthquake zone earthquakes in or near Michigan during past!, and 1928, northwest of Kapuskasing ) have occurred tectonically quiet for a destructive... Will not image all the way here in Detroit ( 130 miles away ) that not! Day suggest that the kinematics determined in the last stage of closure, started in south Dakota and for.. [ 3 ] ± 8-million-year-old quartz diorite dike of Wind River.. Else in it it more of a protocontinent than a future Superior province that! Seismic record will not image all the way here in Detroit shake was felt as an intensity VII reconstruction this. Rocks are usually gneissose and migmatitic Look up most recent measurable earthquake in Galesburg, MI.... Smaller ] [ bigger ] Today | Yesterday | past month | all.. The Sudbury area has had three earthquakes, northwest of Kapuskasing ) have occurred waves were at 50. 30 days all time earthquake occurrence in subduction zones rate of seismic activity remains fairly consistent Memphis Tennessee. Important to remember that areas with high earthquake hazards have drifted away from the Superior Wyoming. Earthquake registering 5.2 on the magnitude scale originated in Olney, Illinois ; and Muncie, Indiana california isn t! Mylonite foliation plunges 42° in a 50-year time span, of michigan earthquake zone mass basic. The region was tectonically quiet for a few hundred million years ago and was intensity X are! In Wisconsin represents margin-type igneous activity terminated by collision went south towards the west though is. But there are also seismic zones \' ratios Airport and I-196 and background info and Memphis zone is a ±! South towards the west Sacred Heart granite quartz diorite dike of Wind River Range earthquake Precursors 50 high. 4.0+ 5.0+ [ smaller ] [ bigger ] Today | Yesterday | past |! And interactive map, updates, links and background info tectonically quiet for a few hundred years. Activity terminated by collision hundred million years ago [ 3 ] | month! And background info and sills are typical of continental rifting and can be to! Afternoon ( very close to Kalamazoo ) years ago and was intensity.... Canada rattled windows in downtown Detroit on April 19, 2018 and continued.! Low. earthquake sequence the Department of Earth and Environmental sciences and southern Ontario ago and was intensity X bigger! One continental block onto another usually occurs because a subduction zone exists beneath of. Occurrence in subduction zones Beach as the tsunami hit Holland around 7:00,! Centered near Amherstburg, Ontario, Canada rattled windows in downtown Detroit on April 19,.... Fall out. and I-196 regular Google search box ( not felt ) to Level X (.. Dike of Wind River Range southeast Michigan on Friday evening Sunday night at depth! 18 are in the St. Lawrence River region in Massena, New York and was as... One continental block onto another usually occurs because a subduction zone consumes the oceanic crust connected to the geological... Primesuspect Beepin n \' Boopin Detroit, MI this afternoon ( very to... Age michigan earthquake zone and occur along a rifted belt Muncie, Indiana n\'t seem to work when the Wyoming province hypothesized... Usually occurs because a subduction zone exists beneath one of Canada \'s most active zones. These are the New Madrid region, much like those caused by the earthquake crashed into Holland Park. By the earthquake crashed into Holland state Park, destroying campsites and everything else in it September 2,,. A 2,170 ± 8-million-year-old quartz diorite dike of Wind River Range greater earthquake more! Night at a depth of 10 kilometres, according to the right Holland 7:00... 6, 9, 11, 15 and 18 are in the last 120 along. Ground can shake edge of the area affected by the earthquake near Minnesota \'s have! Work when the url is typed into Google 4.2 magnitude before being downgraded to 3.8 is hypothesized to have away! 3 kilometers south southeast of Detroit Beach near Monroe County foliation, shear zones and.! Freelance writer past earthquakes in Virginia commonly occur on blind faults that do not reach Earth s. Quakes, but there are 43 earthquake incidents in Michigan magnitude before being downgraded to 3.8 ( 3 to MI. Of Cleveland several hundred kilometers east to west, making it michigan earthquake zone a... Granite body, the tsunami hit downtown Holland and went south towards the.! General, greater shaking is expected in regions closer to active faults that do not necessarily high... Be used to time supercontinent breakup between rock layers in Illinois was in 2012 near Woodstock in County!']"	['<urn:uuid:0b6e3918-0770-429f-836d-5021c5136350>']	open-ended	direct	concise-and-natural	similar-to-document	single-doc	expert	2025-05-12T15:09:02.012753	10	62	2980
17	What happens when we read deeply, and how does it affect prayer?	Deep reading involves moving from not knowing to knowing through critical analysis, leading to self-knowledge and revelation. When applied to prayer, this practice becomes especially meaningful as it helps create authentic communion with God. However, modern digital distractions can hinder this process, as they may prevent full presence and engagement in prayer, particularly during sacred moments like Mass. The key is to find balance between digital connectivity and maintaining silent, contemplative spaces for genuine spiritual growth.	"['What is Hermeneutics? The Practice Of Interpreting Text\nHermeneutics is the theory, practice, and methodology of the interpretation of text.\nHermeneutics is often discussed in regard to the kinds of text that are thought to be ‘worth thinking about,’ evaluating, and seeking different perspectives about. These often include theological and philosophical texts (and by extension, political texts driven by specific ideologies and philosophies).\nHermeneutics is not simply limited to interpretive theory, principles, and skills brought to bear on dense, important, subjective, or otherwise ‘evasive’ text. It is also a matter of comprehension, analysis, as well as oral and written communication. Thus, Hermeneutics is also a kind of philosophical discipline interested in analyzing the conditions for both truth (like epistemology) and understanding.\nFurther, Hermeneutics can be seen as a kind of critical thinking that leads to truth and, ultimately, self-knowledge and revelation. The practice of identifying cognitive biases and how existing knowledge is used to acquire and create new knowledge begins (ideally) with–and further promotes–humility. The nature of knowledge–as well as knowing the difference between knowledge and belief–underpin critical reading and interpretation.\nAs readers, we start off not knowing then, through critical reading, come to know. This necessarily changes a reader, of course, but if the reader then reflects back on the movement from not knowing to knowing, self-knowledge is possible and the process of coming to know becomes more important than what has been learned.\nSee also What Is Critical Reading?\nBy assuming that there is more to know than we currently know and that we are biased and generally prone to logical fallacies, the act of reading is transformed from a passive sequence of mechanical events–decoding words and sentences to ‘finish reading–to an active, ongoing consideration and refinement of everything we know in light of what we are reading.\nBy actively, critically reading, we are reconciling what we think we know with what might be true–and further reconciling what we think and know with the claims made in the text we are reading.\nCritical readers have to assume two things at once: that readers and authors alike are prone to cognitive biases and failures of reason and that these biases and failures are avoidable if we are willing to accept them as not only possible but highly probable.\nPut another way, they have to believe that they are probably missing or misunderstanding the text and that they have the capacity, through rational, patient scrutiny of ideas, to minimize that misunderstanding. (Think of the word ‘misunderstanding’ here to simply mean not entirely grasping the truth and significance of a text.)\nA sequence of ideas to clarify:\nI. Authors write text to communicate ideas\nII. When these ideas are thought to be worth understanding, readers decode and make sense of these texts.\nIII. These meanings–the one intended by the authors and the one assembled by the process of reading–are never the same and inherently incompatible with one another as they can be separated by unique social norms, language use, cultural context, and even the span of centuries and millennia.\nIV. Humble readers will read under the pretense that they are prone to misunderstanding and may be missing key information or background knowledge necessary to evaluate a text.\nV. A second pretense for critical reading: that the author of a text is subject to the same intellectual pre-dispositions (i.e., being prone to irrationality) and the text must be evaluated accordingly and that the significance of data and claims about that data and so must be diligent, rational, methodical, and recursive in their reading.\nIronically, what we believe we know can obfuscate actually knowing–in part because believing and knowing are different and we rarely give enough thought to the important distinctions between the two. If we believe that we know, we are not on alert to create new knowledge in the same way that someone at a market with no money and/or no intention to buy will see the market wares entirely differently than someone with money and/or intending to buy.\nExamples Of Hermeneutics\n-Studying a theological text\n-Debating the truths of a philosophical text\n-Reading Buddha’s sutras (or other culturally-relevant ‘wisdom keepers’ or sages)\n-Analyzing foundational political documents (e.g., The Declaration of Independence, The Ordinance of Louis the Pious, etc.)', '- Prayer and Worship\n- Beliefs and Teachings\n- Issues and Action\n- Catholic Giving\n- About USCCB\nThe ministry of the Word is a fundamental element of evangelization through all its stages, because it involves the proclamation of Jesus Christ, the eternal Word of God.\n“The word of God nourishes both evangelizers and those who are being evangelized so that each one may continue to grow in his or her Christian life”\n(National Directory for Catechesis [NDC] [Washington, DC: United States Conference of Catholic Bishops, 2005], no. 17).\nby Jonathan F. Sullivan\nExecutive Director of the Department of Evangelization, Education, and Liturgy\nDiocese of Lafayette, IN\nPrayer is an integral component of catechesis, for ""communion with Jesus Christ leads the disciples to assume the attitude of prayer and contemplation which the Master himself had . . . When catechesis is permeated by a climate of prayer, the assimilation of the entire Christian life reaches its summit"" (General Directory for Catechesis, no. 85).\nThe practice of Christian prayer is always situated within particular historical and cultural contexts. In recent years, the emergence and widespread adoption of new digital communication tools has presented new challenges and opportunities for how the Church promotes prayer and how the faithful practice it.\nWhile it is hard to pinpoint an exact start date for the internet (ARPANET, the direct predecessor to the modern internet, went online in 1969), the introduction of the World Wide Web in the 1990s and advances in telecommunications technologies (including wireless data delivery) have made networked information sharing nearly ubiquitous in American society. Although a ""digital divide"" does exist (poor, undereducated, and rural Americans are much less likely to use digital technologies), eighty-five percent of Americans report using the Internet on a regular basis.1\nThe result is a world more connected than the wildest dreams of Johann Gutenberg, Samuel Morse, or Alexander Graham Bell. And yet, for all the connectedness we enjoy with people across the world, many individuals increasingly find themselves isolated from people across the room. Studies are finding that technology users today are experiencing a decrease in empathy and face-to-face interactions and an increased difficulty engaging in sustained conversation.2\nThis disconnection has perilous implications for the possibility of encountering Jesus Christ in the modern world. If, as the Catechism of the Catholic Church reminds us, ""we cannot love the God we cannot see if we do not love the brother or sister we do see"" (no. 2840), how much harder will it be to love God when our attention is turned away from the brother or sister in front of us?\nPope Francis focuses on the unitive and dissociative elements of new media in his Message for the 48th World Communications Day when he teaches, ""The desire for digital connectivity can have the effect of isolating us from our neighbors, from those closest to us,"" because ""communication is ultimately a human rather than technological achievement."" That is, communication always involves an encounter between two persons, even when obscured by a screen. In this, Pope Francis echoes Pope Benedict XVI:\nWe also need to be aware that the virtual world will never be able to replace the real world, and that evangelization will be able to make use of the virtual world offered by the new media in order to create meaningful relationships only if it is able to offer the personal contact which remains indispensable (Verbum Domini, no. 113).\nThis ""personal contact,"" which Pope Francis calls ""a culture of encounter,"" is not antithetical to the use of new communication tools. The Holy Father stresses in his message that ""good communication helps us to grow closer, to know one another better, and ultimately, grow in unity."" The question facing catechists, however, is how the use of technology—and the culture it engenders—promotes or hinders our communication with God and ability to foster encounters with Jesus Christ through prayer.\nEven in the short amount of time that people have used the internet for social networking, commerce, communication, and other activities, certain patterns have arisen. While it would be premature to say that these patterns are set, it does seem that a ""digital culture""—a set of behaviors, arts, beliefs, and institutions—is beginning to emerge.\nDigital behaviors include carrying mobile devices, responding to notifications, sending text messages, and sharing previously invisible or private aspects of our daily lives. Digital arts encompass mash-ups, memes, alternate reality games, and the ubiquitous selfie. Digital beliefs include the value of increasing speed, the right to free and unfettered access to information, and the importance of trust in online relationships (both personal and commercial).\nThis digital culture is having an increasing impact on all facets of human activity, whether digital or IRL (""in real life""). To take one example: the proliferation of mobile, connected devices has created the expectation that an individual will always be online and within reach, no matter how physically far away they may be. In essence, the world has shrunk. It is now as easy to contact someone halfway across the world as it is someone halfway across town.\nSuch technologies are most likely a net positive, but the expectation of connectedness—and the corresponding obligation that places on people to always be ready to interrupt what they are doing for the next call, text, or notification—may not be having such a positive influence on human flourishing. This is manifests especially when it interrupts conversation between friends, a moment of grace between parent and child, or the sacred silence of the Mass.\nThe expectation for connectedness can even run the other way, so that a person with a cell phone feels obligated to share updates, pictures, or video, in real time, with followers. It is no longer remarkable to witness a sea of glowing cell phones at concerts, sporting events, or papal liturgies. This desire to share, while laudable, does have the consequence of removing the person from the situation in which they are engaged. They are no longer encountering, but instead mediating the transfer of information to others: they are not fully present, but instead removed behind a screen. This trend is especially unnerving in the liturgy, the nature of which demands full and active participation by the faithful (cf. Sacrosanctum concilium, no. 14).\nThe evolving digital culture presents a number of challenges and opportunities for the Christian faith in general and for the practice of prayer in particular. For instance, new digital technologies have led to a decreasing emphasis on the importance of the physical world in the secular imagination. While the distance between mind and body in philosophy has been increasing ever since Descartes declared, ""Cogito, ergo sum,"" the gulf has only increased in recent years as we have become accustomed to ""inhabiting"" online spaces.\nIn online spaces, people exist in an idealized world as disembodied consciousnesses. Any sensory information is mediated through screens, speakers, and keyboards, and this mediation is remarkably easy to overlook, as anyone who has become immersed in a video game can attest. Without the constraints of physical matter, users are free to craft their own idealized avatar that may bear little resemblance to their ""real life"" self. Even on social networking sites, we tend to choose profile pictures that highlight our best features and minimize our flaws, even taking hundreds of pictures in order to find the one ""perfect"" picture to share.\nThis acceptance of a body/mind dualism is a direct challenge to the incarnational basis of Christian anthropology, which understands persons to be embodied spirits: ""It is because of its spiritual soul that the body made of matter becomes a living, human body; spirit and matter, in man, are not two natures unified, but rather their union forms a single nature"" (CCC, no. 365). Sacred Scripture regularly attests to the sacred nature of our physical forms, comparing us to clay in the potter\'s hands (Jer 18:6) and proclaiming that God knows the number of hairs on our heads (Lk 12:7).\nA pressing question for pastors to address with their connected congregations will be to what extent these mediated, idealized selves can enter into authentic communion with one another. Jesus promises, ""Where two or three are gathered together in my name, there am I in the midst of them"" (Mt 18:20). Is this true in cyberspace? Or does authentic presence require more than our consciousness?\nIn many ways, our digital avatars inhabit spaces of empty symbolism, even when we attempt to inject religious meaning into them. For instance, while some ""digital churches"" allow avatars to ""light"" a digital candle, such representations rob the symbol of their full power. Digital candles illuminate without sacrifice—that is, they are not consumed—and thus they lose their connection to Christ\'s sacrificial act on the Cross. In a very real way, digital candles (and their electric counterparts in the real world) denote a ""Christ without the Cross.""\nThis empty symbolism is also found in the ""cheap engagement"" promoted by online activism and social networking. In the wake of tragedies and natural disasters, social media lights up with people offering opinions and sharing links. This gives the illusion of activity while doing little to actually alleviate suffering, promote solidarity with the poor and vulnerable, or address systemic problems. It is not the ""culture of engagement"" between persons encouraged by Pope Francis, but a culture of immediate response that substitutes the click of a mouse for authentic social justice.\nAll of this is not to say that the emerging digital culture does not also provide opportunities to engage the faithful in their life of prayer. Just as we are encouraged to ""pray without ceasing"" (1 Thes 5:17) in the physical world, finding ways to pray within the context of the digital culture is the work of all connected Christians. As with many facets of society, digital communication has opened new vistas for learning about and engaging in Christian prayer. The task for catechists is to help the faithful identify and adopt those methods that will deepen their lives of prayer.\nOne opportunity that is increasingly employed in catechesis is the countercultural nature of silence in prayer and liturgy. Pope Benedict XVI devoted his 2012 Message for World Communications Day to silence, teaching:\nIf God speaks to us even in silence, we in turn discover in silence the possibility of speaking with God and about God . . . In speaking of God\'s grandeur, our language will always prove inadequate and must make space for silent contemplation. Out of such contemplation springs forth, with all its inner power, the urgent sense of mission, the compelling obligation ""to communicate that which we have seen and heard"" so that all may be in communion with God (1 Jn 1:3).\nPerhaps because their lives are so full of distractions and a cacophony of alerts and alarms, many young people are finding an increased value in simple silence, especially before the Blessed Sacrament. Disengaging from the speed of digital communication and returning to a more human pace can help engender clarity and peace (even if young people find such a pace initially uncomfortable), which is carried back into the digital world. Catechetical programs can tap into that power by integrating time for silence and deliberation into catechetical prayer. Attending to the importance of liturgical silence is another way to help the faithful refocus their attention from electronic signals to the eternal.\nThe great treasure of Catholic art and music also gives us an opportunity to use beauty to evangelize in a culture that increasingly relies on audio and visual mediums. While Christianity in the last 500 years has relied heavily on the written word, new media is altering reading habits. Fortunately, the declining costs of digital storage and high-speed Internet access have made disseminating visual media achievable for parishes, ministries, and individual apostolates (as witnessed by the wide number of Catholic blogs, podcasts, and video producers making digital content available across the globe).\nCatechists can make use of this rich treasury by encouraging reflection on sacred art, producing PowerPoint presentations and other digital aids for prayers such as the Angelus or Chaplet of Divine Mercy, and directing adults to good resources online. These efforts are aided by growing online collections of appropriate religious art available in the public domain or under Creative Commons licenses, although the Church should not neglect her traditional role as a patron in the creation of new religious art.\nFinally, while acknowledging that face-to-face encounters are an indispensable part of Christian fellowship, digital tools can help the faithful to maintain and strengthen connections with one another when physical presence is not possible. Social media platforms may be used to request prayers and respond to prayer requests, while video conferencing services such as Skype can be used to facilitate prayer together across great distances. Multimedia presentations and videos may also be employed to make known the needs of communities across the world— especially in areas marked by poverty or violence—so that local communities can respond with spiritual and material assistance.\nOver the centuries, the Church has exercised careful discernment as new technologies and practices have arisen, adopting what is good for the proclamation of the Gospel. In a time of rapid technological change, this task may be more daunting but is no less vital. As the means of social communication affect how persons communicate with each other, so too will they affect how we think about and practice communication with God.\nIn this we can take comfort in the words of Jesus Christ: ""Then every scribe who has been instructed in the kingdom of heaven is like the head of a household who brings from his storeroom both the new and the old"" (Mt 13:52). As communication grows more varied and complex, the task of catechesis and forming the faithful in lives of prayer remains constant, even in the digital continent.\n1 Monica Anderson and Andrew Perrin, ""15% of Americans don\'t use the internet. Who are they?"" Pew Research Center, http://www.pewresearch.org/fact-tank/2015/07/28/15-of-americans-dont-use-the-internet-who-are-they/ (accessed September 21, 2015).\n2 Lauren Cassani Davis, ""The Flight From Conversation,"" The Atlantic, http://www.theatlantic.com/technology/archive/2015/10/reclaiming-conversation-sherry-turkle/409273 (accessed November 10, 2015).\nCopyright © 2016, United States Conference of Catholic Bishops, Washington, DC. All rights reserved. Permission is hereby granted to duplicate this work without adaptation for non-commercial use.\nExcerpts from the Catechism of the Catholic Church, second edition, copyright © 2000, Libreria Editrice Vaticana–United States Conference of Catholic Bishops, Washington, D.C. (LEV); General Directory for Catechesis, copyright © 1998, LEV; Used with permission. All rights reserved.\nExcerpts from Pope Benedict XVI, Domini Verbum, copyright © 2010, Libreria Editrice Vaticana, Vatican City (LEV); Pope Paul VI, Sacrosanctum Concilium, copyright © 1963, LEV; Used with permission. All rights reserved.\nScripture excerpts used in this work are taken from the New American Bible, rev. ed.© 2010, 1991, 1986, 1970 Confraternity of Christian Doctrine, Inc., Washington, DC. All rights reserved. No part of this work may be reproduced or transmitted in any form or by any means, electronic or mechanical, including photocopying, recording, or by any information storage and retrieval system, without permission in writing from the copyright owner.\nBy accepting this message, you will be leaving the website of the\nUnited States Conference of Catholic Bishops. This link is provided\nsolely for the user\'s convenience. By providing this link, the United\nStates Conference of Catholic Bishops assumes no responsibility for,\nnor does it necessarily endorse, the website, its content, or']"	['<urn:uuid:d97bc873-50ed-4a70-9251-dfe72d7e1dec>', '<urn:uuid:f020297e-53d5-4ac1-8d9b-19dad9ef3156>']	factoid	with-premise	concise-and-natural	distant-from-document	multi-aspect	novice	2025-05-12T15:09:02.012753	12	76	3267
18	What percent of ketone bodies is beta-hydroxybutyrate?	Beta-hydroxybutyrate makes up 78% of ketone bodies.	"[""US 7144709 B2\nA reagent is suitable for measuring the concentration of an analyte in a hemoglobin-containing biological fluid, such as whole blood. The reagent comprises a flavin-dependent enzyme that has specificity for the analyte, a flavin cofactor if, and only if, a flavin is not bound to the enzyme, a tetrazolium dye precursor, an electron transfer agent, and a nitrite salt. The reagent causes dye formation that is a measure of the analyte concentration. The nitrite salt suppresses interfering dye formation caused non-enzymatically by the hemoglobin. Preferably, the reagent is used in a dry strip for measuring glucose in whole blood.\n1. A reagent for measuring a concentration of an analyte in a hemoglobin-containing biological fluid, comprising\n(a) a flavin-dependent enzyme that has a specificity for the analyte and does not have a flavin bound to it,\n(b) a flavin mononucleotide (FMN) or flavin adenine dinucleotide (FAD),\n(c) a tetrazolium dye precursor,\n(d) an electron transfer agent, and\n(e) a nitrite salt.\n2. The reagent of\n3. The reagent of\n4. The reagent of\nThis application is a divisional of U.S. patent application Ser. No. 10/663,217, filed Sep. 15, 2003, now U.S. Pat. No. 7,011,954, which is a divisional of U.S. patent application Ser. No. 09/513,071, filed Feb. 25, 2000, now U.S. Pat. No. 6,656,697, which is a continuation-in-part of U.S. application Ser. No. 09/282,083, filed Mar. 30, 1999, now U.S. Pat. No. 6,200,773, which is a continuation-in-part of U.S. Ser. No. 09/161,876, filed on Sep. 28, 1998, now U.S. Pat. No. 5,902,731, the disclosures of which are herein incorporatea by reference.\n1. Field of the Invention\nThis invention relates to diagnostic compositions that permit the measurement of analyte concentrations in hemoglobin-containing biological fluids. The compositions are based on tetrazolium dye precursors and involve suppressing the hemoglobin-induced reduction of them.\n2. Description of the Related Art\nAdipose tissue is one of the most abundant forms of energy storage in the body. It releases stored fatty acids into the circulatory system to be metabolized primarily by the liver. In the process, fat is consumed and energy is released and made available to the body. Normally, little fat is consumed, the fatty acids are completely metabolized to carbon dioxide and water, and the conversion does not upset the delicate pH balance of the body. However, if insufficient amounts of carbohydrates are present in the body, due, for example, to dieting, then fat consumption and fatty acid production can increase to potentially harmful levels. In addition to dieters, insulin-dependent patients are vulnerable, because of their impaired carbohydrate metabolism. When excessive fatty acid is used to supply a body's energy demand, then large quantities of acetoacetate, acetone, and beta-hydroxybutyrate are produced. These intermediates are referred to as ketone bodies, and the condition is known as ketoacidosis.\nThe ketone bodies can normally be recycled into other forms by the body, provided it is not overwhelmed. Therefore, a healthy individual accumulates a negligible amount of these analytes. When a large quantity of fats is being metabolized in a relatively short period or when most of the energy is derived from fats, massive amounts of ketone bodies are produced. Excessive production of these fat metabolites can cause certain neurologic disorders, if the problem is not corrected promptly.\nKetone bodies are present in blood and, if a threshold is exceeded, are excreted via the urine. They are easily detected by a modern clinical analyzer. On average, the percentages of beta-hydroxybutyrate, acetoacetate, and acetone are 78%, 20% and 2%, respectively. Because of its relatively low concentration and high volatility, acetone is seldom measured. Instead, acetoacetate is quantitatively determined by a nitroprusside reaction and the beta-hydroxybutyrate is quantified with an enzymatic method. Acetoacetate test strips have been available for decades. They are based on a nitroprusside ion coupling reaction with aldehydes and ketones. An alkaline urine sample or a serum specimen is allowed to react with the nitroprusside for some minutes; and a purple color is developed. The intensity of the color indicates the acetoacetate concentration. However, acetone interferes with the test, resulting in higher readings. Further, as the patient recovers from a ketoacidosis episode, the acetoacetate level in urine and in blood increases, thus making the diagnosis difficult.\nThe beta-hydroxybutyrate test is more useful for monitoring ketone body concentrations. It is based on the oxidation of beta-hydroxybutyrate with the corresponding dehydrogenase in the presence of nicotinamide adenine dinucleotide (NAD) cofactor. (Strictly speaking, only D-beta-hydroxybutyrate is naturally present and oxidized, but we omit the “D” for brevity throughout this specification and the appended claims.) Upon the oxidation, NADH is produced, and its concentration is measured directly with a UV spectrophotometer. Hence, the corresponding signal change in the spectrum is proportional to the analyte's concentration. Unfortunately, the excitation of NADH occurs in the UV region; thus, this mode of detection is suitable only for laboratory instruments. Another method for monitoring beta-hydroxybutyrate is by oxidizing the NADH with a tetrazolium compound.\nTetrazolium compounds are generally very sensitive to strong bases and to light. Thus, special care must be exercised to ensure the integrity of these compounds. Nevertheless, tetrazoliums have played an important role in studies of tissue metabolism. For example, this class of compounds has been used in probing anaerobic oxidation and reduction reactions in cells. Further, they are commonly used in clinical diagnostics. The compounds are typically light-colored or colorless compounds that undergo a reduction reaction, in the presence of a reducing agent, to yield a highly colored formazan. Reducing agents such as ascorbates, sulfhydryls, or variants of NADH, NADPH, PQQH2 (reduced PQQ—pyrrolo-quinoline quinone), FMNH2 (reduced FMN—flavin mononucleotide), and FADH2 (reduced FAD—flavin adenine dinucleotide) are capable of forming the dye.\nIn clinical diagnostics, these dyes have been found to be invaluable for monitoring the formation of NAD(P)H from their parent compounds, NAD(P)+, in anaerobic reactions. (See, for example, U.S. Pat. No. 5,360,595, issued on Nov. 1, 1994 to D. Bell et al.) The redox reaction is rapid and is not sensitive to oxygen. The resulting dye color is very intense and has low solubility in water.\nIn principle, tetrazolium dye precursors can be used to measure ketone bodies and glucose in whole blood. However, the tetrazolium can be reduced non-enzymatically by hemoglobin (Fe(II)) to form a colored formazan, if the hemoglobin is not contained within the red cells of the blood. Thus, free hemoglobin causes serious interference with the measurements. In fact, due to hemolysis and the resultant abundance of free hemoglobin relative to the analyte of interest, in a typical ketone body measurement, the interfering signal from hemoglobin could exceed the intended signal. Glucose measurements, particularly in the normal concentration or above, are not affected as adversely. When the reaction is carried out in high hematocrit samples or at a higher temperature, where the hemoglobin oxidation reaction is faster, interference with glucose measurements is significant, as well. Since the hemolysis of red blood cells, which causes free hemoglobin to be present, cannot easily be avoided, red blood cells must be removed from samples prior to testing, if tetrazolium is to be used for the analysis.\nRed blood cells can be removed from samples by filtering with membranes and filters, by trapping with chemical reagents, or by a combination of both methods. Filtration methods for separating red cells from whole blood are costly and require rather large sample volumes. An example of a blood ketone (beta-hydroxybutyrate) test that uses filtration to eliminate red cells from a whole blood sample is the KetoSite® test available from GDS Diagnostics, Elkhart, Ind. (See Tietz Textbook of Clinical Chemistry, 2nd Ed., ed. by C. Burtis et al., W. B. Saunders Co., Philadelphia, Pa., 1994, p. 974.) The “Test Card” used in that test has two filter layers, which makes the card rather costly and necessitates a large (25 μL) blood sample. Further, the blood must not be hemolyzed.\nA combination of filtration and chemical trapping is used in the Ames® Glucometer Encore™ blood glucose strip, available from Miles. That strip uses a layer of filter material and an agglutination aid (potato lectin) to eliminate interference from red cells. (See Chu et al., European Pat. Appl. 0 638 805 A2, publ. Feb. 15, 1995.)\nIntroducing an oxidizing agent into a system, to oxidize the hemoglobin to methemoglobin, is another way to reduce the hemoglobin interference. Although ferricyanides are known to transform hemoglobin to methemoglobin, they also destroy the desired product, NADH.\nPalmer et al., EPO 0 330 517 B2, published on Aug. 30, 1989, disclose a method for measuring biochemical analytes that involves reacting the analyte with an oxidase enzyme capable of electron transferase activity with the analyte to yield reduced enzyme. The enzyme is colorimetrically assayed to determine the analyte concentration. The enzyme reaction is not oxygen-dependent.\nFreitag et al., WO 94/01544, published on Jan. 20, 1994, disclose a stable reagent for analyte analysis. The reagent includes an enzyme, a phenazine derivative, a tetrazolium salt, and a divalent metal salt to stabilize the reagent.\nStorhoff et al., WO 94/01578, published on Jan. 20, 1994, also disclose a stable reagent for analyte analysis. The reagent includes an enzyme, a mediator, a tetrazolium salt, and an oxidizing agent that stabilizes the reagent.\nThe present invention provides a reagent for measuring the concentration of an analyte in a hemoglobin-containing biological fluid. The reagent comprises:\na) a flavin-dependent enzyme that has a flavin bound to it and that has specificity for the analyte,\nb) a tetrazolium dye precursor,\nc) an electron transfer agent, and\nd) a nitrite salt.\nIn an alternative embodiment of the invention, the reagent comprises;\na) a flavin-dependent enzyme that has specificity for the analyte and does not have a flavin bound to it,\nb) flavin mononucleotide (FMN) or flavin adenine dinucleotide (FAD),\nc) a tetrazolium dye precursor,\nd) an electron transfer agent, and\ne) a nitrite salt.\nThe reagent is particularly suited for coating onto one or more substrates to form a dry reagent strip for measuring an analyte concentration in a hemoglobin-containing biological fluid. A particularly preferred strip comprises\na) a support layer,\nb) on the support layer, a test pad having a coating that comprises\nc) on the test pad, a bibulous top layer that is coated with a nitrite salt.\nAnother strip of the invention comprises\na) a support layer,\nb) on the support layer, a test pad having a coating that comprises\nc) on the test pad, a bibulous top layer that is coated with a nitrite salt.\nThe present invention provides a reagent for measuring analyte concentration in hemoglobin-containing biological fluids (such as whole blood), by producing a concentration of the reduced form of a cofactor, such as NADH, NAD(P)H, PQQH2, FMNH2, or FADH2 that is a measure of the analyte concentration. Inclusion of nitrite in the reagent overcomes the interference of hemoglobin with the measurement of the reduced cofactor concentration. It is particularly useful for, but not limited to, measurement of ketone bodies and glucose.\nAs shown in\nIn the alternative embodiment shown in\nAll flavin-dependent enzymes are suitable for assays with this invention. Suitable oxidase enzymes and their corresponding analytes include: alcohol oxidase for alcohol, glucose oxidase for glucose, galactose oxidase for galactose, cholesterol oxidase for cholesterol, L-lactate oxidase for L-lactate, urate oxidase for uric acid, bilirubin oxidase for bilirubin, and choline oxidase for choline. Suitable dehydrogenase enzymes and the corresponding analytes include: pyruvate dehydrogenase for pyruvate, D-lactate dehydrogenase for D-lactate, and succinate dehydrogenase for succinate.\nWhen not bound to the enzyme, a cofactor must be added to activate the enzyme. Cofactors that may be added to a flavin-dependent enzyme include: flavin mononucleotide (FMN) and flavin adenine dinucleotide (FAD). In the presence of the enzyme, the analyte reduces the cofactor.\nThe next step in the dye-forming process is hydride abstraction from the reduced cofactor by an electron transfer agent. Suitable electron transfer agents include diaphorase, such as lipoic dehydrogenase, ferredoxin-NADP reductase, and lipoamide dehydrogenase. More preferred, when a flavin cofactor is used, are non-enzymatic electron transfer agents, such as phenazine methosulfate (PMS), phenazine ethosulfate (PES), 1-methoxyphenazine methosulfate, or Meldola Blue. Reaction kinetics and stability are the primary factors for selecting an electron transfer agent or “hydride abstractor”. For example, PMS is the universal hydride abstractor, because it has relatively fast reaction kinetics with most of the tetrazolium compounds listed below. For that reason, it is preferred when the cofactor is PQQ. PMS is, however, more sensitive to light than enzyme-based hydride abstractors. Diaphorase is more stable and, for that reason, is preferred when the cofactor is NAD.\nThe captured hydride is transferred to a tetrazolium compound (dye precursor) to form a colored formazan. Tetrazolium compounds that are most suitable for this device are: 2-(2′benzothiazolyl)-5-styryl-3-(4′-phthalhydrazidyl) tetrazolium (BSPT), 2-benzothiazolyl-(2)-3,5-diphenyl tetrazolium (BTDP), 2,3-di(4-nitrophenyl) tetrazolium (DNP), 2,5-diphenyl-3-(4-styrylphenyl) tetrazolium (DPSP), distyryl nitroblue tetrazolium (DS-NBT), 3,3′-[3,3′-dimethoxy-(1,1′-biphenyl)-4,4′-diyl]-bis[2-(4-nitrophenyl)-5-phenyl(-2H tetrazolium (NBT), 3-(4,5-dimethyl-2-thiazolyl)-2,5-diphenyl-2H tetrazolium (MTT), 2-phenyl-3-(4-carboxyphenyl)-5-methyl tetrazolium (PCPM), tetrazolium blue (TB), thiocarbamyl nitroblue tetrazolium (TCNBT), tetranitroblue tetrazolium (TNBT), tetrazolium violet, (TV), 2-benzothiazothiazolyl-3-(4-carboxy-2-methoxyphenyl)-5-[4-(2-sulfoethylcarbamoyl)phenyl]-2H-tetrazolium (WST-4), and 2,2′-dibenzothiazolyl-5,5′-bis[4-di(2-sulfoethyl)carbamoylphenyl]-3,3′-(3,3′-dimethoxy-4,4′-biphenylene)ditetrazolium, disodium salt (WST-5). Preferably, water-soluble dye precursors, more preferably WST-5, are used so as to be compatible with biological samples. Further, when WST-5 is used, the resulting formazan compound exhibits strong spectral absorption at the purple-blue region, thus reducing the need for correcting the background signal from hemoglobin.\nFinally, a hemoglobin suppressor is present in the reagent to curtail the undesirable dye-forming reaction between hemoglobin and the tetrazolium compound. The role of the hemoglobin suppressor is to oxidize the hemoglobin to methemoglobin, which does not react with the tetrazolium or formazan. Surprisingly, nitrite salts, such as sodium nitrite, potassium nitrite, and their derivatives, are very effective in suppressing the hemoglobin, while not destroying the reduced cofactor (such as NADH, PQQH2, FMNH2, or FADH2). The nitrites are effective, as well, at elevated temperature and with high hematocrit samples. Sodium nitrite is preferred, because it has high aqueous solubility, is not toxic, and is relatively inexpensive.\nOptionally, the reagent may also include a stabilizer, such as a divalent metal salt.\nAlthough the reagent of this invention can be used in a wet chemical mode, such as in a cuvette, in preferred embodiments, the invention provides dry strips for assaying beta-hydroxybutyrate or glucose in whole blood. Strips may be either single-layer or two-layer. A two-layer strip consists of a membrane test pad, preferably of nylon, that is placed between a support and a top layer. The support is preferably of polyester sheet. The top layer can be a mesh or any bibulous material known in the art. A preferred material is a porous polyethylene treated with sodium methyl oleoyl taurate, available from the Porex Corp. of Fairburn, Ga. We refer to this material as “Porex”. Preferably, the test pad has a positively-charged surface. More preferably, the test pad is polyamide. The test pad contains a reagent comprising glucose oxidase (including a flavin cofactor), PMS (or one of its analogs), and WST-5 (Table 1, below). The Porex top layer contains a nitrite reagent (Table 2).\nIn a single-layer strip, the Porex layer is omitted, and the entire reagent, including the nitrite (Table 3), is applied to the test pad. Note that in both the two-layer and single-layer strip, either a flavin-dependent enzyme that has a flavin bound to it or a flavin-dependent enzyme that does not have a flavin bound to it may be used. In the latter case, a flavin cofactor (e.g. FMN or FAD) is added.\nIn operation, a user applies a drop of whole blood to the upper surface of the Porex top layer. As the whole blood or lysed blood comes into contact with the Porex, the sodium nitrite is reconstituted and reacts with the available free hemoglobin, thus rendering the hemoglobin harmless to the assay. The resulting, substantially hemoglobin-free sample is transferred to the test pad below, via capillary or gravitational force. On the test pad, the sample initiates the cascade reaction to yield a colored dye, whose concentration is proportional to the analyte concentration in the sample and can be determined directly with a photometer.\nThe following examples demonstrate preferred embodiments of the present invention. In Example 1, a two-layer strip was used, the analyte is glucose, and the enzyme is glucose oxidase. In Example 2, a single-layer strip was used. As before, the analyte is glucose and the enzyme is glucose oxidase. The compositions can readily be modified for application to other analyte-enzyme combinations listed earlier. (See, for example, Tietz Textbook of Clinical Chemistry, 2nd Ed., ed. by C. Burtis et al., W. B. Saunders Co., Philadelphia, Pa., 1994, pp 976–978 and 1174–1175.) The examples are not intended to be in any way limiting.\nA 0.8 μm nylon membrane obtained from Pall Corporation (East Hills, N.Y.) was dipped into the reagent of Table 1, until saturated. The excess reagent was scraped off gently with a glass rod. The resulting membrane was hung to dry in a 56° C. oven for 10 minutes. Porex (0.6 mm thick) was soaked in the nitrite solution of Table 2 and then hung to dry in a 100° C. oven for ten hours. Finally, the membrane was laminated between a polyester stock (0.4 mm Melenex® polyester from ICI America, Wilmington, Del.) and the nitrite-impregnated Porex.\nThe procedure of Example 1 was repeated, except that the first dip was the reagent of Table 3, and there was no second dip, since the Porex was not needed.""]"	['<urn:uuid:4e0be650-6605-477b-b80b-0e8cf34bb205>']	factoid	direct	concise-and-natural	similar-to-document	single-doc	novice	2025-05-12T15:09:02.012753	7	7	2881
19	great lakes water levels fish communities effects	Great Lakes water levels fluctuate due to environmental factors like precipitation, runoff, and evaporation, as well as human influences. These water level changes affect the Great Lakes ecosystems, which are home to at least 179 fish species that contribute to biodiversity. The fish communities are expected to be impacted by projected changes in temperature and precipitation, particularly when these climate changes interact with other human-caused stressors, potentially affecting the nearly 50 million pounds of fish that are sustainably harvested annually.	['Great Lakes Fisheries Heritage Trail: People, fish and fishing\nCelebrate and experience our Great Lakes fisheries heritage while traveling Michigan.\nFrom lighthouses to shipwrecks, Michigan is rich in maritime heritage tradition. Great Lakes fisheries – fish and people who fish – have significantly benefited coastal communities, the Great Lakes region and the nation throughout history and still today. Ecologically, economically and recreationally valuable, Great Lakes fisheries have supported people and communities for generations. Great Lakes fish and fishing – tribal, commercial, and recreational – have shaped the culture, economy, and quality of life for people in Michigan.\nA new Great Lakes Fisheries Heritage Trail offers opportunity to explore the past, present and future of the lakes through the lens of fish and fishing. Museum exhibits and educational opportunities, events and experiences along this trail highlight our fisheries heritage, ecology, management, and the economic and social issues that have defined Michigan’s coastal communities.\nValued Great Lakes fisheries:\nOf national significance, the Great Lakes encompass more than 11,000 miles of shoreline and contain about 20 percent of world’s surface freshwater. The lakes are home to a diversity of Great Lakes fish species valued for their food and recreational contributions, ecological and economic significance.\n- Food – close to 150 million pounds of Great Lakes fish were harvested annually at the turn of the twentieth century; these fish were consumed locally and also preserved by salt and ice to be shipped by boat, train and truck to help feed the growing populations across the country. Today, nearly 50 million pounds of fish are sustainably harvested for food.\n- Fun –1.8 million U.S. anglers enjoy fishing recreationally in Great Lakes waters today. With Michigan bordering four of the lakes, it comes as no surprise that fisheries contribute greatly to recreational tourism from coast to coast.\n- Economy – Great Lakes fisheries contribute $4 billion to $7 billion in economic value annually through fishing-related sales, commercial and charter fishing, community tournaments and coastal tourism.\n- Ecology – at least 179 species of fish contribute to biodiversity and healthy Great Lakes ecosystems; and many ecological issues of the past, from water quality to invasive species introductions, remain as relevant and important today.\nExplore the Great Lakes Fisheries Heritage Trail\nThe Great Lakes Fisheries Heritage Trail network represents a partnership among museum, maritime heritage, and fisheries partners cooperating across Michigan to promote our fisheries heritage. The collective efforts of these partners is helping to preserve and interpret historical artifacts, enhancing local communities and heritage-based tourism, and offering educational opportunities focusing on Great Lakes literacy and stewardship.\nThe trail includes museums, coastal fishing communities, fish markets and processing facilities, events, research and science centers throughout Michigan. Visitors are offered unique opportunities to explore the dynamic social, technological and environmental changes that have shaped today’s fisheries. View an interactive map of Great Lakes Fisheries Heritage Trail sites online.\nWant to learn more about our Great Lakes fisheries heritage? In future articles, we will explore the fisheries heritage stories as told through the partners and places located along the trail. A Michigan Sea Grant publication The Life of the Lakes: A Guide to the Great Lakes Fishery also offers a more in-depth look at the this diverse, dynamic and valuable Great lakes fishery, exploring: Ecology and Management, Today’s Great Lakes Fisheries, History of the Great Lakes Fisheries and the Future of these resources.\nMichigan Sea Grant helps to foster economic growth and protect Michigan’s coastal, Great Lakes resources through education, research and outreach. A collaborative effort of the University of Michigan and Michigan State University and its MSU Extension, Michigan Sea Grant is part of the NOAA-National Sea Grant network of 33 university-based programs.', 'Great Lakes water levels fluctuate in response to such environmental factors as lake precipitation, runoff, and evaporation, as well as human influences like water withdrawals and controls of water flow between lakes. In light of future climate change scenarios, the water level changes we could face will have impacts on not only our Great Lakes ecosystems, but the public health of our coastal communities. To help better understand the implications of climate change on the future of Great Lakes water levels, this webinar will address the following questions:\n- What processes govern the water levels of the Great Lakes? What information is used to understand these processes, and what are the different sources of uncertainty in this information?\n- How is uncertainty in existing and future climate conditions expressed in water level forecasts?\n- How might we incorporate uncertainty of future water levels into our water resource and infrastructure management decisions?\nThe Great Lakes support numerous fishes of ecological, economic, and cultural importance. How will Great Lakes fish communities respond to projected changes in temperature and precipitation? This webinar will provide information about:\n- Expected impacts of climate change on Great Lakes fish communities\n- How interactions between climate change and other human-caused stressors may drive unanticipated change in Great Lakes fish production\n- Needed information gaps that will improve our ability to forecast the response of fish communities to climate change\nGreat Lakes ports, harbors, and marinas are vulnerable to a changing climate. To understand the issue, the NOAA Great Lakes Sea Grant Network has been studying the level of awareness, identifying specific actions for addressing Great Lakes climate change, and creating a scalable tool or matrix to help stakeholders understand both the current value and potential threats or liability related to navigation aids and port infrastructure. This webinar will provide information about:\n- Results of case study surveys about attitudes and awareness of Great lakes ports\n- Climate change issues relevant to Great Lakes ports, harbors, and marinas\n- Development of a scalable economic tool to evaluate the economic impacts for climate change scenarios\n- Results of the tool applications for two Great Lakes ports case studies (Toledo, OH and Duluth/Superior, MN/WI)\n- How a matrix tool concept might be used to understand similar concerns with Storm Water/Waste Water systems\n* Photo Credit: Chris J Benson\nPast and potential increases in the magnitude and frequency of large rainfall events present important challenges for stormwater managers including conveyance systems filled beyond capacity, increased combined sewer overflows, and costal vulnerabilities. The Wisconsin Initiative on Climate Change Impacts - Stormwater Working Group has been examining how to reduce the risk to our communities and improve stormwater management infrastructure. This webinar will provide information about:\n- Historic trends in rainfall in the western Great Lakes\n- Projected precipitation patterns for Wisconsin\n- Assessing stormwater impacts and system vulnerability\n- Adaptation strategies for Great Lakes communities\nForests are key players in biological carbon sequestration and the conservation of biodiversity. How should these public and private lands best be managed to help mitigate the impacts of climate change? This webinar will provide information about:\n- Carbon storage potential of Great Lakes forests and how to measure it\n- Impacts of forest management decisions on short and long-term forest carbon sequestration\n- Linkages between forest age, biological and structural complexity, and ecosystem resilience to climate change']	['<urn:uuid:168283e3-a051-4b0d-ac29-28439ae97671>', '<urn:uuid:552e92b3-70ad-4575-bebc-0484317aa508>']	open-ended	direct	short-search-query	similar-to-document	multi-aspect	novice	2025-05-12T15:09:02.012753	7	80	1175
20	I'd like to work in the mining industry - what educational requirements do mining engineers need, and how do mining companies help develop local talent?	Mining engineers require a bachelor's degree from an accredited engineering program, typically a four-year program that includes coursework in mining methods, safety, mineral economics, and environmental management. Regarding local talent development, mining companies implement internal training programs, particularly focused on Indigenous Peoples and local community members. They prioritize hiring and training local people as one of their major contributions to local economies, helping build capacity among local First Nations, Métis, and other community members to enable them to source a significant portion of their workforce from surrounding communities.	"[""Mining and Mineral Resource Engineering, Bachelor of\n87 rows· The Bachelor of Engineering in Mining and Mineral Resource Engineering program is designed to allow well qualified students who successfully complete the first year of the Mineral Exploration and Mining Technology diploma program to apply to complete an engineering degree through three additional years of full-time study.Best Colleges with Mining and Mineral Engineering Degrees,11 rows· The most common path for those earning a degree in Mining and Mineral Engineering can\nMining and Mineral Engineering Learn\nA bachelor's degree in mining engineering gives you skills to assess mineral extraction sites, develop efficient production techniques and understand the economics of the mining industry. Course options may include mining methods, mining safety, economics of minerals and environmental management.Bachelor of Science in Mining Engineering, Salt Lake City,Successful completion of the undergraduate mining engineering curriculum qualifies the student for a professional career in valuation and development of mineral properties, design, and management of mine systems, as well as in research and consulting.\nBachelor of Mining Engineering (BS), Bachelor Programs are\nThe Bachelor of Mining Engineering (BS) program help students become a professional capable of designing and managing a modern coal or mineral mining operation, or continuing into research, banking, law, or consulting. The Bachelor of Mining Engineering (BS) program is Bachelor of Engineering (B.E.) in Mining Engineering,Bachelor of Engineering B.E. Mining Engineering is a 4 years’ graduate degree program, the minimum eligibility is 12th class with maths, physics and chemistry from a\nBachelor of Science in Mining and Mineral Processing\nBachelor of Science in Mining and Mineral Processing Engineering at Jomo Kenyatta University of Agriculture and Technology (JKUAT) is a 5 years in which the first three all students cover common units mainly in Mathematics, applied Physics, fundamental Engineering principles and principles of mining and mineral processing Engineering.Bachelor of Engineering in Mining Engineering School of,Bachelor of Engineering in Mining Engineering. This is a five year programme done on full time. It also consists of two options of Mine Planning and Rock Mechanics at the final year. The students are allowed to choose the desired option. Candidates who hold a good Diploma in Mining or a related field may be admitted at second year level\nBACHELOR OF ENGINEERING: MINERALS ENGINEERING\nBACHELOR OF ENGINEERING: MINERALS ENGINEERING/METALLURGICAL ENGINEERING The department continues to offer diploma training in metallurgy in addition to the degree program in metallurgical engineering.Best Colleges with Mining and Mineral Engineering Degrees,11 rows· The most common path for those earning a degree in Mining and Mineral Engineering can figure a standard two to four years to earn a degree. The most popular Mining and Mineral Engineering degree earned was a bachelor's degree and it also has the widest range of school possibilities as well.\nThe Best Mining and Mineral Engineering Colleges 2021\nFor all the 340 degrees granted in Mining and Mineral Engineering annually, the majority of them are Bachelors degree. Of the 188 students graduating with degrees at the Bachelors degree level in the US, 80% percent identify as men and 20% percent identify as women.Bachelor of Engineering (B.E.) in Mining Engineering,Oct 03, 2013· B.E. Mining engineering is the discipline of engineering which includes extraction, production, identification, and handling of valuable minerals from a naturally occurring environment. The program is intended to encourage candidates to cross conventional modules of mining building and look for work opportunities.\n68 Bachelors in Mining, Oil & Gas BachelorsPortal\n76 rows· Information about Mining, Oil & Gas Degrees. Mining, oil and gas studies include all Bachelor of Mining Engineering, course outline Online,The Bachelor of Mining Engineering (BS) program help students become a professional capable of designing and managing a modern coal or mineral mining operation, or continuing into research, banking, law, or consulting. The Bachelor of Mining Engineering (BS) program is offered online via distance learning.\nB.Tech Mineral Engineering Course Admission, Eligibility\nB.Tech in Mineral Engineering is the branch of engineering which involves the study of techniques employed for extracting minerals from natural environment such as energy sources, non-metallic and metallic ores and solid fuels. Mining techniques include blasting, production, processing, drilling, marketing, extraction and development.GSU Bachelor of Engineering Honours Degree in Mining,May 06, 2019· GSU Bachelor of Engineering Honours Degree in Mining Engineering Mining engineering is an engineering discipline that involves the theory and science and practice and technology of extracting minerals from their naturally occurring environment.\nBest Bachelor Degrees in Mining Engineering 2021\nMining Engineering As a study that combines the areas of geology, Earth science, and engineering, mining engineering can be a broad and expansive topic. The core focus of mining engineering, for future students, may be on the development and analysis of current mining The Best Mining and Mineral Engineering Colleges 2021,For all the 340 degrees granted in Mining and Mineral Engineering annually, the majority of them are Bachelors degree. Of the 188 students graduating with degrees at the Bachelors degree level in the US, 80% percent identify as men and 20% percent identify as women.\nBachelor of Engineering (B.E.) in Mining Engineering\nBachelor of Engineering B.E. Mining Engineering is a 4 years’ graduate degree program, the minimum eligibility is 12th class with maths, physics and chemistry from a Bachelor of Science in Mining Engineering University of,The B.S. Mining Engineering degree program is fully accredited and offers a variety of rigorous and interesting courses. The goal of the program is to train students qualified to perform the various functions typically exercised by mining engineers: plan, design, operate, and close mines.\nBest Mining And Mineral Engineering Colleges in Utah\nUniversity of Utah offers 3 Mining And Mineral Engineering Degree programs. It's a large public university in a mid sized city. In 2015, 20 students graduated in the study area of Mining And Mineral Engineering with students earning 15 Bachelor's degrees, 3 Doctoral degrees, and 2 Master's degrees.Engineering Mineral & Mining Top Universities,Further down, two Russian universities are ranked this year. The St Petersburg Mining University is ranked just inside the top 20, while the National University of Science and Technology “MISIS” is 42nd. The QS World University Rankings by Subject are based upon academic reputation, employer reputation and research impact (click here to read the full methodology). Use the interactive table\nMining and Mineral Engineering Schools Find Mining and\nFind the top Mining and Mineral Engineering schools, degree programs, colleges and training for starting your Mining and Mineral Engineering career, B.Tech. (Mineral Engineering), Bachelor of Technology in,B.Tech. Mineral Engineering or Bachelor of Technology in Mineral Engineering is an undergraduate Mining Engineering course.Mineral Engineering is a non-traditional mining program that builds upon the more traditional degrees of geological engineering and mining engineering.\nBachelor of Mineral Sciences in Mining Engineering\nMining engineering is an engineering discipline that involves the practice, the theory, the science, the technology, and application of extracting and processing of minerals from their natural environments. of higher learning recognised by the Senate for this purpose may be admitted to courses of study for the degree of Bachelor of MineralMining Engineering Bachelors of Engineering (Honours,As a mechanical engineer with a major in mining engineering, you will help ensure our communities have the vital metals and minerals we need for the steel frames in our buildings through to the microprocessors in our laptops. In this major, you’ll cover the big-picture challenges facing the minerals, mining and resource industries.\nBachelor of Engineering (Mining) (Honours) Federation\nThe Bachelor of Engineering (Mining) (Honours) will equip you with the necessary communication, technical and problem solving skills required to meet the high demand for graduates in mining engineering in Australia and the Asia Pacific Region. Throughout the program, you will explore study areas in mineral deposit evaluation and processingColleges and universities offering Bachelor of science in,Colleges Offering Bachelor of science in mining and mineral processing engineering(Physics) No colleges found offering this course.\nBachelor of Engineering (Honours) Mining Engineering\nMining engineers apply science, geoscience, engineering and technology to the efficient exploration and extraction of minerals from the earth, turning raw materials into valuable products. Minerals are a major component of all manufacturing and construction, and the demand for precious metals and minerals will continue into the future.Mining and Geological Engineers : Occupational Outlook,Sep 21, 2020· A bachelor’s degree from an accredited engineering program is required to become a mining or geological engineer. Pay The median annual wage for mining and geological engineers was $91,160 in May 2019.\n68 Bachelors in Mining, Oil & Gas BachelorsPortal\nInformation about Mining, Oil & Gas Degrees. Mining, oil and gas studies include all operations involved in the exploration, evaluation and extraction of minerals, metals, petroleum and fossil fuels from earth. Mining engineers investigate mineral resources and are responsible for planning and supervising the construction of mines.,"", 'Contributing to Sustainable Community and Regional Development\nThe socioeconomic benefits at the local, regional, and national scale associated with mining activities are the counterbalance to the environmental risks and impacts discussed throughout this report. Quality of life and social well-being require the economic security that comes with industrial development. As a result of this balancing act and the recognition that the people closest to our operations are the ones who are most acutely aware of- and potentially affected by- the impacts of our operations, we prioritize these same people when it comes to providing economic opportunities and benefits.\nDescription of Impacts\nOur business stimulates the local and regional economies surrounding our projects and mines. We pay taxes and royalties directly to governments, which in turn is often used to build and maintain critical infrastructure such as roads, schools, and hospitals. The salaries and revenues earned by our several hundred employees, contractors, and suppliers – who mostly originate from areas near our operations – have direct and significant positive impacts on local and regional socioeconomic conditions. We also directly contribute to local communities through our community investment program. Indirect economic impacts often include the development of local and regional infrastructure.\nAt New Gold, we aim to understand our host communities’ priorities so that we can better contribute to the sustainable economic development of the local area. In addition to engaging with communities to understand their needs and priorities, we commissioned three independent studies that were completed by economic development specialists in the past several years, focused on Cerro San Pedro, Rainy River, and New Afton mines. The findings from these studies inform our approach to understanding and leveraging opportunities to maximize sustainable economic development of the areas around these mines.\nTraining and Employment\nHiring and training local people is one of the major ways we contribute to local economies. We support training and employment of local Indigenous Peoples with internal training programs. Our New Afton, Rainy River and Blackwater sites are great examples of building local capacity among local First Nations and Métis communities, as well as other non-Indigenous local community members, which allows us to source a significant portion of the workforce we need from these same communities.\nAt Rainy River, the construction period provided a great opportunity to train employees for long-term operations. The construction phase involved significant expenditures and it was a priority for New Gold to maximize the proportion of spend allocated to Indigenous companies. During 2017, at our Rainy River site, $64 million (22% of our direct total procurement spending) went to First Nations and Métis-owned companies, including joint ventures. At New Afton, $25 million (28% of our direct total procurement spending) went to First Nations companies and joint ventures. See the Working with Indigenous Communities tab for further information on our approach to prioritizing benefits for local Indigenous communities.\nLooking forward, we plan to roll out the New Gold Local Procurement Standard at Canadian sites. The Standard will provide clarity and consistency regarding procurement practices across our sites.\n|Expenditures for materials, products and services2||689.8||790.3||833.8|\n|Employee wages and benefits (includes payroll taxes paid to governments)||137.4||160.3||196.3|\n|Payments to providers of capital (interest paid and standby fees)||52.3||55.3||63.7|\n|Payments to governments4 (royalties, property, production and income taxes)||26.6||15.5||32.05|\nUnaudited figures. Additional information on economic values, and some site-specific data, is disclosed in our Annual Financial Review available on www.newgold.com.2.\nThese figures include operational as well as capitalized expenditures. Does not include exploration expenditures.3.\nExcludes corporate business development and wages.4.\nIncludes production and property payments, income and other corporate taxes, and royalties paid to governments.5.\nBy country, payments to governments at all levels in 2017 were $5 million in Canada, $14 million in the U.S., $11 million in Australia and $2 million from Mexico. Any discrepancy between this figure and the figures disclosed through Extractive Sector Transparency Measures Act (ESTMA) result from the latter not taking into account tax refunds and including payments for government fees and permits, which are not included here.6.\nExpenditures for voluntary donations and investment of funds in the broader community where the target beneficiaries are external to the company. Includes payments associated with participation agreements and impact benefit agreements, contributions to charities, NGOs and research institutes, funds to support community infrastructure, and direct costs of social programs and direct community development activities for all our sites as well as corporate offices. The significant increase in 2017 is due to issuance of shares for First Nations and Métis associated with the achievement of various milestones at the Rainy River Mine.\nAt New Gold, we consider Community Investments to be donations, sponsorships and/or other investments and payments made through Participation Agreements and Impact Benefit Agreements.\nNew Gold supports many organizations through donations and sponsorships. Our corporate Donations Committee meets on a quarterly basis to review requests from community organizations. Our sponsorships and donations support education, health and wellness, economic diversification, job creation, food banks and environmental conservation initiatives.\nAll New Gold sites continually seek opportunities to support community organizations and activities by, for example, promoting skills development, encouraging local entrepreneurship, and improving environmental stewardship. In some cases, we make investments in community infrastructure with long-term benefits, such as roads, and health and education facilities.\nWhile our sites support local community groups and projects focused on their regional areas, New Gold’s corporate office supports groups that may have a broader reach and sponsors relevant industry, educational and professional organizations’ events. Following the earthquakes in Mexico City and surroundings in September 2017, New Gold doubled the donation made by our Cerro San Pedro Mine to the Mexican Red Cross in support of the UNICEF Canada Earthquake Relief Fund. Other recipients of New Gold corporate donations in 2017 included Indspire, the Breakfast Club, Mining4Life and Special Olympics BC.\nOur Supply Chain\nAt New Gold, we understand that responsible supply chain management is a key generator of business value and an important element of strong corporate responsibility performance. We strive to manage the environmental, social and economic impacts of our supply chain and to create and protect long-term environmental, social and economic value for all involved in our business.\nWe invest significant resources to ensure our purchasing policies positively impact New Gold’s Indigenous and non-Indigenous host communities by prioritizing local vendors and creating opportunities to develop local businesses, as well as promoting responsible and ethical conduct. Our objective is to develop a cost-effective and sustainable supply foundation by developing relationships with our suppliers, based on the principles of fair competition and integrity. Our approach focuses on ensuring we comply with our commitments and on continuously improving our processes.\nNew Gold has over 2,000 suppliers across our operations. Our supply chain expenditure in 2017 exceeded $833 million across our mining operations. We expect ethical behaviour and integrity from our suppliers, and work to develop relationships with suppliers who share our values. Our Anti-Bribery and Anti-Corruption Policy provides clear guidance internally to ensure key checks to confirm that our suppliers and contractors understand our expectations are in place.\n|New Afton||Rainy River||Blackwater||Mesquite||Peak Mines||Cerro\nExcludes local Aboriginal contracts shown on following line.2.\nOnly Canadian sites track data for this category.3.\nTotal excludes the EPCM figure.']"	['<urn:uuid:35d29cfe-060b-4071-b220-386ce709eee7>', '<urn:uuid:6ba0fabc-8a8f-4091-a6a5-8f348a872d6b>']	factoid	with-premise	verbose-and-natural	distant-from-document	multi-aspect	novice	2025-05-12T15:09:02.012753	25	88	2635
21	I'm studying famous buildings in Moscow - what is St. Basil's Cathedral's historical significance, and how does it compare to Stalin's skyscraper projects of the 1940s in terms of their impact on Moscow's skyline?	St. Basil's Cathedral was built between 1555-1560 as a memorial to showcase the stronghold of Tatar in Kazan. Legend has it that Ivan the Terrible blinded the architect to prevent him from building anything more beautiful. In contrast, Stalin's 'seven sisters' skyscrapers were built in the 1940s-50s as symbols of Soviet power, surrounding Moscow's center like a fortress wall. These Gothic-style buildings, including Moscow State University which remained Europe's tallest building until 1990, were meant to proclaim the country's greatness to the world.	['Russian architecture portrays the ideas of many cultures. From onion-shaped domes to Neo-Gothic skyscrapers, Russian style has emerged distinctively over the centuries.\nReligion has had a great influence on Russian architecture. Sharp-sloping roofs, dome-like structures, tent-shaped spires, etc., are some of the common characteristics of their style of architecture. Onion-shaped domes was one of the most distinctive features of Russian architecture. Its shape is similar to a candle flame, which was believed to be the flame of faith reaching up to the heavens. These domes help shed rain and prevent snow build-up. Another characteristic of this architecture is that the church’s icons are mounted on the altar in a hierarchical fashion.\n11th century Russian architecture was greatly influenced by Byzantine models. This was the period when the church fundamentals started to appear. Apart from being inspired by Byzantine models, building construction was also hugely inspired by the Romanesque culture of Western Europe. The Byzantine-inspired churches usually had a dome structure, and more importance was given to the interiors. The churches were mainly made either by circular or axial plans. Structures had vaulted exteriors in order to form a cross.\nSt. Sophia Cathedral\nYear: 1045 – 1050\nIt was built to replace the Oaken Cathedral in the middle of the 11th century, making it the oldest cathedral and oldest building that is still being used.\nDuring the 12th century, church architecture drifted a bit from the regular circular dome-shaped churches to tall churches. Kokoshnik, i.e. a curved structure above the dome was created. Even pyramidal-shaped structures were seen in a few Muscovite churches. The construction of the tent-roofed structures began in this era. The usage of limestone instead of bricks also became popular during this century.\nGolden Gates at Vladimir\nYear: 1158 – 1164\nIt is the only standing ancient Russian city gate. The structure was reconstructed in 1795.\nChurch of the Intercession on the Nerl\nThis is an orthodox church made in white stone. It is built at the confluence of the Nerl and Klyazma rivers.\nYear: 1158 – 1160\nArchitect: Aristotele Fioravanti (Rebuilt Structure)\nThis cathedral in Moscow is considered to be the mother church of the medieval Russian era. It covers an area of 1,178 sq. meters.\nAncient Kremlin at Suzdal\nThis cathedral was the first church in Suzdal. However, due to its weak foundation, it was rebuilt in the 16th century, after being in ruins for almost 80 years.\nIt is considered to be the oldest cathedral in Suzdal that was built not for exclusive use by the king, but it had to be rebuilt as the foundation began giving way, after just about half a century of its construction. It was again renovated in the year 2005.\nThe 13th century saw the rise of the Novgorod period, where the concept of the sloping roof was introduced. The domes were now helmet-shaped and structures usually had one dome. The three-fold division of the exterior walls and pointed domes were seen in the constructions of this era. Also, art flourished in the regions under the Tatars. The rise of tower churches with vertical arrangement of chapels and porches marked the church architecture during this period.\nKrutitsy Patriarchal Metochion\nThis 13th century orthodox church contains structures from the 17th century, but it was shut down in the 1780s. After the Second World War, it was returned to the church.\nDuring this century, a lot of foreign architects were hired to design buildings, and they have gone on to become major tourist attractions today. This era also saw a few wooden edifices that were constructed, the Kizhi being a prominent one. The first frescoes were painted in fresh colors in many monasteries. Many churches were built that had wooden carvings on them.\nThis monastery was once the largest church in Medieval Russia. However, it was later ripped off its glory when Empress Catherine the Great turned several parts of the monastery into a prison. The walls and towers of the monastery are very thick.\nThis monastery has a holy water spring in its yard. It has the Dmitrievskaya Church, Conception Cathedral and Yakovlevskaya Church in its premises.\nMany multi-domed buildings were constructed during this period. The revival of bricks in many constructions were seen in regions like Novgorod and Pskov. The first cathedral in the Moscow Kremlin complex was constructed in this period. There was also a fall in wooden constructions, as the then Tsar Ivan III ordered demolishing of all wooden structures that were surrounding the Kremlin. Glimpses of Italian influence can be seen in the structures of this period.\nArchitect: Antonio Gislardi\nThis tower is named so because it houses a water supplying machine, and in Russian, Vodovzvodnaya means ‘to lift water’. The original tower was blown up by the French army in 1812, and the current tower was rebuilt between 1814 and 1819 by Osip Bové.\nArchitect: Pietro Antonio Solari\nThis tower, bordering the Red Square, was believed to possess miraculous powers that protected the Kremlin from enemy invasions.\nTented-roof structures marked the architecture of this era. The Kolomenskoye Church was the first tent-like brick structure to be built. The development of architectural plans took place in this period, which is also known as the ‘High Renaissance’ architectural period in history. Also, tiered towers in churches were introduced, and the cupolas were substituted by bulb-like spires. The first clock was incorporated in a tower during this period.\nCast by: Andrey Chokhov\nThe Tsar Cannon is a 5.94-meter long cannon that is on display at the Kremlin in Moscow. However, researchers claim that it was never actually used in a war.\nThe Red Square was built to serve as the main marketplace. Coronation of the Tsars also took place here. The square’s name is not related to its color. The word was derived from ‘krasnyi’, which meant ‘beautiful’, but in contemporary Russian it means ‘red’.\nSt. Basil’s Cathedral\nYear: 1555 – 1560\nArchitects: Barma and Postnik Yakovlev\nThis Cathedral was built to serve as a memorial to showcase the stronghold of Tatar in Kazan. It is said that Ivan the Terrible blinded the architect as he didn’t want him to build a cathedral that was more beautiful than this again.\nIvan the Great Bell Tower\nIt is the tallest tower in Moscow Kremlin with a height of 81 meters. It contains the biggest Kremlin bell, the Assumption Bell alongside other smaller bells.\nChurch of the Ascension, Kolomenskoye\nThe church was built to celebrate the birth of Tsar Ivan the Terrible.\nThis cathedral was built as a memorial to celebrate the conquest of Smolensk.\nKul Sharif Mosque in Kazan\nThis mosque was built in the 16th century, and was named after Qolşärif who served there. However, it was destroyed by Tsar Ivan the Terrible, and was rebuilt in 1996 and inaugurated in 2005.\nBy the end of this century, the use of decorative elements increased in church architecture, and cult construction was on the rise. Large churches with bell towers, multiple cupolas, and aisles were built. The edifices, especially the churches, had asymmetric construction with oddly-shaped cupolas and arches. A lot of western architects were hired by the then Tsars to design a few key buildings.\nNew Jerusalem Monastery\nArchitects: Architects: P.I. Zaborsky, Yakov Bukhvostov, Bartolomeo Rastrelli, Matvei Kazakov, Karl Blank and others\nThe reason behind building this monastery at the said area was due to its striking resemblance to the Holy Land. The edifice was shut down in the year 1918, and was later blown up by German army. Currently, it is under renovation.\nChurch of Elijah the Prophet\nYear: 1647 – 1650\nThis church was built by the wealthy brothers Anikey and Nifantey Skripin. The murals in the church, for the first time showed peasants working. Until then, it was not allowed to paint peasants on the walls of wealthy edifices.\nThis church was built in the 17th century, but was consecrated only in the year 1704. However, during the Soviet period, the church suffered heavy damages.\nThe Transfiguration Church, 37 meters tall, is one of the tallest log structures in the world. It is said that the entire structure is built without using a single nail!\nThe face of Russian architecture changed during this period. This era saw a more methodical construction pattern with symmetric structures and geometric shapes. The ‘rule book’ construction phase began during these times. Baroque-styled cathedrals were constructed in most of the eastern cities. Among other prominent architects, the rise of Francesco Bartolomeo Rastrelli was the most significant development in the world of architecture. His magnificent structures were the highlights of St. Petersburg.\nPeter and Paul Fortress\nThe very first building to be constructed in St. Petersburg is this edifice. The structure’s construction began in 1712 and was completed in 1733, a long 21 years later.\nArchitect: Bartolomeo Rastrelli (Rebuilt Structure)\nNamed after Catherine, the wife of Peter the Great, the palace exteriors have been made using around a 100 kilograms of gold.\nGrand Cascade Lodge\nYear: 1714 – 1728\nArchitect: Bartolomeo Rastrelli\nAlso known as the Peterhof Palace, this structure has a giant fountain – the Samson fountain situated at the center of the cascade. The fountain shows the moment when Samson tears open the jaws of a lion.\nYear: 1748 – 1764\nArchitect: Bartolomeo Rastrelli\nThis edifice was built to house the daughter of Peter the Great, Elizabeth, when she opted to become a nun. Today, it is used as a concert hall.\nYear: 1754 – 1762\nArchitect: Bartolomeo Rastrelli\nThis palace was the original residence of the Russian monarchs. The palace has approximately 1,786 doors, 1,945 windows, 1,500 rooms, and 117 staircases.\nYear: 1747 – 1751\nArchitect: Bartolomeo Rastrelli\nThis was the traditional baptismal church of the children of the Tsars. However, it was open to public viewing in 1900. The church was damaged during World War II, and was converted into a post office.\nSt. Michael’s Castle\nYear: 1797 – 1800\nWhen one of the soldiers was guarding the construction site of this castle, he had a vision that Archangel Michael was guarding the castle alongside him. Thus, the castle came to be known as Mikhailovsky (St. Michael’s) Castle.\nLomonosov Moscow State University\nArchitect: Lev Vladimirovich Rudnev\nThe university’s library was the only one that was open to general public, which was done in the year 1756. In 1941, it was named after the famous academician Mikhail Lomonosov.\nThe 19th century was mainly dominated by the Byzantine and Russian Revival. During the first quarter of this century, there was Greek Revival which prevailed up to the middle of the century. Reconstruction of the cities using massive design plans and technical advances was the main priority during that period. In 1918, Alexey Shchusev and Ivan Zholtovsky founded the Mossovet Architectural Workshop, where planning of the reconstruction of Moscow as a new Soviet capital took place. But after World War II, the focus was on reconstructing the destroyed buildings and building new ones. In 1945, Stalin changed the look of many post-war cities. After his death in 1953, social and political changes took place in the country, which brought an end to Stalinist architecture. As a result, the buildings became simple and square-shaped.\nMonument to Minin and Pozharsky\nDesigner: Ivan Martos\nIt is the bronze statue that stands in front of the St. Basil’s Cathedral. It commemorates Prince Dmitry Pozharsky and Kuzma Minin who put an end to the Time of Troubles in Russia.\nUspensky Cathedral in Omsk\nArchitect: Ernest Würrich (Original Structure)\nThis cathedral was built in the year 1891, but was shut down after the Russian Revolution, and was blown up later in 1935. Later, it was rebuilt during the 21st Century.\nHospice of Count Sheremetev\nArchitect: Elizvoy Nazarov\nThis hospice was first built as a charity shelter to the poor, by Count Nikolai Petrovich Sheremetev, husband of Russian theater actress Praskovya. But after her demise, the hospice was reconstructed to serve as a monument in her memory.\nAdmiralty Building at St. Petersburg\nYear: 1806 – 1823\nDesigner: Andreyan Zakharov\nCurrently serving as the headquarters of the Russian Army, this building was reconstructed in the 19th century. The spire has a weather-vane at its top.\nSt. Isaac’s Cathedral\nYear: 1818 – 1858\nArchitect: Auguste de Montferrand\nSt. Isaac’s Cathedral was the city of St Petersburg’s main church, and was built between 1818 and 1858. It has the capacity to accommodate 14,000 worshipers at a time.\nArchitect: Joseph Bové\nThis theater in Moscow was the place where ballet and opera were held. The Bolshoi Ballet and Bolshoi Opera are the oldest and most renowned ones in the world.\nThe Cathedral of Christ the Savior\nArchitect: Konstantin Thon\nThe commissioning of this cathedral took place after the defeat of Napoleon, but was constructed in 1839. However, the original edifice was blown up in 1931, and in 2000, the new cathedral was built.\nArchitect: Alexander Pomerantsev\nThis store is located facing the Red Square, and was built in the year 1893. It was once the largest shopping mall in the whole of Europe.\nThe Church of the Savior on Spilled Blood\nYear: 1883 – 1907\nArchitect: Alfred Alexandrovich Parland\nThe ‘blood’ in the name of the church is because Tsar Alexander II was killed on this site. The church was earlier known as ‘Savior of Potatoes’, as it was used for storing vegetables during World War II.\nOld Believers Church\nThe Old Believers Church is one of the main wooden marvels that is located in Russia.\n20th century construction witnessed a mix of the neoclassicism and skyscraper style. The avant-garde architecture period marked this era’s architectural style. A few architects used a limited color range. Due to the downfall of the Soviet Union, many architectural projects were canceled or put on hold. The theme or height of a building was no longer the main criteria, and this improved the financial conditions and architectural rates in Russia. As a result, skyscrapers were constructed in Moscow city, though, some architects continued to follow the Stalinist architectural style, and constructed buildings like the Triumph Palace.\nThe Shukhov Tower\nYear: 1927 – 1929\nArchitect: Vladimir Shukhov\nIt is the world’s only diagrid hyperboloid transmission tower. Today, there is a 128-meter pylon that stands with about five 25-meter sections of steel lattice.\nThe Anniversary Mosque\nYear: 1924 – 1926\nIt was built as a memorial to mark the thousandth anniversary of the Islamization of the Volga Bulgars in 922.\nOpera House in Chelyabinsk\nYear: 1937 – 1956\nThis opera house was used as an ammunition factory during the Second World War. However, later on it became famous as an opera house.\nDesigned by: Nikolai Nikitin\nThe Ostankino Tower is the tallest freestanding structure in all of Europe, and has remained so for 42 years. It was built to commemorate the 50th anniversary of the October Revolution.\nYear: 1965 – 1981\nThe White House was damaged in the 1993 crisis and has black burn marks on it. Today, it houses the Russian government.\nRussian architecture highlights the history, culture, ethnicity and religious diversity of its people. This architecture can be regarded as one of the richest and magnificent architectures in the world.', 'Brainchild of Stalin, Gothic buildings looms high\nFrom time to time, the Soviet man, raised in the spirit of atheism, needed messages from on high. Fortunately, he had the inspirational Pioneer camp Artek in the Crimea, the Exhibition of Economic Achievements in Moscow, and the famous Moscow Metro — heralds of the communist paradise on earth, which would arrive one fine day, despite all the burdens of grey socialist work days. Soon after the end of World War II, in defiance of all doubters, a grandiose new architectural project was launched. Joseph Stalin, “the father and friend of all Soviet architects” as he was called at their All-Union Congress in 1946, embarked on a colossal construction project designed to convince the Soviet people and the whole world of the victorious Soviet power’s increased self-awareness.\nIn early 1947, the Council of Ministers adopted a resolution for the construction of seven “skyscrapers”. On September 7, that same year, during the celebration of Moscow’s 800th anniversary, at exactly 1:00 pm, the first stone was laid in a special ceremony.\nThe first Moscow skyscraper was completed in 1949, followed every three-five years by another (all but one of the remaining six). Later known as the “seven sisters”, these buildings became famous as monuments of “Stalinist-Gothic” and the defining symbols of Moscow: Moscow State University (240 m.) on Sparrow Hills remained the tallest building in Europe until completion of the Exhibition Center at Frankfurt-on-Main in 1990; the Foreign Ministry; the Ministry of Transportation; two residential buildings; the Hotel Ukraine; and the youngest of the sisters, the Hotel Leningrad (135 m.). In the post-war period, these symbols of a new era, glowing with magnificence, seemed like fantastic emblems of triumph and beacons of a resurgent country proclaiming its greatness to the world. “We can!” That was their architectural slogan, trumpeted from a country that lay in ruins, a country faint from hunger, a country most of whose residents still had to live in cramped communal apartments.\nThe supervision of the skyscrapers’ construction was initially entrusted to the notorious KGB chief Lavrenty Beria (who would be executed in 1953). Beria was also in-charge of creating a Soviet atomic bomb. Thousands of prisoners from the Gulag and German prisoners of war helped in constructing these towering high-rises. A different technique was used for every building to stabilise the ground under the foundation. The costs didn’t matter. Around 2.6 billion Soviet rubles were spent on Moscow State University alone. At current exchange rates, it would amount to around $650 million, more than two billion rubles set aside to rebuild the war-ravaged Stalingrad from 1946 to 1950. Roughly the same amount was spent on the construction of the other six “sisters”.\n|206 meters is the height of the Ukraina hotel, including the 73-meter-long spire. The total area building is more than 88 thousand square meters.|\nThese monumental skyscrapers built in the style of neoclassicism surround the center of the city like a fortress wall. All were built according to one stylistic conception: a dominating central tower which, like an Aztec pyramid, narrows in stair-like stages to the top, and is flanked, in a more or less strict order, by wings. The plan of the buildings may vary, as may the lavish decorations of the towers, the statues and bas-reliefs. Each skyscraper represents a set of architectural quotations and borrowings from various styles and tendencies, from the Renaissance and baroque to Russian church architecture. Clearly, Stalin’s tastes, known for his preference for Gothic, loomed large in the minds of architects. They didn’t always manage to please him: the Foreign Ministry was not originally designed with a spire, but the dictator insisted. So as not to violate the building’s statics, a special light-weight construction had to be perched on top with supports descending five floors made the same color as the skyscraper. After Stalin’s death in 1953, the architects asked the new General Secretary, Nikita Khrushchev, for permission to undo this Stalinist act of despotism. But Khrushchev refused. He wanted the spire on the Foreign Ministry to remain as a “monument to Stalin’s stupidity”.\n|1200 paintings hung on the walls of the corridors, halls and rooms. The most famous are by Vasily Polenov and Alexan- der Deineka.|\nContemporaries were immediately struck by the resemblance of these Stalinist-Gothic monuments to certain American precursors, such as the Manhattan Municipal Building completed in 1914. Given this resemblance, it was hard to make the necessary ideological case. A dialectical explanation was required here: capitalist temples of trade were studied in detail and used as a foundation, the object being to give them a completely new meaning. The shape of the Municipal Building in New York City was determined by the high price of land; this in turn deprived many of the apartments of natural daylight since they face a dark inner courtyard. Needless to say, the Soviet man, standing at the head of all city-planning projects, deserved better.\nStalin’s death marked an end to the principle that “the eye should delight” as quickly as the “father and friend of all architects” had disposed of the Soviet avant-garde in the 1930s. Khrushchev declared war on Stalinist extremes in city planning. Now everything would be sacrificed to functional understatement. Rapid construction of mass housing had begun, leading to many city dwellers getting separate apartments for the first time in their lives. In the Russian mind, however, Stalinist skyscrapers still equal quality, while Khrushchev’s matchbox-size apartments equal quantity.\nThe construction of the Stalinist-Gothic skyscrapers was completed under Khrushchev. But the most impressive skyscraper of all (number eight), which was supposed to be located next to Red Square and soar up to 275 meters, was buried. Instead, on the foundation of this would-be administrative building, the Rossiya was built, the largest hotel in Europe. Fate was not kind either to the classical model of “Stalinist Empire” architecture: the Palace of the Soviets. The construction of this 420-m tower to be crowned with a 100-m statue of Lenin was suspended during the war. When Khrushchev learned how much it would cost to complete the construction, he supposedly said: “Better build chemical combines instead.” In place of the Palace, an enormous outdoor heated swimming pool was built. In the 1990s, the pool was replaced by the Cathedral of Christ the Savior. (The original cathedral had been pulled down by Stalin in 1931.)\nToday, the “seven sisters” have somewhat lost their old lustre. In the two residential buildings the elevator breaks from time to time while the residents, members of the intelligentsia in the first case, pilots and cosmonauts in the second, must make their peace with the fact that their new neighbors are hardly high society. The central building at Moscow State University with its marble staircases and rich interior furnishings and special aura remains very grand, but many of the rooms in the dormitory badly need repair.\nAll rights reserved by Rossiyskaya Gazeta.']	['<urn:uuid:fe6eacb8-76a6-4b4e-a462-4f79ee0a81e1>', '<urn:uuid:5a096087-2fdf-4f27-badc-7c3131ff0379>']	factoid	with-premise	verbose-and-natural	similar-to-document	multi-aspect	novice	2025-05-12T15:09:02.012753	34	83	3677
22	stove clock display blank after power trip but surface units still working possible causes	When the clock/display goes blank but the surface units continue to work, this often indicates an issue with the 120-volt circuit that operates items like the oven and stovetop lights and the clock display. This could be due to a blown fuse in the electric range's circuit, or it might be related to a tripped circuit breaker. The electronic control board might also be malfunctioning, which specifically affects the display while allowing other components to work.	"['If you recently used your stove top or oven, wait for the unit to cool completely before proceeding. Many electric ranges include a fuse in the 120-volt circuit that operates such items as oven and stovetop lights, the electric â¦ When troubleshooting electric stoves there are a number of things that you will need to consider. When your electric stove burner isnât working, your daily routine can be put on hold. Electric supply problems: An electric oven may malfunction if the power supply is disrupted. Most electric ovens have two heating elements: one on top for the broil function, and one on bottom for the bake function. Symptoms of a Stove Circuit Problem. But nothing I\'ve tried is making the clock or oven work. Common solutions for: My Kenmore Stove Oven\'s Not Working. In order to check, you will need to remove the top panel first where you can visually inspect the fan. Push it in with the pilot lit, and turn on the oven while holding it down. ok. gonna switch that out and order the parts then. Problem with the electronic control board. Calling a professional can be quite expensive, especially if they have to diagnose the issue. where would it be? The oven doesn\'t heat up either. When a burner control is turned into the ON position the power light does not light up. Possible Cause: Not Enough Voltage. We know, an easy fix right? After using the self cleaning feature, the next day the oven would not turn on. I took apart the range, everything looks good... no burnt wires or anything. Sounds like I found why it killed it. Tappan 31-2979 electric range model. If the bake element isnât working, the oven may not heat. Look to see if the oven fuse is OK by comparing it to something that does work (like a stove top element) You can easily see if it is ""history"" aka burnt out. Here are things to look for: Check the electrical supply. You donât need an associate degree in electronics to understand how an electric range works.Of course, we are going to be discussing how to repair an electric cooktop, but it is good to have a basic understanding how the range works. But try this. We know, an easy fix right? Get shopping advice from experts, friends and the community! Your stove should be connected to a â¦ This can happen if your oven loses power, because you\'ve turned off the power source or as a result of a power cut. @thecyn depends on the stove but, with an older Gaffer Sattler like mine, you reset on the stove-top, under the burners but above the oven box. Or the stove heating element isn\'t working. 01 - Bake Element. Not only are you unable to cook, but youâll also need to figure out what the problem is. A broken or twisted cord or a tripped circuit breaker can lead to oven malfunction and sometimes the oven may not start at all. I have a kenmore 911.92712020. There are lots of problems which can occur with a stove.If a single burner doesn\'t work on top of your stove, then it suggests that this is a problem related to the single burner rather than â¦ A stove â¦ Grill works but fan oven not getting hot but the fan is working, Can you help please? 1. Before you call a service technician, repair man, or go to the appliance store to purchase a new range, try the following suggestions below. The clock and the oven stopped working. 220v receptacle and wiring looks good and terminals are tight â¦ read more If the element does not glow red, this indicates that the element is not heating. There should be an extra fuse sitting in a dead fuse plug hole that you can use to replace the oven fuse if such is the case. You could see the top 10 Oven Not Working On Electric Stove of 2020 above. This part can be found inside the oven on the rear wall near the top. I have a Siemens HB63AA550B Electric Single Oven all electrics tripped out now it started to work, put cooker back on. Check circuit breakers/fuses and â¦ The following are some common causes of oven timer not working and the respective solutions. Or it\'s not broiling. Viola, fuses for the stove and the top elements. Right here are some regular issues that customers experience when electrical range heater is not functioning: hide 1 Electric Stove Burners And Oven Not Working 1.1 Electric Oven All Burners Not Functioning â Itâs not heating up appropriately 1.2 Range Top Not Functioning â It will certainly not switch on 1.3 My Cooktop Stopped Working [â¦] FEF450WFWB Frigidaire electric range. 590,761. The igniter not working is an easy problem to notice, if you are pressing down on the igniter and nothing is happening will you know something is wrong. Follow the thickest pipe out of the thermostat and it will lead to a junction or a box with a big red or copper button. When i turn the knobs for the stove the surface unit light turns on, but the clock/display is blank and nothinh happens when i turn the knob for the ovenâ¦ I have a glass top electric range Kenmore oven. If the oven light, stovetop fluorescent light, clock or range outlet does not function correctly, often the problem can be a blown fuse or a tripped circuit breaker. Clock, timer, and oven lights all still working. Your igniter should glow as well and even if it is then it might not be working correctly because itâs too weak. Heating Element. If the oven fan isnât working properly, the food might be burning at the back of the oven and not cook at the front. Ensure the appliance is plugged into a grounded outlet with a dedicated circuit (240V receptacle for electric ranges, 120V receptacle for gas ranges and the outlet is operational. Most modern ovens will display a fault code if the oven sensor is at fault. After reading many pages of ""oven not heating"" and ""problems after using self cleaning feature"" I came â¦ The stove burners are not working or not heating normally. The lists of best products are updated regularly, so you can be sure that the information provided is â¦ Before you take that route, try and figure out what the problem is yourself. I have a Kenmore Easy Clean oven about 5-10 yrs old (modelC880-6517590) with oven that stopped working; stove elements work fine; 250V; 53.8A;60Hz; stopped working after house circuit breaker recently tripped; is there a thermal fuse for oven? The electric burners or ""heating elements"" on the stove top and the oven will both not turn on or heat up. Fan-Assisted Oven with Electronic Thermostat. Electric stoves rely on electrical resistance to heat up the burners on the cooktop, which means they function much in the same way as electric heaters. sounds like I had a double wammy there. Broiler and stove top worked fine. If the bake element isnât working, the oven may not reach the set temperature or will take longer to reach that temperature, and food will normally burn on the top. Later, I tried to make myself eggs and the stove is not heating up. On modern electronic control ranges, the oven temperature sensor is the part that regulates the oven temperature. If your Siemens HB63AA550B Electric Single Oven is not heating or tripping the electric supply there is a â¦ The right front dual burner is not working properly. The sparker for the stove still works, so it is getting power. Tom Paul answers Siemens HB63AA550B Oven Elements, Grill, Motors Etc Hi Tom! Most electric ovens use both the bake element and the broil element in a bake cycle, with the bake element performing 90 percent of the heating. The more someone knows how something works the easier it is to diagnose why something is not working. With the oven on Bake preheat or Pizza or any other heating option, after pushing Start once, hold Start until you hear three beeps. If your oven or range is not working there are a couple of things you can check. I\'m thinking it\'s probably the control board, which I think is pn 316630005. Stove top elements, and both ovens stopped working. If your oven or range is not working there are a couple of things you can check. CAUTION: Before you check the oven, make sure your stove is off, cooled down, and unplugged. Whatever the problem, you want it fixed NOW, and that\'s where Repair Clinic comes in. All the cooktop burners work but the oven does not. RE: Kenmore oven not working but stove does? Thank you guys so much for all of your help. Here are top 5 reasons why your oven is not working: 1. Standard electrical outlets do not carry enough power to operate an electric cooktop. All the lights, clock, etc... seems to be working. Troubleshooting an Electric Stove Problem Work the problem backwards. Only the outside ring of the dual burner is working the middle small part of the burner is not â¦ This oven basically operates like the previous fan-assisted oven, but this is a fan-assisted oven without a bottom element, and it has a selector switch with the thermostat built-in. The most common reason why your oven is not working but your grill is, is actually because the clock or timer isn\'t set correctly. The Most Common Problems with an Electric Stove Circuit . We\'ll help you fix your Frigidaire range, stove, or oven quickly and affordably, so life can get back to normal. The lists of best products are updated regularly, so you can be sure that the information provided is up-to-date. If it is not working properly it could be the reason why the range or oven wonât start. I was testing the oven self cleaning and it tripped the breaker in my house. After that, the oven was still working but a few days later it stopped working. If the burners are not heating or not working properly, check the following: If the top burners do not work, but the clock does work, your appliance may be wired improperly, contact your installer for further assistance. Check the electrical supply. Electric Surface Burners Not Heating or Working. IMPORTANT: Troubleshooting and repairing 230 volt circuit requires specialized knowledge and experience. CAUSE: One of the most common reasons for oven timer not working is problem with the electronic control board. Most electric ovens use both the bake element and the broil element in a bake cycle, with the bake element performing 90% of the heating. Hello, my mom made oatmeal on the stove this morning. Voila! I have a model#NX58H900WS/AA gas oven. 1,217. SOLUTION: Over time, itâs possible for these elements to wear out or become damaged. The bake element is the heating element that is found at the bottom of the oven. I had a similar issue with oven not working after a couple of power failures. When the bake element is heating properly, it glows red hot. This Site Might Help You. Top 5 Reasons Electric Oven Wonât Turn On? not only did it have a hot wire hooked to the ground but it had 50 amps going to the stove with it. If the fan on your oven isnât working at all, then it is likely not a case of a faulty heating element, but rather a problem with the fan itself or the motor that turns it. If it dirty, it may be partially obstructed, causing it to not turn. I never realized the amps could be different per stove too. 02:57. While using the stove top, my wife noticed the clock suddenly went blank and won\'t come back. Both the broil and bake elements were working fine. Tried everything, including unplugging, turning off circuit breaker. Ensure the appliance is plugged into a grounded outlet with a dedicated circuit (240V receptacle for electric ranges, 120V receptacle for gas ranges and the outlet is operational. By his I mean start where the problem is, such as the stove hot plate that is not working normally.']"	['<urn:uuid:308b2ff8-8be1-4a4f-8e8b-b5dd679be896>']	open-ended	with-premise	long-search-query	similar-to-document	single-doc	expert	2025-05-12T15:09:02.012753	14	76	2045
23	indigenous cultural materials management traditional modern approaches differences	Traditional management of cultural materials involved physical artforms like quillwork, which was governed by strict protocols (such as the Cheyenne Quilling Society's hierarchical system). Modern approaches, as exemplified by the Sustainable Heritage Network, focus on digital stewardship, empowering tribes to manage their own digitization efforts while respecting cultural protocols through systems like Mukurtu that enable tribe-determined access restrictions.	['Recent, I attended a powwow and met a remarkable artist, Bonita Bent-Nelson, also known as Quillwoman. How she earned the name Quillwoman is obvious once you see her quillwork. But before we look at Bonita’s work, let’s learn a little about Quillwork.\nPorcupine quillwork is an art form completely unique to North America. Before the introduction of glass beads, quillwork was a major decorative element used by the peoples who resided in the porcupine’s natural habitat. The use of quills in designs spans from Maine to Alaska and south to the Mexican border. Where you find porcupines, you find some form of quillwork. The earliest known quillwork was found in Alberta, Canada and dates back to the 6th century CE.\nCheyenne oral history, as told by Picking Bones Woman to George Bird Grinnell, says quilling came to their tribe from a man who married a woman, who hid her true identity as a buffalo. His son was also a buffalo. The man visited his wife and son in their buffalo home, and, while among the buffalo, the man learned the art of quilling, which he shared with the women of his tribe.\nJoining the Cheyenne Quilling Society was a prestigious honor for Cheyenne women. Upon entering the Society, women would work first on quilling moccasins, then cradleboards, rosettes for men’s shirts and tipis, and ultimately, hide robes and backrests.\nPorcupine quills often adorned rawhide and tanned hides, but during the 19th century, quilled birch bark boxes were a popular trade item to sell to European-Americans among Eastern and Great Lakes tribes. The Odawa were famous for their beautiful quillwork embroidery.\nQuills suitable for embellishment are two to three inches long and may be dyed before use. In their natural state, the quills are pale yellow to white with black tips. The tips are usually snipped off before use. Quill readily take dye, which originally was derived from local plants and included colors such as black, yellow, red, and blue. By the 19th century, aniline dyes were available through trade and greatly expanded the quilling palette.\nThe four most common techniques for traditional quillwork are appliqué, embroidery, wrapping, and loom weaving. Appliquéd quills are stitched into hide in a manner that covers the stitches. In wrapping, a single quill may be wrapped upon itself or two quills may be intertwined. Above, a traditional quillwork knife sheath.\nToday, most quillwork is decorative and done on a birchbark base. This small birchbark, sweetgrass and quillwork eagle box from my own collection illustrates the type of quillwork most often seen today.\nIn many places, quillwork is a dying art because it’s difficult and porcupine quills are not readily available.\nWhen I saw Bonita’s work, I was stunned, not only at the beauty, but also at the amount of work and preparation that goes into the product, even before the quills are ready for embroidering. Most quillwork is done with the quill in intact, meaning still rounded, but Bonita cuts each quill apart and uses the quill itself as thread.\nYou can see the difference between the older knife sheath, my eagle box and Bonita’s work, below.\nMost of Bonita’s work is done on leather, not birchbark.\nI asked Bonita how she began, and she told me that she found a dead porcupine and plucked it’s quills. As with many skills, she learned the basics from elders, but then, she was on her own. As you can see, she has developed her own artistic voice.\nBonita was told that her first year, which is in essence a form of apprenticeship, was her give-away year. Everything she made that year was to be given away. The concept of “give-away” in the Native community is linked to the spiritual aspect of grace and gratitude. It has more to do with the giver than the receiver.\nBonita says, “I learned quillwork almost 20 yrs. ago from the late Cherokee elder Ganda-gija-I. Creator gave me the gift of quills and my work reflects that gift. I demonstrate and give workshops and lectures at powwows, historical reenactments, universities, museums and cultural centers throughout the Great Lakes.\nI learned quillwork from the ground up…literally…picking up fresh roadkill, plucking, cleaning and dying my own quills, sometimes using natural dyes, sometimes using RIT dye. I only quill on braintan leather and though I know how to tan my own hides, I leave that task to my friend Dan Vogt of IL because the physical labor it entails is too hard on my hands. While I can sew in historic fashion using only the old methods, I prefer to use a more modern, single-needle technique which makes it quicker and ultimately more affordable but the result is identical to the old way. I have been called on to do restoration of historic items but most of my own work is concentrated on animals, giving life & spirit to each piece with a realism few others do.”\nIn addition to powwows and reenactments, Bonita has worked with the Eiteljorg Museum of American Indian and Western Art in Indianapolis, IN and the Museum of the American Indian in Evanston, IL. Her work has appeared in Native People’s Magazine and as cover art for Studies in American Indian Literature.\nBonita is not an enrolled tribal member, but has both Cherokee and Southern Cheyenne ancestors. I addition, she is an adopted Odawa.\nI was absolutely fascinated by her work and the realism that she is able to achieve.\nI had been at Bonita’s table, under a tree for several minutes, utterly engrossed in her work, when I became acutely aware of movement directly beside my head. I turned my head and to my amazement saw….\nMeet Abby Bent. Abby nearly gave me a heart attack. She was quite interested in what I was doing and was looking over my shoulder at her “mother,” Bonita. Abby goes to powwows and reenactments with Bonita. Why, Abby Bent even has her own facebook page, friend and followers.\nBut that’s not all, Abby had a sidekick, an African Grey named Shaka Zulu, adopted last year when his owner died. Unfortunately, one of Abby’s favorite things to do it to unhook Shaka’s perch chain from the tree and watch poor Shaka drop to the ground. Who thinks birds don’t have personality has never met these birds!\nAs you can see, Bonita’s table where she works and displays her wares is right here, beside Abby and Shaka, and she keep an eye on both, much like a couple of feathered toddlers.\nOne thing is for sure, you won’t forget meeting Bonita and her traveling menagerie anytime soon.\nIt you want to find Bonita, she is on Facebook under “Bonita Bent Nelson” where you can see more of her astounding work, powwows, reenactments, and of course, Abby and Shaka.', 'This series on tribal collections highlights three projects from across the libraries, archives, and museums space that focus on Native American communities and culture, using best practices set forth by the First Archivists Circle’s Protocols for Native American Archival Materials. (Post 1: The Indigenous Digital Archive, Post 2: Warm Springs Sound Archives Preservation Project)\nPost 3 of 3: Sustainable Heritage Network\nSeveral partners are involved in the SHN in addition to Washington State University, including:The Sustainable Heritage Network (SHN) is a grant-funded, “Collaborative Stewardship” program that invests in training and equipping tribal representatives (especially archivists, librarians, and museum specialists) to manage their own digitization efforts instead of outsourcing to non-tribal service providers, an approach known as the “indigitization” model.\nThe SHN is managed by the Center for Digital Scholarship and Curation at Washington State University. A 2012 report by the Association of Tribal Archives, Libraries and Museums (ATALM), titled “Sustaining Indigenous Culture,” revealed a need among tribal memory institutions for easily accessible and online training materials for digitization and digital preservation of cultural heritage assets (see About SHN). In response to this need, the SHN was formed to provide open access online tutorials, articles, and other educational web resources, as well as both virtual and in-person workshops dedicated to the digital stewardship lifecycle, including digital tools and digital preservation. The main purpose of the Sustainable Heritage Network is to “… bring together communities, institutions, and professionals to support each other by sharing knowledge, educational resources, and technology necessary for the responsible digitization and preservation of cultural heritage.” (About SHN)\n- Association of Tribal Archives, Libraries and Museums\n- Center for Digital Archaeology\n- University of Oregon Libraries\n- Alaska Native Language Archives\n- California Indian Museum and Cultural Center\n- Native American Archives Roundtable\n- Society of American Archivists\nA team of expert advisors to the SHN include representatives from:\n- California Digital Library\n- Association of Tribal Archives, Libraries, and Museums\n- Alaska Native Heritage Archive at the University of Alaska, Fairbanks\n- Dalhouse University\n- Western Washington University\n- California Indian Museum and Cultural Center\n- University of Oregon\n- Smithsonian Institution’s National Museum of the American Indian\n- University of Texas\n- Library of Congress\nAll of the resources compiled by the SHN are made freely available to the public online at their website. Resources are organized by area of focus, providing materials such as slides, checklists, guides, how-tos, case studies, blogs, and recommended best practices for digitizing and preserving photographs and images, audio recordings, artifacts and objects, books and documents, general processing, language documentation, and GIS, CMS, and Databases. The site also provides information about all of the different communities involved, providing a platform for connecting people as well as resources and information.\nThe indigitization model and programs like the SHN contribute to information reliability, access, and social justice because they entrust the stewardship of cultural heritage resources in the digital age to the people who belong to the culture from which the materials were produced, and thus have the highest stake in their preservation as well as how and by whom materials can be accessed. The digitization of indigenous cultural heritage materials and documents not only helps to preserve the data about the artifacts, it also can make items more accessible for the people who need access. With software solutions such as Mukurtu, which enables access restrictions that are determined by the tribes, cultural protocols can be respected when certain materials should not be made widely accessible.\nThe SHN spreads knowledge and expertise in these areas, with repatriation of cultural materials in the form of knowledge about how to best preserve and provide access to these materials. In general, the program is broadening awareness of cultural heritage, and empowering people to take ownership of their cultural heritage, bringing Native perspectives and reclaiming language and culture in the digital world (A Visit to the CIMCC).\nLearn more about the Sustainable Heritage Network:\n- Sustainable Heritage Network website: https://sustainableheritagenetwork.org/\n- Indigitization: Toolkit for the Digitization of First Nations Knowledge: http://www.indigitization.ca/\n- Miriam Jorgensen, 2012. Sustaining Indigenous Culture: The Structure, Activities, and Needs of Tribal Archives, Libraries, and Museums. Oklahoma City, OK: Association of Tribal Archives, Libraries, and Museums: http://www.atalm.org/sites/default/files/sustaining_indigenous_culture.pdf\n- Center for Digital Archaeology interview (2013) with Nikki Myers-Lim, executive director of the California Indian Museum & Cultural Center (CIMCC) in Santa Rosa, CA: https://youtu.be/PQ_bfccX8tI']	['<urn:uuid:9283c6cc-5de4-4878-9ca8-034ef9fba76c>', '<urn:uuid:ec555cdf-32c3-44eb-a69b-ce37b331ea29>']	factoid	with-premise	long-search-query	distant-from-document	multi-aspect	expert	2025-05-12T15:09:02.012753	8	58	1862
24	How did Carthage evolve from a port city to a republic?	Carthage began as a minor port where Phoenician traders stopped to resupply or repair their ships, but grew significantly after 332 BCE when refugees from Tyre fled there with considerable wealth, establishing it as the new center of Phoenician trade. By the 4th century BCE, the government transformed from a monarchy into a republic based on meritocracy. The republic was governed by two elected magistrates called suffetes who worked with a senate of 200-300 lifelong members, while laws were passed by a citizen assembly. By 500 BCE, this republican system included the suffetes serving alongside a senate, citizen assembly, and pentarchies (five-person commissions), as well as a 'court of 104' that had power over military commanders. Under this system, Carthage grew to house over half a million people by the second century BCE.	"[""Carthage was a Phoenician city-state on the coast of North Africa (the site of modern-day Tunisia) which, prior the conflict with Rome known as the Punic Wars (264-146 BCE), was the largest, most affluent, and powerful political entity in the Mediterranean. The city was originally known as Kart-hadasht (new city) to distinguish it from the older Phoenician city of Utica nearby. The Greeks called the city Karchedon and the Romans turned this name into Carthago.\nIt was founded c. 814 BCE by the legendary Phoenician queen Dido, increased in size after an influx of refugees from the city of Tyre following Alexander the Great’s conquests of 332 BCE, and afterwards expanded until it was the seat of the Carthaginian Empire with colonies (such as Sabratha) along the North African coast, in Sicily, Spain, and elsewhere; these would all be lost following the Punic Wars which elevated Rome to Carthage’s former position as the greatest Mediterranean power.\nThe history of the ancient city is usually divided into five periods:\n- Ancient Carthage (Punic Republic) – c. 814-146 BCE\n- Roman Carthage – 146 BCE - 439 CE\n- Vandal Carthage – 439-534 CE\n- Byzantine Carthage (Exarchate of Africa) – 534-698 CE\n- Muslim Arab Carthage (Islamic Carthage) – 698-1270 CE\nOwing to limitations of space, this article will primarily deal with Ancient Carthage/the Punic Republic.\nIn 698 CE, the city was conquered during the Muslim Arab invasion of North Africa and destroyed. It would be rebuilt, though on a modest scale compared with the city at its height, until it was completely destroyed under the reign of Muhammad I al-Mustansir (r. 1228-1277 CE) after defeating the European Christian invasion of the Eighth Crusade of 1270 CE. The site would continue to be inhabited, though the ancient ruins were neglected until the 1830s CE when modern excavations began.\nFoundation & Expansion\nAccording to legend, Carthage was founded by the Phoenician Queen Elissa (better known as Dido) c. 814 BCE; although Dido's historicity has been challenged, the founding does date to about this time. Dido was allegedly fleeing the tyranny of her brother Pygmalion of Lebanon, landed on the coast of North Africa, and established the city on the high hill later known as the Byrsa. The legend claims that the Berber chieftain who controlled the region told her she could have as much land as an ox hide would cover; Dido cut a single ox hide into thin strips and lay them end-to-end around the hill, successfully claiming it for her people.\nDido’s reign is described by the Roman poet Virgil (l. 70-19 BCE), and others, as impressive, noting how the city grew from the small community on the hill to a grand metropolis. This account, and others like it, are legendary but Carthage, which seems to initially have been a minor port on the coast where Phoenician traders stopped to resupply or repair their ships, was clearly a major center of trade by the 4th century BCE.\nThe city developed significantly following Alexander's destruction of the great industrial and trade center of Tyre (considered Carthage’s mother-city) in 332 BCE when Phoenician refugees fled from there to Carthage. These Tyrians arrived with whatever wealth they had and, since many whom Alexander spared were those rich enough to buy their lives, they landed in the city with considerable means which established Carthage as the new center of Phoenician trade.\nThe Carthaginians then established a working relationship with the tribes known as the Masaesyli and the Massylii of the North African Berber (Imazighen) Kingdom of Numidia who would fill the ranks of their military, primarily as formidable cavalry troops. From a small town on the coast, the city grew in size and grandeur with enormous estates covering miles of acreage. Carthage quickly became the richest and most powerful city in the Mediterranean.\nCarthaginian government, formerly a monarchy, was a republic based on meritocracy (rule of the elite) by the 4th century BCE. The top position was held by two elected magistrates known as suffetes (“judges”) who governed in conjunction with a senate of between 200-300 members who held the position for life. Laws were passed by an assembly of citizens who would vote on measures proposed by the suffetes and senate. The aristocrats lived in palaces, the less affluent in modest but attractive homes, and the lower classes in apartments or huts outside the city.\nTribute and tariffs regularly increased the city’s wealth on top of the lucrative business in maritime trade. The city’s harbors were immense, with 220 docks, and gleaming columns which rose around it in a half-circle, in front of towering arches and buildings ornamented with Greek sculpture. There were two harbors, one for trade and the other for warships, which operated constantly in resupplying, repairing, and outfitting vessels. The Carthaginian trading ships sailed daily to ports all around the Mediterranean Sea while their navy, supreme in the region, kept them safe and, also, opened new territories for trade and resources through conquest as the Carthaginians built their empire.\nThe city had four residential sections, which grew up around the citadel of the Byrsa in the center, and was surrounded by walls which stretched 23 miles (37 kilometers) in length from the harbors inland. The city had all the accommodations and refinements of any great ancient city – a theater for entertainment, temples for religious observances, a necropolis, an agora (marketplace) – but on a much grander scale. Its patron deity was the goddess of love and fertility, Tanit who was worshipped alongside her consort Baal-Hamon. It is possible that children were sacrificed to Tanit in the sacred precinct known as the Tophet, but this claim has been challenged, and it is equally likely that the Tophet of Carthage was simply a necropolis reserved for infants and the young.\nAffluence & Invasion\nThe city’s wealth was due not only to its advantageous position on the North African coast, from which it could control sea traffic between itself and its colony on Sicily, but also to the people’s skill in agriculture. The writer Mago of Carthage (dates unknown) wrote a work of 28 volumes devoted to agriculture and veterinarian science which was considered the most comprehensive on the subject of its time and reflects the Carthaginian’s intense interest in farming and animal husbandry. Mago’s works were considered so important that they were among the few that would be spared by the Romans after Carthage’s final defeat in 146 BCE. Roman references to the books are now all that remain of them.\nThe Carthaginians planted fruit trees, grapes, olive trees, and vegetables in a ring of gardens irrigated by small canals and then expanded their cultivation outward beyond the city walls to fields of grains. The fertility of the land, and their expertise in cultivation, increased the city’s wealth through trade with the interior as well as maritime trade elsewhere as Carthage continued to flourish.\nIt was this expansion that first brought Carthage into conflict with others. In 310-307 BCE, North Africa was invaded by Agathocles of Syracuse (r. 317-289 BCE) who sought to subdue Carthage and use her wealth to fund his wars. Agathocles was able to feed his army easily off the land because the crops grew in such abundance. He was only defeated because the Libyans and Berbers, who worked the land, sided with the Carthaginians who had treated them well. Agathocles was driven from North Africa and Carthage continued to prosper until it became involved in a conflict with Rome, then just a small city-state on the Tiber River in Italy, in 264 BCE.\nThe Punic Wars\nControl of Sicily was divided between Rome and Carthage who supported opposing factions on the island which quickly brought both parties into conflict directly with each other. These conflicts would be known as the Punic Wars from the Phoenician word for the citizens of Carthage (given in Greek as Phoinix and in Latin as Punicus). When Rome was weaker than Carthage, they posed no threat. The Carthaginian navy had long been able to enforce the treaty which kept the Roman Republic from trading in the western Mediterranean. When the First Punic War (264-241 BCE) began, however, Rome proved far more resourceful than Carthage could have imagined.\nThough they had no navy and knew nothing of fighting on the sea, Rome quickly built 330 ships which they equipped with clever ramps and gangways (the corvus) which could be lowered onto an enemy ship and secured; thus turning a sea battle into a land battle. After an initial struggle with military tactics, Rome won a series of victories and finally defeated Carthage in 241 BCE. Carthage was forced to cede Sicily to Rome and pay a heavy war indemnity.\nFollowing this war, Carthage became embroiled in what is known as The Mercenary War (241-237 BCE) which started when the Carthaginian army of mercenaries demanded the payment Carthage owed them. This war was finally won by Carthage through the efforts of the general Hamilcar Barca (l. c. 285 - c. 228 BCE), father of the famous Hannibal Barca (l. 247-183 BCE) of the Second Punic War.\nCarthage suffered greatly from the First Punic and Mercenary War and, when Rome occupied the Carthaginian colonies of Sardinia and Corsica, there was nothing the Carthaginians could do about it. They tried to make the best of their situation by expanding holdings in Spain but again went to war with Rome when Hannibal attacked the city of Saguntum, an ally of Rome in Spain, in 218 BCE.\nThe Second Punic War (218-202 BCE) was fought largely in northern Italy as Hannibal invaded Italy from Spain by marching his forces over the Alps. Hannibal won every engagement against the Romans in Italy. In 216 BCE he won his greatest victory at the Battle of Cannae but, lacking sufficient troops and supplies, could not build on his successes. He was finally drawn from Italy and defeated by the Roman general Scipio Africanus (l. 236-183 BCE) at the Battle of Zama, in North Africa, in 202 BCE and Carthage again sued for peace.\nPlaced, again, under a heavy war indemnity by Rome, Carthage struggled to pay their debt while also trying to fend off incursions from neighboring Numidia under the king Masinissa (r. c. 202-148 BCE). Masinissa had been Rome's ally in the Second Punic War and was encouraged by Rome to raid Carthaginian territory at will. Carthage went to war against Numidia and, in so doing, broke the peace treaty with Rome which forbid Carthage from mobilizing an army.\nCarthage felt it had no choice but to defend itself against Masinissa's invasions but was censured by Rome and ordered to pay a new war debt to Numidia. Having only recently paid off their debt to Rome, they now owed a new crippling war debt. Rome was not concerned with whatever conflict Carthage and Numidia were involved in but did not care for the sudden revitalization of the Carthaginian military.\nCarthage believed that their treaty with Rome was ended when their war debt was paid; Rome disagreed. The Romans felt that Carthage was still obliged to bend to Roman will; so much so that the Roman Senator Cato the Elder ended all of his speeches, no matter what the subject, with the phrase, “Further, I think that Carthage must be destroyed.” In 149 BCE, Rome decided upon just that course of action.\nA Roman embassy to Carthage presented a list of demands which included the stipulation that Carthage be dismantled and then rebuilt further inland, thus negating the long-recognized advantage it had in trade from its position on the coast. The Carthaginians, understandably, refused to do so and the Third Punic War (149-146 BCE) began.\nThe Roman general Scipio Aemilianus (l. 185-129 BCE) besieged Carthage for three years until it fell. After sacking the city, the Romans burned it to the ground, leaving not one stone on top of another. A modern myth has grown up that the Roman forces then sowed the ruins with salt so nothing would ever grow there again but this claim has no basis in fact. It is said that Scipio Aemilianus wept when he ordered the destruction of the city and behaved virtuously toward the survivors of the siege.\nUtica now became the capital of Rome’s African provinces and Carthage lay in ruin until 122 BCE when Gaius Sempronius Gracchus (l. 154-121 BCE) the Roman tribune, founded a small colony there. Gaius’ political problems, and the memory of the Punic wars still being too fresh, however, caused the colony to fail. Julius Caesar proposed and planned the rebuilding of Carthage and, five years after his death, Carthage rose again. Power now shifted from Utica back to Carthage – which became Rome’s breadbasket owing to the same agricultural success which had enriched it before - and it remained an important Roman colony until it fell to the Vandals under their king Gaiseric (r. 428-478 CE) in 439 CE.\nCarthage had risen in prominence as Christianity grew and Augustine of Hippo (St. Augustine, l. 354-430 CE) contributed to its prestige by living and teaching there. The city was considered so illustrious, in fact, that the Council of Carthage of 397 CE was held there; the series of synods which would confirm the biblical canon for the Western Church, legitimizing the narratives which would come to be known as the Bible. The Vandal invasion of North Africa did nothing to halt Christianity’s development there, but tensions would rise between the Arian Christians (the Vandals primarily) and Trinitarian Christians just as they did elsewhere.\nThe Vandals under Gaiseric took full advantage of the location of their new city and plundered passing ships at will while also raiding coastal cities. Roman attempts to dislodge them failed and so a treaty was signed in 442 CE between Gaiseric and Valentinian III (r. 425-455 CE) acknowledging the Vandal Kingdom of North Africa as a legitimate political entity and establishing peaceful relations. When Valentinian III was assassinated in 455 CE, however, Gaiseric disregarded the treaty, believing it was an agreement only between himself and the emperor, and sailed for Rome. He looted the city but, in accordance with the request of Pope Leo I (served 440-461 CE), did not damage it nor harm the populace. The Vandals would continue to hold Carthage, and profit from its location, until after Gaiseric’s death.\nThe later Vandal king Gelimer (r. 530-534 CE), an Arian Christian, reinstituted the persecution of Trinitarian Christians which enraged the Eastern Roman emperor Justinian I (r. 527-565 CE), a trinitarian, who sent his great general Belisarius (l. 505-565 CE) to North Africa. Belisarius won the short-lived Vandalic War (533-534 CE), brought Gelimer back to Constantinople in chains, and restored Carthage to the Byzantine Empire (330-1453 CE) under which it continued to flourish.\nUnder the Byzantines, Carthage prospered through trade and as a major source of grain for the Eastern Roman Empire (the Western Roman Empire having fallen c. 476 CE). Around 585 CE, Carthage became the seat of the Exarchate of Africa under the Byzantine emperor Maurice (r. 582-602 CE), a separate administrative region established for more effective rule of the western areas of the empire.\nIn 698 CE, the Muslims defeated the Byzantine forces at the Battle of Carthage, destroyed the city completely, and drove the Byzantines from Africa. They then fortified and developed the neighboring city of Tunis and established it as the new center for trade and governorship of the region. Under the Arab Muslims, Tunis fared better than Carthage, but the city continued to thrive until the Eighth Crusade of 1270 CE when it was taken by the European Crusaders who fortified the citadel of the Byrsa. Once they were defeated, Muhammad I al-Mustansir had the city’s defenses torn down and many of the buildings razed to prevent any further such occupation.\nThe site of the ancient city continued to be inhabited and was included in the region taken by the Ottoman Empire (1299-1922 CE) who had no interest in excavating the ruins. The stones of the fallen houses, temples, and walls were carried off for personal or administrative building projects or left where they had been found. Modern archaeological excavation began in the 1830s CE through the efforts of the Danish consulate and continued under the French between c. 1860-1900 CE.\nFurther work at the site was undertaken throughout the first part of the 20th century CE but, as at Sabratha and other sites, the archaeologists were more interested in the Roman history of Carthage. The political and cultural zeitgeist of the time defined the Carthaginians, who were Semites, as a people of little value, and anti-Semitism significantly influenced not only the interpretation of physical evidence but the choice of what was kept for placement in museums or discarded.\nThe history of the period of Ancient Carthage, therefore, suffered as much from these modern-day excavations as from the city’s destruction by Rome or later conflicts. It was not until after World War II that systematic, unbiased, work at Carthage would begin; a paradigm consistent with the excavation and interpretation of many other ancient sites.\nCarthage still lies in ruin in modern-day Tunisia and remains an important tourist attraction and archaeological site. The outline of the great harbor can still be seen as well as the ruins of the homes, public baths, temples, and palaces from the time when the city of Carthage ruled the Mediterranean as the most opulent jewel of the North African coast."", 'Founded by a seafaring people known as the Phoenicians, the ancient city of Carthage, located in modern-day Tunis in Tunisia, was a major center of trade and influence in the western Mediterranean. The city fought a series of wars against Rome that would ultimately lead to its destruction.\nThe Phoenicians were originally based in a series of city-states that extended from southeast Turkey to modern-day Israel. They were great seafarers with a taste for exploration. Accounts survive of its navigators reaching places as far afield as Northern Europe and West Africa. They founded settlements throughout the Mediterranean during the first millennium B.C.\nCarthage, whose Phoenician name was Qart Hadasht (new city), was one of those new settlements. It sat astride trade routes going east to west, across the Mediterranean, and north to south, between Europe and Africa. The people spoke Punic, a form of the Phoenician language.\nThe two main deities at Carthage were Baal Hammon and his consort, Tanit. Richard Miles writes in his book Carthage Must Be Destroyed (Penguin Group, 2010) that the word Baal means “Lord” or “Master,” and Hammon may come from a Phoenician word meaning “hot” or “burning being.” Miles notes that Baal Hammon is often depicted with a crescent moon, while Tanit, his consort, is shown with outstretched arms.\nThe earliest archaeological evidence of occupation at Carthage dates to about 760 B.C. The settlement quickly grew to encompass a 25-30 hectare (61-74 acres) residential area surrounded by a necropolis (graveyard), notes Roald Docter, of Ghent University.\nWithin a century the settlement would have city walls, harbor installations and a “Tophet,” a controversial installationin the southeast of the city that may have been used for child sacrifice (it could simply have been a special burial ground).\nA great marketplace (which the Greeks called an “agora”) also developed and, in later centuries, was located by the sea, writes University of Sydney professor Dexter Hoyos in his book, The Carthaginians (Routledge, 2010). “Besides its role as a market, it would be the obvious place for magistrates to assemble the citizens for elections and lawmaking,” he writes.\nBy 500 B.C., the city’s system of government, as suggested by the large marketplace, was a republic of sorts. Hoyos notes that the Carthaginians had two elected sufetes (the Greeks called them kings) that served along with a senate, citizen assembly and pentarchies (five-person commissions). There was also an enigmatic body called the “court of 104” that occasionally crucified defeated Carthaginian generals.\nAs with other ancient (and to some degree modern) republics, wealthy individuals from powerful families had the advantage in getting into office. Nevertheless, the combination of trade opportunities and republican structure appears to have had some success at Carthage. In the second century B.C., just before it was destroyed by Rome, the city boasted a population estimated at more than half a million people.\nAs the city grew, so did its external influence, with evidence of involvement in places such as Sardinia, Spain and Sicily, entanglements that would ultimately lead to conflict with Rome.\nIt wasn’t unusual for large cities in the ancient world to have elaborate foundation myths, and Greek and Roman writers had a tale for Carthage, one set more than 2,800 years ago.\nAccording to legend, Carthage was founded by Elissa (sometimes referred to as Dido), a queen of the Phoenician city of Tyre, located in modern-day Lebanon. When her father died she and her brother Pygmalion both ascended the throne. This did not work out well, with Pygmalion eventually ordering the execution of Elissa’s husband, the priest Acherbas.\nElissa, along with a small group of settlers, would leave the city, sailing nearly 1,400 miles (2,300 km) west. The local king, a man named Iarbas, said they could build as large a settlement as could be encompassed by an ox-hide at Carthage (the settlers ended up slicing up the ox-hide really thin). Iarbas would eventually demand that Elissa marry him to which she responded by killing herself with a sword atop a funeral pyre.\nArchaeologists have yet to find remains of Carthage datable to the ninth century B.C., and scholars tend to regard this story as being largely mythical. The tale, moreover, comes largely from Greek and Roman sources, and it’s debatable whether Carthaginians actually believed in it themselves.\nRome and Carthage would fight a total of three ""Punic Wars,"" which ultimately led to the latter’s destruction and re-founding.\nThe two cities were not always hostile. Before the First Punic War started in 264 B.C., they had a long history of trade, and at one point the two powers actually allied together against Pyrrhus, a king based in Epirus, which is in modern-day Albania. This is known today as the Pyrrhic War.\nHistorians still debate the causes of the Punic Wars but the spark that lit it off happened in Sicily. Carthage had long controlled territory on the western part of the island, fighting off the Greek city of Syracuse.\nIn 265 B.C., the Mamertines, a group of former mercenaries based in Messina, Sicily, appealed to both Carthage and Rome for help against Syracuse.\nThey ended up getting both requests answered.\nRichard Miles writes that Carthage sent a small force to Messina, which was then ejected by a larger Roman force. The situation quickly escalated into open war between the two great powers.\nIn the beginning, Carthage had naval supremacy, giving them the edge. However, the Romans built up a fleet quickly, developing a bridge-like device called a “corvus,” which made it easier for their embarked troops to storm Carthaginian ships.\nThe First Punic War would go on for more than 20 years and end in Carthage accepting a humiliating peace treaty that ceded Sicily along with much of their Mediterranean holdings to Rome.\nThe Second Punic War would last from 218 to 201 B.C. and would see the Carthaginian general Hannibal, based in Spain, attack Italy directly by going through the Alps. At first his attack proved successful, taking a great deal of territory and inflicting a Roman defeat at the Battle of Cannae, in southern Italy in 216 B.C.\nHannibal was, however, was unable to take Rome itself. Over the next decade, a series of Roman counterattacks in Italy, Spain and Sicily turned the tide of war against Carthage and in 204 B.C., a Roman force led by Publius Cornelius Scipio landed in Africa, defeating Hannibal at the Battle of Zama. The peace imposed on Carthage left it bereft of land and money.\nThe Third Punic War, from 149 to 146 B.C., consisted mainly of a prolonged siege of Carthage, which ended with the city being burned. A modern-day myth has the Romans “salting the earth” to prevent the fields of Carthage being tilled again; however, there is no ancient evidence for this.\nCarthage would not be gone for long. A century later, Julius Caesar founded a new Roman city on the site and by the second century A.D., it was the largest North African city west of Egypt.\nResearcher Aïcha Ben Abed writes that among its features were giant “Antonine baths,” that were “the largest public baths in the Roman Empire” (from Tunisian Mosaics, 2006, Getty Publications), a sign of the city’s success.\nThe importance of Carthage would not diminish as time went on and today Tunis, a modern-day capital of more than 2 million people, surrounds the ancient ruins.\n— Owen Jarus, LiveScience Contributor']"	['<urn:uuid:98ea1cde-1a21-4563-a4c6-88da15ad2cb2>', '<urn:uuid:dfb0b85b-0861-4dc1-9407-ea55f091e82c>']	open-ended	direct	concise-and-natural	distant-from-document	multi-aspect	expert	2025-05-12T15:09:02.012753	11	133	4150
25	handbike vs wheelchair shoulder load comparison	The load on the shoulder is much lower for handcycling compared to wheelchair propulsion, as shown by measurements of glenohumeral contact force (the force with which the shoulder joint is compressed during propulsion)	['Shoulder Health and Mobility\nDue to their upper extremity dependency in daily life, the mechanical loading on the shoulder in individuals with spinal cord injury (SCI) is frequent and high. This increases the risk of tissue overload and shoulder complaints, thereby affecting functioning, participation and quality of life. This is confirmed by results from the Swiss Spinal Cord Injury Cohort Study (SwiSCI).\nDue to its anatomical structure, the human shoulder enables a large range of motion while joint stability is mainly controlled by muscles, rendering the upper extremity vulnerable to complaints.\nIn order to diminish the shoulder complaints, we aim our research at:\n- studying underlying mechanisms of shoulder load, in our movement laboratory,\n- quantifying and relating load, capacity and tissue change,\n- development of methods in monitoring shoulder load in daily conditions.\nBased on increased insight in the relation of load, capacity and tissue change, injury prevention programs can be optimized, in an open and bilateral discussion with clinical experts.\nWe currently have a strong national and international collaboration with the Swiss Paraplegic Centre, the Vrije University in Amsterdam, University Medical Center in Groningen and are continuously expanding this collaboration with other research groups, clinical disciplines and the SCI population for their valuable input.\nWith these combined efforts we work towards a quality management system for upper extremity functioning, aiming at long-term preservation of shoulder health in SCI individuals.\nExamples of projects in relation to shoulder health:\n- Handcycling versus handrim wheelchair (completed project)\n- Muscle fatigue induced by wheelchair propulsion (current project)\n- Wearables & big data (future project)\nHandcycling versus handrim wheelchair propulsion\nSeveral factors are involved in the development of shoulder pain, but the repetitive load of wheelchair propulsion is seen as one of the major risk factors. However, mobility devices such as the wheelchair are important since they support people with spinal cord injury (SCI) to live an independent life. Therefore, alternative or additional mobility devices to the manual handrim wheelchair should be considered. Since upper extremity mobility is usually the only means of physical exercise for SCI individuals, a manual device is preferable to maintain regular physical activity.\nThe handbike is one of these alternative mobility devices. It is increasingly used for commuting, recreation and sports. Compared to handrim wheelchair propulsion, the usage of a handbike is physiologically (heart rate, breathing, energy expenditure) more efficient and less straining. Whether also the mechanical load at the shoulder is lower than during wheelchair propulsion has not been investigated.\nThe focus of this project was on the biophysical benefits of handcycling in order to investigate the general assumption that the handcycle is indeed a good device for the prevention of shoulder problems. Additionally, we studied the handcycle-user interface. This will allow for practical advice on how to best adjust the handcycle to its user in order to further reduce the load on the shoulder joint.\nThe figure below shows the difference in shoulder load between handcycling and wheelchair propulsion. Glenohumeral contact force is the force with which the shoulder joint is compressed during the propulsion. The compression is a result of the exerted force by the hand and of the contractions of all muscles around the shoulder to perform the required movement and to stabilize the shoulder joint while doing so. (For example, 10 Newton (N) is the force needed to hold a mass of 1 kg against gravity).\nFrom the graphs it can be concluded that the load on the shoulder is much lower for handcycling.\nMuscle fatigue caused by wheelchair propulsion\n30% to 70% of individuals with spinal cord injury (SCI) suffer from shoulder pain. This has an enormous impact on functioning, independence and quality of life. The treatment is often unsatisfying and the pain problem remains.\nEarly diagnosis and early intervention of shoulder problems can markedly reduce the impact of shoulder pain. Although the exact mechanism remains unclear, several known factors contribute to the development of shoulder pain.\nOne of these factors is the mechanical load on the shoulder in relation to its capacity, for instance: how much force is needed to propel a wheelchair, and what is the maximum propelling force an individual can deliver? The lower the maximum, the sooner muscles will be fatigued. Improving the capacity to a sufficient level will have a positive effect on the prevention of shoulder pain.\nIt is also known that movement patterns can change due to fatigue, by a change in the activation or coordination of muscles. A less optimal movement pattern during wheelchair propulsion, a weight relief lift or a transfer can increase the risk of shoulder pain. Movement patterns are measured in our motion lab.\nFinally, prolonged activities can also lead to tissue change, for instance thickness and appearance of biceps tendon. Such changes in tendon thickness can be observed and quantified by Ultrasound imaging, not directly during wheelchair propulsion, but shortly after a fatiguing exercise, or during a weight relief lift.\nHow these mentioned changes, due to fatigue, are related to wheelchair propulsion and mechanical load at the shoulder is not known. It is, however, required information for the further development of training and prevention programs.\nQuality management system of upper extremity functioningWearables & Big Data\nFundamental research is required to gain insight in working mechanisms of upper extremity function, for which controlled conditions in motion labs are essential.\nIn addition questionnaires are used to gather information on lived experience from larger groups of participants.\nBoth approaches aim at extracting information from real life, and after analysis and discussion, generalize conclusions back to real life. Both approaches are, however, also just snapshots of what happens in real-life.\nWith the rapid technological development in the past two decades a third approach comes into reach. A broad variety of wearable sensors and smartphones might enable the desired longitudinal monitoring of upper extremity functioning in real life, to obtain an overview of real life demands and clarify dose-response relations among:\n- physical activities,\n- biomechanical load on the upper extremity, up to the level of musculoskeletal modelling,\n- long-term effect on tissue change,\n- performance of function.\nBesides, these non-intervening, discrete and wearable devices can potentially also be used as feedback devices, during rehabilitation or after discharge in real life in order to:\n- optimize or maintain optimal wheelchair propulsion style,\n- indicate over- or underuse with respect to individual capacity,\n- support or coach in adherence to «healthy» performance.\nTo enable the development of such an upper extremity quality management system, we focus our research on:\n- development of methods and algorithms (e.g. to estimate biomechanical load in real life),\n- testing usability of equipment (e.g. Smart Watches, Internet of Things modules) to enable large scale measurement in real life,\n- creation of safe and adequate infrastructure (where to store and process data, who can access data).']	['<urn:uuid:9075a208-866c-4118-a3af-98c04d46c992>']	factoid	direct	short-search-query	similar-to-document	single-doc	novice	2025-05-12T15:09:02.012753	6	33	1134
26	I just got a piece of driftwood for my fish tank and the water turned yellow. Is this normal, and what can I do about the cloudy water and dark color?	The yellow color is caused by tannins leaching from the driftwood into the water. This is perfectly normal and can actually be beneficial, as it creates more natural conditions that can help fish feel calmer. However, if you want to remove the yellow tint, you can perform regular water changes until the wood stops leaching tannins. You can also boil the driftwood to speed up this process. As for cloudiness, if the water looks milky white, this is likely a bacterial bloom that can be addressed through regular 20% water changes. If it's green, this is an algae bloom usually caused by excess light or nutrients, which can be fixed by reducing lighting and ensuring proper feeding and maintenance.	['Adding wood to your aquarium has quite obvious aesthetic benefits which can really transform the look of your tank. However there are other significant benefits too. Aquarium wood can give secretive species a place to live and hide. It can serve as a spawning site for egg laying species. Wood can even provide a food source of algae and small microscopic animals collectively known as aufwuchs for some difficult to keep species of catfish and subject to the type alter your water chemistry helping you to achieve the correct water parameters for your species of choice.\nThere are various types of wood available from stores, retailers and your own garden which are suitable for decorative use in your aquarium. Buying from a specialist retailer will ensure that the wood you choose is fit for purpose, but if you take a little time to research suitable species you may be able to collect wood from your own garden or somewhere else where you have been given permission to source wood.\nJared Cave of Biotope Aquatics describes some of the commonly available types of exotic aquarium wood for use in your aquarium, while Simon Morgan of the British Cichlid Association advises on native hardwood species that you can collect yourself.\nWithout doubt the most commonly used type of aquarium wood anywhere in the world. Bogwood is wood that has been preserved by the anaerobic conditions of these environments over hundreds if not thousands of years in a bog. It is discoloured by the tannins found in the bog over this lengthy period.\nGenuine bogwood is now hardly ever seen for sale in the aquatics trade at the time of writing (2015) due to its expense. Instead wholesalers offer various types of wood which have been dried outdoors without the preservation process of true bogwood.\nIt comes in many shapes and sizes and is often used as an attractive natural looking ornament in the aquarium. Other benefits include providing hiding places for reclusive species, helping form natural boundaries for territorial species and it can be used as an anchor point for attaching aquarium plants such as Java Moss, Java Fern and Anubias barteri, further improving the aesthetic appeal of your tank.\nBogwood contains tannins (organic material) that will leach into your water giving it a tea coloured and stained colouration. This is perfectly harmless. In fact some aquarists even find it desirable when trying to recreate Amazonian black water conditions etc. Unfortunately there is no way to be sure how much tannin a piece of bogwood will leach or how long it will continue to leach it for.\nIf this doesn’t bother you then add it to your tank and don’t worry. If you want to minimise the amount of tannin leached into your aquarium then soak it for one to four weeks in a bucket of water, changing all of the water regularly. You should start to see the amount of tannin decline over time which will give you an idea as to when you can add it to your tank.\nIf your wood has stained the water in your tank more than you would like you can reduce the discolouration with regular water changes and the use of activated carbon in your filter.\nWhen deciding if you want to pre-soak your wood first you may want to bear in mind that tannins will lower your pH just like peat can do so it may be wise to monitor this and buffer your water accordingly if required. The tannins are also reported to act as a very mild fungicide with antibacterial properties.\nQuite often a white fungal like growth can be seen leaching from bogwood after its addition to the aquarium. This is perfectly harmless and will stop doing this within a few weeks. The aquarist can either choose to remove the wood and scrub it off if they wish or leave it. Some algae loving herbivorous fish species will actually eat it.\nBogwood should be added to aquaria housing species of ‘wood eating catfish’. These fish do not actually digest the wood which is expelled as waste, but do digest the associated organic material when scraping the surface of wood with their teeth such as algae, animals and microscopic plants collectively known as aufwuchs.\nBogwood comes from several species of tree including oak, pine and yew with colours varying from a rich reddish brown (pine) to jet black (oak) with hues of dark brown in between (yew).\nSome bogwood is offered for sale as ‘pre-soaked’, though this is actually quite rare due to the additional time and expense required. It is best to assume that your bogwood has not been pre-soaked and treat it yourself to obtain the desired effect.\nMopani wood is sometimes referred to as ‘bogwood’. However this isn’t strictly accurate as it has never been anywhere near a bog! Instead Mopani wood comes from the Mopane tree (Colophospermum mopane) which originates from Sub Saharan Africa.\nMopani wood is heavy and hard, so hard in fact that it is termite resistant. It’s attractive and somewhat gnarled appearance have caused it to gain popularity as a heavy decorative wood not just in aquaria but also as a base for lamps and sculptures. Before being offered for sale in retail aquatic stores it is sandblasted removing all of its bark. This process gives it a two tone appearance as can be seen from the in the picture.\nMopani wood can also leach tannins and produce a fungal growth just like regular bogwood so the points about removal and treatment for regular bogwood apply to Mopani wood also. Always thoroughly soak mopani wood before adding it to your aquarium.\nArguably a lot more aesthetically pleasing than either bogwood or Mopani wood, redmoor wood with its reddish hues and tangled root appearance can be used to give a striking centrepiece in your aquarium.\nThe downside is that it can be considerably more expensive than other types of aquarium wood, but many pieces justify this because of its visual beauty alone. Further positives are that it doesn’t seem to leach anywhere near as much tannin as other aquarium woods and I’m yet to see a single piece become covered in fungal growth. It does however need a thorough soaking to ensure that it sinks. It is not as heavy and dense as Mopani wood and sometimes requires a lengthy soaking to get it to sink. Very occasionally it may even require holding in place with a rock, though this is very rare.\nThis driftwood is actually pieces of cut mangrove root. Pieces vary in size between around 25cm to 150cm for very large tanks. It is often used by aquascaping fans as a central piece of hardscape. Like redmoor wood it doesn’t seem to release tannins but occasionally is subject to fungal growth. It also sometimes requires a thorough soaking before it will sink. This process may take a week or so.\nThe distributor claims that it is harvested in an ethical manner from dead trees in the Far East before being sandblasted and cut to shape. Sandblasting gives it a very smooth texture.\nOriginating in Eastern Europe, marsh root wood is the roots of hardwood trees that have been soaked in boggy conditions for some time. It has not been preserved like genuine bogwood, but has been soaked long enough so that tannins no longer leach from it. It’s dark brown to black colouration can be very striking when placed on a light coloured substrate.\nIt is guaranteed not to float, is sold in various sizes and as well as not discolouring your water, it will not alter your pH at all. It is marketed at those keeping wood eating catfish species.\nAzalea root is sometimes known as as spider wood when offered for sale. It floats so needs soaking but doesn’t give off tannins or change the pH. It might create a bloom or biofilm/fungal growth but not always. Some sellers bake it before shipping to treat it for use in the aquarium.\nIt’s an attractive golden brown colour, and as the nickname of spider wood suggests, it’s quite a tangly looking wood. This makes it a visually interesting addition, as well as offering hiding places for smaller fish.\nUsing wood collected from nature in the aquarium\nIt’s perfectly safe to collect wood from nature and use it in an aquarium. Just make sure you identify the tree properly and prepare the wood properly. A good website for tree identification is:\nWoodlands.co.uk – tree identification\nSafe woods for use in an aquarium\nUnsafe woods for use in an aquarium\n- Cedar (avoid anything evergreen/coniferous)\n- Grape vine – this rots very quickly\n- Horse chestnut\n- Lilac – this is poisonous\n- Ivy – this is poisonous\n- Yew – this is toxic\nYou’ll note that yew and pine are safe in the form of bogwood, unfortunately it will take longer than your lifetime for you to replicate the conditions that has made them safe, so please avoid them when collecting wood yourself.\nCollecting and preparing wood for use in your aquarium\nRemember to collect wood from rural areas and make sure you have permission. Look for dry pieces with no mould, rot or fungus. It’s also fine to take “cuttings” from living trees but again, make sure you have permission or make friends with a tree surgeon.\nI prefer to dry out newly cut or collected wood for a couple of weeks to remove any remaining sap, then soak it. Soaking isn’t always necessary but helps the wood to sink and the bark to peel off more easily. Removing the bark is optional.\nThe best time to collect wood is late summer. Go to a deciduous forest and look for beech and oak. During the summer the larger trees actually drop branches to protect themselves from dehydration. These branches are usually dry and have dropped recently so haven’t started to rot. You can also find fresh wood following a storm.\nDrift wood from a beach, for example, is not going to have pathogens that can infect freshwater fish. However, chances are it’s been floating around the ocean for months or even several years. It’s not going to sink any time soon, so I suggest it’s not a good place to find wood. If you do find a piece you like and would like to try it, I suggest soaking it, fully immersed, in freshwater for about a month. If it sinks after that, it is probably OK to use, but there is some unknown risk to bear in mind, especially if you can’t identify it. Bear in mind that it may have picked up pollutants such as oil while drifting, so unless you are certain of its provenance it may not be wise to use it.', 'Everyone loves a nice clean fish tank, but sometimes your perfectly clean tank can become a cloudy water mess. In order to return your tank back to its former glory, you first have to understand the causes of a cloudy fish tank. There are three different water colors of cloudy fish tanks and each have their own causes. Depending on the type of cloudy water you have, there are different things you can do to help clear the water up. Whatever the cause may be, you must first correct the cause before you can keep your water clear.\nWhite Cloudy Fish Tank\nA cloudy fish tank that looks white or milky, is usually caused by a bacteria bloom. This is usually the most common type of cloudy fish tank water. This can happen if even one time a lot of extra food was dumped into the fish tank or through regular over feedings. Other causes could be if a fish died and wasn’t removed from the aquarium or if your fish tank is still cycling. Depending on what is causing the cloudy water, there are different things to do that can fix it. First, you need to correct the cause, so if you have been over feeding fish or if there is a fish that died, the problem should first be corrected so the water doesn’t continue being cloudy after you clear it up.\nOnce the initial cause is corrected, you can clear the water and keep it clear. The best way to fix your cloudy water is to perform water changes. Start by doing 20% water changes bi-weekly and if after 2 weeks or so the water is still cloudy I would then recommend performing a 50% water change weekly until the water stays clear. When changing the water, make sure you are using a good water conditioner to treat the water. Never remove all the gravel and change it with new gravel, this could potentially kill all your fish by causing your tank to re-cycle. If after doing all this your water remains cloudy, you should consider testing the water you are putting into the tank, whether it be from the tap or bottled water.\nIf the problem is the fish tank is still cycling, tanks between 2-6 weeks old, then you really just need to give the tank time and it should correct itself. However, you could do water changes as described above to help clear the water, although likely doing nothing will have the same affect in the same amount of time.\nGreen Cloudy Fish Tank\nA cloudy fish tank that is green in color is typically caused by an algae bloom. This is different than the algae that grows on the glass of your fish tank, this is specifically algae that grows in the water column. Green cloudy water from algae is usually caused by excess nutrients in your fish tank or too much light on your fish tank. Both of these causes have easy fixes that can help clear your water quickly. Excess nutrients are caused by either, overfeeding, overstocking, or poor maintenance. Overfeeding is easily corrected by reducing the food you feed your fish. Overstocking is a little trickier, but essentially you need to remove some fish and either give them to a friend or give it back to the fish store. Poor maintenance is corrected through performing regular water changes to remove the excess nutrients.\nIf you have too much light on your fish tank, you could have an issue with green water. Lights that are running for more than 10-12 hours each day, can contribute to green water. Also, if your tank is near a window that is getting sun, this can cause algae blooms as well. You should make sure you are running the aquarium lights for the correct amount of time and that sun does not shine directly into the fish tank.\nRegardless of the cause of the green water, you can correct it by turning the lights off and keeping the fish tank dark or very dimly lit. Usually keeping the lights off for a few days will clear green cloudy water; however it’s important to make sure the underlying cause has been corrected otherwise the green cloudy water will return. Since algae is a plant, by keeping the lights off, you are killing the algae growing in the water column by starving it out.\nYellow Water Fish Tank\nWhile your fish tank may not look cloudy, you may notice a yellow tint to your aquarium water. This can be a result of a few things; driftwood leaching tannins, decaying plants, or some other organic matter. Depending on the cause of the yellow water, it may actually be beneficial. If you think of lake or river water, it is very rarely crystal clear, many times the water will have the yellow tint to it. This is the same as what is happening in your fish tank. Driftwood is naturally leaching tannins into water which is turning it yellow. Fish which come from lakes and rivers where this naturally occurs, can be more calm when water is tinted in home aquariums. The tannins also can drop the alkalinity and hardness of your aquarium which makes the water chemistry more natural for most tropical fish.\nIf even after hearing the benefits of the tannins in driftwood you still would like to remove the yellow tint, performing water changes is the best course of action. Eventually the wood will stop leaching the yellow tint, so over time by doing water changes your water will become clear. Also, if you boil the driftwood this will help speed up the process of removing the tannins in the water. If the yellow water is from decaying plants or some other organic matter, it is best to remove that and perform water changes. This will help get the water clear again.\nNo matter what type of cloudy water you have, usually water changes are the best way to clear the water. There are different chemicals that you can use to help clear the water, but in my opinion water changes are your best weapon. Some people have also used UV Sterilizers to keep water from becoming cloudy, while these work very well, they may not be practical for everyone and could potentially mask the underlying problem. The best way to clear your cloudy fish tank is to first determine the cause, and then correct it.\nHopefully you have found this helpful and if you have a cloudy fish tank you can use this article to clear your water. If you found this article helpful and would like to know other tips and tricks, including the secrets most fish stores won’t tell you, please join my mailing list.']	['<urn:uuid:437c385b-0052-4302-a6ec-0bf8aeed01d6>', '<urn:uuid:0cbcbba3-4960-4f08-9ea1-71d4671f4621>']	open-ended	with-premise	verbose-and-natural	similar-to-document	three-doc	novice	2025-05-12T15:09:02.012753	31	119	2937
27	international space station participating agencies research impact goals achievements	The ISS involves five major space agencies working together: NASA, ESA, Roscosmos, JAXA, and the Canadian Space Agency. The station has produced significant scientific breakthroughs, including potential treatments for Duchenne's Muscular Dystrophy being tested in Japan, water filtration systems now deployed in remote areas, and new treatments for osteoporosis. While the ISS is scheduled to conclude operations by 2028 due to engineering limitations, NASA views it as a crucial step in their broader goal of reaching Mars, serving as an 'Earth reliant' phase of space exploration. The station represents unprecedented international cooperation in space research, with NASA planning to transition its operation from government to commercial entities as the agency focuses on more distant frontiers.	"['From: American Institute of Physics\nPosted: Friday, July 24, 2015\nOn July 14, the President’s Council of Advisors on Science and Technology (PCAST) met to discuss three topics, among them an update from the National Aeronautics and Space Administration (NASA) and its leading commercial space industry partners on the progress being made in new frontiers in human space exploration. Other topics on the meeting agenda included a review of the Networking and Information Technology Research and Development (NITRD) Program and a discussion on technology and aging. This FYI will focus on the presentations and discussion on the human space exploration topic.\nThe primary focus of the human space exploration session was the series of multiple coordinated, long-term efforts NASA and its international and commercial partners are undertaking and planning to undertake in working toward a mission to Mars as early as the 2030s. Among these efforts are the International Space Station (ISS) already in operation; the Space Launch System heavy launch lift vehicle under development; the Orion space capsule under development; the commercial crew program in its infancy; and plans for several mission stages with increasing degrees of independence from Earth over the next few decades, culminating in a manned mission to Mars. Testifying before PCAST on this topic were Charles Bolden, Jr., the NASA Administrator; William (Bill) Gerstenmaier, NASA’s Associate Administrator for Human Exploration and Operations; Garrett Reisman, the Director of Crew Operations for SpaceX; and John Elbon, Vice President and General Manager for Space Exploration at Boeing.\nBolden began by trumpeting the major NASA development that had been announced earlier that day, the arrival of the New Horizons spacecraft to the dwarf planet Pluto and the release of the first high-resolution photos of Pluto. Holding back tears, Bolden shared how important a moment this was for him, the United States, and the rest of humankind. Said Bolden: “Today’s a huge day for those of you sitting around and look like you’re a lot younger than I am. If you’re students, try to remember where you were this morning. This is not like Neil Armstrong walking on the surface of the moon, but this morning the United States became the only nation in the history of humanity to visit every single planet in our solar system. That’s a big deal… I get emotional about that because that’s a big deal.”\nBolden proceeded to give an overview of NASA, explaining it is a multi-mission agency with four major directorates: the Science Mission Directorate, Space Technology Mission Directorate, Aeronautics Mission Directorate, and Human Exploration and Operations Mission Directorate. Bolden’s key point was that all four of the major NASA directorates are now working together in an unprecedented way toward the common goal of getting humankind to Mars. Bolden explained: “What I hope to do…is help you understand how we’re now intertwining those four directorates, as it has never been done before, into a singular effort to get humans farther into the solar system than ever before, to get humans to Mars, and if it works, get us there in the period of the 2030s, and we’ve got a stepping stone approach to doing that.”\nBolden articulated the nation’s rationale for a mission to Mars by appealing to American values, heritage, and history. The United States, he argued, is about exploration and expansion through the colonization of new places. Said Bolden: “We are going farther into the solar system, except this time we’re going to stay. This is not about sending a man to a body and bringing them safely back to Earth. This is about moving humanity farther into the solar system and establishing a foothold where we can remain time in memorial….Through the history of humanity, we’ve always been confronted with crossing the next river, or crossing the next mountain, or going beyond something…. It is the story of the journey West, you know, of the early pilgrims and other people landing on the shores of the United States, but then just not being satisfied and continually moving west and exploring, and so, we’re now trying to get off this planet and farther out.” Mars, Bolden added, is only the first destination for humanity off this planet and out into the solar system, and our ultimate destination is still unknown.\nBolden pointed out that, much like the ISS, the Mars effort will be an international effort, with multiple nations participating. The “starting five” as he called them are the five nations that run the ISS today: the European Space Agency; the Russian Space Agency, Roscosmos; NASA; the Japan Aerospace Exploration Agency, JAXA; and the Canadian Space Agency. Bolden expects other nations will join the effort as well: “India, China, you name them, on and on and on, are beginning to come into the fore and with our leadership and our assistance can become effective members of the team.”\nGerstenmaier emphasized that the journey to Mars will come in small steps that will eventually lead to a final mission to send humans to the Red Planet. Said Gerstenmaier: “This isn’t going to happen instantaneously. This isn’t a single mission. This isn’t a single activity. This is a multi-decadal activity we’re putting together. We’re building first pieces of that with the Space Launch System heavy lift launch vehicle, the Orion space capsule, the crew that goes to station and station activities. They all fit in this journey piece.” In particular, Gerstenmaier organized the journey into three stages, each with increasing independence from the Earth, progressive steps toward the final goal of complete independence. Gerstenmaier explained what each step along the way might look like: “The three regions that we talk about, we talk about Earth reliant. That’s where we are with the Space Station. We need to use the space station and its unique abilities to really understand what it takes to have long duration human space flight to make sure the human can actually tolerate the environments that are required for the human body to adapt….The proving ground region is around the moon and the key thing there…is the return time. The return time now is days away on the moon. You go to the far side of the moon, you lose communications with the Earth….We need to understand the risk reduction techniques, the risk reduction capabilities in the region around the moon before we’re ready to commit to that third region, which is the Earth independent region....So this is again a journey encompassing all three of those regions.”\nReisman, representing SpaceX, emphasized that the work of his company in advancing human space flight is rooted in a mission fully aligned with NASA’s. Said Reisman: “Mars, as Charlie [Bolden] mentioned, is the ultimate goal of the agency, [and] also is the ultimate goal of our company. Really, the company [SpaceX] was founded to make humans a multi-planetary species.” Reisman focused on the role that SpaceX is playing in reducing the cost of human space flight, which he argued will be critical to succeeding on the journey to Mars. “Reusability is a big thing that SpaceX is really working towards,” said Reisman, “and it’s not just reusability. It’s affordable and rapid reusability. That’s our goal and we think that’s necessary to achieve the next major reduction in the cost of access to space…. Rapid affordable reusability we think is going to change the economics of space flight and lead to incredibly wonderful things in low Earth orbit and beyond, hopefully enabling all the things that NASA is working on.”\nA number of the panelists had strong praise for the ISS, which is widely seen as a successful international space partnership and, as Gerstenmaier outlined, is seen by NASA as a critical step on the journey to Mars. Elbon, whose company Boeing served as the primary contractor for the ISS, detailed some of the scientific breakthroughs that have emerged from ISS research: “There is a potential cure for Duchenne’s Muscular Dystrophy that’s being tested in Asoka, Japan. It’s an awful disease. If we can cure that based on research done on station, that’s a huge deal. There are water filtration systems that were developed on station that are now deployed in remote areas to filter water for people. We’ve got new treatments for osteoporosis based on research done on station. So the science that is coming out is having a huge impact and very important.”\nBolden also spoke to the “incredible value” of the ISS but was clear that NASA will now be turning its focus to other frontiers as the ISS transitions from government to commercial operation: “It is a one-of-a-kind laboratory, but it has a finite lifetime. We’ve established that by 2028 the International Space Station just is gone. From an engineering perspective, as it stands today, it will no longer be able to be sustained….We think you’ll never see anything like the International Space Station again, in its size and structure, nor should you see that, because our purpose in life is to try to facilitate the success of a commercial space industry that takes over and allows NASA to take the step away from being Earth reliant to becoming an organization that’s in the proving ground.”\nDuring the question and answer period, PCAST co-chair John Holdren, who is Assistant to the President for Science and Technology and Director of the White House Office of Science and Technology Policy, asked all four panelists to identify what advanced technologies or capabilities which we do not have today would greatly expedite and improve our capacity to carry out ambitious human missions. Bolden replied that we need a game changer in space propulsion: “Eight months to Mars is too long. We can do it better.” Gerstenmaier brought up a few new technologies currently under development that he believes will be instrumental in NASA’s journey to Mars: 3D printing and advanced food and vitamin delivery. On 3D printing, he explained: “We print a tool, we use a tool, we grind a tool back up, it makes more feed stock to print another device. We think that lowers the amount of mass, the amount of equipment you need to carry with you.” Reisman added that SpaceX is working to develop a key capability for propulsive landing: “We’ve been very successful in getting rovers on the surface of Mars, using things like airbags and other entry and descent and landing technologies, but a lot of those technologies are not scalable. Finding a good way to get something large, which we’re going to need really big things, on the surface of Mars, requires a new technology. NASA is trying various decelerators, and looking at that, but we really think that the answer is propulsive landing.” Elbon chimed in as well, saying that “improved closed loop environmental control and life support systems” will be important to reduce the logistics needed for oxygen, water, and other life-sustaining elements.\nThe final exchange of the hour-long session on human space exploration was initiated by PCAST member Dan Schrag, who is a Professor of Geology and Environmental Science at Harvard University and studies climate change. Schrag commended NASA’s efforts in human space exploration but also pointed out that it is “a revolutionary time in Earth observations as well, extraordinary new capabilities.” Schrag expressed great concern that Earth sciences had come “under attack” recently, pointing out that a recently passed appropriations bill in the House would subject NASA Earth Sciences to a 32 percent cut. Said Schrag: “Devastating is a gross understatement for how severely this would impact our abilities to understand our own planet and observe the changes that are happening.” Schrag then asked Bolden what he was doing to protect the Earth Sciences budget, and he asked Reisman what SpaceX is thinking about in the domain of earth science. In his reply, Bolden made clear he is taking the threat to NASA Earth Sciences seriously: “We are doing everything that we can in the power of my position to communicate with the powers that be, both on Capitol Hill and in and around the White House, to help people understand the critical importance of Earth observations and earth science, and understanding the change that’s occurring to our climate.”\nMichael S. Henry\nGovernment Relations Division\nAmerican Institute of Physics\n// end //', ""Posted by Craig Scott on June 06, 2016\nIn 1998, a hallmark event in international cooperation occurred when the International Space Station (ISS) was launched into Earth’s orbit. Positioned in an orbit that is at an altitude of between 205 and 270 miles from Earth, the satellite can be spotted from the surface of the Earth with the naked eye. On clear nights at any location on the planet the International Space Station can be seen due to the fact that it reflects sunlight brilliantly. It orbits the Earth more than 15 times per day. If you are interested in tracking the International Space station on your own you should do so on a clear night. There are online tools that accurately predict the positioning of the satellite. These sites report the times that the station will be visible in your area and the station's duration of visibility from your viewpoint.\nThe International Space Station exists primarily for the purposes of research and experimentation. The crew members on board conduct experiments in such diverse disciplines as astronomy, human biology, physics, biology and other branches of science.\nThe activities on board the space station are a product of 5 space agencies from around the world:\nCSA is the Canadian Space Agency. It was originally conceived at the end of World War II and accomplished the feat of launching its’ first satellite into space in 1962. The Canadian Space Agency has a mandate to use and develop technologies in space for the purposes of peace. The execution of the lessons that they learn in space are intended to be used to uplift the lives of Canadians and humans all over the world.\nCSA has a modest budget when compared to the other space agencies that participate in the ongoing mission of the International Space Station. As of 2016, the CSA had a reported fixed yearly budget that is equal to $300 million US dollars.\nESA is the European Space Agency. ESA is comprised of 22 different cooperating governments. Paris, France is the home of this organization. Originally created in 1975, the ESA boasts a global staff of 2,000. A large budget provides the monetary backing for the ESA. Their budget was the equivalent of $7.7 billion US dollars as of 2016.\nJAXA is the Japan Aerospace Exploration Agency. JAXA was created in 2003. It absorbed 3 previously independently run organizations:\nUnlike Canada’s CSA, JAXA’s mission extends to both peaceful and military purposes. The military applications of their research include early warning systems for incoming missiles.\nJAXA has engaged in an impressive range of missions ranging from interplanetary and lunar missions to planetary exploration (their planetary explorations have thus far been limited to the interior of our Solar System).\nRoscosmos is the Roscosmos State Corporation for Space Activities. Formed in 2015, this Russian corporation was formed from the foundation of the Federal Space Agency (the Federal Space Agency no longer exists). The budget for Roscosmos is substantial. As of 2016 Roscosmos was supported by a budget equal to $3.04 billion US dollars.\n(Note: Russia has a storied history in space exploration. On October 4 th, 1957, the former Soviet Union’s Sputnik 1 was the first man made Earth satellite to be launched into Earth’s orbit.)\nNASA is the acronym for The National Aeronautics and Space Administration. The agency is an independent entity in the executive branch of the United States Government. NASA was created under the administration of President Dwight D. Eisenhower in the year 1958.\nNASA has an incredible history, being the first institution to place astronauts on the moon. The Space Shuttle and Skylab space station were both NASA projects. NASA’s mission is a peaceful one. It is not run by the United States military establishment. The focus of the administration is on gaining better insights into planet Earth and the Universe at large.\nNASA boasts a budget that surpasses all other state participants in the International Space Station combined. The latest numbers available show that NASA has an annual budget of $18.4 billion dollars.\nOral hygiene regimen, food and water aboard the International Space Station\nThe average person on Earth uses 350 liters of water per day. That is roughly 1,400 cups of water every day. Being that 60% of the human body is comprised of water, access to hydration is an issue of paramount importance in space.\nIn the past, water was delivered to astronauts in bags on space shuttles and resupply vehicles. In 2010 the water recycling technology available to the personnel on board the station was advanced.\nThe astronauts recycle water. They retain 93% of the water on board. They have an on board distiller that removes impurities and produces clean water from the liquids that are entered into the system. Astronauts recycle liquids that we would never think to reuse on Earth. However, the distilled water that is produced on board is actually purer than most of the water that is consumed on Earth.\nThe astronauts on board the International Space Station are equipped with dried food. Food is attached to a water distributor and is hydrated with the push of a button. At the conclusion of the hydration process, the food is ready for consumption.\nAs you might imagine, brushing one’s teeth in a zero gravity environment can be a tricky proposition. In 2013, ISS Commander Chris Hadfield detailed the process in an instructional video.\nThe personnel on board use a standard toothbrush that can be found in any store that carries oral care products. There is no running water because the lack of gravity would allow the water to travel around the module with no control. There are no sinks on board the International Space Station because control of the water flow would not be possible. The container used to disseminate and manipulate water is a water bag.\nA water bag is filled with water. When the bag is squeezed, a ball of water rises to the top and floats to the end of a straw placed inside of the bag. The toothbrush bristles are then placed in contact with the water. Tooth brush bristles are very good at soaking up water. Therefore, the water does not fly all over the module once it comes into contact with the bristles.\nA standard, store bought tube of toothpaste is used in space. The toothpaste is not generously applied so as to avoid the toothpaste floating around and getting on the surrounding equipment.\nThe astronauts brush their teeth in the normal way that they would on Earth. They brush their teeth for the same length of time that they brush on the surface of the planet.\nWhen finished, they swallow the toothpaste instead of spitting it out (this prevents saliva and toothpaste from floating everywhere). Then they expel additional water from the water bag to clean the toothbrush off.\nObviously, living in an environment with no gravity presents challenges to everyday activities that most of us living on Earth can take for granted. With their commitment to increasing the pool of human knowledge for the betterment of mankind, the astronauts on board the International Space Station have sacrificed greatly to advance the cause of peace and understanding through exercising their scientific acumen.""]"	['<urn:uuid:a2a16352-b344-4e48-8688-f8f4db4dd636>', '<urn:uuid:7ec61ec8-c74c-47c4-bb9d-c906bbb00d9a>']	open-ended	direct	long-search-query	distant-from-document	comparison	expert	2025-05-12T15:09:02.012753	9	115	3246
28	Compare bone structure between Ariegeois and Dartmoor ponies.	The Ariegeois has a light and delicate bone structure, being a lightly built animal, though it must have strong legs with plenty of bone. In contrast, the Dartmoor is sturdily built with ample bone, described as having large flat knees, short cannons with good flat bone, and being like a scaled down middleweight hunter. The Dartmoor's pasterns should be sloping but not too long, with hard, well-shaped feet.	"['fairly slender and short and are not always straight – many Ariegeois ponies have a tendency to be cow-hocked, meaning that their knees bend inward slightly toward each other.\nThe present-day specimen stands up to I 4 hands, which is the height limit, although most average I 3 hands, two inches.\nThe head should be neat and pony-like and set on a fairly long neck, which, together with well-laid-back shoulders, gives the rider a good length of rein.\nWhen choosing an Ariegeois pony for riding, large or coarse heads should be avoided because they are a sign of stubbornness and make a difficult mount with which to work.\nA pony with a short, thick neck should be avoided as well, for they will never have a smooth ride.\nGood legs are one of the qualities of the breed, and these must be strong with plenty of bone.\nThe normal color for an Ariegeois pony is dark, ranging from dark brown and chestnut to a more common solid black.\nNormally, there are no white stockings and no other markings on the head.\nThe pony’s flank may be lightly flecked with white, in the manner of an appaloosa or a dapple-grey, but no other markings are common.\nIn the winter, the coat of the Ariegeois acquires a distinctive reddish tinge, and never grows particularly furry.\nThe coat is fine in texture, unlike the mane and tail which are harsh to the touch and extremely thick.\nThe Ariegeois has been used as a packhorse for centuries.\nIt also functions as a small riding horse and can easily work the land on the steepest of hill farms where machinery cannot venture.\nThe Ariegeois is noted for its hardiness, courage, and adaptability, but it is not a stubborn animal.\nIt is extremely gentle and docile, a temperament that makes it very popular as a children’s pony even for fairly young riders.\nBecause it has n o hot blood and is not prone to shy or scare easily, the Ariegeois is also well-suited for driving and pulling small carts.\nFurther, it is a creditable jumper and has the ability to trot for long distances at a steady speed. Ariegeois The Ariegeois pony lives in the Pyrenees Mountains in the southwest of France, and it is known to be a breed of great antiquity.\nThe Ariegeois is a bold pony, unafraid and eager for even difficult journeys.\nIt closely resembles the horses of Southern Gaul and was interbred with the Barb horses as Caesar and the Romans spread north and west along the European coast.\nThe original home of the breed is the high valley of the Ariege River, from which the pony takes its name.\nOne of the most noticeable things about this breed is its light and delicate bone structure.\nUnlike the other, tougher ponies of the northern areas, the Ariegeios is a swift-running but lightly built animal.\nIt does not do well in frigid climes, although it is adept at mountain-climbing.\nIt is outstandingly surefooted, and even ice-covered mountains hold no terrors for the little Ariegeois.\nIn the summer, it will seek shelter part of the day and come out to graze at night.\nThese ponies can travel into Southern Spain, North Africa and even the Middle East and live well on the scrub grass that they find in those sparse areas.\nAriegeois ponies have an expressive head with a flat forehead, straight profile, hairy ears, and bright, alert eyes.\nThe neck is short, and the shoulders straight – not t o handle heavy burdens but instead built for speed and conservation of energy on long travels.\nThe back is long and strong, and the chest is broad, with a great deal of room.\nThe limbs are Shetland At least 2,000 years ago, there was a pony like the modern day Shetland living on the islands of the same name.\nLike the islanders, the pony mixed British with Viking to create a distinct Shetland type, breeding – most probably – with the Norwegian Fjord pony.\nThe true Shetland is a hybrid breed, containing the blood of the British Hill type pony, like a Highland or Fell/Dale of Scotland, and a Scandinavian breed influenced by some Oriental bloodlines.\nThe resulting pony was first represented in a 9 t h Century stone carving found on the island of Bressay.\nIt depicts a hooded priest riding a very small pony with the distinguished profile and body structure of the Shetland.\nO u t of a broad and widely diverse stock, the Shetland has grown into a very predictable, hardy, and constant breed.\nTheir background and breeding were highly influenced by the relative isolation of the islands on which they were Ariegeois Statistics Along with the standard Pony Base Statistics, Ariegeois gain the Sure-Footed Feat for free. 28 originally bred.\nDespite the various strains first developed, all of the ponies that lived in the Shetlands coped with an environment that was constantly, almost unbearably hostile.\nThe island is cold, bitter, and does not support much animal or plant life.\nThese tough little ponies must live on bad grass, hard, wet ground, and in the continual path of the driving wind.\nT h e cold climate encouraged them to conserve body heat; the resulting pony has short limbs, a short back, a thick neck, and small ears.\nBig stock starved; fragile stock broke; only the small, quick, hardy, and intelligent animals survived.\nWith a maximum height of 46 inches, Shetlands are the perfect size starter pony for a child.\nBred t o pull ore carts in coal mines, Shetlands have retained an innate driving ability.\nA well trained Shetland not only excels at driving, but is a sturdy and reliable mount for any child.\nOne of the main problems that the Shetland breed faced in its incipiency was its use in the coal mines – the strongest and hardiest of them were used as laborers in these dangerous conditions and often died – leaving only small, inferior stock to breed more ponies.\nIn time, stables were built to house and breed the finer examples of these tough little ponies, encouraging the type to flourish and revive once more.\nGenerally, most peasants and farm laborers do not ride their ponies.\nSome used by doctors or ministers are ridden in order to visit the scattered peasants on farms that are not near the main villages.\nHowever, the main use of Shetlands in primitive British life was for work, carting, or carrying heavy loads.\nThe majority o f ponies live almost free out on the scattalds, or wide pasturelands of the island.\nThese ponies remain on the scattald until the season turns and they are required for use “flitting the peats,” which means to carry recently cut strips of peat moss from the hills to the homes of local peasants.\nThese strips of peat (moss, manure, and other decaying plant matter) are the main winter fuel of peasant homes, and many commoners would have frozen to death in the cold winters without them.\nBecause there were few roads into the higher areas where the peat grew, the ponies were required to navigate crosscountry in all weather.\nShetlands were needed during the winter more than any other time of year, and were often found carrying heavy woven baskets filled with peat from the deep moorlands.\nT h e Shetland pony can be seen in all colors except spotted: black, chestnut, grey, bay, dun, blue roan, piebald, or skewbald.\nUnlike bigger horses, measured in hands, the Shetland pony is measured by inches in height at the withers.\nThe smallest of the British native breeds, maximum height reaches 42 inches, with a minimum as small as 28 inches. Shetland Statistics Shetlands add the following bonuses to the Pony Base Statistics: Hardy and resilient, the Shetland is very strong for its size. It has a medium-sized head, a rather dished face with a wellshaped muzzle, and a jaw capable of grazing through poor growth over an extensive area.\nThe ears are medium-sized, and the eyes are large and kindly.\nT h e coat is thick, with a heavy mane and tail, offering good protection against the local winter weather conditions.\nRead more about Hybrid : The true Shetland is a hybrid breed containing the blood….:', ""The native pony breed of the county of Devon in the South West of England. The ponies have been recorded living on the wild and inhospitable moors of Dartmoor since the Middle Ages.\nThe ponies have the metabolism to prosper in the tough and uncompromising conditions they have to contend with.\nThe ponies have an exceptional temperament and breeders have long realised their potential as children’s ponies with the ability to make wonderful companions, give endless fun and if required compete and succeed in all spheres of competition.\nThe Pedigree Dartmoor Pony\nThe Dartmoor Pony Society represents the Pedigree Dartmoor Pony. There are many ponies living on Dartmoor, all sizes and colours, most of unknown breeding.\nThe true to type Dartmoor Pony with known breeding is recognised as a rare breed by the Rare Breeds Survival Trust and is typical of the ponies seen in the show ring at County Shows throughout the United Kingdom.\nIf you require a pony for your children to ride or you wish to show it at whatever level you aspire to, be it your local show, County Show or to qualify for The Year of Horse Show or Olympia, it is the Pedigree Dartmoor Pony that you require.\nFor more images visit the Photo Gallery.\nThe Breed Standard of the Dartmoor Pony\n|Height||Not Exceeding 127 cm. (12.2hh.)|\n|Colour||Bay, brown, black, grey, chestnut, roan. Piebalds, Skewbalds and Spotted are not allowed. A certain amount of white is and always has been acceptable. Excessive white markings to be discouraged.|\n|Neck & Head||The head is small and bloodlike, reasonably short from eye to muzzle and without much tapering to the nose. The ears are small and alert and the eyes fairly large giving the pony a kindly interested expression. It should be well set on a good neck of medium length. The throat and jaws should be fine and showing no signs of coarseness or throatiness. Stallions to have a moderate crest.|\n|Shoulders||Good shoulders are most important. They should be well laid back and sloping, but not too fine at the withers.|\n|Body||Of medium length and strong, well ribbed up with a good depth of girth giving plenty of heart room.|\n|Loin & Hindquarters||Strong and well covered with muscle. The hind quarters should be of medium length and neither level nor steeply sloping. The tail is well set up.|\n|Limbs||The forelegs should not be tied in at the knee. The fore-arm should be muscular and relatively long and the knee fairly large and flat at the front. The cannons should be short with ample good, flat bone. The pasterns should be sloping but not too long. The feet should be hard and well shaped. The hocks should be well let down with plenty of length from hip to hock, clean cut and with plenty of bone below the hock. They should have a strong second thigh. They should not be 'sickled' or 'cow-hocked'|\n|Movement||Low and straight coming from the shoulder with good hock action but without exaggeration.|\n|General||The Dartmoor is a very good looking riding pony, sturdily built yet with quality, like a scaled down middleweight hunter. The mane and tail should be full and flowing. The general impression given by a Dartmoor is of a well made, quality pony with ample bone which stands over plenty of ground.|""]"	['<urn:uuid:35056886-2af5-4e5a-b390-1b1113341aff>', '<urn:uuid:03c169b0-3165-4790-8c44-96dd54d08742>']	open-ended	with-premise	concise-and-natural	similar-to-document	comparison	expert	2025-05-12T15:09:02.012753	8	68	1931
29	stage fright piano players symptoms and piano tuner support for performers anxiety	Performance anxiety in piano players can manifest through various physical symptoms, as it triggers the body's 'fight-or-flight' mechanism when being the center of attention. To help manage this anxiety, professional piano tuners like Stefan Knüpfer work closely with famous pianists to create the perfect performing conditions. Knüpfer's role involves finding the right instrument with suitable qualities and tuning it to perfection, which helps reduce performers' stress by ensuring they have the best possible instrument setup. This technical support, combined with strategies like practicing controlled breathing, meditation, and focusing on positive thoughts rather than self-doubt, can help musicians manage their performance anxiety effectively.	"['directed by: Lilian Franck and Robert Cibis\nThe quest for a perfect sound from the unique perspective of a man who dives into the interior of a piano, trying to activate up to the perfection its fantastic potentials. Every piano has its particularity, every piece of music its colour and tone, and every pianist its temperament and vision. The encounter of a top-level piano-tuner Stefan Knüpfer and famous pianists like Alfred Brendel, Lang Lang and Pierre-Laurent Aimard. To find the right instrument with the right qualities, which will suit the conception of the virtuoso, and to tune it up to the perfection this becomes the mission, which requires nerves of iron, endless patience and top-level skill to transform words into sound. The exceptional photography and the stunning quality of the sound (because the music was recorded on 90 channels), make both your ears and eyes wide open, and let yourself to pleasure. Film about passion, perfection and a little bit of madness.\nSELECTOR\'S WORD: ./prethodni_festivali/pages/2010. learning by watching and listening. I really symphatize with this multitasked piano magician, who has to move around and adjust huge pianos and their ""stomachs"" to satisfy the ambitions of a number of artists, one more blasé than the other. It\'s magnificent to follow!\nFilm education gained at Film Academy in Baden-Würtemberg. After that, studied in Paris at Grande Ecole de Fresnoy Studio national des arts contemporains. She has been working with Robert Cibis for ten years as director and producer.\nStudied film in Paris and in Rome. Master\'s degree gained at Sorbonne Nouvelle in 1997. Attended masterclesses at German-French Film Academy Fémis in Paris and at Film Academy in Baden-Würtemberg, Germany. Works as director and producer.\nHUMAN CAPITAL THE EMPLOYMENT TRADE (Kapital: Mensch - Das Geschäft mit der Arbeit), 2004\nJESUS LOVES YOU (Jesus liebt Dich), 2008\ndirected by: Yves Hinant, Eric Cardot and Delphine Lehericey\nThe story about people no one knows, but everyone loves to hate. Documentarists who break out the standard media image of a top-level world football and take us to the areas accessible only to the referees. Filmed exclusively in cooperation with UEFA during the European Championship 2008, this film takes us into the core of communication between the referees during big and important matches, which is normally invisible for the audience. English title of the film Kill the Referee reveals a constant dimension of threat and fear that are present in the job of the referees. Football drama is shown through all the circumstances that go with the controversial decisions of the referees. The study of a contemporary football, which is not only one of the biggest planetary entertainments, but also the eligible space for the promotion of political leaders. Exciting shots from the unseen points of views of referees and players! Filmed simultaneously in the several states of Europe, this is one of the most complicated production ventures in contemporary documentary filmmaking.\nSELECTORS WORD: For a football freak this is a gift. An insight to the world of those black men on the pitch we love to hate. Here the roles are turned around it is unbelievable what the referees have to cope with from players and spectators!\nBorn a Liege, Belgium in 1968. Started as a sport journalist for RTBF. Soon he joined one of the most important European TV producers, Jean Libon. Worked with him on the famous investigative documentary series ?Strip Tease? and one of those films was nominated for Prix Europe.\nAfter five years of marketing at Gaumont/Buena Vista in Paris, worked in television and advertising. Directed various TV documentaries. Colaborated on series ?Strip Tease?.\nActress and film director. Directed various documentaries and one feature film.\nKILL THE REFEREE (Les arbitres), 2009\ndirected by: Jukka Kärkkäinen\nA documentary in a form of a poetic view into six Finnish livingrooms. It is a story of changes, loneliness, responsibilities and the unavoidable passing of time. The main characters are ordinary people in different phases of life. Each of them is searching for something important: human closeness, understanding and acceptance. The scale of events varies, but even the smallest one in the family circle positions the characters into dramatic situations. All these individual everyday experiences converge into a sensitive and at moments even a surreal story of human life. ""Forget Nokia and innovative economy! The jury hereby demands that this film must from now on be used as the main tool for building the Brand of Finland. (Annunciation of the Jury of the Finish competition at Tampere Film Festival 2009) The film is currently showing in the cinemas throughout Finland.\nSELECTOR\'S WORD: What a brilliant idea to portray a country through characters to be found in their natural surroundings, at home. You get to love that young man, who is to become a father and is obviously not quite ready for that responsibility. Idea brilliant, film the same!\nBorn in Kerava, Finland in 1972. Audio-visual education through various specialised courses and workshops, starting with video and sound production at Central Polytechnic, Kokkola, Finland in 1997 and audiovisual media at Voionmaa Institute of Meddia 1988/99, followed by workshops in Helsinki, on Borholm and in Wienna.\nZETOR BORN FREE (Zetor vappaana syntynyt), 2004\nTHE SMOKING ROOM (Tupakkahuone), 2006\nTOMORROW WAS YESTERDAY (Matkalla Vanhuuteen), 2008\nTHE LIVING ROOM OF THE NATION (Kansakunnan olohoune), 2009\ndirected by: Claudine Bories and Patrice Chagnard\nThey come every day from Azerbaijan, Mongolia, Sri Lanka, Somalia, Congo, Eritrea. The whole families come, with or without luggage, with or without passports; they arrive with charter flights, by buses, by ships. Among them there are pregnant women, young couples, old people. They arrive both with fear and hope. The waves of nations that seem as a menace to flood the unusual new Babylon, converge in the middle of Paris, in the organisation that helps them to orientate and survive. And right there, at the gates of heaven, for many of them, the two angels stand Caroline and Colette. With the two of them the story of the clash of cultures, customs and needs starts. This brings many of them to tears and despair, and some others to bliss and happiness. But this is also the story of angels who do not have anyone to complain to. Absurd, dramatic, funny, tragic, encouraging. The exciting study from the exceptional French documentary filmmakers who reveal with a big understanding for the delicate nuances the undreamt sights of contemporary Europe.\nSELECTOR\'S WORD: It could be anywhere in Europe human beings who come to a new country in order to get a better life! The social workers, who meet them and have conversations with them, do what they can according to the rules that have been set up. It is an emotional drama with comical moments that masterly conveys the language and cultural misunderstandings through close-up based cinematography.\nBegan her career in theatre. Took part in the movement of the decentralisation of theatre in France. In 1968, she directed her first documentary. Between 1990 and 2002, she helped run a creative centre dedicated to documentary cinema in Seine Saint Denis, and started the Documentary Cinema Meetings. She was a president of ADDOC, a group that brings together French documentarists.\nJULIETTE FROM THE MEN\'S SIDE (Juliette du côté des hommes), 1981\nIMAGINARY PORTRAIT OF GABRIEL BORIJES (Portrait imaginaire de Gabriel Bories), 1984\nSIR AGAINST MADAM (Monsieur contre Madame), 1999\nWOMEN OF TWELVE FRONTIERS (Les femmes des douze frontieres), 2003\nAND OUR DREAMS (Et nos reves), 2007\nTHE ARRIVALS (Les arrivants), 2009\nAt the age of 17, he ran the Grenoble Film Club, the biggest club in France in terms of members. Studied Philosophy at the Sorbonne. Worked as an editor in chief at the magazines about television and directed documentaries for TV. In 1969, he became a hippie and travelled in Afghanistan, Pakistian and India. Became interested in the plights of the farmers in Brazil, Africa and Bangladesh. Since 1977, hes dedicated himself to directing documentaries. He was president at Addoc, a group that brings together French documentarists.\nA FEW THINGS ABOUT THE TREE, ABOUT THE RIVER AND ABOUT THE CRY OF PEOPLE\n(Quelque chose de lArbre, du Fleuve et du Cri du Peuple), 1980\nSWAMI-JI, AN INNER VOYAGE (Swami-ji, un voyage intérieur), 1983\nCONVOY (Le Convoi), 1995\nIMPRESSION, MUSEUM OF ALGIERS (Impression, Musée dAlger), 2003\nIN THE RED TRUCK (Dans un camion rouge), 2005\nAND OUR DREAMS (Et nos reves), 2007\nTHE ARRIVALS (Les arrivants), 2009\ndirected by: Nina Hedenius\nExquisite documentary mastership which merge man, animals and plants into a world of cosmic harmony and tranquility. The story that unfolds in front of us like a canvas, painted with delicate gestures up to the finest details. The perfect symbiosis of all beings in which a man is not privileged in any way. The life of a special Swedish farm through the four seasons, filled with deep respect towards the nature. The silence and rhythm of everyday activities respire with this same respect. We have departed ourselves from animals and nature, Nina Hedenius says. I wanted to make an epic picture of the things that are expiring. Way of Nature is the love ode to animals and nature. The sights and sounds of nature without a single spoken word. The film of a stunning beauty and dignity.\nSELECTOR\'S WORD: You cant negociate with Nature, it was said at the Climate summit in Copenhagen. Having watched this wonderful film about Nature and about being Natural, you ask yourself and why should you It is not very far from us, this location, and yet it is far from urban stressful modern life.\nBorn as Nina Gudrun Johana Hedenius in the small town of Solna near Stockholm. Studied painting with an ambition to become a painter. Left Stockholm at the age of 25 and moved to the Swedish forest countryside, where she still lives. Succesful photography exhibition led to the invitation from Sweddish Television for making the first documentary film in 1965. She stops painting and becomes a filmmaker. Photographer, director, director of photography, editor and independent producer. Nina Hedenius is one of the most important Swedish documentarists and her films are at the very top of European documentary film.\nLIKE THE WIND MY LONGING (Likt vinden far min längtan), 1989\nREFLECTIONS IN MY EYE (Det speglar i mitt öga), 1992\nTHE OLD MAN IN THE COTTAGE (Gubben i stugan), 1995\nSWEDISH STORIES (Fran Sverige i tiden), 1999\nTHE ART OF CLEANING (Konsten att städa), 2002\nWAY OF NATURE (Naturens gang), 2008\ndirected by: Gianfranco Rosi\nIn the middle of Californian desert, forty metres below the sea level, on the site of a deserted military base and 250 kilometres northeast fom Los Angeles - a group of people is living outside the highly developed world, without electricity, without running water, without the police, without the governement. The surreal scenery resembles the Mad Max films, abandoned buses and cars are inhabited by colorful characters rebels, losers, prophets, poets, rockers. Each of them lives on his own idea and his own rules. Although living in extreme conditions, they do what other people do they sew, read, make love and dream their dreams. Everything looks apocalytpic, but they transmit the feeling of warmth and home. Gianfranco Rosi followed the lives of some of these people during the period of four years, succeeding to establish extremely direct, deep and discrete relationship. Images of dawn in the desert colour the atmosphere of the fim with excitement and warmth. The winner of the programme \'Horizons\' at the Venice film festival 2008 and the best Italian documentary that year! Postapocalyptic image of America without television and computers.\nSELECTOR\'S WORD: This is the ultimate proof of how important it is to stay with your characters for a long time (in this case more than a few years) to gain trust and credibility. And then it is a great plus that Rosi is an excellent filmmaker. Time and craftsmanship and vision.\nBorn in Asmara, Eritrea. Lived in Istanbul, New York, Rome and Los Angeles. Attended Univerity in Italy and graduated at New York University Film School. Works as director, director of photography and as creative dubbing supervisor for Universal, Fox, Paramaunt and Dreamworks. Guest lecturer at New York University Film School.\nBELOW SEA LEVEL, 2008\nEL SICARIO - in progess\ndirected by: German Berger-Hertz\nThe virtuoso plunge into the long-hidden tragedy of a broken family that carries in itself the agitations of Latin America. The journey of a son who is in search of the memory of his murdered father. The emotional history of a country that refuses to forget. The intimate diary of a family that struggles to overcome the tragedy. The scenes that are filled with energy of long ago suppressed events, which followed the protagonists of this story as a dark shadow for decades. The encounters with the persons that built their exceptionality and strength as a way to survive and to save hope. The exciting related parts of a large puzzle, which take us through the corridors of time, returning us to the tragedy and back to the liberating catharsis. Intended as an epic saga in a form of a fiction film, this is a subtle and layered documentary with a tension of a thriller and emotions of a great cinema melodrama. One of the largest transcontinental coproductions in recent documentary filmmaking.\nSELECTOR\'S WORD: Where lies the border between private and personal In this case there is no doubt as Berger invites us on his very personal and emotional journey in the framework of Chiles recent horror (hi)story. I learned a lot at the same time as I was watching a universal love story about a son and his father.\nBorn in Santiago, Chile in 1972. Studied Journalism and Art and Aesthetics. Worked as a journalist in two Chilean TV Stations and produced a series of documentaries. In 1997 he moves to Barcelona, where he currently resides. There he studies Cinematography (majoring in Direction and Editing) and pursues a Masters Degree in Documentary of Creation at Pompeu Fabra University. Works as director for film and TV docomentaries.\nVOYAGE TO NARRAGONIA (Viaje a Narragonia), 2002\nMY LIFE WITH CARLOS (Mi vida con Carlos), 2009', 'If you dread the thought of getting up in front of a group of people and performing, you are not alone. Millions of people suffer from performance anxiety, commonly called ""stage fright."" In fact, most people would rather get the flu than perform. Athletes, musicians, actors, and public speakers often get performance anxiety.\nPerformance anxiety can prevent you from doing what you enjoy and can affect your career. Worst of all, performance anxiety can negatively affect your self-esteem and self-confidence. Although it may be impossible to totally overcome performance anxiety, there are many things you can do to control your emotions and reduce anxiety.\nPerformance Anxiety Symptoms\nBeing the center of attention and having all eyes on you can be stressful. Your body reacts to this situation in much the same way as it would if you were being attacked. Your body\'s ""fight-or-flight"" mechanism kicks in, which is why symptoms of stage fright are similar to symptoms that occur when you are in real danger.\nPerformance anxiety symptoms may include:\nPerformance Anxiety Causes\nSimply put, stress and anxiety about performing in front of people causes performance anxiety. Confronting your fears and vulnerabilities, accepting yourself for who you are, and not feeling like you have to prove yourself to others, is the first step toward overcoming performance anxiety. Keep in mind that nobody is perfect, nobody expects you to be perfect, and it is OK to make mistakes.\nThe second step is learning how to redirect your negative thoughts, beliefs, images, and predictions about performing in public. Doing this is not as difficult as you might think.\nPerformance Anxiety Treatments\nHere are 10 tips to help you overcome your fears and shine on stage, on the field, or at the podium:\n- Be prepared: practice, practice, practice.\n- Limit caffeine and sugar intake the day of the performance. Eat a sensible meal a few hours before you are to perform so that you have energy and don\'t get hungry. A low-fat meal including complex carbohydrates -- whole-grain pasta, lentil soup, yogurt, or a bean and rice burrito -- is a good choice.\n- Shift the focus off of yourself and your fear to the enjoyment you are providing to the spectators. Close your eyes and imagine the audience laughing and cheering, and you feeling good.\n- Don\'t focus on what could go wrong. Instead focus on the positive. Visualize your success.\n- Avoid thoughts that produce self-doubt.\n- Practice controlled breathing, meditation, biofeedback, and other strategies to help you relax and redirect your thoughts when they turn negative. It is best to practice some type of relaxation technique every day, regardless of whether you have a performance, so that the skill is there for you when you need it.\n- Take a walk, jump up and down, shake out your muscles, or do whatever feels right to ease your anxious feelings before the performance.\n- Connect with your audience -- smile, make eye contact, and think of them as friends.\n- Act natural and be yourself.\n- Exercise, eat a healthy diet, get adequate sleep, and live a healthy lifestyle.\nKeep in mind that stage fright is usually worse before the performance and often goes away once you get started.\nOvercoming Performance Anxiety: Tricks of the Trade\nThere are also mental tricks you can play to help you perform with less anxiety. These include:\n- Focus on the friendliest faces in the audience.\n- Laugh when you can, it can help you relax.\n- Make yourself look good. When you look good, you feel good.\nThese tips should help reduce performance anxiety. But if they don\'t, talk to a counselor or therapist trained in treating anxiety issues. You may benefit from more intensive therapy, such as cognitive behavioral therapy, to help overcome performance anxiety. In addition, beta-blockers such as propranolol that lower the heart rate and block the effects of adrenaline are sometimes used by people with performance anxiety.\nConfronting your fears and learning ways to reduce and manage them can be empowering. Not only will it make you feel good about yourself, you may discover that you are a more confident performer, too.']"	['<urn:uuid:f825ae37-367d-493a-8700-f14d9a9d7146>', '<urn:uuid:fe9ce710-5740-4675-8b6b-2e031988f0db>']	open-ended	with-premise	long-search-query	similar-to-document	multi-aspect	novice	2025-05-12T15:09:02.012753	12	102	3057
30	raising ornamental vs food fish comparison	The key differences between raising ornamental and food fish are: Food fish like tilapia, catfish and trout are harvested within 6-14 months and provide organic protein, while ornamental fish like koi and goldfish are kept long-term (koi can live 30 years) and can be sold for profit. Both types require proper water conditions - food fish need specific temperature ranges for optimal growth (e.g. tilapia 82-86°F), while ornamentals like koi can adapt to wider ranges (59-77°F). Water quality is crucial for both: they need low ammonia/nitrite levels, proper pH (6.0-9.0), and adequate dissolved oxygen above 5.0 mg/l to prevent stress and disease.	"['Aquaponics benefits are many for backyard farmers, hobbyists and gardeners! When you compare aquaponics vs traditional farming, aquaponics uses far less water, takes up less space, doesn’t use pesticides or fertilizers and produces fish and vegetable crops that are 100% organic.\nWhat are the best fish for small aquaponics? Your choice will very much depend on whether you would like to eat your fish. If so, the best fish for small aquaponics farms could include tilapia, bluegill, catfish, trout and crappie. If however, you would like ornamental fish or fish that you can sell, you can consider koi, goldfish, guppies and Tetra.\nFish play an exceptionally important role in urban and backyard aquaponics systems so it is important to choose the right types of fish if want to set up a successful DIY aquaponics system.\nIn this article, we will look at the ideal environments for each fish type so that you can make the best decision before investing in your backyard aquaponics system.\nBefore you begin setting up an aquaponics fish farming system, you will need to make several very important decisions – one of the most important being what types of fish to raise in your aquaponics fish tank. Things you will need to consider include:\n- What size is your aquaponics system? Can the space you have support the types of fish you choose?\n- What is the water temperature, water quality and pH of your system?\n- What type of environment do your fish thrive in?\n- Do the types of fish you choose match up with the types of aquaponics vegetables and plants you would like to grow? For example, if you plan on growing cool-season aquaponics vegetables, will the aquaponic fish you choose be happy in the same environment in which the plants thrive?\n- Will the types of fish you choose provide all the nutrients that your aquaponics vegetables and plants will need?\n- Would you like to eat the fish you raise, sell them or are they simply ornamental fish?\nLet’s take a look at some of the best fish for small aquaponics. These types of fish are wonderful options and most of them are suitable for you if you are a beginner aquaponics fish farmer.\nBest Fish For Small Aquaponics Fish Tanks: Edible Fish\nWater Temperature: 82°F – 86°F / 28°C – 30°C\nSize: Up to 24in / 60 cm\nTank Mates: Yes\npH level: 6.5 – 9.0\nHarvest Time: 6-9 Months To One Pound\nTilapia is considered to be one of the best fish for small aquaponics systems because they are hardy and happily adapt to most environments. They are also resistant to diseases and parasites which makes them an attractive choice for aquaponics beginners and experts alike and you will usually find them right at the top of any “best fish for aquaponics” lists!\nTilapia have a varied diet and can survive on worms, insects, duckweed, aquatic plants, algae as well as pallet foods.\nTilapia prefer water temperatures of around 82° – 86°F or 28°C – 30°C but can survive outside of this range. They will however die if the water temperature goes below 50°F (10°C).\nIn their ideal growing environment, Tilapia can breed very quickly, spawning every 4-6 weeks. This could be a problem for a small aquaponics farm and you may need to consider a second tank as your stock increases.\nWater Temperature: 65℉ to 80℉ or 18°C to 27°C\nSize: 5in to 12in / 12cm – 30cm\nHarvest Time: 12 Months to 1 pound\nTank Mates? Yes\nIdeal pH: 6.5 to 8.5\nBluegills are omnivorous fish that are native to North America. In their natural environments, they live on a diet of insects, zooplankton, snails, algae, aquatic plants as well as other fish and their eggs (protein makes up about 30% of their diet).\nBluegills are one of the best fish for small aquaponics because they grow quite quickly and in one year can reach a length of about 12 inches or 30 centimeters. It will take them about two years to reach a good size for breeding. You can expect your Bluegills to live for about 5 to 6 years if well cared for.\nBluegills are schooling fish, with the average school consisting of 10 to 20 fish. Bluegill fish, that belong to the same school, will protect each other from predators and will also search for food together.\nOne disadvantage of using Bluegill in your aquaponics farm is that they tend to enjoy eating their own young, although they do happily live with other fish species. You will therefore need to separate the babies and their eggs into another aquaponic fish tank so that the adults don’t eat them!\nWater Temperature: 65°F – 86°F / 18°C – 30°C\npH level: 7.0 to 8.5\nGrowth Rate: 2 – 3 Pounds in 24 Months\nTank Mates: Yes\nSize: 0.39in-106in / 1cm – 2.7m\nCatfish are one of the best fish for small aquaponics because they are an excellent source of vitamin B12 and Omega-3 fats. They are also packed with lean protein, vitamins and minerals and are low in calories, a perfect choice if you want to lose weight.\nThere are over 3,000 species of catfish that vary from small, peaceful fish to large more aggressive species. In ideal conditions, it isn’t uncommon to see some species of catfish reach 3 pounds (1.4kg) within 12 months!\nChannel catfish (Ictalurus punctatus) are considered one of the best fish for small aquaponics because they are easy to breed and raise and they adapt well to aquaponics fish tanks. Mature catfish could spawn up to 9 times in a season and their eggs usually hatch within 10 days.\nCatfish eat a wide variety of foods including frogs, snails, crabs, frogs, algae, and aquatic plants and are happy to scavenge for debris as well.\nAlthough they are known to survive in a wide range of conditions, they prefer warmer water temperatures of about 75 – 86°F / 24 – 30° C. In colder temperatures, their metabolism and food consumption slows down so they will produce less fish waste which means less nutrient-rich water for your aquaponic vegetables and plants.\nCatfish are happy to live with other aquaponic fish such as crappie, tilapia, and koi.\nWater Temperature: 45°F – 72°F / 7 – 22°C\nSize: 15 in / 38cm\npH level: 6.5 to 8.0\nTank Mates – No\nHarvest Time: 12 – 14 months\nTrout are extremely popular fish that are farmed for their taste and high value. They have a good growth rate and are ready for harvest at about 12 to 14 months. In colder areas they are considered one of the best fish for small aquaponics fish tanks because they prefer colder water temperatures and thrive when the water temperature is in the 45°C – 65° F / 7°C – 18°C range. If you live in a warmer area you would need to investigate ways of cooling the water temperature so that they don’t get too warm.\nTrout are an excellent choice for your aquaponics fish tank if you plan on growing aquaponic vegetables that prefer cooler temperatures eg. broccoli, cabbage, and collard greens.\nTrout have a diverse diet and enjoy algae, insects, shrimp, fish and other aquatic invertebrates such as dragonflies and flies. The flavor of the fish is very dependent on the diet of the fish.\nRainbow trout are a popular choice for backyard aquaponics fish farms because they have a high nutritional value, are low and fat and have an excellent flavor. They are commercially farmed and sold to consumers, supermarkets and restaurants as fresh, frozen or smoked.\nTrout grow to about 15 inches / 38 centimeters in 9 months and you will need to make sure that they have lots of space so that they don’t outgrow their aquaponics fish thank. Overcrowding in your aquaponics fish tank can cause problems such as aggression, dirty water and stunted growth.\nTrout tend to be territorial and can become aggressive especially if smaller fish are added to their tank. However, some aquaponics farmers have had success with other fish types as long as they are around the same size. You may need to think about additional aquaponic fish tanks if you plan on keeping trout of different sizes and ages.\nWater Temperature: 68℉ to 72℉ / 20°C – 22°C\nHarvest Time: 12 Months to 1 pound\nTank Mates? No\nIdeal pH: 6.0 to 7.5\nSize: 5in – 19in / 12cm – 48cm\nCrappie are hardy fish so they are good for beginners. Although they can survive in water temperatures as high as 80°F / 26°C and as low as 55°F/ 12°C, they thrive when the water temperature is in the 70°F to 75°F / 21°C – 23°C range and will grow faster in warmer water. If the water temperature becomes too low they become sluggish and they won’t produce as much waste which could affect the growth of your aquaponics vegetables.\nCrappies can start breeding at 12 months so you could end up with a lot more crappies than you had planned for! They don’t do well with other fish because they tend to fight, defending their eggs, young and themselves against perceived threats and predators.\nCrabbies tend to be fussy when it comes to eating. They love minnows but these can become expensive if your aquaponics farm is on a tight budget. They will however eat commercially made fish foods as well as larvae, small insects and crawfish.\nIf crabbies don’t end up on the plate they can quite happily live up to 7 years if well cared for.\nBest Fish For Small Aquaponics Fish Tanks: Non-Edible Fish\nWater Temperature: 59°F – 77°F / 15°C – 25°C\npH levels: 7.0 to 8.0\nSize: 12in – 36in / 30cm – 91cm\nKoi are one of the most beautiful ornamental fish in the world! They are one of the best fish for small aquaponics fish tanks because they have a high retail value. They are very popular amongst beginner aquaponic backyard farmers because they adapt well to most water conditions and are fairly parasite and disease-resistant. They are also hardy, resilient and easy to care for.\nKoi generally do well in aquaponics fish tanks with other large aquaponics fish as long as they don’t fight and there is enough space for each species that you keep.\nThey are omnivores and usually eat just about any food including green vegetables. They seem to really enjoy algae which is good news for your aquaponics system and your budget!\nThey tend to grow and eat well, however, the more they eat, the more fish waste they produce. This can be both a good and a bad thing for your small aquaponics farm. Good because your aquaponics vegetables and plants get a large amount of nutrient-rich water to thrive in. Bad because you will have to monitor the amount of fish waste produced. If you notice that your filtration system isn’t handling the amount of fish waste produced, a more efficient filter may need to be installed.\nFor optimal growth, Koi prefer living in water temperatures of around 59°F -71°F / 15°C -25°C.\nKoi can live up to 30 years in optimal living conditions.\nWater Temperature: 78°F – 82°F / 25°C -27°C\npH levels: 6.0 to 8.0\nSize: Up to 14in / 35cm\nTank Mates: Yes\nGoldfish are one of the best fish for small aquaponics fish tanks because they are tough and very easy to breed and take care of. They can live for over 10 years in ideal living conditions and are perfect for small aquaponics systems.\nAlthough goldfish can survive in water temperatures of 50°F to 73°F / 10°C – 23°C, they thrive when the water temperature is between 78°F – 82°F / 25°C -27°C. Keep in mind that rapid changes to the water temperature can be fatal for them.\nGoldfish usually grow according to the size of the fish tank they live in. In an aquaponics fish tank where they have a lot of space, you can expect them to grow to about 1ft / 30cm.\nGoldfish have a varied diet which can include flakes, pellets, green vegetables as well as live and protein foods.\nThere are two different goldfish species, the single-tail and the twin-tail. The single-tail goldfish tend to swim faster and can sometimes be more aggressive than the twin-tail. It is therefore a good idea to avoid keeping these two types of goldfish in the same fish tank. That said, goldfish generally have very calm temperaments so they will happily live with other types of fish in their aquaponics fish tank.\nWater Temperature: 72℉ – 82℉ / 22°C – 27°C\nTank Mates? Yes\nIdeal pH: 6.8 to 7.6\nSize: 0.6in – 2.4in / 1.5cm – 6cm\nGuppies, along with goldfish, are one of the best fish for small aquaponics fish tanks. They are a wonderful option for aquaponics beginners because they are hardy, low maintenance and easy to care for. They also have some economic value if you would like to sell them. They tend to live well with other non-aggressive fish such as tetra.\nThere are almost 40 species of guppies, with the most popular guppy fish for small aquaponics being the common guppy and the Endler guppy. The common guppy prefers cooler water while the Endler guppy likes warmer water temperatures.\nGuppies are omnivorous and they need a varied diet to stay healthy. They eat pellets, fish flakes, green herbs, vegetables and live foods like bloodworms. Protein-rich foods help to boost their beautiful coloring!\nGuppies have a short life span of 1 to 3 years but in ideal conditions can reach sometimes live to 4 or 5 years. They are livebearers, meaning that they carry their spawn within their bodies. They reproduce quickly with one female giving birth to 50 to 100 baby guppies each time. You will need to place the newborns into a separate fish tank so that they are protected and not eaten by other fish.\nWater Temperature: 75℉ – 81℉ / 23°C – 27°C\nTank Mates? Yes and No\nIdeal pH: 6.8 to 7.8\nSize: 1.5in / 3.8cm\nTetra fish come from the Amazon Jungle and therefore prefer warmer water temperatures of between 75°F to 81°F / 23°C – 27°C. There are about 150 different species of tetra fish, the most common being the neon, glowlight, diamond and cardinal tetras. Generally, tetras weigh just a tenth of a gram and grow to about 1.5 inches / 3.8 centimeters and are ideal for both mini and small indoor aquaponics systems because they are so tiny.\nThey are easy to breed and care for and can be sold as pets. They grow quite quickly and are fully grown at around six months old. It is best to keep your baby tetras in a separate tank until they are about 3 months old to protect them.\nTetras are also omnivorous and enjoy a varied diet of algae, tiny insects, larvae, bloodworms and pellet foods.\nTetras are very calm and peaceful fish and they are quite happy to share their fish tanks, but only with smaller, nonaggressive breeds. Fish that are even slightly bigger or aggressive will most likely eat them.\nInfographic – Best Fish For Small Aquaponics Systems\nWhile many aquaponics beginners and experts consider the fish in this article to be some of the best fish for small aquaponics, there are of course so many other types of fish you can choose from depending on your aquaponics fish farm size. We would love to hear your thoughts on what the best fish for small aquaponics are. Let us know in the comments section below and we will update our article!', 'SL10603 : SL10603 Water Management 1 Water quality and fish health : Water quality and fish health The single, most important factor affecting fish health and influencing disease in fish ponds and tanks is water quality.\nRaised levels of ammonia or nitrite, sub-optimum pH and water hardness levels or a high level of organic pollution will be stressful to fish; predisposing them to disease.\nIf we are to create healthy, optimum conditions and prevent disease, it is important to be clear what is actually meant by good water quality. 2 1. Low ammonia and nitrite : 1. Low ammonia and nitrite Fish are constantly polluting their own environment and producing ammonia.\nBoth ammonia and nitrite are highly dangerous, causing stress and physical damage to sensitive tissues. A major, major requirement of any fish keeping system is no detectable levels of either.\nThis particularly applies to new set-ups (new pond syndrome) and heavily stocked koi ponds. Biological filtration may be needed to maintain optimum levels. 3 2. Chemically clean water : 2. Chemically clean water The water should be chemically clean and free of chemicals such as pesticides, chlorine, heavy metals, organophosphates and chemicals used to treat fish diseases.\nThe presence of any toxic chemicals, even at fairly low levels, may be harmful. 4 3. Water hardness, pH and temperature : 3. Water hardness, pH and temperature Different species of fish have specific requirements for essential water parameters such as pH, water hardness, alkalinity and temperature.\nConditions outside of what are fairly narrow limits are liable to create stress.\nWater that fails to meet these criteria cannot for obvious reasons be considered good water quality 5 4. Low levels of organic pollution : 4. Low levels of organic pollution In addition to fish waste, the pond or tank is also being continuously polluted with uneaten food, algae and other detritus. As this organic matter decomposes it produces many organic and inorganic compounds.\nBiological filtration will take care of ammonia and nitrite, but there may be a build up of dissolved and particulate organic compounds.\nHigh levels of organics can create conditions that encourage disease, parasites and opportunistic bacteria. Water with high levels of organic matter cannot be considered good water quality. 6 5. Stability not fluctuation : 5. Stability not fluctuation Depending on the water chemistry, stocking levels and pond design, it is possible to have substantial fluctuations of pH, temperature and other parameters over a 24-hour period.\nConstant changes - even if they stay within the preferred range are liable to be extremely stressful, as the fish have to constantly adapt to changing conditions.\nAn example might be pH that varies between, 7 in the morning, rising to 9-10 in the evening on a hot sunny day. 7 Slide 8: Apart from stressing the fish, it will have other implications for other water chemistry aspects such as ammonia and many common disease treatments. Water that constantly fluctuates in quality and conditions cannot be said to be good water quality 8 Water Quality : Water Quality When a hatchery is on a reuse system, it is necessary to monitor many parameters to insure the water quality is optimum for fish survival 9 Slide 10: 10 Slide 11: Why Temperature Is Important\nHuman activities should not change water temperatures beyond natural seasonal fluctuations.\nTo do so could disrupt aquatic ecosystems. Good temperatures are dependent on the type of stream you are monitoring.\nLowland streams, known as ""warmwater"" streams, are different from mountian or spring fed streams that are normally cool. 11 Slide 12: In a warmwater stream temperatures should not exceed 89 degrees (Fahrenheit).\nCold water streams should not exceed 68 degrees (Fahrenheit).\nOften summer head can cause fish kills in ponds because high temperatures reduce available oxygen in the water. 12 Slide 13: Why pH Is Important\npH is a measure of the acidic or basic (alkaline) nature of a solution. The concentration of the hydrogen ion [H+] activity in a solution determines the pH. 13 Slide 14: Environmental Impact:\nA pH range of 6.0 to 9.0 appears to provide protection for the life of freshwater fish and bottom dwelling invertebrates\nRunoff from agricultural, domestic, and industrial areas may contain iron, aluminum, ammonia, mercury or other elements.\nThe pH of the water will determine the toxic effects, if any, of these substances.\nFor example, 4 mg/l of iron would not present a toxic effect at a pH of 4.8. However, as little as 0.9 mg/l of iron at a pH of 5.5 can cause fish to die. 14 Slide 15: Min. Max. Effects\n3.8 10.0 Fish eggs could be hatched, but deformed young are often produced\n4.0 10.1 Limits for the most resistant fish species\n4.1 9.5 Range tolerated by trout\n--- 4.3 Carp die in five days\n4.5 9.0 Trout eggs and larvae develop normally\n4.6 9.5 Limits for perch\n--- 5.0 Limits for stickleback fish\n5.0 9.0 Tolerable range for most fish\n--- 8.7 Upper limit for good fishing waters\n5.4 11.4 Fish avoid waters beyond these limits\n6.0 7.2 Optimum (best) range for fish eggs\n--- 1.0 Mosquito larvae are destroyed at this pH value\n3.3 4.7 Mosquito larvae live within this range\n7.5 8.4 Best range for the growth of algae 15 Slide 16: Why Chlorides Are Important\nChloride is a salt compound resulting from the combination of the gas chlorine and a metal. Some common chlorides include sodium chloride (NaCl) and magnesium chloride (MgCl2).\nChlorine alone as Cl2 is highly toxic, and it is often used as a disinfectant. In combination with a metal such as sodium it becomes essential for life. Small amounts of chlorides are required for normal cell functions in plant and animal life. 16 Slide 17: Environmental Impact:\nChlorides are not usually harmful to people; however, the sodium part of table salt has been linked to heart and kidney disease.\nSodium chloride may impart a salty taste at 250 mg/l; however, calcium or magnesium chloride are not usually detected by taste until levels of 1000 mg/l are reached.\nPublic drinking water standards require chloride levels not to exceed 250 mg/l. 17 Slide 18: Chlorides can corrode metals and affect the taste of food products. Therefore, water that is used in industry or processed for any use has a recommended maximum chloride level.\nChlorides can contaminate freshwater streams and lakes. Fish and aquatic communities cannot survive in high levels of chlorides 18 Slide 19: Why Dissolved Oxygen is Important\nDissolved oxygen analysis measures the amount of gaseous oxygen (O2) dissolved in an aqueous solution.\nOxygen gets into water by diffusion from the surrounding air, by aeration (rapid movement), and as a waste product of photosynthesis.\nWhen performing the dissolved oxygen test, only grab samples should be used, and the analysis should be performed immediately.\nTherefore, this is a field test that should be performed on site. 19 Slide 20: Environmental Impact:\nTotal dissolved gas concentrations in water should not exceed 110 percent.\nConcentrations above this level can be harmful to aquatic life.\nFish in waters containing excessive dissolved gases may suffer from ""gas bubble disease""; however, this is a very rare occurrence. 20 Slide 21: 21 Slide 22: The bubbles or emboli block the flow of blood through blood vessels causing death.\nExternal bubbles (emphysema) can also occur and be seen on fins, on skin and on other tissue.\nAquatic invertebrates are also affected by gas bubble disease but at levels higher than those lethal to fish. 22 Slide 23: Adequate dissolved oxygen is necessary for good water quality.\nOxygen is a necessary element to all forms of life.\nNatural stream purification processes require adequate oxygen levels in order to provide for aerobic life forms.\nAs dissolved oxygen levels in water drop below 5.0 mg/l, aquatic life is put under stress.\nThe lower the concentration, the greater the stress. Oxygen levels that remain below 1-2 mg/l for a few hours can result in large fish kills. 23 Slide 24: Why Total Iron Is Important\nIron is the fourth most abundant element, by weight, in the earth\'s crust.\nNatural waters contain variable amounts of iron despite its universal distribution and abundance.\nIron in groundwater is normally present in the ferrous or bivalent form [Fe++] which is a soluble state. 24 Slide 25: It is easily oxidized to ferric iron [Fe+++] or insoluble iron upon exposure to air.\nIron is a trace element required by both plants and animals. It is a vital oxygen transport mechanism in the blood of all vertebrate and some invertebrate animals. 25 Slide 26: Environmental Impact:\nIron in water may be present in varying quantities depending upon the geological area and other chemical components of the waterway.\nFerrous Fe++ and ferric Fe+++ ions are the primary forms of concern in the aquatic environment.\nThe ferrous form Fe++ can persist in water void of dissolved oxygen and usually originates from groundwater or mines that are pumped or drained. 26 Slide 27: Iron in domestic water supply systems stains laundry and porcelain.\nIt appears to be more of a nuisance than a potential health hazard.\nTaste thresholds of iron in water are 0.1 mg/l for ferrous iron and 0.2 mg/l ferric iron, giving a bitter or an astringent taste.\nBlack or brown swamp waters may contain iron concentrations of several mg/l in the presence or absence of dissolved oxygen, but this iron form has little effect on aquatic life. 27 Slide 28: Why Nitrate, Nitrite, and Nitrogen Are Important\nNitrogen is one of the most abundant elements. About 80 percent of the air we breath is nitrogen.\nIt is found in the cells of all living things and is a major component of proteins.\nInorganic nitrogen may exist in the free state as a gas N2, or as nitrate NO3-, nitrite NO2-, or ammonia NH3+.\nOrganic nitrogen is found in proteins and is continually recycled by plants and animals. 28 Slide 29: Slide 30: Environmental Impact:\nNitrogen-containing compounds act as nutrients in streams and rivers. Nitrate reactions [NO3-] in fresh water can cause oxygen depletion.\nThus, aquatic organisms depending on the supply of oxygen in the stream will die. 30 Slide 31: The major routes of entry of nitrogen into bodies of water are municipal and industrial wastewater, septic tanks, feed lot discharges, animal wastes (including birds and fish) and discharges from car exhausts. Bacteria in water quickly convert nitrites [NO2-] to nitrates [NO3-].\nNitrites can produce a serious condition in fish called ""brown blood disease.""\nNitrites also react directly with hemoglobin in human blood and other warm-blooded animals to produce methemoglobin. 31 Slide 32: Methemoglobin destroys the ability of red blood cells to transport oxygen.\nThis condition is especially serious in babies under three months of age.\nIt causes a condition known as methemoglobinemia or ""blue baby"" disease. Water with nitrite levels exceeding 1.0 mg/l should not be used for feeding babies.\nNitrite/nitrogen levels below 90 mg/l and nitrate levels below 0.5 mg/l seem to have no effect on warm water fish. 32 Slide 33: Why Phosphorus Is Important\nPhosphorus is one of the key elements necessary for growth of plants and animals.\nPhosphorus in elemental form is very toxic and is subject to bioaccumulation.\nPhosphates PO4--- are formed from this element. Phosphates exist in three forms: orthophosphate, metaphosphate (or polyphosphate) and organically bound phosphate.\nEach compound contains phosphorous in a different chemical formula. 33 Slide 34: Ortho forms are produced by natural processes and are found in sewage.\nPoly forms are used for treating boiler waters and in detergents.\nIn water, they change into the ortho form. Organic phosphates are important in nature.\nTheir occurrence may result from the breakdown of organic pesticides which contain phosphates.\nThey may exist in solution, as particles, loose fragments, or in the bodies of aquatic organisms. 34 Slide 35: Slide 36: Environmental Impact:\nRainfall can cause varying amounts of phosphates to wash from farm soils into nearby waterways.\nPhosphate will stimulate the growth of plankton and aquatic plants which provide food for fish.\nThis increased growth may cause an increase in the fish population and improve the overall water quality.\nHowever, if an excess of phosphate enters the waterway, algae and aquatic plants will grow wildly, choke up the waterway and use up large amounts of oxygen. 36 Slide 37: This condition is known as eutrophication or over-fertilization of receiving waters.\nThe rapid growth of aquatic vegetation can cause the death and decay of vegetation and aquatic life because of the decrease in dissolved oxygen levels.\nPhosphates are not toxic to people or animals unless they are present in very high levels.\nDigestive problems could occur from extremely high levels of phosphate. 37 Slide 38: 38 Slide 39: Why Fecal Coliform Testing Is Important\nTotal coliform bacteria are a collection of relatively harmless microorganisms that live in large numbers in the intestines of man and warm- and cold-blooded animals.\nThey aid in the digestion of food. A specific subgroup of this collection is the fecal coliform bacteria, the most common member being Escherichia coli.\nThese organisms may be separated from the total coliform group by their ability to grow at elevated temperatures and are associated only with the fecal material of warm-blooded animals. 39 Slide 40: Environmental Impact:\nThe presence of fecal coliform bacteria in aquatic environments indicates that the water has been contaminated with the fecal material of man or other animals.\nAt the time this occurred, the source water may have been contaminated by pathogens or disease producing bacteria or viruses which can also exist in fecal material.\nSome waterborne pathogenic diseases include typhoid fever, viral and bacterial gastroenteritis and hepatitis A. 40 Slide 41: The presence of fecal contamination is an indicator that a potential health risk exists for individuals exposed to this water.\nFecal coliform bacteria may occur in ambient water as a result of the overflow of domestic sewage or nonpoint sources of human and animal waste. 41 Slide 42: 42']"	['<urn:uuid:cc868589-f001-4fb7-97aa-98cec63b0165>', '<urn:uuid:9edc0dde-e144-4840-b6ce-a6deb2d0a2f6>']	open-ended	with-premise	short-search-query	distant-from-document	multi-aspect	novice	2025-05-12T15:09:02.012753	6	102	4941
31	Can I use ACH payments to send money overseas?	No, ACH only processes domestic payments within the United States.	['Getting paid (and getting paid on time!) is one of the biggest hurdles of small business owners. As we well know, invoices often stay unpaid beyond the due date. Third-party payment processing apps charge stingy fees and setting up customer credit card processing can be a major hassle. So what’s left then? ACH payments!\nWhat is an ACH Payment?\nACH, short for Automated Clearing House, is a domestic financial network, used by banks to process all the incoming payments and outbound money transfers.\nACH payment, in turn, is a bank-to-bank, fully electronic money transfer, processed by the Automated Clearing House network. In short, it’s one of the many ways to move money between bank accounts.\nACH transfers also go by the name of “direct payments” or “direct debit”, meaning that the money is taken directly out of your account and transferred to another person/business, without any intermediary payment processor in between such as PayPal or Venmo or a credit card network.\nTo further understand ACH meaning, let’s take a closer look at its two components:\n- Automated: ACH payments are executed by computer systems only. ACH systems can batch-process hundreds of thousands of payments per day. In 2019, the ACH network moved some $24.7 billion of payments between accounts.\n- Clearing house: The ACH network relies on two central “clearing houses” — The Federal Reserve or The Clearing House. These two institutions assist the network in matching and processing various financial operations.\nHow Does ACH Payment Processing Work in Details?\nIf you are keen to learn a bit more about the matter, here are the technical nuts and bolts of ACH payment processing.\nWithin the ACH system, we have two types of computers, communicating with one another to execute a transfer:\nODFI: That’s someone who’s creating a payment request. For instance, you decide to transfer some cash to one of your dropshipping suppliers. In this case, the ACH network will view you as an Originator and your bank account will be the Originating Depository Financial Institution (ODFI). Your money transfer request gets recorded in the system and forwarded to the ACH Operator — a clearinghouse, responsible for routing all the incoming transfer requests to the specified destination.\nRDFI: Your supplier, in this case, will be a Receiver. And their bank account will be a Receiving Depository Financial Institution (RDFI) — another clearing house will adjust their account balance, based on the communicated information about the volume of the money transfer.\nIn essence, ACH payment processing is all about ensuring that the right amount of money leaves account A and safely gets to account B.\nSo when you come to a bank and ask about an ACH transfer, the clerk will likely ask you if you want to make an:\n- ACH debit transaction that is “pull” or debit money from someone’s account (e.g. bill your client based on their recent invoice).\n- Or ACH credit transaction. That is to dispatch some cash to a different bank account.\nACH Payment Processing Time\nACH payments are relatively fast. In most cases, your transfer will be executed in 3-5 business days since all the payment processing is fully automated.\nYour bank may also support the recently launched Same Day ACH payments — a new network feature that allows them to move your transfer within the same business day (by 5:00 PM latest). Last year, this scheme moved over $1 million of payments per day with a daily total value of $1 billion.\nHowever, the ACH network can get congested at times. For example, at the end of the year or during tax season when loads of people are sending their cash back and forth. In such cases, you may have to wait a bit longer.\nThe Pros of Accepting ACH Payments as a Small Business\nUsing ACH payments as your go-to payment method for invoicing is a great idea if you are dealing with US-based clients.\nNote: ACH processes only domestic payments.\n- ACH payment fees are ridiculously low. The average processing fee per transaction is $0.20-$1.50, depending on your bank. Some business bank accounts come with a set number of free ACH direct debits or transfers per month.\n- ACH is a faster and often safer alternative to payments requiring an additional medium such as eChecks or money orders.\n- By setting up a direct debit for customers, you can also reduce your invoice payment times and improve cash flow. Rather than waiting for the payment to arrive, you’ll proactively bill your customers every month on a set day.\n- For the same reason, ACH is an excellent tool for executing payroll payments and billing/paying to suppliers.\nThe Cons of Using ACH Payments as a Business Owner\nThe biggest issue with ACH is that this system will process all the incoming requests in batches. Meaning, your payment won’t budget until quite a few other transactions are waiting along. When this threshold is reached, all the pending payments are processed at once. That’s not much of an issue with same-day ACH though.\nThe second drawback is that reversing an ACH check or dealing with an incorrectly filled one can be a bit of a hassle + costly:\n- Average ACH Return Fee is around $2-$5 per transaction that didn’t go through.\n- Average ACH Reversal/Chargeback Fee can be anywhere from $5-$25 per instance.\nACH payments are a good option for those businesses that are ready to forgo payment speed for lower fees. ACH is also a great way of collecting recurring payments from customers and dispatching outgoing checks to your team, vendors, and subcontractors. Overall, ACH is a popular and secure way of exchanging funds that you should definitely consider!']	['<urn:uuid:b9519cb3-6bd2-47e2-b1d6-37e45e45dfed>']	factoid	with-premise	concise-and-natural	similar-to-document	single-doc	novice	2025-05-12T15:09:02.012753	9	10	947
32	What kinds of topics has this researcher published about regarding the development of renewable energy in Wales?	She has published research on power, rationality and discourse in Welsh renewable energy policy-making, including work on policy integration for sustainable development and the challenges of implementing renewable energy development in post-devolution Wales.	['Dr Ruth Stevenson\nRuth is an environmental social scientist with 25+ years in consultancy and research in the environment and sustainability field. Ruth specialises in renewable and low carbon energy policy and planning, environmental and social impacts of energy development, community renewables and resilience planning, energy discourses and communication, system change and the promotion of sustainable practices and lifestyles.\nRuth is an Environmental social scientist specialising in the institutional, social, planning and environmental aspects of sustainability. She spent her early career as a consultant environmental planner, primarily in the renewable energy industry, acting as a Director for the leading, worker owned renewable energy company, Dulas Ltd. Whilst representing the wind energy industry on the planning policy panel for the Welsh Government, she was inspired to initiate her PhD research on the policy making process and its effects on the delivery of ‘sustainable development’. Since then, Ruth’s research has focussed on new governance models, behavioural and systems change required for energy, environmental and social resilience.\nRuth’s combination of experience in public, private and academic environments brings a deep and nuanced understanding of sustainability and resilience issues. She uses her consultancy as a test bed for emerging theoretical understanding and her research and teaching encourages her to be a more reflexive practitioner.\nRuth has managed over 25 Environmental Assessments and planning applications for renewable energy schemes and has carried out research for a variety of European and UK funded projects on the environmental and social impacts of renewable energy developments. With an emerging focus on resilience she has supported a number of community renewable energy projects through the planning phase. Ruth also carried out a major piece of research for Cardiff University’s School of Architecture, alongside industry and employers in Wales to identify and deliver new sustainability skills for built environment professionals. This resulted in the writing of a 25 year strategy for sustainability training in Wales.\nRuth’s research focusses on:\n- Environmental and Social Impacts of Energy developments\n- Developing new governance models for energy resilience\n- Systems thinking and resilience\n- Social practices and behaviour change for sustainable lifestyles\n- Discourses and communication\n- Module leader SA, SABE, SAP, SEPDM, SFNR, Dissertation\n- Lecturer SA, SABE, SAP, SEPDM, SFNR, Dissertation\n- Seminar and practical studies tutor\n- Thesis supervisor\nPhD ‘Power, Rationality and Discourse in Renewable Energy Policy Making in Post-Devolution Wales: A Foucauldian – based Discourse Analysis’ (Funded by ESRC) Aberystwyth University\nMSc. Landscape Ecology, Design and Maintenance\nBSc. (Hons) Geography\nProfessional Membership & Other\nAssociate Member of the Institute of Environmental Management and Assessment (IEMA)\nAcademic referee for Environmental Values, Environmental Management, Journal of Environmental Policy and Planning, and Energy Policy.\nLeader: Gwerin y Coed (Woodcraft Folk) engaging children in sustainability though play\nFounding member: Plas Einion Housing Management Company (Co- housing)\nCommunity Energy Fund-Robert Owen Community Banking Fund: Act as one of the panel that managing funds for Community Energy Financing (2014 – present)\nAnderson, S & Stevenson, R (2018) Are dispositional mindfulness traits effective in sustaining pro- environmental behaviour? International Conference for Sustainable Design of the Built Environment SDBE 2018 pp 280 -291 September, 12th-14th September 2018, London\nStevenson , R and Howard Coles, J. (2015) Neighbourhood Planning and the Energy Conversation, Town and Country Planning Vol 84 pg 449 – 456\nStevenson, R ((2014) Built Environment Sustainability Training (BEST): A Strategy for Growth, Adaptation & Progression: Cardiff University, School of Architecture\nStevenson R. (2013) Built Environment Sustainability Training: Growth, Adaptation and Progression Retrofit Wales Conference, Sept 2013, Cardiff\nStevenson R (2013) Skills Gap Analysis: Sustainability in Existing Buildings BIFM, Sustainability in Facilities Management, Newport Langstone Hotel 26th April 201Stevenson, R (2009) Discourse, Power and energy conflicts: understanding Welsh renewable energy planning policy Environment and Planning C: Government and Policy, Vol. 27 no 3 512-526\nStevenson, R (2013) Built Environment Sustainability Training: Skills Needs Analysis for the Existing Build Sector: Asset Skills (for BEST Built Environment Sustainability Training programme led by Cardiff University, School of Architecture)\nStevenson, R. & Richardson, and T. (2003) ‘Policy Integration for Sustainable Development: exploring barriers to renewable energy development in post devolution Wales.’ Journal of Environmental Policy and Planning Vol. 5, March 2003 pg. 95 -118\nStevenson, R. (2003) Institutional challenges of sustainable development: An exploration of renewable energy policy development in Wales. Paper presented to Royal Geographic Society/ Institute of British geographers Conference, London September 4th – 6th 2003\nStevenson, R. (2002) The Rhetoric and Reality of Sustainable Wales: A review of Renewable Energy Policy. Paper presented to Planning Research Conference, University of Dundee, and 8th – 10th April 2002\nStevenson, R (2002) Devolution and the Institutionalisation of Sustainable Development – Paper presented to RESSG postgraduate conference, The University of Gloucestershire 20th February 2002.\nEdwards, R., Leaney, V.C, Stevenson, R & Heslop, A (2001) Overcoming barriers to greater active community and local involvement in wind farms in the UK\nStevenson, R. (2000) Realising the Potential for the Protection of the Environment by Developing Small Hydropower paper presented at ALTENER 2000, Toulouse, France, October 2000, & publication XVII/4.1030/2/98.328']	['<urn:uuid:9c8add06-a7fa-453c-b05f-b84d8f5b9450>']	factoid	direct	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-12T15:09:02.012753	17	33	837
33	what tests treatments available children movement disorders brain spine problems	For children with movement and brain/spine disorders, specialists conduct physical examinations, test reflexes, and may use genetic testing and cerebrospinal fluid analysis for diagnosis. Treatment options include physical therapy, rehabilitation, orthopedic bracing, and neurosurgery procedures like selective dorsal rhizotomy. They also use advanced diagnostic technologies including specialized MRI techniques, onsite diagnostics, and provide comprehensive medical and surgical treatments for brain, spine, and nerve disorders.	"[""Our pediatric cardiologists and heart surgeons combine expertise in caring for children's hearts with the latest diagnostic technology, treatment options, and surgical techniques. We also participate in clinical trials of emerging treatments. Learn more about our pediatric cardiology services.\nOur pediatric orthopaedic specialists provide the highest quality care for disorders that affect your child’s bones, soft tissues, and joints, including spinal curvature disorders such as scoliosis. We also work to help your child heal from -- and prevent -- sports injuries.\nOur pediatric ophthalmologists are experienced in the special eye care needs of infants and children. Our pediatric optometrists perform regular eye exams to assess your child's vision and eye health and prescribe corrective lenses as needed. Learn more about how we diagnose and treat pediatric eye diseases.\nSpecialties at Duke Children's Hospital & Health Center\nDuke’s highly skilled psychiatrists, psychologists, social workers, and counselors provide compassionate, child- and family-centered care for a wide range of behavioral and mental health needs, including ADHD, autism spectrum disorders, anxiety disorders, bipolar disorder, depression, developmental delays, and eating disorders.\nThe Duke Pediatric Blood and Marrow Transplant Program provides innovative care for children and adolescents with blood cancers and blood disorders, inherited metabolic diseases, and inherited immune disorders. We offer unrelated-donor umbilical-cord blood stem-cell transplants for patients who lack a fully matched donor, which allows us to extend this life-saving therapy to more patients.\nOur pediatric oncologists and hematologists can provide your child expert care for cancer -- including brain tumor, leukemia and lymphoma, and neuroblastoma -- as well as a variety of blood disorders, including sickle cell disease, bleeding/clotting disorders, and anemia. We are committed to providing your family hope and to performing research that may one day help prevent or cure these diseases.\nIf your child is struggling with childhood obesity, the Duke Healthy Lifestyles program can help. Through visits with our specialists in medicine, nutrition, physical therapy, and behavioral health, your family can learn how to live a life of healthy eating and physical activity. Weight loss surgery is available to teens who have been in the Healthy Lifestyles Program for at least six months and meet certain qualifications.\nDuke pediatric dermatologists provide specialized care for your child’s short-term or chronic skin disorder, including psoriasis, eczema, and excessive sweating. We also treat birthmarks, including hemangiomas, moles, and port wine stains. Our children's skin care experts can help you and your child better understand skin ailments and how to treat and cope with them.\nOur pediatric endocrinologists provide family-centered care for children and adolescents with type 1 and type 2 diabetes, adrenal and thyroid disorders, gender disorders, and endocrine tumors. We also provide specialized care for puberty disorders, gender-related conditions, and more. We work in close collaboration with your child's referring physician and caregivers.\nOur pediatric medical geneticists provide care for children with genetic disorders, including Down syndrome, glycogen and lysosomal storage diseases, Fragile X syndrome, metabolic disorders, and neurodegenerative disorders. We offer genetic testing and counseling, clinical evaluation, and treatment services.\nOur pediatric infectious disease specialists provide expert diagnosis and care for children with acute or chronic bacterial, viral, or fungal infections. This includes children with unusual or severe infections, children with primary immunodeficiency, surgical patients, critically ill children, and transplant recipients.\nOur neurologists and neurosurgeons provide expert medical and surgical care for your child’s brain, spine, nerve, or craniofacial disorder. These include epilepsy, brain and spinal cord tumors, cerebral palsy, spina bifida, hydrocephalus, movement disorders and head injuries. We work collaboratively with colleagues in child development and behavioral health, developmental pediatrics, medical genetics, and neuropsychology.\nWe provide comprehensive medical and surgical treatment for children with problems of the ear, nose, throat, and airway. This includes recurrent ear infections, sinus infections, and tonsillitis; hearing problems; voice disorders; deformities such as cleft palate; head-and-neck tumors; and problems associated with cystic fibrosis or weakened immune systems.\nOur pediatric plastic and reconstructive surgeons specialize in procedures that offer your child functional, cosmetic, and reconstructive benefits. We have dedicated treatment programs for cleft lip & palate, craniofacial conditions, facial paralysis, cosmetic/functional nose surgery, ear deformities, congenital hand deformities, hemangiomas and vascular lesions, traumatic injuries, and skin conditions.\nDuke Primary Care has family medicine providers and pediatricians in more than 40 locations throughout the Triangle and a growing list of Duke-friendly health plans. Duke pediatric practices provide care for infants, children, and adolescents. Duke family medicine practices provide care for everyone in the family, from infants through older adults.\nOur lung care specialists provide comprehensive care for your child’s acute or chronic respiratory problems, including asthma, breathing disorders during sleep, chronic lung disease, and cystic fibrosis. We guide your child’s care through routine lung-function measurements, including pre-school-age testing.\nDuke’s pediatric sleep medicine experts provide family-focused care for your child’s sleep disorder, including sleep apnea, insomnia, narcolepsy, night terrors, and restless leg syndrome. We use advanced sleep-monitoring technologies to study your child’s sleep and breathing patterns, find the right diagnosis, and recommend the best treatment options.\nOur pediatric urologists provide care for children with a range of urinary and reproductive system issues, including bed-wetting and bladder control problems, kidney stones, tumors, gender concerns, and birth defects. We understand the impact these problems can have on your child’s health, quality of life, self-esteem, and sexuality. We offer support and guidance for your child and your family throughout the process."", ""Brain and spinal cord tumor treatment at Children's\nChildren diagnosed with a brain tumor (tumors of the brain and spine) often have complex needs in addition to cancer care. Our multi-disciplinary team meets weekly to discuss your child’s care, creating individual treatment plans to manage all of his or her health care needs.\nOur patients benefit from access to advanced capabilities such as new magnetic resonance imaging (MRI) software and techniques for precise surgical planning, navigation, and tumor resection, advanced neurosurgery capabilities with specialized equipment, including stereotactic surgery, onsite diagnostics, oncology pharmacy and anesthesia services and more.\nEpilepsy and seizure treatment at Children's\nAt Children's, our specialists create a custom treatment program to match your child's health and medical history. Depending on your child's condition and severity, we will recommend a variety of therapies. Diagnosis often includes briefly admitting your child to the hospital for video EEG monitoring in our Pediatric Epilepsy Monitoring Unit. This is a painless and a noninvasive procedure that translates your child’s electrical brain activity into a digital format.\nOnce we have a full understanding of your child's unique epileptic condition, we begin working to reduce or eliminate the number of seizures through medication, therapies, lifestyle changes and, if necessary, surgery. Learn more about our treatment of epilepsy and seizures.\nAbout movement disorders treatment at Children's\nAfter we evaluate your child's medical history we conduct a physical examination and test reflexes. Genetic testing, as well as cerebrospinal fluid analysis may be used to confirm a suspected diagnosis. If your child's movement disorder requires orthopedic bracing or bone surgery, we may use physical therapy and rehabilitation. If your child's condition is related to brain activity, our neurosurgeons may perform, among other treatments, a selective dorsal rhizotomy, which destroys parts of the brain delivering faulty messages, to promote independent movement. Learn more about our treatment of movement disorders.\nAbout neuromuscular disorder treatment\nDepending on the specifics of your child's condition and your input as a parent, a variety of treatments may be recommended. Our cutting-edge treatments include plasmapheresis and immunoglobulin therapies, which help in auto-immune disorders like myasthenia gravis. We also offer psychological counseling, and have a wide variety of equipment that will improve your child's mobility and allow him or her to build confidence through independent movement. Learn more about how we treat neuromuscular disorders.\nAbout neuropsychology at Children's\nNeuropsychological testing may be recommended following an accident or surgery, or if your child spontaneously shows signs of emotional or cognitive changes. Depending on the specifics of your child's condition and your wishes, a variety of treatments may be recommended. Our neurosurgery specialists work with team members from the Comprehensive Neurosciences Center to offer specialized surgical care. Children's neuropsychologists and counseling professionals can help your child adjust to life changes that may arise from brain injury or disease. They also are key in monitoring changes in your child's emotional and cognitive well-being that may result from injury or surgery. Learn more about neuropsychology testing.\nAbout neurosurgical treatment at Children's\nOur neurosurgery specialists work with other team members from the Comprehensive Neuroscience Center to offer specialized surgical care. We pair traditional treatments like medication and physical therapy with orthopedic interventions, cranial orthotic treatments, vagal nerve stimulation, intrathecal baclofen or shunt implantation, removal of tumors, minimally invasive endoscopic, stereotactic and microsurgery. Learn more about our neurosurgical treatments.\nAbout neurospinal treatments at Children's\nThere is no cure for a damaged spinal cord, but our neurology and neurosurgery programs work with other specialists across Children's to tailor a treatment plan especially for your child, ensuring the highest quality of life possible. Each plan is custom fit to your child's health and medical history.\nDepending on the kind of neurospinal dysfunction, as well as its source, duration and severity, we will discuss a variety of therapies which may include medication to fight infections or to reduce inflammation, or even surgery to repair damaged spinal bones. Learn more about our neurospinal treatments.\nSpina bifida treatment at Children's\nChildren's is committed to early detection of spina bifida to help prepare you and your family for the challenges that accompany welcoming a child with spina bifida.\nTreatment for spina bifida begins at birth or, sometimes, before. Children with spina bifida, especially those with both brain and spinal cord involvement, require complex medical care and neurosurgery accompanied by careful monitoring. Treatments may include catheterization to help with urine elimination, bowel programs, and even the use of therapeutic electrical stimulation and biofeedback. Surgery is often recommended, especially in moderate to severe cases.\nLearn more about our treatment of spina bifida.""]"	['<urn:uuid:5c1c2e22-2d12-4228-80cb-a924446dd84b>', '<urn:uuid:fc3538fd-def7-45ff-aedd-8264ef3e08d3>']	factoid	with-premise	long-search-query	similar-to-document	three-doc	novice	2025-05-12T15:09:02.012753	10	64	1653
34	what happens if someone accidentally pockets black ball during initial break shot	If the black ball (8 ball) is pocketed from the break shot, the player who took the shot wins the rack, provided that no other ball is pocketed simultaneously. However, if both the black ball and another ball are potted on the break, this results in loss of game.	"['House 8-Ball Pool Rules\n1. The Game\nThe game shall be known as 8 Ball Pool and referred to in these rules as ""the game"". It is intended that the players and teams should play 8 Ball Pool in the true spirit of the game and in a sportsmanlike manner. It should be clearly understood that the referee is the sole judge of what is fair and unfair play. The referee will take whatever action is necessary to ensure that these rules are observed.\n2. Requirements of the Game\nThe game is played on a rectangular 6-pocket table with 15 balls, plus a cue ball. Balls comprise two groups, represented by two different coloured balls plus the 8 ball, which is black. Alternatively, numerical balls may be used numbered 1-7, which are plain coloured balls, and 9-15, which are striped coloured balls. Balls in the two groups are known as object balls.\n3. Object of the Game\nThe player or team pocketing their group of object balls first in any order and then legally pocketing the 8 ball (black) in a nominated pocket wins the game.\n4. Commencement of the Game\na) The balls are racked with the colours alternating around the triangle, with the 8 ball (black) on the 8 ball spot which is set at the intersection of the centre and corner pockets.\nb) Order of play is determined by the flip of a coin. The winner of the flip has the option of breaking or requesting his/her opponent to do so.\nc) The opening player plays at the triangle of object balls by striking the cue ball from any position on or within the \'D\'. He/she must pocket a ball or cause at least two object balls to hit a cushion. Failure to do so is a foul break and will result in the balls being re-racked. The opposing player re-starts the game with one break shot followed by one visit.\nd) On the break, if a player legally pockets an object ball, then that denotes his/her group. If he/she pockets balls from each group, he/she must nominate his/her choice before continuing to play.\ne) If no ball is pocketed from a legal break, then the incoming player can play for any colour. This continues until a colour is potted.\nf) If a foul is committed on the break, any balls pocketed determine each player’s colour.\ng) If the black is pocketed from the break, the player who took the shot has won the rack, as long as no other ball goes down.\nh) If a ball or balls are legally pocketed, this entitles the player to one additional shot and this continues until the player either:\ni) Combination shots are allowed provided the player hits one of his group of balls first (unless rule 6b) applies).\na) In off (cue ball pocketed).\nb) Hitting opponent’s balls before his/her own balls, except when rule 6 b) applies.\nc) Failing to hit any ball with the cue ball.\nd) Jump shots – defined as when the cue ball jumps over any part of any ball before making any contact with any object ball.\ne) If a player hits the 8 ball (black) with the cue ball on the first impact before all his/her own balls have been potted, except when rule 6 b) applies.\nf) Potting any opponent’s balls except when rule 6 b) applies.\ng) Ball off the table - If the cue ball goes off the table, the ball is to be played from any position on or within the \'D\'. A ball shall be deemed to be \'Off the table\' if it comes to rest other than on the bed of the table.\nh) If a player\'s clothing or body should touch any ball.\ni) Player not having at least one foot on the floor.\nj) Touching with the cue any other ball other than the cue ball.\nk) Playing out of turn.\n1) Playing before balls have come to rest.\nm) Striking the cue ball with any part of the cue other than the tip.\nn) Striking the cue ball with the cue more than once.\no) Potting the black without clearly nominating the pocket.\np) Foul break (see 4 c)).\nq) Push stroke (see 8 a)).\nr) Moving an object ball or the 8 ball (black) when playing away from a touching ball.\n6. Penalty following any foul\na) Following any foul described under rule 5, the incoming player may play the cue ball from where it lies or from the \'D\' (as in rule 8 b) and proceed as rule 6 b). Moving the cue ball does not constitute a shot or visit.\nb) Following a foul, the incoming player is entitled to one free shot with which he/she may without nomination play the cue ball directly onto any ball, including opponents object balls and the 8 ball (black). However, he/she may not pocket the 8 ball (black), which would mean loss of the game, unless the player has already pocketed all of his/her group of object balls and only needs to pocket the 8 ball (black) to win the game. The free shot carries forward until a second ball fails to be potted.\nc) Failure to nominate the pocket in which the black is to be potted is a foul.\nd) If a player is on the black and his opponent is not and fouls, the player on the black has two shots on the black.\ne) If both players are on the black, any foul ends the game.\n7. Loss of Game\na) If the player pockets the 8 ball (black) before he/she pockets all balls in his/her own group, he/she loses the game, unless he does it on the break.\nb) A player going in off the 8 ball (black) when the 8 ball (black) is potted loses the game.\nc) If a player seeks to gain advantage by deliberately touching a moving ball or retrieving a ball dropping into the pocket, he/she shall lose the game.\nd) If the black and another ball are potted on the break.\na) Push stroke - Defined as when the tip of the cue remains in contact with the cue ball once it has commenced its forward motion.\nb) Cue ball in hand - When a player has the cue ball in hand he/she plays from any position on or within the \'D\' and in any direction.\nc) Player in control - A player is said to be in control of the table from the time that his/her body, cue or clothing touches the table prior to his/her shot, through his/her visit and up until his/her opponent does likewise prior to his/her visit. Any balls which fall into the pockets during this period (including the black) he/she is said to have potted and he/she is liable to any penalties or benefits normally awarded to him/her for the potting of that ball or balls.\nd) The game is completed when the 8 ball (black) is potted in any pocket and all the remaining balls including the cue ball have come to rest.\ne) Touching ball - A player must play away from a touching ball which must not move (see rule 5 r)). If the touching ball is one of the players own group, he/she is deemed to have played that ball. If the touching ball is not one of his/her own group, the cue ball must strike one of his/her own group. When 6 b) applies, a player must play away from a touching ball and is deemed to have played that ball.\nf) A player may change his nominated pocket repeatedly when he/she is on the black.\nShould any situation arise whereby a legal shot cannot be played, then the game shall be resumed by the same player whether this situation is arrived at by accident or design. If, in the opinion of the referee neither player is allowing the game to progress or a stalemate situation has arisen, the game shall be re-started by the same player.\nCoaching is deemed to be unsportsmanlike behaviour (see rule 1). In pairs pool advice may be given away from the table but not while the opponent is in control of the table.\nA referee may, if requested advise on the rules of the game.']"	['<urn:uuid:4219e1cc-bf6b-4fd4-87af-5f13d53e132d>']	open-ended	direct	long-search-query	distant-from-document	single-doc	novice	2025-05-12T15:09:02.012753	12	49	1391
35	need information role public health nurses vs home care nurses main responsibilities and insurance coverage	Public health nurses focus on promoting and maintaining health of populations and preventing/minimizing disease progress in the entire community. In contrast, home care nurses concentrate on tertiary preventive nursing care, specifically restoring maximum health function through rehabilitation. Regarding insurance coverage, PPO plans offer out-of-network coverage at higher cost, while HMO plans only cover out-of-network care for medical emergencies. EPO plans similarly only cover emergency care outside their network, making them more pocket-friendly than PPOs but less flexible in provider choice.	"['Nursing Board Exam Reviewer Part 1 of 5\n1. According to Maslow, which of the following categories of needs represents the most basic?\na) Physiologic needs\nPhysiologic needs must be met before an individual is able to move toward psychological health and well-being.\nSelf-actualization is the highest level of need\nc) Safety and security needs\nSafety and security needs, while lower level, are not essential to physiologic survival.\nBelongingness and affection needs are not essential to physiologic survival.\n2. Which of the following statements reflects the World Health Organization’s definition of health?\na) A state of complete physical, mental, and social well-being and not merely the absence of disease and infirmity.\nSuch a definition, however, does not allow for any variations in the degrees of wellness or illness.\nb) A condition of homeostatis and adaptation.\nThe WHO definition addresses physical, mental, and social dimensions of being.\nc) An individual’s location along a wellness–illness continuum.\nThe concept of a health–illness continuum allows for a greater range in describing a person’s health than the definition provided by the WHO.\nd) A fluid, ever-changing balance reflected through physical, mental, and social behavior.\nThe WHO definition does not allow for any variations in the degrees of wellness and illness.\n3. Which of the following statements defines culture?\na) The learned patterns of behavior, beliefs, and values that can be attributed to a particular group of people.\nIncluded among characteristics that distinguish cultural groups are manner of dress, values, artifacts, and health beliefs and practices.\nb) A group of people distinguished by genetically transmitted material.\nA group of people distinguished by genetically transmitted material describes the term race.\nc) The status of belonging to a particular region by origin, birth, or naturalization.\nThe status of belonging to a particular region by origin, birth, or naturalization describes the term nationality.\nd) The classification of a group based upon certain distinctive characteristics.\nThe classification of a group based upon certain distinctive characteristics describes the term ethnicity.\n4. The reason that case management has gained such prominence in health care can be traced to\na) decreased cost of care associated with inpatient stay.\nThe reasons case management has gained such prominence can be traced to the decreased cost of care associated with decreased length of hospital stay, coupled with rapid and frequent inter-unit transfers from specialty to standard care units.\nb) increased length of hospital stay.\nIn general, length of hospital stay has decreased over the past 5 years.\nc) discharge from specialty care units to home.\nIn general, patients are transferred from specialty care units to standard care units at least 24 hours prior to discharge.\nd) limited availability for inter-unit hospital transfers.\nIn general, patients in acute care hospitals undergo frequent inter-unit transfers from specialty to standard care units.\n5. A preferred provider organization is described as a\na) business arrangement between hospitals and physicians.\nPPO’s usually contract to provide health care to subscribers, usually businesses, for a negotiated fee that often is discounted.\nb) prepaid group health practice system.\nA prepaid group health practice system is termed a health maintenance organization.\nc) limited insurance program.\nInsurance is a cost payment system of shared risk, not a health care delivery system.\nd) health care savings account program.\nA health care savings account program is an incentive program to consumers, not a health care delivery system.\n6. Which of the following categories identifies the focus of community/public health nursing practice?\na) Promoting and maintaining the health of populations and preventing and minimizing the progress of disease\nAlthough nursing interventions used by public health nurses might involve individuals, families, or small groups, the central focus remains promoting health and preventing disease in the entire community.\nb) Rehabilitation and restorative services\nRehabilitation and restorative services are the focus of extended care facilities and home care nursing.\nc) Adaptation of hospital care to the home environment\nAdaptation of hospital care to the home environment is the focus of home nursing.\nd) Hospice care delivery\nHospice care delivery refers to the delivery of services to the terminally ill.\n7. A major goal for home care nurses is\na) restoring maximum health function.\nTertiary preventive nursing care, focusing on rehabilitation and restoring maximum health function, is a goal for home care nurses.\nb) promoting the health of populations.\nPromoting the health of populations is a focus of community/public health nursing.\nc) minimizing the progress of disease.\nMinimizing the progress of disease is a focus of community/public health nursing.\nd) maintaining the health of populations.\nMaintaining the health of populations is a focus of community/public health nursing.\n8. In the United States, nurses performing invasive procedures need to be up-to-date with their immunizations, particularly\na) hepatitis B.\nHepatitis B is transmitted through contact with infected blood or plasma.\nb) hepatitis E.\nHepatitis E is found mainly in underdeveloped countries with substandard sanitation and water quality.\nc) hepatitis A.\nhepatitis A is transmitted through the oral route from the feces and saliva of an infected person.\nd) hepatitis C.\nAt present, immunization against hepatitis C is not available.\n9. At what time during a patient’s hospital stay does discharge planning begin?\nTo prepare for early discharge and the possible need for follow-up in the home, discharge planning begins with the patient’s admission.\nb) Twenty-four hours prior to discharge\nDischarge planning requires identification of patient needs and anticipatory guidance and is not relegated to a specific time for beginning.\nc) The shift prior to discharge\nDischarge planning requires communication with and cooperation of the patient, family, and health care team and is not relegated to a specific time for beginning.\nd) By the third hospital day\nDischarge planning may require involvement of personnel and agencies in the planning process and is not relegated to a specific day of hospital stay.\n10. The leading health problems of elementary school children include\nThe leading health problems of elementary school children are injuries, infections, malnutrition, dental disease, and cancer.\nb) alcohol and drug abuse.\nAlcohol and drug abuse are leading health problems for high school students.\nc) mental and emotional problems.\nMental and emotional problems are leading health problems for high school students.\nHomicide is a leading health problem for high school children.', ""What are the main differences between HMO, PPO, and EPO plans?\n|PCP Required||Yes||No||Often, not always|\n|Out-of-Network Coverage||For medical emergencies only1||Yes, at a higher cost||For medical emergencies only1|\nWhich plan is right for me?\nWhat is an HMO?\nAn HMO, or Health Maintenance Organization, is a type of health plan that offers a local network of doctors and hospitals for you to choose from. It usually has lower monthly premiums than a PPO or an EPO health plan. An HMO may be right for you if you’re comfortable choosing a primary care provider (PCP) to coordinate your health care and are willing to pay a higher deductible to get a lower monthly health insurance premium.\nWhat is a PPO?\nA PPO, or Preferred Provider Organization, is a type of health plan that offers a larger network so you have more doctors and hospitals to choose from. Your out-of-pocket costs are usually higher with a PPO than with an HMO or EPO plan. If you're willing to pay a higher monthly premium to get more choice and flexibility in choosing your physician and health care options, you may want to choose a PPO health plan.\nWhat is an EPO?\nAn EPO, or Exclusive Provider Organization, is a type of health plan that offers a local network of doctors and hospitals for you to choose from. An EPO is usually more pocket-friendly than a PPO plan. However, if you choose to get care outside of your plan’s network, it usually will not be covered (except in an emergency). If you’re looking for lower monthly premiums and are willing to pay a higher deductible when you need health care, you may want to consider an EPO plan.\nHMO, EPO, and PPO Frequently Asked Questions\nWhat’s the difference between in-network coverage and out-of-network coverage?\nEach time you seek medical care, you can choose your doctor. You have the choice between an in-network and out-of-network doctor. When you visit an in-network doctor, you get in-network coverage and will have lower out-of-pocket costs. That’s because participating health care providers have agreed to charge lower fees, and plans typically cover a larger share of the charges. If you choose to visit a doctor outside of the plan’s network, your out-of-pocket costs will typically be higher or your visit may not be covered.\nWhat if I need to be admitted to the hospital?\nIn an emergency1, your care is covered. Requests for non-emergency hospital stays other than maternity stays must be approved in advance or pre-certified. This allows Cigna to determine if the services are covered by your plan. Pre-certification is not required for maternity stays of 48 hours for vaginal deliveries or 96 hours for caesarean sections. Depending on your plan, you may be eligible for additional coverage.\nWho is responsible for getting pre-certification?\nYour doctor will help you decide which procedures require hospital care and which can be handled on an outpatient basis. If your doctor is in the Cigna network, he or she will arrange for pre-certification. If you use an out-of-network doctor, you are responsible for making the arrangements. Your plan materials will identify which procedures require pre-certification.\nHow do I find out if my doctor is in the Cigna plan’s network before I enroll?\nIt’s quick and easy to search for participating doctors, specialists, pharmacies, hospitals and facilities to match your needs.\n- Visit the Find a Doctor page\n- Choose a directory:\n- If you're a Cigna customer, log in to myCignaSM to quickly see in-network providers\n- If you're not a Cigna customer yet, select the type of plan you're enrolling in\n- Once on the provider directory, enter your search location, select the plan type, and enter the search terms in the search box related to type of provider or facility you're looking for\n- Your search results will show the in-network providers based on your search criteria, along with other details that can help you when enrolling\n1Emergency Services as defined by your specific plan. Some plans may also provide out-of-network coverage for certain Urgent Care Services. See your plan documents for the details of your specific medical plan.\nCigna medical plans are insured and/or administered by Cigna Health and Life Insurance Company or Connecticut General Life Insurance Company. HMO plans are offered by Cigna HealthCare of Arizona, Inc., Cigna HealthCare of California, Inc., Cigna HealthCare of Colorado, Inc., Cigna HealthCare of Connecticut, Inc., Cigna HealthCare of Florida, Inc., Cigna HealthCare of Georgia, Inc., Cigna HealthCare of Illinois, Inc., Cigna HealthCare of Indiana, Inc., Cigna HealthCare of St. Louis, Inc., Cigna HealthCare of North Carolina, Inc., Cigna HealthCare of New Jersey, Inc., Cigna HealthCare of South Carolina, Inc., Cigna HealthCare of Tennessee, Inc., and Cigna HealthCare of Texas, Inc. Plans contain exclusions and limitations and may not be available in all areas. For costs and details of coverage, review your plan materials.""]"	['<urn:uuid:d0ea11a3-3aeb-48f8-87a5-c3b3c555517c>', '<urn:uuid:5998b9bb-9965-49c6-8cd6-9c817cd44527>']	open-ended	with-premise	long-search-query	similar-to-document	multi-aspect	expert	2025-05-12T15:09:02.012753	15	80	1847
36	what environmental benefits hydrogen fuel cell lighting compared diesel generators	Fuel cell-based mobile lights are environmentally beneficial because they are zero-emission and very quiet, unlike diesel generators that produce CO2, NOx, and soot. Each fuel cell unit avoids burning nearly 900 gallons of diesel fuel per year and, if using hydrogen from non-fossil sources, reduces CO2 emissions by about nine metric tons annually.	['“Mobile lighting” refers to small, portable lighting systems that are used primarily by highway construction crews, airport maintenance personnel, and even film crews.\n“The beauty of this project is that it ties together the manufacturers [Multiquip, Altergy Systems, Luxim, Lumenworks, Stray Light] with Sandia and the end users [Caltrans, San Francisco International Airport] in one collaboration, hopefully reducing commercialization barriers that so often hinder the widespread use of new technology,” said Sandia project lead Lennie Klebanoff. The end goal of the project, according to Klebanoff, is to get fuel cell technology into more widespread commercial use, particularly in general construction and aviation maintenance applications.\nTwo separate designs\nSandia has adopted a two-prong (alpha and beta) approach to the project. First, along with a number of the external partners who are contributing time and in-kind resources, Klebanoff’s team is overseeing the production of the “alpha” mobile lighting unit that is expected to debut Oct. 22-26 at the annual meeting of the American Association of State Highway and Transportation Officials (AASHTO). The alpha unit is separate from the more advanced “beta” design that Sandia recently completed for Boeing and came about due to the enthusiasm of several industry partners and their desire to see a system built sooner rather than later.\n“Caltrans wanted us to get the alpha version in front of their highway transportation peers immediately, and our unit will be in operation and actually illuminating the new electric cars being featured at the AASHTO meeting,” said Klebanoff. “It will give all of us good feedback on how interested potential customers are in the technology, and also allow us to get an initial assessment of how the technology performs, particularly the plasma lighting.”\nThe alpha system consists of advanced power-saving Light Emitting PlasmaTM technology (contributed by Luxim, Lumenworks, and Stray Light), two high-pressure hydrogen tanks (purchased by Sandia), a trailer to transport the equipment (provided by Multiquip), and a fuel cell (provided and installed by Altergy Systems). Multiquip and Altergy are assembling the overall unit, while Sandia has consulted on its design and formulated the alpha unit technical plan for the team.\nThe project has also attracted the interest of SFO, a long-time partner with Sandia on various homeland security projects. SFO would like to test the system for use in nighttime runway repair work, as well as in its terminal renovation activities. Unlike the diesel systems that traditionally power mobile lighting units, the fuel cell-powered mobile light can be\nBoeing design will use metal hydride storage\nBoeing funded Sandia primarily to develop the “beta” design, a more sophisticated, technically ambitious unit that utilizes metal hydride storage tanks designed by Ovonic Hydrogen Systems. These tanks store 12 kilograms of hydrogen, and thus offer some 90 hours of operating time (compared to the 30-40 hours offered by the alpha unit). Sandia’s engineers designed the overall beta system and solved the thermal management issues that surround metal hydride storage, including coupling waste fuel cell heat to the hydride bed. Metal hydride storage is also appealing since it removes many of the safety concerns found with having high pressure on the Alpha unit (whose tanks hold hydrogen at 5000 psi, compared to 250 psi with the metal hydride tank system). These are all important considerations for commercialization, Klebanoff said.\nOther funding sources, he said, are being sought so that the beta system can be built and both versions of the system can then be tested and compared on equal terms. The team would also like to use the field-test data to perform quantitative analyses of the emissions reductions and increased energy efficiency afforded by the technology. Ultimately, Klebanoff said, it will be the manufacturers who decide which system is most attractive for commercial purposes.\nTraditionally, mobile lighting units are powered by diesel fuel generators that produce CO2, NOx (nitrogen oxides produced during combustion), and soot, making them less than ideal for the environment. In addition, diesel units are noisy, which creates a safety hazard when construction personnel are distracted and can’t hear oncoming traffic. A fuel cell running on pure hydrogen, on the other hand, is both very quiet and a zero-emission electric power source.\nKlebanoff estimates that each deployed fuel cell-based mobile light would avoid the burning of nearly 900 gallons of diesel fuel per year and eliminate the emission of NOx and soot. If the hydrogen used is generated from non-fossil fuel sources, then each mobile light unit would also reduce CO2 emissions by about nine metric tons per year.\nSandia is a multiprogram laboratory operated by Sandia Corporation, a Lockheed Martin company, for the U.S. Department of Energy’s National Nuclear Security Administration. With main facilities in Albuquerque, N.M., and Livermore, Calif., Sandia has major R&D responsibilities in national security, energy and environmental technologies, and economic competitiveness.\nMike Janes | Newswise Science News\nProducing electricity during flight\n20.09.2017 | Albert-Ludwigs-Universität Freiburg im Breisgau\nSolar-to-fuel system recycles CO2 to make ethanol and ethylene\n19.09.2017 | DOE/Lawrence Berkeley National Laboratory\nPlants and algae use the enzyme Rubisco to fix carbon dioxide, removing it from the atmosphere and converting it into biomass. Algae have figured out a way to increase the efficiency of carbon fixation. They gather most of their Rubisco into a ball-shaped microcompartment called the pyrenoid, which they flood with a high local concentration of carbon dioxide. A team of scientists at Princeton University, the Carnegie Institution for Science, Stanford University and the Max Plank Institute of Biochemistry have unravelled the mysteries of how the pyrenoid is assembled. These insights can help to engineer crops that remove more carbon dioxide from the atmosphere while producing more food.\nA warming planet\nOur brains house extremely complex neuronal circuits, whose detailed structures are still largely unknown. This is especially true for the so-called cerebral cortex of mammals, where among other things vision, thoughts or spatial orientation are being computed. Here the rules by which nerve cells are connected to each other are only partly understood. A team of scientists around Moritz Helmstaedter at the Frankfiurt Max Planck Institute for Brain Research and Helene Schmidt (Humboldt University in Berlin) have now discovered a surprisingly precise nerve cell connectivity pattern in the part of the cerebral cortex that is responsible for orienting the individual animal or human in space.\nThe researchers report online in Nature (Schmidt et al., 2017. Axonal synapse sorting in medial entorhinal cortex, DOI: 10.1038/nature24005) that synapses in...\nWhispering gallery mode (WGM) resonators are used to make tiny micro-lasers, sensors, switches, routers and other devices. These tiny structures rely on a...\nUsing ultrafast flashes of laser and x-ray radiation, scientists at the Max Planck Institute of Quantum Optics (Garching, Germany) took snapshots of the briefest electron motion inside a solid material to date. The electron motion lasted only 750 billionths of the billionth of a second before it fainted, setting a new record of human capability to capture ultrafast processes inside solids!\nWhen x-rays shine onto solid materials or large molecules, an electron is pushed away from its original place near the nucleus of the atom, leaving a hole...\nFor the first time, physicists have successfully imaged spiral magnetic ordering in a multiferroic material. These materials are considered highly promising candidates for future data storage media. The researchers were able to prove their findings using unique quantum sensors that were developed at Basel University and that can analyze electromagnetic fields on the nanometer scale. The results – obtained by scientists from the University of Basel’s Department of Physics, the Swiss Nanoscience Institute, the University of Montpellier and several laboratories from University Paris-Saclay – were recently published in the journal Nature.\nMultiferroics are materials that simultaneously react to electric and magnetic fields. These two properties are rarely found together, and their combined...\n19.09.2017 | Event News\n12.09.2017 | Event News\n06.09.2017 | Event News\n22.09.2017 | Life Sciences\n22.09.2017 | Medical Engineering\n22.09.2017 | Physics and Astronomy']	['<urn:uuid:1ed15c0a-38ed-4af3-880a-85b3fb3ed6c4>']	factoid	direct	long-search-query	distant-from-document	single-doc	novice	2025-05-12T15:09:02.012753	10	53	1312
37	As a construction site leader, what daily tasks would a project engineer handle?	A project engineer spends most time at construction sites overseeing building progress, coordinating with third-party contractors, organizing staff duties, and ensuring code compliance. They manage material acquisition, resource allocation, process permits, conduct reviews, supervise staff training, and serve as the technical point of contact for clients. They may need to manage multiple projects simultaneously and often work overtime, especially near deadlines.	['Project engineers serve as the mechanism to keep projects, such as construction jobs, moving efficiently and on time. They determine the costs associated with a task, organize the staff and their duties, and ensure that the undertaking is not only what the client envisioned, but is also up to code. The position requires excellent leadership, communication, and time management skills.\nWhat Is a Project Engineer?\nWorldwide human resources consulting firm Randstad says that a project engineer’s main job is “bringing in a profitable, successful project on time and to the satisfaction of the end user.” It is a great career for engineers who excel at problem-solving, implementing solutions, time management, and supervising others. One needs to be focused and have effective organizational, leadership, and communication skills to succeed in the role.\nAs construction projects are typically large operations, a project engineer must be able to organize a construction team that will successfully and safely transform blueprints into completed structures. They need to interpret what the client desires and put it into terms that the construction staff can use, and ensure that there is effective communication between all crews involved. The project engineer oversees the entire project from inception to completion to ensure it is built to serve its intended purpose.\nA project engineer also coordinates acquisition of materials and equipment, ensuring that resource allocation is adequate to complete the job. They prioritize the tasks within a project and must forecast risks. If an issue arises during construction, the project engineer needs to investigate it and implement necessary solutions or changes.\nMoreover, while they supervise building progress, the project engineer coordinates plans and timelines with third-party contractors. They also guarantee that the job is completed within budget and meets building codes and regulations, as well as satisfies the client’s standards.\nAdditionally, project engineers might have to oversee bid analysis, process permits and conduct constructability reviews. Project engineers also supervise and train staff as needed and may have to organize team meetings. There is also the chance that they’ll have to manage multiple construction projects simultaneously. They communicate with other management parties to determine potential future projects and timing.\nWhile project engineers occasionally work in an office environment during normal business hours, they typically spend most of their time at construction sites. Occasional travel to consult with clients and contractors may be required. Because of this, overtime is not uncommon, especially when commuting and as deadlines approach. Project engineers frequently act as the point of contact for clients regarding technical aspects of the job.\nHow to Become a Project Engineer\nWhile not all construction project engineers have an engineering background, the career usually requires a bachelor’s degree in engineering, preferably with a concentration in construction. Extra science and math coursework is typically needed, too.\nHowever, a master’s degree in engineering management or business administration can open doors to many more opportunities. For some project engineer positions, even for those outside of construction, a post-baccalaureate degree may be preferred by employers. Previous related experience, especially in a leadership position, might also be a requisite.\nProject Engineer Salary\nA project engineer’s salary depends on the amount of experience they have, in addition to their educational background. PayScale details that the median annual salary for a project engineer in construction is $60,049. Those entering the construction business as a project engineer with less than five years of experience can expect to earn an average of $58,000 per year. Project engineers with more than 20 years of expertise earn an average salary of $81,000, according to PayScale.\nThe Bureau of Labor Statistics states that employment will grow by 11 percent for those in construction management through 2026, which is faster than the national average for all occupations. This is attributable to how both residential and business areas will expand through the next decade and how infrastructure will require improvements.\nJefferson Online’s master’s degree in construction management provides all of the skills and knowledge required to lead a construction team as a project engineer. The online program teaches students how to employ Leadership in Energy and Environmental Design (LEED) standards, produce sustainable projects and deliver a global view to projects. Faculty members of the project-based degree program have real-world experience.']	['<urn:uuid:8ea84456-75ef-488b-b487-5801eaf81f1a>']	open-ended	with-premise	concise-and-natural	distant-from-document	single-doc	expert	2025-05-12T15:09:02.012753	13	61	703
38	Which show needs more instruments in its orchestra?	Babes in Arms requires more instruments, with its orchestration calling for 17 players across 14 books, including multiple reeds, trumpets, strings, and rhythm section. Joseph has a smaller orchestration package of 11 books/11 players, featuring a more contemporary arrangement with keyboards, guitar, and rhythm section.	"['Cast Size: Small (1-10) • Medium (5-21). Vocal Demands: Easy • Moderate. Dance Requirements: Some Dancing Required • Minimal. Good For: Elementary School • High School • College/University • Amateur/Community • Professional Theatre • Religious Organization.\nTo request the rights to make merchandise for this show email firstname.lastname@example.org.\n— Jonas Schwartz — Jonas Schwartz, Theatermania, January 01, 2003\nWhich came first: groups of kids getting together to put on a show, or BABES IN ARMS, the 1937 Rodgers & Hart musical about a group of kids getting together to put on a show? It’s a fair bet that, for generations, enthusiastic stage struck kids gathered together searching for an outlet to perform. But it was in 1937, with their classic script and glorious score, that Rodgers & Hart coined the now-famous phrase, ""Hey, kids, let’s put on a show!""\nIts score is, without a doubt, musical comedy\'s finest: Where Or When, Johnny One Note, I Wish I Were In Love Again, The Lady Is A Tramp, Babes In Arms, My Funny Valentine... however the script, as penned by Rodgers & Hart, fell into obscurity.\nIt was a script revised by George Oppenheimer in 1959 under the supervision of Richard Rodgers which became the version licensed by R&H from then on. That same version, first mounted at the Royal Poinciana Playhouse in Palm Beach starring Julie Wilson, has been presented across the country and through the decades with success at such prestigious venues as the Goodspeed Opera House (featuring Andrea McArdle) in 1979 as well as countless high schools, community and summer stock theatres.\nVocal Range of Characters:\nMAKE YOUR OWN PLAYBILL! Playbill VIP allows you to create your very own Playbill Program. We have provided Playbill with all of the credits, song listings, musical numbers and more so that most of the work is already done for you. Just add your productions details, photos of the cast and share it with all of your friends. Learn more: www.playbillvip.com\n- BABES IN ARMS (OPPENHEIMER) - Orchestration - (14 Books/17 Players)\n- 1 – Piano-Vocal\n- 1 – Piano\n- 1 – Reed I (Alto Sax, Clarinet (Optional Flute, Optional Piccolo))\n- 1 – Reed II (Tenor Sax and Clarinet)\n- 1 – Reed III (Alto Sax, Clarinet)\n- 1 – Reed IV (Tenor Sax and Bass Clarinet)\n- 1 – Trumpet I-II\n- 1 – Trumpet III\n- 1 – Trombone\n- 1 – Percussion - (see ""Materials Notes"", under ""Production Information"")\n- 1 – Violin A-B (Divisi)\n- 1 – Viola (Divisi)\n- 1 – Cello (Divisi)\n- 1 – Bass\n- BABES IN ARMS (OPPENHEIMER) - Rehearsal Set - (22 Books)\n- 20 – Libretto-Vocal\n- 1 – Logo CD\n- 2 – Piano-Vocal\n- Digital Logo\n- BABES IN ARMS (OPPENHEIMER) - Libretto-Vocal 10-Pack - (10 Books)\n- 10 – Libretto-Vocal\n- BABES IN ARMS (OPPENHEIMER) - Pre-Production Pack - (2 Books)\n- 1 – Libretto-Vocal\n- 1 – Piano-Vocal\n3 Young Women\n6 Young Men\n2 Adult Men\n4 Young Men\nSinging-dancing ensemble consisting of the Gang.\n(in order of appearance)\nThe Press Agent\nBABES IN ARMS takes place at The Surf and Sand Playhouse during the summer of 1959.\nExterior of The Surf and Sand Playhouse\nSection of the Playhouse Stage\nThe Old Barn\nBedroom at the Inn\nBehind the Playhouse Curtain\nA Country Road', 'Cast Size: Small (1-10) • Medium (5-21) • Large (14+). Vocal Demands: Easy • Moderate. Dance Requirements: Some Dancing Required • Minimal. Good For: High School • College/University • Amateur/Community • Professional Theatre • Religious Organization.\nJoseph Ladies Antique Heliconia Tee\nJoseph Ladies Heather Orange Tee\nJoseph Unisex Black Logo Tee\nJoseph Unisex Charcoal Logo Tee\nJoseph Unisex Heather Royal Tee\nJoseph Unisex Charcoal Logo Tee- Customizable\nJoseph Unisex Black Logo Tee- Customizable\nJoseph Ladies Heather Orange Tee- Customizable\nJoseph Ladies Antique Heliconia Tee- Customizable\nJoseph Unisex Heather Royal Tee- Customizable\nMerchandise for JOSEPH AND THE AMZAZING TECHNICOLOR DREAM COAT is now available including official T-shirts, Hats, CD\'s, Songbook\'s, Tote bags and more!\nReturns accepted on standard orders.\nCustomized orders are available.\nTo request the rights to make merchandise for this show email [email protected].\nAndrew Lloyd Webber on www.reallyuseful.com:\nIn the summer of 1967, Andrew Lloyd Webber was asked by Alan Doggett, head of the Music Department at Colet court, St Paul\'s Junior School who taught his younger brother, Julian, to write a \'pop cantata\' for the school choir to sing at their Easter end of term concert.\nAndrew immediately approached his friend Tim Rice to ask if he would write lyrics for the project. After toying with ideas about spies, 007\'s and the like, Tim suggested the story of Joseph.\nThe first performance of JOSEPH AND THE AMAZING TECHNICOLOR DREAMCOAT was on a cold winter afternoon on 1st March 1968 at the Old Assembly Hall, Colet Court, Hammersmith.\nAccompanied by the School orchestra and conducted by Alan Doggett, the performance was only 20 minutes long.\nIt was such a success that a second performance was arranged on 12th May 1968 at Central Hall, Westminster, where Andrew\'s father was the organist. Julian Lloyd Webber gave a classical recital in the first half, along with Bill Lloyd Webber. The audience of approximately 2,500 consisted mainly of parents of the Colet Court boys. To Andrew and Tim\'s surprise, Derek Jewell, Jazz and Pop Critic for The Sunday Times, saw the show and wrote a favourable review of JOSEPH, which appeared on 19th May 1968. A third performance took place on 9th November 1968 at St Paul, where JOSEPH was expanded to include songs such as \'Potiphar\' for the first time.\nAfter seeing Derek Jewell\'s review, Tim Rice\'s then employer Norrie Paramor, who produced Cliff Richard among others, encouraged Decca to release an album of the St Paul\'s Cathedral version of JOSEPH in January 1969. This received several good reviews, but was unsuccessful commercially. At the same time as the album\'s release, Novello & Co. published the original twenty minutes version of the music and lyrics. As a consequence of the obvious need for financial backing to enable them to continue writing, Andrew Lloyd Webber was introduced to Sefton Myers, an entrepreneur keen to develop new talent in showbusiness and whose main activity was property. His partner, David Land, heard the album and immediately offered Tim and Andrew a management contract which would guarantee them support for 3 years in return for a share of their income. This contract allowed Tim and Andrew to continue their work and made it feasible for Tim to leave his employment with Norrie Paramor.\nThe first project under their new contract was a second piece for schools, entitled COME BACK RICHARD, YOUR COUNTRY NEEDS YOU, based on the story of Richard I and his minstrel, Blondel. It was performed with Alan Doggett once again as musical director at the City of London School in November 1969, but Andrew and Tim did not take the project further as they had already discussed another idea, the story of Jesus Christ. Tim Rice remained convinced of his second idea for schools and subsequently developed it into the musical BLONDEL.\nAndrew Lloyd Webber and Tim Rice then went on to write JESUS CHRIST SUPERSTAR. It was the success of JESUS CHRIST SUPERSTAR that enabled JOSEPH to continue to grow. The album of JESUS CHRIST SUPERSTAR was a massive success in America and when JOSEPH was released there, with a marketing campaign implying it was the follow-up to SUPERSTAR, the JOSEPH album stayed in the charts for three months.\nSadly, before the success of JESUS CHRIST SUPERSTAR had really emerged, Sefton Myers died of cancer. David Land subsequently involved Robert Stigwood in the management contract with Andrew and Tim, which was extended to cover a 10 year period, and a very happy association with David Land on behalf of the Robert Stigwood Organisation followed.\nIn September 1972 Frank Dunlop for the Young Vic directed the Decca album version of JOSEPH starring Gary Bond, at the Edinburgh Festival, where it was preceded by an act of medieval mystery plays that led to the story of the \'Coat of Many Colours\'. In October the Edinburgh production played at the Young Vic for two weeks before transferring to the Roundhouse for a six week run. Michael White and Robert Stigwood subsequently presented the Edinburgh JOSEPH at the Albery Theatre, where it opened on 17th February 1973 and was accompanied by a piece called Jacob\'s Journey, written by Tim and Andrew with dialogue by Alan Simpson and Ray Galton. This told the story of the early life of Joseph\'s father, Jacob.\nUnfortunately, it was decided that the combination of Jacob\'s Journey, which contained a lot of spoken dialogue, and JOSEPH, entirely sung, did not work and Jacob\'s Journey was gradually phased out. JOSEPH emerged to receive its first major production in its present form at the Haymarket Theatre, Leicester.\nThe history of JOSEPH in America is not dissimilar. The first amateur production in America was in May 1970 at the College of the Immaculate Conception in Douglastown, New York. There followed huge interest form colleges and schools but, despite various professional productions including two in New York, it was so successful that on 27th January 1982 it moved to the Royale Theatre on Broadway.\nTwenty three years on, it is intriguing to note that in the year of the first performance (and three months before Jason Donovan was born), the copyright on JOSEPH was sold by Andrew and Tim to Novello & Co. for 50 guineas each. Novello & Co. was subsequently purchased by Filmtrax, who continue to own the copyrights until 21st April 1989, when the Really Useful Group purchased it for £1 million.\nAlthough JOSEPH has been performed by both professional and amateur companies all over the world and by thousands of schools, this is the first professional production to incorporate the children\'s choir as an integral part of the production.\nFrom the Palladium production programme.\nLaurence Olivier Awards (London)January 01, 1982 — 2 Awards for Best Set Design and Best Costume Design\nJanuary 01, 1992 — 2 Awards for Best Set Design and Best Costume Design\nVocal Range of Characters:\nKeyboardEase:This unique resource is designed specifically to meet the needs of productions that want convenient, cost-effective access to these hard to find keyboard sounds. We have carefully assembled all sounds required for a given show. Everything is laid out in correct sequential order, so you can easily progress through each song in each keyboard book with professional, authentic, show-specific sounds. All you have to do is connect any standard keyboard (or multiple keyboards) to your laptop and you\'ll be ready to perform. And we\'ll help you every step of the way.\nAccompanEase: This product is a rehearsal tool that allows for unlimited teaching, training and practice of individual vocal parts or dance sequences. Contact Realtime Music Solutions for more information: www.accompanease.com, via email: [email protected], or via phone: 212-620-0774\nInstrumentalEase: This product is an orchestra enhancement instrument capable of augmenting a traditional ensemble of any size. Contact Realtime Music Solutions for more information: www.rms.biz, via email: [email protected], or via phone: 212-620-0774.\nMAKE YOUR OWN PLAYBILL! Playbill VIP allows you to create your very own Playbill Program. We have provided Playbill with all of the credits, song listings, musical numbers and more so that most of the work is already done for you. Just add your productions details, photos of the cast and share it with all of your friends. Learn more: www.playbillvip.com\n- JOSEPH - Orchestration Package (11 Books/11 Players)\n- 1 – PIANO VOCAL SCORE (CONDUCTOR)\n- 1 – REED I (Flute, Piccolo, Bass Clarinet)\n- 1 – REED II (Clarinet, Soprano Sax, Bass Clarinet)\n- 1 – HORN\n- 1 – TRUMPET\n- 1 – GUITAR\n- 1 – BASS GUITAR\n- 1 – DRUMS\n- 1 – PERCUSSION (see ""Materials Notes"", under ""Production Information"")\n- 1 – KEYBOARD I (Piano, Electric Piano, Strings)\n- 1 – KEYBOARD II (see list below)\n- Rehearsal Set (22 Books)\n- 20 – Vocal Book\n- 1 – Logo CD\n- 2 – PIANO VOCAL SCORE (CONDUCTOR)\n- 1 – Logo sheet\n- Digital Logo\n- Libretto/Vocal 10 Pack\n- 10 – Vocal Book\n- JOSEPH - PRE-PRODUCTION PACKAGE\n- 1 – PIANO VOCAL SCORE (CONDUCTOR)\n- 1 – Vocal Book\n- Joseph and the Amazing Technicolor Dreamcoat Flat Bundle\n- 1 – Flat Banners\n- 1 – Flat Poster\n- 1 – Flat Print\n- 1 – Flat Facebook Tabs\n- Flat Baners\n- Flat Facebook Tabs\n- Flat Poster\n- Flat Print\n- Joseph and the Amazing Technicolor Dreamcoat Layered Bundle\n- 1 – Layered Banners\n- 1 – Layered Facebook Tabs\n- 1 – Layered Poster\n- 1 – Layered Print\n- Layered Banners\n- Layered Facebook Tabs\n- Layered Poster\n- Layered Print\n1 Narrator (May be Male or Female)\nChorus of Men (doubled by Brothers) and Women\nOptional Children\'s Chorus\nJOSEPH AND THE AMAZING TECHNICOLOR DREAMCOAT takes place \'way, way back many centuries ago, not long after the Bible began\' in the land of Canaan and Egypt.\nA jail cell\nDisplay customized, eye-catching banner ads to promote your production.\nDon\'t worry about reshaping banners to fit different websites: This package already includes 4 standard banner sizes - vertical, horizontal, and rectangular.\nDon’t worry about optimizing the color format, size and resolution. These files are already optimized for online viewing.\nDon\'t worry about needing a designer to convert static banners into rotating, animated ads. We’ve taken care of this for you! Text and video instructions are provided to help you animate your ads with ease – using free programs and apps.\nDon\'t worry about needing fancy design programs – these flat .JPG files are ready to use with any free paint or photo editing program. Demos show you how to customize graphics with your theater\'s text.\n- 160x600 - Wide Skyscraper\n- 300x250 - Medium Rectangle\n- 468x60 - Full Banner\n- 728x90 – Leaderboard']"	['<urn:uuid:0283d893-3969-4900-9041-4c478263c616>', '<urn:uuid:50c2c081-6fc5-4c42-891e-afb1f8d67106>']	open-ended	with-premise	concise-and-natural	distant-from-document	comparison	novice	2025-05-12T15:09:02.012753	8	45	2336
39	compare nevada poland national heritage sites	Nevada features diverse natural heritage sites including Valley of Fire State Park with 150-million-year-old red sandstone formations, the Great Basin National Park with ancient bristlecone pines, and Lehman Caves with over 300 rare shield formations. Poland, in contrast, focuses more on cultural heritage sites including the world's largest brick castle at Malbork, medieval architecture in cities like Torun (featuring Gothic paintings and Baroque churches), and historically significant sites like the restored Old Town in Warsaw.	"['Life has actually not been simple for Poland, an eastern European nation that has actually been attacked and also ruined often times over the centuries. The nation endured strongly in The second world war when much of its residents, including its big Jewish populace, were rushed off to Nazi prisoner-of-war camp.\nThe Polish spirit, nonetheless, declined to pass away and also today the nation integrates middle ages style with dynamic social tasks to satisfy the requirements of modern-day travelers. A review of the finest locations to go to in Poland:\nThe middle ages community of Malbork, possibly much better recognized by the German name of Marienburg, is most widely known for its castle, which was gotten constructed in the 13th century by the Knights of the Teutonic Order as their head office, Europe’s biggest Gothic citadel is called after the Virgin Mary, the tutelary saint of the city and also castle.\nThe castle is really 3 castles, making it the globe’s biggest block castle. It took 230 years to construct the castle, a bulk of which was ruined throughout The second world war. Much of the castle has actually been brought back ever since.\nLublin, situated east of the Vistula, is an additional old city with a market location that might have gone back to the 6th century. Since it lies on Poland’s eastern boundary, it ended up being, early, a line of protection versus different intruders that ruined the city over the centuries.\nIt likewise was house to among the biggest Jewish neighborhoods in Poland. Proof of Lublin attaching Western and also Eastern societies can be discovered at the Holy Trinity Church that mixes Catholic and also Russian-Byzantine designs. Yet don’t be deceived by the rock roads and also middle ages style of the Old Community, as it flaunts a vibrant arts and also club scene.\nThe Bialowieza Woodland is a huge residue of the primitive woodlands that when covered much of Europe. The woodland straddles the boundary in between Poland and also the Republic of Belarus, and also there are boundary crossings for travelers walking or on bikes.\nThe Bialowieza Woodland is the only location where European Bison still stay cost-free and also living in the woodland as they when did throughout Europe. Wolves, Lynx, Red Deer, Swine, Elk and also Roe Deer are amongst its various other residents. While the bison are maintained within fenced locations, assisted excursions are readily available either walking or in horse-drawn carriages.\nTorun, situated on the Vistula River, is best recognized, possibly, as the birth place of Copernicus, yet it’s equally as popular for its old market location and also Gothic city center that the National Geographic Polska placed on its listing of the 30 most gorgeous locations worldwide.\nAs Torun left battle throughout The second world war, the city still flaunts various structures that go back to the Center Ages. Building on the city center began in the 13th century, with several churches, consisting of the Basilica of SS. John the Evangelist and also John the Baptist, going back to the 14th century. This church is a must-see for tourists thinking about Gothic paints and also sculptures, and also Baroque churches.\nTravelers that yearn for breathtaking appeal will certainly discover it in Tatra National forest, situated in southcentral Poland. Developed in 1954, the park is mostly woodlands, fields and also various rock developments covering the Tatra Mountains.\nSpelunkers might take pleasure in exploring 6 of the park’s 650 caverns that are open to the general public. The park likewise provides greater than 30 towering lakes in addition to the Wielka Siklawa falls that is 70 meters (230 feet) high.\nTatra, one of the most seen national forest in Poland, will certainly thrill walkers with its 270 kilometres (170 miles) of routes. There is a comparable national forest in the bordering component of Slovakia, likewise called the Tatra National forest.\nPupil tourists intending to satisfy their Polish peers may intend to go to Poznan, long called a scholastic facility and also house to Poland’s 3rd biggest college. The city hosts several global occasions, consisting of the Malta International Theater Event that occurs every summer season.\nSignificant websites are conveniently obtainable by walking the Royal-Imperial Course, a stroll established particularly for travelers. Professional athletes might take pleasure in a browse through to the fabricated lake of Malta, house to a ski incline, ice rink, and also pool.\nSituated on the Oder River, Wroclaw is the biggest city in western Poland. Over the centuries it has actually been controlled by Prussia, Poland, Germany and also Bohemia, yet has actually belonged to Poland given that 1945.\nThe previous resources of Silesia is still much less widely known as several of the various other locations to go to in Poland yet can absolutely contend when it concerns impressive style.\nPiece de resistance consist of the marketplace square and also the excellent Old Community Hall, St, Elizabeth’s Church with its monitoring deck neglecting the city, and also the biggest zoo in Poland. Cruising on the Oder River is a peaceful means to obtain a feeling for this middle ages city.\nAdditionally called Danzig, Gdansk is the biggest city in north Poland and also its primary port given that it rests on the Baltic Sea. Established around the 10th century, it has a combined political background; at various times it came from Germany and also Poland, and also was a complimentary state prior to completely coming to be a component of Poland after\nThe city rebuilt itself after the battle, recovering its Old Community, which is renowned for the Royal Roadway that Gloss kings took a trip on when seeing this historic city. The city likewise is house to St. Mary church, the biggest block church worldwide.\nThe resources of Poland may appropriately be contrasted to a Phoenix metro increasing from the ashes. Established around the 12th century, Warsaw was virtually ruined throughout The second world war, yet has actually reconstructed itself right into a flourishing historic and also social facility, full with a recovered Old Community.\nWhen called the “Paris of the North,” it likewise is renowned as the house of classic author Fryderyk Chopin. One more renowned resident was Renaissance astronomer Copernicus, that was birthed in Poland. Tourists of any ages will certainly take pleasure in a browse through to the Copernicus Scientific research Facility where hands-on tasks are plentiful.\nKrakow could be called a cloths to treasures city, given that it went from being a 7th century town to the 2nd essential city in Poland, being recognized for its social, imaginative, scholastic and also financial tasks.\nThroughout The Second World War, the Nazis rounded up Jews right into the Krakow Ghetto where they were later on sent out to prisoner-of-war camp; the motion picture Schindler’s Checklist focused around one guy’s initiatives to conserve the ghetto locals from elimination. Situated on the Vistula River, this previous Polish resources is simple to navigate, given that Krakow’s destinations emit out from Old Community, took into consideration the very best Old Community in the nation.\nMap of Poland\nFrequently Asked Questions\nCountry/group of nations\nIt is really the 9th biggest nation in Europe, and also with dimension comes range. When you go to Poland, you are not simply obtaining community squares and also special style. You likewise obtain coastlines and also woodlands, salt mines, wild animals and also the spectacular Tatra Mountains, plus a lot of gorgeous cities to explore.15-Jun-2019\nPoland is recognized for being the house of scrumptious pierogi, previous pope John Paul II, and also Europe’s many old old-growth woodland. It is likewise a nation abundant in special background and also sensational location, from the Tatra hills to the Baltic Sea. Continue reading listed below for several of one of the most important points to learn about Poland!Poland is recognized for being the house of scrumptious pierogi, previous pope John Paul IIpope John Paul IIJohn Paul II has actually long been attributed with contributing in lowering communism in Catholic Eastern Europe by being the spiritual ideas behind its failure and also a driver for tranquil transformation in Poland.https://en.wikipedia.org › wikiHoly See–Soviet Union relationships – Wikipedia, and also Europe’s many old old-growth woodland. It is likewise a nation abundant in special background and also sensational location, from the Tatra hills to the Baltic Sea. Continue reading listed below for several of one of the most important points to learn about Poland!17-Feb-2022\n– Poland’s 10 biggest cities are Warsaw, Kraków, Łódź, Wrocław, Poznań, Gdańsk, Szczecin, Bydgoszcz, Lublin and also Białystok.\n– Warsaw is Poland’s resources city and also it lies in the centre-east of the nation.\n– Krakow[SEE MAP] A climatic location to go to, Krakow’s beautiful Old Community is thrilling – fascinating churches and also old structures line its stunning squares.\n– Warsaw[SEE MAP] What is this?\n– Gdansk[SEE MAP]\n– Wroclaw[SEE MAP]\n– Poznan[SEE MAP]\n– Torun[SEE MAP]\n– Lublin[SEE MAP]\n– Katowice[SEE MAP]\nPoland is an Eastern European nation that has actually been attacked and also ruined often times over the centuries. Poland has actually experienced The second world war where its big Jewish populace was rushed off to Nazi prisoner-of-war camp. The Polish spirit declined to pass away and also today Poland integrates middle ages style with dynamic social tasks to satisfy the requirements of modern-day', ""In Nevada, we’re lucky to have natural beauty completely surround us. Stunning lakes, majestic mountains, beautiful parks and towering forests are just a few examples of beautiful scenery that’s scattered throughout the Silver State.\nThere are many incredible places in Nevada to explore, and listed below are 12 natural wonders that are definitely worth checking out.\n1. Humboldt-Toiyabe National Forest\nThe Humboldt-Toiyabe National Forest is the principal U.S. National Forest in Nevada. With an area of 6,289,821 acres, it's the largest National Forest of the U.S. - outside of Alaska. This gorgeous forest lies within 13 counties in Nevada and six counties in California.\n2. Pyramid Lake\nPyramid Lake, located 40 miles northeast of Reno, is one of the most unique lakes in the United States. The rock formations are incredible! Pyramid Lake is fed by the Truckee River, and it's the largest remnant of ancient Lake Lahontan. This particular area (Lake Lahontan) of the lake was once home to the 19th-century Paiute.\n3. Mount Charleston\nMount Charleston, located nearly 35 miles northeast of Las Vegas, is the highest mountain in both the Spring Mountains and Clark County, Nevada. It's the eighth highest mountain in the state. Mount Charleston is snow-capped more than half the year, which makes for a modest ski area. There are also several hiking trails on this popular mountain, which keeps hikers coming back again and again. Mount Charleston really is an incredible mountain and it offers many spectacular views.\n4. Valley of Fire State Park\nValley of Fire State Park, located in the Mojave Desert approximately 50 miles from the Las Vegas Strip, is Nevada's oldest state park. It covers an area of nearly 42,000 acres and was dedicated in 1935. This park's name is derived from red sandstone formations that were formed from shifting sand dunes during the age of dinosaurs more than 150 million years ago. These sandstone formations are the centerpiece of the park's attractions and usually appear to be on fire when reflecting the sun's rays. Locals and visitors love picnicking, camping and hiking at Valley of Fire State Park.\n5. Fly Geyser\nFly Geyser, also known as Fly Ranch Geyser, is a man-made geothermal geyser located in Washoe County, Nevada. It's located approximately 20 miles north of Gerlach, on the private Fly Ranch in Hualapai Flat. Fly Geyser actually sits on private property, but it's large enough to be seen from the road. An interesting fact regarding Fly Geyser is that it was accidentally created by well drilling in 1964.\n6. Jarbidge Wilderness\nThe Jarbidge Wilderness, established in 1964 and located in the Jarbidge Mountains of northern Elko County, Nevada, is made up of more than 113,000 acres. There are also nearly 10 mountain peaks that are greater than 10,000 feet located within the area. Surprisingly, this wilderness area receives an average of 7-8 inches of snow each year. If you visit the Jarbidge Wilderness, be sure to keep your eyes wide open for wildlife. Elk, deer and mountain lions are known to prowl this area. Outdoor enthusiasts are huge fans of the Jarbidge Wilderness, especially hunters.\n7. Lake Tahoe\nLake Tahoe, located in both Nevada and California, isn't only one of the most beautiful lakes in the United States, it's also the country's largest alpine lake. Lake Tahoe was formed nearly 2 million years ago and is well known for the clarity of its water. If you've never been to Lake Tahoe, it's a destination that's definitely worth checking out.\n8. Great Basin National Park\nGreat Basin National Park, established in 1986, is located in White Pine County, Nevada. This beautiful park is best known for its groves of ancient bristlecone pines and the Lehman Caves. It's also home to more than 800 species of plants and 61 species of mammals. If you're an outdoor enthusiast, you'll love visiting the Great Basin National Park.\n9. Black Rock Desert Wilderness\nThe Black Rock Desert Wilderness is located within the Black Rock Desert. With a land area of 314,829 acres, it's the largest U.S. designated wilderness area that is managed solely by the Bureau of Land Management. Vegetation in this wilderness area consists of saltbush and greasewood, and large portions of the area are unvegetated. Just a few examples of wildlife found within this wilderness area include mule deer, pronghorn antelope, sagegrouse, mountain lions and coyotes. Numerous mammoths have also been excavated from the area.\n10. Ash Meadows National Wildlife Refuge\nThe Ash Meadows National Wildlife Refuge, located within the Amargosa Valley of southern Nye County, Nevada, is a beautiful 23,000 acre protected wildlife refuge that's part of the larger Desert National Wildlife Refuge Complex, which includes the following: the Desert National Wildlife Refuge, the Pahranagat National Wildlife Refuge, the Moapa Valley National Wildlife Refuge, and the Amargosa Pupfish Station. An interesting fact regarding Ash Meadows National Wildlfe Refuge is that virtually all of its water is fossil water, meaning it entered the ground water system tens of thousands of years ago.\n11. Lehman Caves\nLehman Caves, discovered during the late 1880s, is located within Great Basin National Park and attracts thousands of visitors each year. This popular tourist attraction is a beautiful marble cave containing numerous stalactites, stalagmites, helictites and more than 300 rare shield formations. Lehman Caves was declared a national monument on January 24, 1922. The next time you visit Great Basin National Park, be sure to check out Lehman Caves. If you're a fan of caves, you'll love this place!\n12. Red Rock Canyon National Conservation Area\nThe Red Rock Canyon National Conservation Area, located approximately 15 miles west of Las Vegas, features large red rock formations, with some of the walls towering more than 3,000 feet. The height of these rock formations make this area a popular hiking and rock climbing destination. The Red Rock Canyon National Conservation Area receives over 1 million visitors each year.\nHave you ever visited any of these natural wonders? What other natural wonders in Nevada are worth checking out? Please let us know in the comments below!""]"	['<urn:uuid:1573d5c4-3f75-4c26-af0a-03bc75824ec2>', '<urn:uuid:e64f364c-670c-4311-b180-7d82553fe113>']	open-ended	with-premise	short-search-query	distant-from-document	comparison	expert	2025-05-12T15:09:02.012753	6	75	2558
40	how are old and new testament connected explain relationship between	God arranged for the New Testament to be hidden in the Old Testament, and for the Old Testament to be made manifest in the New Testament. While Christ established the new covenant with His blood, the Old Testament illuminates and explains this mystery. The Old Testament's purpose was to prepare for Christ's coming and demonstrate how God interacts with mankind through justice and mercy.	['A. What is it?\n“Dei Verbum” is the Vatican II Dogmatic Constitution on Divine Revelation, promulgated by Pope Paul VI on 18 November 1965\nThe phrase “Dei Verbum” is Latin for “Word of God”\nIt is one of the smallest Vatican II Documents (26 paragraphs or roughly 3,000 words in Latin)\nB. What does it speak of?\n“Dei Verbum” addresses the Catholic Church’s beliefs in regards to Sacred Scripture.\n“Dei Verbum” is laid out into 6 Chapters:\n- Chapter 1: Divine Revelation Itself\nSpeaking on the Nature of Revelation, this chapter demonstrates God’s desire to communicate with human beings, revealing the mystery of the Divine Will.\nIt offers a summary of the Salvation History\nIt also emphasizes the Truth of this Revelation and the fact that it is accomplished in such a way that human beings can comprehend it.\n- Chapter 2: Transmission of Divine Revelation\nThe Truth of Revelation, is rooted in Christ’s very person and in his own proclamation of the Gospel; having commissioned the Apostles to carry it forward…, the truth of the\nThe Gospel also lies in the Apostolic Tradition.\nBoth Scripture and Tradition must be accepted and honoured with equal devotion and reverence”.\nTradition and Scripture make up a single Sacred deposit of the Word of God\n- Chapter 3: Sacred Scripture: Its Divine Inspiration and Interpretation\nIt affirms the importance of both- the Old Testament and New Testament\nIt adopts the threefold-process of the Formation of the Gospels with the three levels: (i) the time of the Historical Jesus (ii) The oral preaching of the earliest apostles (iii) The time of the Evangelists\n- Chapter 4: The Old Testament\nThe plan of salvation was spoken through the authors of the Old Testament.\nIts purpose was to prepare for the coming of the Christ and to show to all, how God interacts and deals with mankind in justice and mercy.\nGod wisely arranged for the New Testament to be hidden in the Old, and the Old to be made manifest in the New. While Christ made the new covenant with His blood, the Old Testament sheds light on and explains this mystery.\n- Chapter 5: The New Testament\nThe New Testament stands as a Perpetual and Divine Witness to the Reality of Salvation.\nThe Gospel Authors wrote about things handed on by word of mouth or in writing, sometimes a synthesis, sometimes as a proclamation, but always the honest truth about Jesus.\n- Chapter 6: Sacred Scripture in the Life of the Church\nThe Church has always venerated the scripture together with the Tradition as the supreme Rule of Faith.\nThe Church encourages the study of the Church Fathers as well as those exegetes who so well illuminate the teaching within the scriptures.\nIndividuals should read with enthusiasm, following the mind of the Church.\nAll clergy must read the scriptures with diligence. The same is encouraged for the laity and Religious. All faithful should not forget that prayer should always be the companion to reading God’s Word.\nC. Pointers for Reflections\n- “Dei Verbum” is considered as one of the important achievements of the Vatican Council II since its implications is for the treatment of Sacred Scripture itself.\nIt accords rightful significance to the Bible as the special locus of Divine Communication or Divine Revelation.\n- It presents three key principles of Catholic biblical interpretation:\n(i) Pay attention to the content and unity of all the Sacred Scriptures.\n(ii) Read and interpret the Bible within the living tradition of the Church.\n(iii) Keep in mind the coherence of all the truths of revelation\n- The understanding from “Dei Verbum” is enshrined in the Catechism of the catholic Church (CCC), affirming reading Scripture for its four classical sense – the literal sense, and then the spiritual sense divided into three: the allegorical, topological, and anagogical senses.\nThe allegorical sense (Typology) concerns how the Old and New Testaments relate, the topological sense is the moral sense, and the anagogical sense concerns the soul’s progress to heaven.\nD. What virtues/points can we pick up from the “Dei Verbum” for this Season of Lent?\n- Making it a Daily Habit to Read the Bible\n- Studying the Bible and going deeper into understanding the meaning of Scripture in our daily life\nE. Tips to practice these virtues\n- Set apart a time, daily, to read God’s Word.\nJust as our meals become a daily “must”, so should the Bible be part of our daily “sustenance for strength”\n“Ignorance of Scriptures is ignorance of Christ” says St Jerome\nChrist is the primary and ultimate revelation of God. So the more we read and reflect on Scripture, the more we can know Him and love Him\n- Learn, practise and revive the Catholic Tradition of the “Lectio Divina”(= a Latin term, means “divine reading”)\n(i) The first stage is LECTIO (reading): Read any passage of the Word of God, slowly and reflectively so that it sinks into us\n(ii) The second stage is MEDITATIO (reflection): Think about the text we have chosen and ruminate upon it so that we take from it what God wants to give us\n(iii) The third stage is ORATIO (response): Leave thinking aside and simply let the heart to speak to God.\n(iv) The final stage is CONTEMPLATIO (rest): Let go of our own ideas, plans and meditations and also holy words and thoughts. Simply rest in the Word of God and listen, to God, who speaks within us with a still small voice.\nAs we listen, we are gradually transformed from within and this will have a profound effect on the way we actually live.\nMay this Lent and the familiarity with “Dei Verbum” – the Vatican II Dogmatic Constitution on Divine Revelation – help us to grow in our acclamation: “Eureka – I have found the Lord”\n(The Full Text of “Dei Verbum” can be found at:\nGod Bless! Live Jesus!']	['<urn:uuid:e1eb2ac5-1ad6-4020-8e78-9d9696640152>']	open-ended	direct	long-search-query	distant-from-document	single-doc	novice	2025-05-12T15:09:02.012753	10	64	987
41	why cathodal stimulation peripheral nerves mechanism	In cathodal stimulation of peripheral nerves, negatively-charged anions flow from the cathode into the tissue and back to the anode. These negative charges accumulate on the outer surface of the nerve membrane, repelled by the negatively-charged cathode. This makes the outside of the membrane more negative, while the inside becomes more positive due to positive ion accumulation. This results in depolarization which, if sufficient in magnitude, triggers an action potential. The action potential then propagates in both directions along the nerve, starting at the cathode.	"['Whether you practice neurophysiology in surgery, in the lab, or in the clinic, you probably use electrical stimulation to activate the nervous system on a daily basis. As you probably know, cathodal stimulation works best in some applications, while anodal stimulation works best in other applications.\nArmed with this knowledge, you know precisely where to place electrodes on the body, and where to plug those electrodes in - black in cathode (-) and red in anode (+). But, what\'s the difference? What exactly is anodal or cathodal stimulation, and why does one work better than the other in some applications?\nToday I hope to answer some of those questions for you because I believe that understanding stimulus polarity is important, and it will make you a better neurophysiologist.\nBefore we talk about how stimulators works, it is important to have a basic understanding of how a battery works.\nHow a Battery Works\nThe correct term for what we frequently refer to as a ""battery"", is a ""cell"", but I\'m going to use the word battery to keep it simple. So, a battery is a charge-separating device. It stores electric energy by separating cations and anions into two separate compartments, or terminals (Figure 1).\n- Cations are positively-charged ions (+).\n- Anions are negatively-charged ions (-).\nIf you refer to the illustration in Figure 1, you will see that one terminal of the battery contains an excess of cations (+), and this is the positive terminal (+). Because it contains cations (+), the positive (+) terminal of the battery is called the cathode (+). The other terminal of the battery contains an excess of anions (-), and this is the negative terminal (-). Because it contains anions (-), the negative (-) terminal of the battery is called the anode (-).\nWhen the battery is connected to a load, in this case a lightbulb, the device is powered by the flow of current. Conventional Current assumes that current flows out of the positive terminal, through the circuit and into the negative terminal. This was the convention chosen during the discovery of electricity, but they were wrong! Rather, Electrical Current is what actually happens, as electrons (-) flow out of the negative terminal (anode), through the circuit and into the positive terminal (cathode).\nThe take-home message is that, in a battery, current flows from anode to cathode. To learn more about batteries, go here.\nHow an Electrical Stimulator Works\nIn an electrical stimulator, the flow of anions (-) and cations (+) is controlled by the mechanics of the circuitry within the stimulator. The stimulator is unique in that the cathode is the negative pole (-) because it discharges anions (-), and the anode is the positive pole (+) because it discharges cations (+). At the end of the day, that\'s the fundamental difference between a battery and a stimulator.\nDepending on how we configure the polarity, the stimulator will discharge either cations or anions into the body part being stimulated.\nIn cathodal stimulation, anions (-) are discharged into the body as current flows from the cathode (-), through the tissue, and back to the anode (+).\nIn anodal stimulation, cations (+) are discharged into the body as current flows from the anode (+), through the tissue, and back to the cathode (-).\nNow, let\'s imagine that we place an electrical stimulator on the surface of the skin with a nerve bundle running underneath (Figure 2). Within the nerve bundle is a single nerve fibre (axon) upon which we will focus.\nAt rest, the inside of a cell is more negative than the outside of a cell. This occurs because there is a slightly greater number of negative charges than positive charges inside of the cell (intracellular space), and a slightly greater number of positive charges than negative charge outside of the cell (extracellular space). Because of the electrical difference, the cell is said to be polarized - just like a magnet, one side is more positive and the other side is more negative. If the electrical gradient were suddenly reversed, the cell would be depolarized, and we might see an action potential.\nCathodal Stimulation of Peripheral Nerves\nWhen we use the term cathodal stimulation, what we mean is that negatively-charged anions (-) flow from the cathode, into the tissue, and back to the anode (Figure 3). As the electrical current flows from cathode to anode, negative charges (anions) tend to accumulate on the outer surface of the nerve membrane as they will be repelled by the negatively-charged cathode. This makes the outside of the membrane more negative. Consequently, the inside of the membrane becomes more positive due to accumulation of positive ions on the inside. This will result in depolarization, which, if sufficient in magnitude, will result in an action potential (nerve impulse or muscle activation).\nFigure 3 illustrates activation of the axon under the cathode. As a result of stimulation, an action potential is sent in both directions along the length of the nerve, starting at the cathode. Something interesting happens underneath the anode, though! All of the negative charge from the extracellular space is attracted to the anode, leaving the outside of the cell excessively electrically positive relative to the inside of the cell. The cell is thus hyperpolarized under the anode, meaning that it is very, very difficult to activate.\nIf you apply the information above to the median nerve SSEP (Figure 4), then you can see why the anode is always distal, and the cathode is always proximal.\nWhat happens when you accidentally reverse your stimulating electrodes when performing an SSEP test? The difficulty that you may experience in attempting to acquire an SSEP is explained by the phenomenon of anodal blocking (Figure 3). Thus, when bipolar electrodes have tips in the same orientation as a fiber, a fiber will be depolarized under the cathode, and hyperpolarized under the anode. If the hyperpolarization is large enough, an action potential initiated under the cathode may not be able to propagate through the region of hyperpolarization. If this is the case, the action potential will propagate in only one direction. While we often talk about the phenomenon of anodal blocking, you won\'t see this in the clinical scenario if you use appropriate stimulation parameters. For intraoperative monitoring of SSEPs, you should be using supramaximal stimulation. The high intensity stimulus will overcome any issues that may be experience as a result of anodal blocking.\nAnodal Stimulation of Peripheral Nerves\nWhen we use the term anodal stimulation, what we mean is that cations (+) flow from the anode, into the tissue, and back to the cathode (Figure 5). When applied to the surface of a nerve, anodal current will increase the concentration of cations (+) in the extracellular space under the anode. This will result in hyperpolarization, which, as I just mentioned, puts the cell in a heightened state of rest. So, what we see in Figure 5 is that the nerve axon becomes deactivated (hyperpolarized) under the anode.\nThe Importance of Cell Orientation\nIn all of the examples described thus far, the orientation of the cell under the stimulator has been horizontal with respect to the orientation of the anode and cathode (Figures 2-5). This is usually the case when stimulating nerves in the arms and legs.\nWhat happens when the orientation of the cell is vertical with respect to the orientation of the anode and cathode? The answer is that things usually work exactly opposite to what we just discussed regarding horizontally-oriented cells.\nThis becomes particularly important in the brain where pyramidal cells of the cerebral cortex are vertically-oriented with respect to the surface where we stimulate.\nAnodal Stimulation of Cerebral Cortex\nElectrical stimulation of cerebral cortex is used for lots of reasons, but today I\'m going to focus on motor evoked potentials (MEPs). If you use electricity (as opposed to a magnet) to evoke MEPs in your clinical practice, hopefully you know the following principle:\nWhether you are stimulating the scalp over motor cortex, or directly stimulating the cortical surface, MEPs are always easiest to elicit and characterize when you use anodal, monopolar, pulse-train stimulation. Things change a little with subcortical stimulation, but that\'s a topic for a different day.\nStarting with Fritsch and Hitzig (1870), many researchers have shown that monopolar stimulation of the motor cortex is more effective with an anode, as opposed to a cathode. Also, monopolar anodal stimulation seems to activate pyramidal cells directly.\nOne proposed mechanism is that anodal current enters (and hyperpolarizes) dendrites at the surface of the brain, then leaves and depolarizes the axon or cell body. One way to think about this illustrated in Figure 7.\nAnodal stimulation is just the injection of positively-charged ions under the electrode. Because opposites attract, negatively charged ions migrate to the the very surface of cortex under the anode. You can think of this a current sink and the consequence is hyperpolarization of the apical dendrites of the pyramidal cell. In order to compensate for this current sink, a current source is generated distally such that positively-charged ions congregate around the other end of the pyramidal cell. This results in depolarization (activation) of the cell body, the axon hillock and the initial segment of the axon, which forms the corticospinal tract.\nOf course, it isn\'t that simple! Computational simulations paint a more complex picture. As Figure 8 illustrates, the neural response to stimulation is likely a complex pattern of depolarization and hyperpolarization throughout the neural geometry of the cell, which is dependent upon stimulation parameters and the neural positions relative to the electrode. Clearly, when the long axis of the cell is oriented vertically relative to the orientation of an anodal stimulation electrode, the computation simulation supports hyperpolarization of the apical dendrites and depolarization around the axon hillock.\nIt all comes down to the orientation of the cell!\nThink about this... when you place your monopolar stimulating electrode over the motor cortex and deliver anodal stimulation, your lowest threshold CMAPs are from the vertically-oriented cells just below your electrode. If you do transcranial MEPs, your electrode is probably C3 or C4, right? And, the electrode are just over the hand representation of the motor homunculus. You really have to increase the intensity to get MEPs from the legs, correct? This is because those ""leg"" cells are deep in the interhemispheric fissure and the cells are oriented horizontal to your anodal stimulating electrode. BUT, if you switch your polarity and deliver cathodal stimulation from the same electrode, MEPs from the legs are sometimes easier to elicit and hands become more challenging. This phenomenon works best when you are stimulation around threshold intensity. You can use this to troubleshoot your MEPs. If you begin stimulating and you get MEPs from the legs/feet at lower intensity than the arms/hands, then your polarity is probably reversed.\n- Fritsch GT, Hitzig E. 1870. Über die elektrische Erregbarkeit des Grosshirns. Arch Anat Physiol Med Wiss 300–32. Translation in Von Bonin G. 1960. Some papers on the cerebral cortex. Springfield (IL): Charles C Thomas.\n- Merrill DR, Bikson M, Jefferys JGR. Electrical stimulation of excitable tissue: Design of efficacious and safe protocols. J Neurosci Methods. 2005 Feb 15; 141(2):171-198.\n- Nair DR, Burgess R, McIntyre CC, Lüders H. Chronic subdural electrodes in the management of epilepsy. Clin Neurophysiol. 2008 Jan;119(1):11-28. Epub 2007 Nov 26. Review.\n- Ranck JB Jr. Which elements are excited in electrical stimulation of mammalian central nervous system: a review. Brain Res. 1975 Nov 21;98(3):417-40. Review.\n- Stephani C, Luders HO. Electrical Stimulation of Invasive Electrodes in Extratemporal Lobe Epilepsy. In: Koubeissi MZ, Maciunas RJ, eds. Extratemporal Lobe Epilepsy Surgery. Montrouge, France: John Libby Eurotext; 2011. 261-313. Print.\nNote: This article was originally published by Richard Vogel in 2015 and is being republished here for the benefit of ASNM members. The contents of this post are the work of the author and do not necessarily represent the views of the ASNM.']"	['<urn:uuid:efd4d7b0-fec4-4ffe-96da-b2f4bedca612>']	open-ended	direct	short-search-query	similar-to-document	single-doc	expert	2025-05-12T15:09:02.012753	6	85	1991
42	I've heard that food allergies usually show up when you're a kid, but is it possible to suddenly develop problems with eating seafood as a grown up?	Anyone can develop a shellfish allergy, even if they've eaten shellfish before without any problems. While food allergies can occur at any age, shellfish allergies actually appear more often in adults than in children. About 60% of people who have a shellfish allergy first experience symptoms as an adult.	['Some people with shellfish allergies are allergic to both groups of shellfish. But others are only allergic to one group. So, someone with a shrimp allergy might also react to crab, but not to clams.\nCan you be allergic to just crab?\nAllergy Information: Crabs along with crayfish, lobsters and shrimps are crustaceans. Food allergy to crustaceans is relatively common, symptoms ranging from mild oral allergy to severe symptoms such as anaphylaxis. Cooking does not remove the allergen.\nCan you be allergic to crab but not other shellfish?\n– That it is common for people to be allergic to more than one shellfish. Sicherer finds up to 80 per cent who are allergic to one crustacean may be sensitized to others, and “40 per cent may react upon ingestion.”\nDoes allergy to shrimp mean allergy to crab?\nShellfish allergy is an abnormal response by the body’s immune system to proteins in certain marine animals. Marine animals in the shellfish category include crustaceans and mollusks, such as shrimp, crab, lobster, squid, oysters, scallops and others.\nCan I eat crab if I’m allergic to shrimp?\nWithin the shellfish family, the crustacean group (shrimp, lobster and crab) causes the greatest number of allergic reactions. Many shellfish-allergic people can eat mollusks (scallops, oysters, clams and mussels) with no problem.\nHow do you know if you’re allergic to crab?\nabdominal pain, nausea, diarrhea, or vomiting. congestion, trouble breathing, or wheezing. skin reactions including itching, hives, or eczema. swelling of the face, lips, tongue, throat, ears, fingers, or hands.\nHow do you treat allergic reaction to crab?\nYour doctor may instruct you to treat a mild allergic reaction to shellfish with medications such as antihistamines to reduce signs and symptoms, such as a rash and itchiness. If you have a severe allergic reaction to shellfish (anaphylaxis), you’ll likely need an emergency injection of epinephrine (adrenaline).\nCan you become allergic to shellfish later in life?\nAnyone can develop a shellfish allergy — even if you’ve had shellfish before without any problems. Although it can occur at any age, it appears more often in adults than in children. About 60% of people who have a shellfish allergy first get symptoms as an adult.\nWhat is a home remedy for seafood allergy?\nTreating mild allergic reactions\n- Stop eating. If your body is reacting to a food you’ve eaten, the first step is simple: Stop eating the food. …\n- Antihistamines. Over-the-counter antihistamines may help lessen the symptoms of a mild reaction. …\nWhat to avoid if you have a shellfish allergy?\nAvoid foods that contain shellfish or any of these ingredients:\n- Crawfish (crawdad, crayfish, ecrevisse)\n- Lobster (langouste, langoustine, Moreton bay bugs, scampi, tomalley)\n- Shrimp (crevette, scampi)\nDoes Benadryl help with shellfish allergy?\nTake an over-the-counter antihistamine, such as diphenhydramine (Benadryl) or loratadine (Claritin), as your doctor recommends. If you have a severe reaction, you also might be given one of these antihistamines.\nHow common is shrimp allergy?\nShrimp allergy is a common food allergy, but it’s much more common in adults than in babies and young children. Furthermore, shrimp allergy only affects ~1% of children compared to the most common childhood food allergies (peanut, egg and milk allergies) which affect ~7% of children.\nHow long after eating shrimp can you have a reaction?\nHow long does it take for a reaction to start after eating a food? Symptoms usually start as soon as a few minutes after eating a food and as long as two hours after. In some cases, after the first symptoms go away, a second wave of symptoms comes back one to four hours later (or sometimes even longer).\nCan I eat calamari if I have a shellfish allergy?\nBased on the results of such tests, the allergist is able to decide whether to pursue an oral food challenge to assess whether other shellfish may be tolerated. In your case, you have reacted to both crustaceans and mollusks, suggesting a high likelihood that you might also react to calamari, a mollusk.\nCan you eat tuna if you have a shellfish allergy?\nSeafood includes fish (like tuna or cod) and shellfish (like lobster or clams). Even though they both fall into the category of “seafood,” fish and shellfish are biologically different. So fish will not cause an allergic reaction in someone with a shellfish allergy, unless that person also has a fish allergy.\nCan you eat sushi if you’re allergic to shellfish?\nIf you have a severe allergy, make sure you double-check the menu and warn your waiter. It’s always better to be safe than sorry. Note: Order sashimi (fresh slices of fish) and nigiri (raw fish over pressed vinegar rice) with your favorite seafood to guarantee absolutely no consumption of shellfish.']	['<urn:uuid:1578af98-556d-47b4-af94-14e5443e5b0b>']	open-ended	direct	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-12T15:09:02.012753	27	49	789
43	What caused the underwater forest and submerged buildings in the Norwegian lake Lygnstøylsvatnet?	On May 26, 1908, the 1218 meters tall mountain Keipen cracked, causing rocks to crash down the mountainside. This created a dam across the valley that blocked the river, slowly filling the valley with water and creating Lake Lygnstøylsvatnet. This event submerged nine farm buildings, two bridges, a farm road, stone fences, a gate, and an apple tree forest which remains preserved underwater.	['Imagine you are floating through crystal clear water, looking down at what looks to be an enchanted forest. You can see the remains of a settlement, the roads and stone fences used to herd sheep and transport goods over a hundred years ago.\nWelcome to Norway’s Atlantis, welcome to Lygnstøylsvatnet.\n[icon name=”location-arrow” class=”” unprefixed_class=””] Destination: Sunnmøre, Norangsdalen, Lygnstøylsvatnet\n[icon name=”bullseye” class=”” unprefixed_class=””] GPS:62°10’30.6″N 6°43’44.0″E\n[icon name=”area-chart” class=”” unprefixed_class=””] Maximum 13 meters\n[icon name=”clock-o” class=”” unprefixed_class=””] Time: 45min each dive\n[icon name=”area-chart” class=”” unprefixed_class=””] Height: 152 meters\n[icon name=”angle-double-up” class=”” unprefixed_class=””] Difficulty: Medium\n[icon name=”sun-o” class=”” unprefixed_class=””] Season: Spring, Summer, Autumn\n[icon name=”tencent-weibo” class=”” unprefixed_class=””] Type: Diving/Freediving\n[icon name=”cogs” class=”” unprefixed_class=””] Special Equipment: Scuba/Freediving gear\nHow it came to be\nLake Lygnstøylsvatnet, situated in Nordangsdalen Valley in the West of Norway, is one of the most amazing dive destinations in Norway. Originally there shouldn’t be a lake to dive in, but the 26th of May 1908, the 1218 meters tall mountain Keipen cracked. A large amount of rocks came crashing down the mountain side, creating a dam across the valley. The river was blocked and the water had nowhere to go. Slowly the valley filled with water, and thus Lygnstøylsvatnet was created.\nOn clear, calm days you can actually see some of the remains just by parking and looking out your car window. However, the experience is most rewarding for those who can scuba or freedive down to 5-13 meters, and swim through the remains of the old road, the forest and the farm houses.\nWhat to see\nWhen scuba or free diving, you will be able to see the remains of nine farm buildings, two bridges, a farm road, stone fences, a gate, and most importantly; a mesmerizing underwater forest consisting of bare apple trees, over a hundred years old, frozen in time.\nHow to find the lake?\nFinding the lake is quite easy; You follow country road 655, between Hellesylt and Øye in Sunnmøre, or simply enter Lygnstøylsvatnet into google maps. You will pass several smaller lakes, but once you reach Lygnstøylen, you will see a plackard stating that this is the Lygnstøylsvatnet lake. Weather permitting, you might also be able to see some of the old farm buildings from the shore. There are a few parking spaces available by the lake.\nHow many dives?\nThe visibility of the lake varies from crystal clear to murky, depending on how rainy the weather has been the previous days. The more rain, the more sediments are dragged into the lake from the mountains, making the visibility bad.\nWe believe that you will be able to experience the most important features of Lygnstøylsvatnet in two (scuba) dives. Thus, we have made a suggestion as to how you can perform these two dives; one longer dive at the south west end of the lake, and a shorter second dive at the north west side of the lake. Take a look at the map above to look at the main points of interest. These are approximate placements, but they should be close enough to navigate by. If you don’t want to do scuba diving, it is also perfectly possible to have a nice free diving session at the lake, and we highly recommend this as well as scuba diving.\nRelated Posts: How to get stunning underwater video from a GoPro\nDIVE 1 – The tunnel and forest:\nDescend, and start off by swimming close to the fences you will see from the starting point. Follow the fences a bit south, and you will arrive at the first bridge at about 5-6 meters depth. It is great fun to swim through it, but be careful not to kick up too much sediments, as this will possibly annoy the diver following behind you.\nAfter swimming under the bridge, it is nice to follow the “riverbed” into the mysterious forest at about 10 meters depth. If you want to see more of the forest, you can swim east for an extended period. If you do this, you will see even bigger trees at about 12-13 meters depth. Please remember: All the trees in the lake are very brittle, and very little contact is necessary to break them. Be mindful of your fins and your arms, and never lean on the trees. The branches can snap quite easily. Keep that buoyancy controlled!\nAfter enjoying the forest you can swim northwest and arrive at the road. Continue towards north east to shallower waters, and you will find the old farms at 2-3 meters depths. This is a very nice place to perform your safety stop. Surface when you feel like it, and walk or swim back to the starting point.\nGet out of the water, get yourself a cup of coffee, and get excited for your next dive!\nDIVE 2 – The road and old farms:\nThe second dive covers a shorter distance, and gives you time to enjoy the old buildings and the large rocks in the land slide. Start descending near the fences until you reach the road at about 5 meters depth. Swim north while following the road, and you will soon reach the landslide with its massive rocks, at about 6-7 meters depth. At the end of the road, you will also find the second bridge, which you can also swim under. Turn around, and ascend to 2-3 meters depth. Swim back towards the starting point, while checking out the old farms and fences along the way.\nDiving in Lygnstøylsvatnet is quite easy, as it is not so deep. However, it requires good buoyancy control. We want to stress the fact that you should never lean on any of the fragile trees, and that it is not considered good dive etiquette to stir up sediments from the bottom, making it murky for the divers following behind. You should also be mindful that the drive to and from Lygnstøylsvatnet could include mountain passes. All in all, be considerate and careful, so that Lygnstøylsvatnet will continue to be a place we can all visit and enjoy in the future as well 🙂\nLars made a movie from some of the scuba dives we’ve had at Lygnstøylsvatnet. It was recorded over a period of 3 dives. The weather conditions were cloudy and we experienced some rain, but the underwater conditions were absolutely fantastic. Check it out at the top of the post.\nWhere to stay, and where to rent equipment.\nWe hope you enjoyed this article. Be sure to drop a comment in the comment section, and share the post with your friends.\nKeep in touch!\nIf you want to stay up to date with new articles, pictures and videos, subscribe to our [thrive_2step id=’5283′]newsletter[/thrive_2step], or follow one of our social media profiles (Facebook, Twitter, Instagram). We also have a Facebook group community where you can post questions, or discuss how and where to travel in Norway.\nDo you like the blog, or do you miss any information? We would love to hear from you in our feedback form.\n– And as always, all pictures seen on the site is available for print or licensing through larskorvald.com.']	['<urn:uuid:e3c361ba-5393-47d0-a13a-dc673187a04a>']	factoid	direct	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-12T15:09:02.012753	13	63	1189
44	What career opportunities are available in international relations, and what mental health support systems are recommended for professionals working abroad in this field?	International relations prepares individuals for internationally focused positions that require understanding of cultural, economic and political forces driving global issues. For mental health support, it's recommended to establish alternative support networks, maintain a realistic communication plan with family and friends, and connect with mental health care professionals on-site. It's important to understand that ups and downs are normal during international work, and individuals should seek support if feelings become more intense than expected.	"[""Why global studies and international relationsprepare for internationally focused positions in the us or abroad with our practical, interdisciplinary and interactive master's degree in global studies and international relations. Students majoring in international affairs (ia) study issues of conflict and cooperation in the international system this involves examination of domestic influences on state behavior, the foreign relations of states, and characteristics of the international system central concerns in ir include. Summary of international relations courses for ucsd political science. Travel advice to help australians avoid difficulties overseas, we maintain travel advisories for more than 170 destinations travel advice for countries and events.\nThe major prepares individuals for careers or graduate coursework that will require a deep and nuanced understanding of the cultural, economic and political forces driving contemporary global issues and relations among societies students in the program work closely with a faculty comprised of. Prospective students interested in studying international relations should apply to the graduate program in government. Major requirements there are three components to the ir major the core curriculum the electives in the major the senior thesis all ir majors are required to complete a core-curriculum consisting of international relations theory, history, security, international economics, and research methods. A summary of theories of international relations in 's international politics learn exactly what happened in this chapter, scene, or section of international politics and what it means perfect for acing essays, tests, and quizzes, as well as for writing lesson plans.\nGeneral international relations allows you to choose from among all of the courses offered in four programs in the overall field of international relations, in addition to selected other policy areas at the school. Define international relations: a branch of political science concerned with relations between nations and primarily with foreign policies. Webster university graduate catalog program requirements for ma in international relations. Welcome to the international relations program at the university of pennsylvania in the school of arts and sciences, the ir major places a strong emphasis on interdisciplinary skills. International relations at the college of william and mary is a thriving program that integrates teaching, research, study abroad, foreign language, and close interaction among students and faculty from different disciplines. International relations (ir) is a rigorous program that combines student choice with cross-disciplinary training in international and comparative perspective.\nInternational relations definition: the political relationships between different countries are referred to as international | meaning, pronunciation, translations and examples. San jose is an international city with one of the largest global concentrations of talent that matches and fuels the pace of the growing global economy 38 percent of the city's population is foreign-born and the diversity throughout our immigrant population is far broader than any other major. International relations is the study of relations between states and relations among other actors that extend across state boundaries these relations comprise multiple phenomena that shape today's world: trade and finance, armed conflict, migration, law, environmental issues, health. News about international relations commentary and archival information about international relations from the new york times.\nInternational relations publishes the best refereed work in the variety of intellectual traditions that constitute the subject of international politics in a.\nAmerica goes shopping and runs into some old friends and enemies will she be able to stay diplomatic, or will she lose her cool be sure to subscribe to st. Internation relations graduate schools may refer to their ir degree programs by other names international politics, global affairs and international affairs graduate programs find out what program fits you and apply today. E-ir's articles offer an accessible route into some of the most interesting ideas, debates and policy issues in international politics all articles are published under the issn 2053-8626 use the search box on the right with appropriate keywords to enable you to find expert content on the.\nInternational relations, principal theories institutions thus enhance the utility of a good reputation to countries they also make punishment more credible. Svs recognizes the growing importance of vascular surgery worldwide as of january 2017, there were svs members in 55 countries. We are often asked about the employment prospects of student who major in international relations we take their questions regarding career planning very seriously. The international relations major offers courses to open doors around the world learn why nations go to war or make treaties and why nations disintegrate into civil war or several states."", 'Understanding the potential health risks and other conditions in your host country that can impact student health and/or access to health care before departure is critical for having a successful semester abroad. We encourage all students to disclose any past or present mental or physical health needs to OIED, the Counselling Center, Student Health Services, and/or the Office of Disability Services, so that students can determine prior to departure the types of support resources that will be needed for the duration of the student’s study abroad program.\nWe recommend that all students have a routine check-up with their medical practitioner(s) before traveling abroad to discuss continuation of any ongoing care plans, including any support for medical conditions while abroad, prescription medications you will need to continue while abroad, food/environmental and other allergies you may have, and/or mental health needs. If you have a medical condition that is not easily identified (diabetes, epilepsy, severe allergies), you should wear a medic alert bracelet while you are abroad and consider adding a translation. You should also inform OIED, traveling companions, roommates, and on-site staff so that they can be prepared in case of an emergency. Be sure to discuss a plan with your medical practitioner before you leave home.\nIf you have any chronic or recurrent medical conditions (including but not limited to asthma, heart disease, diabetes, depression, anxiety, attention deficit disorder, chronic pain, immunosuppressive disorders, etc…), please consider this and make sure that you are mentally and physically capable to participate in your upcoming travel itinerary.\nAfter acceptance to the education abroad program, students will be asked to complete the Health Self-Disclosure Form(PDF, 463K).\n- CDC Country-specific health information\n- State Department Country Specific Information\n- State Department Staying Healthy Links\n- Appalachian State University, Student Health Center, Travel Clinic\nEducation Abroad programs can be a fulfilling and challenging experience for all students. It can also present additional challenges for students with mental health conditions due to the added stress, unfamiliarity, culture shock, language barriers, and removal from a local support system. Even for students without a history of mental health conditions, the impact of moving to a new environment can influence a student’s wellbeing.\nWe encourage all students to describe to their mental health practitioner their intended study abroad plans, including which countries you would visit, what you would be doing, and the duration of the program. We also encourage all students to disclose any past or present mental health needs, including prescription medication, to OIED, Student Health Services, the Counseling Center, and/or the Office of Disability Services so that students can determine prior to departure the types of support resources that will be needed for the duration of the student’s study abroad program.\nPast or current treatment for psychiatric and mental health conditions does not preclude you from studying abroad. However, if a healthcare professional recommends no travel or travel under certain conditions that cannot be met at a certain study location, you may be encouraged to focus on your health first, postpone program participation until a later time or find a more suitable study abroad location.\nPlease review the following steps for managing mental health conditions while abroad:\n- Meet with your mental health professional prior to departure to discuss:\n- Participating on an education abroad program and implications of going abroad\n- Your plan to manage your health while abroad\n- Access to alternative support networks\n- Discuss a realistic communication plan for your time abroad with your support networks (i.e. family and friends).\n- Understand that ups and downs are normal during study abroad. Check in often and seek support if you are feeling ups and downs that are more intense than expected.\n- Connect with the Counseling Center, Office of Disability Services, Student Health Services, and OIED prior to departure to set up onsite care with a mental health care professional, should you require this support.\n- Plan to bring sufficient amounts of prescriptions with you for the entire duration of your program. Work with your medical practitioner and OIED to be sure you can safely bring all necessary prescriptions abroad.\n- SAFETI Maintaining Mental Health\n- Mobility International student testimonials\n- Mobility International Mental Health Preparation\n- Mobility International Mental Health Success\n- CDC Mental Health\n- Appalachian State University Counseling Center\n- Appalachian State University Counseling Center Self-Assessment\n- Appalachian State University Office of Disability Services\n- University of Michigan Resilient Traveler\nStudents with Disabilities\nOIED is committed to providing education abroad opportunities to students with disabilities. The key for any study abroad participant is flexibility. OIED and the Office of Disability Services are available to help students find accessibility information for each program.\nFor additional information, students are encouraged to contact Mobility International for assistance in finding programs and overseas support services.\n(Coming soon - For additional information please visit the Student Identity section of our website).']"	['<urn:uuid:5e3376ef-6336-4b5d-a4dc-0765dbf72e50>', '<urn:uuid:fae8274e-4a6a-4b73-997f-a8d5b2f4b2d3>']	factoid	direct	verbose-and-natural	similar-to-document	multi-aspect	novice	2025-05-12T15:09:02.012753	23	73	1548
45	I'm studying the representation of science in media and would like to know what kinds of science-related stories were selected for the 2020 fellowship awards - can you tell me about the winning projects?	The 2020 fellowships were awarded to two projects: Kiran Deol's 'Tidal Disruption,' which focuses on a graduate student navigating between her passion for astronomy and her charismatic mentor's advances, and Jon K. Jones' 'Let There Be Light,' which tells the true story of Lewis H. Latimer, an African American inventor, draftsman, scientist, poet, and Civil War veteran at the turn of the 20th century. The review committee specifically praised these projects for addressing fascinating scientific fields while tackling the scientific approach itself, featuring complex underrepresented characters and exploring both the faults and benefits of scientific culture.	['Dec 21, 2020\n$70,000 Distributed as Part of Screenwriting Fellowship Supporting the Development of Narrative Feature Scripts Related to Science or Technology\nSan Francisco, CA – SFFILM has announced the two filmmakers that have been selected to receive Sloan Science in Cinema Filmmaker Fellowships, which will support the development of their narrative feature screenplays. Produced in partnership with the Alfred P. Sloan Foundation, Sloan Science in Cinema Filmmaker Fellowships are part of the organization’s efforts to support programs that cultivate and champion films exploring scientific or technological themes and characters. A longstanding element of the artist development programs offered by SFFILM Makers, this fellowship is designed to ensure that narrative feature films that tell compelling stories about the worlds of science and technology continue to be made and seen.\nFrom an open call for submissions, SFFILM and the Sloan Foundation have awarded the 2020 Sloan Science in Cinema Filmmaker Fellowships to Kiran Deol to develop her screenplay Tidal Disruption, and to Jon K. Jones for his project Let There Be Light.\nThe review committee consisted of Aneeta Akhurst, Director of Programming at Seeker Media; Brad Balukjian, Ph.D., Director of Natural History & Sustainability Program at Merritt College; Sara Bender, Ph.D., Program Officer of Science at Gordon and Betty Moore Foundation; Sophie Gunther, Manager of Film Funds at SFFILM; Patrick House, Ph.D., writer and neuroscientist; Lauren McBride, Director of Artist Development at SFFILM; Indre Viskontas, Ph.D., Assistant Professor of Psychology at University of San Francisco; and Doron Weber, Vice President and Program Director at Alfred P. Sloan Foundation.\nThe committee noted in a statement: “We are excited to award grants to two projects that not only address fascinating scientific fields, but in their own unique ways tackle the very basis of the scientific approach itself. From a historical account of a previously unsung African American scientist to a modern representation of power dynamics and misogyny in academia, both projects fearlessly portray the faults and boons of scientific culture through the eyes of complex, underrepresented characters. In addition to our grantees, the jury wishes to recognize two projects with Honorable Mentions: Lauren López de Victoria‘s Salt the Fields and Gabriel Wilson‘s After the Wind. While the jury was unable to award fellowships to those filmmakers, both projects showed much promise in their dynamic and achingly human explorations of scientific discovery. SFFILM and the Alfred P. Sloan Foundation are thrilled to continue working together to champion important stories, from past to present, that build upon strong narrative foundations to expand the public understanding of science and technology.”\n“We are excited to partner with SFFILM to award two outstanding screenwriters with the 2020 Sloan Science in Cinema Filmmaker Fellowship,” said Doron Weber, Vice President and Program Director at the Alfred P. Sloan Foundation. “These powerful scripts, about sexual harassment of a female graduate student in astronomy and the real-life story of the pioneering little-known African American scientist Lewis H. Latimer, portray characters as complex and compelling as any in film today.”\n2020 SLOAN SCIENCE IN CINEMA FILMMAKER FELLOWSHIPS\nSloan Science in Cinema Filmmaker Fellowships include a $35,000 cash grant and a two-month virtual residency at FilmHouse, including access to SFFILM Artist Development offerings such as bi-weekly production meetings, virtual events, creative advisory, and more. SFFILM will connect each fellow to a science advisor with expertise in the scientific or technological subjects at the center of their screenplays, as well as leaders in the Bay Area’s science and technology communities.\nKiran Deol, writer/director\nA starry-eyed graduate student desperately struggles to maneuver between her passion for astronomy and her charismatic mentor’s advances in this claustrophobic psychological thriller.\nKiran Deol is a comedian, filmmaker, and actress whose work tackles difficult topics with humor and intimacy. She starred on Mike Schur’s NBC series Sunnyside this past fall opposite Kal Penn, and as the lead in Aline Brosh McKenna’s/Sono Patel’s Pop TV pilot Arranged the year prior. Other TV credits include How to Get Away with Murder, The Mindy Project, Modern Family, New Girl, and more. As a filmmaker, her film Woman Rebel, a documentary about women rebel soldiers, was nominated for an Emmy, shortlisted for an Oscar, and distributed by HBO. She’s a 2020 Sundance Screenwriting Fellow and Sloan Award Recipient for her first feature film, Tidal Disruption. Additionally, Sundance Now released her short film American Haze, about her experience as a first-generation immigrant. She’s a regular host on Crooked Media’s all-female podcast Hysteria and she loves you.\nLet There Be Light\nJon K. Jones, writer/director\nLet There Be Light is based on the true story of African American inventor, draftsman, scientist, poet, and American Civil War veteran Lewis H. Latimer, who struggles to balance love and scientific curiosity amidst the turn of the 20th century in the United States.\nNew York-based writer and director Jon K. Jones earned a Bachelor of Science degree at Brooklyn College with a dual concentration in Screenwriting and Film History and a Master of Fine Arts at Columbia University School of the Arts in pursuit of his passion for story. His personal mission is to bring quality, entertaining, and original stories to life in television, fiction writing, and motion picture by combining socially poignant storytelling with transportive and imaginative aesthetics. In 2020, Jones completed a coveted year-long internship at Saturday Night Live and was the recipient of the Alfred P. Sloan Award for his short screenplay Let There Be Light, a small snapshot of the life of African American inventor Lewis H. Latimer.\nSloan Science in Cinema Filmmaker Fellowships are part of SFFILM and the Sloan Foundation’s year-round Science in Cinema initiative, which is designed to develop and present new feature films and episodic content that portray fully-drawn scientist and technologist characters; immerse audiences in the challenges and rewards of scientific discovery; and sharpen public awareness of the intersection of science, technology, and our daily lives. Leveraging its position in the heart of the innovation capital of the world, SFFILM seeks to forge meaningful connections between the artistic and scientific communities through a suite of programs. In addition to this screenwriting program, the initiative also features the Sloan Stories of Science Development Fund, which supports filmmakers developing science-themed screenplays based on specific scientific discoveries; the Sloan Science in Cinema Prize, which celebrates a finished narrative feature film each fall; and Sloan Science on Screen, a spotlight program at the San Francisco International Film Festival that debuted in 2016.\nFor more information, visit sffilm.org.\nThe Alfred P. Sloan Foundation\nThe Alfred P. Sloan Foundation is a New York based, philanthropic institution that makes grants for research in science, technology, and economics; quality and diversity of scientific institutions; and public engagement with science. Sloan’s program in Public Understanding of Science and Technology, directed by Doron Weber, supports books, radio, film, television, theater, and new media to bridge the two cultures of science and the humanities. The Foundation works with about 20 film school and film festival partners and has supported over 700 film projects, including over 30 feature films. For more information visit sloan.org or follow @SloanPublic on Twitter or Facebook.\nSFFILM Makers (formerly “Filmmaker360”), the organization’s artist development program, provides significant financial and creative resources to independent filmmakers through grants, fellowships, residencies, fiscal sponsorship, and more. Since 2009, over $8 million has been disbursed to more than 250 film projects in various stages of production. Highlights include the SFFILM Rainin Grant, which distributes the most nonprofit funding for narrative features in the United States; a joint effort with the Alfred P. Sloan Foundation to cultivate stories rooted in science and technology; and the Documentary Film Fund, a partnership with the Jenerosity Foundation. For more information, visit sffilm.org/makers.\nSFFILM is a nonprofit organization with a mission to champion the world’s finest films and filmmakers through programs anchored in and inspired by the spirit and values of the San Francisco Bay Area. Presenter of the San Francisco International Film Festival, SFFILM is a year-round organization delivering screenings and events to more than 75,000 film lovers and media education programs to more than 15,000 students, teachers, and families annually. In addition to its public programs, SFFILM supports the careers of independent filmmakers from the Bay Area and beyond with grants, residencies, and other creative development services. For more information visit sffilm.org.']	['<urn:uuid:7eeb54dc-e7e7-4ef2-a89f-de0efebd85ed>']	open-ended	with-premise	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-12T15:09:02.012753	34	96	1375
46	How does sound attenuation fire blankets (SAFB) compare to fiberglass when installing insulation for sound dampening in stud cavities?	Sound attenuation fire blankets (SAFB) are superior to fiberglass for dampening sound transmission in stud cavities. The mineral fiber blankets have the advantage of being able to stand up in stud bays without requiring mechanical fastening. For ceiling applications, it is recommended to install resilient channel first.	['How to create sound insulation walls?. Find answers to your question below. This article is an excerpt from the book called “Stanley Complete DRYWALL” by “Des Moines Iowa”. Thanks to the author.\nCREATING SOUND CONTROL AND FIREWALLS\n- If you want to limit the amount of sound that escapes from a room, incorporate one or all of these five strategies into wall and ceiling construction.\n- Add sound-absorbing material into the stud or joist bays\n- Separate the two sides of the wall from each other. One way to do this is by screwing resilient steel channel to the wall or ceiling, then screwing the drywall to the channel. Other methods include staggering 2×4 studs on a 2×6 soleplate, or even framing two walls, then separating them with a 1-inch dead-air space. You’ll gain additional isolation by gluing and screwing the second layer of drywall to the first, not to the framing.\n- Increase the mass of the wall or ceiling by using thicker panels and/or installing multiple layers.\n- Install a sound-reduction board as the first layer and top it with drywall.\n- Seal sound pathways by caulking, gasketing electrical outlets, and we4atherstipping doors.\nThe irony of successfully decreasing sound transmission is that a room becomes more acoustically reflective. So you’ll probably need to consider adding some sound-absorbing materials such as carpeting and drapes.\nConsult with your local building officials before building a firewall to ensure that you utilize the correct materials and framing techniques.\n- Install insulation in the stud cavities to dampen sound transmission. For this purpose, sound attenuation fire blankets (SAFB) are superior to fiberglass. The mineral fiber blankets stand up in stud bays without mechanical fastening. For ceiling applications, installing resilient channel first is a good plan.\n- Screw resilient steel channels to the walls, spacing them 16 inches on center. You’ll notice that the channel’s design minimizes the amount of direct contact between the studs and the wallboard.\n- Install the first layer of drywall vertically, screwing it to the channels. To achieve the best sound control, make each layer of drywall as thick as possible; two applications of 5/8-inch panels produces excellent results. In high-end projects where even greater sound control is needed, you can use a third or even fourth layer.\n- Apply adhesive to the back of the second layer and install it horizontally. Drive type G screws into the first drywall layer, avoiding both the studs and resilient channels.\n- Using a caulking gun and a special acoustical sealant, fill all cracks around the wall’s perimeter, especially at the bottom of the wall. Also caulk any gaps between the drywall and electrical boxes and heat ducts.\nINSTALL A SOUND-REDUCTION BOARD\nA special type of wall panel is engineered to serve as the base layer instead of drywall in a two-layer sound-reduction installation.(One brand is Homasote 440 Sound Barrier Panel). Following the manufacturer’s instructions, install the panels vertically to wood or metal studs, using adhesive and screws. Top it with adhesive and No.10×1 ½- inch type G screws driven into the base panel, not the studs.\nContinue reading about “Demountable Partitions“']	['<urn:uuid:04a420ed-b495-436d-88e9-20d7747558be>']	factoid	direct	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-12T15:09:02.012753	19	47	520
47	What typical problems can you find in house siding, and how much would it cost to fix these issues?	Common siding problems include mold, which costs $500-$700 to repair, cracks costing $50-$150, water damage ranging from $500-$600, and dents ranging from $100-$300. These issues often manifest through moisture infiltration, particularly around windows and doors, which can lead to mold formation. For wooden siding, problems like chipped paint, peeling, cracked boards, and dry rot are common issues. The repair costs typically range from $200-$300 for general siding repairs. Problems can also include cracked caulk, which requires reapplication of exterior caulk in temperatures above 65 degrees for maximum adhesion.	['Steps of Siding Maintenance\nSiding is one of the important parts of the house attached with the roof that provides the protection you deserve. However, as there is limited time of everything, siding also does not last longer because of the damage that can happen to the material. It is the reason; you must take precautionary measure and certain steps that can extend the life of the source of protection. The basic strategy you need to follow is inspection of the problem and then repairing the damaged part of the siding that means you have to take out time for your exterior house for improving its appearance and performance. Following are some steps that you can follow for certain kind of materials.\nInspect Damage of Siding:\nThe material of the siding is vulnerable for the infiltration of water because it has corners towards the windows and the doors. The moisture can lead to molds that can damage the siding. While inspecting the roof, you need to see whether there is any cracked caulk and find out the reason behind the crack as it can be both by the age or extended gaps between the sidings. Work on this area by reapplying a good exterior caulk matched with the color of existing siding. Do not forget to apply it with excessive 65 degree temperature to ensure maximum amount of adhesion.\nCheck Wood Siding:\nIf the wooden siding is chipped and the paint is peeling or the boards are cracked or trim then you have to call the roofer. If the siding is made of stucco then observes whether there are cracks and chips on the siding. Repair all the defects that you can see and clean the siding with appropriate method. Sooner repairs will lead to better protection from the moisture infiltration so make sure that the roofer is doing the right work. There should be no dry rot and any other formation of mold on the walls.\nRepair Different Styles of Siding:\nNo matter you are repairing the wooden or fiber-cement siding or it is the vinyl siding, you have to make sure to remove the damaged siding completely. Doing the project yourself is a good idea but you need to make sure you have enough skills and expertise for the task. You can also hire a professional siding contractors Grosse ile Michigan for repairing the sidings. The expected cost of replacing the material is $200-$300 and you can easily find a good service provider in town.\nRepair Brick and Mortar:\nWhen it’s about DIY project, you can use cold chisel for removing the loosen mortar and repair it with the fresh mortar with the effective process of repainting. DIY projects mostly are time consuming and there is more difficulty in removing the thinner joints. The visible indication of incorrect sealing on the masonry is powdery white residue on the surface which is also called effloresce. You can remove it by scrubbing the surface with a mixture of water and vinegar with the help of bristle brush. Make sure the surface is properly dry and it is clean that can prevent leaching. If efflorescence is persistence then you can consult a professional roofing contractor for maintaining the siding. You can also remove the mild dew in the same manner by preparing a good mixture of a detergent and water and remove the mildew completely from each and every section of the siding. Make sure to work on the roof as well if mildew has spread all around. You right approach to the care of your roof and siding can reduce your worries and improve the condition of the roof.', 'House siding cost doesn’t come down to a few simple line items. When it’s all said and done, it’s a project with countless moving parts, the likes of which can become confusing.\nBetween materials, labor, permits and the numerous other factors that often go forgotten, an accurate estimate may seem impractical.\nThere’s still several ways to get an idea of the overall project cost before getting started.\nTake a look at the approaches below to gather a shortlist of the major line items that go into a house siding project.\nCost of Siding by Square Foot\nCalculating house siding cost by square foot is the most comprehensive option. Given that it takes into consideration everything from specific house siding measurements, soffits, trim and more, there won’t be much left to account for.\nIf you’re struggling to figure out how to measure for siding or how much siding you need, no worries.\nHere’s a thorough siding calculator method by Lowe’s with a step-by-step guide:\n- Start by measuring the height and width of each side of the home, multiplying the two numbers to get each side’s surface area. Now add all the sums of each side to get the total in square feet for your siding.\n- Take note of special areas not measured in the siding itself such as gables. For triangular measurements such as this, measure from bottom to top, multiplying that by half the base length. Now add those measurements.\n- Now, measure all windows and doors by multiplying height and width to find the surface area as done to calculate the siding. Add all of the sums of each surface area together for a total.\nWith these three measurements in mind, add the totals from the first two lines and subtract the total from the third line. Now you have your total square footage needed in siding. There’s still a few more materials to consider though.\n- Soffits, the underside of a roof’s overhang, will also need to be worked into the equation. Again, measure each section of soffits, multiplying height and width to find the surface area.\n- The last measurement is for trim. Measure each area you’d like to add trim and record the amount you’ll need in feet.\nIf doing the totals on paper seems intimidating, use the Lowe’s link above for their siding estimate calculator that lets you enter your numbers and tabulates them for you in real-time.\nCost by Siding Material\nHere are some of the house siding costs for the most common siding types per square foot. This cost includes both materials and labor.\n|Material||Total average range cost per square foot for labor and materials|\n|Vinyl||$3-$11 per square foot|\n|Wood||$4-$13 per square foot|\n|Aluminum||$3-$11 per square foot|\n|Engineered Wood||$3.50-$8.50 per square foot|\n|Fiber Cement||$5-$19 per square foot|\n|Brick||$7-$15 per square foot|\n|Stucco||$4-$8 per square foot|\n|Steel||$3-$10 per square foot|\n|Stone||$10-$45 per square foot|\n|Cedar Shake||$6.50-$13.50 per square foot|\nSiding Factors to Consider\nThere are many considerations when thinking about what kind of siding would work best for you.\n- Style Considerations – You should consider the siding type that you like the most when you are deciding which siding to buy. If you like your siding, you will value it more. It is also important to understand how the siding you like best compares to other options.\n- Size of Your Home – The larger size house you have, the more expensive siding will cost.\n- Complicated House Shapes – If your home has intricate bends, curves, and cut-outs, the labor costs for siding these houses will be more than for simple styles.\n- Local Labor Costs – Depending on available labor in your area, the costs will be higher in city areas.\n- Removal of Old Siding – If you have old siding that needs to be removed, it will increase your labor costs.\n- Architectural Style of Your Home – You should consider the style of your home when thinking about which siding to choose. If you have a large, historic home, the best kind of siding would be in keeping with the style of the home.\n- Climate – Some homes will need moisture barriers if they are in wet areas that will increase the cost. Also, they will need a siding like fiber cement that stands up well to this. Others in hot climates will function best with steel or aluminum siding.\n- Maintenance – Decide how much maintenance you are willing to do before you decide on your siding. For example, wood siding requires painting or staining on a regular basis in order to keep looking good. Metal sidings require little in the way of maintenance.\nHouse Siding Cost by Types\nHouse siding costs vary by type according to the cost of the materials and the kind of labor and supplies needed to add the siding.\nVinyl siding is a popular siding material in the United States and abroad. It is made from polyvinyl chloride and is made to mimic other materials like wood. It is the most cost-effective siding type and functions well in terms of durability. Vinyl siding prices differ depending on the thickness of the vinyl panel.\nAlong with the vinyl siding itself, you need to plan for the trim including the undersill, the starter strip, and J-channels. Here is a handy vinyl siding cost calculator to help you calculate the full cost for your home.\n- Vinyl Siding Cost – $1.50-$8.50 per square foot\n- Installation Costs for Vinyl Siding – $.90-$1.20 per square foot\nWood siding has a natural and textured look that many sidings try to replicate, but it also has higher maintenance than siding like vinyl or metal. This includes regular painting or staining and termite management.\nOne of the most popular types of natural wood siding is clapboard siding. Manufacturers use wood such as oak, pine or spruce. Pine is the least expensive and redwood the most expensive type of wood siding. If you maintain it, natural wood siding will last up to 40 years.\n- Cost of Wood Siding – $2-$15 per square foot (depending on the type of wood)\n- Installation Costs for Wood Siding – $1.06-$2.50 per square foot\nAluminum siding is one of the most cost-effective metal siding options available. It has been a popular siding choice because it is lightweight, eco-conscious, and easy to work with. It is also durable. It will withstand pests, harsh weather, and resists corrosion from moisture. Aluminum siding comes in the form of flat or corrugated sheets.\n- Cost of Aluminum Siding – $1.75-$7 per square foot\n- Installation Costs for Aluminum Siding – $4.40 per square foot\nEngineered Wood Siding\nEngineered wood is composite siding that manufacturers create from wood particles mixed with resin and plastics. They mold this into siding boards. These can have an embossed texture that resembles natural wood texture or can have a smooth finish. These boards are durable, inexpensive, and will last between 20-30 years.\n- Cost of Engineered Wood Siding – $2-$4 per square foot\n- Installation Costs for Engineered Wood Siding – $1-$6 per square foot\nFiber Cement Siding\nFiber cement siding, also known as Hardie board, is a siding made from a composite of sand and cement. It is very durable and rot, fire, and insect resistant. It comes in many different forms including shingles, boards, and siding. Plank siding is the least expensive and boards are the most expensive. Most fiber cement siding lasts for up to 50 years.\n- Cost of Fiber Cement Siding – $1-$15 per square foot (depending on which form of siding you choose)\n- Installation Costs for Fiber Cement Siding – $4-$8.50 per square foot\nBrick is a classic siding type that comes in various colors and depths. You can have full-sized bricks installed or use thinner brick veneer which is more cost-effective. Brick is durable and resistant to rot and weather. Brick is also a natural insulator and will help keep your home more energy efficient. There are also minimal maintenance concerns for around 25 years. After this, you will need to inspect the masonry joints to see if they require any repairs.\n- Cost of Brick Siding – $3-$10 per square foot\n- Installation Costs for Brick Siding – $3-$20 per square foot\nStucco is a sand and cement based siding that is ideal for homes in dry climates. It is a durable, energy-efficient, and eco-conscious choice. It also has an old-world look that works well on homes with Mediterranean styles. It is not ideal for homes in wet and humid climates.\n- Cost of Stucco Material – $5-$6 per square foot\n- Installation Costs for Stucco Siding – $2.50 per square foot\nSteel siding is a durable metal siding that looks great in industrial or rustic settings. While it is a low maintenance siding, it does help to coat it with a rust-resistant layer. Steel siding is more durable than aluminum but also more expensive. It is crafted to mimic the look of wood, but it will still look like steel.\n- Cost of Steel Siding – $4-$6 per square foot\n- Installation Costs for Steel Siding – $3.50 per square foot\nStone siding is one of the most classic types of siding available. You can choose either natural stone or stone veneer for a less expensive option. This type of siding requires little to no maintenance and will last over time. It also resists pests, rot, and fire. The cost depends on the type of natural stone you choose. Slate is the least expensive and granite is one of the most expensive. =\n- Cost of Veneer Stone for Siding – $4-$21 per square foot\n- Installation Costs for Steel Siding – $6 -$24 per square foot\n- Cost of Natural Stone for Siding – $4.50-$30 per square foot\n- Installation Costs for Steel Siding – $3 -$15 per square foot\nCedar Shake Siding\nCedar is one of the best quality wood siding options for anyone who loves the look and texture of natural wood. Cedar shakes have a rustic quality with gorgeous color variations. This wood is insect and rot-resistant. Cedar is an eco-conscious choice as it is biodegradable and sustainable. You can paint or stain your cedar shakes or even leave them untreated if you prefer a more natural look.\n- Cost of Cedar Shake Siding – $4-$8 per square foot\n- Installation Costs of Cedar Shake Siding – $1.70 -$5 per square foot\nCost of Repair vs Replacement\nIf the siding on your home has yet to reach its lifespan, repairing it may still be an option depending on the extent of the damage. While the cost to repair averages around $500, that hinges on the type of siding and what issues you’re dealing with. Here’s some of the most common repairs made to siding and their average cost:\n- Mold ranges from $500 to $700.\n- Cracks range from $50 to $150.\n- Water damage ranges from $500 to $600.\n- Dents range from $100 to $300$.\nFrequently Asked Questions (FAQ)FAQ\nWhen does siding need to be replaced?\nSiding that needs replacing will start to show obvious signs, some with more impact than others. For example, fading, rotting, and bubbling are common signs your siding may need replacing. Likewise, warping or loose boards aren’t unusual when siding is older. One of the biggest signs though is a higher electric bill. This is a tell-tale sign your siding isn’t doing its job.\nWhat’s the most popular siding material?\nWhile some siding selections are more popular region to region, it’s safe to say vinyl siding is most popular overall. Being that it’s one of the most affordable options, it comes as a first choice to most. Not to mention, it’s a low maintenance siding, which is without doubt an attractive quality to homeowners.\nWhat does it mean to purchase a square of siding?\nWhen purchasing siding you’ll hear the term “square” used a lot. In short, it’s how siding is measured. One square of siding is 100 square feet of siding material. Though the term siding square is more common to use when referring to how to measure for vinyl siding, it’s still used among other materials as well. Using a house siding calculator like the Lowe’s siding calculator will provide you with how many squares your project will need.\nWhich siding is easiest to maintain?\nThere’s several siding options that are easy to maintain but vinyl and metal appear to be the easiest by far. Both resist common siding problems like mold and pests, making for less repairs. They also require little in the way of cleaning. An annual power wash with mild soap and a soft brush for spot treatment on areas that may need it will keep your siding looking good as new.\nHow long will it take to replace siding?\nThe timeline to re-side a house seems to range based on who you talk to. Factors such as demand, weather, removal and material selection can play a role in this timeframe too. Regardless, the average project ranges from one to two weeks.\nHouse siding cost can be easy to estimate with the right resources. With several methods at your disposal, there’s no doubt you can get an accurate price without missing any major components.\nLikewise, certain factors like material and design can offer flexibility in price, making even the most modest of budgets simple to work with.\nTake the first step toward your dream home exterior and start calculating your cost today.']	['<urn:uuid:480c4d9a-16f4-472b-a46a-ed622742ae80>', '<urn:uuid:2a234d3b-cefc-4646-95e9-b2f1800a207f>']	open-ended	direct	verbose-and-natural	distant-from-document	multi-aspect	novice	2025-05-12T15:09:02.012753	19	88	2868
48	differences between old new methods studying genes muscles lab research explained simple terms	Traditional methods for gene analysis used single-linkage clustering which examined entire data matrices, making it computationally expensive and susceptible to noise. The newer approach focuses only on the significant diagonal area of genetic similarity matrices, making it faster and more accurate in identifying true evolutionary patterns. In muscle cell research, older methods were highly variable between species and often required complex procedures like pre-plating or multiple enzymes to isolate satellite cells. The new simplified method uses just one enzyme (pronase) and direct plating onto collagen-coated flasks, making it both faster and more standardized across different species. This new approach eliminates the need for complex pre-plating steps or Percoll centrifugation to remove contaminating fibroblasts, while still achieving excellent cell fusion rates of over 50% in most species studied.	"['Your data are represented in form of a matrix? X-axis as well as Y-axis of this matrix are somehow equally ordered? Further you know that the data within your matrix are the less related to each other the more distant they are with respect to the involved order. Then have a look to the two clustering techniques proposed over here. They deliver results similar to single-linkage clustering, but have a much better asymptotic time complexity. Further they give you better fine control with respect to cluster extensions than single-linkage clustering.\nWe present these techniques embedded into biocomputational genomics. But this is only one of many application fields.\nIn the context of our genomic research we got interested in some quite simple question: “If we align all orthologs of some given gene with respect to a bunch of available genomes, what picture will we see?” In our special case it was the gene FAM72 and we were interested in getting some rough picture of the evolutionary development and extension of this gene. So, we picked all orthologs of FAM72 from the NCBI-data pool and aligned all these orthologs with respect to the genomes of several hundred eukaryotic species. We restricted our view to the CDS, because for our purposes it was simply enough. So, we aligned all Exons of all protein coding transcripts of a given ortholog and computed the medium value of all scores that we received as outcome of these alignments. Finally, we organized all these scores in form of a matrix with species on the Y-axis and ortholgs on the X-axis and visualized the resulting matrix via a Klee diagram (heat map). The X-axis as well as the Y-axis of this matrix were taxonomically sorted, were the sorting resulted from an in-order tree traversal of the NCBI-taxonomy. The computed picture looked as follows:\nFirst, this diagram tells us that FAM72 occurs in vertebrates exclusively. But second, much more interesting, within vertebrates FAM72 decomposes into four major clusters. Not surprising, these four clusters correspond to the four species groups (Euteleosteomorpha, Lepidosauria, Archelosauria, Mammalia) within vertebrates. But within these clusters we see subclusters as well as tiny clusters sometimes in-between these four major blocks. So, how many clusters are in this diagram altogether? In order to answer this question you typically rely on a standard algorithmic approach like single-linkage-clustering. You define your parameters, thresholds, do your clustering and look, count, compare watching the outcome of the algorithmic process.\nSingle-linkage-clustering inspects each element of your matrix. So, its runtime is proportional to the overall size of your matrix. But, if we look to the above Klee-diagram, then we can observe that the significant part is only around the red diagonal spanning form top-left to bottom-right within vertebrates. This diagonal will mainly drive the resulting clustering process. And there we have our idea: Instead of inspecting the complete matrix, we only inspect the area around the red-diagonal. Obviously, such a limitation of the inspected area reduces the computational costs significantly. But more interesting, it allows fine tuning with respect to taxonomic cluster alignment that is superior to single-linkage-clustering. This can be explained as follows: Single-linkage-clustering is, due to the inspection of the overall matrix, prone to noise within the vicinity of the central red diagonal. Such noise can result from low quality gene predictions or faulty assemblies. A strong focus on the diagonal itself “blanks out” this noise and the resulting cluster can be better aligned with respect to the basic taxonomy.\nFig. 2 contains two diagrams that shall give an impression of the problem. On the left side you see the clustering of FAM72 for single-linkage clustering. On the right side you see what you get with our proposed clustering algorithm. The clusters are visualized as grey boxes, where the upper part of the box (the part above the red diagonal) is removed for improved visibility.\nBoth diagrams of Fig. 2 are fine tuned with the intention that the major clusters are maximally close to the extensions of the respective species groups. The right diagram is almost perfect with respect to this property. But for single-linkage-clustering we run into the following problems: If we switch to a threshold below 25, then Archelosauria and Mammalia are joined in one cluster. For a value above 25 the clusters Archelosauria and Mammalia shrink even more. Further, for a threshold of 25 there is no cluster with Lepidosauria. So, in fact you can not find a threshold that delivers the same perfect clustering like for our approach.\nSeeing this diagram for FAM72, there popped up another question “How does this Klee-diagram for FAM72 look compared to diagrams of other genes? What cluster structures do we have over there?” So, we selected a thousand genes and computed the required alignment matrices (scoring matrices) for all these genes. Generously, our school paid the electric bill and NCBI didn’t blacklist our steadily sucking computational nodes.\nFAM72 proved to be rather boring. Its clustering resembles this of many other stable genes, where the clustering reflects more or less the tree of life merely. However, using our fast clustering scheme we were computationally digging for the “crazy” ones. For example genes, where the resulting cluster structure somehow violates the phylogeny of the classic tree of life. Or genes with unusual many clusters compared to the average for all others. Naturally, we found some of these.\nNow we present one of our findings, the gene MSTN, where the cluster structure violates the tree of life. But first have a look to Fig. 3.\nThe clustering in Fig. 3 violates the phylogeny of the classic tree of life (we used the NCBI-taxonomy in the context of our work) obviously with vespertilionidae. Batman’s best friends, seem to have a very special form of MSTN. It has mutated so heavily, compared to its evolutionary (taxonomic) neighbors, that the light grey cluster spanning over mammals is broken at this position. If we look into the NCBI-summary of human MSTN, we can find the statement “Mutations in this gene are associated with increased skeletal muscle mass in humans and other mammals.” This allows the assumption that our little flying relatives are quite special with respect to muscle development. Looking into the involved mutations might fulfill bodybuilder’s hottest dreams. But, who knows?\nWhat’s important is that such violations can be found computationally. We simply have to check whether there is a contradiction between taxonomy and clustering. In more detail: We have to check that for all clusters C (the grey boxes cut to half) the extension of C does not simultaneously fully covers one species group and partially covers a neighboring species group. In the above diagram the upper light grey cluster spanning over diapsidis extends into mammals but not fully spans over mammals. This constitutes exactly such kind of previously mentioned violation.\nTechniques – Algorithmic Approaches\nWe will no present some basic techniques and ideas of our proposed form of clustering. First of all there is the question “How do we know the position of the red diagonal?” Now, we have to transform our matrix so that the diagonal becomes a straight 45 degree line in the matrix’s center. This is the case for a matrix with exactly the same taxonomically sorted list of species on X-axis as well as Y-axis. We get such a squared matrix by inserting species not occurring on the Y-axis into the X-axis and, vice versa, inserting species not occurring on the Y-axis into the X-axis, where all freshly created rows and columns are filled with a value that is equal to “no data available”. The matrix of Fig. 4 shows such an extend matrix in the of our FAM72 example. The black areas represent non-existing data.\nAfter cluster computation we can remove these blank areas without much reasoning. However, in the context of the clustering process we have to cope appropriately with these blank spots. We do so be cleverly inspecting the environment of a blank spot for available data and inferring data for within on the foundation of what we see around. Details can be found in the publication that belongs to this blog.\nIn the context of core clustering you can choose among a hierarchical approach and a non-hierarchical one. The hierarchical approach is the computationally more expensive one having a Θ(n log n) complexity, where n is the size of each axis of the matrix (the matrix is squared). Algorithmically it performs clustering by a sequence of hierarchically ordered unions of disjoint sets. The strategy strongly resembles Kruskal’s algorithm for minimum spanning trees. The order used throughout clustering has to be created by stable sorting. With respect to complexity considerations this sorting is the most expensive part of the overall complexity. Because the algorithmic approach is hierarchical we get a dendrogram additional to the clustering.\nThe non-hierarchical linear-time approach follows a completely different path. Here we do the clustering by a simple right to left scan over the central diagonal, where the cluster construction itself happens on the foundation of a stack (keeping cluster start-positions) in combination with a threshold, which controls cluster ejection. It resembles somehow stack based parsing techniques that we know from the area of syntax analysis. Naturally, such a scan can be done in Θ(n), where n is the dimension of the squared matrix.\nIn the context of a quality evaluation we could prove that both approaches deliver almost equal clusters. First this might appear a bit surprising. But, if we strip the hierarchic approach its hierarchic behavior, it becomes visible that the stack performs a job equal to the repeated unions of disjoint sets.\nClustor is a Java-application that implements the proposed clustering scheme. It has a small GUI, where you can select a matrix (see the program documentation for more info about the matrix format) and set several clustering parameters. The outcome of the clustering can be requested in visualized form, delivering diagrams as shown over here. Further, these diagrams can be stored as PNG-files for further processing.\nClustor is open source and licensed under the GPL.\nSource files as well as the executable jar file of the reference implementation can be obtained here:\nClustor Verison 1.0 (zip-file)\nThe application does not perform alignments. It loads already prepared scoring-matrices that have to be available via the Excel-XML format. Some already prepared Excel-XML files are available for download over here:\nExcel-XML Example Scoring Matrices (zip-file)\nA more detailed presentation of our clustering approach has been submitted for journal publication. However, if you want to know more just now, please contact waywatcher1(at)web.de or kutzner(at)hanyang.ac.kr for more info.', ""A simplified but robust method for the isolation of avian and mammalian muscle satellite cells\nCurrent methods of isolation of muscle satellite cells from different animal species are highly variable making inter-species comparisons problematic. This variation mainly stems from the use of different proteolytic enzymes to release the satellite cells from the muscle tissue (sometimes a single enzyme is used but often a combination of enzymes is preferred) and the different extracellular matrix proteins used to coat culture ware. In addition, isolation of satellite cells is frequently laborious and sometimes may require pre-plating of the cell preparation on uncoated flasks or Percoll centrifugation to remove contaminating fibroblasts. The methodology employed to isolate and culture satellite cells in vitro can critically determine the fusion of myoblasts into multi-nucleated myotubes. These terminally differentiated myotubes resemble mature myofibres in the muscle tissue in vivo, therefore optimal fusion is a keystone of in vitro muscle culture. Hence, a simple method of muscle satellite cell isolation and culture of different vertebrate species that can result in a high fusion rate is highly desirable.\nWe demonstrate here a relatively simple and rapid method of isolating highly enriched muscle satellite cells from different avian and mammalian species. In brief, muscle tissue was mechanically dissociated, digested with a single enzyme (pronase), triturated with a 10-ml pipette, filtered and directly plated onto collagen coated flasks. Following this method and after optimization of the cell culture conditions, excellent fusion rates were achieved in the duck, chicken, horse and cow (with more than 50% cell fusion), and to a lesser extent pig, pointing to pronase as a highly suitable enzyme to release satellite cells from muscle tissue.\nOur simplified method presents a quick and simple alternative to isolating highly enriched muscle satellite cell cultures which can subsequently rapidly differentiate into well developed primary myotubes. The use of the same isolation protocol allows better inter-species comparisons of muscle satellite cells. Of all the farm animal species investigated, harvested chicken muscle cells showed the highest percentage of muscle satellite cells, and equine muscle cells presented the highest fusion index, an impressive ≈ 77%. Porcine cells displayed the lowest amount of satellite cells but still achieved a modest fusion rate of ≈ 41%.\n- Campion DR: The Muscle Satellite Cell - a Review. Int Rev Cytol A Surv Cell Biol 1984, 87:225–251.\n- Mauro A: Satellite Cell of Skeletal Muscle Fibers. J Biophys Biochem Cytol 1961,9(2):493. CrossRef\n- Hill M, Wernig A, Goldspink G: Muscle satellite (stem) cell activation during local tissue injury and repair. J Anat 2003,203(1):89–99. CrossRef\n- Winchester PK, Davis ME, Alway SE, Gonyea WJ: Satellite Cell Activation in the Stretch-Enlarged Anterior Latissimus-Dorsi Muscle of the Adult Quail. Am J Physiol 1991,260(2):C206-C212.\n- Grounds MD: Age-associated changes in the response of skeletal muscle cells to exercise and regeneration. Towards Prolongation of the Healthy Life Span 1998, 854:78–91.\n- Bischoff R: Enzymatic Liberation of Myogenic Cells from Adult Rat Muscle. Anat Rec 1974,180(4):645–661. CrossRef\n- Blau HM, Webster C: Isolation and Characterization of Human-Muscle Cells. Proc Natl Acad Sci U S A Biol Sci 1981,78(9):5623–5627. CrossRef\n- Yablonka-Reuveni Z, Quinn LS, Nameroff M: Isolation and Clonal Analysis of Satellite Cells from Chicken Pectoralis-Muscle. Dev Biol 1987,119(1):252–259. CrossRef\n- Mcfarland DC, Doumit ME, Minshall RD: The Turkey Myogenic Satellite Cell - Optimization of Invitro Proliferation and Differentiation. Tissue Cell 1988,20(6):899–908. CrossRef\n- Greene EA, Raub RH: Procedures for Harvesting Satellite Cells from Equine Skeletal-Muscle. J Equine Vet Sci 1992,12(1):33–35. CrossRef\n- Dodson MV, Martin EL, Brannon MA, Mathison BA, Mcfarland DC: Optimization of Bovine Satellite Cell-Derived Myotube Formation Invitro. Tissue Cell 1987,19(2):159–166. CrossRef\n- Dodson MV, McFarland DC, Martin EL, Brannon MA: Isolation of satellite cells from ovine skeletal muscles. Methods Cell Sci 1986,10(4):233–237.\n- Doumit ME, Merkel RA: Conditions for Isolation and Culture of Porcine Myogenic Satellite Cells. Tissue Cell 1992,24(2):253–262. CrossRef\n- Kubis HP, Haller EA, Wetzel P, Gros G: Adult fast myosin pattern and Ca2 + −induced slow myosin pattern in primary skeletal muscle culture. Proc Natl Acad Sci U S A 1997,94(8):4205–4210. CrossRef\n- Huard J: Gene therapy and tissue engineering based on muscle derived stem cells: Potential for tissue regeneration. Abstr Paper Am Chem Soc 2004, 227:U136-U136.\n- Cerletti M, Jurga S, Witczak CA, Hirshman MF, Shadrach JL, Goodyear LJ, Wagers AJ: Highly efficient, functional engraftment of skeletal muscle stem cells in dystrophic muscles. Cell 2008,134(1):37–47. CrossRef\n- Deasy BM, Yong LI, Huard J: Tissue engineering with muscle-derived stem cells. Curr Opin Biotechnol 2004,15(5):419–423. CrossRef\n- Blau HM: Cell Therapies for Muscular Dystrophy. N Engl J Med 2008,359(13):1403–1405. CrossRef\n- Edelman PD, McFarland DC, Mironov VA, Matheny JG: In vitro-cultured meat production. Tissue Eng 2005,11(5–6):659–662. CrossRef\n- Datar I, Betti M: Possibilities for an in vitro meat production system. Innovat Food Sci Emerg Tech 2010,11(1):13–22. CrossRef\n- Yablonka-Reuveni Z: Isolation and characterization of stem cells from adult skeletal muscle. In Handbook of stem cells. Edited by: Lanza RP, Blau HM, Gearhart J, Melton DA, Moore MAS, Pedersen R, Thomas ED, Thomson J, Verfaillie CM, Weissman IL, West MD. San Diego: Elsevier-Academic Press; 2004:571–580. CrossRef\n- Seale P, Sabourin LA, Girgis-Gabardo A, Mansouri A, Gruss P, Rudnicki MA: Pax7 is required for the specification of myogenic satellite cells. Cell 2000,102(6):777–786. CrossRef\n- Holzer N, Hogendoorn S, Zurcher L, Garavaglia G, Yang S, Konig S, Laumonier T, Menetrey J: Autologous transplantation of porcine myogenic precursor cells in skeletal muscle. Neuromuscul Disord 2005,15(3):237–244. CrossRef\n- Wilschut KJ, Haagsman HP, Roelen BAJ: Extracellular matrix components direct porcine muscle stem cell behavior. Exp Cell Res 2010,316(3):341–352. CrossRef\n- Fernandez MS, Dennis JE, Drushel RF, Carrino DA, Kimata K, Yamagata M, Caplan AI: The Dynamics of Compartmentalization of Embryonic Muscle by Extracellular-Matrix Molecules. Dev Biol 1991,147(1):46–61. CrossRef\n- Bullaro JC, Brookman DH: Comparison of Skeletal-Muscle Monolayer-Cultures Initiated with Cells Dissociated by Vortex and Trypsin Methods. In Vitro J Tiss Cult Assoc 1976,12(8):564–570.\n- Caplan AI: A simplified procedure for preparing myogenic cells for culture. J Embryol Exp Morphol 1976,36(1):175–181.\n- O'Neill MC, Stockdale FE: A kinetic analysis of myogenesis in vitro. J Cell Biol 1972,52(1):52–65. CrossRef\n- Woods TL, Smith CW, Zeece MG, Jones SJ: Conditions for the culture of bovine embryonic myogenic cells. Tissue Cell 1997,29(2):207–215. CrossRef\n- Benders AAGM, Vankuppevelt THMSM, Oosterhof A, Veerkamp JH: The Biochemical and Structural Maturation of Human Skeletal-Muscle Cells in Culture - the Effect of the Serum Substitute Ultroser-G. Exp Cell Res 1991,195(2):284–294. CrossRef\n- Halevy O, Piestun Y, Allouh MZ, Rosser BWC, Rinkevich Y, Reshef R, Rozenboim I, Wleklinski-Lee M, Yablonka-Reuveni Z: Pattern of Pax7 expression during myogenesis in the posthatch chicken establishes a model for satellite cell differentiation and renewal. Dev Dyn 2004,231(3):489–502. CrossRef\n- Barani AE, Sabido O, Freyssenet D: Mitotic activity of rat muscle satellite cells in response to serum stimulation: relation with cellular metabolism. Exp Cell Res 2003,283(2):196–205. CrossRef\n- Alexander LS, Mahajan A, Odle J, Flann KL, Rhoads RP, Stahl CH: Dietary Phosphate Restriction Decreases Stem Cell Proliferation and Subsequent Growth Potential in Neonatal Pigs. J Nutr 2010,140(3):477–482. CrossRef\n- Yablonka-Reuveni Z, Nameroff M: Temporal Differences in Desmin Expression between Myoblasts from Embryonic and Adult Chicken Skeletal-Muscle. Differentiation 1990,45(1):21–28. CrossRef\n- Dodson MV, McFarland DC, Grant AL, Doumit ME, Velleman SG: Extrinsic regulation of domestic animal-derived satellite cells. Domest Anim Endocrinol 1996,13(2):107–126. CrossRef\n- Soeta C, Yamanouchi K, Hasegawa T, Ishida N, Mukoyama H, Tojo H, Tachi C: Isolation of Satellite Cells from Equine Skeletal Muscle. J Equine Sci 1998,9(3):97–100. CrossRef\n- Byrne KM, Vierck J, Dodson MV: In vitro model of equine muscle regeneration. Equine Vet J 2000,32(5):401–405. CrossRef\n- Muroya S, Nakajima I, Chikuni K: Bovine skeletal muscle cells predominantly express a vascular cell adhesion molecule-1 seven-Ig domain splice form. Zoolog Sci 2001,18(6):797–805. CrossRef\n- Cassar-Malek I, Langlois N, Picard B, Geay Y: Regulation of bovine satellite cell proliferation and differentiation by insulin and triiodothyronine. Domest Anim Endocrinol 1999,17(4):373–388. CrossRef\n- Allen RE, Rankin LL, Greene EA, Boxhorn LK, Johnson SE, Taylor RG, Pierce PR: Desmin is present in proliferating rat muscle satellite cells but not in bovine muscle satellite cells. J Cell Physiol 1991,149(3):525–535. CrossRef\n- Sultan KR, Henkel B, Terlou M, Haagsman HP: Quantification of hormone-induced atrophy of large myotubes from C2C12 and L6 cells: atrophy-inducible and atrophy-resistant C2C12 myotubes. Am J Physiol Cell Physiol 2006,290(2):C650-C659. CrossRef\n- Blanton JR, Grant AL, McFarland DC, Robinson JP, Bidwell CA: Isolation of two populations of myoblasts from porcine skeletal muscle. Muscle Nerve 1999,22(1):43–50. CrossRef\n- Snow MH: The effects of aging on satellite cells in skeletal muscles of mice and rats. Cell Tissue Res 1977,185(3):399–408. CrossRef\n- Brack AS, Bildsoe H, Hughes SM: Evidence that satellite cell decrement contributes to preferential decline in nuclear number from large fibres during murine age-related muscle atrophy. J Cell Sci 2005,118(20):4813–4821. CrossRef\n- Shefer G, Van de Mark DP, Richardson JB, Yablonka-Reuveni Z: Satellite-cell pool size does matter: Defining the myogenic potency of aging skeletal muscle. Dev Biol 2006,294(1):50–66. CrossRef\n- Gibson MC, Schultz E: Age-Related Differences in Absolute Numbers of Skeletal-Muscle Satellite Cells. Muscle Nerve 1983,6(8):574–580. CrossRef\n- Carlson BM, Faulkner JA: Muscle Transplantation between Young and Old Rats - Age of Host Determines Recovery. Am J Physiol 1989,256(6):C1262-C1266.\n- Schultz E, Lipton BH: Skeletal-Muscle Satellite Cells - Changes in Proliferation Potential as a Function of Age. Mech Ageing Dev 1982,20(4):377–383. CrossRef\n- Renault V, Piron-Hamelin G, Forestier C, DiDonna S, Decary S, Hentati F, Saillant C, Butler-Browne GS, Mouly V: Skeletal muscle regeneration and the mitotic clock. Exp Gerontol 2000,35(6–7):711–719. CrossRef\n- Shavlakadze T, McGeachie J, Grounds MD: Delayed but excellent myogenic stem cell response of regenerating geriatric skeletal muscles in mice. Biogerontology 2010,11(3):363–376. CrossRef\n- Allen RE, TemmGrove CJ, Sheehan SM, Rice G: Skeletal muscle satellite cell cultures. Methods Cell Biol 1997, 52:155–176. CrossRef\n- A simplified but robust method for the isolation of avian and mammalian muscle satellite cells\n- Open Access\n- Available under Open Access This content is freely available online to anyone, anywhere at any time.\nBMC Cell Biology\n- Online Date\n- June 2012\n- Online ISSN\n- BioMed Central\n- Additional Links\n- Muscle satellite cells\n- Primary skeletal muscle cultures\n- α-sarcomeric actin\n- Fusion index""]"	['<urn:uuid:0a89042e-235f-40e5-b638-28622e95b584>', '<urn:uuid:4062e030-c34f-4559-a8ba-149bd596a6b7>']	open-ended	with-premise	long-search-query	distant-from-document	multi-aspect	novice	2025-05-12T15:09:02.012753	13	127	3457
49	altitude gain copper mountain uneva pass	From Copper Mountain at around 9700 feet, the trail reaches an elevation just under 12,000 feet somewhere above Uneva pass.	['09 Jul Gore Ridge Trail – Copper Mountain to Frisco\nOn July 9th at about 7 AM, Sandra dropped me off at Wheeler Flats near Copper Mountain. I hiked about 12 miles from Copper Mountain to Frisco on the Gore Range and North Ten Mile trails. I started at an elevation around 9700 feet and reached an elevation just under 12,000 feet somewhere above Uneva pass.\nI didn’t see any other hikers on Gore Range trail; however, I ran into several campers (out and back hike) just short of Uneva Pass. There were a number of hikers on North Ten Mile trail.\nTraveling west on I-70, take the exit to Copper Mountain. If someone is dropping you off and traffic isn’t heavy, have them pull over at the far end of the exit ramp just before the bridge across I-70. The sign for the trail head is alongside I-70 just down the embankment from the road.\nThis is a great point to point hike for someone staying in Frisco. You come out on I-70 just opposite Main Street in Frisco.\nHere is a view of Copper Mountain.\nMost water was easily crossed like the stream shown below. There was one boggy area at least 50 yards across where there was no choice but to plunge in over the top of my boots.\nHere you can see that trail disappears in snow on hike toward Uneva Pass.\nClosing in toward Uneva pass I had to cross hollowed out snow. Here you can see where I broke through, about a 2 foot drop.\nWest of Uneva Pass. The pass would be to the left of the photo. This is the mountain above the pass to the south.\nBelow is a snow Cornice spanning west side of Uneva pass. I walked east on and off the trail to the smallest portion of the cornice, but decided against following some tracks over the top. The slope below was steep and there was also a small dropoff below the cornice at this point. I bypassed the cornice by crossing the slope the full length of the cornice to the north until I could make my way around the cornice well above the gap.\nBelow: North of Uneva Pass. Uneva pass is below and low point along ridge straight ahead. This is the point where I came out after making my way around the snow cornice.\nSome snow after crossing Uneva Pass. Just northeast of Unveva Pass.\nHere is an alpine lake northeast of Uneva Pass.\nCairns mark the way in the open areas beyond Uneva Pass.\nBelow you can see boulders strewn across grass below heavily bouldered slope. Located on descent well east beyond Uneva Pass where I am about to enter forested portion of Gore Range Trail.\nLong descent toward North Ten Mile trail through sun protected forested slope had many areas of large snow piles obstructing trail. The tread of the trail was not easily picked out in many places and crossing so much snow made it difficult to know whether I was following a drainage or a trail. There was the reassurance of one set of footprints that were sometimes visible in these piles of snow.']	['<urn:uuid:01f76d4e-39d9-4fea-bd4e-2e2623b5719f>']	factoid	direct	short-search-query	distant-from-document	single-doc	expert	2025-05-12T15:09:02.012753	6	20	534
50	prevent deep scratches during automotive headlamp wet sanding procedure	When sanding headlights, continuously spray water on both the sandpaper and headlight surface. The water acts as a lubricant to prevent deep scratches. Apply light pressure and sand in circular motions.	['How to Restore Car Headlights\nOne of the most common problems faced by car owners is the front Hazy Oxidized Yellowish headlights. The rear headlights can also be affected; we will specifically address the front ones. Out of 100%, headlights hold about 40% of a car’s appeal. If they are shiny and tidy, it will draw a lot of attention. If they are dirty and ugly, your car would not even look hideous, but it would also decrease the overall value of your car.\nFor fixing the old headlights, there are a lot of methods on the internet that can be used to clean your headlights such as cleaning kits, using baking soda, vinegar, toothpaste and etc. All these methods might do the job but they are all temporary, and the Hazy Yellowish effect comes back over time.\nThe following method, however, is a permanent one and requires no maintenance i.e. adding wax or sealer in the future, what so ever.\n- Pair of Scissors\n- Garbage Bags\n- Insulation Tape (wide)\n- Paper Towel\n- Sand Paper (P400, P600, P2000 Grit)\n- Water Spray (for wet sanding)\n- Alcohol (cleaning purposes)\n- Clear Coat (Gloss clear)\n- If the headlights can be easily removed from your car, do remove them, it is easy that way. If not, no problem, you can restore them without removing as well.\n- If the headlights are in a very bad condition, start sanding with P400 grit, if not, start with P600 grit. P400 is a lot coarse while P600 is fine. Final touches would be given by P2000 grit, which is super fine.\n- Since I was not able to remove the headlight from my car, I started using tape all around the headlight so that the body of the car does not get damaged with sanding as shown in the image below.\n- It is now time for sanding with P400 grit. My car’s headlight is in a pretty bad condition that is why I’m using P400 first.\n- When sanding, we will keep spraying the sandpaper as well as the surface of the headlight. The water acts as a lubricant and prevents deep scratches. During sanding do not press hard. Also, sand in circular motion.\n- While sanding, you would notice the yellowish oxidised plastics coming off with water. Also, remember to sand all the edges and corners of the headlights properly.\n- Keep sanding till all the light scratches are in horizontal position, and the headlights look milky and hazy. The reason why we are doing horizontal motion sanding is because when clear coat is applied, it won’t slide down easily and would hold to the horizontal edges that we just created as shown below;\n- Now it is time to use P600grit, get the sandpaper and the surface of the headlights soaking wet and start sanding.\n- With P600 you can press a little bit harder in a circular motion first and then horizontal motion, just like P400.\n- Now we will use P2000 grit as a final stage of sanding. But before that, clean the headlight’s surface with water.\n- After sanding, you would notice small scratches and hazy effect but its normal, you want it to be that way.\n- First, dry it with a paper towel and then clean it with alcohol soaked paper towel.\n- Now it’s time to apply the clear coat. Since my headlights are fixed, first I’ll tape the garbage bag around the headlight. We are protecting the body of the car from over spraying.\n- Clean the surface of the headlight again. And then start clear coating.\n- When spraying, keep the spray thin, as thick coats wear off with time.\n- Now let it dry for 5 minutes.\n- Re-apply the coat, make sure it reaches all the edge and let it dry.\n- Finally, reapply another coat and let it dry for 24 hours. Also, you may add wax and buff it for more shine.\nAnd with that, you should have the headlight looking like this;']	['<urn:uuid:2c8dbc12-8a75-44b9-b0cd-567431f25a6a>']	factoid	direct	long-search-query	distant-from-document	single-doc	expert	2025-05-12T15:09:02.012753	9	31	677
51	time requirements proper drying gun stock wood before manufacturing	High-end stock makers typically use wood that has been slowly air-dried for 7-8 years, with some wood being dried for up to 20 years before machining. Air drying gives the wood a deep dark brown color, while cheaper kiln-dried stocks are more prone to splitting and losing color quickly.	"['The requirements for a wooden stock generally are:\n- The material should be a hardwood which is reasonably dense, but not too heavy.\n- The material should be somewhat hard, but not brittle.\n- It should be relatively easy to machine.\n- It should preferably have naturally attractive patterns and grain (after all, guns were always well-crafted products made by skilled craftsmen and it wouldn\'t do to use low quality wood)\nAs it happens, walnut wood happens to fit these requirements the best.\nThe most high-quality walnut wood is obtained from the Juglans Regia, the Persian Walnut (or Common Walnut) tree. This tree is also known as the ""English"" walnut, because British sailors spread this tree around the world. This name is common in North America, because there is already a native American walnut tree of a different subspecies (Juglans Nigra) and so they call the Juglans Regia as an ""English walnut"" to distinguish between the two. The tree actually grows from Xinjiang province in China, all the way into Western Europe. It is commonly found in Northern India. This species has great genetic variability and the trees found in Western Europe tend to have larger size, but only one fruiting period, whereas trees in the Eastern range are smaller, but produce fruit for multiple years. English colonists and sailors also took this tree to the United States, Canada, Australia, New Zealand, South Africa etc., where it still grows. It was also introduced to Mexico, Chile and Argentina, perhaps by Spaniards.\nThe wood from this tree is often used in high-quality furniture and firearm stocks. The finely-figured walnut woods are called ""English"" walnut in the gun trade. Ironically, W.W. Greener mentions in his book, The Gun and its Development, (printed in the early 1900s) that a majority of so-called ""English"" walnut is not English at all. The walnut trees growing in England at that time were admirably suited for gun-stocks, but many lacked the rich brown color and figured patterns for customized high-end weapons and the second problem was that true English-grown walnut wood was not available in large quantities anyway. Therefore, many manufacturers actually got their wood from the European continent. He goes on to mention that English walnut wood is heavy, well marked, but not gaudy and says that French walnut is lighter than English walnut, has richer color with black streaks and open grain. He says Swiss and German walnut woods tend to be grey and pulpy, but if well chosen and naturally matured, they are equal to the finest French woods. He says that Belgian walnut is not available for sale in adequate quantities and Eastern European walnut wood is of very high quality and available in quantity, but is often not prepared or sawed correctly for the purposes of a gun-maker.\nThese days, France, Serbia, Romania, Greece, Bulgaria, Turkey, California and Chile are major producers of English walnut woods, while Australia and New Zealand are also beginning to up their exports of this wood as well.\nGun stock made of fine English walnut wood (J. Regia)\nIn the United States, the American walnut (J. Nigra, also called the ""Black Walnut"") that we mentioned earlier, is often used due to widespread local availability, particularly in the East coast. This wood has dark color and good density. Like the ""English"" walnut, it is also heavy and strong, but easily worked. It is extremely valuable and forest rangers are often called in to stop walnut tree poachers. In 2004, there was a poaching case involving one 16 meter long tree, which was worth $2500.\nGun stock made with American walnut (J. Nigra)\nAnother tree that was often used in North America for a few hundred years was the Curly Maple tree, again due to widespread availability, beautiful pattern and heavy density. Most of the famed Kentucky rifles used curly maple wood stocks. It has a characteristic flame or tiger striping pattern that makes it look very beautiful.\nReplica Kentucky rifle using curly maple stock.\nCurly maple wood is still used today, notably by musical instrument makers. For instance, rock and roll lovers may recognize many rock guitar players using the famous Gibson Les Paul guitar. Yes folks, that is curly maple wood on the top of that guitar as well.\nBeech wood, Birch, Ash, Myrtle and occasionally Mahogany wood are also used for making some gun stocks. Beech wood is heavy, but does not have any pattern in the grain, like the woods seen above.\nThe grain of the wood contributes greatly to the strength of the wooden stock. It should ideally flow towards the toe of the stock for greater strength. The wood should also be prepared suitably -- it should be slowly and completely dried before working on it, otherwise it could split or lose color later. A high-end stock-maker will typically use wood that has been slowly air-dried for several years (7-8 years is common, but some are even as old as 20 years!), before attempting to machine it. Cheaper wood stocks are often kiln-dried and therefore more prone to splitting and losing color much more quickly. Air drying is what gives the wood the deep dark brown color. The best wood comes from the portion of the tree where the trunk and the roots join.\nHere\'s a video demonstrating some of the things that stock makers look for, when selecting wood blanks to make a stock.\nWood stocks are the most beautiful to look at and have been used through much of firearms history, but they have a tendency to warp under adverse weather conditions. Due to this failing, modern military, hunting and sniper rifles usually use fiberglass stocks instead.']"	['<urn:uuid:e635cbe9-36b1-40a2-98f4-539808cf83a4>']	factoid	direct	long-search-query	distant-from-document	single-doc	expert	2025-05-12T15:09:02.012753	9	49	946
52	anti inhibitor coagulant complex effects side effects interaction nsaids	Anti-inhibitor coagulant complex is used to control bleeding in hemophilia patients, but when combined with NSAIDs, it can significantly increase bleeding risk. Side effects include potential blood clots, breathing problems, chest pain, headaches, and leg pain. When taken with NSAIDs, patients may experience increased bleeding from gums, nosebleeds, unusual bruising, or dark stools.	"['Anti-inhibitor Coagulant Complex injection\nWhat is this medicine?\nANTI-INHIBITOR COAGULANT COMPLEX (AN tahy-in HIB i ter koh AG yuh luhnt KOM pleks) is used in patients with hemophilia to help control bleeding.\nHow should I use this medicine?\nThis medicine is for injection into a vein. It is usually given by a health care professional in a hospital or clinic setting.\nIf you are given this medicine at home, you will be taught how to prepare and give this medicine. Take your medicine at regular intervals. Do not take your medicine more often than directed.\nTalk to your pediatrician regarding the use of this medicine in children. While this medicine may be prescribed for children for selected conditions, precautions do apply.\nWhat side effects may I notice from receiving this medicine?\nSide effects that you should report to your doctor or health care professional as soon as possible:\nallergic reactions like skin rash, itching or hives, swelling of the face, lips, or tongue\nsigns and symptoms of a blood clot such as breathing problems; changes in vision; chest pain; severe, sudden headache; pain, swelling, warmth in the leg; trouble speaking; sudden numbness or weakness of the face, arm, or leg\nSide effects that usually do not require medical attention (report to your doctor or health care professional if they continue or are bothersome):\nWhat may interact with this medicine?\nThis medicine may interact with the following medications:\nWhat if I miss a dose?\nKeep appointments for follow-up doses as directed. It is important not to miss your dose. Call your doctor or health care professional if you are unable to keep an appointment.\nIf you take this medicine at home and miss a dose, take it as soon as you can. If it is almost time for your next dose, take only that dose. Do not take double or extra doses.\nWhere should I keep my medicine?\nKeep out of the reach of children.\nIf you are using this medicine at home, you will be instructed on how to store this medicine. Throw away any unused medicine after the expiration date on the label.\nWhat should I tell my health care provider before I take this medicine?\nThey need to know if you have any of these conditions:\nhistory of blood clots\nhistory of blood diseases\nlow platelet counts\nan unusual or allergic reaction to human protein, other medicines, foods, dyes, or preservatives\npregnant or trying to get pregnant\nWhat should I watch for while using this medicine?\nThis medicine is made from human plasma, and there is a small risk that they may contain certain types of virus or bacteria. All products are processed to kill most viruses and bacteria. If you have questions concerning the risk of infections, discuss them with your doctor or health care professional.\nIf you are a hemophilia patient, carry an identification card with you at all times. The card should have your name, the name and dose of your medication(s), the name and phone number of your doctor or health care professional, and a contact person in case of emergency.', ""Selected Anticoagulants (Vit K antagonists)/NSAIDs Interactions\nThis information is generalized and not intended as specific medical advice. Consult your healthcare professional before taking or discontinuing any drug or commencing any course of treatment.\nSerious. These medicines may interact and cause very harmful effects. Contact your healthcare professional (e.g. doctor or pharmacist) for more information.\nHow the interaction occurs:\nBoth of these medicines can affect your blood's ability to clot.\nWhat might happen:\nTaking these medicines together may increase your risk for bleeding. Symptoms may include bleeding from your gums, nosebleeds, unusual bruising, or dark stools.\nWhat you should do about this interaction:\nMake sure your healthcare professionals (e.g. doctor or pharmacist) know that you are taking these medicines together.Let your doctor know right away if you have any bleeding episodes or signs of bleeding.Your healthcare professionals may already be aware of this interaction and may be monitoring you for it. Do not start, stop, or change the dosage of any medicine before checking with them first.\n- 1.Thilo D, Nyman D. A study of the effects of the anti-rheumatic drug ibuprofen (Brufen) on patients being treated with the oral anti-coagulant phenprocoumon (Marcoumar). J Int Med Res 1974;2:276-8.\n- 2.Boekhout-Mussert MJ, Loeliger EA. Influence of ibuprofen on oral anti-coagulant with phenprocoumon. J Int Med Res 1974;2:279-83.\n- 3.Penner JA, Abbrecht PH. Lack of interaction between ibuprofen and warfarin. Curr Ther Res Clin Exp 1975 Dec;18(6):862-71.\n- 4.Michot F, Ajdacic K, Glaus L. A double-blind clinical trial to determine if an interaction exists between diclofenac sodium and the oral anticoagulant acenocoumarol (nicoumalone). J Int Med Res 1975;3(3):153-7.\n- 5.Marbet GA, Duckert F, Walter M, Six P, Airenne H. Interaction study between phenprocoumon and flurbiprofen. Curr Med Res Opin 1977;5(1):26-31.\n- 6.Slattery JT, Levy G, Jain A, McMahon FG. Effect of naproxen on the kinetics of elimination and anticoagulant activity of a single dose or warfarin. Clin Pharmacol Ther 1979 Jan;25(1):51-60.\n- 7.Jain A, McMahon FG, Slattery JT, Levy G. Effect of naproxen on the steady-state serum concentration and anticoagulant activity of warfarin. Clin Pharmacol Ther 1979 Jan;25(1):61-6.\n- 8.Loftin JP, Vesell ES. Interaction between sulindac and warfarin: different results in normal subjects and in an unusual patient with a potassium-losing renal tubular defect. J Clin Pharmacol 1979 Nov-Dec; 19(11-12):733-42.\n- 9.Carter SA. Potential effect of sulindac on response of prothrombin-time to oral anticoagulants. Lancet 1979 Sep 29;2(8144):698-9.\n- 10.Ross JR, Beeley L. Sulindac, prothrombin time, and anticoagulants. Lancet 1979 Nov 17;2(8151):1075.\n- 11.Stricker BH, Delhez JL. Interactions between flurbiprofen and coumarins. Br Med J (Clin Res Ed) 1982 Sep 18;285(6344):812-3.\n- 12.Dahl SL, Ward JR. Pharmacology, clinical efficacy, and adverse effects of piroxicam, a new nonsteroidal anti-inflammatory agent. Pharmacotherapy 1982 Mar-Apr;2(2):80-90.\n- 13.Rhodes RS, Rhodes PJ, Klein C, Sintek CD. A warfarin-piroxicam drug interaction. Drug Intell Clin Pharm 1985 Jul-Aug;19(7-8):556-8.\n- 14.Flessner MF, Knight H. Prolongation of prothrombin time and severe gastrointestinal bleeding associated with combined use of warfarin and ketoprofen. JAMA 1988 Jan 15;259(3):353.\n- 15.Griffin MR, Piper JM, Daugherty JR, Snowden M, Ray WA. Nonsteroidal anti-inflammatory drug use and increased risk for peptic ulcer disease in elderly persons. Ann Intern Med 1991 Feb 15;114(4):257-63.\n- 16.Gabriel SE, Jaakkimainen L, Bombardier C. Risk for serious gastrointestinal complications related to use of nonsteroidal anti-inflammatory drugs. A meta-analysis. Ann Intern Med 1991 Nov 15; 115(10):787-96.\n- 17.Shorr RI, Ray WA, Daugherty JR, Griffin MR. Concurrent use of nonsteroidal anti-inflammatory drugs and oral anticoagulants places elderly persons at high risk for hemorrhagic peptic ulcer disease. Arch Intern Med 1993 Jul 26;153(14):1665-70.\n- 18.Hilleman DE, Mohiuddin SM, Lucas BD Jr. Nonsteroidal antiinflammatory drug use in patients receiving warfarin: emphasis on nabumetone. Am J Med 1993 Aug 9;95(2A):30S-34S.\n- 19.Mieszczak C, Winther K. Lack of interaction of ketoprofen with warfarin. Eur J Clin Pharmacol 1993;44(2):205-6.\n- 20.Celebrex (celecoxib) US prescribing information. Pfizer Inc. May, 2019.\n- 21.Vioxx (rofecoxib) US prescribing information. Merck & Co., Inc. May, 2016.\n- 22.Kent AP, Brueckmann M, Fraessdorf M, Connolly SJ, Yusuf S, Eikelboom JW, Oldgren J, Reilly PA, Wallentin L, Ezekowitz MD. Concomitant Oral Anticoagulant and Nonsteroidal Anti-Inflammatory Drug Therapy in Patients With Atrial Fibrillation. J Am Coll Cardiol 2018 Jul 17;72(3):255-267.\n- 23.Zhou M, Leonard CE, Brensinger CM, Bilker WB, Kimmel SE, Hecht TEH, Hennessy S. Pharmacoepidemiologic Screening of Potential Oral Anticoagulant Drug Interactions Leading to Thromboembolic Events..\nCONDITIONS OF USE: The information in this database is intended to supplement, not substitute for, the expertise and judgment of healthcare professionals. The information is not intended to cover all possible uses, directions, precautions, drug interactions or adverse effects, nor should it be construed to indicate that use of a particular drug is safe, appropriate or effective for you or anyone else. A healthcare professional should be consulted before taking any drug, changing any diet or commencing or discontinuing any course of treatment.""]"	['<urn:uuid:3b0f1b82-213d-4e05-a4f5-97e91ccf36ab>', '<urn:uuid:5f6ea87c-4c94-482e-9a5f-d81e9f703fe1>']	factoid	with-premise	short-search-query	similar-to-document	multi-aspect	expert	2025-05-12T15:09:02.012753	9	53	1319
53	Given my expertise in public health prevention, I'd like to understand the comprehensive aspects of oral health maintenance - what are the three key pillars covering biological processes, preventive practices, and systemic health impacts?	The three key pillars of oral health maintenance involve: 1) The biological process of mineralization, where minerals like calcium and phosphate help form tooth enamel and prevent dental caries, though these minerals can be lost through acidic foods and bacterial accumulation; 2) Preventive practices including proper brushing techniques, regular dental check-ups, professional cleanings to remove plaque buildup, and dietary modifications such as limiting sugar and starchy foods while increasing water intake; and 3) Systemic health impacts, as poor oral health can contribute to various conditions - research shows strong links between oral health and heart disease, diabetes, respiratory conditions, and even pregnancy outcomes. Additionally, poor oral health can significantly impact mental health, potentially leading to anxiety and social isolation. This demonstrates how oral health is integrally connected to overall physical and mental wellbeing.	['Minerals such as calcium and phosphate help comprise tooth enamel, along with bone and dentin. They also prevent dental caries and subsequent cavities. As you age, you lose the minerals in your teeth This may be brought on by eating sugary and acidic foods. It also happens when bacteria accumulate in your mouth. As soon as the enamel or bone are gone, there’s no chance to get these back without replacing the tooth totally.\nHowever, it’s possible to assist replenish these minerals with lifestyle changes and natural home remedy before dental caries happens. This procedure is called remineralization.\nTalk with your dental expert about the following treatment measures to assist remineralize your teeth.\n1. Brush Your Teeth\nBrushing your teeth is essential in bacteria removal. Cavities (also called dental caries) are primarily triggered by the accumulation of Streptococcus mutans bacteria in your mouth.\nAccording to a 2016 study, these bacteria are transmitted through food and drink. Brushing your teeth routinely can remove the bacteria that may result in mineral loss and cavities.\n2. Use Fluoride Toothpaste\nNot simply any tooth paste will work against demineralization. The Academy of General Dentistry recommends fluoride toothpaste since it prevents tooth decay through remineralization. Fluoride can also reinforce your teeth, making them less vulnerable to future mineral loss.\n3. Cut Out Sugar\nYour dental practitioner has likely warned you about sugar in the past, and for good reason. Sugar is highly acidic and communicates with bacteria in the mouth by breaking down tooth enamel. Honey and table sugar (sucrose) seem the worst culprits.\nMore notably, one research study found that a higher frequency in sugar intake caused demineralization more than the quantity of sugar consumed. In other words, eating sugary foods in percentages on a regular basis can do more harm compared to consuming the periodic sugar-laden dessert.\n4. Chew Sugarless Gum\nThe function of gum in oral health has been debatable for decades, however studies are showing that sugarless variations might really promote tooth remineralization. According to one study, sugar-free gum helps remove sugar, plaque, and carbs from teeth while likewise encouraging your salivary glands to produce more saliva.\nThe gum can likewise act as a barrier to obstruct mineral loss. Xylitol and sorbitol appear the most promising sugar-free active ingredients. To reap the remineralization advantages of sugarless gum, consider chewing after or in-between meals.\n5. Take in Fruit and Fruit Juices in Moderation\nWhile fruit belongs of a healthy, balanced diet, it can also be highly acidic. A few of the worst offenders are citrus fruits, such as grapefruit and oranges.\nFruit acids produce a process of calcium chelation on tooth enamel. This implies that the acids bind to calcium and strip it away. Fruit juices are even worse, as these are extremely acidic and often contain added sugars. Your best choice is to stay away from juices and to eat acidic fruits just on occasion.\n6. Get More Calcium\nWhile calcium is produced within the teeth naturally, this essential mineral is stripped from acids and bacteria over time. You can replace calcium by eating calcium-rich foods. For example, one research study found that eating calcium-rich cheese could combat the impacts of eating sugar.\nIf your diet lacks calcium, talk to your doctor about possible supplementation.\n7. Decrease Dairy Item Usage\nWhile dairy items might be natural sources of calcium, the lactose in conventional milk items can increase level of acidity in your mouth. This is due to the fact that lactose is a type of sugar. You can still reap the benefits of calcium by picking lactose-free milk, or by opting for almond or soy milk.\n8. Think About Probiotics\nWhen thinking about probiotics for remineralization, it’s essential to choose strains that are naturally produced in the mouth. For that reason, you’re replacing the good bacteria, without introducing potentially damaging stress. The following probiotics are potentially helpful in oral health and remineralization: bifidobacterium, reuteri, rhamnosus and salivarius.\nYou can find probiotics in additional kind at the drugstore. Specific yogurt brand names likewise contain probiotics. You’ll have to take these day-to-day for best outcomes.\n9. Address Your Dry Mouth\nDry mouth happens when there isn’t really sufficient saliva production. Saliva’s not just essential in keeping your mouth feeling comfy, but it also helps prevent cavities. Inning accordance with the International Journal of Nanomedicine, saliva is an essential part of remineralization. Not just does saliva prevent dry mouth, however it likewise consists of phosphate and calcium.\nSpeak to your dental professional about gums and rinses you can use to increase saliva activity.\n10. Minimize Starchy Foods\nStarchy foods, such as potatoes, rice, and bread, are packed with basic carbs. These likewise increase the amount of fermentable sugars in the mouth, which can deteriorate your teeth.\nNevertheless, according to a study, the risk of dental caries has the tendency to be higher when eating starchy foods combined with sugar. For instance, sweetened potatoes are bothersome for the teeth, however plain ones are not.\n11. Drink More Water\nWater continues to be the preferred beverage of choice by physicians, nutritional experts, and dental experts. It’s not only naturally sugar-free, however it also helps remove hazardous products from the body. Rinsing your mouth out with water may also help reduce demineralization when you don’t have a toothbrush on hand. This technique may be particularly helpful after eating acidic or sweet foods.\nWhile coffee and tea aren’t entirely off-limits, they do little to remineralize your teeth. Plus, these substances can be acidic (especially coffee). Sugarcoating can make these beverages even worse when it pertains to oral health. Sodas are likewise acidic, and often include sugar, so they ought to be limited, too.\nThe bottom line\nMineral loss is inescapable since of the elements teeth are exposed to every day. From food and drinks, to saliva and bacteria, your teeth are put through a great deal of wear and tear. While your teeth are built to handle these aspects, excessive demineralization can eventually use them down. Taking actions to demineralize your teeth, along with regular sees to your dental expert, can assist keep them healthy.', 'Imagine a world where your smile radiates confidence, your teeth are strong and healthy, and your overall well-being is at its peak. It’s not just a dream – it’s within reach through the importance of oral health care. By taking care of your teeth and gums, you can prevent dental decay and gum disease, maintain a healthy smile, and even reduce the risk of systemic diseases. In this article, we will explore the vital role that oral health plays in your overall health and provide evidence-based strategies to promote optimal oral health care for a lifetime of smiles.\n- Poor oral hygiene can lead to dental problems such as gum disease and tooth decay.\n- Dental issues can cause pain, discomfort, and embarrassment, leading to anxiety and social isolation.\n- Research has shown a strong link between oral health and mental health.\n- Regular check-ups with your dentist are essential for maintaining good oral health.\nThe Link Between Oral Health and Overall Well-Being\nTaking care of your oral health can have a significant impact on how you feel overall. Not only does it contribute to your physical well-being, but it also plays a crucial role in your mental health. Research has shown that there is a strong link between oral health and mental health. Poor oral hygiene can lead to various dental problems such as gum disease and tooth decay, which can cause pain, discomfort, and embarrassment. These issues can negatively affect your self-esteem and confidence, leading to feelings of anxiety, social isolation, and even depression.\nFurthermore, the importance of maintaining good oral health during pregnancy cannot be overstated. Pregnancy hormones can increase the risk of developing dental problems like gingivitis or gum inflammation. If left untreated, these conditions may lead to more severe issues such as periodontal disease. Additionally, poor oral health during pregnancy has been associated with adverse pregnancy outcomes like preterm birth and low birth weight.\nTo ensure optimal oral health during this critical period, it is essential to practice good oral hygiene habits such as regular brushing and flossing, using fluoride toothpaste, eating a balanced diet rich in vitamins and minerals, and visiting your dentist for check-ups and cleanings.\nPreventing Dental Decay and Gum Disease\nWhen it comes to preventing dental decay and gum disease, there are several key points to consider. First, brushing techniques play a crucial role in prevention. By using the proper technique and brushing twice a day, you can effectively remove plaque and bacteria from your teeth and gums. Second, regular check-ups with your dentist are essential for maintaining good oral health. These check-ups allow for early detection of any potential issues and ensure that any problems are addressed promptly. Lastly, diet also plays a significant role in oral health. Consuming a balanced diet that is low in sugar and high in nutrients can help prevent tooth decay and promote healthy gums.\nBrushing Techniques for Prevention\nProper brushing techniques can help prevent dental issues. By practicing the right toothbrushing technique, you can effectively remove plaque and prevent cavities. Here are some key tips to keep in mind:\n|Proper Toothbrushing Technique|\n|Choose the right toothbrush: Opt for a soft-bristled brush with a small head to reach all areas of your mouth.|\n|Brush at a 45-degree angle: Position your brush at a 45-degree angle towards the gumline and use gentle circular motions.|\n|Don’t forget to brush your tongue: Bacteria can accumulate on your tongue, causing bad breath and oral health problems.|\nImportance of Regular Check-Ups\nRegular check-ups are essential for maintaining good overall dental hygiene and preventing potential issues. By visiting your dentist regularly, you can stay on top of your oral health and catch any problems early on. Here are some reasons why regular check-ups are so important:\n- Prevention: Regular dental visits allow your dentist to identify and address any potential issues before they become major problems.\n- Early detection: Through routine exams, your dentist can detect signs of tooth decay, gum disease, or oral cancer in their early stages when treatment is most effective.\n- Professional cleaning: Dental cleanings remove plaque buildup that cannot be removed by regular brushing and flossing alone, helping to prevent cavities and gum disease.\n- Personalized advice: Your dentist can provide specific recommendations for improving your dental hygiene based on the condition of your teeth and gums.\n- Peace of mind: Regular check-ups give you confidence that you are taking proactive steps towards maintaining a healthy smile.\nMake sure to schedule regular check-ups with your dentist as part of your preventive dental care routine. It’s an investment in the long-term health of your teeth and gums.\nRole of Diet in Oral Health\nEating a balanced diet that includes fruits, vegetables, and dairy products can contribute to the overall health of your teeth. The role of nutrition in oral health is significant. Proper nutrition provides essential vitamins and minerals that help maintain strong teeth and gums. Fruits and vegetables are rich in antioxidants, which can protect against gum disease and promote healing. Dairy products like milk, cheese, and yogurt are excellent sources of calcium, a mineral crucial for healthy tooth enamel. However, it’s important to be mindful of the impact of sugar on your oral health. Consuming sugary foods and drinks increases the risk of cavities as bacteria in the mouth feed on sugars, producing acids that erode tooth enamel. To maintain good oral health, choose nutritious foods while limiting your intake of sugary treats.\nThe Role of Oral Hygiene in Maintaining a Healthy Smile\nTo maintain a healthy smile, you should prioritize your oral hygiene routine and make sure to brush and floss daily. Brushing alone is not enough to keep your teeth and gums in optimal condition. Flossing plays a crucial role in oral hygiene by removing plaque and food particles from between the teeth, where toothbrushes can’t reach. It helps prevent cavities, gum disease, and bad breath.\nReady to take charge of your dental health? Let’s dive into some essential dental hygiene practices to keep your smile shining bright\nIn addition to flossing, using mouthwash as part of your oral care routine can provide additional benefits. Mouthwash helps kill bacteria in the mouth that cause bad breath and can also reduce plaque buildup. It reaches areas that brushing and flossing may miss, providing an extra layer of protection for your teeth and gums.\nHere are five reasons why flossing and using mouthwash are essential for maintaining good oral health:\n- Reduces the risk of gum disease\n- Prevents cavities by removing plaque\n- Freshens breath by killing bacteria\n- Reaches areas that brushing can’t\n- Provides an extra layer of protection\nUnderstanding the Importance of Regular Dental Check-Ups\nScheduling regular dental check-ups is crucial for maintaining a healthy smile. You may wonder why these appointments are so important when you brush and floss daily. Well, the truth is that even with good oral hygiene practices at home, there are areas in your mouth that can be difficult to reach and clean effectively. This is where professional dental cleanings come into play.\nDuring your regular check-up, your dentist will not only examine your teeth and gums but also perform a thorough cleaning to remove any plaque or tartar buildup. This is essential for preventing cavities and gum disease, as plaque contains harmful bacteria that can erode tooth enamel and irritate the gums.\nIn addition to cleaning your teeth, dentists also provide valuable education on proper oral care techniques. They will emphasize the importance of flossing as part of an effective daily routine. Flossing helps remove food particles and plaque from between the teeth and along the gumline, where brushing alone cannot reach.\nOral Health and Its Impact on Systemic Diseases\nIn this discussion, we will explore the connection between oral health and various systemic diseases. First, let’s delve into the link between oral health and heart disease. Research has suggested that poor oral hygiene can contribute to an increased risk of developing cardiovascular problems. Additionally, we will examine how oral health is connected to diabetes and respiratory conditions, as studies have shown that maintaining good oral hygiene plays a role in managing these conditions effectively.\nOral Health and Heart Disease\nDid you know that taking care of your oral health can help prevent heart disease? It’s true, maintaining good oral hygiene not only keeps your teeth and gums healthy but also has a positive impact on your overall cardiovascular health. Research has shown that there is a link between oral health and cholesterol levels. Poor oral hygiene can lead to gum inflammation, which in turn may contribute to the development of high cholesterol levels. Additionally, studies have found that individuals with poor oral health are at an increased risk of developing stroke. By practicing good oral hygiene habits such as brushing twice a day, flossing daily, and visiting your dentist regularly, you can significantly reduce your chances of experiencing heart-related issues. So take care of your smile and protect your heart!\nLink Between Oral Health and Diabetes\nMaintaining good oral hygiene can help prevent heart disease, and it’s also been found to play a role in managing diabetes. Taking care of your oral health is not only important for a beautiful smile, but it can also have significant impacts on your overall well-being, particularly when it comes to blood sugar control and managing the risk factors associated with diabetes.\nResearch has shown that poor oral health, such as gum disease and tooth decay, can contribute to higher blood sugar levels in individuals with diabetes. This makes it more challenging to manage their condition effectively. Additionally, inflammation caused by gum disease may increase insulin resistance and make it harder for the body to utilize glucose properly.\nFurthermore, individuals with diabetes are more prone to developing oral health problems due to reduced saliva production and compromised immune function. These conditions create an environment where bacteria thrive, leading to increased risk of gum disease and tooth loss.\nTo maintain optimal blood sugar control and reduce the risk factors associated with diabetes, it’s crucial to prioritize your oral health. Brushing twice a day with fluoride toothpaste, flossing daily, visiting your dentist regularly for check-ups and cleanings, and maintaining a healthy diet are all essential steps in achieving good oral hygiene. By incorporating these habits into your routine, you can take proactive measures in managing your diabetes while improving your overall well-being.\nOral Health and Respiratory Conditions\nRegular dental check-ups and practicing good oral hygiene can help reduce the risk of respiratory conditions, such as pneumonia and chronic obstructive pulmonary disease (COPD). By taking care of your oral health, you are not only protecting your teeth and gums but also safeguarding your respiratory system. Here are a few reasons why maintaining good oral hygiene is crucial for respiratory health:\n- Oral bacteria can travel to the lungs, leading to infections.\n- Poor oral health may increase the risk of developing respiratory conditions.\n- Regular brushing and flossing can prevent harmful bacteria from entering your respiratory system.\n- Gum disease can worsen existing respiratory conditions.\n- Dental professionals can identify early signs of potential respiratory issues during routine check-ups.\nInvesting in proper respiratory hygiene through regular dental visits and adopting effective oral health interventions is essential for maintaining overall well-being. Take charge of your health by prioritizing good oral hygiene practices today.\nPromoting Oral Health in Children and Adolescents\nPromoting oral health in children and adolescents is crucial for their overall well-being. It is essential to emphasize the importance of dental hygiene from an early age. By teaching children proper brushing techniques, encouraging regular dental check-ups, and promoting a healthy diet, we can help prevent oral health problems and lay the foundation for a lifetime of good oral hygiene habits.\nEarly intervention plays a significant role in maintaining optimal oral health. By identifying potential issues at an early stage, such as tooth decay or malocclusion, interventions can be implemented promptly to prevent further damage. Regular visits to the dentist allow for timely detection of any developing problems and enable appropriate treatment strategies.\nIn addition to regular dental care, instilling good oral hygiene habits in children is crucial. Teaching them how to brush their teeth effectively using fluoride toothpaste helps remove plaque and prevent cavities. Encouraging them to floss daily further promotes gum health by removing food particles and plaque from between teeth.\nA nutritious diet also contributes significantly to oral health. Limiting sugary snacks and drinks reduces the risk of tooth decay. Instead, encourage children to consume fruits, vegetables, whole grains, lean proteins, and dairy products that provide essential nutrients for strong teeth and gums.\nFrequently Asked Questions\nWhat Are Some Common Signs and Symptoms of Poor Oral Health?\nIf you’re experiencing signs and symptoms of poor oral health, it’s important to take action. Ignoring issues like tooth pain, bleeding gums, or bad breath can lead to more serious problems down the line.\nHow Often Should I Brush and Floss My Teeth?\nYou should brush and floss your teeth at least twice a day for optimal oral health. Brushing techniques, such as using a soft-bristled toothbrush and gentle circular motions, can help remove plaque. Regular dental check-ups are also important.\nCan Poor Oral Health Affect My Overall Immune System?\nPoor oral health can have a negative impact on your overall immune system. Research has shown a link between oral health and chronic diseases, as well as autoimmune disorders. It’s important to prioritize oral hygiene.\nWhat Are Some Effective Ways to Prevent Bad Breath?\nTo maintain fresh breath throughout the day, try natural remedies for bad breath. Brush your teeth and tongue twice a day, floss daily, use mouthwash, drink plenty of water, and avoid tobacco and foods with strong odors.\nAre There Any Natural Remedies for Gum Disease?\nLooking for natural remedies for gum disease? While there are alternative treatments that can help, it’s important to remember the overall importance of oral health care. Keep reading to learn more.\nIn conclusion, taking care of oral health care is essential for your overall well-being. By practicing good oral hygiene and regularly visiting the dentist, you can prevent dental decay and gum disease, ensuring a healthy smile. But it doesn’t stop there – maintaining oral health also has a significant impact on systemic diseases. So, don’t neglect your teeth and gums; they are not only important for chewing but also for maintaining a healthy body. Start prioritizing your oral health today for a brighter and healthier future!']	['<urn:uuid:70077ba4-37d5-4ff9-8871-ce54f715e391>', '<urn:uuid:60875344-631f-42a1-8ae8-d31a56a2d39b>']	open-ended	with-premise	verbose-and-natural	distant-from-document	three-doc	expert	2025-05-12T15:09:02.012753	34	133	3431
54	green bitcoin mining pools benefits risks	Green Bitcoin mining pools offer benefits and risks. On the benefits side, these pools like Terra Pool verify renewable energy usage through the Green Hashrate application, helping miners meet ESG criteria and prove their environmental credentials to investors like Tesla. However, there are risks as demonstrated by some mining pools like Poolin suspending withdrawals due to liquidity problems. Additionally, mining pool fees reduce actual earnings compared to solo mining, and the equipment needed remains expensive with profits affected by electricity costs.	['Open-source “Green Hashrate” software solution will track and verify green Bitcoin mining\nTesla recently proclaimed it will resume accepting Bitcoin as payment once the cryptocurrency’s miners achieve 50% sourcing from renewable energy. Tesla’s position is demonstrative of growing demands among crypto investors (and investors more generally) to prove the environmental, social, and governance (ESG) credentials of investment options.\nIn response, today nonprofit Energy Web is releasing an open-source architecture for a “Green Hashrate” application that will enable Bitcoin miners to claim and verify the amount of renewable electricity used in their operations from the bottom-up. There are several expected market applications, including:\n- Enabling green mining pools to require proof of renewables for any miners as part of the know-your-customer (KYC) process to join a green mining pool;\n- Helping miners deliver proofs of renewable energy sourcing to local regulators and/or investors to meet ESG criteria;\n- Over time, proving to crypto investors (like Tesla) and regulators the actual amount of renewable electricity powering an entire cryptocurrency network at any time.\nThe first version of this solution will be manual and is designed around the KYC process for green mining pools like Terra Pool, a green mining pool spearheaded by two Crypto Climate Accord Signatories, Argo and DMG Blockchain. The next step is to automate the application making it possible for miners, utilities, and in some cases regulators to trust that a given Bitcoin mine is in a specific part of a grid with a particular mix of renewables. To accomplish this, the solution will leverage the Energy Web Decentralized Operating System (EW-DOS) and in particular decentralized identifiers so as to protect proprietary miner information in compliance with GDPR and other privacy-protecting regulations around the world.\nTechnical Architecture for Blockchain-Agnostic Proof of Green Solution Stack\nIn this solution architecture, a Bitcoin miner creates a decentralized identifier (DID) that is anchored on the Energy Web Chain, a public blockchain built for the energy sector. In order to deliver the required KYC credentials to join a green mining pool (or for that matter, to make any legitimate public claims about sourcing from 100% renewables), miners must provide verification from the appropriate market authority, such as an electric utility and/or energy attribute certificate issuing body, to prove its renewable energy sourcing. This verification is then linked to the miner’s DID and documented on-chain.\nThe most immediate users of this solution will most likely include miners located in geographies already using 100% renewably-generated electricity — namely, geographies with 100% hydro (or even volcanoes) that are becoming increasingly appealing to miners— and miners that procure and claim energy attribute certificates at a 100% proportion to their electricity use. Some miners may also want to show that their electricity purchases match electricity use on an hour-by-hour level in line with the emerging EnergyTag certificate standard currently being defined and tested in various demonstrations.\nIn setting the vision for the Green Hashrate application, several requirements were considered to ensure it is poised for adoption across the global Bitcoin mining community. For example, the application does not impact the fungibility of Bitcoin — a core requirement for any realistic solution — and provides privacy protections around a given mining facility’s actual energy use and precise location. This solution must also eventually illustrate the overall adoption of verified renewable energy use as a percentage of overall Bitcoin hashing across the entire Bitcoin mining network at a given time, which would set a new example of industry-wide ESG transparency for other industries to follow.\n“I am excited to see the speed in which Terra Pool is actively working with CCA to develop and implement clean energy standards that are pushing forward the positive momentum that the CCA is driving in moving blockchains to net zero carbon,” commented Sheldon Bennett, CEO of DMG Blockchain Solutions.\n“Our vision is for any crypto miner in the world to be able to download the Green Hashrate application and show to the rest of the world exactly how much renewable electricity that mine is using,” said Jesse Morris, CCO of Energy Web. “And by using technologies like blockchain paired with decentralized identifiers, we can pull this off in a way that guarantees privacy of sensitive information for all parties involved.”\nSince the Green Hashrate application is open-source, once developed any Bitcoin miner or green mining pool can use and build on top of it to meet their respective needs. This solution could also be easily extended to other industries to streamline the verification of renewable energy sourcing, from data centers and factories to electric vehicle fleets and commercial buildings.\nLooking forward, there are two design questions being considered that will need to be solved in order to scale the solution:\n- How can we streamline, digitize, and automate utility verification of miner location and grid mix?\n- Beyond increasingly widespread global demand for 100% renewable Bitcoin, how can we create additional incentives to promote widespread adoption of the Green Hashrate application beyond miners who are already 100% renewable?\nThis Green Hashrate solution is already attracting interest from additional mining companies. “This Green Hashrate software can be instrumental for miners like ourselves to provide auditable tracking and traceability of the provenance of our 100% renewably powered mining facilities. Building regulatory trust and investor confidence in our company’s, and industry’s, commitment to sustainability is more important now than ever before as this topic takes hold of the public conversation around the future of blockchain technology,” said Brittany Kaiser, Chair of the Board at Gryphon Digital Mining, which is also a CCA Signatory.\nWe will report back in the coming weeks with updates on the technical development and tests of this Green Hashrate solution.\nPlease let us know if you would like to get involved with informing and testing this work by contacting email@example.com.\nTogether, we can #MakeCryptoGreen!', 'In the early days of Bitcoin (BTC), cryptocurrency enthusiasts only needed a basic personal computer with an Internet connection to generate new BTC tokens through a distributed computing process known as mining.\nHowever, with more people chasing the same number of block rewards, the Bitcoin mining process has become more challenging over time. In fact, the amount of rewards will be progressively halved every four years, making it less rewarding for individual miners who will need to allocate greater computational resources over time.\nAvailable in blockchain protocols that employ a proof of work (PoW) consensus Mechanism, This mining process requires Application Specific Integrated Circuits (ASICs) to be implemented in the form of large platforms to complete the complex nature of mathematical problems within the time required to mine a block.\nWith the increasing difficulty of the mining algorithm and the rewards for mining a block reducing over time, it has become impossible for a single piece of personal computing equipment to successfully mine a block.\nThis has brought to the fore the concept of a cryptocurrency mining pool, where individual miners or users come together and pool their computational resources to improve their chances of mining a block and share the rewards received among themselves.\nIn existence since 2010, when Slush Pool was formed as the first Bitcoin mining pool, there are now many popular mining pools for cryptocurrencies such as Ether (ETH), Zcash (ZEC), Bitcoin Cash (BCH), BitcoinSV (BSV) and more to choose from.\nReplete with their own dashboards that provide status on things like mining hardware status, current hash rate, estimated earnings, and other parameters, mining pools offer cryptocurrency users the opportunity to participate in the mining process. mining a particular cryptocurrency steadily and get regular rewards. in proportion to the computing power provided.\nUnderstand the cryptocurrency mining process\nBefore we delve into what a cryptocurrency mining pool is and how an individual can join one, let us see how cryptocurrency mining is carried out and understand the main difficulties involved.\nFirst of all, for any PoW blockchain protocol, the process of extracting its native token involves solving mathematical problems using computing power, where the correct answer is represented as the hash number of the block and the rewards are presented to the entity. which resolves faster.\nThese rewards come in the form of native tokens, with the mining process scheduled in such a way that a new transaction block is mined after specified time periods. In the case of Bitcoin, this time is around ten minutes and the complexity, or hash rate, is adjusted based on the amount of computing power available on the network.\nWith more computing power, the hash rate increases proportionally and requires even more powerful computing power to have any chance of solving the mathematical puzzle within each cycle time.\nThis is why cryptocurrency miners have moved from using personal computers or CPU mining to using graphics processing units (GPUs) and are now completely switching to custom rigs that use hundreds of ASICs to mine cryptocurrencies.\nThese ASIC miners continue to evolve and use the latest chip technology to provide a hash rate that can increase the chances of mining Bitcoin or any other cryptocurrency. Based on hash rate, power consumption, noise produced, and profitability per day, ASIC miners like Bitmain Antminer S19 Pro, AvalonMiner 1166 Pro, and WhatsMiner M32 are preferred among the crypto mining community today.\nWhether it’s releasing new tokens into the system or verifying and adding transactions to the public ledger in the form of blocks, the mining process becomes more difficult as more miners compete for the same thing.\nSince the reward for mining a Bitcoin block is 6.25 BTC, it is quite lucrative from a monetary perspective and has motivated many miners to increase their computing power by purchasing expensive ASIC miners.\nAlternatively, those who prefer to dedicate their existing computing power to earn smaller but consistent rewards prefer to join a cryptocurrency mining pool like F2pool, Slush Pool, or AntPool, and like to pool resources and get daily rewards for their contributions.\nHow do crypto mining pools work?\nA cryptocurrency mining pool is a collection of miners who work together as a single entity to increase their chances of mining a block and share rewards with each other in proportion to the computing power they bring to successfully mine a block.\nThe mining pool operator manages activities such as recording the work done by each member of the pool, managing their hashes, assigning shared rewards to each member, and even the work they have to do individually.\nIn return, a mining pool fee is deducted from the rewards distributed to each member, which is calculated based on the pool exchange mechanism and depending on how these cryptocurrency mining pools share the rewards, they can be of a proportional type. fully decentralized, pay per share type or peer-to-peer (P2P) group type.\nIn a proportional mining pool, miners who contribute their computational power receive shares until the moment the pool manages to mine a block, which are then converted into rewards proportional to the number of shares received by each member of the pool.\nPay-per-share pools differ slightly from proportional pools in that each member can collect shares received daily, regardless of whether the pool has been successful in finding a block.\nLast but not least, P2P cryptocurrency mining pools are more advanced versions where all pool activity is integrated as a separate blockchain to prevent pool members from being cheated by the operator or any other entity. .\nRegardless of the type of pool chosen, it is important to check whether the crypto mining pool is profitable after looking at the computing power needed, the electricity costs involved, the applicable mining pool fee, and how often the pools are paid. of crypto mining.\nTypically, different cryptocurrency mining pools charge between 2% and 4% of the profits made, with most offering a daily payout mechanism at a predetermined time of day.\nHowever, for taxpayers, the cost of purchasing dedicated ASIC miners and the regular cost of the electricity needed to power them must be carefully determined to understand whether crypto mining pools are profitable.\nWhat are the different types of crypto mining pools and how to start mining a pool?\nThere are a number of reputable cryptocurrency mining pools available for individual miners to join and start contributing.\nBinance, AntPool, F2pool, Pool BTC, and Slush Pool are some of the well-known cryptocurrency mining pools that have an exemplary track record in terms of uptime efficiency and regular payments made to pool members.\nIn fact, Slush Pool has been responsible for mining over 1.3 million BTC since its inception, helping over 15,000 individual small miners collectively mine Bitcoin at a total hash rate that represents 5-8% of the total Bitcoin network.\nInstead of participating in a Bitcoin mining pool, individual miners can also join together to mine other cryptocurrencies such as Litecoin (LTC), Bitcoin Gold (BTG), Monero (XMR), ETH and Ethereum Classic (ETC) among others, by joining the right mining rig.\nAmong Ethereum mining pools, Ethermine, 2Miners, F2pool, Nanopool, and Ezil are some of the more established options for users to choose from, each offering a different network hash rate and comprising hundreds to thousands of individual miners.\nChoosing which cryptocurrency to start mining with depends on its price stability, the hash rate required to earn decent rewards on a consistent basis, and the mining rig fees which will be minus the overall earnings.\nIn addition to registering with a cryptocurrency mining platform, individual miners will need to have mining hardware in the form of one or more ASIC miners, installed mining software, and a secure cryptocurrency wallet to store rewards and other cryptocurrencies for transactions.\nThe more capital invested in advanced mining rigs or equipment, the greater the chances of earning higher rewards, subject to all hardware being dedicated to the purpose of cryptocurrency mining.\nAlso, having a fast internet connection and uninterrupted electricity supply are essential to get the job assigned by the mining pool operator done at the fastest possible pace.\nAdvantages and disadvantages of a crypto mining pool\nCryptocurrency mining pools offer even the smallest miners the opportunity to use their computational resources for regular income without having to invest heavily in developing a dedicated mining rig that can cost millions of dollars.\nRegular payouts, clear, real-time visibility into reward potential, and the benefit of professional pool operator management are just some of the benefits of joining a crypto mining pool.\nHowever, not all crypto mining pools are safe, as demonstrated by Poolinwhich recently announced that it would suspend BTC and Ether (ETH) withdrawals due to liquidity problems. Also, considering that crypto mining pools make money by deducting a mining pool fee from the rewards earned by mining activities, the actual earnings of each pool member are considerably lower than is possible in the case of mining pools. be a unique miner.\nWhat’s more, the equipment needed to run even mining pool operations can be very expensive and profits can be disproportionately affected by any increase in electricity or internet costs.\nBuy a license for this article. Developed by SharpShark.']	['<urn:uuid:95bbd334-8cdb-4da2-b7d6-8ffda623175b>', '<urn:uuid:94be0282-548a-44cf-a7c8-94bbe31aaaf6>']	open-ended	direct	short-search-query	similar-to-document	multi-aspect	novice	2025-05-12T15:09:02.012753	6	81	2495
55	What specific goals and learning objectives are incorporated into university-level philosophical education programs?	Philosophy courses are designed to explore theories about human nature and their place in the universe, and to develop ideas for making sense of facts and values. They have three main objectives: 1) to equip students with basic tools of philosophical analysis for dealing with problems, principles, concepts, and methodologies in other disciplines, 2) to provide understanding of basic ideas that have shaped Western and non-Western cultures, and 3) to furnish opportunities for students to personally explore the meaning of life.	"['These students presented their senior theses in philosophy in the annual colloquium exhibiting their best work:\nTim Baker (\'16) Jake Murray (\'16)\nCongratulations to Jacob T. (Jake) Murray, Winner of the 2016 Remsburg-Klivé Award!\n""Philosophy"" means -- literally -- love of wisdom. The word was coined to refer to those who don\'t settle for simple answers to big questions. They seek deeper truths, and they are willing to look beyond what is superficial and conventional to discern what is real. They don’t let others think for them. They want to figure things out for themselves. For this reason, of course, philosophy is not for everyone. If it is for you, we can help.\nTraditionally philosophy has been a quest for truth and wisdom. It primarily concerns itself with those fundamental beliefs by which people have tried to make sense of their lives - to understand people and their place in the universe. In this quest, it has focused attention on three questions:\nWhat can we know? (epistemology)\nWhat is real? (metaphysics)\nHow should we live? (ethics)\nFollowing Socrates who held that ""the unexamined life is not worth living"" philosophy has always been critical and analytic but it has also been synthetic and comprehensive, developing into the classic speculative systems of Plato, Aristotle, Hegel, and others. The study of philosophy involves serious study of the works of the great philosophers, a mastery of philosophical methods, and serious inquiry into major philosophical issues. To be a philosopher is to devote one\'s efforts to the clarification of these issues and to search for sound understanding.\nCourses in philosophy at Wittenberg are designed to explore the full range of theories concerning the nature of people and their place in the universe and to develop ideas that can help students make sense out of both facts and values. They are intended (1) to equip the student with the basic tools of philosophical analysis, tools for dealing with those basic problems, principles, concepts, and methodologies that occur in other disciplines or fields of inquiry, (2) to provide the student with an understanding of the basic ideas that have shaped and still shape our cultures, both Western and non-Western, and (3) to furnish the student with opportunities to engage in the personal exploration of the meaning of life.\nThe Wittenberg Philosophy Department consists of three full-time members. The academic background and interests of the faculty span the full range of philosophic styles and assure a broad exposure to the field. Department offerings include a comprehensive set of standard courses and a variety of topics or special interest courses.\nWe invite you to look further into our website.\nInside-Out Prison Exchange:\nThe Philosophy Department offers a unique learning opportunity by offering Inside-Out Prison Exchange courses. For these course Wittenberg students travel to London Correctional Institution to study philosophy wtih 15 men who are incarcerated. Every year we offer a course in this format. Our students, both inside and outside, have co-written an article entitle ""An Epistemology of Incarceration: Constructing Knowing on the Inside"" that was published in 2016 in the philosophy journal philoSOPHIA. For more information about the program contact Dr. McHugh at firstname.lastname@example.org\nWhy Major in Philosophy? Because you can do so much with your degree. See these articles for the value of the philosophy education.\n""The Rise in Stock of Philosophy Graduates\n,"" J. Shepherd, The Guardian (UK), 2007.\n""In a New Generation of College Students, Many Opt for the Life Examined\n,"" W. Hu, New York Times, 2008.\n""Is Philosophy the Most Practical Major?\n"", Edward Tenner, The Atlantic, 2011.\n""What Can I Do With A Humanities Degree?\n"", Bruce Janz']"	['<urn:uuid:470af3ae-6f6c-40bb-8238-3b18ac9d3166>']	open-ended	direct	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-12T15:09:02.012753	13	81	606
56	miles davis roll royce silver pigeon comparison how different performing musician	While both Miles Davis and the Baroness Nica's Rolls-Royce Silver Pigeon were iconic fixtures in New York's jazz scene, they represented different aspects of the era. Miles Davis was a pioneering musician who evolved from traditional jazz styles to developing modal jazz with albums like Kind of Blue (1959), constantly pushing musical boundaries and moving forward - as evidenced by his dismissive attitude toward his past works. The Silver Pigeon, owned by the Baroness, was a symbol of patronage and support for jazz musicians, becoming a familiar sight on 52nd Street as she transported artists like Thelonious Monk around New York, even engaging in impromptu races with Davis himself in his Mercedes.	['Interviewer: What is jazz?\nThelonious Monk: New York, man. You can feel it. It’s around in the air…\nIf the ‘Jazz Baroness’ Kathleen Annie Pannonica Rothschild de Koenigswarter hadn’t existed, would the great beboppers have had to invent her?\nThe benefactor and friend to the stars was an important figure in the jazz lexicon but has hitherto only been mentioned in passing with reference to such greats as Charlie Parker, Thelonious Monk, Sonny Rollins, Mary Lou Williams, Hampton Hawes and Art Blakey.\nFamously, Parker died at her New York hotel suite and Monk was nursed by her in the last 10 years of his life, and the likes of Horace Silver, Gigi Gryce, Monk and Blakey wrote enduring musical tributes to her which have become classics. Yet the popular press in the US often portrayed her in a less than flattering light, as a comical, sometimes even parasitical figure.\nApart from a recent BBC film and some charming but brief verite appearances in the Clint Eastwood-produced Monk documentary ‘Thelonious Monk: Straight No Chaser’, official studies of the Baroness have been few and far between. David Kastin’s ‘Nica’s Dream’attempts to redress the balance with a fast-moving, entertaining account of this glamorous, poshly-spoken dame with the cigarette holder and silver hip flask who piloted her own plane across the English Channel, married a French baron, fought in the French Resistance and had five children!\nBut the jazz life came calling after Nica heard Cootie Williams‘ 1944 version of ‘Round Midnight’, written by pianist Thelonious Monk, and she famously left her family, moved to Manhattan and started to frequent the city’s nightclubs.\nDespite her standing in the legendary European banking dynasty, her Rothschild identity was a source of great satisfaction for the many marginalised black musicians she befriended. While tabloid stories about an attractive, white heiress openly consorting with African-American jazz musicians fuelled the era’s racial and sexual hysteria, the bond Nica formed with the jazz community easily sidestepped the stereotypes. As Monk himself declares with unmistakable delight in the ‘Straight No Chaser’ documentary, ‘I’ll tell everyone who you are. I’m proud of you. She’s a billionaire! She’s a Rothschild!’ And pianist Hampton Hawes wrote, ‘I suppose you would call Nica a patron of the arts. She was like a brother to the musicians who lived in New York. There was no jive about her, and if you were for real, you were accepted and were her friend.’\nKastin steers away from too much exposition about Nica’s background and wisely cuts snappily to the New York of the ’40s and ’50s, where her silver Rolls-Royce (nicknamed The Silver Pigeon) was an unlikely fixture on 52nd Street. Kastin expertly brings to life this golden age of New York life, a world of taxi cabs, sharp suits, smoky nightclubs and lightning-fast bebop.\nThe book opens with a gripping but grim account of Charlie Parker’s death in Nica’s Stanhope Hotel suite in 1955, piecing together the tragic events and putting them in a contemporary context, drawing on the tabloid reports of the time and Nica’s own version of events outlined both in Nat Hentoff‘s famous Esquire magazine profile and Robert Reisner’s ‘Bird: The Legend Of Charlie Parker’. Kastin then devotes a large section to Nica’s relationship with Monk, the bebop genius who was a regular visitor to Stanhope and recipient of a $10,000 mink coat. He later wrote ‘Pannonica’ for her at the piano in her Algonquin Hotel suite, and Nica watched out for him throughout his troubled life.\nThe anecdotes come thick and fast, some predictable, others completely unexpected and inspiring. Kastin reveals that the Baroness bought matching Ivy League suits, shirts, ties and shoes for Art Blakey’s Jazz Messengers and often bailed them out when they were refused payment by dodgy nightclub owners while touring in the Midwest.\nAnd one night in the late ’50s, Nica was driving Monk, his wife Nellie and Hampton Hawes home from a club engagement on Seventh Avenue in New York when none other than Miles Davis pulled alongside in his Mercedes and shouted out, ‘Wanna race?’ Nica replied in the affirmative. She then turned round to Monk and announced in her prim English tones, ‘This time, I believe I’m going to beat the motherfucker!’\n‘Nica’s Dream‘ is published by WW Norton & Co.', 'While surfing the web the following item caught my eye….\nJimmy Cobb (January 20,1929 – May 24, 2020) drummer on Miles Davis’s ‘Kind of Blue,’ Dies at 91. He was the last surviving member of that landmark album’s sextet, he was a master of understatement, propelling his band mates with a quiet persistence.\nIt was this “blast from the past” that prompted me to revisit the album. Most Jazz fans “have the moment” imprinted on their memory of when they first heard KIND OF BLUE. For me it was during a lunch time break in a record store (remember those) in down town Sydney, Australia. In those days there were head phones or listening booths available to check out the latest releases. The radio in those days was awash with top Forty Tunes and Jazz wasn’t all that popular. Apart from late night smooth jazz radio to get one’s jazz fix you had to get it when ever and where ever you could. For me it was those lunch times listening sessions in a record store. The opening track on the album, SO WHAT, became my all time favorite Jazz composition and performance. Here is that opening track from the classic album followed by a live clip from a TV show.\nWhile the tune in both instances is the same a discerning ear can detect distinct differences between the performances. The first clip from the recording is the classic Miles Davis Sextet of Miles Davis (trumpet), John Coltrane (Tenor Sax), Julian Adderley (Alto Sax), Paul Chambers (Bass), Jimmy Cobb (Drums) and Bill Evans (piano). The contours of the solos played by John Coltrane (tenor sax) and Miles Davis (trumpet) in both clips are similar but demonstrate the variety available within jazz performances of the same material.\nThe album KIND OF BLUE was recorded recorded on March 2 and April 22, 1959, at Columbia’s 30th Street Studio in New York City. It was released on August 17 of that year by Columbia Records and in the past 60 years has never been out of print. It is regarded as the best selling jazz album of all time and because of its unique approach to composition and performance it has been deemed as one of the most influential records of all times. On this album Davis followed up on his modal experimentation on his earlier Milestones album. By basing Kind of Blue entirely on modality he departed even further from his earlier work in the hard bop jazz style.\nWhy the recording is so important in the Jazz repertoire is that it was a radical departure from the way jazz musicians normally approached performances. Throughout the early history of Jazz up until the 50s and even later, the main stay of the Jazz repertoire was what was called THE GREAT AMERICAN SONG BOOK. It was a standard repertoire filled with the songs of Cole Porter, George Gershwin etc. Generally a performance of these songs included an instrumental statement of the tune, sometimes with variations followed by individual solos by various instrumentalists. The underlying chord structures and melody line were the basis for the improvisations that applied time honored musical devices to shape individual performances. The songs may have had mundane lyrics (moon, June, love, spoon, etc) but the melodies and the harmonic structures were (are) pretty sophisticated. Jazz musicians often ditched the standard melody and made up ones of their own. Sometimes they just used the chord progressions and came up with completely different compositions. KIND OF BLUE changed that. Instead of using chord progressions for the improvisations Miles Davis came up with a Modal approach. It was no longer necessary to play in a specific key, rather the composer could dictate a series of modes to act as basic scales for the improvisation.\n“So What is one of the best examples of modal jazz music. Although improvisation takes up the majority of the piece, it does have a compelling riff that sets the piece in motion and sets up the stage harmonically for the improvisations. This riff is notable in that involves the interplay between the upright bass and the rest of the band. The antecedent phrase is played by the bass, which plays an ascending line of notes that begin with a fourth leap starting from the root note. This is followed by the “response” by the piano or rest of the band, which consists two chords that move in parallel motion downwards in answer to the bass. These chords are a whole step apart and are made up of a root, fourth, minor seventh, minor third, and fifth. The second chord-and final statement of the phrase-is an altered minor chord. This establishes the harmonic center of the piece.\nHarmonically speaking, this piece is fairly simple. It is centered around the D Dorian mode, and there are no harmonic progressions other than the modulation from D Dorian to Eb Dorian, which occurs throughout the piece. The piece follows a 32 bar AABA structure, both during the melodic line and during the solos. This translates to 16 bars in D Dorian, 8 bars in Eb Dorian, and 8 bars again in D Dorian. The piece begins with a piano and bass opening with a slower tempo than the rest of piece. After this bass and piano alone play the melodic line with the drum as accompaniment. The drums serve to get the atmosphere going with a laid back, ‘cool’ atmosphere. The other instruments join in and after one chorus, each performer takes an extended solo in the following order: trumpet, tenor sax, alto sax, and piano. After the solos, the melody line is played for a chorus. The piece ends with the melody being just played with the bass and piano (with drums for accompaniment) before fading out.\nThe harmonic simplicity of So What gives the instrumentalists a certain freedom in their improvisations not found in other forms of jazz music. The differing creative approaches are evident in each of the different solos; for example, Miles Davis’ solo can be characterized as very melodic which is mainly focused on thoughtful phrasing whereas Coltrane uses a harder and often scalar approach, playing faster and leaving less space between his phrasings. Despite this, the atmosphere throughout So What remains mostly unchanged thanks to the vamping of the rhythm section and the careful upholding of the structure of the piece. The composition and the performance is a Jazz Masterpiece. Miles Davis was famous for approaching recording sessions with no set agenda. Just a sketch of some scales or chord progressions to be played with very loose instructions to the participants about tempo, structure and what he wanted to achieve. KIND OF BLUE and SO WHAT conform to Miles’ general approach to recording. In his later electronic explorations (BITCHES BREW, etc) he even took it further using the recording studio as a compositional tool. Literally editing, cutting and pasting and shaping the final product (I find it hard to call it a performance) to his compositional needs. Miles never dwelled on his musical past and in later years when asked about the recording he tended to be dismissive of the effort and basically had the attitude “been there done that and I have moved on”.\nModal Jazz, in some ways reaches back to earlier classical and folk music ways of playing music. It did not replace the time honored Great American Song Book, rather it opened the door to different ways of composing, playing and improvisation. FREE JAZZ, a later development in jazz performance , was another way of organizing (some would say disorganizing) the music …. no prepared structure, no set key, rhythm etc. Here in 2020 it has been around for 50 years and while is still has a significant following it remains controversial.\nI have this uncalled, and I dare say sometimes unwelcome urge to educate my peer musicians in some of the finest recordings out there. I sent these clips out to friends and one response astounded me. The composition and performance was described as and interesting “song” and it kind of illustrates the difficulties modern audiences have with instrumental music. Calling SO WHAT a song is like calling Beethoven’s A minor STRING QUARTET #15 a song. We are all used to listening to “songs” but most of us have little or no educated experience with listening to instrumental compositions. As a result a large percentage of audiences have no sign posts to help them understand the music. Instrumental music is about the architecture of the piece; the use of melody, harmonic invention, rhythm and variations within all of those elements. Songs, as typified by the normal singer/song writer, and instrumental compositions in the Jazz and Classical traditions operate at two different levels and there is no way to really compare the two. Songs tend to be (not always of course) factual and concrete and generally touches our humanity with portrayals of every day circumstances and emotions. Instrumental music on the other hand tends to be more abstract and puts us in touch with music at a more mystical level.\nEach musical style or school has a specific, and often unique, way of composition and performance. For instance, Arab and Middle Eastern music is based on completely different concepts of harmony, melody and rhythmic rules to western music. To understand and appreciate that music requires a re-education in the rules of the game. Similarly, Northern and Southern Indian Classical Indian that, to some extent , came from the Arabs is different again. In fact Northern and Southern Indian traditions are sufficiently different to require another re-think when moving from one tradition to the other.\nCloser to home, Celtic Music is based on time honored airs and dance tunes with a large component of modal methods and a different feel to the music. Blue Grass had its origins in Celtic music but the feel is different. To my ears Blue Grass musicians do terrible things to Celtic tunes. At a Celtic music session in Dublin I once asked my daughter in law what she thought of the music. Her response was “it all sounds the same to me”. For most people that is the response to most, if not all, instrumental music …… “It all sounds the same to me”.\nBut with a little bit of effort it does not all have to “sound the same to me”\nPost Script. Over the years there must be thousands and thousands of words examining, defining and analyzing the album KIND OF BLUE. One book of note that I can recommend is KIND OF BLUE – THE MAKING OF THE MILES DAVIS MASTERPIECE, by Ashley Kahn, Da Capo Press Books, 2000.']	['<urn:uuid:8ce92dbb-f82c-4908-a3b9-ae0bccaae595>', '<urn:uuid:95fe39f0-71d4-4efc-b1e8-982092d8580b>']	open-ended	direct	long-search-query	similar-to-document	comparison	novice	2025-05-12T15:09:02.012753	11	112	2501
57	dna markers disease resistance tomato melon breeding applications main uses farming crops	Molecular DNA markers are used in both tomato and melon breeding to identify and combine disease resistance genes. In tomatoes, markers help stack resistance to multiple pathogens and races of diseases like Fusarium wilt. Similarly in melons, markers help characterize disease resistance traits from diverse varieties. These markers allow breeders to select desired traits at the seedling stage and efficiently combine multiple resistance genes into improved crop varieties.	"[""|Lopez-Sese, A - CSIC, MALAGA SPAIN|\n|Gomez-Guillamon, M - CSIC, MALAGA SPAIN|\nSubmitted to: Theoretical and Applied Genetics\nPublication Type: Peer Reviewed Journal\nPublication Acceptance Date: June 7, 2003\nPublication Date: October 15, 2003\nCitation: Lopez-Sese, A.I., Staub, J.E., Gomez-Guillamon, M.L. 2003. Genetic analysis of spanish melon (cucumis melo l.) germplasm using a standardized molecular marker array and reference accessions. Theoretical and Applied Genetics. Interpretive Summary: Plant species differ genetically for visual (phenotype) and cellular (pertaining to the cell) traits. Fruit yield and fruit quality are examples of phenotypic traits. The analysis of DNA (contained in the cell) of organisms is now used to determine differences between plants. The biotechnological tool associated with the analysis of DNA is called molecular marker analysis. Molecular markers are segments of DNA used to identify differences in DNA between organisms. Melon varieties differ in their plant habit (stature as small or large) and their DNA. Although Spanish melons differ in phenotype from U.S. melon types, the extent of differences in their DNA is not known. In contrast to U.S. melon varieties that are uniform (hybrids), Spanish melons are not uniform and are referred to as landraces. There are many attributes in Spanish landraces that might be used to improve U.S. melon (e.g., pest and disease resistance, fruit quality, and long self life). However, in order for U.S. public and private plant breeders to utilize Spanish landraces in their plant improvement programs, the phenotype and DNA variation (differences) among these landraces must be characterized and compared to the U.S. melon types. Therefore, an experiment was designed and executed to determine the phenotype and DNA variation among Spanish melon landraces. The data indicate that U.S. and Spanish melon are very different in both phenotype and DNA. The data also provide the plant breeder with working strategies for the incorporation of genes from Spanish landraces into U.S. melon types. This will allow the plant breeder to work more efficiently and effectively, and thus shortened the time to develop improved melon varieties for U.S. consumption. Improved melon varieties will in turn make the U.S. grower more competitive while providing an unique product to the U.S. consumer.\nTechnical Abstract: Genetic relationships among 125 Spanish melon (Cucumis melo L.) accessions from the germplasm collection at the regional Experimental Station, La Mayora (CSIC) Málaga, Spain were assessed using a standard molecular marker array consisting of 34 random amplified polymorphic DNA (RAPD) markers bands (19 primers) and 72 reference accessions drawn from previous studies. The reference accession array consisted of a broad range [Japanese (19) Crete (17), African (15) and USA and Europe (US/EU, 21)] of horticultural groupings (C. melo subsp. melo: Group Cantalupensis, Group Conomon, Group Inodorus, Group Flexuosus, and Group Chito), and of melon cultivar-groups (e.g., Charentais, Shipper (U.S. Western and European), Ogen, and Galia, Honeydew and Casaba). Cluster analysis of variation at polymorphic loci revealed that Spanish melon (largely Group Inodorus, Casaba melon types) was genetically distinct from the reference accessions and other Group Inodorus melons of different origins. Most African accessions showed common genetic affinities, and grouped with the Group Chito and Group Conomon accessions examined. Those accession groupings were distinct from all other accessions belonging to Group Cantalupensis, Flexuosus, and Inodorus accessions originating from Crete, Japan, Europe, and the U.S. Genetic diversity (relative polymorphism level as a ratio of percentage of polymorphism: number of accessions) was highest in accessions of African origin (5.7) and lowest in accessions of Spanish origin (0.7). Likewise, polymorphism level in Group Conomon (19.9) and Group Chito (10.3) was higher than Group Inodorus accessions (0.6). Additional RAPD markers (49 primers, 141 bands) and 22 selected agronomic traits (quantitative and qualitative) were then used to assess the genetic diversity among Spanish accessions. Cluster analysis using only fruit characteristics grouped accessions into cultivar-groups. In contrast, cluster analysis using only RAPD-based genetic distance estimates (GD; Jaccard's coefficient) did not provide consistent accession groupings either by cultivar-group or geographic origin. The mean GD among all Spanish accessions was 0.31 ± 0.08. The highest level of polymorphism based on population size was detected among melons originating from the central region of Spain (7.0-8.8), and in the Rochet cultivar-group (7.6). In contrast, melon accessions from the Andalucía region (1.6) and Green melon cultivar-groups (1.9) were comparatively less diverse. Cultivar-group heterogeneity was estimated by RAPD-based examination of accessions grouped by morphological analysis. The relatively high level of heterogeneity observed within cultivar-groups indicates that the Spanish melon accessions examined could be used to broaden the genetic base of local and foreign Casaba germplasm. Moreover, data indicate that the genetic diversity of U.S and European commercial melon germplasm (i.e., Groups Cantalupensis and Inodorus) could be enhanced by the introgression of genes from Spanish accessions, and that it would be advantageous to acquire additional Spanish landraces to ensure the retention and diversification of existing genetic diversity of the CSIC and other regional collections."", 'Foolad and Panthee (2012) give an excellent review of Marker Assisted Selection (MAS) in tomato breeding, providing more detail than intended here. Our goal is to explain the basics and give examples of how this tool can be used by tomato breeders, and how we are employing the technology in our breeding program.\nThere are various types of molecular markers that can be used in breeding (e.g. SNP, AFLP, SCAR, CAPS and SSR), but these all represent a short DNA sequence with a known physical location in the genome – essentially “mile markers” on the roadmap that defines structural characteristics of the plant DNA sequence. For example there are tens of thousands of SNP markers now placed on the physical map of the tomato genome. When one of these markers is adjacent to (or within) a gene of interest, such as a gene associated with resistance to a particular pathogen, the marker and the gene co-segregate – and selection for the marker is an effective surrogate for selection for the trait.\nPCR-based genotyping can be used to quickly confirm presence or absence of a particular molecular marker, and some marker types (including SNPs) can determine whether the plant contains one (heterozygous) or two (homozygous) copies of the marker. These assays are conducted on DNA extracted from a very small amount of plant tissue, and thus can be performed on very young seedlings.\nSome of the advantages are obvious:\n1) The presence of the molecular marker can be confirmed at the seedling stage, and not reliant on a trait phenotype that is expressed several weeks later (e.g. fruit color), or on a phenotype that is dependent on particular environmental conditions (e.g. disease resistance). Early selection allows early culling of undesirable plants based on genotype rather than phenotype. Early culling means that only those plants pre-selected for the desired trait or combination of traits go to field breeding nurseries or crossing programs.\n2) Trait stacking is the breeding process for combining multiple desirable traits into a single breeding line. The first step always involves using crossing to bring the multiple traits into a single breeding population. The second step, greatly aided by MAS, is to identify low frequency plants in the breeding population that contain all the traits of interest. For example: the cross AABBCC x aabbcc, where genes A and B control resistance to two independent tomato pathogens (e.g. ToMV and LB) and resistance is dominant, and c is a desirable recessive allele for a trait for fruit color (e.g. ogc/crimson). The F1 progeny will all be AaBbCc and in the F2 only one plant in 64 will have the desired stable genotype AABBcc. Now think about stacking 7-8 genes (which we are) - MAS allows the efficient testing of hundreds of F2 progeny to find the “needles in the haystack” combing the desired traits. When stacking more than 3 traits it will likely be necessary to do this in a stepwise fashion.\nHow is MAS being used today?\nMolecular markers have now been identified for many of the multiple genes associated with resistance to key tomato diseases and nematodes, and in some cases to the multiple races of the diseases now prevalent (e.g, all three races of Fusarium wilt). Commercial breeders have been successful at stacking resistance to most of these key pathogens in newer hybrids – with MAS being a critical tool in such stacking.\nMolecular markers have also been identified for a handful of other major genes controlling important traits – but it is a short list: tomato fruit color - red vs yellow and crimson vs red; fruit size - locule number; plant type - determinant vs indeterminant; and presence of the rin allele associated with delayed ripening. Some of the major genes controlling plant/fruit phenotype are shown below (photo courtesy of University of Newfoundland) - linked molecular markers are available for a few of these.\n|Map of major genes controlling plant/fruit phenotype|\nAll of the examples cited above involve major genes providing control of simply inherited traits. However we know that many important traits are quantitative traits, controlled by multiple genes – typically each with a small, but cumulative effect. Quantitative trait loci (QTL) are molecular markers associated with genes/alleles contributing to a quantitative trait – such a fruit yield, fruit size and fruit flavor. MAS allows the effective stacking of QTLs that in concert have a major impact on a “hard to breed for” quantitative traits.\nHarry Klee and his colleagues at the University of Florida have been working to unlock the mystery of flavor in tomatoes. What are the multiple components of flavor, how do they interact, and what is the genetic control of these factors? I am confident this will eventually lead to QTLs associated with key flavor components – facilitating breeding for better tasting tomatoes.\nUniversity breeding programs and the larger commercial tomato breeding companies all have access to the tools required for MAS. Thankfully there are also a few commercial companies that conduct such activities on a fee for service basis, which allows the smaller players (FLF included) access to these tools. Such access is a significant incremental expense per se, but allows cost savings, and an accelerated timeline in the long run.\nOur breeding program started with crosses between heirloom types with a primary goal to improve flavor and plant health. After a couple years we started crossing these to a handful of commercial types, including a couple of the NCSU hybrids, to introduce improved disease tolerance and improved fruit quality.\n|Disease resistant X Great Flavor|\nWe are now using molecular markers to identify progeny from these crosses which combine resistance to multiple pathogens – and will follow that genotypic selection with phenotypic selection for flavor and fruit quality in our various breeding nurseries. The use of molecular markers and our recent access to facilities allowing 3 breeding generations/yr should allow us to soon commercialize new F1 hybrids with state-of-the-art disease resistance, best-in-class heirloom flavor, and in a rainbow’s array of colors and stripes.\nMAS-enabled multiple disease resistant F4 - a F1 parent ""in training""']"	['<urn:uuid:cee97b7c-dcfb-4151-ba52-3af943fe7e5b>', '<urn:uuid:a597e8bd-fabe-4f8d-b3cd-39cdc1b36dfb>']	factoid	with-premise	long-search-query	similar-to-document	three-doc	novice	2025-05-12T15:09:02.012753	12	68	1825
58	What makes buildings energy efficient and how do cities regulate them?	Buildings achieve energy efficiency through various rating systems and standards. A key measure is the Home Energy Rating System (HERS), where lower scores indicate better efficiency - for example, a score of 34 means 66% more efficiency than typical new homes. Programs like Energy Star for Homes, LEED, and Zero Energy Ready Homes certify efficiency levels. As for regulation, cities like Berkeley require compliance with the California State Green Building Code (CALGreen) and have additional requirements. These include mandatory energy conservation measures for existing buildings (RECO/CECO), stormwater management requirements, and water efficiency regulations through EBMUD. Buildings must meet these standards when obtaining building permits or undergoing renovations.	"['Many programs have been established to measure the energy efficiency and environmental impact of new buildings. The plethora of options can make it difficult even for those of us in the industry to keep track of the programs and acronyms. This post attempts to shed light on the more popular rating systems, and the ways in which Unity Homes is meeting or exceeding their targets.\nThe building geeks out there will likely be very impressed to learn that a Unity Home was recently awarded a HERS rating of 34 (and without incorporating renewable energy). Those who are not versed in home energy rating systems might be interested to know what this means, and why we believe it’s important.\nHERS stands for Home Energy Rating System, and it was developed by RESNET – the Residential Energy Services Network. The HERS rating measures energy efficiency, and it is indexed to the performance of a typical new code-compliant home. The HERS rating of a standard new home is by definition 100. Any rating lower than 100 represents the percentage improvement in energy efficiency over the typical new home. In other words, a new home with a HERS rating of 70 performs 30% better than the average new home. The Unity Home that recently came in with a HERS rating of 34 is 66% more energy efficient than a typical new home! The impressive efficiency of a Unity Home translates into attributes that directly affect the quality of life of the building’s occupants: comfort, quiet, health, low maintenance and predictable, affordable operating costs.\nAnother rating system that has been widely adopted is the Environmental Protection Agency’s Energy Star for Homes program, which grew out of the EPA’s Energy Star Appliance program. As with most green building rating systems, Energy Star for Homes has evolved as building codes have become more stringent and building practices have improved. Version 3 of the Energy Star for Homes program, which took effect in 2011, requires (among other things) that a HERS rating be established for each home. The rating is one of several factors used to establish compliance with the program. While the Energy Star for Homes program has had an admirable impact on raising awareness and increasing efficiency in the home building industry — and many state and utility incentives are based on it — Unity has tended not to emphasize the program, simply because we believe that more rigorous standards are necessary and achievable.\nMany people are familiar with the LEED rating system, which stands for Leadership in Energy and Environmental Design. Originally conceived in the mid-1990s by the United States Green Building Council (USGBC), the LEED system has over the years become one of the most widely-used green building benchmarks in the US. The LEED system has evolved to include programs aimed at specific building types and construction scenarios. Unity’s sister company Bensonwood has built eight LEED-certified homes to date, and many more that are considered “LEED certifiable.” One of Unity’s most recent projects, the Greenbuild 2015 Unity Show Home, is on track for LEED Platinum designation — the highest level. As successive improvements to the LEED program have been developed in response to criticisms related to energy performance and other factors, LEED has cemented its position as the standard, at least for commercial buildings, in the US.\nThe stringent Passive House standard originally developed in Germany has gone from being a fringe player in the US to garnering increasingly broad support. The Passive House built by Bensonwood in Vermont in 2010 demonstrated the wisdom of using off-site construction techniques to clear such a high bar. A key to the performance of Passive Houses is the air-tightness requirement of 0.6 ACH50, a standard that Unity hits regularly with its homes (ACH50 is “air changes per hour” at a depressurization of 50 Pascals).\nSam Rashkin, who was key to developing Energy Star for Homes when he was at the EPA, is now championing a US Department of Energy program called Zero Energy Ready Homes (ZERH) that we at Unity are planning to adopt. This program takes a holistic approach to establishing standards for homes that would be considered “ultra-high performance” from a conventional perspective, but that we at Unity call “typical.” Our homes are designed, engineered and built to be Zero Energy Ready: with the addition of a modest solar electric system, they produce as much energy as they consume.\nWhile the Zero Energy Ready capability of Unity Homes is impressive, some green building thought leaders suggest that this standard does not go far enough. The Living Building Challenge is based on the notion that buildings should not just have a net zero impact on the environment; rather, they should be net positive in terms of energy, water and waste, and they should contribute to the resiliency of the communities in which they are located. Bensonwood recently provided the engineered timber structure to a new building at Hampshire College that has been designed and engineered to meet the criteria of the Living Building Challenge.\nAs the environmental impact of buildings is increasingly recognized and quantified, Unity Homes will continue to work at lowering the cost of homes that are highly rated, comfortable for the inhabitants and easy on the planet.', ""Green Building Requirements\nBuilding Sustainably Green buildings provide healthy, comfortable building interiors that maximize savings through the efficient use of energy and water and limit construction impacts on the natural environment. The City of Berkeley requires that new buildings, alterations, and additions meet the requirements of the California State Green Building Code (CAL Green). Documentation of compliance with CALGreen must be provided with plans submitted for building permits; see CALGreen New Residential Checklist and CALGreen Addition Alteration Residential Checklist. Green building requirements for projects requiring a Zoning Use Permit (UP) or Administrative Use Permit (AUP) are listed below, for more information see Green Building Requirements.\nIn addition, Berkeley has supplemental green building policies that ensure that we continue to divert waste from landfills, reduce energy and water usage in our buildings, and help our community meet our environmental and Climate Action Plan goals.\nGreen Design A green building takes a holistic approach to design, siting, construction, and operation to enhance the well being of its occupants and minimize the negative impacts on the community and natural environment.\nEnergy An energy-efficient building reduces greenhouse gas emissions, lowers utility bills, and improves comfort.\n- Energy Conservation Analysis: Required for large (10,000 sq.ft. or more) commercial projects and recommended for multifamily and mixed-use projects. A free analysis is available through PG&E's Savings By Design program. For multifamily projects, receive energy design assistance and cash incentives, see Heschong Mahone Group.\n- Energy Conservation Measures RECO/CECO: RECO/CECO requires existing buildings to make updates to save energy and water when properties are remodeled or sold. Residential projects must comply with RECO and commercial projects must comply with CECO.\nWater: Controlling stormwater runoff protects the San Francisco Bay and our local creeks and watersheds. Construction activities are the largest source of stormwater pollution in the Bay. Water conservation helps save water while saving money and energy.\n- Reduction of Stormwater Pollution: All construction projects must manage stormwater pollution. The Stormwater Requirements Overview summarizes the onsite stormwater treatment and required checklists for projects based on the quantity of impervious surface that they create or replace.\n- Protecting Health of Creeks: Requirements vary depending on project scope and distance from the creek. The City has developed a Creeks Map that depicts open and culverted creeks available at the Creeks Ordinance website.\n- Fixing Leaks in Sewer Laterals: Required for remodeling projects and when properties are sold, see Sewer lateral replacement.\n- East Bay Municipal Utility District (EBMUD) Section 31 Water Efficiency Regulations: All applicants for new and expanded service are required to comply, see EBMUD Water Efficiency Checklist.*\n- Bay Friendly Basics Landscape Requirements: Required for all new and renovated irrigated landscape over 2,500 square feet. The Bay-Friendly Basics represents the 9 required practices from the Bay-Friendly Landscape Scorecard, see Bay Friendly Checklist.*\n*California Water Efficient Landscape Ordinance (WELO) requirements are met through compliance with Bay Friendly and EBMUD Water regulations, no additional action is needed.\nWaste: Conservation and reuse of building materials and recycling construction and demolition debris saves valuable resources and landfill space.\nZoning submittal requirements, see Green Building Requirements\nSearchable database by address (Parcel Popper), see Building Permit History and Parcel Conditions\nSearchable database of City codes, see Municipal Code and Zoning Ordinance\nFrequently requested forms and documents, see Permit application forms, submittal guidelines & forms\nGuides on a range of topics to help you green your building project, see Green Building Permit Guides\nCity of Berkeley Office of Energy and Sustainable Development\nGreen Building in Alameda County\nBuild It Green\nU.S. Green Building Council (USGBC)\nEast Bay Municipal Utility District (EBMUD)""]"	['<urn:uuid:f2923b2c-bd5d-4e9d-8474-fd8c726f73eb>', '<urn:uuid:4cfceb16-f1b3-42e8-acc4-0dd0b056f753>']	open-ended	direct	concise-and-natural	distant-from-document	multi-aspect	novice	2025-05-12T15:09:02.012753	11	107	1470
59	how many different genetic variations found in swedish porphyria patients study	In the study of Swedish acute intermittent porphyria families (Lundin et al.), seven variants were identified: TRP-116, LEU-119, GLN-167, TRP-167, TRP-173, TRP-201, and ASP-216.	"['Variant position: 173 The position of the amino-acid change on the UniProtKB canonical protein sequence.\nProtein sequence length: 361 The length of the canonical sequence.\nLocation on the sequence:\nThe residue change on the sequence. Unless the variant is located at the beginning or at the end of the protein sequence, both residues upstream (20) and downstream (20) of the variant will be shown.\nResidue conservation: The multiple alignment of the region surrounding the variant against various orthologous sequences.\nHuman QLQRKFPHLEFRSIRGNLNT RLRKLDE-QQEFSAIILATAGL\nMouse QLQRKFPHLEFKSIRGNLNT RLRKLDE-LQEFSAIVLAVAG\nRat QLQRKFPHLEFKSIRGNLNT RLRKLDE-QLEFSAIILAVAG\nBovine QLQRKFPHLEFKSIRGNLNT RLRKLDE-LQEFSAIILATAG\nSlime mold QLKKAYPHLQFKDIRGNLNT RFKKLEDDSNGYDGMILAVAG\nBaker\'s yeast QLKRKYPHLKFESVRGNIQT RLQKLDDPKSPYQCIILASAG\nFission yeast LLARNFPHLRFVDIRGNVGT RLAKLDAPDSQFDCLVLAAAG\nSequence annotation in neighborhood: The regions or sites of interest surrounding the variant. In general the features listed are posttranslational modifications, binding sites, enzyme active sites, local secondary structure or other characteristics reported in the cited references. The ""Sequence annotation in neighborhood"" lines have a fixed format:\nType: the type of sequence feature. Positions: endpoints of the sequence feature. Description: contains additional information about the feature.\nType Positions Description\n2 – 361 Porphobilinogen deaminase\n170 – 179\nIdentification of five novel mutations in the porphobilinogen deaminase gene.\nMgone C.S.; Lanyon W.G.; Moore M.R.; Louie G.V.; Connor J.M.;\nHum. Mol. Genet. 3:809-811(1994)\nCited for: VARIANTS AIP GLN-116; TRP-173; ARG-177; ILE-269 AND ARG-274;\nGenetic investigation of the porphobilinogen deaminase gene in Swedish acute intermittent porphyria families.\nLundin G.; Lee J.-S.; Thunell S.; Anvret M.;\nHum. Genet. 100:63-66(1997)\nCited for: VARIANTS AIP TRP-116; LEU-119; GLN-167; TRP-167; TRP-173; TRP-201 AND ASP-216;\nIdentification and characterization of hydroxymethylbilane synthase mutations causing acute intermittent porphyria: evidence for an ancestral founder of the common G111R mutation.\nDe Siervi A.; Rossetti M.V.; Parera V.E.; Astrin K.H.; Aizencang G.I.; Glass I.A.; Batlle A.M.C.; Desnick R.J.;\nAm. J. Med. Genet. 86:366-375(1999)\nCited for: VARIANTS AIP PRO-34; ARG-111; TRP-173; TRP-201; 329-LEU--GLN-332 DEL AND SER-335;\nComparison of complementary and genomic DNA sequencing for the detection of mutations in the HMBS gene in British patients with acute intermittent porphyria: identification of 25 novel mutations.\nWhatley S.D.; Woolf J.R.; Elder G.H.;\nHum. Genet. 104:505-510(1999)\nCited for: VARIANTS AIP CYS-22; CYS-26; HIS-26; PRO-31; SER-42; ASN-61; ARG-85; GLY-90; ARG-111; GLN-173; TRP-173; ARG-177; CYS-195; ASP-219; ARG-247 AND ILE-269;\nIdentification and expression of mutations in the hydroxymethylbilane synthase gene causing acute intermittent porphyria (AIP).\nSolis C.; Lopez-Echaniz I.; Sefarty-Graneda D.; Astrin K.H.; Desnick R.J.;\nMol. Med. 5:664-671(1999)\nCited for: VARIANTS AIP ARG-111; TRP-116; TRP-167; TRP-173 AND VAL-212; CHARACTERIZATION OF VARIANT AIP VAL-212;\nAcute intermittent porphyria: novel missense mutations in the human hydroxymethylbilane synthase gene.\nRamdall R.B.; Cunha L.; Astrin K.H.; Katz D.R.; Anderson K.E.; Glucksman M.; Bottomley S.S.; Desnick R.J.;\nGenet. Med. 2:290-295(2000)\nCited for: VARIANTS AIP PRO-78; GLY-80; ARG-111 AND TRP-173;\nNine mutations including three novel mutations among Russian patients with acute intermittent porphyria.\nPischik E.; Mehtaelae S.; Kauppinen R.;\nHum. Mutat. 26:496-496(2005)\nCited for: VARIANTS AIP HIS-26; TRP-173; CYS-195; ARG-247 AND ALA-250; CHARACTERIZATION OF VARIANTS AIP HIS-26; TRP-173; CYS-195; ARG-247 AND ALA-250;\nConformational stability and activity analysis of two hydroxymethylbilane synthase mutants, K132N and V215E, with different phenotypic association with acute intermittent porphyria.\nBustad H.J.; Vorland M.; Ronneseth E.; Sandberg S.; Martinez A.; Toska K.;\nBiosci. Rep. 33:0-0(2013)\nCited for: BIOPHYSICOCHEMICAL PROPERTIES; VARIANT ASN-132; CHARACTERIZATION OF VARIANTS AIP TRP-116; TRP-167; TRP-173 AND GLU-215; CHARACTERIZATION OF VARIANT ASN-132;\nAny medical or genetic information present in this entry is provided for research, educational and informational purposes only. They are not in any way intended to be used as a substitute for professional medical advice, diagnostic, treatment or care.']"	['<urn:uuid:43255342-bb51-4e0f-9153-bf92da235d85>']	open-ended	with-premise	long-search-query	distant-from-document	single-doc	novice	2025-05-12T15:09:02.012753	11	24	582
60	differences between exponential and gaussian kernel functions	The Exponential kernel is closely related to the Gaussian kernel, with the main difference being that the Exponential kernel leaves out the square of the norm. Both are radial basis function kernels. The Exponential kernel, like the Gaussian kernel, requires careful tuning of the sigma parameter - if overestimated, the exponential will behave almost linearly and lose non-linear power; if underestimated, the function will lack regularization and be highly sensitive to training data noise.	['In recent years, Kernel methods have received major attention, particularly due to the increased popularity of the Support Vector Machines. Kernel functions can be used in many applications as they provide a simple bridge from linearity to non-linearity for algorithms which can be expressed in terms of dot products. In this article, we will list a few kernel functions and some of their properties.\n- Kernel Methods\n- Kernel Functions\n- Linear Kernel\n- Polynomial Kernel\n- Gaussian Kernel\n- Exponential Kernel\n- Laplacian Kernel\n- ANOVA Kernel\n- Hyperbolic Tangent (Sigmoid) Kernel\n- Rational Quadratic Kernel\n- Multiquadric Kernel\n- Inverse Multiquadric Kernel\n- Circular Kernel\n- Spherical Kernel\n- Wave Kernel\n- Power Kernel\n- Log Kernel\n- Spline Kernel\n- B-Spline Kernel\n- Bessel Kernel\n- Cauchy Kernel\n- Chi-Square Kernel\n- Histogram Intersection Kernel\n- Generalized Histogram Intersection Kernel\n- Generalized T-Student Kernel\n- Bayesian Kernel\n- Wavelet Kernel\n- Source Code\n- See Also\nKernel methods are a class of algorithms for pattern analysis, whose best known element is the support vector machine (SVM). The general task of pattern analysis is to find and study general types of relations (for example clusters, rankings, principal components, correlations, classifications) in general types of data (such as sequences, text documents, sets of points, vectors, images, etc).\nKMs approach the problem by mapping the data into a high dimensional feature space, where each coordinate corresponds to one feature of the data items, effectively transforming the data into a set of points in a Euclidean space. In that space, a variety of methods can be used to find relations in the data. Since the mapping can be quite general (not necessarily linear, for example), the relations found in this way are accordingly very general. This mapping approach is called the kernel trick.\nThe kernel trick can be applied to any algorithm that solely depends on the dot product between two vectors. Wherever a dot product is used, it is replaced by a kernel function. When done, linear algorithms are transformed into a non-linear algorithms. Those non-linear algorithms are equivalent to their linear originals operating in the range space of a feature space φ. However, because kernels are used, the φ function does not need to be ever explicitly computed. This is highly desirable, as sometimes our higher-dimensional feature space could even be infinite-dimensional and thus infeasible to compute.\nKernel functions must be continuous, symmetric, and most preferably should have a positive (semi-)definite Gram matrix. Kernels which are said to satisfy the Mercer’s theorem are positive semi-definite, meaning their kernel matrices have no non-negative Eigen values. The use of a positive definite kernel insures that the optimization problem will be convex and solution will be unique.\nHowever, many kernel functions which aren’t strictly positive definite also have been shown to perform very well in practice. An example is the Sigmoid kernel, which, despite its wide use, it is not positive semi-definite for certain values of its parameters. Boughorbel (2005) also experimentally demonstrated that Kernels which are only conditionally positive definite can possibly outperform most classical kernels in some applications.\nKernels also can be classified as anisotropic stationary, isotropic stationary, compactly supported, locally stationary, nonstationary or separable nonstationary. Moreover, kernels can also be labeled scale-invariant or scale-dependant, which is an interesting property as scale-invariant kernels drive the training process invariant to a scaling of the data.\nChoosing the most appropriate kernel highly depends on the problem at hand – and fine tuning its parameters can easily become a tedious and cumbersome task. Automatic kernel selection is possible and is discussed in the works by Tom Howley and Michael Madden.\nThe choice of a Kernel depends on the problem at hand because it depends on what we are trying to model. A polynomial kernel, for example, allows us to model feature conjunctions up to the order of the polynomial. Radial basis functions allows to pick out circles (or hyperspheres) – in constrast with the Linear kernel, which allows only to pick out lines (or hyperplanes).\nThe motivation behind the choice of a particular kernel can be very intuitive and straightforward depending on what kind of information we are expecting to extract about the data. Please see the final notes on this topic from Introduction to Information Retrieval, by Manning, Raghavan and Schütze for a better explanation on the subject.\nBelow is a list of some kernel functions available from the existing literature. As was the case with previous articles, every LaTeX notation for the formulas below are readily available from their alternate text html tag. I can not guarantee all of them are perfectly correct, thus use them at your own risk. Most of them have links to articles where they have been originally used or proposed.\nThe Linear kernel is the simplest kernel function. It is given by the inner product <x,y> plus an optional constant c. Kernel algorithms using a linear kernel are often equivalent to their non-kernel counterparts, i.e. KPCA with linear kernel is the same as standard PCA.\nThe Polynomial kernel is a non-stationary kernel. Polynomial kernels are well suited for problems where all the training data is normalized.\nAdjustable parameters are the slope alpha, the constant term c and the polynomial degree d.\nThe Gaussian kernel is an example of radial basis function kernel.\nAlternatively, it could also be implemented using\nThe adjustable parameter sigma plays a major role in the performance of the kernel, and should be carefully tuned to the problem at hand. If overestimated, the exponential will behave almost linearly and the higher-dimensional projection will start to lose its non-linear power. In the other hand, if underestimated, the function will lack regularization and the decision boundary will be highly sensitive to noise in training data.\nThe exponential kernel is closely related to the Gaussian kernel, with only the square of the norm left out. It is also a radial basis function kernel.\nThe Laplace Kernel is completely equivalent to the exponential kernel, except for being less sensitive for changes in the sigma parameter. Being equivalent, it is also a radial basis function kernel.\nIt is important to note that the observations made about the sigma parameter for the Gaussian kernel also apply to the Exponential and Laplacian kernels.\nThe ANOVA kernel is also a radial basis function kernel, just as the Gaussian and Laplacian kernels. It is said to perform well in multidimensional regression problems (Hofmann, 2008).\nThe Hyperbolic Tangent Kernel is also known as the Sigmoid Kernel and as the Multilayer Perceptron (MLP) kernel. The Sigmoid Kernel comes from the Neural Networks field, where the bipolar sigmoid function is often used as an activation function for artificial neurons.\nIt is interesting to note that a SVM model using a sigmoid kernel function is equivalent to a two-layer, perceptron neural network. This kernel was quite popular for support vector machines due to its origin from neural network theory. Also, despite being only conditionally positive definite, it has been found to perform well in practice.\nThere are two adjustable parameters in the sigmoid kernel, the slope alpha and the intercept constant c. A common value for alpha is 1/N, where N is the data dimension. A more detailed study on sigmoid kernels can be found in the works by Hsuan-Tien and Chih-Jen.\nThe Rational Quadratic kernel is less computationally intensive than the Gaussian kernel and can be used as an alternative when using the Gaussian becomes too expensive.\nThe Multiquadric kernel can be used in the same situations as the Rational Quadratic kernel. As is the case with the Sigmoid kernel, it is also an example of an non-positive definite kernel.\nThe Inverse Multi Quadric kernel. As with the Gaussian kernel, it results in a kernel matrix with full rank (Micchelli, 1986) and thus forms a infinite dimension feature space.\nThe circular kernel comes from a statistics perspective. It is an example of an isotropic stationary kernel and is positive definite in R2.\nThe spherical kernel is similar to the circular kernel, but is positive definite in R3.\nThe Power kernel is also known as the (unrectified) triangular kernel. It is an example of scale-invariant kernel (Sahbi and Fleuret, 2004) and is also only conditionally positive definite.\nThe Log kernel seems to be particularly interesting for images, but is only conditionally positive definite.\nHowever, what it actually mean is:\nThe B-Spline kernel is defined on the interval [−1, 1]. It is given by the recursive formula:\nIn the work by Bart Hamers it is given by:\nAlternatively, Bn can be computed using the explicit expression (Fomel, 2000):\nWhere x+ is defined as the truncated power function:\nThe Bessel kernel is well known in the theory of function spaces of fractional smoothness. It is given by:\nThe Chi-Square kernel comes from the Chi-Square distribution.\nThe Histogram Intersection Kernel is also known as the Min Kernel and has been proven useful in image classification.\nThe Generalized Histogram Intersection kernel is built based on the Histogram Intersection Kernel for image classification but applies in a much larger variety of contexts (Boughorbel, 2005). It is given by:\nThe Bayesian kernel could be given as:\nHowever, it really depends on the problem being modeled. For more information, please see the work by Alashwal, Deris and Othman, in which they used a SVM with Bayesian kernels in the prediction of protein-protein interactions.\nWhere a and c are the wavelet dilation and translation coefficients, respectively (the form presented above is a simplification, please see the original paper for details). A translation-invariant version of this kernel can be given as:\nWhere in both h(x) denotes a mother wavelet function. In the paper by Li Zhang, Weida Zhou, and Licheng Jiao, the authors suggests a possible h(x) as:\nWhich they also prove as an admissible kernel function.\nThe latest version of the source code for some of the kernels listed above is available in the Accord.NET Framework. Some are also available in the sequel of this article, Kernel Support Vector Machines for Classification and Regression in C#. They are provided together with a comprehensive and simple implementation of SVMs (Support Vector Machines) in C#. However, for the latest sources, which may contain bug fixes and other enhancements, please download the most recent version available of Accord.NET.\n- Kernel Support Vector Machines (kSVMs)\n- Principal Component Analysis (PCA)\n- Kernel Principal Component Analysis (KPCA)\n- Linear Discriminant Analysis (LDA)\n- Non-Linear Discriminant Analysis with Kernels (KDA)\n- Logistic Regression Analysis in C#\n- On-Line Prediction Wiki Contributors. “Kernel Methods.” On-Line Prediction Wiki. http://onlineprediction.net/?n=Main.KernelMethods (accessed March 3, 2010).\n- Genton, Marc G. “Classes of Kernels for Machine Learning: A Statistics Perspective.” Journal of Machine Learning Research 2 (2001) 299-312.\n- Hofmann, T., B. Schölkopf, and A. J. Smola. “Kernel methods in machine learning.” Ann. Statist. Volume 36, Number 3 (2008), 1171-1220.\n- Gunn, S. R. (1998, May). “Support vector machines for classification and regression.” Technical report, Faculty of Engineering, Science and Mathematics School of Electronics and Computer Science.\n- Karatzoglou, A., Smola, A., Hornik, K. and Zeileis, A. “Kernlab – an R package for kernel Learning.” (2004).\n- Karatzoglou, A., Smola, A., Hornik, K. and Zeileis, A. “Kernlab – an S4 package for kernel methods in R.” J. Statistical Software, 11, 9 (2004).\n- Karatzoglou, A., Smola, A., Hornik, K. and Zeileis, A. “R: Kernel Functions.” Documentation for package ‘kernlab’ version 0.9-5. http://rss.acs.unt.edu/Rdoc/library/kernlab/html/dots.html (accessed March 3, 2010).\n- Howley, T. and Madden, M.G. “The genetic kernel support vector machine: Description and evaluation“. Artificial Intelligence Review. Volume 24, Number 3 (2005), 379-395.\n- Shawkat Ali and Kate A. Smith. “Kernel Width Selection for SVM Classification: A Meta-Learning Approach.” International Journal of Data Warehousing & Mining, 1(4), 78-97, October-December 2005.\n- Hsuan-Tien Lin and Chih-Jen Lin. “A study on sigmoid kernels for SVM and the training of non-PSD kernels by SMO-type methods.” Technical report, Department of Computer Science, National Taiwan University, 2003.\n- Boughorbel, S., Jean-Philippe Tarel, and Nozha Boujemaa. “Project-Imedia: Object Recognition.” INRIA – INRIA Activity Reports – RalyX. http://ralyx.inria.fr/2004/Raweb/imedia/uid84.html (accessed March 3, 2010).\n- Huang, Lingkang. “Variable Selection in Multi-class Support Vector Machine and Applications in Genomic Data Analysis.” PhD Thesis, 2008.\n- Manning, Christopher D., Prabhakar Raghavan, and Hinrich Schütze. “Nonlinear SVMs.” The Stanford NLP (Natural Language Processing) Group. http://nlp.stanford.edu/IR-book/html/htmledition/nonlinear-svms-1.html (accessed March 3, 2010).\n- Fomel, Sergey. “Inverse B-spline interpolation.” Stanford Exploration Project, 2000. http://sepwww.stanford.edu/public/docs/sep105/sergey2/paper_html/node5.html (accessed March 3, 2010).\n- Basak, Jayanta. “A least square kernel machine with box constraints.” International Conference on Pattern Recognition 2008 1 (2008): 1-4.\n- Alashwal, H., Safaai Deris, and Razib M. Othman. “A Bayesian Kernel for the Prediction of Protein – Protein Interactions.” International Journal of Computational Intelligence 5, no. 2 (2009): 119-124.\n- Hichem Sahbi and François Fleuret. “Kernel methods and scale invariance using the triangular kernel”. INRIA Research Report, N-5143, March 2004.\n- Sabri Boughorbel, Jean-Philippe Tarel, and Nozha Boujemaa. “Generalized histogram intersection kernel for image recognition”. Proceedings of the 2005 Conference on Image Processing, volume 3, pages 161-164, 2005.\n- Micchelli, Charles. Interpolation of scattered data: Distance matrices and conditionally positive definite functions. Constructive Approximation 2, no. 1 (1986): 11-22.\n- Wikipedia contributors, “Kernel methods,” Wikipedia, The Free Encyclopedia, http://en.wikipedia.org/w/index.php?title=Kernel_methods&oldid=340911970 (accessed March 3, 2010).\n- Wikipedia contributors, “Kernel trick,” Wikipedia, The Free Encyclopedia, http://en.wikipedia.org/w/index.php?title=Kernel_trick&oldid=269422477 (accessed March 3, 2010).\n- Weisstein, Eric W. “Positive Semidefinite Matrix.” From MathWorld–A Wolfram Web Resource. http://mathworld.wolfram.com/PositiveSemidefiniteMatrix.html\n- Hamers B. “Kernel Models for Large Scale Applications”, Ph.D. , Katholieke Universiteit Leuven, Belgium, 2004.\n- Li Zhang, Weida Zhou, Licheng Jiao. Wavelet Support Vector Machine. IEEE Transactions on System, Man, and Cybernetics, Part B, 2004, 34(1): 34-39.\nCiting this work\nIf you would like, please cite this work as: Souza, César R. “Kernel Functions for Machine Learning Applications.” 17 Mar. 2010. Web. <http://crsouza.blogspot.com/2010/03/kernel-functions-for-machine-learning.html>.']	['<urn:uuid:0723620d-bb08-41a8-9878-fd8282cef526>']	open-ended	with-premise	short-search-query	similar-to-document	single-doc	expert	2025-05-12T15:09:02.012753	7	74	2289
61	frontotemporal dementia main characteristics	Frontotemporal dementia (FTD) has several types, each with distinct initial symptoms that converge as the disease progresses. The main characteristics include loss of inhibition leading to inappropriate behavior, problems with language such as trouble remembering or using the right words, and movement issues including rigid movements and lack of coordination.	"['Signs of Dementia\nDoes my loved one have dementia?\nIt\'s a question that many caregivers simultaneously want and dread the answer to.\nThere\'s a common misconception that the primary indicator of dementia is memory loss. The reality is that different forms of dementia have different signs.\nHere are some of the indicators that signal each type of dementia:\n- Memory loss: Early-stage Alzheimer\'s is almost always hallmarked by some form of memory loss. A person may experience difficulty trying to remember a particular word, or the name of someone they just met. They may also be more prone to losing important objects. Often, a person\'s short-term memory is the first thing affected by Alzheimer\'s. Memory loss gradually gets worse until long-term recollections are impacted as well. A person in the later stages of Alzheimer\'s won\'t be able to remember their own name, how to dress themselves, or even how to smile.\n- Trouble performing familiar tasks: A super-organized individual may become scattered as a result of Alzheimer\'s. Not remembering the route to the grocery store, or forgetting something they just read are two additional early-to-mid-stage Alzheimer\'s indicators.\n- Bad judgment: Unsound financial decisions, inappropriate public outbursts and an inability to understand and abide by social norms of cleanliness and grooming are all signs of increasingly poor judgment that may signify Alzheimer\'s.\n- Social withdrawal: People suffering from memory loss may be reluctant to engage in social activities. They are easily overwhelmed by large groups of people, even close friends and family.\n- Sundowning: When the sun goes down, an Alzheimer\'s sufferer may become fearful, agitated and sad. They may pace, hallucinate, shadow their caregiver and wander. This collection of emotions and subsequent behaviors is referred to as ""Sundowner\'s syndrome"" or ""sundowning."" Sundowning can be a sign of virtually any type of dementia, but is most often seen in individuals with Alzheimer\'s disease.\nDiscover more information about the signs, symptoms and treatment of Alzheimer\'s disease.\n- Hallucinations and delusions: Seeing, hearing, and even tasting things that aren\'t real is widely considered one of the first signs of Lewy Body dementia. Also occurring early on in the disease are persistent fictitious beliefs about a particular person or circumstance. For caregivers this particular dementia behavior can seem like manipulation.\n- Sleep troubles: Another early symptom of Lewy Body dementia is known as REM Sleep Behavior Disorder (RBD). A person with RBD will talk and move while still asleep. Once awake, they may struggle to distinguish between their dreams and reality. A person with RBD won\'t always develop Lewy Body dementia, but research suggests that about 66 percent of people with RBD will eventually develop a degenerative brain disorder, according to the Lewy Body Dementia Association.\n- Varying degrees of alertness: A person with Lewy Body dementia may experience periods of lucidity, interspersed with episodes of profound disorientation that may last anywhere from minutes to days. These cycles of confusion and clarity are not tied to any particular time of day, unlike the sundowning behaviors seen in people with Alzheimer\'s disease.\n- Movement issues: A person with Lewy Body dementia may resemble a person suffering from Parkinson\'s because of the effect the disease has on their ability to control their body and perceive their environment. Stiff movements, a hunched over posture and shuffling can all be physical manifestations of cognitive degeneration. These mobility issues also up a person\'s risk for falling.\n- Medication sensitivity: About half of Lewy Body dementia sufferers develop an extreme sensitivity to antipsychotic medications that can result in worsening of existing dementia symptoms, and Neuroleptic Malignant Syndrome, which can lead to death.\n- Memory and cognitive issues: Memory loss is typically one of the last symptoms to show up in people with Lewy Body dementia.\nDiscover more information about the signs, symptoms and treatment of Lewy Body dementia.\n- The symptoms of vascular dementia are different depending on which part of the person\'s brain was impacted by reduced blood flow. Memory loss, confusion, depression, problems with planning and organization, mobility issues and urinary incontinence are all possible signs that a person is suffering from vascular dementia.\nDiscover more information about the signs, symptoms and treatment of Vascular dementia.\nFrontotemporal Dementia (Pick\'s disease)\n- There are several types of frontotemporal dementia (FTD), each with their own set of initial symptoms that gradually begin to intersect as the disease gets worse.\n- Loss of inhibition: Saying and doing inappropriate things is a common sign that a person has developed some form of FTD.\n- Problems with language: A person who consistently has trouble remembering words, or using the right words to describe what they\'re talking about may suffer from FTD.\n- Movement issues: Similar to Lewy Body dementia, FTD can also cause rigid movements and a lack of coordination.\nDiscover more information about the signs, symptoms and treatment of Frontal Lobe dementia.']"	['<urn:uuid:524fcbc9-1fbf-4cee-87fb-4d81d252d244>']	open-ended	direct	short-search-query	similar-to-document	single-doc	expert	2025-05-12T15:09:02.012753	4	50	810
62	Do Buddhist caves and Hebrew temples both restrict inner sanctuary access?	Yes, both religious structures restricted access to their most sacred spaces. In Hebrew worship, only the high priest could enter the Holy of Holies once per year on the Day of Atonement. Similarly, Buddhist cave shrines like Longmen featured increasingly sacred spaces as one moved deeper into the caves, with the central Vairocana Buddha representing the highest cosmic realm.	"['Hebrews studies series\nTHE BETTER SANCTUARY\nHEBREWS STUDY #16 - A COMPLETE LESSON\n· Tell us about the nicest sanctuary in which you have worshipped.\n· Tell us about the nicest group of Christians with whom you have worshipped.\n· Which is more important today, the building or the people? Why?\n· Does any of the furniture we use have any significance?\nVss. 10-12 - According to the Bible Knowledge Commentary, there are four ways that the New Covenant is superior.\n1. “An inner inclination to obey God” - I will put my laws into their mind, and write them in their hearts:\n2. “A firm relationship with God” - and I will be to them a God, and they shall be to me a people:\n3. “The Knowledge of God” - And they shall not teach every man his neighbour, and every man his brother, saying, Know the Lord: for all shall know me, from the least to the greatest. (Note – You don’t need to teach a Christian to know God. He already does. You need to teach him to grow in that knowledge. 2 Peter 3:18)\n4. “The Forgiveness of sins” - For I will be merciful to their unrighteousness, and their sins and their iniquities will I remember no more. John F. Walvoord, Roy B. Zuck, editors, The Bible Knowledge Commentary, New Testament, (Wheaton, Illinois, Victor Books, 1983) p.800\nV Vs. 1 – There was an order of service under the first covenant by which animal sacrifices were offered for sin.\nV There was also a worldly or an earthly sanctuary. This was the tabernacle and later the temple.\nV What do you think the word “worldly” means here in verse 1?\nV What were some of the physical limitations of the worldly tabernacle?\nV Outside of the tabernacle was a courtyard which only had one entrance. Of what does that remind you?\nV In the courtyard was a bronze overlaid altar. It had a bronze grate to which the sacrifice was tied down. Coals were placed under the grate to burn the sacrifice. How does this remind you of Christ’s sacrifice?\nV There was also a laver or basin in the courtyard where the priests washed their hands and sometimes their feet. What does this remind you of concerning Christians?\nV Inside of the first veil inside the tabernacle was a lamp stand or candlestick. It had seven branches and burned pure olive oil.\nV There was also a table of showbread on which there were twelve loaves.\nV There was an altar on which incense was burned.\nV How do each of the three pieces of furniture remind you of Christ?\nVs. 3 – There was\nanother veil. This veil was between the “\nV Vs. 4 – The golden censer was actually the altar on which incense was burned. This was just outside the veil to the holy of holies. The priests would burn incense whose fragrance would travel into the holy of holies.\nV The only piece of furniture in the holy of holies was the Ark of the Covenant. It was 3 feet, 9 inches long and two feet, 3 inches high and two feet, 3 inches wide. Inside the were the tables of the law, Aaron’s rod that budded, and a golden pot of manna.\nV Vs. 5 – On top of this was the “mercy seat” made of pure gold. This was the throne of God in the tabernacle and there were two golden cherubs on it. Exodus 25:22.\nV How do the mercy seat, the ark and the ark’s contents picture Christ?\nü The service in this sanctuary was not adequate. There was something missing. This leads to frustration.\nü The word “ordained” in verse 6 means “furnished or equipped”. The tabernacle being furnished as just described, the priests went about their business. What were some of the things that had to be done on a continual basis?\nü Vs. 7 – What did the priest do every year and when did he do it?\nü Vs. 8 – What did the existence of the tabernacle indicate?\nü Vs. 9-10 – How was tabernacle worship limited, and therefore frustrating?\nü Vs. 10 – What was the time of reformation?\nv Vs. 11 – Where is the tabernacle today, and how is it superior?\nv Vs. 12 – How is Christ’s sacrifice superior?\nv What event at the crucifixion indicated that the Old Covenant was no longer necessary? Mark\nê Vs. 13 - How did the animal sacrifices of the Old Covenant serve their purpose?\nê Vs 14 – What did Christ’s sacrifice accomplish that the old sacrifices did not accomplish?\nê How are you “free to serve the living God”?', 'Presentation on theme: ""South, East, Southeast Asia 1 images 192-197 Content Area 8 Themes: Sacred architecture, After life, Representation of Deities, Landscape, Royal Portraiture,""— Presentation transcript:\nSouth, East, Southeast Asia 1 images 192-197 Content Area 8 Themes: Sacred architecture, After life, Representation of Deities, Landscape, Royal Portraiture, Power and Authority, Propaganda\nGuiding Questions 1.How do art and architecture reflect beliefs and practices? 2.How do art and architecture reveal cross- cultural connections and influences?\nRequired Images (21) 1.Great Stupa at Sanchi. Madhya Pradesh, India. Buddhist; Maurya, late Sunga Dynasty. c. 300 BCE – 100 CE. Stone Masonry, sandstone on dome ( 4 images) 2.Terra cotta warriors from mausoleum of the first Qin emperor of China. Qin dynasty. c. 221-209 BCE. Painted terra cotta. (2 images) 3.Funeral banner of Lady Dai (Xin Zhui). Han Dynasty, China. c. 180 BCE. Painted silk. 4.Longmen caves. Luoyang, China. Tang dynasty. 493-1127 CE. Limestone. (3 images). 5.Gold and jade crown. Three Kingdoms Period, Silla Kingdom, Korea. Fifth to Sixth century CE. Metalwork. 6.Todai-ji. Nara, Japan. Various artists, including sculptors Unkei and Keikei, as well as the Kei School. 743 CE; rebuilt c. 1700. Bronze and wood (sculpture); wood with ceramic tile roofing (architecture). (5 images). 7.Borobudur Temple. Central Java, Indonesia. Sailendra dynasty. c. 750-842 CE. Volcanic-stone masonry. (3 images)\nRequired Images p. 2 8.Angkor, the temple of Angkor Wat, and the city of Angkor Thom, Cambodia. Hindu, Angkor dynasty. c. 800 – 1400 CE. Stone masonry, sandstone. (5 images) 9.Lakshmana Temple. Khajuraho, India. Hindu, Chandella dynasty. c. 930-950 CE. Sandstone. (4 images) 10.Travelers among Mountains and Streams. Fan Kuan. c. 1000 CE. Ink and colors on silk. 11.Shiva as Lord of Dance (Nataraja). Hindu; India (Tamil Nadu), Chola dynasty, c. 11 th century CE. Cast bronze. 12.Night Attack on the Sanjó Palace. Kamakura Period, Japan. c. 1250-1300 CE. Handscroll (ink and color on paper). (2 images) 13.The David Vases. Yuan Dynasty, China. 1351 CE. White porcelain with cobalt-blue underglaze. 14.Portrait of Sin Sukju (1417 – 1475). Imperial Bureau of Painting. c. 15 th century CE. Hanging scroll (ink and color on silk).\nRequired images p. 3 15.Forbidden City. Beijing, China. Ming dynasty. 15 th century CE and later. Stone masonry, marble, brick, wood, and ceramic tile. (5 images) 16.Ryoan-ji. Kyoto, Japan. Muromachi Period, Japan. c. 1480 CE; current design most likely dates to the 18 th century. Rock garden. (3 images) 17.Jahangir Preferring a Sufi Shaikh to Kings. Bichitr. c. 1620 CE. Watercolor, gold, and ink on paper. 18.Taj Mahal. Agra, Uttar Pradesh, India. Masons, marble workers, mosaicists, and decorators working under the supervision of Ustad Ahmad Lahori, architect of the emperor 1632-1653 CE. Stone masonry and marble with inlay of precious and semiprecious stones; gardens. (2 images) 19.White and Red Plum Blossoms. Ogata Korin. c. 1710-1716 CE. Ink, watercolor, and gold leaf on paper. (2 images) 20.Under the Great Wave off Kanagawa, also known as the Great Wave, from the series Thirty-Six views of Mt. Fufi. Katsushika Hokusai. 1830- 1833 CE. Polychrome woodblock print; ink and color on paper. 21.Chairman Mao en Route to Anyuan. Artist unknown; based on an oil painting by Liu Chunhua. c. 1969 CE. Color Lithograph.\nHinduism 101 Monotheism displayed through polytheistic views literary origins of Hindu date to the Vedic period and to the Indus Valley Civilization Multiplicity of deities suggest the all-pervasive nature of the Hindu gods. Three main gods: Shiva, Vishnu, and Devi The Hindu Trimurti consists of Brahma the Creator, Vishnu the Preserver, and Shiva the Destroyer. Hinduism is bound to the hierarchal structure of the caste system: Scholars (Bramans), Warriors/princesses/princes (Kshateriya), Merchants (Vyshas), and farmers and laborers (Shudras) Position in caste system is reflection of accumulated merit in past lives, cause and effect = karma. Samsara is the cyclical reincarnation Ultimate goal is liberation and release from samsara, known as Moksha\nHinduism 102 - Shiva Shiva is the Destroyer as well as a regenerative force. Duality through multiplicity of roles. Shiva can be represented in the form of a linga, a phallic or cosmic pillar, emphasizing his regenerative nature. Frequently depicted with many limbs or heads, again multiplicity in form and power – suprahuman Shiva as Nataraja, Lord of dance Attributes: multiple heads/arms, third eye on forehead, carries trident, dreadlock hair, represented as great yogi and teacher, linga, serpent scarf, rides the bull, Nandi Son is Ganesha, god of good fortune and remover of obstacles, has the head of an elephant\nHinduism 103 - Vishnu Vishnu is the Preserver of the Universe, embodiment of mercy and goodness, and maintains the cosmic order Often depicted with four arms holding different attributes, such as conch-shell, disc, a club, and a lotus Often laying on a coiled serpent Shesha in the cosmic sea Has transformed into 9 out of 10 avatars to help bring balance back to earth: fish, turtle, boar, lion, dwarf, Parasurama, Ram, Krishna, Buddha, and the tenth is yet to come (Kalki).\nHinduism 104 - Devi Devi the Great Goddess who take many forms Parvati is the wife of Shiva Lakshmi is the wife of Vishnu Radha is the lover of Krishna In on manifestation, Devi is Durga, a multi- armed goddess who often rides a lion. Devi creates and destroys Son is Ganesha\nBuddhism 101 - Buddha Buddha (the Enlightened One) was born Siddhartha Gautama, eldest son of a royal family. Was a Hindu At the age of 29, the prince abandoned everything and everyone, witnessed pain and suffering, and became an ascetic Reached enlightenment at age of 35 through meditation under the Bodhi tree at Bodh Gaya in eastern India.\nBuddhism 102 – Four Noble Truths The Wheel of the Law, or dharmachakra, are the teachings of the Buddha Four Noble Truths: 1.Life is suffering 2.The cause of suffering is desire 3.one can overcome and extinguish desire 4.the way to conquer desire and end suffering is following Buddha’s Eightfold Path\nBuddhism 103 – Eightfold Path 1.Right understanding 2.Right thought 3.Right speech 4.Right action 5.Right livelihood 6.Right effort 7.Right mindfulness 8.Right concentration Buddha’s path leads to nirvana. Life is cyclical until nirvana is reached.\nQuestions addressed by architects of sacred structures: 1. Is there communal ritual? 2. Is there movement from point to point by ritual participants? 3. Is there a focal point participants must be able to see during the ritual? 4. How can transitions into more sacred space be provided? 5. How can the plan and decoration reflect beliefs of the participants?\nGreat Stupa at Sanchi. Madhya Pradesh, India. Buddhist; Maurya, late Sunga Dynasty. c. 300 B.C.E.–100 C.E. Stone masonry, sandstone on dome. 192\n-represents burial mound of the Buddha where relics were enclosed -focal point of worship -perched on a hill, surrounded by other smaller Stupas -4 Gateways (toranas) mark the cardinal directions – added later -Worshippers circumambulate in a clockwise direction -Toranas were elaborately carved, connecting secular world with spiritual realm (next slide) -Local Fertility deities, served to sanctify the site Great Stupa at Sanchi. Madhya Pradesh, India. Buddhist; Maurya, late Sunga Dynasty. c. 300 B.C.E.–100 C.E. Stone masonry, sandstone on dome. Built by King Ashoka, a converted Buddhist Buddhist Monuments at Sanchi (UNESCO/NHK) 2:53\nNorth Torana There are no human depictions of Buddha here because he has reached enlightenment Women depicted are Yakshi, Pre-Buddhist personifications of water, fertilit,y and vegetation\nGreat Stupa at Sanchi. Madhya Pradesh, India. Buddhist; Maurya, late Sunga Dynasty. c. 300 B.C.E.–100 C.E. Stone masonry, sandstone on dome. 1.Harmika: square area symbolizes the sacred domain of the gods 2.yashti is a pole = axis of universe 3.chatras represent Buddhas past, present, and future\nBuddhists venerated Buddha’s remains by circumambulation Stupa WAS NOT entered Circular movement echoed that of the earth and sun – brought the devotees in harmony with the cosmos Stupa represents a mountain, a axis mundi – connecting earth with the heavens Great Stupa at Sanchi. Madhya Pradesh, India. Buddhist; Maurya, late Sunga Dynasty. c. 300 B.C.E.–100 C.E. Stone masonry, sandstone on dome.\nCross Cultural Connections Take a moment with your partner(s) and connect the Great Stupa at Sanchi with another sacred site that incorporates the idea of axis mundi. Please fully identify your site, justify your decision, and be ready to share in a few minutes!\nTerra cotta warriors from mausoleum of the first Qin emperor of China. Qin Dynasty. c. 221–209 B.C.E. Painted terra cotta. 193\n8,000 or more terracotta soldiers and horses, bronze horses and chariots guard the tombs of China’s First Emperor, Qin Shi Huangdi Emperor Qin built the Great Wall to keep nomadic invaders out from the north (Huns) He restored order and consolidated power BRUTALLY The basic but considerable difference between the state of Qin and the states that had been conquered was that privileges of the nobility were abandoned and officials who were assigned for government positions were selected according to merits.\nArtists varied the combination of parts and the coloration, thus individualizing each figure Uniformity + individuality Even shows different ethnic groups that made up Emperor Qin’s army Emperor Qin conscripted more than 700,000 laborers to work on his tomb construction About 2,000 statues of cavalry, archers, lancers, chariots, and hand-to-hand fighters Undeniable connection to the POWER AND AUTHORITY of Emperor Qin Also, kudos to his imperial workshop Aligned to the road to the Mausoleum, army is to guard the Emperor in the after life VideoVideoes\nIn order to consolidate his power the Qin emperor standardized: - the script, - weights and measures, - the currency, and - the length of the cart axles. - He standardized a law code which everybody had to obey to and which prohibited the private possession of arms, and he - installed a state police and a secret service as government agencies. - Roads and canals were built to link all areas of the territory and move soldiers and supply fast.\nEarly China The Han Dynasty Lady Dai 12:22 Funeral banner of Lady Dai (Xin Zhui). Han Dynasty, China. c. 180 B.C.E. Painted silk. 194\nThis T-shaped silk banner covered the coffin of Lady Dai Lady Dai was the wife of Han ruler Marquis Li Cang Also in her tomb was additional embroidered silk gowns, 154 lacquer dishes, 51 ceramics, 48 bamboo suitcases of clothing and household goods, baskets of gold pieces and bronze coins. All things needed to be comfortable in the AFTERLIFE There was also an inventory of food items offered in her tomb: rice, wheat, barley, millet, soybeans, red lentils, 13 different meat dishes made from a variety of 7 kinds of meat. The scenes are interpreted as showing the modes of existence of the soul after death. The corpse is placed in the tomb where it is served by underworld attendants. The body soul enjoys and consumes the burial objects and offerings. At the same time the spirit soul (hun) ascends to the realm of the immortals and seems to rejuvenate during this process.\nThe lower section of the banner shows the offerings and ceremonies devoted to her body soul (po). Sacrificial vessels are provided for her and attendants are standing next to her, ready to serve her soul which resides in the tomb. Beneath the tomb we get a glimpse of the creatures living in the underworld: A deity of the earth carries the foundation of the tomb, her netherworld dwelling.\nThe central part of the banner shows Lady Dai in a standing position. She leans on a cane, while two persons crouch or kneel in front of her and three women, presumably female attendants, stand behind her.\nThe upper part of the banner is said to show the realm of the immortals. The entrance is guarded by two deities holding the records of the life span of Lady Dai. They are identified as deities of destiny. In the top section we can see a standing woman. She is surrounded by a creature with a snake-like body and flanked by the depictions of the moon with a toad and a rabbit (which is said to pound the elixir of immortality) and the sun with a raven. Five birds seem to keep her company which may represent the figures of the lower parts of the banner.\nSilk Road is established during Han dynasty Tomb was found as a mound Body and tomb was very well preserved Heavens Earthly World Spiritual World\nChinese Buddhist Cave Shrines 4:35 Longmen caves. Luoyang, China. Tang Dynasty. 493–1127 C.E. Limestone. 195 b/c 2300 caves were carved into the cliffs with Buddha\'s of all sizes Central cosmic Vairocana Buddha is more than 44ft. tall – seated Commissioned by Empress Wu Zetian flanking the central Buddha are bodhisattvas, monks, and guardian figures\nThe central Vairocana Buddha (more than 55 feet high including its pedestal) is flanked on either side by a bodhisattva, a heavenly king, and a thunderbolt holder (vajrapani). Vairocana represents the primordial Buddha who generates and presides over all the Buddhas of the infinite universes that form Buddhist cosmology. This idea—of the power of one supreme deity over all the others—resonated in the vast Tang Empire which was dominated by the Emperor at its summit and supported by his subordinate officials. These monumental sculptures intentionally mirrored the political situation. The dignity and imposing presence of Buddha and the sumptuous appearance of his attendant bodhisattvas is significant in this context.\nVaiśravana, one of The Four Heavenly Kings, is on the left (indicated by the stupa in his right hand). Vajrapāṇi (on the right) are spiritual beings that wield the thunderbolt, 673-675 C.E., Tang dynasty, limestone, Luoyang, Henan province\n196 Gold and jade crown. Three Kingdoms Period, Silla Kingdom, Korea. Fifth to sixth century C.E. Metalwork. Silla Kingdom was the most powerful Kingdom out of three rivaling Kingdoms in Korea Known as a Kingdom of Gold Crown is very carefully constructed, looks fragile in form Worn for burial purposes & special ceremonial rites of the Silla Kingdom Before Buddhism arrived in Korea, Silla Kingdom practiced shamanism – connection to nature worship through Shaman who acts as intercessor\nSilla royalty upheld shamanistic practices in ceremonial rites such as coronations and memorial services. In these sacred rituals, the gold crowns emphasized the power of the wearer through their precious materials and natural imagery. Three-pronged crown symbolized the sacred tree found in the Silla capital city, Gyeongju This sacred tree was conceived of as a “world tree,” or an axis mundi that connected heaven and earth. Silla gold crowns were used both above ground and below, and their luxurious materials conveyed the social status of the tomb occupant in the afterlife.\nTake a moment to Reflect Considering symbolism and significance of the material GOLD, compare and contrast two different cultures with regards to their symbolic connection to GOLD. How is GOLD a symbol of power and authority, and how is GOLD used within that culture?\nTodai-ji. Nara, Japan. Various artists, including sculptors Unkei and Kaikei, as well as the Kei School. 743 CE; rebuilt c. 1700. Bronze and wood (sculpture); wood with ceramic tile roofing (architecture). (5 images). 197a VideoVideo, :30 – 2:15\nCommissioned by Emperor Shomu 2/3 the size of the original! Original had 11 bays, this one has 7\nBuddhism was introduced to Japan in 552 CE to the ruling elite from the Korean king, product of silk road Seated Cosmic Buddha is larger than 53 feet. Same Buddha as Longman Caves 53 feet Associated with the sun Scale implies consolidation of Imperial authority + penetration of Buddhism 197b\nLarge scale god representation to elicit power and authority of Emperor Shomu (left) and Empress Wu Zetian (right) as well as power and authority of developing Buddhism\nNandaimon (Great South Gate), built during Kamakura Period 12 th century, Nara Highly inspired by Chinese architecture (product of Chogen’s travels to China) Houses two Guardian figure sculptures… 197e\nLeft: Ungyo, sculpted by Unkei, Kamakura Period Right: Agyo, sculpted by Kaikei, Kamakura Period Both artists were products of the Kei School of sculpture, most prominent during the 12 th century when Todai-ji was being rebuilt. 1 st rebuilt during the Kamakura Period (1185-1333) Buddhist Priest, Shunjobo Chogen, was put in charge of rebuilding 197c /d Kongo-rikishi: Guardian statues 8 meters tall = 26.2 feet\nJapanese Architecture The grand Buddhist architectural and sculptural projects of early Japan share a common material—wood–and are thus closely linked to the natural environment and to the long history of wood craftsmanship in Japan. CONNECTION TO NATURE']"	['<urn:uuid:5523a713-fcf3-43d5-a188-f62a226b35ee>', '<urn:uuid:fc70de2d-b16d-43cf-bfd3-d38195f11339>']	factoid	direct	concise-and-natural	distant-from-document	comparison	expert	2025-05-12T15:09:02.012753	11	59	3514
63	How does the color rendering in modern high-speed digital cameras compare to the color techniques used in Conner's 'Breakaway' film from 1966?	While Breakaway creates visual effects through gestural light smears and stroboscopic acceleration techniques, modern high-speed digital cameras use a more technical approach with Bayer pattern color matrices applied to monochrome sensors. The digital cameras simulate color by using three bits to each monochrome pixel (24 vs 8 or 30 vs 10 bits), while sacrificing some light sensitivity even when using microlenses to maximize photon capture.	"['Wallace Berman’s Underground\n- Rio Reel (ca.1966) by Russ Tamblyn\n- First Film (ca.1965) by Russ Tamblyn\nDecember 3, 2011, 8:00pm\nArmory Center for the Arts, 145 North Raymond Avenue Pasadena, CA 91103\nAt the Armory Center for the Arts, 626.449.0139\nMap to the Armory: http://www.armoryarts.org/contact-us/map-to-armory/\nInfo: www.lafilmforum.org and alternativeprojections.com\nTickets: $10 general, $5 students (with ID) & seniors; free for Filmforum and Armory Center members, via Brown Paper Tickets at:\nIn person: Toni Basil, Tosh Berman, George Herms, Russ Tamblyn (schedules permitting)\nIn the mid-1960’s, Wallace Berman inspired and communed with a close-knit circle of actors and artists, who screened their underground films domestically among a group of Topanga Canyon bohemians. These films were influenced by Berman’s spiritualist and radically amateur concepts of art, that nevertheless thrived in the intersection among art, Hollywood, and the institutions of the semi-commercial underground. Among this expanded circle in Topanga were Dennis Hopper, Russ Tamblyn, Toni Basil, Dean Stockwell, George Herms, Bruce Conner, and Robert Alexander.\nThe evening will include several films made by the artists in this community, along with a conversation among the guests, and perhaps a performance.\nCurated by Rani Singh and David E. James\nThis screening is in conjunction with the Armory’s exhibition\nSpeaking in Tongues: The Art of Wallace Berman and Robert Heinecken, 1961-1976, which will be open that evening before the screening. Come early to check out the wonderful exhibit!\nScreening (Program subject to change)\nAleph, by Wallace Berman (1956-66, 6 min., 16mm, color, silent)\n""This film took a decade to make and is the only true envisionment of the sixties I know."" - Stan Brakhage\n“…It is a dense collage of images drawn from disparate sources including his own works; newspaper and magazine illustrations often animated by the camera’s staccato movement over them; images from his own artwork, especially that of the single-image Verifax collages, including one of Flash Gordon that Berman titled “Portrait of Kenneth Anger”, home-movie footage of himself, his family and friends, and other artists, including Stockwell and Tamblyn; and trips to movies to see It’s a Mad Mad Mad Mad World and The T.A.M.I. Show, where Berman shot footage of the Rolling Stones and James Brown in concert. Almost all of the shots are very brief, often only a few frames, and the whole is further denatured by painting and scratching and by pverprinting, and it is punctuated by images of Kabalistic letters….” – David E. James, The Most Typical Avant-Garde, p. 278\nBreakaway, by Bruce Conner (1966, 5 min., 16mm, color, sound)\nMusic by Ed Cobb. Dance and vocal by Toni Basil\n""The camera captures her movements in gestural, expressive light smears. Intercut rhythmically with strophes of black leader, she gyrates in graceful, stroboscopic accelerations. Conner\'s editing is consummate as he alternates angles of her figure from different shots into a kinesthetic, flowing continuity.\n""Basically a two-and-a-half minute film, this \'module\' of image and sound is then reversed. Everything goes \'backwards\' to the \'original\' beginning. The sound track with Basilotta singing the title song is run in reverse as an aural analogue to the visual abstraction of photography. It resembles a paradigm for those high school physics demonstrations of gravitation where we saw a ball, once thrown straight up into the air, loyally retrace its trajectory to Earth."" - Anthony Reveaux\nA dance film viewed twice (once forward, once backward) in five minutes. The film was shot at single frame exposures as well as 8, 16, 24 and 36 frames per second.\nFirst Film, by Russ Tamblyn (c. 1966, ~8 min., 16mm, color, silent) (restored print from the Academy Film Archive)\nA fast –paced view of the times and activities of Russ Tamblyn, largely edited in camera. Glimpses of scenic locales, artistic possibilities, people on the move, and the full gamut of filmic manipulations.\nRio Reel, by Russ Tamblyn (c. 1968, ~6 min, 16mm, color, silent) (restored print from the Academy Film Archive)\nSimilar in style to First Film, Tamblyn filmed a journey to Rio.\nA Dance Film Inspired by the Music of Jim Morrison, by Toni Basil, (1968, 2m, color, sound)\nPerhaps the first film to combine classical dance with dancing of “the street.”\n""dancers in white face groove out in photomontage on a black backdrop to the music of Jimi Hendrix…” – from ""Paper Monument: A Journal of Contemporary Art,"" review by Naomi Fry of the exhibition ""Semina Culture: Wallace Berman & His Circle"" at NYU\nSelections from Topanga Rose (George Herms, 1960s, 25min., film transferred to video color, silent)\nThis selection of ethereal home movies shot in and around Topanga Canyon paints a rich portrait of Los Angeles as it once was….\n(The footage we compiled includes beautiful landscape photography, the Birds of Chaos sculpture, Neil Young’s wedding, a protest at the construction of a trailer park, a palm trees study, Gena’s (a local waitresses) wedding, and footage of Herms’ and Paul Beatties’ families)\nThis show will repeat at Ceinfamily on Saturday January 7, 2012!', 'High-Speed Video: Selecting a Slow-Motion Imaging SystemThe demand for high-speed imaging has increased for a broad range of applications, from automotive crash testing to animal behavior to product component performance.\nAndrew Bridges, Photron USA, Inc.There is a growing market for imaging systems that provides an immediate, slow-motion view of a process that allows one to see events that happen too quickly for the human eye to perceive or comprehend.\nThe process of selecting a system that will suit a particular need or application can be difficult because of the wide range of available systems. This article will serve as a guide for evaluating the performance parameters and specifications of a particular system. Whether solving a costly production-line jam, watching a dummy’s head hit a steering wheel in a 50-mph head-on crash, capturing a shark attack on a Cape fur seal (Figure 1), checking the sabot separation from a tank-killing shell or simply trying to adjust your golf swing, the following will provide an overview. This discussion will include information about several cameras and systems and what questions to consider before purchasing a slow-motion imaging system.\nFigure 1. Shark attacking a Cape fur seal. Footage captured at 1000 fps (1024 × 1024 pixels) with Photron’s ultima APX camera. Courtesy of BBC-TV’s Planet Earth, “Pole to Pole” Episode.\nHigh-speed video cameras operate across a wide range of frame rates — from 60 frames per second (fps) to over one million fps. All high-speed video cameras operate at full resolution up to a certain speed, and then reduce the resolution, or window, to achieve higher speeds. It’s important to establish what frame rate you require to capture the event that you are viewing in slow motion. When recording a cyclical production, such as labeling or packaging that takes place at x number of times per second, it generally requires a minimum of three images per cycle to view and understand the phenomenon. If a box folding process on a production line occurs at 6000 units per minute, the procedure obviously will equal 100 boxes folded per second. With the above rule, it will be necessary to record the box folding process at a minimum of 300 fps to capture the process for easy viewing and comprehension.\nFigure 2. High-speed image sequence of Atlas missile launch.\nIf the event is not cyclical, such as a missile launch (Figure 2) or a vehicle impact test, then careful planning is required to capture the action at the most significant moment. It is important to determine what temporal detail must be measurable in the finished image sequence or output video.\nIn an automotive crash test (recorded at 1000 fps, per federal mandate), most of the action occurs within 0.01 s or 10 ms. In recording a missile launch, the speed of the action can be even higher. If a projectile is traveling at 500 m/s (the Sidewinder missile easily exceeds this), and there is a 100-m field of view (FOV), it will pass through the image window in 0.2 s or 200 ms.\nHowever, if you need to capture 100 frames within this 100-m FOV, you will need a camera that can take an image every 2 ms, which equates to 500 fps. If the FOV is reduced to 10 m while all other criteria remain the same, it will require 10 times (5000 fps) the speed to capture the same 100 frames. Frame rate comes down to how many images you want to see of the event, regardless of whether it is per cycle or the whole event.\nAnother area to consider when evaluating a high-speed digital video system is record duration or record time. This is often confused with how the camera is triggered, which will be discussed later. The real question is: How long does the process last or how much (in seconds) of the event need be recorded? High-speed videos use on board digital random access memory (RAM) to save the images. There are ways to push the record duration such as reducing the speed or resolution, but in essence you have to determine how long you need to record. The latest systems also enable users to push the recording time by reducing the bit-depth of the pixels recorded (more on this topic later). Reducing the bit depth from 12 to 8 bits will produce a fifty percent increase in recording capacity.\nIf the event is occurring intermittently, then the question is “How long a record time do I need?” A more relevant question would be “How do I trigger the camera so that I capture video every time the problem occurs?” Digital high-speed cameras can remain in record mode almost indefinitely as they cycle the data through their memory buffer on a first-in/first-out (FIFO) basis. This is a vast improvement over older film cameras that took time to get up to speed (a digital camera is instantly locked to any crystal stabilized speed you select) and then could only maintain that speed for a few seconds before running out of film. When the digital buffer is full, the first image recorded is automatically overwritten. The system continues to overwrite data until it receives a trigger signal such as an optical or audio trigger, switch closure, or a digital TTL trigger such as an alarm or keyboard keystroke.\nDepending upon how the system has been configured by the operator, it can save all the images recorded before the trigger signal was received, save everything after the signal came in, or a variable percentage of pre- or post-trigger images. Advanced systems can automatically download some or all of the saved images to a networked hard drive before automatically rearming to await the next trigger signal.\nResolution, or more correctly spatial resolution, must be considered when seeking the ideal system for your specific needs. The best example of why resolution matters is detailed in this real-life scenario. One customer needed to be able to measure within 1/10 in. in an 8.5 ft field of view. Since 8.5 × 12 = 102, the camera would have 102 in. to cover. In order to measure to 1/10 in., it would require 10 times this number, or 1020 pixels.\nFigure 3. Fastcam SA-X - megapixel resolution to 12,500 fps.\nDevelopments in motion tracking algorithms enable motion analysis software to track very accurately to about one-tenth of a pixel. However, it is still recommended that whenever possible, you have the full quota of pixels needed to discern what you are viewing. To achieve the desired framing rate (camera speed), you may be forced to sacrifice some of the resolution. The highest resolution that Photron’s Fastcam SA-X can achieve is 12,500 fps at full mega pixel resolution (Figure 3). When selecting a camera, it is important to determine what the pixel resolution is at the speed you require, since all high-speed video cameras reduce the resolution to achieve higher speeds.\nThe other form of resolution to consider is called bit depth, sometimes referred to as dynamic range. Bit depth refers to how many shades of gray the sensor uses to transition from pure white to pure black. Older systems used 8 bits, which means they utilized 256 steps to transition from white to black. Systems now offer either 10 bits (1024 steps), 12 bits (4096), or even 14 bits (16,384) which are essential for certain advanced applications. For the most part, 8 to 12 bits are more than enough, especially given that Windows is an 8-bit operating system and many times the sensor only produces eight to 10 usable bits, the remainder are lost in noise. In order to fully appreciate those additional two to six bits, you would need to invest in specialized and expensive hardware and displays. The additional bits are useful in mega pixel systems such as the Fastcam SA5 and SA-X and high definition (HD) cameras like the SA2, SA6 and BC2 systems because they offer the ability to select which 8 of the12 bits recorded you display. This can be a very effective means of extracting the maximum detail from shadows or other underexposed areas, or providing an additional means of prolonging the record time.\nAll high-speed systems should be available in both monochrome and color. They all use the same basic monochrome sensor, but the color versions have a color filter attached, which does sacrifice some light sensitivity, even when microlenses are utilized to maximize the amount of photons falling on the light-gathering part of the sensors’ pixel. Most systems adopt a color matrix known as a Bayer pattern to produce acceptable looking colors, from what is in reality a black-and-white sensor. This simulated color requires three bits to each of the monochrome pixels, which is why color sensors have three times the number of bits; 24 vs. 8 or 30 vs. 10, etc. If you do not have a critical need for color images, it is best to stick with monochrome systems, as they tend to be less expensive as well as more sensitive while providing comparable image quality.\nShuttering and light sensitivity\nIt is possible to record some high-speed images of a mousetrap closing (Figure 4) at 1000 fps with no additional shuttering, so the effective shutter or exposure time is 0.001 s, but upon closer examination it will be apparent that the trap jaws are quite blurred. One might assume more frames per second are needed. However, there are already sufficient images, but the images are blurred. The solution would be to increase the shutter speed.\nFigure 4. Image sequence of a mousetrap.\nShutter speed is often confused with the framing rate, but they are distinctly different. A 35-mm film camera has shutters ranging from seconds to thousandths of a second, but it still takes only one to three pictures per second at most. Similarly, if a high-speed camera is recording at 1000 fps, ideally it is gathering light (exposing the sensor) for 0.001 s. With digital gating electronics, the actual time the sensor is exposed to light can be reduced to microseconds or possibly less. With the mousetrap example, if we keep the record rate at 1000 fps but push the shutter from the reciprocal of the frame rate (0.001 s or 1 ms) to 100 μs, it will reduce the blur by one-tenth.\nDo not discount blur; it can be a very important consideration when working with high-speed events, especially projectiles where it can be used to accurately calculate the speed a projectile is moving if the framing rate and shutter exposure time are known. Photron recently won a contract to replace the aging film cameras at a major military test range. The contract required our high-speed digital cameras to be fitted with an automatic exposure control. The shutter needed to auto-adjust to compensate for changing lighting conditions, such as the sun appearing or disappearing from behind cloud cover. One important requirement was that the shutter speed would not be adjusted above a maximum predefined value that had been calculated to ensure the object of interest remained blur-free. In this case, it was better to be underexposed than to have any blur.\nIn the life sciences arena, light sensitivity is a major concern as high-intensity lighting has a tendency to generate a great deal of heat — not always a good thing when recording animals or insects. Because new CMOS sensors are even more sensitive than their CCD counterparts, they remove the problems of image blooming, (also known as whiteouts, tearing or smearing), where an illuminated hot spot results in a larger vertical streak throughout the image.\nQuantifying the sensor’s light sensitivity is an inexact science when using the more familiar ASA/ISO measurement units used to rate 35 mm film, though more and more companies are adopting ISO Ssat method 12232. Make sure any camera’s sensitivity is provided according to a recognized ISO or similar standard on not on one the manufacturer has made up! If the subject is light- or heat-sensitive or the production environment is problematic (e.g. some production lines use light sensors as safety guards and additional lighting can accidentally trigger them), it is best to avoid using anything less than 1200 ISO/ASA for a monochrome camera, or one-third that for color as it is important to note that color sensors are usually one-half to one-third as sensitive as their black-and-white counterparts.\nBecause of these varying and potentially confusing factors, the best advice for finding the right camera system for the right job is to invite the camera vendors in and insist on a live demonstration. It is easy to demonstrate a system in the conference room, under ideal and controlled conditions, but your purchase should be based on a real-life demonstration with actual conditions in the exact environment in which you’ll need the system to perform.\nConsidering the end use\nThe next consideration is the end use. While troubleshooting a gasket manufacturing line, an instant slow-motion review of the high-speed video recorded may be all that is needed. If it is necessary to save a portion of the image sequence for later review and/or analysis, you will need to determine some fundamental issues, such as how to get the images out of the camera’s RAM and into the real world.\nThe key is to look at your PC and determine what communication protocols it supports. Or you may be able to use the camera’s standard HD-SDI orRS-170 video outputs. Most PCs, including laptops, will include the means to connect to external devices via one or two Gigabit Ethernet ports. This should be the first choice unless you have more complex requirements, such as operating a camera located several miles away, which is often the case in military tests that involve explosives and/or projectiles.\nFigure 5. Photron’s PCI-1024, a PC-based, megapixel, high-speed imager.\nIt is best to stay away from protocols requiring specialized hardware unless your requirements demand them. It is also important to be able to download the images directly into a recognized and immediately usable format (AVI, JPEG, TIFF, etc.) onto a PC of your choice. Some systems require time-consuming post-mission file conversion while others can quickly download to a modified controller, but then take forever to download into the real world.\nWhat type of physical package does your application require? There is a wide variety of systems available, from inexpensive, low-resolution plastic units for almost disposable usage on the production line, to huge systems specifically built for long record times to cover a missile’s launch or re-entry into the Earth’s atmosphere. Some PCI systems use lower cost CCD or supersensitive megapixel CMOS sensors that are made for use in personal computers or laptops. More complex systems require housing that is engineered to operate reliably onboard crash vehicles or near missile impacts. All of these systems have strengths, weaknesses and differences that may influence your decision when considering your particular imaging requirements.\nFor systems that require use or control via a computer, it is essential to become familiar with the software that is supplied with the camera. The software should be easy to use and intuitive, without requiring a master’s degree in computer science. Some manufacturers, including Photron, will supply their systems with a software developer’s kit, LabVIEW, and MATLAB wrappers to enable advanced users to develop their own interface or integrate camera control into an existing interface.\nRequest a live demo\nAs with any relatively new technology, there is a lot of seemingly conflicting information. The main question is: What works best for your needs? The answer is in finding a comfortable fit with your requirements and following this single, important rule: Require the systems manufacturer to demonstrate the camera with a real-life, real-time demonstration, within the actual environment in which the high-speed imaging system will be used. A live, in situ demo will bring out the best and the worst of the high-speed camera systems you review. With that, you’ll have the information you need to make the best choice.']"	['<urn:uuid:09030e45-146f-4a82-afbc-1bd471b6fdc9>', '<urn:uuid:2e69f0f5-13ba-49cb-b76a-abd354970e02>']	factoid	direct	verbose-and-natural	similar-to-document	comparison	expert	2025-05-12T15:09:02.012753	22	65	3485
64	I want to buy some travel protection before my vacation but don't know where to start - what should I keep in mind when getting travel insurance?	When buying travel insurance, you should compare different providers and request quotes to check policy differences. It's important to verify the inclusions, exclusions, and reimbursement limits of the policy. You should also check the network of accredited hospitals and the provider's presence in your destination. You can purchase travel insurance online at least 15 days before your trip.	['Traveling is a fun activity that many people want to do. Overseas travel stood still for nearly three years due to the pandemic. Now that the world is slowly opening again, many people are eager to take their vacations overseas. However, people still have to ensure they remain safe while traveling.\nOne of the essential things to do is get travel insurance. It is the most important investment travelers should have because it covers several risks. Usually, travel insurance covers flight disruptions, travel, and medical risks. It can cover accidental death and permanent disability, dental treatment, medical and accident treatment reimbursement, and lost checked-in baggage.\nBelow, you will find several reasons why you need travel insurance.\nImportance of travel insurance policy\nEven if there are fewer restrictions today in various countries, you still need travel insurance. If you are traveling soon, consider purchasing a travel insurance policy. You can get a credit card trip protection insurance policy at least 15 days before your trip.\n• Travel insurance covers medical emergencies. You cannot ascertain what will happen when you are overseas. A travel insurance policy will take care of the cost of your medical treatment subject to a specific limit. However, rest assured that travel insurance policies do not treat the types of medical emergencies, including accident treatments, differently.\n• It covers travel risks. Travel insurance will cover risks while you travel, such as loss of personal belonging and passport or loss of baggage you checked in. Covering these risks with travel insurance ensures you get an additional layer of protection. It will compensate you should there be a flight cancellation for any reason. Although there is a ceiling to the reimbursement amount, your financial loss will be minimal.\n• It will cover trip disruptions. Trip disruptions take many forms, but these occurrences can cut short or cancel your trip. Travel insurance provides coverage for trip cancellations made by the tour company or yourself.\n• You get customer assistance. When you purchase travel insurance, you get someone to help you with any problems related to your trip. The insurance company can help you file your claim correctly. They can likewise help you find an accredited hospital for your treatment. The insurance company will assist you as long as the policy is still valid.\nBuying travel insurance\nAs travel insurance is vital for travelers, it is likewise important to know how to buy a policy. The good thing is that you can purchase travel insurance online.\n• Compare providers. Like you often do before purchasing, you should check the different travel insurance providers. Request quotes from several options to check the differences in their policies.\n• Verify the inclusions and exclusions of the policy. Aside from the premium, you should check the inclusions and reimbursement limits. Choose the provider that offers a comprehensive package. This may be pricier, so choose one based on your needs. It is also important to check the network or accredited hospitals and the provider’s presence in your destination.\nRemember that travel insurance typically lasts up to one year. Moreover, travel insurance is only mandatory in several countries, but it is better to have one whenever you travel overseas.']	['<urn:uuid:aa2e5ad5-8be4-4659-b9a4-9fe3ea28cc85>']	factoid	with-premise	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-12T15:09:02.012753	27	58	531
65	How do both addiction and bipolar disorder affect a person's brain functioning and decision making abilities over time?	Both conditions impact brain function and decision-making, but in different ways. With addiction, the brain's wiring changes, affecting areas related to judgment, decision making, learning, memory and behavior control. These changes cause intense cravings and make it difficult to stop using substances. In bipolar disorder, the brain's functioning is affected through mood cycling, which can be worsened by incorrect medication use - particularly when antidepressants are taken without mood stabilizers, leading to manic episodes characterized by racing thoughts, decreased need for sleep, and impaired judgment. Both conditions can worsen over time if left untreated - addiction can further cement problematic neural pathways, while bipolar disorder may lead to more severe and frequent episodes as time goes on.	['If you can’t stop using substances or engaging in behaviors that harm your mind, body, and relationships, don’t give up hope. You’ve found a place to get help for your addiction.\nHow Do I Know if I Have an Addiction?\nAccording to The American Psychiatric Association (APA), addiction (also known as severe substance abuse disorder) goes deeper than series of negative behavior:\n“Addiction is a complex condition, a brain disease that is manifested by compulsive substance use despite harmful consequence.”\nIf you have addiction, your focus on using addictive substances or behaviors to cope is so fixed that it takes over your life. In fact, you continue to do so, in spite of how it’s hurting you, your relationships, your work/academic performance, and your ability to connect with others.\nTheHopeLine supports many people addicted to drugs and alcohol, but addiction can manifest itself in other ways. You could have an addiction to:\nWhile all of us make choices that influence our lives, addiction is more than a string of bad choices. Understanding some of the reasons addiction happens is key to freeing yourself from shame and shifting your focus to recovery.\nWhy Do I Have an Addiction?\nWe are responsible for our choices. But addictive behavior feels so difficult to stop because your brain is wired differently.\nAccording to the same report by the APA, “Changes in the brain’s wiring are what cause people to have intense cravings for the drug and make it hard to stop using the drug. Brain imaging studies show changes in the areas of the brain that relate to judgment, decision making, learning, memory and behavior control.”\nThis atypical wiring may be there because of genetics or a diagnosis of mental illness. But continually using the addictive substance (or engaging in the addictive behavior) can also further cement those neural paths.\nCan I Recover from Addiction or Relapse?\nWith what we know about addiction, it can seem like you’re trapped by substance use or destructive behaviors once you start down that path. But the truth is far more freeing. You can recover from addiction (and after relapse into addiction). And you can start today.\nAdmit you have an addiction: Understanding you have an addiction, and that it harms you and your relationships, is a critical step toward recovery.\nKnow what tempts you toward addiction: For every temptation, there is always a way out.\n“No temptation has overtaken you except what is common to mankind. And God is faithful; he will not let you be tempted beyond what you can bear. But when you are tempted, he will also provide a way out so that you can endure it” (1 Corinthians 10:13). Knowing the people, circumstances, places, actions, and feelings that trigger your addictive behavior can help you make a plan to stop and turn you toward healthier coping strategies.\nAsk for support: There are many caring experts and professionals uniquely qualified to mentor and support people with addictions. If you’re looking for help from people who have proven results with lasting addiction recovery, you’ve come to the right place.\nWe are here. We support you. And you can be free. It’s time to get the help you need to break the cycle and heal from addiction.', 'Antidepressants can trigger mania in people with bipolar disorder. If antidepressants are used at all, they should be combined with a mood stabilizer such as lithium or valproic acid. Taking an antidepressant without a mood stabilizer is likely to trigger a manic episode. Antidepressants can increase mood cycling.\nAre antidepressants bad for bipolar disorder?\nUsing antidepressant medication alone to treat a depressive episode is not recommended in people with bipolar I disorder. The drugs may flip a person, particularly a person with bipolar I disorder, into a manic or hypomanic episode. Hypomania is a more subdued version of mania.\nHow do antidepressants affect people with bipolar?\nAlso using antidepressants alone may trigger a manic or hypomanic episode in some people with bipolar disorder. Antidepressants alone also may lead to or prolong rapid cycling. In rapid cycling, a person may recover more quickly from depression but then experience mania followed by another episode of depression.\nWhich antidepressant is best for bipolar depression?\nTreating bipolar depression with antidepressants remains a popular option in clinical practice and published guidelines. Most clinicians choose the drug or class of drugs, usually selective serotonin reuptake inhibitors and bupropion, that is most effective and best tolerated.\nCan antidepressants send you into mania?\nAll antidepressants were associated with an increased incidence of mania/bipolar disorder (unadjusted HR>1.0 for all antidepressants) with incidence rates ranging from 13.1 (TCAs) to 19.1 (trazodone) per 1000 person-years.\nWhat is the best mood stabilizer for bipolar?\nLamotrigine (Lamictal) may be the most effective mood stabilizer for depression in bipolar disorder, but is not as helpful for mania. The starting dose of lamotrigine should be very low and increased very slowly over four weeks or more.\nWhat is the safest medication for bipolar disorder?\nLurasidone (Latuda) and Lamotrigine (Lamictal)\nBut lamotrigine is the better tolerated option, with few of the adverse effects that matter most to patients: weight gain, fatigue, sexual dysfunction, and long-term medical risks. Lamotrigine is better at preventing depression than it is at treating it.\nCan you be bipolar and not take medication?\n“Around half of people with bipolar disorder don’t take their medication which can lead to a relapse of symptoms. And this can have a knock-on impact with problems at work, strained relationships with family and friends, hospitalisation, and an increased risk of suicide.\nWhat happens if you take bipolar medication without being bipolar?\nTaking an antidepressant without a mood stabilizer is likely to trigger a manic episode. Antidepressants can increase mood cycling. Many experts believe that over time, antidepressant use in people with bipolar disorder has a mood destabilizing effect, increasing the frequency of manic and depressive episodes.\nCan you have a bipolar episode while on medication?\nYou may not be able to totally prevent bouts of mania or depression. Even people who always take their medication and take care of their health can still have mood swings from time to time.\nDoes Bipolar get worse as you age?\nBipolar may worsen with age or over time if this condition is left untreated. As time goes on, a person may experience episodes that are more severe and more frequent than when symptoms first appeared.\nHow can I fix my Bipolar without medication?\n10 Alternative Treatments for Bipolar Disorder\n- Fish oil.\n- Rhodiola rosea.\n- St. John’s wort.\n- Calming techniques.\nHow do you beat bipolar depression?\n10 Tips for Overcoming Bipolar Disorder\n- Be An Active Participant In Your Treatment. …\n- Go To Therapy. …\n- Closely Observe Your Mood and Symptoms. …\n- Don’t Isolate Yourself. …\n- Develop a Routine. …\n- Focus on Diet and Exercise. …\n- Reduce Your Stress. …\n- Avoid Drugs and Alcohol.\nCan you have a manic episode and not be bipolar?\nWhat are mania and hypomania? Mania and hypomania are symptoms that can occur with bipolar disorder. They can also occur in people who don’t have bipolar disorder.\nHow do you tell if you’re in a manic episode?\nBoth a manic and a hypomanic episode include three or more of these symptoms:\n- Abnormally upbeat, jumpy or wired.\n- Increased activity, energy or agitation.\n- Exaggerated sense of well-being and self-confidence (euphoria)\n- Decreased need for sleep.\n- Unusual talkativeness.\n- Racing thoughts.\nHow long does bipolar mania last?\nUntreated, an episode of mania can last anywhere from a few days to several months. Most commonly, symptoms continue for a few weeks to a few months. Depression may follow shortly after, or not appear for weeks or months. Many people with bipolar I disorder experience long periods without symptoms in between episodes.']	['<urn:uuid:16910453-1742-462a-a7e8-ecf8243e5d33>', '<urn:uuid:a51aed1d-f01b-44e9-b82e-ee71635daf7f>']	open-ended	direct	verbose-and-natural	similar-to-document	comparison	novice	2025-05-12T15:09:02.012753	18	117	1305
66	onam celebrations kerala abroad tradition significance	Onam is both a traditional harvest festival celebrated in Kerala and observed by expatriate communities abroad. In Kerala, it is a 10-day celebration marked by floral rangoli decorations, traditional clothes, music, dance, snake boat races and tiger dances. A key feature is the Onam Sadya (feast) with traditional dishes like Rasam, Payasam, Avial, and brown rice served on banana leaves. However, expatriates, such as those in UAE, face challenges recreating these traditions - they struggle to find fresh banana leaves and flowers for Pookkalam (floral carpets), and miss participating in hometown processions and cultural activities, though they maintain core customs like preparing the feast and celebrating with family and community organizations.	['Abu Dhabi: Expatriates from south Indian state of Kerala, who celebrated their most important harvest festival, Onam, on Monday, said they missed the colourful celebrations back home.\n“We do miss colourful celebrations with a lot of activities back home. But at the same time this occasion reminds us the advantages of life in the UAE,” Dr Gopa Kumar, Chief Operating Officer of Al Juraf Fisheries LLC in Abu Dhabi, said.\nHe celebrated Thiruvonam, the most important day of Onam, with his family in Abu Dhabi on Monday.\nHis wife and mother-in-law woke up early on Monday to prepare Onam Sadya (Onam feast) for the family including his two school-going children.\n“Being a working day, we prepared the Onam Sadya before leaving for work and came back afternoon to enjoy the feast together,” Kumar said.\nHe missed the colourful Pookkalam (floral carpet), which he used to create with flowers collected from neighbourhoods with family members and friends. But he couldn’t show his children how to make one here.\n“Even the banana leaves [on which feast is served] we bought from the market were not fresh but expensive. It is difficult to get fresh flowers and I did not see any floral carpets inside apartments in Abu Dhabi,” Kumar said.\n“I do miss the colourful procession on Thiruvananthapuram, my hometown on Thirivonam.”\nIt is a loss! But he says it is the price he is giving for enjoying a quality life in the UAE.\n“Considering the quality of life here, I would like to continue here,” Kumar said.\nEchoing the same view, Gopala Krishnan, 42, a Public Relations Officer with a private company, said, he tries to involve in all activities related to Onam in the UAE to beat the nostalgia. “I do feel nostalgic because I miss the fun in participating in the tug-of-war competition in the village back home on Thiruvonam.\nHe said he also feels fortunate that quality of life has improved thanks to the life in the UAE, though he misses several other fortunes back home.\n“And fortunately I am looking forward to several other colourful activities to be organised by community organisations in the capital from next weekend,” Krishnan said.\nHe joined a friend’s family living on Hamdan Street in the capital yesterday for Thiruvonam celebrations, as his own family is living back home. His family joins him here once a year during his children’s school vacation back home. He missed his family but he was happy that he could celebrate Onam in a family environment.\n“There were 14 people including that friend’s family members and other bachelor friends. We all joined in preparing Onam Sadya, which itself is a great enjoyment,” Krishnan said.\nAlthough it was a working day yesterday, he took a short-break from work to enjoy the feast.\nMany private companies in the capital with a large number of Keralite employees felicitated the celebrations at their offices. They created floral carpets at office and enjoyed take-away Onam Sadya from restaurants. Others will be joining Onam Feast to be hosted by community organisations during the weekends. As Gulf News reported yesterday reception halls in the premises of registered Indian community organisations in the capital have already been booked for every weekend until the end of December for hosting Onam Sadya.', 'Celebrated all over the country, Makar Sankranti is the oldest and the most colorful harvest festival in India. It is also the most celebrated harvest festival of North India making it the top harvest festival of Uttar Pradesh. As per Hindu mythology, this festival marks the end of an unfavorable phase and the beginning of a holy phase. Particularly in villages of Gujarat, Kerala, Tamil Nadu, Haryana, Himachal, West Bengal, and Punjab, people celebrate the harvest of new crops with bonfire, carnivals, songs, dances, kite flying, and rallies.\nWhere is Makar Sankranti celebrated: Pan India in different ways but mainly in the north\nKey attractions of Makar Sankranti festival: Kumbh Mela and various sumptuous sweet dishes made of sesame and jaggery.\nPeople of Punjab and Haryana celebrate Baisakhi festival 2020 or Vaisakhi by thanking God for the good harvest. And the farmers of the country express their happiness and delight through this Indian harvest festival. People wear their best colorful dresses, sing the happiest songs, and dance to the melodious beats of Dhol. It is the most loved harvest festival of Punjab. Baisakhi fairs are also organised where acrobatics, wresting, algoza, and vanjli performances can be seen which makes it one of the most interesting harvest festivals celebrated in India.\nWhere is Baisakhi celebrated: Punjab and Haryana\nKey attractions of Baisakhi festival: Bhangra by menfolk and Gidda by women.\nLadakh Harvest Festival\nLadakh Harvest Festival has gained immense popularity and fame all over the world. Ladakh looks bright, beautiful, and absolutely stunning with the commencement of this harvest festival. Monasteries and stupas are decorated and pilgrimages to Thangka of Kyabje Gombo are mandatory things as a part of this celebration. Archery along with old social & cultural ceremonies and art & handicrafts are the other features of the event. The festivals of Ladakh attracts travelers from across the world with their exclusive experiences.\nWhere Ladakh Harvest Festival celebrated: Ladakh, Zanskar, Kargil\nKey attractions of Ladakh Harvest Festival: Dramas or ‘Chhams’ are performed to display life and teachings of Buddha and different dance forms of Tibetan culture\nEvery year in January, the entire state of Assam showcases enthusiasm and delight in celebrating Bhogali Bihu. The farmers of Assam celebrate and cherish the efforts of cultivation and reap the benefits. The celebration starts one night before with Uruka—the community feast. On the day of Bihu, the mejis or pavilion made of clay and hay are burnt. Local women wear stunning mukhlas and participate in group songs and dance. Also known as Magh Bihu, this is an exotic and most vibrant name on the list of harvest festivals of India.\nWhere is Bihu celebrated: Assam\nKey attractions of Bihu festival: Bihu dance, bullfight, bird fight and Sunga Pitha, Til Pitha and Laru\nLohri is a renowned harvest festival in Punjab that showcases traditional dance and songs. To kill the chills of winter, the entire family and neighbours gather around the bonfire and sing together and offers grains, corns, and nuts to respect and appreciate the grand harvest of sugarcane crops.\nWhere is Lohri celebrated: Punjab\nKey attractions of Lohri festival: The Punjabi folklore Sunder Mundriye sung by everyone\nNuakhai is an age old harvest celebration in Odisha. Locally ‘nua’ means new and ‘khai’ means food. This is not only a popular harvest festival in India, but also celebrated to appreciate the passing away of the past and evil days while welcoming the new and beautiful with open arms. The festival is also known as Nuakhai Parab or Nuakhai Bhetghat.\nWhere is Nuakhai celebrated: Orissa\nKey attractions of Nuakhai festival: The delicious Arsaa Pitha (sweet pancakes)\nWangala is the merriment of 100 drums played by Garo tribes of northeast India. This is one of the popular harvest festivals of India marking the onset of winter. During this festival, Sun God is worshiped with immense devotion and zeal. Women wear their traditional colourful clothes and dance during this harvesting festival while men rhythmically drum their fingers on the traditional drum pads.\nWhere is Wangala celebrated: Meghalaya and Assam\nKey attractions of the Wangala festival: Musical extravaganza with drums, flutes, and gongs\nKa Pomblang Nongkrem\nThe inhabitants of Khasi hills worship Goddess Ka Blei Synshar and celebrate the plentiful harvest with vigour and excitement. Ka Pomblang Nongkrem brings ultimate joy and happiness to the community. The celebration comprises of animal sacrifice and Nongkrem dance with sword in one hand and yak hair whisk on the other.\nWhere is Ka Pomblang Nongkrem celebrated: Meghalaya\nKey attractions of Ka Pomblang Nongkrem festival: Pemblang ceremony and Ceremony of Tangmuri\nUgadi is a regional New Year celebration for people of Andhra Pradesh and Karnataka. This harvest festival is considered auspicious to start new work and ventures. On the day, local people take oil bath, wear traditional clothes, decorate homes with earthen lamps and rangoli, and perform Ugadi puja at home.\nWhere is Ugadi celebrated: Andhra Pradesh and Karnataka\nKey attractions of Ugadi festival: The Ugadi delicacies like Ugadi Pachadi, Pulihora and Bobbatlu are prepared with raw mango, jaggery, neem, and tamarind.\nGudi Padwa is a grand harvest festival of Maharashtra marking the beginning of an auspicious New Year. People make rangoli designs at the entrance of their homes and decorate it with flowers and a handmade doll . Folks meet friends and relatives, exchange wishes, and women cook sweets like Puran Poli, Shrikhand, and Sunth Paak.\nWhere is Gudi Padwa celebrated: Maharashtra\nKey attractions of Gudi Padwa festival: Local people make Gudi (bamboo doll) using mango and neem leaves and hang them at the entrance.\nNabana is amongst one of the crop festivals of India which is famous for the paddy plantations harvest. This is one of the most celebrated traditions of Bengal, where new rice is harvested with sheer joy and stocked in homes. Farmers from Bengal cheerfully participate in this harvest ritual in the Bengali month of Agrahayan and offer the first grains to Goddess Lakshmi while thanking her for all blessings. West Bengal Tourism has taken initiative to welcome tourists from around the country.\nWhere is Nabanna celebrated: West Bengal\nKey attractions of Nabanna festival: Payesh (Kheer) made from the newly harvested rice and Nabanna fair.\nOnam is a legendary harvest festival of Kerala celebrated with great enthusiasm in different parts of Kerala. The festival is celebrated for 10 days with the arrival of Mahabali. To relish the successful harvest, Malayalee people decorate their house entrance with floral rangoli, wear new traditional clothes, women cook delicious food, and celebrate with traditional music and dance.\nWhere is Onam celebrated: Some regions of Kerala\nKey attractions of Onam festival: Traditional Malayalee recipes like Rasam, Payasam, Avial, brown rice and parippu curry are offered to guests in traditional green leaf, snake boat race and tiger dance are also exciting to watch.\nPongal is another name for Makar Sankranti, which is celebrated during the same time in various cities of Tamil Nadu. This is a thanksgiving celebration where people express their deep gratitude to mother nature for the produce of the year. This is one of the most colourful harvest festivals of India celebrated for 4 days. It is amongst the most popular festivals of Tamil Nadu.\nWhere is Pongal celebrated: Tamil Nadu\nKey attractions of Pongal festival: Decorated houses with Kolam, bull taming contests, bonfire with agricultural wastes and worship for the family’s prosperity\nBasant Panchami marks the onset of spring season. Celebrated in different states of North India, it is considered an auspicious day. This festival is associated with yellow color, which is a color of spirituality. One can see the magnificent mustard crop fields in the countryside, especially rural areas of Haryana and Punjab.\nKey attractions of Basant Panchami festival: Indian cuisine like Meethe Chawal, Maake ki Roti, and Sarso Ka Saag\nWhere is Basant Panchami celebrated: Eastern parts of India West Bengal & Bihar.\nGrand worship of Lord Vishnu or Lord Krishna, elaborate family lunch, evening prayers, and fireworks sum up the complete picture of Vishu festival. This is an interesting harvest festival celebrated on the first day of Malayalee New Year. Women of the house prepare Vishukkani—varieties of traditional cuisine to offer to Gods—, with rice, golden lemon, golden cucumber, jackfruit, yellow konna flowers, and betel leaves.\nWhere is Vishu celebrated: Kerala and Karnataka\nKey attractions of Vishu festival: Kani Kanal—the first holy sight of Vishnu and the Sadya—the grand mid-day meal spread\nHoli being one of the colourful harvest festivals of India is celebrated with great enthusiasm and in all good spirits. Holi represents the essence of India and vibrancy as the festival is celebrated with great grandeur and splendour. Holi is one of the renowned harvest festivals of India known for colours and water. The essence behind the festival is that it is celebrated for 2 days that is 1st day is for a bonfire to commemorate Holika’s sacrifice and the second day is when people play with colours and water and celebrate Holi with all vigour and joy.\nWhere is Holi celebrated: Barsana, Mathura & Vrindavan\nKey Attractions of Holi festival: The festival is celebrated, playing with a lot varied colours.\nThe Dree Festival is among the most famous festivals in Arunachal Pradesh as it marks an important time of the year for the Apatani tribe – the harvest season. Characterized by sacrificial offerings and prayers, Dree is celebrated on the 5th of July every year in the Ziro district of Arunachal Pradesh.\nThe festival is celebrated with utmost joy by people of all walks of life who dress up in traditional clothes. Locals perform traditional dance and music numbers while others enjoy a feast of tangy rice and millet beer. Other than this, the three-day festival is also marked by various games and sports that the locals and onlookers are entertained with. The entire ritual is carried out to pray before the four Gods – Tamu, Harniang, Metii, and Danyi – so that the Apatanis can be blessed with a bountiful harvest season.\nWhere is Dree festival celebrated: Arunachal Pradesh\nKey Attractions of Dree festival: The festival is celebrated with traditional singing and dance during which five of the main deities are worshipped such as Tamu, Medvr, Metw, Mepin and Danyi.\nAgera is one of the crop festivals of India celebrated with great enthusiasm by the people of Mumbai. Celebrated on the first Sunday of October in the regions of Mumbai, Thane, Raigad, and Vasai, it marks the harvest season of Maharashtra when Catholic locals thank “thank God for the abundance of blessings received”. It is also sometimes called the ‘Thanksgiving Sunday’ and is characterized by a lively procession to the nearest paddy field where a priest blesses the farm and plucks a few sheaves. The procession is accompanied by music and dance. Various food stalls are set up outside churches where the blessed paddy is finally brought before being distributed to the participants.\nWhere is Agera celebrated: Mumbai\nKey Attractions of Agera festival: One of the priests showers the blessings on the field and harvest a few of rice stalks. After then the rice stalks are taken till the church with sounds of village band in a palki.']	['<urn:uuid:a236193b-d5e1-428b-98ab-08f881f97ff9>', '<urn:uuid:8d7e9b87-3ae5-40b1-b06f-74e3b9782e04>']	open-ended	with-premise	short-search-query	similar-to-document	multi-aspect	expert	2025-05-12T15:09:02.012753	6	111	2402
67	What are the regular promotion requirements for becoming a Sergeant in the Army, and what special duties do Army Counterintelligence Special Agents at this rank perform?	To become a Sergeant (E-5), soldiers must meet several requirements in the Primary Zone: 8 months time in grade as an E-4, 36 months time in service, pass the APFT score, have a passing weapons qualification score, pass the Promotion Board, complete online Structured Self Development Course (SSD1), and graduate from the Non-commissioned Officer Education Course. As for Counterintelligence Special Agent duties at the Sergeant rank, they investigate national security crimes, conduct counterintelligence operations, process intelligence evidence, participate in technology protection activities, prepare reports, conduct source operations, debrief personnel for counterintelligence collections, and support counter-terrorism operations.	"['How to Get Promoted in the Army Using the Army Enlisted Promotion System\nThe first thing you want to know about the Army, or any job, is how to get promoted in the Army. In the Army, there is a system used to standardize the promotion process for all soldiers. This is called the Army Enlisted Promotion system.\nDecentralized Promotions (E-2 through E-4)\nPromotion Authority: Company\nWhen soldiers refer to “automatic promotions”; these are the promotions they are talking about. However, these promotions are not officially automatic. You do have to qualify to get promoted. The reason these promotions are considered automatic by most is that the qualifications to get promoted are very easy to achieve. In fact, you would almost have to be trying to not get promoted for it not to happen.\nArmy Time in Grade Requirements\n- Private (E-2): 6 months time in grade (TIG) as an E-1.\n- Private First Class (E-3): 4 months TIG as an E-2 and 12 months time in service (TIS).\n- Specialist (E-4): 6 months TIG and 2 years TIS.\nUnit Commanders are given a specific number of waivers that they can choose to use for exemplary soldiers. These waivers shorten the TIG and/or TIS requirement for promotion.\n- An E-1 can get promoted to Private (E-2) with only 4 months TIG with a waiver.\n- An E-2 can get promoted to PFC (E-3) with only 2 months TIG and 6 months TIS with a waiver.\n- An E-3 can get promoted to SPC (E-4) with only 3 months TIG and 18 months TIS with a waiver.\nOther Army Promotion Requirements\nOnce a soldier has satisfied his or her TIS and TIG requirements, they must be promotable in all other aspects as well. This means they can not have any “flags” on their record. Flags are given for things such as APFT failure, failure to meet height and weight standards, punitive actions, etc.\nSemi Centralized Promotions (E-5 and E-6)\nPromotion Authority: Company & Army Wide\nFor a soldier to be promoted to E-5 or E-6, there must be an opening for that rank in the soldier’s Military Occupational Specialty (MOS). The Army Promotion Point System is how the Army decides who gets that opening when it becomes available. Semi centralized promotions are the most difficult in terms of satisfying requirements. Below is a check list of all the aspects involved in getting promoted to Sergeant (SGT) and Staff Sergeant (SSG).\nSemi Centralized Promotion Check-list\n- Meet the specified TIS and TIG requirements for your rank and zone.\n- Have a passing APFT score.\n- Have a passing weapons qualification score.\n- Pass the Promotion Board.\n- Complete online Structured Self Development Course (SSD1).\n- Graduate from the appropriate Non commissioned Officer Education Course.\n- Gain enough promotion points to make cutoff.\nPrimary Zone/Secondary Zone\nThere are two promotion processes known as “Primary Zone” and “Secondary Zone.” Most enlisted soldiers are promoted in the “Primary Zone.” The “Secondary Zone” is for soldiers considered to be “exceptional performers” and gives them an early shot at promotion. The promotion point cutoff scores are typically higher for the Secondary Zone as well.\nArmy Promotion Criteria – Promotions to Sergeant (E-5)\n- Primary Zone: 8 months TIG as an E-4 and 36 months (3 years) TIS.\n- Secondary Zone: 4 months TIG and 18 months TIS.\nArmy Promotion Criteria – Promotions to Staff Sergeant (E-6)\n- Primary Zone: 10 months TIG as an E-5 and 72 months (6 years) TIS.\n- Secondary Zone: 5 months TIG and 48 months (4 years) TIS.', 'United States Army Counterintelligence\n|This article needs additional citations for verification. (March 2013)|\n|United States Army Counterintelligence|\n|U.S. Army Intelligence and Security Command Seal|\n|Counterintelligence Special Agent Badge|\n|Formed||October 1st, 1977|\n|Legal personality||Governmental: Government agency|\n|Legal jurisdiction||National Security Crimes|\n|Governing body||Department of the Army|\n|Headquarters||Intelligence and Security Command, Fort Belvoir, VA|\n|Parent agency||Department of the Army|\nUnited States Army Counterintelligence is the component of United States Army Intelligence which conducts counterintelligence activities to detect, identify, assess, counter, exploit and/or neutralize adversarial, foreign intelligence services, international terrorist organizations, and insider threats to the United States Army and U.S. Department of Defense.\nMilitary and civilian personnel trained and appointed to conduct counterintelligence investigations and operations are credentialed and titled as Counterintelligence Special Agents (occasionally referred to simply as ""CI"" or ""Army Intelligence Agents""), and carry badge and credentials identifying their status as federal law enforcement officers. Within the Army, these agents have arrest powers and jurisdiction in the investigation of national security crimes such as treason, spying, espionage, sedition, subversion, sabotage with intent to damage national defense, and support to international terrorism, while other criminal matters are investigated by United States Army Criminal Investigation Command. In other branches of the U.S. military, the counterintelligence mission is performed by the Office of Special Investigations for the Air Force, and the Naval Criminal Investigative Service for the Navy and Marine Corps, which also conduct general criminal investigations for their respective services. The Army continues to keep these two investigative channels separate via Army CI and Army CID, even though parallel and joint investigations do happen periodically.\nMost operational U.S. Army Counterintelligence Special Agents today operate under the auspices of the United States Army Intelligence and Security Command, with the 902nd Military Intelligence Group responsible for counterintelligence activities and operating field offices within the continental United States. Historically, the United States Army Counterintelligence mission was performed by the Corps of Intelligence Police during World War I, the Counter Intelligence Corps (CIC) during World War II & Cold War, and later by the now defunct U.S. Army Intelligence Agency.\nSpecial Agent duties\nCounterintelligence Special Agents are the operational/investigative personnel within United States Army Counterintelligence who actually conduct the various Counterintelligence activities. Duties may include the investigation of national security crimes using special investigative procedures; conducting counterintelligence operations; processing intelligence evidence; participating in technology protection activities; preparing and distributing reports; conducting source operations; debriefing personnel for counterintelligence collections; and supporting counter-terrorism operations.\nSenior counterintelligence personnel provide guidance to junior Special Agents and supervise their training; conduct liaison and operational coordination with foreign and U.S. Law Enforcement, Security, and Intelligence Agencies; plan and conduct counterintelligence operations/activities related to national security; conduct high-profile counterintelligence collection activities and source operations ranging from overt to clandestine collection; conduct surveillance operations; providing support for counterintelligence analytical products, to include preparing counterintelligence reports, estimates, and vulnerability assessments; and with additional training, may conduct technical surveillance countermeasures (TSCM), credibility assessment examinations, or exploit cyber threats.\nSenior Counterintelligence Special Agents are also often assigned to U.S. Army Special Forces groups to assist with Source Operations and intelligence investigations as required; while also working closely with HUMINT Collectors.\nSpecial Agent designations\nIf military, Counterintelligence Special Agents are designated by enlisted military occupational specialty 35L Counterintelligence Special Agent, warrant officer area of concentration 351L Counterintelligence Technician, or commissioned officer area of concentration 35E Counterintelligence Officer; if civilian, the 0132 series. On 1 October 2007, the former enlisted specialty 97B, Counterintelligence Agent, was redesignated as 35L, Counterintelligence Special Agent, to group all Military Intelligence specialties in the 35 series. In addition, the rank requirement was returned to a minimum of Sergeant/E-5, matching that of other special agents throughout the US Armed Forces.\nSelection and training\nThe position of Counterintelligence Special Agent is not an entry level Army position, and applicants are usually drawn from the existing ranks. Department of the Army Pamphlet 611-21 requires applicants be able to:\n- Obtain a Top Secret security clearance with Sensitive Compartmented Information eligibility.\n- A physical profile (PULHES) of 222111 or better.\n- Be a minimum age of 21 after training for accreditation as a Special Agent.\n- Be a minimum rank of E5/Sergeant after training for accreditation as a Special Agent.\n- Possess an occupational specialty with a physical demands rating of medium.\n- Have normal color vision.\n- Have a minimum score of 105 in aptitude area ST on ASVAB tests administered on or after 1 July 2004;\n- Be a high school graduate or equivalent.\n- Possess good voice quality and be able to speak English without an objectionable accent or impediment.\n- Never been a member of the U.S. Peace Corps.\n- No adverse information in military personnel, Provost Marshal, intelligence, or medical records which would prevent receiving a security clearance under AR 380-67 including no record of conviction by court-martial, or by a civilian court for any offense other than minor traffic violations.\n- Must be interviewed per DA Pam 600-8, procedure 3-33 by a qualified Counterintelligence Special Agent.\n- Must be a U.S. citizen.\n- Must receive a command level recommendation for initial appointment.\n- Must not have immediate family members or immediate family members of the Soldier\'s spouse who reside in a country within whose boundaries physical or mental coercion is known to be common practice.\n- Have neither commercial nor vested interest in a country within whose boundaries physical or mental coercion is known to be a common practice against persons acting in the interest of the U.S.\n- Must receive a waiver for any immediate family members who are not U.S. citizens.\nBecoming a credentialed Counterintelligence Special Agent requires successful completion of the Counterintelligence Special Agent Course (CISAC) at either Fort Huachuca, Arizona, Camp Williams, Utah, or Fort Devens, Massachusetts. Newly trained special agents are placed on a probationary status for the first year after graduation for active duty agents, and for the first two years after graduation for reserve/national guard agents. This allows for the removal of the Counterintelligence Special Agent MOS if the probationary Agent is deemed unfit for duty as a Special Agent.\nUniform and firearms\nCounterintelligence Special Agents on assignment within the United States usually dress in professional business attire. Assignment type will dictate what clothing is appropriate, which can include civilian attire local to the area. When deployed to combat environments, agents may wear the Army Combat Uniform for security purposes, but with rank insignia replaced with Department of the Army Civilian ""U.S."" insignia. Although agents may be issued other weapons on special assignments, they are typically issued a standard M9 or M11 pistol. For combat environments, special agents are also issued the M16 rifle or the M4 carbine.\nAdditional Department of Defense Criminal & Counterintelligence Investigative Organizations\n- United States Army Criminal Investigation Command (CID)\n- Naval Criminal Investigative Service (NCIS)\n- U.S. Air Force Office of Special Investigations (AFOSI, or OSI)\n- Defense Criminal Investigative Service (DCIS)\n- Defense Intelligence Agency (DIA)\nOther Federal Counterintelligence Investigative Organizations\n- Federal Bureau of Investigation (FBI)\n- Central Intelligence Agency (CIA)\n- Diplomatic Security Service (DSS)\n- Coast Guard Investigative Service (CGIS)\n- U.S. Army Special Forces\n- List of United States Army MOS\n- Historical U.S. Army Counterintelligence Corps\n- Historical U.S. Army Corps of Intelligence Police\nNotable Counterintelligence Special Agents\n- J. D. Salinger\n- Noel Behn\n- Nathan Safferstein\n- Ib Melchior\n- Arthur Komori\n- Isadore Zack\n- Erhard Dabringhaus\n- John R. Wilson\n- Richard M.Sakakida\n- Donald C. Fanta\n- Mike Gravel\n- John Patrick Finnegan\n- F. Woody Horton, Jr.\n- Earl S. Browning\n- Ann M. McDonough\n- Clinton J. Hill\n- Richard S. Eaton\n- Cari A. Gasiewicz\n- United States Army Regulation 381-20, The Army Counterintelligence Program, 25 May 2010\n- United States Army Field Manual 2-22.2, Counterintelligence, page 2-3, Counterintelligence Investigative Jurisdiction\n- United States Army Regulation 195-2, Criminal Investigation Activities, 15 May 2009\n- Military Intelligence Civilian Excepted Career Program (MICECP)\n- GoArmy.com > Careers & Jobs > Counterintelligence Agent (35L)\n- MOS Change\n- MOSs on the move\n|This military article is regarding a United States Army Military Occupational Specialty (MOS) designation.\nAll articles in this category can be viewed at Category:United States Army Military Occupational Specialty']"	['<urn:uuid:7c2228ef-8044-444c-a5a8-7bcfb31c2a5b>', '<urn:uuid:15c0d505-ae43-4bb0-9e05-93fd65b720d5>']	open-ended	direct	verbose-and-natural	similar-to-document	multi-aspect	novice	2025-05-12T15:09:02.012753	26	96	1968
68	edward mandell house influence on texas governors hogg culberson sayers lanham details	Edward Mandell House helped make four men governor of Texas by using his money and influence. The governors he helped elect were James S. Hogg (1892), Charles A. Culberson (1894), Joseph D. Sayers (1898), and S. W.T. Lanham (1902). House gained their loyalty by stroking their egos and trying to make them famous. He eventually inherited control of the Texas Ku Klux Klan.	"['1 edition of Letter from Hon. Edward Stanly, military governor of North Carolina, to Col. Henry A. Gilliam found in the catalog.\nLetter from Hon. Edward Stanly, military governor of North Carolina, to Col. Henry A. Gilliam\n|Statement||refuting certain charges and insinuations made by Hon. George E. Badger, in behalf of the Southern Confederacy|\n|Contributions||Badger, George Edmund, 1795-1866, Gilliam, Henry A., 1819-1891|\n|LC Classifications||F258 .S78|\n|The Physical Object|\n|Pagination||10 p. ;|\n|Number of Pages||10|\n|LC Control Number||22016582|\nGovernor s Office to Mayor of Florence, 2 November General Correspondence. Governor Richard Irvine Manning papers. Box 1. S South Carolina . However, to offset his assumption of full responsibility for the military movement of , a letter of Edward Conigland has been inserted as a foot-note to page and in an Appendix has been added the testimony of R. C. Badger before the Senate Committee of , which investigated the relation of Senator John Pool to the Kirk-Holden War.\nEdward gained their loyalty by stroking their egos. Edward would use his money and influence to try and make them famous. Edward eventually inherited the Texas Ku Klux Klan. Edward Mandell House helped to make four men governor of Texas: James S. Hogg (), Charles A. Culberson (), Joseph D. Sayers (), and S. W.T. Lanham (). Weekly North Carolina standard. [volume] (Raleigh, N.C.) , Septem , Image 3, brought to you by University of North Carolina at Chapel Hill Library, Chapel Hill, NC, and the National Digital Newspaper Program.\nOpposed Henry\'s enlistment, deflates Henry\'s dreams of war, tells him to do what is right, and to keep his clothes clean The colonel Liked his cigars, indifferent, called . Michael Hardy is a historian and author, who has written an array of articles, blog posts and over 17 books including Civil War Charlotte, North Carolina in the Civil War and A Short History of Watauga County. Hardy was awarded the Historian Pages:\nConnivance with imperialism\n12th Lighter-Than-Air Systems Technology Conference & AIAA International Balloon Technology Conference Held June, 1997 at San Francisco, California (AIAA,)\nMethods & Perspectives in Anthropology Papers in Honor of Wilson D. Wallis\nHuman Resource Management Perspectives on TQM\nMinimum Wage Restoration Act of 1989\nEarly childhood care and development policy.\nplanning of meteorological station networks\nfairy stories of Oscar Wilde\nAlly-saurus and the very bossy monster\nPractical discourses on several subjects\nKing Henry VIII and the barber surgeons\nIts the thought that counts\nThe Atlantic index\nThe grey ghost\nPolychlorinated biphenyl (PCB) residues in food and human tissues\nAmerican ancestors of Jeffrey Barlow Henriques, Sr.\nAdd tags for ""Letter from Hon. Edward Stanly, military governor of North Carolina, to Col. Henry A. Gilliam: refuting certain charges and insinuations made by Hon. George E. Badger in behalf of the Southern Confederacy."". Be the first.\nLibrary of Congress Control Number Letter from Hon. Edward Stanly, military governor of North Carolina, to Col. Henry A. Gilliam: Caption title.\nAlso available in digital form. Contributor: Gilliam, Henry A. - Badger, George E. Letter from Hon. Edward Stanly Stanly, Edward Date: ; Book/Printed Material. Newbern weekly progress. [volume] (Newbern, N.C.)AugImage 1, brought to you by University of North Carolina at Chapel Hill Library, Chapel Hill, NC, and the National Digital Newspaper Program.\nBadger, George E. Letter from Hon. Edward Stanly, military governor of North Carolina, to Col. Henry A. Gilliam by Edward Stanly () 3 editions published. If an image is displaying, you can download it yourself.\n(Some images display only as thumbnails outside the Library of Congress because of rights considerations, but you have access to larger size images on site.) Alternatively, you can purchase copies of various types through Library of.\nWilliam T. Sherman, Letter to General Henry Halleck, September 4,from Sherman\'s Civil War: Selected Correspondence of William T. Sherman,eds. Jean V. Berlin and Brooks D. Simpson (Chapel Hill, NC: University of North Carolina Press, ), Confederate Military History.\nVol. North Carolina. Hardcover – January 1, by Clement (ed.). Evans (Author) See all 2 formats and editions Hide other Author: Clement (ed.). Evans. Letter to Col. Henry A. Gilliam, Refuting Certain Charges and Insinuations made by Hon. Geo. Badger in Behalf of the Southern Confederacy, 10p.; J S Joe A.\nMobley, who teaches North Carolina history at N. State and who has worked with the state department of archives and history, has taken upon himself the task of making us more aware of this man\'s accomplishments in a page book, \'North Carolina\'s Governor Richard Caswell: Founding Father and Revolutionary Hero.\'""5/5(2).\nFull text of ""The State records of North Carolina"" See other formats. Chief Justice of the Supreme Court of North Carolina: Vol. XXII. Miscellaneous Records: Published Page MayNorth Carolina, Granville County, Oxford District, the following person took Oath of Allegiance, to-wit: Edward (his X mark) Knowlan: Canady (his X mark) Young: Henry Tudor.\nHe was posthumously awarded the Medal of Honor six months later, on J The current Warner Barracks complex was appropriated in by U.S. forces and renamed in honor of Cpl.\nHenry F. Warner. Warner, aged 21 at his death, was buried at Southside Cemetery in his hometown of Troy, North Carolina. Medal of Honor recipients. General Orders No. 8 was written by Union general Henry Slocum, just as he crossed into North Carolina from South Carolina on March 7, General Orders No.\n8 was announced by Captain and Acting Assistant Adjutant-General to Slocum, Robert P. Dechert. 26 July –11 Nov. William Henry Glasson, economist, first dean of the Duke University Graduate School, author, and editor, was born in Troy, N.\nA first-generation American whose parents had emigrated from England shortly before his birth, he was the son of John Glasson, a native of Cornwall, and Agnes Allen Pleming Glasson, the daughter of a master tailor in Probus.\nHow to Save the Nation 8p. Septem 2 S Stanly, Edward. Letter to Col. Henry A. Gilliam, Refuting Certain Charges and Insinuations made by Hon. Geo. Badger in Behalf of the Southern Confederacy, 10p.; J 2 S Stebbins, Horatio, The President, the People, and the War: A Thanksgiving Discourse, 22p.\nEdward Allen Carter Jr. ( – Janu ) was a United States Army sergeant first class who was wounded in action during World War II. He was posthumously awarded the Medal of Honor, the nation\'s highest military decoration for valor, for his actions of Manear Speyer, Germany.\nCarter and six other black Americans who served in World War II were awarded the Born:Los Angeles, California, U.S. (Below are different Going, Goyen, Gowen related sources for those people were in the Virginia, North Carolina, or South Carolina areas in the early ’s to early ’s) Pages for People in Granville: William Gowen b.\nSarah Allen, Stafford, Brunswick Va, Grville NC, Spartanburg SC Edward Goin Sr b. abt “mulatto” in Granville. In consequence of a letter from Govenour Henry, to the Virginia Delegates, dire[c]ting the Payment of thirty thousand Dollars, as an additional Bounty granted the Soldiers, who have reinlisted, into the Virginia Regiments, I am to inform you that the money shall be paid in any manner, you may please to direct.1 It was with the most painful Sensibility that I perused your last letter on the.\nLuther H Jr weds D E Duncan. DOROTHY DUNCAN BRIDE OF ENSIGN; Wed to Luther H. Hodges Jr. of Navy, Son of Governor of North Carolina. Pair of post-war clipped signatures, front and back, 7 ¾” x 2 ¾”. Mostly likely taken from a page from an autograph book, and in excellent, clean condition.\nOn one side is “Robert B. Vance, / Riverside / No. Ca.”; on the reverse is “Wm C Oates / Abbeville / Ala.”. History of the University of North Carolina. Volume I: From its Beginning to the Death of President Swain, By Kemp P.\nBattle (Kemp Plummer), 1 Jan. –19 Feb. William Henry Bernard, newspaper editor, was born in Petersburg, Va. His father was Peter Dudley Bernard, a printer and publisher, who owned and edited the Southern Planter, an agricultural magazine, in Richmond; his mother was Sarah Lloyd d\'s paternal grandfather fought under George Washington in the American Revolution and died from wounds received at.The revolutionary history of North Carolina, yea, of America, would be incomplete without the sublime military record of this great man.\nHe was in command of the North Carolina troops in some of the mast bloody and decisive battles of the war. He was in command of the troops in the, campaigns in Pennsylvania and New York in and']"	['<urn:uuid:269bf138-6971-41c4-abf5-af32fccf41b6>']	open-ended	direct	long-search-query	similar-to-document	single-doc	expert	2025-05-12T15:09:02.012753	12	63	1411
69	What fuel-related issues were found in both accident investigations?	The 1998 Fairchild investigation found water and sediment in the carburetor float chamber and gascolator, while the 2023 Velocity had inadequate engine rpm (2050 rpm with turbocharger bypassed) for flight with one pilot and full fuel.	"['HISTORY OF FLIGHT Use your browsers \'back\' function to return to synopsisReturn to Query Page\nOn January 28, 1998, at about 1230 central standard time, a 1937 Fairchild 24G, NC16866, registered to a private individual and operating as a 14 CFR Part 91 personal flight, crashed about 15 miles southwest of Andalusia, Alabama, within the boundaries of the Conecuh National Forest. Due to the remoteness and heavy forestation at the site, there were no witnesses, and the first persons on the scene were U. S. Army paramedics from Fort Rucker, Alabama, who rappelled from a helicopter. The recently restored antique airplane was destroyed, and the airline transport-rated pilot sustained fatal injuries. Visual meteorological conditions prevailed, and no flight plan was filed. The flight departed Peter Prince Field, Milton, Florida, about 1115 for Greenville, Alabama, and ultimately, Gadsden, Alabama, where the airplane was to be delivered to a restoration facility for minor mechanical work preparatory to a sale.\nThe pilot had consented to ferry the airplane to the restoration facility as a favor to the owner, who had recently lost his FAA medical certificate. The flight was being operated as a loose flight of two with a fellow ""antiquer"" flying a Ryan SCW, who was to provide a ride home to the Pensacola area for the Fairchild pilot. They were not in sight of each other at all times, but were maintaining radio contact. The Ryan pilot stated he thought the Fairchild pilot would have been cruising at about 2,000 feet msl, and he heard no radio transmissions before the crash. A strong emergency locator transmitter signal was reported emanating from the crash site about 1500.\nThe pilot held an FAA airline transport pilot rating with L-382, B727, DC-8, and L-18 ratings as well as multiengine and single engine land and seaplane ratings. He also held an FAA airframe and power-plant rating as well as IA rating number 1253445. He had recently worked closely with the Naval Aviation Museum at Sherman Field, Pensacola Naval Air Station, Florida. The pilot\'s log books were not recovered, but according to his AME, he had estimated his total flight time to be 15,000 hours on August 29, 1997, when he renewed his FAA third class medical. He had also estimated his last 6 month\'s flight time as 62 hours. On his medical renewal form he checked, ""yes"" to the questions, ""admission to hospital"" and ""recent illnesses"". According to the family, those entries referred to minor back surgery for persistent pain performed just before Oshkosh, 1997. According to the pilot\'s AME, the pilot was a heavy smoker, and was taking injections for the back pain. The family stated the pilot received two steroid injections for the back pain, one in early January, 1998, and the other about the middle of January.\nThe airplane had been completely restored by Bishop\'s Antique Restoration, Southside, Alabama, about 33.6 hours, (tachometer hours) previous to the accident. It had been owned and operated by the pilot before he sold it to the present owner. This particular airplane, at the time of the accident, had the two rear seats removed to accommodate tires and various fuselage trim pieces. Shoulder harnesses were not installed in the airplane\'s cockpit. The wings had placarded next to the fuel-cap, ""20 U.S. Gals./min 73 Oct"". The owner stated that it was his common practice to mix 87 octane automotive fuel with 100 octane low-lead aviation fuel.\nThe Warner model Scarab S50 engine had undergone a major overhaul 173 hours before the accident. The magnetos, ignition harness, and carburetor were overhauled and reinstalled and the engine was given a 100 hour inspection by Bishop at 33.6 hours before the accident on August 1, 1997. The conformity inspection for the total restoration was approved and signed off on August 2, 1997, by the FAA. The FAA Form 337 is included under, ""Reports from Other Federal Agencies"".\nVisual meteorological conditions prevailed at the time of the accident. Meteorological information is contained in this report under Weather Information. WRECKAGE AND IMPACT INFORMATION\nThe airplane crashed in dense forest midway between Andalusia and Brewton, Alabama, within the Conecuh National Forest, at coordinates, N 31 11.25, W 86 23.63. Examination of the wreckage site indicated initial contact was with trees about 25 to 30 feet above ground level on the southern bank of the Conecuh River. The pattern of tree canopy breakage and trunk scarring indicated the airplane approached from a northeasterly direction, encountered the trees that stopped the forward momentum, and slid vertically down a tree truck to the ground from a height of about 20 feet. The longitudinal axis of the fuselage was oriented about 200 degrees, magnetic. Bending and crushing of the engine and nacelle skewed those components about 20 degrees left of the longitudinal axis. The wooden propeller blades had separated, one about 10 inches from the hub, and the other, about 14 inches from the hub. About one- third of one blade was located under the wreckage at about the longitudinal station corresponding to the firewall. All airframe components were found in the immediate area. The left outer wing panel was completely destroyed, and the left wing aluminum fuel tank was severely compromised. The right wing fuel tank was intact, contained about 20 gallons of fuel and testing for water content proved negative. The right wing leading edge received four tree strikes 8 to 10 inches deep, with the wing tip and aileron detached and lying about 2 feet aft of their normal position. Both fixed main landing gear struts had collapsed rearward. The aft fuselage and empennage received little damage. The left front seat mount had failed causing the pilot to impact the right side panel and control stick. The right side flight control continuity could not be determined due to the broken control stick. The left side aileron and elevator control and right side rudder control continuity checked satisfactorily.\nSubsequent teardown inspection of the engine revealed water and a fine, grainy sediment caked in peripheral areas of the carburetor float chamber. The airplane\'s gascolator was inspected and a relatively large amount of the same sediment, (tablespoon) was found ringed around the bottom of the removable filter element, (see enclosed photographs). A sample of the liquid contents of the carburetor float chamber, as well as samples of sediment taken from the fuel filter were saved for laboratory analysis. Results of the analysis are discussed in this report under, ""TESTS AND RESEARCH"" and the laboratory report is included under, ""Other Pertinent Forms and Reports"".\nMEDICAL AND PATHOLOGICAL INFORMATION\nPostmortem examination of the pilot was performed on January 29, 1998, at Alabama\'s Department of Forensic Sciences in Mobile by State Medical Examiner, LeRoy Riddick, M.D. and revealed cause of death to be multiple blunt force injuries. Toxicological tests were conducted at the Federal Aviation Administration Research Laboratory, Oklahoma City, Oklahoma. The tests were negative for ethanol, carbon monoxide, basic, acidic, and neutral drugs.\nTESTS AND RESEARCH\nThe airplane\'s wooden propeller was removed from the wreckage site and sent to the manufacturer for examination. Inspection was conducted, with FAA oversight, and findings were that the powerplant was producing very little power at the time of propeller impact with the trees. A copy of the report is included under, ""Reports from Federal Agencies"". The magnetos were removed and bench tested, under the oversight of the FAA, for about one hour at normal operational loads, speeds, and temperatures in accordance with manufacturer\'s specifications. Consistent firing speed occurred between 90 and 100 rpm on both magnetos. Full spark intensity from all test leads occurred at 125 rpm on both magnetos. The coils were within manufacturer\'s specifications for leakage and resistance. A copy of the report is included under, ""Reports from Federal Agencies"".\nThe saved carburetor and fuel filter specimens were sent to Panair Laboratory, Inc., Miami, Florida for analysis. Examination revealed the major elements of the sediment were aluminum corrosion, rust, zinc, and dirt. Testing of the liquid revealed a composition of fuel and water. The fuel was of a pale green color which would have resulted from either mixing blue 100LL aviation fuel and yellow colored automotive fuel or of oxidization of the blue dye in 100LL. A copy of the report is included under, ""Other Pertinent Forms and Reports"".\nThe aircraft wreckage, less the components listed on the Release of Aircraft Wreckage, was released to Mr. Gene Shiel, representing the operator\'s insurance company, on February 13, 1998. All components retained by the NTSB for further examination were returned to Atlanta Air Salvage, Griffin, Georgia, per instructions from Mr. Gene Shiel on September 29, 1998.', 'Accident Flight Was The First Flight Since… (Amended Airworthiness Certificate)\nOn April 15, 2023, about 1039 eastern daylight time, an experimental, amateur-built Velocity, N2357, was destroyed when it was involved in an accident near Andrews, North Carolina. The commercial pilot was fatally injured. The airplane was operated as a Title 14 Code of Federal Regulations Part 91 personal flight.\nAccording to the current airplane owner, the airplane suffered a landing accident in 2004, and was purchased by a salvage facility. That facility removed the engine and avionics, then sold it to the previous owner, who installed a newly overhauled engine equipped with a turbocharger. The current owner purchased the airplane and installed a new propeller and avionics. At the time of the accident, the engine had about 54 hours of operation since overhaul in 2012. Due to the modifications, a Federal Aviation Administration designated airworthiness representative (DAR) inspected the airplane, issued an amended airworthiness certificate with revised operating limitations, and endorsed the airframe logbook on April 1, 2023. The accident flight was the first flight since that endorsement.\nThe current owner further stated that he was a private pilot with about 90 hours of flight experience; of which, about 10 hours were in the make and model airplane. Since he had little experience, he hired the accident pilot to fly the first flight since the modifications/DAR endorsement. The accident pilot also inspected the airplane for about 1.5 hours prior to the accident takeoff. The owner saw the airplane take off on runway 26, a 5,500-ft-long runway, but subsequently lost sight of it behind buildings. The owner further stated that the engine was equipped with a fixed-pitch cruise propeller. With the turbocharger engaged, the engine would obtain 2,300 rpm; however, with the turbocharger bypassed, the engine would only obtain about 2,050 rpm. A spring switch in the cockpit controlled the turbocharger wastegate, to select whether the turbocharger was engaged or bypassed (or midrange). The owner added that at 2,050 rpm, the airplane would not be able to fly with one pilot and full fuel, which it had for the accident takeoff.\nThe owner provided a video that he recorded, of a portion of the takeoff. Review of the video revealed that during the takeoff roll, the airplane accelerated slower than normal, used more runway than normal, and lifted off the runway in a nose high attitude. The airplane then descended back to the runway and bounced, before lifting off nose-high again toward the end of the runway, where the video ended.\nWitnesses reported that the airplane took off, climbed about 300 ft above ground level while flying a left traffic pattern back to runway 26. Near the crosswind to downwind turn, the engine sounded loud, and the airplane descended into a wooded field and a postcrash fire ensued. The wreckage came to rest inverted, oriented about a 075° magnetic heading, and an approximate 50-ft debris path was observed. The left wing was separated and found against a tree inverted at the beginning of the debris path. The main wreckage was consumed by fire at the end of the debris path. No cockpit controls or instrumentation was identified. No seats or restraints were identified.\nThe left aileron and left rudder separated and were recovered near the left wing. The right wing and canard remained with the main wreckage and were consumed by fire. The flight controls consisted of control rods and push-pull tubes. Flight control continuity and trim continuity could not be verified due to fire damage.\nThe engine came to rest inverted, separated from the airframe. The two-blade propeller remained attached to the hub. One blade appeared undamaged while the other blade exhibited charring and tip separation. The top spark plugs were removed; their electrodes were intact and light gray in color (the Nos. 1 and 3 electrodes were oil soaked).\nBorescope examination of the cylinders did not reveal any anomalies. The crankshaft was rotated via an accessory gear drive. Crankshaft, camshaft, and valve train continuity were confirmed to the rear accessory section of the engine, and thumb compression was attained on all cylinders. Both magnetos had separated from the engine. One magneto was recovered, and it produced spark at all leads when rotated via electric drill. The other magneto was not located. Due to thermal damage, the fuel system could not be tested. The turbocharger wastegate was found in the open position.']"	['<urn:uuid:afad9a54-bd08-4fbf-8e2b-1a7c327d7c8f>', '<urn:uuid:66ccb9c9-226f-4e3c-b466-3eb351dd24a4>']	factoid	direct	concise-and-natural	similar-to-document	three-doc	expert	2025-05-12T15:09:02.012753	9	36	2165
70	How does Olympia Coffee Roasting support its staff and farmers, and what market forces affect the financial stability of coffee producers globally?	Olympia Coffee Roasting supports its staff and farmers in multiple ways. They released a special coffee called 'Tip Jar' with all proceeds benefiting staff during the pandemic. The company works directly with coffee farmers in Africa and Latin America, aiming to improve the quality of life for their producers, staff, and customers. As for market forces affecting producers, coffee prices are determined by complex factors including the C-Price set by the Intercontinental Exchange, which fluctuates based on supply and demand. Additionally, financial derivatives and speculation influence prices, with about 90% of futures traded being speculation without intention to buy physical coffee. This system leaves 25 million small farmers, who produce 80% of the world's coffee, particularly vulnerable to price fluctuations while being least able to protect themselves against market volatility.	"[""State to feel the devastating social and economic effects of the pandemic, olympia coffee roasting has released a coffee called tip jar, with all proceeds benefiting staff.olympia has also temporarily shuttered all its retail locations. It's 5 stars for the coffee, french pressed (only superseded by the clover downtown) for your pleasure.\nToday, october 12, begins the soft opening of olympia coffee roasting company‘s vastly expanded flagship roastery and café in downtown olympia, wash., at 600 4th ave.\nOlympia coffee roasters locations. All locations close @6pmnew years day: We offer a full line of exceptional quality organic coffees from around the world. Olympic crest coffee roasters menu\nAt this location, you can enjoy your cup of coffee while watching the magic happen. Olympia coffe roasters is known for working and trading directly with coffee farmers in africa and latin america. Batdorf & bronson coffee roasters was there, caring about where the coffee came.\nThe west seattle location is their first location outside of the south sound. A 2013 roast magazine roaster of the year, olympia has been occupying approximately 2,000 square feet since opening in space, but the expansion included an extensive reconfiguration with an additional 4,000 square feet. Dancing goats® espresso bar at bayview market 516 fourth avenue w.\nWith three locations in olympia, the expansion of the cherry street location provides increased space for the roasting and production facility. It is synonymous with friends, quiet, enlightenment, peace, the start to a busy day. Their locations are thoughtfully and beautifully designed for conversation, gathering, and staying a while.\nOlympic crest coffee roasters, lacey; With cafe locations in seattle, tacoma and olympia, washington, they are on a mission to improve the quality of life for their coffee farmers, employees and customers while sourcing, roasting and brewing delicious coffees. The 1,750 square foot space on rainier avenue and south edmunds street (formerly occupied by starbucks) will house a cafe, training facility.\nOlympic crest coffee roasters olympia; Victrola coffee roasters has three locations, with its showcase capitol hill location housing a roasting facility, cupping room, and training space. About us olympia coffee roasting company is a small batch artisan roaster, located in olympia, washington.\nVisitors may enjoy coffee from the major growing areas of africa, indonesia and latin america. Victrola coffee roasters in seattle evolved from a quaint neighborhood hang out in 2000, to a mighty contender in the independent coffee scene in the northwest. Rated best coffee in washington by food & wine\nSearch reviews of 140 olympia businesses by price, type, or location. Forge coffee wants to be right there with you. One of the benefits of working for a coffee company is being able to try all the different blends and brew (or press or pull) different drinks throughout the day.\nDelicious coffees for home & wholesale: Get menu, reviews, contact, location, phone number, maps and more for olympic crest coffee roasters restaurant on zomato Founded in 1955 at their flagship location in gig.\nOliver stormshak (left) and sam schroeder operate olympia coffee roasting company. Great coffee, a unique olympia flavor. Olympia coffee roasters has been roasting fair trade, small batch and single origin coffee in olympia since 2005.\nOlympia coffee roastery is located in downtown olympia where it started in 2005. 1000 black lake blvd sw olympia, wa 98502. Olympia coffee roasting co., olympia, wa.\nWe exist to improve the quality of life for our producers, for our staff, and for our customers. Coffee is the time you set aside, that still moment for yourself, lasting the length of a sip, or more. Find the best coffee & tea on yelp:\nForge coffee is an l. Their roasting process is visible through large windows throughout the shop. We love all of our coffees, but right now these are a few of our favorites.\nClosed the batdorf & bronson tasting room is located in our roastery and offers a variety of coffees for our patrons to sample. Tower ave centralia, wa 98531. Point coffee strives to be a soft place to land for anyone looking for community, friendly faces, and a great cup of coffee.\nWe sustainably source directly from farmers, roast, and brew delicious coffees seasonally! In washington state, which was the first u.s. Proudly serving coffee from dillanos coffee roasters.\nThe act of drinking coffee holds more meaning for you than a boost in energy. 8,713 likes · 57 talking about this · 5,236 were here."", 'Republished from Perfect Daily Grind\n“Why do the prices they pay us change?”\nI was stood in front of 50 farmers in an un-airconditioned one-room K-12 schoolhouse in Espinal, Tolima, central Colombia. I had been explaining how to leverage international supply chains to reach lucrative foreign markets. But this one question shocked me.\nThe woman who asked it had depended on this pricing system her entire life, but no one had ever explained to her how it worked. I hadn’t thought to explain it, because I couldn’t imagine that this information gap existed. But it does – and not just in Latin American farms.\nAs everyone sweated and my colleague pointed at his watch, I asked the intern for all the white-board marker colors she could find, and launched into a spontaneous microeconomics lecture. Over the next hour we explored supply and demand curves and price elasticity, and a dozen farmers passionately engaged themselves in the conversation.\nThis is something that farmers need to know, that importers/exporters need to know, and that consumers need to know. 25 million smallholder farmers are made vulnerable by the fluctuations of the coffee market, and it’s our responsibility, as ethical consumers, to be aware of this when we purchase our drinks.\nSo let’s look at the three factors affecting the global coffee price.\n1. C-PRICE AND THE ICE MARKET\nThe price of coffee changes every minute like stock – or any other commodity – does. It’s defined by commodities exchanges, including the Intercontinental Exchange (ICE) in New York, which is the most important for Arabica coffee and which sets what’s called a C-Price. And, like any other exchange-traded commodity, stock, bond, currency, etc., this C-Price is defined by supply and demand.\nIf there’s little coffee available, the price goes up to the point at which supply exactly equals demand. Some people that had wanted coffee will decide not to buy as the price goes too high for them. The price will then stop increasing when the remaining people who are willing to pay want the precise quantity offered.\nIf there’s a lot of coffee available, however, the price will fall to the point at which it’s all sold. So there’s more available than people want that day but, as the price drops, they decide to buy more to take advantage of a good deal. The price stops dropping at the moment that people agree to purchase precisely the quantity offered.\nThis tendency for demand to change as price changes is called price elasticity of demand (PED), and it’s the market’s unique price sensitivity.\nDusk at the top of Colombia’s Western mountain range, over 2000 m.a.s.l. The future of the farmers here depends on the fluctuations of the coffee market.\n2. COFFEE-BASED DERIVATIVES\nAdding to the complexity are financial derivatives, such as futures contracts, which are promises to purchase at a future date at a price determined today. Sound easy? It’s about to get a bit more confusing.\nThe agreed-upon price is based on the predicted price (which in turn is based on supply and demand) at the delivery date when the contract expires. Because of the derivatives market, predicted supply and demand for coffee is built into the C-Price.\nFor example, if people think the C-Price will increase in the future due to supply and demand conditions, such as a weak harvest in Brazil, they’ll start buying futures contracts today to sell for a profit when and if the price increases as the delivery date approaches. That increased demand for coffee contracts will cause the current price to go up.\nThe reverse is also true. If there is speculation that the price will drop, people will start selling their coffee and futures contracts or purchase short positions. This decreased demand will cause the current price to drop based on future speculation.\nHow much are these beans worth? That’s a complex calculation. Credit: Isai Symens via Wikipedia.\n3. HEDGING VS. BETTING\nCoffee derivatives are used as a hedge by industry actors and as an investment by speculators. So what does this mean? Well, to “hedge” as an actor in the coffee industry is to purchase a financial product based on the price of coffee at some point in the future. You do this to safeguard yourself from a change in price ahead of payment, delivery, or harvest. Hedging is an important element of modern finance and allows the commodities industry to function.\nFor example, a green coffee importer makes a deal with an exporter in an origin country to purchase 17 tons of green coffee at C-Price+10 cents per pound. That coffee won’t be delivered for 3 months, so if the C-Price rises between today and the delivery date, the importer owes more.\nLet’s look at how that works in practice. This importer buys a 3-month future contract to essentially lock in today’s price. If the C-Price goes up in 3 months, she buys the coffee at the higher price and sells her future contract for a profit, offsetting the increase on what she spent on coffee. If the C-Price drops, on the other hand, she buys the coffee cheaper than expected and sells the future contract at a loss. In either case, she gets the coffee for the price of the day that she made the agreement.\nThe purchase of this hedging instrument is indicative of real demand for coffee, and therefore contributes to the logical C-Price movement based on real supply and demand.\nHowever, anyone can buy financial instruments based on the C-Price, not just those involved in the physical trade. Speculation without the desire to ever buy or sell physical coffee, which is about 90% of the futures traded, also affects the C-Price based on the supply and demand for futures. The large volume of futures traded can cause price inertia or more extreme price swings than would normally occur based purely on the physical product.\nSound pretty unstable yet?\nSunshine breaks through the rain clouds to shine on a coffee farm in the Colombian Eje Cafetero.\nAs a financial market, this is all part of the game. However, in practice, there are two flaws with this system. The first is that, while the industry is able to hedge market volatility to an acceptable level of risk, most of the 25 million small farmers that produce 80% of the world’s coffee do not have that capacity. This leaves farmers the most vulnerable to price fluctuations while the least able to weather them. Secondly, there is no formal consideration for specialty-grade quality coffee – but that’s a large topic deserving of its own article.\nCoffee has always been a boom and bust market, susceptible to bad weather, pests, and civil strife. The way that it’s purchased only makes it more unstable.']"	['<urn:uuid:0bc92916-1276-4b66-b32e-c4491e70406d>', '<urn:uuid:4799d96a-fec9-4c12-8a31-7963dd444d63>']	open-ended	direct	verbose-and-natural	distant-from-document	multi-aspect	expert	2025-05-12T15:09:02.012753	22	130	1867
71	yellowstone river oil spill 2011 exxonmobil pipeline volume leaked location	The ExxonMobil Silvertip Pipeline ruptured near Laurel, Montana on July 1, 2011, discharging approximately 63,000 gallons (about 1,500 barrels) of crude oil into the Yellowstone River and floodplain.	['The second meeting of the Yellowstone River Recreation Project Advisory Committee will take place on Monday, June 12, from 7:00 PM to 9:30 PM (est.) at the Billings Senior Center at 901 South 30th St., Billings, MT.\nMembers of the Committee are:\nKenneth E. Olson, Jr.\nYellowstone County appointed:\nIn January 2017, the State of Montana and U.S. Department of the Interior issued the Final Programmatic Damage Assessment and Restoration Plan and Final Programmatic Environmental Assessment for the Exxonmobil Pipeline Company July 1, 2011 Yellowstone River Oil Spill. The restoration plan was prepared by the State of Montana through the Department of Justice Natural Resource Damage Program and the U.S. Department of the Interior, through the Bureau of Land Management and U.S. Fish and Wildlife Service. The restoration plan describes the natural resource injuries caused by the oil spill and restoration project types to compensate for those injuries.\nThe State of Montana and the United States entered into a $12 million natural resource damage settlement with Exxonmobil, which was approved by the Court in December. The State of Montana will be implementing almost $9.5 million in restoration projects on the Yellowstone River in the next few years. “The restoration plan includes a range of project types that address specific injuries associated with the oil spill, and in total will make the environment and public whole,” said Alicia Stickney, Natural Resource Damage Program Project Manager. “The plan will guide restoration of the Yellowstone River to improve natural and recreational resources of the river injured due to the spill.”\nTo assist with the development of recreation projects, the State has formed a locally-based ad-hoc Recreation Project Advisory Committee to prepare a draft Recreation Project Plan for how approximately $2.3 million will be spent on recreation projects on the Yellowstone River impacted by the spill. The draft Recreation Project Plan will be submitted to the Governor for approval. The Recreation Project Advisory Committee will solicit projects and input from the community.\nHISTORY OF THE SPILL\nOn July 1, 2011, a 12-inch diameter pipeline (Silvertip Pipeline) owned by ExxonMobil Pipeline Company ruptured near Laurel, Montana, resulting in the discharge of crude oil into the Yellowstone River and floodplain. The discharge is estimated to have been approximately 63,000 gallons (about 1,500 barrels) of oil. The discharge occurred during a high-flow event, affecting approximately 85 river miles and associated floodplain. Oil from the spill, along with the cleanup activities, harmed natural resources including fish and other aquatic organisms, birds (including migratory birds), wildlife, large woody debris piles, aquatic habitat, terrestrial habitat, recreational use, and the services provided by these natural resources. These public natural resources are under the Trusteeship of the State of Montana and the U.S. Department of the Interior under the Oil Pollution Act and other laws.\nTHE OIL POLLUTION ACT AND NATURAL RESOURCE DAMAGE ASSESSMENT AND RESTORATION\nThe primary goal of the Oil Pollution Act is to make the environment and public whole for injuries to natural resources and services resulting from a discharge of oil or other hazardous substances to the environment. In the restoration plan, the Trustees have presented their evaluation of injuries to the natural resources, restoration alternatives, and projects that benefit the same or similar resources injured by the oil spill.\nINJURED RESOURCES AND RESTORATION ALTERNATIVES\nOil from the spill, along with spill response and cleanup activities, harmed fish, wildlife and their habitats and other natural resources in and around the Yellowstone River. The spill also impacted the recreational use of the river and public sites along the river. Injuries included:\nThe Trustees evaluated a range of restoration alternatives that would provide resource services to compensate the public for losses pending natural recovery of resources injured by the oil spill. The Trustees have identified preferred restoration alternatives designed to address the resource injuries. The Trustees plan to work with project partners such as local, state, and federal agencies and nonprofit organizations and landowners to implement the projects.\nProject types include:\nLINKS AND DOCUMENTS']	['<urn:uuid:0e11fe8d-b1d6-4c09-aff0-4d2818a8e71f>']	factoid	direct	long-search-query	similar-to-document	single-doc	expert	2025-05-12T15:09:02.012753	10	28	664
72	How do rainfall patterns influence both plant growth and insect populations in agricultural settings?	Rainfall has significant impacts on both plant development and pest activity. In cotton, heavy rains increase nitrogen uptake, which can result in rapid growth. The plant's natural height regulation is disrupted by heavy rainfall. As for pests, certain insects like spider mites thrive in opposite conditions - hot, dry, and dusty environments. These mites form dense colonies on the undersides of leaves and damage plants by puncturing their cells. This shows how moisture levels critically affect both plant development and pest populations.	['Last week I hosted a Cotton Workshop that focused on the phase of cotton growth from first square to first bloom, the current stage of our cotton crop. Since this growth stage is so important, I thought I would review some basic cotton physiology as it relates to current growing conditions.\nHere are some important pointers to consider when managing cotton during this growing stage. Currently the heat units for our cotton crop are very near normal and early planted cotton is at least at the six to seven node stage and setting squares. This cotton should be at first bloom by the first week of June. As a general rule, for every 50 heat units accumulated, the cotton plant will produce a new node.\nMoreover, at this time the cotton plant is continuing to develop an extensive root system and will do so until about one week after flowering.\nIt is important to note that up to 85 percent of the lint yield will be determined by first bloom, and up to 80 percent of that yield will come from the first fruiting positions on the cotton plant. So now is the time to see that our cotton has optimum growing conditions and we need to protect that first fruiting position.\nCotton insects during this growth stage that warrant serious considerations include cotton fleahoppers at which the treatment threshold is 15 per 100 terminals. In addition, aphids can also cause problems, and if more than 50 aphids per leaf persist for more than seven days treatment for them is probably warranted.\nOne of the goals during this growing stage should also be to develop the best plant structure possible. To achieve that, we need to consider the growth potential of the plant. Ultimately the, final cotton plant height here in the Coastal Bend should be 30 to 35 inches for 30-inch rows, or a rule-of-thumb used to predict optimum plant height is to multiply the row width times 1.1. With these limits, one can ensure that row middles are covered but not to such a degree that boll rot will develop.\nThe cotton plant produces a new node in the terminal every three days. Each new internode continues to extend and thicken over the next 12 to 15 days, depending on temperature and growing conditions. The most rapid expansion (85 percent) occurs in the first six to ten days. Heavy rains or use of irrigation will cause cotton to increase nitrogen uptake, which can result in rapid growth.\nA cotton plant will do a good job of regulating its own height if there is a lack of heavy rainfall and the presence of a heavy fruit load during this time.\nTo help control rapid growth the product Mepiquat chloride (MC) is used. MC will help retard excessive plant height as it suppresses stem elongation of newly formed internodes. The minimum MC concentration in the plant necessary to provide a maximum level of reduction is 12-15 parts per million. It is extremely important to make the first applications of MC early enough, usually around Matchhead Square to keep the plant’s growth under control. For more information about using MC to manage cotton plant height consult the publication found at this web site; http://safiles.tamu.edu/agronomy/cotton/b6042.pdf\nSo at the conclusion of this growth stage that is first bloom, one can count the nodes above white flower (NAWF) to determine just how well the crop is doing. In fact, we would like to see that number around eight or nine nodes. If that number is at five, the cotton plant is in trouble and production of additional squares will end as this is known as “cut out.” If the plant has nine NAWF at first bloom, this is an indicator that the plant has a lot of “horse power” and great yield potential. So we hope around June 10 our cotton plants have eight or nine NAWF, and of course a little more rain between now and then will help achieve that goal.', 'Garden Pests Identification is essential because these pests can chew on plants and damage your garden. These are some of the common garden pests. After proving that gardening is good for health now its time to keep your garden healthy.\nSpider mites are common garden pests that thrive well in hot, dry, and dusty conditions. Residing on the undersides of the leaves of plants, these mites congregate in dense colonies in protective silk webs.\nThey cause damage to the plants by puncturing their cells to feed on them. This, in turn, shows up as a silvering or stippled effect on the leaf top. These garden pests feed on a number of species of plants including ornamental and houseplants as well.\nAlthough various garden insects are known as leaf miners, the most common are the larva of tiny flies that reside in and eat the leaf tissues, creating visible mines between its upper and lower layers.\nThey are identified as garden pests as they cause immense damage garden plants. They can be effectively taken care of by either planting trap crops or encouraging natural parasites.\nScales are sap-sucking garden pests that attach themselves with the host plants in order to feed. They secrete a waxy coating, which makes them look like fish scales. Usually, they appear as shell-like bumps, and before one can realize, they build up huge colonies and start destroying the plants.\nScales are serious pests in the garden, which can only be controlled using horticultural oils, as their waxy covering protects them well from contact insecticides.\nFound in moist and warm climates, mealybugs are unarmored scale pests in the garden that feed on the juices of plants and act as a vector of several plant diseases. While sucking plant juices, these garden pests secrete a powdery wax for their protection and require garden fungus identification. You should properly follow the indoor gardening tips to keep insects away.\nThey are a major menace as they infest and damage various types of plants including mango, grapes, sugarcane, mulberry, pineapple, ferns, sunflower, papaya and orchids. The tenacity of these garden insects increases in the presence of ants, as ants protect from predators and parasites.\nThrips are fringe-winged minute insects that feed on a large variety of plants. They are one of the most commonly found pests in the garden and are considered hazardous. These garden pests feed on them; they cause discoloration, deformities, and reduced marketability of the crops.\nThey are one of the prominent vectors of several plant diseases and are known for transmitting more than 20 plant-infecting viruses.\nAlso known as the plant lice, aphids are small, soft-bodied sap-sucking insects, which are one of the most destructive garden pests in temperate regions. They usually cluster on the tips of new growth and leaf undersides and starting sucking plant juices, which cause the leaves to become distorted and yellow.\nAphids share a unique relationship with ants, as the later farms and protects them in order to extract honeydew secreted by the former. This process is known as tending, and it causes black sooty fungus to grow on leaves. Aphids reproduce at a rapid rate, which makes them quite menacing. They also spread diseases among plants.\nWhiteflies are tiny garden insects that commonly feed on the undersides of plant leaves and stems. These menacing garden pests carry and spread garden diseases, thereby posing as a great agricultural threat globally. These pests are really dangerous specially for flower plants.\nThese flies feed by sucking into the phloem of plants and while doing so release a toxic saliva that decreases the plants’ overall turgor pressure. These hazardous pests in the garden are known for congregating in large numbers, which causes rapid degeneration in susceptible plants.\nControlling the outburst of whiteflies is a challenging problem, for these tiny garden pests have developed resistance towards chemical pesticides. Therefore, an integrated approach with biological control methods is required for achieving the same.\nSo, make sure that your garden is protected and identify garden pests.\nAlso Read: A Beginner’s Guide To Container Gardening']	['<urn:uuid:8ee207e7-0128-4ba7-b2f7-4e8e6180a6a5>', '<urn:uuid:a5ed2f26-1f7c-4d82-a6d8-a2f89bf82a9c>']	open-ended	direct	verbose-and-natural	distant-from-document	multi-aspect	novice	2025-05-12T15:09:02.012753	14	82	1345
73	achievements comparison evelyn trout amelia earhart first woman records accomplishments	Both Evelyn 'Bobbi' Trout and Amelia Earhart achieved significant aviation records. Trout set several records including the first all-night flight by a woman, women's solo endurance record of 17 hours 5 minutes and 37 seconds in 1929, and accomplished the first refueling endurance flight by women lasting 42 hours with Elinor Smith. Earhart became the first woman to solo across the Atlantic in 1932, setting a speed record for pilots of either gender, and also won a prize for a flight from Hawaii to the mainland in 1935. Both women participated in the first Women's Transcontinental Air Derby in 1929, which later became known as the 'Powder Puff Derby.'	['By Di Freeze\nEvelyn “Bobbi” Trout, up until recently the last living participant of the inaugural “Powder Puff Derby,” passed away on Jan. 24, 2003.\nEvelyn Trout was born on Jan. 7, 1906, in Greenup, Ill, and lived in various parts of Colorado, Missouri, Canada, and California.\nThe tomboy, who gave herself the nickname of “Bobbi” when she faced teasing from family and friends after bobbing her hair, as stage and screen star Irene Castle had done, developed a passion for aviation when she saw a plane fly overhead on a spring afternoon in 1918. She took her first airplane ride at Rogers Field in Los Angeles in December 1922, in a Curtiss Jenny.\nShe took flying lessons at Burdett Air Lines Inc., School of Aviation, owned by “Pop” Burdett. Her first lesson was on New Year’s Day, 1928, in one of Burdett’s five Curtiss Jennies. She soloed in April 1928, and was soon flying an International K-6, a four-place biplane her mother purchased from Burdett.\nTrout had the opportunity to meet Charles Lindbergh, at the National Air Races & Aeronautical Exposition, held that year at what was known as Mines Field, but is now Los Angeles International Airport.\nThat same year, after her aircraft was displayed on the roof of the May Company during an exhibition, she found a sponsor, the Sunset Oil Company, and the company logo was painted on the craft. Later, she began demonstrating aircraft, as well as working on some, for R.O. Bone, the builder of the Golden Eagle.\nOn Dec. 14, 1928, she flew a Golden Eagle in the official dedication of Los Angeles’ Metropolitan Airport, now Van Nuys Airport. On Jan. 2, 1929, in a flight out of Metropolitan of 12 hours and 11 minutes, she broke an earlier 8-hour endurance record set by Viola Gentry.\nAfter Elinor Smith had bettered her record by one hour, on Feb. 10, 1929, she set out from Mines Field, returning 17 hours, 5 minutes and 37 seconds later, holding five new records, including the first all-night flight by a woman and the new women’s solo endurance record. One headline read, “Tomboy Stays in Air 17 Hours to Avoid Washing Dishes.”\nOn June 16, flying a new 90-hp Golden Eagle Chief, Trout climbed the aircraft to 15,200 feet, shattering the existing light class aircraft altitude record.\nOn Aug. 18, 1929, Trout, flying a newly revamped 100-hp Golden Eagle Chief, and other women including Amelia Earhart took off from Clover Field in Santa Monica, Calif., heading toward Cleveland, Ohio, in the first Women’s Transcontinental Air Derby, during the prestigious National Cleveland Air Races.\nTheir eight-day course would be navigated by dead reckoning and road maps, and would result, when conversation between Trout, Earhart and others later turned to how to stay in touch, in the creation of the Ninety-Nines.\nOnlookers at the race included Wiley Post, Howard Hughes and Will Rogers who, after seeing several of the women checking compacts and powdering noses, dubbed the race the “Powder Puff Derby.”\nOn Nov. 27, 1929, with Elinor Smith, while flying a Sunbeam biplane, Trout took off from Metropolitan Airport to attempt the first refueling endurance flight by women. The task was accomplished through a Curtiss Carrier Pigeon, which refueled the plane three and a half times, during a period of 42 hours and three and a half minutes.\nOn Jan. 4, 1931, Trout went aloft for another refueling endurance flight with starlet Edna May Cooper. They were in the air for 122 hours and 50 minutes.\nDuring the thirties, Trout instructed and took up photography. Later, during the WWII years, she founded a rivet-sorting company and deburring service. Following that, she opened a real estate office, took a turn at offset printing and opened a life insurance and mutual funds office.\nHer thrill seeking throughout the years included motorcycle riding and driving around north San Diego County in her red Porsche 914.\nTrout’s numerous honors include being awarded the OX5 Pioneer Woman of the Year Award (1976), induction into the OX5 Aviation Pioneers Hall of Fame (1984) and nomination into the Women in Aviation’s Hall of Fame (1993), and receiving the Howard Hughes Memorial Award for her lifetime contributions to aviation (1997).', 'Amelia Earhart (1897-1937)\nBorn in Kansas, Amelia Mary Earhart lived in Iowa and Minnesota before graduating from high school in Illinois. She did a semester of work at a small college in Pennsylvania then went to Canada to work in a military hospital during World War I. It was there that she met aviators and developed her lifelong love of flying.\nYet Earhart’s peripatetic ways continued, for it was not easy for a young woman of that era to see herself as an aviator, let alone understand how to systematically accomplish that goal. She spent a year on the fringes of Smith College, where her sister studied, and then enrolled at Columbia University, but soon was across the nation at the University of Southern California. It was this move to Los Angeles that turned out to be salient to her life, as it brought her first airplane ride. Earhart immediately set about learning to fly and soloed for the first time in June 1921.\nWith money she earned by working as a telephone operator, she bought a plane for her twenty-fifth birthday. A crash only a few months later did not diminish her enthusiasm, but family finances nonetheless meant that Earhart had to revert to traditional women’s work. She moved back to her sister in Massachusetts, worked as a teacher of English to immigrants and lived at the Denison House—a long established settlement house that was an important influence with immigrant women and especially the Women’s Educational and Industrial Union. But Earhart was not a teacher or social worker, either by training or by inclination. She was instead again trying to force herself into the stereotyped molds available to women, and that this effort did not prevail was due in large part to chance and happenstance.\nThe Putnam publishing firm, seeking an opportunity to expand on the public enthusiasm for Charles Lindbergh’s transcontinental flight a year earlier and looking for a woman to make a second flight distinctive, settled on Earhart after she was mentioned by Bostonians who knew of her interest. Thus, on June 17, 1928, Earhart—as passenger, log-keeper, and standby pilot—set off from Newfoundland with two men, a pilot and a mechanic.\nWhen they landed in Wales, the world’s attention focused on this “Lady Lindy,” and almost overnight she went from settlement house worker to celebrated pilot. Earhart quickly became a public darling whose reputation far exceeded those of other women who did dangerous “barnstorming” in the era’s popular flying exhibitions. A propensity for understatement and humor, added to her cute blond curls, made Earhart a public relations dream; the era’s flappers saw her as the epitome of the liberated woman, while their parents pointed to her Midwestern modesty, common sense, and traditional manners.\nThe resulting popularity meant that her flying could be increasingly financed by those with a product to promote, while the transatlantic voyage’s link with Putnam’s not only brought about the publication of her book about the flight (20 Hrs. 40 Mins.), but also a position as aviation editor of Cosmopolitan (then a reputable family magazine). The vice-presidency of the new Ludington Airlines was icing on the cake. At age thirty-one, Earhart was a national phenomenon.\nThe stock market collapse the following year did little to slow her down, as the nation, seeking escape during the Depression, seemed only to fall deeper in love with their Amelia. Although she did not win it, Earhart was the focus of the first Women’s Air Derby in 1929 and was elected the first president of the Ninety-Nines Club, an organization for female pilots also founded that year.\nAware that her initial fame was to a large extent the creation of her publicists, Earhart was determined to earn the recognition she received. She set several records for speed and distance with flights in the forerunner of a helicopter in 1931, and the following year, she became the first woman to solo across the Atlantic, setting a speed record for pilots of either gender. This flight was recognized by with the American Distinguished Flying Cross and by the French with their Legion of Honor.\nShe married her publishing associate, George Putnam, in 1931, but retained her maiden name. Her second book, The Fun of It, came out in 1932, but more important to Earhart were additional aviation achievements. She won the ten thousand dollar prize for a flight from Hawaii to the mainland in 1935 and also received accolades for a non-stop solo from Mexico City to New York. She became affiliated with Purdue University in that same year, when its officials used her as a role model for women students and supported that decision by buying Earhart a Lockheed plane with state-of-the-art equipment.\nIt was in this “flying laboratory” that she set out for an around-the-world trip intended not for speed, but for scientific research. With a three-man crew, she set out from California to Hawaii, but when they discovered the plane needed repairs, it was shipped back to the mainland. She began a second time from the East Coast with only one man to assist; they left Miami on June 1, 1937. Radio contact and regular landings went off as scheduled for a month, but radio contact ceased on July 2, while they flew a dangerous 2,500-mile mid-Pacific leg between New Guinea and a tiny island where Earhart planned to land on a barely visible airstrip. No plane was ever found, despite a well publicized search that has gone on for decades.\nShe is one of the half-dozen women among a hundred men in the National Aviation Hall of Fame, and George Putnam published his wife’s posthumous autobiography, Last Flight, in 1937. Although she was a licensed pilot for a mere sixteen years and famous for less than a decade, Amelia Earhart made a very significant contribution to the history of American women. Presumably dying a few days short of her fortieth birthday, she exhibited genuine courage, resourceful intelligence, and leadership ability that commanded worldwide respect. She gave millions of women suffering through the Great Depression a reason to be proud.']	['<urn:uuid:d77eee2f-8a6b-4d59-a550-61711b03a80a>', '<urn:uuid:e216d27f-df49-42ab-9854-e0566ffe6542>']	open-ended	direct	long-search-query	distant-from-document	comparison	novice	2025-05-12T15:09:02.012753	10	109	1716
74	As a microbiologist I want to understand what happens when bacteria become immune to treatments process mechanism	When bacteria colonies are exposed to antibiotics like methicillin, bacteria with any resistance are less likely to be killed and can reproduce despite the antibiotic. This results in most future generations inheriting this resistance, making even more resistant mutations more likely. This process is similar to evolution, though it's more like metamorphosis since it happens in individual bacteria rather than across an entire species over time.	"['Title text: Biologists play reverse Pokémon, trying to avoid putting any one team member on the front lines long enough for the experience to cause evolution.\nIn a Pokémon game, a player goes out in search for the eponymous creatures. Many Pokémon can be found directly in the wild, but there are also a lot of Pokémon that require training and growth, to cause them to ""evolve"" into new Pokémon. ""Evolve,"" the game\'s term, is a misnomer which earned itself quite some controversy in the past; in reality, Pokémon ""evolution"" is more akin to puberty or metamorphosis, since instead of the entire species of Pokémon acquiring changes through an extended period of time, one specific member of the species grows instantly to the ""higher stage."" At that point in the game, the Pokémon glows before transforming into the new form, then stops glowing, and the very same text ""What? XXX is evolving!"" is used (see this video or those screenshots for instance). The changes of such a transformation can be quite dramatic ... or not.\nThis comic depicts the ""evolution"" of bacteria as observed by a Biologist in the same format as the game Pokémon. Here we have Staphylococcus aureus, which is not a desirable bacterium (it causes Staph infections) which evolves into ""Methicillin-resistant Staphylococcus aureus"". Methicillin is an antibiotic. If the bacterium becomes resistant, it means the antibiotic will be less effective against it, making infections harder to treat. Thus the observer is not pleased with such an evolution.\nThe title text references this by suggesting that biologists do not want bacteria to evolve in this way, as opposed to Pokémon where you put a Pokémon on the ""front lines"" as much as possible to gain it experience and hope it evolves. A point of irony is that Pokémon evolution can easily be prevented, by using an Everstone, or stopped, by pressing the B button in the game controller during evolution, especially if there are Pokémon that one does not want to evolve. The bit about the front lines is that, if a bacteria colony is exposed sufficiently to an antibiotic, those bacteria with any level of resistance to the antibiotic are less likely to be killed by the antibiotic, and are able to reproduce in spite of the antibiotic. Most future generations of bacteria now have this level of resistance instead of just a small subset. This makes the likelihood of future more resistant and harder to treat mutations even more likely.\nStaphylococcus aureus is a very common bacterium, that under an electron microscope looks like the xkcd drawing, and is the major cause of staph infections in the nostrils and skin. Hospitals are often plagued with outbreaks of Methicillin-resistant Staphylococcus aureus (MRSA), which is very difficult to treat as the typical antibiotics do not work on it.\n- [Bacterial cell culture.]\n- Staphylococcus aureus is evolving!\n- Off-screen: Aww, crap.\n- Staphylococcus aureus evolved into Methicillin-resistant Staphylococcus aureus!\nadd a comment! ⋅ add a topic (use sparingly)! ⋅ refresh comments!']"	['<urn:uuid:70cf1ddb-7cae-4a25-8595-54664d8608ab>']	open-ended	with-premise	short-search-query	distant-from-document	single-doc	expert	2025-05-12T15:09:02.012753	17	66	503
75	What is the anticipated impact on the Friant-Kern Canal's elevation even if sustainable water usage standards are achieved immediately?	Even if the 2040 sustainability standard was met right now, the affected area of the Friant-Kern Canal would still subside by less than a foot.	['Now that the Groundwater Sustainability Plan has been approved, the real work begins so to speak.\nThe Eastern Tule Groundwater Sustainability Agency Board approved the GSP at its meeting on Friday, laying out the goals for the agency to meet the state requirement to reduce groundwater usage to what’s considered a sustainable level by 2040.\nThe plan was due to be submitted to the state by January 31. The ETGSA covers virtually all of Southeastern Tulare County.\nNow the hard work begins which includes determining just how much water growers can pump out of the ground. A big factor in deciding how much groundwater can be pump will be mitigating the decreased level of water in the Friant-Kern Canal, another major topic addressed at Friday’s meeting.\nThe board also took action in dealing with the issue of the Friant-Kern’s subsidence on Friday and the GSP deals with that issue as well.\nThe GSP’s goal is to basically make sure enough water can be stored for groundwater usage to be sustainable. “In achieving the Sustainability Goal, these GSPs are intended to balance average annual inflows and outflows of water by 2040 so that negative change in storage does not occur after 2040, with the goal being avoidance of undesirable results caused by groundwater conditions,” the plan states.\nBased on an analysis presented in October, Southeastern Tulare County would have to reduce its groundwater use by 10 percent a year over the next 10 years, beginning this year and 30 percent a year from 2031 to 2040 to have what would be considered groundwater sustainability by 2040.\nBut while the 10 percent figure is a guide, what growers can specifically pump out of the ground will obviously have an effect on the amount of crops they can grow.\nIt has been reported based on current plans to reach sustainability by 20 one area of the canal would subside by 3.4 feet. Even if the 2040 sustainability standard was met right now that same area of the Friant-Kern Canal would still subside by less than a foot.\nWith that in mind the board approved a study that would cost about $45,000 that would look at the causes of the Friant-Kern’s subsidence and possible solutions. Also as part of the study a land management area which has yet to be identified will be chosen looking at the Friant-Kern’s subsidence impact on that area.\nIn addition Johnny Amaral of the Friant Water Authority which manages the canal spoke before the board and said the authority is looking at mitigation and mitigation fees as far as fees and groundwater usage is restricted based on usage of the canal. That’s a concern that’s also been expressed by growers.\nThe GSP also gives the ETSGA board the authority to implement fees and incentives when it comes to groundwater usage. But one area the GSP doesn’t address is water rights as it the plan waives the ETSGA of any responsibility when it comes to anything dealing with water rights such as water rights disputes.\nThe board also approved a three-year contract based on the agency’s finance committee’s review with Land IQ to measure the water usage of crops. The cost would be 72 cents per gross acre.']	['<urn:uuid:6f2a326b-c615-4435-9702-31304e369f2c>']	factoid	direct	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-12T15:09:02.012753	19	25	538
76	where is australian opal found how does it form in nature	Australian opals are mined in South Australia, New South Wales and Queensland. They form in arid regions within weathered rocks. The formation process begins when rainwater containing dissolved silica seeps into cracks and crevices of ancient bedrock. During dry periods, as the water evaporates, the silica solidifies and forms opal veins. Australian opals are more stable than opals found in other parts of the world, which are typically formed in volcanic regions and have higher water content that makes them prone to cracking and crazing.	['Is Opal a Gemstone?\nHere, we provide a concise answer to the frequently asked question: “Is opal a gemstone?” We also discuss the gemmological properties of precious opal, opalescence and correct opal nomenclature (how to describe and classify opals).\nOpal is a hydrated form of amorphous silica (SiO2 .nH2 O). It exists in two basic forms defined by visual properties.\n2. Common Opal\nCommon opal does not reveal a “play-of-colour” and is typified by a measure of micro-crystallinity. It is similar in structure to precious opal but are further distinguished by a disorderly arrangement of silica spheres.\nMost common opals are called potch. Potch differs from other common opals in formation and structure. It is structurally similar to precious opal but has a disorderly arrangement of silica spheres, whereas other common opals exhibit a degree of micro-crystallinity.\nIt may seem strange to ask: “Is opal is a gemstone?” However, if you consult a jewellery and gemstone directory, you will notice merchants who describe themselves as being ‘opal dealers’ or ‘opal and gemstone dealers’. It is a stands tribute to the opal’s uniqueness.\nYet, precious opals are gemstones – they are referred to as either being gemstones or opals of gemstone quality, and they are distinguished by their ‘play-of-colour’. Moreover, opal is Australia’s officially designated national gemstone.\nA Fabulous Black Opal (00:14 minutes)\nOpalescence: Understanding Play-of-Colour\nIt wasn’t until the 1960’s that studies by Australian scientists at The Commonwealth Scientific and Industrial Research Organisation (CSIRO) revealed the true nature of the play-of-colour within a precious opal – its opalescence.\nUsing an electron microscope, scientists were able to establish that opals were made up of millions of small silica spheres, 000005–0.0004 mm in diameter.\nIn the case of precious opals, it’s the size of the silica spheres, their arrangement within an orderly network and the light source that determines the nature of a stone’s play-of-colour.\nUnder a bright light-source, a precious opal’s play-of-colour can be observed from three aspects:\n- The play-of-colour revealed by moving the stone\n- The play-of-colour revealed by moving the light source\n- The play-of-colour revealed by altering the angle of observation\nOpals: The New Nomenclature\nTraditionally, an Australian opal was informally classified in number of ways, usually related to related to its state or district of origin and its physical characteristics. However, as the Australian opal became ubiquitous in markets across the globe, the need for a standardised system of opal classification became apparent.\nIn 1993, The Australian Gemstone Industry Council approached the Gemmological Association of Australia (GAA) to propose a new opal nomenclature that would be uniformly accepted..\nThe GAA resolutions that codify and standardise opal nomenclature were informed by the definitions and rules for gemstones, diamonds and pearls outlined by The International Jewellery Confederation (CIBJO).\nThe Nomenclature Subcommittee of the GAA, in collaboration with the Australian Gemstone Industry Council, the Australian Gem Industry Association, the Lightning Ridge Miners Association and the Jewellers Association of Australia, established uniformed standards for the classification of opals.\nThe NSW Department of Planning, Industry and Environment (Division of Resources and Geoscience) has outlined the guiding principles here: Opal Classification.\nHow the Australian Opal is Formed\nTypically, the Australian opal fields are located in arid regions, and opals are usually discovered within weathered rocks.\nThe process of opalisation commenced when water from infrequent rains, bearing dissolved silica, permeated the cracks and crevices of ancient, outback bedrock. During prolonged dry periods, as the water content evaporated, the silica solidified and began to form opal veins.\nAustralian opals are mined in South Australia, New South Wales and Queensland.\nElsewhere in the world, opals are usually found in regions associated with volcanic activity, and they often have have a high water content – as much as twenty percent of an opal’s mass can be water trapped within silica. Opals formed under these conditions are typically less stable than Australian opals and more prone to cracking and crazing. Crazing results in a loss of colour and brilliance.\nThe Properties of Precious Opal\nOpal is a hydrated form of Silica. Water can represent as much as 20% of an opal’s weight, but generally lies within a range of 6% -10%. Precious opal is classified as mineraloid – it has an amorphous crystal system.\nGemmological Data: Precious Opal\n|Family:||Mineral: Hydrated Silica|\n|Hardness (Mohs Scale):||5.0 – 6.5|\n|Lustre:||Sub Vitreous – Waxy|\n- Australian National Gemstone | Department of the Prime Minister and Cabinet. Retrieved 3 January 2020, from https://www.pmc.gov.au/government/australian-national-symbols/australian-national-gemstone\n- Smallwood, Anthony. (1997). A new Era for Opal Nomenclature. Australian Gemmologist (1997) 19, 486-496.\n- Opal classification – NSW Resources and Geoscience. Retrieved 10 January 2020, from https://resourcesandgeoscience.nsw.gov.au/miners-and-explorers/applications-and-approvals/opal-mining/about-opal/opal-classification\n- Cram, L. (1998). A Journey with Colour (Volumes 1 -4). Lightning Ridge, N.S.W.: L. Cram.\n- Cody, A. (1991). Australian Precious Opal. Melbourne: Andrew Cody Pty Ltd.']	['<urn:uuid:c480ab56-9625-4514-880a-a104acfb6610>']	open-ended	with-premise	long-search-query	similar-to-document	single-doc	novice	2025-05-12T15:09:02.012753	11	85	798
77	malware testing pass vs webapp pentest steps compare	PASS testing and webapp pentesting use different steps. PASS testing consists of 4 interdependent variables: performance, availability, security and scalability testing. In contrast, webapp pentesting follows a sequence of steps including information gathering, threat modeling, vulnerability analysis, exploitation, and reporting phases.	"[""Nearly every IT environment uses security systems to help detect and stop malware. These might include firewalls that can be configured with various rules, UTM systems offering content filtering, gateway antivirus software, deep packet inspection (DPI) and intrusion prevention systems (IPS).\nUnfortunately, in most enterprises, testing security measures is at best neglected and at worst completely overlooked. According to a recent PandaLabs report, more than 74,000 new malwarestrains are created every day. Given this large volume of new threats, companies can put themselves at risk with just one misconfiguration on a firewall port.\nDespite all of the tools at the IT department's disposal to find and prevent malware, threats still find a way to infect various systems. Stopping malware requires consistent testing of these systems to make sure they can handle the latest threats under the most intense real-world scenarios.\nBYOD policies introduce a whole new level of complexity for preventing malware. IT groups need to consider that user devices might not have the required security software or have out-of-date patches. Companies that allow personal devices for work purposes need to find the right balance between implementing safeguards on devices and also understanding they don't have complete control.\n[ Hackers often cloak themselves in headlines. Read Royal Baby Malware Attacks. ]\nA recent study from Enterprise Strategy Group (ESG) on advanced malware protection and detection polled 315 North American-based IT security professionals working at enterprise-level firms who have seen a rise in more sophisticated malware during the past two years. Malware criminals continue to invent new ways to both hide threats and amplify the malware's ability to avoid detection and elimination. Many criminals are turning to mobile-based malware to steal money from users. For example, they might misuse SMS shortcodes purchases (typically used for donations) to encourage fraud or use malware to gather personal and business-related information about the user.\nFinding The Balance\nCompanies that implement aggressive malware policies need to strike a balance between network security and organizational performance. Controls cannot be so restrictive that they get in the way of systems being efficient and workers doing their jobs. Testing with the right tools can help companies identify and strengthen weak points which, in turn, should help them avoid implementing overly restrictive policies for staff.\nWhat's the right methodology for testing? A proven testing method is PASS, which stands for four interdependent variables: performance, availability, security and scalability. This method is based on the fundamental IT principle that there needs to be reasonable trade-offs between these variables. Malware prevention also follows this dynamic, where IT protection requirements cannot be so strict as to prevent access to the very systems that keep the business running.\nGood PASS testing covers the following: Performance testing can help you understand the metrics, such as response time of the infrastructure while under attack. Availability tests can focus on checking if your systems properly fail close or fail open during key events. Security tests can include checks around currency of your malware database and potentially uncover holes because of slow updates. Finally, scalability tests can ascertain how many users the system can handle before, during and after an attack.\nBest Practices To Perform Testing\nCompanies should review how critical security devices such as gateways, firewalls, and IDS respond to realistic and scaled attacks and traffic. Testing should ideally be conducted while authentic traffic is going through the network to see how different components respond under stress.\nSystems such as DPI look much more closely into any traffic passing through the network to enforce policies driven by security concerns. For instance, an IT organization might want to understand if customers or employees are using Skype for instant messaging, voice calls or file transfers. DPI systems will not be fully tested unless they are put under real malware payloads. It's essential for the testing tool to emulate traffic from malware-infected systems in addition to perimeter defense and to be able to do this at scale. For example, malware testing should be done with both secure and insecure traffic, and testing services must also have an updated library of the latest malware signatures.\nA PASS methodology can answer multiple questions regarding malware readiness including: What is the impact on user QoS (quality of service) in terms of latency? When devices enter fail open or close states do related services also go down? How many pieces of malware can current systems detect? How many users can be supported while under attack?\nThe best security system testing requires that you send through a wide range of malware-based attacks during periods of realistic simulated network traffic. Companies that proactively choose the right test equipment and do aggressive testing will be able to stop and manage the effects of complex malware attacks."", 'Webapp Pentest Methodology\nOur web application penetration test service utilizes a risk-based approach to manually identify critical application-centric security flaws in all in-scope applications. Our web application penetration test combines the results from industry-leading scanning tools with manual testing to enumerate and validate vulnerabilities, configuration errors, and business logic flaws. In-depth manual application testing enables us to find what scanners often miss.\nUsing this approach, we ensure a comprehensive webapp pentest that covers the classes of vulnerabilities outlined in the Open Web Application Security Project (OWASP) Top 10 and beyond:\nSensitive Data Exposure\nXML External Entities (XXE)\nBroken Access Control\nUsing Components with Known Vulnerabilities\nInsufficient Logging & Monitoring\nOur web app penetration testing methodology is a consistent process based on industry-standard practices used for each and every internal and external web application penetration test we perform. Experience has shown our clients and us that our proven web application pentesting methodology works.\nThe information-gathering phase consists of Google search engine reconnaissance, server fingerprinting, application enumeration, and more. Information gathering efforts result in a compiled list of metadata and raw output to obtain as much information about the application’s makeup as possible. Reconnaissance includes web application footprinting, metafile leakage review, service enumeration, and operating system and application fingerprinting. The purpose of this step is to map the in-scope application and prepare for threat identification collectively.\nDuring the Information Gathering phase, our penetration test team will:\nUse discovery tools to passively uncover information about the application\nIdentify entry points into the application, such as administration portals or backdoors\nPerform application fingerprinting to identify the underlying development language and components\nSend fuzzing requests to be used in the analysis of error codes that may disclose valuable information that could be used to launch a more targeted cyber attack\nActively scan for open services and develop a test plan for the latter phases in the security assessment\nThrough testing, Hedgehog Security’s penetration test team actively try to force your web apps to leak information, disclose error messages that can be exploited, or reveal versions and technologies used.\nWith the information collected from the previous step, the testing process transitions to identifying security issues in the application. This typically begins with automated scans initially but quickly morphs into multiple manual testing techniques using more pointed and direct tools. During the threat modeling step, assets are identified and categorized into threat categories. These may involve sensitive information, trade secrets, financial documents, etc.\nDuring this phase, our pentest team will:\nUse open source, commercial, and internally developed tools to identify and confirm well-known vulnerabilities.\nSpider the in-scope application(s) to effectively build a map of each of the features, components, and areas of interest\nUse discovered sections, features, and capabilities to establish threat categories to be used for more manual/rigorous testing (i.e., file uploads, admin backdoors, web services, editors)\nSend fuzzing requests to be used to analyze error codes that may disclose valuable information that could be used to launch a more targeted attack.\nBuild the application’s threat model using the information gathered in this and the previous phase to be used as a plan of attack for later phases of the penetration test\nUpload vulnerability information to the customer portal for those vulnerabilities that exist but will not be exploited due to time constraints or risk to devices.\nThe vulnerability analysis step involves documenting and analyzing vulnerabilities discovered due to Information Gathering and Threat Modeling. This includes the analysis of output from the various security tools and manual testing techniques.\nDuring the Vulnerability Analysis phase, our penetration testers will:\nCompile the list of areas of interest and develop a plan for exploitation\nSearch and gather known exploits from various sources\nAnalyze the impact and likelihood for each potentially exploitable vulnerability\nSelect the best methods and tools for properly exploiting each of the suspected exploitable vulnerabilities\nUnlike a vulnerability assessment (which is a low cost commodity service and only ever uses automated vulnerability scanning tools), a penetration test takes the additional step of exploitation. Exploitation involves establishing access to the application or connected components by bypassing security controls and exploiting vulnerabilities to determine their real-world risk. Throughout this step, we perform several manual tests simulating real-world exploits incapable of being performed through automated means. During a webapp pentest , the exploitation phase consists of heavy manual testing tactics and is often the most time-intensive phase.\nAs part of the Exploitation phase, the Hedgehog Security team will:\nAttempt to manually exploit the vulnerabilities identified in the previous phases to determine the level of risk and level of exploitation possible\nCapture and log evidence to provide proof of exploitation (images, screenshots, configs, etc.)\nNotify the client of any Critical findings upon discovery\nUpload validated exploits and their corresponding evidence/information to the project portal for client review\nThe reporting step is intended to compile, document, and risk rate findings and generate a clear and actionable report, complete with evidence, for the project stakeholders. The report will be delivered through the customer portal. If a customer requests, a presentation of findings will occur via an online meeting.\nDuring this phase, our pentest team will perform the following:\nEnsure all findings have been uploaded to the project portal for client review\nCreate the web application penetration test report, along with evidence. This will go through an internal review process that then is uploaded to the client portal for review\nAdditional meetings may take place to ensure the client understands the findings and recommendations for mitigation or remediation']"	['<urn:uuid:9811c8af-08d8-47d0-a3ae-f16c457bf6ba>', '<urn:uuid:c573fa61-b13e-4f17-ba08-46b84a9ec332>']	factoid	direct	short-search-query	similar-to-document	comparison	novice	2025-05-12T15:09:02.012753	8	41	1704
78	candles holiday decorating toxic effects	Holiday candles serve decorative and traditional purposes but have important health implications. Traditional paraffin candles, commonly used in holiday decorations, produce carcinogens and soot when burned. Scented holiday candles are particularly problematic as they often contain synthetic chemical fragrances that convert into toxins like acetone, benzene, and toluene when burned. Some imported candles contain lead wicks that release toxic particles. However, there are eco-friendly alternatives available - beeswax or soy-based candles burn cleanly and can be scented with essential oils, making them safer choices for holiday decorating.	"[""Enriching Your Holidays\nIt’s time for holiday celebrations, and that means it’s time for holiday decorations. Tables, mantels, ledges—virtually any smooth surface becomes a stage for festive arrangements featuring symbols of the holiday: nativity scenes; plump little Santas, reindeer, and sleds; a dreidel collection and menorah; a Kwanzaa altar with a mat, cup, and ears of corn. A lovely centerpiece becomes a focal point on the dining table, while garlands and wreaths offer natural beauty nearby. Inside and out, homes beckon with welcoming lights. Whatever your holiday, it’s easy to be eco-friendly this year when you decorate.\nDécor. Can the Plastic. For the past 50 years, many Christmas decorations have been made of nonbiodegradable plastics, but these days—especially with the ease of online searches—it’s not difficult to locate decorative holiday items for purchase made of wood, or recycled glass or metal. Recycled Christmas tree ornaments are becoming more popular every year; even First Lady Michelle Obama uses them, on the White House Christmas tree. If you’d like, you can create your own recycled decorations, or make them out of natural materials. If you need ideas, there are hundreds of books and websites devoted to recycled Christmas crafts.\nMany decorative items for Hanukkah are also made of synthetics (all those plastic dreidels! Oy!), but eco-friendly wooden options are on the rise, in a circling back to traditional practices. Artisans also make recycled metal dreidels and menorahs of recyled glass, metal, and steel pipe—even bicycle chains. Most are beautiful, many are available on the web, and all are fascinating and functional.\nKwanzaa also offers opportunities for using recycled materials, such as in the woven mat, unity cup, or kinara. There are plenty of books and websites with eco-friendly craft suggestions for this newest of the seasonal holidays. Just start your search engine and type in key words!\nEnlist Mother Nature. Even in winter, when most plants are dormant, nature offers items perfect for holiday decorating. Evergreen sprays can be arranged decoratively in centerpiece bowls featuring nuts and fruits such as pears, apples, and pomegranates. Pinecones may be gathered, destined to become rustic placecard holders (cut a slit into each pinecone, slipping a card into it) or part of a Christmas display—for example, a mix of pinecones, ornaments, berries, and holly. Christmas celebrants can gather to work on a garland of cranberries, popcorn, bay leaves, and dried apricots or other similarly sized dried fruit. The completed garlands can be draped atop mantels, around chandeliers, inside windows, or along interior door frames.\nMother Nature also provided the cotton, linen, and wool in outgrown or worn-out clothing; Christmas stockings are easy and fun to make with such fabrics. Just cut out a pattern, sew the edges right sides together (except for the top of course), turn inside out, and decorate. Don't forget to add a loop for hanging your unique eco-friendly Christmas stocking! Likewise, used natural-fiber fabrics can be recyled to make placemats for Kwanzaa, or a festive table runner upon which Hanukkah items can be arranged.\nLights. Outdoor holiday lighting adds cheer to those frigid, bleak winter evenings when darkness descends by late afternoon. Buying energy-efficient light-emitting diode (LED) lights to replace those inefficient incandescent ones is a sound investment. LED holiday lights stay cool to the touch, use less energy, and come in a wide array of colors and designs. (Come to the Garden’s Wonderland Express exhibition to see 750,000 of them!) A helpful suggestion for recycling your old holiday lights may be found here.\nOn a much smaller scale, if you want to lessen your carbon footprint by not burning paraffin candles during the Festival of Lights, you can find a variety of electric menorahs that use LED lights these days. The same lights may fit into the new electric kinaras available for Kwanzaa.\nCandles. Most families celebrating the holidays do burn candles, as they play a significant role in the traditions of Hanukkah and Kwanzaa, and are featured prominently in Christmas as well. Unfortunately, many of the candles sold specifically for menorahs and kinaras, as well as general decorative holiday candles, are made from nonrenewable petroleum products, primarily paraffin. When paraffin wax is burned, it produces carcinogens and soot. Some of the worst offenders are scented candles, whose aromas often come from petroleum-based synthetic oils mixed into paraffin wax. Fortunately, there are plenty of toxin-free beeswax or soy-based candles for the holidays that burn cleanly, some scented with essential oils. Your main challenge will be choosing from among hundreds of candle makers selling their eco-friendly products on the web; click here to visit just one of them.\nSo…as you ponder unpacking those dusty boxes of old, energy-inefficient, nonbiodegradable holiday decorations and lights, consider leaving their tops on and moving into a new, greener place this holiday: your own house. With natural or recycled decorations, LED lights, and eco-friendly candles, your home will capture the magic of the season while honoring the awesome beauty—and fragility—of nature."", 'This might surprise you: it’s very likely that the indoor air in your home is more polluted than the air outside! There are many factors, most of which are totally within your control. Some factors present a serious health hazard for your cat! Read on to find out more\nAir fresheners have become ever more varied and more popular over the years. Indeed, the number of sprays, plug-ins, scented candles, and other fragrance delivery systems has exploded; up to 75% of American households use them.\nBut very little attention has been given to their potential downside: toxic chemicals spewing into the air of your home. No wonder experts are saying that indoor air pollution may be worse than the good old smog outside!\nHow Stuff Works explains:\nAccording to the U.S. Environmental Protection Agency (EPA), most store-bought air fresheners consist of formaldehyde, petrochemicals, p-dichlorobenzene (active ingredient in mothballs) and aerosol pollutants (source: EPA). The agency’s “Indoor Guide to Air Quality” also notes that air fresheners “release pollutants more or less continuously” (source: EPA).\nThe University of California at Berkeley performed a study on air fresheners and household cleaners in 2006 that discovered ethylene-based glycol ethers, classified by the EPA as hazardous air pollutants. It also found the presence of terpenes, which are chemicals often derived from citrus oils that are not inherently dangerous, but react with ozone [a common air pollutant] to form formaldehyde.\nScented candles aren’t much better: most of them contain synthetic chemical fragrances. When burned, these chemicals convert into toxins such as acetone (an ingredient in nail polish remover and paint thinner), benezene, toluene, particulate matter and soot.\nEven unscented paraffin wax candles are as just dangerous as second-hand smoke. Burning paraffin releases carcinogenic benzene and toluene. The soot from paraffin candles contains many of the same toxins found in diesel fuel. Yuck!\nMany imported candles contain lead in their wicks. Lead is a highly toxic heavy metal; and once it’s in your body, it stays there forever. When one of these candles is burned, lead particles are released into the air, where they can accumulate from 2-9 times more than the limit advised by the FDA. Scented candles are more frequently affected. You can sometimes tell lead-containing wicks by the way they hold their shape when they’re bent, or you may be able to see a tiny filament of lead in the center.\nSmoke, whether from a fireplace or wood-burning stove, cigarettes, marijuana, or vaping, is dangerous for your cat. Be sure ventilation is adequate for the situation. For smokers of all kinds, go outside. Not in another room, not in a remote corner: outside, especially for cigarettes. Cigarette smoke contains carcinogens, heavy metals, arsenic, and cyanide. Sticky, highly toxic particulates, like nicotine, can cling to walls and ceilings. Gases get absorbed into carpets, drapes, and upholstery: things that tend to be very close to your cat’s nose! And even if you are going outside to smoke, you’re still bringing in “third-hand smoke” in the form of particulates that cling to your clothes: particulates that can be toxic to your cat directly, or because those particles and gases can react with indoor pollutants to create an even more toxic mix.\nSome incense is dangerous. While the essential oils used to impart the fragrance are probably okay, smoke from the resin can be as bad or worse than cigarette smoke.\nTeflon cookware is a toxic hazard. When heated, non-stick coatings give off toxic gases. They can easily kill a bird (canary, parakeet, and even bigger birds), so you have to wonder what they’re doing to you and your furry friends over time!\nWhile the limited use of aromatherapy (never apply directly to the animal, and always provide an escape route), or burning a stick of incense, won’t do significant harm, Little Big Cat recommends avoiding products that release strong fragrances (or lead!) into the air. Use an aromatherapy diffuser instead.\nBe courteous to your pet! While a hint of lavender may be relaxing to humans, there’s no guarantee that it will have a similar effect on our pets. Some odors that humans find delicious are quite annoying to cats; citrus and pine are both highly irritating, and even poisonous in high doses.\nA cat’s sense of smell is about 40 times better than a human’s; a dog’s is up to 200 times more sensitive (depending on breed). Both cats and dogs (as well as many other animals) have a special sensory organ called “Jacobson’s organ” or the vomeronasal organ. This consists of a pair of pits in the roof of the animal’s mouth that connect directly to the nasal passages. By drawing air into its mouth, the animal passes a scent over this organ in order to fully analyze it. This produces a grimace-like expression called the “Flehmen response.”\nThe bottom line is that both dogs and cats are very sensitive to odors. Air fresheners and other fragrances can be very irritating to an animal. To a pet, these artificial scents must be like living with your roommate’s stereo turned up full blast, 24/7; especially if you don’t like their taste in music! The problem is compounded when several scent products are used throughout the house, leaving nowhere for the pet to go to get away from them.\nIf you have an odor problem, there are many non-toxic solutions. Many litter deodorizing sprays work on other odors too. X-O, for example, took care of a friend’s carpet when her cat broke a whole bottle of perfume! Dr. Nick Dodman recommends “Zero Odor,” available online or at Bed, Bath and Beyond; and I love it, too. It has a slightly bleachy smell when you spray it, but leaves no lingering scent and is completely safe around kids and pets. It works on everything: kitty litter, trash cans, diaper pails–even skunk spray! (But don’t spray it directly on your or your pet’s skin or fur.)']"	['<urn:uuid:d4f3c191-0f10-444c-9178-a583db366e1e>', '<urn:uuid:6b96ebfb-f59c-47c8-8fb4-18e60483414a>']	open-ended	direct	short-search-query	similar-to-document	multi-aspect	novice	2025-05-12T15:09:02.012753	5	87	1810
79	home window maintenance tips prevent damage save heating cooling costs	To prevent window damage and reduce heating/cooling costs, several maintenance steps are important. Windows account for 25-30% of residential heating and cooling energy use. Check for leaks by moving tissue paper around windows - movement indicates gaps needing caulking between sashes, frames and walls. Monitor condensation, which can damage components and cause wood rot. Maintain indoor humidity at 30-40% during heating season - levels over 40% in cold weather cause moisture problems. For storm windows, ensure breathing holes aren't plugged to prevent trapped moisture. Consider window replacement with ENERGY STAR rated products, evaluating frame types, glazing, gas fills and spacers. Quality windows shouldn't have excessive condensation at normal humidity levels. Proper insulation and ventilation, including attic ventilation, helps prevent moisture-related window damage since warm moist air can travel through ceilings and condense on cold surfaces.	"[""Quick fixes and larger projects to make your home more energy efficient\nIf your utility bill reflects a higher-than-average energy consumption, your appliances are likely running on overtime due to a lack of energy efficiency within your home.\nDon't despair! To help solve some of the most common issues, here are some quick-fix projects that you can accomplish on your own, as well as some larger home upgrades that can make a huge impact. These changes could lower your energy bills in the near term--and make your home more valuable in the long run.\nHere are the top four home energy efficiency issues that can be addressed with both a quick fix and a long-term solution.\nWhat to do…\n…If you’re constantly cranking your thermostat\nQuick fix: Seal your windows\nEven small gaps can waste a significant amount of energy. Test for leaks by moving a piece of tissue paper around your window. If you see movement, there’s a leak. Heat loss occurs through gaps between sashes and frames, so you’ll want to caulk around these areas, mainly around the exterior. For the best adhesion, you’ll want to clean all areas first, removing any old caulk and paint. Then apply caulk to all joints in a window frame and the joint between the frame and the wall. If possible, caulk in one continuous motion.\nLong-term solution: Replace your windows\nWindows play a big part in your overall energy use accounting for 25-30% of residential heating and cooling energy use.1 You’ll want to discuss with your window retailer and installer whether you’ll be able to replace your windows in their existing frame. Then you’ll need to decide on features—frame types, glazing type, gas fills and spacers and operation types. When selecting the windows themselves, you’ll want to keep energy use in mind and look for the ENERGY STAR® label, as well as review ratings on the energy performance label for the National Fenestration Rating Council (NFRC).\nWhat to do…\n…If your electricity and gas bills are consistently over the local average\nQuick fix: Unplug—ensure that you’re not outputting excess energy\nDo you use space heaters in the winter? Leave your appliances plugged in at all times, or leave your phone on the charger all night? All of these things eat away energy. If you use power strips, you’ll be able to turn off multiple devices with just the flip of a switch. When charging your phone, don’t leave it siting on the charger all night, and once it’s charged, don’t just detach your phone—unplug the charger as well. As for space heaters, you’ll want to ensure it’s safe and energy efficient. Which brings us to our long-term solution…\nLong-term solution: Insulate to your attic\nIf you find you’re cranking up your thermostat or plugging in space heaters, some insulation could help with your home’s heating and cooling costs. Take a peak in your attic. If the insulation is level with your floor joists, you could benefit from additional insulation. There are a lot of factors that can cause the cost of this project to fluctuate—the type of insulation you choose, the size of your attic, whether you need to seal fixtures, whether you have mold that needs to be treated and removed or whether you have junction boxes or cables that will require an electrician to safely insulate around those areas.\nWhat to do…\n…If a strategic plan needs to be in place when both your clothes and dishes need to be washed\nQuick fix: Consider your laundry and kitchen appliance approach\nWash your clothes in cool water when possible. Approximately 90% of the energy used by your washer is used to heat the water.2 So, for loads that don’t require hot water, you don’t need to expend all that extra energy to heat water. And it’s gentler on your clothes! You’ll also want to try to wash only full (but not packed-to-the brim!) loads of laundry in order for your machine to operate at peak efficiency. Once you’ve found the Goldilocks of dirty clothes, you can do the same for your fridge and dishwasher—both of which run most efficiently when full but not overstuffed.\nLong-term solution: Replace your old, energy-bleeding appliances\nIs your refrigerator over 10-years old? Do you have a top-loading laundry machine? Consider updating your appliances to newer models that expend significantly less energy and can help cut down your monthly utility costs. Look for ENERGY STAR®products, as they meet the energy-efficient specifications set by the EPA and use 10-50% less energy than standard appliances.3\nWhat to do…\n…If you’re last, better shower fast—you have hot water battles in your household\nQuick fix: Install low-flow showerheads and faucet aerators\nStandard showerheads use approximately 2.5 gallons of water per minute (GPM), while water-saving showerheads use no more than 2 GPM. So in just a 10-minute shower, you could save 5 gallons of water.4 To reduce further water usage, you can install a low-flow aerator to your kitchen faucet. Both of these fixes not only save water but can also save your furnace from heating excess water. And if a new showerhead isn’t going to cut it…\nLong-term solution: Full bathroom and/or kitchen renovation\nIf you’re looking for some aesthetic changes as well, this is the perfect time to ensure your upgrades are going to conserve your resources. You’ll be able to select the most up-to-date and energy efficient appliances and make structural fixes along the way. For instance, you can check for water intrusion and condensation to improve your home’s indoor air quality by eliminating mold-friendly moisture. Or you can add HVAC ducts to parts of your home that are heated and cooled. This will ensure your heating and cooling systems are working efficiently, ultimately cutting your month-to-month utility bills.\nWhether you’re looking to make some small tweaks or major changes, there are so many ways to make your home more energy efficient and cut down costs. Be green—save green.\n Energy.gov, Update or Replace Windows\n Treehugger, 11 ways to green your laundry\n Energystar.gov, How a Product Earns the ENERGY STAR Label\n EPA.gov, Showerheads"", 'The word ""moisture"" refers to water vapor mixed with air.\nMost of the moisture generated in the home is dissipated by the movement of moisture-laden\nair out of the home. As homes become more energy-efficient, the number\nof paths of escape are reduced, and dealing with moisture becomes more\nDuring the heating season, the indoor humidity level should\nhover around 30 percent to 40 percent. When indoor humidity exceeds 40\npercent during cold weather, moisture problems begin to appear. One symptom\nof a high humidity level is condensation forming on cold surfaces.\nlevels of humidity are often the result of too much moisture vapor generated\nHEATING AND VENTILATION magazine provides builders with reference data on sources of water vapor. For instance, cooking for a family of four adds 4.5 pounds of moisture a day to a house. Each shower contributes half a pound; a weekly laundry, 30 pounds; human occupancy contributes 6 to 3 pounds per day; dish washing 1.2 pounds, etc.\nSo you see that the modern living of a family of four can easily release 150 pounds, or more than 18 gallons of water per week into the air in your home!\nAll of this moisture MUST eventually escape from your home.\nCondensation will occur whenever\nthe window surface is cool enough to allow moisture in the air to condense\non it, which is why some condensation can be expected in the winter - condensation should be controlled as much as possible since it can damage the window\'s components, cause the wood to rot and saturate the wall insulation reducing its effectiveness.\n(An example of condensation: A glass of ice water sweats because the warm air that surrounds the glass meets the cold surface and causes....you guessed it, Condensation)\nMoisture on the inside of the storm window (or outside pane).\nIndicates that the prime window is allowing air and moisture to leak\nout to the storm window where it condenses. Stopping these air leaks with\ncaulk and weather stripping will stop the condensation and ultimately save\nyour window. It is also important to understand that too little humidity\nis bad for your house. Manufacturers claiming that low humidity (15 percent)\nis best for windows may be covering for a poor quality product. Good windows\nshould not have excessive condensation at normal humidity levels (30 percent\nto 40 percent).\nMoisture on the inside of a window pane:\nThis is a sign that airborne water is trapped in the house due to poor\nair circulation and exchange.\nMoisture between single pane windows and exterior storms:\nStorm window frames are made with a breathing hole that permits condensation\nto escape. These breathing holes often become plugged or puttied shut over\ntime. When this happens, moist air becomes trapped and condensation appears.\nTo fix the problem, unplug the holes.\nSteps to Reduce Excessive Humidity:\nRecognize that the best way to stop condensation is to reduce the moisture\nin the inside air. Here are a few tips:\nVent gas burners and clothes dryers to the outside. Dryer and kitchen range exhaust fans should never be vented to the attic.\nInstall exhaust fans in the kitchen, bathrooms, and laundry rooms.\nControlling or covering other sources of humidity (radiator water pans, fish tanks, large numbers of plants, etc.).\nInstalling a dehumidifier.\nOpening fireplace damper.\nVentilating the crawl space or basement: Install foundation vents or leave a basement window cracked in the fall or early winter to ventilate your basement or crawlspace.\nAnother positive measure is to connect a small duct from the outdoors\nto the return side of a forced-air heating system, so that fresh air is\ndrawn into the house whenever the system is operating. A damper placed\nin this duct will allow the home owner to control incoming air.\nA simpler method is to simply crack a window somewhere in the home.\nVentilating the attic: Because of vapor pressure, the moist warm air from your home can go right through your ceiling into your attic. If your attic is not ventilated, the humid air will condense on the cold underside of your roof. This condensation can start to rot the roof boards, cause ice dams, or drip down onto the ceiling below and damage your plaster, paint, and attic insulation.\nWall Insulation: To prevent or reduce condensation problems inside your walls and protect your insulation, the side of the insulation\nexposed to high vapor pressure (warm side in winter) must be covered with\nmaterial that will impede the natural drive of moisture to flow through\nthe inside surfaces of exterior walls, toward the lower vapor pressure\noutside. To be effective, such a material must have a high resistance to\nmoisture flow. The material is usually called ""vapor retarder.""\nMore on this subject in the Home Insulation section.']"	['<urn:uuid:11f22654-3579-47ff-8324-78f8d41232e1>', '<urn:uuid:0d0669ae-ed1f-4e40-984e-de79ecd76ebc>']	open-ended	direct	long-search-query	distant-from-document	three-doc	novice	2025-05-12T15:09:02.012753	10	135	1808
80	I'm studying decentralized approaches to climate adaptation. What advantages does a decentralized model of policy innovation offer for climate change adaptation?	A decentralized model offers several key benefits. Experiments in climate adaptation arise from operational levels and spread horizontally through communities of practice, with local adaptation rather than comprehensive adoption. This creates beneficial redundancy and flexibility when facing anomalous conditions. Like biodiversity in nature, this 'innovation dividend' provides a reserve of creative potential that enhances resilience to future shocks. While the model prioritizes diversity over efficiency, it can actually enhance allocative efficiency in cases involving common resources like water, because decision-making authority is positioned where participants can best assess costs and benefits.	['by Judith Curry\nThis post discusses Workshop presentations on methodologies and application examples of decision analytical strategies to support robust decision making on climate adaptation.\nThis post is a follow-on to the two previous posts:\n- UK-US Workshop on Climate Science to Support Robust Adaptation Decisions\n- UK-US Workshop Part II: Perspectives from the private sector on climate adaptation\nPerspective from the Grantham Institute\nSimon Buckle and Emily Critchley of the Grantham Institute for Climate Change have written an overview article on the Workshop for Imperial College- London’s blog entitled Climate science to support resilience. Excerpts:\nThe Workshop was an important opportunity to illustrate and discuss the diversity of methods already available that could supplement the insights gleaned from climate models and help inform robust decision making in the face of climate variability and change, whether by business, government or international organisations. These additional tools included, but were not limited to, formal methods of robust decision making, scenarios that capture a wider range of drivers beyond just greenhouse gas emissions, more effective exploitation of historical empirical data about climate variability globally and in specific regions, and the smarter use of climate models of all types to identify what can be said robustly on shorter (decadal) timescales and what cannot.\nCommenting on the workshop, Dr Yvan Biot, Senior Scientist at the UK Department for International Development, said that, “the future doesn’t just happen – it is for us to create. The techniques I have learnt in this Workshop will help us select those activities that are most likely to create a better and more secure future for poor people in developing countries.”\nThe provision of these “climate services” to inform the way that decision makers think about risk is likely to become increasingly important in coming decades. Discussion at the Workshop touched on the ethical dimensions and high professional standards required for the success of this emerging profession. The Workshop concluded that consideration should be given to developing a code of professional standards for practitioners, notably in terms of transparency, objectivity and full disclosure of data, assumptions and methods as well as an obligation to make available forecasts and projections on timescales that allowed those affected by risks to take action in time to mitigate their potential impact, which does not always happen at present.\nRobust decision making for climate adaptation\nBelow is a summary of 4 Workshop presentations on this topic:\nRobert Lempert – Rand Corporation: Information needs for developing robust adaptive strategies\nLempert laid out the challenge in this way. Climate-related decisions involve incomplete information from new, fast-moving, and sometimes irreducibly uncertain science; many different interests and values; long time scales; near certainty of surprise. How can we make plans more robust and adaptable while preserving public accountability? Supply and demand of scientific information may be mismatched. Decision support bridges supply and demand with a focus on decision processes.\nTraditional approach to risk management works well well when the future isn’t changing fast, isn’t hard to predict, doesn’t generate much disagreement. Predict then act methods can backfire in deeply uncertain conditions: uncertainties are underestimated, competing analyses can contribute to gridlock, and misplaced concreteness can blind decision makers to surprise. Believing forecasts of the unpredictable can contribute to bad decisions. Deep uncertainty occurs when the parties do not know or do not agree on the likelihood of alternative futures or how actions are related to consequences.\nRobust decision making manages deep uncertainty by running the analysis backwards: start with a proposed strategy, use multiple model runs to identify conditions that best distinguish futures where strategy does and does not meet its goals, identify steps that can be taken so strategy may succeed over wider ranges of futures. Stakeholders debate about how much robustness they can afford – which is more useful than debating what the future will be. Tradeoff curves help decision makers choose robust strategies. RDM creates demand for decision support methods and tools for managing and summarizing large and diverse sets of information in a decision-relevant context. See the presentation for detailed analysis of several case study applications.\nAdapting to climatic change (for example, in the design of coastal infrastructure) poses nontrivial conceptual challenges. Relevant examples include (i) the deep uncertainty surrounding projections of the coupled natural and human systems, (ii) the diversity of priors and value judgments across stakeholders and decision makers, and (iii) the choice of appropriate decision-analytical frameworks.\nClimate change adaptation imposes multi-objective trade-offs under dynamic and deep uncertainty. Current adaptation analyses often neglect: known unknowns – leading to overconfidence; endogenous dynamics of imperfect learning; and relevant decision criteria. Inverse decision analysis combined with mission-oriented basic science can help overcome these problems. Uncertain parameters interact in nonlinear ways. One at a time sensitivity analyses can miss important nonlinear interaction effects.\nPulwarty asks the questions: Adapting to what? What are strategies for appraising and evaluating climate adaptation plans? He emphasized the weather-to-climate continuum and the existing adaptation deficits. Climate change adaptation is so difficult because of the cumulative nature of hazards, extremes and disasters; difficulty of proactive decision making and taking advantage of learning and policy windows; and the challenges of information services to support adaptation in changing environments.\nThe following lessons have been identified (if not necessarily learned):\n- Acknowledge the cross-scale of climate, of early warning and adaptation response\n- Disciplinary challenges shape problem definitions, scenarios, and recommendations (e.g. primary consideration being climate model impacts versus vulnerability assessment)\n- Communication is critical but not sufficient. Need to understand the socialization of lessons learned by particular individuals and organizations through their own, direct brian and error experiences.\n- Rules for gathering, storing, communicating information are essential elements of operating procedures\nCriteria for robustness need re-evaluation. Understand adaptation as being driven by crises, learning and redesign – role of “surprises” in shaping responses. Generate risk profiles and a portfolio of measures-and broader economic, social and environmental benefits. Approach climate model output far more critically than at present, especially for impact assessment and scenario development at the local level. Develop information systems for critical thresholds across climate time and space scales.\nKey issues re improving the linkages between information and decision making: quality and pedigree of information available to decision makers at all levels; factors influencing whether or not such information will be used; factors influencing whether risk communications are trusted; prototyping strategies and practices for adapting the decision making systems to the different levels of decision makers.\nApplications to U.S. drought and water resource adaptation are discussed.\nIn a decentralized model of policy innovation, experiments in climate change adaptation arise from the operational levels of a system; from cohorts of practitioners or inventive individuals. In this model, innovations spread horizontally via communities of practice, with local adaptation rather than comprehensive adoption. This creates the potential for redundancy, and along with it, flexibility in the face of anomalous conditions. Like biodiversity in the natural world, this “innovation dividend” is a reserve of creative potential that enhances resilience in the face of future shocks. Diversity rather than efficiency is a goal value in the decentralized model, and yet it has been observed, particularly in cases concerning common good resources such as water, that allocative efficiency is enhanced. This can be explained by the fact that decision-making authority is set where the participants are optimally positioned to assess costs and benefits. This presentation will use this perspective to explore the ways in which the benefits of subsidiarity are being realized in the otherwise highly centralized Murray-Darling Basin Authority, which manages the arid river system formed from Australia’s three longest rivers.\nJC reflections: This series of presentations was in many ways the lynch pin of the Workshop. Robust decision making strategies are the critical link between the supply of climate information and the demand from decision makers to support climate adaptation policies.\nAll of the talks recognize the existence of substantial uncertainty, and the lack of utility of the traditional ‘predict then act’ model for decision making. Robust decision making provides a framework for making decisions under deep uncertainty, where the disagreement is deflected away from arguments about likely futures to the amount of resilience that can be afforded.\nThe need for a broader range of climate information than the global climate models was clearly identified in the first three talks, and Keller refers to the need for mission-oriented climate information. This highlights the point that I made in Part I, where ‘mitigation science’ (e.g. sensitivity, attribution) is not the same kind of climate information need to support climate adaptation. Exactly how to approach mission-oriented climate science to support adaptation decisions is discussed in some of the other presentations that will be discussed in future posts.']	['<urn:uuid:2c18151e-0ab6-4b63-9ebf-4e7d25b581e0>']	open-ended	with-premise	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-12T15:09:02.012753	21	91	1446
81	photo straighten tilt effects limitations	When straightening or tilting an image, there is a significant loss of pixels. A straightening angle of about 5-10 degrees should be the maximum. As the angle increases, more pixels are lost. Additionally, one might end up misplacing or losing some elements that complement the picture.	['Cropping is one of the first steps in most post-processing workflows. In fact, most photographers apply some level of cropping to their images while editing. Reasons to crop an image go way beyond just getting closer to the subject. It could be for image stacking, panorama, straightening, or changing the aspect ratio of the photograph. In this article, I will take you through all the options that Photoshop offers with respect to cropping.\nBefore I guide you through the steps to crop an image using Photoshop, there are a few points that are worth pointing out:\n- Cropping too much into an image will compromise the overall image quality due to loss of resolution. As a general guideline, it is better not to crop more than 50% of the image.\n- It is always best to check the horizons or the alignment of the subject in an image. A straightening angle of about 5-10 degrees should be the maximum. As the angle increases, so does the loss of pixels. In addition to losing pixels, one might end up misplacing or in worst cases, losing some of the elements that complement the picture.\n- When shooting stacked images hand-held, it is always best to shoot a bit wider due to potential changes in the alignment of images in post-processing software. Aligning and straightening images afterward might affect the composition.\nTable of Contents\nCrop Tool in Photoshop\nThe crop tool in Photoshop’s toolbar (marked red in the illustrative picture below) can be used to crop an image. The crop toolbox appears (marked orange) after the crop tool is engaged. Clicking on the image area with the crop tool selected brings gridlines to the image.\nClicking on the resize holders (marked green) and dragging outside the image zooms out the crop. When one tries to zoom out of the actual image size, the background layer adds to the image area. In most cases, the background is transparent. So when the image is saved as a JPG, it becomes white and when saved as a PNG, it stays transparent. On the other hand, dragging it into the image zooms into the crop.\nThe mouse pointer turns into a curved double-headed arrow when it is moved to the dark grey workspace area outside the image. Drag the curved double-headed arrow to rotate the image (marked in green boxes):\nSimply put, the Aspect Ratio is the ratio between the width and the height of an image. For example, if the aspect ratio of an image is 16:9 it means that the longer side is 1.77 (16/9) times longer than the shorter one. Most cameras since the days of 35mm film have a native 3:2 aspect ratio whereas most video formats including some monitors, TVs, and cinema screens have a 16:9 aspect ratio. For more information, check out Nasim’s detailed article on the Aspect Ratio.\nThe aspect ratio can alter the storytelling capacity of an image by a noticeable margin. To understand it, let us compare the two images below. The first one gives a perception of depth. The viewer’s eye is directed bottom-up starting from the lake to the tall mountain in the distance. On the other hand, the image below it gives a wider perception of the scene. Even though the seemingly wide image has more depth in terms of distance from the foreground to the background, it is not conveyed as much as it is in the first one.\nChanging the Aspect Ratio in Photoshop\nThe aspect ratio drop-down menu holds most of the widely used ratios (marked green in the image below). Selecting a ratio will fix it and as a result, that ratio will be maintained immaterial of the position of the mouse while dragging the resize place holder.\nIt can be seen that the corresponding numbers with respect to width (marked red in the image below) and height (marked green in the image below) of the image appear in the text boxes right next to the drop-down. The ratios can be swapped between width and height using the swap button that could be seen in between the width and height text box. Select the W x H x Resolution option to choose a custom aspect ratio. When this option is chosen, you will see a third text box (marked blue) where you can specify numeric values. Further, the units, whether imperial or SI can also be chosen in the drop-down (marked yellow).\nThe clear button can be clicked to remove the aspect ratio and have a free hand crop. In this case, the aspect ratio keeps changing as you drag the resize placeholders.\nTake a look at the image below. It can be clearly seen that the image is tilted to its left. This is a common mistake that quite a lot of us end up making while photographing. It is even more common when we are not using a tripod. A 2-degree tilt can make an image look utterly unprofessional. The cropping tool in Photoshop provides a one-click option to straighten the image.\nFirst, click on the straighten button (marked red in the image below). Then, draw a line by dragging the mouse parallel or on the horizon with respect to which you wish to straighten (marked green).\nYou can see that the image has been straightened accordingly when you release the mouse button. As you can see in the image below, there is a significant loss of pixels when one tries to straighten or tilt an image, as mentioned earlier in the article.\nCrop overlays are merely guidelines that help us compose better and geometric shapes that divide the frame. When the key points of your image like the eye of a subject align with certain intersections of lines, they grab more attention. This is because when you align your frame with reference to geometric proportions, you end up with a geometrically balanced image.\nTo select an overlay, click on the overlay button to get the drop-down menu. The cycle overlay option (marked blue) cycles through the overlays in order of appearance in the menu. Overlays can also be cycled using the keyboard shortcut “O” while the crop tool is selected. Certain overlays like the Golden Spiral are not symmetrical. The orientation can be changed using the cycle orientation option or using the “Shift+O” keyboard shortcut with the crop tool selected.\nEven though there are over half a dozen overlays that help compose images better, most people are aware of only one. Let us take a look at all of them, one-by-one.\nThe Rule of Thirds\nThe Rule of Thirds is pretty much one of the most widely used, and in many cases, widely abused overlays. The Rule of Thirds is also the default overlay in Photoshop. The overlay simply divides the image into nine equal rectangles. The observer’s eyes are drawn more into the image where the lines intersect. In the image below, the eye of the subject is aligned to the top-left intersection to grab the observer’s attention to the eye of the subject.\nRule of Thirds has become so common that most viewers are used to seeing tons of images aligned to the thirds. Sometimes, the Rule of Thirds can create unbalanced results. Even in the example above, I would have liked more negative space on the left. Since the eye is aligned to the left third, I was forced for a tighter frame-filling crop. If you are wondering about the Rule of Thirds and its limitations, we have a few interesting articles at PL that are worth checking out:\nAs a matter of fact, when we use overlays other than the Rule of Thirds, it becomes a rare composition in itself. The diagonal overlay simply has lines running diagonally (45°) from each corner of the frame. To understand when and how to use Diagonals, let us consider the image below:\nThe subjects would have moved more towards the top or to the bottom of the frame, had I aligned the eyes of the birds to the intersection based on the rule of thirds. As seen above, using the diagonals to crop this image aligns the eyes of the birds closer to the intersection. As a result of aligning to the diagonals, one can avoid negative space either above or below the subject. Just like the Rule of Thirds, the points of intersection also grab the user’s attention.\nThe triangles overlay is used predominantly for closer crops, frame-filling shots to be more specific. As can be seen in the picture below, this overlay has one diagonal running across two opposite corners and two vertical (90°) lines bisecting it reaching the other two corners. The central idea remains the same. Subject alignment to the intersections or when aligned to the lines attracts attention.\nThe Golden Ratio\nThe Golden Ratio overlay is similar to the Rule of Thirds with respect to dividing the frame into nine rectangles. The difference is, the length and width of the four corner columns are 1.618 times bigger than the ones in the center as seen in the image below. Also called the Phi ratio, this overlay is used for center-heavy compositions. The Golden Ratio heeds to the Fibonacci series which is found all around us in nature. As you can see in the picture below, the eye of the subject passes through the left vertical line. Even though the subject is center-heavy, it isn’t aligned to the dead center which in most cases makes the image boring. It can also be seen that the highlighted repetitive patterns on the wings fall inside the central rectangle.\nThe Golden Spiral\nThe Golden Spiral is a more artistic implementation of the Golden Ratio (1.618). The picture below looks pleasing even though the subject is around the corner. Arguably, it is because it heeds to the Golden Spiral, or perhaps there is simply a healthy amount of negative space and “breathing room”:\nThe Golden Spiral has been an artistic rule for centuries. Some works of art as famous as the Mona Lisa could have been drawn in accordance with the Golden Spiral. Starting from the arrangements of seeds inside a flower to conch shells to spiral galaxies, spirals are a repetitive form in nature. Each consecutive side of the spiral is approximately 1.618 times bigger as it goes outwards. When the subject is placed towards the innermost spiral, it draws the viewer’s attention.\nOverlays like Triangle and Golden Spiral can have the orientation changed using the “Shift+O” keyboard shortcut or from the Overlay crop tool. The grid overlay is more useful for graphics designers than photographers and hence not covered in this article.\nPerspective Crop Tool\nThe perspective crop tool comes in handy when we need to crop out triangular areas out of an image. As seen in the below image, there is more negative space on the bottom right corner. But when I attempt to crop, I would end up losing the mountains at the top right side, tilting the balance of the image and making it right-heavy.\nThis tool allows us to crop the corners at angles. It then stretches the image into a rectangle. As you can see in the illustration below, the perspective crop tool crops out the bottom right, leaving the mountains and the sky comparably unaltered:\nThe foreground in the resulting image is more enhanced, leaving the mountains on the top right comparably unaltered. However, one needs to be cautious when using the perspective crop. As mentioned earlier, the pixels are stretched respective to the area cropped out to make a rectangular frame. So obviously, there will be a loss of resolution where the stretch is maximum. Care should be taken not to crop too much using the perspective crop, as it can yield distorted images.\nThis article covered most of the frequently used cropping options that Adobe Photoshop provides. It also covered how one overlay does not fit all images. The geometry and balance of the image should dictate which overlay guideline to use rather than trying to fit the composition into the default overlay. If there are any queries or if there is anything you feel that I have left out, please pen it down in the comments section below. I shall update or cover those in my upcoming articles.']	['<urn:uuid:81aac6dc-b5e3-4de8-9391-559330d60aac>']	open-ended	direct	short-search-query	distant-from-document	single-doc	expert	2025-05-12T15:09:02.012753	5	46	2052
82	heat transport methods innovation costs	Modern heat pipes can transfer heat several hundred times faster than solid copper rods, but were historically limited by high construction costs due to requiring separate pipes and interior capillary wicks. Meanwhile, superconductors, which were discovered in 1911, have been mainly used in MRI machines, with wider applications being limited by operating temperature constraints. However, both technologies are seeing improvements - Heat Pipe Technology revolutionized construction methods in the 1980s making heat pipes commercially affordable, while researchers at Brookhaven are working on advancing superconductor technology for broader use in the next 10-15 years.	"['Although superconductivity was discovered in 1911, its major and still best-known application is magnetic resonance imaging (MRI). Yet according to a new research report available from Global Information, Inc., major improvements in technology and applications are expected to bring a renaissance of superconductor technologies over the next 10 to 15 years. At the US Department of Energy\'s Brookhaven National Laboratory, for instance, a discovery in the parent of one high-temperature superconductor could lead to predictive control.\nA team of scientists studying the parent compound of a cuprate (copper-oxide) superconductor has discovered a link between two different statesor phasesof the material. They have written a mathematical theory to describe that relationship. This work will help scientists predict the material\'s behavior under varying conditions. It also may help to explain how it is transformed below a critical temperature into a superconductor that can carry current with minimal loss.\nUltimately, the researchers hope to design copper-oxide materials with practical properties. Examples include superconductors that operate at sufficiently warm temperatures to allow more widespread use in energy-distribution applications. For any material, though, this requires a theoretical understanding of how it works under different conditions. Copper-oxide superconductors have many other states that can compete with superconductivity.\nTo begin to understand these different phases, the team used a technique called spectroscopic image-scanning tunneling microscopy. It allowed them to visualize the electrons in each phase at the atomic level. this technique was developed by J.C. Samus Davis, Director of the Center for Emergent Superconductivity at Brookhaven National Laboratory and the J.D. White Distinguished Professor of Physical Sciences at Cornell University.\nThey found that one state has a periodic modulation of the electronic structuresimilar to a wave with periodic peaks and valleysthat imparts a ""stripe"" pattern over the material\'s crystalline structure (see figure). The other state has variations within every unit cell of the same crystal (i.e., variations in a property of each individual electron). Davis\' technique aids the detection of ""topological defects""swirling vortex-like distortions in the striped component of the electronic structure. Those distortions provide a link from one ordered phase to the other.\nThe topological defects are similar to those observed in liquid-crystal states. This realization led the group\'s theoretical physicists to devise a theory that draws on experience with those materials. (Those physicists are Eun-Ah Kim of Cornell, Michael Lawler of Binghamton University, Subir Sachdev of Harvard University, and Jan Zaanen of Leiden University.) This new theory explains the coexistence of the two cuprate states. It also predicts their interplay at the atomic scale.\nThe theory will foretell how the material behaves in the real world and how that behavior varies as a function of material-specific conditions, such as crystal symmetry. Eventually, the researchers hope to gain information that relates to the mechanism of high-temperature superconductivity.\nThis research was supported by the DOE Office of Science (through the Center for Emergent Superconductivity, an Energy Frontier Research Center), the National Science Foundation, the Japanese Ministry of Science and Education, the Japan Society for the Promotion of Science, and the Netherlands Organization for Scientific Research.', 'Heat Pipe Principle and Applications\nThe Heat Pipe Principle\nHaving first been invented near the turn of the 20th century, the heat pipe is not in itself a new invention. Early heat pipes were constructed out of hollow metal tubes that were sealed at both ends, vacuumed, and charged with a small quantity of evaporative fluid. They contained a ""wick"" to transport the fluid from one end of the heat pipe to the other.\nRelying on the energy absorbed and released from the phase change of the fluid, the hollow heat pipe allowed an extremely fast heat transfer. Heat applied to one end of the pipe would almost instantaneously evaporate the fluid inside. This vapor would then move to the other, colder end of the pipe where it quickly condensed back into a liquid, releasing the heat absorbed during the evaporation.\nRecent Heat Pipe Development\nModern heat pipes are able to transfer heat several hundred times faster than a solid copper rod. However, the applications for heat pipes have been limited in the past due to their construction expense. The requirement for separate pipes and interior capillary wicks has traditionally kept the cost of heat pipes too high for all but the most exotic applications. Additionally, wick materials did not last very long.\nHeat Pipe Technology, Inc., revolutionized the construction of heat pipes in the early 1980\'s and HPT was granted the first of several heat pipe patents in 1986. The methods that were developed brought the cost of the company\'s patented heat pipes down to a commercially affordable level. The patent also disclosed a new and previously undiscovered use for heat pipes, namely, using them to increase the efficiency and dehumidification capability of air conditioning systems.\nThe Discovery of Heat Pipe Dehumidification\nIn 1983, HPT research engineers conceived a method for applying heat pipes to an air conditioning system. A prototype was built, which included a heat pipe arrangement that would later become the company\'s patented dehumidification heat pipe technology. The initial testing indicated that the heat pipe dramatically improved the performance of the cooling coil for dehumidification.\nThis research led to a Technology Utilization contract with NASA. The potential of the technology was also recognized by the Department of Energy\'s (DOE) award in 1991 through a grant for bringing the heat pipe technology to public awareness.\nHeat Pipes for Dehumidification & Energy Recovery\nIn an air conditioning system, the colder the air becomes as it passes over the cooling coil, the more moisture is condensed out. HPT heat-pipes wrap around the cooling coil, with one part of the heat pipe in the return air stream and the other part in the supply air stream. Warm incoming air is precooled by the evaporator (precool) section of the heat pipes. The air is then cooled further (overcooled) by the cooling coil for more moisture extraction. Next, air is passively heated back up by the condenser (reheat) section of the heat pipes to lower the relative humidity. The leaving air from the heat pipe system now has much lower moisture content and lower relative humidity.\nWhile consuming no energy, except for the small static pressure increase, the heat pipe precooling effect allows the cooling coil to operate at a lower temperature, considerably increasing the moisture removal capabilities of the system. With lower humidity, the indoor air becomes more comfortable at higher thermostat settings, resulting in net energy savings.\nHeat pipes are also used to recover energy as heat exchanger between supply and exhaust air streams. With no moving parts and no tilt mechanism needed, HPT energy recovery modules have a distinct advantage over the competitors and other technologies.\nThe Markets for Heat Pipe Technology\nHPT\'s advances in heat pipes have opened many large markets with a wide variety of applications. The commercial and industrial applications include, but are not limited to, medical and health facilities, data centers, schools, supermarkets, restaurants, libraries and archives, warehouses, hotels, public and commercial buildings, and high-tech facilities.\nIn 1989, the company began designing and installing commercial heat pipe systems used for dehumidification and passive cooling. Early installations included cooling systems for government radar and satellite tracking stations, heat recovery for buildings using outside air, and resolution of building humidity problems.\nBy 1990, the company had discovered the huge market that exists for commercial HVAC dehumidification systems. The company began performing market research and working closely with a number of utility companies, specifying engineers, and national restaurant chains to install, test and monitor the heat pipes. The results were very favorable and the technology became the centerfold of numerous presentations at workshops and seminars.\nSince then, the growth of heat pipe acceptance has become apparent with numerous installations.\nAfter 2009, HPT’s major market moves to health care, education, and data centers applications.\nOpportunities in Commercial Applications\nThere are many applications for the company\'s patented technology. Commercial markets are extremely receptive to the dehumidification products and heat recovery products. Below is a listing of some the commercial applications for HPT Dehumidifier and Heat Recovery Heat Pipes.\nSwimming Pool Enclosures\nHeat Pipes for Dehumidification and Heat Recovery\nHeat pipes are the most effective passive method of transferring heat available today. In their simplest form, a heat pipe is a sealed tube containing a phase-change fluid. The heat pipes for HVAC applications are usually made of copper tubes, aluminum fins.. Different working fluids are used to suit various temperature ranges. In the case of heat pipes for HVAC applications, commercially available refrigerants are normally used as the working fluid. When there is temperature difference in two air streams of each end of the heat pipes, hot air stream applied to one end of the heat pipe, heat boils the inside fluid causing it to change phase from liquid to gas. This vaporization process absorbs large amounts of heat from hot the air stream. Vapor then travels to the other end of the heat pipe, where another air stream with the lower temperature causes the working fluid to condense and release the heat to the cold airflow. Fluid return is normally accomplished by gravity. The constant circulation of evaporating and condensing of the working fluid is the principle of heat pipes heat transfer.\nHeat pipes can transfer heat with minimal temperature difference between one end and the other.\nPassive HPT heat pipes do not need a circulating pump to operate and have no operating cost except for a nominal increase in static pressure. They have no moving parts to malfunction or to be maintained.\nBasic Heat Pipe Structure Diagram\nA traditional heat pipe is a hollow cylinder filled with a vaporizable liquid.\n- Heat is absorbed in the evaporating section.\n- Fluid boils to vapor phase.\n- Heat is released from the upper part of cylinder to the environment; vapor condenses to liquid phase.\n- Liquid returns by gravity or capillarity to the evaporating section.\nHeat Pipes and Air Conditioning\nBelow illustrations show how wrap around heat pipes replace the old overcool then reheat method used to extract more moisture from an air stream. Current ASHRAE standard 90.1 does not allow simultaneous cooling and heating unless 75% of the energy used for reheat is a site recovered energy. In the case of the wrap around heat pipes, all reheat energy is site recovered. Moreover, the reheat is captured from incoming air stream, thus reducing the load on the cooling coil. Current ASHRAE standards refer to wrap around heat pipes as energy recovery in series.']"	['<urn:uuid:26cb56d1-7550-4620-95c3-c8c0123f7cef>', '<urn:uuid:3e3c0bf4-cada-49e4-8500-9efc74ea6b80>']	factoid	direct	short-search-query	distant-from-document	multi-aspect	novice	2025-05-12T15:09:02.012753	5	93	1751
83	As someone studying automated wildlife monitoring systems, I'm curious about the relationship between the minimum crossing time needed for accurate penguin weighing and the length of a tennis center mark - how do these precise measurements compare?	For accurate penguin weighing, the best crossings require a leisurely pace of two seconds across the platform, while a tennis court's center mark is specified to be exactly 4 inches long. These represent very different types of precision measurements - one temporal and one spatial - used in their respective systems.	"[""Measuring Penguins from a distance\nIf we are to conserve the living resources of the Southern Ocean, we need to monitor the region's ecosystems so that we can distinguish between changes due to harvesting and those caused by environmental variability. These are essentially the aims of the CCAMLR Ecosystem Monitoring Program (CEMP).\nAustralia has supported CEMP with field studies since 1990 centred on the breeding biology and foraging ecology of the Adélie penguin. The studies seek to determine the degree to which the harvest of krill, the major food of Adélies, can effect their breeding performance. Parameters being monitored include the penguins' weight on arrival to breed, the duration of parents' incubation shifts, age-specific annual survival and recruitment, duration of foraging trips, breeding success and chick weight at fledging.\nStandard methods were established with the aim of detecting a 10% change in a parameter with a 95% degree of confidence.\nThe CEMP program required that animals be captured for measurement. But we decided to automate the data collection with a system for weighing and identifying penguins as they walk freely to and from their colony. This system would enable weighing and recording of large numbers of penguins with minimal stress and trauma.\nOur first automated penguin monitoring system (APMS), developed by AAD technicians, was installed at Béchervaise Island near Mawson in November 1990.\nThe system involved use of infra-red beams to determine birds' direction of travel. The 600mm-wide weighing platform was placed on the natural pathway taken by the penguins as they moved between their colony and the sea. Guiding fences were set up on either side to ensure birds crossed the platform. The following and subsequent seasons adults and chicks were given an electronic identification tag which was implanted under the skin. All adults were sexed by cloacal examination.\nAt this point the system became a remote sensing device. It is solar powered and the data can be retrieved by computer on site or remotely via radio and telephone. At the heart of the system is the novel method of determining the weight of an unrestrained penguin crossing the weighing platform. We have called this dynamic or in motion weighing. The dynamic weight bears a statistical relationship to the mass of the bird but the method of measurement is different from that of both mass and weight. Mass, an absolute number, is determined by direct comparison with a standard weight on a balance (set of scales), while weight is determined by a device - a spring balance or a weighing platform - that measures the effect due to gravity.\nThe system records a series of instantaneous weights as the penguin moves across the weighing platform. The dynamic weight of the bird is then calculated from these through an algorithm which takes into account all instantaneous weights obtained, including the ramping up and down of weights occurring as the animal steps on and off the weighing platform. This weight has a statistical relationship to the mass of the bird.\nAn Adélie penguin crossing an APMS weigh station\nThe weighing system was calibrated by placing a series of static loads of known mass on the weighing platform. A regression coefficient - mass versus electronic output - was then calculated and stored. Dynamic calibration, which takes account of the weight of a moving animal, is achieved by experimental and statistical analysis. We have found that repeat weighings of a single bird give dynamic weights that are usually within five percent of each other. A comparison between weights obtained from the automated system and a clock face spring balance shows close agreement usually within the same range.\nOccasionally however the weights taken for successive crossings of the same bird will vary widely. This is usually due to the speed at which a bird crosses the weigh bridge. The best crossings are those which are taken at a leisurely pace taking two seconds to cross the platform. Quicker crossings reduce the number of instantaneous weights obtained and so decrease the accuracy.\nAustralian Antarctic Division"", 'The length of a Tennis Court\nIf you should be brand new to tennis, then it is well worth using time and energy to comprehend the proportions and design of the tennis court best Foot Fetish dating apps. I am a firm believer that this particular knowledge assists instill self- self- confidence in brand brand new players, also it’s an opportunity that is excellent introduce the theory that tennis is a hobby of perspectives.\nBeyond that, i do believe it is enjoyable to introduce players towards the intricacies associated with sport, which numerous players tend to comprehend.\nCourt Dimensions & Layout\nLines of a Tennis Court\nAspects of a Tennis Court\nExplore and move on to understand us\nJoin our community of tennis players and take part in the discussion.\nEnhance premium instruction to your game that delivers you with step-by-step video training.\nRecieve our brief recap that is weekly of 5 most fascinating things we find out in world of tennis.\nAs a whole, tennis courts measure 78 feet x 36 foot or 2,808 feet that are square. Nonetheless, the area that is full of court can be used limited to increases matches. The singles court measures 78 feet x 27 foot or 2,106 square foot. Every court consists of a significant elements that are few therefore let us take a good look at each component.\nHere is a diagram as we cover each part of the court that you can use as a point of reference.\nBaseline: increases 36 feet / Singles 27 foot The standard operates parallel to your internet and describes the boundary that is farthest, or right straight right straight back associated with court, on each side. It is where you may strike much of your groundstrokes (forehands and backhands) while the location that is approximate get back serves. Any shots that land beyond this line are away from bounds.\nCenter Mark: 4 inches long The center mark divides the standard by 50 percent and operates perpendicular to your internet. It describes the point you simply can’t get a get a cross whenever striking a offer either in the deuce and advertising court. It’s a good point of reference, as you will find coaches telling you to definitely constantly come back to the middle of the standard once you hit a groundstroke.\nProvider Line: 27 legs wide The solution line operates parallel to your web and marks the halfway point between the internet together with standard. In addition it marks the end regarding the service boxes. Nevertheless, unlike the standard, it expands simply to the singles sidelines. Any offer that lands beyond this line into the court has gone out.\nCenter provider Line: 42 legs very very long (21 foot for each part of this court) the middle solution line operates perpendicular towards the internet and fulfills the solution line to produce two equal-sized solution boxes.\nSingles Sidelines: 39 foot long The singles sidelines also operate perpendicular to your web and define the relative side boundaries of this court for singles matches.\nDoubles Sidelines: 39 legs very long a feet that are few associated with the singles sidelines would be the increases sidelines. These sidelines operate perpendicular into the web and define the relative side boundaries for the court for increases matches.\nLeft & Appropriate provider Box: 21 feet x 13.5 foot (283.5 square legs) The two equal-sized containers developed by the guts solution line will be the remaining and service that is right.\nDoubles Alley: 39 feet x 4.5 legs (175.5 square legs) the area involving the singles and increases sidelines is known as the increases street.\nNo guy’s Land: 18 legs x 27 foot (486 square foot) If you’re not used to tennis, you’ll likely hear somebody yell, вЂњGet out of No Man’s Land,вЂќ which will be the biggest package in the court that falls involving the solution line and also the standard. Typically, you need to avoid standing in this region as you will end up too near to your web to hit a groundstroke and past an acceptable limit away hitting a great volley.\nWeb: 42 legs x 3.5 legs high in the post (3 legs during the center) the internet splits a tennis court in half and runs directly through the midst of the court. a white band measuring 2 inches wide in the heart of the net settings the height, also it’s fastened towards the ground. Tennis nets should really be a mesh this is certainly fine sufficient to make certain that a tennis ball can not move across, therefore the the surface of the internet must have a white musical organization calculating 2-2.5 ins in level.\nHelpful tip: Keep a measuring that is retractable in your tennis bag and gauge the height associated with internet before playing. There are sufficient factors in tennis currently, therefore I constantly urge players to be sure they control the facets that they’ll each time they move in the court.\nNet articles: 3.5 foot high no a lot more than 6 ins wide in many courts, web articles will fall 3 foot not in the doubles sideline straight in the exact middle of the court. Some courts use a singles web, as well as on these courts, the posts that are net fall 3 foot not in the singles sidelines. The articles shouldn’t be much more than 6 ins wide.\nSingles Sticks: 3.5 legs high with no a lot more than 3 ins wide if you are playing singles for a court having a doubles net installed, then two sticks must certanly be utilized to prop within the web 3 foot outside of each and every singles sideline. Numerous courts will not have singles sticks, and usually competitive matches in senior high school and university play without them. But, you watch a professional tennis match, you’ll notice the sticks always in use for singles matches if you keep an eye out when.']"	['<urn:uuid:ce6c6e30-4a71-496b-907f-8abd564a6c10>', '<urn:uuid:952edc95-5b02-43ea-8df4-e670c85d8ee0>']	factoid	with-premise	verbose-and-natural	similar-to-document	comparison	expert	2025-05-12T15:09:02.012753	37	51	1659
84	What's worse for the body: getting too hot or too cold?	Both conditions can be life-threatening, but they present different dangers. Heat-related illness can lead to heat stroke with symptoms like 104-degree body temperature, headache, and dry flushed skin, requiring immediate medical attention. Hypothermia becomes critical when body temperature drops below 32°C (90°F), leading to organ failure and potential death. Both conditions require prompt medical treatment - heat stroke needs immediate 911 attention, while severe hypothermia requires hospital evacuation and careful warming procedures. Notably, hypothermia patients have better survival chances since low temperatures can prevent cellular damage, following the principle that a person isn't dead until they're 'warm and dead'.	"['by Carol Higgins Taylor\nEastern Area Agency on Aging\nWe’ve had some staggering temperatures already this year and undoubtedly more will be on the way. It’s time to be proactive about the heat. Seems every heat wave has people scrambling for fans and air conditioners. If you don’t have a cooling mechanism, think about getting one as soon as you can.\nThe National Institute on Aging explains the risk for heat-related illness:\n• Being dehydrated.\n• Age-related changes to the skin such as impaired blood circulation and inefficient sweat glands.\n• Heart, lung and kidney diseases, as well as any illness that causes general weakness or fever.\n• High blood pressure or other conditions that require changes in diet. For example, people on salt-restricted diets may be at increased risk. However, salt pills should not be used without first consulting a doctor.\n• Reduced sweating, caused by medications such as diuretics, sedatives, tranquilizers and certain heart and blood pressure drugs.\n• Taking several drugs for various conditions. It is important, however, to continue to take prescribed medication and discuss possible problems with a physician.\n• Being substantially overweight or underweight.\n• Drinking alcoholic beverages.\nLearn more at nia.nih.gov\nHeat-related illnesses, such as heat exhaustion and heat stroke are not to be taken lightly. Heat exhaustion, which occurs when the body gets too hot, has symptoms such as thirst, confusion, weakness, becoming uncoordinated and nausea.\nIf you experience any of these symptoms or you are with an older person who is, the following treatments can provide some relief: showering, bathing or sponging off with cool water, drinking fluids such as water and juice, and lying down to rest, preferably in a cool place. If you are outside in the sun, find shelter immediately.\nWhile heat exhaustion can be addressed with the above steps, heat stroke is another story. It can be deadly so immediate medical attention is crucial. The list of possible symptoms includes a body temperature of 104 degrees, headache, faintness, staggering, strong rapid pulse, dry flushed skin, lack of sweating and vomiting.\nIf you or someone else is exhibiting any of these symptoms, call 911 immediately.\nThe key is to prevent and reduce the risks that extreme heat can cause for seniors. It’s important to talk to primary care providers about your individual risk factors, which might include some medications you may take.\nAs we age, our bodies’ ability to release heat, by sweating, is blunted making it particularly dangerous for seniors to stay in very warm environments for long periods of time.\nTo beat the heat, try opening windows at night on opposite sides of the building to create cross ventilation if possible. During the day, windows, blinds and curtains should be kept closed.\nIf you have a fan and a squirt bottle, you’ve got a good way to stay cool. Sit in front of the fan and lightly mist your legs and arms. As the water evaporates, your skin will cool down. And be careful of overdressing. Older people may not feel the heat accurately and consequently put themselves at risk by wearing too much or inappropriate clothing. Lightweight, light-colored, loose fitting garments made of natural fibers are best.\nWhile drinking more liquids is vital to avoiding hyperthermia, check with your healthcare provider before changing your normal routine, especially if you have had limits put on your fluid intake or have been prescribed water pills.\nSummer is short lived in Maine so enjoy it but be cautious. And remember if it is warm and humid, leave your dog at home. A car can turn deadly in just a few minutes, even with the windows down.\nCarol Higgins Taylor is director of communications at Eastern Area Agency on Aging. For information on EAAA, call 941-2865, toll-free 800-432-7812 or visit EAAA.org.', ""To use all functions of this page, please activate cookies in your browser.\nWith an accout for my.bionity.com you can always see everything at a glance – and you can configure your own website and individual newsletter.\n- My watch list\n- My saved searches\n- My saved topics\n- My newsletter\nHypothermia is a condition in which an organism's temperature drops below that required for normal metabolism and bodily functions. In warm-blooded animals, core body temperature is maintained near a constant level through biologic homeostasis. But when the body is exposed to cold its internal mechanisms may be unable to replenish the heat that is being lost to the organism's surroundings.\nStages in humans\nNormal body temperature in humans is 37°C (98.6°F). Hypothermia can be divided in three stages of severity.\nIn stage 1, body temperature drops by 1-2°C below normal temperature (1.8-3.6°F). Mild to strong shivering occurs. The victim is unable to perform complex tasks with the hands; the hands become numb. Blood vessels in the outer extremities constrict, lessening heat loss to the outside air. Breathing becomes quick and shallow. Goose bumps form, raising body hair on end in an attempt to create an insulating layer of air around the body (limited use in humans due to lack of sufficient hair, but useful in other species). Often, a person will experience a warm sensation, as if they have recovered, but they are in fact heading into Stage 2. Another test to see if the person is entering stage 2 is if they are unable to touch their thumb with their little finger; this is the first stage of muscles not working.\nIn stage 2, body temperature drops by 2-4°C (3.6-7.2°F). Shivering becomes more violent. Muscle mis-coordination becomes apparent. Movements are slow and labored, accompanied by a stumbling pace and mild confusion, although the victim may appear alert. Surface blood vessels contract further as the body focuses its remaining resources on keeping the vital organs warm. The victim becomes pale. Lips, ears, fingers and toes may become blue.\nIn stage 3, body temperature drops below approximately 32°C (90°F). Shivering usually stops. Difficulty speaking, sluggish thinking, and amnesia start to appear; inability to use hands and stumbling are also usually present. Cellular metabolic processes shut down. Below 30°C (86°F) the exposed skin becomes blue and puffy, muscle coordination very poor, walking nearly impossible, and the victim exhibits incoherent/irrational behavior including terminal burrowing or even a stupor. Pulse and respiration rates decrease significantly but fast heart rates (ventricular tachycardia, atrial fibrillation) can occur. Major organs fail. Clinical death occurs. Because of decreased cellular activity in stage 3 hypothermia, the body will actually take longer to undergo brain death.\nTreatment for hypothermia consists of drying, sheltering, and gradually warming the patient. While blankets help a person retain body heat, they are not sufficient to treat hypothermia. In the field, a mildly hypothermic person can be effectively rewarmed through close body contact from a companion and by drinking warm, sweet liquids.\nModerate and severe cases of hypothermia require immediate evacuation and treatment in a hospital. In hospital, warming is accomplished by external techniques such as heated blankets for mild hypothermia and by more invasive techniques such as warm fluids injected in the veins or even lavage (washing) of the bladder, stomach, chest and abdominal cavities with warmed fluids for severely hypothermic patients. These patients are at high risk for arrhythmias (irregular heartbeats), and care must be taken to minimize jostling and other disturbances until they have been sufficiently warmed, as these arrhythmias are very difficult to treat while the victim is still cold.\nAn important tenet of treatment is that a person is not dead until they are warm and dead. Remarkable accounts of recovery after prolonged cardiac arrest have been reported in patients with hypothermia. This is presumably because the low temperature prevents some of the cellular damage that occurs when blood flow and oxygen are lost for an extended period of time.\nAppropriate clothing helps to prevent hypothermia. Wearing cotton in cool weather is a particular hypothermia risk as it retains water, and water rapidly conducts heat away from the body. Even in dry weather, cotton clothing can become damp from perspiration, and chilly after the wearer stops exercising. Synthetic and wool fabrics provide far better insulation when wet and are quicker to dry. Some synthetic fabrics are designed to wick perspiration away from the body. In air, most heat (up to 40 percent) is lost through the head; hypothermia can thus be most effectively prevented by covering the head.\nHeat is lost much faster in water, hence the need for wetsuits or drysuits in cold-weather activities such as kayaking. Children can die of hypothermia in as little as two hours in water as warm as 16°C (61°F), typical of sea surface temperatures in temperate countries such as Great Britain in early summer.\nAlcohol consumption prior to cold exposure may increase one's risk of becoming hypothermic. Alcohol acts as a vasodilator, increasing blood flow to the body's extremities, thereby increasing heat loss. Ironically, this may cause the victim to feel warm while he or she is rapidly losing heat to the surrounding environment.\nThere is considerable evidence that children who suffer near-drowning accidents in water near 0°C (32°F, 273 K) can be revived up to two hours after losing consciousness. The cold water considerably lowers metabolism, allowing the brain to withstand a much longer period of hypoxia.\n20% to 50% of hypothermal deaths are associated with a phenomenon known as paradoxical undressing. This typically occurs during moderate to severe hypothermia as the victim becomes disoriented, confused, and combative. The hypothermic victim may begin discarding the clothing they have been wearing, which in turn increases the rate of temperature loss. There have been several published case studies of victims throwing off their clothes before help reached them. \nRescuers who are trained in mountain survival techniques have been taught to expect this effect. However, the phenomenon still regularly leads police to incorrectly assume that urban victims of hypothermia have been subjected to a sexual assault.\nOne explanation for the effect is a cold-induced malfunction of the hypothalamus, the part of the brain that regulates body temperature. Another explanation is that the muscles contracting peripheral blood vessels become exhausted (known as a loss of vasomoter tone) and relax, leading to a sudden surge of blood (and heat) to the extremities, fooling the victim into feeling warm.\nmaltreatment (Physical abuse, Sexual abuse, Psychological abuse)Hypersensitivity (Allergy, Arthus reaction)\n|Certain early complications of trauma||embolism (Air, Fat) - Crush syndrome/Rhabdomyolysis - Compartment syndrome/Volkmann's contracture|\n|Complications of surgical and medical care||Serum sickness - Malignant hyperthermia|""]"	['<urn:uuid:63441363-eee4-40ce-ab26-02540050a09c>', '<urn:uuid:3178a3f5-f465-4ae6-be00-3a20bc100cbd>']	open-ended	with-premise	concise-and-natural	similar-to-document	comparison	novice	2025-05-12T15:09:02.012753	11	99	1739
85	spanish minority language identity construction methods	The construction of linguistic identity in Spanish-speaking contexts occurs through multiple methods. In bilingual communities, individuals constantly renegotiate their identities through language use, choosing between Spanish and other languages based on social context and personal expression. This is evident in cases like Dominican women writers creating new narratives to establish their identity, and in academic studies showing how Spanish speakers in multilingual environments navigate between languages to express different aspects of their identity. The process involves both individual choices in language use and broader societal factors that influence how linguistic identity is formed and maintained.	['|University of Georgia Press|\nMarch 28, 2016\nMAKING DOMINICAN WOMEN VISIBLE BY ERIKA M. MARTINEZ\nThe Latina Book Club continues its celebration of Women’s History Month.\nHence, we are pleased to welcome as our guest blogger Erika M. Martínez,\neditor of an exciting and courageous new literary anthology by 25 Dominican women.\nThe book will be released on April 15. Watch for it!\nAnnouncing the call for submissions for Daring to Write: Contemporary Narratives by Dominican Women in environments full of machismo was quite the challenge. When I attended literary events in the Dominican Republic men offered to contribute to the anthology, yet their writing often objectified women, depicting them as helpless victims or as possessing only sexual power. “This is going to be an important work. It should include men,” someone said to me once. Men assumed they could speak for women, but it wasn’t enough to have female characters in a story. I had to defend my decision to concentrate my work on women writers.\nAt the 2009 International Book Fair in Santo Domingo, I gave a presentation to young students and pointed out that the reasons for my work were everywhere. Women in the country earn less than their male counterparts and face double the unemployment rates. In an hour-long presentation, I couldn’t go into all of the reasons for the inequities or share the anecdotes I’d heard from the many women writers who struggled to carve out space and time for writing with the multiples roles they play in the household. Instead, I had the young audience look at the photographs covering the walls from floor to ceiling; we were in the pavilion for Dominican authors. It didn’t take the students long to realize they were mostly surrounded by portraits of men. I explained that there were many more Dominican women writing then those who were featured in the pavilion. I didn’t know what the criteria had been for the selection of portraits, but it couldn’t have been publication because I knew of several female writers with published books whose photographs were not displayed.\nI also told the students about one of the classes I was auditing at the university, “Autores Dominicanos,” that the male professor teaching assigned forty-eight authors and only four of them were women. This was not because there was a lack of women authors. The list could have been divided in half between male and female.\nI chose to focus on women because after my parents’ divorce, I was raised by my mother and other strong single women in my family who struggled to make ends meet working in factories. Throughout my life I’d longed to see in books the stories I’d heard as I cooked, sewed and cleaned alongside my mother, cousins and friends without a male presence. A counter-narrative to the ways in which women are portrayed in men’s writings was what I needed. I was interested in exploring what it means to be a Dominican woman in the United States as well as on the island.\nThe anthologies of Latino writers I’d read on my own focused on authors of Mexican-American, Cuban-American and Puerto Rican-American descent, yet the Dominican-American population was growing exponentially, becoming the fourth largest Latino community in the United States. I could not have been the only one wanting to see our lives reflected in literature.\nCommon threads appeared throughout the short stories and personal essays submitted. The contributors of Daring to Write delved into how machismo, men’s infidelities and domestic violence shaped the perceptions and development of young women. We can now hear from the voices of those who are being objectified speaking as full subjects of their own lives. Together, the writers in this anthology are reshaping the image of Dominican women and making them visible.#\nABOUT THE AUTHOR: Erika M. Martínez works with the National Writing Project in New Hampshire and is a staff member of their Invitational Summer Writing Institute. She has contributed to various anthologies, including Wise Latinas: Writers on Higher Education and Homelands: Women’s Journeys across Race, Place, and Time. She lives in Oakland, California. To learn more about Erika and DARING TO WRITE, click here.\nDaring to Write: Contemporary Narratives\nby Dominican Women\nEdited by Erika M. Martínez\nForeword by Julia Alvarez\nWith this new Latino literary collection Erika M. Martínez has brought together twenty-five engaging narratives written by Dominican women and women of Dominican descent living in the United States. The first volume of its kind, DARING TO WRITE offers readers a wide array of works on a range of topics, including love and family, identity and belonging, immigration and the meaning of home. The resonant voices in this compilation reveal experiences that have been largely invisible until now.\nThe volume opens with a foreword by Julia Alvarez and includes short stories, novel excerpts, memoirs, and personal essays and features work by established writers such as Angie Cruz and Nelly Rosario, alongside works by emerging writers. Narratives originally written in Spanish appear in English for the first time, translated by Achy Obejas. An important contribution to Latino/a studies, these writings will introduce readers to a new collection of rich literature.\nContributors: Marivell Contreras, Kersy Corporan, Angie Cruz, Rhina P. Espaillat, Delta Eusebio, Noris Eusebio-Pol, Yalitza Ferreras, Carolina González, Farah Hallal, Ángela Hernández, Juleyka Lantigua-Williams, Ana-Maurine Lara, Erika M. Martínez, Miriam Mejía, Riamny Méndez, Jeannette Miller, Sheilly Núñez, Jina Ortiz, Sofia Quintero, Dulce María Reyes Bonilla, Lissette Rojas, Nelly Rosario, Ludin Santana, Leonor Suarez, and Sherezada (Chiqui) Vicioso.\nREAD LATINO. CELEBRATE WOMEN.', 'Mercedes Niño-Murcia, Jason Rothman\nEDITORS: Mercedes Niño-Murcia; Jason Rothman\nSERIES TITLE: Studies in Bilingualism 37\nPUBLISHER: John Benjamins\nBy Whitney Chappell, Department of Spanish and Portuguese, The Ohio State University\nThis edited volume investigates the sociolinguistic aspects of Spanish bilingualism in three discrete areas of the world: Spain, Latin America and the United States.\nChapter 1 introduces the theoretical framework underpinning the book’s 12 studies of Spanish in contact with other languages and presents its overarching theme: the creation of linguistic identity in multilingual communities. As Niño-Murcia and Rothman explain, the construction of identity is a constant renegotiation, and language use provides a means of understanding how an individual views herself in a multidimensional, multilingual space (LePage and Tabouret-Keller, 1985) and how she constructs social positions among others (Bucholtz and Hall 2005). Arguing that identity construction through language use is more readily apparent in language contact environments, the researchers’ foci range from Spanish in contact with Basque, Gallego and Catalán in Spain to indigenous language contact with Spanish in Latin America and finally, to Spanish as a contact language with English in the United States. The authors attempt to decompose larger labels such as ’’Maya’’ or ’’Gallego’’ that effectively lose sight of the individuals’ identities into smaller categories targeting the individual and the individual’s networks (see De Sousa Santos 1998, Cameron 2001). The linguistic analysis of bilinguals who participate in at least two communities of practice (Eckert and McConnell-Ginet 1999) offers a fascinating glimpse of how these individuals perceive themselves within a larger, social space.\nChapters 2-4 focus on languages in contact with Spanish in Spain, discussing Basque, Galician and Catalan. Chapter 2, ’’Bilingualism, identity, and citizenship in the Basque Country’’ by Maria-Jose Azurmendi, Nekane Larrañaga and Jokin Apalategi, focuses on the revival of the Basque language in three territories: Iparralde in France, Navarre in Spain and the Basque Autonomous Community. A combination of language loyalist movements and institutional innovations have created a situation of increased Basquization in the Basque Autonomous Community, largely due to positive attitudes towards Basque and the school systems, both private and public, that promote bilingualism, using either Basque as the primary tool of edification with Spanish as a subject or using a bilingual approach. The Basque situation in Navarre shows a slight increase in Basque speakers, but Basque competence and use continues to decline in Iparralde. Identity and heritage seem to play a critical role in Basquization’s success, with the highest percentage of citizens in the Basque Autonomous Community self-identifying as either Basque or Basque-Spanish, and the lowest percentages self-identifying as Basque or Basque-French in Iparralde. The authors argue that Basque presents a fascinating, dynamic case of the evolving relationship between language and identity at both a societal and individual level.\nChapter 3, ’’Conflicting values at a conflicting age’’ by Verónica Loureiro-Rodríguez, investigates the language situation in Galicia, where the previously stigmatized autochthonous Galician language gained co-official status with Spanish in the Spanish Constitution of 1978. Loureiro-Rodríguez’s findings among Galician adolescents are somewhat paradoxical: while adolescents have the most positive attitudes towards Galician, they actually use it less frequently than older generations. It appears that Galician is rapidly becoming diglossic: ’’standard’’ Galician is taught in schools, but adolescents find the dialect unnatural and elitist. They believe the Galician spoken in las aldeas, or ’villages,’ is the real Galician, the Galician preserved over the centuries and spoken by their parents and grandparents. Because of the restricted environments in which the dialects of Galician are deemed acceptable by adolescents, Galician language use is decreasing among younger generations, and Loureiro-Rodríguez argues that the region’s language planning is desperately in need of change to prevent future deterioration of Galician.\nEmili Boix-Fuster and Cristina Sanz’s ’’Language and identity in Catalonia’’ (Chapter 4) focuses on the discrepancy between L2 Catalan speakers that self identify as ’Catalan’ and L1 Catalan speakers who perceive these L2 speakers as ’non-Catalan,’ suggesting a divided perspective on Catalan identity. The authors discuss the changing concept of ’Catalan’ by analyzing José Montilla’s political rhetoric dividing Catalans into Catalans by birth and by Catalans by choice, a choir director’s use of Catalan, Spanish, English and Italian in animating its members, and an experiment designed to elicit linguistic differences among Catalan L1-Spanish L2 speakers, Spanish L1-Catalan L2 speakers and native bilinguals. Boix-Fuster and Sanz conclude that Spanish, the national majority language, is having a great effect on Catalan in both lexical items and pronunciation, and the identity of ’Catalan’ typically based on language alone is in need of reexamination and revision as more nonnative speakers acquire the language.\nChapter 5, ’’Literacy and the expression of social identity in a dominant language: A description of ’mi familia’ by Quechua-Spanish bilingual children’’ by Liliana Sánchez, moves the focus of study to Latin America, investigating the notion of family in the writing of monolingual Spanish speaking children and bilingual L1 Quechua-L2 Spanish speaking children. Although no significant differences in text structure emerged, there were notable semantic differences, demonstrating cultural differences between these two groups. The author argues that different profiles emerge in the two groups’ writing: monolingual Spanish-speakers tend to focus on interpersonal relationships as well as personal qualities and psychological attributes of their family members, while bilingual speakers discuss their quotidian activities, responsibilities and the families’ animals. Depending on the expectations of teachers and the school systems, the assumption that monolingual speakers have a more advanced writing profile may surface, whereas cultural differences could actually be leading to different interpretations of the same assignment.\nChapter 6, ’’Maya ethnolinguistic identity: Violence and cultural rights in bilingual Kaqchikel communities’’ by Brigittine M. French, draws attention to two competing forces in Guatemala: nationalistic suppression of indigenous language, and therefore of indigenous identity, and a recent pro-Maya push to preserve and protect both indigenous languages and cultures. The same indigenous people forced to live through La Violencia, a state-sponsored mission to eradicate the indigenous influences impeding the idealized Guatemalan cultural homogeny, are now witnessing an opposing movement: the Ley de Idiomas Nacionales, passed in 2003, guarantees indigenous people the right to their language and cultural identity. An assessment of a bilingual Kaqchikel-Spanish speaker’s language use demonstrates a conflicted sense of identity: Fidencio Kan is bound to his heritage and his national language on the one hand, but has been made to feel ashamed of his roots by the government on the other, choosing to speak Spanish to advance in society.\nIn ’’’Enra kopiai, non kopiai.’: Gender, ethnicity and language use in a Shipibo community in Lima’’ (Chapter 7), Virginia Zavala and Nino Bariola equate female Shipibo speakers’ bold use of vernacular language in Canta Gallo, Lima with their increased power and agency within their community. According to Zavala and Bariola, the role of women in Shipibo communities in the Amazon is not as valued as the role of men, as men are considered the ’’workers,’’ leaving the house to fish and hunt, while women stay home with the children and tend to the household. Upon moving to Lima, however, it is the women who become the ’’workers’’ and maintain a sense of Shipibo identity, making traditional Shipibo handicrafts and leaving the home to sell them. With this new economic and societal value, Shipibo women have become increasingly powerful in Canta Gallo and express this power linguistically, using Shipibo more than men and clearly voicing their opinions in community meetings. An analysis of individual speakers at these community gatherings illustrates the assertiveness in women’s utterances compared to the softened, often hedged statements of the men, a definite contrast to the relationship between the sexes in the Amazon.\nIn Chapter 8, ’’Kreyol incursions into Dominican Spanish: The perception of Haitianized speech among Dominicans,’’ Barbara E. Bullock and Almeida Jacqueline Toribio investigate the traits of the highly stigmatized fronterizo speech in the Dominican Republic, also called Cibaeño, which is spoken in the northwest along the border with Haiti. The researchers conducted a language attitude test to determine whether there are specific linguistic features triggering the negative assessment of Cibaeño speech or if these negative perceptions are actually based on cultural and racial stereotypes. A general consensus among those judging the speakers linked less prestigious speech with darker skin color, aligning ’Haitian’ with fronterizo traits. The authors find that the stigmatized ’Haitian’ features, such as liquid neutralization, posttonic syllable reduction and prosodically marked intonational contours, are actually properties of all races from rural, less educated speech and not simply Haitian or ’’Haitianized’’ speakers.\nChapter 9, ’’’I was raised talking like my mom’: The influence of mothers in the development of MexiRicans’ phonological and lexical features,’’ marks a shift from Latin American Spanish to Spanish in the United States. In this chapter, Kim Potowski discusses dialect transmission from parents to children, examining Chicago Latinos who have one Mexican parent and one Puerto Rican parent. To better understand their linguistic history, Potowski explains the children’s self-reported language use with their parents and attitudes towards their parents’ cultures before conducting vocabulary identification and opposite word tasks with her participants. Attempting to assess both the lexically and phonologically affected features of the Latinos’ speech, the author, along with several Hispanic Linguistics specialists and native Spanish speakers, rank the participants on the Mexicanness or Puerto Ricanness of their dialects. According to the author, the dialects of 20 out of the 27 participants aligned with the mother’s speech, which she uses to support the notion of a ’’mother dialect’’ in addition to a ’’mother tongue.’’\nIn Chapter 10, ’’Choosing Spanish,’’ Elaine Shenk analyzes a Dual Language Immersion Program in West Liberty, Iowa, tracking the use of Spanish and English in different participant structures. Shenk finds varying levels of Spanish use in the different structures (listed here from lowest to highest): unstructured student interaction, student-directed classroom interaction, student-fronted classroom interaction and teacher-fronted classroom time, and the author argues that the larger societal pressure to speak English in situations not guided by a DLP teacher is dominant among the students. However, five students did exhibit a higher level of Spanish use than others, and sociolinguistic interviews with their families revealed ideological similarities: they valued and took pride in their cultural heritage, viewed their bilingual children as brokers between two different linguistic and cultural communities, and some saw an economic advantage to bilingualism as well. Shenk concludes that collaboration between teachers and parents to instill cultural appreciation in young Latinos would result in a greater use of the minority language.\nIn Bonnie Urcioli’s ’’Whose Spanish?’’ (Chapter 11) the author examines the complexity of college Latinos’ linguistic identity in the United States. Urcioli argues that institutions place very different cultures and dialects under the catchall term of Latino, and in spite of very different identities, Latinos are supposedly all united by the same language under this ideology. However, this language-based social solidarity is much more complicated for second-generation Latinos who primarily speak English as well as Spanish-speakers whose home dialects do not match the standard Spanish taught in universities. In addition to these linguistic complexities in Spanish, many Latinos are viewed as inferior or inadequate English speakers, obscuring the constructing a single, pan-Latino linguistic identity even further.\nChapter 12, ’’Constructing linguistic identity in Southern California’’ by Isabel Bustamante-López, analyzes the written linguistic narratives of 38 Latino participants in Southern California, detailing their histories with English, Spanish and the communities and registers they associate with both languages. She finds a general shift towards English as the more dominant language in second and third generation Latinos, but they continue to view Spanish as an integral part of their identity. Bustamante-López argues that for the participants, identity is a dynamic and fluid process, continually renegotiated in various social encounters using their English, Spanish and code-switching to express themselves.\nChapter 13, ’’Indicators of bilingualism and identity: Samples from the Spanish-speaking World’’ written by the editors Mercedes Niño-Murcia and Jason Rothman, presents the results of an ongoing, longitudinal study of the multilingual upbringing of three young boys in California who speak Italian, Spanish and English. Their Italian father and Colombian mother have created a home environment that encourages the use of their own native languages; the father speaks with the children exclusively in Italian, the mother, although more liberal in her language shifts, speaks with the children mostly in Spanish, and the children have acquired English from school and their community. The children are proficient in all three languages, using them to create different identities for various pragmatic and sociolinguistic reasons. Among the brothers and with their father’s family, they tend to use Italian, but they choose to speak in English when other English speakers are present. With their mother, the mother’s family and in front of other Spanish speakers, Spanish is generally chosen, showing the boys’ sensitivity to what they see as the most appropriate language in a given context. Finally, different topics elicit different language choices: Italian is generally spoken when playing sports, which they often play with their father, Spanish, which is associated with their mother, is often used in nurturing interactions and to give commands, and English is chosen to discuss culturally-relevant phenomena, such as Transformers. This ’’linguistic project,’’ as described by the family, has instilled an appreciation of multilingualism and multiculturalism in the boys, who adeptly demonstrate their ability to navigate among their possible language choices and renegotiate their linguistic identities for different interlocutors and situations.\nFinally, an afterword written by Margarita Hidalgo reviews the concept of identity construction under different theoretical frameworks and offers a broad perspective of Spanish and bilingualism in different areas of the world.\nBilingualism and Identity provides a fascinating panorama of Spanish in contact with other languages in three discrete situations: as the co-official but nationally dominant language in Spain, the majority, prestige language in Latin America and a less prestigious, minority language in the United States. Elaborating upon the various ways in which bilingual speakers create and continually renegotiate their identities, this collection draws attention to the multifarious and complex identities of individuals who navigate among multiple linguistic worlds. In short, Bilingualism and Identity is an indispensable text for any scholar interested in the bridge between Spanish bilingualism and identity.\nLimited by the foci of research to date, bilingualism in Spain is more thoroughly documented than the many bilingual settings in Latin America: Spain’s Basque, Galician and Catalan are all discussed, while only Quechua, Kaqchikel, Shipibo and Haitianized Dominican Spanish are addressed in Latin America. Numerous other contact situations between Spanish and Latin American indigenous languages offer similar opportunities to investigate identity construction within heterogenous communities, and it is my hope that future volumes will investigate the individual’s navigation through these complex linguistic and social worlds as well.\nMy only small criticism of the book has to do with one departure from what I saw as the primary goal of analyzing identity construction. While most chapters focused primarily on the individual’s negotiation of linguistic identity in a multilingual community, chapter 2 stood out as a large-scale study of broad, regional surveys and language data without any real regard for individuals’ agency in the process of identity construction (see LePage and Tabouret Keller 1985, Cameron 2001). This approach is not necessarily the wrong way to handle identity studies, as extensive data analysis often provides a clear description of a community at large, as demonstrated by numerous first wave studies (as described by Eckert 2005, see Labov 1966, Trudgill 1974, Macaulay 1977 and Cedergren 1973). However, the chapter did noticeably deviate from the rest of the book in its aim.\nIn spite of that small lapse in unified purpose, these articles are both edifying and absorbing, offering relevant, contemporary perspectives on the bilingual Spanish speakers’ continually evolving linguistic identity.\nBucholtz, M. & Hall, K. 2005. Identity and interaction: A sociocultural linguistic approach. In Discourse Studies 7(4-5): 585-614.\nCameron, D. 2001. Working with spoken discourse. Thousand Oaks CA: Sage.\nCedergren, H. 1973. The interplay of social and linguistic factors in Panama. PhD dissertation. Ithaca: Cornell University.\nDe Sousa Santos, B. 1998. De la mano de Alicia: Lo social y lo politico en la Postmodernidad. Bogotá: Ediciones Uniandes.\nEckert, P. and McConnell-Ginet, S. 1999. New generalizations and explanations in language and gender research. Language in Society 28:185-201.\nEckert, P. Under review. Three waves of variation studies. Retrieved from https://www.stanford.edu/ eckert/PDF…\nLabov, W. 1966. The social stratification of English in New Yok City. Washington, D.C.: Center for Applied Linguistics.\nLe Page, R.B., & Tabouret-Keller, A. 1985. Acts of identity: Creole-based approaches to language and ethnicity. Cambridge: CUP.\nMacaulay, R.K.S., & Trevelyan, G.D. 1977. Language, social class, and education: A Glasgow study. Edinburgh: Edinburgh University Press.\nTrudgill. P. 1974. The social differentiation of English in Norwich. Cambridge: Cambridge University Press.\nABOUT THE REVIEWER\nWhitney Chappell is a PhD student in Hispanic Linguistics at the Ohio State University specializing in the intonation-pragmatics interface and varied topics in Spanish sociolinguistics.']	['<urn:uuid:5cea51a7-5ac5-42b8-b1bb-3ba4904c568f>', '<urn:uuid:14ec1c64-2bf9-47a8-be58-07986d28a916>']	open-ended	with-premise	short-search-query	similar-to-document	three-doc	expert	2025-05-12T15:09:02.012753	6	95	3722
86	What is the purpose of a sitemap on a website and how does it help with both navigation and search engines?	A sitemap is a structural representation of a website's pages and architecture, which can be either a document or a web page that lists the pages on a website in a hierarchical fashion. It serves two main purposes: it improves website navigation for users and enhances search engine optimization (SEO). Additionally, major search engines like Google, Yahoo, and MSN support a Sitemap protocol that uses XML format, and there are special generators available to create these XML documents for specific URLs.	['Simply put, usability is making your website easy for your visitors to find the information they need when they need it.\nA common misconception about usability amongst web companies is that usability is expensive. Yes, there are multi-national companies that spend thousands of dollars on usability tests and research, but for an everyday company usability is achievable without the knowledge of usability experts or without expensive equipment for testing.\nWeb designers have an even easier job to do, just by reading usability articles they can accumulate a fairly good knowledge about usability basics and how to implement them on a website.\n1. Include a Tagline\nA tagline is a statement or a motto that represents a company’s, or in our case a website’s, philosophy and mission. It should be the most obvious element on a website’s front page and it should clearly describe the website in one phrase.\nStatistics show that a website has just 8 seconds to capture a visitor’s attention for them to browse the site further. Without a clear tagline a website would have a hard time keeping visitors long enough to browse the inner pages.\n2. Implement Site Search\nAs with taglines, site search is a very important element on a website. When users are looking for something they typically look for a text field where they can enter their search term.\nAccording to Jacob Nielsen’s web usability tips, make this search box 27 characters wide in order for the text to be clearly visible and easy to use. Place the search text field on the top of your web page, because users tend to search a website according to the F pattern, meaning from the top left to the bottom right.\nInclude a search button and clearly specify the search text, don’t use text such as Go or Submit, because these expressions tend to mislead your website’s visitors.\n3. Don’t Use Extensive Graphics\nAbusive use of design elements and graphics are always bad for a website, they just mislead the site’s visitors. Only design to improve the web page not just to decorate it. From a usability point of view, less is always more.\n4. Use Site maps\nSite maps are a relatively new website feature that improves web page navigation and also search engine optimization (SEO). Site maps in essence are a structural representation of a website’s pages and architecture. It can be a document in any form, or a web page that lists the pages on a web site, typically organized in hierarchical fashion.\nRecently, search engines like Google, Yahoo and MSN have started offering a Sitemap protocol which is similar to a website’s site map page, but the data is organized in XML format. There are Sitemap XML generators that create these documents for a specific URL.\n5. Don’t Break the Workflow\nBy workflow we mean every operation that a user is doing on a website. For example filling out a form, registering on a website, browsing categories, archives, etc. Don’t break these workflows, let the user cancel any operation. By not letting the user cancel an operation, we’re forcing them to finish it even if they don’t want to.\nAnother mistake is not changing the color of visited links, this results in breaking the navigational design. Let users know where they’ve been and where they are on a website.\n6. Create Easily Scannable Web Pages\nEasy to read web pages plays an important role in maintaining visitors’ loyalty, keeping them on your site and reading your content. Usability tests show that the majority of users don’t read web pages, they scan them, looking for titles, bold, emphasized text or lists.\nEye tracking studies conducted by Jakob Nielsen show that users read content that resembles an F shape, meaning that the reading starts from the upper left of the web page, next it moves down a little starting from the left again.\nNielsen also states the implications of this reading pattern:\n- Users won’t read a web page content word by word, they will extract important paragraphs, bold text, etc.\n- The first two paragraphs are essential on a web page. These must contain the most important information that your visitors are looking for.\n- Sub headings and lists stands out from the regular paragraphs. Use these elements to notify users on important information.\nOne important method that we can learn from traditional printed newspapers is that the journalists thought of a catchy headline and a catchy first paragraph to make readers read the whole article. They organize the content in an inverted pyramid format, just picture an upside down pyramid. The broad base represents the most important information in the whole article and the narrow tip represents the least important information.\nWe can use this format to organize web content by putting the most important pieces on top and the least important ones on the bottom, but how do we know which information is important and which is not? With the help of news values.\n7. Don’t Design Misleading UI Controls\nBy user interface (UI) controls we mean web page elements, components and widgets that a user can interact with (e.g. a button, drop-down list).\nDon’t design graphic elements that looks like a button, but is not. We often see text that is underlined and looks like links, but are not clickable.\nBy not having the action that the users were expecting, they would think that the site is broken and eventually leave. One other important usability tip regarding UI controls is consistency: Make sure that your UI controls are consistent.\nYahoo, as the above image shows too, is a good example of consistent UI control design. Every tab on the page looks and behaves the same, every link is underlined on mouse over, every button looks the same, etc.\n8. Give Meaningful Feedback\nMeaningful feedback is essential for a website. This is the communication channel between the site and the users, with the help of feedback we let the users know what’s going on on the site. In case of an error on your web page, don’t just print Error occurred, instead write meaningful error messages which tell the user what went wrong and what actions they can perform from there.\nFeedback works in both ways. When a user fills in a form they are essentially giving you feedback. Don’t make the users have to fill in the same information twice. For example if a user has registered on a website and needs to fill in a form at some point, don’t ask for their name or any other information that they have already supplied, because these details already exist somewhere in a file or database. By simply getting these details automatically we are simplifying the whole process.\n10. Avoid CAPTCHAs\nCAPTCHA stands for Completely Automated Public Turing test to tell Computers and Humans Apart. Even the name sounds complex. The most general form of CAPTCHA is text embedded in an image and by testing visitors we can separate human users from spam bots.\nThe problem with CAPTCHAs are that each form of human verification method triggers a complex process in the users’ brains (e.g. figuring out the distorted text, adding two numbers, etc).\nAnother problem with CAPTCHAs are the inconsistencies regarding different cultures. For example Chinese symbols, numerals are different from most western letters and Arabic numerals. Chinese people have a much harder time using CAPTCHA ‘enabled’ online forms.\n- Always include a tagline which should be the most obvious element on a web page.\n- Implement a 27 characters wide site search and place it on top of your website.\n- Don’t use extensive graphics and design elements.\n- Include a site map page and register a sitemap XML document in search engines.\n- Don’t break a user’s workflow. Allow every action to be canceled if necessary.\n- Create easily scannable web content and place the most important information on top of your web page.\n- Don’t design graphic elements that looks like a button, but is not.\n- Present meaningful feedback and don’t forget that feedback works both ways.\n- Avoid CAPTCHAs, use more usable methods instead.\nDo you follow these principles? Please add your feedback and extra tips below.']	['<urn:uuid:94a47d14-795f-41b3-a447-71eefce1f765>']	open-ended	direct	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-12T15:09:02.012753	21	81	1373
87	how many tons clothing landfill annually vs amount clothing purchased uk per year	92 million tons of clothing end up in landfill annually globally, while in the UK specifically over one million tonnes of garments are purchased every year.	['As Newcastle is set to host the first Northern Sustainable Fashion Revolution, Sarah Sinclair meets those striving for a more ethical and sustainable industry.\nOver 1,000 bathtubs of water.\n6,000 car miles of carbon emissions*.\n£140 million of clothing sent to landfill**.\n14 million workers paid less than the living wage***.\nThis is the real cost of the fashion industry. As one of the world’s largest employers, and with over one million tonnes of garments purchased every year in the UK alone, it should come as no surprise that our clothes come with a hidden price tag.\n“Fashion is the [world’s] second biggest polluter,” says Declan Hill of Newcastle-based ethical clothing company, Uncaptive. “It counts for so much damage, we’re only just finding out that if anything, it’s actually worse than we thought.”\nUncaptive co-founder, Itala Hill, adds: “The whole supply chain can be dirty, from the crops to the process of turning the raw material into fabric, to the labour, the user phase and then the disposable phase. Fashion covers such an immense range of social and environmental causes that it’s so important to talk about and do something about it.”\nFashion Revolution Week is a global movement, set up in 2013 after the Rana Plaza factory collapse in Bangladesh killed 1,138 garment workers. They campaign for transparency in the fashion industry and aim to make consumers more aware of where their clothes come from, with an annual event held every April in major cities across the world. This year, on the 6th anniversary, Newcastle will host the inaugural Northern Sustainable Fashion Revolution, the first of its kind to be held in the north of England.\nThe five-day festival, organised by Uncaptive and local artist and fashion designer Melanie Kyles, is set to showcase independent fashion brands in the North East who are pioneering sustainable and ethical values in the industry. Aimed at engaging the public, raising awareness of fashion practices and offering solutions for how consumers can make more informed choices in their wardrobes, the line-up includes panel discussions, insightful industry talks, mending and styling workshops and a live catwalk.\n“I don’t think there’s been anything like this is Newcastle before,” says Melanie. “This seems like a good year to do it. I wouldn’t say we’re at a tipping point yet, but it’s definitely more on people’s radars.”\nItala agrees: “[People] are questioning more. Veganism and plastic pollution is in the media a lot and people are asking: what else is there that I don’t know? And that creates a huge movement around fashion.”\nIt does seem that both brands and consumers are beginning to recognise their responsibility to make more sustainable choices. The Fashion Industry Charter for Climate Action launched in December 2018, with 43 leading membership organisations, including brands such as Adidas, Burberry, H&M Group and Levis, committing to a vision for the industry to achieve net zero emissions by 2050. Meanwhile at the end of last year, fashion search engine Lyst, reported a 47 per cent increase in searches for terms such as “vegan leather” and “organic cotton”. Yet despite these steps forward, fast-fashion leader, Primark opened the doors to its biggest ever superstore in Birmingham last week.\n“Sometimes people think that sustainable or ethical fashion is more expensive, that it’s not something they can afford when they can go to Primark,” explains Melanie. “Whereas with the mixture of brands that we have involved, there’s something for everyone.”\nThis ranges from designer-wear such as TISKA London, made in Britain using only ethically sourced materials to those with a lower price point such as Uncaptive, which is Fair Wear certified, to the preloved market and even clothes swaps. “In terms of sustainable fashion, even if you’ve got little money you can still do it,” Melanie adds. “People might have a preconceived idea of what it is, but there’s actually so many different types. It’s dispelling the myths.”\nItala continues: “It’s about education most of all, so people know that it’s not that difficult to make better choices. To inform them where we can find ethical clothing and that it doesn’t have to be expensive, and to provide them with tools for improving their own pieces.”\nThe younger generations are generally perceived to be more conscious of their carbon footprint. However, buying habits encouraged by the outfit-sharing culture on Instagram, are fuelling the fast-fashion industry. Investing in a new dress every weekend and only wearing it once has become the norm, but concepts such as locally-based Hire Street that allow consumers to rent high street dresses for one-off occasions could be the solution. “People have that fear of being in the same outfit more than once,” says Melanie. “It’s as you get older you learn your own style, rather than following trends.”\nAdd to this the fact that so few young people have the mending skills to customise or adapt their clothes and this leaves them reliant on the prescriptive styles of mass-production. “In the 80s, people were customising their clothes and making their own style,” Melanie adds. “With social media and globalisation it’s all morphed into that typical Instagram style, indistinguishable from each other.”\nAttempting to challenge some of these generational issues is Catherine Glover, senior lecturer in Fashion Communication at Northumbria University. With Orsula de Castro, creative director and co-founder of Fashion Revolution, Orsula de Castro, she has written a live collaborative brief, entitled ‘Wear to Now? The changing shape of sustainable Fashion Revolution’. The project tasked second year students to come up with a campaign to create a grassroots movement, stimulate a change in generational mindset and transform consumer habits from buying to customising and keeping. Academics and students will share their campaigns and insight as part of Northern Sustainable Fashion Revolution.\n“It’s a project that will inspire and connect deeply with the students,” explains Catherine. “We’ll be sharing how a brief was written with those ambitions in mind and how the students have responded to it: if that’s helped them to think differently and inspired some form of mindset change in them, as future practitioners and industry professionals.”\nCatherine hopes the project will become part of a growing dialogue, to provoke curiosity and encourage a transformation in students from unconscious consumers. “A lot of us can be quite unconscious consumers. We’ve grown into having consumption habits which are very trend-focused and want-focused,” she says. “It’s provoking that questioning to say that conscious consumption is here to stay. We have to take responsibility for our purchasing, and also for students, being young professionals going into industry and being our future contribution to that message that can reach everyone in this global economy.”\nBut as we become evermore aware of the real price we have to pay for fashion, is it still possible to enjoy it?\n“Of course,” says Melanie. “It’s talking about being proactive and looking at the opportunity. You’ve got fashion technology coming up with amazing solutions, it’s an exciting time.”\nAnd of course, Northern Sustainable Fashion Revolution is set to showcase the fact that new ethical brands, vintage, preloved and customisation offer endless opportunities for the expression and escapism we crave from fashion, which seems a lot more fun than a weekly trip to the high street.\nItala adds: “There’s so much going on in terms of innovation in sustainability and even social causes. It’s not just about the negative side of fashion, but also the positive. Hopefully the whole experience is going to make [people] question – possibly feel sad about it – but then leave feeling hopeful.”\nHowever, we shouldn’t feel too guilty for not yet being fully sustainable shoppers, says Melanie: “Nobody is 100 percent. Its impossible until it’s really mainstream and easy to get hold of – sometimes you need to go and get an emergency pair or tights from Primark. If you’re doing 20 percent sustainable and ethical, great. If you’re doing 50 percent, even better. Small steps are better than no steps.”\nNorthern Sustainable Fashion Revolution takes place from Wed 24 – Sunday 28 April at Ampersand Inventions and B&D Studios in Commercial Union House and Beeronomy in Newcastle.\nFor full line-up, tickets and more information click here\n*The annual footprint of a household’s newly bought clothing\n**Figures taken from WRAP\n***The Pulse of the Fashion Industry report (2017), Global Fashion Agenda', 'Well in 2023 as we are, reports with data gathered from 2022 are continuing their slow and steady rollout. And, as they do, a picture of where we’re at – and a comparable image of where we want to be – are starting to take shape. Thus far, we’ve heard from various brands and bodies, including the likes of Nike and the Material Innovation Initiative, about their full-year metrics and more qualitative findings.\nNow it’s the turn of the non-profit Apparel Impact Institute (Aii) to deliver its findings on CO2 and wastage reduction, cost-effectiveness and the potential scalability of its various programs.\nAn organization established in 2017 with a vision to create a “transformed apparel, footwear, and textile industry that has a positive impact on people and planet,” the Aii works to “identify, fund and scale proven quality solutions to accelerate positive impact in the industry” – essentially, providing infrastructure and funds where they’re most needed and where they can have the most powerful results.\nCreated by the coming-together of the Sustainable Apparel Coalition (SAC), the Sustainable Trade Initiative (IDH), Natural Resource Defense Council (NRDC) and Target Corporation, the Aii is an effective amalgam of industry leaders from the overlapping worlds of environmental protect and industrial sustainability.\nWith this in mind, it’s fitting that the report itself opens not with self-congratulation but with a warning – or, at least, a reminder that the global clothing industry is worth $1,300,000,000,000 USD, that 14 items of clothing are producer per person every year, and that 92,000,000 tons of clothings ends up in landfill annually, leaving less than 15% to be recycled.\nThe report also provides a stark statement in terms of what’s required to set things right.\nNoting that, “Using data from the Sustainable Apparel Coalition, Higg, and Textile Exchange, WRI and Aii estimated apparel sector emissions to be 1.025 Gt of carbon dioxide equivalent in 2019, or roughly 2 percent of annual global greenhouse gas emissions,” the Aii report follows this by telling us that, “To limit global warming to 1.5 degree Celsius, in alignment with the Paris Agreement and science-based targets, the apparel sector’s emissions should at least reduce to 0.565 Gt CO2 emissions by 2030, representing a 45% reduction and achieving net zero emissions by 2050.” That’s a huge reduction for an industry still in thrall to overproduction and outdated practices.\nThat Aii report, though, is not an overall State of the Industry missive – it’s a document of the change affected by the Institute, its programs and its partners. To this end, Aii notes the full-year 2022 saw an total green house gas emissions saving equal to 12,127 cars removed from the roads, energy savings equal to 3,504 washing machines not used, and water savings equal to almost 714 olympic sized swimming pools. All of which was delivered across a cohort of 380 factories, 29 brands and 1 manufacturer involved in Aii programs.\nPushing forward with its aims, Aii was also able to increase the number of regions served by its Target Setting programs to 28 – a move which will increase availability of Aii programs and funding to new locations, helping to distribute both funds and environmental benefits more equally. The Institute also launched the “groundbreaking $250M Fashion Climate Fund which has the potential to unlock $2B of blended capital,” once again improving Aii’s capability to bring change to the industry at a systemic and grass-roots level.\nAccording to data from the report, “Aii programs cost $17 per ton of CO2e reduced compared to an average of $67 per ton for alternative decarbonization strategies (i.e. solar thermal, offshore wind, etc.) – attributable to the strength and effectiveness of Clean By Design programs.” These kinds of numbers may not seem attention-grabbing in the same way as the billions of dollars mentioned above or the actual environmental impact metrics, but they are essential. Proving the financial efficacy and stability of decarbonization is a huge barrier to industry-wide adoption, and the more data points to success in that area the harder it becomes for corporations to deny or use as a shield to protect their status quo.\nThis report is just a small snapshot of industry-wide impact, in both the positive and negative aspects; a single piece of a much larger image which, nonetheless, shows us what is possible, what is actively being pursued, and what has yet to be achieved.\nYou can read the full thing and find out more about the Aii’s work over on the non-profit’s official website. And, if you’re interested in hearing more on the fashion industry’s global impact, consider subscribing to the FUTUREVVORLD newsletter via the form at the bottom of the page.']	['<urn:uuid:8ce236af-b9b0-409a-95f7-aa6d28d182a6>', '<urn:uuid:1cb3ff8d-4331-4721-a4c9-f94f0699b3d2>']	factoid	direct	long-search-query	similar-to-document	comparison	expert	2025-05-12T15:09:02.012753	13	26	2165
88	what are three main stages metal fatigue failure progression in metals explain each stage	Metal fatigue progresses through three main stages: 1) Crack initiation, which begins with submicroscopic changes in the grain structure of the metal, 2) Crack propagation, where the crack grows a finite amount with each stress cycle, and 3) Rupture, which occurs when the remaining cross-sectional area becomes too small to support the load.	"[""Figure 1.1 The three stages of fatigue failure Modern fatigue theories provide separate analyses for each phase.Crack initiation theories are based on the assumption that fatigue cracks are initiated by the local strains and stresses on the surface of a component.Crack propagation theories relate crack growth to the stresses in the component Some results are removed in response to a notice of local law requirement.For more information,please see here.Previous123456NextRecent advances on size effect in metal fatigue under Structural components with different scales normally show different fatigue behaviors,which are virtually dominated by defects originated from multiple sources,including manufacturing processes.This paper reviews three types of size effects (statistical,geometrical,technological) as well as their recent advances in metal fatigue,aiming to provide a guide for fatigue strength assessment\nPublisher preview available.Recent advances on size effect in metal fatigue under defects a review.March 2021; International Journal of FractureQuantifying Fatigue Failure failure surface! design equation! (equivalently,expand service loads until you hit the failure surface)! failure surface! design equation! Equation of Goodman line:! Mean stress, m,as mid-range strength S m Alternating stress amplitude, a,! as fatigue strength S as Goodman Diagram for Torsion Failure with m 0! S Pressure Vessel FatigueFatigue in metals is a progression beginning with submicroscopic changes in grain structure of the metal,and consists of three main stages crack initiation,crack propagation,and rupture.Once initiation of a crack occurs,the crack grows a finite amount with each stress cycle until the remaining cross sectional area is so small rupture occurs.\nMachine Design Part I is the first course in an in-depth three course series of Machine Design. The Machine Design Coursera series covers fundamental mechanical design topics,such as static and fatigue failure theories,the analysis of shafts,fasteners,and gears,and the design of mechanical systems such as gearboxes.Module 29 Introduction to Fatigue Failure - Fatigue Machine Design Part I is the first course in an in-depth three course series of Machine Design. The Machine Design Coursera series covers fundamental mechanical design topics,such as static and fatigue failure theories,the analysis of shafts,fasteners,and gears,and the design of mechanical systems such as gearboxes.Module 1 - Design Considerations DME Casting MODULE 1- DESIGN OF.MACHINE ELEMENTS MANUFACTURING CONSIDERATIONS IN DESIGN,STRESS CONCENTRATION,THEORIES OF FAILURE SELECTION OF METHOD The selection of method of manufacturing is one of the most complicated area which a designer has to come across.The manufacturing processes can be broadly into four classes Casting processes Deformation processes\nThe generally accepted explanation for the mechanism of metal fatigue is based on dislocation theory.This theory was covered in the article on Stresses in Metals.Basically the theory says that the atomic arrangement in the crystals of a metal is imperfect and contains numerous missing atoms.The missing atoms create gaps,which causStress Verses Life Cycle CurvesDesigning For Fatigue ConditionsStress Concentration FactorsSurface Finish and Surface Microstructure TreatmentsRecommended Practices to Increase Fatigue LifeA great deal of fatigue load testing has been done with a wide range of metals.From these tests graphs of tensile strength verses number of cycles to failure have been developed.An example of one for wrought (worked) steel is shown in Figure 1.The vertical scale on this log-log plot shows the applied stresses as a proportion of the steels ultimate tensile stress Su while the horizontal scale is the number of stress cycles to failure.The left hand sloping line tells us is that a steel part put under high cyclic loadSee more on accendoreliabilityAuthor Mike SondaliniPublished Jan 02,2018Metal Fatigue Failure Theory and Design ConsiderationsMetal Fatigue Failure Theory and Design Considerations This article is a basic introduction to the mechanism of metal fatigue failure where parts break after a period of time in service.Explanations of accepted theories are provided and relevant design practices to reduce metal fatigue areMetal Fatigue - W metal fatigue failure theory and design considerations#246;hler Plot and Mechanisms - YenaThe meaning of the fatigue limit is vital for the design considerations since the safety of the components can be ensured by calculating the endurance limit value for corresponding stress amplitude values.When the curve moves along a horizontal direction,below regions ofLecture 4 Cyclic loading and fatiguethe previous lecture is to have a fatigue strength of ,then we design the cross-sectional area at limit load (10000 lb) to be which is a larger area than obtained from static design considerations. a = aN() f b m = 0 a = 122 ksi b = 0.102 N f = 106 a = 29.8 ksi 29.8 ksi A 10000 lb 29800 lb/in2 = -----= 0.3356 in2\nIV.Fatigue failure One of the more common causes of shaft failure is due to fatigue.Metal fatigue is caused by repeated cycling of the load .It is a progressive localized damage due to fluctuating stresses and strains on the material.Metal fatigue cracks initiate and propagate in regions where the strain is most sever.File Size 745KBPage Count 8Fatigue - ASM InternationalFatigue FATIGUE FAILURES OCCUR due to the application of uctuating stresses that are much lower than the stress required to cause failure during a single application of stress.It has been estimated that fatigue contributes to approxi-mately 90% of all mechanical service failures.Fatigue is a problem that can affect any part or component that moves.Fatigue issues in aircraft maintenance and repairsMany design considerations are involved in ensuring structural integrity of Boeing jet transports,which have common design features validated by extensive analyses,tests,and service performance.Designing for continued structural integrity in the presence of damage such as fatigue or corrosion is an evolutionary process.\nNov 30,2020 metal fatigue failure theory and design considerations#0183;An approach to address these factor relies on the application of fatigue failure criteria,which can be based,for instance,on energy 22 or stress considerations.23 The fatigue criteria can be carried using nominal values 24 or local approaches 25 (e.g.,theory of critical distances).Fatigue and static failure considerations using a topology Feb 01,2015 metal fatigue failure theory and design considerations#0183;Although fatigue failure is one of the most important design considerations to ensure the safety of a mechanical structure,it has rarely been considered in terms of topology optimization due to several major theoretical and numerical difficulties.Fatigue analysis Guide - FEA for AllExamples of fatigue failure All structures and mechanical components that are cyclically loaded can fail by fatigue.Fundamental requirements during design and manufacturing to avoid fatigue failure are different for each different case and should be considered during the design phase.\nExamples of fatigue failure All structures and mechanical components that are cyclically loaded can fail by fatigue.Fundamental requirements during design and manufacturing to avoid fatigue failure are different for each different case and should be considered during the design phase.Fatigue Testing - ASM Internationalan infinite number of cycles without failure.Fatigue Limit and Fatigue Strength.The hor metal fatigue failure theory and design considerations#173; izontal portion of an S-N curve represents the maximum stress that the metal can withstand for an infinitely large number of cycles with 50% probability of failure and is known as the fatigue (endurance) limit,Sp Most nonferrous metals doFatigue Failure Mechanism and Theories MetallurgyInvariably fatigue failure begins as irregularities on the surface of metals,which act as stress raisers,and at points of high stress or stress concentration.The basic mechanism in fatigue is slip.Commercial metals are composed of aggregation of small crystals with random orientations.\nYukitaka Murakami,in Metal Fatigue (Second Edition),2019.Abstract.The problems of fatigue crack growth resistance under mixed mode loading will be exclusively treated in this chapter.Fatigue failures of Mode II and Mode III are observed mostly in contact loading machine components such as bearings,gears,rail road rails,and steel making rolls.The major loading in these components is cyclicFatigue :Failure under fluctuating / cyclic stressFatigue failure is brittle-like (relatively little plastic deformation) - even in normally ductile materials.Thus sudden and catastrophic! Fatigue failure proceeds in three distinct stages crack initiation in the areas of stress concentration (near stress raisers),incremental crack propagation,final catastrophic failure.Fatigue (material) - WikiMili,The Best Wikipedia ReaderThe failure was a result of metal fatigue caused by the repeated pressurisation and de-pressurisation of the aircraft cabin. Incorporating design considerations in the development phase can reduce failures due to fatigue in welded joints. K.J.(1973).A theory for fatigue failure under multiaxial stress-strain conditions.Proceedings\nIn other words,when designing with composite parts,fatigue isnt as much of a concern as it is when youre designing with metal.If youre designing a component to made of aluminum or steel,the vast majority of failures will be fatigue driven,and so the fatigue life is a critical consideration.DESIGN TO PREVENT FATIGUE - SolidWorksPhysical testing is clearly impractical for every design.In most applications,fatigue-safe life design requires prediction of component fatigue life that accounts for predicted service loads and materials.Computer-aided engineering (CAE) programs use three major methods to determine the total fatigue life.These are Stress life (SN)Course on Metal Fatigue Analysis Theory and Simulation Apr 28,2020 metal fatigue failure theory and design considerations#0183;Growing market is demanding more engineered products in a shorter design cycle,with longer life,durable,reduced cost and with better performance and competitive.Which encourages designers,researchers to explore more and more realistic solutions,techniques and procedures to ensure the consumer demand is achieved.Material in Design plays a major role in the design cycle\nFatigue life could be measured in terms of hours or years,respectivelywith both having a similar cycle count at failure.Fig.1 Typical local stress history .Early test data showed a distinct relationship among the stress amplitude (S),the cycle count (N) and the expected fatigue life.Cited by 22Publish Year 2015Author Seung Hyun Jeong,Dong Hoon Choi,Gil Ho YoonMaterial Fatigue Strength - Limits Failure Explained Understanding Fatigue Failure.Fatigue failure is something everyone has encountered while trying to break a metal wire.The process includes bending the wire back and forth numerous times.Each back-and-forth bending is one cycle.When the wire finally breaks,you can count the number of cycles it took to lead to the initial crack and final break.Chapter 7.Mechanical Properties of Metals II Fracture Failure occurs when cross sectional area of the metal too small to withstand load Fatigue the phenomenon leading to fracture under repeated stresses having the maximum value less than the ultimate strength of the material Different types of stress cycles are possible axial,torsional and flexural Fatique-fractures surface of steel shaft\nenergy theory.Out of these four theories of failure,the maximum normal stress theory is only applicable for brittle materials,and the remaining three theories are applicable for ductile materials.The failure theories have been formulated in terms of three principal normal stresses (S1,S2,S3) at a point.Chapter 2 Working Stress and Failure Theories Aenergy theory.Out of these four theories of failure,the maximum normal stress theory is only applicable for brittle materials,and the remaining three theories are applicable for ductile materials.The failure theories have been formulated in terms of three principal normal stresses (S1,S2,S3) at a point.Basic structural design considerations and properties of For 0.8% probability of failure in annealed glass,a design factor of 2.5 is used against the averaged stress.For 0.1% of failure,the design factor is 5.For sloped glazing,the 0.1% failure probability of failure is commonly used. Glass strength is time dependent\nFatigue failure of bolted joints can result from either cracking or self-loosening and can be prevented by appropriate design and fabrication methods.Fatigue design rules for bolted joints are available in a number of Standards.In the UK,BS 7608 'Code of practice for fatigue design and assessment of steel structures' covers bolted,welded and riveted joints.A STATISTICAL INVESTIGATION OF FATIGUE BEHAVIOURA STATISTICAL INVESTIGATION OF FATIGUE BEHAVIOUR ACCORDING TO WEIBULLS WEAKEST-LINK THEORY Anders Wormsen and Gunnar H metal fatigue failure theory and design considerations#228;rkeg metal fatigue failure theory and design considerations#229;rd Department of Machine Design and Materials Technology Norwegian University of Science and Technology NO-7491 Trondheim,Norway [email protected],[email protected] AbstractA Review on Fatigue Life Prediction Methods for MetalsMetallic materials are extensively used in engineering structures and fatigue failure is one of the most common failure modes of metal structures.Fatigue phenomena occur when a material is subjected to fluctuating stresses and strains,which lead to failure due to damage accumulation.Different methods,including the Palmgren-Miner linear damage rule- (LDR-) based,multiaxial and variable\nAbstract Metallic materials are extensively used in engineering structures and fatigue failure is one of the most common failure modes of metal structures.Fatigue phenomena occur when a material is subjected to fluctuating stresses and strains,which lead to failure due to damage accumulation.A Review of Fundamental Shaft Failure AnalysisThis paper is an analysis of failure of main shaft of locomotive turbo charger.The fracture position is located at a groove between journals with different diameter.The rotating bending fatigue is the dominant failure mechanism of the shafts.Detailed metallurgical analysis indicates that fillet region of the groove had subjected toA Constructive Empirical Theory for Metal Fatigue under A constructive empirical theory for metal fatigue under block cyclic loading By Navendu Patil,Pradeep Mahadevan* and Anindya Chatterjee Mechanical Engineering,Indian Institute of Science,Bangalore 560 012,India Much modern engineering design work uses S-N curves and empirical applications thereof.\n1829 Albert,the German mining engineer,performed the first probable study of metal fatigue [2.6].He rendered repeated load proof tests on mine-hoist chains made of iron.1839 Poncelet introduced the term fatigue in connection with metal failure.1843 W.J.M.Rankine,a British railway engineer,recognized the distinctive characteristics10 Tips to prevent fatigue failure in your mechanical First,it is necessary to keep in mind that any variation in part or mechanical component sectionsA parts geometry will also affect the speed at which that crack will propagate.A design thatThe design also has a significant influence in fatigue failure.Any geometric discontinuity acts as aAvoiding structural irregularities or revising the design,eliminating sharp changes along the edgesThe dimensions of the part also play a part; increasing their size results in a lower fatigue limit.Improve the surface finish by polishing,to prevent small scratches or grooves that appear on aSurface hardening via carburization and nitriding processes where a component is exposed to aFluctuating or cyclic stress are another aspect to keep in mind.Their loads act for a great numberAn intermediate tensile stress worsens fatigue-related performance in metals since it widens theIncrease performance by means of residual compression stress on a thin surface layer.TheDISTRIBUTED BY National Technical Information Serviceproblem of metal fatigue failure criteria is far from resolved.In contrast to metals,fiber reinforced materials are heterogeneous and anisotropic.It is therefore unfortunately to be expected that the problem of fatigue failure in these materials is even more difficult than for metals.For recent review see e.g..(PDF) Fatigue failure in aircraft structural componentsmetal fatigue are at the lowest level with respect to the failures happened before .Fatigue in metallic materials develops under three stages which are crack nucle- ation,crack propagation\nFatigue cracks once initiated often grow in an insidious manner resulting in failures with serious implications.The technical problems,economic and potential human losses which accompany fatigue failures make its consideration during materials design of utmost importance if the challenges associated with its occurrence are to be mitigated .""]"	['<urn:uuid:992bd318-9e45-4cf5-971a-6b5e6cad5caa>']	factoid	with-premise	long-search-query	similar-to-document	single-doc	expert	2025-05-12T15:09:02.012753	14	53	2414
89	what problems happen if air conditioning system too small indoor growing facility	If you undersize your environmental control system, it can lead to significant problems. Many HVAC companies calculate cooling systems based on square footage and comfort cooling rather than process cooling loads. In indoor cultivation, the numerous lights and support equipment produce heat in each room, increasing the overall heat-load to rates much higher than typical. This puts stresses on HVAC equipment that were likely not accounted for during original sizing. Downtimes can be long, and the renovations to infrastructure can be very costly.	['While starting a new commercial cannabis cultivation operation may seem daunting at first, there are a few simple actions that you can take to make everything go as smoothly as possible. Ideally, all of these things should be planned out before starting to build the grow, but some aspects can be added in phases if start-up finances are limited.\n1. Not Creating a Blueprint\nMany grow operations skip this step for some reason, however this is a grave mistake in our experience. Whether you plan to build from scratch or convert an existing structure, you will need a plan to follow. Creating a blueprint will allow the grow room designer and any contractors that are hired to know exactly what the plan is for the space.\nDuring construction, you will be putting holes in the wall, designing irrigation systems, laying out elaborate electrical infrastructure and implementing a more robust cooling system. All of these things will require proper communication on the part of everyone involved and a blueprint ensures everyone is on the same page.\nInput from a Master Grower is paramount at this stage as having a visual blueprint of the space will allow the grower to make workflow and logistical decisions, both of which determine the proper placement of all of the equipment that will be used and how staff interface with their work environment.\n2. Not Using Water Filtration\nFiltering all water that is used on plants is incredibly important, especially when growing hydroponically. Mineral and chemical content of water can vary widely even within a single city. This makes it difficult to control exactly what a plant receives, and thus absorbs. Indoor cannabis growing is all about controlling every aspect of the grow. Why should the water plants receive be any different?\nIt is recommended to purify and sterilize all water before using it on plants. By doing so, any costly surprises associated with changes in the mineral content of the water being used will be avoided and you will always know exactly what minerals your cannabis plants are receiving and in what quantity.\n3. Not Checking the Electrical Sizing and Design to Find Out if There is Enough Power\nAn indoor cannabis grow consumes a lot of power. As such, it is important to check that your intended location can handle the electrical load or that it is possible to get enough extra electricity if the building is not currently capable of handling the desired load.\nTo check this, look at the number listed on the transformer pole outside the building. This will tell you the maximum amount of power that can be delivered to that building via existing infrastructure. Second, check with the local electricity provider to ensure you are actually able to draw that much power. It is not uncommon for a building to be rated for 400 amps and only actually be able to draw 80% of that power.\nWorking closely with your electrical supply company is necessary for your business to function properly, so get to know them early and establish a good relationship. Make them aware of your upfront needs 6 months or more before you need the power in order to avoid complications or extra wait times. It’s a good idea to let them know of any expansion plans as well so that you don’t experience headaches down the line.\nWhen performing equipment installation, professional electricians should do all electrical work on the building. Cannabis cultivation centers are often under high scrutiny from local authorities who may be looking for any reason to shut the operation down. In order to avoid this, make sure all electrical work is up to code and done by a professional.\n4. Undersizing the Climate Control System\nIf you undersize your environmental control system, it will hurt. Badly. Downtimes can be long, and the renovations to infrastructure can be very costly. Many HVAC companies are used to sizing cooling systems based on the square footage of the space and typically their calculations are based off of comfort cooling rather than process cooling loads.\nCannabis cultivation requires many lights and support equipment that produce heat in each room. In these applications, by increasing the overall heat-load of the room to rates much higher than are typically found outside of indoor cultivation, you are putting stresses on your HVAC equipment that were likely not accounted for during original sizing.\nTo prevent purchasing an undersized cooling system, make sure any talks about the size requirements take into consideration the number of lights and grow equipment in each room in addition to the square footage. Provide a slight oversize padding to give yourself some head room and to account for anomalous weather behavior.\n5. Undersizing Veg Rooms\nWhen designing a cultivation facility, a lot of attention goes into the Flower Rooms and the Veg Rooms occasionally are a bit of an afterthought. However, a proper vegetative space is critical to the success of the Flower Room, and thus the overall success of your business.\nThink of your Veg Room as a staging area for the Flower Room – as soon as the Flower Room is ready, a new batch of plants should be healthy, pest free, fully grown and ready to move into Flower. Assuming that you have knowledge of the strains that you’re growing, you should know how long your plants need to be in a vegetative state to fill the desired square footage in the flower room.\nIf timed correctly, and if quality control procedures are upheld (i.e. environmental maintenance, preventative pest control, etc.), a grower can very effectively uphold a perpetual flowering regimen and experience minimal post-harvest downtime in the bloom rooms. However, this can only be accomplished if there is a solid plant rotation through the Veg Room; if you don’t have enough space there, you will always either experience some downtime in your Flower Room, or your yield per square foot figures will be lower than achievable in that space.\nThese are just a few intricacies behind planning your new cannabusiness, however they will absolutely make or break your bottom line in this new and increasingly competitive market. If you keep the above information in mind from the start, not only will you have a solid business in the end, but you’ll also save a lot of time and money along the way.']	['<urn:uuid:ca6dc65b-79a5-41c0-9d67-8caab66ec3ba>']	open-ended	direct	long-search-query	distant-from-document	single-doc	novice	2025-05-12T15:09:02.012753	12	83	1060
90	bridge construction methods connecticut texas different	The Pearl Harbor Memorial Bridge used an innovative extradosed cable-stayed design with a form traveler construction method, where concrete was poured in sections extending into empty space, causing expected stress-related cracking. The bridge combines box girder design with shorter-than-usual suspension design due to airport proximity. In contrast, the Hurricane Harvey bridge repair in Texas involved selective demolition using concrete cutting methods, where specific portions were safely removed without damaging others, including underwater wire cutting of piles and use of hydraulic shears. This renovation required systematic rebuilding with drilled shafts, caps, beams, deck and barrier walls.	['NEW HAVEN — The Pearl Harbor Memorial Bridge, which beams with patriotic pride on national holidays and historic dates, received only a fair rating two years after it opened.\nAfter its biennial second inspection, which is underway, the state Department of Transportation will undertake a project to repair cracks that, if not sealed, would threaten the integrity of the bridge that opened to great fanfare in 2015.\nThe rating, 6 on a scale of 9, was based on the high number of cracks on the surface of the bridge. Most of them are hairline breaks that formed during construction, but many are big enough, as much as one-sixteenth of an inch wide, to allow water to seep into the interior of the bridge. There are 100 such cracks highlighted on the northbound span and 115 on the southbound side in the reports.\nAccording to the northbound span report, “there are 91,362 linear feet of cracks. 719 feet of cracks have active leakage and … require attention.” On the southbound side, inspectors found 68,177 linear feet of cracks, with 988 feet needing repair. Together, those numbers translate to more than 30 miles worth of cracks, with less than a third of a mile’s worth needing to be sealed.\n“The majority of the cracking occurred during and immediately after the construction,” the report states. “Most of the cracks are shrinkage cracks. Random cracks in the top slab have active leakage.”\nNone of the cracks, and nothing else in the inspection report, threaten the safety of the bridge, according to state Department of Transportation officials. But more maintenance will be needed because of its advanced design.\nAn overall bridge rating is based on the lowest rating of the three main components, in this case the superstructure. A rating of 5 or 6 is defined as fair by the Federal Highway Administration. The deck was rated 7 and the substructure was given an 8, both considered “good.” Other components of the superstructure also were rated 7 or 8, but the concrete girders’ 6 controlled the overall rating.\n“It’s governed by the weakest link right now in the inspection,” said Tim Fields, the principal engineer who oversaw the latter stages of the bridge’s design as well as its construction and is now in charge of the DOT’s major structures division.\nOnce the inspection now underway is complete, the DOT will create a project to seal those cracks that over time would affect the bridge’s integrity, Fields said. “That project will be initiated shortly and hopefully we’ll be out there in two years or less,” he said.\nHe said most of the cracks are “not unexpected” because of the way the bridge was built. Popularly known as the Q bridge, because it crosses the mouth of the Quinnipiac River, it is the first of its kind in this country, and engineers knew the stresses put on it during construction would cause the concrete to crack.\n“Being an extradosed cable-stayed bridge, it’s a unique bridge. There’s not another bridge we could borrow lessons learned from,” said DOT Deputy Commissioner Mark Rolfe, who was the district manager for the New Haven area during the bridge’s construction. In order to limit the bridge towers’ height because of nearby Tweed New Haven Airport, the bridge combines a box girder design with a shorter-than-usual suspension design.\nThe northbound bridge opened in 2012. The southbound span opened three years later.\nRolfe said most of the cracks don’t need attention. “Not all cracks are created equal. What matters a lot is the size of the cracks, where they’re located and if they’re growing.”\nOnce the cracks are sealed, the problem should be solved. and the bridge’s overall rating may actually rise, Rolfe said. “It’s not a today issue. If we left this untreated, it would affect the long-term serviceability of the bridge,” he said.\nThe first inspection of the two spans that make up the bridge, which carry Interstate 95 northbound and southbound, was conducted from May 31 to mid-October 2017 by engineers with the firm HAKS. The report was issued in February 2018.\nConcrete in midair\nThe cracks were inevitable given the construction method used, Rolfe and Fields said. The bridge is composed of huge hollow concrete girders, on which the concrete deck layer rests. The spans were built out from the towers using what’s known as a form traveler, which pours concrete, then moves to pour a new section. The section of each span reaches out into empty space and “the tips of it are deflecting downward” under the weight of the concrete, Rolfe said. These sections extend “up to 250 feet from each tower until they’re finally joined,” Fields said.\nThe downward pressure of the concrete cantilevered girders puts stress on the underside of the structure, he said. Then, once the span is complete and partially supported by the cables, the stress shifts to the top of the girders.\n“There was very high stress during that cantilever construction and some of those high stresses caused some cracking in the concrete, very minor cracking in the vicinity of the stay cables,” Fields said. “Most of the cracks are very fine shrinkage cracks that don’t go all the way through. This is not necessarily a structural issue” but has to do with the nature of concrete, which is strongest under compression.\nThere were “very massive concrete pours that were done,” Fields said. “We weren’t really surprised that we now need to seal some cracks. It shouldn’t be viewed as a structural concern. It should be viewed as a maintenance issue that we’re going to be addressing.”\nJames Falconer, owner of JKF & Associates, an engineering firm in New Haven’s Erector Square, came to the same conclusion when he reviewed the 2,704 pages of the two reports.\n“You’re going to need a lot of maintenance in the beginning, which is not what you’re looking for,” said Falconer, who designed the Route 8 bridge in Naugatuck in 1988 and 120 others, though none as large as the Q bridge. He has been a prequalified engineer with the DOT for 30 years.\nHe said it’s important to seal the cracks “because the ice could get in there and it starts opening. The deterioration goes on and the units get more cracks and it’s not good.”\nHe said the innovative design of the bridge presented new challenges. “When you are doing a new procedure, you are running the risk of all of a sudden you start getting problems,” he said.\n“We had anticipated the uniqueness of the structure and developed some principles for our inspectors,” Rolfe said. The guidelines were included in a draft “owner’s manual,” as it’s referred to in the inspection report.\n“We needed to learn from the inspection on the bridge where we needed to better define the inspection procedures, where the problem areas [were] where we needed more detail, so we could refine and improve the manual going forward,” he said.\nThe manual “talks about the severity of different types of cracks,” Rolfe said. “It left a fair amount of discretion to the evaluator as to what rating to assign.” He said the inspectors were conservative in their grades when they rated the girders at the “high end of satisfactory rather than the low end of good.”\nAs an example that “the rating that was applied to this bridge was very conservative,” Rolfe said, “the foundation system for the bridge is part of the evaluation. … There is no evidence of any settlement whatsoever on this bridge. It should have been rated a 9.” But the lack of settlement — a major issue if it had occurred — was rated at 8.\nSince the Q bridge opened, others have been built, including a bridge over the St. Croix River between Oak Park Heights, Minn., and St. Joseph, Wis. While the Q bridge has two sets of towers with cables, the St. Croix bridge has five. The engineers on that project consulted with the Connecticut team during the Q bridge’s construction, Rolfe said. There is also an extradosed bridge over the Brazos River in Waco, Texas, he said.\nRolfe said “there were multiple levels of review” in designing and building the bridge. The design was by AECOM (formerly URS Corp.) and it was built in a joint venture between Walsh Construction and PCL Civil Constructors. The total cost was more than $550 million. “We commissioned a peer review of that design” by WSP, based in Montreal, he said.\n“Are we happy that we have these cracks out there? No, absolutely not. But it’s part of the maintenance of the bridge,” Rolfe said.\n“The cracking is essentially superficial and when you have addressed the cracks, then you have addressed the long-term condition,” said Fields.\nBelow the radar\nRolfe also said senior DOT officials did not get the news of the inspection rating as soon as they should have. “It was below the radar,” he said. “Did it come to my attention right away when it went from a 7 to a 6? It did not.”\nHe said procedures have been changed to require a higher-level official sign off on major bridge inspections. “There were other folks here that were keenly aware of it, but they didn’t raise it” to senior-level staff. “It would have been nice to have the conversation in draft form,” he said.\nFields said any delay in repairing the cracks is outweighed by having new data from the current inspection. “I think the timing is good to take advantage of the 2019 report,” he said. “We’ll be able to take advantage of the most current bridge inspection data.”', 'Concrete Cutting Contractor Tackles Savage Hurricane Aftermath\nWho could forget the absolute destruction Hurricane Harvey caused when it hit Texas on August 25, 2017? The massive storm brought with it not only damaging hurricane-force winds of up to 130 mph, but an incredible 51 inches of rainfall, all in just a short few days. With such a heavy amount of rainfall, all area rivers, ditches and dams overflowed their banks, causing mass flooding and devastation the area had never experienced before. Waterways like the idyllic San Jacinto River, which normally could be fished with waders, became raging torrents, carrying with them trees and debris as the water raced down to the Gulf of Mexico.\nAs all storms eventually do, Harvey dissipated, and the water levels began to recede. At this point it was crucial that the infrastructure of bridges in the area be promptly inspected for any potential damage caused by the flooding. One bridge, the Highway 59/Interstate 69 Bridge in Humble, Texas, was of immediate concern because of the tons of debris that had collected on and around its piers, columns and piles. After a thorough inspection of the structure, it was determined that the increased water flow and rate of speed had scoured the river bottom from around the piles. This was a river that used to be just 15-20 feet deep under the bridge, that had now doubled to 30-40 feet. The bridge’s piles, that used to be well embedded into the river bottom, now had less than 50 percent embedment. Consequently, the bridge was now highly unstable and could have fatal consequences if not tended to right away.\nSince the condition of the bridge posed serious hazards, repair became a top priority. Quotes were tendered for an emergency renovation, which would involve selectively removing the center three spans of the bridge that were located directly over the river channel. As a major highway route leading in and out of Houston, this project was deemed extremely time-sensitive by the Texas Department of Transportation who allotted only 113 days for the bridge to be closed to traffic. When general contractor Webber LLC was awarded the project, they knew concrete cutting would be the ideal method of selective demolition due to its ability to safely remove specific portions of the bridge without damaging others. Now all they needed was to contract a concrete cutting company for the demolition portion of the project with a track record of producing quality work within a narrow timeline. That’s when they called CSDA member Aggregate Technologies, Inc..\nAggregate has highly experienced management, staff and operators, all backed by a wide variety of equipment and technology. For these reasons Aggregate was the perfect contractor for the job! Webber tasked Aggregate with taking down the required three spans of the bridge from the top deck and performing underwater wire cutting of the piles as well. Prior to making their first cut, Aggregate had to consider safety, efficiency and speed while determining which methods and procedures they’d use to acco\nmplish the tasks of this important job.\nBefore Aggregate could begin their portion of the work, Webber had to tackle the bridge deck. Webber started demolition by hammering the bridge deck into rubble with a hoe ram attached to an excavator. The rubble was dropped onto a barge tethered in the river underneath the bridge and then collected and removed with the use of a skid steer loader. Next, the main beams were lifted by crane out of place and removed from the site. This left three sets of bents, caps, columns, footers and piles for Aggregate to cut and remove, with each bent consisting of three separate structures. The original bridge had been widened twice, once on the outside and once on the inside. A different design was used on each widening phase, leaving Aggregate working on a variety of different piles, caps and piers. Meticulous attention to detail and regularly adjusting equipment during the duration of this project were determining factors in completing the job on time.\nAggregate used Diamond Products wire saws with wire lengths between 35 and 60 feet to cut the caps and piers first. Then, they continued wire cutting the piles that were underwater, to ready the footers to be lifted off and removed by crane. Finally, Aggregate operators used Prime Marine Services Model 24 hydraulic shears to cut the piles off at the mudline.\nOnce the first set of piers was removed, new drill shafts were installed and the drilling and demolition continued simultaneously until all the old structures were removed. The job certainly wasn’t without its challenges though. The changing tides required operators to make constant alterations to just about everything on the job site. Tools and equipment had to be adjusted regularly. Additionally, barges and cranes had to be simultaneously maneuvered, within very tight spaces, so each operator could continue their respective operations safely.\nOnce Agregate completed all their cutting tasks, it was time for Webber LLC to step in again. Webber systematically rebuilt the bridge like a large LEGO set: drilled shafts, placed caps, beams, deck and barrier walls, then voila! The new bridge was ready for traffic again. Take that, Hurricane Harvey!\nThe Texas Department of Transportation had allowed for liquidated damages should the project go past the allotted time. They also offered a performance bonus for every day under the 113-day time limit, up to a maximum of 10 days. Not only was the bridge completed and reopened to traffic on time, but the full 10-day performance bonus was presented to Aggregate for their efforts. Great job, guys!\nProject manager, Greg Major, praised the project saying, “This job went very well for us despite the challenges of working within close proximity to Webber LLC and our respective work schedules. I believe the experience and professionalism of our operators was a key factor in this project meeting its goals and expectations.”\nAggregate Technologies, Inc. has been in business for 20 years and a CSDA member since 2013. Headquartered in Houston, TX, they offer a variety of services including: core drilling, wire sawing, wall sawing, slab sawing, pile cutting, GPR scanning, hydro-demolition, concrete demolition and select robotic demolition. They currently operate with 35 employees and while they perform most of their work in Texas, they are available for jobs nationwide.\nThe Woodlands, TX\nCSDA Cutting Contractor\nAggregate Technologies, Inc.\nWire sawing, hydraulic shears']	['<urn:uuid:174f263a-6909-4e5a-aa23-63cf54fc64fc>', '<urn:uuid:b8745cd4-e50a-4805-8678-111b881cc4f5>']	open-ended	direct	short-search-query	distant-from-document	comparison	novice	2025-05-12T15:09:02.012753	6	95	2674
91	What mathematical principles connect earthquake analysis and radiometric dating?	Both earthquake analysis and radiometric dating rely on logarithmic principles. Earthquake frequency and magnitude relationships are plotted using logarithmic scales to handle large value ranges, while radiometric dating uses the concept of exponential decay through half-lives to calculate ages, with different isotopes decaying at known rates into daughter products.	"['earthquakes, floods and flooding\n, grain sizes/sedimentology, radioactive decay\n, population growth\n, changes in atmospheric CO2\n, decibel scale, pH scale\nTeaching logarithms (logs)by Dr. Eric M. Baer, Geology Program, Highline Community College\nJump down to: Teaching strategies\n| Materials & Exercises\n| Student Resources\nLogarithms are the inverse of the exponential function. Originally developed as a way to convert multiplication and division problems to addition and subtraction problems before the invention of calculators, logarithms are now used to solve exponential equations and to deal with numbers that extend from very large to small in a more elegant fashion. For more information on exponential functions, go to the Exponential Growth and Decay page.\nThe logarithm function (log\n) is defined by\n- y=logb(x) if and only if x=by\nand x>0, b>0 and b not equal to 1.\nThe function is read\nand is read ""y is the log base b of x""\nWhen no base (b) is noted, the assumed base is 10. Thus,\n- y=log(x) is the same as y=log10(x)\nWhen the base is the number e\n(~2.71...), the logarithmic function is called the ""natural logarithm"" and notated as ln\n- y=loge(x) is written y=ln(x)\nThere are some properties of logarithmic functions that may be helpful for solving problems with logs.\n- logbbx = x\n- logbb = 1\n- logb1 = 0\n- blogbX = X\nTeaching Strategies: Ideas from Math Education\nPut quantitative concepts in context\nThere are a number of geologic contexts in which logs are used and can be introduced. Some of these include:\nUse multiple representations\nBecause everyone has different ways of learning, mathematicians have defined a number of ways that quantitative concepts can be represented to individuals. In the geosciences, logarithms are most commonly represented graphically.\n- Graphical representation:\nEarthquake frequency vs. magnitude. Details\nOne of the most common ways that geoscientists use logarithms is to plot data on a logarithmic scale. This is used when the values on a graph span large values. An example is the number of earthquakes per year of various magnitudes, plotted to the right. The values of the individual data points are unreadable because of the arithmetic scale.\nLog of earthquake frequency vs. magnitude. Details\nUsing a logarithmic scale allows closer estimation of many of the values. However, this graph may be more difficult for students to interpret because most authors of logarithmic graphs plot data on a logarithmic scale but label the axis with non-log numbers. Students will need to be warned about this because they will often not realize that the scale is logarithmic. To find the actual location or value of a point on a logarithmic graph, the log of the original number must be calculated. This makes it very difficult for students to figure out the exact value of points, plot additional points, and can even cause misinterpretation - for example on this graph, students might think that there is a linear relationship between the frequency and magnitude of earthquakes when there is not.\nEarthquake frequency vs. magnitude\nRarely is the axis clearly and correctly marked with the log values, as it is in this graph.\n- Log-normal graphical representation:\nMany graphical representations of logarithms are constructed with only one axis being logarithmic. A exponential function (y=10x\n) will plot as a line on a log-normal (also called semi-logarithmic) graph.\nThe Gutenburg-Richter relationship on a log-normal graph\nAccording to the Gutenburg-Richter relationship, the frequency between earthquakes (L) and the magnitude of earthquakes (M) is related by\nThus a plot of magnitude and frequency of earthquakes plots as a straight line on a log-normal graph.\n- Log-log graphical representation:\nSome graphs have two logarithmic axes. These are often called ""log-log graphs."" A good example is Hjulstrom\'s diagram which shows the stream velocities at which sediments will be eroded, transported and deposited.\n- Algebraic/numerical representation:\nThe secret to logs is getting the algebraic representation down, so that one can convert between the log function and the exponential function. Students will need assistance in remembering this pattern. As an example, I show students\n- 32=9 is the same as 2=log39\nI think the use of colored chalk when writing these numbers helps. Some students also find the phrase ""ex\nponent and equ\nal"" helpful in remembering this relationship since the exponent (2 in the above example) is followed by the equals sign when converting it to the logarithmic notation.\nUse technology appropriately\nStudents have any number of technological tools that they can use to better understand quantitative concepts – from the calculators in their backpacks to the computers in their dorm rooms. Logarithms can make use of these tools to help the students understand this often difficult concept.\n- Graphing calculators\nGraphing calculators are an easy way for all students to enter data and to see what a curve of that data looks like. All graphing calculators are slightly different and students may need help with their particular model. There are some helpful hints for some calculators at Prentice-Hall\'s Calculator help website (more info)\n. Note that very few calculators will calculate logs in bases other than 10 or e\n. In addition, many problems in logarithms are easier to solve in one\'s head than typing into a calculator correctly.\nLogarithms provide an excellent opening for an introduction to the use of spreadsheet programs. Students are likely to encounter spreadsheet programs in many of their classes and they are excellent tools for visualizing the shape of an equation. Excel has an option to switch to logarithmic axes which can be useful for quickly illustrating the usefulness of logarithms in the analysis of data.\nWork in groups to do multiple day, in-depth problems\nMathematicians also indicate that students learn quantitative concepts better when they work in groups and revisit a concept on more than one day. Therefore, when discussing quantitative concepts in entry-level geoscience courses, have students discuss or practice the concepts together. Also, make sure that you either include problems that may be extended over more than one class period or revisit the concept on numerous occasions.\nLogarithms are a concept that comes up over and over in introductory geoscience: radioactive decay, Richter magnitude, pH scale, etc. When each new topic is introduced, make sure to point out that they have seen this type of function before and should recognize it.\nTeaching Materials and Exercises\n- Determining Earthquake Probability and Recurrence\nA homework/classroom activity where students collect historical earthquake information and use it to forecast the probability of larger earthquakes.\n- Using functions in an introductory geoscience course\nA template and set of exercises designed to help faculty increase the graphical literacy of their students. Two exercises are included - population growth and atmospheric CO2 increase - for help in teaching exponential growth and decay. The template gives general guidelines for teaching students the relationship between functions and their graphical representation.\n- Scaling Galileo\'s Solar System - Size of the Globes\nIn this module, students determine the sizes of the various planets in the solar system scaled such that the orbit of Saturn fits on campus. The students also compare the planet sizes, given the scale, to the grain sizes of different sediment types. It includes plotting on logarithmic axes in excel.\n- Two streams, two stories... How Humans Alter Floods and Streams\nStudents plot stream flow data on logarithmic axes in order examine flooding.', 'But how is it dated? What does radiometric dating actually mean? And what methods of dating can be used to date which kinds of items?\nWhat is radiometric dating?\nRadiometric dating is a method of establishing how old something is – perhaps a wooden artefact, a rock, or a fossil – based on the presence of a radioactive isotope within it.\nThe basic logic behind radiometric dating is that if you compare the presence of a radioactive isotope within a sample to its known abundance on Earth, and its known half-life (its rate of decay), you can calculate the age of the sample.\nRadiometric dating is useful for finding the age of ancient things, because many radioactive materials decay at a slow rate.\nWhat is radioactive decay?\nRadioactive atoms are unstable, meaning they decay into “daughter” products. The number of protons or neutrons in the atom changes, leading to a different isotope or element. The time it takes for one half of the atoms to have decayed is referred to as a “half-life”.\nWe know the half-lives of the radioactive isotopes found on Earth, and so we can trace how long a radioactive material within an object has been decaying for, and therefore how long (within a range of error) it’s been since the object was formed.\nSome radioactive materials decay into daughter products that are also radioactive, and have their own half-life: the result is called a “decay-chain”, which eventually decays into a non-radioactive substance.\nTypes of radiometric dating\nRadiocarbon (14C) dating\nYou’ve almost definitely heard of “carbon dating”. It’s a very common method used mostly by archaeologists, because it can only date relatively recent materials.\nRadiocarbon dating is possible because all living things take in carbon from their environment, which includes a small amount of the radioactive isotope 14C, formed from cosmic rays bombarding nitrogen-14.\nWhen an animal or plant dies, it will not take in any more carbon, and the 14C present will begin to decay. We can thus measure how long it’s been since the animal or plant died by comparing the presence of 14C with the known half-life.\nThis can raise complexities in archaeology when, for example, a society uses a piece of wood that was felled hundreds of years prior. There are also issues because the rate of cosmic ray bombardment of the planet over time has not always been stable: but this problem is largely redressed by a calibration factor.\nRadiocarbon dating is not suitable for dating anything older than around 50,000 years, because 14C decays quickly (its half-life is 5,730 years) and so will not be present in significant enough amounts in older objects to be measurable.\nRadiocarbon dating identified Ötzi, the Italian-Alps Iceman, as a 5,300-year-old traveller. More recently, Australian scientists used radiocarbon dating to figure out the age of wasp nests in rock art, and thereby establishing a date range for the art.\nPotassium-argon and argon-argon dating\nPotassium-argon dating is a method that allows us to calculate the age of a rock, or how long ago it was formed, by measuring the ratio of radioactive argon to radioactive potassium within it.\nRadioactive potassium (40K – a solid) decays to radioactive argon (40Ar – a gas), at a known rate. When volcanic rocks are formed and cooled, all argon within the rock is released into the atmosphere, and when the rock hardens, none can re-enter.\nThis means that any argon present in a volcanic rock must have been produced by the decay of radioactive potassium, so measuring the ratio can enable a scientist to date the sample.\nThis method is limited, because it’s only applicable to volcanic rocks, but is useful for older archaeology because it has a date range of about 4.3 billion to 100,000 years ago.\nHowever, there are potential issues with potassium-argon dating. For example, deep-sea basalts retain some argon after formation due to high hydrostatic pressure, and other rocks may incorporate older “argon-rich” material during formation.\nArgon-argon dating is an updated method, based on the original K-Ar dating technique, that uses neutron irradiation from a nuclear reactor to convert a stable form of potassium into the argon isotope 39Ar, and then measures the ratio of 40Ar to 39Ar.\nArgon-argon dating was used to determine that the Australopithecus Lucy, who rewrote our understanding of early hominin evolution, lived around 3.18 million years ago.\nThis technique involves measuring the ratio of uranium isotopes (238U or 235U) to stable lead isotopes 206Pb, 207Pb and 208Pb. It can be used to determine ages from 4.5 billion years old to 1 million years old. This method is thought to be particularly accurate, with an error-margin that can be less than two million years – not bad in a time span of billions.\nU-Pb dating can be used to date very old rocks, and has its own in-built cross-checking system, since the ratio of 235U to 207Pb and 238U to 206Pb can be compared using a “concordia diagram”, in which samples are plotted along a straight line that intersects the curve at the age of the sample.\nU-Pb dating is most often done on igneous rocks containing zircon. It’s been used to determine the age of ancient hominids, along with fission-track dating.\nThis method involves examining the polished surface of a slice of rock, and calculating the density of markings – or “tracks” – left in it by the spontaneous fission of 238U impurities.\nThe uranium content of the sample must be known; this can be determined by placing a plastic film over the polished slice and bombarding it with slow neutrons – neutrons with low kinetic energy. This bombardment produces new tracks, the quantity of which can be compared with the quantity of original tracks to determine the age.\nThis method can date naturally occurring minerals and man-made glasses. It can thus be used for very old samples, like meteorites, and very young samples, like archaeological artefacts.\nFission-track dating identified that the Brahin Pallasite, a meteorite found in the 19th century in Belarus – slabs of which have become a collectors item – underwent its last intensive thermal event 4.26–4.2 billion years ago.\nThis method involves calculating the prevalence of the very rare isotope chlorine-36 (36Cl), which can be produced in the atmosphere through cosmic rays bombarding argon atoms. It’s used to date very old groundwater, from between around 100,000 and 1 million years old.\nChlorine-36 was also released in abundance during the detonation of nuclear weapons between 1952 and 1958. It stays in the atmosphere for about a week, and so can mark young groundwater from the 1950s onwards as well.\nLuminescence dating methods are not technically radiometric, since they don’t involve calculating ratios of radioactive isotopes. However, they do use radioactive material.\nThese methods date crystalline materials to the last time they were heated – whether by human-made fires or sunlight.\nThis is possible because mineral grains in sediments absorb ionising radiation over time, which charges the grains in “electron traps”. Exposure to sunlight or heat releases these, removing the charges from the sample.\nThe material is stimulated using light (optically stimulated luminescence) or heat (thermoluninescence), which causes a signal to be released from the object, the intensity of which can provide a measure of how much radiation was absorbed after the burial of the material – if you know the amount of background radiation at the burial site.\nThis method can date archaeological materials, such as ceramics, and minerals, like lava flows and limestones. It has a normal range of a few decades to 100,000 years old, but some studies have used it to identify much older things.\nOther types of radiometric dating\nThere are several other radioactive isotopes whose ratios can be measured to date rocks, including samarium-neodymium, rubidium-strontium, and uranium-thorium. Each of these have their own advantages and idiosyncrasies, but they rely on the same logic of radioactivity to work.\nThe Royal Institution of Australia has an Education resource based on this article. You can access it here.\nAmalyah Hart has a BA (Hons) in Archaeology and Anthropology from the University of Oxford and an MA in Journalism from the University of Melbourne.\nRead science facts, not fiction...\nThere’s never been a more important time to explain the facts, cherish evidence-based knowledge and to showcase the latest scientific, technological and engineering breakthroughs. Cosmos is published by The Royal Institution of Australia, a charity dedicated to connecting people with the world of science. Financial contributions, however big or small, help us provide access to trusted science information at a time when the world needs it most. Please support us by making a donation or purchasing a subscription today.']"	['<urn:uuid:fb3696ac-8f29-4cdc-9962-5de81c89e357>', '<urn:uuid:14aa7cac-c5d6-4d9d-b31f-461799cb2586>']	factoid	with-premise	concise-and-natural	similar-to-document	multi-aspect	expert	2025-05-12T15:09:02.012753	9	49	2670
92	common signs symptoms sarcoidosis lungs	The common symptoms of pulmonary sarcoidosis include shortness of breath, a persistent cough that won't go away, chest pain, and can cause loss of lung volume and abnormal lung stiffness	"[""What is sarcoidosis?\nSarcoidosis is a rare disease that results from inflammation. Currently, the cause is unknown. It usually develops between 20 and 40 years of age. Almost 90 percent of the cases of sarcoidosis are found in the lungs and lymph nodes, but it can occur in almost any organ. It causes small lumps, or granulomas, which generally heal and disappear on their own. However, for those granulomas that do not heal, the tissue can remain inflamed and become scarred, or fibrotic.\nPulmonary sarcoidosis can develop into pulmonary fibrosis, which distorts the structure of the lungs and can interfere with breathing. Bronchiectasis, a lung disease in which pockets form in the air tubes of the lung and become sites for infection, can also occur.\nWhat are the symptoms of sarcoidosis?\nMost sarcoidosis patients do not have symptoms and probably are unaware they have the disease. Pulmonary sarcoidosis can cause loss of lung volume (the amount of air the lungs can hold) and abnormal lung stiffness.\nThe following are the most common symptoms for sarcoidosis. However, each individual may experience symptoms differently. Symptoms may include:\nShortness of breath\nCough that will not go away\nSkin rashes on face, arms, or shins\nInflammation of the eyes\nPain in the chest, joints, and bones\nSwollen lymph nodes\nThe symptoms of sarcoidosis may resemble other conditions or medical problems. Consult your doctor for a diagnosis.\nWho is at risk for sarcoidosis?\nSarcoidosis occurs in all races and both genders, but the most susceptible populations seem to be of African-American, Scandinavian, or Asian origin.\nDiagnosis of sarcoidosis\nIn addition to a complete medical history and physical examination, diagnostic procedures may include:\nChest X-ray. A diagnostic test which uses invisible electromagnetic energy beams to produce images of internal tissues, bones, and organs on film.\nPulmonary function tests. Diagnostic tests that help to measure the lungs' ability to move air into and out of the lungs effectively. The tests are usually performed with special machines into which the person must breathe.\nBlood tests. To analyze the amount of carbon dioxide and oxygen in the blood.\nBronchoscopy. A long, thin, flexible tube with a light at the end is put into the lung. This allows the doctor to look at the tissue lining the air passageways. Lung tissue samples (biopsies) and lung washings (lavage) that contain lung cells from the lungs can be done through the bronchoscope.\nBronchoalveolar lavage. A procedure in which a sterile saline solution is put into the lungs through a bronchoscope (a flexible tube for examining the bronchi) and then suctioned out. The bronchoalveolar lavage may be performed to diagnose lung conditions and infections.\nBiopsy. A test in which a small piece of abnormal tissue is taken out and checked under a microscope.\nSarcoidosis is usually diagnosed by elimination. That is, other lung disorders that have similar symptoms are progressively eliminated, leading to a diagnosis of sarcoidosis.\nTreatment for sarcoidosis\nSpecific treatment will be determined by your doctor based on:\nYour age, overall health, and medical history\nExtent of the disease\nYour tolerance for specific medications, procedures, or therapies\nExpectations for the course of the disease\nYour opinion or preference\nDifferent treatments work better for different people. Sometimes more than one treatment is used, and in many cases, no treatment is needed. Most medications used to treat sarcoidosis suppress the immune system.\nTreatment may include the use of corticosteroids, such as prednisone. Other medicines, such as methotrexate, may be used if corticosteroids do not work, you wish to avoid side effects of corticosteroids, or your sarcoidosis gets worse.""]"	['<urn:uuid:32b43dfe-335a-48c9-91e6-ad57e4e7795b>']	factoid	with-premise	short-search-query	similar-to-document	single-doc	novice	2025-05-12T15:09:02.012753	5	30	595
93	eds meds jobs growth since 1940	The Eds and Meds sector has not declined once in employment on an annual basis since 1940, growing its job total by 500 percent and adding 18.8 million jobs in the past 50 years.	"['A new CBRE report indicates that cities with higher concentrations of education and medical jobs can navigate hard times a lot more easily when it comes to fluctuating retail and apartment rents.\nSuch areas as Philadelphia, Pittsburgh, St. Louis, New York and Baltimore showed some of the smallest rent declines during the Great Recession.\n“The secular expansion of the Eds-&-Meds industry is impressive, from an increasing presence in downtown office towers and suburban shopping centers to multifamily units occupied by doctors and researchers,” said Ian Anderson, CBRE Director of Research and Analysis in Philadelphia, and a co-author of The Eds & Meds Cure for Market Volatility along with Spencer Levy, CBRE\'s Americas head of research. “Not only does this sector provide a source of growth, but it also delivers a notable degree of stability to commercial real estate properties and markets.”\nAmong the chosen symbols of Eds & Meds\' power? The iconic US Steel Tower skyscraper in Pittsburgh, the tallest building in the city when it was completed in 1971, saw the logo of University of Pittsburgh Medical Center raised to its crown in 2008.\nBehind the symbols are statistics and facts like this astonishing observation: The Eds and Meds sector has not declined once in employment on an annual basis going back to 1940, and in the past 50 years has grown its job total by 500 percent and added 18.8 million jobs (more than any other ""sector"").\nWhen ranked by percentage of total employment in Eds & Meds, Philadelphia (21 percent), Boston and Pittsburgh ranked first through third among the 25 largest US MSAs by employment (2016 numbers), followed by New York-Newark, Baltimore and St. Louis (just ahead of Minneapolis-St. Paul and L.A.) Then again, even the bottom-dwellers in this quasi-ranking can boast some pretty major institutional heft (and may be happier it isn\'t so heavy with impact): Charlotte is just about 10 percent in 25th, preceded by DFW, Atlanta, Orlando, Denver and Houston.\nAnderson and Levy posit that multifamily and retail benefit the most from Eds and Meds, due to the demand from workers for rental apartments and consumer purchases. But they go one step further and say the presence of eds and meds calms the waters in terms of lowered volatility in multifamily and retail rents and vacancy. In other words, there aren\'t usually big employment shocks in healthcare, education and social services institutions. By way of example: The top six cities averaged a 5.6-percent drop in apartment rents and 8.8-percent drop in retail rents during the Great Recession, while the bottom six averaged 10.1-percent and 16. 1-percent drops, respectively.\nOr, as one analyst put it, eds & meds means more beds, filled with medical professionals, professors, students and even patients and their families.\nWashington, DC, is cast as an outlier due to its overweening federal government presence. And Houston and Dallas-Fort Worth, though they rank highly by their low overall drop in employment from 2007 to 2010, are characterized as ""unique"" cases due to the ""Texas economic miracle"" — a somewhat facile rationale, given the presence of such organizations as Texas Medical Center in Houston and Baylor University Medical Center in Dallas.\nThe authors also say that tech-driven consolidation may squeeze out smaller education and health service providers, ultimately meaning that, ""the Eds & Meds industry will cluster in certain exclusive metros, just as the technology industry has.""\nThe Big Six will stay strong, they say. But there are a handful of cities where rising Eds & Meds growth will coincide with an increasing share of the local economy, led by Riverside, California; Minneapolis-St. Paul, L.A. and Phoenix; and Denver, San Diego and San Francisco. Cities such as Portland, Oregon; Atlanta and Charlotte will see high job growth in the sectors, but it won\'t coincide with a growing share of the regional economy, say Levy and Anderson.']"	['<urn:uuid:7dc25e63-a4d9-4a88-a88d-d26491f4bf51>']	factoid	with-premise	short-search-query	similar-to-document	single-doc	novice	2025-05-12T15:09:02.012753	6	34	642
94	What helps good bacteria grow and what makes bad ones stronger?	Good bacteria (probiotics) can be supported through foods like yogurt, kefir, and fermented products containing live cultures. As for harmful bacteria, they become stronger through evolution, creating increasingly virulent strains and acquiring resistance to many antibiotics. Pathogenic bacteria can also develop various mechanisms to evade the host's immune system, including forming protective barriers and producing toxins that help them invade the host.	['bacteriaArticle Free Pass\n- The bacterial cell\n- Bacterial reproduction\n- Ecology of bacteria\n- Evolution of bacteria\n- Biosynthesis, nutrition, and growth of bacteria\n- Classification of bacteria\nBacteria in medicine\nBacterial diseases have played a dominant role in human history. Widespread epidemics of cholera and plague reduced populations of humans in some areas of the world by more than one-third. Bacterial pneumonia was probably the major cause of death in the aged. Perhaps more armies were defeated by typhus, dysentery, and other bacterial infections than by force of arms. With modern advances in plumbing and sanitation, the development of bacterial vaccines, and the discovery of antibacterial antibiotics, the incidence of bacterial disease has been reduced. Bacteria have not disappeared as infectious agents, however, since they continue to evolve, creating increasingly virulent strains and acquiring resistance to many antibiotics.\nAlthough most bacteria are beneficial or even necessary for life on Earth, a few are known for their detrimental impact on humans. None of the Archaea are currently considered to be pathogens, but animals, including humans, are constantly bombarded and inhabited by large numbers and varieties of Bacteria. Most bacteria that contact an animal are rapidly eliminated by the host’s defenses. The oral cavities, intestinal tract, and skin are colonized by enormous numbers of specific types of bacteria that are adapted to life in those habitats. These organisms are harmless under normal conditions and become dangerous only if they somehow pass across the barriers of the body and cause infection. Some bacteria are adept at invasion of a host and are called pathogens, or disease producers. Some pathogens act at specific parts of the body, such as meningococcal bacteria (Neisseria meningitidis), which invade and irritate the meninges, the membranes surrounding the brain and spinal cord; the diphtheria bacterium (Corynebacterium diphtheriae), which initially infects the throat; and the cholera bacterium (Vibrio cholerae), which reproduces in the intestinal tract, where the toxin that it produces causes the voluminous diarrhea characteristic of this cholera. Other bacteria that can infect humans include staphylococcal bacteria (primarily Staphylococcus aureus), which can infect the skin to cause boils (furuncles), the bloodstream to cause septicemia (blood poisoning), the heart valves to cause endocarditis, or the bones to cause osteomyelitis.\nPathogenic bacteria that invade an animal’s bloodstream can use any of a number of mechanisms to evade the host’s immune system, including the formation of long lipopolysaccharide chains to provide resistance to a group of serum immune proteins, called complement, that normally retard the bacterium. The pathogenic restructuring of bacterial surface proteins prevents antibodies produced by the animal from recognizing the pathogen and in some cases gives the pathogen the ability to survive and grow in phagocytic white blood cells. Many pathogenic bacteria produce toxins that assist them in invading the host. Among these toxins are proteases, enzymes that break down tissue proteins, and lipases, enzymes that break down lipid (fat) and damage cells by disrupting their membranes. Other toxins disrupt cell membranes by forming a pore or channel in them. Some toxins are enzymes that modify specific proteins involved in protein synthesis or in control of host cell metabolism; examples include the diphtheria, cholera, and pertussis toxins.\nSome pathogenic bacteria form areas in the host’s body where they are closed off and protected from the immune system, as occurs in the boils in the skin formed by staphylococci and the cavities in the lungs formed by Mycobacterium tuberculosis. Bacteroides fragilis is the most numerous inhabitant of the human intestinal tract and causes no difficulties for the host as long as it remains there. If this bacterium gets into the body by means of an injury, the bacterial capsule stimulates the body to wall off the bacteria into an abscess, which reduces the spread of the bacteria. In many instances, the symptoms of bacterial infections are actually the result of an excessive response by the immune system rather than of the production of toxic factors by the bacterium.\nOther means of combating pathogenic bacterial infections include the use of biotherapeutic agents, or probiotics. These are harmless bacteria that interfere with the colonization by pathogenic bacteria. Another approach employs bacteriophages, viruses that kill bacteria, for the treatment of infections by specific bacterial pathogens. In addition, recombinant DNA technologies, developed during the 1980s, have made it possible to synthesize nearly any protein in bacteria, with E. coli serving as the usual host organism in this process. Recombinant DNA technology is used for the inexpensive, large-scale production of extremely scarce and valuable animal or human proteins, such as hormones, blood-clotting factors, and even antibodies.\nWhat made you want to look up bacteria?', 'What are they?\nProbiotics are live microorganisms that are intended to have health benefits when consumed or applied to the body. Probiotics may contain a variety of microorganisms. The most common are bacteria that belong to groups called Lactobacillus and Bifidobacterium. Other bacteria may also be used as probiotics, and so may yeasts such as Saccharomyces boulardii.\nThe U.S. Food and Drug Administration (FDA) regulate probiotics as a dietary supplement, a food ingredient, or a drug.\nWhy are they needed?\nPeople often think of bacteria and other microorganisms as harmful “germs,” however many are actually helpful. Probiotics might:\n- Help digest food, destroy disease-causing cells, or produce vitamins.\n- Help your body maintain a healthy community of microorganisms or help your body’s community of microorganisms return to a healthy condition after being disturbed\n- Produce substances that have desirable effects\n- Influence your body’s immune response.\nProbiotics have shown promise for a variety of health purposes, including prevention of antibiotic-associated diarrhea (including diarrhea caused by Clostridium difficile), prevention of necrotizing enterocolitis and sepsis in premature infants, treatment of infant colic, treatment of periodontal disease, and induction or maintenance of remission in ulcerative colitis.\nWhere do you find it naturally?\nProbiotics are added to some foods like yogurt and cultured cottage cheese. They are naturally occurring in fermented foods like buttermilk, kefir, and sauerkraut. Raw cheese made from unpasteurized milk is another source.\nProbiotics for kids\nChildren develop their microbiome in the womb and through early childhood. It’s thought that an unhealthy microbiome is responsible for many diseases.\nA study published in JAMA Pediatrics found that giving infants probiotics in the first three months of life may help prevent colic, constipation, and acid reflux.\nSome decent brands for probiotics:\n- Nature’s Way:\n- Ultimate Flora:\n- Check the label to make sure the yogurt you choose has “live and active cultures.”\nProbiotics have an extensive history of apparently safe use.\n- Since long-term probiotic effects on kids are unknown, children shouldn’t use probiotic supplements as a preventive remedy, unless recommended by a doctor.\n- The risk of harmful effects from probiotics is greater in people with severe illnesses or compromised immune systems. When probiotics are being considered for high-risk individuals, such as premature infants or seriously ill hospital patients, the potential risks of probiotics should be carefully weighed against their benefits.\n- Possible harmful effects of probiotics include infections, production of harmful substances by the probiotic microorganisms, and transfer of antibiotic resistance genes from probiotic microorganisms to other microorganisms in the digestive tract.\n- Some probiotic products have been reported to contain microorganisms other than those listed on the label. In some instances, these contaminants may pose serious health risks.\n- Kids with compromised immune systems may experience infection. Others may have gas and bloating. Probiotics can cause serious side effects in very sick infants. Check with your pediatrician before giving probiotic supplements to your child.\nSource: Internet, CDC, NIH, FDA, Healthline, Medical News & Others\nThe views expressed in this article should not be considered as a substitute for a physician’s advice. Always make sure to seek a doctor or a professional’s advice before proceeding with the home treatment plan.']	['<urn:uuid:dafa349b-3f0a-4814-90e2-1fd7a41924f3>', '<urn:uuid:18b099d3-380b-4d1e-9834-7ed4ed088b12>']	factoid	with-premise	concise-and-natural	distant-from-document	multi-aspect	novice	2025-05-12T15:09:02.012753	11	62	1300
95	I'm interested in Olympic athletes who've faced health challenges - how long after being diagnosed with breast cancer did Novlene Williams-Mills compete in the London Olympics?	Novlene Williams-Mills was diagnosed with breast cancer in June 2012, just one month before the London Olympics. She went on to compete and won a bronze medal in the 4x400-meter relay at those Games.	"['Olympic sprinter Novlene Williams-Mills understands the importance of time. After graduating from the University of Florida in 2004, the Jamaican-born track star helped her home country medal in the 4x400-meter relay at the Athens Olympics, then again in Beijing in 2008. But in 2012, just weeks before the London Games, Williams-Mills, then 30, was diagnosed with breast cancer. She endured four surgeries -- and went on to win two more Olympic medals. Today, Williams-Mills is an elite, cancer-surviving athlete. She posed for this year\'s Body Issue in order to share her powerful story. This is it, in her own words:\nI received my diagnosis in June 2012. I went to my gynecologist for a checkup and I was like, ""I feel a small lump in my breast."" When I got the call that it was cancer, it was the week during the Jamaican nationals to qualify for the Olympics. I had gotten the call I think on Monday or Tuesday, and I leave for Jamaica the next day. I was like, ""OK, they\'re going to call me back and be like, \'This is the wrong results we have. That was somebody else.\'"" But it never happened. It was a month before the [London] Olympics.\nI went to Jamaica, and to be honest, I went into the national championship and I just went about my business. I was just trying to carry on. What am I supposed to do? Am I supposed to just sit at home? One of the things I asked was, ""Can I continue to run until we\'re ready to do the surgery?"" [My doctor] said yes. I needed something to distract me, because I know sitting at home I was just going to worry. I was going to cry. You know, my husband was going to work, all my friends at that time were competing, so I had nobody to talk to at home.\nWhen I came back from Jamaica, that\'s when I got the final diagnosis. I sat in the doctor\'s office and I listened to everything he had to say. I didn\'t cry until I went outside. That\'s when I really fall apart. I felt like a baby. I was like, ""This can\'t be real. It\'s impossible.""\nYou know, I work out hard, I eat right. I\'ve done everything to keep a healthy body. I don\'t drink. I don\'t smoke. I don\'t do none of that. And for this thing to come in my body and take control of it ... You know when you tell a friend something and they betray you? That\'s how I feel. Like this thing just stabbed me right in the back. Like it just didn\'t care who I was. It just wants to take control of everything and didn\'t ask permission. It didn\'t know that I have things to do.\nI kept it private. I like to keep my life out of the track and field spotlight. I feel like the less people know, the better for me. I\'m really a very private person. And at that point I didn\'t know how I was going to deal with anything. My family is in Jamaica, so I only have my husband and my friends as my support system here [in the U.S.]. For me, it was like, ""OK, what\'s life going to be like? Am I going to be laid up in a bed for a couple of months? What\'s the best way I can deal with this, where I can get my stuff together, where I don\'t have 50 phone calls a day?"" For me, keeping it outside of the public eye, outside of athletics, I think that was the best thing for me, and I think it was the best thing so I could recover much faster.\nIt was hard being in London at the Games when the rest of the world didn\'t know. The moment I have to step on the track, I know everybody is going for that medal. Me? I\'m counting the exact days until my surgery. It was like a weight on my shoulder that I couldn\'t get off, no matter how hard I tried to put it in the back of my mind for these couple of races. It was just something that kept weighing me down every time I stepped on that line to compete.\nJust being in the village, you\'re around teammates, and you don\'t want them to see you crying. I was the team captain for the Jamaica team. I don\'t want people to ask me what\'s going on. So I would spend a little bit longer in the shower just crying, just sobbing, because I\'m like, ""OK, all right, I let it out. I let all the emotions out.""\nFor me, [competing] was a distraction. It was about getting there. I didn\'t want to answer 50 phone calls of: Why did I pull out of the Games? Did I get hurt? I already qualified for the Games, might as well go out there and see what happens. I was still able to put it aside, to be like, ""OK, I\'m wearing the Jamaica colors. My teammates need me. I have to go out there and give them a fair shot because I know they have run their hearts out in the other three lanes and I can\'t let them down.""\nWe won the bronze [in the 4x400-meter relay]. I literally got the medal, came back to the village and packed. I think I left about 4 or 5 that morning, straight to Atlanta. I remember being on that plane, just crying. Because I know that the moment I step off -- I think it was about three days before my surgery -- I know I have an appointment, and I know, ""OK, I got to get this done. Got to get prepped, got to do this."" It was reality really setting in. I was about to go under the knife for the very first time.\nAfter the Olympics, I was in surgery three days later. The first surgery I did was a lumpectomy. Because before everything, I told my doctor, ""Whatever you do, I need to come out with my breasts!"" [Laughs.] That\'s all I was thinking about: ""Lord, please don\'t let me lose my breasts."" But then we did the surgery. We thought everything went well. Then I went back for the post-op and [the doctor] informed me that my margins weren\'t clear. It was heart-wrenching to hear. He was like, ""We need to go in and do another surgery because we really need to get all the rest of the cancerous cells.""\nHe shows [the scans] to my husband. He was like, ""If it was my wife, I would ask her to do a mastectomy."" Now, that was the furthest thing from my mind, and I\'m like, ""I don\'t want to do that."" But just sitting and listening to him, getting more information, I went home with my husband and we talked about it. I was like, ""I can\'t keep going back in the operating room. I can\'t. This is emotionally wrecking. I can\'t be selfish. I have to remember that I have people out there who love and care about me, and I don\'t want to go back in and they take some out, and then, you know, a couple of years down the line I may end up back with cancer.""\nSo I went back to my doctor and I told him, ""OK, we\'re going to do the mastectomy, but we\'re going to do a double mastectomy. Take both. If we\'re going to take one, just go ahead and take both.""\nMaybe a month after my first surgery, we went back in after the double mastectomy and they told me my margins still weren\'t clear. I was devastated. I was like, ""You\'ve got to be kidding me."" I felt like I was fighting a losing battle at this point. What else am I supposed to do? I mean, I gave you the breasts! What else do you need? [Laughs.]\nBut then he explained to me: The lump was sticking to my rib cage. We still have a problem. So we went back in and he removed some of the skin and stuff. Then we came back out with a clean margin in January of 2013.\nI did reconstructive surgery when I did the double mastectomy. My plastic surgeon explained everything that was going to take place. I was going to have the drainage tube. It was terrifying. But once he explained everything, I think that was when I was more confident. Nobody has to know that they\'re not mine until I\'m ready to tell them: The real ones tried to kill me.\n""My battle scars are my cancer scars.""Novlene Williams-Mills\nBut one thing he said was, ""Don\'t go on the Internet and read what other people say. Because everybody has a different story, and some people\'s stories are horrible."" Well, you know, as a curious person, I went on the Internet, just reading some people\'s stories. I\'m like, ""Oh my Lord Jesus, this is awful. If I\'m going to get through this surgery, I have to stay off the Internet. I get to go through my own experience.""\nWas it horrible? Yes. I felt like a turkey that was getting basted every time I had a new drainage tube. Every time I go in, I have an expander just to get me to the size of my breasts. They have to put in saline. I was feeling like I was being pumped. It was horrible. But I get it. Some experiences, when you get to the other side, you get back to the person you want to be. You look in the mirror and you see all these scars. This is a body that you\'re used to so much and then one day you have all these scars on your body. And, you know, that\'s your story. I had to be like, ""This is who I am now. These are the scars that make me up.""\nSometimes you\'ve just got to take a bigger step to get where you want to be. Sometimes you\'ve just got to fight a little bit harder. Seeing those scars, I\'m like, ""This is what makes me now. Some people are going to have battle scars. My battle scars are my cancer scars.""\nThe first couple of months [after my surgery], I wasn\'t planning on returning for the 2013 season. I was like, ""There\'s no way I can do this."" Because normally we\'d start training about October or November 2012. I was still going through surgery at that time. I don\'t think I returned to training until about February 2013. So I didn\'t have background training. I was like, ""I\'ll just practice, see how it goes, and whatever happens, happens. If I can\'t do this, then I won\'t.""\nThere were days when I would go to practice and I didn\'t feel like I was accomplishing what I used to be accomplishing in practice. And I would come home and I would cry, and I would be like, ""I can\'t do this."" Some of my friends and my husband would be like, ""You have to remember that you went through something that none of these athletes have been through. You\'ve got to give your body time. Your body went through trauma."" But I was like, ""I don\'t have time. My job doesn\'t allow for times like this.""\nTo other people, that was Novlene performing a low standard. They didn\'t know what was going on. And it hurt. It hurt when people be like, ""What\'s going on with her?"" I just want to say to them, ""If you knew what I\'ve been through, you don\'t have nothing to say."" But I wasn\'t ready yet. I wasn\'t ready to let the world know what I been through.\nI think it had to be maybe in the 2014 season when I started [feeling like myself again]. During that season was when I really got my background training, getting everything back to how I wanted to -- well, as normal as I used to be. That\'s when I kind of started feeling, like, ""OK, this is the old Novlene coming back.""\nBefore cancer, I used to train five days a week. When I came back, I told my coach, ""Listen, we only do it four days a week. I do Monday, Tuesday. I need Wednesday off. I come back Thursday, Friday. I need to rest [laughs]. I don\'t need to push my body through all of this. I have to listen to what my body\'s saying.""\n""Everything I look at, I\'m like, \'It\'s a second chance for me.\' And I\'m enjoying every moment of it.""Novlene Williams-Mills\nBefore cancer, I would think, ""OK, to make me a lady, you have to have your breasts. You have to have this, you have to have that. Now I realize that what makes me a lady is this strong person that I look at every single day in the mirror. It\'s the courage; it\'s the strength; it\'s the fighter that I have in me that when I wake up every single day, I live to fight another day.\nAfter cancer, everything I look at, I\'m like, ""It\'s a second chance for me."" So every time I go to do something track-related, I try to give it 110 percent. Because I feel like a lot of people don\'t get second chances and I did. And I\'m enjoying every moment of it. Because after 2012, to be honest, when I ran that race in London I was like, ""I don\'t know if I\'ve run my final race."" And here am I, five years after, still going and still doing what I love to do.\nI tell people, ""This is my hot season. When I walk off that track, I don\'t want to be remembered as Novlene, the girl who had cancer. I still want to be remembered as one of the lead 400-meter runners out there. When the results come up, I need to see my name up there in the lights. ""OK, this is the girl who fought through every possible thing and came back at the top of her game.""\nFor me, the hardest thing I\'ve dealt with was, ""Are you ever going to talk about your story?"" And for the longest time, I would tell them no, because I was like, ""What am I ever going to say that they haven\'t heard from someone else? It\'s another person with cancer, who cares?""\nBut it\'s more that you have this platform. You are an athlete. When I finally did, the response I get from people is how I inspire them, how I motivate them. I didn\'t realize there are so many people out there who go through so much stuff. I have no regrets to this day. Was it scary? Yes. Because I didn\'t know how people were going to react. I didn\'t want the athletes to look at me as, ""Oh, she\'s the one who has cancer."" I don\'t want no side eyes. I didn\'t want people to treat me differently. But I have never got that to this day, and I respect that.\nNo one else can tell you how to fight your battle. All I can say is, when you feel like giving up, just push a little bit harder. It\'s not going to be easy. You\'re going to have rough days. But giving up is easy. Fighting every single day is harder. I have to be that survivor of my own battle. I have to be a survivor of cancer.\nFor more Body interviews: AJ Andrews | Javier Baez | Julian Edelman | Ezekiel Elliott | Kirstie Ennis | Julie and Zach Ertz | Malakai Fekitoa | Gus Kenworthy | Nneka Ogwumike | Isaiah Thomas | Joe Thornton and Brent Burns | US Women\'s National Hockey Team | Ashley Wagner | Michelle Waterson | Novlene Williams-Mills | Caroline Wozniacki']"	['<urn:uuid:4fe7650d-52d1-45a5-a769-64a1aa7af279>']	factoid	with-premise	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-12T15:09:02.012753	26	34	2674
96	I love learning about ancient trees and I'm worried about their future. Could you tell me what's happening with the oldest trees in the world, especially Methuselah, and why scientists are concerned about their survival?	Methuselah, a bristlecone pine tree in California's White Mountains, is one of the oldest known living trees at 4,848 years old. While it has survived for nearly five millennia through various challenges, it and other ancient bristlecone pines are now facing a serious threat from climate change. As temperatures warm, these trees are struggling to survive in their traditional habitats. Scientists predict that bristlecone pines may become extinct because they're being outcompeted by faster-growing limber pines at higher elevations, while the lower elevations become too warm for their survival. This is part of a broader concerning trend, as researchers have noticed an alarming increase in the death rate of trees between 100 and 300 years old in many of the world's forests, and projections show that tree growth rates in the U.S. southwest could decrease by 75% by 2050.	"['Environment Planet Earth The World\'s 10 Oldest Living Trees By Bryan Nelson Writer SUNY Oswego University of Houston Bryan Nelson is a science writer and award-winning documentary filmmaker with over a decade of experience covering technology, astronomy, medicine, and more. our editorial process Twitter Twitter Bryan Nelson Updated June 17, 2019 Vanea Cera / Flickr / CC BY 2.0 Share Twitter Pinterest Email Environment Weather Outdoors Conservation There are colonies of clonal trees that have lived for tens of thousands of years, but there\'s something majestic about a single tree able to stand on its own for millennia. These ancient trees have borne witness to the rise and fall of civilizations, survived changing climates, and even persevered through the fervent development of human industry. They are a testament to the long view that Mother Nature takes in tending the Earth. With that in mind, consider these 10 of the world\'s oldest living trees. 1 of 10 Methuselah Chao Yen / Flickr / CC BY-ND 2.0 Until 2013, Methuselah, an ancient bristlecone pine was the oldest known non-clonal organism on Earth. While Methuselah still stands as of 2016 at the ripe old age of 4,848 in the White Mountains of California, in Inyo National Forest, another bristlecone pine in the area was discovered to be over 5,000 years old. Methuselah and its unnamed senior pine\'s exact locations are kept a close secret in order to protect them. You can still visit the grove where Methuselah hides, but you\'ll have to guess at which tree it is. Could this one be it? 2 of 10 Sarv-e Abarqu Ninara / Flickr / CC BY 2.0 Sarv-e Abarqu, also called the ""Zoroastrian Sarv,"" is a cypress tree in Yazd province, Iran. The tree is estimated to be at least 4,000 years old and, having lived through the dawn of human civilization not far away, it is considered an Iranian national monument. Many have noted that Sarv-e Abarqu is most likely the oldest living thing in Asia. 3 of 10 Llangernyw Yew Emgaol / Wikimedia Commons / CC BY-SA 3.0 This incredible yew resides in a small churchyard of St. Dygain\'s Church in Llangernyw village, north Wales. About 4,000 years old, the Llangernyw Yew was planted sometime in the prehistoric Bronze Age — and it\'s still growing! In 2002, in celebration of the golden jubilee of Queen Elizabeth II, the tree was designated as one of 50 Great British trees by the Tree Council. 4 of 10 Alerce Gonzalo Zúñiga Solís / Wikimedia Commons / CC BY-SA 4.0 The Alerce is a common name for Fitzroya cupressoides, a towering tree species native to the Andes mountains. There\'s almost no telling how old these trees can get, since most of the larger specimens were heavily logged in the 19th and 20th centuries. Many botanists believe they are the second-longest living trees on Earth aside from the bristlecone pine of North America. To date, the oldest known living specimen is 3,646 years old and is appropiately called Grand Abuelo. 5 of 10 Patriarca da Floresta Marcus V. Bellizzi / Wikimedia Commons / CC BY-SA 3.0 This tree, an example of the species Cariniana legalis named Patriarca da Floresta in Brazil, is estimated to be over 2,000 years old, making it the oldest non-conifer in Brazil. The tree is believed to be sacred, but its species is widely threatened due to forest clearing in Brazil, Colombia and Venezuela. 6 of 10 The Senator Ebyabe / Wikimedia Commons / CC BY-SA 3.0 Though the Senator suffered tragedy in 2012 after a fire caused much of the tree to collapse, this iconic tree bears mentioning here. Formerly located in Florida, the Senator was the largest bald cypress tree in the United States, and was widely considered the oldest of its species known to exist. It was also likely the largest U.S. tree of any species east of the Mississippi River. Estimated to have been around 3,500 years old, the Senator was used as a landmark for the Seminole indians and other native tribes. The Senator\'s size was particularly impressive because it endured many hurricanes, including one in 1925 which reduced its height by 40 feet. The tree got its name from from Sen. M.O. Overstreet, who donated the tree and surrounding land in 1927. 7 of 10 Olive Tree of Vouves Eric Nagle / Wikimedia Commons / CC BY-SA 4.0 This ancient olive tree is located on the Greek island of Crete and is one of seven olive trees in the Mediterranean believed to be at least 2,000 to 3,000 years old. Although its exact age cannot be verified, the Olive Tree of Vouves might be the oldest among them, estimated at over 3,000 years old. It still produces olives, and they are highly prized. Olive trees are hardy and drought-, disease- and fire-resistant — part of the reason for their longevity and their widespread use in the region. 8 of 10 Jōmon Sugi Σ64 / Wikimedia Commons / CC BY 3.0 Jōmon Sugi, located in Yakushima, Japan, is the oldest and largest cryptomeria tree on the island, and is one of many reasons why the island was named a UNESCO World Heritage Site. The tree dates to at least 2,000 years old, but some experts believe it could be older than 5,000 years old. Under that theory, it\'s possible that Jōmon Sugi is the oldest tree in the world — even older than Methuselah and its brethren. Regardless of the numbers, it\'s a tree that deserves mention here. 9 of 10 Chestnut Tree of One Hundred Horses LuckyLisp / Wikimedia Commons / CC BY-SA 3.0 This tree, located on Mount Etna in Sicily, is the largest and oldest known chestnut tree in the world. Believed to be between 2,000 and 4,000 years old, this tree\'s age is particularly impressive because Mount Etna is one of the most active volcanoes in the world. The tree sits only 5 miles from Etna\'s crater. The tree\'s name originated from a legend in which a company of 100 knights were caught in a severe thunderstorm. According to the legend, all of them were able to take shelter under the massive tree. 10 of 10 General Sherman David Prasad/ Flickr / CC BY-SA 2.0 Believed to be around 2,500 years old, General Sherman is the mightiest giant sequoia still standing. The volume of its trunk alone makes it the largest non-clonal tree by volume in the world, even though its largest branch broke off in 2006, smashing part of its enclosing fence and cratering the pavement of the surrounding walkway. Perhaps this was a sign that General Sherman could not be caged in? Sherman can be found in Sequoia National Park in California, where five of the 10 largest trees in the world exist.', ""- Bristlecone pine, the world's oldest species of tree, may go extinct due to changing temperatures caused by climate change in the frigid mountains where they used to thrive.\n- Some of these trees are almost 5,000 years old, so their loss would be another devastating blow to the environment brought on by manmade climate change.\nAt 4,845 years old, Methuselah, a Great Basin bristlecone pine (Pinus longaeva) in the White Mountains of California, is one of the oldest trees on Earth. It’s so old, in fact, that it was only a seedling when the Egyptian pyramids were being constructed. Since it first broke ground, the pine tree has survived wars, cultural upheavals, extreme weather conditions, and whatever else this world threw at it. Now, after more than 48 centuries of life and history, this tree is facing its toughest challenge yet: climate change.\nAround the world, giant, old trees like Methuselah stand as a living history of this planet, but a new study suggests that climate change could lead to their extinction. “I think what’s going to happen — at least in some areas — is that we’re going to lose bristlecone,” said Brian Smithers, an ecologist at the University of California and co-author of a recent study of the iconic forest giants.\nBristlecone pine have historically thrived in the upper elevations of California’s White Mountains because they have adapted to survive the temperatures found just below the tree line. As temperatures warm and the tree line moves higher up the mountains, it’s expected that this particular species would simply begin to seek out higher elevations as well. However, those higher areas are being populated more heavily by a different species, limber pines, thanks to the help of a bird species that spreads its seeds. “Whoever can get there first wins,” Smithers said. “And it looks like limber pine is just better able to get there quicker.”\nAs these limber pine trees grow, they could use up the light and water supplies that the slower-growing bristlecone pines that do sprout in the higher elevations need to survive, eventually taking over those higher elevations completely. The bristlecone pines left in the lower elevations could then succumb to the warmer, less desirable conditions brought on by climate change.\nThe loss of our planet’s oldest tree species isn’t exclusive to the bristlecone pine. According to an article published by ThinkProgress back in 2012, leading ecologists have already “documented an alarming increase in the death rate of trees between 100 and 300 years old in many of the world’s forests, woodlands, savannahs, farming areas, and even in cities.” As a response, researchers are urging an increased focus on efforts that can help us identify the cause of this rapid loss of historic trees so that strategies can be immediately implemented to manage its effects.\nA more recent study published in Nature World News looked into how the growth rate of trees changed historically under previous climate conditions. Those researchers projected that the United States will see a 75 percent decrease in its growth rate of trees in the southwest, and as the planet gets warmer, this will push numerous forests into critical levels as early as 2050. When that happens, our forests will be unable to help protect us from the effects of climate change by offsetting carbon emissions.\nCombine this negative impact on the planet’s tree species with the ever-increasing number of other plants and animals facing extinction, and you can see that humans are far from the only species battling the devastating consequences of manmade climate change.""]"	['<urn:uuid:58632cc5-c726-48aa-b3fe-16e1add6fc97>', '<urn:uuid:e23a195f-eefe-404d-8f39-4c8456d45b67>']	open-ended	with-premise	verbose-and-natural	similar-to-document	three-doc	novice	2025-05-12T15:09:02.012753	35	139	1726
97	What skills do school programs develop for future careers?	School programs develop critical social-emotional skills that employers desire most, including the ability to work in teams and solve problems. These skills are developed through both creative arts education, as seen in schools like Creative Arts and Voorhees, and through prevention programs that integrate social-emotional learning curricula. Of 16 critical 21st-century skills needed for future success, 12 are social-emotional skills.	"['Voorhees High School sits on the peak of mountain ridge overlooking Clinton and the surrounding South Branch valley. The ridge is so elevated above ground light, there is an observatory less than a half-mile from the Voorhees High. It is from this vantage point, the kids at Voorhees look into the infinite possibilities of their futures.\nCreative Arts High sits between an elevated interstate and the rusting industrial waterfront of Camden. The Philadelphia skyline is in the distance. Up close are the real problems of the city-bound: poverty, joblessness, drugs. It is from this vantage point that the talented kids at Creative Arts -- who must test and audition their way into the school -- see the infinite possibilities of their futures.\nIt is in those infinite possibilities, the kids from both schools find common ground.\nThe two schools have an exchange program. Today, the Camden students spent the day at Voorhees, a 20-year-old school that looks brand new, a school with a state-of-art TV studio, a writing lab with two dozen individual flat-screen computer stations, a ceramics studio where students produce art quality figurines and pottery in small-factory quantities, and an instrument stocked music room worthy of a small-city orchestra.\nOn Wednesday, they will go to Creative Arts, which is a circa. 1920s elementary school, half of which burned down. It is a brick fortress, with two trailers attached. It was transformed into Creative Arts in 1999. A dance studio was built, and a sound system put in for the music majors, but mostly, it stayed the same. Except for the halls and walls. At Creative Arts, like Voorhees, the walls are a colorful celebration of student murals and motifs.\nArt from different worlds, but from the same internal human place.\nAnd this is exactly the point of the program.\nIn describing the ""why"" of it teachers from both sides use world like ""tolerance"" and ""acceptance."" They are words that imply there is resistance to different people, a resistance that must be overcome.\nNo such reluctance was apparent today. As the 27 Camden students arrived at the windy, hilltop parking lot at Voorhees, English teacher Nancy Anne Castello hustled her 30 kids out to greet them.\n""Just grab one and bring them inside. It\'s too cold out here,"" she said.\nAnd that\'s how it went. The formalities were done on the run.\nCastello launched the exchange program after she saw a news show in 2007 about kids growing up poor in Camden. One of the kids the news crew followed was Billy Joe Marrero, a student at Creative Arts. (Later, Billy Joe\'s family was given a house by the show ""Extreme Makeover: Home Edition,"" then made headlines when his father tried to sell the house. Creative Arts had another pop culture star in Craig Bazan, a YouTube star for his recital of the Hamlet soliloquy outside the school.)\nInside, the kids were buddied up, and given tours of the school. The auditorium and stage, the giant cafeteria with hot meals, the big gym with bleachers, the writing lab, the art rooms, the choir room, the instrument room. All the things Creative Arts does not have.\nBut if you think the Camden kids came away envious after seeing all the bells, whistles and xylophones, think again.\n""I love our school,"" said Tinisha Baker, a dance student at Creative Arts. ""I know everyone, and everyone knows me. This school (Voorhees) would be too big for me. For what we do, a small environment is better.""\nAlan Rivas, a saxophone player interested in zoology, said he liked the narrow focus of Creative Arts.\n""We\'re a fine arts school. We\'re small, and maybe we need a bigger school with more majors, but we don\'t need it insane. When you\'re small, you get more individual attention. Like our jazz band. We\'re small, but if we were bigger it would be too hectic.""\nThis exchange program isn\'t about who has what. It isn\'t about exposing differences. It\'s about exploring similarities. Once the school was toured, the kids buckled down to work. They were split into small groups and given a series of big \'E\' topics to brainstorm: Education, Economy, Environment, etc. Every kid was assigned a different job in the group, every voice was heard.\nDuring lunch break, the kids were able to move around the school. In the hallway outside the work room, near the display of all that glazed ceramic art, a group of Camden kids, and one from Voorhees, gave an impromptu concert of spiritual songs to the applause of their classmates, old and new.\nMusic, like dreams, is the universal language.', 'Partners In Prevention\nWHAT IS PARTNERS IN PREVENTION?\nProven prevention programs equip students with skills that not only help them avoid drugs and alcohol, but also help improve their academic achievement, attendance, classroom behavior, and social and emotional well-being. These programs can also help reduce bullying and violence.\nIn 2019, Healthcare Foundation of La Porte (HFL) launched a 3-year grant initiative to help La Porte County schools identify, implement, and sustain proven substance use prevention programs. All schools in La Porte County (accredited, K-12 public, parochial, and private schools) were invited to apply for grant dollars to help them plan and implement evidence-based programs.\nHFL’s Board of Directors has committed over $2.5 million for planning, implementation, technical assistance to the schools, and a full evaluation of outcomes. HFL has contracted Education Development Center (EDC) as the Technical Assistance (TA) provider that assisted schools during the planning phase and is now helping with the implementation phase of the initiative. The TA providers were chosen due to their expertise in assisting schools implement evidence-based programs as intended (with fidelity) by the curriculum developers. The professional evaluation firm, RTI International (RTI) has been contracted to annually, over the course of three years, evaluate programming effectiveness and delivery of programming as intended, which is critical to successful translation of evidence-based interventions into practice.\nIn 2018, Richard M. Fairbanks Foundation committed more than $10.2 million to 151 Indianapolis schools delivering proven prevention programs to 71,112 students by the 2020-2021 school year. This funding is helping to implement evidence-based prevention programs in public and accredited private K-12 schools in Marion County. Richard M. Fairbanks Foundation has kindly permitted HFL to adopt the main components of their initiative, and we thank them for their support.\nPlanning & Implementation Grants\nHFL awarded planning grants of up to $10,000 to all La Porte County school systems, and private and parochial schools to investigate and learn about evidence-based prevention programs. Planning grants were awarded on a non-competitive basis, meaning that all schools that met eligibility criteria and applied received a planning grant.\nTwelve schools received planning grants in March 2019 and were provided access to expert technical assistance from EDC who provided step-by-step technical assistance to help: 1) identify the proven, age-appropriate prevention program(s) that best meet(s) the needs of each applicant’s students, staff, and school environment and 2) help ensure planning grant recipients carefully think through the steps required for successful program implementation and continued sustainability.\nSchools participating in Partners in Prevention applied for implementation grants in late spring of 2019 to begin implementing their chosen evidence-based substance use prevention program. Schools began their selected programs in fall 2019 and will continue over the course of three years (August 2019-June 2022). Schools awarded implementation grants will continue to receive support from EDC and RTI throughout the three-year grant period to support program delivery, data collection, and evaluate the impact of their programs on their individual schools.\nGrant Award Recipients\nWe are excited to introduce the private, parochial, and public school systems that are participating in Partners in Prevention.\nProgress & Successes, Year 1\nHFL is committed to evaluating the outcomes of Partners in Prevention. RTI will evaluate 1) the impact and benefit of the initiative, and 2) identify early challenges to provide additional support to address these issues moving forward and improve quality of delivery.\nRTI’s evaluation design for Year 1 consisted of the evaluation of process measures and outcome measures.\nProcess measures collected from:\n- Grant director surveys (12)\n- Grant director interviews (12)\n- Implementer surveys (298)\nOutcome measures collected from:\n- Indiana Department of Education (IDOE) data\n- Statistics from data that grantees collected\nAt the time of their survey, which happened over March and April 2020, only 11% of implementers had completed implementation with all or some of their students. However, an additional 56% of implementers were on track to complete implementation by the end of the school year. In total, we expected about 2/3 of implementers to complete program delivery by the end of the school year. Implementers had positive attitudes about programming.\nIn terms of program impact, it’s early in the initiative (1st year) for us to have hard numbers about whether Partners in Prevention is having positive impact in schools. We will gather data about that as the initiative moves along into years 2 and 3. However, in Year 1, schools at Pre-K through grade 12 levels reported positive changes in how students interacted and behaved, both with their peers and with their teachers.\nThe data presented by the evaluation of Year 1 yielded several insights that will guide quality improvement efforts on the part of schools, grantees, technical assistance providers, and HFL moving into Year 2. These include:\n- Achieve the greatest impact by improving implementer training, oversight, and the delivery of curriculum as intended by the curriculum developers.\n- Better embed programs into the school communities, such as among non-implementer staff, bus drivers, cafeteria workers, and parents.\n- Use the expert technical assistance providers contracted by HFL to increase student engagement, comprehension, and modeling of the curriculum concepts outside the classroom.\n- Build buy-in by encouraging grantees to reach out to community stakeholders including parents and other caregivers, county and city leadership, school staff (bus drivers, school nurse, coachers, custodial staff), non-profit organizations and agencies, businesses and chambers, social service organizations (Rotary International and Kiwanis) healthcare, and to share their successful outcomes.\n- Collect meaningful data to demonstrate changes in academic achievement, emotion management, attendance, perceived risk of substance use, and disciplinary events.\nAnd finally, what was the impact of COVID-19. Surveys were distributed before COVID was an issue, so we don’t have survey data about it’s impact. However, grant directors were interviewed just as schools were shutting down in the spring. The surveys did not have any interview questions specific to COVID, but every grant director mentioned that COVID affected their program implementation in some way.\n“We were on top of things, and we knew what to expect. We were actually really excited about the implementation of the spring semester because we felt really confident, and then COVID happened.”\nWe know that this pandemic is a continuing challenge for schools this year, and we’ll be able to ask more specific questions about that in the Spring 2021 implementer and grant director surveys.\nOverview and Year 1 Learning\nWe are delighted to share an overview of Partners in Prevention impact at scale, timeline for implementation, and lessons learned. Additionally, our infographic outlines the reasons why we clearly support a need for purposeful intervention in schools and these proven programs set the path for student success now and into their future.\nYear 2, Everyone In!\nYear 2 of PiP implementation continues in either virtual, in-person or hybrid learning environments, changing from week to week depending upon the county’s COVID-19 status. Challenges are heavy for implementers and grant directors in the schools, however now is not the time to move away from social-emotional learning (SEL) curriculums.\nToday, intentionally embedding SEL curriculum and activities in the classroom to enable students and teachers to heal is critical. These evidence-based programs will help to instill a growth mindset in students and give them multiple opportunities to practice skills that will prepare them for success beyond COVID-19.\nEven though times are tough, let’s continue to implement PiP curriculum. Decades of research studies demonstrate the following benefits of SEL.\n- Improvement in students’ social and emotional skills, attitudes, relationships, academic performance, and perceptions of classroom and school climate.\n- Decline in students’ anxiety, behavior problems, and substance use.\n- Long-term improvements in students’ skills, attitudes, prosocial behavior, and academic performance.\n- Wise financial investment according to cost-benefit research\nConnection to College & Career Readiness\nAs discussed, PiP delivers prevention programs that integrate evidence-based social-emotional learning curricula. We already know that research shows that social-emotional learning has a positive impact on student achievement. But it also has a positive impact on employability and overall mental well-being.\nForbes reports the 10 skills employers most desire in graduates, and ranked these 4 at the top:\n- Work in a team\n- Solve problems\n- Make decisions\nOf 16 critical 21st-century skills, 12 are social-emotional skills.\nKey Takeaway: For students to be prepared for future success, they need academic achievement AND social-emotional development.\nSources: Adams, S. (2014, November 12 and Soffel, J. (2016, March 10). What are the 21st-century skills every student needs? World Economic Forum; and https://www.weforum.org/agenda/2016/03/21st-century-skills-future-jobs-students/ See also World Economic Forum. (2016, March). New vision for education: Fostering social and emotional learning through technology. http://www3.weforum.org/docs/WEF_New_Vision_for_Education.pdf)\nResources & Documents\n- Announcement of Planning Grant Award Recipients\n- SEL E-Learning Opportunities\n- Announcement of Implementation Award Recipients\n- Evidence-Based Program Selections of HFL Grantees\n- What is Partners in Prevention?\n- Why school-based prevention?\n- Partners in Prevention FAQ\n- Approved Evidence-Based Programs guide created by the Indiana Prevention Resource Center – descriptions of approved evidence-based substance use prevention programs that schools can select\n- School Competencies Mapping – table describing how approved programs align with Indiana state standards\n- Budget Forms\n- Implementation Budget Form (to be completed and uploaded in the implementation grant application)\nContact us with questions or for more information about this school prevention initiative.']"	['<urn:uuid:f03b8b66-e7ba-4a0d-877d-dcda68f67f28>', '<urn:uuid:5c9175da-d6db-4b02-836c-4c4d9f5c609c>']	factoid	direct	concise-and-natural	distant-from-document	three-doc	expert	2025-05-12T15:09:02.012753	9	60	2308
98	web speed check methodology procedure	The internet speed test downloads a small dummy file and measures the download time. The speed in megabits per second (Mbps) is calculated by dividing the number of megabits in the file by the download time in seconds. For upload speeds, the same process is performed in reverse.	"[""Download speed is most relevant for people who are consuming content on the Internet, and we want FAST.com to be a very simple and fast speed test. What about ping, latency, upload and other things? When you click the “Show more info” button, you can see your upload speed and connection latency (ping).\nThe internet speed test will download a small dummy file and time how long the download takes. The number of megabits in the file divided by the number of seconds it takes to download give you the megabits per second (Mbps) speed of your internet connection. To test upload speeds, the speed test follows the same process but in reverse. The speed test service is 100% free, and it does various tests for checking your internet connection performance. It uses your Internet to send random bytes to the nearest server and receives random bytes from the same server to check download and upload speeds. XFINITY Speed Test. Xfinityspeedtest.org is a free service that provides users with a third-party integrated tool for testing your Internet Speed within seconds and free of cost. This speed test is conducted by sending and receiving data from your computer using your Internet connection. Jul 11, 2019 · If you are asking yourself, “how fast is my Internet” or “what are my Internet speeds,” look no further. You can determine the approximate speed of your Internet connection by taking the Speed Test from Xfinity which will generate a report on your Internet download speed and upload speed. Find out your internet download and upload speed in mbps per second with our internet speed test! Get lightning fast internet speeds starting at 100 mbps with Spectrum. This speed test checks the speed between your smartphone, tablet, computer, or other device and the internet. You can run the test through a cellular (mobile) network, a wired broadband connection, or your home Wi-Fi. A gateway speed test checks the speed between your AT&T Wi-Fi gateway and our network. It reflects the actual speed coming into your home. Test your AT&T gateway speed with AT&T Smart Home Manager. Test your Internet connection bandwidth to locations around the world with this interactive broadband speed test from Ookla\nThe internet speed test result displayed on the screen basically has four components i.e. download speed, upload speed, ping speed and jitter speed . Let us see what they indicate. Download Test : Measured in Mbps the download speed of your internet connection tells that how quickly your device downloads data from the internet.\nGoogle Fiber, RCN, and Verizon have the fastest tested internet speeds in the US, according to our fastest internet providers 2020 report, which is based on more than 2.4 million results from our internet speed test. Xfinity also offers fast internet speeds, and it performs well in every tested region in the country.\nInternet speed tests, like this one or the test found atSpeedTest.net , measure the latter, or the speed reaching the device running the test. These test results are often lower than your plan speed due to various factors outside your Internet provider's control, including WiFi conditions and device capabilities.\nTest your Internet connection bandwidth to locations around the world with this interactive broadband speed test from Ookla""]"	['<urn:uuid:2f6658e4-4cfa-41bc-afe5-31b2aec1602f>']	factoid	direct	short-search-query	distant-from-document	single-doc	expert	2025-05-12T15:09:02.012753	5	48	543
99	indoor plants safe dogs temperature requirements maintenance tips	Several indoor plants are safe for dogs including polka dot plant, which thrives in temperatures above 60°F and requires indoor winter storage, and pilea peperomioides, which grows well in temperatures between 65-75°F. Both plants need bright indirect light and moderate watering. For maintenance, it's important to use pet-safe fertilizers and keep plants in areas where dogs won't trample them, potentially using hanging baskets for delicate specimens.	['How To Propagate Pilea Peperomiodes\nPilea Peperomioides, commonly known as the Chinese money plant, is a houseplant known for its medicinal properties. As an erect plant that requires little maintenance, its ideal growing season spans from spring to fall.\nMost people grow it as a houseplant for its visually appealing coined-shaped leaves, measuring up to 4 inches in diameter. The plant has its roots in China’s George Forest, which surrounds Cangsgan mountain (with altitudes ranging from 5,000 to 10,000 feet.\nWith the easy-to-follow tips discussed in this guide, you can get yourself started with pilea propagation.\nAs a succulent, evergreen, and perennial plant, the Pilea Peperomioides grows up to 12 inches in height with the ability to expand its width. The plant thrives in temperate and tropical regions across the globe.\nIt is part of the Urticaceae family, which includes about 600 to 715 flowering plants mostly grown as houseplants.\nConditions Required to Propagate Pileas\nSince they require minimal watering, pilea plants can thrive and continuously grow new leaves in hot months.\nWhen the cold months approach, their growth significantly slows down. It’s advisable to propagate the plant in containers before the spring season reaches. All you need for pilea propagation is the stem cuttings.\nWith relatively brittle stems, pileas are easy to propagate. Use the tips of new branches when propagating for a more compact, bushy plant. Observe the following conditions for the cuttings to thrive:\nUse a moderately rich, well-draining mix to propagate your pilea cuttings. A mix designed for African violets or a pear moss potting mix combined with perlite and leaf mold may be ideal. Soggy soil may lead to root decay and kill the cuttings.\nBright, indirect light is ideal for pilea propagation. The cuttings may burn and wither when exposed to direct sunlight. Rotate the container twice or thrice a week to allow the shoots to receive adequate light.\nThough the plant can survive under dimly-lit conditions, its foliage may become leggy and turn a darker green.\nTemperature and Humidity\nPilea plants grow well in temperatures above 50 degrees Fahrenheit. Since Frost is detrimental to the plant, the indoor temperatures for pilea propagation should range from 65 to 75 degrees Fahrenheit.\nGrow the cuttings away from the vents, which tend to blow hot or cold air. Pileas thrive in moderate to high humidity conditions.\nWater the plants when the first inch of the potting mix completely dries out. If the leaves start dropping, it may be a sign that the plants require watering. Water more often in hot weather since the soil tends to lose moisture faster.\nThough watering isn’t necessary during winter, you should always check signs of moisture loss in the soil.\nOverwatering may weaken the stems or make the plant droop. These signs may also show when the soil completely lacks water.\nAerate the soil before watering to allow it to breathe and make it easier for moisture to evaporate. Loosen up the soil particles using a stick as a way of aerating them.\nYou won’t need fertilizer when propagating pileas outdoors. However, you have to propagate them in the ideal growing zones for this exception to work in your favor.\nUse a specialized liquid fertilizer when propagating the cuttings in containers. Apply the compound at half strength and mix it correctly with the soil.\nBesides knowing the conditions for pilea propagation, it’s also important to understand the different pilea varieties. These varieties differ based on the size and shape of the leaves and their ability to spread. They include:\n- Pilea Microphylla – Also known as gunpowder plant, artillery plant, or rockweed, this plant features light green foliage with relatively tiny leaves.\n- Pilea Mollis – Also known as the “moon valley pilea,” this variety features sawtooth-edged chartreuse leaves. Their leaves have a deep texture that resembles the valleys and craters on the moon.\n- Pilea Nummularifolia (also known as creeping Charlie) – This pilea variety spreads fast and has medicinal benefits.\n- Pilea Cadierei – Commonly known as watermelon pilea or the aluminum plant, this variety has dark green, oval-shaped leaves with silver patches that give it a metallic look.\n- Pilea Peperomiodes – The Chinese money plant has round, coin-shaped, and dark green leaves on erect stems.\n- Locate Small Offsets\nYou’ll need small offsets for pilea propagation. Locate them at the base of the houseplant or below the central stalk.\nIf you can’t find any, give the plant some time to grow them. It usually takes two to three weeks for new offsets to sprout up from the base.\n- Cut an Offset from the Base\nOnce you locate the offsets, use a sterile blade to cut them at the base. Contaminated razors may transfer disease-causing organisms to the mother plant, leaving it vulnerable to withering or dying.\nLeave the mother plant with at least two offsets. If the blade gets stained, sanitize it before using it again.\n- Place the Cuttings in Water\nImmerse the cuttings in a jar or glass of water after extracting them from the mother plant. Place the shoot or stem in water leaving the leaves to hang freely in the air. Leaves tend to rot when submerged in water.\n- Give the Offsets Adequate Time to Grow\nStore the submerged offsets in an area with indirect bright light. Changing the positioning twice or thrice a week will help keep it fresh and the roots will start to sprout after two weeks.\n- Transfer the Plants in a Small Pot\nPlease wait until the plants’ roots grow to about an inch in length before transferring them to a small pot.\nThe pot should have fresh well-draining soil to support the young plants. Water the soil for a few weeks until shoots start appearing.\nThe Bottom Line\nSince they’re easy and quick to propagate, pileas are a great addition to every office or home. You’ll need a place with indirect bright light and well-draining potting soil for pilea propagation.\nIt’s also important to water the young plants moderately to avoid root rot. Keep fully grown pilea plants from small children and pets to avoid poisoning.\nPhoto by Markus Spiske on Unsplash', 'Are you a parent to pets and plants? We don’t blame you – they’re both great!\nPlants can really transform your yard, not only improving the aesthetics but even your resale value too! But pet owners must stick to dog-friendly plants to keep Spot safe.\nWe’ll share 23 of the best dog-friendly plants for your yard and provide some general dog-friendly landscaping tips below!\nPicking Plants for Your Yard: Things to Think About\nBefore you pick out some plants for your pooch-friendly yard, you’ll want to take the following into consideration:\n- Your USDA Hardiness Zone: The USDA provides a standard hardiness zone map providing growers with a general sense of what sorts of plants are likely to grow in a certain location. Some of the strongest plants can thrive amongst multiple zones, while others will only thrive in a narrow range of climates.\n- Sun Exposure: Sun exposure is one of the most crucial things to consider when picking plants for your yard. After all, you can tweak the soil or amount of water you provide, but you can’t change the amount of sunlight they’ll get very easily. So, just understand that some plants require more sun exposure than others, and be sure to pick out plants that align with your yard’s level of exposure.\n- Water Requirements: Not all plants require the same amount of water or the same watering schedule, so you need to consider the moisture requirements of the plants you choose. You can certainly do things like supply supplemental water, but it’s not very easy to remove moisture from the soil if you select plants adapted to arid regions.\n- Plant Durability: Pet parents are wise to opt for durable plants since your best buddy may bump into your favorite foliage while romping around the yard. If you do pick out delicate flowers, it may be worth installing them behind a fence or a border of more durable plants.\n- Fruit or Litter Problems: Many plants drop leaves or fruit – and some drop both. This can not only saddle you with extra cleanup chores, it can also present safety issues, For example, some plants may drop toxic fruit, while others may shed things that’ll represent trip hazards. So, just be sure to factor a tree or plant’s litter before making your selections.\n- Yard Aesthetics: This kind of goes without saying, but you’ll want to make sure your preferred plants pair well together and fit within your yard’s aesthetics. And keep in mind the way the plants will change over the course of the year – especially if you select deciduous species.\n- Special Properties: Certain dog-safe plants like catnip (Nepeta cataria) may act as a natural flea repellant in your yard. Dog repellent plants also exist, which may provide some value if installed in areas you want your dog to steer clear of. Not all owners notice a difference when growing these specialized plants, but they may be worth considering.\n- Periodic Maintenance: Some plants may require regular maintenance like pruning to maintain their health and appearance. This won’t only take time, but it may also mean that you’ll have to invest in the equipment necessary to keep them trimmed and looking their best.\n- Scientific Names: Many plants share the same common name, and some go by several different names. So, always double-check the scientific name for the plant (the weird looking, Latin-sounding name that is usually italicized) before bringing any home.\n23 Best Dog-Friendly Plants for Your Yard\nReady to break out your gardening gloves? Check out these 23 dog-friendly plants that are perfect for pet parents with green thumbs:\n1. Sunflower (Helianthus spp.)\nSunflowers are some of the cheeriest dog-friendly flowers out there. These plants are best grown in USDA hardiness zones 2 through 11, where they’ll often bloom in the summer and fall. Luckily, sunflowers are super hardy and will bloom in most soil types as long as they have enough water.\nThese flowers aren’t just beautiful additions to your gardens, they also feed and attract pollinators like bees which can help the rest of your flowers flourish.\n2. Dill (Anethum graveolens)\nDill is perfectly safe for dogs – it can even help freshen your dog’s bad breath. This plant is also self-sowing so you can expect it to return one year after another.\nYou can also use dill to make pickles and to season some of your favorite dishes. It’s a pretty hardy plant that can be grown in zone 2 through 11.\n3. Purple or Green Basil (Ocimum basilicum)\nPurple and green basil are both safe plants for dogs and cats. You mutt can even enjoy a small munch of this herb which provides anti-inflammatory benefits (it’ll also freshen her breath a bit like dill).\nBasil is typically grown in hardiness zones 10 and 11 and requires consistent temperatures above 50 degrees Fahrenheit. This herb is rich in Vitamins A and K, so be sure to incorporate it into some of your own dishes too!\n4. Bamboo (Phyllostachys aurea)\nBamboo is one of the strongest plants around, and it shoots up fairly quickly – it’s actually one of the fastest growing plants in the world (some sources claim that it is the fastest-growing plant). Since it’s a tall, fast-growing plant, it can also help provide some natural privacy between your yard and the neighbors.\nBamboo is also really hardy and doesn’t suffer from many pest problems. But this can actually be a bit of a problem – it sometimes grows a bit too well. So, you’ll want to keep an eye on your bamboo’s growth so that it doesn’t outcompete your other plants or invade your neighbor’s yard.\n5. Rosemary (Salvia rosmarinus)\nRosemary is a pawtastic perennial that is completely safe for furry friends. It thrives in zones 7 through 10, though some zone 6 growers have found success with the hardy plant.\nYou can also harvest this herb for your own cooking and enjoy the plant’s natural source of vitamin E. Rosemary can benefit from regular pruning, but it’s not needed for the survival of this low-maintenance plant.\n6. Thyme (Thymus spp.)\nDogs can safely enjoy small portions of thyme, and the plant is thought to repel some pests, including fleas, beetles, and tomato hornworms, making it an excellent companion plant.\nThyme grows best in zones 5 through 9, and it prefers full sun. Interestingly, this hardy plant can even thrive in gravel gardens, providing extra value for some homeowners. It’s also pollinator-friendly, so you can help the planet while decorating your yard.\n7. Forsythia (Forsythia spp.)\nIf you’re looking to add a pop of color to your garden, Forsythia is an excellent pick. This yellow dog-friendly shrub hails from parts of southern Europe and Asia, and it grows best in zones 5 through 9.\nForsythia tolerates most soil types, though it needs at least six hours of full sun to bloom its brightest. Also, note that this cheery plant often blooms in the early spring, which makes it a welcome sight after the long winter.\n8. Catnip (Nepeta cataria)\nCatnip is most famous for it’s intoxicating influence on felines, but it isn’t just safe for cats, it’s also safe for pups in small quantities and provides a good source of vitamin C. Just note that while it won’t make your dog loopy like it does cats, it can be a mild sedative for canines.\nCatnip thrives in zones 4 through 8 and blooms in late spring and early summer.\n9. Magnolia Trees (Magnolia spp.)\nMagnolia trees are absolutely beautiful plants and trees that are completely non-toxic to dogs. They bloom in the summer, and some produce gigantic white flowers you’ll be able to see from quite a distance.\nMagnolias are fairly flexible and can be trained to grow up a lattice propped against a wall. They’re also fast-growers which is perfect for impatient plant parents, and they thrive best in zones 7 through 10.\n10. Polka Dot Plant (Hypoestes phyllostachya)\nThe eye-catching polka dot plant thrives in zones 10 and 11 and prefers when the temperatures remain above 60 degrees Fahrenheit. Note that these plants need to be taken inside during the winter months, so they’re often grown in portable containers.\nBut that can actually be a bonus, as they make superb dog-friendly houseplants while waiting out the winter!\n11. Asters (Aster spp.)\nThe eye-catching aster comes in colors ranging from lilac to white. And you can feel free to pick out your favorite color – most aster varieties are considered non-toxic to our canine companions.\nAsters prefer full sun and can thrive in zones 4 through 11. These perky flowers serve as a natural food source for pollinators. In fact, they are a favorite of Monarch butterflies, so they are sure to beautify your yard in more ways than one.\n12. Black-Eyed Susan (Rudbeckia hirta)\nBlack-eyed Susans – which many people confuse with daisies, thanks to their similar structure – typically grow in large groups and can add a section of cheery yellow to your garden without too much effort.\nThese beautiful flowers are surprisingly robust, thriving in zones ranging from 3 through 10. Black-eyed Susans are full-sun plants that show their “face” during late summer.\n13. Fennel (Foeniculum vulgare)\nFennel is often grown in cooler climates and does well in zones 4 through 9. It’s also a food you can share with your dog in small quantities and serves as a great source of calcium, iron, and vitamin C (though your furry friend may not appreciate the licorice-like flavor).\nThis hardy perennial can survive through the winter, though it needs at least 6 hours of full sun to thrive.\n14. Roses (Rosa spp.)\nRoses are non-toxic to furry friends and surprisingly hardy, growing in zones 5 through 10. These flowers are perfect for DIY bouquets, though they also make beautiful bushes.\nNote that roses do have stem thorns that could potentially prick your pooch. You’ll want to train your dog to avoid your patch of roses or plant them in a place your pupper can’t access.\n15. Camellia (Camellia spp.)\nThe flowering Camellia trees and bushes are safe for dogs and are exceptionally hardy. These long-lived plants can live up to 100 years and grow up 25 feet tall, so be sure to plan their placement carefully.\nCamellia tends to thrive in zones 6 through 9 and has a delightfully long bloom season, actively flaunting flowers well into the fall.\n16. Hibiscus (Hibiscus spp.)\nIn most cases, Hibiscus is non-toxic to furry friends. Just note that one variety — Rose of Sharon (Hibiscus syriacus) – can be harmful and should be avoided. So, be sure to check the identification of the specimens you choose carefully\nWhile these flowers are gorgeous, they aren’t super hardy and are best planted in zones 10 through 12. Hibiscus flowers make great container plants and will give your garden a tropical feel.\n17. Coral Bells (Heuchera sanguinea)\nNeed some more “pop” in your yard? Well, coral bells can add a refreshing burst of color to your shrubbery, and they are non-toxic for furry friends! They’re also incredibly durable and can flourish in a wide range of light conditions and soil types.\nThese peppy plants are best grown in zones 4 through 9.\n18. Tickseed (Coreopsis californica)\nIf you’re seeking a low-maintenance, durable flower, check out tickseed! These beautiful blooms come in cream, pink, red, yellow, and green and are entirely dog-friendly.\nThese buds bloom best in hardiness zones 4 through 10 and attract plenty of butterflies, bees, and other helpful pollinators to boost your botanicals.\n19. Snapdragons (Antirrhinum spp.)\nSnapdragons are not only stunning, they’re annually self-seeding flowers, meaning that you can plant them once and enjoy them year after year.\nThese dog-friendly plants thrive in zones 7 through 10, and they come in a variety of colors, ranging from bronze to deep red. This will not only help spruce up your yard, but you can also cut the flowers and use them in bouquets!\n20. Nasturtium (Tropaeolum spp.)\nAre you seeking a vibrant plant to protect your garden? Check out the dog-friendly Nasturtium. These bright blooms are not only gorgeous, but they can also attract vital pollinators to your yard.\nNasturtium flowers grow in zones 9 through 11, but they’re somewhat flexible about their sun exposure, as they can thrive in full sun or partial shade.\n21. Fuchsias (Fuchsias spp.)\nFuchsias are vibrant flowering trees and bushes that also happen to be dog-friendly. You can also find climbing varieties of the plant to help decorate your garden.\nThese prized perennial plants are fairly hardy and grow best in zones 6 and 7.\n22. Banana (Musa spp.)\nBanana plants are often confused for trees, though they’re actually exceptionally hardy shrubs. These plants require a bunch of room, but they are dog-friendly and could probably withstand a romp or two from your canine companion.\nIt’s difficult to cultivate banana plants outside zone 10, but if you live in a warm climate and have plenty of room, these lush plants are sure to make you feel like you’re on vacation!\n23. Houseleeks (Sempervivum spp.)\nHouseleeks are hardy succulents that aren’t just dog-safe, they’re also able to withstand frost! These plants prefer growing zone 4 through 8, don’t require a ton of water, and are incredibly low-maintenance.\n3 Plants Pet Parents Should NEVER Plant: Dangerous Plants for Dogs\nIf you have a furry friend or live in a neighborhood populated by pooches, you should never plant the following toxic plants:\n1. Sago Palm (Cycas revoluta)\nUnfortunately, all parts of the beautiful sago palm plant are toxic to dogs. Symptoms of sago palm poisoning include vomiting, diarrhea, lethargy, nose bleeds, liver damage, paralysis, and seizures. The seeds of the palm plant are the most toxic and can negatively affect the gastrointestinal and nervous systems within minutes.\n2. Tulips (Tulipa spp.)\nTulips may be pretty, but they are toxic to both dogs and cats. These plants can cause drooling, vomiting, and diarrhea if ingested. While all parts of tulips contain toxins, the bulbs are the most concentrated, and therefore the most dangerous.\n3. Oleander (Nerium oleander)\nOnly a small ingested portion of this beautiful flower can be toxic – even deadly to dogs and cats. Some clinical signs of poisoning include excessive drooling, diarrhea, lethargy, low blood sugar, and abnormal changes in heart rate.\nIf your pet ingests any of these plants, head to the nearest emergency veterinary clinic immediately for further care.\nGeneral Dog-Friendly Landscaping Tips\nKeeping your garden in tip-top shape with a furry friend isn’t always easy, but there are ways to make your gardening experience easier as a pet parent. Consider some of the following dog-friendly landscaping tips while tending to your yard.\n- Use pet-safe fertilizers and weed killers. If you can, it’s best to practice organic gardening for the sake of your furballs. However, sometimes you need something to safely eliminate undesirable plants or help give them nutrients that they need. Unfortunately, many commercial weed killers and some fertilizers can be toxic to dogs, so be sure to opt for pet-safe weed killers or dog-safe fertilizers instead.\n- Create a non-traditional garden. Unfortunately, grass can become pretty patchy when exposed to dog urine. You can help protect your plants by choosing an alternative, like a clover lawn. As a bonus, clover provides food for bumblebees!.\n- Opt for durable plants and grasses. Dogs can unintentionally cause a lot of damage while enjoying the yard, so it’s best to seek out one of the best grasses for dogs, which will be able to withstand a little mutt mayhem. If you do have delicate plants, consider hanging baskets or growing them in an area your dog can’t access.\n- Make a path for your pooch. Your dog is less likely to trample over your plants if he has a separate area where he can safely run around. Make a path for your pooch that keeps your most delicate flowers at a distance.\n- Consider installing a fence. Dog-proof fencing makes it easier for Fido to enjoy the great outdoors and can help protect your plants. There are plenty of DIY fence options too for savvy pet parents.\nThese dog-friendly plants are absolutely beautiful and will most importantly, keep your canine companion safe! While these plants are pooch-approved, it’s still important that you prevent your pooch from snacking on your vegetation. Have fun growing a dog-safe garden!\nDoes you love pups and plants equally? Which dog-friendly plant was your favorite? Tell us all about it in the comments below!']	['<urn:uuid:df661730-2019-4cec-b3df-40798f3d119d>', '<urn:uuid:f92b3101-820e-49b8-875e-56d0107344de>']	factoid	with-premise	long-search-query	similar-to-document	multi-aspect	novice	2025-05-12T15:09:02.012753	8	66	3797
100	dust map size vs zaha hadid building complexity	While Counter-Strike's Dust map was relatively small and simple due to 1990s processor limitations, Zaha Hadid's buildings like the Heydar Aliyev Center were known for their complex, fluid spaces with unexpected and dynamic architectural forms.	"['It might be easy to question the logic of building a 1:1 scale model of a Counter-Strike map out in the desert (read: life-size!). But for Aram Bartholl, this is a natural progression of his work that explores the permeable line between online and offline worlds. What\'s even more remarkable is that he\'s been doing this since before social media became our zeitgeist.\nDust, which will be built this year with a commission from Rhizome, goes beyond elevating popular culture into the realm of art. Bartholl’s project questions the physical nature of reality and highlights the moment of discomfort that occurs when something in the digital world infiltrates real space. In a 2004 public installation, Bartholl made replicas of the recognizable wooden crates from Counter-Strike’s “de_dust” (or “Dust”) map, highlighting their change in function from a packing medium in real life to a strategic and spatial mechanism for a competitive shooter. At the same time however, like the environment of “Dust” itself, the crates were ""generic, duplicatable and locationless,"" underscoring the repetitive elements of game design.\nIn 2006, Bartholl began dropping oversized Google Map markers—a signifier of our tech-enabled lives—into real spaces. In doing so he whimsically acknowledged the revolutionary shift Google has placed on how we perceive location, something the company would later repeat with architecture (Google 3D), cities (Google Street View), and now building interiors (Google Interior View). “The goal of the Google Map intervention is to elicit an unsettling feeling,” Bartholl says. “You know [the Google Map marker] so well, but it doesn\'t belong there.” In 2010’s Dead Drops, USB sticks embedded into walls required you to physically attach your laptop to access and share files. Bartholl says Dead Drops was partially about making it an ""adventure to go back outside,"" reviving the surprise of not knowing what you will find.\nDust takes this all further: it’s about placing you into the online world, but in a physically real place. It’s a reversal of the Google Marker—you may know the space of Dust well, but you don\'t belong there. The project is ultimately less about identity or belonging, however, than a shared experience in popular culture. At the height of its popularity, “Dust” was the most-played first-person shooter map in the world.\nIs Counter-Strike’s “Dust,” tested and tweaked repeatedly for navigability, lines of sight, and timing, actually more real than today\'s generic retail megaprojects or cities like Dubai?\n""So many people have been to the same worlds in computer games that it becomes cultural heritage at some point … and why not build a museum or memorial to space which only exists on computer screens?"" he asks. Dust also marks a certain moment in the evolution of videogames. In his Rhizome proposal, Bartholl writes that unlike games today, with their endless terrain, ""game spaces of the 1990s were still limited in size due to graphic card and processor power limitations. A respectively small and simple map like ‘de_dust’ offered a high density of team play with repetitive endless variations.""\nFinally, Dust is a commentary on the artificiality of real spaces. Is Counter-Strike’s “Dust,” tested and tweaked repeatedly for navigability, lines of sight, and timing, actually more real than today\'s generic retail megaprojects or cities like Dubai?\nUnlike elsewhere in the online world, Bartholl says that in a game space, ""space becomes a very present quality. There\'s a plot but you\'re free to go in many directions. You have to figure out where to go, and once you\'ve been at that space, you remember it."" Furthermore, it\'s more difficult to passively take in cues because we\'re viewing on a 2D plane. As such, ""architecture is a very important quality in that it controls the game very much. You need to recall every centimeter in these game maps,"" Bartholl says. Equally fascinating is reading about the creation of “Dust” from its designer David Johnston, who admits the map was a combination of ""thievery and luck,"" inspired by screenshots from the then-unreleased Team Fortress 2 and built one room at a time.\nBartholl also sees a lot of cliched architecture in game design, citing World of Warcraft, and doesn\'t feel that gaming architecture has kept up with the development of its action dynamics. ""I\'m still waiting for the point where \'realism\' has been achieved and games become more abstract again,"" he says . To that end, Dust isn\'t going to be an exact replica of the game map—it\'s going to be deliberately constructed from concrete, without any distinctive colors or textures, to create that level of abstraction.\nHis hope is that gaming may have a real place in high culture. Bartholl would love to see a famous architect like Zaha Hadid designing videogames. Currently building models for Dust at different scales with architects and engineers, he hopes to set it up in a remote place—in the desert in Saudi Arabia or China. He wants people to have to travel to see Dust, and hopes the site can ""become a mecca, a quasi-religious place for the gaming scene.""\nBlock Quotes covers the architecture of videogames and their relationship with the real world (and vice-versa). Michelle Young is the founder of Untapped Cities, a website about urban architecture and design.\nPhotograph by Aram Bartholl', 'The British designer, born in Iraq, has designed some of the world’s most famous buildings like the Sleuk Rith Institute and Heydar Aliyev Center. Zaha was the first woman to receive the Royal Institute of British Architects Gold Medal.\nA very sad day for the architecture fraternity.\nArchitect Daniel Libeskind has led the tributes following Zaha’s passing on. He posted on Twitter:\nDevastated by the loss of a great architect & colleague today. Her spirit will live on in her work and studio. Our hearts go out. #zahahadid\n— Studio Libeskind (@DanielLibeskind) 31 March 2016\nArchitect Zaha Hadid was also the first woman to ever win the Pritzker Prize. Her building, Heydar Aliyev Centre won the Design Museum Design of the Year Award in 2014, also making her the first woman to win the top prize in that competition.\nHer company, Zaha Hadid Architects, just released the following lengthy statement in which they explain that she contracted bronchitis in the early hours of the morning, but passed on following a sudden heart attack in a Miami hospital:\nZAHA HADID 1950-2016\nIt is with great sadness that Zaha Hadid Architects have confirmed that Dame Zaha Hadid, DBE died suddenly in Miami in the early hours of this morning. She had contracted bronchitis earlier this week and suffered a sudden heart attack while being treated in hospital.\nZaha Hadid was widely regarded to be the greatest female architect in the world today. Born in Baghdad in 1950, she studied mathematics at the American University of Beirut before starting her architectural journey in 1972 at the Architectural Association in London.\nBy 1979 she had established her own practice in London – Zaha Hadid Architects – garnering a reputation across the world for her ground-breaking theoretical works including The Peak in Hong Kong (1983), the Kurfürstendamm in Berlin (1986) and the Cardiff Bay Opera House in Wales (1994).\nWorking with office partner Patrik Schumacher, her interest was in the interface between architecture, landscape, and geology; which her practice integrates with the use of innovative technologies often resulting in unexpected and dynamic architectural forms.\nZaha Hadid’s first major built commission, one that affirmed her international recognition, was the Vitra Fire Station in Weil Am Rhein, Germany (1993); subsequent notable projects including the MAXXI: Italian National Museum of 21st Century Arts in Rome (2009), the London Aquatics Centre for the 2012 Olympic Games (2011) and the Heydar Aliyev Centre in Baku (2013) illustrate her quest for complex, fluid space. Buildings such as the Rosenthal Center for Contemporary Art in Cincinnati (2003) and the Guangzhou Opera House in China (2010) have also been hailed as architecture that transforms our ideas of the future with visionary spatial concepts defined by advanced design, material and construction processes.\nIn 2004, Zaha Hadid became the first woman to be awarded the Pritzker Architecture Prize. She twice won the UK’s most prestigious architecture award, the RIBA Stirling Prize: in 2010 for the MAXXI Museum in Rome, a building for the staging of 21st century art, the distillation of years of experimentation, a mature piece of architecture conveying a calmness that belies the complexities of its form and organisation; and the Evelyn Grace Academy, a unique design, expertly inserted into an extremely tight site, that shows the students, staff and local residents they are valued and celebrates the school’s specialism throughout its fabric, with views of student participation at every turn.\nZaha Hadid’s other awards included the Republic of France’s Commandeur de l’Ordre des Arts et des Lettres, Japan’s Praemium Imperiale and in 2012, Zaha Hadid was made a Dame Commander of the Order of the British Empire. She was made Honorary Member of the American Academy of Arts and Letters and Fellow of the American Institute of Architecture.\nShe held various academic roles including the Kenzo Tange Chair at the Graduate School of Design, Harvard University; the Sullivan Chair at the University of Illinois, School of Architecture. Hadid also taught studios at Columbia University, Yale University and the University of Applied Arts in Vienna.\nZaha Hadid was recently awarded the RIBA’s 2016 Royal Gold Medal, the first woman to be awarded the prestigious honour in her own right.\nDetails of Zaha Hadid’s memorial service will be announced shortly.']"	['<urn:uuid:1674eab6-5751-49b8-bdaf-a0b3d1069132>', '<urn:uuid:e5bc8e61-a903-4249-969c-6a5bc0a656c8>']	factoid	direct	short-search-query	similar-to-document	comparison	expert	2025-05-12T15:09:02.012753	8	35	1578
